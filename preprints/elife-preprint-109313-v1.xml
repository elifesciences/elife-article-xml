<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">109313</article-id>
<article-id pub-id-type="doi">10.7554/eLife.109313</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.109313.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories><title-group>
<article-title>Linear and categorical coding units in the mouse gustatory cortex drive population dynamics and behavior in taste decision-making</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5606-6370</contrib-id>
<name>
<surname>Lang</surname>
<given-names>Liam</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Zheng</surname>
<given-names>Camelia Yuejiao</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="author-notes" rid="n1">†</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Blackwell</surname>
<given-names>Jennifer M</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="author-notes" rid="n1">†</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7834-6472</contrib-id>
<name>
<surname>Camera</surname>
<given-names>Giancarlo La</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a4">4</xref>
<email>giancarlo.lacamera@stonybrook.edu</email>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4561-9563</contrib-id>
<name>
<surname>Fontanini</surname>
<given-names>Alfredo</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
<email>alfredo.fontanini@stonybrook.edu</email>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05qghxh33</institution-id><institution>Department of Neurobiology and Behavior, Stony Brook University</institution></institution-wrap>, <city>Stony Brook</city>, <country country="US">United States</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05qghxh33</institution-id><institution>Graduate Program in Neuroscience, Stony Brook University</institution></institution-wrap>, <city>Stony Brook</city>, <country country="US">United States</country></aff>
<aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05qghxh33</institution-id><institution>Medical Scientist Training Program, Stony Brook University</institution></institution-wrap>, <city>Stony Brook</city>, <country country="US">United States</country></aff>
<aff id="a4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05qghxh33</institution-id><institution>Center for Neural Circuit Dynamics, Stony Brook University</institution></institution-wrap>, <city>Stony Brook</city>, <country country="US">United States</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Kahnt</surname>
<given-names>Thorsten</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>National Institute on Drug Abuse Intramural Research Program</institution>
</institution-wrap>
<city>Baltimore</city>
<country country="US">United States</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Gold</surname>
<given-names>Joshua I</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/00b30xv10</institution-id><institution>University of Pennsylvania</institution>
</institution-wrap>
<city>Philadelphia</city>
<country country="US">United States</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="equal"><label>†</label><p>These authors contributed equally to this work</p></fn>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-12-12">
<day>12</day>
<month>12</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP109313</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-10-06">
<day>06</day>
<month>10</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-10-07">
<day>07</day>
<month>10</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.10.06.680705"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Lang et al</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Lang et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-109313-v1.pdf"/>
<abstract>
<p>Cortical circuits produce time-varying patterns of population and single neuron activity that play a fundamental role in perceptual and behavioral processes. However, the functional contributions of individual neuron activity to population dynamics and behavior remain unclear. Here we addressed this issue focusing on the mouse gustatory cortex (GC) and using a taste mixture-based decision-making task, high-density electrophysiology, and computational modeling. GC population dynamics represented stimuli linearly during taste sampling and choices categorically before decisions. Single neurons were classified by their linear and categorical activity patterns, revealing subpopulations encoding sensory, perceptual, and decisional variables. To test their functional role, we built a recurrent neural network model of GC. Model perturbations showed linear and categorical neurons were essential for driving normal population dynamics and behavioral performance, whereas many units with other activity patterns could be silenced without consequence. These results have implications that extend beyond GC, and demonstrate the role of linear and categorical coding neurons in cortical dynamics and behavior during perceptual decision-making.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>

</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Cortical circuits produce time-varying patterns of population and single neuron activity that play a fundamental role in perceptual and behavioral processes (<xref ref-type="bibr" rid="c51">Shuler and Bear, 2006</xref>; <xref ref-type="bibr" rid="c16">Guo et al., 2014b</xref>; <xref ref-type="bibr" rid="c5">Buetfering et al., 2022</xref>). Over the past decade, the gustatory cortex (GC) has emerged as a model for studying such cortical dynamics (<xref ref-type="bibr" rid="c1">Arieli et al., 2022</xref>; <xref ref-type="bibr" rid="c30">Livneh et al., 2020</xref>; <xref ref-type="bibr" rid="c31">Mahmood et al., 2025</xref>; <xref ref-type="bibr" rid="c55">Vincis et al., 2020</xref>; <xref ref-type="bibr" rid="c56">Vincis and Fontanini, 2016</xref>). Population and single neuron activity in GC show characteristic time-varying modulations encoding multiple variables associated with a gustatory experience. Early studies on GC dynamics provide evidence for three temporal epochs following intraoral delivery of tastants in rats. Right after taste delivery, GC neurons encode the somatosen-sory component of the stimulus hitting the tongue. After a few hundred milliseconds, neurons be-gin to encode the chemical identity of the tastant and, ultimately, its palatability (<xref ref-type="bibr" rid="c20">Katz et al., 2001</xref>). A similar sequence of activity has been described also in the GC of mice actively sampling tastants by licking a spout (<xref ref-type="bibr" rid="c4">Bouaichi and Vincis, 2020</xref>). These dynamics are not limited to the processing of taste; GC can also represent signals related to expectation (<xref ref-type="bibr" rid="c35">Mazzucato et al., 2019</xref>; <xref ref-type="bibr" rid="c28">Livneh and Andermann, 2021</xref>) and decision-making (<xref ref-type="bibr" rid="c55">Vincis et al., 2020</xref>; <xref ref-type="bibr" rid="c24">Lang et al., 2023</xref>).</p>
<p>Recent work relying on delayed response decision-making paradigms shows that populations as well as single neurons in GC can sequentially encode sensory, perceptual, and decisional variables. Head restrained mice were trained in a two-alternative choice (2AC) task (<xref ref-type="bibr" rid="c15">Guo et al., 2014a</xref>; <xref ref-type="bibr" rid="c6">Churchland and Ditterich, 2012</xref>) to sample gustatory stimuli, wait during a delay period, and lick either a left or a right spout based on specific taste-direction associations. In the context of this task, GC activity progresses from taste-coding during the sampling period to representing the licking direction predicted by each taste during the delay period (<xref ref-type="bibr" rid="c55">Vincis et al., 2020</xref>; <xref ref-type="bibr" rid="c24">Lang et al., 2023</xref>). Consistent results were observed in a similar task relying on taste mixtures to guide directional licking decisions. Two-photon calcium imaging has revealed that GC activity first encodes mixture components linearly and then, during the delay period, represents the binary decision to lick left or lick right (<xref ref-type="bibr" rid="c22">Kogan and Fontanini, 2024</xref>).</p>
<p>These dynamics are not epiphenomenal, as perturbations of neural activity at specific times in the trial interfere with ingestive behaviors as well as taste-guided decision-making. For instance, silencing GC during the palatability epoch delays the onset of aversive reactions to taste (<xref ref-type="bibr" rid="c41">Mukherjee et al., 2019</xref>). In a 2AC task, silencing GC during the delay period affects task performance (<xref ref-type="bibr" rid="c55">Vincis et al., 2020</xref>). The importance of these dynamics has therefore spurred extensive investigations of their underlying mechanisms. Spiking network models have unveiled architectural features that are sufficient for producing population dynamics matching those seen in GC during taste-processing, expectation, and decision-making (<xref ref-type="bibr" rid="c39">Miller and Katz, 2010</xref>; <xref ref-type="bibr" rid="c36">Mazzucato et al., 2015</xref>, <xref rid="c37" ref-type="bibr">Mazzucato et al., 2016</xref>, <xref rid="c35" ref-type="bibr">Mazzucato et al., 2019</xref>; <xref ref-type="bibr" rid="c24">Lang et al., 2023</xref>). Furthermore, these studies have provided important information on how perturbing activity during different temporal epochs can impact behavior (<xref ref-type="bibr" rid="c24">Lang et al., 2023</xref>). Yet, as important as this work has been in advancing our understanding of cortical dynamics, many questions remain unanswered. The relationship among individual neuron activity patterns, population-level dynamics, and behavioral outcomes has yet to be fully elucidated. Most critically, we still do not understand how neurons encoding specific task features contribute to population dynamics and influence overall performance.</p>
<p>Previous computational studies were not designed to investigate the role of specific single neuron firing patterns as both network connectivity and the contribution of functional groups of neurons were established <italic>a priori</italic> and tuned to obtain the desired dynamics and behavior. In this study we overcome the limitations of previous approaches by combining high-density behavioral electrophysiology (<xref ref-type="bibr" rid="c19">Jun et al., 2017</xref>) with recurrent neural network (RNN) modeling (<xref ref-type="bibr" rid="c8">Cohen et al., 2020</xref>; <xref ref-type="bibr" rid="c54">Valente et al., 2022</xref>). Specifically, we recorded ensembles of GC neurons in mice performing a taste mixture directional task analogous to the task used by <xref ref-type="bibr" rid="c22">Kogan and Fontanini (2024</xref>). Population analyses revealed a progression from linear encoding of taste concentrations to categorical prospective encoding of directional licking decisions. Guided by population dynamics, we identified single units that either encoded taste concentration linearly, or task events categorically. A subpopulation of neurons linearly tracked the concentration of the components in the mixture, while others categorically encoded the prevailing taste quality or the imminent licking direction. Linear coding of the stimulus was more predominant early on, following taste sampling, while categorical coding of licking direction was more pronounced later in the trial, before lateral licking. Categorical coding of taste quality was present, albeit in small percentage, throughout the period from sampling to lateral licking. To test the functional significance of single neuron firing patterns, we trained an RNN on both the recorded neural activity and the behavioral performance of the mice for each session. A fraction of the network’s units were trained to match the firing activity of recorded single units, while the rest of the units were free from constraints during training. All the single units recorded in an individual session were fed to the network to ensure that the RNN would not be biased toward linear or categorical patterns or any experimenter-selected feature. After training, the RNNs exhibited linear and categorical patterns in both their constrained and unconstrained units. We explored the performance of the RNNs after systematically removing units showing specific patterns that had emerged during training. The simulations revealed that linear coding neurons as well as categorical neurons representing both perceptual and decisional variables were necessary for driving realistic population dynamics and behavioral performance, while a large fraction of the units, exhibiting different patterns of activity, could be silenced without consequence for performance.</p>
<p>Altogether, the results presented here demonstrate the functional significance of specific single neuron firing patterns observed in GC during a taste mixture 2AC task and establish an approach that successfully relates population-level dynamics, individual neuron activity patterns, and behavioral outcomes. Furthermore, since these dynamics are not unique to GC, but have been observed in a variety of cortical circuits (<xref ref-type="bibr" rid="c14">Goltstein et al., 2021</xref>; <xref ref-type="bibr" rid="c42">Niessing and Friedrich, 2010</xref>; <xref ref-type="bibr" rid="c47">Reinert et al., 2021</xref>), our work provides insights that generalize far beyond taste.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Behavioral task and electrophysiological recordings</title>
<p>Thirteen mice were tested on a binary sucrose/NaCl mixture-based perceptual decision-making task (<xref rid="fig1" ref-type="fig">Figure 1A</xref>). The task design is based on a two-alternative choice (2AC) paradigm (<xref ref-type="bibr" rid="c15">Guo et al., 2014a</xref>; <xref ref-type="bibr" rid="c6">Churchland and Ditterich, 2012</xref>; <xref ref-type="bibr" rid="c22">Kogan and Fontanini, 2024</xref>). Briefly, mice were trained to sample either sucrose (100 mM) or NaCl (100 mM) from a central spout (for ~0.9 s), wait for a delay period (~3.0 s), then lick one of two lateral spouts according to the task policy (e.g., sucrose → lick left; NaCl → lick right). Taste-side pairings were counterbalanced across subjects. Correct lateral licks were rewarded with a drop of water from the lateral spout. The delay period—important for temporally separating the sensory and cognitive processing during this task—was implemented such that the average time between the first lick to the central spout (time point “T”) and the first lick to a lateral spout (time point “D”) was ~3.9 s. Upon reaching criterion for discriminating sucrose from NaCl (i.e., 85% correct performance for three days in a row), mice were tested with the following mixtures (expressed in %Sucrose/%NaCl): 0/100, 25/75, 35/65, 45/55, 55/45, 65/35, 75/25, or 100/0. If the mixture was predominantly NaCl, mice had to lick on the side that was trained to be associated with NaCl; if it was predominantly sucrose, mice had to lick on the sucrose side.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Experimental paradigm.</title>
<p><bold>A</bold>: Schematic of the behavioral task. The blue rectangle indicates the temporal window over which all analyses were conducted, from 1 s before the first central lick, T, to 1 s after the first lateral lick, D. <bold>B</bold>: Psychometric curve averaged across sessions and subjects. Circles and error bars represent mean ± s.e.m. (<italic>N</italic> = 23 sessions across 13 subjects) for the probability of a choice in the sucrose-associated direction for each stimulus value; the continuous curve is a sigmoidal curve fit to the means. <bold>C</bold>: Schematic of acute probe insertion. <bold>D</bold>: Example histological section indicating accurate probe placement in GC (blue: Hoechst; yellow: DiI applied to probe). <bold>E</bold>: Example spike raster plot for neurons simultaneously recorded within a single session from GC of behaving mice.</p></caption>
<graphic xlink:href="680705v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Mice were tested on this task up to 3 times each (average ~1.8 sessions per animal), resulting in a total of 23 sessions. Mice performed an average of 137 trials per test session (range: 65 to 195) with an average overall accuracy of 77.2 ± 4.3% (range: 69.7% to 86.2%). As expected, performance was near chance level for difficult discriminations (average 56.9 ± 8.9% over sessions for 45/55 and 55/45 trials) and well above it for easy discriminations (average 93.1 ± 3.5% over sessions for 0/100 and 100/0 trials). The psychometric curve for session-averaged performance is plotted in <xref rid="fig1" ref-type="fig">Figure 1B</xref>. Just before each testing session, high-density Neuropixels probes were acutely inserted in the GC so that single unit electrophysiological recordings could be obtained during performance of the test (<xref rid="fig1" ref-type="fig">Figure 1C-E</xref>). Electrode positioning was reconstructed histologically upon the termination of the experiment. A Python-based GUI for Histological E-data Registration in Brain Space was used to register the slice images onto the Allen CCF mouse atlas (<xref ref-type="bibr" rid="c12">Fuglstad et al., 2023</xref>). <xref rid="figS1" ref-type="fig">Figure S1</xref> shows the reconstructed positioning of the probes. All channels were sorted, but only those mapped within GC were used for analysis. Simultaneously recorded GC ensembles had an average size of ~27 neurons (range: 7 to 68), for a total of 626 neurons across all sessions.</p>
</sec>
<sec id="s2b">
<title>Population dynamics during mixture-based decision-making</title>
<p>To assess the involvement of GC in representing different events within a taste mixture 2AC task, we analyzed task-related, population firing activity. We used a “warped” time scale to allow for consistent analysis of dynamics with respect to multiple behavioral events of interest that have trial-to-trial variability. Each neuron’s peristimulus time histograms (PSTHs) were constructed by aligning spike trains to the first central lick T, warping each trial’s duration between first central and lateral lick to the overall average (~3.9 s), calculating firing rates in ~50 ms bins, averaging over correct trials of each mixture separately, and smoothing with Gaussian kernels. Visual inspection of the population PSTH averaged across all recorded neurons and for all stimuli (<xref rid="fig2" ref-type="fig">Figure 2A</xref>) revealed increases in firing rates aligned with the central and lateral licks. To identify when populations of GC neurons discriminate between trial types (correct predominantly-sucrose vs correct predominantly-NaCl trials), we computed auROCs and measured differences in firing rate distributions between the two types of trials (<xref rid="fig2" ref-type="fig">Figure 2B</xref>). Neurons could maximally discriminate between correct sucrose and NaCl trial types at all time points (white dots), with noticeable concentrations of differential activity around T and D (white traces overlaid on the heatmaps are neuron-averaged auROCs). When separating neurons based on whether their peak differential activity was in favor of predominantly-sucrose or predominantly-NaCl mixtures, we found no significant difference between the number of neurons that “preferred” one to the other (306 vs 320; 2-tailed binomial test, <italic>p</italic> = 0.548). Though there were slight qualitative differences between mean auROC traces, they had similar peaks during sampling (0.062 for NaCl-preferring, 0.052 for sucrose-preferring) and postdecision (0.077 for NaCl-preferring, 0.075 for sucrose-preferring). Moreover, the distribution of peak auROCs was not different between NaCl- and sucrose-preferring neurons (rank-sum test, <italic>p</italic> = 0.789).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Population activity and information encoding during taste mixture-based decision-making.</title>
<p><bold>A</bold>: Population PSTH (<italic>N</italic> = 626). Vertical dashed lines indicate the first central (T) and lateral licks (D), respectively. The trace represents mean firing rate; shading represents s.e.m. <bold>B</bold>: Population heatmaps for single unit differential activity between correct predominantly-sucrose and correct predominantly-NaCl trials. White dots indicate each unit’s time of peak differential activity. Traces are ordered by peak time and separated by whether peak differential activity is in favor of NaCl (“NaCl-preferring”) or sucrose (“Sucrose-preferring”). White trace is the mean auROC across neurons. <bold>C-D</bold>: Decoding of task-relevant variables. For each session (grey trace), accuracy is plotted over time with colored shaded traces representing the mean ± s.e.m. over sessions. Trial labels to be decoded were mixtures (<bold>C</bold>) and choice (<bold>D</bold>). Horizontal solid line represents theoretical chance level. Horizontal dashed line represents theoretical significant decoding threshold (<italic>α</italic> = 0.01). Vertical dashed lines represent the first central and lateral licks, respectively.</p></caption>
<graphic xlink:href="680705v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To assess how such task-related firing encoded task variables (e.g., stimuli and decisions), we trained classifiers to decode stimulus and choice variables from activity vectors for each ensemble of simultaneously recorded neurons (23 ensembles with a median size of 27 neurons). For each recording session, all trials were labeled according to the delivered stimulus (8 possible labels depending on the mixture) and whether the animal chose the left or right lateral spout. At each time point, a decoder then predicted a label for each trial as the label whose trial-averaged activity vector was nearest (in terms of Euclidean distance) to the activity vector of the trial in question.</p>
<p>Session-averaged decoding for both stimulus and choice was significantly above chance throughout the period between taste delivery and reward; however, the dynamics differed significantly (2-way within-subjects ANOVA with factors time [sampling/delay] and decoded variable [stimulus/choice]; interaction <italic>p</italic> &lt; 0.001). Stimulus decoding peaked at 31.0% ~425 ms after stimulus delivery (<xref rid="fig2" ref-type="fig">Figure 2C</xref>), while choice decoding also rose with stimulus delivery but ramped before the lateral leaks and peaked at 81.9% ~75 ms after the decision time (<xref rid="fig2" ref-type="fig">Figure 2D</xref>).</p>
<p>To further assess response dynamics, population activity trajectories across different trial types were analyzed with both unsupervised and supervised dimensionality reduction techniques. For the unsupervised method, we calculated pairwise Euclidean distances in 626-dimensional neural space between all stimulus types and time points (<xref rid="fig3" ref-type="fig">Figure 3A</xref>). We then used a t-distributed stochastic neighbor embedding (t-SNE) to non-linearly map the neural data into a 2-dimensional space while attempting to preserve the true distance structure (<xref rid="fig3" ref-type="fig">Figure 3B</xref>). Notably, activity trajectories diverged at the time of taste delivery according to stimulus type, with more distant stimuli (e.g., 0/100 vs 100/0) corresponding to more distant neural activities and more similar stimuli (e.g., 45/55 vs 55/45) corresponding to closer neural activities. The trajectories then binarized according to stimulus choice, with a large distance between trials predicting different licking directions regardless of exact stimuli. To separate the components associated with the stimulus from those associated with the choice, we employed a demixed principal component analysis (dPCA; <xref ref-type="bibr" rid="c21">Kobak et al., 2016</xref>) and found the dimensions of maximal data variance with respect to stimulus- and choice-specific variance. The projection of the population activity onto the principal stimulus component (<xref rid="fig3" ref-type="fig">Figure 3C</xref>) shows a monotonic, linear separation of activity according to mixture, irrespective of the ultimate choice (note how each average error trial trajectory, the dotted lines, overlaps with its average correct trial trajectory, the solid lines). In contrast, the projection of population activity onto the principal choice component (<xref rid="fig3" ref-type="fig">Figure 3D</xref>) shows a binary separation of activity according to upcoming choice irrespective of mixture (note how average error trial trajectories for predominantly-sucrose mixtures overlap with average correct trial trajectories for predominantly-NaCl mixtures, and vice versa). The time courses of the projected activities suggest that a binarization of activity according to selected choice emerges just before lateral licking as the graded stimulus-based activity slowly collapses.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Low-dimensional population activity trajectories.</title>
<p><bold>A</bold>: Euclidean distances between pairs of trial-averaged pseudo-population activity trajectories. <bold>B</bold>: t-SNE of trial-averaged pseudo-population trajectories for all stimuli (%Sucrose/%NaCl) based on pairwise Euclidean distances between activities. <bold>C</bold>: One-dimensional linear projections of trial-averaged pseudo-population trajectories onto the demixed principal component explaining maximum stimulus-specific variance. Solid lines are correct trial averages; dotted lines are incorrect trial averages. <bold>D</bold>: Same as <bold>C</bold>, but for the demixed principal component explaining maximum choice-specific variance. T: time of first central lick; D: time of first lateral lick.</p></caption>
<graphic xlink:href="680705v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>In summary, population analyses show a linear representation of taste mixture information toward the beginning of the trial and a categorical representation of decisions toward the end.</p>
</sec>
<sec id="s2c">
<title>Single unit responses during mixture-based decision-making</title>
<p>Upon observing that population activity can represent task variables either in a linear or binary fashion, we investigated whether such representations might also be found at the level of single units. A response profile analysis was performed. To extract a response profile (essentially a tuning curve) a neuron’s firing rate in a specified time window was averaged over correct trials of a particular stimulus and plotted as a function of the mixture. Two temporally separated windows of interest, [T, T + 500 ms] and [D – 500 ms, D], were chosen and, for each, the single unit response profiles for all neurons were constructed. Profiles were assigned a label, “linear” or “step”, after a least-squares regression statistically determined the shape that fit the profile best (if neither fit was significant, it was assigned the “other” label; see <bold>Methods: Response profiles</bold>). The shape templates were chosen based on previous published work (<xref rid="c22" ref-type="bibr">Kogan and Fontanini, 2024</xref>; <xref rid="c33" ref-type="bibr">Maier and Katz, 2013</xref>), with linear fits representing response profiles that track the concentration of one of the components in the mixture and step fits representing response profiles that change abruptly at the 50/50 mixture. <xref rid="fig4" ref-type="fig">Figure 4A</xref> shows examples of linear (left) and step (middle, right) single unit response profiles (bottom), as well as these neurons’ corresponding PSTHs (top).</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Classification of single unit coding types.</title>
<p><bold>A</bold>: Representative single unit PSTH (top) and response profiles (bottom) exemplifying the different coding types within a time window (grey bar, top): linear (left), step-perception (middle), and step-choice (right). Step-perception (middle) and step-choice (right) types were disentangled by comparing correct trials to error trials (dashed lines in bottom plots). Color scale corresponds to different mixture stimuli (%Sucrose/%NaCl). <bold>B</bold>: Visualization of each neuron’s coding type label (vertical axis) between two time windows (horizontal axis). Each neuron is a point in both windows, with lines connecting the same neurons. T: time of first central lick; D: time of first lateral lick. <bold>C</bold>: Distribution of coding types across all neurons (pooled over all sessions) over time. For each time point (a window ~200 ms wide), the coding type classification analysis depicted in <bold>A</bold> was applied to each neuron.</p></caption>
<graphic xlink:href="680705v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Step coding neurons could represent either a perceptual category (i.e., sweet vs salty) independently of concentration and licking direction, or the imminent licking direction independently of the stimulus. To disambiguate these options we analyzed error trials—that is, trials in which a mouse received a mixture and licked toward the wrong direction. If a step coding neuron had an average firing rate that was consistently elevated for trials where the same choice was taken, regardless of stimulus, the neuron was defined as a “step-choice” neuron (<xref rid="fig4" ref-type="fig">Figure 4A</xref>, right). On the contrary, if a step coding neuron had an average firing rate that was elevated for trials where the same stimulus was presented, regardless of the choice, the step coding neuron was considered a “step-perception” neuron (<xref rid="fig4" ref-type="fig">Figure 4A</xref>, middle).</p>
<p>Comparing the first 500 ms of the sampling period to the last 500 ms of the delay period, there was a similar proportion of neurons whose response profile could be significantly fit by either linear or step functions (6.5%, 41/626 for the first 500 ms vs 9.4%, 59/626 for the last 500 ms, Chisquared <italic>p</italic> = 0.061) (<xref rid="fig4" ref-type="fig">Figure 4B</xref>). It is worth noting that neurons with no significant fits could still show significant responses to task events (see <bold>Methods: Responsivity and selectivity analyses</bold>). For instance, in the first 500 ms 57.1% (334/585) were taste responsive and 10.1% (59/585) were taste selective (i.e., they responded differently to the mixtures), while in the last 500 ms 42.0% (238/567) showed preparatory responses in anticipation of lateral licks (63 of which were selective).</p>
<p>Within the sub-groups of neurons with significant fits there was a change in the distribution of response profile types over time: there was a significant increase in the proportion of step coding neurons from the beginning to the end of the trial (24.4%, 10/41 vs 62.7%, 37/59, Chi-squared <italic>p</italic> &lt; 0.001); equivalently, there was a significant decrease in the proportion of linear coding neurons (75.6%, 31/41 vs 37.3%, 22/59, Chi-squared <italic>p</italic> &lt; 0.001). The increase in step coding neurons from the beginning to the end of the trial was driven not by changes in the amount of step-perception neurons, which remained stable (24.4%, 10/41 vs 37.3%, 12/59, Chi-squared <italic>p</italic> = 0.631), but by an increase in the amount of step-choice neurons (0/41 vs 42.4%, 25/59, Chi-squared <italic>p</italic> &lt; 0.001) (<xref rid="fig4" ref-type="fig">Figure 4B</xref>). Furthermore, the change in distribution over time seemed to be driven mostly by separate populations of linear and step coding neurons, rather than a single population of coding neurons that switched its coding type: 77.4% of the linear coding neurons at the beginning of the trial had no significant response fit at the end of the trial; similarly, 86.5% of step coding neurons at the end of the trial had no significant fit at the beginning of the trial. The remaining neurons multiplexed across time.</p>
<p>To investigate the dynamics of single neuron responses, the time course of the distribution of fits was computed by running the response profile analysis with a moving window of ~200 ms. When quantified in this way, we found that 24.8% (155/626) of neurons were linear coding in at least one bin, 26.7% (167/626) were step-perception, and 18.2% (114/626) step-choice. That said, the peak percent of coding units in any specific bin was much lower (maximum 10.7% total). Visual inspection of <xref rid="fig4" ref-type="fig">Figure 4C</xref> indicates the same trend of switching from mostly linear coding to mostly step-choice coding over time (<xref rid="fig4" ref-type="fig">Figure 4C</xref>) seen at the population level (<xref rid="fig3" ref-type="fig">Figure 3</xref>). In addition, the analysis reveals a small and time-invariant proportion of step-perception neurons.</p>
<p>Altogether, single neuron analyses confirm the population results on coding dynamics and extend those findings to show that GC single units can encode in a binary fashion both the choice of licking direction (i.e., left vs right) as well as the perceptual category (i.e., sweet vs salty). These results also raise questions about the functional significance of the relatively low percentage of linear and step coding neurons and their contribution to population dynamics and task performance.</p>
</sec>
<sec id="s2d">
<title>Recurrent neural networks capture experimental neural and behavioral results</title>
<p>To investigate the functional role of single neuron response types described above, we relied on a computational approach and, for each recording session, built a recurrent neural network (RNN) constrained by the single neuron data and capable of reproducing behavioral performance. For each experimental session, we modeled the simultaneously recorded neurons as a fraction of a larger system of units that received external stimulus input, noise input, and recurrent input from other units. The model was partitioned into units that were trained to reproduce the neural activity directly observed during the experiment, termed “constrained,” and those that were not, termed “unconstrained.” An additional unit allowed for the model to produce “choice activity” by weighting the firing rates of all units. Discrete choices were obtained by thresholding the average choice activity over a decision window (from D – 100 ms to D, for D = 3.9 s, the average decision time in the experimental dataset). The network’s training incorporated two processes: reproducing the experimentally observed patterns of neural activity within the constrained population, while simultaneously selecting the appropriate behavioral response to each stimulus. That is, the output of each constrained unit was trained to match the PSTHs of a corresponding neuron actually recorded from the mouse GC during behavior. This approach, like the one described in <xref ref-type="bibr" rid="c8">Cohen et al., 2020</xref>, enhanced the biological realism of the RNN trained to perform the task since its internal activity was explicitly instructed to resemble true neural activity. <xref rid="fig5" ref-type="fig">Figure 5A</xref> illustrates the key components of our RNN model.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Recurrent neural network design and behavior.</title>
<p><bold>A</bold>: Model architecture. <italic>N</italic> neurons are modeled as dynamic units with internal activity <bold>h</bold> that is influenced by the external stimulus input (<italic>m</italic>(<bold>x</bold>); the time course of an example <bold>x</bold> for mixture stimulus 75/25 is shown), recurrent input (via <bold>W</bold><sub>rec</sub>), and noise input (not shown). A decision unit <italic>z</italic> measures the network’s choice by taking a weighted sum of activities via <bold>w</bold><sub><italic>z</italic></sub>. The loss function <italic>L</italic> is minimized during training based on choice (<italic>z</italic>) and the activity of the constrained units (grey dots). <bold>B</bold>: Psychometric curve fit to across-model means for the probability of the sucrose choice as a function of the stimulus. Circles and error bars represent mean and s.e.m. <bold>C</bold>: Example of experimentally observed PSTH (left) and the corresponding activity trajectory for the unit in the network trained to match it (right). <bold>D</bold>: Example activity trajectory for a unit in the network not explicitly trained to match any experimentally observed PSTH. Color scale corresponds to different mixture stimuli (%Sucrose/%NaCl).</p></caption>
<graphic xlink:href="680705v1_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The models successfully learned to perform the decision-making task and produced psychometric curves qualitatively similar to real animals’ when presented with noisy mixture stimuli (<xref rid="fig5" ref-type="fig">Figure 5B</xref>). Although the psychometric functions were significantly different between model and experiment (extra-sum-of-squares F-test, <italic>p</italic> &lt; 0.001), with a greater slope for the model’s (0.15 vs 0.08), this was unsurprising given that we tuned the level of input noise only to match overall accuracy, which was 77.2%, comparable to the 77.2% we saw from mice (t-test, <italic>p</italic> = 0.964). At the same time, the models successfully reproduced the experimentally observed neural activity. <xref rid="fig5" ref-type="fig">Figure 5C</xref> shows an example experimental PSTH (left) and the activity of the corresponding unit in the model trained to reproduce it when presented with noiseless mixture stimuli (right). This unit has a root-mean-squarederror between model output and target PSTH of 1.86 Hz; the median value across all constrained units was 1.26 Hz. Unconstrained units learned to produce a variety of responses to stimuli, some of which resembled patterns seen in the experimental dataset. An example unconstrained unit is shown in <xref rid="fig5" ref-type="fig">Figure 5D</xref>, and breakdowns of all responses are shown in <xref rid="figS2" ref-type="fig">Figures S2</xref>-<xref rid="figS3" ref-type="fig">3</xref>.</p>
<p>Additional support for the overall agreement between experimental and model dynamics and coding schemes came from population analyses. 160 trials (20 per mixture stimulus) of data from each model were simulated, using the same levels of noise added to stimuli as were used to produce realistic psychometric curves. We then pooled all the units (constrained and unconstrained) across models and applied the same dPCA procedure we used on experimental data to find the principal stimulus- and choice-coding components. Population activity projected on the principal stimulus component (<xref rid="fig6" ref-type="fig">Figure 6A</xref>) showed a graded separation of trajectories according to stimulus and regardless of choice, while the projection on the principal choice component (<xref rid="fig6" ref-type="fig">Figure 6B</xref>) showed a binary separation of trajectories according to choice and regardless of stimulus. The time courses suggested a transition from stimulus-representing activity to choice-representing activity over the period between central and lateral licks. These patterns of activity are qualitatively consistent with those observed in the experimental data and demonstrate that the RNNs produce biologically realistic population dynamics.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Modeled population activity and single unit coding properties.</title>
<p><bold>A</bold>: Trial-averaged pseudo-population activity trajectories projected onto demixed principal component of maximal stimulus-specific variance. Solid lines are correct trial averages; dotted lines are incorrect trial averages. Color scale corresponds to different mixture stimuli (%Sucrose/%NaCl). <bold>B</bold>: Same as <bold>A</bold> but for the demixed principal component of maximal choice-specific variance. <bold>C</bold>: Left: Venn diagram showing percentages of neurons with all possible combinations of coding types over time. Right: Distribution of coding types across all units (pooled over all models) over time.</p></caption>
<graphic xlink:href="680705v1_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To further validate the realism of the network and identify the salient features of neural activity on a single unit level, the same response profile classification analysis performed on experimental neurons was applied to model units. Using the results of the simulations described above, response profiles were calculated for all units (for correct and error trials, separately) in 200 ms bins, and the same procedure was used to assign a coding type label—linear, step-perception, step-choice, or other—to each response profile in each bin. The Venn diagram in <xref rid="fig6" ref-type="fig">Figure 6C</xref> (left) displays the breakdown in percentages of all units that exhibited each possible combination of coding types in at least one bin during the task period. In total, ~24.2% (885/3681) of units were classified as linear coding, ~26.8% (987/3681) of units were step-perception coding, and ~25.5% (943/3681) of units were step-choice coding at some time point. As in the case of the experimental results, the model’s neurons that did not show significant fits (~56.8% of units) could still be taste responsive (29.4%, 615/2092), taste selective (9.4%, 197/2092), and show preparatory responses (23.4%, 490/2092) (<xref rid="figS2" ref-type="fig">Figures S2</xref>-<xref rid="figS3" ref-type="fig">3</xref>).</p>
<p>Analyses on the time course of the distribution of coding types—linear, step-perception, and step-choice—across all units (pooled over all 23 models) showed qualitative agreement with the experimental findings (<xref rid="fig6" ref-type="fig">Figure 6C</xref>, right). As in the experimental data, the peak percent of coding units in any specific bin was relatively low (maximum 14.9% total). The prevalence of linear coding units peaked soon after mixture sampling, while the step-choice coding units peaked soon before lateral licking. As in the experimental data, the model produced a lower percentage of step-perception coding units whose prevalence tiled the entire trial.</p>
<p>Altogether, the results show that the RNN models trained to reproduce behavioral performance and, in a fraction of the units, the observed neural activity, generate population and single unit coding patterns analogous to those observed in GC of behaving mice.</p>
</sec>
<sec id="s2e">
<title>Model perturbations reveal behavioral significance of coding unit types</title>
<p>Generating a series of RNNs that aligned with experimentally observed neural activity and behavioral performance allowed for an exploration of the functional role of the different types of coding units (linear, step-perception, and step-choice). A series of virtual “ablation” experiments were conducted by re-running simulations while clamping the firing rates of specific sub-populations of units to 0. “Ablation” experiments were conducted for units that exhibited linear coding at any time point in the original simulations, those that were classified as step-perception coding at any time point, those that were labeled as step-choice at any time, and those that never followed any of these coding patterns (i.e., the “other” units).</p>
<p>All three coding types contributed to model dynamical activity along the stimulus- and choicecoding dimensions, as projecting the post-ablation activity onto the originally identified axes resulted in a noticeable blunting (<xref rid="fig7" ref-type="fig">Figure 7A</xref>). Quantitatively, mean absolute projection values were significantly reduced (post-hoc Bonferroni-corrected paired t-tests; stimulus projections: control vs linear, <italic>p</italic> &lt; 0.001; control vs perception, <italic>p</italic> &lt; 0.001; control vs choice, <italic>p</italic> &lt; 0.001; choice projections: control vs linear, <italic>p</italic> &lt; 0.001; control vs perception, <italic>p</italic> &lt; 0.001; control vs choice, <italic>p</italic> &lt; 0.001). Similarly, new stimulus- and choice-coding dimensions identified after ablating did not align with the old ones (<xref rid="fig7" ref-type="fig">Figure 7B</xref>) (absolute cosine similarities between vectors; stimulus components: control vs linear, 0.208; control vs perception, 0.244; control vs choice, 0.557; choice components: control vs linear, 0.016; control vs perception, 0.169; control vs choice, 0.021). The effects of the “ablations” could simply be the result of the removal of roughly a quarter of the units in a highly recurrent network leading to a large non-specific disruption of dynamics. However, this is not the case, as the “ablation” of the “other” units (i.e., those that do not show any significant fit), which constitute a much larger fraction of the network (56.8%, 2092/3681), left dynamics largely intact. Activity projections onto the original stimulus- and choice-coding dimensions after ablating “other” units (<xref rid="fig7" ref-type="fig">Figure 7A</xref>) were similar to the control condition without ablation (<xref rid="fig6" ref-type="fig">Figure 6A-B</xref>) (stimulus projection: <italic>p</italic> = 0.105; choice projection: <italic>p</italic> &gt; 0.999) and newly identified coding dimensions (after the ablations) overlapped highly with the originals (i.e., before the ablations; <xref rid="fig7" ref-type="fig">Figure 7B</xref>) (stimulus component: 0.947; choice component: 0.959). This is relevant as neurons in this group show firing modulations to task events (see above).</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7.</label>
<caption><title>Effect of selective ablations on model dynamics and behavior.</title>
<p><bold>A</bold>: Model dynamics after selectively ablating linear coding units, step-perception coding units, step-choice coding units, or “other” units. Post-ablation activity is projected onto the stimulus-(left column) and choice-coding (right column) components identified in the control condition (i.e., the same ones in <xref ref-type="fig" rid="fig6">Figure 6A-B</xref>). Color scale corresponds to different mixture stimuli (%Sucrose/%NaCl); solid and dashed lines correspond to correct and error trials. <bold>B</bold>: Pairwise overlaps between stimulus-(top) and choice-coding (bottom) components for control (-) and each ablation condition (o: other, l: linear, p: step-perception, c: step-choice). <bold>C</bold>: Behavioral performance of the model after selectively ablating categories of coding units. Left: across-model distributions of task accuracy vs ablation condition. Bars represent means. * indicates significant difference vs control condition (post-hoc paired t-test Bonferroni-adjusted <italic>p</italic> &lt; 0.01). Right: psychometric functions fit to across-model mean probability of sucrose choice for different ablation conditions. Circles and error bars represent mean and s.e.m.</p></caption>
<graphic xlink:href="680705v1_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>In terms of behavioral impact, all three coding types were also necessary for normal model performance, as task accuracy dropped significantly upon ablating any of them, whereas task performance was unaffected by ablating the “other” units (post-hoc paired t-tests with Bonferroni correction; control vs linear, <italic>p</italic> &lt; 0.001; control vs step-perception, <italic>p</italic> &lt; 0.001; control vs step-choice, <italic>p</italic> &lt; 0.001; control vs “other,” <italic>p</italic> = 0.197; <xref rid="fig7" ref-type="fig">Figure 7C</xref>). Furthermore, the psychometric functions were not significantly different between the control and ablated “other” conditions, while they were different between the control and all other conditions (extra-sum-of-squares F-tests with Bonferroni correction; control vs linear, <italic>p</italic> &lt; 0.001; control vs perception, <italic>p</italic> &lt; 0.001; control vs choice, <italic>p</italic> &lt; 0.001; control vs “other,” <italic>p</italic> = 0.235).</p>
<p>In summary, the effect of these ablations on dynamics and behavior suggests that the model was quite robust to perturbation in general, but sensitive to manipulations that targeted linear and step coding units.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>GC plays a fundamental role in representing multiple sensory, affective, cognitive, and motor processes associated with a gustatory experience (<xref ref-type="bibr" rid="c57">Yamamoto et al., 1985</xref>; <xref ref-type="bibr" rid="c49">Samuelsen et al., 2012</xref>; <xref ref-type="bibr" rid="c13">Gardner and Fontanini, 2014</xref>; <xref ref-type="bibr" rid="c56">Vincis and Fontanini, 2016</xref>). This function is performed through time-varying patterns of neural activity that sequentially encode for different variables associated with a taste-related task. Neural dynamics in GC have been extensively studied both in single neurons and at the population level (<xref ref-type="bibr" rid="c48">Sadacca et al., 2016</xref>; <xref ref-type="bibr" rid="c32">Mahmood et al., 2023</xref>; <xref ref-type="bibr" rid="c36">Mazzucato et al., 2015</xref>; <xref ref-type="bibr" rid="c38">Mendoza et al., 2024</xref>; <xref ref-type="bibr" rid="c28">Livneh and Andermann, 2021</xref>), and their role in producing behavior is beginning to be elucidated (<xref ref-type="bibr" rid="c23">Kusumoto-Yoshida et al., 2015</xref>; <xref ref-type="bibr" rid="c41">Mukherjee et al., 2019</xref>; <xref ref-type="bibr" rid="c55">Vincis et al., 2020</xref>). Yet, the relationship among single neuron firing patterns, population dynamics, and behavior is not completely understood. Here we investigate how sub-populations of GC neurons defined by their single unit response profiles influence population dynamics and behavioral performance in the context of a taste mixture-based 2AC task.</p>
<p>By recording neuronal activity with high-density probes in the GC of behaving mice, we unveiled population and single neuron dynamics associated with a taste mixture 2AC task. We found that both population and single neuron activities go through a phase in which mixtures are linearly coded by their components’ concentration to a phase where stimuli are binarily coded. Additional analyses of single neuron activity show that units with binary coding could further be divided as either representing the predominant mixture component—that is, its overall taste quality (sweet vs salty, “step-perception”)—or the directional licking decisions cued by the stimulus (left vs right, “step-choice”). While some neurons showed only one coding pattern, others could have different response profiles at different times during the trial. Overall, the neurons whose tuning curves could be significantly fit by a linear or step function at any point in time were less than 50% of the total number of recorded neurons, with each specific type constituting no more than 27%.</p>
<p>To study the functional role of such groups of single units, we built RNN models (<xref ref-type="bibr" rid="c54">Valente et al., 2022</xref>; <xref ref-type="bibr" rid="c8">Cohen et al., 2020</xref>) of GC (one per session) and trained them to perform the taste mixture 2AC task while also reflecting the experimentally observed single neuron firing. The RNNs matched experimentally observed single neuron PSTHs, GC population dynamics, and rodent behavioral performance. Perturbing the model by removing different groups of neurons with distinct coding properties showed that linear and step coding neurons are necessary for neural population dynamics as well as behavioral performance. Ablation of the neurons that did not fit into the above categories had no impact on dynamics and performance, highlighting the functional importance of the single neuron firing patterns identified in this study.</p>
<p>Altogether the results presented in this study explain the role of single neuron firing patterns in a decision-making task and validate a data-driven, machine learning-based approach to modeling and generating hypotheses about the functional significance of system components (<xref ref-type="bibr" rid="c52">Song et al., 2016</xref>; <xref ref-type="bibr" rid="c2">Barak, 2017</xref>; <xref ref-type="bibr" rid="c58">Yang and Wang, 2020</xref>; <xref ref-type="bibr" rid="c54">Valente et al., 2022</xref>).</p>
<sec id="s3a">
<title>Coding of task-related variables in GC of mice engaged in a taste mixture 2AC task</title>
<p>Since the pioneering work of <xref ref-type="bibr" rid="c20">Katz et al. (2001</xref>), it has been known that GC population dynamics can sequentially encode different aspects of a gustatory experience, from somatosensation to chemosensation to hedonic evaluation. More recent work has extended these findings to include GC population-level dynamics coding for taste-predictive cues, expectation, licking preparation, and abstract decision-making in the context of taste-based behavioral tasks (<xref ref-type="bibr" rid="c53">Stapleton, 2007</xref>; <xref ref-type="bibr" rid="c49">Samuelsen et al., 2012</xref>; <xref ref-type="bibr" rid="c29">Livneh et al., 2017</xref>; <xref ref-type="bibr" rid="c11">Fonseca et al., 2018</xref>; <xref ref-type="bibr" rid="c55">Vincis et al., 2020</xref>; <xref ref-type="bibr" rid="c24">Lang et al., 2023</xref>). For instance, <xref ref-type="bibr" rid="c55">Vincis et al. (2020</xref>) showed population activity trajectories separating according to sensory quality (sweet vs bitter) before licking decision (lick left vs lick right) in GC of mice performing a taste-based 2AC task.</p>
<p>The population-level analyses presented here add to the growing body of evidence for GC dynamics’ involvement in taste-based decision-making (<xref ref-type="bibr" rid="c39">Miller and Katz, 2010</xref>; <xref ref-type="bibr" rid="c11">Fonseca et al., 2018</xref>; <xref ref-type="bibr" rid="c55">Vincis et al., 2020</xref>; <xref ref-type="bibr" rid="c24">Lang et al., 2023</xref>; <xref ref-type="bibr" rid="c17">Jezzini and Padoa-Schioppa, 2024</xref>; <xref ref-type="bibr" rid="c22">Kogan and Fontanini, 2024</xref>; <xref ref-type="bibr" rid="c59">Zheng et al., 2025</xref>). In the context of the taste mixture-based 2AC task presented here, we found neurons that discriminate between predominantly-sucrose and predominantly-NaCl mixtures throughout the trial time course, with population firing rates featuring two peaks, one related to the sampling of taste and one preceding lateral licking. Decoding of population activity showed that the representation of taste mixtures peaks early while choice-related coding peaks just before lateral licking. We applied dimensionality reduction techniques, t-SNE and demixed PCA (<xref ref-type="bibr" rid="c21">Kobak et al., 2016</xref>), to extract the dominant trajectories coding for the task components in a neural space. The low-dimensional activity trajectories revealed a graded, linear separation based on mixture stimuli early on with sampling, and a binary separation based on selected choice later, prior to the decision. These population-level results, along with previous studies (<xref rid="c22" ref-type="bibr">Kogan and Fontanini, 2024</xref>; <xref ref-type="bibr" rid="c33">Maier and Katz, 2013</xref>), led us to search for single neurons with linear and step coding responses. Indeed, a subset of single units whose tuning curves represent mixture stimuli as a linear or step function were identified. Based on the analysis of correct and error trials, the step coding units could be further divided as either representing the predominant mixture component (step-perception) or the directional licking decisions cued by the stimulus (step-choice). It is worth mentioning that while some neurons displayed only one coding pattern, others showed coding patterns that could vary in time, providing evidence for multiplexing at the single neuron level. Regardless, the time course of the prevalence of linear and step-choice responses was consistent with the dynamics observed at the population level, with the former peaking during sampling and the latter before lateral licking. While the existence of these coding types suggests a role in driving population dynamics, the relatively limited presence of specific coding types in any time bin may cast doubts on their functional significance. In particular, step-perception units did not show any peak and appeared in a uniformly low proportion throughout the trial, raising additional questions about the functional role of single unit coding patterns.</p>
<p>To address these questions on the functional role of the single unit activity described above, we relied on a modeling approach that would allow us to reproduce the experimentally recorded single unit activity as well as the behavioral performance for each session.</p>
</sec>
<sec id="s3b">
<title>Using RNNs to investigate the role of single neuron coding patterns</title>
<p>Determining the functional role of a particular brain region’s dynamics typically relies on optogenetic manipulations, which have become the gold standard due to their high temporal precision and the availability of specific genetically- and/or anatomically-targeted viral constructs (<xref ref-type="bibr" rid="c25">Li et al., 2019</xref>; <xref ref-type="bibr" rid="c10">Emiliani et al., 2022</xref>). Optogenetic silencing of GC and its inputs at different times during a trial has revealed the dynamic role of GC in encoding of palatability information (<xref ref-type="bibr" rid="c27">Lin et al., 2021</xref>), gaping behaviors (<xref ref-type="bibr" rid="c41">Mukherjee et al., 2019</xref>), expectation (<xref ref-type="bibr" rid="c23">Kusumoto-Yoshida et al., 2015</xref>), and taste-based decision-making (<xref ref-type="bibr" rid="c55">Vincis et al., 2020</xref>). As powerful as the approach is, it cannot be applied to selectively perturb neurons that are characterized by a specific coding pattern with no known genetic or connectivity signature. In other words, the specific coding populations we explored here cannot be manipulated by traditional optogenetic techniques. To address this gap, we relied on simulated manipulations in computational models where there is full control over all individual units.</p>
<p>Previous modeling efforts on GC have largely focused on replicating population-level phenomena (e.g., sequences of metastable states) starting from <italic>a priori</italic> architectures and tuning parameters by hand to reproduce population dynamics and behavioral performance (<xref ref-type="bibr" rid="c39">Miller and Katz, 2010</xref>; <xref ref-type="bibr" rid="c36">Mazzucato et al., 2015</xref>, <xref rid="c37" ref-type="bibr">Mazzucato et al., 2016</xref>, <xref rid="c35" ref-type="bibr">Mazzucato et al., 2019</xref>; <xref ref-type="bibr" rid="c24">Lang et al., 2023</xref>). While advancing our knowledge of the properties and origin of GC population dynamics, these efforts have not directly furthered our understanding of the role of single unit firing patterns. Here we turned to RNNs as an unbiased method for reproducing single unit firing activity (<xref ref-type="bibr" rid="c2">Barak, 2017</xref>; <xref ref-type="bibr" rid="c58">Yang and Wang, 2020</xref>). In particular, RNNs do not assume a specific synaptic matrix ahead of training. We took advantage of the relative ease of training RNNs (<xref ref-type="bibr" rid="c52">Song et al., 2016</xref>; <xref ref-type="bibr" rid="c44">Paszke et al., 2019</xref>) to learn single neuron activity and behavioral performance, capturing population dynamics in the process (<xref ref-type="bibr" rid="c45">Perich et al., 2020</xref>; <xref ref-type="bibr" rid="c8">Cohen et al., 2020</xref>; <xref ref-type="bibr" rid="c54">Valente et al., 2022</xref>; <xref ref-type="bibr" rid="c46">Rajan et al., 2016</xref>). Our RNN was composed of “constrained” and “unconstrained” units. Each constrained unit was paired with a target neuron from the experimental dataset, and the mismatch between model and experimental PSTHs was included in the loss function. Unconstrained units were included to represent unobserved neurons in the experimental recordings, and to add degrees of freedom to the network tasked with matching the constrained units’ activities to targets. Each unit was driven by stimulus input, recurrent input, and noise input. Unlike previous models (<xref ref-type="bibr" rid="c24">Lang et al., 2023</xref>; <xref ref-type="bibr" rid="c7">Cisek et al., 2009</xref>), an external preparatory input prior to decision was not necessary. While this is not proof that GC lacks preparatory inputs, it demonstrates that these dynamics can be produced internally.</p>
<p>The tractability of training RNNs via automatic differentiation typically comes at the expense of realism and mechanistic understanding when considering the network as a model of the brain. In contrast, spiking neural networks offer much increased biophysical plausibility, but are much harder to train (<xref ref-type="bibr" rid="c3">Bohte, 2011</xref>; <xref ref-type="bibr" rid="c26">Li et al., 2021</xref>; <xref ref-type="bibr" rid="c9">DePasquale et al., 2016</xref>) and often require <italic>a priori</italic> decisions about their architecture. Here we took additional measures to alleviate the trade-off between these two approaches by training a subset of neurons to reproduce the experimental PSTHs. This enhances biological realism and allows for RNN predictions to have more meaningful interpretations (<xref ref-type="bibr" rid="c8">Cohen et al., 2020</xref>; <xref ref-type="bibr" rid="c46">Rajan et al., 2016</xref>). For our ablation studies, we identified the sub-populations of coding units based on their response patterns in the simulations. We then ran new simulations while clamping the firing rates of units in specific sub-populations to 0. We found that all three coding types—linear, step-perception, and step-choice—were required for normal population dynamics and behavior. We showed the impact of these unit types on populationlevel trajectories measured with demixed PCA and on behavioral performance measured with a psychometric function. The removal of linear coding units made the network unable to produce appropriate stimulus-related and choice-related population activity as well as flattened the psychometric function. Surprisingly, the same effect was obtained by the ablation of step-perception units. Ablation of step-choice neurons had a less dramatic effect on stimulus-related population activity but flattened choice-related trajectories. Crucially, ablating all other neurons (which were much more plentiful) left dynamics and behavior intact. This lack of effect from ablation was not because the activity of those neurons was unrelated to the task. Indeed, many represented stimuli and upcoming choices, only in ways outside of our defined coding types. This demonstrates the disproportionate importance of linear, step-perception, and step-choice coding types to the model compared to alternative coding strategies, and highlights their relevance. Interestingly, our results emphasize the importance of step-perception neurons, which appear to be responsible for bridging early stimulus-evoked dynamics with successive choice-related activity.</p>
<p>The work presented here leaves some open questions that present promising avenues for future research. Accumulating evidence indicates that GC’s ongoing, taste-evoked, and decision-making activity is supported by metastable dynamics (<xref ref-type="bibr" rid="c18">Jones et al., 2007</xref>; <xref ref-type="bibr" rid="c36">Mazzucato et al., 2015</xref>; <xref ref-type="bibr" rid="c48">Sadacca et al., 2016</xref>; <xref ref-type="bibr" rid="c24">Lang et al., 2023</xref>). Our model was not specifically constructed to exhibit metastability as we fit it to single neuron activities and behavioral performance without enforcing <italic>a priori</italic> structural constraints. Presumably, though, the most faithful model of GC would capture both single unit coding types and metastability, and future work could explore the implementation of a constrained fitting procedure that achieves this. Recent evidence also indicates that discrimination learning on this mixture task (that is, learning to improve difficult mixture pair discriminations via additional training) is associated with an increase in choice selective cells during the later delay period (<xref rid="c22" ref-type="bibr">Kogan and Fontanini, 2024</xref>). The mechanistic origins of this finding are unclear, and a modified version of the model presented here may prove to be a useful tool for clarifying them.</p>
</sec>
</sec>
<sec id="s4">
<title>Conclusions</title>
<p>In conclusion, our work shows that GC, a well-studied model for understanding cortical dynamics in sensory areas, can encode taste mixtures linearly or categorically, and choices categorically, during a mixture-based decision-making task. These phenomena are observed at the population level as well as at the single neuron level, and our findings are consistent with a dynamic progression of coding from representation of stimulus information to decision-making, with coding of perceptual category providing a bridging signal. The different types of coding sub-populations all make essential contributions to population dynamics and behavioral performance in our model of GC, underscoring the relevance of even small groups of neurons encoding task-relevant variables in very specific ways. It is worth noting that the neurons outside of these groups, whose activity was not necessary for normal population dynamics or behavioral performance in this particular task, may be critical for other taste-based decision-making tasks. Indeed, these “other” neurons may constitute a reservoir from which functionally-significant units emerge during learning according to task-specific demands. We believe the modeling approach taken here is a powerful means of analyzing the impact of single units dynamics on network activity and performance and makes a case for data-driven, interpretable RNNs as useful tools in neuroscience that compromise between realistic biophysical models and “black box” machine learning models.</p>
<p>While the research presented here focuses on GC, its implications go beyond taste. Both the findings and the approach are relevant for understanding population and single neuron dynamics in areas where sensory, cognitive, and motor activity are jointly encoded.</p>
</sec>
<sec id="s5">
<title>Methods</title>
<sec id="s5a">
<title>Stereotaxic surgeries</title>
<p>Mice were anesthetized using a cocktail of ketamine (70 mg/kg) and dexmedetomidine (1 mg/kg) via intraperitoneal injection. After the animal was fully anesthetized, the head was shaved and cleaned with iodine and 70% ethanol. The animal was then transferred onto a stereotaxic apparatus. During the surgery, the depth of anesthesia was monitored via visual inspection of breathing rate, toe pinch reflex, and whisking. A heating pad was used to maintain body temperature. After the skin was excised, the skull was exposed and cleaned with saline, dry swabs, and 70% ethanol. A small amount of Vetbond (3M) was used to secure the skin around the edge of the incision. A pencil was used to trace the coronal, interfrontal, sagittal, and lambdoid sutures. GC craniotomy sites (AP: +1.2 mm, ML: ±3.7 mm relative to Bregma) were marked with a permanent marker and covered with Kwik-Sil (World Precision Instruments). A craniotomy site above the cerebellum was drilled and a ground wire soldered to a male pin was placed (A-M system, Cat.No.786000). The midline of a custom head bar was aligned with the interfrontal and sagittal suture markings and positioned 1 mm posterior to Bregma. It was then secured with dental acrylic (C&amp;B Metabond), covering both the skull and the top of the head bar. DV coordinates of Bregma and Lambda were remeasured, and a calibration point was marked on the head bar for stereotaxic reference.</p>
</sec>
<sec id="s5b">
<title>Immunohistochemistry</title>
<p>Mice were deeply anesthetized with 220 mg/kg pentobarbital sodium (390 mg/ml) and were perfused with phosphate buffer saline (PBS) followed by 4% paraformaldehyde (PFA) in PBS. After post-fixing overnight in 4% PFA, the brains were sliced at 50 µm with a vibratome (Leica VT-1000S). The brain slices were counterstained with Hoechst 33342 (1:5000 dilution, H3570, Thermo Fisher, Waltham, MA). Sections were mounted, cover-slipped, and imaged using a fluorescent microscope (Olympus BX51WI).</p>
<p>A Python-based GUI for Histological E-data Registration in Brain Space (HERBS) was used to register the slice images onto Allen CCF mouse atlas based on anatomical features for 2D and 3D visualization (<xref ref-type="bibr" rid="c12">Fuglstad et al., 2023</xref>; <ext-link ext-link-type="uri" xlink:href="https://github.com/Whitlock-Group/HERBS">https://github.com/Whitlock-Group/HERBS</ext-link>). Reconstruction and visualization of electrode track trajectories was performed with open-source Allen CCF Tools (<xref ref-type="bibr" rid="c50">Shamash et al., 2018</xref>; <ext-link ext-link-type="uri" xlink:href="https://github.com/cortex-lab/allenCCF">https://github.com/cortex-lab/allenCCF</ext-link>) in a custom MATLAB script.</p>
</sec>
<sec id="s5c">
<title>Statistical tests</title>
<p>For simple distribution comparisons, we used Mann-Whitney U tests (i.e., rank-sum tests) or t-tests (Python: Scipy <italic>stats</italic>). For comparing proportions, we used Chi-squared tests or 2-tailed binomial tests (Python: Scipy <italic>stats</italic>). For within-subjects comparisons with more than two levels, we used 1-way repeated measures ANOVAs (Python: AnovaRM from <italic>statsmodels</italic>) and followed up significant results with post-hoc paired t-tests (Python: Scipy <italic>stats</italic>). Bonferroni corrections were implemented by multiplying <italic>p</italic> values by <italic>K</italic>-choose-2, where <italic>K</italic> is the number of levels. For within-subjects comparisons with two predictors, we used 2-way repeated measures ANOVAs (MATLAB: <italic>fitrm</italic> and <italic>ranova</italic>; MathWorks). Additional statistical tests (such as extra-sum-of-squares F-test; see below) were implemented with custom code in Python or MATLAB. Significance level was taken as <italic>α</italic> = 0.01.</p>
</sec>
<sec id="s5d">
<title>Behavioral data</title>
<p>All psychometric curves (<xref rid="fig1" ref-type="fig">Figures 1B</xref>, <xref ref-type="fig" rid="fig5">5B</xref>, <xref ref-type="fig" rid="fig7">7C</xref>) are least-squares fitted 4-parameter logistic functions of the form:
<disp-formula id="ueqn1">
<graphic xlink:href="680705v1_ueqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>y</italic> is the probability of a sucrose choice, <italic>s</italic> ∈ (0, 100) is the %Sucrose of the stimulus, <italic>p</italic><sub>1</sub> is the upper asymptote, <italic>p</italic><sub>2</sub> is the slope parameter, <italic>p</italic><sub>3</sub> is the inflection point, and <italic>p</italic><sub>4</sub> is the lower asymptote. Rather than averaging psychometric curves over sessions/models, a single psychometric was always fitted to the session-/model-averaged response as a function of the stimulus. Fitting was performed with Python’s <italic>scipy</italic> library, using the <italic>curve_fit</italic> method from the <italic>optimize</italic> module, with restrictions on the parameters: 0 ≤ <italic>p</italic><sub>1</sub> ≤ 1; 15 ≤ <italic>p</italic><sub>3</sub> ≤ 85; 0 ≤ <italic>p</italic><sub>4</sub> ≤ 1.</p>
<p>Psychometric curves were compared to each other using an extra-sum-of-squares F-test. The F statistic was calculated as (<xref ref-type="bibr" rid="c40">Motulsky and Christopoulos, 2004</xref>; <xref ref-type="bibr" rid="c34">Maxwell et al., 2017</xref>):
<disp-formula id="ueqn2">
<graphic xlink:href="680705v1_ueqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where SSE<sub>1</sub> is the sum of squared errors when fitting all data points with a single curve, SSE<sub>2</sub> is the sum of squared errors when fitting the separate data points with two separate curves, df <sub>1</sub> = <italic>N</italic><sub>points</sub> − 4, and df <sub>2</sub> = <italic>N</italic><sub>points</sub> − 8 (<italic>N</italic><sub>points</sub> is the total number of data points). The <italic>p</italic> value was calculated as the area under the F(df <sub>1</sub> − df <sub>2</sub>, df <sub>2</sub>) distribution to the right of <italic>F</italic><sub>stat</sub> and evaluated at the <italic>α</italic> = 0.01 significance level. Bonferroni corrections were applied by multiplying <italic>p</italic> by <italic>K</italic>-choose-2, where <italic>K</italic> is the total number of psychometrics being considered.</p>
</sec>
<sec id="s5e">
<title>Electrophysiological data acquistion</title>
<p>Prior to each recording session, Neuropixel 1.0 probes were coated with Vybrant™ DiI (Thermo-Fischer) or neuro-DiO (Biotium). Before recording, the animal was placed in an induction chamber under 2.5% isoflurane for 2 to 3 minutes and then placed on a stereotaxic frame where anes-thesia was maintained with 1 to 2% isoflurane. Dental acrylic over the Kwik-Sil was removed to expose the craniotomy site. A craniotomy was drilled based on the marker and cleaned with gel foam and saline. The animal was then transferred to the behavior platform. A multi-probe motorized manipulator system was used for recordings (New Scale Technologies). Bregma and Lambda were calibrated based on their relative distances from the calibration point. Neuropixels trajectory explorer with the Allen CCF mouse atlas was used to visualize the probe location in the brain (<ext-link ext-link-type="uri" xlink:href="http://github.com/petersaj/neuropixels_trajectory_explorer">http://github.com/petersaj/neuropixels_trajectory_explorer</ext-link>). Craniotomies were kept moist with frequent application of saline during recordings and were sealed with Kwik-Sil and covered with a thin layer of dental cement after recording. The open-source software package SpikeGLX (<ext-link ext-link-type="uri" xlink:href="https://billkarsh.github.io/SpikeGLX/">https://billkarsh.github.io/SpikeGLX/</ext-link>) was used for data acquisition.</p>
</sec>
<sec id="s5f">
<title>Spike sorting</title>
<p>Spike sorting was performed with Kilosort 2 and Kilosort 4 (<xref ref-type="bibr" rid="c43">Pachitariu et al., 2024</xref>; <ext-link ext-link-type="uri" xlink:href="http://github.com/MouseLand/Kilosort">http://github.com/MouseLand/Kilosort</ext-link>) and sorted clusters were manually curated using Phy (Cyrille Rossant, International Brain Laboratory) and custom MATLAB scripts. Units were identified with distinct clusters in waveform principal component space and a clear refractory period (&gt; 1 ms) in auto-correlation histograms.</p>
</sec>
<sec id="s5g">
<title>Firing rate data</title>
<p>To analyze firing rate dynamics with respect to two discrete trial events—the time of the first central lick, T, and the time of the first lateral lick, D—simultaneously, we used a warped time scale. Spike trains were aligned to T, and a fixed number of bins (77) was used to calculate firing rates between T and D. This inter-event interval, IEI = D – T, varied from trial to trial, with an average duration of 3.85 s across the entire dataset (thus, the mean bin duration was ~50 ms). The fixed number of bins ensured firing rate timeseries could be aligned to both T and D across all trials from all sessions. Firing rates before T and after D were calculated using 50 ms bins. After averaging over trials to construct PSTHs, firing rate trajectories were smoothed using acausal Gaussian kernels 11 bins wide.</p>
</sec>
<sec id="s5h">
<title>auROC</title>
<p>Area under the receiver operating characteristic curve (auROC) was used to measure each neuron’s average difference in firing rate between %Sucrose &lt; %NaCl and %Sucrose &gt; %NaCl trials over time. Each ROC curve was constructed as Pr(<italic>R</italic><sub>1</sub> &gt; <italic>θ</italic>) vs Pr(<italic>R</italic><sub>2</sub> &gt; <italic>θ</italic>) for <italic>R</italic><sub>1</sub> the firing rate in %Sucrose &lt; %NaCl trials, <italic>R</italic><sub>2</sub> the firing rate in %Sucrose &gt; %NaCl trials, and <italic>θ</italic> the threshold parameter. Thus, an auROC value of 0 indicated firing rates in predominantly-sucrose trials were always greater, a value of 1 indicated firing rates in predominantly-NaCl trials were always greater, and a value of 0.5 represented complete overlap between distributions of firing rates in both trial types. Peak auROC values were identified as those with greatest absolute difference from 0.5, and neurons were labeled as sucrose- or NaCl-”preferring” based on whether this peak value was closer to 0 or 1.</p>
</sec>
<sec id="s5i">
<title>Responsivity and selectivity analyses</title>
<p>In line with previous work (<xref rid="c22" ref-type="bibr">Kogan and Fontanini, 2024</xref>), we classified neurons as responsive in the sampling (T to T + 0.5 s) or delay (D – 0.5 s to D) periods if their firing rate distributions were significantly different from baseline (T – 3 s to T – 2.5s for sampling baseline; D – 5.5 s to D – 5 s for delay baseline). We then checked responsive neurons to see if their firing rate distributions within sampling or delay periods were significantly different between predominantly-sucrose and predominantly-NaCl trials—if so, they were considered selective. All statistical comparisons were done via Mann-Whitney U tests at the <italic>α</italic> = 0.01 significance level. Only correct trials were used. We applied the same analyses to RNN units but with T – 0.5 s to T as the baseline for both sampling and delay periods.</p>
</sec>
<sec id="s5j">
<title>t-SNE</title>
<p>A t-distributed stochastic neighbor embedding (t-SNE) was used as a non-linear dimensionality reduction approach for visualizing pseudo-population firing rate trajectories. This method aims to preserve the true distance structure among points in the original, high-dimensional space when mapping to the low-dimensional embedding space. We concatenated correct trial PSTHs to construct an (<italic>N</italic><sub>stim</sub> ⋅ <italic>N</italic><sub>time</sub>) × <italic>N</italic><sub>neu</sub> pseudo-population matrix for <italic>N</italic><sub>stim</sub> = 8 the number of unique stimuli, <italic>N</italic><sub>time</sub> = 117 the total number of time points, and <italic>N</italic><sub>neu</sub> = 626 the total number of neurons in the pseudo-population. The number of columns in the matrix was then reduced to 2 via the embedding—we used the <italic>TSNE</italic> class from the <italic>manifold</italic> module of Python’s <italic>scikit-learn</italic> library with default parameters.</p>
</sec>
<sec id="s5k">
<title>dPCA</title>
<p>A demixed principal component analysis (dPCA) was performed as a linear, supervised alternative to t-SNE for dimensionality reduction. Detailed methods are described in <xref ref-type="bibr" rid="c21">Kobak et al. (2016</xref>). Briefly, this analysis began by organizing the firing rate data in a multi-dimensional array <inline-formula id="inline-eqn-1"><inline-graphic xlink:href="680705v1_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula> of shape <italic>N</italic><sub>trials</sub> × <italic>N</italic><sub>neurons</sub> × <italic>S</italic> × <italic>Q</italic> × <italic>T</italic>, where <italic>T</italic> = 117 is the number of time bins, <italic>Q</italic> = 2 is the number of choices, <italic>S</italic> = 8 is the number of stimuli, <italic>N</italic><sub>neurons</sub> = 626 is the total number of recorded neurons, and <italic>N</italic><sub>trials</sub> is the maximum number of trials across all sessions for any stimulus and choice combination (correct and error trials are included). Whenever a session had no trials for a particular stimulus/choice combination, we fit simple linear models to each time bin’s available data and used them to predict the missing data:
<disp-formula id="ueqn3">
<graphic xlink:href="680705v1_ueqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where stim (in %Sucrose) is the stimulus value, choice ∈ {0, 1} is the animal’s choice (0 for “NaCl choice” and 1 for “sucrose choice”), <italic>y</italic>(<italic>t</italic>) is the predicted firing rate in time bin <italic>t</italic>, and the <italic>β</italic>(<italic>t</italic>)s are the fitted regression weights. At least 2 trials per session and stimulus/choice combination are required for optimizing the regularization hyperparameter in dPCA (if only 1 existed, it was copied), though the main dPCA analysis operates on the trial-averaged data matrix <inline-formula id="inline-eqn-2"><inline-graphic xlink:href="680705v1_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula> of shape <italic>N</italic><sub>neurons</sub> ×<italic>SQT</italic>. The analysis partitions this matrix into marginalized contributions from each variable, <inline-formula id="inline-eqn-3"><inline-graphic xlink:href="680705v1_inline3.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, where <italic>ϕ</italic> ∈ {<italic>s, q, t, sq, st, qt, sqt</italic>} is a variable combination (<italic>s</italic> for stimulus, <italic>q</italic> for choice, <italic>t</italic> for time; we joined <italic>s</italic> with <italic>st, q</italic> with <italic>qt</italic>, and <italic>sq</italic> with <italic>sqt</italic>), then minimizes the loss <italic>L</italic><sub><italic>ϕ</italic></sub> for each:
<disp-formula id="ueqn6">
<graphic xlink:href="680705v1_ueqn6.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <bold>F</bold><sub><italic>ϕ</italic></sub> and <bold>D</bold><sub><italic>ϕ</italic></sub> are encoders and decoders, respectively, <inline-formula id="inline-eqn-4"><inline-graphic xlink:href="680705v1_inline4.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is the average covariance matrix over all parameter combinations (⟨⋅ ⟩ <sub><italic>ϕ</italic></sub> denotes averaging over <italic>ϕ</italic> and (⋅)<sup>T</sup> denotes matrix/vector transposition), <italic>μ</italic> is the regularization hyperparameter, and ∥⋅∥ <sub>2</sub> denotes the Frobenius norm for matrices and the 2-norm for vectors. After fitting, one-dimensional projections of pseudo-population activity were obtained by calculating the inner product of <bold>d</bold><sub><italic>ϕ</italic></sub> and the <italic>N</italic><sub>neurons</sub>-dimensional vector over time, where <bold>d</bold><sub><italic>ϕ</italic></sub> is the row of <bold>D</bold><sub><italic>ϕ</italic></sub> that maximized projected variance.</p>
<p>Overlaps between components obtained via dPCA were calculated as an absolute cosine similarity between vectors:
<disp-formula id="ueqn7">
<graphic xlink:href="680705v1_ueqn7.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
</sec>
<sec id="s5l">
<title>Minimum-distance decoding</title>
<p>For each session, we trained minimum-distance classifiers to decode several task-relevant variables from population firing rate activity over time. These custom classifiers may be thought of as variants of 1-nearest neighbor classifiers where neighbors are centroids (class averages). At each point in time, all trials were represented as population firing rate vectors and their associated labels {(<bold>r</bold><sub><italic>i</italic></sub>, <italic>l</italic><sub><italic>i</italic></sub>)} for <italic>i</italic> indexing trials and <italic>l</italic><sub><italic>i</italic></sub> ∈ <italic>U</italic>, the set of unique labels (e.g., for decoding Choice, <italic>U</italic> = {Left, Right}). Each trial i was held out, and mean population firing rate vectors were calculated for each label <italic>𝓊</italic> ∈ <italic>U</italic> :
<disp-formula id="ueqn8">
<graphic xlink:href="680705v1_ueqn8.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where ∧ denotes logical “and.”</p>
<p>The held-out trial was then assigned the class label corresponding to the nearest mean firing rate vector:
<disp-formula id="ueqn9">
<graphic xlink:href="680705v1_ueqn9.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>d</italic> is a distance metric. We chose the Euclidean distance metric, <italic>d</italic>(<bold>r</bold><sub><italic>i</italic></sub>, <bold>c</bold><sub><italic>𝓊</italic></sub>) = ∥<bold>r</bold><sub><italic>i</italic></sub> − <bold>c</bold><sub><italic>𝓊</italic></sub>∥ <sub>2</sub>. The class-balanced leave-one-out test accuracy was calculated as:
<disp-formula id="ueqn10">
<graphic xlink:href="680705v1_ueqn10.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where |<italic>U</italic> | is the cardinality of <italic>U</italic>, i.e., the number of unique labels, and <italic>I</italic> is the indicator function:
<disp-formula id="ueqn11">
<graphic xlink:href="680705v1_ueqn11.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
A one-tailed <italic>α</italic>-significance threshold for the session-averaged decoding accuracy was calculated from the binomial distribution as <italic>k</italic>/<italic>N</italic>, where <italic>N</italic> is the average number of trials and <italic>k</italic> is the minimum number of hits such that the tail probability to the right of <italic>k</italic> is still below <italic>α</italic>. That is:
<disp-formula id="ueqn12">
<graphic xlink:href="680705v1_ueqn12.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where Pr(<italic>y</italic>) is the probability mass function of a binomial random variable parameterized by <italic>N</italic> and <italic>p</italic>. We used <italic>α</italic> = 0.01, <italic>N</italic> = 137 (the average number of trials across all sessions), and <italic>p</italic> ∈ {1/8, 1/2} (the theoretical chance levels of decoding each variable).</p>
<p>We used a 2-way within-subjects ANOVA with factors decoding (stimulus or choice) and time (sampling or delay) to compare the time courses of decoding. Each decoding time course had its theoretical chance level subtracted prior to the test, and decoding time courses were averaged within the first 10 bins after T (T to ~T + 0.5 s) and last 10 bins before D (~D – 0.5 s to D) for sampling and delay, respectively.</p>
</sec>
<sec id="s5m">
<title>Response profiles</title>
<p>Single unit response profiles were analyzed with a least-squares regression-based pipeline similar to that of <xref ref-type="bibr" rid="c33">Maier and Katz (2013</xref>). Let <italic>x</italic><sub><italic>k,t</italic></sub> represent a single neuron’s pre-processed firing rate data (i.e., already time-warped and smoothed) for <italic>k</italic> indexing trials and <italic>t</italic> indexing time. Let <italic>σ</italic>(<italic>k</italic>) be the stimulus administered on trial <italic>k</italic> (in terms of %Sucrose, for simplicity) and <italic>o</italic>(<italic>k</italic>) be the outcome of the trial (i.e., correct or error). For each neuron from each session, the response profile <italic>r</italic> was calculated as a function of the stimulus <italic>s</italic> (again, in terms of %Sucrose) for a given time window <italic>w</italic>:
<disp-formula id="ueqn13">
<graphic xlink:href="680705v1_ueqn13.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where again ⟨ ⋅⟩<sub><italic>x</italic></sub> denotes averaging over <italic>x</italic> and ∧ denotes logical “and”. The shape of each response profile was then labeled “linear,” “step,” or “other” by comparing to template shapes: a 2-parameter line,
<disp-formula id="ueqn14">
<graphic xlink:href="680705v1_ueqn14.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
and a 3-parameter step function,
<disp-formula id="ueqn15">
<graphic xlink:href="680705v1_ueqn15.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
The comparison was carried out by finding the best fit (in the least-squares sense) for each template, and then comparing the resulting <italic>F</italic> values. The <italic>F</italic><sub>stat</sub> value for each template was calculated from the extra-sum-of-squares <italic>F</italic> formula above (<bold>Methods: Behavioral data</bold>), now applied to a fitted vs null model comparison rather than a nested model comparison (<xref ref-type="bibr" rid="c40">Motulsky and Christopoulos, 2004</xref>; <xref ref-type="bibr" rid="c34">Maxwell et al., 2017</xref>):
<disp-formula id="ueqn16">
<graphic xlink:href="680705v1_ueqn16.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where SSE<sub>1</sub> is the sum of squared error for the null model (the mean of the data), SSE<sub>2</sub> is the sum of squared error for the fitted model, df <sub>1</sub> and df <sub>2</sub> are the corresponding degrees of freedom, <inline-formula id="inline-eqn-5"><inline-graphic xlink:href="680705v1_inline5.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is the average of <italic>r</italic>(<italic>s</italic>), <italic>N</italic><sub><italic>d</italic></sub> is the number of data points, and <italic>N</italic><sub><italic>p</italic></sub> is the number of parameters. The shape of the response profile was then assigned as the template with the largest associated <italic>F</italic><sub>stat</sub> value, as long as this <italic>F</italic><sub>stat</sub> value’s corresponding <italic>p</italic> value (area under the F(df <sub>1</sub> − df <sub>2</sub>, df <sub>2</sub>) distribution to the right of <italic>F</italic><sub>stat</sub>) was less than <italic>α</italic> = 0.005 (0.01, Bonferroni-corrected for the number of tests). If this was not the case, the response profile’s shape was assigned as “other.” Least-squares fitting for <italic>f</italic><sub>line</sub> was performed as a constrained fit, subject to <italic>f</italic><sub>line</sub>(<italic>s</italic>) ≥ 0 for all <italic>s</italic>, using Python’s <italic>scipy</italic> library (<italic>minimize</italic> method of the <italic>optimize</italic> module). Least-squares fitting for <italic>f</italic><sub>step</sub> was performed manually by varying <italic>p</italic><sub>3</sub> ∈ {40, 50, 60} and, for each, finding the optimal remaining parameters as <inline-formula id="inline-eqn-6"><inline-graphic xlink:href="680705v1_inline6.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.</p>
<p>To sub-classify neurons labeled “step” into “step-perception” and “step-choice,” we incorporated error trials. To be considered a “step-choice” neuron, two criteria had to be met: (i) the inflection point of the step response profile (<italic>p</italic><sub>3</sub>) had to occur at <italic>s</italic> = 50; (ii) the average firing rate of the neuron had to be consistently (between correct and error trials) greater for trials where the same direction was chosen. For example, if the firing rate averaged over correct trials of <italic>s</italic> &gt; 50 was greater than the average over correct trials of <italic>s</italic> &lt; 50, then we required its firing rate averaged over error trials of <italic>s</italic> &lt; 50 to be greater than the average over error trials of <italic>s</italic> &gt; 50 (since that would indicate a consistent “preference” for trials of one lick direction). More explicitly, we calculated <inline-formula id="inline-eqn-7"><inline-graphic xlink:href="680705v1_inline7.gif" mimetype="image" mime-subtype="gif"/></inline-formula> for <italic>x</italic> ∈ {correct, error} (where <italic>r</italic><sub>correct</sub> (<italic>s</italic>) = <italic>r</italic>(<italic>s</italic>) and <italic>r</italic> <sub>error</sub> (<italic>s</italic>) is obtained by replacing the condition <italic>σ</italic>(<italic>k</italic>) = correct with <italic>σ</italic>(<italic>k</italic>) = error in the above definition of <italic>r</italic>(<italic>s</italic>)) and required <italic>δ</italic><sub>correct</sub><italic>δ</italic><sub>error</sub> &lt; 0 for the “step-choice” label. If no error trials existed for stimulus values on either side of <italic>s</italic> = 50 (relevant for some simulated data), “step” neurons were not sub-classified.</p>
<p>We examined the proportions of all neurons pooled over all sessions and subjects that were classified as each shape at the beginning and end of the trial using windows <italic>w</italic><sub>1</sub> = [T, T + 0.5 s] and <italic>w</italic><sub>2</sub> = [D − 0.5 s, D] on the un-warped time scale. Chi-squared tests of proportions were done without Yates’ correction, using <italic>chi2_contingency</italic> from the <italic>stats</italic> module of Python’s <italic>scipy</italic> library. We also visualized the proportions over the full trial time course by using a moving window 4 bins wide (~200 ms) on the warped time scale, stepped by 4 bins (the final window was only 1 bin wide since the total number of time points was not divisible by 4).</p>
</sec>
<sec id="s5n">
<title>RNN: Components and dynamics</title>
<p>Recurrent neural network models were inspired by <xref ref-type="bibr" rid="c8">Cohen et al. (2020</xref>) and adapted from opensource code (<xref ref-type="bibr" rid="c54">Valente et al., 2022</xref>; <ext-link ext-link-type="uri" xlink:href="https://github.com/adrian-valente/lowrank_inference">https://github.com/adrian-valente/lowrank_inference</ext-link>). Each RNN used here is comprised of <italic>N</italic><sub>c</sub> constrained and <italic>N</italic><sub>u</sub> unconstrained artificial units (for <italic>N</italic><sub>c</sub> equal to the number of simultaneously recorded neurons in the corresponding experimental session and <italic>N</italic><sub>u</sub> = round(5.88 ⋅ <italic>N</italic><sub>c</sub>)). Thus, the total number of units in each network is <italic>N</italic> = <italic>N</italic><sub>c</sub> + <italic>N</italic><sub>u</sub> (the additional decision unit, described later, is not included in this count).</p>
<p>The internal activity of all units in the network, <bold>h</bold> ∈ ℝ<sup><italic>N</italic></sup>, is influenced by external stimulus input, noise input, and recurrent input. The external stimulus input, <italic>m</italic>(<bold>x</bold>), is the mixture stimulus modeled as a 2-dimensional vector—e.g., 25/75 (%Sucrose/%NaCl) is <bold>x</bold> = [0.25, 0.75]<sup>T</sup>—passed through the non-linear mapping <italic>m</italic> : ℝ<sup>2</sup> → ℝ<sup><italic>N</italic></sup> defined by <italic>m</italic>(<bold>x</bold>) = <bold>A</bold><sup>(2)</sup>tanh(<bold>A</bold><sup>(1)</sup><bold>x</bold>) for matrices <bold>A</bold><sup>(1)</sup> ∈ ℝ<sup>100×2</sup>, <bold>A</bold><sup>(2)</sup> ∈ ℝ<sup><italic>N</italic> ×100</sup>, and tanh applied element-wise to vectors. The noise input is <bold>η</bold> for <italic>η</italic><sub><italic>i</italic></sub> ~<italic>𝒩</italic> (0, <italic>σ</italic><sub><italic>η</italic></sub>) resampled at each time step from a Gaussian distribution with mean 0 and standard deviation <italic>σ</italic><sub><italic>η</italic></sub> = 0.05/<italic>α</italic> (<italic>α</italic> defined below). The recurrent input is <bold>W</bold><sub>rec</sub><italic>f</italic> (<bold>h</bold> + <bold>b</bold>) for the synaptic matrix <bold>W</bold><sub>rec</sub> ∈ ℝ<sup><italic>N</italic> ×<italic>N</italic></sup>, the input bias <bold>b</bold> ∈ ℝ<sup><italic>N</italic></sup>, and the transfer function <italic>f</italic>, applied element-wise to vectors, is a rectified linear function with a maximum value of 80, i.e., <italic>f</italic> (<italic>z</italic>) = min(max(<italic>z</italic>, 0), 80). The output of the transfer function is interpreted as a firing rate, i.e., <bold>r</bold> = <italic>f</italic> (<bold>h</bold> + <bold>b</bold>). Network activity evolves according to:
<disp-formula id="ueqn17">
<graphic xlink:href="680705v1_ueqn17.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
for time constant <italic>τ</italic>. We integrated this equation in discrete time using the forward Euler algorithm with step size <italic>α</italic> = d<italic>t</italic>/<italic>τ</italic> = 0.2. The model’s decision over time is governed by an additional decision unit that is functionally external from the network (i.e., it does not appear in the equation for <bold>h</bold> above). This unit is denoted by <italic>z</italic> and its internal activity is driven by the firing rates of all <italic>N</italic> units in the network:
<disp-formula id="ueqn18">
<graphic xlink:href="680705v1_ueqn18.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
for weight vector <bold>w</bold><sub><italic>z</italic></sub> ∈ ℝ<sup><italic>N</italic></sup>. This equation is integrated in parallel with the one for <bold>h</bold> and the model’s binary choice is determined by interpreting <italic>c</italic> = tanh(<italic>z</italic>) as “sucrose choice” if <italic>c</italic> &gt; 0 and as “NaCl choice” if <italic>c</italic> &lt; 0.</p>
</sec>
<sec id="s5o">
<title>RNN: Training</title>
<p>The goal during training is for the model to respond to any particular stimulus input by producing the correct choice (i.e., value of <italic>c</italic>) during a pre-defined decision window as well as constrained firing rate trajectories (i.e., first <italic>N</italic><sub>c</sub> components of <bold>r</bold>) that match the correct trial PSTHs of the neurons in the corresponding session. Thus, we define an overall loss as:
<disp-formula id="ueqn19">
<graphic xlink:href="680705v1_ueqn19.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
for behavioral loss <italic>L</italic><sub>beh</sub>, neural loss <italic>L</italic><sub>neu</sub>, and associated weights <italic>λ</italic><sub>beh</sub> = 150 and <italic>λ</italic><sub>neu</sub> = 1 to counterbalance the different error scales. The behavioral loss is:
<disp-formula id="ueqn20">
<graphic xlink:href="680705v1_ueqn20.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>k</italic> indexes stimuli, <italic>t</italic> indexes time, win<sub>0</sub> = [T − 1 s, T] is the pre-stimulus window for T the stimulus delivery time, win<sub>D</sub> = [D − 0.1 s, D] is the decision window for D the decision time, <italic>c</italic><sub><italic>k,t</italic></sub> is the network’s value of <italic>c</italic> in response to stimulus <italic>k</italic> at time <italic>t, γ</italic><sub><italic>k</italic></sub> is the correct decision in response to stimulus <italic>k</italic> (e.g., for <italic>k</italic> = 0/100, <italic>γ</italic><sub><italic>k</italic></sub> = −1; for <italic>k</italic> = 100/0, <italic>γ</italic><sub><italic>k</italic></sub> = +1), and <italic>β</italic><sub>beh</sub> is the total number of terms in the sums. The neural loss is:
<disp-formula id="ueqn21">
<graphic xlink:href="680705v1_ueqn21.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>n</italic> indexes constrained neurons, <italic>r</italic><sub><italic>k,t,n</italic></sub> is the network’s firing rate output for neuron <italic>n</italic> in response to stimulus <italic>k</italic> at time <italic>t, ρ</italic> is the experimentally observed correct trial PSTHs, and <italic>β</italic><sub>neu</sub> is the total number of terms in the sum.</p>
<p>Training was carried out in PyTorch (<xref ref-type="bibr" rid="c44">Paszke et al., 2019</xref>): <italic>L</italic> was minimized with respect to the network’s trainable parameters—<bold>A</bold><sup>(1)</sup>, <bold>A</bold><sup>(2)</sup>, <bold>W</bold><sub>rec</sub>, <bold>b, w</bold><sub><italic>z</italic></sub>, and the initial value of <bold>h</bold>—via backpropagation, using the Adam optimizer with a learning rate of 0.01 and gradient clipping above 1.0. Elements of <bold>A</bold><sup>(1)</sup> and <bold>A</bold><sup>(2)</sup> were randomly initialized as 𝒩 (0, 1). Elements of <bold>W</bold><sub>rec</sub> were randomly initialized as <inline-formula id="inline-eqn-8"><inline-graphic xlink:href="680705v1_inline8.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, with self-connections prohibited. Elements of <bold>w</bold><sub><italic>z</italic></sub> were randomly initialized as <italic>𝒩</italic> (0, 1/<italic>N</italic>). Elements of <bold>b</bold> and the initial values of <bold>h</bold> were initialized at 0. Training proceeds for 2000 iterations or until <italic>L</italic> &lt; 1.</p>
</sec>
<sec id="s5p">
<title>RNN: Simulations</title>
<p>Single trial simulations (both during and after training) were conducted for 5.9 s each, matching the time-warped window of analysis used for experimental data. The stimulus <bold>x</bold> was “on” 1 s after trial start and lasted for 1.2 s. When off, <bold>x</bold> = [0, 0]<sup>T</sup>. After training, simulations were carried out with persistent additional noise, changing the external input current to <italic>m</italic>(<bold>x</bold> + <bold>ϵ</bold>) with <italic>ϵ</italic><sub><italic>i</italic></sub> ~<italic>𝒩</italic> (0, <italic>σ</italic>) resampled at each time step. The level of external noise, <italic>σ</italic>, was tailored to each model such that its overall accuracy was within 5% of the accuracy from the corresponding experimental session (it ranged from 0.10 to 1.15). We simulated 20 trials per stimulus, and choices were obtained from the sign of the average value of <italic>c</italic> over the decision window, which covers 0.1 s before the decision time (which occurs 3.9 s after stimulus start) up to the decision time.</p>
<p>For ablation simulations, elements of <bold>r</bold> = <italic>f</italic> (<bold>h</bold> + <bold>b</bold>) corresponding to firing rates of units belonging to specific sub-populations of interest (identified based on results from simulations without ablation) were clamped to 0 for all time. Ablations can result in the model becoming highly biased toward one choice direction; to limit inclusion of inferred missing data for the dPCA of model dynamics across ablation conditions, we excluded models that did not have at least 2 trials for each chosen direction under all conditions (14/23 models passed this criterion).</p>
</sec>
</sec>
</body>
<back>
<sec sec-type="supplementary" id="supplementary30">
<title>Supplementary figures</title>
<fig id="figS1" position="float" fig-type="figure">
<label>Supplementary Figure 1.</label>
<caption><title>Neuropixels probe trajectory reconstruction.</title>
<p><bold>A</bold>: 3D reconstruction of the 23 probe trajectories from the experimental dataset. <bold>B</bold>: 2D reconstruction of the same 23 probe trajectories, overlaid on the Allen Brain Atlas at varying anteroposterior (AP) distances (relative to Bregma in mm) around GC. At these coordinates, both GU (gustatory areas) and AI (anterior insular areas) account for GC. Reconstructions performed with open-source Allen CCF Tools (<xref ref-type="bibr" rid="c50">Shamash et al., 2018</xref>; <ext-link ext-link-type="uri" xlink:href="http://github.com/cortex-lab/allenCCF">github.com/cortex-lab/allenCCF</ext-link>).</p></caption>
<graphic xlink:href="680705v1_figS1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS2" position="float" fig-type="figure">
<label>Supplementary Figure 2.</label>
<caption><title>RNN unit responsiveness.</title>
<p><bold>A</bold>: Activity of all RNN units grouped by responsiveness during the sampling period. If the unit’s firing rate distribution during the sampling period (T to T + 0.5 s) was significantly different from its baseline (T – 0.5 s to T) firing rate distribution, it was sampling responsive and grouped by whether its mean firing rate increased (left) or decreased (middle); otherwise it was non-responsive (right). <bold>B</bold>: Activity of all RNN units grouped by responsiveness during the delay period. Same as <bold>A</bold> except the firing rate distribution of interest is calculated over D – 0.5 s to D. <bold>C</bold> and <bold>D</bold>: Same as <bold>A</bold> and <bold>B</bold>, respectively, except that the only units considered are those labeled “other” by the response profile analysis of <xref rid="fig6" ref-type="fig">Figure 6C</xref>. Firing rates are expressed relative to baseline, and traces are population mean ± s.e.m.</p></caption>
<graphic xlink:href="680705v1_figS2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS3" position="float" fig-type="figure">
<label>Supplementary Figure 3.</label>
<caption><title>RNN unit activity patterns.</title>
<p><bold>A</bold>: Heatmaps of firing rate activities for units that responded significantly during the sampling and/or delay periods, broken down into coding units (linear, step-perception, and/or step-choice) (top) and “other” units (not linear, not step-perception, and not step-choice) (bottom). Firing rates are expressed relative to baseline and normalized to the maximum absolute value. <bold>B</bold>: Two example “other” unit responses. Both respond significantly during the sampling period, but neither response pattern matches the linear or step templates. Color scale corresponds to different mixture stimuli (%Sucrose/%NaCl).</p></caption>
<graphic xlink:href="680705v1_figS3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="das" sec-type="data-availability">
<title>Data availability</title>
<p>Experimental dataset available by request. Modeling dataset and code for all analyses available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/llang6/linear-categorical">https://github.com/llang6/linear-categorical</ext-link>.</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>Work supported by R01DC018227 from NIH/NIDCD (A.F.), 1UF1NS115779 from NIH/NINDS Brain Initiative (AF and GLC), American Association of University Women (AAUW) International Fellowship (C.Y.Z), K12GM102778 from NIH/NGM (J.M.B).</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Arieli</surname> <given-names>E</given-names></string-name>, <string-name><surname>Younis</surname> <given-names>N</given-names></string-name>, <string-name><surname>Moran</surname> <given-names>A.</given-names></string-name></person-group> <article-title>Distinct Progressions of Neuronal Activity Changes Underlie the Formation and Consolidation of a Gustatory Associative Memory</article-title>. <source>Journal of Neuroscience</source>. <year>2022</year> <month>Feb</month>; <volume>42</volume>(<issue>5</issue>):<fpage>909</fpage>–<lpage>921</lpage>. doi: <pub-id pub-id-type="doi">10.1523/JNEUROSCI.1599-21.2021</pub-id>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barak</surname> <given-names>O.</given-names></string-name></person-group> <article-title>Recurrent Neural Networks as Versatile Tools of Neuroscience Research</article-title>. <source>Current Opinion in Neuro-biology</source>. <year>2017</year> <month>Oct</month>; <volume>46</volume>:<fpage>1</fpage>–<lpage>6</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.conb.2017.06.003</pub-id>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Bohte</surname> <given-names>SM</given-names></string-name></person-group>. <chapter-title>Error-Backpropagation in Networks of Fractionally Predictive Spiking Neurons</chapter-title>. In: <person-group person-group-type="editor"><string-name><surname>Honkela</surname> <given-names>T</given-names></string-name>, <string-name><surname>Duch</surname> <given-names>W</given-names></string-name>, <string-name><surname>Girolami</surname> <given-names>M</given-names></string-name>, <string-name><surname>Kaski</surname> <given-names>S</given-names></string-name>, editors</person-group>. <source>Artificial Neural Networks and Machine Learning – ICANN 2011</source>, vol. <volume>6791</volume> <publisher-loc>Berlin, Heidelberg</publisher-loc>: <publisher-name>Springer Berlin Heidelberg</publisher-name>; <year>2011</year>. p. <fpage>60</fpage>–<lpage>68</lpage>. doi: <pub-id pub-id-type="doi">10.1007/978-3-642-21735-7_8</pub-id>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bouaichi</surname> <given-names>CG</given-names></string-name>, <string-name><surname>Vincis</surname> <given-names>R.</given-names></string-name></person-group> <article-title>Cortical Processing of Chemosensory and Hedonic Features of Taste in Active Licking Mice</article-title>. <source>Journal of Neurophysiology</source>. <year>2020</year> <month>May</month>; <volume>123</volume>(<issue>5</issue>):<fpage>1995</fpage>–<lpage>2009</lpage>. doi: <pub-id pub-id-type="doi">10.1152/jn.00069.2020</pub-id>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Buetfering</surname> <given-names>C</given-names></string-name>, <string-name><surname>Zhang</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Pitsiani</surname> <given-names>M</given-names></string-name>, <string-name><surname>Smallridge</surname> <given-names>J</given-names></string-name>, <string-name><surname>Boven</surname> <given-names>E</given-names></string-name>, <string-name><surname>McElligott</surname> <given-names>S</given-names></string-name>, <string-name><surname>Häusser</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Behaviorally Relevant Decision Coding in Primary Somatosensory Cortex Neurons</article-title>. <source>Nature Neuroscience</source>. <year>2022</year> <month>Sep</month>; <volume>25</volume>(<issue>9</issue>):<fpage>1225</fpage>–<lpage>1236</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41593-022-01151-0</pub-id>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Churchland</surname> <given-names>AK</given-names></string-name>, <string-name><surname>Ditterich</surname> <given-names>J.</given-names></string-name></person-group> <article-title>New Advances in Understanding Decisions among Multiple Alternatives</article-title>. <source>Current Opinion in Neurobiology</source>. <year>2012</year> <month>Dec</month>; <volume>22</volume>(<issue>6</issue>):<fpage>920</fpage>–<lpage>926</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.conb.2012.04.009</pub-id>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cisek</surname> <given-names>P</given-names></string-name>, <string-name><surname>Puskas</surname> <given-names>GA</given-names></string-name>, <string-name><surname>El-Murr</surname> <given-names>S.</given-names></string-name></person-group> <article-title>Decisions in Changing Conditions: The Urgency-Gating Model</article-title>. <source>The Journal of Neuroscience</source>. <year>2009</year> <month>Sep</month>; <volume>29</volume>(<issue>37</issue>):<fpage>11560</fpage>–<lpage>11571</lpage>. doi: <pub-id pub-id-type="doi">10.1523/JNEUROSCI.1844-09.2009</pub-id>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Cohen</surname> <given-names>Z</given-names></string-name>, <string-name><surname>DePasquale</surname> <given-names>B</given-names></string-name>, <string-name><surname>Aoi</surname> <given-names>MC</given-names></string-name>, <string-name><surname>Pillow</surname> <given-names>JW</given-names></string-name></person-group>, <article-title>Recurrent Dynamics of Prefrontal Cortex during Context-Dependent Decision-Making</article-title>; <source>bioRxiv</source> <year>2020</year>. doi: <pub-id pub-id-type="doi">10.1101/2020.11.27.401539</pub-id>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>DePasquale</surname> <given-names>B</given-names></string-name>, <string-name><surname>Churchland</surname> <given-names>MM</given-names></string-name>, <string-name><surname>Abbott</surname> <given-names>LF</given-names></string-name></person-group>, <article-title>Using Firing-Rate Dynamics to Train Recurrent Networks of Spiking Model Neurons</article-title>; <source>arXiv</source><year>2016</year>. doi: <pub-id pub-id-type="doi">10.48550/ARXIV.1601.07620</pub-id>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Emiliani</surname> <given-names>V</given-names></string-name>, <string-name><surname>Entcheva</surname> <given-names>E</given-names></string-name>, <string-name><surname>Hedrich</surname> <given-names>R</given-names></string-name>, <string-name><surname>Hegemann</surname> <given-names>P</given-names></string-name>, <string-name><surname>Konrad</surname> <given-names>KR</given-names></string-name>, <string-name><surname>Lüscher</surname> <given-names>C</given-names></string-name>, <string-name><surname>Mahn</surname> <given-names>M</given-names></string-name>, <string-name><surname>Pan</surname> <given-names>ZH</given-names></string-name>, <string-name><surname>Sims</surname> <given-names>RR</given-names></string-name>, <string-name><surname>Vierock</surname> <given-names>J</given-names></string-name>, <string-name><surname>Yizhar</surname> <given-names>O.</given-names></string-name></person-group> <article-title>Optogenetics for Light Control of Biological Systems</article-title>. <source>Nature Reviews Methods Primers</source>. <year>2022</year> <month>Jul</month>; <volume>2</volume>(<issue>1</issue>):<fpage>55</fpage>. doi: <pub-id pub-id-type="doi">10.1038/s43586-022-00136-4</pub-id>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fonseca</surname> <given-names>E</given-names></string-name>, <string-name><surname>De Lafuente</surname> <given-names>V</given-names></string-name>, <string-name><surname>Simon</surname> <given-names>SA</given-names></string-name>, <string-name><surname>Gutierrez</surname> <given-names>R.</given-names></string-name></person-group> <article-title>Sucrose Intensity Coding and Decision-Making in Rat Gustatory Cortices</article-title>. <source>eLife</source>. <year>2018</year> <month>Nov</month>; <volume>7</volume>:<elocation-id>e41152</elocation-id>. doi: <pub-id pub-id-type="doi">10.7554/eLife.41152</pub-id>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fuglstad</surname> <given-names>JG</given-names></string-name>, <string-name><surname>Saldanha</surname> <given-names>P</given-names></string-name>, <string-name><surname>Paglia</surname> <given-names>J</given-names></string-name>, <string-name><surname>Whitlock</surname> <given-names>JR</given-names></string-name></person-group>. <article-title>Histological E-data Registration in Rodent Brain Spaces</article-title>. <source>eLife</source>. <year>2023</year> <month>Jan</month>; <volume>12</volume>:<elocation-id>e83496</elocation-id>. doi: <pub-id pub-id-type="doi">10.7554/eLife.83496</pub-id>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gardner</surname> <given-names>MPH</given-names></string-name>, <string-name><surname>Fontanini</surname> <given-names>A.</given-names></string-name></person-group> <article-title>Encoding and Tracking of Outcome-Specific Expectancy in the Gustatory Cortex of Alert Rats</article-title>. <source>Journal of Neuroscience</source>. <year>2014</year> <month>Sep</month>; <volume>34</volume>(<issue>39</issue>):<fpage>13000</fpage>–<lpage>13017</lpage>. doi: <pub-id pub-id-type="doi">10.1523/JNEUROSCI.1820-14.2014</pub-id>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goltstein</surname> <given-names>PM</given-names></string-name>, <string-name><surname>Reinert</surname> <given-names>S</given-names></string-name>, <string-name><surname>Bonhoeffer</surname> <given-names>T</given-names></string-name>, <string-name><surname>Hübener</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Mouse Visual Cortex Areas Represent Perceptual and Semantic Features of Learned Visual Categories</article-title>. <source>Nature Neuroscience</source>. <year>2021</year> <month>Oct</month>; <volume>24</volume>(<issue>10</issue>):<fpage>1441</fpage>–<lpage>1451</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41593-021-00914-5</pub-id>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guo</surname> <given-names>ZV</given-names></string-name>, <string-name><surname>Hires</surname> <given-names>SA</given-names></string-name>, <string-name><surname>Li</surname> <given-names>N</given-names></string-name>, <string-name><surname>O’Connor</surname> <given-names>DH</given-names></string-name>, <string-name><surname>Komiyama</surname> <given-names>T</given-names></string-name>, <string-name><surname>Ophir</surname> <given-names>E</given-names></string-name>, <string-name><surname>Huber</surname> <given-names>D</given-names></string-name>, <string-name><surname>Bonardi</surname> <given-names>C</given-names></string-name>, <string-name><surname>Morandell</surname> <given-names>K</given-names></string-name>, <string-name><surname>Gutnisky</surname> <given-names>D</given-names></string-name>, <string-name><surname>Peron</surname> <given-names>S</given-names></string-name>, <string-name><given-names>Xu</given-names> <surname>Nl</surname></string-name>, <string-name><surname>Cox</surname> <given-names>J</given-names></string-name>, <string-name><surname>Svoboda</surname> <given-names>K.</given-names></string-name></person-group> <article-title>Procedures for Behavioral Experiments in Head-Fixed Mice</article-title>. <source>PLOS One</source>. <year>2014a</year> <month>Feb</month>; <volume>9</volume>(<issue>2</issue>):<fpage>e88678</fpage>. doi: <pub-id pub-id-type="doi">10.1371/journal.pone.0088678</pub-id>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guo</surname> <given-names>ZV</given-names></string-name>, <string-name><surname>Li</surname> <given-names>N</given-names></string-name>, <string-name><surname>Huber</surname> <given-names>D</given-names></string-name>, <string-name><surname>Ophir</surname> <given-names>E</given-names></string-name>, <string-name><surname>Gutnisky</surname> <given-names>D</given-names></string-name>, <string-name><surname>Ting</surname> <given-names>JT</given-names></string-name>, <string-name><surname>Feng</surname> <given-names>G</given-names></string-name>, <string-name><surname>Svoboda</surname> <given-names>K.</given-names></string-name></person-group> <article-title>Flow of Cortical Activity Underlying a Tactile Decision in Mice</article-title>. <source>Neuron</source>. <year>2014b</year> <month>Jan</month>; <volume>81</volume>(<issue>1</issue>):<fpage>179</fpage>–<lpage>194</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2013.10.020</pub-id>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jezzini</surname> <given-names>A</given-names></string-name>, <string-name><surname>Padoa-Schioppa</surname> <given-names>C.</given-names></string-name></person-group> <article-title>Neuronal Activity in the Gustatory Cortex during Economic Choice</article-title>. <source>The Journal of Neuroscience</source>. <year>2024</year> <month>Aug</month>; <volume>44</volume>(<issue>33</issue>):<fpage>e2150232024</fpage>. doi: <pub-id pub-id-type="doi">10.1523/JNEUROSCI.2150-23.2024</pub-id>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jones</surname> <given-names>LM</given-names></string-name>, <string-name><surname>Fontanini</surname> <given-names>A</given-names></string-name>, <string-name><surname>Sadacca</surname> <given-names>BF</given-names></string-name>, <string-name><surname>Miller</surname> <given-names>P</given-names></string-name>, <string-name><surname>Katz</surname> <given-names>DB</given-names></string-name></person-group>. <article-title>Natural Stimuli Evoke Dynamic Sequences of States in Sensory Cortical Ensembles</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2007</year> <month>Nov</month>; <volume>104</volume>(<issue>47</issue>):<fpage>18772</fpage>–<lpage>18777</lpage>. doi: <pub-id pub-id-type="doi">10.1073/pnas.0705546104</pub-id>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jun</surname> <given-names>JJ</given-names></string-name>, <string-name><surname>Steinmetz</surname> <given-names>NA</given-names></string-name>, <string-name><surname>Siegle</surname> <given-names>JH</given-names></string-name>, <string-name><surname>Denman</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Bauza</surname> <given-names>M</given-names></string-name>, <string-name><surname>Barbarits</surname> <given-names>B</given-names></string-name>, <string-name><surname>Lee</surname> <given-names>AK</given-names></string-name>, <string-name><surname>Anastassiou</surname> <given-names>CA</given-names></string-name>, <string-name><surname>Andrei</surname> <given-names>A</given-names></string-name>, <string-name><surname>Aydin</surname> <given-names>Ç</given-names></string-name>, <string-name><surname>Barbic</surname> <given-names>M</given-names></string-name>, <string-name><surname>Blanche</surname> <given-names>TJ</given-names></string-name>, <string-name><surname>Bonin</surname> <given-names>V</given-names></string-name>, <string-name><surname>Couto</surname> <given-names>J</given-names></string-name>, <string-name><surname>Dutta</surname> <given-names>B</given-names></string-name>, <string-name><surname>Gratiy</surname> <given-names>SL</given-names></string-name>, <string-name><surname>Gutnisky</surname> <given-names>DA</given-names></string-name>, <string-name><surname>Häusser</surname> <given-names>M</given-names></string-name>, <string-name><surname>Karsh</surname> <given-names>B</given-names></string-name>, <string-name><surname>Ledochowitsch</surname> <given-names>P</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Fully Integrated Silicon Probes for High-Density Recording of Neural Activity</article-title>. <source>Nature</source>. <year>2017</year> <month>Nov</month>; <volume>551</volume>(<issue>7679</issue>):<fpage>232</fpage>–<lpage>236</lpage>. doi: <pub-id pub-id-type="doi">10.1038/nature24636</pub-id>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Katz</surname> <given-names>DB</given-names></string-name>, <string-name><surname>Simon</surname> <given-names>SA</given-names></string-name>, <string-name><surname>Nicolelis</surname> <given-names>MAL</given-names></string-name></person-group>. <article-title>Dynamic and Multimodal Responses of Gustatory Cortical Neurons in Awake Rats</article-title>. <source>The Journal of Neuroscience</source>. <year>2001</year> <month>Jun</month>; <volume>21</volume>(<issue>12</issue>):<fpage>4478</fpage>–<lpage>4489</lpage>. doi: <pub-id pub-id-type="doi">10.1523/JNEUROSCI.21-12-04478.2001</pub-id>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kobak</surname> <given-names>D</given-names></string-name>, <string-name><surname>Brendel</surname> <given-names>W</given-names></string-name>, <string-name><surname>Constantinidis</surname> <given-names>C</given-names></string-name>, <string-name><surname>Feierstein</surname> <given-names>CE</given-names></string-name>, <string-name><surname>Kepecs</surname> <given-names>A</given-names></string-name>, <string-name><surname>Mainen</surname> <given-names>ZF</given-names></string-name>, <string-name><surname>Qi</surname> <given-names>XL</given-names></string-name>, <string-name><surname>Romo</surname> <given-names>R</given-names></string-name>, <string-name><surname>Uchida</surname> <given-names>N</given-names></string-name>, <string-name><surname>Machens</surname> <given-names>CK</given-names></string-name></person-group>. <article-title>Demixed Principal Component Analysis of Neural Population Data</article-title>. <source>eLife</source>. <year>2016</year> <month>Apr</month>; <volume>5</volume>:<elocation-id>e10989</elocation-id>. doi: <pub-id pub-id-type="doi">10.7554/eLife.10989</pub-id>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kogan</surname> <given-names>JF</given-names></string-name>, <string-name><surname>Fontanini</surname> <given-names>A.</given-names></string-name></person-group> <article-title>Learning Enhances Representations of Taste-Guided Decisions in the Mouse Gustatory Insular Cortex</article-title>. <source>Current Biology</source>. <year>2024</year> <month>May</month>; <volume>34</volume>(<issue>9</issue>):<fpage>1880</fpage>–<lpage>1892.e5</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.cub.2024.03.034</pub-id>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kusumoto-Yoshida</surname> <given-names>I</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>H</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>BT</given-names></string-name>, <string-name><surname>Fontanini</surname> <given-names>A</given-names></string-name>, <string-name><surname>Bonci</surname> <given-names>A.</given-names></string-name></person-group> <article-title>Central Role for the Insular Cortex in Mediating Conditioned Responses to Anticipatory Cues</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2015</year> <month>Jan</month>; <volume>112</volume>(<issue>4</issue>):<fpage>1190</fpage>–<lpage>1195</lpage>. doi: <pub-id pub-id-type="doi">10.1073/pnas.1416573112</pub-id>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lang</surname> <given-names>L</given-names></string-name>, <string-name><surname>La Camera</surname> <given-names>G</given-names></string-name>, <string-name><surname>Fontanini</surname> <given-names>A.</given-names></string-name></person-group> <article-title>Temporal Progression along Discrete Coding States during Decision-Making in the Mouse Gustatory Cortex</article-title>. <source>PLOS Computational Biology</source>. <year>2023</year> <month>Feb</month>; <volume>19</volume>(<issue>2</issue>):<fpage>e1010865</fpage>. doi: <pub-id pub-id-type="doi">10.1371/jour-nal.pcbi.1010865</pub-id>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname> <given-names>N</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>S</given-names></string-name>, <string-name><surname>Guo</surname> <given-names>ZV</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>H</given-names></string-name>, <string-name><surname>Huo</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Inagaki</surname> <given-names>HK</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>G</given-names></string-name>, <string-name><surname>Davis</surname> <given-names>C</given-names></string-name>, <string-name><surname>Hansel</surname> <given-names>D</given-names></string-name>, <string-name><surname>Guo</surname> <given-names>C</given-names></string-name>, <string-name><surname>Svoboda</surname> <given-names>K.</given-names></string-name></person-group> <article-title>Spatiotemporal Constraints on Optogenetic Inactivation in Cortical Circuits</article-title>. <source>eLife</source>. <year>2019</year> <month>Nov</month>; <volume>8</volume>:<elocation-id>e48622</elocation-id>. doi: <pub-id pub-id-type="doi">10.7554/eLife.48622</pub-id>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Guo</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Zhang</surname> <given-names>S</given-names></string-name>, <string-name><surname>Deng</surname> <given-names>S</given-names></string-name>, <string-name><surname>Hai</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Gu</surname> <given-names>S.</given-names></string-name></person-group> <article-title>Differentiable Spike: Rethinking Gradient-Descent for Training Spiking Neural Networks</article-title>. <source>Advances in Neural Information Processing Systems</source>, vol. <volume>34</volume> <year>2021</year>. p. <fpage>23426</fpage>–<lpage>23439</lpage>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lin</surname> <given-names>JY</given-names></string-name>, <string-name><surname>Mukherjee</surname> <given-names>N</given-names></string-name>, <string-name><surname>Bernstein</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Katz</surname> <given-names>DB</given-names></string-name></person-group>. <article-title>Perturbation of Amygdala-Cortical Projections Reduces Ensemble Coherence of Palatability Coding in Gustatory Cortex</article-title>. <source>eLife</source>. <year>2021</year> <month>May</month>; <volume>10</volume>:<elocation-id>e65766</elocation-id>. doi: <pub-id pub-id-type="doi">10.7554/eLife.65766</pub-id>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Livneh</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Andermann</surname> <given-names>ML</given-names></string-name></person-group>. <article-title>Cellular Activity in Insular Cortex across Seconds to Hours: Sensations and Predictions of Bodily States</article-title>. <source>Neuron</source>. <year>2021</year> <month>Nov</month>; <volume>109</volume>(<issue>22</issue>):<fpage>3576</fpage>–<lpage>3593</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2021.08.036</pub-id>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Livneh</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Ramesh</surname> <given-names>RN</given-names></string-name>, <string-name><surname>Burgess</surname> <given-names>CR</given-names></string-name>, <string-name><surname>Levandowski</surname> <given-names>KM</given-names></string-name>, <string-name><surname>Madara</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Fenselau</surname> <given-names>H</given-names></string-name>, <string-name><surname>Goldey</surname> <given-names>GJ</given-names></string-name>, <string-name><surname>Diaz</surname> <given-names>VE</given-names></string-name>, <string-name><surname>Jikomes</surname> <given-names>N</given-names></string-name>, <string-name><surname>Resch</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Lowell</surname> <given-names>BB</given-names></string-name>, <string-name><surname>Andermann</surname> <given-names>ML</given-names></string-name></person-group>. <article-title>Homeostatic Circuits Selectively Gate Food Cue Responses in Insular Cortex</article-title>. <source>Nature</source>. <year>2017</year> <month>Jun</month>; <volume>546</volume>(<issue>7660</issue>):<fpage>611</fpage>–<lpage>616</lpage>. doi: <pub-id pub-id-type="doi">10.1038/nature22375</pub-id>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Livneh</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Sugden</surname> <given-names>AU</given-names></string-name>, <string-name><surname>Madara</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Essner</surname> <given-names>RA</given-names></string-name>, <string-name><surname>Flores</surname> <given-names>VI</given-names></string-name>, <string-name><surname>Sugden</surname> <given-names>LA</given-names></string-name>, <string-name><surname>Resch</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Lowell</surname> <given-names>BB</given-names></string-name>, <string-name><surname>Andermann</surname> <given-names>ML</given-names></string-name></person-group>. <article-title>Estimation of Current and Future Physiological States in Insular Cortex</article-title>. <source>Neuron</source>. <year>2020</year> <month>Mar</month>; <volume>105</volume>(<issue>6</issue>):<fpage>1094</fpage>–<lpage>1111.e10</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2019.12.027</pub-id>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Mahmood</surname> <given-names>A</given-names></string-name>, <string-name><surname>Steindler</surname> <given-names>JR</given-names></string-name>, <string-name><surname>Katz</surname> <given-names>DB</given-names></string-name></person-group>, <article-title>Perceptual Processing of Tastes Is Performed by the Amygdala-Cortical Loop</article-title>; <source>bioRxiv</source> <year>2025</year>. doi: <pub-id pub-id-type="doi">10.1101/2025.07.01.662567</pub-id>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mahmood</surname> <given-names>A</given-names></string-name>, <string-name><surname>Steindler</surname> <given-names>J</given-names></string-name>, <string-name><surname>Germaine</surname> <given-names>H</given-names></string-name>, <string-name><surname>Miller</surname> <given-names>P</given-names></string-name>, <string-name><surname>Katz</surname> <given-names>DB</given-names></string-name></person-group>. <article-title>Coupled Dynamics of Stimulus-Evoked Gustatory Cortical and Basolateral Amygdalar Activity</article-title>. <source>Journal of Neuroscience</source>. <year>2023</year> <month>Jan</month>; <volume>43</volume>(<issue>3</issue>):<fpage>386</fpage>–<lpage>404</lpage>. doi: <pub-id pub-id-type="doi">10.1523/JNEUROSCI.1412-22.2022</pub-id>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Maier</surname> <given-names>JX</given-names></string-name>, <string-name><surname>Katz</surname> <given-names>DB</given-names></string-name></person-group>. <article-title>Neural Dynamics in Response to Binary Taste Mixtures</article-title>. <source>Journal of Neurophysiology</source>. <year>2013</year> <month>Apr</month>; <volume>109</volume>(<issue>8</issue>):<fpage>2108</fpage>–<lpage>2117</lpage>. doi: <pub-id pub-id-type="doi">10.1152/jn.00917.2012</pub-id>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Maxwell</surname> <given-names>SE</given-names></string-name>, <string-name><surname>Delaney</surname> <given-names>HD</given-names></string-name>, <string-name><surname>Kelley</surname> <given-names>K.</given-names></string-name></person-group> <source>Designing Experiments and Analyzing Data: A Model Comparison Perspective, Third Edition</source>. |<edition>3</edition> ed. <publisher-loc>New York</publisher-loc>: <publisher-name>Routledge</publisher-name>; <year>2017</year>. doi: <pub-id pub-id-type="doi">10.4324/9781315642956</pub-id>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mazzucato</surname> <given-names>L</given-names></string-name>, <string-name><surname>La Camera</surname> <given-names>G</given-names></string-name>, <string-name><surname>Fontanini</surname> <given-names>A.</given-names></string-name></person-group> <article-title>Expectation-Induced Modulation of Metastable Activity Underlies Faster Coding of Sensory Stimuli</article-title>. <source>Nature Neuroscience</source>. <year>2019</year> <month>May</month>; <volume>22</volume>(<issue>5</issue>):<fpage>787</fpage>–<lpage>796</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41593-019-0364-9</pub-id>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mazzucato</surname> <given-names>L</given-names></string-name>, <string-name><surname>Fontanini</surname> <given-names>A</given-names></string-name>, <string-name><surname>La Camera</surname> <given-names>G.</given-names></string-name></person-group> <article-title>Dynamics of Multistable States during Ongoing and Evoked Cortical Activity</article-title>. <source>The Journal of Neuroscience</source>. <year>2015</year> <month>May</month>; <volume>35</volume>(<issue>21</issue>):<fpage>8214</fpage>–<lpage>8231</lpage>. doi: <pub-id pub-id-type="doi">10.1523/JNEUROSCI.4819-14.2015</pub-id>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mazzucato</surname> <given-names>L</given-names></string-name>, <string-name><surname>Fontanini</surname> <given-names>A</given-names></string-name>, <string-name><surname>La Camera</surname> <given-names>G.</given-names></string-name></person-group> <article-title>Stimuli Reduce the Dimensionality of Cortical Activity</article-title>. <source>Frontiers in Systems Neuroscience</source>. <year>2016</year> <month>Feb</month>; <volume>10</volume>. doi: <pub-id pub-id-type="doi">10.3389/fnsys.2016.00011</pub-id>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mendoza</surname> <given-names>G</given-names></string-name>, <string-name><surname>Fonseca</surname> <given-names>E</given-names></string-name>, <string-name><surname>Merchant</surname> <given-names>H</given-names></string-name>, <string-name><surname>Gutierrez</surname> <given-names>R.</given-names></string-name></person-group> <article-title>Neuronal Sequences and Dynamic Coding of Water-Sucrose Categorization in Rat Gustatory Cortices</article-title>. <source>iScience</source>. <year>2024</year> <month>Dec</month>; <volume>27</volume>(<issue>12</issue>): <elocation-id>11287</elocation-id>. doi: <pub-id pub-id-type="doi">10.1016/j.isci.2024.111287</pub-id>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Miller</surname> <given-names>P</given-names></string-name>, <string-name><surname>Katz</surname> <given-names>DB</given-names></string-name></person-group>. <article-title>Stochastic Transitions between Neural States in Taste Processing and Decision-Making</article-title>. <source>The Journal of Neuroscience</source>. <year>2010</year> <month>Feb</month>; <volume>30</volume>(<issue>7</issue>):<fpage>2559</fpage>–<lpage>2570</lpage>. doi: <pub-id pub-id-type="doi">10.1523/JNEUROSCI.3047-09.2010</pub-id>.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Motulsky</surname> <given-names>H</given-names></string-name>, <string-name><surname>Christopoulos</surname> <given-names>A.</given-names></string-name></person-group> <source>Fitting Models to Biological Data Using Linear and Nonlinear Regression: A Practical Guide to Curve Fitting</source>. <publisher-name>Oxford University Press</publisher-name>; <year>2004</year>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mukherjee</surname> <given-names>N</given-names></string-name>, <string-name><surname>Wachutka</surname> <given-names>J</given-names></string-name>, <string-name><surname>Katz</surname> <given-names>DB</given-names></string-name></person-group>. <article-title>Impact of Precisely-Timed Inhibition of Gustatory Cortex on Taste Behavior Depends on Single-Trial Ensemble Dynamics</article-title>. <source>eLife</source>. <year>2019</year> <month>Jun</month>; <volume>8</volume>:<elocation-id>e45968</elocation-id>. doi: <pub-id pub-id-type="doi">10.7554/eLife.45968</pub-id>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Niessing</surname> <given-names>J</given-names></string-name>, <string-name><surname>Friedrich</surname> <given-names>RW</given-names></string-name></person-group>. <article-title>Olfactory Pattern Classification by Discrete Neuronal Network States</article-title>. <source>Nature</source>. <year>2010</year> <month>May</month>; <volume>465</volume>(<issue>7294</issue>):<fpage>47</fpage>–<lpage>52</lpage>. doi: <pub-id pub-id-type="doi">10.1038/nature08961</pub-id>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pachitariu</surname> <given-names>M</given-names></string-name>, <string-name><surname>Sridhar</surname> <given-names>S</given-names></string-name>, <string-name><surname>Pennington</surname> <given-names>J</given-names></string-name>, <string-name><surname>Stringer</surname> <given-names>C.</given-names></string-name></person-group> <article-title>Spike Sorting with Kilosort4</article-title>. <source>Nature Methods</source>. <year>2024</year> <month>May</month>; <volume>21</volume>(<issue>5</issue>):<fpage>914</fpage>–<lpage>921</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41592-024-02232-7</pub-id>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Paszke</surname> <given-names>A</given-names></string-name>, <string-name><surname>Gross</surname> <given-names>S</given-names></string-name>, <string-name><surname>Massa</surname> <given-names>F</given-names></string-name>, <string-name><surname>Lerer</surname> <given-names>A</given-names></string-name>, <string-name><surname>Bradbury</surname> <given-names>J</given-names></string-name>, <string-name><surname>Chanan</surname> <given-names>G</given-names></string-name>, <string-name><surname>Killeen</surname> <given-names>T</given-names></string-name>, <string-name><surname>Lin</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Gimelshein</surname> <given-names>N</given-names></string-name>, <string-name><surname>Antiga</surname> <given-names>L</given-names></string-name>, <string-name><surname>Desmaison</surname> <given-names>A</given-names></string-name>, <string-name><surname>Kopf</surname> <given-names>A</given-names></string-name>, <string-name><surname>Yang</surname> <given-names>E</given-names></string-name>, <string-name><surname>DeVito</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Raison</surname> <given-names>M</given-names></string-name>, <string-name><surname>Tejani</surname> <given-names>A</given-names></string-name>, <string-name><surname>Chilamkurthy</surname> <given-names>S</given-names></string-name>, <string-name><surname>Steiner</surname> <given-names>B</given-names></string-name>, <string-name><surname>Fang</surname> <given-names>L</given-names></string-name>, <string-name><surname>Bai</surname> <given-names>J</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>PyTorch: An Imperative Style, High-Performance Deep Learning Library</article-title>. <source>Advances in Neural Information Processing Systems</source>, vol. <volume>32</volume> <year>2019</year>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Perich</surname> <given-names>MG</given-names></string-name>, <string-name><surname>Arlt</surname> <given-names>C</given-names></string-name>, <string-name><surname>Soares</surname> <given-names>S</given-names></string-name>, <string-name><surname>Young</surname> <given-names>ME</given-names></string-name>, <string-name><surname>Mosher</surname> <given-names>CP</given-names></string-name>, <string-name><surname>Minxha</surname> <given-names>J</given-names></string-name>, <string-name><surname>Carter</surname> <given-names>E</given-names></string-name>, <string-name><surname>Rutishauser</surname> <given-names>U</given-names></string-name>, <string-name><surname>Rudebeck</surname> <given-names>PH</given-names></string-name>, <string-name><surname>Harvey</surname> <given-names>CD</given-names></string-name>, <string-name><surname>Rajan</surname> <given-names>K</given-names></string-name></person-group>, <article-title>Inferring Brain-Wide Interactions Using Data-Constrained Recurrent Neural Network Models</article-title>; <source>bioRxiv</source> <year>2020</year>. doi: <pub-id pub-id-type="doi">10.1101/2020.12.18.423348</pub-id>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rajan</surname> <given-names>K</given-names></string-name>, <string-name><surname>Harvey</surname> <given-names>CD</given-names></string-name>, <string-name><surname>Tank</surname> <given-names>DW</given-names></string-name></person-group>. <article-title>Recurrent Network Models of Sequence Generation and Memory</article-title>. <source>Neuron</source>. <year>2016</year> <month>Apr</month>; <volume>90</volume>(<issue>1</issue>):<fpage>128</fpage>–<lpage>142</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2016.02.009</pub-id>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Reinert</surname> <given-names>S</given-names></string-name>, <string-name><surname>Hübener</surname> <given-names>M</given-names></string-name>, <string-name><surname>Bonhoeffer</surname> <given-names>T</given-names></string-name>, <string-name><surname>Goltstein</surname> <given-names>PM</given-names></string-name></person-group>. <article-title>Mouse Prefrontal Cortex Represents Learned Rules for Categorization</article-title>. <source>Nature</source>. <year>2021</year> <month>May</month>; <volume>593</volume>(<issue>7859</issue>):<fpage>411</fpage>–<lpage>417</lpage>. doi: <pub-id pub-id-type="doi">10.1038/s41586-021-03452-z</pub-id>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sadacca</surname> <given-names>BF</given-names></string-name>, <string-name><surname>Mukherjee</surname> <given-names>N</given-names></string-name>, <string-name><surname>Vladusich</surname> <given-names>T</given-names></string-name>, <string-name><surname>Li</surname> <given-names>JX</given-names></string-name>, <string-name><surname>Katz</surname> <given-names>DB</given-names></string-name>, <string-name><surname>Miller</surname> <given-names>P.</given-names></string-name></person-group> <article-title>The Behavioral Relevance of Cortical Neural Ensemble Responses Emerges Suddenly</article-title>. <source>The Journal of Neuroscience</source>. <year>2016</year> <month>Jan</month>; <volume>36</volume>(<issue>3</issue>):<fpage>655</fpage>–<lpage>669</lpage>. doi: <pub-id pub-id-type="doi">10.1523/JNEUROSCI.2265-15.2016</pub-id>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Samuelsen</surname> <given-names>CL</given-names></string-name>, <string-name><surname>Gardner</surname> <given-names>MPH</given-names></string-name>, <string-name><surname>Fontanini</surname> <given-names>A.</given-names></string-name></person-group> <article-title>Effects of Cue-Triggered Expectation on Cortical Processing of Taste</article-title>. <source>Neuron</source>. <year>2012</year> <month>Apr</month>; <volume>74</volume>(<issue>2</issue>):<fpage>410</fpage>–<lpage>422</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2012.02.031</pub-id>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Shamash</surname> <given-names>P</given-names></string-name>, <string-name><surname>Carandini</surname> <given-names>M</given-names></string-name>, <string-name><surname>Harris</surname> <given-names>KD</given-names></string-name>, <string-name><surname>Steinmetz</surname> <given-names>NA</given-names></string-name></person-group>, <article-title>A Tool for Analyzing Electrode Tracks from Slice Histology</article-title>; <source>bioRxiv</source> <year>2018</year>. doi: <pub-id pub-id-type="doi">10.1101/447995</pub-id>.</mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shuler</surname> <given-names>MG</given-names></string-name>, <string-name><surname>Bear</surname> <given-names>MF</given-names></string-name></person-group>. <article-title>Reward Timing in the Primary Visual Cortex</article-title>. <source>Science</source>. <year>2006</year> <month>Mar</month>; <volume>311</volume>(<issue>5767</issue>):<fpage>1606</fpage>–<lpage>1609</lpage>. doi: <pub-id pub-id-type="doi">10.1126/science.1123513</pub-id>.</mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Song</surname> <given-names>HF</given-names></string-name>, <string-name><surname>Yang</surname> <given-names>GR</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>XJ</given-names></string-name></person-group>. <article-title>Training Excitatory-Inhibitory Recurrent Neural Networks for Cognitive Tasks: A Simple and Flexible Framework</article-title>. <source>PLOS Computational Biology</source>. <year>2016</year> <month>Feb</month>; <volume>12</volume>(<issue>2</issue>):<fpage>e1004792</fpage>. doi: <pub-id pub-id-type="doi">10.1371/jour-nal.pcbi.1004792</pub-id>.</mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stapleton</surname> <given-names>JR</given-names></string-name></person-group>. <article-title>Ensembles of Gustatory Cortical Neurons Anticipate and Discriminate between Tastants in a Single Lick</article-title>. <source>Frontiers in Neuroscience</source>. <year>2007</year> <month>Nov</month>; <volume>1</volume>(<issue>1</issue>):<fpage>161</fpage>–<lpage>174</lpage>. doi: <pub-id pub-id-type="doi">10.3389/neuro.01.1.1.012.2007</pub-id>.</mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Valente</surname> <given-names>A</given-names></string-name>, <string-name><surname>Pillow</surname> <given-names>JW</given-names></string-name>, <string-name><surname>Ostojic</surname> <given-names>S.</given-names></string-name></person-group> <article-title>Extracting Computational Mechanisms from Neural Data Using Low-Rank RNNs</article-title>. <source>Advances in Neural Information Processing Systems</source>. <year>2022</year> <month>Dec</month>; <volume>35</volume>:<fpage>24072</fpage>–<lpage>24086</lpage>.</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vincis</surname> <given-names>R</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>K</given-names></string-name>, <string-name><surname>Czarnecki</surname> <given-names>L</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>J</given-names></string-name>, <string-name><surname>Fontanini</surname> <given-names>A.</given-names></string-name></person-group> <article-title>Dynamic Representation of Taste-Related Decisions in the Gustatory Insular Cortex of Mice</article-title>. <source>Current Biology</source>. <year>2020</year> <month>May</month>; <volume>30</volume>(<issue>10</issue>):<fpage>1834</fpage>–<lpage>1844.e5</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.cub.2020.03.012</pub-id>.</mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vincis</surname> <given-names>R</given-names></string-name>, <string-name><surname>Fontanini</surname> <given-names>A.</given-names></string-name></person-group> <article-title>A Gustocentric Perspective to Understanding Primary Sensory Cortices</article-title>. <source>Current Opinion in Neurobiology</source>. <year>2016</year> <month>Oct</month>; <volume>40</volume>:<fpage>118</fpage>–<lpage>124</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.conb.2016.06.008</pub-id>.</mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yamamoto</surname> <given-names>T</given-names></string-name>, <string-name><surname>Yuyama</surname> <given-names>N</given-names></string-name>, <string-name><surname>Kato</surname> <given-names>T</given-names></string-name>, <string-name><surname>Kawamura</surname> <given-names>Y.</given-names></string-name></person-group> <article-title>Gustatory Responses of Cortical Neurons in Rats</article-title>. <source>II. Information Processing of Taste Quality. Journal of Neurophysiology</source>. <year>1985</year> <month>Jun</month>; <volume>53</volume>(<issue>6</issue>):<fpage>1356</fpage>–<lpage>1369</lpage>. doi: <pub-id pub-id-type="doi">10.1152/jn.1985.53.6.1356</pub-id>.</mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname> <given-names>GR</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>XJ</given-names></string-name></person-group>. <article-title>Artificial Neural Networks for Neuroscientists: A Primer</article-title>. <source>Neuron</source>. <year>2020</year> <month>Sep</month>; <volume>107</volume>(<issue>6</issue>):<fpage>1048</fpage>– <lpage>1070</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2020.09.005</pub-id>.</mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zheng</surname> <given-names>CY</given-names></string-name>, <string-name><surname>Blackwell</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Fontanini</surname> <given-names>A.</given-names></string-name></person-group> <article-title>Deficits in Taste-Guided Behaviors and Central Processing of Taste in the Transgenic TDP-43Q331K Mouse Model of Frontotemporal Dementia</article-title>. <source>Neurobiology of Disease</source>. <year>2025</year> <month>Apr</month>; <volume>207</volume>:<fpage>106850</fpage>. doi: <pub-id pub-id-type="doi">10.1016/j.nbd.2025.106850</pub-id>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.109313.1.sa4</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Kahnt</surname>
<given-names>Thorsten</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>National Institute on Drug Abuse Intramural Research Program</institution>
</institution-wrap>
<city>Baltimore</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Compelling</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>important</bold> work advances our understanding of the single neuron coding types in the mouse gustatory cortex and the functional roles of these neurons for perceptual decision-making. The conclusions are based on <bold>compelling</bold> evidence from rigorous behavioral experiments, high-density electrophysiology, sophisticated data analysis, and neural network modeling with in silico perturbations of functionally-identified units. This work will be of broad interest to systems neuroscientists.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.109313.1.sa3</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This manuscript provides several important findings that advance our current knowledge about the function of the gustatory cortex (GC). The authors used high-density electrophysiology to record neural activity during a sucrose/NaCl mixture discrimination task. They observed population-based activity capable of representing different mixtures in a linear fashion during the initial stimulus sampling period, as well as representing the behavioral decision (i.e., lick left or right) at a later time point. Analyzing this data at the single neuron level, they observed functional subpopulations capable of encoding the specific mixture (e.g., 45/55), tastant (e.g., sucrose), and behavioral choice (e.g., lick left). To test the functional consequences of these subpopulations, they built a recurrent neural network model in order to &quot;silence&quot; specific functional subpopulations of GC neurons. The virtual ablation of these functional subpopulations altered virtual behavioral performance in a manner predicted by the subpopulation's presumed contribution.</p>
<p>Strengths:</p>
<p>Building a recurrent neural network model of the gustatory cortex allows the impact of the temporal sequence of functionally identifiable populations of neurons to be tested in a manner not otherwise possible. Specifically, the author's model links neural activity at the single neuron and population level with perceptual ability. The electrophysiology methods and analyses used to shape the network model are appropriate. Overall, the conclusions of the manuscript are well supported.</p>
<p>Weaknesses:</p>
<p>One potential concern is the apparent mismatch between the neural and behavioral data. Neural analyses indicate a clear separation of the activity associated with each mixture that is independent of the animal's ultimate choice. This would seemingly indicate that the animals are making errors despite correctly encoding the stimulus. Based solely on the neural data, one would expect the psychometric curve to be more &quot;step-like&quot; with a significantly steeper slope. One potential explanation for this observation is the concentration of the stimuli utilized in the mixture discrimination task. The authors utilize equivalent concentrations, rather than intensity-matched concentrations. In this case, a single stimulus can (theoretically) dominate the perception of a mixture, resulting in a biased behavioral response despite accurate concentration coding at the single neuron level. Given the difficulty of isointensity matching concentrations, this concern is not paramount. However, the apparent mismatch between the neural and behavioral data should be acknowledged/addressed in the text.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.109313.1.sa2</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Lang et al. investigate the contribution of individual neuronal encoding of specific task features to population dynamics and behavior. Using a taste-based decision-making behavioral task with electrophysiology from the mouse gustatory cortex and computational modeling, the authors reveal that neurons encoding sensory, perceptual, and decision-related information with linear and categorical patterns are essential for driving neural population dynamics and behavioral performance. Their findings suggest that individual linear and categorical coding units have a significant role in cortical dynamics and perceptual decision-making behavior.</p>
<p>Overall, the experimental and analytical work is of very high quality, and the findings are of great interest to the taste coding field, as well as to the broader systems neuroscience field.</p>
<p>I have a couple of suggestions to further enhance the authors' important conclusions:</p>
<p>My main comment is the distinction between constrained and unconstrained units. The authors train a small percentage of units to match the real neural data (constrained units), and then find some unconstrained units that are similar to the real neural data and some that are not. As far as I could tell, the relative fraction of constrained and unconstrained units in the trained RNN is not reported; I assume the constrained ones are a much smaller population, but this is unclear. The selection of different groups of neurons for the RNN ablation experiments appears to be based on their response profiles only. Therefore, if I understood correctly, both constrained and unconstrained units and ablated together for a given response category (e.g., linear or step-perception). It would be useful, therefore, to separately compare the effects of constrained vs. unconstrained RNN units.</p>
<p>Specifically:</p>
<p>(1) For the analyses in the initial version of the manuscript, the authors should specify how many units in each ablation category are constrained and unconstrained.</p>
<p>(2) The authors should repeat Figure 6, but only for unconstrained units to test how much of the effects in the initial version of Figure 6 are driven by constrained vs. unconstrained RNN units.</p>
<p>(3) The authors should repeat Figure 7, but performing ablations separately on the constrained and unconstrained units to examine how the network behaves in each case and the resulting &quot;behavioral&quot; effect.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.109313.1.sa1</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Primary taste cortex neurons show a variety of dynamic response profiles during taste decision-making tasks, reflecting both sensory and decision variables. In the present study, Lang et al. set out to determine how neurons with distinct response profiles contribute to perceptual decisions about taste stimuli.</p>
<p>The methods, with reference to the behavioral task and electrophysiological recordings/data analysis, are straightforward, solid, and appropriate. The computational model is presented in a clear and conceptually intuitive manner, although the details are outside of my area of expertise.</p>
<p>The experimental design features a simple 2-alternative forced-choice design that yielded clear psychometric curves across a range of stimuli. In vivo recordings were performed using Neuropixels and yielded an appropriate sample of single neuron responses. The strength of the model lies in the fact that it consists of single neurons whose response profiles mimic those recorded in vivo, and allows neuron-selective manipulation.</p>
<p>By virtually lesioning specific subsets of neurons in the network, the authors demonstrate that a relatively small population of neurons with specific tuning profiles was sufficient to produce the observed neural dynamics and behavioral responses. This effect was selective as lesioning other responsive neurons did not affect overall response dynamics or performance.</p>
<p>These findings provide new insight into the relation between the response profiles of single neurons in sensory cortex, their population-level activity dynamics, and the perceptual decisions they inform.</p>
<p>The approach is particularly innovative as it uses computational modeling to target functionally-defined &quot;cell types&quot;, which cannot necessarily be targeted by more conventional genetic approaches.</p>
</body>
</sub-article>
<sub-article id="sa4" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.109313.1.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Lang</surname>
<given-names>Liam</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5606-6370</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Zheng</surname>
<given-names>Camelia Yuejiao</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Blackwell</surname>
<given-names>Jennifer M</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Camera</surname>
<given-names>Giancarlo La</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7834-6472</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Fontanini</surname>
<given-names>Alfredo</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4561-9563</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Public review):</bold></p>
<p>This manuscript provides several important findings that advance our current knowledge about the function of the gustatory cortex (GC). The authors used high-density electrophysiology to record neural activity during a sucrose/NaCl mixture discrimination task. They observed population-based activity capable of representing different mixtures in a linear fashion during the initial stimulus sampling period, as well as representing the behavioral decision (i.e., lick left or right) at a later time point. Analyzing this data at the single neuron level, they observed functional subpopulations capable of encoding the specific mixture (e.g., 45/55), tastant (e.g., sucrose), and behavioral choice (e.g., lick left). To test the functional consequences of these subpopulations, they built a recurrent neural network model in order to &quot;silence&quot; specific functional subpopulations of GC neurons. The virtual ablation of these functional subpopulations altered virtual behavioral performance in a manner predicted by the subpopulation's presumed contribution.</p>
<p>Strengths:</p>
<p>Building a recurrent neural network model of the gustatory cortex allows the impact of the temporal sequence of functionally identifiable populations of neurons to be tested in a manner not otherwise possible. Specifically, the author's model links neural activity at the single neuron and population level with perceptual ability. The electrophysiology methods and analyses used to shape the network model are appropriate. Overall, the conclusions of the manuscript are well supported.</p>
<p>Weaknesses:</p>
<p>One potential concern is the apparent mismatch between the neural and behavioral data. Neural analyses indicate a clear separation of the activity associated with each mixture that is independent of the animal's ultimate choice. This would seemingly indicate that the animals are making errors despite correctly encoding the stimulus. Based solely on the neural data, one would expect the psychometric curve to be more &quot;step-like&quot; with a significantly steeper slope. One potential explanation for this observation is the concentration of the stimuli utilized in the mixture discrimination task. The authors utilize equivalent concentrations, rather than intensity-matched concentrations. In this case, a single stimulus can (theoretically) dominate the perception of a mixture, resulting in a biased behavioral response despite accurate concentration coding at the single neuron level. Given the difficulty of isointensity matching concentrations, this concern is not paramount. However, the apparent mismatch between the neural and behavioral data should be acknowledged/addressed in the text.</p>
</disp-quote>
<p>We thank the Reviewer for the insightful comments and thoughtful suggestions. Our electrophysiological recordings show that GC dynamically encodes stimulus concentration of mixture elements, dominant perceptual quality, and decisions of directional lick. With regard to the encoding of mixtures, the clear separation of activity associated with each mixture (Figure 3) is present at a trial-averaged pseudo-population level, and average activities associated with more similar, intermediate mixtures are closer to each other in this space. In fact, at a single trial level activity evoked by similar, intermediate mixtures can be hard to separate. This increased similarity can lead to behavioral errors resulting from either incorrect encoding of the stimulus or from the inability to interpret the stimuli to guide the correct decision.</p>
<p>The psychometric function, which shows that more distinct stimuli (100/0 vs 0/100) lead to fewer mistakes than more ambiguous, intermediate mixtures (55/45 vs 55/45), is consistent with the increased ambiguity of responses to intermediate mixtures and with the possibility that, compared to pure stimuli, intermediate mixtures lead to more trials in which the binary choice component of neural activity is inverted, resulting in more directional errors.</p>
<p>The Reviewer is correct that there could be a slight mismatch in the perceived intensity of the mixture components. This mismatch could be the reason for the slight asymmetry in our psychometric function (Figure 1B). However, it is not uncommon for mice in these 2AC tasks to also have a motor laterality bias in their responses that manifests itself for the more ambiguous stimuli. We chose not to model this bias given its subtlety and its unknown origin. Rather, we chose to model an ideal scenario in which stimuli have matched intensity and no motor bias exists. In the revised version we will discuss this issue.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public review):</bold></p>
<p>Lang et al. investigate the contribution of individual neuronal encoding of specific task features to population dynamics and behavior. Using a taste-based decision-making behavioral task with electrophysiology from the mouse gustatory cortex and computational modeling, the authors reveal that neurons encoding sensory, perceptual, and decision-related information with linear and categorical patterns are essential for driving neural population dynamics and behavioral performance. Their findings suggest that individual linear and categorical coding units have a significant role in cortical dynamics and perceptual decision-making behavior.</p>
<p>Overall, the experimental and analytical work is of very high quality, and the findings are of great interest to the taste coding field, as well as to the broader systems neuroscience field.</p>
<p>I have a couple of suggestions to further enhance the authors' important conclusions:</p>
<p>My main comment is the distinction between constrained and unconstrained units. The authors train a small percentage of units to match the real neural data (constrained units), and then find some unconstrained units that are similar to the real neural data and some that are not. As far as I could tell, the relative fraction of constrained and unconstrained units in the trained RNN is not reported; I assume the constrained ones are a much smaller population, but this is unclear. The selection of different groups of neurons for the RNN ablation experiments appears to be based on their response profiles only. Therefore, if I understood correctly, both constrained and unconstrained units and ablated together for a given response category (e.g., linear or step-perception). It would be useful, therefore, to separately compare the effects of constrained vs. unconstrained RNN units.</p>
</disp-quote>
<p>We thank the Reviewer for the constructive feedback and are pleased that the work is considered of broad interest. The Reviewer is correct that ablations were carried out with respect to response categories only and included both constrained and unconstrained units.</p>
<p>The ratio of total units to constrained units is fixed at 5.88, thus constrained units are ~17% of the network and unconstrained units are ~83%. This value is specified in the Methods (RNN: Components and dynamics), but we will report it in the Results of the revised manuscript as well for clarity.</p>
<disp-quote content-type="editor-comment">
<p>Specifically:</p>
<p>(1) For the analyses in the initial version of the manuscript, the authors should specify how many units in each ablation category are constrained and unconstrained.</p>
</disp-quote>
<p>In the revised manuscript, we will specify the fractions of constrained and unconstrained units within each response category. For convenience, they are reported here: Linear = 194 constrained and 691 unconstrained units; Step-perception = 147 constrained and 840 unconstrained units; Step-choice = 129 constrained and 814 unconstrained units; Other = 353 constrained and 1739 unconstrained units.</p>
<disp-quote content-type="editor-comment">
<p>(2) The authors should repeat Figure 6, but only for unconstrained units to test how much of the effects in the initial version of Figure 6 are driven by constrained vs. unconstrained RNN units.</p>
</disp-quote>
<p>In the revised version we will add a Supplemental Figure in which the contribution of constrained vs unconstrained units is addressed.</p>
<disp-quote content-type="editor-comment">
<p>(3) The authors should repeat Figure 7, but performing ablations separately on the constrained and unconstrained units to examine how the network behaves in each case and the resulting &quot;behavioral&quot; effect.</p>
</disp-quote>
<p>The revised version will include a Supplemental Figure with these simulations.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #3 (Public review):</bold></p>
<p>Primary taste cortex neurons show a variety of dynamic response profiles during taste decision-making tasks, reflecting both sensory and decision variables. In the present study, Lang et al. set out to determine how neurons with distinct response profiles contribute to perceptual decisions about taste stimuli.</p>
<p>The methods,with reference to the behavioral task and electrophysiological recordings/data analysis, are straightforward, solid, and appropriate. The computational model is presented in a clear and conceptually intuitive manner, although the details are outside of my area of expertise.</p>
<p>The experimental design features a simple 2-alternative forced-choice design that yielded clear psychometric curves across a range of stimuli. In vivo recordings were performed using Neuropixels and yielded an appropriate sample of single neuron responses. The strength of the model lies in the fact that it consists of single neurons whose response profiles mimic those recorded in vivo, and allows neuron-selective manipulation.By virtually lesioning specific subsets of neurons in the network, the authors demonstrate that a relatively small population of neurons with specific tuning profiles was sufficient to produce the observed neural dynamics and behavioral responses. This effect was selective as lesioning other responsive neurons did not affect overall response dynamics or performance.These findings provide new insight into the relation between the response profiles of single neurons in sensory cortex, their population-level activity dynamics, and the perceptual decisions they inform.</p>
<p>The approach is particularly innovative as it uses computational modeling to target functionally-defined &quot;cell types&quot;, which cannot necessarily be targeted by more conventional genetic approaches.</p>
</disp-quote>
<p>We thank the Reviewer for the positive assessment of our study.</p>
</body>
</sub-article>
</article>