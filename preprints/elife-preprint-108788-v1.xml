<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">108788</article-id>
<article-id pub-id-type="doi">10.7554/eLife.108788</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.108788.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories><title-group>
<article-title>Frequency-selective contrast sensitivity modulation driven by fine-tuned exogenous attention at the foveal scale</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0008-6637-2284</contrib-id>
<name>
<surname>Guzhang</surname>
<given-names>Yue</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>yzh191@u.rochester.edu</email>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Jaeger</surname>
<given-names>T Florian</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4773-8745</contrib-id>
<name>
<surname>Poletti</surname>
<given-names>Martina</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a4">4</xref>
<email>martina_poletti@urmc.rochester.edu</email>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/022kthw22</institution-id><institution>Department of Brain and Cognitive Sciences, University of Rochester</institution></institution-wrap>, <city>Rochester</city>, <country country="US">United States</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/022kthw22</institution-id><institution>Center for Visual Science, University of Rochester</institution></institution-wrap>, <city>Rochester</city>, <country country="US">United States</country></aff>
<aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/022kthw22</institution-id><institution>Goergen Institute for Data Science and Artificial Intelligence, University of Rochester</institution></institution-wrap>, <city>Rochester</city>, <country country="US">United States</country></aff>
<aff id="a4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/022kthw22</institution-id><institution>Department of Neurosciences, University of Rochester</institution></institution-wrap>, <city>Rochester</city>, <country country="US">United States</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Salinas</surname>
<given-names>Emilio</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Wake Forest University School of Medicine</institution>
</institution-wrap>
<city>Winston-Salem</city>
<country country="US">United States</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Luo</surname>
<given-names>Huan</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>Peking University</institution>
</institution-wrap>
<city>Beijing</city>
<country country="CN">China</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-12-08">
<day>08</day>
<month>12</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP108788</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-08-27">
<day>27</day>
<month>08</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-09-01">
<day>01</day>
<month>09</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.08.27.672541"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Guzhang et al</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Guzhang et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-108788-v1.pdf"/>
<abstract>
<p>Exogenous attention is a rapid, involuntary mechanism that automatically reallocates processing resources toward salient stimuli. It enhances visual sensitivity in the vicinity of the salient stimulus, both in extrafoveal regions and within the high-acuity foveola. While the spatial frequencies modulated by exogenous attention in extrafoveal vision are well characterized, it remains unknown how this mechanism operates within the foveola, which can resolve spatial frequencies up to 30 cycles per degree (CPD). Here, we examined which spatial frequencies were enhanced by fine-grained deployments of exogenous attention within this highest-acuity region of the visual field. Using high-precision eye-tracking and gaze-contingent display control to precisely localize gaze during attentional allocation, we found that exogenous attention at the foveal scale selectively enhances contrast sensitivity for low- to mid-range spatial frequencies (4–8 CPD), with no significant benefits for higher spatial frequencies (12–20 CPD). In contrast, attention-related benefits on asymptotic performance at the highest contrast were observed across a wide range of spatial frequencies. These results indicate that, despite the high-resolution capacity of the foveola, exogenous attention remains an inflexible mechanism that, even at this scale, selectively enhances contrast gain for lower spatial frequencies—mirroring its behavior in extrafoveal vision.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>

</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Visual spatial attention is a fundamental mechanism that enables both humans (<xref ref-type="bibr" rid="c8">Carrasco, 2011</xref>) and animals (<xref ref-type="bibr" rid="c65">Saban et al., 2017</xref>; <xref ref-type="bibr" rid="c26">Hahner and Nieder, 2025</xref>) to selectively process information from their environment. Often, shifts in spatial attention are accompanied by eye movements to focus on a specific location, a process known as overt spatial attention (<xref ref-type="bibr" rid="c34">Kaspar, 2013</xref>). However, covert spatial attention — the ability to shift attention independently of eye movements — is equally crucial in daily life. This ability enables us to monitor locations beyond our line of sight, such as when driving and keeping track of peripheral surroundings.</p>
<p>Covert spatial attention is typically categorized into two types: endogenous and exogenous attention. Endogenous attention refers to the voluntary allocation of processing resources to a specific location. While this shift occurs relatively slowly, taking approximately 200–300 ms to reach the target region, it can be sustained for an extended duration (<xref rid="c70" ref-type="bibr">Theeuwes, 1994</xref>; <xref rid="c19" ref-type="bibr">Findlay, 2003</xref>; <xref rid="c14" ref-type="bibr">Chica and Lupiáñez, 2009</xref>; <xref ref-type="bibr" rid="c8">Carrasco, 2011</xref>; <xref ref-type="bibr" rid="c17">Dugué et al., 2020</xref>). In contrast, exogenous attention is driven by salient stimuli that automatically capture attention (<xref rid="c70" ref-type="bibr">Theeuwes, 1994</xref>; <xref rid="c19" ref-type="bibr">Findlay, 2003</xref>; <xref rid="c14" ref-type="bibr">Chica and Lupiáñez, 2009</xref>; <xref ref-type="bibr" rid="c8">Carrasco, 2011</xref>; <xref ref-type="bibr" rid="c17">Dugué et al., 2020</xref>). This shift is rapid but transient, often followed by a phenomenon known as inhibition of return, moving attention away from the initially attended location (<xref ref-type="bibr" rid="c35">Klein, 2000</xref>; <xref rid="c14" ref-type="bibr">Chica and Lupiáñez, 2009</xref>). Compared to endogenous attention, exogenous attention is more automatic and less flexible <xref ref-type="bibr" rid="c16">Corbetta and Shulman (2002)</xref>; <xref ref-type="bibr" rid="c36">Knudsen (2007)</xref>; <xref ref-type="bibr" rid="c8">Carrasco (2011)</xref>.</p>
<p>Until recently, research on the effects of covert attention on visual perception has focused primarily on extrafoveal vision. A vast body of literature has demonstrated that covert attention enhances visual contrast sensitivity (<xref ref-type="bibr" rid="c11">Carrasco et al., 2000</xref>; <xref ref-type="bibr" rid="c47">Martínez-Trujillo and Treue, 2002</xref>; <xref ref-type="bibr" rid="c59">Reynolds and Chelazzi, 2004</xref>; <xref ref-type="bibr" rid="c52">Pestilli and Carrasco, 2005</xref>; <xref ref-type="bibr" rid="c41">Li et al., 2008</xref>; <xref ref-type="bibr" rid="c20">Foster et al., 2021</xref>) and increases spatial resolution (<xref ref-type="bibr" rid="c76">Yeshurun and Carrasco, 1998</xref>; <xref ref-type="bibr" rid="c12">Carrasco et al., 2002</xref>, <xref ref-type="bibr" rid="c10">2006</xref>; <xref ref-type="bibr" rid="c32">Jigo and Carrasco, 2018</xref>) at selectively cued locations in the extrafovea. In contrast, attention within the high-acuity 1-deg foveola has often been considered uniform and distributed evenly throughout this small region. Therefore, the effects of attention in the fovea are traditionally studied using large stimuli encompassing one or more degrees of visual angle (<xref ref-type="bibr" rid="c48">Miniussi et al., 2002</xref>; <xref ref-type="bibr" rid="c33">Jigo and Carrasco, 2020</xref>; <xref ref-type="bibr" rid="c51">Papaioannou and Luck, 2020</xref>). However, recent findings showed that even within the 1-degree foveola, both endogenous (<xref ref-type="bibr" rid="c55">Poletti et al., 2017</xref>) and exogenous (<xref ref-type="bibr" rid="c24">Guzhang et al., 2021</xref>) attention can be covertly allocated in a highly spatially selective manner. For both types of covert attention, observers were better able to discriminate the orientation of fine details at an attended location—cued endogenously or exogenously—compared to nearby uncued locations just 0.26° away. Although these results highlighted the strikingly fine grain of attentional control, they also raised new questions. In particular, it remains unknown which spatial frequencies benefit from fine-grained attentional shifts within the foveola. While <bold><italic>Guzhang et al</italic></bold>. demonstrated visual enhancement from exogenous attention at the foveal scale, the orientation discrimination task used in the study was relatively coarse, requiring participants to determine whether a stimulus was tilted ±45°. Despite the small size of the stimulus, such a task does not require high spatial frequencies (<italic>e</italic>.<italic>g., &gt;</italic> 10 cycles per degree); in fact, frequencies around 4-8 cycles per degree (CPD) should be sufficient to perform it effectively. Therefore, the perceptual enhancement observed in <bold><italic>Guzhang</italic></bold> et al. could be due to an enhancement of only lower or only higher spatial frequencies, or perhaps a broad range of spatial frequencies. The overall improvement in orientation discrimination of fine spatial stimuli is compatible with any of these scenarios.</p>
<p>The effects of <italic>extra</italic>foveal attention have been found to differ across spatial frequencies: while extrafoveal endogenous attention enhances a broad range of spatial frequencies (<xref ref-type="bibr" rid="c45">Lu and Dosher, 2004</xref>; <xref ref-type="bibr" rid="c33">Jigo and Carrasco, 2020</xref>), extrafoveal exogenous attention selectively enhances high spatial frequencies (<xref ref-type="bibr" rid="c10">Carrasco et al., 2006</xref>; <xref ref-type="bibr" rid="c1">Barbot et al., 2011</xref>, <xref ref-type="bibr" rid="c2">2012</xref>; <xref ref-type="bibr" rid="c13">Carretié et al., 2012</xref>; <xref ref-type="bibr" rid="c33">Jigo and Carrasco, 2020</xref>; <xref ref-type="bibr" rid="c18">Fernández et al., 2022</xref>), peaking just above the spatial frequency characterized by the highest sensitivity at a given eccentricity (<xref ref-type="bibr" rid="c33">Jigo and Carrasco, 2020</xref>). Whether fine spatial exogenous attention at the foveal scale modulates visual discrimination similarly is an open question. Generally, fine control of spatial attention at the foveal scale is required when examining fine spatial details, such as reading small text in a book or noticing subtle changes, like a traffic light switching or unexpected pedestrians from afar while driving (<xref rid="fig1" ref-type="fig">Figure 1A</xref>). In these tasks, precise allocation of attention likely helps distinguishing and recognizing individual letters and details. It is possible that in the foveola, exogenous attention modulates a narrow range of spatial frequencies, similar to how it operates extrafoveally. However, while humans can resolve spatial frequencies up to 30 cycles per degree (CPD) in the foveola (<xref ref-type="bibr" rid="c30">Intoy and Rucci, 2020</xref>; <xref ref-type="bibr" rid="c15">Clark et al., 2022</xref>), extrafoveally, spatial frequencies above 10 CPD cannot be resolved. Therefore, even if the perceptual enhancement driven by fine spatial attention is limited to a narrow range of lower spatial frequencies, the enhanced frequency range may shift toward higher spatial frequencies in the foveola compared to what happens extrafoveally (<xref rid="fig1" ref-type="fig">Figure 1<italic>B</italic></xref>). Alternatively, attention at the foveal scale might preserve its enhancement of low spatial frequencies while extending it to high spatial frequencies, leading to a broad, rather than narrow, range of modulation (<xref rid="fig1" ref-type="fig">Figure 1<italic>C</italic></xref>). Any of these scenarios could account for the improvement in orientation discrimination observed in <bold><italic>Guzhang et al</italic></bold>..</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Fine-tuning exogenous attention within the foveola.</title>
<p>(<bold>A</bold>) Fine-tuning of exogenous attention within the foveola occurs, for example, when we are looking at a distant traffic light—occupying less than 1° of our visual field—that suddenly turns green, capturing our attention and prompting us to move forward. As a result of the fine-tuning of exogenous attention, contrast sensitivity could be enhanced for a narrow range of spatial frequencies, centered around lower spatial frequencies (blue) or higher spatial frequencies (green) (<bold>B</bold>). On the other hand, contrast sensitivity may be enhanced uniformly across a wide range of spatial frequencies (<bold>C</bold>).</p></caption>
<graphic xlink:href="672541v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>In the current study, we addressed two main questions. First, does exogenous attention at the foveolar scale enhance visual processing across a narrow or a broader range of spatial frequencies? Second, if the enhancement operated within a narrow frequency band, which range of spatial frequencies benefits the most from such fine-grained shifts of attention? Addressing these questions is crucial because, while it is now established that covert attention can be selectively shifted even within the central fovea, it remains unclear whether it follows the same <italic>modus operandi</italic> foveally and extrafoveally. If a similar range of spatial frequencies is enhanced by exogenous attention in both the foveola and extrafovea, it would suggest that exogenous attention operates similarly across the visual field, regardless of the spatial resolution achievable at different eccentricities. In contrast, if the modulation of spatial frequencies differs, it would indicate that the mechanisms of exogenous attention are flexibly tuned in the foveola and adjusted based on the spatial resolution that can be achieved at this scale.</p>
<p>Studying attentional control in the foveola presents unique challenges. Continuous microscopic eye movements during fixation cause constant displacement of the retinal input (<xref ref-type="bibr" rid="c46">Martinez-Conde et al., 2004</xref>; <xref ref-type="bibr" rid="c64">Rucci and Poletti, 2015</xref>; <xref ref-type="bibr" rid="c38">Krauzlis et al., 2017</xref>), making it difficult to limit visual stimulation to the desired eccentricity at this scale. This poses a significant issue when investigating covert attention in the central foveola. To address these challenges, we employed high-precision eye-tracking (<xref ref-type="bibr" rid="c73">Wu et al., 2023</xref>) combined with gaze-contingent display control (<xref ref-type="bibr" rid="c66">Santini et al., 2007</xref>) to precisely monitor gaze position throughout each trial to ensure that any effects observed are solely due to covert exogenous attention and are not driven by fixational saccades (<xref ref-type="bibr" rid="c25">Hafed and Clark, 2002</xref>; <xref ref-type="bibr" rid="c77">Yuval-Greenberg et al., 2014</xref>; <xref ref-type="bibr" rid="c68">Shelchkova and Poletti, 2020</xref>; <xref ref-type="bibr" rid="c23">Guzhang et al., 2024</xref>).</p>
</sec>
<sec id="s2">
<title>Results</title>
<p>To examine the effects of high-resolution exogenous attention within the fovea on visual discrimination of stimuli at different spatial frequencies, we employed a 2AFC visual discrimination task in which observers were asked to discriminate the orientation of a small Gabor patch (30′ x 30′ with an overlaying 5.4′ Gaussian window, tilted ±45<sup><italic>°</italic></sup>) 30′ from either left or right of the fixation marker when prompted by a response cue (<xref rid="fig2" ref-type="fig">Figure 2<italic>A</italic></xref>). Note that, the Gabor patches used in the current study were much smaller than those typically used in studies probing extrafoveal attention (<xref ref-type="bibr" rid="c61">Rossi and Paradiso, 1995</xref>; <xref ref-type="bibr" rid="c22">Gobell and Carrasco, 2005</xref>; <xref ref-type="bibr" rid="c28">Herrmann et al., 2010</xref>; <xref ref-type="bibr" rid="c33">Jigo and Carrasco, 2020</xref>). On each trial, the orientation and phase of the Gabor patch was randomized at each location independently. Eye movements were monitored at high resolution using a digital Dual Purkinje Image eye tracker (<xref ref-type="bibr" rid="c73">Wu et al., 2023</xref>) to ensure that observers maintained the center of gaze within a 10′×10′ window around the fixation point throughout the trial (<xref rid="fig2" ref-type="fig">Figure 2<italic>D</italic></xref>).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption>
<title>Experimental protocol.</title>
<p>(<bold>A</bold>) Trials started with a fixation marker at the center of the monitor. Observers were instructed to maintain fixation at the center throughout the trial. After a brief flash of the exogenous cue to capture observers’ attention, two Gabor patches independently tilted (±45<sup><italic>°</italic></sup>) were briefly displayed, one on each side of the fixation marker. At the end of the trial, a response cue appeared, and observers had to report the orientation of the stimulus that was previously presented at the cued location. (<bold>B</bold>) In valid trials, the exogenous cue and response cue indicated the same spatial location. In neutral trials, no exogenous cue was presented. Valid and neutral trials had the same probability of occurrence. The Gabor patches had a Gaussian window of 5.4′ standard deviation, creating a 30′ x 30′ visible region. (<bold>C</bold>) Stimuli used in the experiment. Gabor patch of all spatial frequencies tested from 4 to 20 cycles per degree (CPD). (<bold>D</bold>) 68% contour of the gaze probability distribution in valid and neutral conditions during Gabor presentation. Color represents individual observers. <xref ref-type="fig" rid="fig2_S1">Figure 2—figure supplement 1</xref>. Number of trials included in the analysis after filtering.</p>
</caption>
<graphic xlink:href="672541v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The experiment included two cueing conditions—valid and neutral—that were randomly interleaved with equal probability within each experimental block. In the valid condition, shifts of exogenous attention were elicited by a small and brief white flash (exogenous cue) presented 100 ms before the target either on the left or the right of the visual field. The cue, with 100% validity, appeared just outside the upcoming target location. In the neutral condition, no exogenous cue was presented.</p>
<p>We tested four spatial frequencies (SFs)—4, 8, 12, and 20 CPDs, <xref rid="fig2" ref-type="fig">Figure 2<italic>C</italic></xref>)—ensuring at least one full cycle of modulation within the Gabor patch even at the lowest SF (4 CPD) (<xref ref-type="bibr" rid="c29">Howell and Hess, 1978</xref>). The highest spatial frequency (20 CPD) is close to the limit of visual resolution at the eccentricity tested here. For each spatial frequency tested, an initial threshold contrast was estimated by methods of constant stimuli, then discrimination accuracy was measured at four contrast levels around the initial threshold estimate, and one additional level at the maximum contrast to measure the asymptotic performance (see Methods). The contrast level was kept constant within each experimental block but was randomized across blocks.</p>
<p>To examine how high-resolution exogenous attention influences performance for stimuli at different spatial frequencies, we fitted individual psychometric curves of contrast level versus discrimination accuracy and estimated contrast thresholds for each cueing condition and spatial frequency for each observer (<xref rid="fig3" ref-type="fig">Figure 3<italic>A</italic></xref> shows the psychometric curves for one example observer with the result of all psychometric curves included in <xref rid="fig3_S1" ref-type="fig">Figure 3—figure Supplement 1</xref>).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption>
<title>Effect of fine-grained exogenous attention on contrast sensitivity.</title>
<p>(<bold>A</bold>) Psychometric functions illustrating example observers’ discrimination accuracy for Gabor patches with spatial frequencies of 4, 8, 12, and 20 cycles per degree (CPD). The size of each dot corresponds to the number of trials included at a specific contrast value. Vertical lines indicate contrast thresholds, while horizontal lines represent the accuracy level midway between chance performance and maximum performance. (<bold>B</bold>) Average contrast sensitivity, calculated as the inverse of the contrast threshold, across spatial frequencies in valid and neutral conditions. Each dot represents an individual observer. Error bars denote the standard error of the mean (SEM). Asterisks mark a significant difference in contrast sensitivity between pairs of spatial frequencies. (<bold>C</bold>) Average contrast sensitivity in neutral condition against that in valid condition at each spatial frequency. Each dot represents an individual observer. Error bars indicate the bootstrapped confidence intervals. (<bold>D</bold>) Average difference in log-scaled contrast sensitivity between valid and neutral conditions across different spatial frequencies. Each line corresponds to the log-scaled contrast sensitivities from each observer. Error bars represent the bootstrapped confidence intervals. Asterisks mark post-hoc pairwise comparison results between valid and neutral conditions within each spatial frequency. <xref ref-type="fig" rid="fig3_S1">Figure 3—figure supplement 1</xref>. Psychometric functions for all observers in all conditions. <xref ref-type="fig" rid="fig3_S2">Figure 3—figure supplement 2</xref>. Contrast sensitivity results including 2 CPD. <xref ref-type="fig" rid="fig3_S3">Figure 3—figure supplement 3</xref>. Relation between mean and variability of contrast sensitivity (CS).</p>
</caption>
<graphic xlink:href="672541v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We first examined the full factorial effects of spatial frequency (SF) and cueing on contrast sensitivity estimated from the observers’ psychometric functions by fitting a linear mixed-effects regression to the estimates of log-transformed contrast sensitivity at all 8 conditions (4 SF x 2 cueing) across observers. The contrast sensitivity captures the effects on the intercept and/or slope of the psychometric function.</p>
<p>Consistent with the literature (<xref ref-type="bibr" rid="c29">Howell and Hess, 1978</xref>; <xref ref-type="bibr" rid="c4">Bex et al., 2009</xref>; <xref ref-type="bibr" rid="c44">Lovegrove et al., 1980</xref>; <xref ref-type="bibr" rid="c62">Rovamo et al., 1992</xref>, <xref ref-type="bibr" rid="c63">1993</xref>; <xref ref-type="bibr" rid="c54">Pointer and Hess, 1989</xref>), we observed a main effect of spatial frequency on contrast sensitivity (<italic>χ</italic><sup>2</sup>(3) = 65.3, <italic>p &lt;</italic> 0.0001, <xref rid="fig3" ref-type="fig">Figure 3<italic>B</italic></xref>); contrast sensitivity was highest at 4 CPD and decreased as the spatial frequency increased. [Post-hoc pairwise comparisons revealed several significant differences between spatial frequencies (post-hoc pairwise comparisons of the estimated marginal means, <italic>p</italic>s ≤ 0.0001 for 4 vs 8 CPD, 4 vs. 12 CPD, 4 vs. 20 CPD, 8 vs. 20 CPD, 12 vs. 20 CPD).] We also observed a significant main effect of attention on contrast sensitivity (<italic>χ</italic><sup>2</sup>(1) = 7.3, <italic>p &lt;</italic> 0.001; mean<sub>valid</sub> = 10.1 ± 7.56SD and mean<sub>neutral</sub> = 9.03 ± 6.39SD): averaging across all spatial frequencies, the valid cueing condition resulted in higher contrast sensitivity (<xref rid="fig3" ref-type="fig">Figure 3<italic>B, C</italic></xref>). These findings indicate that exogenous attention led to a contrast gain across spatial frequencies in the attended subfoveolar region.</p>
<p>Notably, the improvement in contrast sensitivity driven by fine-grained attention was not uniform across spatial frequencies (<xref rid="fig3" ref-type="fig">Figure 3<italic>D</italic></xref>, also visible in <xref rid="fig3" ref-type="fig">Figure 3<italic>B, C</italic></xref>). We observed a statistically significant interaction between spatial frequency and attention (<italic>χ</italic><sup>2</sup>(3) = 9.3, <italic>p</italic> = 0.0258), indicating that contrast gains were selective. Specifically, contrast sensitivity exhibited a contrast gain in the valid condition compared to the neutral condition at lower spatial frequencies (4 and 8 CPD) (mean gain<sub>4 CPD</sub> = 2.62 ± 2.13 SD and mean gain<sub>8 CPD</sub> = 1.36 ± 1.25 SD, <italic>p</italic>s<italic>&lt;</italic> 0.004). However, the contrast sensitivity gains at higher spatial frequencies (12 and 20 CPD) were smaller and did not reach statistical significance (mean gain<sub>12 CPD</sub> = 0.09 ± 0.91SD and mean gain<sub>20 CPD</sub> = 0.11 ± 0.13SD, <italic>p</italic>s<italic>&gt;</italic> 0.5). In addition to examining the contrast gain within each spatial frequency, we also compared the amount of contrast gain within each pair of spatial frequencies. Post-hoc pairwise comparisons revealed that attention modulation did not differ between the two low-mid spatial frequencies (4 and 8 CPD, <italic>p &gt;</italic> 0.8) or between the two mid-hight spatial frequencies (12 and 20 CPD, <italic>p &gt;</italic> 0.7). Importantly, attention led to a larger enhancement of contrast sensitivity at the low-mid spatial frequencies (4 and 8 CPD) compared to 12 CPD (Δmean gain<sub>4 CPD - 12 CPD</sub> = 2.53 ± 2.16SD and Δmean gain<sub>8 CPD - 12 CPD</sub> = 1.27 ± 0.99SD, <italic>p</italic>s<italic>&lt;</italic> 0.025). When comparing the low-mid spatial frequencies (4 and 8 CPD) to the highest spatial frequency tested (20 CPD), differences in contrast gains were even larger, though these effects were not statistically significant (Δmean gain<sub>4 CPD - 20 CPD</sub> = 3.35±1.96SD, <italic>p</italic> = 0.066 and Δmean gain<sub>8 CPD - 20 CPD</sub> = 1.45±1.46SD, <italic>p</italic> = 0.084). As detailed in Methods, two observers did not have data for the 20 CPD condition. Statistical power might thus have been reduced for comparisons against this condition.</p>
<p>These results demonstrate that, similar to the selectivity in enhancements in visual periphery, micro-shifts of exogenous attention within the central fovea selectively enhanced contrast sensitivity primarily for low- to mid-range frequencies (4 to 8 CPD).</p>
<p>In addition to contrast sensitivity, we examined the effects of attention on asymptotic performance. Research on <italic>extra</italic>foveal vision has returned mixed results with respect to the effects of exogenous attention on asymptotic performance. On the one hand, it has been found that both exogenous and endogenous attention can enhance not only contrast sensitivity (contrast gain) but also asymptotic performance, a phenomenon known as response gain (<xref ref-type="bibr" rid="c49">Morrone et al., 2002</xref>, <xref ref-type="bibr" rid="c50">2004</xref>; <xref ref-type="bibr" rid="c42">Ling and Carrasco, 2006</xref>; <xref ref-type="bibr" rid="c53">Pestilli et al., 2009</xref>; <xref ref-type="bibr" rid="c60">Reynolds and Heeger, 2009</xref>; <xref ref-type="bibr" rid="c28">Herrmann et al., 2010</xref>). For <italic>exogenous</italic> attention, however, some previous studies have found significant effects only on contrast sensitivity, with no notable impact on asymptotic performance in extrafoveal vision (<xref ref-type="bibr" rid="c7">Cameron et al., 2002</xref>; <xref ref-type="bibr" rid="c28">Herrmann et al., 2010</xref>; <xref ref-type="bibr" rid="c33">Jigo and Carrasco, 2020</xref>). It has been argued that whether covert attention influences contrast gain, response gain, or both, depends on stimulus size, size of the attended area as well as spatial uncertainty(<xref ref-type="bibr" rid="c28">Herrmann et al., 2010</xref>; <xref ref-type="bibr" rid="c74">Wu et al., 2021</xref>; <xref ref-type="bibr" rid="c60">Reynolds and Heeger, 2009</xref>).</p>
<p>To examine how asymptotic performance was impacted by micro-shifts of foveal exogenous attention across spatial frequencies, we fit a generalized linear mixed-effects regression to the estimated asymptotic performance from all 8 conditions of all observers. Observers’ ability to discriminate the orientation at full contrast (asymptotic performance) decreased with increasing frequency (<xref rid="fig4" ref-type="fig">Figure 4<italic>B, C</italic></xref>), but this change was not significant (<italic>χ</italic><sup>2</sup>(3) = 7.6, <italic>p</italic> = 0.0545). [Post-hoc pairwise comparisons revealed significant differences in asymptotic performance only between 8 and 20 CPD (<italic>p</italic> = 0.015) as well as 12 and 20 CPD (<italic>p</italic> = 0.048).] The main effect of attention was significant, with overall higher asymptotic performance in the valid condition compared to the neutral condition (<italic>χ</italic><sup>2</sup>(1) = 11.9, <italic>p &lt;</italic> 0.001; mean<sub>valid</sub> = 0.97 ± 0.03SD and mean<sub>neutral</sub> = 0.94 ± 0.04SD; see <xref rid="fig4" ref-type="fig">Figure 4<italic>A, C</italic></xref>). These findings suggest that fine-grained attention resulted in a general response gain, enhancing the ability to discriminate the orientation of high-contrast stimuli.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption>
<title>Effect of fine-grained exogenous attention on asymptotic performance.</title>
<p>(<bold>A</bold>) Average asymptotic performance, defined as discrimination accuracy at maximum contrast, pooled across spatial frequencies in valid and neutral conditions. Each dot represents an individual observer. Error bars denote the standard error of the mean (SEM). (<bold>B</bold>) Average asymptotic performance across spatial frequencies in valid and neutral conditions. Each dot represents an individual observer. Error bars denote the standard error of the mean (SEM). Asterisks mark a significant difference in asymptotic performance between pairs of spatial frequencies. (<bold>C</bold>) Average asymptotic performance in the neutral condition against that in the valid condition at each spatial frequency. Each dot represents an individual observer. Error bars indicate the bootstrapped confidence intervals. (<bold>D</bold>) Average difference in asymptotic performance between valid and neutral conditions across different spatial frequencies. Each line corresponds to an individual observer. Error bars indicate the bootstrapped confidence intervals. Asterisks mark post-hoc pairwise comparison results between valid and neutral conditions within each spatial frequency. <xref ref-type="fig" rid="fig4_S1">Figure 4—figure supplement 1</xref>. Maximum a posteriori (MAP) estimates (points) and 95% confidence intervals for contrast sensitivity (CS) and asymptotic performance (AP).</p>
</caption>
<graphic xlink:href="672541v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Unlike for contrast sensitivity, the effect of attention on asymptotic performance was not modulated by spatial frequency; we did not observe a significant interaction between spatial frequency and attention on asymptotic performance (<xref ref-type="fig" rid="fig4">Figs.4<italic>D</italic></xref>, <italic>χ</italic><sup>2</sup>(3) = 5.1, <italic>p &gt;</italic> 0.15). [Post-hoc pairwise comparisons between valid and neutral conditions within each spatial frequency revealed that attention significantly increased asymptotic performance compared to neutral condition at 8 and 12 CPD (mean gain<sub>8</sub> <sub>CPD</sub> = 0.05 ± 0.04SD, <italic>p &lt;</italic> 0.0001 and mean gain<sub>12 CPD</sub> = 0.03 ± 0.03SD, <italic>p</italic> = 0.0108) but not at 4 and 20 CPD (mean gain<sub>4 CPD</sub> = 0.02 ± 0.03SD, <italic>p</italic> = 0.0819 and Δmean gain<sub>20</sub> <sub>CPD</sub> = 0.03 ± 0.04SD, <italic>p</italic> = 0.0501). When comparing the attentional benefit on asymptotic performance across pairs of spatial frequencies, we found a significant difference (Δmean gain) only between 4 and 8 CPD (<italic>p</italic> = 0.0240).] Therefore, asymptotic performance showed only independent, additive effects of frequency and attention, without a systematic influence of spatial frequency on the attentional benefit.</p>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Whereas attention is often believed to be either uniformly allocated at the center of gaze or selectively shifted to locations outside of the central fovea, recent research has shown that humans are also capable of allocating attention within the central fovea in a spatially selective manner, enhancing our ability to perceive fine spatial stimuli (<xref ref-type="bibr" rid="c55">Poletti et al., 2017</xref>; <xref ref-type="bibr" rid="c24">Guzhang et al., 2021</xref>). Humans can focus processing resources on a specific region of the central fovea, enhancing visual processing within that small area while suppressing processing at other unattended locations just a few arcminutes away.</p>
<p>These findings raise the question of what spatial frequencies are enhanced by fine-grained shifts of covert attention within the foveola. In our previous work (<xref ref-type="bibr" rid="c24">Guzhang et al., 2021</xref>), observers were asked to perform a coarse orientation (±45°) discrimination task. This experiment did not manipulate spatial frequency. Subjectively, however, the stimuli in this task could be distinguished as long as frequency information of more than 3 cycles per degree (CPD) was available to the observer. The attentional gain we observed in the discrimination task could therefore have resulted from foveal exogenous attention enhancing spatial frequencies anywhere above 3 CPD. Thus, it remains unclear which spatial frequencies are enhanced when exogenous attention is allocated at the fine scale within the foveola. Additionally, it is unclear whether fine-grained attention in the foveola is governed by the same principles and is modulated similarly to extrafoveal attention, especially considering the stark differences in spatial resolution between the foveola and the rest of the visual field. The high-acuity foveola can resolve spatial frequencies up to 30 CPD, whereas just five degrees away from the center of gaze, this limit drops to around 10 CPD (<xref ref-type="bibr" rid="c72">Virsu and Rovamo, 1979</xref>). Therefore, rather than enhancing the same range of low spatial frequencies as for extrafoveal vision, fine-grained foveal attention may shift or extend its enhancement toward higher frequencies in the foveola.</p>
<p>Our findings indicate that fine-grained shifts of covert exogenous attention in the foveola enhance contrast sensitivity within a narrow range of spatial frequencies, peaking at low to mid frequencies (4–8 CPD). In particular, we found little or no attentional gain at higher spatial frequencies (12–20 CPD), which are closer to the limits of visual resolution at the eccentricity tested (0.3° from the preferred locus of fixation). Whereas enhancements in contrast sensitivity were relatively selective to a narrow band of spatial frequencies, overall asymptotic performance increased as a result of exogenous attention, with no detected dependence on spatial frequency. However, it is important to remember that the statistical power to detect the interaction might differ between analyses of contrast sensitivity and analyses of asymptotic performance, given that the latter (almost by definition) tends to involve differences close to its bounds (<xref ref-type="bibr" rid="c5">Bicknell et al., 2025</xref>; <xref ref-type="bibr" rid="c31">Jaeger, 2008</xref>).</p>
<p>These results shed light on the benefits of exogenous attention reported in <bold><italic>Guzhang et al</italic></bold>.. In that study, oriented bars were presented at threshold contrast levels. The results described here suggest that the performance improvements observed in <bold><italic>Guzhang et al</italic></bold>. were primarily driven by the enhancement of the low-mid spatial frequencies between 4 to 8 cycles per degree, which were sufficient to perform the coarse ±45° orientation discrimination task. In everyday life, we frequently rely on fine-grained exogenous attention, for example when a salient road sign captures our attention while we are looking into the distance while driving. Accurately identifying the details, such as the small texts on the road sign, often depends on the ability to perceive high spatial frequency components of the stimulus. Based on our findings, if the text on the road sign is at maximal contrast, drivers should benefit from exogenous attention, as we have shown that attention enhances asymptotic performance across a broad range of spatial frequencies, including those near the limits of visual resolution. However, if the sign is faded and the text is close to the threshold contrast, the benefit of exogenous attention will be minimal, as the high spatial frequencies crucial for resolving fine details receive little enhancement from fine-grained exogenous attention in the foveola.</p>
<p>For extrafoveal vision, exogenous attention has been reported to enhance contrast sensitivity selectively within a narrow range of spatial frequencies, peaking at the spatial frequency slightly higher than the ones with the highest contrast sensitivity for a given eccentricity, while sensitivity drops sharply at adjacent spatial frequencies (<xref ref-type="bibr" rid="c33">Jigo and Carrasco, 2020</xref>; <xref ref-type="bibr" rid="c18">Fernández et al., 2022</xref>). In our study, the small stimulus size required to assess localized attention within the foveola limited our ability to measure contrast sensitivity reliably for spatial frequencies below 4 CPD. Within the spatial frequency range we tested, we observed a monotonic decrease in contrast sensitivity from 4 CPD to 20 CPD as spatial frequency increased. Additionally, we conducted a post-hoc evaluation of contrast sensitivity at 2 CPD using the same Gabor patch size to estimate the peak spatial frequency (see <xref rid="fig3_S2" ref-type="fig">Figure 3—figure Supplement 2</xref>). We note that at 2 CPD, the stimulus contained less than one full cycle of modulation, which may have affected the observers’ performance (<xref ref-type="bibr" rid="c29">Howell and Hess, 1978</xref>). With this caveat in mind, our post-hoc analysis found similar levels of contrast sensitivity at 2 and 4 CPD. This, combined with the drop in contrast sensitivity at 8 CPD, suggests sensitivity might reach a plateau between 2 to 4 CPD. In addition, attention significantly improved contrast sensitivity at 2 CPD (pair-wise comparison did not reveal any difference in contrast gain between 2 CPD and the rest of the spatial frequencies tested). While our study was not specifically designed to examine the relationship between spatial frequencies with peak contrast sensitivity and those with peak contrast gain from attention, our results were in line with previous research studying the effects of exogenous attention in extrafoveal vision (<xref ref-type="bibr" rid="c33">Jigo and Carrasco, 2020</xref>; <xref ref-type="bibr" rid="c18">Fernández et al., 2022</xref>), showing a contrast gain in a similar range of spatial frequencies.</p>
<p>While the present study examined the range of spatial frequencies enhanced by fine-grained shifts of attention within the foveola, attention can also be distributed uniformly across the entire foveola. In such cases, it would be interesting to explore whether the range of spatial frequencies enhanced by the broadly distributed attention is comparable to that of fine-grained attention reported here. It is possible that the enhancements from broad attention primarily peak around lower spatial frequencies compared to fine-grained attention. This is because localized attention in the foveola is often used to explore and preview fine spatial details before engaging in further examination, whereas broadly distributed attention may function more as a mechanism to enhance the global pattern of the foveal input, which does not necessarily require the selective processing of high spatial frequencies.</p>
<p>In addition to contrast gain, we also observed a sizable response gain, evident as an increase in asymptotic performance in the valid compared to the neutral condition. This indicates that even at the maximum contrast level, observers were better at discriminating the orientation of the small Gabor patch when attending, compared to baseline. On the contrary, no such enhancement in asymptotic performance has been observed in the extrafovea (<xref ref-type="bibr" rid="c33">Jigo and Carrasco, 2020</xref>). Methodological differences, particularly in spatial uncertainty, might account for the presence of response gain in our results. In our study, the neutral condition had only two possible stimulus locations, making the target location more predictable, whereas <bold><italic>Jigo and Carrasco</italic></bold> required observers to monitor seven locations, introducing greater spatial uncertainty. Prior research has shown that the presence of a response gain is more likely when the stimulus location is fixed and the stimulus is small, whereas high spatial uncertainty and larger stimuli tend to elicit contrast gain (<xref ref-type="bibr" rid="c28">Herrmann et al., 2010</xref>). Due to the lower spatial uncertainty and small stimulus size in our study, attention likely influenced both contrast gain and response gain.</p>
<p>Here, we examined selective contrast sensitivity enhancements in spatial frequency driven by fine-grained exogenous attention within the foveola. In the extrafovea, endogenous attention can flexibly modulate different visual features depending on their relevance, while the effects of exogenous attention are relatively inflexible (<xref ref-type="bibr" rid="c27">Hein et al., 2006</xref>; <xref ref-type="bibr" rid="c21">Giordano et al., 2009</xref>; <xref ref-type="bibr" rid="c6">Bocanegra and Zeelenberg, 2011</xref>; <xref ref-type="bibr" rid="c9">Carrasco and Barbot, 2014</xref>; <xref ref-type="bibr" rid="c33">Jigo and Carrasco, 2020</xref>). Consequently, if fine-grained endogenous attention is engaged, we would expect the range of enhanced spatial frequencies to be higher and closer to the limit of visual resolution or to be modulated based on task demands. Further research is needed to address this point. Understanding how these attentional mechanisms operate in the foveola could provide valuable insights into the functional distinctions between endogenous and exogenous attention in fine spatial processing.</p>
<p>In everyday life, our covert exogenous attention is often engaged when a salient stimulus captures our focus. This evolutionarily important mechanism ensures that we continuously monitor our environment for unexpected events and prepare to respond accordingly (<xref ref-type="bibr" rid="c75">Yantis, 1993</xref>; <xref ref-type="bibr" rid="c71">Theeuwes, 2010</xref>). Our previous work has demonstrated that attentional shifts can also occur locally within the high-acuity foveola. Here we show that these fine-grained attention shifts function similarly to those in the extrafoveal region, enhancing visual sensitivity to coarse stimulus features. This mechanism is essential for everyday tasks, such as driving or reading. Our findings not only shed light on the functionality of fine-grained covert attention within the foveola but also reinforce the idea that exogenous attention operates under similar principles as extrafoveal vision. Specifically, exogenous attention remains an inflexible mechanism for selective processing—even in the foveola, where higher spatial frequency information is available, it does not enhance contrast sensitivity of the finer details but instead prioritizes coarser stimulus features. Functionally, this selective enhancement of contrast sensitivity at low to mid spatial frequencies provides a preview of small but salient stimuli located just a few arcminutes from the preferred locus of fixation in everyday tasks. By enhancing the visibility of these stimuli before direct fixation, this mechanism enables the visual system to rapidly assess their relevance and guide the planning of microsaccades, ensuring efficient and precise shifts of gaze to bring these stimuli into the foveal region for detailed examination.</p>
</sec>
<sec id="s4">
<title>Methods and Materials</title>
<sec id="s4a">
<title>Observers</title>
<p>7 human observers in total, 6 emmetropic observers, and 1 observer with 20/20 corrected vision participated in the experiments (4 females, 3 males; age range 18 - 27 years old). The experiment was approved by the University of Rochester Institutional Review Boards. The experimenter reviewed and explained the material in the consent form to the participants before conducting the experiment. The form was signed only after the participant fully understood the material and voluntarily agreed to take part in the study. Consent was obtained from all participants in the study.</p>
</sec>
<sec id="s4b">
<title>Stimuli and Apparatus</title>
<p>Stimuli were displayed on an LCD monitor (ASUS ROG SWIFT 360Hz PG259QN) at a refresh rate of 360 Hz and spatial resolution of 1920 x 1080 pixels. Observers performed the task monocularly with their right eye while the left eye was patched. A dental-imprint bite bar and a headrest were used to prevent head movements. Eye movements were recorded with high precision using a custom-made digital Dual Purkinje Image (dDPI) eye tracker, which has a sampling rate of 1 kHz (<xref ref-type="bibr" rid="c73">Wu et al., 2023</xref>). The system has an internal noise well below 1′ and a spatial resolution of 1′ (<xref ref-type="bibr" rid="c37">Ko et al., 2016</xref>; <xref ref-type="bibr" rid="c73">Wu et al., 2023</xref>). Stimuli were rendered using EyeRIS, a custom-developed system that allows flexible gaze-contingent display control (<xref ref-type="bibr" rid="c66">Santini et al., 2007</xref>). This system acquires eye movement signals from the eye tracker, processes them in real time, and updates the stimulus on the display according to the desired combination of estimated oculomotor variables.</p>
</sec>
<sec id="s4c">
<title>Procedure and Experimental Task</title>
<sec id="s4c1">
<title>Calibration</title>
<p>Every session started with the setup of the bite bar. A magnetized helmet was used to position the observer’s head. When accurate localization of gaze position is necessary, calibration represents an important stage of the experimental procedure, which was performed in two phases. During the first phase, observers sequentially fixated on each of the nine points of a 3-by-3 grid, as is customary in all oculomotor experiments. In the second phase, observers refined the pixel-to-pixel mapping, given by the automatic calibration. Observers fixated again on each of the nine points of the grid while the location of the line of sight was displayed in real time on the screen. Observers used a joypad to correct the predicted gaze location, shifting the real-time display to align with the grid point for each fixation, if necessary. These corrections were then incorporated into the transformation of the gaze position as well. This dual-step calibration procedure allows more accurate localization of gaze position than standard single-step procedures. The manual calibration procedure was repeated at the center of the fixation before each trial to compensate for unpreventable head movements.</p>
</sec>
<sec id="s4c2">
<title>Experimental task</title>
<p>Observers were instructed to fixate on a central marker (5 by 5 arcminutes) throughout each trial. On valid trials, an exogenous cue—a white square (8-by-8 arcminutes)—appeared 500ms after fixation. The cue appeared for 30 ms at 0.75 deg eccentricity to the left/right of the fixation marker, with each location occurring randomly with equal probability. The smaller exogenous cue, positioned offset from the Gabor patch, was used to prevent forward masking and ensure clear perception of the Gabor patch. Shortly after the cue disappeared (70 ms), two small Gabor patches (0.5 deg visible area), tilted +/− 45 degrees, with a phase of 0 or 90 degrees were shown (50 ms) on the left/right side at 0.5 deg eccentricity. The tilt of the two Gabor patches was randomly and independently chosen on each trial. And the phase was randomly selected on each trial but consistent between the two patches. The spatial frequency of the Gabors was 4, 8, 12, or 20 CPD. After the stimulus offset, a response cue was presented, and observers were instructed to report the orientation of the stimulus previously presented at that location. The trial concluded either when observers responded or automatically after 1000 ms if no response was given following the appearance of the response cue. On valid trials, the response cue always indicated the same location as the exogenous cue, making the cue 100% valid. On neutral trials, no exogenous cue was presented, and the response cue indicated one of the two possible locations randomly.</p>
<p>Given that contrast sensitivity varies considerably across SF and eccentricity (<xref ref-type="bibr" rid="c62">Rovamo et al., 1992</xref>), for each spatial frequency tested, observers underwent a preliminary session in which an initial estimate of contrast threshold, defined as the contrast needed to achieve 70% discrimination accuracy in the neutral condition. The order of spatial frequency tested was randomized across observers. After the threshold was obtained, each observer was tested at five different contrast values around the estimated threshold. One of these values included presenting the grating at 100% contrast to obtain a precise estimate for the upper-performance asymptote. The remaining four levels were ±0.075 and ±0.225 log<sub>10</sub> units from the initial threshold estimate. If the initial estimates were within 0.225 log<sub>10</sub> units of 100% contrast (i.e., <italic>&gt;</italic>= 60% contrast), the rest of the four contrast values were −0.6, −0.45, −0.3, and −0.15 log<sub>10</sub> units compared to the initial estimate (<xref ref-type="bibr" rid="c56">Prins, 2012</xref>). Within each experimental session, a single spatial frequency was tested, and the corresponding contrast levels were presented in a block design. All five contrast levels were tested within a single experimental session on the same day. Each contrast level included between 50 and 100 filtered trials.</p>
<p>Two observers were not tested at 20 CPD because their performance remained at chance level even with gratings at maximal contrast. It is possible given that 20 CPD was near the visual resolution limit at the tested eccentricity.</p>
</sec>
</sec>
<sec id="s4d">
<title>Data Analysis</title>
<p>Only trials with uninterrupted tracking in which the fourth Purkinje image was never eclipsed by the pupil margin, were selected for data analysis. Trials in which the gaze was <italic>&gt;</italic> 10’ away from the center position 50 ms before the onset of the exogenous cue t0 50 ms after the offset of the target, and trials with blinks, saccades, or microsaccades occurring at any time during the period of interest (50 ms before the onset of the exogenous cue to 200 ms after the offset of the Gabor patches), were discarded. Periods of blinks were automatically detected by the dDPI eye tracker. Eye movements with a minimal amplitude of 30 and a peak velocity higher than 3°/s were categorized as saccades. Saccades with an amplitude of less than 0.5° (30’) were defined as microsaccades. Saccade amplitude was defined as the vector connecting the point where the speed of the gaze shift grew greater than 3°/s (saccade onset) and the point where it became less than 3°/s (saccade offset). Periods that were not classified as saccades or blinks were labeled as drifts. Observers had 1000 ms to respond, and trials were excluded from further analysis if observers responded too fast (<italic>&lt;</italic> 100 ms) or too slow (<italic>&gt;</italic> 1000 ms), resulting in the exclusion of 0.02% ± 0.02% of the trials. <xref rid="tbl1" ref-type="table">Table 1</xref> summarizes the data remaining for analysis for each condition (see <xref rid="fig2_S1" ref-type="fig">Figure 2—figure Supplement 1</xref> for a detailed breakdown by observer).</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><title>Average number of trials included in the analysis after filtering (± SEs over by-observer counts), across different spatial frequencies and cueing conditions.</title>
<p>Parentheses show inclusions as percentages of total trials collected.</p></caption>
<graphic xlink:href="672541v1_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>Weibull functions were fitted to the responses of the orientation discrimination task, using the maximum likelihood procedure implemented in the <monospace>psignifit 4</monospace> toolbox (<xref ref-type="bibr" rid="c67">Schütt et al., 2016</xref>) for MATLAB. Separate functions were fitted for each combination of observer, attention conditions (attended and neutral), and spatial frequency, for a total of 8 psychometric function fits (2 attention conditions x 4 spatial frequencies) per observer. Each fit resulted in maximum a posteriori (MAP) estimates for the intercept <italic>α</italic>, slope <italic>β</italic>, threshold <italic>θ</italic>, and lapse rate <italic>λ</italic> of the psychometric function (the guess rate <italic>γ</italic> was set to .5, given the 2AFC task). Two estimates were extracted from the MAP estimates to examine the effects of fine-grained exogenous attention across spatial frequencies — contrast sensitivity and asymptotic performance. Contrast sensitivity was defined as the inverse of the threshold (the midpoint on the psychometric curve between chance performance and maximum performance). Asymptotic performance was calculated by subtracting the lapse rate from 1, representing the discrimination accuracy at the highest contrast level of the stimuli. In total, this procedure resulted in 52 estimates each of contrast sensitivity and asymptotic performance (5 observers with 4 SFs x 2 cueing conditions, and 2 observers, who did not complete the 20 CPD condition, with 3 SFs x 2 cueing conditions).</p>
<p>Contrast sensitivity (CS) and asymptotic performance (AP) were both analyzed with (different types of) mixed-effects regressions. Each of the mixed-effects regressions contained cueing, spatial frequency, and their interactions as fixed-effects predictors. Cueing was effect-coded (“attended” = .5 vs. “neutral” = −.5), and frequency was coded using sliding difference, comparing the effects for each spatial frequency against the next highest spatial frequency (4 vs. 8, 8 vs. 12, 12 vs. 20). Following the recommended procedure (<xref ref-type="bibr" rid="c43">Lohse, 2022</xref>), we included the maximal possible random effect structure: random intercepts by observer, by unique combination of observer and cueing condition, and by unique combination of observer and spatial frequency condition.</p>
<p>CS is a bounded variable with a natural limit in that it cannot be lower than zero. Importantly, the variance of bounded variables tends to systematically decrease as their mean approaches the bound. This violates the assumption of homoskedasticity—the idea that variance should be independent of the mean and thus remain roughly constant across different conditions — an assumption that is shared by widely used statistical methods like <italic>t</italic>-tests, ANOVA (analysis of variance) and linear mixed-effects models (LMMs). When this assumption is violated, it can impact the reliability of statistical conclusions, affecting both Type I errors (false positives) and Type II errors (false negatives) (<xref ref-type="bibr" rid="c31">Jaeger, 2008</xref>).</p>
<p>Indeed, we observed a strong positive correlation between the mean and variance of contrast sensitivity: smaller variances for smaller means (<xref rid="fig3_S3" ref-type="fig">Figure 3—figure Supplement 3</xref>). To address this issue, we log-transformed CS before analyzing it with an LMM using the <monospace>lmer</monospace> function from the <monospace>lme4</monospace> package (<xref ref-type="bibr" rid="c3">Bates et al., 2025</xref>) in R (<xref ref-type="bibr" rid="c58">R Core Team, 2024</xref>). This largely mitigated the heteroskedasticity, except potentially in the 20 CPD condition (see <xref rid="fig3_S3" ref-type="fig">Figure 3—figure Supplement 3</xref>). As a precautionary measure, we verified that all main findings remained unchanged when this condition was excluded. This included the critical interaction between spatial frequency and attention (<italic>χ</italic><sup>2</sup>(2) = 6.6, <italic>p &lt;</italic> .04), which remained statistically significant.</p>
<p>AP is bounded both at the lower and the upper end (as it cannot be larger than 1, or smaller than the guess rate). Following recommended procedure, we thus normalized asymptotic performance to the range between 0 and 1, and analyzed it with a mixed-effects Beta model (with a logit link) using <monospace>lme4</monospace>’s <monospace>glmer</monospace> function.</p>
<p>Post-hoc pairwise comparisons for both mixed-effects analyses were conducted by estimating the relevant marginal means of the fitted mixed-effects regression, using the <monospace>emmeans</monospace> package (<xref ref-type="bibr" rid="c39">Lenth et al., 2025</xref>) in R.</p>
<p>Below, we summarize the key considerations for interpreting our results.</p>
<sec id="s4d1">
<title>Limitations</title>
<p>Here, we analyzed log-transformed CS and AP in two separate analyses, each conducted over the observer-level estimates for each condition. We did so both (1) because this approach remains the standard in psychophysics—including in research on the role of covert attention (<xref ref-type="bibr" rid="c7">Cameron et al., 2002</xref>; <xref ref-type="bibr" rid="c52">Pestilli and Carrasco, 2005</xref>; <xref ref-type="bibr" rid="c28">Herrmann et al., 2010</xref>; <xref ref-type="bibr" rid="c40">Li et al., 2021</xref>)—and (2) because the alternative would have required fitting mixed-effects <italic>trial-level</italic> psychometric models to the combined data from all conditions and observers (an approach that is computationally demanding, and has not yet been broadly validated). The approach taken here and in prior work on extrafoveal attention does, however, have several known limitations, some of which might be of particular relevance to questions about the effects of attention. We summarize these potential downsides here, so that they can be considered in the interpretation of our results, and addressed in future work.</p>
<p>First, summarizing each observer’s performance in a particular condition in terms of the best-fitting estimates of the parameters of the psychometric function (e.g., sensitivity or asymptotic performance) discards all uncertainty about these estimates. The repeated-measures ANOVA or, in our case, mixed-effects regression analyses that are conducted over the best-fitting estimates have no access to information contained in the trial-level observations. This means that two estimates with very different levels of uncertainty (see <xref rid="fig4_S1" ref-type="fig">Figure 4—figure Supplement 1</xref>) can have the same impact on the analysis, underweighting less uncertain estimates and overweighting more uncertain estimates. [Differences in uncertainty across conditions and/or across observers can result from a variety of sources. This includes, among other things, differences in the number of trials available to fit the psychometric model, differences in which subsets of trials meet the exclusion criteria (even when those criteria are constant across conditions), and differences in where along the perceptual continuum observers were queried—i.e., at which levels of the observer’s true probability of an accurate answer, <italic>p</italic>(<italic>accurate answer</italic> |<italic>stimulus</italic>), which in turn depends on the true parameterization—intercept, slope, and lapse rate—of the observer’s psychometric function. For instance, for observers who have not reached peak performance at 100% contrast, it is difficult to dissociate the slope and lapse rate of their psychometric function, leading to increased uncertainty about the observer’s contrast threshold, sensitivity, and asymptotic performance.] A failure to adequately account for uncertainty can also increase Type I and Type II errors.</p>
<p>Second, the standard approach discards all information about the <italic>covariation</italic> between the different parameters. For instance, the same data can sometimes be described well by either having a larger slope in the perceptual model (and thus a lower threshold and higher sensitivity) combined with a lower asymptotic performance or a smaller slope combined with higher asymptotic performance. Any information about such correlations between parameters of the psychometric function is lost under the traditional approach we have followed here. This might contribute to seemingly heterogeneous results across the literature with regard to whether the effects of attention result in contrast or response gain (see Discussion).</p>
<p>Future research could employ alternative analysis approaches. In particular, it is now possible to fit mixed-effects psychometric models to the trial-level data from all conditions and all observers (<xref ref-type="bibr" rid="c57">Prins, 2024</xref>; <xref ref-type="bibr" rid="c69">Tan and Jaeger, 2025</xref>). While this approach is computationally more demanding and requires familiarity with nonlinear mixed-effects modeling, it allows statistical tests that avoid the downsides described above.</p>
</sec>
</sec>
</sec>
</body>
<back>
<sec id="s6" sec-type="supplementary">
<title>Supplementary Figures</title>
<fig id="fig2_S1" position="float" fig-type="figure">
<label>Figure 2—figure supplement 1.</label>
<caption><title>Number of trials included for analysis by condition.</title> <p>Each line is an observer. Error bars show the mean of by-observer counts and SEM.</p></caption>
<graphic xlink:href="672541v1_fig2_S1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="fig3_S1" position="float" fig-type="figure">
<label>Figure 3—figure supplement 1.</label>
<caption><title>Psychometric Weibull function fits for all observers and conditions.</title></caption>
<graphic xlink:href="672541v1_fig3_S1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="fig3_S2" position="float" fig-type="figure">
<label>Figure 3—figure supplement 2.</label>
<caption><p>(<bold>A</bold>) Average contrast sensitivity, calculated as the inverse of the contrast threshold, across spatial frequencies, including 2 CPD in valid and neutral conditions. Each dot represents an individual observer. Error bars denote the standard error of the mean (SEM). Asterisks mark a significant difference in contrast sensitivity between 2 CPD and other spatial frequencies. (<bold>B</bold>) Average difference in log-scaled contrast sensitivity between valid and neutral conditions across different spatial frequencies. Each line corresponds to the log-scaled contrast sensitivities from each observer. Error bars represent the bootstrapped confidence intervals. Asterisks mark post-hoc pairwise comparison results between valid and neutral conditions within each spatial frequency.</p></caption>
<graphic xlink:href="672541v1_fig3_S2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="fig3_S3" position="float" fig-type="figure">
<label>Figure 3—figure supplement 3.</label>
<caption><title>Relation between mean and variability of contrast sensitivity (CS), depending on whether CS is log-transformed (right panel) or not (left panel).</title> <p>Without a logtransform, the mean and standard deviation (SD) of CS are almost perfectly correlated, constituting a strong violation of the homoskedasticity assumption of linear models. For the present data, logtransforming CS <italic>mostly</italic> removes this correlation (except for the 20 CPD condition).</p></caption>
<graphic xlink:href="672541v1_fig3_S3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="fig4_S1" position="float" fig-type="figure">
<label>Figure 4—figure supplement 1.</label>
<caption><title>Maximum a posteriori (MAP) estimates (points) and 95% confidence intervals for contrast sensitivity (CS) and asymptotic performance (AP) for each experimental condition across seven observers.</title> <p>Both CS and AP were transformed in the same way as used in our mixed-effects analyses.</p></caption>
<graphic xlink:href="672541v1_fig4_S1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<ack>
<title>Acknowledgements</title>
<p>The authors wish to thank Nora Rooney for assisting with data collection.</p>
</ack>
<sec id="s5" sec-type="additional-information">
<title>Additional Information</title>
<sec id="s5a">
<title>Funding</title>
<p>This work was funded by META, NIH R01 EY029788-01 (M.P.), and NIH grant EY001319 to the Center for Visual Science.</p>
</sec>
<sec id="s5b">
<title>Author Contributions</title>
<p>Y.G. and M.P. designed research; Y.G. performed research; Y.G. and T.J. analyzed data; all authors drafted the paper and approved the final version of the manuscript.</p>
</sec>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barbot</surname> <given-names>A</given-names></string-name>, <string-name><surname>Landy</surname> <given-names>MS</given-names></string-name>, <string-name><surname>Carrasco</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Exogenous attention enhances 2nd-order contrast sensitivity</article-title>. <source>Vision Research</source>. <year>2011</year>; <volume>51</volume>(<issue>9</issue>):<fpage>1086</fpage>–<lpage>1098</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barbot</surname> <given-names>A</given-names></string-name>, <string-name><surname>Landy</surname> <given-names>MS</given-names></string-name>, <string-name><surname>Carrasco</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Differential effects of exogenous and endogenous attention on second-order texture contrast sensitivity</article-title>. <source>Journal of Vision</source>. <year>2012</year>; <volume>12</volume>(<issue>8</issue>):<fpage>6</fpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Bates</surname> <given-names>D</given-names></string-name>, <string-name><surname>Maechler</surname> <given-names>M</given-names></string-name>, <string-name><surname>Bolker</surname> <given-names>B</given-names></string-name>, <string-name><surname>Walker</surname> <given-names>S</given-names></string-name>, <string-name><surname>Christensen</surname> <given-names>RHB</given-names></string-name>, <string-name><surname>Singmann</surname> <given-names>H</given-names></string-name>, <string-name><surname>Dai</surname> <given-names>B</given-names></string-name>, <string-name><surname>Scheipl</surname> <given-names>F</given-names></string-name>, <string-name><surname>Grothendieck</surname> <given-names>G</given-names></string-name>, <string-name><surname>Green</surname> <given-names>P</given-names></string-name>, <string-name><surname>Fox</surname> <given-names>J</given-names></string-name>, <string-name><surname>Bauer</surname> <given-names>A</given-names></string-name>, <string-name><surname>Krivitsky</surname> <given-names>P</given-names></string-name>, <string-name><surname>Tanaka</surname> <given-names>E</given-names></string-name>, <string-name><surname>Jagan</surname> <given-names>M.</given-names></string-name></person-group> <source>lme4: Linear Mixed-Effects Models using Eigen and S4</source>; <year>2025</year>, <ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=lme4">https://CRAN.R-project.org/package=lme4</ext-link>, r package version 1.1.35.5.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bex</surname> <given-names>PJ</given-names></string-name>, <string-name><surname>Solomon</surname> <given-names>SG</given-names></string-name>, <string-name><surname>Dakin</surname> <given-names>SC</given-names></string-name></person-group>. <article-title>Contrast sensitivity in natural scenes depends on edge as well as spatial frequency structure</article-title>. <source>Journal of Vision</source>. <year>2009</year>; <volume>9</volume>(<issue>10</issue>):<fpage>1</fpage>–<lpage>1</lpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bicknell</surname> <given-names>K</given-names></string-name>, <string-name><surname>Bushong</surname> <given-names>W</given-names></string-name>, <string-name><surname>Tanenhaus</surname> <given-names>MK</given-names></string-name>, <string-name><surname>Jaeger</surname> <given-names>TF</given-names></string-name></person-group>. <article-title>Maintenance of subcategorical information during speech perception: revisiting misunderstood limitations</article-title>. <source>Journal of Memory and Language</source>. <year>2025</year>; <volume>140</volume>:<fpage>104565</fpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bocanegra</surname> <given-names>BR</given-names></string-name>, <string-name><surname>Zeelenberg</surname> <given-names>R.</given-names></string-name></person-group> <article-title>Emotional cues enhance the attentional effects on spatial and temporal resolution</article-title>. <source>Psychonomic Bulletin &amp; Review</source>. <year>2011</year>; <volume>18</volume>(<issue>6</issue>):<fpage>1071</fpage>–<lpage>1076</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cameron</surname> <given-names>EL</given-names></string-name>, <string-name><surname>Tai</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Carrasco</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Covert attention affects the psychometric function of contrast sensitivity</article-title>. <source>Vision Research</source>. <year>2002</year>; <volume>42</volume>(<issue>8</issue>):<fpage>949</fpage>–<lpage>967</lpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carrasco</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Visual attention: The past 25 years</article-title>. <source>Vision Research</source>. <year>2011</year>; <volume>51</volume>(<issue>13</issue>):<fpage>1484</fpage>–<lpage>1525</lpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carrasco</surname> <given-names>M</given-names></string-name>, <string-name><surname>Barbot</surname> <given-names>A.</given-names></string-name></person-group> <article-title>How Attention Affects Spatial Resolution</article-title>. <source>Cold Spring Harbor symposia on quantitative biology</source>. <year>2014</year>; <volume>79</volume>:<fpage>149</fpage>–<lpage>160</lpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carrasco</surname> <given-names>M</given-names></string-name>, <string-name><surname>Loula</surname> <given-names>F</given-names></string-name>, <string-name><surname>Ho</surname> <given-names>YX</given-names></string-name></person-group>. <article-title>How attention enhances spatial resolution: Evidence from selective adaptation to spatial frequency</article-title>. <source>Attention, Perception, &amp; Psychophysics</source>. <year>2006</year>; <volume>68</volume>(<issue>6</issue>):<fpage>1004</fpage>–<lpage>1012</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carrasco</surname> <given-names>M</given-names></string-name>, <string-name><surname>Penpeci-Talgar</surname> <given-names>C</given-names></string-name>, <string-name><surname>Eckstein</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Spatial covert attention increases contrast sensitivity across the CSF: support for signal enhancement</article-title>. <source>Vision Research</source>. <year>2000</year>; <volume>40</volume>(<issue>10-12</issue>):<fpage>1203</fpage>–<lpage>1215</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carrasco</surname> <given-names>M</given-names></string-name>, <string-name><surname>Williams</surname> <given-names>PE</given-names></string-name>, <string-name><surname>Yeshurun</surname> <given-names>Y.</given-names></string-name></person-group> <article-title>Covert attention increases spatial resolution with or without masks: Support for signal enhancement</article-title>. <source>Journal of Vision</source>. <year>2002</year>; <volume>2</volume>(<issue>6</issue>):<fpage>467</fpage>–<lpage>479</lpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carretié</surname> <given-names>L</given-names></string-name>, <string-name><surname>Ríos</surname> <given-names>M</given-names></string-name>, <string-name><surname>Periáñez</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Kessel</surname> <given-names>D</given-names></string-name>, <string-name><surname>Álvarez Linera</surname> <given-names>J.</given-names></string-name></person-group> <article-title>The Role of Low and High Spatial Frequencies in Exogenous Attention to Biologically Salient Stimuli</article-title>. <source>PLoS ONE</source>. <year>2012</year>; <volume>7</volume>(<issue>5</issue>):<fpage>e37082</fpage>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chica</surname> <given-names>AB</given-names></string-name>, <string-name><surname>Lupiáñez</surname> <given-names>J.</given-names></string-name></person-group> <article-title>Effects of endogenous and exogenous attention on visual processing: An Inhibition of Return study</article-title>. <source>Brain Research</source>. <year>2009</year>; <volume>1278</volume>:<fpage>75</fpage>–<lpage>85</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Clark</surname> <given-names>AC</given-names></string-name>, <string-name><surname>Intoy</surname> <given-names>J</given-names></string-name>, <string-name><surname>Rucci</surname> <given-names>M</given-names></string-name>, <string-name><surname>Poletti</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Eye drift during fixation predicts visual acuity</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2022</year>; <volume>119</volume>(<issue>49</issue>):<fpage>e2200256119</fpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Corbetta</surname> <given-names>M</given-names></string-name>, <string-name><surname>Shulman</surname> <given-names>GL</given-names></string-name></person-group>. <article-title>Control of goal-directed and stimulus-driven attention in the brain</article-title>. <source>Nature Reviews Neuroscience</source>. <year>2002</year>; <volume>3</volume>:<fpage>201</fpage>–<lpage>215</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dugué</surname> <given-names>L</given-names></string-name>, <string-name><surname>Merriam</surname> <given-names>EP</given-names></string-name>, <string-name><surname>Heeger</surname> <given-names>JH</given-names></string-name>, <string-name><surname>Carrasco</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Differential impact of endogenous and exogenous attention on activity in human visual cortex</article-title>. <source>Scientific Reports</source>. <year>2020</year>; <volume>10</volume>:<fpage>21274</fpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fernández</surname> <given-names>A</given-names></string-name>, <string-name><surname>Okun</surname> <given-names>S</given-names></string-name>, <string-name><surname>Carrasco</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Differential Effects of Endogenous and Exogenous Attention on Sensory Tuning</article-title>. <source>Journal of Neuroscience</source>. <year>2022</year>; <volume>42</volume>(<issue>7</issue>):<fpage>1316</fpage>–<lpage>1327</lpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Findlay</surname> <given-names>JM</given-names></string-name></person-group>. <chapter-title>Visual Selection, Covert Attention and Eye Movements</chapter-title>. In: <person-group person-group-type="editor"><string-name><surname>Findlay</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Gilchrist</surname> <given-names>ID</given-names></string-name></person-group> <source>Active Vision: The Psychology of Looking and Seeing Oxford Psychology Series</source>, <publisher-name>Oxford University Press</publisher-name>; <year>2003</year>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Foster</surname> <given-names>JJ</given-names></string-name>, <string-name><surname>Thyer</surname> <given-names>W</given-names></string-name>, <string-name><surname>Wennberg</surname> <given-names>JW</given-names></string-name>, <string-name><surname>Awh</surname> <given-names>E.</given-names></string-name></person-group> <article-title>Covert Attention Increases the Gain of Stimulus-Evoked Population Codes</article-title>. <source>Journal of Neuroscience</source>. <year>2021</year>; <volume>41</volume>(<issue>8</issue>):<fpage>1802</fpage>–<lpage>1815</lpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Giordano</surname> <given-names>AM</given-names></string-name>, <string-name><surname>McElree</surname> <given-names>B</given-names></string-name>, <string-name><surname>Carrasco</surname> <given-names>M.</given-names></string-name></person-group> <article-title>On the automaticity and flexibility of covert attention: A speed-accuracy trade-off analysis</article-title>. <source>Journal of Vision</source>. <year>2009</year>; <volume>9</volume>(<issue>3</issue>):<fpage>30.1</fpage>–<lpage>30.10</lpage>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gobell</surname> <given-names>J</given-names></string-name>, <string-name><surname>Carrasco</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Attention alters the appearance of spatial frequency and gap size</article-title>. <source>Psychological Science</source>. <year>2005</year>; <volume>16</volume>(<issue>8</issue>):<fpage>644</fpage>–<lpage>651</lpage>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guzhang</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Shelchkova</surname> <given-names>N</given-names></string-name>, <string-name><surname>Clark</surname> <given-names>AM</given-names></string-name>, <string-name><surname>Poletti</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Ultra-fine resolution of pre-saccadic attention in the fovea</article-title>. <source>Current Biology</source>. <year>2024</year>; <volume>34</volume>(<issue>1</issue>):<fpage>147</fpage>–<lpage>155</lpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guzhang</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Shelchkova</surname> <given-names>N</given-names></string-name>, <string-name><surname>Ezzo</surname> <given-names>R</given-names></string-name>, <string-name><surname>Poletti</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Transient perceptual enhancements resulting from selective shifts of exogenous attention in the central fovea</article-title>. <source>Current Biology</source>. <year>2021</year>; <volume>31</volume>(<issue>12</issue>):<fpage>2698</fpage>–<lpage>2703</lpage>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hafed</surname> <given-names>ZM</given-names></string-name>, <string-name><surname>Clark</surname> <given-names>JJ</given-names></string-name></person-group>. <article-title>Microsaccades as an overt measure of covert attention shifts</article-title>. <source>Vision Research</source>. <year>2002</year> <month>October</month>; <volume>42</volume>(<issue>22</issue>):<fpage>2533</fpage>–<lpage>2545</lpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hahner</surname> <given-names>L</given-names></string-name>, <string-name><surname>Nieder</surname> <given-names>A.</given-names></string-name></person-group> <article-title>Volitional spatial attention is lateralized in crows</article-title>. <source>Proceedings of the Royal Society B</source>. <year>2025</year>; <volume>292</volume>:<fpage>20242540</fpage>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hein</surname> <given-names>E</given-names></string-name>, <string-name><surname>Rolke</surname> <given-names>B</given-names></string-name>, <string-name><surname>Ulrich</surname> <given-names>R.</given-names></string-name></person-group> <article-title>Visual attention and temporal discrimination: Differential effects of automatic and voluntary cueing</article-title>. <source>Visual Cognition</source>. <year>2006</year>; <volume>13</volume>(<issue>1</issue>):<fpage>29</fpage>–<lpage>50</lpage>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Herrmann</surname> <given-names>K</given-names></string-name>, <string-name><surname>Montaser-Kouhsari</surname> <given-names>L</given-names></string-name>, <string-name><surname>Carrasco</surname> <given-names>M</given-names></string-name>, <string-name><surname>Heeger</surname> <given-names>DJ</given-names></string-name></person-group>. <article-title>When size matters: attention affects performance by contrast or response gain</article-title>. <source>Nature Neuroscience</source>. <year>2010</year>; <volume>13</volume>:<fpage>1554</fpage>–<lpage>1559</lpage>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Howell</surname> <given-names>ER</given-names></string-name>, <string-name><surname>Hess</surname> <given-names>RF</given-names></string-name></person-group>. <article-title>The functional area for summation to threshold for sinusoidal gratings</article-title>. <source>Vision Research</source>. <year>1978</year>; <volume>18</volume>(<issue>4</issue>):<fpage>369</fpage>–<lpage>374</lpage>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Intoy</surname> <given-names>J</given-names></string-name>, <string-name><surname>Rucci</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Finely tuned eye movements enhance visual acuity</article-title>. <source>Nature Communications</source>. <year>2020</year>; <volume>11</volume>:<fpage>795</fpage>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jaeger</surname> <given-names>TF</given-names></string-name></person-group>. <article-title>Categorical data analysis: Away from ANOVAs (transformation or not) and towards logit mixed models</article-title>. <source>Journal of Memory and Language</source>. <year>2008</year>; <volume>59</volume>(<issue>4</issue>):<fpage>434</fpage>–<lpage>446</lpage>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jigo</surname> <given-names>M</given-names></string-name>, <string-name><surname>Carrasco</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Attention alters spatial resolution by modulating second-order processing</article-title>. <source>Journal of Vision</source>. <year>2018</year>; <volume>18</volume>(<issue>7</issue>):<fpage>2</fpage>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jigo</surname> <given-names>M</given-names></string-name>, <string-name><surname>Carrasco</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Differential impact of exogenous and endogenous attention on the contrast sensitivity function across eccentricity</article-title>. <source>Journal of Vision</source>. <year>2020</year>; <volume>20</volume>(<issue>6</issue>):<fpage>11</fpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kaspar</surname> <given-names>K.</given-names></string-name></person-group> <article-title>What Guides Visual Overt Attention under Natural Conditions? Past and Future Research</article-title>. <source>International Scholarly Research Notices</source>. <year>2013</year>; p. <fpage>8</fpage>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Klein</surname> <given-names>RM</given-names></string-name></person-group>. <article-title>Inhibition of return</article-title>. <source>Trends in Cognitive Sciences</source>. <year>2000</year>; <volume>4</volume>(<issue>4</issue>):<fpage>138</fpage>–<lpage>147</lpage>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Knudsen</surname> <given-names>EI</given-names></string-name></person-group>. <article-title>Fundamental components of attention</article-title>. <source>Annual Review of Neuroscience</source>. <year>2007</year>; <volume>30</volume>:<fpage>57</fpage>–<lpage>78</lpage>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ko</surname> <given-names>H</given-names></string-name>, <string-name><surname>Snodderly</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Poletti</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Eye movements between saccades: Measuring ocular drift and tremor</article-title>. <source>Vision Research</source>. <year>2016</year>; <volume>122</volume>:<fpage>93</fpage>–<lpage>104</lpage>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krauzlis</surname> <given-names>RJ</given-names></string-name>, <string-name><surname>Goffart</surname> <given-names>L</given-names></string-name>, <string-name><surname>Hafed</surname> <given-names>ZM</given-names></string-name></person-group>. <article-title>Neuronal control of fixation and fixational eye movements</article-title>. <source>Philosophical Transactions of the Royal Society B</source>. <year>2017</year>; <volume>372</volume>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Lenth</surname> <given-names>RV</given-names></string-name>, <string-name><surname>Banfai</surname> <given-names>B</given-names></string-name>, <string-name><surname>Bolker</surname> <given-names>B</given-names></string-name>, <string-name><surname>Buerkner</surname> <given-names>P</given-names></string-name>, <string-name><surname>Giné-Vázquez</surname> <given-names>I</given-names></string-name>, <string-name><surname>Herve</surname> <given-names>M</given-names></string-name>, <string-name><surname>Jung</surname> <given-names>M</given-names></string-name>, <string-name><surname>Love</surname> <given-names>J</given-names></string-name>, <string-name><surname>Miguez</surname> <given-names>F</given-names></string-name>, <string-name><surname>Piaskowski</surname> <given-names>J</given-names></string-name>, <string-name><surname>Riebl</surname> <given-names>H</given-names></string-name>, <string-name><surname>Singmann</surname> <given-names>H.</given-names></string-name></person-group> <source>emmeans: Estimated Marginal Means, aka Least-Squares Means</source>; <year>2025</year>, <ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=emmeans">https://CRAN.R-project.org/package=emmeans</ext-link>, r package version 1.10.5.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname> <given-names>HH</given-names></string-name>, <string-name><surname>Pan</surname> <given-names>J</given-names></string-name>, <string-name><surname>Carrasco</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Different computations underlie overt presaccadic and covert spatial attention</article-title>. <source>Nature Human Behaviour</source>. <year>2021</year>; <volume>5</volume>(<issue>10</issue>):<fpage>1418</fpage>–<lpage>1431</lpage>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname> <given-names>X</given-names></string-name>, <string-name><surname>Lu</surname> <given-names>ZL</given-names></string-name>, <string-name><surname>Tjan</surname> <given-names>BS</given-names></string-name>, <string-name><surname>Dosher</surname> <given-names>BA</given-names></string-name>, <string-name><surname>Chu</surname> <given-names>W.</given-names></string-name></person-group> <article-title>Blood oxygenation level-dependent contrast response functions identify mechanisms of covert attention in early visual areas</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2008</year>; <volume>105</volume>:<fpage>6202</fpage>–<lpage>6207</lpage>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ling</surname> <given-names>S</given-names></string-name>, <string-name><surname>Carrasco</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Sustained and transient covert attention enhance the signal via different contrast response functions</article-title>. <source>Vision Research</source>. <year>2006</year>; <volume>46</volume>:<fpage>1210</fpage>–<lpage>1220</lpage>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Lohse</surname> <given-names>KR</given-names></string-name></person-group>, <source>Mixed Effects Models: Section 3 - Factorial Designs</source>; <year>2022</year>. <ext-link ext-link-type="uri" xlink:href="https://keithlohse.github.io/mixed_effects_models/lohse_MER_section_03_factorial.html">https://keithlohse.github.io/mixed_effects_models/lohse_MER_section_03_factorial.html</ext-link>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lovegrove</surname> <given-names>WJ</given-names></string-name>, <string-name><surname>Bowling</surname> <given-names>A</given-names></string-name>, <string-name><surname>Badcock</surname> <given-names>D</given-names></string-name>, <string-name><surname>Blackwood</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Specific Reading Disability: Differences in Contrast Sensitivity as a Function of Spatial Frequency</article-title>. <source>Science</source>. <year>1980</year>; <volume>210</volume>:<fpage>439</fpage>–<lpage>440</lpage>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lu</surname> <given-names>ZL</given-names></string-name>, <string-name><surname>Dosher</surname> <given-names>BA</given-names></string-name></person-group>. <article-title>Spatial attention excludes external noise without changing the spatial frequency tuning of the perceptual template</article-title>. <source>Journal of Vision</source>. <year>2004</year>; <volume>4</volume>(<issue>10</issue>):<fpage>10</fpage>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Martinez-Conde</surname> <given-names>S</given-names></string-name>, <string-name><surname>Macknik</surname> <given-names>SL</given-names></string-name>, <string-name><surname>Hubel</surname> <given-names>DH</given-names></string-name></person-group>. <article-title>The role of fixational eye movements in visual perception</article-title>. <source>Nature Reviews Neuroscience</source>. <year>2004</year>; <volume>5</volume>:<fpage>229</fpage>–<lpage>240</lpage>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Martínez-Trujillo</surname> <given-names>J</given-names></string-name>, <string-name><surname>Treue</surname> <given-names>S.</given-names></string-name></person-group> <article-title>Attentional modulation strength in cortical area MT depends on stimulus contrast</article-title>. <source>Neuron</source>. <year>2002</year>; <volume>35</volume>(<issue>2</issue>):<fpage>365</fpage>–<lpage>370</lpage>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Miniussi</surname> <given-names>C</given-names></string-name>, <string-name><surname>Rao</surname> <given-names>A</given-names></string-name>, <string-name><surname>Nobre</surname> <given-names>AC</given-names></string-name></person-group>. <article-title>Watching where you look: Modulation of visual processing of foveal stimuli by spatial attention</article-title>. <source>Neuropsychologia</source>. <year>2002</year>; <volume>40</volume>:<fpage>2448</fpage>–<lpage>2460</lpage>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Morrone</surname> <given-names>MC</given-names></string-name>, <string-name><surname>Denti</surname> <given-names>V</given-names></string-name>, <string-name><surname>Spinelli</surname> <given-names>D.</given-names></string-name></person-group> <article-title>Color and luminance contrasts attract independent attention</article-title>. <source>Current Biology</source>. <year>2002</year>; <volume>12</volume>:<fpage>1134</fpage>–<lpage>1137</lpage>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Morrone</surname> <given-names>MC</given-names></string-name>, <string-name><surname>Denti</surname> <given-names>V</given-names></string-name>, <string-name><surname>Spinelli</surname> <given-names>D.</given-names></string-name></person-group> <article-title>Different attentional resources modulate the gain mechanisms for color and luminance contrast</article-title>. <source>Vision Research</source>. <year>2004</year>; <volume>44</volume>:<fpage>1389</fpage>–<lpage>1401</lpage>.</mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Papaioannou</surname> <given-names>O</given-names></string-name>, <string-name><surname>Luck</surname> <given-names>SJ</given-names></string-name></person-group>. <article-title>Effects of eccentricity on the attention-related N2pc component of the event-related potential waveform</article-title>. <source>Psychophysiology</source>. <year>2020</year>; <volume>57</volume>:<fpage>e13532</fpage>.</mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pestilli</surname> <given-names>F</given-names></string-name>, <string-name><surname>Carrasco</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Attention enhances contrast sensitivity at cued and impairs it at uncued locations</article-title>. <source>Vision Research</source>. <year>2005</year>; <volume>45</volume>(<issue>14</issue>):<fpage>1867</fpage>–<lpage>1875</lpage>.</mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pestilli</surname> <given-names>F</given-names></string-name>, <string-name><surname>Ling</surname> <given-names>S</given-names></string-name>, <string-name><surname>Carrasco</surname> <given-names>M.</given-names></string-name></person-group> <article-title>A population-coding model of attention’s influence on contrast response: estimating neural effects from psychophysical data</article-title>. <source>Vision Research</source>. <year>2009</year>; <volume>49</volume>:<fpage>1144</fpage>–<lpage>1153</lpage>.</mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pointer</surname> <given-names>JS</given-names></string-name>, <string-name><surname>Hess</surname> <given-names>RF</given-names></string-name></person-group>. <article-title>The contrast sensitivity gradient across the human visual field: With emphasis on the low spatial frequency range</article-title>. <source>Vision Research</source>. <year>1989</year>; <volume>29</volume>(<issue>9</issue>):<fpage>1133</fpage>–<lpage>1151</lpage>.</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Poletti</surname> <given-names>M</given-names></string-name>, <string-name><surname>Rucci</surname> <given-names>M</given-names></string-name>, <string-name><surname>Carrasco</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Selective attention within the foveola</article-title>. <source>Nature Neuroscience</source>. <year>2017</year>; <volume>20</volume>:<fpage>1413</fpage>–<lpage>1417</lpage>.</mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Prins</surname> <given-names>N.</given-names></string-name></person-group> <article-title>The psychometric function: The lapse rate revisited</article-title>. <source>Journal of Vision</source>. <year>2012</year>; <volume>12</volume>(<issue>6</issue>):<fpage>25</fpage>.</mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Prins</surname> <given-names>N.</given-names></string-name></person-group> <article-title>Easy, bias-free Bayesian hierarchical modeling of the psychometric function using the Palamedes Toolbox</article-title>. <source>Behavior Research Methods</source>. <year>2024</year>; <volume>56</volume>(<issue>1</issue>):<fpage>485</fpage>–<lpage>499</lpage>.</mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="web"><person-group person-group-type="author"><collab>R Core Team</collab></person-group>. <source>R: A Language and Environment for Statistical Computing</source>; <year>2024</year>, <ext-link ext-link-type="uri" xlink:href="https://www.R-project.org/">https://www.R-project.org/</ext-link>.</mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Reynolds</surname> <given-names>JH</given-names></string-name>, <string-name><surname>Chelazzi</surname> <given-names>L.</given-names></string-name></person-group> <article-title>Attentional Modulation of Visual Processing</article-title>. <source>Annual Review of Neuroscience</source>. <year>2004</year>; <volume>27</volume>:<fpage>611</fpage>–<lpage>647</lpage>.</mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Reynolds</surname> <given-names>JH</given-names></string-name>, <string-name><surname>Heeger</surname> <given-names>DJ</given-names></string-name></person-group>. <article-title>The Normalization Model of Attention</article-title>. <source>Neuron</source>. <year>2009</year>; <volume>61</volume>(<issue>2</issue>):<fpage>168</fpage>–<lpage>185</lpage>.</mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rossi</surname> <given-names>AF</given-names></string-name>, <string-name><surname>Paradiso</surname> <given-names>MA</given-names></string-name></person-group>. <article-title>Feature-specific Effects of Selective Visual Attention</article-title>. <source>Vision Research</source>. <year>1995</year>; <volume>35</volume>(<issue>5</issue>):<fpage>621</fpage>–<lpage>634</lpage>.</mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rovamo</surname> <given-names>J</given-names></string-name>, <string-name><surname>Franssila</surname> <given-names>R</given-names></string-name>, <string-name><surname>Näsänen</surname> <given-names>R.</given-names></string-name></person-group> <article-title>Contrast sensitivity as a function of spatial frequency, viewing distance and eccentricity with and without spatial noise</article-title>. <source>Vision Research</source>. <year>1992</year>; <volume>32</volume>(<issue>4</issue>):<fpage>631</fpage>–<lpage>637</lpage>.</mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rovamo</surname> <given-names>J</given-names></string-name>, <string-name><surname>Luntinen</surname> <given-names>O</given-names></string-name>, <string-name><surname>Näsänen</surname> <given-names>R.</given-names></string-name></person-group> <article-title>Modelling the dependence of contrast sensitivity on grating area and spatial frequency</article-title>. <source>Vision Research</source>. <year>1993</year>; <volume>33</volume>(<issue>18</issue>):<fpage>2773</fpage>–<lpage>2788</lpage>.</mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rucci</surname> <given-names>M</given-names></string-name>, <string-name><surname>Poletti</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Control and Functions of Fixational Eye Movements</article-title>. <source>Annual Review of Vision Science</source>. <year>2015</year>; <volume>1</volume>:<fpage>499</fpage>–<lpage>518</lpage>.</mixed-citation></ref>
<ref id="c65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Saban</surname> <given-names>W</given-names></string-name>, <string-name><surname>Sekely</surname> <given-names>L</given-names></string-name>, <string-name><surname>Klein</surname> <given-names>RM</given-names></string-name>, <string-name><surname>Gabay</surname> <given-names>S.</given-names></string-name></person-group> <article-title>Endogenous orienting in the archer fish</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>. <year>2017</year>; <volume>114</volume>(<issue>29</issue>):<fpage>7577</fpage>–<lpage>7581</lpage>.</mixed-citation></ref>
<ref id="c66"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Santini</surname> <given-names>F</given-names></string-name>, <string-name><surname>Redner</surname> <given-names>G</given-names></string-name>, <string-name><surname>Iovin</surname> <given-names>R</given-names></string-name>, <string-name><surname>Rucci</surname> <given-names>M.</given-names></string-name></person-group> <article-title>EyeRIS: a general-purpose system for eye-movement-contingent display control</article-title>. <source>Behavioral Research Methods</source>. <year>2007</year>; <volume>39</volume>:<fpage>350</fpage>–<lpage>364</lpage>.</mixed-citation></ref>
<ref id="c67"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schütt</surname> <given-names>HH</given-names></string-name>, <string-name><surname>Harmeling</surname> <given-names>S</given-names></string-name>, <string-name><surname>Macke</surname> <given-names>JH</given-names></string-name>, <string-name><surname>Wichmann</surname> <given-names>FA</given-names></string-name></person-group>. <article-title>Painfree and accurate Bayesian estimation of psychometric functions for (potentially) overdispersed data</article-title>. <source>Vision Research</source>. <year>2016</year>; <volume>122</volume>:<fpage>105</fpage>–<lpage>123</lpage>.</mixed-citation></ref>
<ref id="c68"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shelchkova</surname> <given-names>N</given-names></string-name>, <string-name><surname>Poletti</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Modulations of foveal vision associated with microsaccade preparation</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2020</year>; <volume>117</volume>(<issue>20</issue>):<fpage>11178</fpage>–<lpage>11183</lpage>.</mixed-citation></ref>
<ref id="c69"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tan</surname> <given-names>M</given-names></string-name>, <string-name><surname>Jaeger</surname> <given-names>TF</given-names></string-name></person-group>. <article-title>Learning to understand an unfamiliar talker: Testing distributional learning as a model of rapid adaptive speech perception</article-title>. <source>Cognition</source>. <year>2025</year>; <volume>265</volume>: <elocation-id>106195</elocation-id>.</mixed-citation></ref>
<ref id="c70"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Theeuwes</surname> <given-names>J.</given-names></string-name></person-group> <article-title>Endogenous and Exogenous Control of Visual Selection</article-title>. <source>Perception</source>. <year>1994</year>; <volume>23</volume>(<issue>4</issue>):<fpage>429</fpage>–<lpage>440</lpage>.</mixed-citation></ref>
<ref id="c71"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Theeuwes</surname> <given-names>J.</given-names></string-name></person-group> <article-title>Top–down and bottom–up control of visual selection</article-title>. <source>Acta Psychologica</source>. <year>2010</year>; <volume>135</volume>(<issue>2</issue>):<fpage>77</fpage>–<lpage>99</lpage>.</mixed-citation></ref>
<ref id="c72"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Virsu</surname> <given-names>V</given-names></string-name>, <string-name><surname>Rovamo</surname> <given-names>J.</given-names></string-name></person-group> <article-title>Visual resolution, contrast sensitivity, and the cortical magnification factor</article-title>. <source>Experimental Brain Research</source>. <year>1979</year>; <volume>37</volume>(<issue>3</issue>):<fpage>475</fpage>–<lpage>494</lpage>.</mixed-citation></ref>
<ref id="c73"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wu</surname> <given-names>R</given-names></string-name>, <string-name><surname>Clark</surname> <given-names>AM</given-names></string-name>, <string-name><surname>Cox</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Intoy</surname> <given-names>J</given-names></string-name>, <string-name><surname>Jolly</surname> <given-names>PC</given-names></string-name>, <string-name><surname>Zhao</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Rucci</surname> <given-names>M.</given-names></string-name></person-group> <article-title>High-resolution eye-tracking via digital imaging of Purkinje reflections</article-title>. <source>Journal of Vision</source>. <year>2023</year>; <volume>23</volume>(<issue>5</issue>):<fpage>4</fpage>.</mixed-citation></ref>
<ref id="c74"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wu</surname> <given-names>X</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>A</given-names></string-name>, <string-name><surname>Zhang</surname> <given-names>M.</given-names></string-name></person-group> <article-title>How the size of exogenous attentional cues alters visual performance: From response gain to contrast gain</article-title>. <source>Quarterly Journal of Experimental Psychology</source>. <year>2021</year>; <volume>74</volume>(<issue>10</issue>):<fpage>1773</fpage>–<lpage>1783</lpage>.</mixed-citation></ref>
<ref id="c75"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yantis</surname> <given-names>S.</given-names></string-name></person-group> <article-title>Stimulus-driven attentional capture</article-title>. <source>Psychological Bulletin</source>. <year>1993</year>; <volume>114</volume>(<issue>1</issue>):<fpage>108</fpage>–<lpage>129</lpage>.</mixed-citation></ref>
<ref id="c76"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yeshurun</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Carrasco</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Attention improves or impairs visual performance by enhancing spatial resolution</article-title>. <source>Nature</source>. <year>1998</year>; <volume>396</volume>:<fpage>72</fpage>–<lpage>75</lpage>.</mixed-citation></ref>
<ref id="c77"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yuval-Greenberg</surname> <given-names>S</given-names></string-name>, <string-name><surname>Merriam</surname> <given-names>EP</given-names></string-name>, <string-name><surname>Heeger</surname> <given-names>DJ</given-names></string-name></person-group>. <article-title>Spontaneous Microsaccades Reflect Shifts in Covert Attention</article-title>. <source>Journal of Neuroscience</source>. <year>2014</year>; <volume>34</volume>(<issue>41</issue>):<fpage>13693</fpage>–<lpage>13700</lpage>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108788.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Salinas</surname>
<given-names>Emilio</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Wake Forest University School of Medicine</institution>
</institution-wrap>
<city>Winston-Salem</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Compelling</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study explores how exogenous attention operates at the finest spatial scale of vision, within the foveola - a topic that has not been previously explored. The question is <bold>important</bold> for understanding how attention shapes perception, and how it differs between the periphery and the central regions of highest visual acuity. The evidence is <bold>compelling</bold>, as shown by carefully designed experiments with state-of-the-art eye tracking to monitor attended locations just a few tens of minutes of arc away from the fixation target, but additional clarification regarding analyses and implications for vision and oculomotor control would broaden the impact of the study.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108788.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The manuscript investigates how exogenous attention modulates spatial frequency sensitivity within the foveola. Using high-precision eye-tracking and gaze-contingent stimulus control, the authors show that exogenous attention selectively improves contrast sensitivity for low- to mid-range spatial frequencies (4-8 cycles/degree), but not for higher frequencies (12-20 CPD). In contrast, improvements in asymptotic performance at the highest contrast levels occur across all spatial frequencies. These results suggest that, even within the foveola, exogenous attention operates through a mechanism similar to that observed in peripheral vision, preferentially enhancing lower spatial frequencies.</p>
<p>Strengths:</p>
<p>The study shows strong methodological rigor. Eye position was carefully controlled, and the stimulus generation and calibration were highly precise. The authors also situate their work well within the existing literature, providing a clear rationale for examining the fine-grained effects of exogenous attention within the foveola. The combination of high spatial precision, gaze-contingent presentation, and detailed modeling makes this a valuable technical contribution.</p>
<p>Weaknesses:</p>
<p>The manipulation of attention raises some interpretive concerns. Clarifying this issue, together with additional detail about statistics, participant profiles, other methodological elements, and further discussion in relation to oculomotor control in general, could broaden the impact of the findings.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108788.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This study aims to test whether foveal and non-foveal vision share the same mechanisms for endogenous attention. Specifically, they aim to test whether they can replicate at the foveola previous results regarding the effects of exogenous attention for different spatial frequencies.</p>
<p>Strengths:</p>
<p>Monitoring the exact place where the gaze is located at this scale requires very precise eye-tracking methods and accurate and stable calibration. This study uses state-of-the-art methods to achieve this goal. The study builds on many other studies that show similarities between foveal vision and non-foveal vision, adding more data supporting this parallel.</p>
<p>Weaknesses:</p>
<p>The study lacks a discussion of the strength of the effect and how it relates to previous studies done away from the fovea. It would be valuable to know if not just the range of frequencies, but the size of the effect is also comparable.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108788.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This paper explores how spatial attention affects foveal information processing across different spatial frequencies. The results indicate that exogenously directed attention enhances contrast sensitivity for low- to mid-range spatial frequencies (4-8 CPD), with no significant benefits for higher spatial frequencies (12-20 CPD). However, asymptotic performance increased as a result of spatial attention independently of spatial frequency.</p>
<p>Strengths:</p>
<p>The strengths of this article lie in its methodological approach, which combines a psychophysical experiment with precise control over the information presented in the foveola.</p>
<p>Weaknesses:</p>
<p>The authors acknowledge that they used the standard approach of analyzing observer-averaged data, but recognize that this method has limitations: it ignores the uncertainty associated with parameter estimates and the relationships between different parameters of the psychometric model. This may affect the interpretation of attentional effects. In the future, mixed-effects models at the trial level could overcome these limitations.</p>
</body>
</sub-article>
</article>