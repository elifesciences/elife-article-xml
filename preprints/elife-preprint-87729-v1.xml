<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">87729</article-id>
<article-id pub-id-type="doi">10.7554/eLife.87729</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.87729.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.3</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>A generative model of electrophysiological brain responses to stimulation</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9650-2229</contrib-id>
<name>
<surname>Vidaurre</surname>
<given-names>Diego</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Center for Functionally Integrative Neuroscience, Department of Clinical Medicine, Aarhus University</institution>, 8000 (<country>Denmark</country>)</aff>
<aff id="a2"><label>2</label><institution>Department of Psychiatry, Oxford University</institution>, OX3 7JX (<country>UK</country>)</aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Luo</surname>
<given-names>Huan</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Peking University</institution>
</institution-wrap>
<city>Beijing</city>
<country>China</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Behrens</surname>
<given-names>Timothy E</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Oxford</institution>
</institution-wrap>
<city>Oxford</city>
<country>United Kingdom</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label> Corresponding email: <email>dvidaurre@cfin.au.dk</email></corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2023-05-31">
<day>31</day>
<month>05</month>
<year>2023</year>
</pub-date>
<volume>12</volume>
<elocation-id>RP87729</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-03-29">
<day>29</day>
<month>03</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-05-20">
<day>20</day>
<month>05</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.01.03.522583"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2023, Vidaurre</copyright-statement>
<copyright-year>2023</copyright-year>
<copyright-holder>Vidaurre</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-87729-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Each brain response to a stimulus is, to a large extent, unique. However this variability, our perceptual experience feels stable. Standard decoding models, which utilise information across several areas to tap into stimuli distributed representations and processing, are fundamentally based on averages and, therefore, can focus precisely on the features that are most stable across stimulus presentations. But what are these stable features that may sustain stable perception across experiences is still poorly understood. This question is difficult to address in the absence of a generative model of the signal. Here, I introduce <italic>genephys</italic>, a generative model of brain responses to stimulation publicly available as a Python package that, when confronted with a decoding algorithm, can reproduce the structured patterns of decoding accuracy observed in real data. Using this approach, I characterise how these patterns may be brought about by the different aspects of the signal, which in turn may translate into distinct putative neural mechanisms. In particular, the model shows that the features in the data that support successful decoding —and, therefore, likely reflect stable mechanisms of stimulus representation— have an oscillatory component that spans multiple channels, frequencies and latencies of response; and an additive, slower response with a specific (cross-frequency) relation to the phase of the oscillatory, faster component. At the individual trial level, still, responses are found to be highly variable, which can be due to various factors including phase noise and probabilistic activations.</p>
</abstract>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>This is a minor revision prior for the manuscript to be posted as an eLife preprint, where I have shortened the title for simplicity and added some acknowledgements that were missing.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>There are virtually infinite manners by which a constant stimulus can impinge into the sensorium of an animal. For instance, our noses have many receptors that can sense a given odorant molecule, but only a small subset of those are excited each time the odour is perceived (<xref ref-type="bibr" rid="c1">Axel, 1995</xref>). Similarly, photons hit and excite photoreceptors in the retina randomly and sparsely for a given presented image (<xref ref-type="bibr" rid="c7">Dowling, 1987</xref>). An important aspect of sensation and perception is that never the exact same receptors are excited every time we perceive and, still, our perceptual experiences are quite stable. So the brain must have a way to transit from lack of invariance at the microscopic sensory level toward invariance at the macroscopic level, which ultimately supports the invariant aspects of conscious perception and behaviour. However, we observe significant variability in the brain responses at the trial level (<xref rid="c24" ref-type="bibr">Stein, et al., 2005</xref>; <xref ref-type="bibr" rid="c19">McIntosh, et al., 2008</xref>; <xref rid="c11" ref-type="bibr">Garrett, et al., 2013</xref>), including at the earliest layers of the perceptual hierarchy (<xref ref-type="bibr" rid="c5">Croner, et al., 1993</xref>; <xref ref-type="bibr" rid="c9">Freeman, 1978</xref>) —that is, each perceptual experience is associated with a unique neural trajectory that does not repeat. The gap between stability in subjective perception and the changing nature of brain responses in an important question in neuroscience. Here, I investigate the distributed aspects of brain activity that are most stable across experimental repetitions, and are therefore most likely to support stable perceptual experiences.</p>
<p>Decoding analysis uses a multivariate machine learning algorithm to predict the identity of the observed stimulus from brain data (<xref ref-type="bibr" rid="c13">Haxby, et al., 2014</xref>; <xref ref-type="bibr" rid="c26">Stokes, et al., 2015</xref>), producing a set of algebraic subspaces (one per time point) where the brain signals maximally discriminate between conditions, and yielding a measure of accuracy across time that reflects how much information the data conveys about the stimuli. The assessment, via decoding accuracy, of how the discriminative space changes throughout the trial offers a view of the properties of stimulus representation and processing. However, it is not straightforward to know what specific aspects of the signal cause the patterns of decoding accuracy that we observe in perceptual experiments. Without this capacity, it is hard to link these patterns to actual neural mechanisms.</p>
<p>To help fill this gap, I introduce a generative model of multichannel electrophysiological activity (e.g. EEG or MEG) that, under no stimulation, exhibits chaotic phasic and amplitude fluctuations; and that, when stimulated, responds by manipulating certain aspects of the data, such as ongoing phase or signal amplitude, in a stimulus-specific manner. Specifically, in every trial, each channel may or may not respond to stimulation, according to a certain probability. When a channel responds, it can do it in different ways: (i) by phase resetting of the ongoing oscillation to a given target phase and then entraining to a given frequency, (ii) by an additive oscillatory response independent of the ongoing oscillation, (iii) by modulating the amplitude of the stimulus-relevant oscillations, or (iv) by an additive non-oscillatory (slower) response. Each of these effects can arguably be underpinned by distinct neural mechanisms. I named this model <italic>genephys</italic> by <italic>gen</italic>erative model of <italic>e</italic>mpirical electro<italic>phys</italic>iological signals. This model is empirical in the sense that it purely accounts for the features in the signal that are observable, without making any assumption about the underlying neurobiological causes; that is, it can generate signals that, depending on its parametrisation, can share empirical properties with real data. In particular, when confronted with a decoding algorithm, the data generated by this model can show, depending on its configuration, patterns of decoding accuracy with similar characteristics to we observe in real data.</p>
<p>Using real data during a visual experiment as a benchmark, I observed that two different mechanisms can produce realistic decoding results as we see in real visual perception: either phase resetting to a stimulus-specific phase followed by frequency entrainment, or an additive oscillation with a stimulus-specific phase. Either way, a cross-frequency coupling effect is also necessary, where an additive slower response holds a specific phasic relation with the oscillatory (faster) response. Furthermore, the stimulus-related oscillations need to span multiple channels, and have a diversity of frequencies and latencies of response. Other experimental paradigms can be investigated with g<italic>enephys</italic>, which is publicly available as a Python package<sup><xref ref-type="fn" rid="fn1">1</xref></sup>.</p>
</sec>
<sec id="s2">
<title>Methods</title>
<sec id="s2a">
<title>A generative model of empirical electrophysiological signals: <italic>genephys</italic></title>
<p>While the system is unperturbed, <italic>genephys</italic> is based on sampling spontaneously varying instantaneous frequency and amplitude (square root of power) time series, <italic>f</italic><sup>rest</sup> and <italic>a</italic><sup>rest</sup> respectively, that are analytically combined to form the sampled signal <italic>x</italic>. Amplitude and frequency are allowed to oscillate within ranges <italic>r</italic><sup><italic>f</italic></sup> and <italic>r</italic><sup><italic>a</italic></sup>. Instantaneous frequency here refers to angular frequency, from which we can obtain the ordinary frequency in Hertz as <inline-formula><alternatives><inline-graphic xlink:href="522583v3_inline1.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, where <italic>F</italic> is the sampling frequency of the signal. Both <italic>f</italic><sup>rest</sup> and <italic>a</italic><sup>rest</sup> are sampled separately from an autoregressive process of order one, endowing them with chaotic, non-oscillatory dynamics. Given autoregressive parameters <italic>b</italic><sup><italic>f</italic></sup>, <italic>b</italic><sup><italic>a</italic></sup> &lt;1, and Gaussian-noise variables <inline-formula><alternatives><inline-graphic xlink:href="522583v3_inline2.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, I generate <italic>f</italic><sup>rest</sup> and <italic>a</italic><sup>rest</sup> for a given channel as
<disp-formula id="ueqn1">
<alternatives><graphic xlink:href="522583v3_ueqn1.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
Without stimulation, a phase time series <italic>φ</italic><sup>rest</sup> is then built as
<disp-formula id="ueqn2">
<alternatives><graphic xlink:href="522583v3_ueqn2.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
Then, given some Gaussian-distributed measurement noise <italic>∈</italic><sub><italic>t</italic></sub> with standard deviation <italic>σ</italic><sub><italic>∈</italic></sub>, I build <italic>x</italic> (in absence of stimulation) as
<disp-formula id="ueqn3">
<alternatives><graphic xlink:href="522583v3_ueqn3.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
This process is done separately per channel and per trial. Note that, under no stimulation, the channel time series are therefore (asymptotically) uncorrelated. We can think of them as dipoles in brain space. We can induce correlations for instance by projecting these time series into a higher-dimensional space, which we can consider to be in sensor space, or by using correlated noise. Altogether, this generates chaotic oscillatory data akin to real data.</p>
<p>When a stimulus is presented at time point <italic>τ</italic> of the trial, a perturbation is introduced into the system on the <italic>p</italic> channels that are stimulus-relevant, which can be a subset of the total number of channels. When a channel is not relevant, it does not respond; when it is relevant, it responds to the stimulus stochastically:
<disp-formula id="ueqn4">
<alternatives><graphic xlink:href="522583v3_ueqn4.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
Where <italic>θ</italic><sub><italic>j</italic></sub> is a hyperparameter representing a certain probability. In simpler words, relevant channels might respond in some trials, but not in others. In all the simulations, I set all channel probabilities to a single value, <italic>θ</italic><sub><italic>j</italic></sub> <italic>= θ</italic>, but other configurations are possible.</p>
<p>Given some stimulus presentation at time point <italic>τ</italic>, a channel may respond:</p>
<list list-type="simple">
<list-item><label>-</label><p>By phase-resetting to a condition-specific target phase, and then, when the target phase is reached, by frequency entraining to a target frequency.</p></list-item>
<list-item><label>-</label><p>By adding a transient, oscillatory response with a condition-specific phase, amplitude and frequency.</p></list-item>
<list-item><label>-</label><p>By increasing the (absolute) amplitude of the ongoing oscillation following stimulus presentation (with no phase effect).</p></list-item>
<list-item><label>-</label><p>By adding a transient, non-oscillatory response with a condition-specific amplitude.</p></list-item>
</list>
<p>To implement these effects, I use an double logarithmic response function, asymmetric around the time of maximum effect <italic>t</italic><sub>max</sub>. For the left side (before <italic>t</italic><sub>max</sub>), this function is parametrised by: <italic>δ</italic><sub>1</sub>, reflecting the latency of the response in number of time points; and <italic>δ</italic><sub>2</sub>, reflecting how many time points it takes the logarithmic function to go from zero to its maximum before it changes to the logarithmic function. Therefore <italic>t</italic><sub>max <italic>=</italic></sub> <italic>δ</italic><sub>1</sub> + <italic>δ</italic><sub>2</sub> + <italic>τ</italic>. I introduce some noise in <italic>δ</italic><sub>1</sub> per trial to make the timing of the response to vary, as per <inline-formula><alternatives><inline-graphic xlink:href="522583v3_inline3.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, where <inline-formula><alternatives><inline-graphic xlink:href="522583v3_inline4.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> is a model hyperparameters. This latency noise could be fixed for all channels (absolute stochastic latency) or per channel (relative stochastic latency). It is also possible to use different parametrisations per channel. For example, we can induce a diversity of latencies for the different channels by using different values of <italic>δ</italic><sub>1</sub> per channel — so that some channels (e.g. those more closely related to primary sensory areas) respond earlier than others (e.g. those related to associative areas). Once the activation reaches its maximum at <italic>t</italic><sub>max</sub>, the decay is also parametrised by a logarithmic function with a parameter <italic>δ</italic><sub>3</sub>, reflecting how many time points it takes the logarithmic function to go from its maximum to zero. A different response function can be used for each type of effect. In the <bold>Supplemental Information</bold> there is a full mathematical specification of the response function.</p>
<p>With respect to the phase-reset and frequency entrainment effect, the phase reset occurs before <italic>t</italic><sub>max</sub>, when the target phase is reached. For each trial and channel,
<disp-formula id="ueqn5">
<alternatives><graphic xlink:href="522583v3_ueqn5.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
Where, for each trial, <italic>φ</italic><sup><italic>k</italic></sup> is randomly sampled from a von Mises distribution with mean the target phase <inline-formula><alternatives><inline-graphic xlink:href="522583v3_inline5.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> and standard deviation <italic>σ</italic><sub><italic>φ</italic></sub> ; ∇<sub><italic>t</italic></sub> is the polar gradient between the target phase and the ongoing phase <italic>φ</italic><sub><italic>t</italic>-1</sub> ; and <italic>g</italic><sub><italic>t</italic></sub> is the value taken by the response function at time point <italic>t</italic>. After <italic>t</italic><sub>max</sub>, phase-resetting is over, and the phase entrainment period starts,
<disp-formula id="ueqn6">
<alternatives><graphic xlink:href="522583v3_ueqn6.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
The system then entrains to a possibly stimulus-specific, possibly channel-specific, target frequency <italic>f</italic><sup><italic>k</italic></sup>, with a strength that logarithmically decreases as moves <italic>t</italic> away from <italic>t</italic><sub>max</sub>.</p>
<p>With respect to the additive oscillatory response, we consider a sinusoidal oscillator, which is damped by the action of the response function <italic>g</italic><sub><italic>t</italic></sub>:
<disp-formula id="ueqn7">
<alternatives><graphic xlink:href="522583v3_ueqn7.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
Here, <italic>α</italic><sup><italic>k</italic></sup> reflects the amplitude of the additive oscillation, <italic>ω</italic><sup><italic>k</italic></sup> its frequency, and <italic>γ</italic><sup><italic>k</italic></sup> its phase.</p>
<p>For the amplitude modulation, I apply a multiplying factor to the ongoing amplitude time series:
<disp-formula id="ueqn8">
<alternatives><graphic xlink:href="522583v3_ueqn8.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <italic>m</italic><sup><italic>k</italic></sup> is a proportional increment; for example, <italic>m</italic><sup><italic>k</italic></sup> <italic>=</italic> 0.1 would produce an increment of 10% in amplitude at <italic>t</italic><sub>max</sub>.</p>
<p>With respect to the additive non-oscillatory response, we have:
<disp-formula id="ueqn9">
<alternatives><graphic xlink:href="522583v3_ueqn9.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <italic>S</italic><sup><italic>k</italic></sup> is sampled from a Gaussian distribution, <inline-formula><alternatives><inline-graphic xlink:href="522583v3_inline6.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, where <inline-formula><alternatives><inline-graphic xlink:href="522583v3_inline7.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> is stimulus-specific.</p>
<p>Given these elements, the signal is built as
<disp-formula id="ueqn10">
<alternatives><graphic xlink:href="522583v3_ueqn10.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
This model can be trivially extended to have correlated noise <italic>∈</italic><sub><italic>t</italic></sub> across channels, which would also make the channels non-independent.</p>
<p><bold><xref rid="fig1" ref-type="fig">Figure 1</xref></bold> shows two examples of how the effect of stimulation looks for one trial and one channel. The left panel corresponds to a phase resetting plus frequency entrainment effect, and the middle panel corresponds to an additive oscillation; both are accompanied by an additive non-oscillatory response. Here, the sampled signal <italic>x</italic> is shown in blue on top, and the phase <italic>φ</italic>, frequency <italic>f</italic>, amplitude <italic>a</italic>, additive non-oscillatory response <italic>z</italic>, and additive oscillatory response <italic>y</italic> are shown in red underneath. For comparison, the right panel shows real magnetoencephalography data from a passive visual experiment where a number of images are shown to the subjects at a rate of one image per second (<xref ref-type="bibr" rid="c4">Cichy, et al., 2016</xref>); the measured (filtered) signal is shown in blue, while the red curves correspond to analytical phase, frequency and amplitude (computed via the Hilbert transform on the filtered signal). <bold><xref rid="tbl1" ref-type="table">Table 1</xref></bold> summarises all the hyperparameters that configure the model.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><p>Left and middle: single-trial example of the generated signal (in blue) and its constitutive components (in red): instantaneous phase, frequency and amplitude, as well as an additive non-oscillatory and oscillatory response components; the left panel reflects a phase resetting plus frequency entrainment effect, while the middle panel corresponds to an additive oscillatory component. Right: real (filtered) magnetoencephalography data collected during passive viewing; the red curves are the analytically computed phase, frequency and amplitude (via the Hilbert transform).</p></caption>
<graphic xlink:href="522583v3_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><p><italic>genephys</italic> configuration hyperparameters.</p></caption>
<graphic xlink:href="522583v3_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s2b">
<title>Decoding accuracy to characterise structured invariance</title>
<p>One possible approach to characterise the stable aspects of brain responses to stimulation is the analysis of average evoked responses potentials or fields (ERP/F) (<xref ref-type="bibr" rid="c6">Dawson, 1954</xref>; <xref ref-type="bibr" rid="c25">Steven &amp; Kappenman, 2011</xref>; <xref ref-type="bibr" rid="c21">Pfurtscheller &amp; Lopes da Silva, 1999</xref>). However, this is limited because perceptual experiences emerge from activity patterns across multiple brain areas acting in a distributed fashion, whereas ERP/Fs are separately evaluated channel by channel. Also, ERP/F analyses are not concerned with what aspects of the signal carry specific information about the stimulus —i.e. they are not predictive of the stimulus (<xref ref-type="bibr" rid="c15">Kragel, et al., 2018</xref>).</p>
<p>I instead focus on decoding, which finds patterns of differential activity between conditions across channels and throughout time in a multivariate way (<xref ref-type="bibr" rid="c12">Grootswagers, et al., 2017</xref>). I use linear discriminant analysis (LDA), which estimates a projection or subspace in the data that maximally discriminate between conditions. Throughout the trial, this set of projections reflects information about the dynamics of stimulus processing.</p>
<p>Specifically, I use the temporal generalisation matrix (TGM), a <italic>T</italic> × <italic>T</italic> matrix of decoding accuracies (where <italic>T</italic> is the number of time points in the trial), such that one decoding model is trained per time point and tested on every time point of the trial using cross-validation (<xref ref-type="bibr" rid="c14">King &amp; Dehaene, 2014</xref>). This way, the diagonal of the TGM reflects how well can we can decode information time point by time point, while the off-diagonal of the TGM shows how well decoding models generalize to time points different from those where they were trained. As illustrated in <bold><xref rid="figS1" ref-type="fig">Supplemental Figure 1</xref></bold>, where I show a real-data TGM from a subject performing a simple visual task (<xref ref-type="bibr" rid="c4">Cichy et al., 2016</xref>; <xref rid="c27" ref-type="bibr">Vidaurre et al, 2019</xref>), the TGM exhibits some characteristic features that we often see throughout the literature. First, there is a strong diagonal band that is relatively narrow early in the trial, often surrounded by areas of worse-than-baseline accuracy. Then, the accuracy on the diagonal becomes progressively wider and weaker, expanding until relatively late in the trial. Also, there are bands of higher-than-baseline accuracy stemming vertically and horizontally from the time points of maximum accuracy after a brief period of depression, which often show oscillatory behaviour throughout the band. Central to this paper is the observation that the variability of brain responses to stimuli are structured in a specific manner, and that the TGM can reflect various aspects of this structure —but not others. Below, I explore <italic>genephys’</italic> configuration space in relation to its ability to produce patterns of decoding accuracy similar to these from real data.</p>
</sec>
</sec>
<sec id="s3">
<title>Results</title>
<p>In the experiments below, I confront <italic>genephys</italic> to classification-based decoding analysis to characterise the stochastic nature of the subspace of brain activity that carry stimulus-specific information. In each simulation, I generated 10 data sets per combination of parameters, each with <italic>N</italic>=250 trials and 250 time points per trial (i.e. one second for a sampling frequency of 250Hz). For simplicity, only one spontaneous oscillation was sampled, with (angular) frequencies broadly ranging between 0.01 and 0.25π. The number of channels is set to 32. All All TGMs reflect cross-run averages.</p>
<p>For comparison, I use magnetoencephalography (MEG) data recorded while participants viewed object images across 118 categories, as presented in (<xref ref-type="bibr" rid="c4">Cichy, et al., 2016</xref>). Each image category were presented 30 times each. Presentation occurred during the first 500ms of the trial, and trials were 1s long, sampled at 250Hz. The multi-channel sensor-space data, epoched around the presentation of each visual stimulus, can be used to train a decoder to predict which visual image is being presented (<xref ref-type="bibr" rid="c4">Cichy, et al., 2016</xref>; <xref ref-type="bibr" rid="c28">Vidaurre, et al., 2021</xref>). Here, I decoded whether the image corresponded to an animate category (a dog) or inanimate (a pencil).</p>
<sec id="s3a">
<title>Oscillatory components underlying the observed decoding patterns</title>
<p>In real data, we often see oscillatory patterns in the TGM, indicating that the subspace of brain activity that carries information about the stimulus must have some oscillatory element. At least two distinct mechanisms may be behind this phenomenon: first, an ongoing oscillation might reset its phase and then entrain to a given frequency in a stimulus-specific fashion; second, a stimulus -specific oscillatory response might by added to the signal after stimulus presentation on top of the existing ongoing oscillation. Essentially, the difference between the two is that, in the phase resetting case, the ongoing oscillations are altered; while in the other case the additive oscillation coexists with the ongoing oscillations. Next, I use <italic>genephys</italic> together with decoding analysis to compare between these two alternatives, showing that both can produce decoding patterns similar to what we observe empirically in real experiments.</p>
<p>In the simulations, all 32 channels convey information but with a relatively low activation probability (<italic>θ</italic> = 1/6). For phase resetting and frequency entrainment, I considered a diverse range of entrainment frequencies (between 0.1 and 0.2 in angular frequency) and latencies of response (<italic>θ</italic><sub>1</sub> = 0–160ms) across channels. For the additive oscillatory, I similarly considered a similar range of frequencies and latencies of response across channels. (I will show below that channel stochasticity and frequency diversity are both important to produce realistic decoding patterns). The difference between the two fictitious stimuli lied in their different target frequencies (that is, <inline-formula><alternatives><inline-graphic xlink:href="522583v3_inline8.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> for phase resetting and <italic>γ</italic><sup><italic>k</italic></sup> for the additive oscillation; see specification of the model in <bold>Methods</bold>). I also included an additive non-oscillatory response with a stimulus-specific amplitude, which (as I will also show later) is important to produce realistic decoding results. I did not optimise the parameters of the model to reflect the fine details from real data TGMs, since TGMs vary across subjects (see <bold><xref rid="figS2" ref-type="fig">Supplementary Figure 2</xref></bold>) and across experimental paradigms (<xref ref-type="bibr" rid="c14">King &amp; Dehaene, 2014</xref>).</p>
<p><bold><xref rid="fig2" ref-type="fig">Figure 2</xref></bold> (top) shows TGMs together with one-channel ERPs (where each stimulus is represented by a different tonality of blue or red; bottom) for the sampled signal <italic>x</italic> and its various constitutive elements: ongoing phase <italic>φ</italic>, frequency <italic>f</italic>, amplitude <italic>a</italic>, additive non-oscillatory response <italic>z</italic>, and, when applicable, an additive oscillatory response. The left panels show results for phase reset plus frequency entrainment, where we can see an effect on the ongoing phase. The middle panels show results for the additive oscillation; here, there is no effect on the ongoing phase, and, instead, the additive oscillatory component <italic>y</italic> is shown at the bottom. The right panels show an example from real data, where phase, frequency and amplitude were computed analytically using the Hilbert transform on the filtered data.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><p>Examples of two configurations based on phase resetting and frequency entrainment (left) and additive oscillatory responses (middle), shown together with results obtained from real data (right). At the top, temporal generalisation matrix (TGM) from standard decoding analysis; on the bottom, average evoked responses (ERP/F) for the sampled signal (blue) and its components (red), for the two stimuli (represented as different tonalities of blue or red).</p></caption>
<graphic xlink:href="522583v3_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Although the exact details differ from the right panels of the figure, both types of effects produce patterns reproducing the characteristic signatures of real data. These include the strong diagonal, the vertical/horizontal bands of high generalisation accuracy, and the broadening of accuracy in later stages of the trial (see <bold><xref rid="figS1" ref-type="fig">Supplementary Figure 1</xref></bold>). Note that phase resetting plus frequency entrainment is, everything else held constant, a stronger effect than an additive oscillatory response. This is because, for the latter, the ongoing oscillations (here, non-stimulus specific) can interfere with the phase of the additive response, impeding cross-trial phase locking throughout the trial; while, for phase resetting, the ongoing oscillation <italic>is</italic> the effect and there is therefore no interference. In this particular example, anyway, the range for the additive oscillation (0.1–0.2) was much narrower than that of the ongoing oscillation (0.01–0.25π), making the interference more unlikely; that is, the ongoing oscillation phase is approximately averaged out, and treated as noise by the decoding algorithm.</p>
</sec>
<sec id="s3b">
<title>The distribution of stimulus-specific information spans multiple channels and is stochastic</title>
<p>Next, I use <italic>genephys</italic> to show that the stimulus-specific information spans a large number of channels, and do so stochastically. I focus on the additive oscillatory response effect, which, as shown in the previous section, can produce comparable results to phase resetting followed by frequency entrainment.</p>
<p>I varied the number of relevant channels <italic>p</italic> as well as the probability of activation <italic>θ</italic> for the relevant channels, so that the subset of channels that activate is different for every trial. <bold><xref rid="fig3" ref-type="fig">Figure 3</xref></bold> shows the TGMs for various combinations of <italic>p</italic> and <italic>θ</italic>, from a configuration where there are few relevant channels that always respond (<italic>p</italic> = 1, <italic>θ</italic> = 1) to another where there are many relevant channels that only respond sparsely (<italic>p</italic> = 32, <italic>θ</italic> = 1/8). As previously, channels have diverse frequencies and latencies of response; and an additive non-oscillatory response is also included as an effect.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><p>Having more dimensions (channels) carrying stimulus-specific information, but with a larger degree of stochasticity, produces more realistic decoding patterns than having fewer dimensions with a lower degree of stochasticity. Here stochasticity referred to the channels’ probability of activation.</p></caption>
<graphic xlink:href="522583v3_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Contrary to empirical TGMs (which have a relatively stylised diagonal), having only a few relevant channels (first three panels of <bold><xref rid="fig3" ref-type="fig">Figure 3</xref></bold>) produces unrealistically geometric patterns. This indicates that, in real data, the subspace of the data that contains information about the stimulus needs to be multi-dimensional; that is, that the amount of relevant channels must be relatively high (as in the fourth panel of <bold><xref rid="fig3" ref-type="fig">Figure 3</xref></bold>). However, this must occur in combination with an unstable informational contribution of the channels (in this case expressed by having probabilistic activations), or else the decoding accuracy would become unrealistically perfect. In summary, the subspace of brain activity that carries out information about the condition is highly stochastic at the single trial level.</p>
</sec>
<sec id="s3c">
<title>Frequency entrainment span multiple frequencies and latencies</title>
<p>In the previous sections, I showed that a noisy, additive oscillation effect (or phase reset effect) across multiple channels can generate decoding patterns as we see in real data. Next, I demonstrate that the effect must span a diversity of frequencies across channels,), as well as a diversity of latencies of response. In real data, frequency diversity can be expressed as, for example, a gradient of frequencies from primary towards more associative areas; while diversity in latency could reflect phenomena such that primary areas respond earlier than associative areas.</p>
<p>For frequency diversity, each channel is endowed with a different effect-related frequency that are not multiples of each other, i.e. different values of <italic>ω</italic><sup><italic>k</italic></sup> between 0.1 and 0.2 in angular frequency. For latency diversity, channels do not respond simultaneously but with different values of <italic>δ</italic><sub>1</sub> between 0 and 120ms (see the specification of the model in <bold>Methods</bold>). <bold><xref rid="fig4" ref-type="fig">Figure 4</xref></bold> shows a two-by-two design. On the left column, I set <italic>genephys</italic> to have a uniform frequency of response, while on the right column it uses a diversity of frequencies. On the top row, we have a uniform latency of response (i.e. all channels have the same latency of response), whereas on the bottom row we have a diversity of latencies of response. See <bold><xref rid="figS3" ref-type="fig">Supplemental Figure 3</xref></bold> for a similar result with phase resetting followed by frequency entrainment.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><p>Oscillatory responses to stimulation occur in a diversity of frequencies and latencies across channels. Top row, single latency of response; bottom row, diverse latencies across channels; left column, single frequency; right column; diverse frequencies across channels.</p></caption>
<graphic xlink:href="522583v3_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>As mentioned, real data normally yield a relatively tight band of high decoding accuracy along the diagonal, often accompanied from contiguous parallel bands of below-baseline. Critically, the fact that we do not typically observe a chequer pattern means that the trajectory of phase across channels does not repeat itself periodically. If it did, it would show patterns as in the top left panel, where the uniformity of frequencies and latencies gives rise to an unrealistically regular pattern —such that a decoder trained at a certain time point will become equally accurate again after one cycle at the entrained frequency. Having a diversity of frequencies but not of latencies produces another regular pattern consisting of alternating, parallel bands of higher/lower than baseline accuracy. This, shown in the bottom left panel, is not what we see in real data either. Having a diversity of latencies but not of frequencies gets us closer to a realistic pattern, as we see in the top right panel. Finally, having diversity of both frequencies and latencies produces the most realistic pattern, as we can see by comparing to the examples in <bold><xref rid="fig2" ref-type="fig">Figure 2</xref></bold> or in <bold><xref rid="figS2" ref-type="fig">Supplemental Figure 2</xref></bold>, and many others throughout the literature (<xref ref-type="bibr" rid="c14">King &amp; Dehaene, 2014</xref>). Similar conclusions can be drawn from <bold><xref rid="figS3" ref-type="fig">Supplemental Figure 3</xref></bold>, where the effect is based on phase resetting and subsequent frequency entrainment.</p>
<p>In summary, these results show that it is not only important for the stimulus-relevant subspace of activity to be high-dimensional in space, but also in the time domain.</p>
</sec>
<sec id="s3d">
<title>A slower additive component must be coupled with the oscillatory response</title>
<p>In real data, we normally also see a general broadening of decoding accuracy in the TGM as time progresses throughout the trial (see <bold>Figure SI-1</bold>). This is often interpreted as neural representations becoming more stable at latter stages of the trial, which is putatively linked to memory encoding and higher cognitive processes.</p>
<p>In <bold><xref rid="fig5" ref-type="fig">Figure 5A</xref></bold>, I show that this effect can be reproduced on synthetic data through the addition of a slowly-progressing, non-oscillatory response. Specifically, I set up a response function such that, after stimulus presentation, the non-oscillatory additive response ramps up to a stimulus-specific target value in about 100s, and then slowly decays to vanish at around 800ms. Also, I modulate the strength of the oscillatory response using values of <inline-formula><alternatives><inline-graphic xlink:href="522583v3_inline9.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> (see <bold>Methods</bold>) that differ between the two stimuli by a magnitude that ranges from 0.0 (no difference) to 1.0 (for reference, the examples in <bold><xref rid="fig2" ref-type="fig">Figure 2</xref></bold> had difference of 0.5). As seen in <bold><xref rid="fig5" ref-type="fig">Figure 5A</xref></bold>, the broadening of decoding accuracy gets stronger as the difference in the slow response increases.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><p>An additive non-oscillatory response produces an slow expansion of decoding accuracy toward the end of the trial. <bold>A</bold>: By increasing the strength of the non-oscillatory response, the broadening of accuracy becomes more prominent. <bold>B</bold>: Changing the nature of the phasic relationship between the slower and the faster (oscillatory component) greatly changes the TGM, from all in-phase (left) towards all anti-phase (right).</p></caption>
<graphic xlink:href="522583v3_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Another feature commonly seen on real data are the vertical and horizontal bars of high accuracy stemming from the time point of maximum accuracy (see <bold>Figure SI-1</bold>), which is sometimes interpreted as evidence of recurrence of the stimulus representations in the brain.</p>
<p>I show in <bold><xref rid="fig5" ref-type="fig">Figure 5B</xref></bold> that this feature emerges from the following property in the data: that the amplitude differences of the slow component must be consistent with the phase differences of the oscillatory component. For example, if the phase difference of the oscillatory component between stimulus A and B is positive at the time of maximum activation (<italic>t</italic><sub>max</sub>), then the difference in amplitude of the slower component has to be also positive throughout the trial —i.e. the two effects must be in-phase. That was the case for all panels of <bold><xref rid="fig5" ref-type="fig">Figure 5A</xref></bold>. For <bold><xref rid="fig5" ref-type="fig">Figure 5B</xref></bold>, while keeping a difference between the values of <italic>z</italic><sup><italic>k</italic></sup> equal to 0.5 (as in the middle panel of <bold><xref rid="fig5" ref-type="fig">Figure 5A</xref></bold>), I varied the phase consistency between the oscillatory and the non-oscillatory components. In the leftmost panel, the oscillatory and the non-oscillatory components are in-phase for all channels, while in the rightmost panel, they are anti-phase for all channels; in between, 25%, 50% and 75% of the channels are in-phase (and 75%, 50% and 25% are anti-phase, respectively). As observed, the type of phase consistency between the oscillatory and the non-oscillatory component has a strong impact on the TGM. In particular, an in-phase relation bears the most consistent patterns with the real data shown throughout the paper.</p>
<p>Altogether, these results reflect the importance of a specific form of cross-frequency coupling in order to obtain results as we observe in real experiments.</p>
</sec>
<sec id="s3e">
<title>Amplitude increases modulate the size of the effect</title>
<p>Are modulations in the amplitude of the stimulus-specific oscillation necessary for the effects we observe in real data? They are not, but they can enhance the already existing patterns.</p>
<p>I generated various data sets, all with the same phase modulation based on additive oscillatory components. In each of them, I applied a different amount of amplitude enhancement, from no increase to a five-fold increase —which, critically, did not entail any effect on the signals’ phase. Note that an amplitude effect without a phase effect would not result in any phase locking across trials, and therefore could not lead to any decoding accuracy. Having applied decoding analysis, I looked at two characteristic features of the TGM: (i) the diagonal, and (ii) a vertical cut stemming from the time point of maximum accuracy. <bold><xref rid="fig6" ref-type="fig">Figure 6</xref></bold> shows the results. As observed, the main features are present in all runs regardless of the size of the amplitude effect, although they were more prominent for higher amplitude modulations.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6.</label>
<caption><p>Amplitude enhancement of the stimulus-relevant oscillation is not strictly necessary to produce realistic results, but it can enlarge the effects. Two features of the TGM are highlighted: the diagonal, and a vertical cut at the time point of maximum accuracy.</p></caption>
<graphic xlink:href="522583v3_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</sec>
<sec id="s4">
<title>Discussion</title>
<p>Brain’s responses to even the simplest stimuli are characteristically variable. This is not surprising, given the brain’s plasticity, and that it never stops generating ever-changing endogenous activity. It also speaks to the brain’s degeneracy (<xref ref-type="bibr" rid="c8">Edelman &amp; Gally, 2001</xref>) —i.e. the fact that there are many possible neural trajectories that can achieve a single purpose. How this variability translates into behaviour and experience is however an open question. Anyhow, it seems reasonable that, at some level, brain responses must keep some invariant aspects so that our perceptual experiences remain stable. Here, I investigated, using a novel generative model, the most stable aspects of brain responses to stimuli as seen through the lens of decoding accuracy, which is by definition based on averaging.</p>
<p>Previous work has analysed the nature of brain responses to perceptual stimulation using average evoked responses (<xref rid="c22" ref-type="bibr">Sauseng, et al., 2007</xref>), arguing either for a predominant role of additive responses (<xref rid="c23" ref-type="bibr">Shah, et al., 2004</xref>; <xref ref-type="bibr" rid="c18">Mazaheri &amp; Jensen, 2006</xref>) or phase resetting (<xref rid="c17" ref-type="bibr">Makeig, et al., 2002</xref>). These studies looked at the average response to a given stimulus, but did not investigate what aspects of the data carry information about the identity of the stimulus; this is the focus of this paper and the goal of the proposed model.</p>
<p>It is important to note that the list of effects that I have explored is non-exhaustive. For example, I have considered additive oscillatory responses in the form of sinusoidal waves. Another possibility could be to have additive oscillatory responses that are non-linear, i.e. with a tendency to spend more time in certain phases (for example, having wider peaks than throughs); in this case, even in the absence of phase locking between trials, we could potentially have a significant evoked response due to phase asymmetry (<xref rid="c20" ref-type="bibr">Nikulin, et al., 2007</xref>). For simplicity, I have considered independent sources of activity that exhibit correlations only through the induced effect. In practice, brain areas are in constant communication even in the absence of stimulation. Alternatives where sources are modelled as coupled oscillators (<xref ref-type="bibr" rid="c2">Breakspear, et al., 2010</xref>; <xref rid="c3" ref-type="bibr">Cabral, et al., 2014</xref>), or where there is correlated noise, are also possible. Also for simplicity, I have considered that every channel has only one fundamental frequency (besides the additive oscillation); in practice, multiple ongoing frequencies coexist and interact, potentially affecting the TGM if they are do not completely average out across trials. Finally, the inherent stochasticity of the stimulus-specific space of activity can take various forms; here, I have explored a probabilistic activation of the channels, but others, such as noise in the phase distribution, are also possible and can be readily be simulated using <italic>genephys</italic>.</p>
<p>Importantly, I have shown that standard decoding analysis can differentiate between these explanations only to some extent. For example, it cannot trivially disambiguate between phase-resetting and additive oscillatory components, except for the fact that phase resetting might lead to higher accuracy —but this could be balanced by manipulating the signal-to-noise ratio of the signal. In future work, alternatives to standard decoding analysis might be used to disentangle these sources of variation (<xref rid="c27" ref-type="bibr">Vidaurre, et al., 2019</xref>). In order to explore the space of configurations more effectively, an automatic exploration of the hyperparameter space using, for instance, Bayesian optimisation (<xref ref-type="bibr" rid="c16">Lorenz, et al., 2017</xref>) is an alternative for future consideration.</p>
<p>Overall, the results obtained from applying <italic>genephys</italic> suggest that the stable aspects of brain activity regarding stimulus processing are underpinned by phasic modulations of an oscillatory component coupled with a slower component in a very specific manner. The subspace of brain activity induced by the effect is high-dimensional in both the spatial domain (it must span many channels) and the frequency domain (it must involve a great diversity of frequencies and exhibit a diversity of latencies). This effect may be accompanied by an amplitude modulation. Above and beyond these average patterns, the stimulus-specific subspace of brain responses is highly stochastic at the trial level. Moving forward, the evidenced role of oscillations and slow responses in stimulus processing, together with its high dimensionality in space and frequency, may point at a relevant role for largely distributed neural ensembles besides more localised circuits.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>DV is supported by a Novo Nordisk Foundation Emerging Investigator Fellowship (NNF19OC-0054895) and an ERC Starting Grant (ERC-StG-2019-850404). This research was funded in part by the Wellcome Trust (215573/Z/19/Z). For the purpose of Open Access, the author has applied a CC BY public copyright licence to any Author Accepted Manuscript version arising from this submission.</p>
</ack>
<sec id="s5">
<title>Conflicts of interest</title>
<p>None</p>
</sec>
<sec id="s6">
<title>Code accessibility</title>
<p>The model is available as a Python package in PyPI.</p>
</sec>
<ref-list>
<title>Bibliography</title>
<ref id="c1"><mixed-citation publication-type="other"><string-name><surname>Axel</surname>, <given-names>R.</given-names></string-name>, <year>1995</year>. <article-title>The molecular logic of smell</article-title>. <source>Scientific American</source>, pp. <fpage>154</fpage>–<lpage>159</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="other"><string-name><surname>Breakspear</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Heitmann</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Daffertshofer</surname>, <given-names>A.</given-names></string-name>, <year>2010</year>. <article-title>Generative models of cortical oscillations: neurobiological implications of the Kuramoto model</article-title>. <source>Frontiers in human neuroscience</source>, p. <fpage>190</fpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="other"><string-name><surname>Cabral</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal>, <year>2014</year>. <article-title>Exploring mechanisms of spontaneous functional connectivity in MEG: How delayed network interactions lead to structured amplitude envelopes of band-pass filtered oscillations</article-title>. <source>NeuroImage</source>, pp. <fpage>423</fpage>–<lpage>435</lpage>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="other"><string-name><surname>Cichy</surname>, <given-names>R. M.</given-names></string-name>, <string-name><surname>Pantazis</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>Oliva</surname>, <given-names>A.</given-names></string-name>, <year>2016</year>. <article-title>Similarity-based fusion of MEG and fMRI reveals spatio-temporal dynamics in human cortex during visual object recognition</article-title>. <source>Cerebral Cortex</source>, pp. <fpage>3563</fpage>–<lpage>3579</lpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="other"><string-name><surname>Croner</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Purpura</surname>, <given-names>K.</given-names></string-name> &amp; <string-name><surname>Kaplan</surname>, <given-names>E.</given-names></string-name>, <year>1993</year>. <article-title>Response variability in retinal ganglion cells of primates</article-title>. <source>Proceedings of the National Academy of Sciences</source>, pp. <fpage>8128</fpage>–<lpage>8130</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="other"><string-name><surname>Dawson</surname>, <given-names>G. D.</given-names></string-name>, <year>1954</year>. <article-title>A summation technique for the detection of small evoked potentials</article-title>. <source>Electroencephalography &amp; clinical neurophysiology</source>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="book"><string-name><surname>Dowling</surname>, <given-names>J. E.</given-names></string-name>, <year>1987</year>. <source>The retina: an approachable part of the brain. s.l</source>.:<publisher-name>Harvard University Press</publisher-name>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="other"><string-name><surname>Edelman</surname>, <given-names>G.</given-names></string-name> &amp; <string-name><surname>Gally</surname>, <given-names>J.</given-names></string-name>, <year>2001</year>. <article-title>Degeneracy and complexity in biological systems</article-title>. <source>Proceedings of the National Academy of Sciences</source>, pp. <fpage>13763</fpage>–<lpage>13768</lpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="other"><string-name><surname>Freeman</surname>, <given-names>W. J.</given-names></string-name>, <year>1978</year>. <article-title>Spatial properties of an EEG event in the olfactory bulb and cortex</article-title>. <source>Electroencephalography and Clinical Neurophysiology</source>, pp. <fpage>586</fpage>–<lpage>605</lpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="book"><string-name><surname>Freeman</surname>, <given-names>W. J.</given-names></string-name>, <year>2000</year>. <source>How brains make up their minds</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Columbia University Press</publisher-name>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="other"><string-name><surname>Garrett</surname>, <given-names>D. D.</given-names></string-name> <etal>et al.</etal>, <year>2013</year>. <article-title>Moment-to-moment brain signal variability: A next frontier in human brain mapping?</article-title>. <source>Neuroscience &amp; Biobehavioral Reviews</source>, pp. <fpage>610</fpage>–<lpage>624</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="other"><string-name><surname>Grootswagers</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Wardle</surname>, <given-names>S. G.</given-names></string-name> &amp; <string-name><surname>Carl</surname>, <given-names>T. A.</given-names></string-name>, <year>2017</year>. <article-title>Decoding Dynamic Brain Patterns from Evoked Responses: A Tutorial on Multivariate Pattern Analysis Applied to Time Series Neuroimaging Data</article-title>. <source>Journal of Cognitive Neuroscience</source>, Issue <issue>29</issue>, p. <fpage>677</fpage>–<lpage>697</lpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="other"><string-name><surname>Haxby</surname>, <given-names>J. V.</given-names></string-name>, <string-name><surname>Connolly</surname>, <given-names>A. C.</given-names></string-name> &amp; <string-name><surname>Guntupalli</surname>, <given-names>S.</given-names></string-name>, <year>2014</year>. <article-title>Decoding Neural Representational Spaces Using Multivariate Pattern Analysis</article-title>. <source>Annual review of neuroscience</source>, pp. <fpage>435</fpage>–<lpage>456</lpage>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="other"><string-name><surname>King</surname>, <given-names>J.-R.</given-names></string-name> &amp; <string-name><surname>Dehaene</surname>, <given-names>S.</given-names></string-name>, <year>2014</year>. <article-title>Characterizing the dynamics of mental representations: the temporal generalization method</article-title>. <source>Trends in cognitive sciences</source>, pp. <fpage>203</fpage>–<lpage>210</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="other"><string-name><surname>Kragel</surname>, <given-names>P. A.</given-names></string-name>, <string-name><surname>Koban</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Feldman Barrett</surname>, <given-names>L.</given-names></string-name> &amp; <string-name><surname>Wager</surname>, <given-names>T. D.</given-names></string-name>, <year>2018</year>. <article-title>Representation, pattern information, and brain signatures: from neurons to neuroimaging</article-title>. <source>Neuron</source>, pp. <fpage>257</fpage>–<lpage>273</lpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="other"><string-name><surname>Lorenz</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Hampshire</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Leech</surname>, <given-names>R.</given-names></string-name>, <year>2017</year>. <article-title>Neuroadaptive Bayesian optimization and hypothesis testing</article-title>. <source>Trends in Cognitive Sciences</source>, pp. <fpage>155</fpage>–<lpage>167</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="other"><string-name><surname>Makeig</surname>, <given-names>S.</given-names></string-name> <etal>et al.</etal>, <year>2002</year>. <article-title>Dynamic Brain Sources of Visual Evoked Responses</article-title>. <source>Science</source>, pp. <fpage>690</fpage>–<lpage>694</lpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="other"><string-name><surname>Mazaheri</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Jensen</surname>, <given-names>O.</given-names></string-name>, <year>2006</year>. <article-title>Posterior α activity is not phase-reset by visual stimuli</article-title>. <source>Proceedings of the National Academy of Sciences</source>, pp. <fpage>2948</fpage>–<lpage>2952</lpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="other"><string-name><surname>McIntosh</surname>, <given-names>A. R.</given-names></string-name>, <string-name><surname>Kovacevic</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Itier</surname>, <given-names>R. J. J.</given-names></string-name>, <year>2008</year>. <article-title>Increased Brain Signal Variability Accompanies Lower Behavioral Variability in Development</article-title>. <source>PLOS Computational Biology</source>, p. <fpage>e1000106</fpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="other"><string-name><surname>Nikulin</surname>, <given-names>V.</given-names></string-name> <etal>et al.</etal>, <year>2007</year>. <article-title>A novel mechanism for evoked responses in the human brain</article-title>. <source>European Journal of Neuroscience</source>, pp. <fpage>3146</fpage>–<lpage>3154</lpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="other"><string-name><surname>Pfurtscheller</surname>, <given-names>G.</given-names></string-name> &amp; <string-name><surname>Lopes da Silva</surname>, <given-names>F.</given-names></string-name>, <year>1999</year>. <article-title>Event-related EEG/MEG synchronization and desynchronization: basic principles</article-title>. <source>Clinical Neurophysiology</source>, pp. <fpage>1842</fpage>–<lpage>1857</lpage>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="other"><string-name><surname>Sauseng</surname>, <given-names>P.</given-names></string-name> <etal>et al.</etal>, <year>2007</year>. <article-title>Are event-related potential components generated by phase resetting of brain oscillations? A critical discussion</article-title>. <source>Neuroscience</source>, pp. <fpage>1435</fpage>–<lpage>1444</lpage>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="other"><string-name><surname>Shah</surname>, <given-names>A. S.</given-names></string-name> <etal>et al.</etal>, <year>2004</year>. <article-title>Neural Dynamics and the Fundamental Mechanisms of Event-related Brain Potentials</article-title>. <source>Cerebral Cortex</source>, p. <fpage>476</fpage>–<lpage>483</lpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="other"><string-name><surname>Stein</surname>, <given-names>R. B.</given-names></string-name>, <string-name><surname>Gossen</surname>, <given-names>E. R.</given-names></string-name> &amp; Jones, K. E., <year>2005</year>. <article-title>Neuronal variability: noise or part of the signal?</article-title>. <source>Nature Reviews Neuroscience</source>, p. <fpage>389</fpage>–<lpage>397</lpage>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="book"><string-name><surname>Steven</surname>, <given-names>L. J.</given-names></string-name> &amp; <string-name><surname>Kappenman</surname>, <given-names>S. E.</given-names></string-name>, <year>2011</year>. <source>The Oxford handbook of event-related potential components. s.l</source>.:<publisher-name>Oxford university press</publisher-name>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="other"><string-name><surname>Stokes</surname>, <given-names>M. G.</given-names></string-name>, <string-name><surname>Wolff</surname>, <given-names>M. J.</given-names></string-name> &amp; <string-name><surname>Spaak</surname>, <given-names>E.</given-names></string-name>, <year>2015</year>. <article-title>Decoding Rich Spatial Information with High Temporal Resolution</article-title>. <source>Trends in Cognitive Sciences</source>, pp. <fpage>636</fpage>–<lpage>638</lpage>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="other"><string-name><surname>Vidaurre</surname>, <given-names>D.</given-names></string-name> <etal>et al.</etal>, <year>2019</year>. <article-title>Temporally unconstrained decoding reveals consistent but time-varying stages of stimulus processing</article-title>. <source>Cerebral Cortex</source>, pp. <fpage>863</fpage>–<lpage>874</lpage>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="other"><string-name><surname>Vidaurre</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Cichy</surname>, <given-names>R. M.</given-names></string-name> &amp; <string-name><surname>Woolrich</surname>, <given-names>M. W.</given-names></string-name>, <year>2021</year>. <article-title>Dissociable Components of Information Encoding in Human Perception</article-title>. <source>Cerebral Cortex</source>, pp. <fpage>5664</fpage>–<lpage>5675</lpage>.</mixed-citation></ref>
</ref-list>
<sec id="s7">
<title>Supplemental methods</title>
<sec id="s7a">
<title>The response function</title>
<p>Assuming the stimulus was presented at time point <italic>τ</italic> within a given trial, and that both <italic>t</italic> and <italic>τ</italic> are expressed in number of time points, the response function is asymmetric around <italic>t</italic><sub>max</sub>, when the function takes the value 1.0 from both sides. In the experiments above, both left and right parts are logarithmic. Mathematically,
<disp-formula id="ueqn11">
<alternatives><graphic xlink:href="522583v3_ueqn11.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where</p>
<list list-type="simple">
<list-item><label>-</label><p><italic>δ</italic><sub>1</sub> reflects the latency of the response in number of time points,</p></list-item>
<list-item><label>-</label><p><italic>δ</italic><sub>2</sub> is how many time points it takes the left logarithmic function to go from 0.0 to 1.0,</p></list-item>
<list-item><label>-</label><p><italic>δ</italic><sub>3</sub> is how many time points it takes the right logarithmic function to go from 1.0 to 0.0,</p></list-item>
<list-item><label>-</label><p><italic>t</italic><sub>max</sub> = <italic>δ</italic><sub>1</sub> + <italic>δ</italic><sub>2</sub> + <italic>τ</italic> is the time point of maximum response (i.e. the changing point between the two functions),</p></list-item>
<list-item><label>-</label><p><italic>C</italic><sub>1</sub>, <italic>C</italic><sub>2</sub>,<italic>T</italic><sub>1</sub>, <italic>T</italic><sub>2</sub> are normalisation constants chosen such that the logarithmic functions are bounded between 0.0 and 1.0, and G(<italic>t</italic><sub>max</sub>; <italic>τ</italic>) = 1.0 from both sides.</p></list-item>
<list-item><label>-</label><p><italic>ς</italic><sub>1</sub> and <italic>ς</italic><sub>2</sub> determine the shape of the logarithmic functions (here chosen to 2 and 4 respectively).</p></list-item>
</list>
<p>Note that, thanks to the normalisation constants, both the left and the right side of the response function take values between 0.0 and 1.0. There is also the possibility of using an exponential function —which is faster to decay— in either side, but I did not use it in the experiments. For example, in the left part, this would take the form:</p>
<p><inline-formula><alternatives><inline-graphic xlink:href="522583v3_inline10.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, where <italic>C</italic><sub>3</sub> and <italic>C</italic><sub>4</sub> are normalisation constants.</p>
</sec>
</sec>
<sec id="s8">
<title>Supplemental figures</title>
<fig id="figS1" position="float" fig-type="figure">
<label>Supplemental Figure 1:</label>
<caption><p>Example of real TGM, where the different characteristic features have been highlighted.</p></caption>
<graphic xlink:href="522583v3_figS1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS2" position="float" fig-type="figure">
<label>Supplemental Figure 2:</label>
<caption><p>TGMs from six real data example subjects performing a passive viewing paradigm</p></caption>
<graphic xlink:href="522583v3_figS2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS3" position="float" fig-type="figure">
<label>Supplemental Figure 3:</label>
<caption><p>Phase reset plus frequency entrainment effect. Top row, single latency of response; bottom row, diverse latencies across channels; left column, single frequency; right column; diverse frequencies across channels.</p></caption>
<graphic xlink:href="522583v3_figS3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<fn-group>
<fn id="fn1">
<label><sup>1</sup></label>
<p><ext-link ext-link-type="uri" xlink:href="https://test.pypi.org/project/genephys">https://test.pypi.org/project/genephys</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://github.com/vidaurre/genephys">https://github.com/vidaurre/genephys</ext-link></p></fn>
</fn-group>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.87729.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Luo</surname>
<given-names>Huan</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Peking University</institution>
</institution-wrap>
<city>Beijing</city>
<country>China</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study presents a <bold>valuable</bold> finding on developing a generative model of brain electrophysiological signals to explain temporal decoding matrices that have been widely used in cognitive neuroscience. The evidence supporting the claims of the authors is <bold>convincing</bold>, although adding more neurobiological interpretation of signal properties and the underlying brain mechanism would have strengthened the study. The work will be of interest to cognitive neuroscientists using electrophysiological recordings.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.87729.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>With genephys, the author provides a generative model of brain responses to stimulation. This generative model allows mimicking of specific parameters of a brain response at the sensor level, to test the impact of those parameters on critical analytic methods utilized on real M/EEG data. Specifically, they compare the decoding output for differently set parameters to the decoding pattern observed in a classical passive viewing study in terms of the resulting temporal generalization matrix (TGM). They identify that the correspondence between the mimicked and the experimental TGM depends on an oscillatory component that spans multiple channels, frequencies, and latencies of response; and an additive, slower response with a specific (cross-frequency) relation to the phase of the oscillatory, faster component.</p>
<p>A strength of the article is that it considers the complexity of neural data that contributes to the findings obtained in stimulation experiments. An additional strength is the provision of a Python package that allows scientists to explore the potential contribution of different aspects of neural signals to obtained experimental data and thereby to potentially test their theoretical assumptions critical parameters that contribute to their experimental data.</p>
<p>A weakness of the paper is that the power of the model is illustrated for only one specific set of parameters, added in a stepwise manner and the comparison to on specific empirical TGM, assumed to be prototypical; And that this comparison remains descriptive. (That is could a different selection of parameters lead to similar results and is there TGM data which matches these settings less well.) It further remained unclear to me, which implications may be drawn from the generative model, following from the capacities to mimic this specific TGM (i) for more complex cases, such as the comparison between experimental conditions, and (ii) about the complex nature of neural processes involved.</p>
<p>Towards this end, I would appreciate (i) a more profound explanation of the conclusions that can be drawn from this specific showcase, including potential limitations, as well as wider considerations of how scientists may empower the generative model to (ii) understand their experimental data better and (iii) which added value the model may have in understanding the nature of underlying brain mechanism (rather than a mere technical characterization of sensor data).</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.87729.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This paper introduces a new model that aims to explain the generators of temporal decoding matrices (TGMs) in terms of underlying signal properties. This is important because TGMs are regularly used to investigate neural mechanisms underlying cognitive processes, but their interpretation in terms of underlying signals often remains unclear. Furthermore, neural signals are often variant over different instances of stimulation despite behaviour being relatively stable. The author aims to tackle these concerns by developing a generative model of electrophysiological data and then showing how different parameterizations can explain different features of TGMs. The developed technique is able to capture empirical observations in terms of fundamental signal properties. Specifically, the model shows that complexity is necessary in terms of spatial configuration, frequencies and latencies to obtain a TGM that is comparable to empirical data.</p>
<p>The major strength of the paper is that the novel technique has the potential to further our understanding of the generators of electrophysiological signals which are an important way to understand brain function. Furthermore, the used techniques are state-of-the-art and the developed model is publicly shared in open source code.</p>
<p>On the other hand, the results of comparisons between simulations and real data are not always clear for an inexperienced reader. For example, the comparisons are qualitative rather than quantitative, making it hard to draw firm conclusions. Relatedly, it is unclear whether the chosen parameterizations are the only/best ones to generate the observed patterns or whether others are possible. In the case of the latter, it is unclear what we can actually conclude about underlying signal generators. It would have been different if the model was directly fitted to empirical data, maybe of different cognitive conditions. Finally, the neurobiological interpretation of different signal properties is not discussed. Therefore, taken together, in its currently presented form, it is unclear how this method could be used exactly to further our understanding of the brain.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.87729.1.sa3</article-id>
<title-group>
<article-title>Author Response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Vidaurre</surname>
<given-names>Diego</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9650-2229</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>I appreciate the time and effort of both Reviewers, who have raised important points that I would like to briefly discuss before I start working on a full revision of the paper.</p>
<p>Generality. First, there is the question of how much these conclusions broadly apply across experimental paradigms and subjects, which could give rise to potentially very different TGMs. As the Reviewers mention, I have focussed on one specific TGM that I assumed prototypical, and it could be that these conclusions fit other TGMs less well. Further, the model has quite a few hyperparameters so that it can flexibly accommodate a broad span of scenarios. This flexibility comes at a price, as pointed out by Reviewer 1: that “a different selection of parameters could lead to similar results”, i.e. that other configurations could fit this specific TGM just as well. This is related to the next point, so I will address them jointly.</p>
<p>Lack of quantitative evaluation, “making it hard to draw firm conclusions”. Indeed, I have not explicitly quantified the fit of the hyperparameters to this empirical TGM using a specific measure, and (related to the previous point) I have not made a systematic search through the space of model configurations based on such measure.</p>
<p>There is here a trade-off between generality and specificity. In fact, it is intentional that I did not optimise the hyperparameters to this specific TGM, and that I chose not to show a quantitative measure of fitness. This is because the TGM that I show in the paper is only meant as an example. Instead of focussing on fitting a specific TGM, I aimed at characterising some prominent general features that we often see throughout the literature, which this specific TGM shows in its own specific way. That is, if the paper was meant to focus on a specific paradigm (e.g. passive vision), then the use of a specific metric to fit the model to one or various empirical TGMs would have perhaps been more adequate, but this was not the case here. In future work, when focussing on specific paradigms, I will adapt methods of Bayesian optimisation (Lorenz et al., 2017) for this purpose, as mentioned in the Discussion. Note that doing this right is not trivial and would complicate the paper significantly; for this reason, I feel it should belong to a different piece of work.</p>
<p>I would also like to note that evaluating the different features of the data one by one (“in a stepwise manner”) was necessary for interpretation. One can loosely think of it as a sort of F-test: one is showing how important a feature is by comparing the full model vs. a nested  model that does not have that feature. While the Reviewer is right that there might be interactions between the features that we can only unveil through a joint evaluation, my approach is at least valid as a first approximation. I will discuss this limitation in an updated version of the paper in more detail.</p>
<p>In a future revision of the paper, I will argue more specifically why and how these model configurations are, in general terms, necessary to produce these main effects in the TGM, and why other alternative configurations could not easily generate them.</p>
<p>Practical guidelines for researchers. It was suggested to make it clearer how researchers could leverage this model in their own studies to understand their data better and to help relating their TGMs to specific neurobiological mechanisms.</p>
<p>In a future revision of the paper, I will introduce a new section explaining how to use genephys practically, emphasising both opportunities and current limitations.</p>
<p>Neurobiological interpretation. It was criticised that the results were a mere characterisation of sensor space data, and that these were not related clearly to any neurobiological aspect.</p>
<p>In a future revision, I will work toward relating the main findings to existing literature in order to strengthen the neurobiological interpretation of the results, and toward a better justification of how genephys can help shed light on specific brain mechanisms.</p>
<p>Above and beyond these specific points, I intend to restructure the text so that the main goals of the study become clearer. This includes clarifying in the Introduction more unambiguously what is the gap of knowledge this work is specifically tackling.</p>
<p>Again, I would like to thank the Reviewers for helping me realise the limitations of the current version of the paper.</p>
</body>
</sub-article>
</article>