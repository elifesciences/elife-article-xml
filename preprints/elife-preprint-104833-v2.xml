<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">104833</article-id>
<article-id pub-id-type="doi">10.7554/eLife.104833</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.104833.2</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.3</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories><title-group>
<article-title>Novel and optimized mouse behavior enabled by fully autonomous HABITS: Home-cage Assisted Behavioral Innovation and Testing System</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Yu</surname>
<given-names>Bowen</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Li</surname>
<given-names>Penghai</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Xu</surname>
<given-names>Haoze</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Wang</surname>
<given-names>Yueming</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Xu</surname>
<given-names>Kedi</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0005-2628-8297</contrib-id>
<name>
<surname>Hao</surname>
<given-names>Yaoyao</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a4">4</xref>
<email>yaoyaoh@zju.edu.cn</email>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00a2xv884</institution-id><institution>The State Key Lab of Brain-Machine Intelligence, Zhejiang University</institution></institution-wrap>, <city>Hangzhou</city>, <country country="CN">China</country></aff>
    <aff id="a2"><label>2</label><institution>Nanhu Brain-computer Interface Institute</institution>, <city>Hangzhou</city>, <country country="CN">China</country></aff>
<aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00a2xv884</institution-id><institution>Department of Biomedical Engineering, Zhejiang University</institution></institution-wrap>, <city>Hangzhou</city>, <country country="CN">China</country></aff>
<aff id="a4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00a2xv884</institution-id><institution>College of Computer Science and Technology, Zhejiang University</institution></institution-wrap>, <city>Hangzhou</city>, <country country="CN">China</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Flagel</surname>
<given-names>Shelly B</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Michigan</institution>
</institution-wrap>
<city>Ann Arbor</city>
<country country="US">United States</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Taffe</surname>
<given-names>Michael A</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of California, San Diego</institution>
</institution-wrap>
<city>San Diego</city>
<country country="US">United States</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-02-14">
<day>14</day>
<month>02</month>
<year>2025</year>
</pub-date>
<pub-date date-type="update" iso-8601-date="2025-08-06">
<day>06</day>
<month>08</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP104833</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-11-14">
<day>14</day>
<month>11</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-11-14">
<day>14</day>
<month>11</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.09.29.615652"/>
</event>
<event>
<event-desc>Reviewed preprint v1</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2025-02-14">
<day>14</day>
<month>02</month>
<year>2025</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.104833.1"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.104833.1.sa4">eLife Assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.104833.1.sa3">Reviewer #1 (Public review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.104833.1.sa2">Reviewer #2 (Public review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.104833.1.sa1">Reviewer #3 (Public review):</self-uri>
<self-uri content-type="author-comment" xlink:href="https://doi.org/10.7554/eLife.104833.1.sa0">Author response:</self-uri>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Yu et al</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Yu et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-104833-v2.pdf"/>
<abstract>
<title>Abstract</title><p>Mice are among the most prevalent animal models used in neuroscience, benefiting from the extensive physiological, imaging and genetic tools available to study their brain. However, the development of novel and optimized behavioral paradigms for mice has been laborious and inconsistent, impeding the investigation of complex cognitions. Here, we present a home-cage assisted mouse behavioral innovation and testing system (HABITS), enabling free-moving mice to learn challenging cognitive behaviors in their home-cage without any human involvement. Supported by the general programming framework, we have not only replicated established paradigms in current neuroscience research but also developed novel paradigms previously unexplored in mice, resulting in more than 300 mice demonstrated in various cognition functions. Most significantly, HABITS incorporates a machine-teaching algorithm, which comprehensively optimized the presentation of stimuli and modalities for trials, leading to more efficient training and higher-quality behavioral outcomes. To our knowledge, this is the first instance where mouse behavior has been systematically optimized by an algorithmic approach. Altogether, our results open a new avenue for mouse behavioral innovation and optimization, which directly facilitates investigation of neural circuits for novel cognitions with mice.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>mouse cognition</kwd>
<kwd>autonomous training</kwd>
<kwd>behavioral innovation</kwd>
<kwd>machine teaching</kwd>
<kwd>behavioral optimization</kwd>
</kwd-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Figure 2 updated for clarification; Add new figure S2H; Add new discussions; Add subtitles for supplementary videos; other minor revisions</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Complex goal-directed behaviors are the macroscopic manifestation of high-dimensional neural activity, making animal training in well-defined tasks a cornerstone of neuroscience <sup><xref ref-type="bibr" rid="c1">1</xref>–<xref ref-type="bibr" rid="c3">3</xref></sup>. Over the past decades, researchers have developed a diverse array of cognitive tasks and achieved significant insights into the underlying cognitive computations <sup><xref ref-type="bibr" rid="c4">4</xref></sup>. Mouse has been increasingly utilized as model animal for investigating neural mechanisms of decision making, due to the abundant tools available in monitoring and manipulating individual neurons in intact brain <sup><xref ref-type="bibr" rid="c5">5</xref></sup>. One notable example is the field of motor planning <sup><xref ref-type="bibr" rid="c6">6</xref></sup>, which, after introduced into mouse model <sup><xref ref-type="bibr" rid="c7">7</xref></sup>, was significantly advanced by obtaining causal results from whole brain circuits to genetics <sup><xref ref-type="bibr" rid="c8">8</xref></sup>.</p>
<p>Traditionally, training mice in cognitive tasks was inseparable from human involvement in frequent handling and modifying shaping strategies according to the performance <sup><xref ref-type="bibr" rid="c9">9</xref></sup>, thus labor-intensive and inconsistent as well as introducing unnecessary noise and stress <sup><xref ref-type="bibr" rid="c10">10</xref></sup>. Recently, many works dedicated to design standard training setups and workflows, aiming for more stable and reproducible outcomes <sup><xref ref-type="bibr" rid="c11">11</xref>–<xref ref-type="bibr" rid="c20">20</xref></sup>. For example, The International Brain Laboratory has recently showed mice can perform the task comparably across labs after a standard training within identical experimental setup <sup><xref ref-type="bibr" rid="c19">19</xref></sup>. However, human intervention still has been a significant factor, which inevitable introduced the variability. Furthermore, training efficiency was still restricted by the limited experimental time as before, which necessitates motivational techniques like water restriction. The trainings were often restricted to a specific task and have not been extensively tested in other complex paradigms because of the requirement of prolonged training duration. These limitations highlighted the challenges to broadly and swiftly study comprehensive cognitive behaviors in mouse.</p>
<p>A promising solution to this scenario is to implement fully autonomous training systems. In recent years, researchers have focused on combining home-cage environments with automated behavioral training methodologies, offering a viable avenue to realize autonomous training <sup><xref ref-type="bibr" rid="c21">21</xref>–<xref ref-type="bibr" rid="c34">34</xref></sup>. For instance, efforts have been made to incorporate voluntary head fixation within the home-cage to train mice on cognitive tasks <sup><xref ref-type="bibr" rid="c21">21</xref>,<xref ref-type="bibr" rid="c27">27</xref>,<xref ref-type="bibr" rid="c29">29</xref>,<xref ref-type="bibr" rid="c30">30</xref></sup>. At the cost of increased training difficulty, they successfully integrate large-scale whole-brain calcium imaging <sup><xref ref-type="bibr" rid="c21">21</xref>,<xref ref-type="bibr" rid="c29">29</xref>,<xref ref-type="bibr" rid="c30">30</xref></sup> and optogenetic modulations <sup><xref ref-type="bibr" rid="c27">27</xref></sup> with fully automated home-cage behavior training. Moreover, other groups have conducted mouse behavior training in group-housed home-cages and utilizes RFID technology to distinguish individual mice <sup><xref ref-type="bibr" rid="c28">28</xref>,<xref ref-type="bibr" rid="c29">29</xref>,<xref ref-type="bibr" rid="c32">32</xref>,<xref ref-type="bibr" rid="c34">34</xref></sup>. There are also studies which directly train freely moving animals in their home-cage to reduce stress and facilitate deployment <sup><xref ref-type="bibr" rid="c10">10</xref>,<xref ref-type="bibr" rid="c25">25</xref>,<xref ref-type="bibr" rid="c28">28</xref>,<xref ref-type="bibr" rid="c31">31</xref>,<xref ref-type="bibr" rid="c32">32</xref>,<xref ref-type="bibr" rid="c34">34</xref>–<xref ref-type="bibr" rid="c36">36</xref></sup>. However, many of these studies have focused on single paradigms and incorporated complex components in their systems, which hindered high-throughput deployment for high-efficiency and long-term behavioral testing and exploring.</p>
<p>The training protocols employed in existing studies, no matter in manual or autonomous training, were often artificially designed <sup><xref ref-type="bibr" rid="c19">19</xref>,<xref ref-type="bibr" rid="c27">27</xref></sup>, potentially failing to achieve optimal outcomes. For instance, a key issue in cognitive behavioral training is that mouse is likely to develop bias, i.e., obtaining reward only from one side. Various ‘anti-bias’ techniques <sup><xref ref-type="bibr" rid="c19">19</xref>,<xref ref-type="bibr" rid="c27">27</xref>,<xref ref-type="bibr" rid="c37">37</xref></sup> have been implemented to counteract the bias yet their efficacy in accelerating training or enhancing testing reliability remains unproven. From a machine learning standpoint, if we can accurately infer the animal’s internal models, it is possible to select a specific sequence of stimuli that will reduce the ‘teaching’ dimension of the animal and thus maximize the learning rate <sup><xref ref-type="bibr" rid="c38">38</xref></sup>. Recently, an adaptive optimal training policy, known as AlignMax, was developed to generate an optimal sequence of stimuli to expedite the animal’s training process in simulation experiments <sup><xref ref-type="bibr" rid="c39">39</xref></sup>. While many relative works have realized the theorical demonstration of the validity of machine teaching algorithms under specific conditions, these have been limited to teaching silicon-based learners in simulated environment <sup><xref ref-type="bibr" rid="c39">39</xref>–<xref ref-type="bibr" rid="c41">41</xref></sup>. The direct application and empirical demonstration of these algorithms in real-world scenarios, particularly in teaching animals to master complex cognitive tasks, remain unexplored. There are two fundamental barriers for testing these algorithms in real animals training: firstly, traditional session-based behavioral training results in a discontinuous training process, introducing abrupt variation of learning rate and uncontrollable noise <sup><xref ref-type="bibr" rid="c19">19</xref>,<xref ref-type="bibr" rid="c42">42</xref></sup>, which could undermine the algorithm’s capability; secondly, the high computation complexity of model fitting <sup><xref ref-type="bibr" rid="c39">39</xref>,<xref ref-type="bibr" rid="c40">40</xref></sup> poses challenges for deployment on microprocessor, thereby impeding extensive and high-throughput experiments. In the lack of human supervision, a fully autonomous behavioral training system necessitates an optimized training algorithm. Therefore, integrating fully automated training with machine teaching-based algorithms could yield mutually beneficial outcomes.</p>
<p>To address these challenges, we introduced a home-cage assisted behavioral innovation and testing system, referred as HABITS, which is a comprehensive platform featuring adaptable hardware and a universal programming framework. This system facilitates the creation of a wide array of mouse behavioral paradigms, regardless of complexity. With HABITS, we have not only replicated established paradigms commonly used in contemporary neuroscience research but have also pioneered novel paradigms that have never been explored in mice. Crucially, we have integrated a machine teaching-based optimization algorithm into HABITS, which significantly enhances the efficiency of both training and testing. Consequently, this study provides a holistic system and workflow for a variety of complex, long-term mouse behavioral experiments, which has the potential to greatly expand the behavioral reservoir for neuroscience and pathology research.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>System design of HABITS</title>
<p>The entire architecture of HABITS was comprised by two parts: a custom home-cage and behavioral components embedded in the home-cage (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>). The home-cage was made of acrylic plates with a dimension of 20×20×30 cm, which is more extensive than most of commercial counterparts for single-housed mouse. A tray was located at the bottom of the cage where <italic>ad libitum</italic> food, bedding, nesting material (cotton) and enrichment (a tube) were placed (<xref rid="fig1" ref-type="fig">Fig. 1B</xref>). Experimenters can change the bedding effortlessly just by exchanging the tray. The home-cage also included an elevated, arc-shaped weighting platform inside, providing a lose body constraint for the mouse during task performing (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>). Notably, a micro load cell was installed beneath the platform, which can readout body weight of the mouse for long-term health monitoring. The cage was compatible with the standard mouse rack and occupied as small space as standard mouse cage (<xref rid="fig1" ref-type="fig">Fig. 1C</xref>).</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Fig. 1.</label>
<caption><title>System setup for HABITS.</title><p>(<bold>A</bold>), Front (left) and side (right) view of HABITS, showing components for stimulus presenting (LEDs &amp; buzzers), rewarding (water tanks and pumps), behavioral reporting (lickports) and health monitoring (weight platform). These components are coordinated by controller unit and integrated into mouse home-cage with a tray for bedding change. (<bold>B</bold>), HABITS installed on standard mouse cage rack. (<bold>C</bold>), Mouse, living in home-cage with food, bedding, nesting material (cotton) and enrichment (tube), is performing task on the weight platform. (<bold>D</bold>), System architecture for high-throughput behavioral training, showing different tasks are running in parallel groups of HABITS, which further wirelessly connect to one single PC through Wi-Fi to stream real-time data to the graphic user interface (GUI).</p></caption>
<graphic xlink:href="615652v3_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To perform behavioral training and testing in HABITS, we constructed a group of training-related components embedded in the front panel of the home-cage (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>). Firstly, three stimulus modules (LEDs and buzzers) for light and sound presenting were protruded from front panel and placed in the left, right and top position around the weighting platform, enabling generation of visual and auditory stimulus modalities in three different spatial locations. The mouse reported the decisions about the stimuli by licking either left, right or middle lickports installed in the front of the weighting platform. Finally, peristaltic pumps draw water from water tanks into lickports, serving as the reward for the task, which was the sole water source for the mouse throughout the period living in the home-cage. In the most common scenario, mouse living in home-cage stepped on the weighting platform and triggered trials by licking on the lickports to obtain water (<xref rid="fig1" ref-type="fig">Fig. 1B</xref>, Movie S1).</p>
    <p>To endow autonomy to HABITS, a microcontroller was used to interface with all training-related components and coordinate the training procedure <xref ref-type="fig" rid="figs1">(Fig. S1A)</xref>. We implemented a microcontroller-based general programming framework to run finite state machine with millisecond-level precision (see Methods). By using the APIs provided by the framework, we can easily construct arbitrarily complex behavioral paradigms and deploy them into HABITS <xref ref-type="fig" rid="figs1">(Fig. S1B)</xref>. Meanwhile, the paradigms were usually divided into small steps from easy to hard and advanced according to the performance of the mouse. Another important role of the microcontroller was to connect the HABITS to PC wirelessly and stream real-time behavioral data via a Wi-Fi module. A graphic user interface (GUI), designed to remotely monitor each individual mouse’s performance, displayed history performance, real-time trial outcomes, body weights, etc. <xref ref-type="fig" rid="figs1">(Fig. S1C)</xref>. Meanwhile, the program running in the microcontroller could be updated remotely by the GUI when changing mouse and/or task. As a backup, information of training setup, task parameters and all behavioral data were also stored in a SD card for offline analysis.</p>
    <p>To increase the throughput of behavioral testing, we built more than a hundred of independent HABITS and installed them on standard mouse racks <xref ref-type="fig" rid="figs1">(Fig. S1D)</xref>. The total material cost for each HABITS was less than $100 <xref ref-type="fig" rid="tbls1">(Table SI)</xref>. All HABITS, operating different behavioral tasks across different cohorts of mice, were organized into groups according to the tasks, and wireless connected to a single PC (<xref rid="fig1" ref-type="fig">Fig. 1D</xref>). The states of each individual HABITS can be accessed and controlled remotely by monitoring the corresponded panels in GUI, thereby significantly improving the experimental efficiency. We developed a workflow to run behavioral training and testing experiment in HABITS <xref ref-type="fig" rid="figs1">(Fig. S1E)</xref>. Firstly, initiate HABITS system by preparing the home-cage, deploying training protocols and weighting the naive mouse that did not need to undergo any water restriction. Then, mouse interacted with fully autonomous HABITS at their own pace without any human intervention. In this study, mice housed in HABITS went through 24/7 behavioral training and testing for up to 3 months (Movie S2), though longer duration was supported. Finally, data were harvested from SD card and offline analyzed.</p>
<p>Therefore, HABITS permitted high-throughput, parallel behavioral training and testing in a fully autonomous way, which, contrasting with manual training, allows for possible behavioral innovation and underlining neural mechanism investigation.</p>
</sec>
<sec id="s2b">
<title>HABITS performance probed by multimodal d2AFC task</title>
<p>We next deployed a well-established mouse behavioral paradigm, delayed two-alternative forced choice (d2AFC), which was used to study motor planning in mouse <sup><xref ref-type="bibr" rid="c7">7</xref>,<xref ref-type="bibr" rid="c43">43</xref></sup>, in HABITS to demonstrate the performance of our system (<xref rid="fig2" ref-type="fig">Fig. 2</xref>).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Fig. 2.</label>
<caption><title>HABITS performance in d2AFC task.</title><p><bold>(A)</bold>, Task structure for d2AFC based on sound frequency. <bold>(B)</bold>, Example licks for correct (blue), error (red) and earlylick (gray) trials. Choice is the first lick after response onset. <bold>(C)</bold>, Correct rate (black line) and earlylick rate (grey line) of an example mouse during training in HABITS for the first 13 days. Shaded blocks indicate trials occurred in dark cycle. Trials with earlylick inhabitation only occur after blue vertical line. Red vertical dash lines represent delay duration advancement from 0.2 s to 1.2 s. <bold>(D)</bold>, Averaged correct rate (left) and earlylick rate (right) for all mice trained in d2AFC. Criterion level (75%) and chance level (50%) are labeled as gray and red dash lines, respectively. <bold>(E)</bold>, Same as (D) but for manual training (1∼3 hour/day in home-cage). <bold>(F)</bold>, Averaged correct rate (left), earlylick rate (middle) and no response rate (right) of expert mice trained with the two protocols. <bold>(G)</bold>, Averaged number of trials (left) and days (right) to reach the criterion performance for the two training protocols. Circles, individual mice. Errorbar, mean and 95% CI across mice. <bold>(H)</bold>, Left, number of trials performed per day throughout the training schedule for three different protocols. Error bar indicates the mean and 95% confidence interval (CI) across mice. Middle, volume of water harvested per day. Right, Relative body weights of mice in day 0, 8, 16, 26. Bold line and shades indicate mean and 95% CI across mice. <bold>(I)</bold>, Behavioral performance of all mice training in d2AFC task based on sound orientation (left), light orientation (middle), and light color (right). <bold>(J)</bold>, Box plot of average number of trials (left) and days (right) to reach the criterion performance for d2AFC tasks with different sensory modalities. <bold>(K)</bold>, Left, percentage of trials performed as a function of time in a day for the four modalities trained autonomously (thick black shows the average). Shaded area indicates the dark cycle. Top right, averaged correct rate of grouped mice in dark cycle versus light cycle. Error bars show 95% CI across mice. Bottom right, box plot of the averaged proportion of trials performed in dark cycle for the four modalities. Data collected from expert mice. <bold>(L)</bold>, Left, percentage of trials in blocks with varying number of consecutive trails for automated training in home-cage. Right, correct rate and earlylick rate as functions of trial block size. Grey dash line, the criterion performance; Red dash line, chance performance level. Data collected from trials of expert mice. For significance levels not mentioned in all figures, n.s., not significant, p&gt; 0.05; *, p&lt;0.05; **, p&lt;0.01 (two-sided Wilcoxon rank-sum tests).</p></caption>
<graphic xlink:href="615652v3_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
    <p>Mice, living in HABITS all the time, licked any of the lickports to trigger a trial block at any time. In d2AFC task with sound frequency modality (<xref rid="fig2" ref-type="fig">Fig. 2A</xref>), mice needed to discriminate two tone frequency presented at the beginning of the trial for a fixed duration (sample epoch, 1.2 sec) and responded the choice by licking left (low tone) or right (high tone) lickports following a brief ‘go’ cue after a fixed delay duration (1.2 sec). Licks during delay epoch were prohibited and unwished lick (early licks) will pause the trial for a while. Correct choices were rewarded, while incorrect choices resulted in noise and timeout. If mice did not lick any of the lickports after ‘go’ cue for a fixed period (i.e., no-response trial), the trial block was terminated. The next trial block was immediately entering the state of to be triggered. Mice can only learn the stimulus-action contingency by trial-and-error. To promote learning, we designed an algorithm comprised of many subprotocols to shape the behavior step by step <xref ref-type="fig" rid="figs2">(Fig. S2A)</xref>. <xref rid="fig2" ref-type="fig">Fig. 2B</xref> illustrated example licks during correct, error and early lick trials for the task. As training progressed, the correct rate increased and earlylick rate declined gradually for the example mouse within the first 2-week (<xref rid="fig2" ref-type="fig">Fig. 2C</xref>). All the 10 mice enrolled in this task effectively learned the task and suppressed licking during the delay period within 15 days (<xref rid="fig2" ref-type="fig">Fig. 2D</xref>), achieving an average of 980 ± 25 (mean ± SEM) trials per day.</p>
    <p>We also tested another training scheme, i.e., limited duration per day in HABITS, to simulate the situation of manual training with human supervision. These mice were water restricted and manually transferred from traditional home-cage to HABITS daily for 1-3 hours training session. The duration of sessions was determined by the speed of harvesting water as we controlled the daily available volumes of water to approximately 1 ml <sup><xref ref-type="bibr" rid="c9">9</xref></sup>. All the 6 mice learned the task as the autonomous counterpart (<xref rid="fig2" ref-type="fig">Fig. 2E</xref>) with similar final correct and earlylick rate (except that the no-response rate was significantly lower for manual training) (<xref rid="fig2" ref-type="fig">Fig. 2F</xref>). Logistic regression of the mice’s choice revealed similar behavioral strategies were utilized throughout the training for both group (<xref ref-type="fig" rid="figs2">Fig. S2B-D</xref>). Autonomous training needed significantly more trials than manual training (10,164 ± 1,062 vs. 6,845 ± 782) to reach the criterion performance, however, the number of days was slightly less due to the high trial number per day (<xref rid="fig2" ref-type="fig">Fig. 2G</xref>). As shown in <xref rid="fig2" ref-type="fig">Fig. 2H</xref>, autonomous training yielded significantly higher number of trial/day (980 ± 25 vs. 611 ± 26, <xref rid="fig2" ref-type="fig">Fig. 2H</xref> left) and more volume of water consumption/day (1.65 ± 0.06 vs. 0.97 ± 0.03 ml, <xref rid="fig2" ref-type="fig">Fig. 2H</xref> middle), which resulted in monotonic increase of body weight that was even comparable to the free water group (<xref rid="fig2" ref-type="fig">Fig.2H</xref> right). In contrast, the body weight in manual training group experienced a sharp drop at the beginning of training and was constantly lower than autonomous group throughout the training stage (<xref rid="fig2" ref-type="fig">Fig. 2H right</xref>). As the training advanced, the number of trials triggered by mice per day decreased gradually for both groups of mice, but the water consumption per day kept relatively stable. At the end of manual training, we transferred all mice to autonomous testing, and found that the number of trial and consumption water per day dramatically increased to the level of the autonomous training, suggesting mice actually needed more water throughout the day (<xref ref-type="fig" rid="figs2">Fig. S2E</xref>). These results indicated that autonomous training achieved similar training performance as manual training and maintained a more health state of mice.</p>
<p>Three more cohorts of mice were used in d2AFC tasks with different modalities, which included sound orientation (left vs. right sound), light orientation (left vs. right light) and light color (red vs. blue). Using the same training protocol as in the sound frequency modality, we trained 10, 11 and 8 mice on these tasks, respectively (<xref rid="fig2" ref-type="fig">Fig. 2I</xref>). Mice required different amounts of trials or days to discriminate these modalities, with light color discrimination being the most challenging (an average of 82,932 ± 6,817 trials), consistent with the limited sensitivity to light wavelength of mice (<xref rid="fig2" ref-type="fig">Fig. 2J</xref>). We also tried other modalities, like blue vs. green and flashed blue vs. green, but all failed (see <xref rid="tbl1" ref-type="table">Table I</xref>).</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><title>All tasks training in HABITS.</title></caption>
<graphic xlink:href="615652v3_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
<graphic xlink:href="615652v3_tbl1a.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
    <p>The learning rate between sound and light orientation discrimination tasks was similar (p = 0.439, two-sided Wilcoxon rank-sum test), but the variation for light orientation was large, indicating possible individual differences (<xref rid="fig2" ref-type="fig">Fig. 2J</xref>). All modalities maintained good health state indicated by the body weight for up to 2 months (<xref ref-type="fig" rid="figs2">Fig. S2F</xref>). Another two types of 2AFC, reaction time <sup><xref ref-type="bibr" rid="c44">44</xref></sup> (RT-2AFC, <xref ref-type="fig" rid="figs3">Fig. S3</xref>) and random foraging (<xref ref-type="fig" rid="figs4">Fig. S4</xref>) task, were also successfully tested in HABITS. Notably, the dynamic foraging task <sup><xref ref-type="bibr" rid="c45">45</xref>,<xref ref-type="bibr" rid="c46">46</xref></sup>, which heavily relies on historical information, was first demonstrated in a fully autonomous training scheme for freely moving mice with similar block size and performance.</p>
<p>Two important behavioral characteristics were revealed across all the modalities in 2AFC task. Firstly, as our high-throughput behavioral training platform operated on a 12:12 light-dark cycle, the long-term circadian rhythm of mice can be evaluated based on the number of triggered trials and performance during both cycles. We found all mice exhibited clear nocturnal behavior with peaks in trial proportion at the beginning and end of the dark period (<xref rid="fig2" ref-type="fig">Fig. 2K</xref>), which was consistent with previous studies <sup><xref ref-type="bibr" rid="c25">25</xref>,<xref ref-type="bibr" rid="c27">27</xref></sup>. The light color modality exhibited slight lower percentage of trials during dark (57.89% ± 3.18% vs. above 66% for other modalities) (<xref rid="fig2" ref-type="fig">Fig. 2K</xref>), possibly the light stimulus during trials affected the circadian rhythms of the mice. It was also observed that all mice except the light color modality showed no significant differences in correct rate between light and dark cycle after they learned the task (<xref rid="fig2" ref-type="fig">Fig. 2K</xref>). The higher performance in dark environment for light color modality implied that light stimulus presented in dark environment was with higher contrast and thus better discernibility. Secondly, as we organized the trials into blocks, the training temporal dynamic at trial-level could be examined. We found more than two-third of the trials was done in &gt;5-trial blocks (<xref rid="fig2" ref-type="fig">Fig. 2L left</xref>) which resulted in more than 55% of the trials were with inter-trial-interval less than 2 seconds (Fig. S2H). The averaged block duration was 27.64 ± 1.73 sec and mice triggered another block of trials within 60 sec in more than 60% of cases. Meanwhile, we also found that the averaged correct rate increased and the earlylick rate decreased as the length of block increased (<xref rid="fig2" ref-type="fig">Fig. 2L right</xref>), which suggested that mice were more engaged in the task during longer blocks.</p>
<p>These results showed that mice can learn and perform cognitive tasks in HABITS with various modalities in a fully autonomous way. During the training process, mice maintained good health condition, although without any human intervention. Due to the high-efficiency training with less labor and time, it gave us an opportunity to explore and study more widespread cognitive behavioral tasks in mice.</p>
</sec>
<sec id="s2c">
<title>Various cognitive tasks demonstrated in HABITS</title>
<p>We next tested several representative tasks that were commonly used in the field of cognitive neuroscience to demonstrate the universality of HABITS. It is worth noting that many new features of the behavior could be explored due to the autonomy and advantages of HABITS, in terms of either quantity or quality (<xref rid="fig3" ref-type="fig">Fig. 3</xref>).</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Fig. 3.</label>
<caption><title>Representative cognitive task performed in HABITS.</title><p>(<bold>A</bold>), Contingency reversal task. (<italic>A1</italic>), Task structure. (<italic>A2</italic>), Correct rate of example mice with different learning rates. Grey vertical lines indicate contingency reversal. (<italic>A3</italic>), Relative number of trials to reach the criterion as a function of reverse times. Grey lines, individual mice. Black lines, linear fit. (<italic>A4</italic>), Number of trials in the first reversal learning versus the average number of trials of the rest of contingency reversal learning for each mouse (each dot). Black line, linear regression. Red dash line, diagonal line. (<bold>B</bold>), Working memory task with sound frequency modality. (<italic>B1</italic>), Task structure. (<italic>B2</italic>), Stimulus generation matrix (SGM) for left (orange) and right (green) trials. (<italic>B3</italic>), left, averaged correct rate for each stimulus combination tested. Right, averaged correct rate for each (S1+S2) stimulus combination across mice. Black line and shade, linear regression and 95% CI. (<italic>B4</italic>), Averaged psychometric curves, i.e., percentage of right choice as a function of frequency difference between sample1 and sample2. (<italic>B5</italic>), Averaged correct rate as a function of delay duration. <bold>(C)</bold>, Evidence accumulation with spatial cue task. (<italic>C1</italic>), Task structure. (<italic>C2</italic>), Averaged psychometric curves, i.e., performance as a function of the difference between right and left clicks rates. (<italic>C3</italic>), Averaged correct rate across all mice as a function of sample duration for different Poisson rates (different colors). Error bar represents 95% CI. <bold>(D)</bold>, Multimodal integration task. (<italic>D1</italic>), Task structure. (<italic>D2</italic>), Averaged correct rate across all mice as a function of sample duration for different stimulus modalities (different colors). (<italic>D3</italic>), Averaged event rates during sample period for left (red) and right (blue) choice trials. (<italic>D4</italic>), Averaged weights (black line) of logistic regression fitting to the choice of trials across expert mice tested in &gt; 1000 trials (N = 11 mice) from the first bin (40ms) to the last bin (1000ms) of the sample period. Gray dash line represents null hypothesis. Grey dots indicate significance, p&lt;0.05, two-sided <italic>t</italic>-tests. (<italic>D5</italic>), Psychometric curve for trials with multimodal stimulus. <bold>(E),</bold> Confidence probing task. (<italic>E1</italic>), Task structure. (<italic>E2</italic>), Psychometric curve, i.e., right choice rate as a function of relative contrast (log scaled relative frequency). (<italic>E3</italic>), Histogram of time invested (TI) for both correct and error trials. (<italic>E4</italic>), Averaged correct rate across all mice as a function of TI. (<italic>E5</italic>), Averaged TI as a function of absolute relative contrast for both correct and error trials. Cycles, individual mice; *, p&lt;0.05; **, p&lt;0.01, two-sided Wilcoxon rank-sum tests.</p></caption>
<graphic xlink:href="615652v3_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
    <p>Contingency reversal task was cognition-demanding task and previously used to investigate cognitive flexibility <sup><xref ref-type="bibr" rid="c47">47</xref></sup> (<xref rid="fig3" ref-type="fig">Fig. 3A</xref>). In the task, the contingency for reward switched without any cues once mice hit the criteria performance (<xref rid="fig3" ref-type="fig">Fig. 3A1</xref>). Mice can dynamically reverse their stimulus-action contingency, though with different learning rate across individuals (<xref rid="fig3" ref-type="fig">Fig. 3A2</xref>). Given the advantages of long-term autonomous training in HABITS, all mice undergone contingency reversal for an average of 52.25±16.39 times and one mouse achieved up to 125 times in 113 days. Most of mice (6/8) gradually decreased the number of trials to reach criterion across multiply contingency reversal representing an effect of learning to learn <sup><xref ref-type="bibr" rid="c45">45</xref>,<xref ref-type="bibr" rid="c48">48</xref></sup> (<xref rid="fig3" ref-type="fig">Fig. 3A3</xref>). Meanwhile, the average number of trials to reach criterion during the reversal was highly correlated with the trial number in the first reversal learning which represented the initial cognitive ability or the sensory sensitivity of individual mice (<xref rid="fig3" ref-type="fig">Fig. 3A4</xref>).</p>
    <p>Working memory was another important cognition that were vastly investigated using rodent model with auditory and somatosensory modalities <sup><xref ref-type="bibr" rid="c48">48</xref>,<xref ref-type="bibr" rid="c49">49</xref></sup>. Here we utilized a novel modality, regular sound clicks, to implement a self-initiated working memory task, which required mice to compare two click rates separated by a random delay period (<xref rid="fig3" ref-type="fig">Fig. 3B1</xref>). We initially validated that mice did employ a comparison strategy in a 3×3 stimulus generation matrix (SGM), instead just taking the first cue as a context <xref ref-type="fig" rid="figs5">(Fig. S5A)</xref>. Subsequently, we expanded the paradigm’s perception dynamics to 5×5, and reduced the relative perceptual contrast between two neighboring stimuli to one octave (<xref rid="fig3" ref-type="fig">Fig. 3B2</xref>). HABITS enabled investigation of detailed behavioral parameters swiftly. We noticed that the discrimination ability for mice was significantly better in higher frequency range (<xref rid="fig3" ref-type="fig">Fig. 3B3</xref>), which may be caused by the different sensitivity of mice across the spectrum of regular click rate. During testing stage, we varied the contrast of the preceding stimulus while maintaining the succeeding one; the psychometric curves affirmed mice’s decision-making based on perceptual comparison of two stimuli and validated their perceptual and memory capacities (<xref rid="fig3" ref-type="fig">Fig. 3B4</xref>). Meanwhile, mice could maintain stable working memory during up to 1.8 sec delay, demonstrating mice can perform this task robustly (<xref rid="fig3" ref-type="fig">Fig. 3B5</xref>).</p>
    <p>Evidence accumulation introduced more dynamics to the decision-making within individual trials and were widely utilized <sup><xref ref-type="bibr" rid="c50">50</xref>–<xref ref-type="bibr" rid="c52">52</xref></sup>. In the task implemented in HABITS, mice needed to compare the rate of sound clicks randomly appeared over two sides during sample epoch and made decision following a ‘go’ cue after a brief delay (<xref rid="fig3" ref-type="fig">Fig. 3C1</xref>). We successfully trained 8/10 mice to complete this task as revealed by the psychometric curves (<xref rid="fig3" ref-type="fig">Fig. 3C2</xref>). After mice learned the task, we systematically tested the effect of evidence accumulation versus the task performance. All mice exhibited consistent behavioral patterns which was correlated with the evidence of stimulus, i.e., longer sample period and/or higher stimulus contrast led to higher performance (<xref rid="fig3" ref-type="fig">Fig. 3C3</xref>). It showed an evident positive correlation between evidence accumulation and task performance.</p>
    <p>Multimodal integration <sup><xref ref-type="bibr" rid="c53">53</xref>–<xref ref-type="bibr" rid="c55">55</xref></sup> was also tested in HABITS with sound clicks and light flashes as dual-modality events in the evidence accumulation framework. Mice were required to differentiate whether event rates were larger or smaller than 12 event/sec (<xref rid="fig3" ref-type="fig">Fig. 3D1</xref>). We successfully trained 13/15 mice in this paradigm with multimodal or sound clicks stimulus (<xref rid="fig3" ref-type="fig">Fig. 3D2</xref>), and only 3 mice achieved performance criteria in trials with light flashes stimulus. Since the events were presented non-uniformly within each trial, we wondered the dynamics of decision-making process along the trial. Firstly, we divided all trials with multimodal stimulus into two groups according to the choice of expert mice. The uniform distribution of events within a trial indicated that mice considered the whole sample period to make decision (<xref rid="fig3" ref-type="fig">Fig. 3D3</xref>). Secondly, we used a logistic regression model to illustrate the mice’s dependency on perceptual decisions throughout the entire sample period. We found that mice indeed tended to favor earlier stimuli (i.e., higher weights) in making their final choices (<xref rid="fig3" ref-type="fig">Fig. 3D4</xref>), consistent with previous research findings <sup><xref ref-type="bibr" rid="c54">54</xref></sup>. Lastly, we further tested modulated unimodal stimuli with different sample period in testing stage, in which accuracy correlated positively with sample period and conditioned test for different combination of modalities demonstrated evidence accumulation and multimodal integration effect, respectively. (<xref rid="fig3" ref-type="fig">Fig. 3D5</xref>).</p>
    <p>Confidence was another important cognition along with the process of decision-making, which was investigated in rat <sup><xref ref-type="bibr" rid="c56">56</xref>,<xref ref-type="bibr" rid="c57">57</xref></sup> and more recently in mice <sup><xref ref-type="bibr" rid="c58">58</xref></sup> model previously. We introduced confidence-probing task in HABITS (<xref rid="fig3" ref-type="fig">Fig. 3E</xref>), in which mice needed to lick twice the correct side for acquiring a reward; the two licks were separated by a random delay during which licking at other lickports prematurely ended the trial (<xref rid="fig3" ref-type="fig">Fig. 3E1</xref>). This unique design connects mice’s confidence about the choice, which was hidden, with the time investment (TI) of mice between two licks, which was an explicit and quantitative metric. We successfully trained 5/6 mice (<xref rid="fig3" ref-type="fig">Fig. 3E2</xref>), and most importantly, there was a noticeable difference of TI in correct versus incorrect trials (<xref rid="fig3" ref-type="fig">Fig. 3E3</xref>). In detail, trials with longer TIs tended to have higher accuracies (<xref rid="fig3" ref-type="fig">Fig. 3E4</xref>). Furthermore, the TI was also modulated by the contrasts of stimuli; as contrast decreased, mice exhibited reduced confidence about their choices, manifesting as decreased willingness to wait in correct trials, and conversely in error trials (<xref rid="fig3" ref-type="fig">Fig. 3E5</xref>).</p>
<p>In summary, mice could undergo stable and effective long-term training in HABITS with various cognitive task commonly used in state-of-the-art neuroscience. These tasks running in HABITS were demonstrated to exhibit similar behavioral characteristics to previous studies. In addition, some new aspects of the behavior could be systematically tested in HABITS due to its key advantage of autonomy. This high level of versatility, combined with the ability to support arbitrary paradigm designs, suggests that more specialized behavioral paradigms could potentially benefit from HABITS to enhance experimental novelty.</p>
</sec>
<sec id="s2d">
<title>Innovating mouse behaviors in HABITS</title>
<p>One of the main goals of HABITS was to expand mouse behavioral reservoir by developing complex and innovative paradigms that had previously proven challenging or even impossible for mice. These paradigms imposed higher cognitive abilities demands, which required extensively long period to test in mouse model. HABITS enabled unsupervised, efficient and standardized training of these challenging paradigms at scale, and thus was suitable for behavioral innovations.</p>
    <p>Firstly, leveraging the autonomy of HABITS, we tested mouse’s ability to successively learn up to 5 tasks one after another without any cues (<xref rid="fig4" ref-type="fig">Fig. 4A</xref>). These tasks included 2AFC based on sound frequency, sound frequency reversal, sound orientation (pro), sound orientation (anti), and light orientation (<xref rid="fig4" ref-type="fig">Fig. 4A1</xref>). Firstly, the results showed that mice could quickly switch from one task to another and the learning rates across these sub-tasks roughly followed the learning difficulty of modalities (<xref rid="fig4" ref-type="fig">Fig. 4A2</xref>). Specially, reversal of sound frequency was cognitively different from reversal of sound orientation (i.e., from pro to anti) which resulted in significant longer learning duration (<xref rid="fig4" ref-type="fig">Fig. 4A2</xref>). Secondly, mice dealt with new tasks with higher reaction time and gradually decreased as training progressed (<xref rid="fig4" ref-type="fig">Fig. 4A3</xref>). It implied a uniform strategy mice applied: mice chose to respond more slowly in order to learn quickly <sup><xref ref-type="bibr" rid="c59">59</xref></sup>. Lastly, mice exhibited large bias at the beginning of each task in all task including task without reversals (<xref rid="fig4" ref-type="fig">Fig. 4A4</xref>). This means that mice acquired reward only from one lickport in the early training and switched strategy to follow current stimulus gradually, which implied a changing strategy from exploration to exploitation.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Fig. 4.</label>
<caption><title>Challenging mouse tasks innovated in HABITS.</title><p>(<bold>A</bold>), Continuous learning task. (<italic>A1</italic>), Task structure showing mice learning five subtasks one by one. (<italic>A2</italic>), Left, averaged correct rate of all mice performing the five tasks (different colors) continually. All task schedules are normalized to their maximum number of trials and divided to 10 stages equally. Right, box plot of number of trials to criteria for each task. (<italic>A3</italic>), Left, averaged reaction time of all mice performing the five tasks continually. Right, averaged median reaction time across the five tasks during early (perf. &lt; 0.55), middle (perf. &lt; 0.75) and trained (perf. &gt; 0.75) stage. Error bar indicates 95% CI. (<italic>A4</italic>), Same as (A3) but for absolute performance bias. n.s., p&gt;0.05; **, p&lt;0.01, two-sided Wilcoxon signed-rank tests. <bold>(B),</bold> Double delayed match sample task (dDMS) with sound frequency modality. (<italic>B1</italic>), Task structure. (<italic>B2</italic>), Averaged correct rate across all mice during training (left) and averaged number of days to reach the criterion (right). (<italic>B3</italic>), Averaged earlylick rate across all mice. (<italic>B4</italic>), Averaged correct rate (black) and earlylick rate (gray) for all combination of sample and test stimulus. (<italic>B5</italic>), Heatmap of error rate (left) and earlylick rate (right) varies with different combination of delay1 and delay2 durations. <bold>(C),</bold> Delayed 3 alternative forced choice (d3AFC). (<italic>C1</italic>), Task structure. (<italic>C2</italic>), Averaged correct rate across all mice during training (left, colors indicate trial types) and averaged number of days to reach the criterion performance (right). (<italic>C3</italic>), Averaged correct rate (colors indicate trial types) and earlylick rate (gray) for different trial types. (<italic>C4</italic>), Averaged error rate of choices conditioning trial types. In each subplot, the position of bars corresponds to different choices. ****, p&lt;0.0001, n.s., p&gt;0.05, two-sided t-tests. (<italic>C5</italic>), Averaged choice rates for the three lickports (colors) as a function of sample frequency. Data collected from trained mice. <bold>(D),</bold> Context-dependent attention task. (<italic>D1</italic>), Task structure. (<italic>D2</italic>), Averaged correct rate across all mice during training (left, data only from trials with multimodal w/ conflict) and averaged number of days to reach the criterion (right). (<italic>D3</italic>), Correct rate (left) and reaction time (right) conditioning modalities. (<italic>D4</italic>), Averaged psychometric curve and partitioned linear regression for the multimodal with and without conflict conditions, respectively. (<italic>D5</italic>), Performance bias to sound orientation modal as a function of pre-cue contrast, for the two multimodal conditions. (<italic>D6</italic>), Averaged correct rate as a function of delay duration.</p></caption>
<graphic xlink:href="615652v3_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
    <p>Delayed match sample task was quite challenging for mice, and only olfactory and tactile modalities were implemented previously <sup><xref ref-type="bibr" rid="c60">60</xref>–<xref ref-type="bibr" rid="c62">62</xref></sup>. Recently, auditory modality was introduced but only in go/no-go paradigm <sup><xref ref-type="bibr" rid="c63">63</xref></sup>. We next constructed a novel double delayed match sample task (dDMS) task (<xref rid="fig4" ref-type="fig">Fig. 4B</xref>), which required mice to keep working memory of first sound frequency (low or high) during the first delay, match to the second sound based on XOR rules, make a motor planning during the second delay, and finally make a 2AFC choice (<xref rid="fig4" ref-type="fig">Fig. 4B1</xref>). All the 10 mice achieved the performance criteria during the automated training process, though, an averaged 64.45 ± 7.88 days was required, which was equivalent to more than 120,000 trials (<xref rid="fig4" ref-type="fig">Fig. 4B2-3</xref>). After training, the four trial types (i.e., four combinations of frequencies) achieved equally well performance (<xref rid="fig4" ref-type="fig">Fig. 4B4</xref>). During testing stage, we systematically randomized the duration of the two delays (ranging from 1 to 3 sec), and revealed increased error rates and earlylick rates as the delay increased (<xref rid="fig4" ref-type="fig">Fig. 4B5</xref>). Challenging tasks which demanded months of training were well suitable for HABITS, otherwise, difficult or even impossible for manual training.</p>
    <p>Subsequently, we attempted to expand the choice repertoire of d2AFC into 3-alternative forced choice (d3AFC), utilizing the three lickports installed in HABITS (<xref rid="fig4" ref-type="fig">Fig. 4C</xref>). Previous studies have implemented multiple choice tasks, but only based on spatial modalities <sup><xref ref-type="bibr" rid="c64">64</xref>–<xref ref-type="bibr" rid="c66">66</xref></sup>. In our system, mice learned to discriminate low (8 kHz), medium (16 kHz) and high (32 kHz) sound frequencies and lick respectively left, middle and right lickport to get reward (<xref rid="fig4" ref-type="fig">Fig. 4C1</xref>). Mice needed to construct two psychological thresholds to conduct correct choices. We successfully trained all the 14 mice to perform the tasks in 13.85 ± 1.05 days, with similar performance among the left, middle and right trial types (<xref rid="fig4" ref-type="fig">Fig. 4C2</xref>). The final correct rate and early lick rate made no differences for the three trial types (<xref rid="fig4" ref-type="fig">Fig. 4C3</xref>). Interestingly, mice made error choices more in the most proximity lickport; for the middle trials, mice made error choice equally in the left and right side (<xref rid="fig4" ref-type="fig">Fig. 4C4</xref>). In addition, we tested the whole spectrum of sound frequencies between 8 to 32 kHz, and found that mice presented two evident psychological thresholds to deal with this three-choice task (<xref rid="fig4" ref-type="fig">Fig. 4C5</xref>). Finally, we also implemented sound orientation based d3AFC in another separated group of mice, which actually required longer training duration (45.16±11.46 days) (<xref ref-type="fig" rid="figs5">Fig. S5B</xref>). The d3AFC was also tested for reversal contingency paradigm and an accelerated learning was revealed (<xref ref-type="fig" rid="figs5">Fig. S5C</xref>), which potentially provides new insight into the cognitive flexibility <sup><xref ref-type="bibr" rid="c66">66</xref></sup>.</p>
    <p>Finally, we introduced one of the most challenging cognitive tasks in mouse model, delayed context-dependent attention task, in HABITS (<xref rid="fig4" ref-type="fig">Fig. 4D</xref>). This task was previously implemented by light and sound orientation modalities <sup><xref ref-type="bibr" rid="c67">67</xref>,<xref ref-type="bibr" rid="c68">68</xref></sup>, however, due to the difficulty, it was not well repeated broadly. In HABITS, we tailored this task into a sound-only based but multimodal decision-making task (<xref rid="fig4" ref-type="fig">Fig. 4D1</xref>). We constructed this task using three auditory modalities: regular clicks (16 vs. 64 clicks/sec) as context, sound frequency (3k <italic>vs.</italic> 12 kHz) and sound orientation (left vs. right) as the two stimulus modalities. Mice needed to pay attention to one of the modalities, which presented simultaneous during sample epoch, according to the context cue indicated by the clicks (low click rate to sound frequency and high rate to sound orientation), and make a 2AFC decision accordingly. We successfully trained all the 6 mice enrolled in this task, with an average of 48.09 ± 7.54 days (<xref rid="fig4" ref-type="fig">Fig. 4D2</xref>). To validate the paradigm’s stability and effectiveness, the direction of stimulus features was presented randomly and independently during the final testing stage.</p>
    <p>Mice exceeded criterion performance across different trial types (i.e., unimodal, multimodal w/ conflict, multimodal w/o conflict), indicating effective attention to both stimulus features (<xref rid="fig4" ref-type="fig">Fig. 4D3</xref>). Trials with conflicting stimulus features, requiring mice to integrate context information for correct choice, exhibited reduced decision speeds and accuracy compared to trials without conflicting for all tested mice (<xref rid="fig4" ref-type="fig">Fig. 4D3</xref>). We further systematically varied the click rate from 16 to 64 Hz to change context contrast. For trials with conflicts, mice decreased their accuracy following the decline of context contrast, formulating a flat psychometric curve, however, for trials without conflicts, mice performed as a near-optimal learner (<xref rid="fig4" ref-type="fig">Fig. 4D4</xref>). Meanwhile, as the contrast decreased, mice tended to bias to orientation feature against frequency in conflicting trials, but not for the trials without conflicts (<xref rid="fig4" ref-type="fig">Fig. 4D5</xref>). All these results represented mice dealt with different conditioned trials by a dynamic decision strategy synthesizing context-dependent, multimodal integration and perceptual bias. Lastly, the performance of both trial types declined with increased delay duration but maintained criterion above up to 2-sec delay (<xref rid="fig4" ref-type="fig">Fig. 4D6</xref>), confirming mice could execute this paradigm robustly in our system.</p>
<p>As a summary, by introducing changes in trial structure, cognition demands, and perceptual modalities, we extended mice behavior patterns in HABITS. These behaviors were usually challenging and very difficult to test previously with manual training. Thus, the training workflow of our system potentially allows for large-scale and efficient validation and iteration of innovative paradigms which aimed to explore unanswered cognitive questions with mouse model.</p>
</sec>
<sec id="s2e">
<title>Machine learning aided behavioral optimization in HABITS</title>
<p>Mice can be trained to learn challenging tasks in a fully autonomous way in HABITS, however, whether the training efficiency is optimal was unknow. We hypothesized that an optimal train sequence generated by integrating all histories could enhance training procedure, comparing with commonly used random or anti-bias strategies. Benefitted from recent advances in machine teaching (MT) <sup><xref ref-type="bibr" rid="c38">38</xref></sup>, and inspired by previous simulations in optimal animal behavior training experiments <sup><xref ref-type="bibr" rid="c39">39</xref></sup>, we developed a MT-based automated training sequence generation framework in HABITS to further improve the training qualities.</p>
<p><xref rid="fig5" ref-type="fig">Fig. 5A</xref> illustrated the architecture of the MT-based training framework. Initially, mice made an action corresponding the stimuli presented in current trial <italic>t</italic> in HABITS; subsequently, an online logistic regression model was constructed to fit the mice’s history choices by weighted sum of multiple features including current stimulus, history, and rules. This model was deemed as the surrogate of the mouse and was used in the following steps; finally, sampling was performed across the entire trial type repertoire and the fitted model predicted positions of potential future trials in the latent weight space; the trial type with closest position to the goal was selected as the next trials. This entire process forms a closed-loop behavioral training framework, ensuring that the mice’s training direction continually progresses towards the goal.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Fig. 5.</label>
<caption><title>MT enabled faster learning with higher quality.</title><p>(<bold>A</bold>), The framework of machine teaching (MT) algorithm (see text for details). (<bold>B</bold>), Working memory task as in <xref rid="fig4" ref-type="fig">Fig. 4A</xref>, but with full stimulus generation matrix. (<bold>C</bold>), Averaged number of trials needed to reach the criterion for MT-based and random trial type selection strategies. **, p&lt;0.01, two-sided Wilcoxon rank-sum test. (<bold>D</bold>), The absolute difference between contrast (contr.) of sample1 (S1) and sample2 (S2) during training process for the two strategies. (<bold>E</bold>), same as (D) but for correct rate. (<bold>F</bold>), MT-based d2AFC task training. Box plot of correct rate of expert mice (left) and number of trials needed to reach the criterion (right) for different training strategies (MT, anti-bias, and random). n.s., p&gt;0.05, Kruskal–Wallis tests. (<bold>G</bold>), Left, averaged absolute performance bias for the three strategies during different training stages. Right, averaged across training stages. (<bold>H</bold>), same as (G) but for absolute trial type bias. (<bold>I</bold>), Percentage of trials showing significance for different regressors during task learning. (<bold>J-K</bold>), box plot of correct rate (J) and prediction performance difference between the full model and partial model excluding current stimulus (S0) (K) for different trained stage, including early (perf. &gt; 75%), middle (perf. &gt; 80%), and well (perf. &gt; 85%) trained. *, p&lt;0.05, **, p&lt;0.01, ***, p&lt;0.001, n.s., p&gt;0.05, two-sided Wilcoxon rank-sum tests with Bonferroni correction.</p></caption>
<graphic xlink:href="615652v3_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
    <p>We firstly validated the theoretical feasibility and efficiency of the algorithms in simulated 2AFC experiments (<xref ref-type="fig" rid="figs6">Fig. S6</xref>). Faster increasement in sensitivity to current stimuli was observed through effective suppression of noise like biases and history dependence with MT algorithm <xref ref-type="fig" rid="figs6">(Fig. S6A-B)</xref>. Notably, if the learner was ideal (i.e., without any noisy), there was no different between random and MT strategies to train (<xref ref-type="fig" rid="figs6">Fig. S6C</xref>). This implied that the training efficiency was improved by suppression of noise in MT.</p>
<p>To demonstrate MT in real animal training, we initially tested a working memory task similar with <xref rid="fig3" ref-type="fig">Fig. 3B</xref>, but with a fully stimulus generation matrix. As shown in <xref rid="fig5" ref-type="fig">Fig. 5B</xref>, this task utilized a complete set of twenty trial types (colored dots), categorized into four levels of difficulty (dot sizes) according to the distance from decision boundary. Trial type selection using a MT algorithm against a baseline of random selection was tested in two separated groups. Mice trained with the MT algorithm achieved criteria performance with significantly fewer trials comparing with the random group (<xref rid="fig5" ref-type="fig">Fig. 5C</xref>); three out of the eight mice in random group even did not reach the criteria performance at the end of training (60 days). We then asked what kind of strategy the algorithm used that supported an accelerated learning. Analysis of the trial type across learning revealed that the MT-based training presented easier trials first then gradually increased the difficulty, i.e., exhibiting a clear curriculum learning trajectory (<xref rid="fig5" ref-type="fig">Fig. 5D</xref>). However, this did not mean that the MT only presented easy trials at the beginning; hard trials were occasionally selected when the model deemed that a hard trial could facilitate the learning. This strategy enabled mice to maintain consistently higher performance than random group throughout the training process (<xref rid="fig5" ref-type="fig">Fig. 5E</xref>). These results suggested that MT-based method enabled more efficient training for specific challenging tasks.</p>
<p>To further validate the effectiveness of MT in more generalized perceptual decision-making tasks, we trained three groups of mice using random, antibias, and MT strategy respectively in sound-frequency based 2AFC task. Due to the fact that this task was relatively simple, all three groups of mice achieved successful training, with comparable efficiency and final performance (<xref rid="fig5" ref-type="fig">Fig. 5F</xref>). But interestingly, MT algorithm effectively reduced mice’s preference towards a specific lickport (i.e., bias) (<xref rid="fig5" ref-type="fig">Fig. 5G</xref>) throughout the training process by generating trial types with opposite bias more aggressively (<xref rid="fig5" ref-type="fig">Fig. 5H</xref>). Using a model-based methodology, we demonstrated that while the MT algorithm minimized bias dependency, it did not increase, and even decreased, mice’s reliance on other noise variables, like previous action <italic>A<sub>1</sub></italic>, reward <italic>R<sub>1</sub></italic>and stimulus <italic>S<sub>1</sub></italic> (<xref rid="fig5" ref-type="fig">Fig. 5I</xref>). Notably, we noticed that all trained mice demonstrated similar low bias (<xref rid="fig5" ref-type="fig">Fig. 5G</xref>), while only MT algorithm still exhibited relatively high anti-bias strategy during the trained stage (<xref rid="fig5" ref-type="fig">Fig. 5H</xref>). This suggests that the MT algorithm might keep regulating cognitive processes actively even in expert mice. To verify this, we segmented the trained trials into early, middle, and well-trained stages based on performance level, and showed that all three groups of mice had similar overall accuracies across stages (<xref rid="fig5" ref-type="fig">Fig. 5J</xref>). However, when we examined the reliance on the current stimulus <italic>S<sub>0</sub></italic>, i.e., to what extend the decision was made according to current stimulus, we found that MT group had significant higher weights for <italic>S<sub>0</sub></italic> than both anti-bias and random groups (<xref rid="fig5" ref-type="fig">Fig. 5K</xref>). This means that MT-generated sequences across all stages encouraged mice to rely only on current stimuli, rather than noise factors. These results suggested that MT-based training had higher quality for both training and trained stage.</p>
<p>In summary, MT algorithm automatically chose optimal trial type sequences to enable faster and more efficient training. By modelling the effect of history, choice and other noise behavioral variables, MT method manifested higher quality training results. Based on these characteristics, the MT algorithm could enhance training efficiency in challenging paradigms and promoted testing robustness in more general paradigms.</p>
</sec>
<sec id="s2f">
<title>Behavioral optimization for multi-dimensional tasks</title>
<p>One of the advantages of MT algorithm remains that it considers multi-dimensional features altogether and gives the optimal trial sequences to guide the subject to learn. To test this feature, we next expanded the 2AFC task to two stimulus dimensions and trained mice to learn a dynamic stimuli-action contingency. The task was similar to the one applied in <xref rid="fig4" ref-type="fig">Fig. 4D</xref> which presented both sound frequency and orientation features but without context cues. As illustrated in <xref rid="fig6" ref-type="fig">Fig. 6A</xref>, the mice were initially required to focus on sound orientation to obtain reward, while ignoring the frequency (Goal 1). Subsequently, the stimulus-action contingency changed, making sound frequency, rather than orientation, the relevant stimuli dimension for receiving reward (Goal 2). Finally, the relevant cue was still sound frequency but with reversed stimulus-action contingency (Goal 3). Throughout the training process, we employed the MT algorithm to adaptively generate trial types about not only the reward location (left or right) but also the components of the sound stimuli (frequency and orientation combinations), and compared with random control group. MT algorithm allowed for the straightforward construction of a dynamic multi-goal training just by setting the coordinates of target goals within the latent weight space (<xref rid="fig6" ref-type="fig">Fig. 6B</xref>).</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Fig. 6.</label>
<caption><title>MT manifested distinct learning path with faster forgetting and higher learning rate.</title><p>(<bold>A</bold>), task structure. (<bold>B</bold>), chart of training path in latent decision space following three goals one by one. (<bold>C</bold>), top, averaged correct rate across grouped mice during training (color, machine teaching; black, random). Bottom, same as top but performance for non-relative cue. (<bold>D</bold>), top, the slopes of linear regression between trial number and correct rate. Bottom, same as top but between trial number and performance for non-relative cue. **, p&lt;0.01; n.s., p&gt;0.05; two-sided Wilcoxon rank-sum tests. (<bold>E</bold>), the learning path of mice (lines) in latent decision space for machine teaching and random training strategies. Light dots represent model weights fitted by individual mice’s behavioral data. Shaded dots, averaged across mice. (Square dots, testing protocol; Cross dots, the first or the last half of trials in learning protocol; Cycle dots, all trials in learning protocol) (<bold>F</bold>), left, averaged absolute trial type bias between stay and switch conditions across grouped mice for the MT and random strategies from L1 to L3. Right, same as middle but for the bias between left and right trials. (<bold>G</bold>), same as (H) but for absolute performance bias in T1 and T2 protocols. L1, the first 500 trials of frequency learning protocol; L2, intermediate trials of frequency learning protocol; L3, the last 200 trials of frequency learning protocol; T1, testing orientation protocol; T2, testing frequency protocol. *, p&lt;0.05; n.s., p&gt;0.05; two-sided t-tests.</p></caption>
<graphic xlink:href="615652v3_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
    <p>Both groups of mice successfully completed all the goals, achieving an overall correct rate of over 80% (<xref rid="fig6" ref-type="fig">Fig. 6C</xref>). During the first and the third goal of training, the learning rates of mice in both groups were similar, showing low sensitivity to irrelevant cue. However, in the second goal of training (i.e., transition from orientation to frequency modality), the MT group exhibited a significantly higher learning rate compared to the random group, along with a significantly faster rate of forgetting of the irrelevant cue (<xref rid="fig6" ref-type="fig">Fig. 6D</xref> and <xref ref-type="fig" rid="figs7">S7A-D</xref>). To construct a paired comparison, we also retrained the MT group mice in the same protocols but with random sequences after forgetting, and confirmed the improvements for both the learning rate and training efficiency (<xref ref-type="fig" rid="figs7">Fig. S7F-G</xref>). We again employed the logistic regression model to extract the weights for each variable, and plotted the learning trajectories in the latent weight space. MT algorithm manifested distinct learning path against random group in the space (<xref rid="fig6" ref-type="fig">Fig. 6E</xref>); MT algorithm quickly suppressed the sensitivity of irrelevant modality (i.e., <italic>W<sub>orient</sub></italic><sub>.</sub>), keeping low sensitivity to noise dimensions (i.e., <italic>W<sub>noise</sub></italic>) in the meantime. This resulted in a circuitous learning path in the space compared to random group.</p>
    <p>We then asked how MT achieved this learning strategy and what is the benefit. Compared to the random sequence, MT algorithm effectively suppressed the mice’s reliance on irrelevant strategies by dynamically adjusting the ratio of stay/switch trials and left/right trial types (<xref rid="fig6" ref-type="fig">Fig. 6F</xref> and <xref ref-type="fig" rid="figs7">S7E</xref>). After trained, we employed the same random trial sequence to test the performance of both groups. Notably, those mice trained with the MT algorithm exhibited significantly lower left/right bias and stay/switch bias compared to the randomly trained mice (<xref rid="fig6" ref-type="fig">Fig. 6G</xref> and <xref ref-type="fig" rid="figs7">S7H</xref>). This suggested that the MT algorithm enabled mice to exhibit more stable and task-aligned behavioral training, which implied an internal influence to psychological decision strategies after the MT conditioning.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>In this study, we developed a fully autonomous behavioral training system known as HABITS, which facilitates free-moving mice to engage in 24/7 self-triggered training in their home-cage without the need for water restriction. The HABITS equipped with a versatile hardware and software framework, empowering us to swiftly deploy a spectrum of cognitive functions, including motor planning, working memory, confidence, attention, evidence accumulation, multimodal integration, etc. Leveraging the advantages of long-term and parallel running of HABITS, we explored several challenging and novel tasks, some of which introduced new modalities or had never been previously attempted in mouse model. Notably, the acquisition of several tasks spanned more than three months to learn. Benefited from the power of machine teaching algorithms, we endowed the automated training in HABITS with an optimal training sequence which further significantly improved the training efficiency and testing robustness. Furthermore, we extended the machine teaching algorithm to a more generalized form, incorporating multi-dimensional stimuli, which has resulted in diverse training trajectories in the latent space and thus elevated training qualities. Altogether, this study presents a fully autonomous platform that offers innovative and optimal mouse behaviors that could advance the field of behavioral, cognitive and computational neuroscience.</p>
<p>One of the pivotal contributions of this research is provision of an extensive behavioral dataset, derived from ∼300 mice training and testing in more than 20 diverse paradigms. This comprehensive dataset consisted of the entire learning trajectory with well-documented training strategies and behavioral outcomes. This unprecedented scale of data generated in a single study is mainly attributed to the three distinct features of HABITS system. Firstly, the hardware was engineered to fit a broad spectrum of cognitive tasks for mice, diverging from the typical focus on specific tasks in previous studies <sup><xref ref-type="bibr" rid="c21">21</xref>–<xref ref-type="bibr" rid="c34">34</xref></sup>. It integrated both visual and auditory stimuli across three spatial locations, as well as up to three lickports for behavioral report, offering various combinations to explore. Secondly, the software within HABITS implemented a general-purpose state machine runner for step-by-step universal task learning, and run standalone without PC in the loop, which contrasted with previous system running on PCs <sup><xref ref-type="bibr" rid="c21">21</xref>,<xref ref-type="bibr" rid="c24">24</xref>–<xref ref-type="bibr" rid="c26">26</xref>,<xref ref-type="bibr" rid="c31">31</xref></sup>. Thirdly, the cost of the HABITS was quite low (less than $100) comparing previous systems (ranging from $250 to $1500) <sup><xref ref-type="bibr" rid="c25">25</xref>,<xref ref-type="bibr" rid="c26">26</xref>,<xref ref-type="bibr" rid="c32">32</xref>,<xref ref-type="bibr" rid="c34">34</xref></sup>, which facilitated large scale deployment and thus high-throughput training and testing. Together, these unique attributes have simplified behavioral exploration, which would otherwise be a time– and labor-intensive endeavor.</p>
<p>Another significant contribution was the expansion of the behavioral repertoire for mice, made possible again by the autonomy of HABITS. We have introduced auditory stimuli and multiple delay epochs into the DMS paradigm <sup><xref ref-type="bibr" rid="c60">60</xref>–<xref ref-type="bibr" rid="c63">63</xref></sup>, allowing for investigation of working memory across different modality and stages within single trials. Additionally, we have advanced the traditional d2AFC task <sup><xref ref-type="bibr" rid="c7">7</xref>,<xref ref-type="bibr" rid="c43">43</xref></sup> to d3AFC, enabling the study of motor planning in multi-classification scenarios. Furthermore, we have implemented delayed context-dependent tasks <sup><xref ref-type="bibr" rid="c67">67</xref>,<xref ref-type="bibr" rid="c68">68</xref></sup> based on multi-dimensional auditory stimuli, facilitating research of complex and flexible decision-making processes. Collectively, the advancement of our high-throughput platform was anticipated to improve the experimental efficiency and reproducibility, in either the creation of standardized behavioral datasets for individual paradigms or in the exploration of a multitude of complex behavioral training paradigms.</p>
<p>Last but not the least, we have incorporated machine teaching algorithms into the mouse behavioral training process and significantly enhanced the training efficacy and quality. To our knowledge, this is the first study demonstrating the utility of machine teaching in augmenting animal behavioral training, which complements previous simulation studies <sup><xref ref-type="bibr" rid="c39">39</xref></sup>. The impact of machine teaching algorithms is threefold. First, the training duration of complex tasks was substantially reduced, primarily due to the real-time optimization of trial sequences based on mouse performance, which significantly reduces the mice’s reliance on suboptimal strategies. Second, the final training outcomes was demonstrated to be less influenced by the task-irrelevant variables. Prior study has indicated that suboptimal strategies, such as biases, are common among expert mice trained in various paradigms, potentially stemming from their exploration in real-world uncertain environments <sup><xref ref-type="bibr" rid="c69">69</xref>–<xref ref-type="bibr" rid="c72">72</xref></sup>. Machine teaching-based techniques can significantly reduce the noise dependency, thus facilitating the analysis of the relationship between behavior and neural signals. Third, the machine learning algorithm lowers the barriers for designing effective anti-bias strategies, which were challenging and prone to lopsided in multidimensional tasks. By simply setting the task goals in the fitted decision model, machine teaching can automatically guide the mouse to approach the goal optimally and robustly.</p>
<p>Our study was designed to standardize behavior for the precise interrogation of neural mechanisms, specifically addressing within-subject questions. However, investigators are often interested in between-subject differences—such as sex differences or genetic variants—which can have long-term behavioral and cognitive implications <sup><xref ref-type="bibr" rid="c73">73</xref>,<xref ref-type="bibr" rid="c74">74</xref></sup>. This is particularly relevant in mouse models due to their genetic tractability <sup><xref ref-type="bibr" rid="c75">75</xref></sup>. Although our primary focus was not on between-subject differences, the dataset we generated provides preliminary evidence for such investigations. Several behavioral readouts revealed individual variability among mice, including large disparities in learning rates across individuals (<xref rid="fig2" ref-type="fig">Fig. 2I</xref>), differences in overall learning rates between male and female subjects (<xref rid="fig2" ref-type="fig">Fig. 2D</xref> vs. Fig. S2G), variations in nocturnal behavioral patterns (<xref rid="fig2" ref-type="fig">Fig. 2K</xref>), etc. Furthermore, a detailed logistic regression analysis dissected the strategies mice employed during training (Fig. S2B). Notably, the regression identified variables associated with individual task-performance strategies (Fig. S2C), which also differed between manually and autonomously trained groups (Fig. S2D). Thus, our system could facilitate high-throughput behavioral studies exploring between-subject differences in the future.</p>
<p>Our study marks the inaugural endeavor to innovate mouse behavior through autonomous setups, yet it comes with several limitations. Firstly, our experiments were confined to single-housed mice, which is known to influence murine behavior and physiology, potentially affecting social interaction and stress levels <sup><xref ref-type="bibr" rid="c76">76</xref></sup>. In our study, individual housing was necessary to ensure precise behavioral tracking, eliminate competitive interactions during task performance, and maintain consistent training schedules without disruptions from cage-mate disturbances. However, the potential of group-housed training has been explored with technologies such as RFID <sup><xref ref-type="bibr" rid="c28">28</xref>,<xref ref-type="bibr" rid="c29">29</xref>,<xref ref-type="bibr" rid="c32">32</xref>–<xref ref-type="bibr" rid="c34">34</xref></sup> to distinguish individual mice, which potentially improving the training efficiency and facilitating research of social behaviors <sup><xref ref-type="bibr" rid="c77">77</xref></sup>. Notably, it has shown that simultaneous training of group-housed mice, without individual differentiation, can still achieve criterion performance <sup><xref ref-type="bibr" rid="c25">25</xref></sup>. Secondly, we have not yet analyzed any videos or neural signals from mice trained in the home-cage environment. Recent studies have harnessed a variety of technologies and methodologies to gain a deeper understanding of natural animal behavior in home-cage environments<sup><xref ref-type="bibr" rid="c78">78</xref>,<xref ref-type="bibr" rid="c79">79</xref></sup>. Voluntary head-fixation, employed in previous studies, has facilitated real-time brain imaging <sup><xref ref-type="bibr" rid="c17">17</xref>,<xref ref-type="bibr" rid="c18">18</xref>,<xref ref-type="bibr" rid="c21">21</xref>,<xref ref-type="bibr" rid="c29">29</xref>,<xref ref-type="bibr" rid="c30">30</xref></sup>. Future integration of commonly-used tethered, wireless head-mounted <sup><xref ref-type="bibr" rid="c80">80</xref></sup>, or fully implantable devices <sup><xref ref-type="bibr" rid="c81">81</xref>,<xref ref-type="bibr" rid="c82">82</xref></sup>, could allow for investigation of neural activity during the whole period in home-cage. Lastly, while HABITS achieves criterion performance in a similar or even shorter overall days compared to manual training, it requires more trials to reach the same learning criterion (<xref rid="fig2" ref-type="fig">Fig. 2G</xref>). We hypothesize that this difference in trial efficiency may stem from the constrained engagement duration imposed by the experimenter in manual training, which could compel mice to focus more intensely on task execution, resulting in less trial omissions (<xref rid="fig2" ref-type="fig">Fig. 2F</xref>). In contrast, the self-paced nature of autonomous training may permit greater variability in attentional engagement <sup><xref ref-type="bibr" rid="c83">83</xref></sup> and inter-trial-intervals, which could be problematic for data analysis relaying on consistent intervals and/or engagements. Future studies should explore how controlled contextual constraints enhance learning efficiency and whether incorporating such measures into HABITS could optimize its performance.</p>
<p>The large-scale autonomous training system we proposed can be readily integrated into current fundamental neuroscience research, offering novel behavioral paradigms, extensive datasets on mouse behavior and learning, and a large cohort of mice trained on specific tasks for further neural analysis. Additionally, our research provides a potential platform for testing computational models of cognitive learning, contributing to the field of computational neuroscience.</p>
</sec>
<sec id="s4">
<title>Materials and Methods</title>
<sec id="s4a">
<title>Design and implementation of HABITS</title>
<sec id="s4a1">
<title>Architecture</title>
<p>A single HABITS was comprised of a custom home-cage and integrated behavioral apparatuses. All the building materials were listed in the supplementary Table I, with source and price information provided. The home-cage was made of acrylic panels, with a dimension of 20 × 20 × 30 cm<sup>3</sup>. Top panel was movable and could equipped with cameras to record mouse natural behaviors. A compatible tray was located at the bottom of the home-cage, facilitating bedding materials changing. A notch was designed in the front of tray where an elevated platform was installed. The platform formed an arch-shape to loosely constrain the mouse body when the mouse stepped on it to perform task. A micro load cell was installed beneath the platform and used for daily body weighting.</p>
<p>Most of the behavioral apparatuses were installed in the front panel of the home-cage. A lickport holder with up to seven slots was installed in front of the weighting platform. Three lickports (1.5 mm diameter, 10 mm apart) were used in this study. Water was drawn by peristaltic pumps from water tanks (centrifuge tube, 50 ml) to the lickports. Three groups of LEDs and buzzers for light and sound stimuli were extruded from the front panel and placed in the left, right and top position around the weighting platform. Notably, the top module contained a RGB LED, but white LEDs for the others. Buzzers were the same in all stimulus modules and produced 3-15 kHz pure tones at 80 dB. In some experiments (<xref rid="fig3" ref-type="fig">Fig. 3E</xref>, <xref rid="fig4" ref-type="fig">Fig. 4C</xref>), the top buzzer was replaced with a micro ultrasound speaker (Elecfans Inc.) which was able to emit 40khz pure tone for up to100 dB.</p>
</sec>
<sec id="s4a2">
<title>Control system</title>
<p>The core of the control system was a microprocessor (Teensy 3.6) which interacted with all peripheral devices and coordinated the training processes (Fig. S1A). The microprocessor generated PWM signal to directly control the sound and light stimuli. Reward water was dispersed by sending pulses to solid state relays which controlled the pumps. Two toggle switches were used for flushing the tubing. Each lickports were electrically connected to a capacitive sensing circuit for lick detection. Additionally, another switch was used for manually controlling the start and pause of training process. Real-time weight data were read from the load cell at a sampling rate of 1 Hz. A Wi-Fi module was connected with the microprocessor to transmitted data wirelessly to a host computer. Meanwhile, all the data were also stored on a local SD card, with the microprocessor’s clock as the timestamps for all behavioral events.</p>
<p>We have developed a software framework for constructing behavioral training programs, which is a general-purpose state machine runner for training animal behaviors (gpSMART, <ext-link ext-link-type="uri" xlink:href="https://github.com/Yaoyao-Hao/gpSMART">https://github.com/Yaoyao-Hao/gpSMART</ext-link>). This framework supported construction of arbitrarily complex cognitive behavioral paradigms as state machines (Fig. S1B). Basically, each state was comprised of a unique name, output actions, transition conditions and maximum timing. Within each trial, the microprocessor generates the state matrix based on the defined state machine and executes the state transition according to the external events (e.g., licks) or timing (e.g., a delay period of 1.2 sec). This is similar to the commonly used Bpod system (Sanworks Inc.), but gpSMART could run on microprocessors with a hardware-level time resolution. Between trials, training protocol updating, behavioral data recording, and wireless data communication were executed. Various training assistances (e.g., free reward) were also performed when necessary to help the training processes. All the training progress and protocols were stored on SD card for each mouse; thus, training can be resumed after any pause event and supports seamless switching between multiple HABITS systems. The system was designed to operate standalone without PC connected. Finally, the firmware on the microprocessor could be updated wirelessly to facilitate paradigm changing.</p>
</sec>
<sec id="s4a3">
<title>High-throughput training and GUI</title>
<p>We constructed over a hundred of HABITS to facilitate large-scale, fully autonomous in-cage behavioral training (Fig. S1D). Each HABITS was piled on standard mouse cage racks, with sound-proof foams installed between them to minimize cross-cage auditory interference. The cage operated independently with each other, with only a 12V standard power supply connected. The training room were maintained under a standard 12:12 light-dark cycle. All the cages communicated with a single PC via unique IP addresses using the UDP protocol.</p>
<p>To monitor the training process of all the cages, a MATLAB-based graphic user interface (GUI) running on a PC was developed (Fig. S1C). The GUI displayed essential information for each mouse, such as the paradigm name, training duration, training progress, and performance metrics like long-term task accuracy, weight changes, and daily trial numbers, etc. Meanwhile, the whole history of training performance, detailed trial outcomes in the last 24-hour and real-time body weight could be plotted. The GUI also enabled real-time updating of each cage’s training parameters for occasional manual adjusting. Training settings can also be modified by physically or remotely updating the SD card files.</p>
</sec>
</sec>
<sec id="s4b">
<title>Mice and overall training procedures</title>
<sec id="s4b1">
<title>Mice</title>
    <p>All experimental data used in this study were collected from a total of 302 mice (C57BL/6J). For most of the autonomous experiments, males were used with starting age at around 8-week (see <xref rid="tbl1" ref-type="table">Table I</xref>). A separate group of 6 females were tested in a sound-frequency based 2AFC task (<xref ref-type="fig" rid="figs2">Fig. S2G</xref>). Mice were single housed in our home-cage systems for ranging from 1 to more than 3 months. A group of 6 mice were used for supervised manual training. Another 6 mice were used for <italic>ad libitum</italic> reward testing in HABITS. All experiments were conducted in compliance with the Zhejiang University Animal Care Committee’s regulations.</p>
</sec>
<sec id="s4b2">
<title>Workflow for behavioral testing in HABITS</title>
    <p>The entire workflow for fully automated behavioral training experiment in HABITS can be divided into three stages (<xref ref-type="fig" rid="figs1">Fig. S1E</xref>). The first stage was the initialization of HABITS. This involved setting up the home cage by placing an appropriate amount of bedding, food, cotton, and enrichments into the drawer of the home cage. Behavioral paradigms and training protocols, programmed within our software framework, were then deployed on the microcontroller of HABITS. Each mouse was provided with a unique SD card that stores its specific behavioral training data, including the training paradigm, cage number, initial paradigm parameters, and progresses. The load cell was initialized through the host computer, which includes zeroing and calibration processes. The flush switch of the peristaltic pump was activated to fill the tubing with water. Finally, the mouse was placed into the HABITS after initial body weight measuring. Note that any of habituations or water restriction were not required.</p>
<p>The second stage was the fully autonomous training phase, during which no intervention from the experimenter was needed. Typically, this stage included three main training sub-protocols: habituation, training, and testing. During the habituation phase, free rewards are randomly given on either lickports to guide the mouse establish connection between lickports and water reward. Subsequently, in the training phase, the protocols are gradually advanced, form very easy one to the final paradigm, based on the learning performance of the mouse. Assistances, like reward at correct lickport, were gradually decreased as the mouse learned the task. Finally, predefined behavioral tests, such as psychometric curve testing, random trials, additional delays, etc. were conducted. The entire training process of all cages were remotely monitored via the GUI. The bedding in the drawer were replaced every other week to ensure that the mouse lives in a clean environment.</p>
<p>The third stage involved data collection and analysis. All raw data, including detailed event, trail and configuration information, were stored on the SD card; data wirelessly transmitted to PC were mainly used for monitoring. These behavioral data were analyzed offline with Python and the mice were ready for other subsequent testing.</p>
</sec>
<sec id="s4b3">
<title>Manual Training</title>
    <p>To compare with fully autonomous training, we also used HABITS as a behavioral chamber to perform manual training protocol for freely moving mice. The mice were first single-housed in standard home cages and subjected to water restriction. After several days, when the mice’s body weight dropped to approximately 85% of their original weight <sup><xref ref-type="bibr" rid="c9">9</xref></sup>, behavioral training began. The mice were trained in a session-based manner; in each session, experimenters transferred the mice from the standard home-cage to HABITS, where they underwent 1-3 hours of training to receive around 1 ml of water. The amount of water consumed was estimated by HABITS based on the number of rewards. HABITS weighed the mice daily, ensuring that all mice maintained stable body weight throughout the training process. The manually trained mice underwent the same training protocols as in the autonomous ones (<xref ref-type="fig" rid="figs2">Fig. S2A</xref>). Once the mice completed the final protocol and reached the criterion performance (75%), they were considered successfully trained. After completing the manual training, the mice were then transitioned into autonomous testing in HABITS (<xref ref-type="fig" rid="figs2">Fig. S2E</xref>).</p>
</sec>
</sec>
<sec id="s4c">
<title>Behavioral data analysis</title>
<sec id="s4c1">
<title>Bias calculation</title>
<p>We calculated mice’s bias toward different trial types, e.g., left and right, by evaluating their performance under these trial types (perf. bias). The strength of the bias was quantified by calculating the absolute difference between the proportion of performance under specific trial type relative to the summed value across trial types, and the balance point, i.e., 50%. Similarly, we applied this method for presentation of trial sequence to compute the trial type bias during paradigm training, illustrating the dynamic changes in training strategies.</p>
</sec>
<sec id="s4c2">
<title>Data preprocessing</title>
<p>For the fully autonomous training, we excluded data from the habituation phase, as we believed the mice had not yet understood the structure of the trials during that stage. Additionally, we removed trials where the mice did not make a choice, i.e., no-response trials. For each mouse, the trials were concatenated in chronological order, ignoring the time span between trials during the continuous multi-day home-cage training sessions; the same approach was applied to manual training data. We then organized the data for each mouse into multiple 500-trial windows, sliding from the beginning to the end of the training with a step size of 100-trial. Windows containing fewer than 500 trials at the end of the dataset were discarded. We assumed that within each window, the mouse employed a consistent strategy, and a new logistic regression model was fit in each window.</p>
</sec>
<sec id="s4c3">
<title>Logistic regression of behavioral data</title>
    <p>Similar to our previous study <sup><xref ref-type="bibr" rid="c27">27</xref></sup>, we employed an offline logistic regression model to predict the choices made by the mice (<xref ref-type="fig" rid="figs2">Fig. S2B-D, </xref><xref rid="fig5" ref-type="fig">Fig. 5I</xref>, <xref rid="fig6" ref-type="fig">Fig. 6</xref>). This model calculates a weighted sum of all behavioral variables and transforms the decision variable into a probability value between 0 and 1 using a sigmoid function, representing the probability of choosing the left side. The variables include the current stimulus (<italic>S<sub>0</sub></italic>; –1 for licking left trials; 1 for licking right trials), the previous stimulus (<italic>S<sub>1</sub></italic>), reward (<italic>R<sub>1</sub></italic>; –1 for no reward; 1 for reward), action (<italic>A<sub>1</sub></italic>; –1 for left choice; 1 for right choice), win-stay-loss-switch (<italic>WSLS</italic>; which is <italic>A<sub>1</sub></italic>× <italic>R<sub>1</sub></italic>), and a constant bias term (<italic>bias</italic>). The model can be formulated by the following equation:
<disp-formula>
<graphic xlink:href="615652v3_ueqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where the β’s were the weights for the regressors. We used 0.5 as the decision threshold: predictions above 0.5 were classified as right choices, while below were classified as left choices.</p>
<p>Model performance was assessed using 10-fold cross-validation. For each cross-validation iteration, 450 trials were randomly selected as the training set, and gradient descent was employed to minimize the cross-entropy loss function. The remaining 50 trials were used as the test set. Training was considered complete (early stopping) once the calculated loss in the test set stabilized. The accuracy of the model in predicting the mouse’s choices in the test set was recorded as the result of one cross-validation iteration. This process was repeated 10 times, and the final performance of the model was averaged across all iterations.</p>
</sec>
<sec id="s4c4">
<title>Significance calculation</title>
    <p>To evaluate the contribution of each regressor, we compared the performance of a partial model, where a specific variable was removed, with that of the full model. Specifically, the value of the variable in testing was set to zero, and we checked whether the performance of the partial model showed a significant decline. We applied a corrected t-test using a 10×10 cross-validation model comparison method to compute the <italic>p</italic>-value <sup><xref ref-type="bibr" rid="c84">84</xref></sup>. For each window, we trained 100 models, and the performance differences between the partial and full models formed a <italic>t</italic>-distribution. By examining the distribution of performance differences, we determined the significance level of each regression variable’s contribution. When <italic>p</italic> &lt; 0.05, the regression variable was considered to have a significant contribution to predicting the mouse’s choice in that window. Additionally, we calculated the proportion of windows across the entire training process in which a particular regression variable had a significant contribution, to estimate the degree to which the mouse relied on that variable. The same significance evaluation method was applied to both autonomous and manual training, allowing for direct comparison of the learning strategies employed in two conditions at the individual mouse level (<xref ref-type="fig" rid="figs2">Fig. S2B-D, </xref><xref rid="fig5" ref-type="fig">Fig. 5I</xref>).</p>
</sec>
<sec id="s4c5">
<title>Logistic regression in evidence accumulation: Multimodal integration</title>
    <p>For each mouse in evidence accumulation task (<xref rid="fig3" ref-type="fig">Fig. 3D4</xref>), we trained a group of logistic regression models to estimate the psychophysical kernel. The entire sample period was divided into 25 bins of 40 ms each, with each bin assigned a weight to predict the mouse’s choice. An event occurring in a bin was set to 1, otherwise, set to 0. We trained 100 pairs of models for each mouse. Each pair of models trained using 10% total trials randomly. Each pair of models included one model trained on the original data and another trained on data with bin-wised shuffled within each trial. The psychophysical kernel for each mouse was derived by averaging the first 100 models, compared to a baseline kernel obtained from the second. Finally, we averaged the results across all 13 mice to statistically estimate the temporal dynamics of mice’s evidence dependence in this task.</p>
</sec>
</sec>
<sec id="s4d">
<title>Behavioral tasks and training protocols</title>
<sec id="s4d1">
<title>General training methodology</title>
<p>In the fully autonomous behavioral training process, all mice learn the required behavioral patterns through trials and errors. The training protocols were pre-defined based on experience. Given that the entire training process is long-term and continuous, a free reward is triggered if a mouse fails to obtain water within last 3-or 6-hour period, ensuring the mouse receives sufficient hydration. Throughout the training process, we employed a custom-designed ‘anti-bias’ algorithm to avoid mice always lick one side. Basically, we implemented several priority-based constraints to prevent mice from developing a preference for a particular reward direction:
<list list-type="bullet">
<list-item><p><italic>Highest Priority</italic>: If a mouse consecutively made three errors or no-response in a specific trial type, the next trial would maintain the same reward direction.</p></list-item>
<list-item><p><italic>Second Priority</italic>: If three consecutive trials shared the same reward direction (including no-response trials), the reward direction would switch in the subsequent trial.</p></list-item>
<list-item><p><italic>Third Priority</italic>: The reward direction of the next trial was sampled based on the average performance of left and right trials, using the following formula:</p></list-item></list>
<disp-formula>
<graphic xlink:href="615652v3_ueqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>N</italic> represented the number of recorded historical trials (set to 50 in our case). <italic>Ri</italic> and <italic>Li</italic> were set to 1 if the reward direction of the <italic>i<sub>th</sub></italic> historical trial was right or left, respectively; otherwise, they were set to 0. Similarly, <italic>Corr<sub>i</sub></italic>and <italic>Err<sub>i</sub></italic> were set to 1 or –1 if the mouse’s choice in the <italic>i<sub>th</sub></italic> trial was correct or incorrect, respectively; otherwise, they were set to 0. <italic>P<sub>left</sub></italic> represented the probability of left trial type in the next trial.</p>
</sec>
<sec id="s4d2">
<title>d2AFC with multi-modal</title>
<p>The task of d2AFC, delayed two-alternative forced choice, required mice to learn the stimulus-action contingency separated by a delay for motor planning. A complete trial consisted of three parts: the sample, delay, and response epochs. The sample epoch lasted for 1.2 sec and is accompanied by auditory or visual stimuli. The delay epoch elapsed for another 1.2 sec, during which mice were required to withhold licking until a 100 ms response cue (6 kHz tone) was played. Any premature licking (early licks) during this period immediately paused the trial for 300ms. Response epoch lasted for 1 sec. The first lick made by the mouse during this period was recorded as its choice for the current trial, and feedback is provided accordingly. A correct lick delivered approximately 0.25µl of water to the corresponding spout (achieved by activating the peristaltic pump for 30ms), while an incorrect choice results in an immediate 500 ms white noise and 8000 ms timeout for penalty. After each trial, the mouse must refrain from licking for 1000 ms before the next trial began automatically. If the mouse failed to make a choice during the response period, the trial was marked as a no-response trial, and the mouse must lick either spout to initiate the next trial. The stimuli modalities tested in this study were as follows:
<list list-type="bullet">
<list-item><p>Sound frequency modality: A 3 kHz tone corresponds to a left choice, while a 10 kHz tone corresponds to a right choice.</p></list-item>
<list-item><p>Sound orientation modality: A sound from the left speaker corresponds to a left choice, while a sound from the right speaker corresponds to a right choice.</p></list-item>
<list-item><p>Light orientation modality: The left white LED lighting up corresponds to a left choice, and the right white LED lighting up corresponds to a right choice.</p></list-item>
<list-item><p>Light color modality: The top tricolor LED lighting up blue corresponds to a left choice, and red corresponds to a right choice. For light color modality, we tested multiple variations since the mouse did not learn the task very well, including green <italic>vs.</italic> blue and flashed green <italic>vs.</italic> blue.</p></list-item></list></p>
<p>In the reaction time version of the paradigm (RT task, Fig. S3), a central spout was introduced in addition to the left and right lickports, to allow the mouse to self-initiate a trial. The mouse must lick the central spout to initiate a trial; licking either side following would result in a brief (100ms) white noise and immediate termination of the trial, followed by a timeout period. During the sample epoch, a tone from the top speaker (3 kHz for left reward; 10 kHz for right reward) plays for 1000ms. The mouse can immediately indicate its choice by licking either side lickports, which terminated the sample period and triggered trial outcomes as above. An inter-trial interval (ITI) of 1000ms was followed. The next trial required the mouse to lick the central spout again. The central spout did not provide any rewards; all rewards are contingent upon the mouse’s choice of the left or right spouts.</p>
</sec>
<sec id="s4d3">
<title>Training and testing of other tasks</title>
<p>The training and testing method for all other tasks were detailed in the text of supplementary materials.</p>
</sec>
</sec>
<sec id="s4e">
<title>Machine teaching algorithms</title>
<p>We employed machine teaching (MT) algorithm <sup><xref ref-type="bibr" rid="c41">41</xref></sup> to design an optimal trial sequence that enables the mice to rapidly approach a target state, i.e., trained in a specific task. In this context, the MT algorithm can be referred to as the ‘teacher’ while the mice are the ‘students’; the size of the training dataset is termed ‘teaching dimension’ of the student model <sup><xref ref-type="bibr" rid="c38">38</xref></sup>. Specifically, the teacher samples from a pre-defined discrete dataset, and the student updates its internal model using the sampled data. The teacher then prepares the next round of training based on the student’s progress, creating a closed-loop system. In this study, a logistic regression model was employed to infer the internal decision-making model of the mice based on their choices trial-by-trial (i.e., model-based). The model was updated in real-time and used for the optimization and sampling of subsequent trials. L1 regularization and momentum were introduced to smooth the fitted weights, mitigating overfitting and oscillations. The mice’s choices and outcomes served as feedback for MT. <xref rid="fig5" ref-type="fig">Figure 5A</xref> illustrated the complete closed-loop optimization process of MT algorithm. It was similar to an imitation teacher <sup><xref ref-type="bibr" rid="c41">41</xref></sup> whose objective was to iteratively minimize the distance between the model weights of next trial and target.</p>
<p>In detail, the logistic regression model to fit the choices of mouse was updated trial-by-trial according to the following formula:
<disp-formula>
<graphic xlink:href="615652v3_ueqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where the parameter ω<italic><sup>t</sup></italic> represents the decision model parameters fitted to the current and past choices (i.e., <italic>y<sub>choice</sub></italic>) performed by the mice at the <italic>t</italic>-th trial. The hyperparameter λ controls the strength of L1 regularization. Momentum parameter η determines the window width for exponential smoothing of the loss gradient. <italic>m</italic> represents an exponential smoothed gradient across past trials.</p>
<p>Then, the objective of this algorithm can be formalized as the following equation:
<disp-formula>
<graphic xlink:href="615652v3_ueqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where, (<italic>x, y</italic>) represents a pair of stimuli-action contingency. The parameter ω<italic>*</italic>denotes the target weight within the implicit decision space of the simulated mouse model, typically set to converge to the model weights according to the current task rules. <italic>T<sub>1</sub></italic> can be interpreted as the trial difficulty, predicting the probability of incorrect choices performed by mice in this trial, and <italic>T<sub>2</sub></italic> as the effectiveness of this trial, predicting the correlation between the upcoming mouse behavioral strategy updates and the shortest learning path between ω<italic><sup>t</sup></italic> and ω<italic>*</italic>. The balance between these two metrics is achieved through hyperparameters γ, i.e., hypothetical learning rate of mouse. In this study, we assume that this model reflects the actual decision-making process of the mice. Subsequently, this algorithm can select the next trial type using the following formula:
<disp-formula>
<graphic xlink:href="615652v3_ueqn5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>X</italic> and <italic>Y</italic> represent the repertoires of available trial types and action, respectively.</p>
<p>Finally, we presented the selected stimuli <italic>x</italic> in the next trials and expected the mouse made correct/incorrect choice <italic>y</italic> and received reward/punishment.</p>
<p>We have implemented the aforementioned MT-based optimization algorithm on the microprocessors of HABITS, as a superior alternative to existing ‘anti-bias’ algorithms. The computation load for running MT optimization on the microprocessors was high and latency was relative long comparing trial resolution. However, since the computation was conducted between trials, it did not interfere with the execution of the trials themselves under the gpSMART framework. Additionally, for each mouse, additional files were used to record the hyperparameters and weight changes of the online logistic regression model for each trial. No-response trials were not used for model fitting. However, if the previous trial was a no-response trial, the history-dependance regressors of current trial were set to 0.</p>
<sec id="s4e1">
<title>Simulation experiments</title>
<p>We employed a logistic regression model as the student, tasked with completing 2AFC task, which involved mapping the current stimulus <italic>S<sub>0</sub></italic>to a choice while ignoring interference from other features. Another logistic regression model, serving as the imitation teacher, was then used to fit the choices made by the student. Both models operated within the same feature space and utilized the same update algorithm. The hyperparameters were set as follows: α=0.1, η=0.9, γ=1, and λ=0.1.</p>
<p>We first simulated the biases and history-dependence typically observed in naïve mice during the early stages of training by setting the initial values of <italic>S<sub>1</sub></italic> and <italic>bias</italic> to –2 and 2, respectively. During the trial-by-trial update process, we tracked the changes in the student’s weights under the MT algorithm and compared them to those under random training, which served as the baseline. Additionally, we simulated conditions without noise to further examine the differences between the MT algorithm and random training in influencing the student’s weight updates.</p>
</sec>
<sec id="s4e2">
<title>Animal experiments 1: Working Memory Task with Full SGM</title>
<p>The first task we tested with MT algorithm was working memory task with full 5×5 stimulus matrix (<xref rid="fig5" ref-type="fig">Fig. 5B</xref>). The delay duration was set to 500ms. Mice were randomly assigned to two groups: random (<italic>N</italic> = 8) and MT (<italic>N</italic> = 7). Once the mice achieved a 75% correct response rate in the eight most challenging trial types, they advanced to the testing phase. At this stage, only the eight most challenging trial types were randomly presented. When the correct rate reached 75%, the mice are considered to have learned the task. MT used seven features as the inputs for the logistic regression model: <italic>bias</italic>, <italic>S<sub>0</sub></italic> (the frequency of the first stimulus, where {8, 16, 32, 64, 128} Hz corresponds to values of {-1, –0.5, 0, 0.5, 1}), <italic>T<sub>0</sub></italic> (the frequency of the second stimulus), <italic>S<sub>1</sub></italic>, <italic>A<sub>1</sub></italic>, <italic>R<sub>1</sub></italic>, and <italic>WSLS</italic>. Hyperparameters were set as follows: α=0.01, η=0, γ=0.03, and λ=0.</p>
</sec>
<sec id="s4e3">
<title>Animal experiments 2: 2AFC task</title>
<p>In 2AFC task (<xref rid="fig5" ref-type="fig">Fig. 5F</xref>), Mice were divided into three groups, each using different methods to generate the stimulus frequency (3 kHz or 10 kHz) for the next trial: random selection (<italic>N</italic> = 10), the anti-bias strategy (<italic>N</italic> = 10), and the MT algorithm (<italic>N</italic> = 10). The online logistic regression model settings for this task remained consistent with those in Figure S2. The hyperparameters for the MT algorithm were set as follows: α=0.1, η=0.9, γ=1, and λ=0.1.</p>
</sec>
<sec id="s4e4">
<title>Animal experiments 3: dynamic 2AFC task with multi-dimensional stimuli</title>
<p>In the third task, we expanded the stimulus dimension of 2AFC with the combination of sound frequency (high and low) and orientation (left and right), to test MT algorithm (<xref rid="fig6" ref-type="fig">Fig. 6A</xref>). In each trial, the stimulus could be one of the four combinations, but whether the mouse should attend to frequency or orientation modality was not informed. In other words, no any modality cues were presented for mice and mice must rely solely on feedback from past trials to identify what the current modality was. Mice were divided into random (<italic>N</italic> = 8) and MT groups (<italic>N</italic> = 10). In MT group, both the stimulus combinations and reward direction are determined by the MT algorithm simultaneously. The entire task involved learning three different rules one by one, including sound orientation, sound frequency, and reversed sound frequency. When the mice in each group achieved an accuracy of 80% in the first 500 choice trials under the current rule, they advance to a testing protocol consisting of at least 100 random trials. When a mouse achieved 80% accuracy in the last 100 trials of the testing protocol, it transitioned to next rule <sup><xref ref-type="bibr" rid="c85">85</xref></sup>. Hyperparameters were set as follows: α=0.1, η=0.9, γ=1, and λ=0.1.</p>
</sec>
</sec>
<sec id="s5">
<title>Statistics</title>
<p>To maximize the utility of HABITS in a wider range of paradigms, we usually employed 6 mice per paradigm. For experiments where we aimed to conduct between-group comparisons, we increased the sample size to 10 to ensure the stability and reliability of statistical significance. All significance tests were conducted by comparing different groups of animals (e.g., comparing performance levels across different mouse groups). Non-parametric tests, such as the Wilcoxon signed-rank test or rank-sum test, were used for comparisons between two groups, and the Kruskal–Wallis test was used for comparisons among three groups, unless otherwise stated in the figure legends. Data are presented as mean ± 0.95 confidence intervals (CI) across animals, as specified in the figure legends. In the box plots, the center lines represent the median values, the box limits indicate the upper and lower quartiles, the whiskers show 1.5 times the interquartile range, and the points represent outliers. Significance levels are denoted as *, p &lt; 0.05, **, p &lt; 0.01, and ***, p &lt; 0.001 in all figures. All data analyses were performed using Python (version 3.8.13) with the following packages: NumPy (1.21.5), SciPy (1.10.1), matplotlib-inline (0.1.3), pandas (1.3.4), PyTorch (1.11.0), and seaborn (0.13.0).</p>
</sec>
</sec>
</body>
<back>
<sec id="s10">
<title>Supplementary Materials</title>
<sec id="s10a">
<title>Tasks tested in HABITS</title>
<sec id="s10a1">
<title>Value-based dynamic foraging task</title>
    <p>In <xref ref-type="fig" rid="figs1">Figure S4</xref>, we introduced the dynamic foraging task. Mice must first lick the center spout to initiate a trial block. Each block consists of one or more trials, and if a mouse fails to make a choice in any given trial, the block ends and waits for the mouse to trigger the next one. Within a trial block, trials are separated by an inter-trial interval (ITI) ranging randomly from 0.5 to 2 seconds, with an average of 1 second. The next trial automatically begins after the ITI.</p>
<p>At the start of each trial, a 500ms light cue is emitted from the top LED, signaling the beginning of the trial. This is followed by a delay period lasting either 1 or 1.5 seconds, during which the mouse must restrict from licking the left or right spouts. If the mouse licks prematurely, the trial pauses for 300ms. After delay, a 6 kHz pure tone lasting up to 2000ms is played from the top buzzer, prompting the mouse to choose by licking either the left or right spout. The first lick during this period is registered as choice for this trial, followed by an auditory cue lasting 50ms (3 kHz for left, 10 kHz for right). If the choice matches the assigned reward direction, a 0.25μL water reward is dispensed from the corresponding spout.</p>
<p>In this task, mice are unable to obtain any useful cues from single trial to make a rewarded choice. All rewards in individual trials are randomly assigned to the left or right spouts according to default probabilities. We use a minimum of 500 trials per rotation, during which the reward probabilities for left and right spouts are rotated in the following sequence: {60:10}, {52.5:17.5}, {10:60}, and {17.5:52.5}. Additionally, mice cannot obtain rewards from one spout if the reward allocated to the other spout has not yet been consumed. Only when the mouse chooses the spout with the higher reward probability in more than 50% probabilities, the rotation advances. As the mouse’s performance hits criteria, the frequency of rotations increases, starting from minimum every 500 trials and gradually decreasing to every 100 trials.</p>
</sec>
<sec id="s10a2">
<title>Contingency reversal learning</title>
<p>In <xref rid="fig3" ref-type="fig">Figure 3A</xref>, we extended the self-initiated paradigm (as shown in Fig. S3) by introducing multiple reversals in the relationship between stimulus and action. Specifically, when a mouse achieves an accuracy rate of over 75% in the most recent 100 trials, the association between sound frequency and reward direction is immediately reversed, while the trial structure and parameters remain unchanged. The mouse receives no additional cues indicating the rule reversal, relying solely on reward and error feedback to adapt. Subsequently, the contingency is reversed each time the mouse reaches the specified accuracy under the current rule.</p>
</sec>
<sec id="s10a3">
<title>Working Memory Task</title>
<p>In <xref rid="fig3" ref-type="fig">Figure 3B</xref>, the mouse begins by licking the central spout to initiate a trial. After a brief delay, the first stimulus is presented, lasting 500ms, and consisting of a sequence of regular clicks. This is followed by a 200ms delay period, during which the mouse must refrain from licking the side spouts. Any licking during this delay immediately terminates the trial and results in a noise burst and a timeout penalty. Following the delay, a second 500ms stimulus of regular clicks is presented. The mouse must then wait for a brief response cue after the delay and indicate its choice by licking either side spout, receiving feedback based on its decision: correct choices yield a water reward, while incorrect choices trigger a 500ms noise burst and a timeout. The correct choice is determined by comparing the click rates of the two stimuli—when the first stimulus has a higher click rate, the reward is on the right side, and when it is lower, the reward is on the left.</p>
<p>The trial types are generated using an anti-bias algorithm to determine the left or right reward direction, after which one of the four possible click rates for that direction is randomly selected as the stimulus for the current trial. The SGM comprises five click rates separated by octave intervals: 8, 16, 32, 64, and 128 Hz.</p>
<p>During the testing phase, the delay period is randomly sampled between 500 and 2000ms. Additionally, in half of the trials, the click rate of the second stimulus is fixed at 32 Hz, while the click rate of the first stimulus is randomly sampled from the set {16, 20, 25, 32, 40, 50, 64 Hz}. If the first click rate is set at 32 Hz, the rewarded choice is randomly assigned to the left or right spout.</p>
<p>In Figure S5, a 3×3 SGM was used with a two-octave difference between the click rates of the first and second stimuli. After training, a certain percentage of probe trials were introduced, where the click rates of the two stimuli were identical, and the reward direction was randomly assigned. The mouse’s performance in these probe trials was at chance level, indicating that the mouse indeed relied on comparing the frequencies of the two stimuli to complete the task.</p>
</sec>
<sec id="s10a4">
<title>Evidence accumulation</title>
<p>In <xref rid="fig3" ref-type="fig">Fig. 3C, a</xref> new trial block is initiated when a mouse licks either of the two spouts. After a brief delay (200-500ms), independent click sequences, following an exponential distribution with predefined parameters, are generated from speakers on both sides. After a second brief delay period, a response cue signals the mouse to choose by licking either the left or right spout. The mouse should select the left spout if the click rate on the left is higher, and the right spout if the click rate on the right is higher. Correct choices are immediately rewarded with 0.25 µl of water at the corresponding spout, while incorrect choices result in a noise burst and a timeout penalty.</p>
<p>The 1000ms sample period is divided into 40 bins, each lasting 25ms. To approximate a discrete event sequence with an exponential distribution, a coin-flip method is used for each bin to determine whether a click event occurs, based on the set probability. Each click event consists of a 10ms, 10 kHz auditory cue followed by a 15ms interval. The hazard rates for generating clicks on the left and right sides are randomly selected from {39:1, 37:3, 31:9, 26:14}. The onset time of the clicks is randomly chosen from within the first 0 to 900ms of the sample period, in 100ms increments.</p>
</sec>
<sec id="s10a5">
<title>Evidence accumulation with multimodal integration</title>
<p>In <xref rid="fig3" ref-type="fig">Fig. 3D, a</xref> trial block is initiated when the mouse licks either the left or right spout. After a brief delay, a top speaker emits click sequences following an exponential distribution, while both the left and right white LEDs flash according to the same event sequence. Following the delay period, a response cue indicates the start of the response period, during which the mouse must decide if the event rate exceeds 12 clicks per second. If the event rate is below 12, the mouse should choose the left spout; if it is above 12, the right spout should be chosen. For trials where the event rate is exactly 12, the reward is randomly assigned to either the left or right spout.</p>
<p>The sample period is divided into 40 bins, each lasting 40ms. Similar to the previous task, a coin-flip method is used to approximate the exponential distribution of discrete event sequences, determining whether a multimodal event occurs in each bin. Each multimodal event consists of 20ms light flash paired with an auditory click, followed by 20ms interval. For trials where the reward is assigned to the left spout, the hazard rate for event sequence generation is 4; for trials with the reward on the right spout, the hazard rate is 20. The sample period lasts for 1600ms, with the event onset fixed at 600ms to ensure that the events continue for 1000ms.</p>
<p>During the testing phase, a portion of the trials had event onset times randomly selected from 0, 400, 800, or 1200ms after the start. We also tested the mouse’s performance under unimodal conditions, using only clicks or only flashes as stimuli. To verify the effect of multimodal integration, we adjusted the sound decibel level (by controlling PWM duty cycle) for clicks and the brightness (by controlling PWM amplitude) for flashes to achieve similar performance levels under unimodal conditions. We then examined whether there was an enhancement effect under multimodal stimulation with these parameter settings.</p>
</sec>
<sec id="s10a6">
<title>Confidence-proved task</title>
<p>In <xref rid="fig3" ref-type="fig">Fig. 3E</xref>, mice initiated each trial by licking the central spout, while suppressing licking of the lateral spouts for a brief period. Following this, a sound stimulus ranging from 8 kHz to 32 kHz was emitted from the top buzzer for a duration of up to 1000ms. During the first 250ms of the stimulus, the mice had to inhibit any early licks. Failure to do so triggered 100ms noise cue, prematurely terminated the current trial, and imposed a timeout penalty lasting 3 to 7 seconds. The mice’s first choice of either the left or right spout after the 250ms sample period was recorded as their decision, ending the stimulus. If the choice was correct, a small reward (approximately 0.25μL) was delivered at the corresponding spout after a brief delay. The mice then had to confirm their decision by licking the rewarded spout within 1000ms to receive a second reward (0.25μL); failure to confirm was treated as a no-response trial. During the delay, mice were required to maintain their choice, refraining from licking any other spout. Licking a non-chosen spout during the delay was interpreted as forfeiture of the decision, resulting in the termination of the trial. If the central spout was licked during this period, the trial ended immediately and a new trial began. For correct choices, the delay duration was sampled from an exponential distribution with a maximum of 5000ms, a minimum of 500ms, and an average of 1000ms. For incorrect choices, the delay was fixed at 20 seconds, with no additional error feedback provided; mice had to lick the other spouts twice to terminate the trial. Trials where mice did not actively terminate within 20 seconds were classified as no-response trials. During the sample period, the task was to discriminate whether the sound frequency exceeded 16 kHz, indicating a right spout choice, or was below 16 kHz, indicating a left spout choice. The frequency range was logarithmically partitioned around the 16 kHz midpoint into nine intervals: {-1, –0.6, –0.2, –0.1, 0, 0.1, 0.2, 0.6, 1}. Negative values corresponded to a left choice, positive values to a right choice, and 0 represented a random choice between left and right. During the testing phase, a certain percentage of the trials were designated as probe trials: when the mice made a correct choice, the delay was set to 20 seconds, and the first reward was omitted. The mice were required to lick another spout to terminate these trials.</p>
</sec>
<sec id="s10a7">
<title>Continual training</title>
<p>In <xref rid="fig4" ref-type="fig">Fig. 4A</xref>, mice initiated a new trial by licking the central spout, followed by a brief delay before entering the sample period. During the first 350ms of both the delay and sample period, the mice were required to refrain from licking the lateral spouts; doing so resulted in a noise cue and a timeout penalty. After the first 350ms of the sample period, the first lick on either lateral spout was recorded as the mouse’s choice for that trial, marking the end of the sample period. A correct choice resulted in 0.25μL water reward at the corresponding spout, while an incorrect choice triggered a noise cue and a timeout penalty. The stimuli presented during the sample period followed a specific sequence: sound frequency discrimination (3 kHz vs. 12 kHz), followed by reversed sound frequencies (12 kHz vs. 3 kHz), sound direction (left vs. right), reversed sound direction (right vs. left), and finally, light direction (left vs. right). Progression to the next stimulus condition occurred only when the mice achieved and maintained a performance accuracy above 75% in the previous discrimination task.</p>
</sec>
<sec id="s10a8">
<title>DMS</title>
<p>In <xref rid="fig4" ref-type="fig">Fig. 4B</xref>, mice initiated a trial block by licking either the left or right spout. After a brief delay, they entered a 500ms sample period, during which a sound stimulus of either 3 kHz or 12 kHz was emitted from the top buzzer. Following this, a 1-second delay period began, during which licking either the left or right spout caused the trial to pause for 300ms. The delay period was followed by a 500ms test period, with another 3 kHz or 12 kHz sound stimulus delivered from the top buzzer. This was followed by a second 1-second delay period, during which the mice were again required to refrain from licking the lateral spouts. A brief response cue then indicated that the mice could express their choice by licking either the left or right spout. A correct choice resulted in 0.25μL water reward, while an incorrect choice led to a noise cue and a timeout penalty. When the sound frequencies presented during the sample and test periods were identical, the correct choice was the left spout. When the frequencies differed, the correct choice was the right spout. During the testing phase, the durations of the two delay periods were independently and randomly sampled from {1, 1.5, 2, 2.5, 3s}.</p>
</sec>
<sec id="s10a9">
<title>d3AFC</title>
<p>In <xref rid="fig4" ref-type="fig">Fig. 4C, a</xref> paradigm similar to that described in <xref rid="fig2" ref-type="fig">Fig. 2A</xref> was used, but with three possible choices. Mice could initiate a trial block by licking any of the three spouts. The task required them to discriminate between three different sound frequencies: 8 kHz, 16 kHz, and 32 kHz, with the corresponding spouts being left, center, and right, respectively, to receive a reward. During the testing phase, stimuli were logarithmically spaced around the 16 kHz midpoint, with values expanded to {-1, –0.75, –0.5, –0.25, 0, 0.25, 0.5, 0.75, 1}.</p>
    <p>Frequencies corresponding to {-1, –0.75, –0.5} indicated a left spout choice; {-0.25, 0, 0.25} indicated a center spout choice; and {0.5, 0.75, 1} indicated a right spout choice. In <xref ref-type="fig" rid="figs5">Fig. S5C</xref>, for some mice that did not undergo the psychometric curve testing phase, the left and right stimulus-choice associations were reversed after they had learned the initial task, while the center stimulus-choice association remained unchanged. Whenever the mice achieved a 75% accuracy rate across all three trial types and maintained it for some time, the left-right stimulus-choice associations were immediately reversed again. Mice could only detect these reversals through trial feedback, with no additional cues indicating changes in task rules.</p>
</sec>
<sec id="s10a10">
<title>Delayed Context-dependent task</title>
<p>In <xref rid="fig4" ref-type="fig">Fig. 4D</xref>, mice triggered a new trial by licking the central spout. After a brief delay, 500ms rule-indicating clicks stimulus was emitted from the top buzzer. This was followed by a delay period during which the mice were required to suppress licking the lateral spouts; otherwise, the current trial would end, accompanied by a noise cue and timeout penalty. Subsequently, 200ms auditory cue (3 kHz or 12 kHz) was delivered from either the left or right buzzer. Mice could report their choice 100ms into this cue. A correct choice resulted in 0.25μL water reward at the chosen spout, while an incorrect choice led to a noise cue and timeout penalty.</p>
<p>The click stimulus represented different task rules based on its frequency: 16 Hz clicks indicated that the mice should make their choice based on the direction of the sound, while 64 Hz clicks indicated that the reward was associated with the sound frequency. When the trial required attention to sound direction, the mice needed to choose based on the sound source location (left buzzer for left spout, right buzzer for right spout), ignoring the sound frequency. Conversely, for trials requiring attention to sound frequency, the mice had to discriminate the sound frequency (3 kHz for left, 12 kHz for right) to make their choice. The context and sample periods were separated by a 250ms delay period. Trials where the correct choices based on direction and frequency aligned were termed “coherent trials,” while those where they conflicted were termed “conflict trials.” Trials involving only one modality of stimulus were termed “unimodal trials” (for single sound direction trials, the frequency was set at 6 kHz; for single frequency trials, the sound was delivered from the top buzzer). Trials were randomly presented as 10% unimodal, 70% conflict, and 20% coherent, with mice required to achieve 75% accuracy on conflict trials.</p>
<p>During the testing phase, the delay duration was randomly chosen from a range of 200ms to 2000ms. Additionally, the click rate, representing the context, was extended to {16, 20, 25, 32, 40, 50, 64 Hz}, where rates below 32 Hz indicated attention to sound direction and rates above 32 Hz indicated attention to sound frequency. For trials with a 32 Hz click rate, the reward choice was randomly linked to either sound direction or frequency.</p>
<fig id="figs1" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Fig. S1.</label>
<caption><title>HABITS system.</title><p>(<bold>A</bold>) Block diagram of control system of HABITS, showing peripherals connected with microcontroller through digital input/output (DIO) or serial port. (<bold>B</bold>) Graphic user interface (GUI) of a specific cage (left, magnified) and data plot window (right) when click ‘plot’ button in the GUI, showing daily performance in all previous days, trial performance (green for correct and red for error trials) in last 24 hours, and body weight data in last 24 hours. (<bold>C</bold>) Example protocol programs for HABITS. (<bold>D</bold>) Around 100 HABITS are packed on standard racks for large-scale mouse behavioral testing. (<bold>E</bold>) Workflow pipeline for HABITS, showing fully autonomous mouse behavioral training after initialization of HABITS, before data harvest from SD card for analysis.</p></caption>
<graphic xlink:href="615652v3_figs1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs2" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Fig. S2.</label>
<caption><title>Autonomous versus manual training in home-cage.</title><p>(A), Flow chart of the task training protocol in home-cage (Materials and Methods). (B), Logistic regression model. (C), top, behavioral performance of example mouse in the autonomous training. Bottom, the significance of individual regressors; Circle size corresponds to p values; The significance of a regressor is evaluated by comparing the prediction of the full model to a partial model with the regressor of interest excluded. <italic>p</italic>-values are based on cross-validation t-test (Materials and methods). (D), percentage of trials significantly predicted by different regressors during task learning. Cycles and light lines, individual mice; Bars and bold lines, average across mice; Shades and error bars, 0.95 CI. *, p&lt;0.05, n.s., p&gt;0.05, two-sided Wilcoxon rank-sum tests. (E), averaged water harvested per day (left) and number of trials per day (right) changing from manual to autonomous training in home-cage. Cycles, individual mice; Bar plot and error bar, mean and 0.95 CI across mice. (F), averaged relative body weights as a function of training days for free water (blue) and all d2AFC training mice (black). Shaded area shows 95% CI. (G), performance of all 6 female mice performing d2AFC task in home-cage automatically. (H), The histogram of inter-trial-interval for both autonomous and manual training in HABITS.</p></caption>
<graphic xlink:href="615652v3_figs2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs3" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Fig. S3.</label>
<caption><title>Reaction time based 2AFC task training in home-cage automatically.</title><p>(<bold>A</bold>), task structure of RT-based 2AFC task. (B), Flow chart of training protocol in home-cage. (C), conditioned behavioral data of example trials for correct (blue block) and error (red block) choice. (D), performance of example mouse performing task in home-cage. The color of background corresponding to (B). Grey blocks indicate dark cycle. Grey dash line, the criterion performance. Red horizontal dash line, chance performance level. (E), correct rate of all mice. (F), reaction time of all mice. Black line fitting to all mice from the onset to the end of training. (G), histogram of reaction time. Data collected from all mice. The bold vertical line represents the median of RT. (H), conditioned histogram of inter-trial-interval (ITI) for correct (blue) and error (red) trials.</p></caption>
<graphic xlink:href="615652v3_figs3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs4" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Fig. S4.</label>
<caption><title>Value-based dynamic foraging task.</title><p>(<bold>A</bold>), task structure. (<bold>B</bold>), example performance of a mouse in the early (top, first 6000 trials) and late (bottom, last 6000 trials) training stages with block size 500. Blue lines represent moving averaged behavioral probability of left choice within 40 trials. Purple lines show the assignment probability for left reward. (<bold>C</bold>), averaged probability of the choosing the lickport with the higher assignment probability (P(high)) across mice gradually increases following the number of trials. Black line indicates the assignment probability for left and right lickports is 60% (grey line, 52.5%) and 10% (grey line, 17.5%), respectively. Dots and errorbar, mean and 95% CI. (<bold>D</bold>), left, averaged P(high) across mice follows training sub-protocols with different block size. Right, the number of days to complete all training protocols from block size 500 to 100. Square dots indicate individual mice. (<bold>E</bold>), same as (B) but data collected from the sub-protocol with block size 100.</p></caption>
<graphic xlink:href="615652v3_figs4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs5" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Fig. S5.</label>
<caption><title>Other complex cognitive behavioral tasks training in home-cage automatically.</title><p>(A), Left, stimulus generation matrix of working memory task. Middle, number of days to train. Right, correct rate for SGM. Values lying in the diagonal line corresponding to the correct rate of probe trials. (B), Top, d3AFC task according to sound orientation and number of days to reach the criterion performance. Dots indicate individual mice. Performance (Middle) and earlylick rate (bottom) of all mice performing the d3AFC task. Red dash line, chance performance level; Grey dash line, the criterion performance. (C), Left, contingency reversal of d3AFC task according sound frequency (top) and performance of an example mouse (bottom). Right, averaged correct rate across all mice for different reverse times (top). Number of trials needed to learn as a function of reverse training times (bottom). Dots, individual mice. Line and shades, linear regression.</p></caption>
<graphic xlink:href="615652v3_figs5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs6" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Fig. S6.</label>
<caption><title>Simulation of machine teaching algorithm in decision-making scenario.</title><p>(<bold>A</bold>). the weight of regressors in an ideal learner vary during learning a 2AFC task. Note that the initial weights of bias and S1 regressors are not zero. (<bold>B</bold>), the presented trial types generated by random (black) and MT (red) during entire training process. (<bold>C</bold>), same as (A) but weights of all regressors begin at zero.</p></caption>
<graphic xlink:href="615652v3_figs6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figs7" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Fig. S7.</label>
<caption><title>Details of behavioral analysis for multi-dimensional tasks.</title><p>(<bold>A</bold>), left, linear regression between trial number and correct rate in task requiring mice attend to sound frequency. Right, the R-square of every individual linear regression. (<bold>B</bold>), same as (A) but for performance following non-relative cue. (<bold>C</bold>), the number of trials to reach criterion performance for MT and random group. (<bold>D</bold>), performance of both grouped mice in T1 and T2 protocol. n.s., no significant. two-sided Wilcoxon rank-sum tests. (<bold>E</bold>), the presented individual trials with Stay/Switch (top) and Left/Right (bottom) trial type generated by MT (L3) and Random (T2). (<bold>F</bold>, <bold>G</bold>), After mice were trained by MT as in <xref rid="fig6" ref-type="fig">fig. 6A</xref>, they were intermediately set the training protocol to the beginning and retrained with randomly generated trial sequence. We compared correct rate of trials with sound frequency stimulus in the first and the second training, presented in (F). (G) shows the learning rate (left) and training efficiency (right) of the first and the second training processes. **, p&lt;0.01; two-sided Wilcoxon signed-rank tests. (<bold>H</bold>), correct rate of both grouped mice for stay and switch trials in T2 protocol. n.s., no significant. two-sided Wilcoxon rank-sum tests.</p></caption>
<graphic xlink:href="615652v3_figs7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<table-wrap id="tbls1" orientation="portrait" position="float">
<label>Supplementary Table S1.</label>
<caption><title>Building materials of HABITS.</title></caption>
<graphic xlink:href="615652v3_tbls1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
</sec>
</sec>
<sec id="s9" sec-type="data-availability">
<title>Data and materials availability</title>
<p>The guidance for construction of HABITS, all the training programs, and example behavioral data are available on GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/Yaoyao-Hao/HABITS">https://github.com/Yaoyao-Hao/HABITS</ext-link>). The general-purpose state machine runner for training animal behaviors (gpSMART) is also available on GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/Yaoyao-Hao/gpSMART">https://github.com/Yaoyao-Hao/gpSMART</ext-link>). All data in the main text or the supplementary materials are available on <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.27192897">https://doi.org/10.6084/m9.figshare.27192897</ext-link>.</p>
</sec>
<sec id="d1e2520" sec-type="additional-information">
<title>Additional information</title>
<sec id="s6">
<title>Funding</title>
<p>This work was supported by STI 2030—Major Projects (2021ZD0200405), National Natural Science Foundation of China (62336007), Pioneer R&amp;D Program of Zhejiang (2024C03001), the Starry Night Science Fund of Zhejiang University Shanghai Institute for Advanced Study (SN-ZJU-SIAS-002), and the Fundamental Research Funds for the Central Universities (2023ZFJH01-01, 2024ZFJH01-01).</p>
</sec>
<sec id="s7">
<title>Author contributions</title>
<p>Conceptualization: BY, YH; Methodology: BY, KX, YW, YH; Investigation: BY, PL, HX, YH; Visualization: BY, YH; Supervision: KX, YW, YH; Writing—original draft: BY, YH; Writing—review &amp; editing: BY, KX, YW, YH.</p>
</sec>
</sec>
<sec id="suppd1e2520" sec-type="supplementary-material">
<title>Additional files</title>
<supplementary-material id="d1e2490">
<label>Supplemental video 1</label>
    <caption><title>Free moving mouse performing task in HABITS.</title></caption>
<media xlink:href="supplements/615652_file02.mp4"/>
</supplementary-material>
<supplementary-material id="d1e2497">
<label>Supplemental video 2</label>
    <caption><title>The 24-hour activities of mouse living in HABITS.</title></caption>
<media xlink:href="supplements/615652_file03.mp4"/>
</supplementary-material>
<supplementary-material id="d1e2504">
<label>old Supplemental video 1</label>
<media xlink:href="supplements/615652_file04.mp4"/>
</supplementary-material>
<supplementary-material id="d1e2511">
<label>old Supplemental video 2</label>
<media xlink:href="supplements/615652_file05.mp4"/>
</supplementary-material>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carandini</surname>, <given-names>M</given-names></string-name></person-group>. <article-title>From circuits to behavior: a bridge too far?</article-title> <source>Nat. Neurosci</source>. <volume>15</volume>, <fpage>507</fpage>–<lpage>509</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krakauer</surname>, <given-names>J. W.</given-names></string-name>, <string-name><surname>Ghazanfar</surname>, <given-names>A. A.</given-names></string-name>, <string-name><surname>Gomez-Marin</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>MacIver</surname>, <given-names>M. A.</given-names></string-name> &amp; <string-name><surname>Poeppel</surname>, <given-names>D</given-names></string-name></person-group>. <article-title>Neuroscience Needs Behavior: Correcting a Reductionist Bias</article-title>. <source>Neuron</source> <volume>93</volume>, <fpage>480</fpage>–<lpage>490</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Niv</surname>, <given-names>Y</given-names></string-name></person-group>. <article-title>The primacy of behavioral research for understanding the brain</article-title>. <source>Behav. Neurosci</source>. <volume>135</volume>, <fpage>601</fpage>–<lpage>609</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nau</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Schmid</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Kaplan</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Baker</surname>, <given-names>C. I.</given-names></string-name> &amp; <string-name><surname>Kravitz</surname>, <given-names>D. J</given-names></string-name></person-group>. <article-title>Centering cognitive neuroscience on task demands and generalization</article-title>. <source>Nat. Neurosci</source>. <fpage>1</fpage>–<lpage>12</lpage> (<year>2024</year>) doi:<pub-id pub-id-type="doi">10.1038/s41593-024-01711-6</pub-id>.</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vázquez-Guardado</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Bandodkar</surname>, <given-names>A. J.</given-names></string-name> &amp; <string-name><surname>Rogers</surname>, <given-names>J. A</given-names></string-name></person-group>. <article-title>Recent advances in neurotechnologies with broad potential for neuroscience research</article-title>. <source>Nat. Neurosci</source>. <volume>23</volume>, <fpage>1522</fpage>–<lpage>1536</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tanji</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Evarts</surname>, <given-names>E. V</given-names></string-name></person-group>. <article-title>Anticipatory activity of motor cortex neurons in relation to direction of an intended movement</article-title>. <source>J. Neurophysiol</source>. <volume>39</volume>, <fpage>1062</fpage>–<lpage>1068</lpage> (<year>1976</year>).</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guo</surname>, <given-names>Z. V.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Flow of Cortical Activity Underlying a Tactile Decision in Mice</article-title>. <source>Neuron</source> <volume>81</volume>, <fpage>179</fpage>–<lpage>194</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Svoboda</surname>, <given-names>K.</given-names></string-name> &amp; <string-name><surname>Li</surname>, <given-names>N</given-names></string-name></person-group>. <article-title>Neural mechanisms of movement planning: motor cortex and beyond</article-title>. <source>Curr. Opin. Neurobiol</source>. <volume>49</volume>, <fpage>33</fpage>–<lpage>41</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guo</surname>, <given-names>Z. V.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Procedures for Behavioral Experiments in Head-Fixed Mice</article-title>. <source>PLOS One</source> <volume>9</volume>, <fpage>e88678</fpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Balcombe</surname>, <given-names>J. P.</given-names></string-name>, <string-name><surname>Barnard</surname>, <given-names>N. D.</given-names></string-name> &amp; <string-name><surname>Sandusky</surname>, <given-names>C</given-names></string-name></person-group>. <article-title>Laboratory Routines Cause Animal Stress</article-title>. <source>J. Am. Assoc. Lab. Anim. Sci</source>. <volume>43</volume>, <fpage>42</fpage>–<lpage>51</lpage> (<year>2004</year>).</mixed-citation></ref>
    <ref id="c11"><label>11.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Findling</surname>, <given-names>C.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Brain-wide representations of prior information in mouse decision-making</article-title>. <source>bioRxiv</source> Preprint at <pub-id pub-id-type="doi">10.1101/2023.07.04.547684</pub-id> (<year>2023</year>).</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Han</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Zhu</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>Y.</given-names></string-name> &amp; <string-name><surname>Li</surname>, <given-names>C. T</given-names></string-name></person-group>. <article-title>High-Throughput Automatic Training System for Odor-Based Learned Behaviors in Head-Fixed Mice</article-title>. <source>Front. Neural Circuits</source> <volume>12</volume>, (<year>2018</year>).</mixed-citation></ref>
    <ref id="c13"><label>13.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Laboratory</surname>, <given-names>I. B.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>A Brain-Wide Map of Neural Activity during Complex Behaviour</article-title>. <source>bioRxiv</source> Preprint at <pub-id pub-id-type="doi">10.1101/2023.07.04.547681</pub-id> (<year>2023</year>).</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mah</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Schiereck</surname>, <given-names>S. S.</given-names></string-name>, <string-name><surname>Bossio</surname>, <given-names>V.</given-names></string-name> &amp; <string-name><surname>Constantinople</surname>, <given-names>C. M</given-names></string-name></person-group>. <article-title>Distinct value computations support rapid sequential decisions</article-title>. <source>Nat. Commun</source>. <volume>14</volume>, <fpage>7573</fpage> (<year>2023</year>).</mixed-citation></ref>
    <ref id="c15"><label>15.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Mohammadi</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Ashwood</surname>, <given-names>Z. C.</given-names></string-name>, <string-name><surname>Laboratory</surname>, <given-names>T. I. B.</given-names></string-name> &amp; <string-name><surname>Pillow</surname>, <given-names>J. W</given-names></string-name></person-group>. <article-title>Identifying the factors governing internal state switches during nonstationary sensory decision-making</article-title>. <source>biorxiv</source> Preprint at <pub-id pub-id-type="doi">10.1101/2024.02.02.578482</pub-id> (<year>2024</year>).</mixed-citation></ref>
    <ref id="c16"><label>16.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Pan-Vazquez</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Pre-existing visual responses in a projection-defined dopamine population explain individual learning trajectories</article-title>. <source>bioRxiv</source> Preprint at <pub-id pub-id-type="doi">10.1101/2024.02.26.582199</pub-id> (<year>2024</year>).</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rich</surname>, <given-names>P. D.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Magnetic voluntary head-fixation in transgenic rats enables lifespan imaging of hippocampal neurons</article-title>. <source>Nat. Commun</source>. <volume>15</volume>, <fpage>4154</fpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Scott</surname>, <given-names>B. B.</given-names></string-name>, <string-name><surname>Brody</surname>, <given-names>C. D.</given-names></string-name> &amp; <string-name><surname>Tank</surname>, <given-names>D. W</given-names></string-name></person-group>. <article-title>Cellular Resolution Functional Imaging in Behaving Rats Using Voluntary Head Restraint</article-title>. <source>Neuron</source> <volume>80</volume>, <fpage>371</fpage>–<lpage>384</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><collab>The International Brain Laboratory</collab> <etal>et al.</etal></person-group> <article-title>Standardized and reproducible measurement of decision-making in mice</article-title>. <source>eLife</source> <volume>10</volume>, <elocation-id>e63711</elocation-id> (<year>2021</year>). <pub-id pub-id-type="doi">10.7554/eLife.63711</pub-id></mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Wu</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Jeong</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Burke</surname>, <given-names>D. A.</given-names></string-name> &amp; <string-name><surname>Namboodiri</surname>, <given-names>V. M. K</given-names></string-name></person-group>. <article-title>An open-source behavior controller for associative learning and memory (B-CALM)</article-title>. <source>Behav. Res. Methods</source> (<year>2023</year>) doi:<pub-id pub-id-type="doi">10.3758/s13428-023-02182-6</pub-id>.</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Aoki</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Tsubota</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Goya</surname>, <given-names>Y.</given-names></string-name> &amp; <string-name><surname>Benucci</surname>, <given-names>A</given-names></string-name></person-group>. <article-title>An automated platform for high-throughput mouse behavior and physiology with voluntary head-fixation</article-title>. <source>Nat. Commun</source>. <volume>8</volume>, <fpage>1196</fpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bernhard</surname>, <given-names>S. M.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>An automated homecage system for multiwhisker detection and discrimination learning in mice</article-title>. <source>PLOS One</source> <volume>15</volume>, <fpage>e0232916</fpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bollu</surname>, <given-names>T.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Automated home cage training of mice in a hold-still center-out reach task</article-title>. <source>J. Neurophysiol</source>. <volume>121</volume>, <fpage>500</fpage>–<lpage>512</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Caglayan</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Stumpenhorst</surname>, <given-names>K.</given-names></string-name> &amp; <string-name><surname>Winter</surname>, <given-names>Y</given-names></string-name></person-group>. <article-title>Learning Set Formation and Reversal Learning in Mice During High-Throughput Home-Cage-Based Olfactory Discrimination</article-title>. <source>Front. Behav. Neurosci</source>. <volume>15</volume>, (<year>2021</year>).</mixed-citation></ref>
    <ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Francis</surname>, <given-names>N. A.</given-names></string-name>, <string-name><surname>Bohlke</surname>, <given-names>K.</given-names></string-name> &amp; <string-name><surname>Kanold</surname>, <given-names>P. O.</given-names></string-name></person-group> <article-title>Automated Behavioral Experiments in Mice Reveal Periodic Cycles of Task Engagement within Circadian Rhythms</article-title><source>eneuro</source> <elocation-id>ENEURO.0121-19.2019</elocation-id> (<year>2019</year>) doi:<pub-id pub-id-type="doi">10.1523/ENEURO.0121-19.2019</pub-id>.</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Francis</surname>, <given-names>N. A.</given-names></string-name> &amp; <string-name><surname>Kanold</surname>, <given-names>P. O</given-names></string-name></person-group>. <article-title>Automated Operant Conditioning in the Mouse Home Cage</article-title>. <source>Front. Neural Circuits</source> <volume>11</volume>, <fpage>10</fpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hao</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Thomas</surname>, <given-names>A. M.</given-names></string-name> &amp; <string-name><surname>Li</surname>, <given-names>N</given-names></string-name></person-group>. <article-title>Fully autonomous mouse behavioral and optogenetic experiments in home-cage</article-title>. <source>eLife</source> <volume>10</volume>, <elocation-id>e66112</elocation-id> (<year>2021</year>). <pub-id pub-id-type="doi">10.7554/eLife.66112</pub-id></mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kiryk</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>IntelliCage as a tool for measuring mouse behavior – 20 years perspective</article-title>. <source>Behav. Brain Res</source>. <volume>388</volume>, <fpage>112620</fpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Murphy</surname>, <given-names>T. H.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Automated task training and longitudinal monitoring of mouse mesoscale cortical circuits using home cages</article-title>. <source>eLife</source> <volume>9</volume>, <elocation-id>e55964</elocation-id> (<year>2020</year>). <pub-id pub-id-type="doi">10.7554/eLife.55964</pub-id></mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Murphy</surname>, <given-names>T. H.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>High-throughput automated home-cage mesoscopic functional imaging of mouse cortex</article-title>. <source>Nat. Commun</source>. <volume>7</volume>, <fpage>11611</fpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Poddar</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Kawai</surname>, <given-names>R.</given-names></string-name> &amp; <string-name><surname>Ölveczky</surname>, <given-names>B. P</given-names></string-name></person-group>. <article-title>A Fully Automated High-Throughput Training System for Rodents</article-title>. <source>PLoS ONE</source> <volume>8</volume>, <fpage>e83171</fpage> (<year>2013</year>).</mixed-citation></ref>
    <ref id="c32"><label>32.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Qiao</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Mouse Academy: high-throughput automated training and trial-by-trial behavioral analysis during learning</article-title>. <source>bioRxiv</source> Preprint at <pub-id pub-id-type="doi">10.1101/467878</pub-id> (<year>2019</year>).</mixed-citation></ref>
    <ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Salameh</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Jeffers</surname>, <given-names>M. S.</given-names></string-name>, <string-name><surname>Wu</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Pitney</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Silasi</surname>, <given-names>G</given-names></string-name></person-group>. <article-title>The Home-Cage Automated Skilled Reaching Apparatus (HASRA): Individualized Training of Group-Housed Mice in a Single Pellet Reaching Task</article-title>. <source>eneuro</source> <volume>7</volume>, <elocation-id>ENEURO.0242-20.2020</elocation-id> (<year>2020</year>).</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Silasi</surname>, <given-names>G.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Individualized tracking of self-directed motor learning in group-housed mice performing a skilled lever positioning task in the home cage</article-title>. <source>J. Neurophysiol</source>. <volume>119</volume>, <fpage>337</fpage>–<lpage>346</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jankowski</surname>, <given-names>M. M.</given-names></string-name>, <string-name><surname>Polterovich</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kazakov</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Niediek</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Nelken</surname>, <given-names>I</given-names></string-name></person-group>. <article-title>An automated, low-latency environment for studying the neural basis of behavior in freely moving rats</article-title>. <source>BMC Biol</source>. <volume>21</volume>, <fpage>172</fpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schaefer</surname>, <given-names>A. T.</given-names></string-name> &amp; <string-name><surname>Claridge-Chang</surname>, <given-names>A</given-names></string-name></person-group>. <article-title>The surveillance state of behavioral automation</article-title>. <source>Curr. Opin. Neurobiol</source>. <volume>22</volume>, <fpage>170</fpage>–<lpage>176</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Do</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Jung</surname>, <given-names>M. W.</given-names></string-name> &amp; <string-name><surname>Lee</surname>, <given-names>D</given-names></string-name></person-group>. <article-title>Automating licking bias correction in a two-choice delayed match-to-sample task to accelerate learning</article-title>. <source>Sci. Rep</source>. <volume>13</volume>, <fpage>22768</fpage> (<year>2023</year>).</mixed-citation></ref>
    <ref id="c38"><label>38.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Zhu</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Singla</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Zilles</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Rafferty</surname>, <given-names>A. N</given-names></string-name></person-group>. <article-title>An Overview of Machine Teaching</article-title>. <source>arxiv</source> <pub-id pub-id-type="doi">10.48550/arXiv.1801.05927</pub-id> (<year>2018</year>).</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Bak</surname>, <given-names>J. H.</given-names></string-name>, <string-name><surname>Choi</surname>, <given-names>J. Y.</given-names></string-name>, <string-name><surname>Akrami</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Witten</surname>, <given-names>I.</given-names></string-name> &amp; <string-name><surname>Pillow</surname>, <given-names>J. W.</given-names></string-name></person-group> <article-title>Adaptive optimal training of animal behavior</article-title>. In <conf-name>Advances in Neural Information Processing Systems</conf-name>, <year>2016</year>).</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jha</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Ashwood</surname>, <given-names>Z. C.</given-names></string-name> &amp; <string-name><surname>Pillow</surname>, <given-names>J. W</given-names></string-name></person-group>. <article-title>Active Learning for Discrete Latent Variable Models</article-title>. <source>Neural Comput</source>. <volume>36</volume>, <fpage>437</fpage>–<lpage>474</lpage> (<year>2024</year>).</mixed-citation></ref>
    <ref id="c41"><label>41.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Liu</surname>, <given-names>W.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Iterative Machine Teaching</article-title>. in <conf-name>Proceedings of the 34th International Conference on Machine Learning</conf-name> <fpage>2149</fpage>–<lpage>2158</lpage> (<publisher-name>PMLR</publisher-name>, <year>2017</year>).</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Roy</surname>, <given-names>N. A.</given-names></string-name>, <string-name><surname>Bak</surname>, <given-names>J. H.</given-names></string-name>, <string-name><surname>Akrami</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Brody</surname>, <given-names>C. D.</given-names></string-name> &amp; <string-name><surname>Pillow</surname>, <given-names>J. W</given-names></string-name></person-group>. <article-title>Extracting the dynamics of behavior in sensory decision-making experiments</article-title>. <source>Neuron</source> <volume>109</volume>, <fpage>597</fpage>–<lpage>610.e6</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Inagaki</surname>, <given-names>H. K.</given-names></string-name>, <string-name><surname>Inagaki</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Romani</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Svoboda</surname>, <given-names>K</given-names></string-name></person-group>. <article-title>Low-Dimensional and Monotonic Preparatory Activity in Mouse Anterior Lateral Motor Cortex</article-title>. <source>J. Neurosci</source>. <volume>38</volume>, <fpage>4163</fpage>–<lpage>4185</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Munoz</surname>, <given-names>D. P.</given-names></string-name> &amp; <string-name><surname>Everling</surname>, <given-names>S</given-names></string-name></person-group>. <article-title>Look away: the anti-saccade task and the voluntary control of eye movement</article-title>. <source>Nat. Rev. Neurosci</source>. <volume>5</volume>, <fpage>218</fpage>–<lpage>228</lpage> (<year>2004</year>).</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hattori</surname>, <given-names>R.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Meta-reinforcement learning via orbitofrontal cortex</article-title>. <source>Nat. Neurosci</source>. <volume>26</volume>, <fpage>2182</fpage>–<lpage>2191</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hattori</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Danskin</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Babic</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Mlynaryk</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Komiyama</surname>, <given-names>T</given-names></string-name></person-group>. <article-title>Area-Specificity and Plasticity of History-Dependent Value Coding During Learning</article-title>. <source>Cell</source> <volume>177</volume>, <fpage>1858</fpage>–<lpage>1872.e15</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Izquierdo</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Brigman</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Radke</surname>, <given-names>A. K.</given-names></string-name>, <string-name><surname>Rudebeck</surname>, <given-names>P. H.</given-names></string-name> &amp; <string-name><surname>Holmes</surname>, <given-names>A</given-names></string-name></person-group>. <article-title>The neural basis of reversal learning: An updated perspective</article-title>. <source>Neuroscience</source> <volume>345</volume>, <fpage>12</fpage>–<lpage>26</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Akrami</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kopec</surname>, <given-names>C. D.</given-names></string-name>, <string-name><surname>Diamond</surname>, <given-names>M. E.</given-names></string-name> &amp; <string-name><surname>Brody</surname>, <given-names>C. D</given-names></string-name></person-group>. <article-title>Posterior parietal cortex represents sensory history and mediates its effects on behaviour</article-title>. <source>Nature</source> <volume>554</volume>, <fpage>368</fpage>–<lpage>372</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fassihi</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Akrami</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Esmaeili</surname>, <given-names>V.</given-names></string-name> &amp; <string-name><surname>Diamond</surname>, <given-names>M. E</given-names></string-name></person-group>. <article-title>Tactile perception and working memory in rats and humans</article-title>. <source>Proc. Natl. Acad. Sci</source>. <volume>111</volume>, <fpage>2331</fpage>–<lpage>2336</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brunton</surname>, <given-names>B. W.</given-names></string-name>, <string-name><surname>Botvinick</surname>, <given-names>M. M.</given-names></string-name> &amp; <string-name><surname>Brody</surname>, <given-names>C. D</given-names></string-name></person-group>. <article-title>Rats and Humans Can Optimally Accumulate Evidence for Decision-Making</article-title>. <source>Science</source> <volume>340</volume>, <fpage>95</fpage>–<lpage>98</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Erlich</surname>, <given-names>J. C.</given-names></string-name>, <string-name><surname>Brunton</surname>, <given-names>B. W.</given-names></string-name>, <string-name><surname>Duan</surname>, <given-names>C. A.</given-names></string-name>, <string-name><surname>Hanks</surname>, <given-names>T. D.</given-names></string-name> &amp; <string-name><surname>Brody</surname>, <given-names>C. D</given-names></string-name></person-group>. <article-title>Distinct effects of prefrontal and parietal cortex inactivations on an accumulation of evidence task in the rat</article-title>. <source>eLife</source> <volume>4</volume>, <elocation-id>e05457</elocation-id> (<year>2015</year>). <pub-id pub-id-type="doi">10.7554/eLife.05457</pub-id></mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hanks</surname>, <given-names>T. D.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Distinct relationships of parietal and prefrontal cortices to evidence accumulation</article-title>. <source>Nature</source> <volume>520</volume>, <fpage>220</fpage>–<lpage>223</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Meijer</surname>, <given-names>G. T.</given-names></string-name>, <string-name><surname>Pie</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Dolman</surname>, <given-names>T. L.</given-names></string-name>, <string-name><surname>Pennartz</surname>, <given-names>C. M. A.</given-names></string-name> &amp; <string-name><surname>Lansink</surname>, <given-names>C. S</given-names></string-name></person-group>. <article-title>Audiovisual Integration Enhances Stimulus Detection Performance in Mice</article-title>. <source>Front. Behav. Neurosci</source>. <volume>12</volume>, (<year>2018</year>).</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Odoemene</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Pisupati</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Nguyen</surname>, <given-names>H.</given-names></string-name> &amp; <string-name><surname>Churchland</surname>, <given-names>A. K</given-names></string-name></person-group>. <article-title>Visual Evidence Accumulation Guides Decision-Making in Unrestrained Mice</article-title>. <source>J. Neurosci</source>. <volume>38</volume>, <fpage>10143</fpage>–<lpage>10155</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Raposo</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Sheppard</surname>, <given-names>J. P.</given-names></string-name>, <string-name><surname>Schrater</surname>, <given-names>P. R.</given-names></string-name> &amp; <string-name><surname>Churchland</surname>, <given-names>A. K</given-names></string-name></person-group>. <article-title>Multisensory Decision-Making in Rats and Humans</article-title>. <source>J. Neurosci</source>. <volume>32</volume>, <fpage>3726</fpage>–<lpage>3735</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kepecs</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Uchida</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Zariwala</surname>, <given-names>H. A.</given-names></string-name> &amp; <string-name><surname>Mainen</surname>, <given-names>Z. F</given-names></string-name></person-group>. <article-title>Neural correlates, computation and behavioural impact of decision confidence</article-title>. <source>Nature</source> <volume>455</volume>, <fpage>227</fpage>–<lpage>231</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Masset</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Ott</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Lak</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Hirokawa</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Kepecs</surname>, <given-names>A</given-names></string-name></person-group>. <article-title>Behavior– and Modality-General Representation of Confidence in Orbitofrontal Cortex</article-title>. <source>Cell</source> <volume>182</volume>, <fpage>112</fpage>–<lpage>126.e18</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schmack</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Bosc</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Ott</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Sturgill</surname>, <given-names>J. F.</given-names></string-name> &amp; <string-name><surname>Kepecs</surname>, <given-names>A</given-names></string-name></person-group>. <article-title>Striatal dopamine mediates hallucination-like perception in mice</article-title>. <source>Science</source> <volume>372</volume>, <fpage>eabf4740</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Masís</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Chapman</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Rhee</surname>, <given-names>J. Y.</given-names></string-name>, <string-name><surname>Cox</surname>, <given-names>D. D.</given-names></string-name> &amp; <string-name><surname>Saxe</surname>, <given-names>A. M</given-names></string-name></person-group>. <article-title>Strategically managing learning during perceptual decision making</article-title>. <source>eLife</source> <volume>12</volume>, <elocation-id>e64978</elocation-id> (<year>2023</year>). <pub-id pub-id-type="doi">10.7554/eLife.64978</pub-id></mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Condylis</surname>, <given-names>C.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Context-Dependent Sensory Processing across Primary and Secondary Somatosensory Cortex</article-title>. <source>Neuron</source> <volume>106</volume>, <fpage>515</fpage>–<lpage>525.e5</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname>, <given-names>D.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Medial prefrontal activity during delay period contributes to learning of a working memory task</article-title>. <source>Science</source> <volume>346</volume>, <fpage>458</fpage>–<lpage>463</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Taxidis</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Differential Emergence and Stability of Sensory and Temporal Representations in Context-Specific Hippocampal Sequences</article-title>. <source>Neuron</source> <volume>108</volume>, <fpage>984</fpage>–<lpage>998.e9</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c63"><label>63.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yu</surname>, <given-names>L.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>The causal role of auditory cortex in auditory working memory</article-title>. <source>eLife</source> <ext-link ext-link-type="uri" xlink:href="https://elifesciences.org/articles/64457/figures">https://elifesciences.org/articles/64457/figures</ext-link> (<year>2021</year>) doi:<pub-id pub-id-type="doi">10.7554/eLife.64457</pub-id>.</mixed-citation></ref>
<ref id="c64"><label>64.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Asinof</surname>, <given-names>S. K.</given-names></string-name> &amp; <string-name><surname>Paine</surname>, <given-names>T. A</given-names></string-name></person-group>. <article-title>The 5-Choice Serial Reaction Time Task: A Task of Attention and Impulse Control for Rodents</article-title>. <source>J. Vis. Exp. JoVE</source> <volume>51574</volume> (<year>2014</year>) doi:<pub-id pub-id-type="doi">10.3791/51574</pub-id>.</mixed-citation></ref>
<ref id="c65"><label>65.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Birtalan</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Bánhidi</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Sanders</surname>, <given-names>J. I.</given-names></string-name>, <string-name><surname>Balázsfi</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>Hangya</surname>, <given-names>B</given-names></string-name></person-group>. <article-title>Efficient training of mice on the 5-choice serial reaction time task in an automated rodent training system</article-title>. <source>Sci. Rep</source>. <volume>10</volume>, <issue>22362</issue> (<year>2020</year>).</mixed-citation></ref>
<ref id="c66"><label>66.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Piantadosi</surname>, <given-names>P. T.</given-names></string-name>, <string-name><surname>Lieberman</surname>, <given-names>A. G.</given-names></string-name>, <string-name><surname>Pickens</surname>, <given-names>C. L.</given-names></string-name>, <string-name><surname>Bergstrom</surname>, <given-names>H. C.</given-names></string-name> &amp; <string-name><surname>Holmes</surname>, <given-names>A</given-names></string-name></person-group>. <article-title>A novel multichoice touchscreen paradigm for assessing cognitive flexibility in mice</article-title>. <source>Learn Mem</source>. <volume>26</volume>, <fpage>24</fpage>–<lpage>30</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c67"><label>67.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mukherjee</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Lam</surname>, <given-names>N. H.</given-names></string-name>, <string-name><surname>Wimmer</surname>, <given-names>R. D.</given-names></string-name> &amp; <string-name><surname>Halassa</surname>, <given-names>M. M</given-names></string-name></person-group>. <article-title>Thalamic circuits for independent control of prefrontal signal and noise</article-title>. <source>Nature</source> <volume>600</volume>, <fpage>100</fpage>–<lpage>104</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c68"><label>68.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wimmer</surname>, <given-names>R. D.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Thalamic control of sensory selection in divided attention</article-title>. <source>Nature</source> <volume>526</volume>, <fpage>705</fpage>–<lpage>709</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c69"><label>69.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pisupati</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Chartarifsky-Lynn</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Khanal</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Churchland</surname>, <given-names>A. K</given-names></string-name></person-group>. <article-title>Lapses in perceptual decisions reflect exploration</article-title>. <source>eLife</source> <volume>10</volume>, <elocation-id>e55490</elocation-id> (<year>2021</year>). <pub-id pub-id-type="doi">10.7554/eLife.55490</pub-id></mixed-citation></ref>
<ref id="c70"><label>70.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rosenberg</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Perona</surname>, <given-names>P.</given-names></string-name> &amp; <string-name><surname>Meister</surname>, <given-names>M</given-names></string-name></person-group>. <article-title>Mice in a labyrinth show rapid learning, sudden insight, and efficient exploration</article-title>. <source>eLife</source> <volume>10</volume>, <elocation-id>e66175</elocation-id> (<year>2021</year>). <pub-id pub-id-type="doi">10.7554/eLife.66175</pub-id></mixed-citation></ref>
<ref id="c71"><label>71.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Gerken</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Wieland</surname>, <given-names>J. R.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>R. C.</given-names></string-name> &amp; <string-name><surname>Fellous</surname>, <given-names>J.-M</given-names></string-name></person-group>. <article-title>The effects of time horizon and guided choices on explore–exploit decisions in rodents</article-title>. <source>Behav. Neurosci</source>. <volume>137</volume>, <fpage>127</fpage>–<lpage>142</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c72"><label>72.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhu</surname>, <given-names>Z.</given-names></string-name> &amp; <string-name><surname>Kuchibhotla</surname>, <given-names>K. V</given-names></string-name></person-group>. <article-title>Performance errors during rodent learning reflect a dynamic choice strategy</article-title>. <source>Curr. Biol</source>. <volume>34</volume>, <fpage>2107</fpage>–<lpage>2117.e5</lpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c73"><label>73.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lassalle</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Halley</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Daumas</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Verret</surname>, <given-names>L.</given-names></string-name> &amp; <string-name><surname>Francés</surname>, <given-names>B</given-names></string-name></person-group>. <article-title>Effects of the genetic background on cognitive performances of TG2576 mice</article-title>. <source>Behav. Brain Res</source>. <volume>191</volume>, <fpage>104</fpage>–<lpage>110</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c74"><label>74.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Weekes</surname>, <given-names>N. Y</given-names></string-name></person-group>. <chapter-title>CHAPTER 13 – Sex Differences in the Brain</chapter-title>. in <source>Neuropsychology</source> (ed. <person-group person-group-type="editor"><string-name><surname>Zaidel</surname>, <given-names>D. W.</given-names></string-name></person-group>) <fpage>293</fpage>–<lpage>315</lpage> (<publisher-name>Academic Press</publisher-name>, <publisher-loc>San Diego</publisher-loc>, <year>1994</year>). doi:<pub-id pub-id-type="doi">10.1016/B978-0-08-092668-1.50019-3</pub-id>.</mixed-citation></ref>
<ref id="c75"><label>75.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Hemann</surname>, <given-names>M. T</given-names></string-name></person-group>. <chapter-title>The Development and Use of Genetically Tractable Preclinical Mouse Models</chapter-title>. in <source>Genetically Engineered Mice for Cancer Research: design, analysis, pathways, validation and pre-clinical testing</source> (eds. <person-group person-group-type="editor"><string-name><surname>Green</surname>, <given-names>J. E.</given-names></string-name> &amp; <string-name><surname>Ried</surname>, <given-names>T.</given-names></string-name></person-group>) <fpage>477</fpage>–<lpage>495</lpage> (<publisher-name>Springer</publisher-name>, <publisher-loc>New York, NY</publisher-loc>, <year>2012</year>). doi:<pub-id pub-id-type="doi">10.1007/978-0-387-69805-2_23</pub-id>.</mixed-citation></ref>
<ref id="c76"><label>76.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Arndt</surname>, <given-names>S. S.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Individual housing of mice — Impact on behaviour and stress responses</article-title>. <source>Physiol. Behav</source>. <volume>97</volume>, <fpage>385</fpage>–<lpage>393</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c77"><label>77.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Torquet</surname>, <given-names>N.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Social interactions impact on the dopaminergic system and drive individuality</article-title>. <source>Nat. Commun</source>. <volume>9</volume>, <fpage>3081</fpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c78"><label>78.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Grieco</surname>, <given-names>F.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Measuring Behavior in the Home Cage: Study Design, Applications, Challenges, and Perspectives</article-title>. <source>Front. Behav. Neurosci</source>. <volume>15</volume>, (<year>2021</year>).</mixed-citation></ref>
<ref id="c79"><label>79.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jhuang</surname>, <given-names>H.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Automated home-cage behavioural phenotyping of mice</article-title>. <source>Nat. Commun</source>. <volume>1</volume>, <fpage>68</fpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c80"><label>80.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shin</surname>, <given-names>H.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Interference-free, lightweight wireless neural probe system for investigating brain activity during natural competition</article-title>. <source>Biosens Bioelectron</source>. <volume>195</volume>, <fpage>113665</fpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c81"><label>81.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ouyang</surname>, <given-names>W.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>A wireless and battery-less implant for multimodal closed-loop neuromodulation in small animals. <italic>Nat</italic></article-title>. <source>Biomed Eng</source>. <volume>7</volume>, <fpage>1252</fpage>–<lpage>1269</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c82"><label>82.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wright</surname>, <given-names>J. P.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>A fully implantable wireless bidirectional neuromodulation system for mice</article-title>. <source>Biosens Bioelectron</source>. <volume>200</volume>, <fpage>113886</fpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c83"><label>83.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Smolen</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>Y.</given-names></string-name> &amp; <string-name><surname>Byrne</surname>, <given-names>J. H</given-names></string-name></person-group>. <article-title>The right time to learn: mechanisms and optimization of spaced learning</article-title>. <source>Nat. Rev. Neurosci</source>. <volume>17</volume>, <fpage>77</fpage>–<lpage>88</lpage> (<year>2016</year>).</mixed-citation></ref>
    <ref id="c84"><label>84.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Gardner</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Brooks</surname>, <given-names>C.</given-names></string-name></person-group>. <article-title>A Statistical Approaches to the Model Comparison Task in Learning Analytics</article-title> <conf-name>Workshop on Methodologies for Learning Analytics</conf-name> (<year>2017</year>).</mixed-citation></ref>
<ref id="c85"><label>85.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bernklau</surname>, <given-names>T. W.</given-names></string-name>, <string-name><surname>Righetti</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Mehrke</surname>, <given-names>L. S.</given-names></string-name> &amp; <string-name><surname>Jacob</surname>, <given-names>S. N</given-names></string-name></person-group>. <article-title>Striatal dopamine signals reflect perceived cue– action–outcome associations in mice</article-title>. <source>Nat. Neurosci</source>. <fpage>1</fpage>–<lpage>11</lpage> (<year>2024</year>) doi:<pub-id pub-id-type="doi">10.1038/s41593-023-01567-2</pub-id>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.104833.2.sa4</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Flagel</surname>
<given-names>Shelly B</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Michigan</institution>
</institution-wrap>
<city>Ann Arbor</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This manuscript describes a novel approach for assessing cognitive function in freely moving mice in their home-cage, without human involvement. The authors provide <bold>convincing</bold> evidence in support of the tasks they developed to capture a variety of complex behaviors and demonstrate the utility of a machine learning approach to expedite the acquisition of task demands. This work is <bold>important</bold> given its potential utility for other investigators interested in studying mouse cognition.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.104833.2.sa3</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This is a new and important system that can efficiently train mice to perform a variety of cognitive tasks in a flexible manner. It is innovative and opens the door to important experiments in the neurobiology of learning and memory.</p>
<p>Strengths:</p>
<p>Strengths include: high n's, a robust system, task flexibility, comparison of manual-like training vs constant training, circadian analysis, comparison of varying cue types, long-term measurement, and machine teaching.</p>
<p>Weaknesses:</p>
<p>I find no major problems with this report.</p>
<p>Comments on revisions:</p>
<p>My concerns have been addressed now.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.104833.2.sa2</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The manuscript by Yu et al. describes a novel approach for collecting complex and different cognitive phenotypes in individually housed mice in their home cage. The authors report a simple yet elegant design that they developed for assessing a variety of complex and novel behavioral paradigms autonomously in mice.</p>
<p>Strengths:</p>
<p>The data are strong, the arguments are convincing, and I think the manuscript will be highly cited given the complexity of behavioral phenotypes one can collect using this relatively inexpensive ($100/box) and high-throughput procedure (without the need of human interaction). Additionally, the authors include a machine learning algorithm to correct for erroneous strategies that mice develop which is incredibly elegant and important for this approach, as mice will develop odd strategies when given complete freedom.</p>
<p>Weaknesses:</p>
<p>A limitation to this approach is that it requires mice to be individually housed for days to months. This is now adequately addressed in the discussion.</p>
<p>A major issue with continuous self-paced tasks such as the autonomous d2AFC used by the authors is that the inter-trial intervals can vary significantly. Mice may do a few trials, lose interest and disengage from the task for several hours. This is problematic for data analysis that relies on trial duration to be similar between trials (e.g., reinforcement learning algorithms). The authors now provide information regarding task engagement of the mice across a 24 hour cycle (e.g., trials started, trials finished across a 24 h period).</p>
<p>Movies - it would be beneficial for the authors to add commentary to the video (hit, miss trials). It was interesting watching the mice but not clear whether they were doing the task correctly or not. The new videos adequately address these concerns.</p>
<p>The strength of this paper (from my perspective) is the potential utility it has for other investigators trying to get mice to do behavioral tasks. However, not enough information was provided about the construction of the boxes, interface, and code for running the boxes. If the authors are not willing to provide this information through eLife, GitHub, or their own website then my evaluation of impact and significance of this paper would go down significantly. This information is now available to readers.</p>
<p>Minor concerns</p>
<p>Learning rate is confusing for Figure 3 results as it actually refers to trials to reach criterion, and not the actual rate of learning (e.g., slope). This has been modified in the manuscript.</p>
<p>Comments on revisions:</p>
<p>The authors have addressed all my concerns regarding this very exciting manuscript.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.104833.2.sa1</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>In this set of experiments, the authors describe a novel research tool for studying complex cognitive tasks in mice, the HABITS automated training apparatus, and a novel &quot;machine teaching&quot; approach they use to accelerate training by algorithmically providing trials to animals that provide the most information about the current rule state for a given task.</p>
<p>Strengths:</p>
<p>There is much to be celebrated in an inexpensively constructed, replicable training environment that can be used with mice, which have rapidly become the model species of choice for understanding the roles of distinct circuits and genetic factors in cognition. Lingering challenges in developing and testing cognitive tasks in mice remain, however, and these are often chalked up to cognitive limitations in the species. The authors' findings, however, suggest that instead we may need to work creatively to meet mice where they live. In some cases it may be that mice may require durations of training far longer than laboratories are able to invest with manual training (up to over 100k trials, over months of daily testing) but that the tasks are achievable. The &quot;machine teaching&quot; approach further suggests that this duration could be substantially reduced by algorithmically optimizing each trial presented during training to maximize learning.</p>
<p>Weaknesses:</p>
<p>Cognitive training and testing in rodent models fill a number of roles. Sometimes, investigators are interested in within-subjects questions - querying a specific circuit, genetically defined neuron population, or molecule/drug candidate, by interrogating or manipulating its function in a highly trained animal. In this scenario, a cohort of highly trained animals which have been trained via a method that aims to make their behavior as similar as possible is a strength.</p>
<p>However, often investigators are interested in between-subjects questions - querying a source of individual differences that can have long term and/or developmental impacts, such as sex differences or gene variants. This is likely to often be the case in mouse models especially, because of their genetic tractability. In scenarios where investigators have examined cognitive processes between subjects in mice who vary across these sources of individual difference, the process of learning a task has been repeatedly shown to be different. The authors recognize that their approach is currently optimized for testing within-subjects questions, but begin to show how between-subjects questions might be addressed with this system.</p>
<p>The authors have perhaps shown that their main focus is highly-controlled within-subjects questions, as their dataset is almost exclusively made up of several hundred young adult male mice, with the exception of 6 females in a supplemental figure. It is notable that these female mice do appear to learn the two-alternative forced choice task somewhat more rapidly than the males in their cohort, and the authors suggest that future work with this system could be used to uncover strategies that differ across individuals.</p>
<p>Considering the implications for mice modeling relevant genetic variants, it is unclear to what extent the training protocols and especially the algorithmic machine teaching approach would be able to inform investigators about the differences between their groups during training. For investigators examining genetic models, it is unclear whether this extensive training experience would mitigate the ability to observe cognitive differences, or select for the animals best able to overcome them - eliminating the animals of interest. Likewise, the algorithmic approach aims to mitigate features of training such as side biases, but it is worth noting that the strategic uses of side biases in mice, as in primates, can benefit learning, rather than side biases solely being a problem. However, the investigators may be able to highlight variables selected by the algorithm that are associated with individual strategies in performing their tasks, and this would be a significant contribution.</p>
<p>A final, intriguing finding in this manuscript is that animal self-paced training led to much slower learning than &quot;manual&quot; training, by having the experimenter introduce the animal to the apparatus for a few hours each day. Manual training resulted in significantly faster learning, in almost half the number of trials on average, and with significantly fewer omitted trials. This finding does not necessarily argue that manual training is universally a better choice, because it led to more limited water consumption. However, it suggests that there is a distinct contribution of experimenter interactions and/or switching contexts in cognitive training, for example, by activating an &quot;occasion setting&quot; process to accelerate learning for a distinct period of time. Limiting experimenter interactions with mice may be a labor saving intervention, but may not necessarily improve performance. This could be an interesting topic of future investigation, of relevance to understanding how animals of all species learn.</p>
</body>
</sub-article>
<sub-article id="sa4" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.104833.2.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Yu</surname>
<given-names>Bowen</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Li</surname>
<given-names>Penghai</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Xu</surname>
<given-names>Haoze</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Wang</surname>
<given-names>Yueming</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Xu</surname>
<given-names>Kedi</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Hao</surname>
<given-names>Yaoyao</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0005-2628-8297</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>The following is the authors’ response to the original reviews.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Public review):</bold></p>
<p>Summary:</p>
<p>This is a new and important system that can efficiently train mice to perform a variety of cognitive tasks in a flexible manner. It is innovative and opens the door to important experiments in the neurobiology of learning and memory.</p>
<p>Strengths:</p>
<p>Strengths include: high n's, a robust system, task flexibility, comparison of manual-like training vs constant training, circadian analysis, comparison of varying cue types, long-term measurement, and machine teaching.</p>
<p>Weaknesses:</p>
<p>I find no major problems with this report.</p>
<p>Minor weaknesses:</p>
<p>(1)  Line 219: Water consumption per day remained the same, but number of trails triggered was more as training continued. First, is this related to manual-type training? Also, I'm trying to understand this result quantitatively, since it seems counter-intuitive: I would assume that with more trials, more water would be consumed since accuracy should go up over training (so more water per average trial). Am I understanding this right? Can the authors give more detail or understanding to how more trials can be triggered but no more water is consumed despite training?</p>
</disp-quote>
<p>Thanks for the comment. We would like to clarify the phenomenon described in Line 219: As the training advanced, the number of trials triggered by mice per day decreased (rather than increased as you mentioned in the comment) gradually for both manual and autonomous groups of mice (Fig. 2H left). The performance, as you mentioned, improved over time (Fig. 2D and 2E), leading to an increased probability of obtaining water and thus relatively stable daily water intake (Fig. 2H middle). We believe the stable daily intake is the minimum amount of water required by the mice under circumstance of autonomous behavioral training. To make the statement more clearly, we indicated the corresponding figure numbers in the text.</p>
<p>Results “… As shown in Fig. 2H, autonomous training yielded significantly higher number of trial/day (980 ± 25 vs. 611 ± 26, Fig. 2H left) and more volume of water consumption/day (1.65 ± 0.06 vs. 0.97 ± 0.03 ml, Fig. 2H middle), which resulted in monotonic increase of body weight that was even comparable to the free water group (Fig.2H right). In contrast, the body weight in manual training group experienced a sharp drop at the beginning of training and was constantly lower than autonomous group throughout the training stage (Fig. 2H right).”</p>
<disp-quote content-type="editor-comment">
<p>(2) Figure 2J: The X-axis should have some label: at least &quot;training type&quot;. Ideally, a legend with colors can be included, although I see the colors elsewhere in the figure. If a legend cannot be added, then the color scheme should be explained in the caption.</p>
</disp-quote>
<p>Thanks for the suggestion. The labels with corresponding colors for x-axis have been added for Fig. 2J.</p>
<disp-quote content-type="editor-comment">
<p>(3) Figure 2K: What is the purple line? I encourage a legend here. The same legend could apply to 2J.</p>
</disp-quote>
<p>Thanks for the suggestion. The legend has been added for Fig. 2K.</p>
<disp-quote content-type="editor-comment">
<p>(4) Supplementary Figure S2 D: I do not think the phrase &quot;relying on&quot; is correct. Instead, I think &quot;predicted by&quot; or &quot;correlating with&quot; might be better.</p>
</disp-quote>
<p>We thank the reviewer for the valuable suggestion. The phrase has been changed to ‘predicted by’ for better suitability.</p>
<p>Figure S2 “(D), percentage of trials significantly predicted by different regressors during task learning. …”</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public review):</bold></p>
<p>Summary:</p>
<p>The manuscript by Yu et al. describes a novel approach for collecting complex and different cognitive phenotypes in individually housed mice in their home cage. The authors report a simple yet elegant design that they developed for assessing a variety of complex and novel behavioral paradigms autonomously in mice.</p>
<p>Strengths:</p>
<p>The data are strong, the arguments are convincing, and I think the manuscript will be highly cited given the complexity of behavioral phenotypes one can collect using this relatively inexpensive ($100/box) and high throughput procedure (without the need for human interaction). Additionally, the authors include a machine learning algorithm to correct for erroneous strategies that mice develop which is incredibly elegant and important for this approach as mice will develop odd strategies when given complete freedom.</p>
<p>Weaknesses:</p>
<p>(1) A limitation of this approach is that it requires mice to be individually housed for days to months. This should be discussed in depth.</p>
</disp-quote>
<p>Thank you for raising this important point. We agree that the requirement for individual housing of mice during the training period is a limitation of our approach, and we appreciate the opportunity to discuss this in more depth. In the manuscript, we add a section to the Discussion to address this limitation, including the potential impact of individual housing on the mice, the rationale for individual housing in our study, and efforts or alternatives made to mitigate the effects of individual housing.</p>
<p>Discussion “… Firstly, our experiments were confined to single-housed mice, which is known to influence murine behavior and physiology, potentially affecting social interaction and stress levels [76]. In our study, individual housing was necessary to ensure precise behavioral tracking, eliminate competitive interactions during task performance, and maintain consistent training schedules without disruptions from cage-mate disturbances. However, the potential of group-housed training has been explored with technologies such as RFID [28,29,32–34] to distinguish individual mice, which potentially improving the training efficiency and facilitating research of social behaviors [77]. Notably, it has shown that simultaneous training of group-housed mice, without individual differentiation, can still achieve criterion performance [25].”</p>
<disp-quote content-type="editor-comment">
<p>(2) A major issue with continuous self-paced tasks such as the autonomous d2AFC used by the authors is that the inter-trial intervals can vary significantly. Mice may do a few trials, lose interest, and disengage from the task for several hours. This is problematic for data analysis that relies on trial duration to be similar between trials (e.g., reinforcement learning algorithms). It would be useful to see the task engagement of the mice across a 24-hour cycle (e.g., trials started, trials finished across a 24-hour period) and approaches for overcoming this issue of varying inter-trial intervals.</p>
</disp-quote>
<p>Thank you for your insightful comment regarding the variability in inter-trial intervals and its potential impact on data analysis. We agree that this is an important consideration for continuous self-paced tasks.</p>
<p>In our original manuscript, we have showed the general task engagement across 24-hour cycle (Fig. 2K), which revealed two peaks of engagements during the dark cycle with relatively fewer trials during the light cycle. To facilitate analyses requiring consistent trial durations, we defined trial blocks as sequences between two no-response trials. Notably, approximately 66.6% of trials occurred within blocks of &gt;5 consecutive trials (Fig. 2L), which may be particularly suitable for such analyses.</p>
<p>In the revised manuscript, we also added the analysis of the histogram of inter-trial-interval for both the autonomous and manual training paradigms in HABITS (Fig. S2H), which shows that around 55.2% and 77.5% of the intervals are less than 2 seconds in autonomous and manual training, respectively.</p>
<p>Results “… We found more than two-third of the trials was done in &gt;5-trial blocks (Fig. 2L left) which resulted in more than 55% of the trials were with inter-trial-interval less than 2 seconds (Fig. S2H).”</p>
<p>Regarding the approaches to mitigate the issue of varying inter-trial interval, we observed that manual training (i.e., manually transferring to HABITS for ~2 hr/day) in Fig. S2H resulted in more trials with short inter-trial-interval, suggesting that constrained access time promotes task engagement and reduces interval variability. Fig. 2L also indicated that the averaged correct rate increased and the earlylick rate decreased as the length of block increased. This approach could be valuable for studies where consistent trial timing is critical. In the context of our study, we could actually introduce a light, for example, to serve as the cue that prompt the animals to engage during a fixed time duration in a day.</p>
<p>Discussion “… In contrast, the self-paced nature of autonomous training may permit greater variability in attentional engagement 83 and inter-trial-intervals, which could be problematic for data analysis relaying on consistent intervals and/or engagements. Future studies should explore how controlled contextual constraints enhance learning efficiency and whether incorporating such measures into HABITS could optimize its performance.”</p>
<disp-quote content-type="editor-comment">
<p>(3) Movies - it would be beneficial for the authors to add commentary to the video (hit, miss trials). It was interesting watching the mice but not clear whether they were doing the task correctly or not.</p>
</disp-quote>
<p>Thanks for the reminder. We have added subtitles to both of the videos. Since the supplementary video1 was not recorded with sound, the correctness of the trials was hard to judge. We replaced the video with another one with clear sound recordings, and the subtitles were commented in detail.</p>
<disp-quote content-type="editor-comment">
<p>(4) The strength of this paper (from my perspective) is the potential utility it has for other investigators trying to get mice to do behavioral tasks. However, not enough information was provided about the construction of the boxes, interface, and code for running the boxes. If the authors are not willing to provide this information through eLife, GitHub, or their own website then my evaluation of the impact and significance of this paper would go down significantly.</p>
</disp-quote>
<p>Thanks for this important comment. We would like to clarify that the construction methods, GUI, code for our system, PCB and CAD files (newly uploaded) have already been made publicly available on <ext-link ext-link-type="uri" xlink:href="https://github.com/Yaoyao-Hao/HABITS">https://github.com/Yaoyao-Hao/HABITS</ext-link>. Additionally, we have open-sourced all the codes and raw data for all training protocols (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.27192897">https://doi.org/10.6084/m9.figshare.27192897</ext-link>). We will continue to maintain these resources in the future.</p>
<disp-quote content-type="editor-comment">
<p>Minor concerns:</p>
<p>(5) Learning rate is confusing for Figure 3 results as it actually refers to trials to reach the criterion, and not the actual rate of learning (e.g., slope).</p>
</disp-quote>
<p>Thanks for pointing this out. The ‘learning rate’ which refers to trial number to reach criterion has been changed to ‘the number of trials to reach criterion’.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #3 (Public review):</bold></p>
<p>Summary:</p>
<p>In this set of experiments, the authors describe a novel research tool for studying complex cognitive tasks in mice, the HABITS automated training apparatus, and a novel &quot;machine teaching&quot; approach they use to accelerate training by algorithmically providing trials to animals that provide the most information about the current rule state for a given task.</p>
<p>Strengths:</p>
<p>There is much to be celebrated in an inexpensively constructed, replicable training environment that can be used with mice, which have rapidly become the model species of choice for understanding the roles of distinct circuits and genetic factors in cognition. Lingering challenges in developing and testing cognitive tasks in mice remain, however, and these are often chalked up to cognitive limitations in the species. The authors' findings, however, suggest that instead, we may need to work creatively to meet mice where they live. In some cases, it may be that mice may require durations of training far longer than laboratories are able to invest with manual training (up to over 100k trials, over months of daily testing) but the tasks are achievable. The &quot;machine teaching&quot; approach further suggests that this duration could be substantially reduced by algorithmically optimizing each trial presented during training to maximize learning.</p>
<p>Weaknesses:</p>
<p>(1) Cognitive training and testing in rodent models fill a number of roles. Sometimes, investigators are interested in within-subjects questions - querying a specific circuit, genetically defined neuron population, or molecule/drug candidate, by interrogating or manipulating its function in a highly trained animal. In this scenario, a cohort of highly trained animals that have been trained via a method that aims to make their behavior as similar as possible is a strength.</p>
<p>However, often investigators are interested in between-subjects questions - querying a source of individual differences that can have long-term and/or developmental impacts, such as sex differences or gene variants. This is likely to often be the case in mouse models especially, because of their genetic tractability. In scenarios where investigators have examined cognitive processes between subjects in mice who vary across these sources of individual difference, the process of learning a task has been repeatedly shown to be different. The authors do not appear to have considered individual differences except perhaps as an obstacle to be overcome.</p>
<p>The authors have perhaps shown that their main focus is highly-controlled within-subjects questions, as their dataset is almost exclusively made up of several hundred young adult male mice, with the exception of 6 females in a supplemental figure. It is notable that these female mice do appear to learn the two-alternative forced-choice task somewhat more rapidly than the males in their cohort.</p>
</disp-quote>
<p>Thank you for your insightful comments and for highlighting the importance of considering both within-subject and between-subject questions in cognitive training and testing in rodent models. We acknowledge that our study primarily focused on highly controlled within-subject questions. However, the datasets we provided did show preliminary evidences for the ‘between-subject’ questions. Key observations include:</p>
<p>The large variability in learning rates among mice observed in Fig. 2I;</p>
<p>The overall learning rate difference between male and female subjects (Fig. 2D vs. Fig. S2G);</p>
<p>The varying nocturnal behavioral patterns (Fig. 2K), etc.</p>
<p>We recognize the value of exploring between-subjects differences in mouse model and discussed more details in the Discussion part.</p>
<p>Discussion “Our study was designed to standardize behavior for the precise interrogation of neural mechanisms, specifically addressing within-subject questions. However, investigators are often interested in between-subject differences—such as sex differences or genetic variants—which can have long-term behavioral and cognitive implications [72,74]. This is particularly relevant in mouse models due to their genetic tractability [75]. Although our primary focus was not on between-subject differences, the dataset we generated provides preliminary evidence for such investigations. Several behavioral readouts revealed individual variability among mice, including large disparities in learning rates across individuals (Fig. 2I), differences in overall learning rates between male and female subjects (Fig. 2D vs. Fig. S2G), variations in nocturnal behavioral patterns (Fig. 2K), etc.”</p>
<disp-quote content-type="editor-comment">
<p>(2) Considering the implications for mice modeling relevant genetic variants, it is unclear to what extent the training protocols and especially the algorithmic machine teaching approach would be able to inform investigators about the differences between their groups during training. For investigators examining genetic models, it is unclear whether this extensive training experience would mitigate the ability to observe cognitive differences, or select the animals best able to overcome them - eliminating the animals of interest. Likewise, the algorithmic approach aims to mitigate features of training such as side biases, but it is worth noting that the strategic uses of side biases in mice, as in primates, can benefit learning, rather than side biases solely being a problem. However, the investigators may be able to highlight variables selected by the algorithm that are associated with individual strategies in performing their tasks, and this would be a significant contribution.</p>
</disp-quote>
<p>Thank you for the insightful comments. We acknowledge that the extensive training experience, particularly through the algorithmic machine teaching approach, could potentially influence the ability to observe cognitive differences between groups of mice with relevant genetic variants. However, our study design and findings suggest that this approach can still provide valuable insights into individual differences and strategies used by the animals during training. First, the behavioral readout (including learning rate, engagement pattern, etc.) as mentioned above, could tell certain number of differences among mice. Second, detailed modelling analysis (with logistical regression modelling) could further dissect the strategy that mouse use along the training process (Fig. S2B). We have actually highlighted some variables selected by the regression that are associated with individual strategies in performing their tasks (Fig. S2C) and these strategies could be different between manual and autonomous training groups (Fig. S2D). We included these comments in the Discussion part for further clearance.</p>
<p>Discussion “… Furthermore, a detailed logistic regression analysis dissected the strategies mice employed during training (Fig. S2B). Notably, the regression identified variables associated with individual task-performance strategies (Fig. S2C), which also differed between manually and autonomously trained groups (Fig. S2D). Thus, our system could facilitate high-throughput behavioral studies exploring between-subject differences in the future.”</p>
<disp-quote content-type="editor-comment">
<p>(3) A final, intriguing finding in this manuscript is that animal self-paced training led to much slower learning than &quot;manual&quot; training, by having the experimenter introduce the animal to the apparatus for a few hours each day. Manual training resulted in significantly faster learning, in almost half the number of trials on average, and with significantly fewer omitted trials. This finding does not necessarily argue that manual training is universally a better choice because it leads to more limited water consumption. However, it suggests that there is a distinct contribution of experimenter interactions and/or switching contexts in cognitive training, for example by activating an &quot;occasion setting&quot; process to accelerate learning for a distinct period of time. Limiting experimenter interactions with mice may be a labor-saving intervention, but may not necessarily improve performance. This could be an interesting topic of future investigation, of relevance to understanding how animals of all species learn.</p>
</disp-quote>
<p>Thank you for your insightful comments. We agree that the finding that manual training led to significantly faster learning compared to self-paced training is both intriguing and important. One of the possible reasons we think is due to the limited duration of engagement provided by the experimenter in the manual training case, which forced the mice to concentrate more on the trials (thus with fewer omitting trials) than in autonomous training. Your suggestion that experimenter interactions might activate an &quot;occasion setting&quot; process is particularly interesting. In the context of our study, we could actually introduce, for example, a light, serving as the cue that prompt the animals to engage; and when the light is off, the engagement was not accessible any more for the mice to simulate the manual training situation. We agree that this could be an interesting topic for future investigation that might create a more conducive environment for learning, thereby accelerating the learning rate.</p>
<p>Discussion “… Lastly, while HABITS achieves criterion performance in a similar or even shorter overall days compared to manual training, it requires more trials to reach the same learning criterion (Fig. 2G). We hypothesize that this difference in trial efficiency may stem from the constrained engagement duration imposed by the experimenter in manual training, which could compel mice to focus more intensely on task execution, resulting in less trial omissions (Fig. 2F). In contrast, the self-paced nature of autonomous training may permit greater variability in attentional engagement 83 and inter-trial-intervals, which could be problematic for data analysis relaying on consistent intervals and/or engagements. Future studies should explore how controlled contextual constraints enhance learning efficiency and whether incorporating such measures into HABITS could optimize its performance.”</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Recommendations for the authors):</bold></p>
<p>As I mentioned in the weaknesses, I did not see code or CAD drawings for their home cages and how these interact with a computer.</p>
</disp-quote>
<p>Thanks for the comment. We would like to clarify that the construction methods, GUI, code for our system, PCB and CAD files (newly uploaded) have already been made publicly available on <ext-link ext-link-type="uri" xlink:href="https://github.com/Yaoyao-Hao/HABITS">https://github.com/Yaoyao-Hao/HABITS</ext-link>.</p>
</body>
</sub-article>
</article>