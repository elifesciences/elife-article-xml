<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">97014</article-id>
<article-id pub-id-type="doi">10.7554/eLife.97014</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.97014.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Whole-brain neural substrates of behavioral variability in the larval zebrafish</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Manley</surname>
<given-names>Jason</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8346-7551</contrib-id>
<name>
<surname>Vaziri</surname>
<given-names>Alipasha</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Laboratory of Neurotechnology and Biophysics, The Rockefeller University</institution>, New York, NY 10065, <country>USA</country></aff>
<aff id="a2"><label>2</label><institution>The Kavli Neural Systems Institute, The Rockefeller University</institution>, New York, NY 10065, <country>USA</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Brody</surname>
<given-names>Carlos D</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Princeton University, Howard Hughes Medical Institute</institution>
</institution-wrap>
<city>Princeton</city>
<country>United States of America</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Gold</surname>
<given-names>Joshua I</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Pennsylvania</institution>
</institution-wrap>
<city>Philadelphia</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>Correspondence: <email>vaziri@rockefeller.edu</email></corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-05-30">
<day>30</day>
<month>05</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP97014</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-03-03">
<day>03</day>
<month>03</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-03-06">
<day>06</day>
<month>03</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.03.03.583208"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Manley &amp; Vaziri</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Manley &amp; Vaziri</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-97014-v1.pdf"/>
<abstract>
<title>Abstract</title><p>Animals engaged in naturalistic behavior can exhibit a large degree of behavioral variability even under sensory invariant conditions. Such behavioral variability can include not only variations of the same behavior, but also variability across qualitatively different behaviors driven by divergent cognitive states, such as fight-or-flight decisions. However, the neural circuit mechanisms that generate such divergent behaviors across trials are not well understood. To investigate this question, here we studied the visual-evoked responses of larval zebrafish to moving objects of various sizes, which we found exhibited highly variable and divergent responses across repetitions of the same stimulus. Given that the neuronal circuits underlying such behaviors span sensory, motor, and other brain areas, we built a novel Fourier light field microscope which enables high-resolution, whole-brain imaging of larval zebrafish during behavior. This enabled us to screen for neural loci which exhibited activity patterns correlated with behavioral variability. We found that despite the highly variable activity of single neurons, visual stimuli were robustly encoded at the population level, and the visual-encoding dimensions of neural activity did not explain behavioral variability. This robustness despite apparent single neuron variability was due to the multi-dimensional geometry of the neuronal population dynamics: almost all neural dimensions that were variable across individual trials, i.e. the “noise” modes, were orthogonal to those encoding for sensory information. Investigating this neuronal variability further, we identified two sparsely-distributed, brain-wide neuronal populations whose pre-motor activity predicted whether the larva would respond to a stimulus and, if so, which direction it would turn on a single-trial level. These populations predicted single-trial behavior seconds before stimulus onset, indicating they encoded time-varying internal modulating behavior, perhaps organizing behavior over longer timescales or enabling flexible behavior routines dependent on the animal’s internal state. Our results provide the first whole-brain confirmation that sensory, motor, and internal variables are encoded in a highly mixed fashion throughout the brain and demonstrate that de-mixing each of these components at the neuronal population level is critical to understanding the mechanisms underlying the brain’s remarkable flexibility and robustness.</p>
</abstract>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Animals are not deterministic input-output machines, but instead display highly flexible behavioral responses even under sensory invariant conditions. A holistic understanding of the neuronal mechanisms underlying decision making requires explaining such variability in behavior at the single trial level. However, there are many putative sources of trial-to-trial neuronal variability. In particular, it is unclear whether such variability results from deterministic sources, such as internal states and long-timescale dynamics, or stochasticity. Individual neurons exhibit non-negligible noise from a variety of sources, including electrical noise due to ion channel fluctuations, synaptic noise due to biochemical processes, jitter in the timing of action potentials, and “digitization” noise due to the all-or-nothing nature of the action potential (<xref ref-type="bibr" rid="c18">Faisal et al., 2008</xref>).</p>
<p>However, trial-to-trial variability in neuronal firing is generally not independent across neurons, but instead highly correlated over repeated stimulus presentations within certain groups of neurons (<xref ref-type="bibr" rid="c33">Kohn et al., 2015</xref>; <xref ref-type="bibr" rid="c57">Shadlen and Newsome, 1998</xref>; <xref ref-type="bibr" rid="c71">Zohary et al., 1994</xref>), suggesting that variability in neural circuits may not be dominated by the stochasticity of individual neurons. Such structured covariation is referred to as “noise correlations” (<xref ref-type="bibr" rid="c12">Cohen and Kohn, 2011</xref>) because they are unrelated to the often experimenter-controlled external variable that is simultaneously encoded within the neuronal population. While certain structures of noise correlations are known to limit the information encoding capacity of the neuronal population (<xref ref-type="bibr" rid="c43">Moreno-Bote et al., 2014</xref>; <xref ref-type="bibr" rid="c5">Bartolo et al., 2020</xref>; <xref ref-type="bibr" rid="c54">Rumyantsev et al., 2020</xref>), there is little consensus about both their origin (<xref ref-type="bibr" rid="c27">Kanitscheider et al., 2015</xref>; <xref ref-type="bibr" rid="c72">Zylberberg et al., 2016</xref>) and behavioral impact (<xref ref-type="bibr" rid="c71">Zohary et al., 1994</xref>; <xref ref-type="bibr" rid="c25">Huang and Lisberger, 2009</xref>). In particular, there are opposing reports in different species and under different task conditions as to whether such inter-neuronal correlations can improve (Cafaro and Rieke, 2010; <xref ref-type="bibr" rid="c72">Zylberberg et al., 2016</xref>; <xref ref-type="bibr" rid="c64">Valente et al., 2021</xref>) or interfere (<xref ref-type="bibr" rid="c13">Cohen and Maunsell, 2009</xref>; Ruda et al., 2020; <xref ref-type="bibr" rid="c26">Kafashan et al., 2021</xref>) with the neural computations underlying decision making. As such, a general framework capable of reconciling such widely varying reports and explaining the functional impact of noise correlations on neural computation and behavior is currently missing.</p>
<p>Further, few experimental studies have linked noise correlations in sensory regions to pre-motor dynamics and ultimately behavior (<xref ref-type="bibr" rid="c64">Valente et al., 2021</xref>). Instead, most reports have mainly focused on the scale and structure of such covariations across sensory neurons in anesthetized animals or without regard to the animal’s behavioral state. However, recent studies have shown that many species encode the animal’s own movements in a highly distributed fashion, including across early sensory regions (<xref ref-type="bibr" rid="c31">Kauvar et al., 2020</xref>; <xref ref-type="bibr" rid="c44">Musall et al., 2019</xref>; <xref ref-type="bibr" rid="c61">Stringer et al., 2019</xref>). These brain-wide, motor-related fluctuations must then drive at least some of the observed neuronal covariation across stimulus presentations. Thus, noise correlations are not merely stochastic “noise”, but instead may encode important variables that are stimulus-independent and perhaps related to the animal’s proprioception and context, such as long-timescale behavioral and internal state dynamics.</p>
<p>Such highly overlapping representations of sensory information and additional contextual variables may underly the brain’s remarkable ability to flexibly control behavior and select the most appropriate action at any given moment based on the animal’s goals and internal state. As such, naturalistic decision making is a function of not just incoming sensory stimuli, but also internal variables such as the animal’s motivations and recent experience or learned behaviors. For example, foraging has been shown across species to be modulated by hunger (<xref ref-type="bibr" rid="c19">Filosa et al., 2016</xref>), long-timescale exploration versus exploitation states (<xref ref-type="bibr" rid="c21">Flavell et al., 2013</xref>; <xref ref-type="bibr" rid="c40">Marques et al., 2020</xref>), and other hidden internal variables (<xref ref-type="bibr" rid="c59">Sternson, 2020</xref>; <xref ref-type="bibr" rid="c63">Torigoe et al., 2021</xref>; <xref ref-type="bibr" rid="c20">Flavell et al., 2022</xref>). This evidence suggests that answering longstanding questions regarding the neuronal mechanisms underlying naturalistic decision making will require understanding the intersection of numerous neural circuits distributed throughout the vertebrate brain.</p>
<p>Thus, probing the structure of the neuronal mechanisms underlying behavioral variability requires high spatiotemporal resolution recording of brain-wide neuronal dynamics and behavior across many trials. While it is often necessary to average across trials to deal with both the inherent variable firing of single neurons and experimental measurement noise, such trial averaging inherently precludes any investigation of the link between neural and behavioral variability on the trial-by-trial level. Instead, methods that utilize the entire neuronal population dynamics have shown that pooling information across neurons can allow for successful decoding of information that is not possible from individual neurons. This is because simultaneous multi-neuron recordings can leverage statistical power across neurons to capture the most salient aspects of population dynamics within single trials. Such population-level approaches have revolutionized the fields of motor planning and decision making, providing highly robust brain-machine interfaces (<xref ref-type="bibr" rid="c28">Kao et al., 2015</xref>; <xref ref-type="bibr" rid="c49">Pandarinath et al., 2018</xref>) that combine information from at least a few recording sites and making it possible to predict decisions (<xref ref-type="bibr" rid="c66">Wei et al., 2019</xref>; <xref ref-type="bibr" rid="c36">Lin et al., 2020</xref>), reaction time (<xref ref-type="bibr" rid="c1">Afshar et al., 2011</xref>), and additional behavioral states (<xref ref-type="bibr" rid="c30">Kaufman et al., 2015</xref>; <xref ref-type="bibr" rid="c40">Marques et al., 2020</xref>) at the single trial level. Recently, optical imaging techniques (<xref ref-type="bibr" rid="c67">Weisenburger and Vaziri, 2018</xref>; <xref ref-type="bibr" rid="c32">Kim and Schnitzer, 2022</xref>; <xref ref-type="bibr" rid="c39">Machado et al., 2022</xref>) have dramatically increased the attainable number of simultaneously recorded neurons within increasingly larger brain volumes at high speed and resolution. Thus, large-scale neural recording provides a promising approach to both screening for potential sources of variability across the brain and identifying robust population-level dynamics at the level of single trials. However, due to the difficulty of obtaining whole-brain optical access in many vertebrates, previous studies have not been able to quantify brain-wide noise correlations at the single neuron level and link such noise modes to variable decisions at the single trial level.</p>
<p>In this study, we sought to identify the neural loci which drive or encode information related to behavioral variability across trials. To do so, we performed whole-brain recording at cellular resolution in larval zebrafish engaged in ethologically relevant visually-evoked behaviors to identify neuronal populations that were predictive of behavioral variability under sensory invariant conditions. While it is well-known that larval zebrafish on average exhibit a target-directed prey capture response to small visual stimuli and a target-avoidance escape response to large visual stimuli, we demonstrated that these ethological, oppositely valanced, and highly divergent responses exhibited significant variability across trials of identical stimulus presentations. Turning first to visually-evoked neural populations, we found that despite trial-to-trial variability in the responses of single neurons, visual information was reliably encoded at the population level across trials of each stimulus. As such, the visual-encoding neuronal activity patterns did not account for the larvae’s variable behavioral responses across trials.</p>
<p>A key feature of our system, unlike previous studies, was that it allowed investigating the geometry of trial-to-trial variability of neuronal dynamics on the whole-brain-level, by simultaneous observation of brain-wide neural variability during a visual decision-making behavior. Thus, we were able to identify whole-brain modes of neural variability which were related to the larva’s motor actions. In particular, we identified highly distributed neuronal populations whose pre-motor activity predicted the larvae’s responsiveness and turn direction on a single trial level, indicating that behavioral variability is not represented in particular anatomical neural loci. We found that this predictability exhibited two dominant timescales: a longer-timescale and pre-stimulus turn bias that was not time-locked to the stimulus presentations or motor timing; and a rapid increase in predictability and ramping activity about one to two seconds before movement initiation. Consistent with result from previous studies, we speculate that the former, longer-timescale bias is related to a circuitry that has evolved to optimize an exploration versus exploitation behavior in forging while the latter, short-timescale ramping activity likely drives the downstream motor circuitry to execute the actual selected action in each trial. Our data suggest that behavioral variability in response to repetitions of the same sensory stimulus may not be driven by a single brain region. Rather, it is more likely generated by a combination of factors encoded by neurons throughout the brain, including a time-varying and internal turn direction bias, in addition to the well-studied visuomotor transformations.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Fourier Light Field Microscopy enables high-speed imaging of neuronal population dynamics</title>
<p>In order to investigate the whole-brain neural correlates of behavioral variability, we designed and built a Fourier light field microscope (fLFM) that was optimized for high-resolution, whole-brain recoding of neuronal activity in the larval zebrafish. Conventional light field microscopy (cLFM) provides an elegant solution to volumetric snapshot imaging by placing a microlens array (MLA) in the image plane to encode both the position and angle of incidence of the light rays onto a camera sensor (<xref ref-type="bibr" rid="c35">Levoy et al., 2006</xref>). Combined with 3D deconvolution algorithms for computational reconstruction of the recorded volume (<xref ref-type="bibr" rid="c2">Agard, 1984</xref>; <xref ref-type="bibr" rid="c10">Broxton et al., 2013</xref>; <xref ref-type="bibr" rid="c52">Prevedel et al., 2014</xref>), LFM enables imaging of an entire volume without requiring any scanning. Due to its high speed and volumetric capabilities, cLFM has been widely applied to image the dynamics of <italic>in vivo</italic> biological systems, particularly neuronal dynamics (<xref ref-type="bibr" rid="c52">Prevedel et al., 2014</xref>; <xref ref-type="bibr" rid="c3">Aimon et al., 2019</xref>; <xref ref-type="bibr" rid="c36">Lin et al., 2020</xref>; <xref ref-type="bibr" rid="c53">Quicke et al., 2020</xref>; <xref ref-type="bibr" rid="c69">Yoon et al., 2020</xref>). Further, additional computational strategies have been devised to image deep into scattering tissue, such as the mouse brain (<xref ref-type="bibr" rid="c45">Nöbauer et al., 2017</xref>; <xref ref-type="bibr" rid="c58">Skocek et al., 2018</xref>; <xref ref-type="bibr" rid="c46">Nöbauer et al., 2023</xref>). However, a primary limitation of cLFM is a dramatic drop in resolution near the native image plane (NIP) because its spatio-angular sampling is uneven across depth and highly redundant near the NIP. This low resolution at the center of the sample can only be partially overcome using techniques such as wavefront coding (<xref ref-type="bibr" rid="c14">Cohen et al., 2014</xref>). In contrast, fLFM has been shown to provide high-resolution imaging across a two-to three-fold extended depth by processing the light field information through the Fourier domain (<xref ref-type="bibr" rid="c38">Llavador et al., 2016</xref>; <xref ref-type="bibr" rid="c55">Scrofani et al., 2017</xref>; <xref ref-type="bibr" rid="c15">Cong et al., 2017</xref>; <xref ref-type="bibr" rid="c24">Guo et al., 2019</xref>; <xref ref-type="bibr" rid="c37">Liu et al., 2020</xref>); i.e., placing the MLA conjugate to the back focal plane of the objective. In this configuration, the MLA segments the wavefront by transmitting the various spatial frequencies (which correspond to angular information) into images on different regions of the camera, providing a well-aliased sampling of the spatio-angular information without significant redundancy near the NIP.</p>
<p>We simultaneously optimized our design for simplicity and cost-effectiveness by using exclusively off-the-shelf elements, as opposed to previous implementations of fLFM which relied on custom optical components. Our design (<xref rid="fig1" ref-type="fig">Figure 1A</xref>, see Methods for details) enables imaging of an approximately 750 × 750 × 200 μm<sup>3</sup> volume, corresponding to roughly the whole brain of a 7 days post fertilization (dpf) larval zebrafish. 3D information is captured in the raw images (<xref rid="fig1" ref-type="fig">Figure 1B</xref>) because each lenslet in the MLA segments a region of the Fourier plane and thus forms an image of the sample from a unique perspective. Experimentally, the point spread function (PSF) full width at half maximum (FWHM) of our system measured 3.3 ± 0.21 μm (95% confidence interval) laterally and 5.4 ± 0.4 μm axially (<xref rid="fig1" ref-type="fig">Figure 1C</xref>), consistent with theoretical estimates of 3.1 μm and 4.7 μm, respectively. This represents a substantial improvement in axial resolution compared to our previous cLFM, which had a PSF FWHM of 3.4 μm laterally and 11.3 μm axially (<xref ref-type="bibr" rid="c52">Prevedel et al., 2014</xref>). As such, our design enabled cellular-resolution imaging across the whole brain of the larval zebrafish.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Fourier Light Field Microscopy (fLFM) provides a simple and cost-effective method for whole-brain imaging of larval zebrafish during behavior</title>
<p><bold>A.</bold> Schematic of the fLFM system. The sample is illuminated with a 470 nm LED through a 20×/1.0-NA imaging objective (Obj). The fluorescence is sent to the imaging path via a dichroic mirror (DM). An Olympus-style f=180mm tube lens (TL) and f=180mm Fourier lens (FL) are used to conjugate the back focal plane of the objective onto a microlens array (MLA). An sCMOS sensor is positioned at the focal plane of the MLA to capture the raw fLFM images.</p><p><bold>B.</bold> An example raw sensor image. Each lenslet in the 8×8 array forms an image of the sample from a slightly different perspective, allowing for reconstruction of the 3D volume.</p>
<p><bold>C.</bold> Experimental measurement of the point spread function (PSF). Left: the x-y (top) and x-z (bottom) profiles of a reconstructed image of a 1 μm fluorescent bead. Right: corresponding cross sections of the PSF (points). A Gaussian profile (lines) was fit to these data to measure the full width at half maximum (FWHM), which was 3.3 μm laterally and 5.4 μm axially.</p>
<p><bold>D.</bold> Schematic of our fLFM data processing pipeline (see Methods for detailed description).</p>
<p><bold>E.</bold> A maximum intensity projection (MIP) of a conventional LFM (cLFM) larval zebrafish recording resulting in strong grid-like artifacts and low resolution near the native image plane (black arrows). A reconstructed volume of 750 × 750 × 200 μm<sup>3</sup> is shown.</p>
<p><bold>F.</bold> An MIP of a fLFM recording. fLFM exhibits higher axial resolution and does not contain artifacts at the native image plane. A reconstructed volume of 750 × 375 × 200 μm<sup>3</sup> is shown.</p>
<p><bold>G.</bold> A heatmap of extracted neuronal activity from an example one hour recording of 15,286 neurons. Neurons are sorted using the rastermap algorithm (<xref ref-type="bibr" rid="c61">Stringer et al., 2019</xref>), such that nearby neurons exhibit similar temporal activity patterns. Multiple distinct activity patterns are seen, included strong activity during two sets of drifting grating-induced optomotor response trials (black arrows).</p>
<p><bold>H.</bold> Example neurons tuned to tail movements and visual stimuli. In black are six example neuron traces from the designated region in panel G, which exhibited correlations with the GCaMP-kernel-convolved tail vigor (top trace, see Methods for details). In red are six example neuron traces from the designated region in panel G, which exhibited correlations with the visual stimuli presented in the left visual field (denoted by the red lines at the bottom of the plot).</p></caption>
<graphic xlink:href="583208v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Next, we developed a custom pipeline (<xref rid="fig1" ref-type="fig">Figure 1D</xref>) for 3D reconstruction and neuronal segmentation to extract the dynamics of neurons across the field of view. This consisted of three main steps: denoising, 3D reconstruction, and neuronal segmentation. As one of the key limitations of LFM is signal-to-noise ratio (SNR) due to the distribution of emitted photons onto a sensor array, we first denoised the raw sensor images. To do so we trained a DeepInterpolation (<xref ref-type="bibr" rid="c34">Lecoq et al., 2021</xref>) deep neural network model, which has been shown to increase the SNR of the resulting neuronal timeseries. Next, the full 3D volume was reconstructed from denoised sensor images using Richardson-Lucy deconvolution (<xref ref-type="bibr" rid="c2">Agard, 1984</xref>; <xref ref-type="bibr" rid="c10">Broxton et al., 2013</xref>; <xref ref-type="bibr" rid="c52">Prevedel et al., 2014</xref>) and an experimentally measured PSF. In addition to enabling high-resolution imaging across an extended depth of field, a key advantage of fLFM is that the reconstruction of the volume images can be performed approximately 100 times faster than in cLFM, due to fLFM’s shift-invariant point spread function. Finally, to identify neuronal regions of interest (ROIs) and their dynamics within the reconstructed volume, we utilized CNMF-E (<xref ref-type="bibr" rid="c70">Zhou et al., 2018</xref>), a constrained matrix factorization approach to extract <italic>in vivo</italic> calcium signals from one-photon imaging data. The CNMF-E algorithm was applied to each plane in parallel, after which the putative ROIs from each plane were collated and duplicate neurons across planes were merged.</p>
<p>To validate our setup, we imaged whole-brain dynamics from head-immobilized larval zebrafish expressing nuclear-localized GCaMP6s (NL-GCaMP6s) pan-neuronally (<xref ref-type="bibr" rid="c65">Vladimirov et al., 2014</xref>) while monitoring the larva’s tail movements using a high-speed camera and presenting visual stimuli, which as we will discuss below consisted of single dots of 3-5 different sizes moving from the center toward the left or right visual field. Across our 1-2 hour recordings, we identified 16,524 ± 3,942 neurons per animal (mean ± 95% confidence interval; range: 6,425 to 35,928). Thus, the combination of fLFM and the improvement in our reconstruction pipeline enabled the detection of significantly higher neuron numbers than the ∼5,000 neurons as reported in our previous cLFM realizations (<xref ref-type="bibr" rid="c52">Prevedel et al., 2014</xref>; <xref ref-type="bibr" rid="c36">Lin et al., 2020</xref>). The performance improvement over cLFM could also be visualized by inspecting the maximum intensity projection (MIP) of a zebrafish recording in each modality. While cLFM (<xref rid="fig1" ref-type="fig">Figure 1E</xref>) exhibits lower resolution and grid-like artifacts near the native image plane (black arrows) due to redundant sampling near the NIP, fLFM’s well-aliased sampling of spatio-angular information provides cellular-resolution imaging throughout the entire volume (<xref rid="fig1" ref-type="fig">Figure 1F</xref>).</p>
<p>Within these observed large-scale dynamics, we found a diversity of neuronal activity patterns (<xref rid="fig1" ref-type="fig">Figure 1G</xref>). For example, we identified neurons tuned to the vigor the larva’s tail movements (see Methods for details) and those tuned to the presentation of visual stimuli as described below (<xref rid="fig1" ref-type="fig">Figure 1H</xref>), providing a proof of principle that fLFM enables whole-brain imaging of the relevant neuronal population activity encoding sensory inputs and behavior.</p>
</sec>
<sec id="s2b">
<title>Larval zebrafish exhibit highly variable motor responses to visual stimuli</title>
<p>Whole-brain, cellular-resolution imaging at high speed enabled us to screen for regions across the brain which exhibited covariations related to variability in behavior and naturalistic decision making. We thus set out to investigate the neuronal basis of trial-to-trial variability in action selection during two different ethologically-relevant behaviors which are known to be generated by brain-wide sensorimotor circuitries (<xref ref-type="bibr" rid="c11">Chen et al., 2018</xref>). In the larval zebrafish, several visually-evoked behaviors such as prey capture (<xref ref-type="bibr" rid="c9">Borla et al., 2002</xref>; <xref ref-type="bibr" rid="c50">Patterson et al., 2013</xref>) and escape response (<xref ref-type="bibr" rid="c62">Temizer et al., 2015</xref>) have been widely studied. In particular, varying a single stimulus parameter, the size of a visual object, can elicit dramatically distinct average behavioral responses (<xref ref-type="bibr" rid="c4">Barker and Baier, 2015</xref>), ranging from target-directed responses (e.g., prey capture) to small stimuli, to target-avoidance behaviors (e.g., escape response) to large stimuli. These distinct behaviors can be evoked in the laboratory using simple visual stimuli and in a head-fixed imaging preparation (<xref ref-type="bibr" rid="c7">Bianco et al., 2011</xref>; <xref ref-type="bibr" rid="c56">Semmelhack et al., 2014</xref>; <xref ref-type="bibr" rid="c62">Temizer et al., 2015</xref>; <xref ref-type="bibr" rid="c4">Barker and Baier, 2015</xref>; <xref ref-type="bibr" rid="c6">Bianco and Engert, 2015</xref>; Timothy W. Dunn et al., 2016; <xref ref-type="bibr" rid="c19">Filosa et al., 2016</xref>; <xref ref-type="bibr" rid="c22">Förster et al., 2020</xref>; <xref ref-type="bibr" rid="c48">Oldfield et al., 2020</xref>). As such, the neural circuitry underlying each of the individual behaviors is well understood (<xref ref-type="bibr" rid="c51">Portugues and Engert, 2009</xref>; <xref ref-type="bibr" rid="c8">Bollmann, 2019</xref>) on the trial-averaged level. However, importantly these behaviors are not reflexive. They involve the processing of information across multiple brain regions and are subjected to neuromodulatory effects and longer time scale changes of internal states (<xref ref-type="bibr" rid="c19">Filosa et al., 2016</xref>; <xref ref-type="bibr" rid="c40">Marques et al., 2020</xref>). As such, the larvae do not deterministically perform the same actions over multiple sensory invariant trials. Even under highly optimized and invariant conditions, prey capture is only observed in up to 30% of trials (<xref ref-type="bibr" rid="c7">Bianco et al., 2011</xref>), whereas escape response is more consistently observed in 80% of trials (<xref ref-type="bibr" rid="c62">Temizer et al., 2015</xref>). However, the neuronal populations and the underlying circuitry driving such variability in responsiveness and action selection in either of these paradigms have not been identified, yet these ethologically highly divergent behaviors can be elicited by tuning a single parameter. We thus hypothesized that modulating the size of the visual object should reveal a regime of behavioral variability between these highly divergent, naturalistic behaviors, providing a useful means and context to study questions such as how behavioral strategies may switch across trials or how neural and behavioral variability changes as a function of the ambiguity of the presented stimulus.</p>
<p>Thus, we first sought to characterize the trial-to-trial variability of the larvae’s behavioral responses to repetitions of simple visual stimuli of various sizes. In a freely swimming context (<xref rid="fig2" ref-type="fig">Figure 2A</xref>), we displayed moving dots of various sizes ranging from 1 to 40 visual degrees (see Methods for details) on a screen positioned below the larvae. Analyzing these behavioral recordings for different dot sizes, we indeed found characteristic target-avoidance bouts similar to escape response (<xref rid="fig2" ref-type="fig">Figure 2B</xref>) and target-directed bouts similar to prey capture response (<xref rid="fig2" ref-type="fig">Figure 2C</xref>; see also Video 1). For each bout of behavior in which a larva was close to a visual object, we quantified whether it approached or avoided the target using the larva’s change in distance from the object as a metric (see Methods for details). Consistent with previous work (<xref ref-type="bibr" rid="c4">Barker and Baier, 2015</xref>), on average the larvae exhibited target-directed behavior to small stimuli (1-5°), followed by a crossover point at which the larvae were not preferentially target-directed or target-avoiding for stimuli of 7° in size, and then a target-avoidance behavioral regime to stimuli at above 10° or larger which elicited characteristic escape responses on average (<xref rid="fig2" ref-type="fig">Figure 2D</xref>). Moreover, across individual trials the larvae’s responses exhibited significant variability, yielding many trials in which the larvae either did not respond or responded in the opposite direction of the average response, as indicated by the large standard deviation across bouts for the same stimulus size (<xref rid="fig2" ref-type="fig">Figure 2D</xref>).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Zebrafish exhibit highly variable motor responses to visual stimuli</title>
<p><bold>A.</bold> Schematic of the freely-behaving experimental setup. A single larva is placed in a 90 mm petri dish with a shallow (approximately 3 mm) amount of water. The dish is placed on a screen which displays visual stimuli consisting of dots of various sizes drifting in a constant direction and speed. The behavior is monitored with a camera from above.</p>
<p><bold>B.</bold> An example target-avoidance bout. A composite image taken of four frames from start (white arrow) to near the finish (black arrow) of a bout in which the larvae avoided a large visual stimulus. See also Video 1.</p>
<p><bold>C.</bold> An example target-directed bout. A composite image taken of three frames from start (white arrow) to finish (black arrow) of a bout in which the larvae made a directed movement toward a small visual stimulus. See also Video 1.</p>
<p><bold>D.</bold> The behavioral response of larvae to various size visual stimuli. For each size stimulus, all bouts of movement in which the larva was within 10 body lengths of a visual stimulus were considered. For each bout, the change in distance between the larvae and the stimulus during the movement was monitored. Thus, target-directed bouts exhibited negative values corresponding to a decrease in the distance to the stimulus, whereas target-avoidance bouts exhibited positive values. Stimuli less than 7° in size evoked target-directed responses on average, whereas stimulus greater than 10° evoked target-avoidance responses. Shown is the mean ± standard deviation of n=9 larvae.</p>
<p><bold>E.</bold> Schematic of the head-fixed experimental setup. A larva is embedding in agarose in order to keep its head fixed during whole-brain imaging. The agarose around the tail and eyes are removed, such that the tail can be tracked (indicated by black dots along the tail) and visual stimuli can be presented. Visual stimuli of various sizes are presented moving from the center of visual field to either the left or right.</p>
<p><bold>F.</bold> The behavioral response of larvae to various size visual stimuli during head fixation. Visual stimuli are presented in either the left (pink) or right (green) visual field. The directedness of tail movements is monitored by computing the mean tail curvature during a bout of movement, with positive values indicating leftward motions. Similar to freely-behaving experiments, visual stimuli of 7° or less evoked target-directed responses, whereas stimuli larger than 10° evoked target-avoidance. Shown is the mean ± standard deviation of n=10 larvae. Asterisks indicate stimuli with significant difference between presentations on the left and right visual field (p&lt;0.05, paired t-test).</p>
<p><bold>G.</bold> Example behavioral responses to various stimuli. For each of four stimulus sizes on the left and right visual fields, a histogram of the mean tail curvature during bouts is shown for an example larva. While stimulus-evoked behavioral responses are variable in all cases, they appear the least variable in the case of largely target-avoidance bouts to large 44° stimuli (rightmost column).</p></caption>
<graphic xlink:href="583208v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Next, we confirmed that these behaviors were preserved in a head-fixed imaging preparation, in which the larvae were embedded in agarose with their eyes and tail cut free (<xref rid="fig2" ref-type="fig">Figure 2E</xref>), such that their variable behavioral responses to visual stimuli could be tracked while performing whole-brain neuronal recordings using our fLFM system. To do so, we presented visual stimuli as dots of a certain size moving in either the left or right visual field of the animals (see Methods for details). Visual stimuli were created using a projector that projected onto the edge of the circular 35 mm petri dish in which the larvae were embedded. Utilizing curvature of the tail to the left or the right as a metric for target-directed versus -avoidance behavior, we again identified the stimulus-size dependence of the larvae’s average behavioral response (<xref rid="fig2" ref-type="fig">Figure 2F</xref>) that recapitulated what was observed in freely behaving larvae. We also confirmed that the corresponding opposite tail responses were observed when the stimuli were presented on the other side of the visual field, demonstrating that even during head-fixation the larvae exhibit on average directed behaviors that depend on the stimulus size. However, at the single trial level, we observed behavioral variability to nearly all stimulus sizes (<xref rid="fig2" ref-type="fig">Figure 2G</xref>), even in the stimulus size regime known to optimally drive prey capture and escape response behaviors. The most widely variable responses were at 4° and 11°, corresponding to stimuli in the target-directed regime and near the crossover between target-directed and avoidance, respectively. This high degree of variability among responses to small and intermediate stimuli is consistent with previous literature estimates that even in optimized setups, the prey capture response is observed at rates less than 30% during head-fixation (<xref ref-type="bibr" rid="c7">Bianco et al., 2011</xref>) and any motor response at all to small visual stimuli is observed at rates up to 60% of trials in free behavior (<xref ref-type="bibr" rid="c19">Filosa et al., 2016</xref>). However, the neural mechanisms and circuitry underlying such trial-to-trial behavioral variability are not understood. In particular, it is unclear whether such variability within these ethologically relevant, yet divergent behaviors is driven by noise and inherent stochasticity in neuronal circuits, or represents modulation by time-varying internal states, such as motivation and hunger.</p>
</sec>
<sec id="s2c">
<title>Trial-to-trial variability in visually-evoked neurons is largely orthogonal to visual decoding dimensions</title>
<p>Previous studies have reported that individual neurons tuned to specific stimuli often exhibit significant variability in their responses over multiple presentations of the same stimulus (<xref ref-type="bibr" rid="c42">Montijn et al., 2016</xref>; <xref ref-type="bibr" rid="c54">Rumyantsev et al., 2020</xref>; <xref ref-type="bibr" rid="c57">Shadlen and Newsome, 1998</xref>; <xref ref-type="bibr" rid="c71">Zohary et al., 1994</xref>; <xref ref-type="bibr" rid="c72">Zylberberg et al., 2016</xref>). Thus, one potential mechanism underlying our observed behavioral variability could be trial-to-trial deviations in the neural encoding of visual stimuli. Given that we had observed behavioral variability across the entire studied range of stimulus sizes, we proceeded to record whole-brain dynamics with the fLFM while presenting many repetitions of 3 to 6 different stimulus sizes spanning 1° to 40° (see Methods for details). Investigating the responses of individual neurons across the whole brain, we indeed found that even neurons highly tuned to a particular stimulus exhibited variability in their responses across multiple presentations of the same stimuli (<xref rid="fig3" ref-type="fig">Figure 3A</xref>). Given that downstream decision-making neuronal ensembles likely pool information from many visually tuned neurons, we asked whether an optimal population decoder could reliably extract information about the visual stimulus across trials. We proceeded to build various logistic regression classifiers to decode which visual stimulus was presented from the whole-brain neuronal activity pattern during the stimulus presentation period of each trial. We found that despite the observed variability on the single neuron level, the stimuli could be reliably decoded from the visually-tuned neurons identified within the whole-brain population activity (<xref rid="fig3" ref-type="fig">Figure 3B</xref>) at the single trial level with an accuracy of 94 ± 2% (mean ± 95% confidence interval). This robust decodability suggests that the observed single neuron variability does not severely limit the information encoding capacity at the population level.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3:</label>
<caption><title>Trial-to-trial variability in visually-evoked neurons is largely orthogonal to visual decoding dimensions</title>
<p><bold>A.</bold> Individual visually tuned neurons exhibit trial-to-trial variability in their responses to stimuli. For each of the six visual stimuli (three object sizes on both the left and right visual fields), the two neurons exhibiting the highest correlation with the stimulus kernel (see Methods for details) are shown for an example larva. Each column represents a neuron, and each line represents its response to a given stimulus during a single trial.</p>
<p><bold>B.</bold> Visual stimuli are reliably decodable from whole-brain dynamics on the single trial level. The visual stimuli were decoded using a logistic regression classifier with lasso regularization (see Methods for details). For each larva, a confusion matrix is computed for the test trials during 6-fold cross-validation. Shown is the average confusion matrix across n=8 larvae which were shown six visual stimuli.</p>
<p><bold>C.</bold> Schematic of potential geometric relationships between sensory decoding and neural variability dimensions. In each plot, each dot represents the neural response during a single presentation of stimulus A or B. The decision boundary for an optimal classifier is denoted with a dashed line, and the optimal stimulus decoding direction is denoted by the vector <inline-formula><inline-graphic xlink:href="583208v1_inline32.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. The direction representing the maximal trial-to-trial variance is denoted by <inline-formula><inline-graphic xlink:href="583208v1_inline33.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, and can be calculated by finding the first eigenvector of the noise covariance matrix (see Methods for details). These vectors can be: (i) orthogonal, such that neuronal variability does not limit the stimulus decoding; (ii) show little relationship, for example in the case of uniform variability; or (iii) aligned, such that variability likely limits the information encoding capacity along <inline-formula><inline-graphic xlink:href="583208v1_inline34.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.</p>
<p><bold>D.</bold> The trial-to-trial noise correlation matrix appears multi-dimensional. Shown is the average noise correlation matrix across all stimulus types presented. The neurons are sorted using rastermap, which produces a one-dimensional embedding of the neurons, such that neurons which show similar correlation profiles are placed near to one another. A number of neuronal populations exhibiting correlations across trials are apparent from the clusters of high correlations near the diagonal.</p>
<p><bold>E.</bold> Trial-to-trial variability in the visually-evoked neurons is largely orthogonal to visual decoding dimensions. The fraction of trial-to-trial variance explained by each noise mode <inline-formula><inline-graphic xlink:href="583208v1_inline35.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is plotting against the angle between <inline-formula><inline-graphic xlink:href="583208v1_inline36.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and the optimal stimulus decoding direction <inline-formula><inline-graphic xlink:href="583208v1_inline37.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. Shown are the <inline-formula><inline-graphic xlink:href="583208v1_inline38.gif" mimetype="image" mime-subtype="gif"/></inline-formula> for n=8 larvae, colored by their rank order <italic>α</italic> based on the fraction of variance explained. The largest noise modes were approximately orthogonal (∼90°) to the stimulus decoding direction, whereas only a few of the smallest noise modes exhibited angles less than 90°.</p>
<p><bold>F.</bold> Example projections of single trial neural activity along the stimulus decoding and noise dimensions. Each dot represents the average neural activity within a single trial projected along <inline-formula><inline-graphic xlink:href="583208v1_inline39.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="583208v1_inline40.gif" mimetype="image" mime-subtype="gif"/></inline-formula> for an example larva. Each of the six visual stimuli, three object sizes presented on either the right (green) or left (pink) visual field, are robustly encoded along <inline-formula><inline-graphic xlink:href="583208v1_inline41.gif" mimetype="image" mime-subtype="gif"/></inline-formula> across trials; however, in all stimuli there is strong orthogonal variability along <inline-formula><inline-graphic xlink:href="583208v1_inline42.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, the largest noise mode representing 39.5% of the trial-to-trial variance.</p>
<p><bold>G.</bold> Example neuron coefficients for <inline-formula><inline-graphic xlink:href="583208v1_inline43.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. Shown are the 366 neurons with the largest weights over a maximum intensity projection of the recorded volume. The visually-evoked neurons which encode stimulus information are concentrated within the optic tectum.</p>
<p><bold>H.</bold> Example neuron coefficients for <inline-formula><inline-graphic xlink:href="583208v1_inline44.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. Shown are the 828 neurons with the largest weights over a maximum intensity projection of the recorded volume. The visually-evoked neurons contributing to the largest noise mode are highly overlapping with the neurons contributing to <inline-formula><inline-graphic xlink:href="583208v1_inline45.gif" mimetype="image" mime-subtype="gif"/></inline-formula> in panel G.</p>
<p><bold>I.</bold> The neural noise modes are highly correlated with tail movements. Shown are both the GCaMP kernel-convolved tail vigor and the neuronal projection onto the first noise mode <inline-formula><inline-graphic xlink:href="583208v1_inline46.gif" mimetype="image" mime-subtype="gif"/></inline-formula> for a representative larva. Over the full two-hour recording, the tail vigor and noise mode projection exhibit a significant correlation of r=0.58, p&lt;10<sup>-6</sup>.</p>
<p><bold>J.</bold> The largest neural noise modes reflect brain-wide motor encoding. Shown are the correlations between the first noise mode <inline-formula><inline-graphic xlink:href="583208v1_inline47.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and the tail vigor (blue) or the first principal component (PC 1, orange) of whole-brain data (see Figure S3C). Dots show data from individual larvae, whereas the violin plots below show the null distribution for temporally shuffled data, in which the tail vigor or PC 1 are circularly permuted.</p></caption>
<graphic xlink:href="583208v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Given the wealth of literature debating whether trial-to-trial noise correlations could interfere with stimulus encoding (<xref ref-type="bibr" rid="c43">Moreno-Bote et al., 2014</xref>; <xref ref-type="bibr" rid="c27">Kanitscheider et al., 2015</xref>; <xref ref-type="bibr" rid="c73">Zylberberg et al., 2017</xref>; <xref ref-type="bibr" rid="c5">Bartolo et al., 2020</xref>; <xref ref-type="bibr" rid="c54">Rumyantsev et al., 2020</xref>; <xref ref-type="bibr" rid="c64">Valente et al., 2021</xref>; <xref ref-type="bibr" rid="c26">Kafashan et al., 2021</xref>) and potentially drive behavioral variability, we next asked how the observed neuronal variability was structured to prevent degradation of the visual encoding. We began by considering the dimensions that maximally explain trial-to-trial neuronal variability within the high-dimensional space of neuronal population dynamics, which are sometimes referred to as “noise modes” (<xref ref-type="bibr" rid="c54">Rumyantsev et al., 2020</xref>). Historically, the term “noise” is used to describe such trial-to-trial variability that is not related to the external stimulus; however, such noise could represent significant internal neuronal dynamics and not just measurement shot noise, for example. If the primary noise modes (represented by neural activity along the vectors <inline-formula><inline-graphic xlink:href="583208v1_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula>) are orthogonal to the optimal stimulus decoding direction <inline-formula><inline-graphic xlink:href="583208v1_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, then trial-to-trial variability will not hinder the visual stimulus decoding (<xref rid="fig3" ref-type="fig">Figure 3C</xref>(i)). In this case, the neuronal population may carry a multi-dimensional set of at least two variables and the visual stimulus encoding would be preserved. Trial-to-trial variability could also not be limited to a particular set of dimensions, for example if it represented noise that is uniformly distributed in the neural state space (<xref rid="fig3" ref-type="fig">Figure 3C</xref>(ii)), in which case pooling or averaging across sufficient neurons may still recover adequate stimulus information. Finally, trial-to-trial noise modes may be aligned with the stimulus decoding dimension (<xref rid="fig3" ref-type="fig">Figure 3C</xref>(iii)), which would maximally degrade the visual stimulus decoding.</p>
<p>To assess which of these scenarios applied to the geometry of trial-to-trial neural variability in our data, we first utilized partial least squares (PLS) regression to identify a low-dimensional subspace of the whole-brain neural activity that optimally preserved information about the visual stimulus (Figure S3A, see Methods for details), which we refer to as the visually-evoked neuronal activity patterns. Importantly, this approach ensures that we are identifying trial-to-trial neural variation that is contained within the visually-evoked neurons, as opposed to variability that is completely unrelated to visual encoding. Within these visually-evoked neurons, PLS regression also identifies the optimal stimulus decoding direction <inline-formula><inline-graphic xlink:href="583208v1_inline3.gif" mimetype="image" mime-subtype="gif"/></inline-formula> (Figure S3B). Additionally, trial-to-trial variability of the visually-evoked neurons is summarized by their noise covariance matrix, which describes how the activity of neurons covaries across trials (<xref ref-type="bibr" rid="c43">Moreno-Bote et al., 2014</xref>; <xref ref-type="bibr" rid="c33">Kohn et al., 2015</xref>). The average noise correlation matrix across all stimuli (see Methods for details) appeared highly structured and multi-dimensional (<xref rid="fig3" ref-type="fig">Figure 3D</xref>), indicating the presence of multiple neuronal ensembles whose activity is strongly correlated across trials. We analyzed the structure of this trial-to-trial noise by finding the eigenvectors <inline-formula><inline-graphic xlink:href="583208v1_inline4.gif" mimetype="image" mime-subtype="gif"/></inline-formula> of the average neural noise covariance matrix across all stimuli, following (<xref ref-type="bibr" rid="c54">Rumyantsev et al., 2020</xref>). As such, these noise modes <inline-formula><inline-graphic xlink:href="583208v1_inline5.gif" mimetype="image" mime-subtype="gif"/></inline-formula> represented the dimensions of neuronal activity within the visually-evoked neurons that maximally covaried across trials. We found that the noise modes were strongly structured since the trial-to-trial variance was concentrated in relatively few dimensions. The single largest noise mode captured up to 50% of the variance across larvae (<xref rid="fig3" ref-type="fig">Figure 3E</xref>, y-axis), indicating that such activity is likely not merely “noise” but potentially physiologically relevant. Thus, the observed neuronal variability was not independent across neurons, but strongly correlated. To assess the impact these noise modes could have on the stimulus decoding, we calculated the angles between the noise modes <inline-formula><inline-graphic xlink:href="583208v1_inline6.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="583208v1_inline7.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. We discovered that the noise modes containing the majority of the variance were orthogonal to <inline-formula><inline-graphic xlink:href="583208v1_inline8.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, while only the smallest noise modes contained any overlap the stimulus decoding direction <inline-formula><inline-graphic xlink:href="583208v1_inline9.gif" mimetype="image" mime-subtype="gif"/></inline-formula> (<xref rid="fig3" ref-type="fig">Figure 3E</xref>). This finding demonstrates that the structure underlying trial-to-trial neuronal variability in the zebrafish visual system lies in a regime closely resembling the orthogonal variability as illustrated in <xref rid="fig3" ref-type="fig">Figure 3C</xref>(i), as also previously observed in a subregion of mouse primary visual cortex (<xref ref-type="bibr" rid="c54">Rumyantsev et al., 2020</xref>). Thus, while even a small degree of observed overlap between sensory and noise modes can in principle limit the information encoding capacity of the visually-evoked neurons (<xref ref-type="bibr" rid="c43">Moreno-Bote et al., 2014</xref>), this orthogonal structure minimizes this limitation and is consistent with our previous finding that the stimuli presented in this study are highly decodable from the neuronal population dynamics (<xref rid="fig3" ref-type="fig">Figure 3B</xref>). The orthogonal relationship between sensory and noise modes can be visualized by projecting average neural activity within each trial onto the stimulus decoding direction <inline-formula><inline-graphic xlink:href="583208v1_inline10.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and the noise modes (<xref rid="fig3" ref-type="fig">Figure 3F</xref>).</p>
<p>We next mapped these neural coefficient vectors defining the stimulus decoding direction and the noise modes onto their anatomical locations of the larvae’s brain. As expected, the visually-evoked neurons were highly concentrated within the optic tectum, such that both the stimulus decoding direction (<xref rid="fig3" ref-type="fig">Figure 3G</xref>) and noise modes (<xref rid="fig3" ref-type="fig">Figure 3H</xref>) highly overlapped. The significance of each neuron’s contribution to <inline-formula><inline-graphic xlink:href="583208v1_inline11.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="583208v1_inline12.gif" mimetype="image" mime-subtype="gif"/></inline-formula> was assessed by comparing its coefficient to a distribution of coefficients derived from trial-shuffled data (see Methods for details). Overall, 30 ± 6% of visually-evoked neurons that significantly contributed to the largest noise mode <inline-formula><inline-graphic xlink:href="583208v1_inline13.gif" mimetype="image" mime-subtype="gif"/></inline-formula> also exhibited significant contributions to the stimulus decoding direction <inline-formula><inline-graphic xlink:href="583208v1_inline14.gif" mimetype="image" mime-subtype="gif"/></inline-formula> (mean ± 95% CI across n=10 larvae). Therefore, while many visually-evoked neurons have response components along both <inline-formula><inline-graphic xlink:href="583208v1_inline15.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="583208v1_inline16.gif" mimetype="image" mime-subtype="gif"/></inline-formula> , the neuronal population dynamics are highly structured such that activity patterns encoding external visual stimuli are reliable and largely independent from any trial-to-trial noise modes.</p>
<p>Given that these noise modes represented highly-structured neuronal variability across trials, we next asked whether they were at all related to the larvae’s behavior. First, we asked whether any noise modes were correlated with the vigor of the larvae’s tail movements, defined as the absolute tail curvature time series convolved with the GCaMP response kernel (see Methods for details). We found that the largest noise modes were correlated with the larvae’s instantaneous tail vigor (<xref rid="fig3" ref-type="fig">Figure 3I</xref>). While we identified the noise modes within the visually-evoked neuronal population, these noise modes were also highly correlated with the largest principal component (PC) of the whole-brain dynamics (<xref rid="fig3" ref-type="fig">Figure 3J</xref>). This indicates that both the observed trial-to-trial neuronal variability in visual regions and elsewhere across the brain are dominated by behavior-related activity (Figure S3C). In fact, 35 ± 15% of neurons with significant coefficients in the largest visual noise mode <inline-formula><inline-graphic xlink:href="583208v1_inline17.gif" mimetype="image" mime-subtype="gif"/></inline-formula> also significantly contributed to the first brain-wide PC (mean ± 95% CI across n=10 larvae, see Methods for details). While the lower variance noise modes did not exhibit clear motor-related activity, we suspected they may be involved in additional internal computations that may modulate decision making across trials. Taken together, these results show that visual stimuli are faithfully represented on the population level, and that the observed behavioral variability is not driven by changes in the fidelity of sensory encoding across trials. Instead, behavioral variability may be explained by additional, orthogonal dimensions of neuronal activity either within the visually-evoked population or elsewhere in the brain that are stimulus-independent but predictive of the larvae’s behavior.</p>
</sec>
<sec id="s2d">
<title>Pre-motor neuronal populations predictive of single-trial behavior</title>
<p>We hypothesized that there exists a pre-motor neuronal population that would be predictive of the larvae’s behavioral response in any given trial <italic>before</italic> movement initiation. As such, we aimed to identify any neural locus predictive of the larvae’s turn direction at various timepoints through each visual stimulus presentation. Thus, we looked beyond only the visually-evoked population and returned to the whole-brain activity patterns. In order to build predictive models from the neuronal dynamics despite varying reaction time across trials, we applied time-warping to the neuronal timeseries within each trial such that the stimulus onset and movement initiation timepoints were aligned across trials (<xref rid="fig4" ref-type="fig">Figure 4A</xref>, see Methods for details). We selected trials in which the larvae had a reaction time of at least one second from the stimulus onset (providing sufficient pre-motor neuronal data) and made its first tail movement with a defined minimum tail curvature to either the left or right, so as to separate clear left and right turns from simple forward locomotion. Further, we utilized trials from all visual object sizes to collect enough trials to reliably train models and thus identify populations predictive of decisions regardless of incoming sensory information. We found that there appeared to be neurons with differing time-warped activity patterns during left and right turn trials (<xref rid="fig4" ref-type="fig">Figure 4A</xref>, bottom). Additionally, we extracted trials in which the larva did not respond following the stimulus presentation, which were time-warped according to a randomly selected reaction time from the distribution in responsive trials. As such, each trial could be categorized according to the stimulus presented, the larva’s responsiveness (response/no response), and its turn direction (left/right) within responsive trials.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4:</label>
<caption><title>Pre-motor neuronal populations predictive of single-trial behavior.</title>
<p><bold>A.</bold> Trials are time-warped to align stimulus and decision onsets before classifying the turn direction. Top: Time-warped tail curvatures for trials in which the fish performed leftward or rightward turns, on the left and right, respectively. Bottom: Trial-averaged and time-warped neuronal timeseries for 15,286 neurons during left and right turns. The neurons are sorted using the rastermap algorithm. A time window is swept across the stimulus and decision timepoints to train binary classification models to predict the turn direction from the associated neuronal dynamics.</p>
<p><bold>B.</bold> Stimulus classification accuracy peaks after the onset of visual stimulation. The mean F score across n=7 larvae is used to assess the performance of 6-way multiclass classification of the presented visual stimulus as a function of warped time surrounding the stimulus onset (Stim.) and decision timepoint (Dec.). Shown is the mean ± 95% confidence interval of the F score for the best time window ending at the given timepoint (Data), compared to shuffled data in which the class labels are randomized. The black bar at the bottom indicates timepoints where the data have a significantly higher F score than the shuffled data (p&lt;0.05, paired t-test).</p>
<p><bold>C.</bold> Binary classification of responsiveness, whether or not the fish responds in a given trial, is significant throughout all time periods but accuracy peaks near movement initiation. As in panel B, except for binary classification of responsiveness. Nonresponsive trials are time-warped by randomly selecting a reaction time from the response trials and applying the same transformation.</p>
<p><bold>D. (i)</bold> Turn direction classification accuracy is significantly higher than shuffled data across the entire time-warped interval, but peaks near movement initiation. As in panel B, except for binary classification of turn direction. <bold>(ii)</bold> Single trial classification of turn direction across larvae. The mean confusion matrix across n=7 larvae, which show an accuracy of 77 ± 4% (mean ± 95% confidence interval).</p>
<p><bold>E.</bold> Single trial trajectories are separated based on responsiveness and turn direction. Shown are neural activity trajectories during single trials in an example larva projected onto the brain-wide neural dimensions that optimally separated turn direction and responsiveness.</p>
<p><bold>F.</bold> Consistent trial-averaged trajectories across larvae. As in panel F, except for the trial-averaged responses for n=6 example larvae. For the one bold animal, timepoints across the trial are indicated by a circle for trial start, diamond for the decision timepoint, and an X for the trial end.</p>
<p><bold>G.</bold> Real-time single-trial dynamics in an example larva. Along the turn direction neural projection, left and right trials are separated for many seconds before the decision timepoint, which is longer than the three second length of visual presentations. Activity along this dimension shows consistent ramping across trials approximately one second before movement.</p>
<p><bold>H.</bold> Example turn direction neuronal ensemble. Shown are the coefficients for all neurons which showed significantly higher (one-tailed t-test, p&lt;0.05) absolute coefficients in the real models compared to shuffled data in which the turn direction labels are randomly permuted.</p>
<p><bold>I.</bold> Highly distributed encoding of turn direction across larvae. The percentage of significant turn direction neurons located with the four major brain regions (Tel – telencephalon, Tec – optic tectum, Cer – cerebellum, and Hind – hindbrain) are shown for n=10 larvae. There is no significant difference between the percentage of neurons across brain regions (p&gt;0.05, paired t-test).</p>
<p><bold>J.</bold> Example responsiveness neuronal ensemble. As in panel I, except for responsiveness. Shown are the coefficients for all neurons which showed significantly higher (one-tailed t-test, p&lt;0.05) absolute coefficients in the real models compared to shuffled data in which the turn direction labels are randomly permuted.</p>
<p><bold>K.</bold> Highly distributed encoding of responsiveness across larvae. As in panel J, except for responsiveness. The percentage of significant turn direction neurons located with the four major brain regions (Tel – telencephalon, Tec – optic tectum, Cer – cerebellum, and Hind – hindbrain) are shown for n=10 larvae. There is no significant difference between the percentage of neurons across brain regions (p&gt;0.05, paired t-test).</p></caption>
<graphic xlink:href="583208v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We first asked whether the larvae’s responsiveness and turn direction could be accurately classified from the whole-brain neuronal dynamics within single trials, as well as how this predictability behaved over the pre-motor period. To identify the timepoints throughout the trial within which these could be accurately classified, we varied the time window of neuronal dynamics used to build a binary logistic regression classification model (Figure S4A). Neuronal activity across all neurons was integrated from the window start to the window end separately for each trial and then a model was trained on 80% of the trials. To assess the prediction accuracy at various timepoints throughout the trial, we utilized the mean F score across larvae on held-out trials, which measures the harmonic mean of the precision and recall. As expected, the multiclass stimulus prediction accuracy peaked shortly after the stimulus onset and remained high throughout the pre-motor and decision periods (<xref rid="fig4" ref-type="fig">Figure 4B</xref>). For both the responsiveness (<xref rid="fig4" ref-type="fig">Figure 4C</xref>) and the turn direction (<xref rid="fig4" ref-type="fig">Figure 4D</xref>(i)), the mean F score was consistent across the pre-stimulus and stimulus periods, before quickly ramping near the movement initiation timepoint. Interestingly, the classification performance was significantly higher than shuffled data at all timepoints (<xref rid="fig4" ref-type="fig">Figure 4C-D</xref>), including before the start of the stimulus presentation, with an average accuracy of 77.4 ± 4.4% (mean ± 95% CI across n=10 larvae) during the pre-motor period (<xref rid="fig4" ref-type="fig">Figure 4D</xref>(i)). These results suggest there are two dominant timescales which contribute to the larva’s behavioral response: a longer-timescale and relatively weak (but significant) activity pattern that does not appear aligned to stimulus or behavioral events, which we term the pre-stimulus turn bias; and a fast-timescale dramatic increase in predictability very near the decision, which we term the movement initiation dynamics.</p>
<p>Given that we observed the largest degree of behavioral variability in the responses to small-to-intermediate size stimuli (<xref rid="fig2" ref-type="fig">Figure 2G</xref>), we hypothesized that the pre-stimulus turn bias would be most influential (and thus most predictive of behavior) during such stimulus presentations, and less so during presentations of larger stimuli. Indeed, while the mean F scores for turn direction prediction were highly variable across larvae, on average the largest stimuli exhibited the lowest predictability from the pre-stimulus turn bias signal (Figure S4B, blue line). This likely reflects a more salient stimulus drive during large stimulus trials, which in the natural environment could reflect predators and a potential life-or-death decision for the larvae.</p>
<p>However, significant predictability was observed across all stimulus sizes during the movement initiation dynamics (Figure S4B, orange line). We thus argue that the pre-stimulus turn bias is subsequently combined with incoming stimulus information during action selection. Ultimately, the larva’s decision is then signaled by the dramatic increase in predictability during the movement initiation dynamics.</p>
<p>These single-trial predictions could be visualized by projecting the brain-wide neuronal activity during each trial onto the neural dimensions that optimally classified turn direction and responsiveness. Consistent with our classification performance, we found that the trajectories during single trials (<xref rid="fig4" ref-type="fig">Figure 4E</xref>) were highly separated according to the ultimate behavioral response. On average and across larvae, these trajectories remained localized in distinct quadrants throughout the entire trial (<xref rid="fig4" ref-type="fig">Figure 4F</xref>), including before and during the stimulus presentation period. This suggests that the observed behavioral variability is due in part to the initial internal state of the neural dynamics at the time of stimulus presentation and decision. Indeed, by removing the time-warping and observing the dynamics during single trials in real time, left and right turn trials appear separated for many seconds prior to the movement (longer than the 3 second visual trials). Ultimately, the decision to turn during the movement initiation dynamics appeared driven by a strong ramping activity approximately one second before the turn (<xref rid="fig4" ref-type="fig">Figure 4G</xref>). Thus, the identified neuronal dimensions exhibited reliable decoding within single trials driven by an initial bias and ultimately resulting in the observed movement initiation dynamics.</p>
<p>Next, we asked which specific neuronal populations across the brain contributed to the accurate pre-motor classification of behaviors, and thus could be involved in driving the decision of when and how to act. We considered a neuron to be significantly contributing to the behavioral prediction if its distribution of absolute coefficients across 6-fold cross-validation was significantly higher (one-tailed t-test, p&lt;0.05) when fit to real behavioral data as opposed to a null distribution created by randomly permuting the trial type labels. We found that both the ensemble of neurons which significantly contributed to the turn direction prediction (<xref rid="fig4" ref-type="fig">Figures 4H-I</xref>) and the responsiveness ensemble (<xref rid="fig4" ref-type="fig">Figures 4J-K</xref>) were highly distributed across the brain. Both of these distinct neuronal ensembles showed no significant difference in their distribution across the four major brain regions: the telencephalon (Tel), optic tectum (Tec), cerebellum (Cer), and hindbrain (Hind). Further, while this population included visually-evoked neurons within the optic tectum, we found that our previously identified noise modes <inline-formula><inline-graphic xlink:href="583208v1_inline18.gif" mimetype="image" mime-subtype="gif"/></inline-formula> were similarly predictive of single trial turn direction (Figure S4C), whereas the optimal stimulus decoding direction <inline-formula><inline-graphic xlink:href="583208v1_inline19.gif" mimetype="image" mime-subtype="gif"/></inline-formula> (<xref rid="fig3" ref-type="fig">Figure 3G</xref>) was not able to predict single-trial turn direction (Figure S4D). Thus, our data suggest that the neural dynamics underlying single-trial action selection are the result of a widely-distributed circuit that contains subpopulations encoding internal time-varying biases related to both the larva’s responsiveness and turn direction, yet distinct from the sensory encoding circuitry.</p>
<p>What could be the origin of these trial-to-trial biases in the larvae’s behavior? Given that our results demonstrate that it is possible to predict a behavioral bias before the visual stimulus is shown, we hypothesized these results could reflect the influence of the zebrafish neuronal circuitry for spontaneous turns, which includes the hindbrain oscillator (or anterior rhombencephalic turning region, ARTR) known to bias sequential turns towards a given direction (Dunn et al. 2016). While our pre-motor neuronal population is not exclusively localized to the ARTR, we did identify many neurons in the cerebellum and hindbrain (<xref rid="fig4" ref-type="fig">Figures 4J-K</xref>) whose locations were consistent with these known populations. As such, we asked whether spontaneous turns could be predicted from this same turn direction neuronal ensemble (<xref rid="fig5" ref-type="fig">Figure 5A</xref>). To address this question, we selected spontaneous turns that occurred either during inter-trial intervals or within a 2-minute period at the beginning of each recording without any stimulus presentations, utilizing the same criteria to define left and right turns as previously (see Methods for details). We then asked whether the spontaneous turn direction during periods without sensory stimulation could be predicted from the same turn direction neuronal ensemble and coefficients previously identified in <xref rid="fig4" ref-type="fig">Figure 4H-I</xref>. We found a significant correlation between the pre-motor turn direction predictions and the observed spontaneous tail curvature across larvae (<xref rid="fig5" ref-type="fig">Figure 5B</xref>, r=0.41, p&lt;0.05), suggesting this same ensemble is activated prior to both spontaneous and visually-evoked turns. This ensemble had a pre-motor turn direction classification accuracy of 70.2 ± 6.0% (mean ± 95% CI across n=5 larvae, <xref rid="fig5" ref-type="fig">Figure 5C</xref>). Thus, these results demonstrate that a portion of the observed behavioral variability is overlapping with the larva’s motor circuitry responsible for generation of spontaneous behavior.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5:</label>
<caption><title>Spontaneous turns are predictable from the same pre-motor neuronal population</title>
<p><bold>A.</bold> Schematic of the approach to predict spontaneous turns. Models are fit to predict left or right turn direction during visual trials (top), as in <xref rid="fig4" ref-type="fig">Figure 4</xref>. They are then tested on pre-motor periods one second before the spontaneous turn.</p>
<p><bold>B.</bold> Spontaneous turns are predicted from visual-evoked model. Shown is the relationship between the spontaneous tail curvature and the predicted pre-motor turn direction using the visual-evoked model. Each dot is a single spontaneous turn and each color represents a different larva. They exhibit a significant correlation of r=0.41, p&lt;0.05.</p>
<p><bold>C.</bold> Spontaneous turn classification accuracy. The mean cross-validated confusion matrix for spontaneous turn classification over n=5 larvae. Spontaneous turns are predicted with an accuracy of 70.2 ± 6.0% (mean ± 95% CI across n=5 larvae).</p></caption>
<graphic xlink:href="583208v1_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Our data highlight that the neural mechanisms involved in single-trial decision making are reflected in a highly distributed ensemble of neurons across the larval zebrafish brain. Further, behavioral variability, particularly in the larvae’s responses to small-to-intermediate size stimuli, can be partially explained by an internal, task-independent turn bias that is unrelated to the visual stimulation, while their stimulus-driven responses to larger predator-like stimuli exhibited a comparatively lower level of behavioral variability. This suggests the importance of considering how internal biases and circuits governing spontaneous movements interact with the well-studied sensorimotor circuits to govern how the brain generates behavior in a naturalistic context.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>In this study, we designed and built an optimized, high-resolution Fourier light field microscope (fLFM) to perform whole-brain imaging of the larval zebrafish in order to investigate the nature of trial-to-trial variability in neuronal dynamics and behavior on whole-brain yet cellular level. To do so, we studied visually-evoked turns within two ethologically relevant behaviors with opposing valance, prey capture and escape response, each of which are on average driven by distinct pre-motor neuronal ensembles (<xref ref-type="bibr" rid="c8">Bollmann, 2019</xref>) dependent on the size of the given sensory stimulus. Consistent with previous results (<xref ref-type="bibr" rid="c4">Barker and Baier, 2015</xref>), we found that the larvae’s behavioral responses were highly variable across presentations of the same stimulus, with behavioral variability peaking in response to stimulus of an intermediate size between those which optimally drive attraction or avoidance behaviors. Given that we lack a mechanistic understanding of which specific neuronal circuits drive the observed variance across trials, we utilized fLFM to screen whole-brain dynamics at cellular resolution and identify neuronal ensembles which contribute to behavioral variability at the single-trial level.</p>
<p>We first asked whether the observed behavioral variability could be explained by noise or trial-to-trial deviations in encoding of the visual stimuli. We found that despite the variable responses of individual neurons to visual stimuli across trials, the population response faithfully and reliably encoded the visual stimulus in each trial. Further, we discovered that the visually-evoked neuronal activity patterns were largely orthogonal to those dimensions that maximally covaried across stimulus repetitions, i.e. the noise modes, indicating that the source of behavioral variability was not unfaithful representation of the sensory inputs. Instead, we found that at least a third of the visually-evoked neurons which contributed to noise modes were related to motor behavior. We ultimately identified two brain-wide neuronal populations which could predict the larvae’s turn direction and responsiveness at the single-trial level. Surprisingly, a pre-stimulus bias component of these neuronal population activity could predict the larvae’s trial-by-trial turn direction even before the onset of the stimulus presentation with an average accuracy of 77%. while after stimulus onset, a sharp ramping of the activity of this neuronal population approximately one second before movement initiation allowed for an increased turn direction prediction accuracy of 90%. Taken together, our data show that the larva’s trial-by-trial decisions in response to any given stimulus are partially explained by pre-stimulus turn biases, and then ultimately driven by movement initiation dynamics which are broadcast within brain-wide neuronal ensembles.</p>
<p>In this context, the design of our behavioral paradigm has allowed us to gain insights into the nature of trial-to-trail neuronal and behavioral variability within and across two different ethologically relevant but highly divergent behaviors by tuning only a single parameter. This has allowed us to show that functionally different neuronal circuits have evolved to exhibit different levels of variability. Further, the differential interaction of such neuronal variability with the well-studied sensorimotor circuits may govern how the brain generates optimal behavior in different naturalistic contexts.</p>
<p>In addition, our study represents the first to our knowledge that identifies behavior-related noise correlations throughout an entire brain-wide sensorimotor decision-making circuit. The nearly orthogonal relationship between the stimulus decoding direction and trial-to-trial noise correlations is highly consistent with previous studies which found that noise correlations within single brain regions are organized so as to prevent additional information encoding channels within the same population from limiting sensory encoding capacity (<xref ref-type="bibr" rid="c26">Kafashan et al., 2021</xref>; <xref ref-type="bibr" rid="c54">Rumyantsev et al., 2020</xref>). However, even a small degree of overlap between noise and sensory dimensions may decrease the information encoding capacity of the population (<xref ref-type="bibr" rid="c43">Moreno-Bote et al., 2014</xref>). Why then might the brain favor a coding scheme in which populations mix information encoding with additional noise correlation structure?</p>
<p>Our data offer one possibility: that such additional correlations could encode internal or behavioral states that modulate sensorimotor transformations and behavioral output, enabling dynamic and flexible behavioral responses. Indeed, we found that a large fraction of the observed trial-to-trial neuronal variability was related to the larva’s behavior: including activity correlated the instantaneous behavioral state of the animal as well as pre-stimulus turn biases that correlated with responsiveness and turn direction. We found that the largest trial-to-trial noise mode within the visually-evoked neurons was a subset of a brain-wide population correlated with the vigor of the larva’s tail movements. This is conceptually similar to recent evidence in rodents that a large fraction of spontaneous neural activity reflects spontaneous and uninstructed movements (<xref ref-type="bibr" rid="c44">Musall et al., 2019</xref>; <xref ref-type="bibr" rid="c61">Stringer et al., 2019</xref>).</p>
<p>Taken together, our study represents the first whole-brain confirmation that behaviorally relevant information is highly mixed throughout neuronal populations involved in processing sensory and other information, potentially enabling flexible and context-dependent behavior. Our observation of time-varying neuronal ensembles encoding a turn direction bias is reminiscent of the larval zebrafish’s spontaneous swimming circuitry, which involves a central pattern generator (the ARTR) that biases the larva to swim in chains of turns in alternating directions (Timothy W Dunn et al., 2016); however, the neuronal populations we identified were not localized to the previously identified circuitry, and instead were distributed across the brain. While such spontaneous turn sequences are thought to underlie efficient exploration of local environments, our data could reflect a similar sensorimotor circuitry that injects variability as a learning mechanism to explore the space of possible sensorimotor consequences. Given the brain-wide distribution of the behavior-related ensembles within the variable visually-evoked behaviors studied here, we expect that they are not driven solely by a single central pattern generator as with ARTR and spontaneous turns, but instead involve the interaction of such pattern generators with the larva’s internal state and recent experience. It has been shown that such hindbrain oscillatory activity integrates recent visual to enable efficient phototaxis (<xref ref-type="bibr" rid="c68">Wolf et al., 2017</xref>), suggesting these pattern generators could act in concert with additional contextual populations. For example, it has been shown that hunger shifts decisions from avoidance to approach due to neuromodulation from the hypothalamic and serotonergic systems (<xref ref-type="bibr" rid="c19">Filosa et al., 2016</xref>). Further, our observed dynamics could also reflect the foraging state of the larva, which is known to be encoded by an oscillatory, neuromodulatory network distributed across the brain (<xref ref-type="bibr" rid="c40">Marques et al., 2020</xref>) and is a likely candidate to modulate a larva’s response to prey-sized stimuli. We envision that utilization of the wide array of genetically labelled lines that have been associated with these sensorimotor and neuromodulatory circuits (<xref ref-type="bibr" rid="c56">Semmelhack et al., 2014</xref>; <xref ref-type="bibr" rid="c4">Barker and Baier, 2015</xref>; <xref ref-type="bibr" rid="c40">Marques et al., 2020</xref>; <xref ref-type="bibr" rid="c47">Okamoto et al., 2021</xref>) could disentangle the specific contributions of the sensory, pre-motor, and internal state circuitry within the brain-wide populations observed here. Of particular interest will be how the activity of these populations is organized over longer timescales and modulated by visual input or internal states related to hunger and foraging, which are critical to balance feeding behaviors and predator avoidance within the developing larvae.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>We thank Q. Lin and S. Otero Coronel for discussions and feedback on the manuscript, T. Nöbauer and Y. Zhang for discussions regarding optical designs, and the members of the Vaziri Lab for discussions regarding the experiments and data analysis. We also thank A. Kaczynska, S. Campbell, and J. Hudspeth for housing zebrafish, and the Rockefeller University High Performance Computing Cluster for compute access. This work was supported in part by the National Institute of Neurological Disorders and Stroke of the National Institutes of Health under award numbers 1RF1NS113251 and 1RF1NS110501 and the Kavli Foundation through the Kavli Neural Systems Institute.</p>
</ack>
<sec id="s4">
<title>Author contributions</title>
<p>J.M. contributed to the project conceptualization, designed and built the imaging system, performed experiments, analyzed data, and wrote the manuscript. A.V. conceived, led and supervised the project, designed the imaging system and biological experiments, guided data analysis, and wrote the manuscript.</p>
</sec>
<sec id="s5">
<title>Methods</title>
<sec id="s5a">
<title>fLFM setup</title>
<p>The sample is illuminated with an LED excitation light (470 nm, Thorlabs M470L4) via Köhler illumination through a standard GFP filter set (Thorlabs MDF-GFP) and a 20×/1.0-NA water immersion objective (Olympus XLUMPLFLN). In order to reduce the amount of excitation light reaching the eyes of the zebrafish, an aluminum mask is placed in the Köhler illumination path conjugate to the sample plane. The imaging path consisted of a f=180 mm Olympus-style tube lens (Thorlabs TTL180-A), a f=180 mm achromatic doublet (Thorlabs AC508-180-A-ML) for the Fourier lens, and a 13×13 mm microlens array with 1.5 mm pitch and r=13.9 mm radius of curvature (OKO Tech APO-GB-P1500-R13.9). The microlens array is mounted inside a five-axis kinematic mount (Thorlabs) to allow precise placement of the array orthogonal to the optical axis. A 5.5-megapixel sCMOS camera (Andor Zyla) is then positioned at the focus of the microlens array to capture the fLFM images.</p>
<p>The theoretical lateral resolution of an fLFM Is limited by the numerical aperture <italic>NA<sub>ML</sub></italic> of the microlenses and the diffraction-limited spot size at the sensor. For an emission wavelength λ, Fourier lens focal length <italic>f<sub>fl</sub></italic>, objective magnification of <italic>M</italic>, and microlens diameter <italic>d<sub>MLA</sub></italic>, the Abbe diffraction limit when converted to object space and under the paraxial approximation is given by <inline-formula><inline-graphic xlink:href="583208v1_inline20.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. The theoretical axial resolution for a microlens array with a radius <italic>d<sub>max</sub></italic> is given by <inline-formula><inline-graphic xlink:href="583208v1_inline21.gif" mimetype="image" mime-subtype="gif"/></inline-formula> (<xref ref-type="bibr" rid="c24">Guo et al., 2019</xref>).</p>
</sec>
<sec id="s5b">
<title>Zebrafish experiments</title>
<p>For head-fixed zebrafish experiments, n=13 <italic>huc:h2b-gcamp6s</italic> larvae with pan-neuronal and nuclear-localized GCaMP6s (NL-GCaMP6s) expression were imaged 6-9 days post fertilization (dpf). The day before experiments were performed, we immobilized larvae by embedding them in 2.5% agarose approximately 10 mm from the edge of a 35mm petri dish. We then removed the agarose around their eyes and tail to allow for visual stimulation and tail movement. Larvae were not fed after immobilization and were thus in a starved state on the day of the experiment.</p>
<p>The petri dish was covered in a rear projection film (Screen Solutions Int.) such that visual stimuli could be projected directly onto the dish. The projector (BenQ TH671ST) output was filtered with a 610 nm longpass filter (Schott RG610) such that only red light was displayed, removing crosstalk between the stimulation and GCaMP fluorescence. The tail was illuminated with an 850 nm LED and then monitored from below using a near infrared CMOS camera (Ximea MQ013RG-ON).</p>
<p>Visual stimulation was controlled by Stytra (<xref ref-type="bibr" rid="c60">Štih et al., 2019</xref>). To check for intact visual circuitry, drifting gratings with a period of 40° (visual angle) and speed of 40°/s to the left or right were shown three times every 30 minutes. Only larvae that displayed a robust optomotor response were further analyzed. The remaining trials consisted of drifting dots that began in the center of the visual field and moved to either the left or right at 30°/s. Dots were shown at maximum contrast against a dark background. Various diameters were shown from 0.3° to 44° visual angle, with 3 to 6 different sizes used in a recording. Each trial lasted 3 seconds and the inter-trial interval was randomly distributed with a mean of 9 seconds and a standard deviation of 3 seconds.</p>
</sec>
<sec id="s5c">
<title>Data acquisition</title>
<p>The fLFM camera was triggered at 5 or 10 Hz using a microcontroller (Adafruit Grand Central). The first trigger was used to initiate the tail behavior camera. The tail was monitored in real-time using Stytra (<xref ref-type="bibr" rid="c60">Štih et al., 2019</xref>) at approximately 200 Hz. The recording duration lasted 1 to 2 hours.</p>
</sec>
<sec id="s5d">
<title>Data processing</title>
<p>Raw fLFM images were denoised using a custom-trained DeepInterpolation (<xref ref-type="bibr" rid="c34">Lecoq et al., 2021</xref>) model. We trained a “unet_single_1024” model with 5 pre and post frames on a training set of n=20 example recordings and validation set of n=5 recordings. We ran the training until convergence of the validation loss. Denoised raw fLFM images were then reconstructed using the Richardson-Lucy deconvolution algorithm. We performed the deconvolution with an experimental PSF found by measuring the profile of a 1 μm fluorescent bead through the axial depth in 2 μm increments. The Richardson-Lucy algorithm took about 1 second per iteration on a GPU (NVIDIA TITAN V) and we used 12 to 20 iterations per frame. This resulted in a reconstructed volume of approximately 760 × 360 × 280 μm<sup>3</sup> with voxels of 2.4 μm laterally and 4 μm axially.</p>
<p>Neuronal ROIs and timeseries were then extracted using the CNMF-E (<xref ref-type="bibr" rid="c70">Zhou et al., 2018</xref>) variant of the CaImAn software package (<xref ref-type="bibr" rid="c23">Giovannucci et al., 2019</xref>), which is optimized for processing of one-photon imaging data. Each plane was analyzed individually and then the results were merged. To determine neuronal ROIs, the SNR threshold was set at 2, the spatial consistency (rval) threshold was set at 0.8, and the CNN-based classifier threshold was set at 0.9. Neuronal timeseries were not deconvolved. Background fluorescence was factored out using the CNMF-E ring model. The planes were then collated by merging any units with a correlation greater than 0.7, lateral distance less than 10 μm, and axial distance less than 16 μm. Overlapping units were merged by summing each timeseries weighted by its SNR. Effects of photobleaching were removed by normalizing by a fit to the mean signal <italic>f</italic>(<italic>t</italic>) across all neurons over the recording with a bi-exponential model <inline-formula><inline-graphic xlink:href="583208v1_inline22.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. Each neuronal timeseries was then z-scored before all following analyses.</p>
</sec>
<sec id="s5e">
<title>Analysis of freely swimming behavior</title>
<p>For freely swimming experiments, n=9 6-9 dpf <italic>huc:h2b-gcamp6s</italic> larvae were individually placed in a 90 mm petri dish with a shallow (∼3 mm) amount of water. The dish was placed above a display (Apple iPad) with a 6 mm piece of clear acrylic in between. Black dots of sizes ranging from 1° to 30° were randomly shown at maximum contrast and moving across the dish in one direction at 30°/s. A camera (FLIR Grasshopper3 GS3-U3-41C6M-C) with a zoom lens (Navitar MVL7000) was mounted above to monitor the larvae’s behavior at &gt;100 Hz.</p>
<p>Each larva’s movements were tracked using DeepLabCut (<xref ref-type="bibr" rid="c41">Mathis et al., 2018</xref>), which was trained to track the position of the eyes, the swim bladder, and four points along the spline of the tail. Anipose was used to build a pipeline to process large numbers of videos (<xref ref-type="bibr" rid="c29">Karashchuk et al., 2020</xref>). Movement bouts were extracted by applying a threshold to the velocity of the centroid of the tracked points. Only movement bouts in which the centroid was within approximately six body lengths of the visual stimulus were further analyzed. For each bout, we then calculated the mean change in distance to the visual stimulus, with positive values denoting the larvae moving further away from the visual stimulus.</p>
</sec>
<sec id="s5f">
<title>Analysis of head-fixed behavior</title>
<p>During head-fixed visual experiments, 20 points along the spline of the larva’s tail were tracked in real time using Stytra (<xref ref-type="bibr" rid="c60">Štih et al., 2019</xref>). The overall tail curvature was then quantified by summing the angles between each segment of the tail tracking. For comparison with neural data, this was convolved with the NL-GCaMP6s kernel to define the tail direction kernel, while the GCaMP-kernel-convolved absolute tail curvature defined the tail vigor kernel.</p>
<p>Bouts of movement were extracted by thresholding the absolute tail curvature with a value <italic>σ<sub>active</sub></italic> set to one standard deviation of the absolute tail curvature over time. To study the behavioral response to various stimuli, the mean tail curvature during active bouts was computed for each stimulus presentation period; trials in which there were no movement bouts were excluded. For turn direction analyses, trials with a mean tail curvature during bouts &gt; <italic>σ<sub>active</sub></italic> were considered as left turn trials, whereas trials with a mean tail curvature during bouts &lt; −<italic>σ<sub>active</sub></italic> were considered right turn trials.</p>
</sec>
<sec id="s5g">
<title>Visual stimulus decoding</title>
<p>For the decoding shown in <xref rid="fig3" ref-type="fig">Figure 3B</xref>, the stimulus-evoked neural response was taken as the average response of each neuron during a single stimulus presentation. For each larva, a logistic regression model with lasso regularization was trained on all trials using 6-fold cross-validation with 3 repetitions. The lasso regularization parameter, which induces sparsity, was swept and the model with the highest average cross-validated accuracy was used. The confusion matrix, computed on the held-out testing trials, was reported as the average over all rounds of cross-validation.</p>
</sec>
<sec id="s5h">
<title>Identification of stimulus decoding and noise dimensions</title>
<p>The comparison of the neural dimensions encoding visual stimuli versus trial-to-trial noise was modeled after (<xref ref-type="bibr" rid="c54">Rumyantsev et al., 2020</xref>). Partial least squares (PLS) regression was used to find a low-dimensional space that optimally predicted the visual stimuli, which we refer to as the visually-evoked neuronal activity patterns. To perform regression, a visual stimulus kernel was constructed by summing the timeseries of each individual stimulus type, weighted by the stimulus size and negated for trials on the right visual field, thus providing a single response variable encoding both the location, size, and timing of all the stimulus presentations. This stimulus kernel was the convolved with the temporal response kernel of our calcium indicator (NL-GCaMP6s). The dimensionality <italic>d</italic> of PLS regression was optimized using 6-fold cross-validation with 3 repeats and choosing the dimensionalities with the lowest cross-validated mean squared error. The optimal stimulus decoding direction <inline-formula><inline-graphic xlink:href="583208v1_inline23.gif" mimetype="image" mime-subtype="gif"/></inline-formula> was identified by re-fitting the optimal PLS regression model with all timepoints.</p>
<p>For each stimulus type, the noise covariance matrix <italic>C</italic> was computed in the low-dimensional PLS space, given that direct estimation of the noise covariances across many thousands of neurons would likely be unreliable. A noise covariance matrix was calculated separately for each stimulus, and then averaged across all stimuli. The noise modes <inline-formula><inline-graphic xlink:href="583208v1_inline24.gif" mimetype="image" mime-subtype="gif"/></inline-formula> for <italic>α</italic> = 1 … <italic>d</italic> were identified by eigendecomposition of the mean noise covariance matrix across all stimuli, <inline-formula><inline-graphic xlink:href="583208v1_inline25.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. The angle between the optimal stimulus decoding direction and the noise modes is thus given by <inline-formula><inline-graphic xlink:href="583208v1_inline26.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.</p>
<p>The significance of each neurons’ contribution to a given neural population vector was evaluated by comparison to shuffled datasets. To created shuffled datasets, the ground truth stimulus presentation labels were randomly permuted. The same analysis above was performed on n=10 shuffled datasets, to identify a distribution of shuffled coefficients for the optimal stimulus decoding direction, noise modes, and largest principal component. A neuron was then considered to be significantly contributing to a given population vector if its absolute coefficient was greater than three standard deviations above the mean of that of the shuffled datasets.</p>
</sec>
<sec id="s5i">
<title>Classification of single trial turn direction, responsiveness, and stimulus</title>
<p>To predict decisions from neural activity despite the variable reaction times, each trial was time-warped in order to align the stimulus onset and the movement initiation timepoints, following (<xref ref-type="bibr" rid="c36">Lin et al., 2020</xref>). For no response trials, a random reaction time was selected from the responsive trials and the corresponding time-warping was applied. Logistic regression binary classification models with lasso regularization were fit to classify left versus right turn trials or response versus no response trials from various time windows of the time-warped neural activity. Thus, time-warped neuronal activity was averaged over windows from various start and end timepoints to determine the predictability at each time window. The optimal predictability at any given timepoint was then considered as the best time window that ended at that timepoint. For each larvae, 6-fold cross-validation with 3 repetitions was utilized to determine the cross-validated F score, accuracy, and confusion matrix. For stimulus classification, logistic regression was similarly applied for multi-class classification using the one-versus-rest scheme. Overall classification performance was quantified using the mean F score over larvae and was compared to shuffled data, in which the class labels had been randomly permuted.</p>
<p>Visualizations of single trial trajectories were made by projecting the time-warped trials onto the weights of an example, randomly chosen logistic regression model.</p>
<p>Significant neurons contributing to turn direction and responsiveness classification were identified by comparing a neuron’s absolute coefficient across the multiple cross-validation rounds to that from models fit to shuffled class labels. Neurons were deemed to be significantly contributed using a one-tailed t-test, p&lt;0.05. Brain regions (telencephalon, optic tectum, cerebellum, and hindbrain) were manually annotated to quantify the brain-wide distribution of significant neurons.</p>
</sec>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Afshar</surname> <given-names>A</given-names></string-name>, <string-name><surname>Santhanam</surname> <given-names>G</given-names></string-name>, <string-name><surname>Yu</surname> <given-names>BM</given-names></string-name>, <string-name><surname>Ryu</surname> <given-names>SI</given-names></string-name>, <string-name><surname>Sahani</surname> <given-names>M</given-names></string-name>, <string-name><surname>Shenoy</surname> <given-names>KV</given-names></string-name>. <year>2011</year>. <article-title>Single-Trial Neural Correlates of Arm Movement Preparation</article-title>. <source>Neuron</source> <volume>71</volume>:<fpage>555</fpage>–<lpage>564</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2011.05.047</pub-id></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Agard</surname> <given-names>DA</given-names></string-name>. <year>1984</year>. <article-title>Optical Sectioning Microscopy: Cellular Architecture in Three Dimensions</article-title>. <source>Annu Rev Bioph Biom</source> <volume>13</volume>:<fpage>191</fpage>–<lpage>219</lpage>. doi:<pub-id pub-id-type="doi">10.1146/annurev.bb.13.060184.001203</pub-id></mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Aimon</surname> <given-names>S</given-names></string-name>, <string-name><surname>Katsuki</surname> <given-names>T</given-names></string-name>, <string-name><surname>Jia</surname> <given-names>T</given-names></string-name>, <string-name><surname>Grosenick</surname> <given-names>L</given-names></string-name>, <string-name><surname>Broxton</surname> <given-names>M</given-names></string-name>, <string-name><surname>Deisseroth</surname> <given-names>K</given-names></string-name>, <string-name><surname>Sejnowski</surname> <given-names>TJ</given-names></string-name>, <string-name><surname>Greenspan</surname> <given-names>RJ</given-names></string-name>. <year>2019</year>. <article-title>Fast near-whole–brain imaging in adult Drosophila during responses to stimuli and behavior</article-title>. <source>Plos Biol</source> <volume>17</volume>:<fpage>e2006732</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pbio.2006732</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Barker</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>Baier</surname> <given-names>H</given-names></string-name>. <year>2015</year>. <article-title>Sensorimotor Decision Making in the Zebrafish Tectum</article-title>. <source>Curr Biol</source> <volume>25</volume>:<fpage>2804</fpage>–<lpage>2814</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cub.2015.09.055</pub-id></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Bartolo</surname> <given-names>R</given-names></string-name>, <string-name><surname>Saunders</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Mitz</surname> <given-names>AR</given-names></string-name>, <string-name><surname>Averbeck</surname> <given-names>BB</given-names></string-name>. <year>2020</year>. <article-title>Information-Limiting Correlations in Large Neural Populations</article-title>. <source>J Neurosci</source> <volume>40</volume>:<fpage>1668</fpage>–<lpage>1678</lpage>. doi:<pub-id pub-id-type="doi">10.1523/jneurosci.2072-19.2019</pub-id></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Bianco</surname> <given-names>IH</given-names></string-name>, <string-name><surname>Engert</surname> <given-names>F</given-names></string-name>. <year>2015</year>. <article-title>Visuomotor Transformations Underlying Hunting Behavior in Zebrafish</article-title>. <source>Curr Biol</source> <volume>25</volume>:<fpage>831</fpage>–<lpage>846</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cub.2015.01.042</pub-id></mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Bianco</surname> <given-names>IH</given-names></string-name>, <string-name><surname>Kampff</surname> <given-names>AR</given-names></string-name>, <string-name><surname>Engert</surname> <given-names>F</given-names></string-name>. <year>2011</year>. <article-title>Prey Capture Behavior Evoked by Simple Visual Stimuli in Larval Zebrafish</article-title>. <source>Frontiers Syst Neurosci</source> <volume>5</volume>:<fpage>101</fpage>. doi:<pub-id pub-id-type="doi">10.3389/fnsys.2011.00101</pub-id></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Bollmann</surname> <given-names>JH</given-names></string-name>. <year>2019</year>. <article-title>The Zebrafish Visual System: From Circuits to Behavior</article-title>. <source>Annu Rev Vis Sc</source> <volume>5</volume>:<fpage>269</fpage>–<lpage>293</lpage>. doi:<pub-id pub-id-type="doi">10.1146/annurev-vision-091718-014723</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Borla</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Palecek</surname> <given-names>B</given-names></string-name>, <string-name><surname>Budick</surname> <given-names>S</given-names></string-name>, <string-name><surname>O’Malley</surname> <given-names>DM</given-names></string-name>. <year>2002</year>. <article-title>Prey Capture by Larval Zebrafish: Evidence for Fine Axial Motor Control</article-title>. <source>Brain Behav Evol</source> <volume>60</volume>:<fpage>207</fpage>–<lpage>229</lpage>. doi:<pub-id pub-id-type="doi">10.1159/000066699</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Broxton</surname> <given-names>M</given-names></string-name>, <string-name><surname>Grosenick</surname> <given-names>L</given-names></string-name>, <string-name><surname>Yang</surname> <given-names>S</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>N</given-names></string-name>, <string-name><surname>Andalman</surname> <given-names>A</given-names></string-name>, <string-name><surname>Deisseroth</surname> <given-names>K</given-names></string-name>, <string-name><surname>Levoy</surname> <given-names>M</given-names></string-name>. <year>2013</year>. <article-title>Wave optics theory and 3-D deconvolution for the light field microscope</article-title>. <source>Opt Express</source> <volume>21</volume>:<fpage>25418</fpage>–<lpage>39</lpage>. doi:<pub-id pub-id-type="doi">10.1364/oe.21.025418</pub-id></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Chen</surname> <given-names>X</given-names></string-name>, <string-name><surname>Mu</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Hu</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Kuan</surname> <given-names>AT</given-names></string-name>, <string-name><surname>Nikitchenko</surname> <given-names>M</given-names></string-name>, <string-name><surname>Randlett</surname> <given-names>O</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>AB</given-names></string-name>, <string-name><surname>Gavornik</surname> <given-names>JP</given-names></string-name>, <string-name><surname>Sompolinsky</surname> <given-names>H</given-names></string-name>, <string-name><surname>Engert</surname> <given-names>F</given-names></string-name>, <string-name><surname>Ahrens</surname> <given-names>MB</given-names></string-name>. <year>2018</year>. <article-title>Brain-wide Organization of Neuronal Activity and Convergent Sensorimotor Transformations in Larval Zebrafish</article-title>. <source>Neuron</source> <volume>100</volume>:<fpage>876</fpage>–<lpage>890</lpage>.e5. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2018.09.042</pub-id></mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Cohen</surname> <given-names>MR</given-names></string-name>, <string-name><surname>Kohn</surname> <given-names>A</given-names></string-name>. <year>2011</year>. <article-title>Measuring and interpreting neuronal correlations</article-title>. <source>Nat Neurosci</source> <volume>14</volume>:<fpage>811</fpage>–<lpage>819</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.2842</pub-id></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>Cohen</surname> <given-names>MR</given-names></string-name>, <string-name><surname>Maunsell</surname> <given-names>JHR</given-names></string-name>. <year>2009</year>. <article-title>Attention improves performance primarily by reducing interneuronal correlations</article-title>. <source>Nat Neurosci</source> <volume>12</volume>:<fpage>1594</fpage>–<lpage>1600</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.2439</pub-id></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Cohen</surname> <given-names>N</given-names></string-name>, <string-name><surname>Yang</surname> <given-names>S</given-names></string-name>, <string-name><surname>Andalman</surname> <given-names>A</given-names></string-name>, <string-name><surname>Broxton</surname> <given-names>M</given-names></string-name>, <string-name><surname>Grosenick</surname> <given-names>L</given-names></string-name>, <string-name><surname>Deisseroth</surname> <given-names>K</given-names></string-name>, <string-name><surname>Horowitz</surname> <given-names>M</given-names></string-name>, <string-name><surname>Levoy</surname> <given-names>M</given-names></string-name>. <year>2014</year>. <article-title>Enhancing the performance of the light field microscope using wavefront coding</article-title>. <source>Opt Express</source> <volume>22</volume>:<fpage>24817</fpage>–<lpage>39</lpage>. doi:<pub-id pub-id-type="doi">10.1364/oe.22.024817</pub-id></mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Cong</surname> <given-names>L</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Chai</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Hang</surname> <given-names>W</given-names></string-name>, <string-name><surname>Shang</surname> <given-names>C</given-names></string-name>, <string-name><surname>Yang</surname> <given-names>W</given-names></string-name>, <string-name><surname>Bai</surname> <given-names>L</given-names></string-name>, <string-name><surname>Du</surname> <given-names>J</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>K</given-names></string-name>, <string-name><surname>Wen</surname> <given-names>Q.</given-names></string-name> <year>2017</year>. <article-title>Rapid whole brain imaging of neural activity in freely behaving larval zebrafish (Danio rerio)</article-title>. <source>Elife</source> <volume>6</volume>:<fpage>e28158</fpage>. doi:<pub-id pub-id-type="doi">10.7554/elife.28158</pub-id></mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><given-names>Dunn</given-names> <surname>Timothy W.</surname></string-name>, <string-name><surname>Gebhardt</surname> <given-names>C</given-names></string-name>, <string-name><surname>Naumann</surname> <given-names>EA</given-names></string-name>, <string-name><surname>Riegler</surname> <given-names>C</given-names></string-name>, <string-name><surname>Ahrens</surname> <given-names>MB</given-names></string-name>, <string-name><surname>Engert</surname> <given-names>F</given-names></string-name>, <string-name><surname>Del Bene</surname> <given-names>F</given-names></string-name>. <year>2016</year>. <article-title>Neural Circuits Underlying Visually Evoked Escapes in Larval Zebrafish</article-title>. <source>Neuron</source> <volume>89</volume>:<fpage>613</fpage>–<lpage>628</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2015.12.021</pub-id></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><given-names>Dunn</given-names> <surname>Timothy W</surname></string-name>, <string-name><surname>Mu</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Narayan</surname> <given-names>S</given-names></string-name>, <string-name><surname>Randlett</surname> <given-names>O</given-names></string-name>, <string-name><surname>Naumann</surname> <given-names>EA</given-names></string-name>, <string-name><surname>Yang</surname> <given-names>C-T</given-names></string-name>, <string-name><surname>Schier</surname> <given-names>AF</given-names></string-name>, <string-name><surname>Freeman</surname> <given-names>J</given-names></string-name>, <string-name><surname>Engert</surname> <given-names>F</given-names></string-name>, <string-name><surname>Ahrens</surname> <given-names>MB</given-names></string-name>. <year>2016</year>. <article-title>Brain-wide mapping of neural activity controlling zebrafish exploratory locomotion</article-title>. <source>Elife</source> <volume>5</volume>:<fpage>e12741</fpage>. doi:<pub-id pub-id-type="doi">10.7554/elife.12741</pub-id></mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Faisal</surname> <given-names>AA</given-names></string-name>, <string-name><surname>Selen</surname> <given-names>LPJ</given-names></string-name>, <string-name><surname>Wolpert</surname> <given-names>DM</given-names></string-name>. <year>2008</year>. <article-title>Noise in the nervous system</article-title>. <source>Nat Rev Neurosci</source> <volume>9</volume>:<fpage>292</fpage>–<lpage>303</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nrn2258</pub-id></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Filosa</surname> <given-names>A</given-names></string-name>, <string-name><surname>Barker</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>Dal Maschio</surname> <given-names>M</given-names></string-name>, <string-name><surname>Baier</surname> <given-names>H</given-names></string-name>. <year>2016</year>. <article-title>Feeding State Modulates Behavioral Choice and Processing of Prey Stimuli in the Zebrafish Tectum</article-title>. <source>Neuron</source> <volume>90</volume>:<fpage>596</fpage>–<lpage>608</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2016.03.014</pub-id></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Flavell</surname> <given-names>SW</given-names></string-name>, <string-name><surname>Gogolla</surname> <given-names>N</given-names></string-name>, <string-name><surname>Lovett-Barron</surname> <given-names>M</given-names></string-name>, <string-name><surname>Zelikowsky</surname> <given-names>M</given-names></string-name>. <year>2022</year>. <article-title>The emergence and influence of internal states</article-title>. <source>Neuron</source> <volume>110</volume>:<fpage>2545</fpage>–<lpage>2570</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2022.04.030</pub-id></mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Flavell</surname> <given-names>SW</given-names></string-name>, <string-name><surname>Pokala</surname> <given-names>N</given-names></string-name>, <string-name><surname>Macosko</surname> <given-names>EZ</given-names></string-name>, <string-name><surname>Albrecht</surname> <given-names>DR</given-names></string-name>, <string-name><surname>Larsch</surname> <given-names>J</given-names></string-name>, <string-name><surname>Bargmann</surname> <given-names>CI</given-names></string-name>. <year>2013</year>. <article-title>Serotonin and the Neuropeptide PDF Initiate and Extend Opposing Behavioral States in C. elegans</article-title>. <source>Cell</source> <volume>154</volume>:<fpage>1023</fpage>–<lpage>1035</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cell.2013.08.001</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Förster</surname> <given-names>D</given-names></string-name>, <string-name><surname>Helmbrecht</surname> <given-names>TO</given-names></string-name>, <string-name><surname>Mearns</surname> <given-names>DS</given-names></string-name>, <string-name><surname>Jordan</surname> <given-names>L</given-names></string-name>, <string-name><surname>Mokayes</surname> <given-names>N</given-names></string-name>, <string-name><surname>Baier</surname> <given-names>H</given-names></string-name>. <year>2020</year>. <article-title>Retinotectal circuitry of larval zebrafish is adapted to detection and pursuit of prey</article-title>. <source>Elife</source> <volume>9</volume>:<fpage>e58596</fpage>. doi:<pub-id pub-id-type="doi">10.7554/elife.58596</pub-id></mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Giovannucci</surname> <given-names>A</given-names></string-name>, <string-name><surname>Friedrich</surname> <given-names>J</given-names></string-name>, <string-name><surname>Gunn</surname> <given-names>P</given-names></string-name>, <string-name><surname>Kalfon</surname> <given-names>J</given-names></string-name>, <string-name><surname>Brown</surname> <given-names>BL</given-names></string-name>, <string-name><surname>Koay</surname> <given-names>SA</given-names></string-name>, <string-name><surname>Taxidis</surname> <given-names>J</given-names></string-name>, <string-name><surname>Najafi</surname> <given-names>F</given-names></string-name>, <string-name><surname>Gauthier</surname> <given-names>JL</given-names></string-name>, <string-name><surname>Zhou</surname> <given-names>P</given-names></string-name>, <string-name><surname>Khakh</surname> <given-names>BS</given-names></string-name>, <string-name><surname>Tank</surname> <given-names>DW</given-names></string-name>, <string-name><surname>Chklovskii</surname> <given-names>DB</given-names></string-name>, <string-name><surname>Pnevmatikakis</surname> <given-names>EA</given-names></string-name>. <year>2019</year>. <article-title>CaImAn an open source tool for scalable calcium imaging data analysis</article-title>. <source>Elife</source> <volume>8</volume>:<fpage>e38173</fpage>. doi:<pub-id pub-id-type="doi">10.7554/elife.38173</pub-id></mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Guo</surname> <given-names>C</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>W</given-names></string-name>, <string-name><surname>Hua</surname> <given-names>X</given-names></string-name>, <string-name><surname>Li</surname> <given-names>H</given-names></string-name>, <string-name><surname>Jia</surname> <given-names>S</given-names></string-name>. <year>2019</year>. <article-title>Fourier light-field microscopy</article-title>. <source>Opt Express</source> <volume>27</volume>:<fpage>25573</fpage>. doi:<pub-id pub-id-type="doi">10.1364/oe.27.025573</pub-id></mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Huang</surname> <given-names>X</given-names></string-name>, <string-name><surname>Lisberger</surname> <given-names>SG</given-names></string-name>. <year>2009</year>. <article-title>Noise correlations in cortical area MT and their potential impact on trial-by-trial variation in the direction and speed of smooth-pursuit eye movements</article-title>. <source>J Neurophysiol</source> <volume>101</volume>:<fpage>3012</fpage>–<lpage>30</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.00010.2009</pub-id></mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>Kafashan</surname> <given-names>M</given-names></string-name>, <string-name><surname>Jaffe</surname> <given-names>AW</given-names></string-name>, <string-name><surname>Chettih</surname> <given-names>SN</given-names></string-name>, <string-name><surname>Nogueira</surname> <given-names>R</given-names></string-name>, <string-name><surname>Arandia-Romero</surname> <given-names>I</given-names></string-name>, <string-name><surname>Harvey</surname> <given-names>CD</given-names></string-name>, <string-name><surname>Moreno-Bote</surname> <given-names>R</given-names></string-name>, <string-name><surname>Drugowitsch</surname> <given-names>J</given-names></string-name>. <year>2021</year>. <article-title>Scaling of sensory information in large neural populations shows signatures of information-limiting correlations</article-title>. <source>Nat Commun</source> <volume>12</volume>:<fpage>473</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41467-020-20722-y</pub-id></mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>Kanitscheider</surname> <given-names>I</given-names></string-name>, <string-name><surname>Coen-Cagli</surname> <given-names>R</given-names></string-name>, <string-name><surname>Pouget</surname> <given-names>A</given-names></string-name>. <year>2015</year>. <article-title>Origin of information-limiting noise correlations</article-title>. <source>Proc National Acad Sci</source> <volume>112</volume>:<fpage>E6973</fpage>–<lpage>E6982</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1508738112</pub-id></mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><string-name><surname>Kao</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Nuyujukian</surname> <given-names>P</given-names></string-name>, <string-name><surname>Ryu</surname> <given-names>SI</given-names></string-name>, <string-name><surname>Churchland</surname> <given-names>MM</given-names></string-name>, <string-name><surname>Cunningham</surname> <given-names>JP</given-names></string-name>, <string-name><surname>Shenoy</surname> <given-names>KV</given-names></string-name>. <year>2015</year>. <article-title>Single-trial dynamics of motor cortex and their applications to brain-machine interfaces</article-title>. <source>Nat Commun</source> <volume>6</volume>:<fpage>7759</fpage>. doi:<pub-id pub-id-type="doi">10.1038/ncomms8759</pub-id></mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><string-name><surname>Karashchuk</surname> <given-names>P</given-names></string-name>, <string-name><surname>Rupp</surname> <given-names>KL</given-names></string-name>, <string-name><surname>Dickinson</surname> <given-names>ES</given-names></string-name>, <string-name><surname>Walling-Bell</surname> <given-names>S</given-names></string-name>, <string-name><surname>Sanders</surname> <given-names>E</given-names></string-name>, <string-name><surname>Azim</surname> <given-names>E</given-names></string-name>, <string-name><surname>Brunton</surname> <given-names>BW</given-names></string-name>, <string-name><surname>Tuthill</surname> <given-names>JC</given-names></string-name>. <year>2020</year>. <article-title>Anipose: A toolkit for robust markerless 3D pose estimation</article-title>. <source>Cell Reports</source> <volume>36</volume>:<fpage>109730</fpage>. doi:<pub-id pub-id-type="doi">10.1016/j.celrep.2021.109730</pub-id></mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>Kaufman</surname> <given-names>MT</given-names></string-name>, <string-name><surname>Churchland</surname> <given-names>MM</given-names></string-name>, <string-name><surname>Ryu</surname> <given-names>SI</given-names></string-name>, <string-name><surname>Shenoy</surname> <given-names>KV</given-names></string-name>. <year>2015</year>. <article-title>Vacillation, indecision and hesitation in moment-by-moment decoding of monkey motor cortex</article-title>. <source>Elife</source> <volume>4</volume>:<fpage>e04677</fpage>. doi:<pub-id pub-id-type="doi">10.7554/elife.04677</pub-id></mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>Kauvar</surname> <given-names>IV</given-names></string-name>, <string-name><surname>Machado</surname> <given-names>TA</given-names></string-name>, <string-name><surname>Yuen</surname> <given-names>E</given-names></string-name>, <string-name><surname>Kochalka</surname> <given-names>J</given-names></string-name>, <string-name><surname>Choi</surname> <given-names>M</given-names></string-name>, <string-name><surname>Allen</surname> <given-names>WE</given-names></string-name>, <string-name><surname>Wetzstein</surname> <given-names>G</given-names></string-name>, <string-name><surname>Deisseroth</surname> <given-names>K</given-names></string-name>. <year>2020</year>. <article-title>Cortical Observation by Synchronous Multifocal Optical Sampling Reveals Widespread Population Encoding of Actions</article-title>. <source>Neuron</source>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2020.04.023</pub-id></mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><string-name><surname>Kim</surname> <given-names>TH</given-names></string-name>, <string-name><surname>Schnitzer</surname> <given-names>MJ</given-names></string-name>. <year>2022</year>. <article-title>Fluorescence imaging of large-scale neural ensemble dynamics</article-title>. <source>Cell</source> <volume>185</volume>:<fpage>9</fpage>–<lpage>41</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cell.2021.12.007</pub-id></mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><string-name><surname>Kohn</surname> <given-names>A</given-names></string-name>, <string-name><surname>Coen-Cagli</surname> <given-names>R</given-names></string-name>, <string-name><surname>Kanitscheider</surname> <given-names>I</given-names></string-name>, <string-name><surname>Pouget</surname> <given-names>A</given-names></string-name>. <year>2015</year>. <article-title>Correlations and Neuronal Population Information</article-title>. <source>Annu Rev Neurosci</source> <volume>39</volume>:<fpage>1</fpage>–<lpage>20</lpage>. doi:<pub-id pub-id-type="doi">10.1146/annurev-neuro-070815-013851</pub-id></mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Lecoq</surname> <given-names>J</given-names></string-name>, <string-name><surname>Oliver</surname> <given-names>M</given-names></string-name>, <string-name><surname>Siegle</surname> <given-names>JH</given-names></string-name>, <string-name><surname>Orlova</surname> <given-names>N</given-names></string-name>, <string-name><surname>Ledochowitsch</surname> <given-names>P</given-names></string-name>, <string-name><surname>Koch</surname> <given-names>C</given-names></string-name>. <year>2021</year>. <article-title>Removing independent noise in systems neuroscience data using DeepInterpolation</article-title>. <source>Nat Methods</source> <volume>18</volume>:<fpage>1401</fpage>–<lpage>1408</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41592-021-01285-2</pub-id></mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>Levoy</surname> <given-names>M</given-names></string-name>, <string-name><surname>Ng</surname> <given-names>R</given-names></string-name>, <string-name><surname>Adams</surname> <given-names>A</given-names></string-name>, <string-name><surname>Footer</surname> <given-names>M</given-names></string-name>, <string-name><surname>Horowitz</surname> <given-names>M</given-names></string-name>. <year>2006</year>. <article-title>Light field microscopy</article-title>. <source>Acm T Graphic</source> <volume>25</volume>:<fpage>924</fpage>. doi:<pub-id pub-id-type="doi">10.1145/1141911.1141976</pub-id></mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><string-name><surname>Lin</surname> <given-names>Q</given-names></string-name>, <string-name><surname>Manley</surname> <given-names>J</given-names></string-name>, <string-name><surname>Helmreich</surname> <given-names>M</given-names></string-name>, <string-name><surname>Schlumm</surname> <given-names>F</given-names></string-name>, <string-name><surname>Li</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Robson</surname> <given-names>DN</given-names></string-name>, <string-name><surname>Engert</surname> <given-names>F</given-names></string-name>, <string-name><surname>Schier</surname> <given-names>A</given-names></string-name>, <string-name><surname>Nöbauer</surname> <given-names>T</given-names></string-name>, <string-name><surname>Vaziri</surname> <given-names>A</given-names></string-name>. <year>2020</year>. <article-title>Cerebellar Neurodynamics Predict Decision Timing and Outcome on the Single-Trial Level</article-title>. <source>Cell</source> <volume>180</volume>:<fpage>536</fpage>–<lpage>551</lpage>.e17. doi:<pub-id pub-id-type="doi">10.1016/j.cell.2019.12.018</pub-id></mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="other"><string-name><surname>Liu</surname> <given-names>FL</given-names></string-name>, <string-name><surname>Kuo</surname> <given-names>G</given-names></string-name>, <string-name><surname>Antipa</surname> <given-names>N</given-names></string-name>, <string-name><surname>Yanny</surname> <given-names>K</given-names></string-name>, <string-name><surname>Waller</surname> <given-names>L.</given-names></string-name> <year>2020</year>. <article-title>Fourier DiffuserScope: Single-shot 3D Fourier light field microscopy with a diffuser</article-title>. <source>Arxiv</source>. doi:<pub-id pub-id-type="doi">10.1364/oe.400876</pub-id></mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><string-name><surname>Llavador</surname> <given-names>A</given-names></string-name>, <string-name><surname>Sola-Pikabea</surname> <given-names>J</given-names></string-name>, <string-name><surname>Saavedra</surname> <given-names>G</given-names></string-name>, <string-name><surname>Javidi</surname> <given-names>B</given-names></string-name>, <string-name><surname>Martínez-Corral</surname> <given-names>M</given-names></string-name>. <year>2016</year>. <article-title>Resolution improvements in integral microscopy with Fourier plane recording</article-title>. <source>Opt Express</source> <volume>24</volume>:<fpage>20792</fpage>–<lpage>8</lpage>. doi:<pub-id pub-id-type="doi">10.1364/oe.24.020792</pub-id></mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><string-name><surname>Machado</surname> <given-names>TA</given-names></string-name>, <string-name><surname>Kauvar</surname> <given-names>IV</given-names></string-name>, <string-name><surname>Deisseroth</surname> <given-names>K</given-names></string-name>. <year>2022</year>. <article-title>Multiregion neuronal activity: the forest and the trees</article-title>. <source>Nat Rev Neurosci</source> <volume>23</volume>:<fpage>683</fpage>–<lpage>704</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41583-022-00634-0</pub-id></mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><string-name><surname>Marques</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Li</surname> <given-names>M</given-names></string-name>, <string-name><surname>Schaak</surname> <given-names>D</given-names></string-name>, <string-name><surname>Robson</surname> <given-names>DN</given-names></string-name>, <string-name><surname>Li</surname> <given-names>JM</given-names></string-name>. <year>2020</year>. <article-title>Internal state dynamics shape brainwide activity and foraging behaviour</article-title>. <source>Nature</source> <volume>577</volume>:<fpage>239</fpage>–<lpage>243</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41586-019-1858-z</pub-id></mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><string-name><surname>Mathis</surname> <given-names>A</given-names></string-name>, <string-name><surname>Mamidanna</surname> <given-names>P</given-names></string-name>, <string-name><surname>Cury</surname> <given-names>KM</given-names></string-name>, <string-name><surname>Abe</surname> <given-names>T</given-names></string-name>, <string-name><surname>Murthy</surname> <given-names>VN</given-names></string-name>, <string-name><surname>Mathis</surname> <given-names>MW</given-names></string-name>, <string-name><surname>Bethge</surname> <given-names>M</given-names></string-name>. <year>2018</year>. <article-title>DeepLabCut: markerless pose estimation of user-defined body parts with deep learning</article-title>. <source>Nat Neurosci</source> <volume>21</volume>:<fpage>1281</fpage>–<lpage>1289</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41593-018-0209-y</pub-id></mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><string-name><surname>Montijn</surname> <given-names>JS</given-names></string-name>, <string-name><surname>Meijer</surname> <given-names>GT</given-names></string-name>, <string-name><surname>Lansink</surname> <given-names>CS</given-names></string-name>, <string-name><surname>Pennartz</surname> <given-names>CMA</given-names></string-name>. <year>2016</year>. <article-title>Population-Level Neural Codes Are Robust to Single-Neuron Variability from a Multidimensional Coding Perspective</article-title>. <source>Cell Reports</source> <volume>16</volume>:<fpage>2486</fpage>–<lpage>2498</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.celrep.2016.07.065</pub-id></mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><string-name><surname>Moreno-Bote</surname> <given-names>R</given-names></string-name>, <string-name><surname>Beck</surname> <given-names>J</given-names></string-name>, <string-name><surname>Kanitscheider</surname> <given-names>I</given-names></string-name>, <string-name><surname>Pitkow</surname> <given-names>X</given-names></string-name>, <string-name><surname>Latham</surname> <given-names>P</given-names></string-name>, <string-name><surname>Pouget</surname> <given-names>A</given-names></string-name>. <year>2014</year>. <article-title>Information-limiting correlations</article-title>. <source>Nat Neurosci</source> <volume>17</volume>:<fpage>1410</fpage>–<lpage>1417</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.3807</pub-id></mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><string-name><surname>Musall</surname> <given-names>S</given-names></string-name>, <string-name><surname>Kaufman</surname> <given-names>MT</given-names></string-name>, <string-name><surname>Juavinett</surname> <given-names>AL</given-names></string-name>, <string-name><surname>Gluf</surname> <given-names>S</given-names></string-name>, <string-name><surname>Churchland</surname> <given-names>AK</given-names></string-name>. <year>2019</year>. <article-title>Single-trial neural dynamics are dominated by richly varied movements</article-title>. <source>Nat Neurosci</source> <volume>22</volume>:<fpage>1677</fpage>–<lpage>1686</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41593-019-0502-4</pub-id></mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><string-name><surname>Nöbauer</surname> <given-names>T</given-names></string-name>, <string-name><surname>Skocek</surname> <given-names>O</given-names></string-name>, <string-name><surname>Pernía-Andrade</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>Weilguny</surname> <given-names>L</given-names></string-name>, <string-name><surname>Traub</surname> <given-names>FM</given-names></string-name>, <string-name><surname>Molodtsov</surname> <given-names>MI</given-names></string-name>, <string-name><surname>Vaziri</surname> <given-names>A</given-names></string-name>. <year>2017</year>. <article-title>Video rate volumetric Ca2+ imaging across cortex using seeded iterative demixing (SID) microscopy</article-title>. <source>Nat Methods</source> <volume>14</volume>:<fpage>811</fpage>–<lpage>818</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nmeth.4341</pub-id></mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><string-name><surname>Nöbauer</surname> <given-names>T</given-names></string-name>, <string-name><surname>Zhang</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Kim</surname> <given-names>H</given-names></string-name>, <string-name><surname>Vaziri</surname> <given-names>A</given-names></string-name>. <year>2023</year>. <article-title>Mesoscale volumetric light-field (MesoLF) imaging of neuroactivity across cortical areas at 18 Hz</article-title>. <source>Nat Methods</source> <volume>20</volume>:<fpage>600</fpage>–<lpage>609</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41592-023-01789-z</pub-id></mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><string-name><surname>Okamoto</surname> <given-names>H</given-names></string-name>, <string-name><surname>Cherng</surname> <given-names>B-W</given-names></string-name>, <string-name><surname>Nakajo</surname> <given-names>H</given-names></string-name>, <string-name><surname>Chou</surname> <given-names>M-Y</given-names></string-name>, <string-name><surname>Kinoshita</surname> <given-names>M</given-names></string-name>. <year>2021</year>. <article-title>Habenula as the experience-dependent controlling switchboard of behavior and attention in social conflict and learning</article-title>. <source>Curr Opin Neurobiol</source> <volume>68</volume>:<fpage>36</fpage>–<lpage>43</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.conb.2020.12.005</pub-id></mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><string-name><surname>Oldfield</surname> <given-names>CS</given-names></string-name>, <string-name><surname>Grossrubatscher</surname> <given-names>I</given-names></string-name>, <string-name><surname>Chávez</surname> <given-names>M</given-names></string-name>, <string-name><surname>Hoagland</surname> <given-names>A</given-names></string-name>, <string-name><surname>Huth</surname> <given-names>AR</given-names></string-name>, <string-name><surname>Carroll</surname> <given-names>EC</given-names></string-name>, <string-name><surname>Prendergast</surname> <given-names>A</given-names></string-name>, <string-name><surname>Qu</surname> <given-names>T</given-names></string-name>, <string-name><surname>Gallant</surname> <given-names>JL</given-names></string-name>, <string-name><surname>Wyart</surname> <given-names>C</given-names></string-name>, <string-name><surname>Isacoff</surname> <given-names>EY</given-names></string-name>. <year>2020</year>. <article-title>Experience, circuit dynamics and forebrain recruitment in larval zebrafish prey capture</article-title>. <source>Elife</source> <volume>9</volume>:<fpage>e56619</fpage>. doi:<pub-id pub-id-type="doi">10.7554/elife.56619</pub-id></mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><string-name><surname>Pandarinath</surname> <given-names>C</given-names></string-name>, <string-name><surname>Ames</surname> <given-names>KC</given-names></string-name>, <string-name><surname>Russo</surname> <given-names>AA</given-names></string-name>, <string-name><surname>Farshchian</surname> <given-names>A</given-names></string-name>, <string-name><surname>Miller</surname> <given-names>LE</given-names></string-name>, <string-name><surname>Dyer</surname> <given-names>EL</given-names></string-name>, <string-name><surname>Kao</surname> <given-names>JC</given-names></string-name>. <year>2018</year>. <article-title>Latent Factors and Dynamics in Motor Cortex and Their Application to Brain–Machine Interfaces</article-title>. <source>J Neurosci</source> <volume>38</volume>:<fpage>9390</fpage>–<lpage>9401</lpage>. doi:<pub-id pub-id-type="doi">10.1523/jneurosci.1669-18.2018</pub-id></mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><string-name><surname>Patterson</surname> <given-names>BW</given-names></string-name>, <string-name><surname>Abraham</surname> <given-names>AO</given-names></string-name>, <string-name><surname>MacIver</surname> <given-names>MA</given-names></string-name>, <string-name><surname>McLean</surname> <given-names>DL</given-names></string-name>. <year>2013</year>. <article-title>Visually guided gradation of prey capture movements in larval zebrafish</article-title>. <source>J Exp Biology</source> <volume>216</volume>:<fpage>3071</fpage>–<lpage>3083</lpage>. doi:<pub-id pub-id-type="doi">10.1242/jeb.087742</pub-id></mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><string-name><surname>Portugues</surname> <given-names>R</given-names></string-name>, <string-name><surname>Engert</surname> <given-names>F</given-names></string-name>. <year>2009</year>. <article-title>The neural basis of visual behaviors in the larval zebrafish</article-title>. <source>Curr Opin Neurobiol</source> <volume>19</volume>:<fpage>644</fpage>–<lpage>647</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.conb.2009.10.007</pub-id></mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><string-name><surname>Prevedel</surname> <given-names>R</given-names></string-name>, <string-name><surname>Yoon</surname> <given-names>Y-G</given-names></string-name>, <string-name><surname>Hoffmann</surname> <given-names>M</given-names></string-name>, <string-name><surname>Pak</surname> <given-names>N</given-names></string-name>, <string-name><surname>Wetzstein</surname> <given-names>G</given-names></string-name>, <string-name><surname>Kato</surname> <given-names>S</given-names></string-name>, <string-name><surname>Schrödel</surname> <given-names>T</given-names></string-name>, <string-name><surname>Raskar</surname> <given-names>R</given-names></string-name>, <string-name><surname>Zimmer</surname> <given-names>M</given-names></string-name>, <string-name><surname>Boyden</surname> <given-names>ES</given-names></string-name>, <string-name><surname>Vaziri</surname> <given-names>A</given-names></string-name>. <year>2014</year>. <article-title>Simultaneous whole-animal 3D imaging of neuronal activity using light-field microscopy</article-title>. <source>Nat Methods</source> <volume>11</volume>:<fpage>727</fpage>–<lpage>730</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nmeth.2964</pub-id></mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><string-name><surname>Quicke</surname> <given-names>P</given-names></string-name>, <string-name><surname>Howe</surname> <given-names>CL</given-names></string-name>, <string-name><surname>Song</surname> <given-names>P</given-names></string-name>, <string-name><surname>Jadan</surname> <given-names>HV</given-names></string-name>, <string-name><surname>Song</surname> <given-names>C</given-names></string-name>, <string-name><surname>Knöpfel</surname> <given-names>T</given-names></string-name>, <string-name><surname>Neil</surname> <given-names>M</given-names></string-name>, <string-name><surname>Dragotti</surname> <given-names>PL</given-names></string-name>, <string-name><surname>Schultz</surname> <given-names>SR</given-names></string-name>, <string-name><surname>Foust</surname> <given-names>AJ.</given-names></string-name> <year>2020</year>. <article-title>Subcellular resolution 3D light field imaging with genetically encoded voltage indicators</article-title>. <source>Biorxiv</source> 2020.05.22.108191. doi:<pub-id pub-id-type="doi">10.1101/2020.05.22.108191</pub-id></mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><string-name><surname>Rumyantsev</surname> <given-names>OI</given-names></string-name>, <string-name><surname>Lecoq</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Hernandez</surname> <given-names>O</given-names></string-name>, <string-name><surname>Zhang</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Savall</surname> <given-names>J</given-names></string-name>, <string-name><surname>Chrapkiewicz</surname> <given-names>R</given-names></string-name>, <string-name><surname>Li</surname> <given-names>J</given-names></string-name>, <string-name><surname>Zeng</surname> <given-names>H</given-names></string-name>, <string-name><surname>Ganguli</surname> <given-names>S</given-names></string-name>, <string-name><surname>Schnitzer</surname> <given-names>MJ</given-names></string-name>. <year>2020</year>. <article-title>Fundamental bounds on the fidelity of sensory cortical coding</article-title>. <source>Nature</source> <volume>580</volume>:<fpage>100</fpage>–<lpage>105</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41586-020-2130-2</pub-id></mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><string-name><surname>Scrofani</surname> <given-names>G</given-names></string-name>, <string-name><surname>Sola-Pikabea</surname> <given-names>J</given-names></string-name>, <string-name><surname>Llavador</surname> <given-names>A</given-names></string-name>, <string-name><surname>Sanchez-Ortiga</surname> <given-names>E</given-names></string-name>, <string-name><surname>Barreiro</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Saavedra</surname> <given-names>G</given-names></string-name>, <string-name><surname>Garcia-Sucerquia</surname> <given-names>J</given-names></string-name>, <string-name><surname>Martínez-Corral</surname> <given-names>M</given-names></string-name>. <year>2017</year>. <article-title>FIMic: design for ultimate 3D-integral microscopy of in-vivo biological samples</article-title>. <source>Biomed Opt Express</source> <volume>9</volume>:<fpage>335</fpage>. doi:<pub-id pub-id-type="doi">10.1364/boe.9.000335</pub-id></mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><string-name><surname>Semmelhack</surname> <given-names>JL</given-names></string-name>, <string-name><surname>Donovan</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Thiele</surname> <given-names>TR</given-names></string-name>, <string-name><surname>Kuehn</surname> <given-names>E</given-names></string-name>, <string-name><surname>Laurell</surname> <given-names>E</given-names></string-name>, <string-name><surname>Baier</surname> <given-names>H</given-names></string-name>. <year>2014</year>. <article-title>A dedicated visual pathway for prey detection in larval zebrafish</article-title>. <source>Elife</source> <volume>3</volume>:<fpage>e04878</fpage>. doi:<pub-id pub-id-type="doi">10.7554/elife.04878</pub-id></mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><string-name><surname>Shadlen</surname> <given-names>MN</given-names></string-name>, <string-name><surname>Newsome</surname> <given-names>WT</given-names></string-name>. <year>1998</year>. <article-title>The Variable Discharge of Cortical Neurons: Implications for Connectivity, Computation, and Information Coding</article-title>. <source>J Neurosci</source> <volume>18</volume>:<fpage>3870</fpage>–<lpage>3896</lpage>. doi:<pub-id pub-id-type="doi">10.1523/jneurosci.18-10-03870.1998</pub-id></mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><string-name><surname>Skocek</surname> <given-names>O</given-names></string-name>, <string-name><surname>Nöbauer</surname> <given-names>T</given-names></string-name>, <string-name><surname>Weilguny</surname> <given-names>L</given-names></string-name>, <string-name><surname>Traub</surname> <given-names>FM</given-names></string-name>, <string-name><surname>Xia</surname> <given-names>CN</given-names></string-name>, <string-name><surname>Molodtsov</surname> <given-names>MI</given-names></string-name>, <string-name><surname>Grama</surname> <given-names>A</given-names></string-name>, <string-name><surname>Yamagata</surname> <given-names>M</given-names></string-name>, <string-name><surname>Aharoni</surname> <given-names>D</given-names></string-name>, <string-name><surname>Cox</surname> <given-names>DD</given-names></string-name>, <string-name><surname>Golshani</surname> <given-names>P</given-names></string-name>, <string-name><surname>Vaziri</surname> <given-names>A</given-names></string-name>. <year>2018</year>. <article-title>High-speed volumetric imaging of neuronal activity in freely moving rodents</article-title>. <source>Nat Methods</source> <volume>15</volume>:<fpage>429</fpage>–<lpage>432</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41592-018-0008-0</pub-id></mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><string-name><surname>Sternson</surname> <given-names>SM</given-names></string-name>. <year>2020</year>. <article-title>Exploring internal state-coding across the rodent brain</article-title>. <source>Curr Opin Neurobiol</source> <volume>65</volume>:<fpage>20</fpage>–<lpage>26</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.conb.2020.08.009</pub-id></mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><string-name><surname>Štih</surname> <given-names>V</given-names></string-name>, <string-name><surname>Petrucco</surname> <given-names>L</given-names></string-name>, <string-name><surname>Kist</surname> <given-names>AM</given-names></string-name>, <string-name><surname>Portugues</surname> <given-names>R</given-names></string-name>. <year>2019</year>. <article-title>Stytra: An open-source, integrated system for stimulation, tracking and closed-loop behavioral experiments</article-title>. <source>Plos Comput Biol</source> <volume>15</volume>:<fpage>e1006699</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pcbi.1006699</pub-id></mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><string-name><surname>Stringer</surname> <given-names>C</given-names></string-name>, <string-name><surname>Pachitariu</surname> <given-names>M</given-names></string-name>, <string-name><surname>Steinmetz</surname> <given-names>N</given-names></string-name>, <string-name><surname>Reddy</surname> <given-names>CB</given-names></string-name>, <string-name><surname>Carandini</surname> <given-names>M</given-names></string-name>, <string-name><surname>Harris</surname> <given-names>KD</given-names></string-name>. <year>2019</year>. <article-title>Spontaneous behaviors drive multidimensional, brainwide activity</article-title>. <source>Science</source> <volume>364</volume>:<fpage>eaav7893</fpage>. doi:<pub-id pub-id-type="doi">10.1126/science.aav7893</pub-id></mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><string-name><surname>Temizer</surname> <given-names>I</given-names></string-name>, <string-name><surname>Donovan</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Baier</surname> <given-names>H</given-names></string-name>, <string-name><surname>Semmelhack</surname> <given-names>JL</given-names></string-name>. <year>2015</year>. <article-title>A Visual Pathway for Looming-Evoked Escape in Larval Zebrafish</article-title>. <source>Curr Biol</source> <volume>25</volume>:<fpage>1823</fpage>–<lpage>1834</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cub.2015.06.002</pub-id></mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><string-name><surname>Torigoe</surname> <given-names>M</given-names></string-name>, <string-name><surname>Islam</surname> <given-names>T</given-names></string-name>, <string-name><surname>Kakinuma</surname> <given-names>H</given-names></string-name>, <string-name><surname>Fung</surname> <given-names>CCA</given-names></string-name>, <string-name><surname>Isomura</surname> <given-names>T</given-names></string-name>, <string-name><surname>Shimazaki</surname> <given-names>H</given-names></string-name>, <string-name><surname>Aoki</surname> <given-names>T</given-names></string-name>, <string-name><surname>Fukai</surname> <given-names>T</given-names></string-name>, <string-name><surname>Okamoto</surname> <given-names>H</given-names></string-name>. <year>2021</year>. <article-title>Zebrafish capable of generating future state prediction error show improved active avoidance behavior in virtual reality</article-title>. <source>Nat Commun</source> <volume>12</volume>:<fpage>5712</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41467-021-26010-7</pub-id></mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><string-name><surname>Valente</surname> <given-names>M</given-names></string-name>, <string-name><surname>Pica</surname> <given-names>G</given-names></string-name>, <string-name><surname>Bondanelli</surname> <given-names>G</given-names></string-name>, <string-name><surname>Moroni</surname> <given-names>M</given-names></string-name>, <string-name><surname>Runyan</surname> <given-names>CA</given-names></string-name>, <string-name><surname>Morcos</surname> <given-names>AS</given-names></string-name>, <string-name><surname>Harvey</surname> <given-names>CD</given-names></string-name>, <string-name><surname>Panzeri</surname> <given-names>S</given-names></string-name>. <year>2021</year>. <article-title>Correlations enhance the behavioral readout of neural population activity in association cortex</article-title>. <source>Nat Neurosci</source> <volume>24</volume>:<fpage>975</fpage>–<lpage>986</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41593-021-00845-1</pub-id></mixed-citation></ref>
<ref id="c65"><mixed-citation publication-type="journal"><string-name><surname>Vladimirov</surname> <given-names>N</given-names></string-name>, <string-name><surname>Mu</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Kawashima</surname> <given-names>T</given-names></string-name>, <string-name><surname>Bennett</surname> <given-names>DV</given-names></string-name>, <string-name><surname>Yang</surname> <given-names>C-T</given-names></string-name>, <string-name><surname>Looger</surname> <given-names>LL</given-names></string-name>, <string-name><surname>Keller</surname> <given-names>PJ</given-names></string-name>, <string-name><surname>Freeman</surname> <given-names>J</given-names></string-name>, <string-name><surname>Ahrens</surname> <given-names>MB</given-names></string-name>. <year>2014</year>. <article-title>Light-sheet functional imaging in fictively behaving zebrafish</article-title>. <source>Nat Methods</source> <volume>11</volume>:<fpage>883</fpage>–<lpage>884</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nmeth.3040</pub-id></mixed-citation></ref>
<ref id="c66"><mixed-citation publication-type="journal"><string-name><surname>Wei</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Inagaki</surname> <given-names>H</given-names></string-name>, <string-name><surname>Li</surname> <given-names>N</given-names></string-name>, <string-name><surname>Svoboda</surname> <given-names>K</given-names></string-name>, <string-name><surname>Druckmann</surname> <given-names>S</given-names></string-name>. <year>2019</year>. <article-title>An orderly single-trial organization of population dynamics in premotor cortex predicts behavioral variability</article-title>. <source>Nat Commun</source> <volume>10</volume>:<fpage>216</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41467-018-08141-6</pub-id></mixed-citation></ref>
<ref id="c67"><mixed-citation publication-type="journal"><string-name><surname>Weisenburger</surname> <given-names>S</given-names></string-name>, <string-name><surname>Vaziri</surname> <given-names>A</given-names></string-name>. <year>2018</year>. <article-title>A Guide to Emerging Technologies for Large-Scale and Whole-Brain Optical Imaging of Neuronal Activity</article-title>. <source>Annu Rev Neurosci</source> <volume>41</volume>:<fpage>431</fpage>–<lpage>452</lpage>. doi:<pub-id pub-id-type="doi">10.1146/annurev-neuro-072116-031458</pub-id></mixed-citation></ref>
<ref id="c68"><mixed-citation publication-type="journal"><string-name><surname>Wolf</surname> <given-names>S</given-names></string-name>, <string-name><surname>Dubreuil</surname> <given-names>AM</given-names></string-name>, <string-name><surname>Bertoni</surname> <given-names>T</given-names></string-name>, <string-name><surname>Böhm</surname> <given-names>UL</given-names></string-name>, <string-name><surname>Bormuth</surname> <given-names>V</given-names></string-name>, <string-name><surname>Candelier</surname> <given-names>R</given-names></string-name>, <string-name><surname>Karpenko</surname> <given-names>S</given-names></string-name>, <string-name><surname>Hildebrand</surname> <given-names>DGC</given-names></string-name>, <string-name><surname>Bianco</surname> <given-names>IH</given-names></string-name>, <string-name><surname>Monasson</surname> <given-names>R</given-names></string-name>, <string-name><surname>Debrégeas</surname> <given-names>G</given-names></string-name>. <year>2017</year>. <article-title>Sensorimotor computation underlying phototaxis in zebrafish</article-title>. <source>Nat Commun</source> <volume>8</volume>:<fpage>651</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41467-017-00310-3</pub-id></mixed-citation></ref>
<ref id="c69"><mixed-citation publication-type="journal"><string-name><surname>Yoon</surname> <given-names>Y-G</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Pak</surname> <given-names>N</given-names></string-name>, <string-name><surname>Park</surname> <given-names>D</given-names></string-name>, <string-name><surname>Dai</surname> <given-names>P</given-names></string-name>, <string-name><surname>Kang</surname> <given-names>JS</given-names></string-name>, <string-name><surname>Suk</surname> <given-names>H-J</given-names></string-name>, <string-name><surname>Symvoulidis</surname> <given-names>P</given-names></string-name>, <string-name><surname>Guner-Ataman</surname> <given-names>B</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>K</given-names></string-name>, <string-name><surname>Boyden</surname> <given-names>ES</given-names></string-name>. <year>2020</year>. <article-title>Sparse decomposition light-field microscopy for high speed imaging of neuronal activity</article-title>. <source>Optica</source> <volume>7</volume>:<fpage>1457</fpage>. doi:<pub-id pub-id-type="doi">10.1364/optica.392805</pub-id></mixed-citation></ref>
<ref id="c70"><mixed-citation publication-type="journal"><string-name><surname>Zhou</surname> <given-names>P</given-names></string-name>, <string-name><surname>Resendez</surname> <given-names>SL</given-names></string-name>, <string-name><surname>Rodriguez-Romaguera</surname> <given-names>J</given-names></string-name>, <string-name><surname>Jimenez</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Neufeld</surname> <given-names>SQ</given-names></string-name>, <string-name><surname>Giovannucci</surname> <given-names>A</given-names></string-name>, <string-name><surname>Friedrich</surname> <given-names>J</given-names></string-name>, <string-name><surname>Pnevmatikakis</surname> <given-names>EA</given-names></string-name>, <string-name><surname>Stuber</surname> <given-names>GD</given-names></string-name>, <string-name><surname>Hen</surname> <given-names>R</given-names></string-name>, <string-name><surname>Kheirbek</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Sabatini</surname> <given-names>BL</given-names></string-name>, <string-name><surname>Kass</surname> <given-names>RE</given-names></string-name>, <string-name><surname>Paninski</surname> <given-names>L</given-names></string-name>. <year>2018</year>. <article-title>Efficient and accurate extraction of in vivo calcium signals from microendoscopic video data</article-title>. <source>Elife</source> <volume>7</volume>:<fpage>e28728</fpage>. doi:<pub-id pub-id-type="doi">10.7554/elife.28728</pub-id></mixed-citation></ref>
<ref id="c71"><mixed-citation publication-type="journal"><string-name><surname>Zohary</surname> <given-names>E</given-names></string-name>, <string-name><surname>Shadlen</surname> <given-names>MN</given-names></string-name>, <string-name><surname>Newsome</surname> <given-names>WT</given-names></string-name>. <year>1994</year>. <article-title>Correlated neuronal discharge rate and its implications for psychophysical performance</article-title>. <source>Nature</source> <volume>370</volume>:<fpage>140</fpage>–<lpage>143</lpage>. doi:<pub-id pub-id-type="doi">10.1038/370140a0</pub-id></mixed-citation></ref>
<ref id="c72"><mixed-citation publication-type="journal"><string-name><surname>Zylberberg</surname> <given-names>J</given-names></string-name>, <string-name><surname>Cafaro</surname> <given-names>J</given-names></string-name>, <string-name><surname>Turner</surname> <given-names>MH</given-names></string-name>, <string-name><surname>Shea-Brown</surname> <given-names>E</given-names></string-name>, <string-name><surname>Rieke</surname> <given-names>F</given-names></string-name>. <year>2016</year>. <article-title>Direction-Selective Circuits Shape Noise to Ensure a Precise Population Code</article-title>. <source>Neuron</source> <volume>89</volume>:<fpage>369</fpage>–<lpage>383</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.019</pub-id></mixed-citation></ref>
<ref id="c73"><mixed-citation publication-type="journal"><string-name><surname>Zylberberg</surname> <given-names>J</given-names></string-name>, <string-name><surname>Pouget</surname> <given-names>A</given-names></string-name>, <string-name><surname>Latham</surname> <given-names>PE</given-names></string-name>, <string-name><surname>Shea-Brown</surname> <given-names>E</given-names></string-name>. <year>2017</year>. <article-title>Robust information propagation through noisy neural circuits</article-title>. <source>Plos Comput Biol</source> <volume>13</volume>:<fpage>e1005497</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pcbi.1005497</pub-id></mixed-citation></ref>
</ref-list>
<sec>
<p><bold>Supplementary Figure S3, related to <xref rid="fig3" ref-type="fig">Figure 3</xref>, trial-to-trial variability in visually-evoked neurons is largely orthogonal to visual decoding dimensions</bold></p>
<p><bold>A.</bold> Schematic of trial-to-trial noise mode identification. First, dimensionality reduction is applied to the whole-brain dynamics (left) to identify the neuronal activity patterns that optimally preserve visual information using partial least squares regression. Within these visually-evoked neurons, each trial’s average activity during the visual presentation is computed (middle, each dot represents a single trial corresponding to the pink or green stimulus condition). Finally, the covariance across trials is decomposed to find the noise modes <inline-formula><inline-graphic xlink:href="583208v1_inline27.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, which represent orthogonal directions within the visually-evoked neurons and ranked in order of decreasing variance.</p>
<p><bold>B.</bold> <inline-formula><inline-graphic xlink:href="583208v1_inline28.gif" mimetype="image" mime-subtype="gif"/></inline-formula> robustly encodes the visual stimulus. Shown are example time traces of the stimulus kernel (blue, where the size of the stimulus is encoded by the magnitude and which visual field it is presented in is encoded by the sign) and the neural projection onto <inline-formula><inline-graphic xlink:href="583208v1_inline29.gif" mimetype="image" mime-subtype="gif"/></inline-formula> (orange), which exhibit a correlation of r=0.88, p&lt;10<sup>-6</sup>.</p>
<p><bold>C.</bold> The largest brain-wide principal component (PC) encodes motor behavior. (i) Example time traces of the tail vigor (blue) and PC 1 (orange), which exhibit a correlation of r=0.51, p&lt;10<sup>-6</sup>. (ii) The coefficients of the neurons contributing most to the PC, which are distributed across the brain and are nearly all positively correlated with tail vigor.</p>
<p><bold>Supplementary Figure S4: related to <xref rid="fig4" ref-type="fig">Figure 4</xref>, pre-motor neuronal populations predictive of single-trial behavior.</bold></p>
<p><bold>A.</bold> Classification of turn direction as a function of time window analyzed. The mean F score across n=7 larvae is used to assess the performance of multi-class classification of the visual stimulus. Top: a time window is swept across various start timepoints (y-axis) and end timepoints (x-axis) to determine the classification performance across various time intervals of the neuronal dynamics. Bottom: Mean ± 95% confidence interval of the F score for the best time interval ending at the given timepoint (Data), compared to shuffled data in which the stimulus labels are randomized. The classification accuracy is significantly higher than shuffled data (p&lt;0.05, paired t-test) only after stimulus onset.</p>
<p><bold>B.</bold> Turn direction classification as a function of stimulus size. On average before stimulus onset (blue line), the F score is highest for the smallest size stimuli, whereas the F score is relatively constant at the time of movement initiation (orange line, mean ± 95% CI across n=5 larvae).</p>
<p><bold>C.</bold> As in A, except for classifying left or right turn direction from the projections onto the trial-to-trial noise modes <inline-formula><inline-graphic xlink:href="583208v1_inline30.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, as opposed to the whole-brain dynamics as used in <xref rid="fig4" ref-type="fig">Figure 4B</xref>.</p>
<p><bold>D.</bold> As in A, except for classifying left or right turn direction from the projection onto the optimal stimulus decoding dimension <inline-formula><inline-graphic xlink:href="583208v1_inline31.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.</p>
<p><bold>Video 1: related to <xref rid="fig2" ref-type="fig">Figure 2</xref>. Example target-directed and target-avoidance bouts in free behavior.</bold></p>
<p>On the left, an example target-directed bout showing a 7dpf larval zebrafish approaching a stimulus presented on a screen below the dish (see <xref rid="fig2" ref-type="fig">Figure 2A</xref>). On the right, a similar target-avoidance bout from the same larva. The videos are slowed down 10x. These videos correspond to the composite images shown in <xref rid="fig2" ref-type="fig">Figure 2B-C</xref>.</p>
</sec>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.97014.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Brody</surname>
<given-names>Carlos D</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Princeton University, Howard Hughes Medical Institute</institution>
</institution-wrap>
<city>Princeton</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>Manley and Vaziri introduce an <bold>important</bold> new method for brain-wide imaging of cellular activity in zebrafish and provide evidence for the applicability of this technique. They use this method to explore the question of how neural variability gives rise to variability in behavior. The analyses used are mostly <bold>convincing</bold>, with some central results that are currently <bold>incomplete</bold> and difficult to interpret.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.97014.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>In this paper, Manley and Vaziri investigate whole-brain neural activity underlying behavioural variability in zebrafish larvae. They combine whole brain (single cell level) calcium imaging during the presentation of visual stimuli, triggering either approach or avoidance, and carry out whole brain population analyses to identify whole brain population patterns responsible for behavioural variability. They show that similar visual inputs can trigger large variability in behavioural responses. Though visual neurons are also variable across trials, they demonstrate that this neural variability does not degrade population stimulus decodability. Instead, they find that the neural variability across trials is in orthogonal population dimensions to stimulus encoding and is correlated with motor output (e.g. tail vigor). They then show that behavioural variability across trials is largely captured by a brain-wide population state prior to the trial beginning, which biases choice - especially on ambiguous stimulus trials. This study suggests that parts of stimulus-driven behaviour can be captured by brain-wide population states that bias choice, independently of stimulus encoding.</p>
<p>Strengths:</p>
<p>-The strength of the paper principally resides in the whole brain cellular level imaging in a well-known but variable behaviour.</p>
<p>- The analyses are reasonable and largely answer the questions the authors ask.</p>
<p>- Overall the conclusions are well warranted.</p>
<p>Weaknesses:</p>
<p>A more in-depth exploration of some of the findings could be provided, such as:</p>
<p>- Given that thousands of neurons are recorded across the brain a more detailed parcelation of where the neurons contribute to different population coding dimensions would be useful to better understand the circuits involved in different computations.</p>
<p>- Given that the behaviour on average can be predicted by stimulus type, how does the stimulus override the brain-wide choice bias on some trials? In other words, a better link between the findings in Figures 2 and 3 would be useful for better understanding how the behaviour ultimately arises.</p>
<p>- What other motor outputs do the noise dimensions correlate with?</p>
<p>The dataset that the authors have collected is immensely valuable to the field, and the initial insights they have drawn are interesting and provide a good starting ground for a more expanded understanding of why a particular action is determined outside of the parameters experimenters set for their subjects.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.97014.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Overview</p>
<p>In this work, Manley and Vaziri investigate the neural basis for variability in the way an animal responds to visual stimuli evoking prey-capture or predator-avoidance decisions. This is an interesting problem and the authors have generated a potentially rich and relevant data set. To do so, the authors deployed Fourier light field microscopy (Flfm) of larval zebrafish, improving upon prior designs and image processing schemes to enable volumetric imaging of calcium signals in the brain at up to 10 Hz. They then examined associations between neural activity and tail movement to identify populations primarily related to the visual stimulus, responsiveness, or turn direction - moreover, they found that the activity of the latter two populations appears to predict upcoming responsiveness or turn direction even before the stimulus is presented. While these findings may be valuable for future more mechanistic studies, issues with resolution, rigor of analysis, clarity of presentation, and depth of connection to the prior literature significantly dampen enthusiasm.</p>
<p>Imaging</p>
<p>- Resolution: It is difficult to tell from the displayed images how good the imaging resolution is in the brain. Given scattering and lensing, it is important for data interpretation to have an understanding of how much PSF degrades with depth.</p>
<p>- Depth: In the methods it is indicated that the imaging depth was 280 microns, but from the images of Figure 1 it appears data was collected only up to 150 microns. This suggests regions like the hypothalamus, which may be important for controlling variation in internal states relevant to the behaviors being studied, were not included.</p>
<p>- Flfm data processing: It is important for data interpretation that the authors are clearer about how the raw images were processed. The de-noising process specifically needs to be explained in greater detail. What are the characteristics of the noise being removed? How is time-varying signal being distinguished from noise? Please provide a supplemental with images and algorithm specifics for each key step.</p>
<p>- Merging: It is noted that nearby pixels with a correlation greater than 0.7 were merged. Why was this done? Is this largely due to cross-contamination due to a drop in resolution? How common was this occurrence? What was the distribution of pixel volumes after aggregation? Should we interpret this to mean that a 'neuron' in this data set is really a small cluster of 10-20 neurons? This of course has great bearing on how we think about variability in the response shown later.</p>
<p>- Bleaching: Please give the time constants used in the fit for assessing bleaching.</p>
<p>Analysis</p>
<p>- Slow calcium dynamics: It does not appear that the authors properly account for the slow dynamics of calcium-sensing in their analysis. Nuclear-localized GCaMP6s will likely have a kernel with a multiple-second decay time constant for many of the cells being studied. The value used needs to be given and the authors should account for variability in this kernel time across cell types. Moreover, by not deconvolving their signals, the authors allow for contamination of their signal at any given time with a signal from multiple seconds prior. For example, in Figure 4A (left turns), it appears that much of the activity in the first half of the time-warped stimulus window began before stimulus presentation - without properly accounting for the kernel, we don't know if the stimulus-associated activity reported is really stimulus-associated firing or a mix of stimulus and pre-stimulus firing. This also suggests that in some cases the signals from the prior trial may contaminate the current trial.</p>
<p>- Partial Least Squares (PLS) regression: The steps taken to identify stimulus coding and noise dimensions are not sufficiently clear. Please provide a mathematical description.</p>
<p>- No response: It is not clear from the methods description if cases where the animal has no tail response are being lumped with cases where the animal decides to swim forward and thus has a large absolute but small mean tail curvature. These should be treated separately.</p>
<p>Results</p>
<p>- Behavioral variability: Related to Figure 2, within- and across-subject variability are confounded. Please disambiguate. It may also be informative on a per-fish basis to examine associations between reaction time and body movement.</p>
<p>- Data presentation clarity: All figure panels need scale bars - for example, in Figure 3A there is no indication of timescale (or time of stimulus presentation). Figure 3I should also show the time series of the w_opt projection.</p>
<p>- Pixel locations: Given the poor quality of the brain images, it is difficult to tell the location of highlighted pixels relative to brain anatomy. In addition, given that the midbrain consists of much more than the tectum, it is not appropriate to put all highlighted pixels from the midbrain under the category of tectum. To aid in data interpretation and better connect this work with the literature, it is recommended that the authors register their data sets to standard brain atlases and determine if there is any clustering of relevant pixels in regions previously associated with prey-capture or predator-avoidance behavior.</p>
<p>Interpretation</p>
<p>- W_opt and e_1 orthogonality: The statement that these two vectors, determined from analysis of the fluorescence data, are orthogonal, actually brings into question the idea that true signal and leading noise vectors in firing-rate state-space are orthogonal. First, the current analysis is confounding signals across different time periods - one could assume linearity all the way through the transformations, but this would only work if earlier sources of activation were being accounted for. Second, the transformation between firing rate and fluorescence is most likely not linear for GCaMP6s in most of the cells recorded. Thus, one would expect a change in the relationship between these vectors as one maps from fluorescence to firing rate.</p>
<p>- Sources of variability: The authors do not take into account a fairly obvious source of variability in trial-to-trial response - eye position. We know that prey capture responsiveness is dependent on eye position during stimulus (see Figure 4 of PMID: 22203793). We also expect that neurons fairly early in the visual pathway with relatively narrow receptive fields will show variable responses to visual stimuli as the degree of overlap with the receptive field varies with eye movement. There can also be small eye-tracking movements ahead of the decision to engage in prey capture (Figure 1D, PMID: 31591961) that can serve as a drive to initiate movements in a particular direction. Given these possibilities indicating that the behavioral measure of interest is gaze, and the fact that eye movements were apparently monitored, it is surprising that the authors did not include eye movements in the analysis and interpretation of their data.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.97014.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>In this study, Manley and Vaziri designed and built a Fourier light-field microscope (fLFM) inspired by previous implementations but improved and exclusively from commercially available components so others can more easily reproduce the design. They combined this with the design of novel algorithms to efficiently extract whole-brain activity from larval zebrafish brains.</p>
<p>This new microscope was applied to the question of the origin of behavioral variability. In an assay in which larval zebrafish are exposed to visual dots of various sizes, the fish respond by turning left or right or not responding at all. Neural activity was decomposed into an activity that encodes the stimulus reliably across trials, a 'noise' mode that varies across trials, and a mode that predicts tail movements. A series of analyses showed that trial-to-trial variability was largely orthogonal to activity patterns that encoded the stimulus and that these noise modes were related to the larvae's behavior.</p>
<p>To identify the origins of behavioral variability, classifiers were fit to the neural data to predict whether the larvae turned left or right or did not respond. A set of neurons that were highly distributed across the brain could be used to classify and predict behavior. These neurons could also predict spontaneous behavior that was not induced by stimuli above chance levels. The work concludes with findings on the distributed nature of single-trial decision-making and behavioral variability.</p>
<p>Strengths:</p>
<p>The design of the new fLFM microscope is a significant advance in light-field and computational microscopy, and the open-source design and software are promising to bring this technology into the hands of many neuroscientists.</p>
<p>The study addresses a series of important questions in systems neuroscience related to sensory coding, trial-to-trial variability in sensory responses, and trial-to-trial variability in behavior. The study combines microscopy, behavior, dynamics, and analysis and produces a well-integrated analysis of brain dynamics for visual processing and behavior. The analyses are generally thoughtful and of high quality. This study also produces many follow-up questions and opportunities, such as using the methods to look at individual brain regions more carefully, applying multiple stimuli, investigating finer tail movements and how these are encoded in the brain, and the connectivity that gives rise to the observed activity. Answering questions about variability in neural activity in the entire brain and its relationship to behavior is important to neuroscience and this study has done that to an interesting and rigorous degree.</p>
<p>Points of improvement and weaknesses:</p>
<p>The results on noise modes may be a bit less surprising than they are portrayed. The orthogonality between neural activity patterns encoding the sensory stimulus and the noise modes should be interpreted within the confounds of orthogonality in high-dimensional spaces. In higher dimensional spaces, it becomes more likely that two random vectors are almost orthogonal. Since the neural activity measurements performed in this study are quite high dimensional, a more explicit discussion is warranted about the small chance that the modes are not almost orthogonal.</p>
<p>The conclusion that sparsely distributed sets of neurons produce behavioral variability needs more investigation because the way the results are shown could lead to some misinterpretations. The prediction of behavior from classifiers applied to neural activity is interesting, but the results are insufficiently presented for two reasons.</p>
<p>(1) The neurons that contribute to the classifiers (Figures 4H and J) form a sufficient set of neurons that predict behavior, but this does not mean that neurons outside of that set cannot be used to predict behavior. Lasso regularization was used to create the classifiers and this induces sparsity. This means that if many neurons predict behavior but they do so similarly, the classifier may select only a few of them. This is not a problem in itself but it means that the distributions of neurons across the brain (Figures 4H and J) may appear sparser and more distributed than the full set of neurons that contribute to producing the behavior. This ought to be discussed better to avoid misinterpretation of the brain distribution results, and an alternative analysis that avoids the confound could help clarify.</p>
<p>(2) The distribution of neurons is shown in an overly coarse manner in only a flattened brain seen from the top, and the brain is divided into four coarse regions (telencephalon, tectum, cerebellum, hindbrain). This makes it difficult to assess where the neurons are and whether those four coarse divisions are representative or whether the neurons are in other non-labeled deeper regions. For these two reasons, some of the statements about the distribution of neurons across the brain would benefit from a more thorough investigation.</p>
</body>
</sub-article>
</article>