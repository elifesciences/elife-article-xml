<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">96402</article-id>
<article-id pub-id-type="doi">10.7554/eLife.96402</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.96402.2</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.3</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories><title-group>
<article-title>Nonlinear feedback modulation contributes to the optimization of flexible decision-making</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Wu</surname>
<given-names>Xuanyu</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Zhou</surname>
<given-names>Yang</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
<email>yangzhou1@pku.edu.cn</email>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>Peking-Tsinghua Center for Life Sciences, Peking University</institution></institution-wrap>, <city>Beijing</city>, <country country="CN">China</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>School of Psychological and Cognitive Sciences, Peking University</institution></institution-wrap>, <city>Beijing</city>, <country country="CN">China</country></aff>
<aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>PKU-IDG/McGovern Institute for Brain Research, Peking University</institution></institution-wrap>, <city>Beijing</city>, <country country="CN">China</country></aff>
<aff id="a4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/024mw5h28</institution-id><institution>Department of Neurobiology, The University of Chicago</institution></institution-wrap>, <city>Chicago</city>, <country country="US">United States</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Bi</surname>
<given-names>Yanchao</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Peking University</institution>
</institution-wrap>
<city>Beijing</city>
<country country="CN">China</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Bi</surname>
<given-names>Yanchao</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Peking University</institution>
</institution-wrap>
<city>Beijing</city>
<country country="CN">China</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="con"><p><bold>Author Contributions:</bold> Y.Z. designed the experiments and wrote the manuscript. Y.Z. trained monkeys and collected the behavioral and neuronal data, Y.Z. and X.W. analyzed the data and made the figures. Y.Z. and X.W. designed the network models, X.W. trained the RNNs, analyzed the RNNs and implemented the RNN inactivation experiment. Y.Z. supervised the project.</p></fn>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-06-13">
<day>13</day>
<month>06</month>
<year>2024</year>
</pub-date>
<pub-date date-type="update" iso-8601-date="2025-07-14">
<day>14</day>
<month>07</month>
<year>2025</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP96402</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-02-05">
<day>05</day>
<month>02</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-03-25">
<day>25</day>
<month>03</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.07.15.549136"/>
</event>
<event>
<event-desc>Reviewed preprint v1</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2024-06-13">
<day>13</day>
<month>06</month>
<year>2024</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.96402.1"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.96402.1.sa2">eLife assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.96402.1.sa1">Reviewer #1 (Public Review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.96402.1.sa0">Reviewer #2 (Public Review):</self-uri>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Wu &amp; Zhou</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Wu &amp; Zhou</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-96402-v2.pdf"/>
<abstract>
<title>Abstract</title>
<p>Neural activity in the primate brain correlates with both sensory evaluation and action selection aspects of decision-making. However, the intricate interaction between these distinct neural processes and their impact on decision behaviors remains unexplored. Here, we examined the interplay of these decision processes in posterior parietal cortex (PPC) when monkeys performed a flexible decision task. We found that the PPC activity related to monkeys’ abstract decisions about visual stimuli was nonlinearly modulated by monkeys’ following saccade choices directed outside each neuron’s response field. Recurrent neural network modeling indicated that the feedback connections, matching the learned stimuli-response associations during the task, might mediate such feedback modulation. Further analysis on network dynamics revealed that selectivity-specific feedback connectivity intensified the attractor basins of population activity underlying saccade choices, thereby increasing the reliability of flexible decisions. These results highlight an iterative computation between different decision processes, mediated primarily by precise feedback connectivity, contributing to the optimization of flexible decision-making.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>Decision-making</kwd>
<kwd>Monkey electrophysiology</kwd>
<kwd>Posterior parietal cortex</kwd>
<kwd>Feedback modulation</kwd>
<kwd>Artificial neural network</kwd>
<kwd>attractor basin</kwd>
</kwd-group>
<funding-group>
<award-group id="funding-1">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/01h0zpd94</institution-id>
<institution>National Natural Science Foundation of China</institution>
</institution-wrap>
</funding-source>
<award-id>32171036</award-id>
</award-group>
</funding-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Main text and method section are updated to provide more necessary details; Figure 2 revised; Supplementary figure S2 added; Method section updated to provide the method related to S2.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Perceptual decisions typically involve the transformation of sensory inputs to discrete motor responses. Consequently, sensory evaluation and action selection emerge as two fundamental processes essential for implementing perceptual decision behavior<sup><xref ref-type="bibr" rid="c1">1</xref>–<xref ref-type="bibr" rid="c7">7</xref></sup>. Neural activity associated with either the sensory or motor aspects of decision-making is widely distributed across different brain areas, such as PPC <sup><xref ref-type="bibr" rid="c8">8</xref>–<xref ref-type="bibr" rid="c22">22</xref></sup>, frontal cortex <sup><xref ref-type="bibr" rid="c18">18</xref>,<xref ref-type="bibr" rid="c23">23</xref>–<xref ref-type="bibr" rid="c28">28</xref></sup>, superior colliculus <sup><xref ref-type="bibr" rid="c29">29</xref>,<xref ref-type="bibr" rid="c30">30</xref></sup>, and caudate <sup><xref ref-type="bibr" rid="c31">31</xref></sup>. A recent inactivation study has shown that the lateral intraparietal area (LIP), a subregion of PPC, plays a causal role in flexible visuomotor decisions, with preferential involvement in sensory evaluation rather than action selection <sup><xref ref-type="bibr" rid="c14">14</xref></sup>. Meanwhile, areas outside PPC, like frontal eye field and superior colliculus, have been shown to be causally involved in the action selection aspect of decision-making <sup><xref ref-type="bibr" rid="c32">32</xref>,<xref ref-type="bibr" rid="c33">33</xref></sup>. These findings suggest that sensory evaluation and action selection likely involve distinct neural processing in the primate brain during flexible decision-making.</p>
<p>However, previous reports have also shown that neural activity related to sensory evaluation and action selection overlaps temporally and spatially in the brain <sup><xref ref-type="bibr" rid="c34">34</xref></sup>. This leaves open the possibility of interplay between these distinct processes during decision-making. From the perspective of information processing, the abstract result of sensory evaluation should be transmitted to the motor planning circuits to guide the action selection process in a feedforward manner, although both processes could proceed in parallel in the brain. However, whether and how action selection processes might exert a feedback influence on sensory evaluation have not been explicitly studied.</p>
<p>In this study, we examined the activities of single LIP neurons during a flexible decision task in which monkeys needed to report their decisions about a motion stimulus with a saccade to one of two color targets. Specifically, we arranged the motion stimuli inside each neuron’s response field (RF), and positioned the saccade targets in the direction perpendicular to the axis of neural RFs. We found that LIP activity responded to visual motion was nonlinearly modulated by the monkeys’ following saccade choice direction relative to the recorded brain hemisphere. Notably, this modulation was aligned precisely with the functional properties of each neuron, as well as specifically impacted the decision-correlated but not the stimulus-correlated activity of LIP neurons. This suggests a precise ‘feedback’ modulation from action selection process to the neural processing of sensory evaluation during decision-making.</p>
<p>RNN models trained on complex behavioral tasks have shown promise for understanding neural computations and circuit mechanisms underlying cognitive functions <sup><xref ref-type="bibr" rid="c35">35</xref>–<xref ref-type="bibr" rid="c37">37</xref></sup>. To further explore how action selection can modulate sensory evaluation during decision-making, we trained multi-module RNNs, which consist of different hemispheres and RF structures, to perform the same decision task and analyzed the activity of network units during task performance. These RNNs exhibited similar behavioral performance and neural activity patterns as observed in the monkey electrophysiology experiment, including patterns of nonlinear feedback modulation from action selection to sensory evaluation. Combining analysis on network activity and connectivity with projection-specific inactivation experiments in the RNNs, we further showed that the precise feedback connections between units that showed matched functional properties within different network modules were the key circuit mechanism for mediating the modulation of sensory evaluation by action selection. Such feedback modulation significantly enhanced the consistency of the RNNs’ decisions by strengthening the attractor basins of network dynamics underlying saccade choices.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Nonlinear modulation of saccade choice on visual motion selectivity in LIP</title>
<p>To test the mechanisms underlying the feedback modulation of action selection on sensory evaluation, we trained two monkeys to perform a reaction-time version of the flexible visual-motion discrimination (FVMD) task, in which they needed to choose one of two colored saccade targets based on their decisions about the motion direction of a sample stimulus shown at different coherence levels (<xref rid="fig1" ref-type="fig">Figure 1A</xref>). Monkeys learned the mappings between the two motion directions (315° and 135°) and two target colors (red and green) at the start of training, and the mappings were fixed across the study. Because the locations of the red and green targets were randomly interleaved across trials, neither of the motion directions was directly linked with one specific saccade direction. Both the performance accuracy and the reaction time (RT) changed systematically as a function of motion coherence levels (<xref rid="fig1" ref-type="fig">Figure 1B-1E</xref>): as the motion coherence increased, both monkeys chose the correct target more frequently and more rapidly.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Behavioral task.</title>
<p>(<bold>A</bold>) The flexible visual-motion discrimination (FVMD) task. Monkeys needed to report their decision about the direction of the visual motion stimuli by choosing either the green or red saccade target. The appearance of the two color targets preceded that of the visual-motion stimulus, and the target positions were randomly chosen on each trial to avoid fixed mapping between motion stimulus and saccade direction. Monkeys could initiate their saccade as soon as they had made their decision. (<bold>B-C</bold>) Psychometric curves for the two monkeys. The averaged performance accuracy from all recording sessions for each monkey is plotted as the proportion of trials in which 315° was chosen as a function of the directions and coherence levels of the motion stimuli. (<bold>D-E</bold>) Chronometric curves are shown separately for the two monkeys. (<bold>F-G</bold>) Two trial conditions, contralateral (F) and ipsilateral (G), defined according to the spatial configurations of task stimuli during neural recording.</p></caption>
<graphic xlink:href="549136v3_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We recorded single-neuron activity from the LIP while the monkeys performed the FVMD task. We used the memory-guided saccade (MGS) task, which is commonly employed in LIP studies, to map the receptive fields (RFs) of all isolated LIP neurons. Specifically, we mapped both the visual and memory RFs of each neuron by analyzing their activity during the target presentation and delay periods of the MGS task (see Methods). To examine the neural activity related to the evaluation of stimulus motion, we presented the motion stimuli within the RF of each neuron, while positioning the saccade targets at locations orthogonal to the line connecting the center of the RF (which also marks the center of the motion stimulus) and the fixation dot. In total, 104 of 194 visually responsive LIP neurons (monkey M: 50/78; monkey B: 54/116) showed significant direction selectivity (DS) to the motion stimuli (one-way ANOVA, P &lt; 0.01). To examine the influence of action selection on sensory evaluation, we analyzed data from the subset of sessions in which the saccade targets were aligned more closely with the horizontal direction than the vertical direction (83 of 104 neurons). In these sessions, the motor planning corresponding to a saccade to either target would be mediated primarily by one brain hemisphere. We therefore defined the conditions under which the correct target was contralateral or ipsilateral to the recorded hemisphere as the contralateral target (CT) condition or ipsilateral target (IT) condition, respectively (<xref rid="fig1" ref-type="fig">Figure 1F</xref> and <xref ref-type="fig" rid="fig1">1G</xref>).</p>
<p><xref rid="fig2" ref-type="fig">Figure 2A-2F</xref> shows three example LIP neurons that exhibited significant motion coherence correlated DS. Surprisingly, LIP neurons showed greater DS in the CT condition than in the IT condition, even though the same motion stimuli were used in the same spatial location for both conditions. The averaged population activity showed this DS difference between CT and IT conditions for all four coherence levels (<xref rid="fig2" ref-type="fig">Figure 2G, 2H</xref>). During presentation of their preferred motion direction, LIP neurons showed significantly elevated activity in the CT relative to the IT at all coherence levels (Figure S1A, S1B, nested ANOVA: P<sub>(high)</sub> = 0.0326, F = 4.65; P<sub>(medium)</sub> = 0.0088, F = 7.03; P<sub>(low)</sub> = 0.0076, F = 7.32; P<sub>(zero)</sub> = 0.0124, F = 6.4), and a trend toward lower activity to the nonpreferred direction for CT vs. IT (Figure S1C, S1D, nested ANOVA: P<sub>(high)</sub> = 0.0994, F = 2.75; P<sub>(medium)</sub> = 0.0649, F = 3.12; P<sub>(low)</sub> = 0.0311, F = 4.73; P<sub>(zero)</sub> = 0.0273, F = 4.96).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Nonlinear feedback modulation of saccade choice on sensory evaluation in LIP.</title>
<p><bold>(A)</bold> The activity of one example neuron in the CT condition of the FVMD task is shown for each motion-coherence level. The zero-coherence trials were grouped based on the monkey’s choices. The two vertical dashed lines denote the time of target and motion stimulus onset, respectively.</p>
<p><bold>(B)</bold> The same example neuron’s activity in the IT condition of the FVMD task. (<bold>C-F</bold>) The activities of two more example neurons. (<bold>G-H</bold>) The averaged population activities of all direction-selective neurons (n = 83) that were collected during the recording sessions in which the saccade targets were arranged in either horizontal or oblique directions. The activity to each motion direction and coherence level is shown separately for the CT condition (G) and IT condition (H). (<bold>I</bold>) The activity differences between CT and IT conditions (CT minus IT) of single LIP neurons were plotted for both preferred and nonpreferred motion directions. Each dot represents the activity of a single neuron. The histograms in horizontal and vertical axis represent the distribution of activity difference between CT and IT conditions for preferred and nonpreferred motion directions, respectively. (<bold>J</bold>) An ROC analysis was used for quantifying the motion DS for both CT (solid) and IT (dashed) conditions. The colored dots denote the time points for which there was a significant difference between the CT and IT conditions (paired t-test: P &lt; 0.01). (<bold>K</bold>) The average DS for low- and zero-coherence trials is shown as in (J). (<bold>L</bold>) The mean activity (averaged across all motion directions and coherence levels) was compared between the two saccade directions (CT vs. IT) at the population level. Activity was aligned to either motion stimulus onset (left panel) or saccade onset (right panel).There was no significant difference between CT and IT conditions before monkeys made saccade choices. (<bold>M</bold>) Variance in LIP population activity as explained by the individual demixed principal components. Each bar shows the proportion of total explained variance that was contributed by the four task variables. The pie chart shows the total variance explained by each task variable. H, high; M, medium; L, low; 0, zero; P, preferred; NP nonpreferred.</p></caption>
<graphic xlink:href="549136v3_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Most of the LIP neurons (48 of 83) showed such opposing trends in activity modulation between the preferred and nonpreferred directions (<xref rid="fig2" ref-type="fig">Figure 2I</xref>). These results indicated a nonlinear modulation of saccade choice on motion DS in LIP, aligned precisely with the response property of each neuron. This is unlikely to be driven by a linear gain modulation of saccade direction selectivity. Receiver operating characteristic (ROC) analysis further confirmed significantly greater motion DS in the CT condition than in the IT condition (<xref rid="fig2" ref-type="fig">Figure 2J</xref> and <xref ref-type="fig" rid="fig2">2K</xref>; nested ANOVA: P<sub>(high)</sub> = 5.0e-4, F= 12.44; P<sub>(medium)</sub> = 9.53e-6, F = 20.91; P<sub>(low)</sub> = 9.33e-7, F = 26.03; P<sub>(zero)</sub> = 2.56e-8, F= 34.3). Such DS differences were observed even before stimulus onset. Moreover, LIP neurons exhibited similar levels of mean activity between different saccade directions (CT vs. IT) before monkeys’ saccade choice (<xref rid="fig2" ref-type="fig">Figure 2L</xref>), further supporting that saccade direction selectivity did not significantly contribute to the observed modulation of LIP neurons’ responses to motion stimuli.</p>
<p>To better quantify the influence of saccade direction on neuronal responses to motion stimuli, we calculated a modulation index for each neuron (STAR Methods). We then compared the modulation indices across neurons with different direction preferences and found no systematic relationship between direction preference and saccade-related modulation in LIP neurons at the population level (Figure S2). Furthermore, a demixed principal component analysis on the pseudo-population activity (STAR Methods) revealed that the saccade direction related representation was a substantial component of LIP activity, as the saccade direction and motion–saccade interaction together explained a similar amount of variance in the population activity as the stimulus motion direction did (<xref rid="fig2" ref-type="fig">Figure 2M</xref> and Figure S3). In contrast, we did not observe significant DS differences between the CT and IT conditions in the data sessions in which the saccade targets were aligned close to the vertical direction (21 of 104 neurons, Figure S4).</p>
</sec>
<sec id="s2b">
<title>Decision-correlated but not stimulus-correlated activity was modulated in LIP</title>
<p>We then examined the impact of nonlinear feedback modulation on the correlation between LIP DS and monkeys’ choice behavior. We found that LIP DS was more decision-correlated in the CT condition than in the IT condition. Illustrated in <xref rid="fig2" ref-type="fig">Figure 2K</xref>, the LIP DS on zero-coherence trials, which reflected monkeys’ trial-by-trial categorical choice, was significantly greater in the CT condition than in the IT condition (nested ANOVA: P = 2.56e-8, F= 34.3). We also quantified the correlation between LIP neural activity and the trial-by-trial categorical choice or the physical motion direction by comparing LIP neural activity on correct versus incorrect trials. We used low-coherence trials, as monkeys made enough errors in these trials. In the CT condition but not the IT condition, LIP DS at the population level was significantly reversed in sign on incorrect trials as compared to correct trials (<xref rid="fig3" ref-type="fig">Figure 3A</xref> and <xref ref-type="fig" rid="fig3">3B</xref>; nested ANOVA: P<sub>(CT)</sub> = 0.0045, F = 8.32). Accordingly, in the CT condition but not in the IT condition, LIP activity correlated more closely with the monkeys’ trial-by-trial abstract decisions about motion direction, as opposed to the physical motion direction (<xref rid="fig3" ref-type="fig">Figure 3C</xref> and <xref ref-type="fig" rid="fig3">3D</xref>; nested ANOVA, P<sub>(CT)</sub> = 0.0016, F = 10.31; P<sub>(IT)</sub> = 0.443, F = 0.59). Meanwhile, LIP activity correlated more closely with the trial-by-trial abstract decisions during the CT condition relative to the IT condition on the low coherence trials (nested ANOVA: P = 1.95e-8, F = 34.94). Furthermore, we used partial correlation analysis to examine decision- and stimulus-related components of DS (i.e., r-decision and r-stimulus, <xref rid="fig3" ref-type="fig">Figure 3E</xref> and <xref ref-type="fig" rid="fig3">3F</xref>) using all four coherence levels. The decision-related component of LIP DS was significantly greater in the CT condition than in the IT condition (<xref rid="fig3" ref-type="fig">Figure 3E</xref>; nested ANOVA: P = 1.07e-6, F= 25.72), and this difference emerged even before motion stimulus onset. This suggests that the LIP DS was more closely correlated with monkeys’ decisions in the CT condition than in the IT condition. The upregulation in r-decision for contralateral choices may reflect the monkeys’ internal choice bias or expectation (choice between two motion directions) prior to stimulus presentation, which could influence their subsequent decisions more in the CT condition. However, the stimulus-related component of the LIP DS was similar at the population level between the two conditions (<xref rid="fig3" ref-type="fig">Figure 3F</xref>; nested ANOVA: P = 0.7606, F = 0.09), suggesting that the modulation of LIP DS by the later saccade choice was primarily related to a decision process rather than basic sensory processing.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Feedback modulation specifically impacted the decision-correlated activity.</title>
<p>(<bold>A-B</bold>) Averaged population activities on low-coherence trials in the CT condition (A) and IT condition (B) are shown separately for correct (corr) and error (err) trials. (<bold>C-D</bold>) An ROC analysis quantified the stimulus-related and decision-related LIP DS on low-coherence trials. The correlations between LIP neural activity and the monkeys’ decisions about motion direction (red) or the physical direction of the motion stimulus (blue) in both the CT (C) and IT (D) conditions are shown over time. (<bold>E-F</bold>) Partial correlation analysis revealed the decision-related and stimulus-related components of LIP activity. The values for r-decision (E) (the partial correlation between neuronal activity and monkeys’ choice, given the stimulus direction) and r-stimulus (F) (partial correlation between neuronal activity and stimulus direction, given the monkeys’ choices) were compared between the IT and CT conditions. (<bold>G-H</bold>) Correlation between LIP DS and the monkeys’ RTs on zero-coherence trials. The choice selectivity on zero-coherence trials is shown for the faster RT and slower RT trials. Shaded areas denote ±SEM. The black stars indicate time periods in which there was a significant difference (paired t-test: P &lt; 0.01).</p></caption>
<graphic xlink:href="549136v3_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We further examined the impact of nonlinear feedback modulation on the correlation between LIP DS and the monkeys’ RTs. Shortly after motion stimulus onset, LIP neurons showed greater population response to their preferred motion direction on shorter versus longer RT trials for all motion coherence levels in the CT condition (Figure S5) but not in the IT condition (Figure S6). On zero-coherence trials (<xref rid="fig3" ref-type="fig">Figure 3G</xref> and <xref ref-type="fig" rid="fig3">3H</xref>), DS evolved more rapidly on shorter vs. longer RT trials in the CT condition but not in the IT condition (bootstrap: P<sub>(CT)</sub> &lt; 0.01, P<sub>(IT)</sub> = 0.87). Together, these results indicated that the feedback modulation of saccade choice on sensory evaluation predominantly impacted the decision-correlated activity in LIP.</p>
</sec>
<sec id="s2c">
<title>Trained multi-module RNNs replicated the nonlinear feedback modulation</title>
<p>Our electrophysiology data show that action selection nonlinearly modulates the neural processing of sensory evaluation, which indicates a complex, iterative computation for flexible decision-making. Training RNNs on behavioral tasks used in experimental neurophysiological studies has proven to be helpful for exploring putative circuit computations underlying cognitive tasks<sup><xref ref-type="bibr" rid="c28">28</xref>,<xref ref-type="bibr" rid="c36">36</xref>,<xref ref-type="bibr" rid="c37">37</xref></sup>. Therefore, we trained multi-module RNNs to perform the FVMD task to examine the circuits and computation mechanisms underlying the interplay of different decision processes. We adopted simple neurobiological principles to constrain the connection structure but not the functional roles to generate recurrently connected modules (STAR Methods). Because our neurophysiological results showed that the modulation effect of action selection on sensory evaluation depended on the saccade direction relative to the recorded brain hemisphere, we implemented RNNs composed of two main modules organized in parallel to simulate two brain hemispheres. Each main module consisted of two nominal modules, with each nominal module receiving the visual motion input (motion module) or the target color input (target module), corresponding to the two neuron populations whose RFs covered the motion stimulus or saccade targets, respectively (<xref rid="fig4" ref-type="fig">Figure 4A</xref>).</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Multi-module RNNs trained with the FVMD task.</title>
<p>(<bold>A</bold>) Model schematic of the RNNs. Each RNN consists of nine motion direction tuned input units, eight color tuned target input units, 200 hidden units, and two response units. The hidden layer of each RNN consists of two main modules. Each main module consists of two nominal modules, each of which receives either the visual motion input (motion module) or the target color input (target module). Only the target modules project to the two response units, and each main module projects primarily to one response unit. All four nominal modules were assigned with equal number of units (25%) in the network, which consisted of 80% excitatory and 20% inhibitory units. (<bold>B-C</bold>) The performance accuracies (B) and RTs (C) of all 50 trained RNNs are shown separately for each motion coherence level. (<bold>D-E</bold>) Two example units from an example RNN. (<bold>D</bold>) The neural activity of an example unit from the motion module is shown for each motion direction and coherence level. (<bold>E</bold>) The neural activity of an example unit from the target module is shown for each saccade direction and coherence level. (<bold>F-G</bold>) The motion DS for the motion module (F) and saccade DS for the target module (G) for the example RNN. (<bold>H-I</bold>) The averaged population activities of all direction-selective units in the motion module of the example RNN are shown for the CT condition (H) and IT condition (I). (<bold>J-K</bold>) The averaged motion DS in the motion module of the example RNN for both the CT (solid) and IT (dashed) conditions was quantified by ROC analysis. (<bold>L-M</bold>) Partial correlation analysis. The values for r-decision (L) and r-stimulus (M) are compared between the IT and CT conditions for the example RNN. (<bold>N</bold>) A comparison of the motion DS in the motion module of all trained RNNs between the CT and IT conditions is shown for each coherence level. (<bold>O</bold>) A comparison of the r-decision and r-stimulus between the IT and CT conditions is shown for all trained RNNs. (Paired t-test: ***, P &lt; 0.001).</p></caption>
<graphic xlink:href="549136v3_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We independently trained 50 such networks with randomly initialized weights and identical hyperparameters to perform the FVMD task. The FVMD task setup used for training RNNs was tailored to match the monkey experiments. Specifically, the RNNs were trained using motion stimuli with two high-coherence levels and were tested using stimuli with another four different coherence levels (high, medium, low, and zero). After training, all 50 networks converged to perform the FVMD task with high accuracies (&gt;99%) on the training coherence and exhibited coherence-dependent performances when tested with untrained stimuli (<xref rid="fig4" ref-type="fig">Figure 4B</xref> and <xref ref-type="fig" rid="fig4">4C</xref>): accuracy increased and RT decreased with motion coherence.</p>
<p>We then analyzed the unit activity in different modules when the trained RNNs were tested with untrained motion stimuli. Across all networks, the units in the motion module and target modules exhibited activity corresponding to sensory evaluation and action selection, respectively. Specifically, units in the motion modules showed coherence-correlated motion DS (<xref rid="fig4" ref-type="fig">Figure 4D</xref> and <xref ref-type="fig" rid="fig4">4F</xref> and Figure S7 and S8; mean r =0.29; one-sample t-test: P = 4.09e-42, t(49)= 46.31), and neuronal activity on zero-coherence motion trials reflected the trial-by-trial abstract decisions of the networks (t-test: P<sub>(example RNN)</sub> = 5.97e-27, t(91) = 15.33; P<sub>(population)</sub> = 1.05e-31, t(49) = 27.86). Such motion DS resembled our electrophysiology data when the motion stimuli were presented within the RFs of the LIP neurons. Meanwhile, units in the target modules showed coherence-correlated saccade DS (<xref rid="fig4" ref-type="fig">Figure 4E</xref> and <xref ref-type="fig" rid="fig4">4G</xref> and Figure S7 and S8), and the neuronal activity on zero-coherence motion trials also showed significant choice probability (t-test: P<sub>(example RNN)</sub> = 7.06e-8, t(68) =15.83; P<sub>(population)</sub> = 2.08e-22, t(49) = 17.21). Such saccade DS was consistent with the commonly observed decision-related activity in previous studies in which the saccade target was presented within the RFs of LIP neurons<sup><xref ref-type="bibr" rid="c9">9</xref>–<xref ref-type="bibr" rid="c11">11</xref></sup>.</p>
<p>Furthermore, we found that the motion DS of units in the motion modules was significantly greater in the CT condition than in the IT condition for the majority of RNNs (<xref rid="fig4" ref-type="fig">Figure 4H</xref> and 4I and Figure S9A and S9B): in the CT condition relative to the IT condition, activity was significantly greater for the preferred motion direction but weaker for the nonpreferred direction (Figure S10). ROC analysis confirmed that the motion DS in the motion module was significantly greater for all four coherence levels in the CT vs. IT conditions in most RNNs (<xref rid="fig4" ref-type="fig">Figure 4J, 4K</xref> and <xref ref-type="fig" rid="fig4">4N</xref> and Figure S9C and S9D; two-way ANOVA: P<sub>(example RNN)</sub> = 1.53e-11, F = 47.49; P<sub>(population)</sub> = 3.50e-77, F = 660.84). Similar to the monkey electrophysiology data, the decision-correlated motion DS (r-decision) in the motion module was dramatically reduced in the IT versus CT condition (paired t-test: P = 6.84e-17, t(49)= −12.53), and this difference was substantially greater than the difference in the stimulus-related (r-stimulus) motion DS between the two conditions (paired t-test: P = 2.02e-14, t(49) = −10.70; <xref rid="fig4" ref-type="fig">Figure 4L, 4M</xref> and <xref ref-type="fig" rid="fig4">4O</xref> and Figure S9E and S9F). These results indicated that action selection also nonlinearly modulated the neural processing of sensory evaluation during decision-making in the RNNs.</p>
</sec>
<sec id="s2d">
<title>Selectivity-specific feedback connections mediate the modulation of sensory evaluation by action selection</title>
<p>Our multi-module RNNs showed a remarkable similarity to both the behavioral performances and the neural activity patterns in the monkey electrophysiology data, suggesting that these networks may have adopted mechanisms similar to those in the monkey brain to mediate the decision processes in the FVMD task. Therefore, we explored the potential circuit mechanisms underlying the modulation of action selection on sensory evaluation in RNNs. We hypothesized that this modulation might result from the feedback connections from the target module to the motion module. To test this hypothesis, we examined the recurrent weights of the cross-module connections (STAR Methods). Both the feedback and feedforward cross-module connection weights were significantly greater between the selectivity-matched unit pairs (e.g., units in the motion module preferred to encode 315° and units in the target module preferred to encode red) than the selectivity-nonmatched unit pairs (e.g., units in the motion module preferred to encode 315° while units in the target module preferred to encode green) (<xref rid="fig5" ref-type="fig">Figure 5A</xref>; paired t-test: P<sub>(feedforward)</sub> = 7.18e-16, t(49) = −11.76; P<sub>(feedback)</sub> = 5.26e-18, t(49) = −13.40). In particular, the average feedback connectivity was primarily excitatory between the selectivity-matched unit pairs but was inhibitory on average between the selectivity-nonmatched unit pairs. Furthermore, most of the networks exhibited positive correlations between the connection weight and the match extent of the neural selectivity of each cross-module unit pair (<xref rid="fig5" ref-type="fig">Figure 5B</xref>; mean r = 0.11; one-sample t-test: P = 6.39e-16; t(49) = 11.79; STAR Methods), indicating that units that exhibited stronger encoding preference to one motion direction in the motion module were more likely to receive more extensive feedback projections from the units that exhibited stronger encoding on the matched target color in the target module. These results suggested precise feedback connections between RNN modules that were aligned with the functional properties of different units.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><title>The circuit mechanisms underlying the nonlinear feedback modulation in RNNs.</title>
<p>(<bold>A</bold>) The averaged cross-module connection weights are shown for both feedforward and feedback connections. Units in the motion module (M) and target module (T) were grouped based on their preferences for motion DS (315° vs. 135°) and target color selectivity (red [r] vs. green [g]), respectively. (<bold>B</bold>) The correlation between the match extent of the neural encoding between units in the motion module and those in target modules and the connection weights between them. Each dot denotes data from one RNN. (<bold>C-D</bold>) A comparison of the performance accuracy (C) and RT (D) of the full-model RNNs, RNNs without feedback connections, and RNNs with shuffled feedback connections. (<bold>E-F</bold>) The averaged activity of units in the motion module of the example RNN after the feedback connections were ablated is shown for CT (E) and IT (F) conditions. (<bold>G</bold>) The comparison of the averaged motion DS between CT and IT conditions for all trained RNNs after feedback connections were ablated. An ROC analysis was used to quantify the motion DS. (<bold>H</bold>) The differences in motion DS between CT and IT conditions were compared between full-model RNNs and RNNs with shuffled feedback connectivity.</p></caption>
<graphic xlink:href="549136v3_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To test the causal contribution of the selectivity-specific feedback connections to the modulation of action selection on sensory evaluation, we conducted three projection-specific inactivation experiments in the RNNs (STAR Methods). First, we performed nonspecific ablation of all the feedback projections from the target module to the motion module when testing with untrained motion stimuli. In most of the tested RNNs, this caused a dramatic reduction in their performance in all nonzero-coherence stimulus conditions (<xref rid="fig5" ref-type="fig">Figure 5C</xref>; two-way ANOVA: P = 4.74e-80, F = 704.65) as well as significantly prolonged RTs for high- and medium-coherence stimulus conditions (<xref rid="fig5" ref-type="fig">Figure 5D</xref>; two-way ANOVA: P = 2.45e-4, F = 13.79). The mean RTs became more dispersed across all the trained RNNs and did not differ among different motion coherences after ablation (one-way ANOVA: P = 0.68, F = 0.50). Ablating feedback connections significantly affected the motion DS in the motion module. On average, although the averaged motion DS did not decrease after ablation (Figure S11A and S11C), the difference in the motionDS between the CT and IT conditions vanished (<xref rid="fig5" ref-type="fig">Figure 5E-5G</xref> and Figure S12A and S12B; two-way ANOVA: P<sub>(CT vs. IT)</sub> = 0.14, F = 2.21). These results indicated a dramatic reduction in the nonlinear feedback modulation on sensory evaluation by action selection in the RNNs. To further test the importance of different patterns of feedback connectivity for the RNNs to solve the FVDM task, we next performed pattern-specific ablation of the feedback connections in RNNs. We separated the feedback projections in each RNN into specific (i.e., the feedback connection weights were positive or negative between the selectivity-matched or selectivity-nonmatched unit pairs, respectively) and nonspecific groups. Despite similar numbers and weights of the feedback connections in these two groups (Figure S13A and S13B), ablating the feedback connection in the specific group versus the nonspecific group resulted in much more severe impairments in the RNNs’ behavior performance (Figure S13C and S13D). These results indicated that the feedback connections that reflected the learned stimulus–response association was crucial for the RNNs to solve the FVDM task.</p>
<p>Second, we disrupted the selectivity-specific feedback connectivity without changing the total strength of the feedback connections by randomly rearranging the feedback connection weights. This also resulted in a significant reduction in the RNNs’ performance accuracy for nonzero-coherence motion stimuli (<xref rid="fig5" ref-type="fig">Figure 5C</xref>; two-way ANOVA: P = 1.38e-90, F = 883.61) and prolonged RTs for high- and medium-coherence motion stimuli (<xref rid="fig5" ref-type="fig">Figure 5D</xref>; two-way ANOVA: P = 1.94e-12, F = 54.06). The changes of RNN units’ activity patterns after scrambling feedback connections were similar to the effects after feedback connectivity was fully ablated (Figure S11B, S11C, S14A, S14B, S14D and S14E). Particularly, the levels of nonlinear modulation of sensory evaluation by saccade selection dramatically decreased, as evident by the diminished difference in the motion DS between the CT and IT conditions (<xref rid="fig5" ref-type="fig">Figure 5H</xref>, two-way ANOVA: P = 5.81e-12, F = 51.52).</p>
<p>Third, we trained another 50 RNNs without feedback connectivity to learn the FVMD task. Similar to the full-model RNNs, all 50 networks converged to perform the FVMD task with high accuracies (&gt;99%) after training and exhibited coherence-dependent performances when tested with untrained stimuli (Figure S15A and S15B). Meanwhile, units in the motion module and target modules exhibited coherence-dependent motion DS and saccade DS, respectively (Figure S15C and S15D). Consistent with the above connectivity ablation experiment, units in the motion module of these RNNs did not exhibit different levels of motion DS between CT and IT conditions (Figure S15E-S15G; two-way ANOVA: P = 0.63, F = 0.24), indicating no noticeable nonlinear feedback modulation on sensory evaluation by action selection. Importantly, the performance accuracies of these RNNs decreased significantly when tested with untrained nonzero-coherence stimuli (Figure S15H; two-way ANOVA: P = 1.46e-14, F = 65.64), as compared to the full-model RNNs. Furthermore, we trained an additional 50 RNNs without feedback connections to learn the FVMD task. These RNNs were initialized with greater recurrent connection probabilities than the full-model RNNs, such that the number of total trainable connection weights matched that in the full-model RNNs. Interestingly, these RNNs still exhibited significantly lower performance accuracies when tested with high- and medium-coherence stimuli relative to the full-model RNNs (Figure S16; two-way ANOVA: P = 8.24e-6, F = 20.60). Together, these results suggested that the nonlinear feedback modulation, which was mediated by the selectivity-specific feedback connections, were important for the RNNs to efficiently solve flexible decision tasks.</p>
</sec>
<sec id="s2e">
<title>Nonlinear feedback modulation enhanced the decision consistency by strengthening the attractor basins of network dynamics</title>
<p>Our RNN modeling indicates a crucial role for nonlinear feedback modulation in optimizing flexible decision-making. Subsequently, we delved into the computational mechanisms embodied by nonlinearfeedback modulation during the decision-making process. Specifically, we examined the unit activity in the target module, a direct contributor to the decision outputs of RNNs. Strikingly, the projection-specific inactivation experiments led to a significant reduction in the magnitude of saccade DS in the nonzero-coherence trials (<xref rid="fig6" ref-type="fig">Figure 6A-6C</xref>, P<sub>(ablating feedback)</sub> = 6.90e-5, F = 16.29; P<sub>(shuffling feedback)</sub> = 1.2e-19, F = 95.08; two-way ANOVA). Additionally, saccade DS emerged earlier than the motion stimulus onset in the nonzero-coherence trials, and its positive correlation with the motion coherence levels diminished after the projection-specific inactivation (<xref rid="fig6" ref-type="fig">Figure 6A-C</xref> and Figure S12C, S14C and S14F; mean r<sub>(ablating feedback)</sub> = −0.034; mean r<sub>(shuffling feedback)</sub> = –0.030). These disrupted patterns of saccade DS observed in the target module following projection-specific inactivation aligned with the decreased decision consistency of RNNs, where decision consistency reflects the degree of agreement in the model’s choices under specific task conditions. This suggests a diminished reliance on sensory input and an increased dependence on internal noise in the decision-making process.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6.</label>
<caption><title>The computational mechanisms underlying the nonlinear feedback modulation in decision-making.</title>
<p><bold>(A)</bold> The averaged activity of units in the target module of the example RNN, after the feedback connections were ablated, is shown separately for different saccade directions and coherence levels. (<bold>B</bold>) The averaged saccade DS in the target module of the example RNN after full feedback ablation. (<bold>C</bold>) The averaged saccade DS in the target module of the full-model RNNs, RNNs without feedback connections, and RNNs with shuffled feedback connections. (Paired t-test: *, P &lt; 0.05; **, P &lt; 0.01; ***, P &lt; 0.001; n.s., not significant). (<bold>D-G</bold>) The evolution of the averaged energy landscapes was shown over time. A numerical approximation of the energy landscape in the 1-D decision (saccade choice) subspace is constructed for both full-model RNNs and RNNs with various types of projection-specific inactivation. Each plot represents the averaged results of 50 RNNs, where Position 0 signifies the SVM decision boundary, and the vertical dashed line marks the time of motion stimulus onset. Unvisited portions of the state space are left blank as there is no gradient or potential estimate. (<bold>H-k</bold>) Averaged numerical estimate of energy landscapes for trials with different task difficulty levels (motion coherence). Results from two different saccade choices were average together. Only the potential values at positions continuously visited by four or more models were retained. Shaded areas denote ±SEM.</p></caption>
<graphic xlink:href="549136v3_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Previous studies have demonstrated that attractor dynamics in networks can explain choice consistency, with steeper landscapes around attractor basins reflecting consistent decisions<sup><xref ref-type="bibr" rid="c38">38</xref>–<xref ref-type="bibr" rid="c42">42</xref></sup>. Consequently, we investigated attractor dynamics in the state space of network activity that underlies decision-making variability in RNNs with different types of feedback connectivity. Similar to prior studies<sup><xref ref-type="bibr" rid="c40">40</xref></sup>, we examined the neural dynamics underlying decisions in a 1-D neural subspace using unit activity in the target module responsible for saccade choices (see methods). Beginning with the reconstruction of a numerical approximation of the energy landscape in this 1-D subspace, we explored changes in this landscape after different types of projection-specific inactivation. This revealed a dramatic reduction in the depth of attractor basins in the energy landscape of population activity after ablating all feedback connectivity (<xref rid="fig6" ref-type="fig">Fig. 6D-E</xref>, paired t-test: P = 2.28e-11, t(49) = −8.61). Moreover, ablating the feedback connections led to a more severe reduction in the depth of attractor basins in the network dynamics within the specific group compared to the nonspecific groups (<xref rid="fig6" ref-type="fig">Fig. 6F-G</xref>, paired t-test: P = 1.59e-6, t(49) =-5.46).</p>
<p>We further examined how the energy landscape in the 1-D subspace changed in relation to task difficulty (motion coherence). Consistent with prior findings<sup><xref ref-type="bibr" rid="c40">40</xref></sup>, trials with lower decision consistency (trials using lower motion coherence) exhibited shallower attractor basins at the time of decision for all types of RNNs (<xref rid="fig6" ref-type="fig">Fig. 6H-K</xref>). However, both the depth and the positional separation of attractor basins in the network dynamics significantly decreased for all non-zero motion coherence levels after the ablation of all feedback connections (comparing <xref rid="fig6" ref-type="fig">Figure 6I</xref> with <xref rid="fig6" ref-type="fig">Figure 6H</xref>; P<sub>(depth)</sub> = 5.20e-25, F = 122.80; P<sub>(position)</sub> = 1.82e-27, F = 137.75; two-way ANOVA). Notably, this reduction in basin depth and separation was more pronounced in the specific group compared to the nonspecific groups after ablating the feedback connections (comparing <xref rid="fig6" ref-type="fig">Figure 6J</xref> with <xref rid="fig6" ref-type="fig">Figure 6K</xref>; P<sub>(depth)</sub> = 2.65e-13, F =57.35; P<sub>(position)</sub> = 3.73e-14, F = 61.79; two-way ANOVA). These results might underlie the computational mechanisms that explain the observed reduction in the decision consistency of RNNs following projection-specific inactivation: the shallower and closer attractor basins after ablating feedback connections resulted in less consistent decisions. This happened because the variability in neural activity made it more likely for population activity to stochastically shift out of the shallower basins and into nearby alternative ones.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Here we show that primate LIP activity related to evaluating the visual motion stimulus was nonlinearly modulated by an impending saccade choice that was used to report decisions during a FVMD task, even though the saccades were toward non-RF locations. This suggests that the sensory evaluation and action selection may proceed iteratively during decision-making. This view is also consistent with the common observation that action selection related activity arises at the early stage of evidence accumulation during decision-making<sup><xref ref-type="bibr" rid="c3">3</xref>,<xref ref-type="bibr" rid="c9">9</xref>,<xref ref-type="bibr" rid="c34">34</xref></sup>, as well as our observation that the modulation of action selection on sensory evaluation emerged during the early task period even before motion stimulus onset in the FVMD task. Brain areas that are related to different decision processes, although spatially separated<sup><xref ref-type="bibr" rid="c14">14</xref>,<xref ref-type="bibr" rid="c21">21</xref>,<xref ref-type="bibr" rid="c33">33</xref></sup>, likely form a real-time associated network to solve current decision tasks. The instantaneous result of sensory evaluation may be transmitted to the brain areas responsible for action selection during decision-making in a feedforward manner, and the action selection process may also exert a real-time modulation on the neural processing of sensory evaluation in a feedback manner.</p>
<p>The feedback modulation we observed during decision-making was distinct from the modulation of feature-based attention in early sensory cortex. Although both modulation effects match the stimulus tuning of recipient cells<sup><xref ref-type="bibr" rid="c43">43</xref>–<xref ref-type="bibr" rid="c47">47</xref></sup>, only the feedback modulation observed in the current study reflects the neural processing of decision-making. This is because only the decision-related component, not the stimulus-related component, of LIP activity was modulated by the monkeys’ later saccade choice during the FVMD task (<xref rid="fig3" ref-type="fig">Figure 3</xref>). This suggests that the feedback modulation from action selection to LIP activity was primarily related to the decision process rather than low-level sensory processing.</p>
<p>A recent study demonstrated that neurons in the middle temporal area responded more strongly to motion stimuli when monkeys saccaded toward their RFs in a standard decision task with a fixed mapping between motion stimuli and saccade directions<sup><xref ref-type="bibr" rid="c48">48</xref></sup>. This modulation emerged through the training process and contributed causally to the monkeys’ following saccade choices. Consistently, we found that the response of LIP neurons to motion stimuli was more strongly correlated with the monkeys’ decisions in the CT condition (saccades toward RFs) than in the IT condition, in a more flexible decision task. Together, these results suggest that the modulation of action selection on sensory processing may be a general process in perceptual decision-making. However, the observed modulation of saccade direction on LIP neurons’ responses to motion stimuli cannot be simply explained by saccade direction selectivity. Several lines of evidence argue against this possibility. First, the modulation effect was nonlinear; specifically, neuronal firing rates increased for preferred motion directions but decreased for non-preferred directions (<xref rid="fig2" ref-type="fig">Figure 2I</xref> and Figure S1). This pattern is unlikely to be driven by a linear gain modulation based on saccade directions. Second, we found that LIP neurons exhibited similar levels of activity in both the CT and IT conditions (<xref rid="fig2" ref-type="fig">Figure 2M</xref>), which is inconsistent with the presence of clear saccade direction selectivity.</p>
<p>The selectivity-specific feedback modulation from action selection to sensory evaluation emerged in our multi-module RNNs during training, although the cross-module connections were randomly initialized before training. Importantly, our causal in-silico experiments demonstrated that these precise feedback connections played an essential role in mediating the modulation of action selection on sensory evaluation while solving the FVDM task. Previous studies showed that both the corticocortical feedback from the secondary visual cortex to the primary visual cortex and the corticogeniculate feedback in primates are organized into parallel streams resembling the reciprocal feedforward pathways<sup><xref ref-type="bibr" rid="c49">49</xref>–<xref ref-type="bibr" rid="c51">51</xref></sup>, suggesting a potential functionally specific feedback connection in visual processing. However, to the best of our knowledge, a similar segregation of feedback that reflects the encoding properties of the target neurons has not been evident in decision network in vivo. Therefore, it will be important for future studies to examine the connectivity and correlation of neural activity among neural groups related to different decision processes through sophisticated anatomical experimental approaches as well as multi-channel recordings in vivo.</p>
<p>Our brain includes extensive feedback connections across different brain areas, which, in some cases, even outnumber the feedforward connections<sup><xref ref-type="bibr" rid="c51">51</xref>,<xref ref-type="bibr" rid="c52">52</xref></sup>. However, compared to the feedforward connections, much less is known about the function of feedback connections. Feedback modulation has been implicated in top-down modulation of neuronal responses in the early sensory cortex, such as attention and expectation, which facilitate the processing of important stimuli and suppress distractors<sup><xref ref-type="bibr" rid="c53">53</xref>–<xref ref-type="bibr" rid="c55">55</xref></sup>. Furthermore, both experimental and computational studies have shown that weak decision-correlated neural activity (i.e., choice probability) as well as the correlated firing of pairs of neurons (i.e., noise correlation) in the early sensory cortex might partially result from feedback input in decision tasks<sup><xref ref-type="bibr" rid="c56">56</xref>–<xref ref-type="bibr" rid="c58">58</xref></sup>, suggesting a potential role for feedback connection in modulating early sensory processing during decision-making. Consistently, the nonlinear feedback modulation, mediated primarily by selectivity-specific feedback connections, were important for our multi-module RNNs to efficiently solve the FVMD task, as the RNNs’ decision behavior became more stochastic following ablating/disrupting the feedback connectivity. This was evident not only in the diminished behavioral performance of the RNNs but also in the disrupted patterns of activity related to saccade choice in the target module. Notably, the nonlinear feedback modulation intensified the attractor basins of the population activity associated with saccade choice, led to more reliable decisions based on sensory input. Our results unveil a novel pattern of feedback modulation during the neural processing of decision-making, and suggest a potentially critical role that feedback modulation plays in increasing the consistency of flexible sensorimotor decisions.</p>
<p>Two-state attractor models have been widely employed to elucidate two-alternative forced decision-making processes<sup><xref ref-type="bibr" rid="c38">38</xref>–<xref ref-type="bibr" rid="c42">42</xref>,<xref ref-type="bibr" rid="c59">59</xref>,<xref ref-type="bibr" rid="c60">60</xref></sup>. In these models, decisions arise when network activity falls into one of two attractor basins. Previous studies have posited that decision consistency is influenced by the configuration of the energy landscape surrounding these attractor basins<sup><xref ref-type="bibr" rid="c40">40</xref>,<xref ref-type="bibr" rid="c42">42</xref>,<xref ref-type="bibr" rid="c60">60</xref></sup>. Essentially, steep-sided and deep-basin energy landscapes contribute to consistent decision-making, as it becomes challenging for internal noise to shift activity between basins. Conversely, when energy landscapes are relatively flat and attractor basins are shallow, decisions are generated more stochastically, as it is easier for internal noise to drive activity out of the attractor basins and into alternative ones. Consistently, our RNNs modelling showed that shallower and less separated attractor basins were associated with decreased decision consistency in more difficult trials. Building upon previous research, our results provide in-silico evidence supporting the notion that the energy landscape within the state space of population activity causally influences decision consistency. Moreover, our findings present the initial circuit mechanism through which the configuration of the energy landscape for decision-related activity is modulated by feedback modulation, to our knowledge. Future studies are needed to explore the connections between different types of circuit connectivity and population activity dynamics in cognitive processing in vivo.</p>
<p>Our results are consistent with predictive coding theories of feedback function, which propose that an internal model of the world is generated in the brain based on sensory data and prior experience and is refined by incoming sensory data<sup><xref ref-type="bibr" rid="c61">61</xref>–<xref ref-type="bibr" rid="c64">64</xref></sup>. In terms of the architecture of hierarchical predictive coding schemes, different neuronal ensembles encode different attributes/choices in either the action selection or sensory evaluation process at each level of the cortical hierarchy during flexible decision-making. Meanwhile, the conditionally independent expectations are functionally segregated, so that descending predictions from the action selection process are limited to the sensory evaluation process on the matched\associated stimulus attribute but not the opposite attribute. The selectivity-specific feedback connectivity in our RNNs fits the functional segregation of expectation very well during the interplay between distinct neural processes of decision-making. Specifically, the neural ensembles related to either sensory evaluation or action selection processes for the same choice might form precise recurrently connected loops. The prediction signal carried by the precise feedback connections might facilitate sensory evaluation of the associated stimulus but prohibit evaluation of the nonmatched stimulus. This could, in turn, amplify the task-relevant sensory input, facilitate the sensorimotor transformation, and ultimately result in faster and more accurate action choice in flexible decisions. In future work, it will be important to use techniques such as projection-specific inactivation and microstimulation in vivo to test the causal contribution of feedback connectivity in decision-making and other cognitive functions.</p>
</sec>
<sec id="s4">
<title>Materials and Methods</title>
<sec id="s4a">
<title>Behavioral task, stimulus display, and animal preparation</title>
<p>The flexible visual motion discrimination (FVMD) task (<xref rid="fig1" ref-type="fig">Figure 1A</xref>) has been reported previously<sup><xref ref-type="bibr" rid="c14">14</xref></sup> and is briefly summarized below. In this task, monkeys were required to saccade to either the green or red targets based on the direction of the visual motion stimulus. Two motion directions (135°, 315°) were used, each with four different coherence levels (0%, 9%, 18%, 36% for monkey M; and 0%, 13%, 25%, 50% for monkey B) were tested. If the sample direction was 135°, the monkeys must saccade to the green target to receive a juice reward, whereas the 315° direction was associated with the red target. The rewarded target (red or green) was randomly chosen (with 50% probability) on each zero-coherence trial. The positions of red and green targets were randomly chosen between the two positions on each trial at each recording session. Therefore, there is no fixed mapping between motion stimulus and saccade direction.</p>
<p>To initiate each trial, monkeys must hold a touch-bar and acquire gaze fixation. They then needed to maintain fixation within a 2.0-2.5° window throughout the trial before their saccade choice. After a 500ms fixation period, two colored saccade targets appeared simultaneously at opposite positions relative to the fixation point with equal eccentricities (8° and 9° for Monkey M and B, respectively). 400ms later, a sample motion stimulus was presented at a location orthogonal to the axis of, but at the same eccentricity as, the saccade targets. We used motion stimuli that were full contrast, 8° diameter, random-dot movies composed of 190 dots per frame, and the dots moved at 10°/s. Monkeys needed to saccade to either red or green targets within a 60-2000ms window after sample stimulus onset. The two saccade targets were equidistant from the stimulus, with the distance typically ranging from 12 to 15 degrees. A juice reward would be delivered to the monkeys if they made correct saccade choice.</p>
<p>Two male monkeys (Macaca mulatta, 15~16 years old, 8–14 kg) were trained on the FVMD task and implanted with a head post as well as a recording chamber positioned over PPC. Our surgical, behavioral, and neurophysiological approach has been described in detail in a previous study<sup><xref ref-type="bibr" rid="c14">14</xref></sup>. Stereotaxic coordinates for chamber placement were determined from magnetic resonance imaging (MRI) scans obtained before chamber implantation. LIP chambers were centered on the intraparietal sulcus (IPS), 4.0 mm posterior to the intra-aural line and 1.0 mm lateral from the midline for monkey M, and 0 mm anterior to the intra-aural line and 15.0 mm lateral from the midline for monkey B. Monkeys were housed in individual cages under a 12-hour light/dark cycle. Behavioral training and experimental recordings were conducted during the light portion of the cycle. Monkeys sat comfortably while head-fixed in a custom-made primate chair inside a dark experiment rig. The task stimuli were displayed on a 21-inch color CRT monitor (1280*1024 resolution, 75 Hz refresh rate, 57 cm viewing distance). Both monkeys were tested with identical stimuli and timing. A solenoid-operated reward system was used to deliver juice reward to the monkeys. Monkeys’ eye positions were monitored by an optical eye tracker (SR Research) at a sampling rate of 1 kHz and stored for offline analysis. Stimulus presentation, task events, rewards, and behavioral data acquisition were accomplished using an Intel-based PC equipped with MonkeyLogic software running in MATLAB (<ext-link ext-link-type="uri" xlink:href="http://www.monkeylogic.net">http://www.monkeylogic.net</ext-link>). All experimental and surgical procedures were in accordance with the University of Chicago Animal Care and Use Committee and National Institutes of Health guidelines.</p>
</sec>
<sec id="s4b">
<title>Electrophysiological recording</title>
<p>We used either 75-μm tungsten microelectrodes (FHC, ~1 MΩ) or 16-channel V-Probes (Plexon) to record single neuron activity in LIP. Neurophysiological signals were amplified, digitized, and stored for offline spike sorting (Plexon) to verify the quality and stability of neuronal isolations. We recorded neuronal activity in a memory-guided saccade task to map LIP RF locations before each FVMD recording session.</p>
<p>Our LIP recordings targeted different hemispheres in the two monkeys (monkey M: left hemisphere; monkey Q: right hemisphere). Therefore, the contralateral target (CT) condition and ipsilateral target (IT) conditions in <xref rid="fig1" ref-type="fig">Figure 1F</xref> and <xref ref-type="fig" rid="fig1">1G</xref> referred to opposite saccade directions (target locations) between the two monkeys. For monkey M, the CT condition corresponded to the trials in which the correct saccade target was on the right visual field, whereas the CT condition for monkey Q referred to the trials in which the correct saccade was toward the left visual field. We localized LIP in each monkey according to the patterns of neuronal activity in the MGS task (i.e., spatial selectivity during stimulus presentation and delay). All neurons included in the dataset were recorded from the same locations (the same grid holes and similar depths: ~5-10 mm from the cortical surface) where we encountered spatial selectivity in the MGS task. LIP neurons were also identified based on anatomical criteria, such as the location of each electrode track relative to that expected from the MRI scans, the pattern of gray–white matter transitions encountered on each electrode penetration, and the relative depths of each neuron.</p>
<p>We aimed to present the visual motion stimulus inside the RFs of the identified neurons during each recording session. For single-channel electrode recording, only neurons exhibited visual responses to the motion stimuli during prescreening (tested with the FVMD task) were recorded with sufficient trials (~300-600) of the FVDM task. For neurons exhibiting clear spatial RFs during the MGS task, we presented the motion stimulus inside LIP neurons’ RFs; while for those neurons which did not show a clear RF during the MGS task, we presented motion stimuli in the positions (always in the visual field contralateral to the recorded hemisphere) in which neurons exhibited the strongest response to the motion stimuli. For the multi-channel recordings, we recorded all neurons isolated across all channels and presented the motion stimulus inside one of the isolated neurons’ RFs. Because adjacent recording sites were located 100µm apart, nearby neurons typically showed similar RF locations.</p>
</sec>
<sec id="s4c">
<title>Data analysis</title>
<sec id="s4c1">
<title>Neuronal pre-screening</title>
<p>While part of the neural data was presented in a previous report<sup><xref ref-type="bibr" rid="c14">14</xref></sup>, the current analysis focuses on a different phenomenon which was not examined previously. We included all neurons recorded from single-channel electrodes for the analysis. For multi-channel recordings, we only included the neurons which showed significant modulation (different from fixation period activity, one-way ANOVA, p &lt; 0.01) of their averaged activity across all motion stimuli because the stimulus could not always be presented within the RF of all the recorded neurons. The low-firing neurons whose maximum firing rates were less than 2.0 spikes/s (to the direction producing greater average responses) during stimulus presentation were also excluded for further analysis. We then applied a one-way ANOVA test to compare activity between the two different motion directions during the period following motion stimulus onset (50-250 ms after motion stimulus onset) to select neurons that showed significant motion direction selectivity (DS) during the decision period. Only neurons that showed significant (p &lt; 0.01) DS were used for further analysis.</p>
</sec>
<sec id="s4c2">
<title>Receiver operating characteristic (ROC) analysis</title>
<p>To quantify each neuron’s DS in the FVMD task, we applied an ROC analysis to the distribution of firing rates within sliding windows (100 ms width, 5 ms steps). The ROC value, which ranges between 0.0 and 1.0, indicates the performance of an ideal observer in assigning motion direction based on each neuron’s trial-by-trial firing rates. Values of 1.0 and 0.0 correspond to perfect classification (i.e., strong DS), while a value of 0.5 indicates chance-level classification performance (i.e., no DS). For trials with zero coherence motion, we assigned direction labels on each trial based on the monkey’s choice.</p>
<p>In <xref rid="fig3" ref-type="fig">Figure 3</xref>, in order to test whether DS reflected monkeys’ trial-by-trial choices, we used an ROC analysis to quantify whether LIP activity correlated with monkeys’ trial-by-trial categorical choices more than the physical direction of motion stimulus by analyzing both correct and error trials. We only included low coherence trials in this analysis because there were sufficient numbers of error trials (average performance: Monkey M: 74% correct, Monkey B: 67% correct). LIP neuronal activity was analyzed by ROC according to either the monkey’s trial-by-trial categorical choices or the direction of the sample stimulus on each trial. Furthermore, for this analysis, we only used neurons for which we recorded sufficient trials (for both correct and error trials, N&gt;4) for the low coherence condition of each motion direction (n = 45).</p>
</sec>
<sec id="s4c3">
<title>Partial correlation analysis</title>
<p>We performed a partial correlation analysis to quantify the correlation between LIP neural activity and the monkeys’ trial-by-trial categorical choices or the physical motion direction of the stimulus using all trials. For each trial, we obtained three parameters for the calculation: the stimulus direction, the pre-choice neuronal activity, and the monkeys’ choice. We assigned the stimulus directions with different values for different directions and coherence levels: positive and negative values were used for preferred and nonpreferred directions, respectively; while 4, 2, 1 and 0 are used for code the high, medium, low, and zero coherence levels. We also assigned different values to different choice directions (−2 for choosing the preferred direction, and + 2 for choosing the nonpreferred direction). Two measures were then calculated: r stimulus = r (neuronal activity, stimulus direction| choice direction), the partial correlation between neuronal activity and stimulus direction given the monkeys’ choices; and r choice = r (neuronal activity, choice direction | stimulus direction), the partial correlation between neuronal activity and the monkeys’ categorical choice given the stimulus direction. In <xref rid="fig3" ref-type="fig">Figure 3</xref>, we used the mean activity within a sliding window (100ms width, sliding with 5ms steps) for each neuron to perform the partial correlation analysis.</p>
</sec>
<sec id="s4c4">
<title>Modulation Index</title>
<p>We have calculated a modulation index for each neuron to reflect the influence of saccade direction on neuron’s response to visual stimuli. The modulation index is calculated as:
<disp-formula id="ueqn1">
<graphic xlink:href="549136v3_ueqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
, where <inline-formula><inline-graphic xlink:href="549136v3_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula> represents the average firing rate from 50ms to 250ms after sample onset for all contralateral saccade trails with a neuron’s preferred moving direction of visual stimuli. The naming conventions are the same for<inline-formula><inline-graphic xlink:href="549136v3_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="549136v3_inline3.gif" mimetype="image" mime-subtype="gif"/></inline-formula> An MI value between 0 and 1 indicate higher modulation in contralateral saccade trials, and an MI value between −1 and 0 indicates higher modulation in ipsilateral saccade trials.</p>
</sec>
<sec id="s4c5">
<title>dPCA analysis</title>
<p>We conducted demixed principal component analysis using the methodology and the code from a previous study<sup><xref ref-type="bibr" rid="c65">65</xref></sup> (<ext-link ext-link-type="uri" xlink:href="http://github.com/machenslab/dPCA">http://github.com/machenslab/dPCA</ext-link>) to reduce the dimensionality of the population activity as the standard PCA and demixes all task variables. Specifically, we tested how much each task variable (motion direction of sample stimuli, saccade direction, motion-saccade interaction, timing) contributes to the LIP population activity during the DMC task.</p>
<p>As demonstrated in the previous study, the dPCA finds separate decoder (F) and encoder (D) matrices for each task variable (∅) by minimizing the loss function:
<disp-formula id="ueqn2">
<graphic xlink:href="549136v3_ueqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where X is a linear decomposition of the data matrix, which contains the instantaneous firing rate of the recorded neurons, into variable-specific averages:
<disp-formula id="ueqn3">
<graphic xlink:href="549136v3_ueqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Here, we decomposed the neural activities into four parts: condition-independent, stimulus-dependent (two motion directions with four coherence levels), saccade-dependent (two saccade directions), dependent on the stimulus-saccade interaction, and noise. The decoder and encoder axes permit us to reduce the data into a few components capturing the majority of the variance of the data dependent on each task variable.</p>
</sec>
</sec>
<sec id="s4d">
<title>Recurrent neural network (RNN) training</title>
<sec id="s4d1">
<title>Network Implementation</title>
<p>We trained biologically inspired networks to perform the FVMD task using methodology similar to previous studies<sup><xref ref-type="bibr" rid="c28">28</xref>,<xref ref-type="bibr" rid="c36">36</xref></sup>. We implemented multiple modules in the networks through constraints on the input/output structure and the initial recurrent connectivity of the hidden layer. Specifically, we built excitatory-inhibitory networks with 200 hidden units divided into two equal-size main modules to simulate two brain hemispheres. Each main module was further divided into two nominal modules, with each one only receiving the visual motion input (motion module) or target color input (target module), respectively. This design was intended to simulate the two neuron populations whose RFs covered the motion stimulus or saccade target in the monkey electrophysiology experiment (<xref rid="fig4" ref-type="fig">Figure 4A</xref>). Every nominal module was allocated one quarter of the excitatory units (40) and one quarter of the inhibitory units (10) in the overall network to ensure that the modules did not differ in their balance of excitation/inhibition prior to training. Meanwhile, in order to simulate the local and long-range connection structures in the brain, we set different levels of recurrent connectivity within and between different modules: the local (connectivity within each nominal module) recurrent connection density (probability) was the highest (50%); the across-RF (connectivity between the two nominal modules within the same main module) connection density was set to be in the medium level (25%); the cross-hemisphere (connectivity between either the motion modules or the target modules across different main modules) connection density was the lowest (10%). Only excitatory neurons could have “cross-hemisphere” projections to the corresponding nominal module (e.g., from the motion module of the “left hemisphere” to the motion module of the “right hemisphere”). Only the connection weight within the hidden layer was updated during training following methods described previously<sup><xref ref-type="bibr" rid="c28">28</xref></sup>. In addition, the connection weights between network units are endowed with short-term synaptic plasticity, which is aimed to provide connection weights with activity-dependent fluctuation over short timescales within each trial.</p>
<p>The input to the network consisted of two parts: 9 motion input units and 8 target color input units. The preferred directions of motion input units were evenly spaced across 360°, with response tuning distributed according to a von Mises function. The value of the nth motion input unit was set to
<disp-formula id="ueqn4">
<graphic xlink:href="549136v3_ueqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
, where <inline-formula><inline-graphic xlink:href="549136v3_inline4.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, θ is the direction of motion stimulus in radian, θ<sub><italic>pref</italic></sub> is the preferred direction of this motion input unit,<inline-formula><inline-graphic xlink:href="549136v3_inline5.gif" mimetype="image" mime-subtype="gif"/></inline-formula> after stimulus onset but 0 elsewhere, c ∈ [0,1] is the coherence of the dot motion stimulus, <italic>b</italic>. is a binary value that equals 0 before stimulus onset and 1 after that, and <italic>d</italic> is a constant visual input signal with an amplitude of 2 that decays with time. Specifically, for zero-coherence input, since <inline-formula><inline-graphic xlink:href="549136v3_inline6.gif" mimetype="image" mime-subtype="gif"/></inline-formula> would be zero, we set this term as 0.4<italic>max</italic>(<italic>c</italic>)</p>
<p>The target input units were initially evenly divided into two groups projected to the two target modules of hidden units. Each group was further divided into red and green subgroups. The color subgroup was set as active with an amplitude of <inline-formula><inline-graphic xlink:href="549136v3_inline7.gif" mimetype="image" mime-subtype="gif"/></inline-formula> to represent the color within the projected target module, while the other color group remained silent (amplitude =0). An exponential decay filter was also used to fit the activity of sensory neurons in the early sensory cortex across time:
<disp-formula id="ueqn5">
<graphic xlink:href="549136v3_ueqn5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
, where <italic>x</italic> is the constant visual input for motion input and the color signal for color input,<italic>t</italic> is time in miliseconds.</p>
<p>The two output units of the network simulate two different saccade directions. In order to simulate the oculomotor control in the brain, each brain hemisphere (main module) projects much more densely to the contralateral response units (probability = 0.32) than the ipsilateral response units (probability = 0.08). To generate a probability distribution over output values at each time point, we also applied a softmax function to scale the response unit activities in the output layer. To reduce the stochasticity of the network activity brought by input and output connections, we randomly sampled input and output weights from a normal distribution (𝒩 (0.2,0.05)). In addition, the input weights were re-initialized if there were extreme values (the minimum value was smaller than ¾ of the maximum value) after multiplying the stimulus signal and weight of motion or target input. Similarly, the output weights were re-initialized if there were extreme values in the output weight values. The input units had excitatory and random projections to the recurrent units with a probability of 0.32. However, only the excitatory units in the target modules of each “hemisphere” could project to the output units. Both the input and output weights were fixed for each network during task training.</p>
</sec>
<sec id="s4d2">
<title>Network training</title>
<p>The networks were trained using BrainPy<sup><xref ref-type="bibr" rid="c66">66</xref></sup> on an Intel(R) Core(TM) i9-9900K CPU (3.60GHz, 8 cores). The network was optimized using backpropagation through time (BPTT) and stochastic gradient descent with an Adam optimizer (default setting, first moment estimates decay rate=0.9, second moment estimates decay rate =0.999) to minimize a loss function. The network parameters (recurrent weights/biases) were optimized to minimize a loss function with three parts as in a previous study<sup><xref ref-type="bibr" rid="c28">28</xref></sup>: (a) a performance loss; (b) a metabolic cost on mean neuronal activity; and (c) a metabolic cost on connectivity. The gradient was clipped to a maximum L2 value of 0.1 to avoid the exploding gradient problem. During training, only the hidden unit related parameters (weights, bias, and initial activities) were updated. The training process was terminated when the network’s performance accuracy reached 99% or till the maximum number of iterations (2000).</p>
<p>During each trial of the training and testing of the FVMD task, networks were first presented with two color targets through the target input units, and then presented with the motion direction through the motion input units. Both the motion and target inputs persisted until the end of each trial. A short time after the motion input (100ms, 5 time steps), the networks were required to report the direction of the stimulus motion by choosing the saccade target with the appropriate color. Specifically, each element of the task design in the FVMD task that the models were trained to perform was tailored to match those used in the monkey experiments: the directions of the motion stimuli, the target colors, as well as the task (stimulus) durations were the same as that used in monkey electrophysiology experiments. Trials were programmatically generated by constructing motion/target inputs to the networks at each timestep and the desired response (left saccade, right saccade) at each timestep. In total, we trained 50 networks to perform the FVDM task. All networks were first trained using motion directions with two coherence levels (60% and 90%) and were then tested using motion stimuli with another four different coherence levels (75%, 55%, 35%, and zero), which had never been presented during training. Besides the difference in the coherence of motion input, the color inputs remained the same during the testing period. All the networks achieved consistently high performance by the end of training (&gt; 99% accuracy). All the important model hyperparameters were listed in Table S1.</p>
</sec>
<sec id="s4d3">
<title>Quantification of the networks’ behavioral performance</title>
<p>To test whether our multi-module RNNs exhibited decision behavior similar to monkey subjects, we examined their performance accuracies and RTs when tested by novel stimuli with different coherence levels. The performance accuracy was defined as whether the output of the response units (starting from 100ms after stimulus onset to the trial end) matched the desired output. Furthermore, we defined the networks’ RTs as the time point from which the differences between two output units were greater than a threshold (0.8) for three consecutive time points after the stimulus onset. During some trials, the threshold was never reached until the end of the trial (500ms after the motion stimulus onset). In these cases, we artificially set the RT to be 600ms in these trials for further analysis.</p>
</sec>
<sec id="s4d4">
<title>Analysis of RNN activity</title>
<p>We performed the same analyses on the RNN units as we did on the neurophysiology data. In <xref rid="fig4" ref-type="fig">Figure 4</xref>–<xref ref-type="fig" rid="fig5">5</xref>, data from both the example network and averaged results across all the networks were shown. For every network, we only included the units which exhibited at least one kind of task-related modulation during the test period (i.e., motion direction selectivity or saccade direction selectivity, one-way ANOVA test, p &lt; 0.01). In order to quantify the activity related to evaluating motion stimulus, we analyzed the motion DS only including the units in the motion modules, whereas only the saccade DS of units in the target modules were calculated to quantify the activity related to saccade selection during the decision-making.</p>
</sec>
<sec id="s4d5">
<title>Analysis of RNN connectivity</title>
<p>To examine the potential circuit mechanisms underlying the modulation of action selection on sensory evaluation during decision-making in the RNNs, we examined the cross-module connection weights in the trained networks. Specifically, we defined the feedforward connection as the projection from units in the motion module to units in the target module within the same main module (hemisphere). We also defined the feedback connection as the projection from units in the target module to units in the motion module within the same main module. Furthermore, we grouped the cross-module connections into the selectivity-matched and selectivity-mismatched groups based on the preferences of the neural encoding of units in the motion and target modules. The selectivity-matched group included two types of unit pairs: 1) units in the motion module preferred to encode 315° and units in the target module preferred to encode red, 2) units in the motion module preferred to encode 135° and units in the target module preferred to encode green. The selectivity-mismatched group includes the other two types of unit pairs: 3) units in the motion module preferred to encode 315° while units in the target module preferred to encode green, and 4) units in the motion module preferred to encode 135°while units in the target module preferred to encode red. The values of connection weights projected from excitatory and inhibitory units were set as positive and negative, respectively.</p>
<p>We also examined the correlation between the similarity of neural selectivity and connection strength for different unit pairs in the RNNs based on the following steps: First, both the preference and strength of motion direction encoding or target color encoding were quantified for units in the motion module or target module, respectively. This was done by calculating the averaged differential activity to the 315° and 135° motion stimuli after motion stimulus onset or calculating the averaged differential activity to the red and green targets after target onset. In this case, the unit pairs that exhibited matched selectivity would show selectivity values with the same sign (positive or negative), whereas the unit pairs that exhibited mismatched selectivity would show selectivity values with the opposite signs. Second, the units in both the motion module and target modules were ranked based on selectivity values. Third, the selectivity similarity of each cross-module unit pair was quantified by calculating the reverse value of the absolute differences between the target color selectivity rank and the motion direction selectivity rank. The rank of the weight value of each pair was calculated and then reversed to give the lower weight value a higher rank score. Finally, we calculated the Pearson correlation between weight rank and selectivity similarity. A positive correlation indicates that units that exhibited stronger encoding preference to one motion direction in the motion module were more likely to connect with the units in the target module that exhibited stronger encoding on the matched target color.</p>
</sec>
<sec id="s4d6">
<title>Inactivation experiments in silico</title>
<p>Our examination of the network connectivity within the hidden layer of the RNNs revealed that the selectivity-specific top-down connections originated from the target module to the motion module. To assess the causal contribution of such precise feedback connections to the modulation of action selection on sensory evaluation, we performed two in-silico analogues of neuronal inactivation experiments similar to a previous study<sup><xref ref-type="bibr" rid="c28">28</xref></sup>. We hypothesized that ablating or disrupting the precise feedback connection from the target module to the motion module would significantly impact the activity patterns of the units in the motion module. Specifically, such inactivation on connectivity was expected to reduce the difference in motion DS in the notion module between CT and IT conditions. To test this hypothesis, we performed the projection-specific inactivation experiments in the RNNs in three different ways. First, we ablated all the feedback projections from the target module to the motion module while keeping all the other network parameters unchanged after the networks were fully trained. We then tested the networks with the untrained motion stimuli used in the normal experiment. The connectivity ablation was implemented by directly setting the connection weights from units in the target module to units in the motion module to zero. Second, we randomly rearranged the connection weights from the target module to the motion module after the network was fully trained by shuffling the corresponding weights in the weight matrix. Then, we tested the networks with the testing motion stimuli. This was aimed to disrupt the selectivity-specific feedback connection without changing the total strength of the feedback connection. We repeated this random feedback weight rearrangement process 100 times for each of the 50 trained networks. Subsequently, we measured the impact on the networks’ behavior performance and the activity patterns in both the motion and saccade modules. In particular, for each network, we tested whether there were still different levels of motion direction selectivity of units in the motion module between CT and IT conditions after inactivating the feedback connectivity.</p>
<p>We further performed pattern-specific ablation of the feedback connections in the RNNs, in order to examine the causal roles of different patterns of feedback connectivity in solving the FVDM task. Specifically, we separated the feedback projections in each RNN into the specific group and the nonspecific group. The specific group included two conditions: 1) the feedback connection weight was positive between the selectivity-matched unit pairs, and 2) the feedback connection weight was negative between the selectivity-nonmatched unit pairs; whereas the nonspecific group included the rest of the feedback conditions in each RNN. We then tested the effects of the pattern-specific connectivity inactivation on the RNNs’ behavior performance when tested with the untrained motion stimuli.</p>
<p>In the third inactivation experiment, we trained 50 additional RNNs without feedback connections to learn the FVMD task, in order to test the importance of feedback connectivity in solving the flexible decision task. These networks were initialized using identical hyperparameters and trained with the same methodology as the normal RNNs, except that the feedback connections from the target module to the motion module were ablated before training. We then examined these RNNs’ behavior performance and unit activity when testing with the untrained motion stimuli used in the normal experiment. Furthermore, we trained another 50 RNNs without feedback connection to learn the FVMD task. These RNNs were initialized with higher recurrent connection probabilities than the full-model RNNs to keep the number of the total trainable connection weight comparable to that in the full-model RNNs. We raised the recurrent connection probability by a factor of 1.176 after removing feedback connections (average number of connections in 50 normal RNNs = 8193, average number of connections in 50 networks without feedback = 8184, p = 0.53, independent sample t-test). Except for the recurrent connection probability, all the other hyperparameters and the training methodology were the same as the normal RNNs. We then compared the behavior performance of these RNNs with that of the normal RNNS when testing with the untrained motion stimuli.</p>
</sec>
<sec id="s4d7">
<title>Analysis of neural landscape</title>
<p>For each network, we adopted a methodology similar to a previous study (cite) to reconstruct the energy landscape of population activity within the target module. Initially, units in the target module exhibiting saccade direction selectivity were identified. Subsequently, we employed principal component analysis (PCA) to reduce the dimensionality of the population activity. Specifically, PCA was performed on the average activity across these units, considering each stimulus motion direction, coherence level, and choice. We retained the first five principal components (PCs) for further analysis, as they explained over 90% of the total variance in population activity. Following this, the trial-by-trial population activities were transformed into 5-dimensional data using the aforementioned five PCs.</p>
<p>To predict trial-by-trial choice, we employed a linear Support Vector Machine (SVM) classifier with 10-fold cross-validation. Specifically, we utilized the average activity of the last 100 ms of each trial as input for the classifier. The choice axis was determined by selecting the normal vector of the separating hyperplane from the SVM classifier that demonstrated the best performance. Subsequently, the 5-dimensional data points were projected onto the choice axis, resulting in 1-dimensional projections. These projections represented the positions along the choice axis, with the intersection between the normal vector and the hyperplane serving as the zero point.</p>
<p>The potential in this context is determined by integrating the spatial component of the time derivative of the population activity, denoted as <italic>X</italic><sub><italic>t</italic></sub>, for a given condition. To be more precise, we began by computing the expected value across trials of the time derivative of the unit activities for each choice. Subsequently, we employed the potential function <italic>V</italic>(<italic>x,t</italic>) to to evaluate the potential at position x and time t,
<disp-formula id="ueqn6">
<graphic xlink:href="549136v3_ueqn6.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Crucially, we computed the potential separately for each choice, establishing the potential at position 0 as the zero-potential reference. To provide a holistic evaluation of the potential landscape, we combined the potentials of both choices at position 0.</p>
<p>Furthermore, we expanded the computation of potentials to encompass each stimulus coherence level using the aforementioned approach. Similar to the prior analysis, the time derivatives were still derived from the 1-D projections of each data point onto the choice axis. However, in this instance, the conditions were based on the stimulus coherence level rather than the choice. For a representative potential value for each model, we averaged the potentials at the time point of 300ms after the stimulus onset. Additionally, recognizing that the positions visited by each model might differ, we ensured the accuracy of standard error estimation by retaining only the potential values at positions continuously visited by four or more models.</p>
</sec>
</sec>
</sec>

</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>We thank Tianming Yang, Matthew Rosen, Siyu Wang, Cheng Xue, Gongcheng Yu, Mingze Li and Ou Zhu for their comments on an earlier version of this manuscript. We also thank the veterinary staff at The University of Chicago Animal Resources Center for expert assistance.</p>
<p>This study was supported by STI2030-Major Projects (2021ZD0203800), NSFC32171036.</p>
</ack>
<sec id="suppd1e1558" sec-type="supplementary-material">
<title>Additional files</title>
<supplementary-material id="d1e1549">
<label>Supplementary Figures</label>
<media xlink:href="supplements/549136_file02.pdf"/>
</supplementary-material>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>O’Connell</surname>, <given-names>R. G.</given-names></string-name>, <string-name><surname>Shadlen</surname>, <given-names>M. N.</given-names></string-name>, <string-name><surname>Wong-Lin</surname>, <given-names>K.</given-names></string-name> &amp; <string-name><surname>Kelly</surname>, <given-names>S. P.</given-names></string-name></person-group> <article-title>Bridging Neural and Computational Viewpoints on Perceptual Decision-Making</article-title>. <source>Trends Neurosci</source> <volume>41</volume>, <fpage>838</fpage>–<lpage>852</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.tins.2018.06.005</pub-id> (<year>2018</year>).</mixed-citation></ref>
<ref id="c2"><label>2</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Freedman</surname>, <given-names>D. J.</given-names></string-name> &amp; <string-name><surname>Assad</surname>, <given-names>J. A.</given-names></string-name></person-group> <article-title>Neuronal Mechanisms of Visual Categorization: An Abstract View on Decision Making</article-title>. <source>Annu Rev Neurosci</source> <volume>39</volume>, <fpage>129</fpage>–<lpage>147</lpage>, doi:<pub-id pub-id-type="doi">10.1146/annurev-neuro-071714-033919</pub-id> (<year>2016</year>).</mixed-citation></ref>
<ref id="c3"><label>3</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name> &amp; <string-name><surname>Shadlen</surname>, <given-names>M. N.</given-names></string-name></person-group> <article-title>The neural basis of decision making</article-title>. <source>Annu Rev Neurosci</source> <volume>30</volume>, <fpage>535</fpage>–<lpage>574</lpage>, doi:<pub-id pub-id-type="doi">10.1146/annurev.neuro.29.051605.113038</pub-id> (<year>2007</year>).</mixed-citation></ref>
<ref id="c4"><label>4</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huk</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Katz</surname>, <given-names>L. N.</given-names></string-name> &amp; <string-name><surname>Yates</surname>, <given-names>J. L.</given-names></string-name></person-group> <article-title>The Role of the Lateral Intraparietal Area in (the Study of) Decision Making</article-title>. <source>Annu Rev Neurosci</source> <volume>40</volume>, <fpage>349</fpage>–<lpage>372</lpage>, doi:<pub-id pub-id-type="doi">10.1146/annurev-neuro-072116-031508</pub-id> (<year>2017</year>).</mixed-citation></ref>
<ref id="c5"><label>5</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hanks</surname>, <given-names>T. D.</given-names></string-name> &amp; <string-name><surname>Summerfield</surname>, <given-names>C.</given-names></string-name></person-group> <article-title>Perceptual Decision Making in Rodents, Monkeys, and Humans</article-title>. <source>Neuron</source> <volume>93</volume>, <fpage>15</fpage>–<lpage>31</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2016.12.003</pub-id> (<year>2017</year>).</mixed-citation></ref>
<ref id="c6"><label>6</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shadlen</surname>, <given-names>M. N.</given-names></string-name> &amp; <string-name><surname>Kiani</surname>, <given-names>R.</given-names></string-name></person-group> <article-title>Decision making as a window on cognition</article-title>. <source>Neuron</source> <volume>80</volume>, <fpage>791</fpage>–<lpage>806</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2013.10.047</pub-id> (<year>2013</year>).</mixed-citation></ref>
<ref id="c7"><label>7</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Freedman</surname>, <given-names>D. J.</given-names></string-name> &amp; <string-name><surname>Assad</surname>, <given-names>J. A.</given-names></string-name></person-group> <article-title>A proposed common neural mechanism for categorization and perceptual decisions</article-title>. <source>Nat Neurosci</source> <volume>14</volume>, <fpage>143</fpage>–<lpage>146</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nn.2740</pub-id> (<year>2011</year>).</mixed-citation></ref>
<ref id="c8"><label>8</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Platt</surname>, <given-names>M. L.</given-names></string-name> &amp; <string-name><surname>Glimcher</surname>, <given-names>P. W.</given-names></string-name></person-group> <article-title>Neural correlates of decision variables in parietal cortex</article-title>. <source>Nature</source> <volume>400</volume>, <fpage>233</fpage>–<lpage>238</lpage>, doi:<pub-id pub-id-type="doi">10.1038/22268</pub-id> (<year>1999</year>).</mixed-citation></ref>
<ref id="c9"><label>9</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Roitman</surname>, <given-names>J. D.</given-names></string-name> &amp; <string-name><surname>Shadlen</surname>, <given-names>M. N.</given-names></string-name></person-group> <article-title>Response of neurons in the lateral intraparietal area during a combined visual discrimination reaction time task</article-title>. <source>J Neurosci</source> <volume>22</volume>, <fpage>9475</fpage>–<lpage>9489</lpage> (<year>2002</year>).</mixed-citation></ref>
<ref id="c10"><label>10</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shadlen</surname>, <given-names>M. N.</given-names></string-name> &amp; <string-name><surname>Newsome</surname>, <given-names>W. T.</given-names></string-name></person-group> <article-title>Motion perception: seeing and deciding</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source> <volume>93</volume>, <fpage>628</fpage>–<lpage>633</lpage>, doi:<pub-id pub-id-type="doi">10.1073/pnas.93.2.628</pub-id> (<year>1996</year>).</mixed-citation></ref>
<ref id="c11"><label>11</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shadlen</surname>, <given-names>M. N.</given-names></string-name> &amp; <string-name><surname>Newsome</surname>, <given-names>W. T.</given-names></string-name></person-group> <article-title>Neural basis of a perceptual decision in the parietal cortex (area LIP) of the rhesus monkey</article-title>. <source>J Neurophysiol</source> <volume>86</volume>, <fpage>1916</fpage>–<lpage>1936</lpage>, doi:<pub-id pub-id-type="doi">10.1152/jn.2001.86.4.1916</pub-id> (<year>2001</year>).</mixed-citation></ref>
<ref id="c12"><label>12</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sugrue</surname>, <given-names>L. P.</given-names></string-name>, <string-name><surname>Corrado</surname>, <given-names>G. S.</given-names></string-name> &amp; <string-name><surname>Newsome</surname>, <given-names>W. T.</given-names></string-name></person-group> <article-title>Matching behavior and the representation of value in the parietal cortex</article-title>. <source>Science</source> <volume>304</volume>, <fpage>1782</fpage>–<lpage>1787</lpage>, doi:<pub-id pub-id-type="doi">10.1126/science.1094765</pub-id> (<year>2004</year>).</mixed-citation></ref>
<ref id="c13"><label>13</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yates</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Park</surname>, <given-names>I. M.</given-names></string-name>, <string-name><surname>Katz</surname>, <given-names>L. N.</given-names></string-name>, <string-name><surname>Pillow</surname>, <given-names>J. W.</given-names></string-name> &amp; <string-name><surname>Huk</surname>, <given-names>A. C.</given-names></string-name></person-group> <article-title>Functional dissection of signal and noise in MT and LIP during decision-making</article-title>. <source>Nat Neurosci</source> <volume>20</volume>, <fpage>1285</fpage>–<lpage>1292</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nn.4611</pub-id> (<year>2017</year>).</mixed-citation></ref>
<ref id="c14"><label>14</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname>, <given-names>Y.</given-names></string-name> &amp; <string-name><surname>Freedman</surname>, <given-names>D. J.</given-names></string-name></person-group> <article-title>Posterior parietal cortex plays a causal role in perceptual and categorical decisions</article-title>. <source>Science</source> <volume>365</volume>, <fpage>180</fpage>–<lpage>185</lpage>, doi:<pub-id pub-id-type="doi">10.1126/science.aaw8347</pub-id> (<year>2019</year>).</mixed-citation></ref>
<ref id="c15"><label>15</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Freedman</surname>, <given-names>D. J.</given-names></string-name> &amp; <string-name><surname>Assad</surname>, <given-names>J. A.</given-names></string-name></person-group> <article-title>Experience-dependent representation of visual categories in parietal cortex</article-title>. <source>Nature</source> <volume>443</volume>, <fpage>85</fpage>–<lpage>88</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nature05078</pub-id> (<year>2006</year>).</mixed-citation></ref>
<ref id="c16"><label>16</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Freedman</surname>, <given-names>D. J.</given-names></string-name> &amp; <string-name><surname>Assad</surname>, <given-names>J. A.</given-names></string-name></person-group> <article-title>Distinct encoding of spatial and nonspatial visual information in parietal cortex</article-title>. <source>J Neurosci</source> <volume>29</volume>, <fpage>5671</fpage>–<lpage>5680</lpage>, doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2878-08.2009</pub-id> (<year>2009</year>).</mixed-citation></ref>
<ref id="c17"><label>17</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bennur</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name></person-group> <article-title>Distinct representations of a perceptual decision and the associated oculomotor plan in the monkey lateral intraparietal area</article-title>. <source>J Neurosci</source> <volume>31</volume>, <fpage>913</fpage>–<lpage>921</lpage>, doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.4417-10.2011</pub-id> (<year>2011</year>).</mixed-citation></ref>
<ref id="c18"><label>18</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Swaminathan</surname>, <given-names>S. K.</given-names></string-name> &amp; <string-name><surname>Freedman</surname>, <given-names>D. J.</given-names></string-name></person-group> <article-title>Preferential encoding of visual categories in parietal cortex compared with prefrontal cortex</article-title>. <source>Nat Neurosci</source> <volume>15</volume>, <fpage>315</fpage>–<lpage>320</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nn.3016</pub-id> (<year>2012</year>).</mixed-citation></ref>
<ref id="c19"><label>19</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Mohan</surname>, <given-names>K.</given-names></string-name> &amp; <string-name><surname>Freedman</surname>, <given-names>D. J.</given-names></string-name></person-group> <article-title>Abstract Encoding of Categorical Decisions in Medial Superior Temporal and Lateral Intraparietal Cortices</article-title>. <source>J Neurosci</source> <volume>42</volume>, <fpage>9069</fpage>–<lpage>9081</lpage>, doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.0017-22.2022</pub-id> (<year>2022</year>).</mixed-citation></ref>
<ref id="c20"><label>20</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kiani</surname>, <given-names>R.</given-names></string-name> &amp; <string-name><surname>Shadlen</surname>, <given-names>M. N.</given-names></string-name></person-group> <article-title>Representation of confidence associated with a decision by neurons in the parietal cortex</article-title>. <source>Science</source> <volume>324</volume>, <fpage>759</fpage>–<lpage>764</lpage>, doi:<pub-id pub-id-type="doi">10.1126/science.1169405</pub-id> (<year>2009</year>).</mixed-citation></ref>
<ref id="c21"><label>21</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Katz</surname>, <given-names>L. N.</given-names></string-name>, <string-name><surname>Yates</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Pillow</surname>, <given-names>J. W.</given-names></string-name> &amp; <string-name><surname>Huk</surname>, <given-names>A. C.</given-names></string-name></person-group> <article-title>Dissociated functional significance of decision-related activity in the primate dorsal stream</article-title>. <source>Nature</source> <volume>535</volume>, <fpage>285</fpage>–<lpage>288</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nature18617</pub-id> (<year>2016</year>).</mixed-citation></ref>
<ref id="c22"><label>22</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Zhu</surname>, <given-names>O.</given-names></string-name> &amp; <string-name><surname>Freedman</surname>, <given-names>D. J.</given-names></string-name></person-group> <article-title>Posterior Parietal Cortex Plays a Causal Role in Abstract Memory-Based Visual Categorical Decisions</article-title>. <source>J Neurosci</source> <volume>43</volume>, <fpage>4315</fpage>–<lpage>4328</lpage>, doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2241-22.2023</pub-id> (<year>2023</year>).</mixed-citation></ref>
<ref id="c23"><label>23</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kim</surname>, <given-names>J. N.</given-names></string-name> &amp; <string-name><surname>Shadlen</surname>, <given-names>M. N.</given-names></string-name></person-group> <article-title>Neural correlates of a decision in the dorsolateral prefrontal cortex of the macaque</article-title>. <source>Nat Neurosci</source> <volume>2</volume>, <fpage>176</fpage>–<lpage>185</lpage>, doi:<pub-id pub-id-type="doi">10.1038/5739</pub-id> (<year>1999</year>).</mixed-citation></ref>
<ref id="c24"><label>24</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rossi-Pool</surname>, <given-names>R.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Decoding a Decision Process in the Neuronal Population of Dorsal Premotor Cortex</article-title>. <source>Neuron</source> <volume>96</volume>, <fpage>1432</fpage>–<lpage>1446 e1437</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2017.11.023</pub-id> (<year>2017</year>).</mixed-citation></ref>
<ref id="c25"><label>25</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ding</surname>, <given-names>L.</given-names></string-name> &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name></person-group> <article-title>Neural correlates of perceptual decision making before, during, and after decision commitment in monkey frontal eye field</article-title>. <source>Cereb Cortex</source> <volume>22</volume>, <fpage>1052</fpage>–<lpage>1067</lpage>, doi:<pub-id pub-id-type="doi">10.1093/cercor/bhr178</pub-id> (<year>2012</year>).</mixed-citation></ref>
<ref id="c26"><label>26</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ferrera</surname>, <given-names>V. P.</given-names></string-name>, <string-name><surname>Yanike</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Cassanello</surname>, <given-names>C.</given-names></string-name></person-group> <article-title>Frontal eye field neurons signal changes in decision criteria</article-title>. <source>Nat Neurosci</source> <volume>12</volume>, <fpage>1458</fpage>–<lpage>1462</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nn.2434</pub-id> (<year>2009</year>).</mixed-citation></ref>
<ref id="c27"><label>27</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Heitz</surname>, <given-names>R. P.</given-names></string-name> &amp; <string-name><surname>Schall</surname>, <given-names>J. D.</given-names></string-name></person-group> <article-title>Neural mechanisms of speed-accuracy tradeoff</article-title>. <source>Neuron</source> <volume>76</volume>, <fpage>616</fpage>–<lpage>628</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2012.08.030</pub-id> (<year>2012</year>).</mixed-citation></ref>
<ref id="c28"><label>28</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname>, <given-names>Y.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Distributed functions of prefrontal and parietal cortices during sequential categorical decisions</article-title>. <source>eLife</source> <volume>10</volume>, doi:<pub-id pub-id-type="doi">10.7554/eLife.58782</pub-id> (<year>2021</year>).</mixed-citation></ref>
<ref id="c29"><label>29</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Horwitz</surname>, <given-names>G. D.</given-names></string-name> &amp; <string-name><surname>Newsome</surname>, <given-names>W. T.</given-names></string-name></person-group> <article-title>Separate signals for target selection and movement specification in the superior colliculus</article-title>. <source>Science</source> <volume>284</volume>, <fpage>1158</fpage>–<lpage>1161</lpage>, doi:<pub-id pub-id-type="doi">10.1126/science.284.5417.1158</pub-id> (<year>1999</year>).</mixed-citation></ref>
<ref id="c30"><label>30</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Peysakhovich</surname>, <given-names>B.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Primate superior colliculus is engaged in abstract higher-order cognition</article-title>. <source>bioRxiv</source>, doi:<pub-id pub-id-type="doi">10.1101/2023.01.17.524416</pub-id> (<year>2023</year>).</mixed-citation></ref>
<ref id="c31"><label>31</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ding</surname>, <given-names>L.</given-names></string-name> &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name></person-group> <article-title>Caudate encodes multiple computations for perceptual decisions</article-title>. <source>J Neurosci</source> <volume>30</volume>, <fpage>15747</fpage>–<lpage>15759</lpage>, doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2894-10.2010</pub-id> (<year>2010</year>).</mixed-citation></ref>
<ref id="c32"><label>32</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name> &amp; <string-name><surname>Shadlen</surname>, <given-names>M. N.</given-names></string-name></person-group> <article-title>Representation of a perceptual decision in developing oculomotor commands</article-title>. <source>Nature</source> <volume>404</volume>, <fpage>390</fpage>–<lpage>394</lpage>, doi:<pub-id pub-id-type="doi">10.1038/35006062</pub-id> (<year>2000</year>).</mixed-citation></ref>
<ref id="c33"><label>33</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jun</surname>, <given-names>E. J.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Causal role for the primate superior colliculus in the computation of evidence for perceptual decisions</article-title>. <source>Nat Neurosci</source> <volume>24</volume>, <fpage>1121</fpage>–<lpage>1131</lpage>, doi:<pub-id pub-id-type="doi">10.1038/s41593-021-00878-6</pub-id> (<year>2021</year>).</mixed-citation></ref>
<ref id="c34"><label>34</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shushruth</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Mazurek</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Shadlen</surname>, <given-names>M. N.</given-names></string-name></person-group> <article-title>Comparison of Decision-Related Signals in Sensory and Motor Preparatory Responses of Neurons in Area LIP</article-title>. <source>J Neurosci</source> <volume>38</volume>, <fpage>6350</fpage>–<lpage>6365</lpage>, doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.0668-18.2018</pub-id> (<year>2018</year>).</mixed-citation></ref>
<ref id="c35"><label>35</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Engel</surname>, <given-names>T. A.</given-names></string-name>, <string-name><surname>Chaisangmongkon</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Freedman</surname>, <given-names>D. J.</given-names></string-name> &amp; <string-name><surname>Wang</surname>, <given-names>X. J.</given-names></string-name></person-group> <article-title>Choice-correlated activity fluctuations underlie learning of neuronal category representation</article-title>. <source>Nat Commun</source> <volume>6</volume>, <fpage>6454</fpage>, doi:<pub-id pub-id-type="doi">10.1038/ncomms7454</pub-id> (<year>2015</year>).</mixed-citation></ref>
<ref id="c36"><label>36</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Masse</surname>, <given-names>N. Y.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>G. R.</given-names></string-name>, <string-name><surname>Song</surname>, <given-names>H. F.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>X. J.</given-names></string-name> &amp; <string-name><surname>Freedman</surname>, <given-names>D. J.</given-names></string-name></person-group> <article-title>Circuit mechanisms for the maintenance and manipulation of information in working memory</article-title>. <source>Nat Neurosci</source> <volume>22</volume>, <fpage>1159</fpage>–<lpage>1167</lpage>, doi:<pub-id pub-id-type="doi">10.1038/s41593-019-0414-3</pub-id> (<year>2019</year>).</mixed-citation></ref>
<ref id="c37"><label>37</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Song</surname>, <given-names>H. F.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>G. R.</given-names></string-name> &amp; <string-name><surname>Wang</surname>, <given-names>X. J.</given-names></string-name></person-group> <article-title>Training Excitatory-Inhibitory Recurrent Neural Networks for Cognitive Tasks: A Simple and Flexible Framework</article-title>. <source>PLoS Comput Biol</source> <volume>12</volume>, <fpage>e1004792</fpage>, doi:<pub-id pub-id-type="doi">10.1371/journal.pcbi.1004792</pub-id> (<year>2016</year>).</mixed-citation></ref>
<ref id="c38"><label>38</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Deco</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Rolls</surname>, <given-names>E. T.</given-names></string-name>, <string-name><surname>Albantakis</surname>, <given-names>L.</given-names></string-name> &amp; <string-name><surname>Romo</surname>, <given-names>R.</given-names></string-name></person-group> <article-title>Brain mechanisms for perceptual and reward-related decision-making</article-title>. <source>Prog Neurobiol</source> <volume>103</volume>, <fpage>194</fpage>–<lpage>213</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.pneurobio.2012.01.010</pub-id> (<year>2013</year>).</mixed-citation></ref>
<ref id="c39"><label>39</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Finkelstein</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Attractor dynamics gate cortical information flow during decision-making</article-title>. <source>Nat Neurosci</source> <volume>24</volume>, <fpage>843</fpage>–<lpage>850</lpage>, doi:<pub-id pub-id-type="doi">10.1038/s41593-021-00840-6</pub-id> (<year>2021</year>).</mixed-citation></ref>
<ref id="c40"><label>40</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Falcone</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Richmond</surname>, <given-names>B.</given-names></string-name> &amp; <string-name><surname>Averbeck</surname>, <given-names>B. B.</given-names></string-name></person-group> <article-title>Attractor dynamics reflect decision confidence in macaque prefrontal cortex</article-title>. <source>Nat Neurosci</source> <volume>26</volume>, <fpage>1970</fpage>–<lpage>1980</lpage>, doi:<pub-id pub-id-type="doi">10.1038/s41593-023-01445-x</pub-id> (<year>2023</year>).</mixed-citation></ref>
<ref id="c41"><label>41</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname>, <given-names>X. J.</given-names></string-name></person-group> <article-title>Probabilistic decision making by slow reverberation in cortical circuits</article-title>. <source>Neuron</source> <volume>36</volume>, <fpage>955</fpage>–<lpage>968</lpage>, doi:<pub-id pub-id-type="doi">10.1016/s0896-6273(02)01092-9</pub-id> (<year>2002</year>).</mixed-citation></ref>
<ref id="c42"><label>42</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wong</surname>, <given-names>K. F.</given-names></string-name>, <string-name><surname>Huk</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Shadlen</surname>, <given-names>M. N.</given-names></string-name> &amp; <string-name><surname>Wang</surname>, <given-names>X. J.</given-names></string-name></person-group> <article-title>Neural circuit dynamics underlying accumulation of time-varying evidence during perceptual decision making</article-title>. <source>Front Comput Neurosci</source> <volume>1</volume>, <fpage>6</fpage>, doi:<pub-id pub-id-type="doi">10.3389/neuro.10.006.2007</pub-id> (<year>2007</year>).</mixed-citation></ref>
<ref id="c43"><label>43</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Motter</surname>, <given-names>B. C.</given-names></string-name></person-group> <article-title>Neural correlates of attentive selection for color or luminance in extrastriate area V4</article-title>. <source>J Neurosci</source> <volume>14</volume>, <fpage>2178</fpage>–<lpage>2189</lpage>, doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.14-04-02178.1994</pub-id> (<year>1994</year>).</mixed-citation></ref>
<ref id="c44"><label>44</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Motter</surname>, <given-names>B.C.</given-names></string-name></person-group> <article-title>Neural correlates of feature selective memory and pop-out in extrastriate area V4</article-title>. <source>J Neurosci</source> <volume>14</volume>, <fpage>2190</fpage>–<lpage>2199</lpage>, doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.14-04-02190.1994</pub-id> (<year>1994</year>).</mixed-citation></ref>
<ref id="c45"><label>45</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Martinez-Trujillo</surname>, <given-names>J. C.</given-names></string-name> &amp; <string-name><surname>Treue</surname>, <given-names>S.</given-names></string-name></person-group> <article-title>Feature-based attention increases the selectivity of population responses in primate visual cortex</article-title>. <source>Curr Biol</source> <volume>14</volume>, <fpage>744</fpage>–<lpage>751</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.cub.2004.04.028</pub-id> (<year>2004</year>).</mixed-citation></ref>
<ref id="c46"><label>46</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bichot</surname>, <given-names>N. P.</given-names></string-name>, <string-name><surname>Rossi</surname>, <given-names>A. F.</given-names></string-name> &amp; <string-name><surname>Desimone</surname>, <given-names>R.</given-names></string-name></person-group> <article-title>Parallel and serial neural mechanisms for visual search in macaque area V4</article-title>. <source>Science</source> <volume>308</volume>, <fpage>529</fpage>–<lpage>534</lpage>, doi:<pub-id pub-id-type="doi">10.1126/science.1109676</pub-id> (<year>2005</year>).</mixed-citation></ref>
<ref id="c47"><label>47</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Maunsell</surname>, <given-names>J. H.</given-names></string-name> &amp; <string-name><surname>Treue</surname>, <given-names>S.</given-names></string-name></person-group> <article-title>Feature-based attention in visual cortex</article-title>. <source>Trends Neurosci</source> <volume>29</volume>, <fpage>317</fpage>–<lpage>322</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.tins.2006.04.001</pub-id> (<year>2006</year>).</mixed-citation></ref>
<ref id="c48"><label>48</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Laamerad</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>L. D.</given-names></string-name> &amp; <string-name><surname>Pack</surname>, <given-names>C. C.</given-names></string-name></person-group> <article-title>Decision-related activity and movement selection in primate visual cortex</article-title>. <source>Sci Adv</source> <volume>10</volume>, <fpage>eadk7214</fpage>, doi:<pub-id pub-id-type="doi">10.1126/sciadv.adk7214</pub-id> (<year>2024</year>).</mixed-citation></ref>
<ref id="c49"><label>49</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Federer</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Ta’afua</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Merlin</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Hassanpour</surname>, <given-names>M. S.</given-names></string-name> &amp; <string-name><surname>Angelucci</surname>, <given-names>A.</given-names></string-name></person-group> <article-title>Stream-specific feedback inputs to the primate primary visual cortex</article-title>. <source>Nat Commun</source> <volume>12</volume>, <fpage>228</fpage>, doi:<pub-id pub-id-type="doi">10.1038/s41467-020-20505-5</pub-id> (<year>2021</year>).</mixed-citation></ref>
<ref id="c50"><label>50</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Briggs</surname>, <given-names>F.</given-names></string-name> &amp; <string-name><surname>Usrey</surname>, <given-names>W. M.</given-names></string-name></person-group> <article-title>Parallel processing in the corticogeniculate pathway of the macaque monkey</article-title>. <source>Neuron</source> <volume>62</volume>, <fpage>135</fpage>–<lpage>146</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2009.02.024</pub-id> (<year>2009</year>).</mixed-citation></ref>
<ref id="c51"><label>51</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Briggs</surname>, <given-names>F.</given-names></string-name></person-group> <article-title>Role of Feedback Connections in Central Visual Processing</article-title>. <source>Annu Rev Vis Sci</source> <volume>6</volume>, <fpage>313</fpage>–<lpage>334</lpage>, doi:<pub-id pub-id-type="doi">10.1146/annurev-vision-121219-081716</pub-id> (<year>2020</year>).</mixed-citation></ref>
<ref id="c52"><label>52</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Harris</surname>, <given-names>K. D.</given-names></string-name> &amp; <string-name><surname>Mrsic-Flogel</surname>, <given-names>T. D.</given-names></string-name></person-group> <article-title>Cortical connectivity and sensory coding</article-title>. <source>Nature</source> <volume>503</volume>, <fpage>51</fpage>–<lpage>58</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nature12654</pub-id> (<year>2013</year>).</mixed-citation></ref>
<ref id="c53"><label>53</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Moore</surname>, <given-names>T.</given-names></string-name> &amp; <string-name><surname>Armstrong</surname>, <given-names>K. M.</given-names></string-name></person-group> <article-title>Selective gating of visual signals by microstimulation of frontal cortex</article-title>. <source>Nature</source> <volume>421</volume>, <fpage>370</fpage>–<lpage>373</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nature01341</pub-id> (<year>2003</year>).</mixed-citation></ref>
<ref id="c54"><label>54</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gilbert</surname>, <given-names>C. D.</given-names></string-name> &amp; <string-name><surname>Li</surname>, <given-names>W.</given-names></string-name></person-group> <article-title>Top-down influences on visual processing</article-title>. <source>Nature Reviews Neuroscience</source> <volume>14</volume>, <fpage>350</fpage>–<lpage>363</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nrn3476</pub-id> (<year>2013</year>).</mixed-citation></ref>
<ref id="c55"><label>55</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McManus</surname>, <given-names>J. N.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>W.</given-names></string-name> &amp; <string-name><surname>Gilbert</surname>, <given-names>C. D.</given-names></string-name></person-group> <article-title>Adaptive shape processing in primary visual cortex</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source> <volume>108</volume>, <fpage>9739</fpage>–<lpage>9746</lpage>, doi:<pub-id pub-id-type="doi">10.1073/pnas.1105855108</pub-id> (<year>2011</year>).</mixed-citation></ref>
<ref id="c56"><label>56</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nienborg</surname>, <given-names>H.</given-names></string-name> &amp; <string-name><surname>Cumming</surname>, <given-names>B. G.</given-names></string-name></person-group> <article-title>Decision-related activity in sensory neurons reflects more than a neuron’s causal effect</article-title>. <source>Nature</source> <volume>459</volume>, <fpage>89</fpage>–<lpage>92</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nature07821</pub-id> (<year>2009</year>).</mixed-citation></ref>
<ref id="c57"><label>57</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bondy</surname>, <given-names>A. G.</given-names></string-name>, <string-name><surname>Haefner</surname>, <given-names>R. M.</given-names></string-name> &amp; <string-name><surname>Cumming</surname>, <given-names>B. G.</given-names></string-name></person-group> <article-title>Feedback determines the structure of correlated variability in primary visual cortex</article-title>. <source>Nat Neurosci</source> <volume>21</volume>, <fpage>598</fpage>–<lpage>606</lpage>, doi:<pub-id pub-id-type="doi">10.1038/s41593-018-0089-1</pub-id> (<year>2018</year>).</mixed-citation></ref>
<ref id="c58"><label>58</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wimmer</surname>, <given-names>K.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Sensory integration dynamics in a hierarchical network explains choice probabilities in cortical area MT</article-title>. <source>Nat Commun</source> <volume>6</volume>, <fpage>6177</fpage>, doi:<pub-id pub-id-type="doi">10.1038/ncomms7177</pub-id> (<year>2015</year>).</mixed-citation></ref>
<ref id="c59"><label>59</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Prat-Ortega</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Wimmer</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Roxin</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>de la Rocha</surname>, <given-names>J.</given-names></string-name></person-group> <article-title>Flexible categorization in perceptual decision making</article-title>. <source>Nat Commun</source> <volume>12</volume>, <fpage>1283</fpage>, doi:<pub-id pub-id-type="doi">10.1038/s41467-021-21501-z</pub-id> (<year>2021</year>).</mixed-citation></ref>
<ref id="c60"><label>60</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wong</surname>, <given-names>K. F.</given-names></string-name> &amp; <string-name><surname>Wang</surname>, <given-names>X. J.</given-names></string-name></person-group> <article-title>A recurrent network mechanism of time integration in perceptual decisions</article-title>. <source>J Neurosci</source> <volume>26</volume>, <fpage>1314</fpage>–<lpage>1328</lpage>, doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.3733-05.2006</pub-id> (<year>2006</year>).</mixed-citation></ref>
<ref id="c61"><label>61</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rao</surname>, <given-names>R. P.</given-names></string-name> &amp; <string-name><surname>Ballard</surname>, <given-names>D. H.</given-names></string-name></person-group> <article-title>Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects</article-title>. <source>Nat Neurosci</source> <volume>2</volume>, <fpage>79</fpage>–<lpage>87</lpage>, doi:<pub-id pub-id-type="doi">10.1038/4580</pub-id> (<year>1999</year>).</mixed-citation></ref>
<ref id="c62"><label>62</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Friston</surname>, <given-names>K.</given-names></string-name> &amp; <string-name><surname>Kiebel</surname>, <given-names>S.</given-names></string-name></person-group> <article-title>Predictive coding under the free-energy principle</article-title>. <source>Philos Trans R Soc Lond B Biol Sci</source> <volume>364</volume>, <fpage>1211</fpage>–<lpage>1221</lpage>, doi:<pub-id pub-id-type="doi">10.1098/rstb.2008.0300</pub-id> (<year>2009</year>).</mixed-citation></ref>
<ref id="c63"><label>63</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bastos</surname>, <given-names>A. M.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Canonical microcircuits for predictive coding</article-title>. <source>Neuron</source> <volume>76</volume>, <fpage>695</fpage>–<lpage>711</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2012.10.038</pub-id> (<year>2012</year>).</mixed-citation></ref>
<ref id="c64"><label>64</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shipp</surname>, <given-names>S.</given-names></string-name></person-group> <article-title>Neural Elements for Predictive Coding</article-title>. <source>Front Psychol</source> <volume>7</volume>, <fpage>1792</fpage>, doi:<pub-id pub-id-type="doi">10.3389/fpsyg.2016.01792</pub-id> (<year>2016</year>).</mixed-citation></ref>
<ref id="c65"><label>65</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kobak</surname>, <given-names>D.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Demixed principal component analysis of neural population data</article-title>. <source>eLife</source> <volume>5</volume>, doi:<pub-id pub-id-type="doi">10.7554/eLife.10989</pub-id> (<year>2016</year>).</mixed-citation></ref>
<ref id="c66"><label>66</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Chaoming Wang</surname>, <given-names>X. C.</given-names></string-name>, <string-name><given-names>Tianqiu</given-names> <surname>Zhang</surname></string-name>, <string-name><given-names>Si</given-names> <surname>Wu</surname></string-name></person-group>. <article-title>BrainPy: a flexible, integrative, efficient, and extensible framework towards general-purpose brain dynamics programming</article-title>. <source>bioRxiv</source>, doi:<pub-id pub-id-type="doi">10.1101/2022.10.28.514024</pub-id> (<year>2022</year>).</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.96402.2.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Bi</surname>
<given-names>Yanchao</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Peking University</institution>
</institution-wrap>
<city>Beijing</city>
<country>China</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>valuable</bold> study by Wu and Zhou combines neurophysiological recordings and computational modelling to address an interesting question regarding the sequence of events from sensing to action. Neurophysiological evidence remains <bold>incomplete</bold>: explicit mapping of saccade-related activity in the same neurons and a better understanding of the influence of the spatial configuration of stimulus and targets would be required to pinpoint whether such activity might contribute, even partially, to the observed results and interpretations. These results are of interest for neuroscientists investigating decision-making.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.96402.2.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>In this manuscript, the authors recorded activity in the posterior parietal cortex (PPC) of monkeys performing a perceptual decision-making task. The monkeys were first shown two choice dots of two different colors. Then, they saw a random dot motion stimulus. They had to learn to categorize the direction of motion as referring to either the right or left dot. However, the rule was based on the color of the dot and not its location. So, the red dot could either be to the right or left, but the rule itself remained the same. It is known from past work that PPC neurons would code the learned categorization. Here, the authors showed that the categorization signal depended on whether the executed saccade was in the same hemifield as the recorded PPC neuron or in the opposite one. That is, if a neuron categorized the two motion directions such that it responded stronger for one than the other, then this differential motion direction coding effect was amplified if the subsequent choice saccade was in the same hemifield. The authors then built a computational RNN to replicate the results and make further tests by simulated &quot;lesions&quot;.</p>
<p>Strengths:</p>
<p>Linking the results to RNN simulations and simulated lesions.</p>
<p>Weaknesses:</p>
<p>Potential interpretational issues due to a lack of explicit evidence on the sizes and locations of the response fields of the neurons. For example, is the contra/ipsi effect explained by the fact that in the contra condition, the response target and the saccade might have infringed on the outer edges of the response fields?</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.96402.2.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Wu</surname>
<given-names>Xuanyu</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Zhou</surname>
<given-names>Yang</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>The following is the authors’ response to the original reviews</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Public Review):</bold></p>
<p>Summary:</p>
<p>This valuable study by Wu and Zhou combined neurophysiological recordings and computational modelling to investigate the neural mechanisms that underpin the interaction between sensory evaluation and action selection. The neurophysiological results suggest non-linear modulation of decision-related LIP activity by action selection, but some further analysis would be helpful in order to understand whether these results can be generalised to LIP circuitry or might be dependent on specific spatial task configurations. The authors present solid computational evidence that this might be due to projections from choice target representations. These results are of interest for neuroscientists investigating decision-making.</p>
<p>Strengths:</p>
<p>Wu and Zhou combine awake behaving neurophysiology for a sophisticated, flexible visual-motion discrimination task and a recurrent network model to disentangle the contribution of sensory evaluation and action selection to LIP firing patterns. The correct saccade response direction for preferred motion direction choices is randomly interleaved between contralateral and ipsilateral response targets, which allows the dissociation of perceptual choice from saccade direction.</p>
<p>The neurophysiological recordings from area LIP indicate non-linear interaction between motion categorisation decisions and saccade choice direction.</p>
<p>The careful investigation of a recurrent network model suggests that feedback from choice target representations to an earlier sensory evaluation stage might be the source for this non-linear modulation and that it is an important circuit component for behavioural performance.</p>
<p>The paper presents a possible solution to a central controversy about the role of LIP in perceptual decision-making, but see below.</p>
<p>Weaknesses:</p>
<p>The paper presents a possible solution to a central controversy about the role of LIP in perceptual decision-making. However, the authors could be more clear and upfront about their interpretational framework and potential alternative interpretations.</p>
<p>Centrally, the authors' model and experimental data appears to test only that LIP carries out sensory evaluation in its RFs. The model explicitly parks the representation of choice targets outside the &quot;LIP&quot; module receiving sensory input. The feedback from this separate target representation provides then the non-linear modulation that matches the neurophysiology. However, they ignore the neurophysiological results that LIP neurons can also represent motor planning to a saccade target.</p>
<p>The neurophysiological results with a modulation of the direction tuning by choice direction (contralateral vs ipsilateral) are intriguing. However, the evaluation of the neurophysiological results are difficult, because some of the necessary information is missing to exclude alternative explanations. It would be good to see the actual distributions and sizes of the RF, which were determined based on visual responses not with a delayed saccade task. There might be for example a simple spatial configuration, for example, RF and preferred choice target in the same (contralateral) hemifield, for which there is an increase in firing. It is a shame that we do not see what these neurons would do if only a choice target would be put in the RF, as has been done in so many previous LIP experiments. The authors exclude also some spatial task configurations (vertical direction decisions), which makes it difficult to judge whether these data and models can be generalised. The whole section is difficult to follow, partly also because it appears to mix reporting results with interpretation (e.g. &quot;feedback&quot;).</p>
<p>The model and its investigation is very interesting and thorough, but given the neurophysiological literature on LIP, it is not clear that the target module would need to be in a separate brain area, but could be local circuitry within LIP between different neuron types.</p>
<p><bold>Reviewer #2 (Public Review):</bold></p>
<p>Summary:</p>
<p>In this manuscript, the authors recorded activity in the posterior parietal cortex (PPC) of monkeys performing a perceptual decision-making task. The monkeys were first shown two choice dots of two different colors. Then, they saw a random dot motion stimulus. They had to learn to categorize the direction of motion as referring to either the right or left dot. However, the rule was based on the color of the dot and not its location. So, the red dot could either be to the right or left, but the rule itself remained the same. It is known from past work that PPC neurons would code the learned categorization. Here, the authors showed that the categorization signal depended on whether the executed saccade was in the same hemifield as the recorded PPC neuron or in the opposite one. That is, if a neuron categorized the two motion directions such that it responded stronger for one than the other, then this differential motion direction coding effect was amplified if the subsequent choice saccade was in the same hemifield. The authors then built a computational RNN to replicate the results and make further tests by simulated &quot;lesions&quot;.</p>
<p>Strengths:</p>
<p>Linking the results to RNN simulations and simulated lesions.</p>
<p>Weaknesses:</p>
<p>Potential interpretational issues due to a lack of evidence on what happens at the time of the saccades.</p>
<p><bold>Recommendations for the authors:</bold></p>
<p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p>
<p>(1) The neurophysiological results with a modulation of the direction tuning by choice direction are intriguing. However, the evaluation of the neurophysiological results are difficult because some of the necessary information is missing to exclude alternative explanations.</p>
</disp-quote>
<p>We thank the reviewer for the helpful comments. We have addressed this point in detail in the following response.</p>
<disp-quote content-type="editor-comment">
<p>(a) Clearly state in the results how the response field &quot;RF&quot;, where the stimulus was placed, was mapped. The methods give as &quot;MGS&quot;&quot; (i.e., spatial selectivity during stimulus presentation and delay)&quot; task rather than the standard delayed saccade. And also &quot;while for those neurons which did not show a clear RF during the MGS task, we presented motion stimuli in the positions (always in the visual field contralateral to the recorded hemisphere) in which neurons exhibited the strongest response to the motion stimuli.&quot; All this sounds more like a sensory receptive field not an eye movement response filed&quot;. What was the exact task and criterion?</p>
</disp-quote>
<p>We agree with the reviewer that the original description of how we mapped the response fields (RFs) of LIP neurons lacked sufficient detail. In this study, we used the memory-guided saccade (MGS) task to map the RFs of all isolated LIP neurons. Both MGS and delayed saccade tasks are commonly used to map a neuron's response field in previous decision-making studies.</p>
<p>In the MGS task, monkeys initially fixate on the center of the screen. Subsequently, a dot randomly flashes at one of the eight possible locations surrounding the fixation dot with an eccentricity of 8 degree, requiring the monkeys to memorize the location of the flashed dot. After a delay of 1000 ms, the monkeys are instructed to saccade to the remembered location once the fixation dot disappears. The MGS task is a standard behavior task for mapping visual, memory, and motor RFs, particularly in brain regions involved in eye movement planning and control, such as LIP, FEF, and the superior colliculus.</p>
<p>We believe the reviewer's confusion may stem from whether we mapped the visual, memory, or motor RFs of LIP neurons in the current study, as these &quot;RFs&quot; are not always consistent across individual neurons. In our study, we primarily mapped the visual and memory RFs of each LIP neuron by analyzing their activity during both the target presentation and delay periods. To focus on sensory evaluation-related activity, we presented the visual motion stimulus within the visual-memory RF of each neuron. For neurons that did not show a significant visual-memory RF, we used a different approach: we tested the neurons with the main task by altering the spatial configuration of the task stimuli to identify the visual field that elicited the strongest response when the motion stimulus was presented within it. This approach was used to guide the placement of the stimulus during the recording sessions.</p>
<p>Following the reviewer’s suggestion, we have added the following clarification to the results section to better describe how we mapped the RF of LIP neurons:</p>
<p>‘We used the memory-guided saccade (MGS) task, which is commonly employed in LIP studies, to map the receptive fields (RFs) of all isolated LIP neurons. Specifically, we mapped both the visual and memory RFs of each neuron by analyzing their activity during the target presentation and delay periods of the MGS task (see Methods).’.</p>
<disp-quote content-type="editor-comment">
<p>(b) l.85 / l126: What do you mean by &quot;orthogonal to the axis of the neural RF&quot; - was the RF shape asymmetric, if so how did you determine this? OR do you mean the motion direction axis? Please explain.</p>
</disp-quote>
<p>We realized that the original description of this point may have been unclear and could lead to confusion. The axis of the neural RF refers to the line connecting the center of the RF (which coincides with the center of the motion stimulus) to the fixation dot. We have revised this sentence in the revised manuscript as follows:</p>
<p>‘To examine the neural activity related to the evaluation of stimulus motion, we presented the motion stimuli within the RF of each neuron, while positioning the saccade targets at locations orthogonal to the line connecting the center of the RF (which also marks the center of the motion stimulus) and the fixation dot.’</p>
<disp-quote content-type="editor-comment">
<p>(c) Behavioural task. Figure 1 - are these example session? Please state this clearly. Can you show the examples (psychometric function and reaction times) separated for trials where correct choice direction aligning with the motion preference (within 90 degrees) and those that did not?</p>
</disp-quote>
<p>Figure 1 shows the averaged behavioral results from all recording sessions. We have added this detail in the revised legend of Figure 1.</p>
<p>We are uncertain about the reviewer’s reference to the “correct choice direction aligning with the motion preference,” as the term “motion preference” is specific to the neuron response, which are different for different neurons recorded simultaneously using multichannel recording probe.</p>
<p>Nonetheless, following the reviewer’s suggestion, we grouped the trials in each recording session into two groups based on the relationship between the saccade direction and the preferred motion direction of the identified LIP neuron during one example single-channel recording. Both the RT and the performance accuracy during one example session were shown in the following figure.</p>
<fig id="sa2fig1">
<label>Author response image 1.</label>
<graphic mime-subtype="jpg" xlink:href="elife-96402-sa2-fig1.jpg" mimetype="image"/>
</fig>
<disp-quote content-type="editor-comment">
<p>Give also the performance averaged across all sites included in this study and range.</p>
<p>
If performance does differ for different configuration, please, show that the main modulatory effect does not align with this distinction.</p>
</disp-quote>
<p>To clarify this point, we have plotted performance accuracy and RTs for horizontal, oblique, and vertical target position configurations separately, which are shown for both monkeys in the following figures. We did not observe any systematic influences of task configurations on the monkeys' performance accuracy. While the RTs did differ across different configurations, we believe these differences are likely attributable to several factors, such as varying levels of familiarity introduced by our training process and the intrinsic RT difference between different saccade directions.</p>
<fig id="sa2fig2">
<label>Author response image 2.</label>
<graphic mime-subtype="jpg" xlink:href="elife-96402-sa2-fig2.jpg" mimetype="image"/>
</fig>
<disp-quote content-type="editor-comment">
<p>(d) Show the distribution of RF positions and the direction preferences for the recording sites included in the quantitative analysis of this study. (And if available, separately those excluded).</p>
</disp-quote>
<p>Following the reviewer’s suggestion, we have plotted the centers of the RFs for all neurons with identifiable RFs, categorizing them by their preferred motion directions. To determine each neuron’s RF, we analyzed the average firing rates from both the target presentation and delay periods during each trial of the memory-guided saccade (MGS) task. The RF centers of neurons with significant RFs were determined through a two-step process. First, we selected neurons that exhibited significant RFs in the MGS based on the following criteria: 1) there must be a significant activity difference between the eight target locations, and 2) the mean activity during the selected periods should be significantly greater than the baseline activity during the fixation period. Second, we fitted the activity data from the eight conditions to a Gaussian distribution, using the center of the fitted distribution as the RF center. A significant proportion of neurons from both monkeys that exhibited significant response to motion stimuli did not exhibited notable RFs based our current method. The following figures show the distributions of RFs and motion direction preference for all LIP neurons with identifiable RFs separately for each monkey. Since this is not the focus of the current study, we are not planning to include this result in the revised manuscript.</p>
<fig id="sa2fig3">
<label>Author response image 3.</label>
<graphic mime-subtype="jpg" xlink:href="elife-96402-sa2-fig3.jpg" mimetype="image"/>
</fig>
<disp-quote content-type="editor-comment">
<p>(e) Following on from d), was there a systematic relationship between RF position or direction preference and modulation by choice direction? For instance could the responses be simply explained by an increase in modulation for choices into the same (contralateral) hemifield as where the stimulus was placed?</p>
</disp-quote>
<p>The reviewer raised a good point. To address whether there was a systematic relationship between RF position or direction preference and modulation by choice direction, we calculated a modulation index for each neuron to quantify the influence of saccade direction on neuronal responses to motion stimuli. We then plotted the modulation index against the RF position for each LIP neuron, shown as following:</p>
<fig id="sa2fig4">
<label>Author response image 4.</label>
<graphic mime-subtype="jpg" xlink:href="elife-96402-sa2-fig4.jpg" mimetype="image"/>
</fig>
<p>As shown in the figures above, neurons with RFs farther from the horizontal meridian were more likely to exhibit stronger modulation by the saccade direction, while neurons with RFs closer to the horizontal meridian showed inconsistent and weaker modulation. This is because when the RFs was on the horizontal meridian, saccade directions were aligned with the vertical axis (with no contralateral or ipsilateral directions). This is consistent with the finding in Figure S3—no significant differences in direction selectivity between the CT and IT conditions in the data sessions where the saccade targets were aligned close to the vertical direction. Since fewer than half of the identified neurons showed clear receptive fields using our method, the figure above did not include all the neurons used in the analysis in the manuscript. Therefore, we chose not to include this figure in the revised manuscript.</p>
<p>Additionally, we quantified the relationship between the modulation index and direction preference for neurons in sessions where the monkeys’ saccades were aligned to either horizontal or oblique directions. As shown in the following figure, no systematic relationship was found between direction preference and modulation by the choice direction for LIP neurons at the population level.</p>
<fig id="sa2fig5">
<label>Author response image 5.</label>
<graphic mime-subtype="jpg" xlink:href="elife-96402-sa2-fig5.jpg" mimetype="image"/>
</fig>
<p>We have added this result as Figure S 2 in the revised manuscript.</p>
<p>Notably, the observed modulation of saccade direction on LIP neurons’ response to motion stimuli cannot be simply explained by saccade direction selectivity. We presented two more evidence to rule out such possibility in the original manuscript. First, the modulation effect we observed was nonlinear; specifically, the firing rate of neurons increased for the preferred motion direction but decreased for the non-preferred motion direction (Figure 2i and Figure S1A-D). This phenomenon is unlikely to be attributed to a linear gain modulation driven by saccade directions. Second, we plotted the averaged neural activity for contralateral and ipsilateral saccade directions separately, and found that LIP neurons showed similar levels of activity between two saccade directions (revised Figure 2L).</p>
<p>Additionally, we added a paragraph in the Methods section to describe the way we calculated modulation index as follows:</p>
<p>“We have calculated a modulation index for each neuron to reflect the influence of saccade direction on neuron’s response to visual stimuli. The modulation index is calculated as:</p>
<disp-formula id="sa2equ1">
<graphic mime-subtype="jpg" xlink:href="elife-96402-sa2-equ1.jpg" mimetype="image"/>
</disp-formula>
<disp-formula id="sa2equ2">
<graphic mime-subtype="jpg" xlink:href="elife-96402-sa2-equ2.jpg" mimetype="image"/>
</disp-formula>
<disp-formula id="sa2equ3">
<graphic mime-subtype="jpg" xlink:href="elife-96402-sa2-equ3.jpg" mimetype="image"/>
</disp-formula>
<p>where <inline-formula id="sa2equ4"><inline-graphic xlink:href="elife-96402-sa2-equ4.jpg" mimetype="image" mime-subtype="jpeg"/></inline-formula> represents the average firing rate from 50ms to 250ms after sample onset for all contralateral saccade trails with a neuron’s preferred moving direction of visual stimuli. The naming conventions are the same for <inline-formula id="sa2equ5"><inline-graphic xlink:href="elife-96402-sa2-equ5.jpg" mimetype="image" mime-subtype="jpeg"/></inline-formula>, <inline-formula id="sa2equ6"><inline-graphic xlink:href="elife-96402-sa2-equ6.jpg" mimetype="image" mime-subtype="jpeg"/></inline-formula>, and <inline-formula id="sa2equ7"><inline-graphic xlink:href="elife-96402-sa2-equ7.jpg" mimetype="image" mime-subtype="jpeg"/></inline-formula>. An MI value between 0 and 1 indicate higher modulation in contralateral saccade trials, and an MI value between -1 and 0 indicates higher modulation in ipsilateral saccade trials.”</p>
<disp-quote content-type="editor-comment">
<p>Please split Figures 2G,H,I J,K, by whether the RF was located contralaterally or ipsilaterally. If there are only a small number of ipsilateral RFs, please show these examples, perhaps in an appendix.</p>
</disp-quote>
<p>This is a reasonable suggestion; however, it is not applicable to our study. Among all the neurons included in our analysis, only one neuron from each monkey exhibited ipsilateral receptive fields (RFs). Therefore, we believe it may not be necessary to plot the result for this outlier.</p>
<disp-quote content-type="editor-comment">
<p>(f) Were the choice targets always equi-distant from the stimulus and at what distance was this? Please give quantitative details in methods.</p>
</disp-quote>
<p>The review was correct that the choice targets were always equidistant form the stimulus. The distance between the motion stimulus and the target was typically 12-15 degree. We have added the details in the revised Methods section as follows:</p>
<p>‘Therefore, the two saccade targets were equidistant from the stimulus, with the distance typically ranging from 12 to 15 degrees.</p>
<disp-quote content-type="editor-comment">
<p>(2) For Figure 3E, how do you explain that there is an up regulation of for contralateral choices before the stimulus onset, i.e. before the animal can make a decision? Is this difference larger for error trials?</p>
</disp-quote>
<p>This is a good question, which we have attempted to clarify in the revised manuscript. We believe that the observed upregulation in neural activity for contralateral choices may reflect the monkeys’ internal choice bias or expectation (choice between two motion directions) prior to stimulus presentation, which could influence their subsequent decisions. In Figure 3E, we calculated the r-choice to assess the correlation between the neuron’s direction selectivity and the monkeys’ decisions on motion stimuli, separately for contralateral and ipsilateral choice conditions. The increased r-decision during the pre-stimulus period indicates stronger neural activity for trials in which the monkeys later reported that the upcoming stimulus was in the preferred direction, and weaker activity for trials where the stimulus was judged to be in the non-preferred direction. This correlation was more pronounced for contralateral choices than for ipsilateral ones. It is important to note that while the monkeys cannot predict the upcoming stimulus direction with greater-than-chance accuracy, these results suggest that pre-stimulus neural activity in LIP is correlated with the monkeys’ eventual decision for that trial. Furthermore, LIP neural activity was more strongly correlated with the monkeys’ decisions in the contralateral choice condition compared to the ipsilateral one.</p>
<p>Additionally, we clarify that the r-decision was calculated using both correct and error trials. When comparing Figure 2J with Figure 2K, the correlation between neural activity and the monkeys’ upcoming decision during the pre-stimulus period was most prominent in low- and zero-coherence trials, where the monkeys either made more errors or based decisions on guesswork. We infer that the monkeys' confidence in these decisions was likely lower compared to high-coherence trials. Thus, the decision process appears to be influenced by pre-stimulus neural activity, particularly in low-coherence and zero-coherence trials.</p>
<p>Although it is unclear precisely what covert process this pre-stimulus activity reflects, similar patterns of choice-predictive pre-stimulus activity have been observed in LIP and other brain areas (Shadlen, M.N. and Newsome,T.W., 2001; Coe, B., at al. 2002; Baso, M.A. and Wurtz, R.H., 1998; Z. M. Williams at al. 2003). We have clarified this point in the revised manuscript, including a revision of the relevant sentence in the Results section for clarity, shown as follows:</p>
<p>“Furthermore, we used partial correlation analysis to examine decision- and stimulus-related components of DS (i.e., r-decision and r-stimulus, Figure 3E and 3F) using all four coherence levels. The decision-related component of LIP DS was significantly greater in the CT condition than in the IT condition (Figure 3E; nested ANOVA: P = 1.07e-6, F= 25.72), and this difference emerged even before motion stimulus onset. This suggests that the LIP DS was more closely correlated with monkeys’ decisions in the CT condition than in the IT condition. The upregulation in r-decision for contralateral choices may reflect the monkeys’ internal choice bias or expectation (choice between two motion directions) prior to stimulus presentation, which could influence their subsequent decisions more in the CT condition”</p>
<disp-quote content-type="editor-comment">
<p>(3) Figure 2K: what is the very large condition-independent contribution? It almost seems as most of what these neurons code for is neither saccade or motion related.</p>
</disp-quote>
<p>The condition-independent contribution is the time-dependent component that is unrelated to saccade, motion, or their interaction. Our findings are consistent with previous methodological studies, where this time-dependent component was shown to account for a significant portion of the variance in population activity (Kobak, D. et al., 2016)</p>
<disp-quote content-type="editor-comment">
<p>(4) Abstract:</p>
<p>a) &quot;We found that the PPC activity related to monkeys' abstract decisions about visual stimuli was nonlinearly modulated by monkeys' following saccade choices directing outside each neuron's response field.&quot;</p>
<p>This sentence is not clear/precise in two regards:</p>
<p>Should &quot;directing&quot; be &quot;directed&quot;?</p>
<p>Also, it is not just saccades directed outside the RF, but towards the contralateral hemifield.</p>
</disp-quote>
<p>We thank the reviewer for the suggestion. We agree that ‘directing’ should be ‘directed’ and revised it accordingly. However, we do not believe that ‘directed outside each neuron's response field’ should be replaced with “towards the contralateral hemifield”. There are two major reasons. First, the modulation effect was identified as the difference between contralateral and ipsilateral saccade directions. We cannot conclude that the modulation mainly happened in the contralateral saccade direction. Second, we used ‘directed outside each neuron's response field’ to emphasize that this modulation cannot be simply explained by saccade direction selectivity, whereas ‘towards the contralateral hemifield’ cannot fulfill this purpose.</p>
<disp-quote content-type="editor-comment">
<p>(b) &quot; Recurrent neural network modeling indicated that the feedback connections, matching the learned stimuli-response associations during the task, mediated such feedback modulation.&quot;</p>
<p>- should be &quot;that feedback connection .... might mediate&quot;. A model can only ever give a possible explanation.</p>
</disp-quote>
<p>Thanks for the help on the writing again! We have revised this sentence as following: “Recurrent neural network modeling indicated that the feedback connections, matching the learned stimuli-response associations during the task, might mediate such feedback modulation.”</p>
<disp-quote content-type="editor-comment">
<p>(c) &quot;thereby increasing the consistency of flexible decisions.&quot; I am not sure what is really meant by increasing the consistency of flexible decisions? More correct or more the same?</p>
</disp-quote>
<p>We apologize for the confusion. In the manuscript, &quot;decision consistency&quot; refers to the degree of agreement in the model's decisions under specific conditions. A higher decision consistency indicates that the model is more likely to produce the same choice when encountering encounters a stimulus in that condition. We have incorporated your suggestion and revise this sentence as “thereby increasing the reliability of flexible decisions”. We also clarified the definition of consistency in the main text as follows:</p>
<p>“These disrupted patterns of saccade DS observed in the target module following projection-specific inactivation aligned with the decreased decision consistency of RNNs, where decision consistency reflects the degree of agreement in the model's choices under specific task conditions. This suggests a diminished reliance on sensory input and an increased dependence on internal noise in the decision-making process.”.</p>
<disp-quote content-type="editor-comment">
<p>(5) Results: headers should be changed to reflect the actual results, not the interpretation:</p>
<p>&quot;Nonlinear feedback modulation of saccade choice on visual motion selectivity in LIP&quot;</p>
<p>&quot;Feedback modulation specifically impacted the decision-correlated activity in LIP&quot;</p>
<p>These first parts of the results describe neurophysiological modulations of LIP activity, the source cannot be known from the presented data alone. I thought that this feedback is suggested by the modelling results in the last part of the results. It is confusing to the reader that the titles already refer to the source of the modulation as &quot;feedback&quot;. The titles should more accurelty describe what is found, not pre-judge the interpretation.</p>
</disp-quote>
<p>We thank the reviewer for those valuable suggestions. We have updated the subtitles to: “Nonlinear modulation of saccade choice on visual motion selectivity in LIP” and “Decision-correlated but not stimulus-correlated activity was modulated in LIP.”</p>
<disp-quote content-type="editor-comment">
<p>(6) page 8, l366-380. Can you link the statements more directly to panels in Figure 6. For Figure 6H-K, it needs to be clarified that the headers for 6D-G also apply to H-K.</p>
</disp-quote>
<p>­We have added headers for Figure 6H-K in the revised version, and revised the corresponding results section as follows.</p>
<p>‘We further examined how the energy landscape in the 1-D subspace changed in relation to task difficulty (motion coherence). Consistent with prior findings, trials with lower decision consistency (trials using lower motion coherence) exhibited shallower attractor basins at the time of decision for all types of RNNs (Fig. 6H-K). However, both the depth and the positional separation of attractor basins in the network dynamics significantly decreased for all non-zero motion coherence levels after the ablation of all feedback connections (comparing Figure 6I with Figure 6H; P(depth) = 5.20e-25, F = 122.80; P(position) = 1.82e-27, F = 137.75; two-way ANOVA). Notably, this reduction in basin depth and separation was more pronounced in the specific group compared to the nonspecific groups after ablating the feedback connections (comparing Figure 6J with Figure 6K; P(depth) = 2.65e-13, F =57.35; P(position) = 3.73e-14, F = 61.79; two-way ANOVA). These results might underlie the computational mechanisms that explain the observed reduction in the decision consistency of RNNs following projection-specific inactivation: the shallower and closer attractor basins after ablating feedback connections resulted in less consistent decisions. This happened because the variability in neural activity made it more likely for population activity to stochastically shift out of the shallower basins and into nearby alternative ones.’</p>
<disp-quote content-type="editor-comment">
<p>(7) line 556-557: Please provide a reference or data for the assertion that nearby recording sites in LIP (100 microns apart) have similar RFs.</p>
</disp-quote>
<p>The reviewer raised an interesting question that we are unable to address in depth with the current data, as we lack information on the specific cortical location for each recording session. In the original manuscript, we suggested that nearby recording sites in LIP have similar receptive fields (RFs), based on both our own experience with LIP recordings and previous studies. Specifically, we observed that neurons recorded within a single penetration using a single-channel electrode typically exhibited similar RFs. Similarly, the majority of neurons recorded from the same multichannel linear probe within a single session also showed comparable RFs. Additionally, several studies (both electrophysiological and fMRI) have reported topographic organization of RFs in LIP (Gaurav H. Patel et al., 2010; S. Ben Hamed et al., 2001; Gene J. Blatt et al., 1990).</p>
<disp-quote content-type="editor-comment">
<p>(8) Line 568, Methods: a response criterion of a maximum firing rate of 2 spikes/s seems very low, especially for LIP. How do the results change if this lifted to something more realistic like 5 spikes/s or 10 spikes/s?</p>
</disp-quote>
<p>We chose this criterion to ensure we included as many neurons as possible in our analysis. To further clarify, we have plotted the distribution of maximum firing rates across all neurons. Based on our findings, relaxing this criterion is unlikely to affect the results, as the majority of neurons exhibit maximum firing rates well above 5 spikes/s, and many exceed 10 spikes/s. We hope this explanation addresses the concern.</p>
<fig id="sa2fig6">
<label>Author response image 6.</label>
<graphic mime-subtype="jpg" xlink:href="elife-96402-sa2-fig6.jpg" mimetype="image"/>
</fig>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p>
<p>In this manuscript, the authors recorded activity in the posterior parietal cortex (PPC) of monkeys performing a perceptual decision-making task. The monkeys were first shown two choice dots of two different colors. Then, they saw a random dot motion stimulus. They had to learn to categorize the direction of motion as referring to either the right or left dot. However, the rule was based on the color of the dot and not its location. So, the red dot could either be to the right or left, but the rule itself remained the same. It is known from past work that PPC neurons would code the learned categorization. Here, the authors showed that the categorization signal depended on whether the executed saccade was in the same hemifield as the recorded PPC neuron or in the opposite one. That is, if a neuron categorized the two motion directions such that it responded stronger for one than the other, then this differential motion direction coding effect was amplified if the subsequent choice saccade was in the same hemifield. The authors then built a computational RNN to replicate the results and make further tests by simulated &quot;lesions&quot;.</p>
<p>The data are generally interesting, and the manuscript is generally well written (but see some specific comments below on where I was confused). However, I'm still not sure about the conclusions. The way the experiment is setup, the &quot;contra&quot; saccade target is essentially in the same hemifield as the motion patch stimulus. Given that the RF's can be quite large, isn't it important to try to check whether the saccade itself contributed to the effects? i.e. if the RF is on the left side, and the &quot;contra&quot; saccade is to the left, then even if it is orthogonal to the location of the stimulus motion patch itself, couldn't the saccade still be part of a residual edge of the RF? This could potentially contribute to elevating the firing rate on the preferred motion direction trials. I think it would help to align the data on saccade onset to see what happens. It would also help to have fully mapped the neurons' movement fields by asking the monkeys to generate saccades to all screen locations in the monitor. The authors mention briefly that they used a memory-guided saccade task to map RF's, but it is also important to map with a visual target. And, in any case, it would be important to show the mapping results aligned on saccade onset.</p>
<p>Another comment is that the authors might want to mention this other recent related paper by the Pack group: <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2023.08.03.551852v2.full.pdf">https://www.biorxiv.org/content/10.1101/2023.08.03.551852v2.full.pdf</ext-link></p>
</disp-quote>
<p>We thank the reviewer for the comments and realized that we did not explain our results clearly in the original manuscript. We agree with the reviewer that saccade direction selectivity might be a confounding factor for the modulation of the saccade choice direction onto LIP neurons’ activity responded to visual motion stimuli. Because the RFs of LIP neurons might be large and the saccade target might be presented within the edge of the RFs. However, we believe that the observed modulation of saccade direction on LIP neurons’ response to motion stimuli cannot be simply explained by saccade direction selectivity. We presented several pieces of evidence to rule out such possibility. First, the modulation effect we observed was not linear; specifically, the firing rate of neurons increased for the preferred motion direction but decreased for the non-preferred motion direction (Figure 2i and Figure S1A-D). This phenomenon is unlikely to be attributed to a linear gain modulation driven by saccade directions. Second, we plotted the averaged neural activity for contralateral and ipsilateral saccade directions separately, aligned the activity to either motion stimulus onset or saccade onset, and found that LIP neurons showed similar levels of activity between the contralateral and ipsilateral directions (revised Figure 2L), which is not consistent with obvious saccade direction selectivity.</p>
<p>To better control for this confound, we have added figures plotting the mean neural activity aligned to saccade onset for both contralateral and ipsilateral saccades, which are now included in the revised main Figure 2. These figures are presented in the detailed response below. Additionally, we have revised the corresponding results section to clarify our points, as outlined below:</p>
<p>“Figure 2A-2F shows three example LIP neurons that exhibited significant motion coherence correlated DS. Surprisingly, LIP neurons showed greater DS in the CT condition than in the IT condition, even though the same motion stimuli were used in the same spatial location for both conditions. The averaged population activity showed this DS difference between CT and IT conditions for all four coherence levels (Figure 2G, 2H). During presentation of their preferred motion direction, LIP neurons showed significantly elevated activity in the CT relative to the IT at all coherence levels (Figure S1A, S1B, nested ANOVA: P(high) = 0.0326, F = 4.65; P(medium) = 0.0088, 142 F = 7.03; P(low) = 0.0076, F = 7.32; P(zero) = 0.0124, F = 6.4), and a trend toward lower activity to the nonpreferred direction for CT vs. IT (Figure S1C, S1D, nested ANOVA: P(high) = 0.0994, F = 2.75; P(medium) = 0.0649, F = 3.12; P(low) = 0.0311, F = 4.73; P(zero) = 0.0273, F = 4.96). Most of the LIP neurons (48 of 83) showed such opposing trends in activity modulation between the preferred and nonpreferred directions (Figure 2I). These results indicated a nonlinear modulation of saccade choice on motion DS in LIP, aligned precisely with the response property of each neuron. This is unlikely to be driven by a linear gain modulation of saccade direction selectivity. Receiver operating characteristic (ROC) analysis further confirmed significantly greater motion DS in the CT condition than in the IT condition (Figure 2J 148 and 2K; nested ANOVA: P(high) = 5.0e-4, F= 12.44; P(medium) = 9.53e-6, F = 20.91; P(low) = 9.33e-7, F 149 = 26.03; P(zero) = 2.56e-8, F= 34.3). Such DS differences were observed even before stimulus onset. Moreover, LIP neurons exhibited similar levels of mean activity between different saccade directions (CT vs. IT) before monkeys’ saccade choice (Figure 2L), further supporting that saccade direction selectivity did not significantly contribute to the observed modulation of LIP neurons’ responses to motion stimuli.</p>
<p>We also thank the reviewer for pointing out the missing of this relevant study, we have added the suggested refence in the revised discussion section as follows:</p>
<p>‘A recent study demonstrated that neurons in the middle temporal area responded more strongly to motion stimuli when monkeys saccaded toward their RFs in a standard decision task with a fixed mapping between motion stimuli and saccade directions. This modulation emerged through the training process and contributed causally to the monkeys' following saccade choices. Consistently, we found that the response of LIP neurons to motion stimuli was more strongly correlated with the monkeys' decisions in the CT condition (saccades toward RFs) than in the IT condition, in a more flexible decision task. Together, these results suggest that the modulation of action selection on sensory processing may be a general process in perceptual decision-making. However, the observed modulation of saccade direction on LIP neurons' responses to motion stimuli cannot be simply explained by saccade direction selectivity. Several lines of evidence argue against this possibility. First, the modulation effect was nonlinear; specifically, neuronal firing rates increased for preferred motion directions but decreased for non-preferred directions (Figure 2I and Figure S1). This pattern is unlikely to be driven by a linear gain modulation based on saccade directions. Second, we found that LIP neurons exhibited similar levels of activity in both the CT and IT conditions (Figure 2L), which is inconsistent with the presence of clear saccade direction selectivity.</p>
<disp-quote content-type="editor-comment">
<p>Some more specific comments are below:</p>
<p>- I had a bit of a hard time with the abstract. It does not appear to be crystal clear to me, and it is the first thing that I am reading after the title. For example, if there is a claim about both perceptual decision-making and later target selection, then I feel that the task should be explained a bit more clearly than saying &quot;flexible decision&quot; task. Also, &quot;..modulated by monkeys' following saccade choices directing outside each neuron's response field&quot; was hard to read. It needs to be rewritten. Maybe just say &quot;...modulated by the subsequent eye movement choices, even when these eye movement choices always directed the eyes away from the recorded neuron's response field&quot;. Also, I don't fully understand what &quot;selectivity-specific feedback&quot; means. Then, the concept of &quot;consistency&quot; in flexible decisions is brought up, again without much context. The above are examples of why I had a hard time with the abstract.</p>
</disp-quote>
<p>We realize that our original statement may have been unclear and potentially caused confusion for the readers. Following the reviewer’s suggestions, we have revised the abstract as follows:</p>
<p>‘Neural activity in the primate brain correlates with both sensory evaluation and action selection aspects of decision-making. However, the intricate interaction between these distinct neural processes and their impact on decision behaviors remains unexplored. Here, we examined the interplay of these decision processes in posterior parietal cortex (PPC) when monkeys performed a flexible decision task, in which they chose between two color targets based on a visual motion stimulus. We found that the PPC activity related to monkeys’ abstract decisions about visual stimuli was nonlinearly modulated by their subsequent saccade choices, which were directed outside each neuron’s response field. Recurrent neural network modeling indicated that the feedback connections, matching the learned stimuli-response associations during the task, might mediate such feedback modulation. Further analysis on network dynamics revealed that selectivity-specific feedback connectivity intensified the attractor basins of population activity underlying saccade choices, thereby increasing the reliability of flexible decisions. These results highlight an iterative computation between different decision processes, mediated primarily by precise feedback connectivity, contributing to the optimization of flexible decision-making.’</p>
<p>Specifically, selectivity-specific feedback refers to the feedback connections with positive or negative weights between selectivity-matched and selectivity-nonmatched unit pairs, respectively.</p>
<p>Regarding &quot;decision consistency,&quot; we define it as the degree to which the model’s decisions remain congruent under specific conditions. A higher level of decision consistency indicates that the model is more likely to produce the same choice each time it is presented with a stimulus under those conditions, in another words, decision reliability. We have revised the corresponding results section to make these concepts clearer.</p>
<disp-quote content-type="editor-comment">
<p>- Line 69: I'm not fully sure, but I think that some people might suggest that superior colliculus is also involved in the sensory aspect of the evaluation. But, I guess the sentence itself is correct as you write it. So, I don't think anyone should argue with it. However, if someone does argue with it, then they would flag the next sentence, since if the colliculus does both, then do the sensory and motor parts really employ distinct neural processes? Anyway, I think this is very minor.</p>
</disp-quote>
<p>This is an interesting point. We have also noticed a recent study that demonstrates that the superior colliculus is causally involved in the sensory aspect of decision-making, specifically in visual categorization. However, the study also distinguishes between neural activity related to categorical decisions and that related to saccade planning. This suggests that the sensory and motor aspects of decision-making likely involve distinct neural processing, even within the same brain region—potentially reflecting separate populations of neurons. Therefore, we stand by our statement in the ‘next sentence’.</p>
<disp-quote content-type="editor-comment">
<p>- Line 79-80: you might want to look at this work because I feel that it is relevant to cite here: <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2023.08.03.551852v2">https://www.biorxiv.org/content/10.1101/2023.08.03.551852v2</ext-link></p>
</disp-quote>
<p>We have discussed this reference in the revised discussion section of the manuscript, please refer to the above response.</p>
<disp-quote content-type="editor-comment">
<p>- For a result like that shown in Fig. 2, I feel that it is important to show RF mapping with a saccade task alone. i.e. for the same neurons, have a monkey make a delayed visually guided saccade task to all possible locations on the display, and demonstrate that there is no modulation by saccades to the targets. Otherwise, the result in Fig. 2 could reflect first an onset response by a motion, and then the saccade-related response that would happen anyway, even without the decision task. So, I feel that now, it is not entirely clear whether the result reflects this so-called feedback modulation, or whether simply planning the saccade to the target itself activates the neurons. With large RF's, this is a distinct possibility in my opinion.</p>
<p>- Line 174: this would also be predicted if the neuron's were responding based on the saccade target plan independent of the motion stimulus</p>
<p>- On a related note, I would recommend plotting all data also aligned on saccade onset. This can help establish what the cause of the effects described is</p>
</disp-quote>
<p>We understand the reviewer’s concern that the modulation might be related to saccade planning, and we acknowledge that the original manuscript might not adequately address this potential confound. Unfortunately, we did not map the LIP neurons' receptive fields (RFs) using a saccade-only task. However, as mentioned earlier, we believe that the modulation of LIP neurons' responses to motion stimuli based on saccade choice direction cannot be simply attributed to saccade direction selectivity. Several lines of evidence support this conclusion. First, the modulation we observed was nonlinear: the firing rate of neurons increased for the preferred motion direction but decreased for the non-preferred motion direction (Figure 2i and Figure S1A-D). This pattern is inconsistent with a simple linear gain modulation driven by saccade direction selectivity. Second, we directly compared LIP neuronal activity for contralateral and ipsilateral target conditions, and found no significant differences between the two. This suggests that saccade direction selectivity is unlikely to be the primary contributor to the observed modulation. In the revised figure, we added a plot (Figure 2L) that aligns neural activity to saccade onset, in addition to the original alignment to motion stimulus onset (Figure S1E). This new analysis further supports our interpretation.</p>
<fig id="sa2fig7">
<label>Author response image 7.</label>
<graphic mime-subtype="jpg" xlink:href="elife-96402-sa2-fig7.jpg" mimetype="image"/>
</fig>
<disp-quote content-type="editor-comment">
<p>- Even when reading the simulation results, I'm still not 100% sure I understand what is meant by this idea of &quot;consistency&quot; of flexible decision-making</p>
</disp-quote>
<p>We have addressed this issue in a previous comment and please refer to the response above.</p>
</body>
</sub-article>
</article>