<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">105531</article-id>
<article-id pub-id-type="doi">10.7554/eLife.105531</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.105531.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Auditory stimuli extend the temporal window of visual integration by modulating alpha-band oscillations</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Xu</surname>
<given-names>Mengting</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
<xref ref-type="aff" rid="a2">b</xref>
<xref ref-type="author-notes" rid="n1">†</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Han</surname>
<given-names>Biao</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
<xref ref-type="aff" rid="a2">b</xref>
<xref ref-type="author-notes" rid="n1">†</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Chen</surname>
<given-names>Qi</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
<xref ref-type="aff" rid="a2">b</xref>
<email>qi.chen27@gmail.com</email>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Shen</surname>
<given-names>Lu</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
<xref ref-type="aff" rid="a2">b</xref>
<email>lu.shen2013@gmail.com</email>
</contrib>
<aff id="a1"><label>a</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01kq0pv72</institution-id><institution>Center for Studies of Psychological Application, South China Normal University</institution></institution-wrap>, <city>Guangzhou</city>, <country country="CN">China</country></aff>
<aff id="a2"><label>b</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01kq0pv72</institution-id><institution>School of Psychology, South China Normal University</institution></institution-wrap>, <city>Guangzhou</city>, <country country="CN">China</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>van Gaal</surname>
<given-names>Simon</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Amsterdam</institution>
</institution-wrap>
<city>Amsterdam</city>
<country>Netherlands</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Luo</surname>
<given-names>Huan</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Peking University</institution>
</institution-wrap>
<city>Beijing</city>
<country>China</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="equal"><label>†</label><p>These authors contribute equally to the present work.</p></fn>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-04-17">
<day>17</day>
<month>04</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP105531</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-12-19">
<day>19</day>
<month>12</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-12-04">
<day>04</day>
<month>12</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.01.31.578121"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Xu et al</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Xu et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-105531-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>In multisensory environments, how inputs from different sensory modalities interact to shape perception are not fully understood. In this study, we investigated how auditory stimuli influence the temporal dynamics of visual processing using electroencephalography (EEG). Participants were presented with two consecutive visual flashes, either accompanied by an auditory beep or without, and were asked to report their perception of one or two flashes. Behaviorally, we found that the introduction of auditory input induced a longer temporal window for integration. Alpha frequency analysis further revealed that the presence of auditory stimuli led to poststimulus alpha frequency degradation, positively correlating with the prolonged temporal window, supporting the idea that alpha oscillations represent the temporal window of visual integration. Further exploration of prestimulus alpha oscillations revealed that auditory stimuli diminished the predictive role of prestimulus alpha frequency while enhancing the predictive role of prestimulus alpha phase in shaping perceptual outcomes. A follow-up transcranial alternating current stimulation (tACS) experiment confirmed that alpha oscillations have a causal role in modulating visual perception in the absence of auditory stimuli but not when auditory stimuli were present. To probe the underlying mechanisms, we developed a computational model based on the phase-resetting hypothesis and perceptual cycle theory, which successfully replicated the core findings. These results reveal that auditory input extends the temporal window of visual integration by resetting alpha oscillations in the visual cortex, leading to alpha frequency reduction and an altered perception of visual events. This study advances the understanding of cross-modal interactions and highlights the dynamic, adaptive processes underlying sensory integration.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>Multisensory perception</kwd>
<kwd>fusion illusion</kwd>
<kwd>alpha oscillations</kwd>
<kwd>phase reset</kwd>
</kwd-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>A new transcranial alternating current stimulation (tACS) experiment was added to provide causal evidence for the role of alpha oscillations in modulating visual perception.
The discussion was reframed to offer a more comprehensive perspective on phase resetting, emphasizing its role in cross-modal interactions and dynamic adaptation of sensory processing.
Supplemental files were updated.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>In our daily lives, we are constantly bombarded with information from various senses. Our brains face the challenge of organizing and integrating these signals into coherent perceptual experiences, and this becomes more complex due to the interactions between different sensory modalities (<xref ref-type="bibr" rid="c14">Cooke et al., 2019</xref>; <xref ref-type="bibr" rid="c53">Shams et al., 2002</xref>; <xref ref-type="bibr" rid="c65">Watkins et al., 2006</xref>). Numerous studies consistently highlight the noteworthy influence of sound signals on visual perception, particularly in the temporal domain. For example, the introduction of sound has been observed to influence the perceived duration of visual stimuli or rate of visual events (<xref ref-type="bibr" rid="c17">Gebhard and Mowbray, 1959</xref>; <xref ref-type="bibr" rid="c56">Shipley, 1964</xref>; <xref ref-type="bibr" rid="c63">Walker and Scott, 1981</xref>; <xref ref-type="bibr" rid="c66">Welch et al., 1986</xref>). The temporal relationship between visual and auditory stimuli plays a crucial role, either enhancing or degrading visual temporal resolution (<xref ref-type="bibr" rid="c16">Fendrich and Corballis, 2001</xref>; <xref ref-type="bibr" rid="c55">Shimojo et al., 2001</xref>). These findings intriguingly suggest that auditory stimuli may exert a profound influence on the temporal processing of the visual system. However, the neural mechanisms that underlie this cross-modal influence remain elusive.</p>
<p>Temporal windows, a fundamental attribute of the visual system, refer to time intervals during which discrete stimuli interact to influence perception (Samaha and Romei, 2023). A simple example is the fusion of two brief stimuli into a unified percept when they occur within a certain time range. The rhythmic patterns of alpha oscillations, serve as a potential mechanism for defining this temporal window (<xref ref-type="bibr" rid="c3">Baumgarten et al., 2015</xref>; <xref ref-type="bibr" rid="c10">Cecere et al., 2015</xref>; <xref ref-type="bibr" rid="c49">Samaha and Postle, 2015</xref>). This notion gains support from research demonstrating that the phase and frequency of alpha oscillations shape the temporal integration process. Alpha oscillation phase influences visual signal detectability at the perceptual threshold (<xref ref-type="bibr" rid="c8">Busch and VanRullen, 2010</xref>; <xref ref-type="bibr" rid="c7">Busch et al., 2009</xref>; <xref ref-type="bibr" rid="c35">Mathewson et al., 2009</xref>), the perceived timing of stimuli (<xref ref-type="bibr" rid="c11">Chakravarthi and Vanrullen, 2012</xref>; <xref ref-type="bibr" rid="c39">Milton and Pleydell-Pearce, 2016</xref>), and the occurrence of perceptual illusions (<xref ref-type="bibr" rid="c20">Gulbinaite et al., 2017</xref>; <xref ref-type="bibr" rid="c44">Rohe et al., 2019</xref>; <xref ref-type="bibr" rid="c46">Ronconi et al., 2017</xref>). Moreover, emerging evidence highlights a correlation between the frequency of alpha oscillations and temporal integration (<xref ref-type="bibr" rid="c10">Cecere et al., 2015</xref>; <xref ref-type="bibr" rid="c14">Cooke et al., 2019</xref>; <xref ref-type="bibr" rid="c21">Han et al., 2023</xref>; <xref ref-type="bibr" rid="c49">Samaha and Postle, 2015</xref>; <xref ref-type="bibr" rid="c54">Shen et al., 2019</xref>). Notably, this frequency not only correlates with but also causally influences observers’ tendency to integrate signals within (<xref ref-type="bibr" rid="c21">Han et al., 2023</xref>; <xref ref-type="bibr" rid="c49">Samaha and Postle, 2015</xref>; <xref ref-type="bibr" rid="c54">Shen et al., 2019</xref>) and across different sensory modalities (<xref ref-type="bibr" rid="c10">Cecere et al., 2015</xref>; <xref ref-type="bibr" rid="c14">Cooke et al., 2019</xref>; <xref ref-type="bibr" rid="c26">Keil and Senkowski, 2017</xref>). However, it is important to note that some studies have failed to find a significant correlation between alpha oscillations and temporal parsing of visual signals (<xref ref-type="bibr" rid="c6">Buergers and Noppeney, 2022</xref>; <xref ref-type="bibr" rid="c18">Gray and Emmanouil, 2020</xref>; <xref ref-type="bibr" rid="c47">Ruzzoli et al., 2019</xref>). A recent study provide evidence that pre-stimulus alpha frequency does not substantially influence the temporal segmentation of visual signals in visual or audiovisual perception(<xref ref-type="bibr" rid="c6">Buergers and Noppeney, 2022</xref>). This highlights the need for further research to confirm the relationship between alpha oscillations and the temporal window within and across the senses.</p>
<p>In the context of audiovisual processing, the presentation of two visual flashes with an auditory stimulus leads to an increased likelihood of perceiving them as a single flash, inducing fusion illusions (<xref ref-type="bibr" rid="c1">Andersen et al., 2004</xref>). This observation suggests that cross-modal stimulation has the potential to impact the temporal window of visual processing. Neural studies have revealed significant activation changes in the primary visual cortex (V1) when visual stimuli are presented concurrently with incongruent auditory stimuli, which are closely linked to reports of visual illusions (<xref ref-type="bibr" rid="c65">Watkins et al., 2006</xref>). Furthermore, research on animals and humans has demonstrated that auditory stimuli can modulate early visual cortex processing through phase-reset mechanisms (<xref ref-type="bibr" rid="c24">Kayser et al., 2008</xref>; <xref ref-type="bibr" rid="c25">Keil et al., 2014</xref>; <xref ref-type="bibr" rid="c28">Lakatos et al., 2007</xref>; <xref ref-type="bibr" rid="c37">Mercier et al., 2013</xref>), particularly in the alpha frequency range. Building upon these findings, one potential hypothesis is that cross-modal sound stimuli may influence the temporal window of visual integration by exerting an influence on alpha oscillations.</p>
<p>To test this hypothesis, we conducted an experiment where observers performed a visual flash discrimination task while their EEG data was recorded. We analyzed the frequency and phase of alpha oscillations for two experimental conditions: one with only two visual flashes (F2) and the other with two visual flashes accompanied by an auditory beep (F2B1) (<xref rid="fig1" ref-type="fig">Figures 1A</xref> and <xref rid="fig1" ref-type="fig">B</xref>). Upon comparing different conditions, our investigation revealed that the introduction of auditory stimuli effectively prolonged the temporal window of integration by reducing the instantaneous frequency of alpha oscillations. Notably, in the F2 condition, the instantaneous frequency of alpha oscillations plays a predictive role in perceptual outcomes, while in the F2B1 condition, this predictive role is absent. Conversely, the phase of alpha oscillations exhibits a predictive role in perceptual outcomes in the F2B1 condition, but not in the F2 condition. Further transcranial alternating current stimulation (tACS) experiment confirmed the casual role of alpha frequency in modulating perception specifically in F2 condition. To elucidate the underlying mechanisms, we introduced a sound-induced phase-resetting model. Our simulation results indicate that the introduction of auditory input resets the phase of alpha oscillations, subsequently extending the temporal window through a reduction in alpha frequency. This modification significantly influences the predictive roles of both phase and frequency.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Paradigm and behavioral results.</title><p>(A) Schematic illustration of the F2 and F2B1 conditions. (B) Illustration of one trial sequence. On each trial, the first visual stimulus presented below the fixation, either accompanied by an auditory beep or without it (the sound icon in the figure is not part of the actual experiment). After a variable ISI, the second visual stimulus was presented. Participants were required to report whether they perceived one or two flashes. Participants were more likely to report perceiving one flash with a short ISI (30 ms) and two flashes with a long ISI (100 ms). Perception became bistable during trials where the ISI matched fusion threshold, individually determined for each participant, resulting in approximately equal proportions of 1-flash and 2-flash reports. (C) Psychometric curves represent the best fit of the average probability of perceiving the two flashes plotted as a function of different ISIs in the F2 and F2B1 conditions. Error bars represent ±1 SEM. (D) Fusion threshold ISIs derived from the psychophysical procedure for each condition. (E) Percentage of 1-flash and 2-flash percepts for the bistable trials in the F2 and F2B1 conditions of the main EEG experiment. ***<italic>p</italic> &lt; 0.001.</p></caption>
<graphic xlink:href="578121v2_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Psychophysical Results</title>
<p>Prior to the main EEG experiment, participants underwent a psychophysical pretest to determine the fusion threshold for each condition. Psychometric curves were fitted to the proportion of perceiving two flash percepts at each of the eight ISIs for the F2 and F2B1 conditions, respectively (<xref rid="fig1" ref-type="fig">Figure 1C</xref>). The fusion threshold, representing the ISI at which equal proportions of 1-flash and 2-flash trials were reported, was derived for each condition and participant (Figure S1). This threshold provides an estimate of the temporal window for integration within the visual modality (F2) and across the audiovisual modality (F2B1). A two-tailed paired t-test revealed that the fusion threshold was significantly shorter (<italic>t</italic> <sub>(33)</sub> = 5.23, <italic>p</italic> = 9.00×10<sup>−6</sup>; <xref rid="fig1" ref-type="fig">Figure 1D</xref>) in the F2 (52.68 ± 12.25 ms, mean ± SD) than in the F2B1 condition (65.18 ± 13.17 ms, mean ± SD), indicating a significant shift in the fusion threshold between the two conditions. Further analysis revealed that the auditory stimulus affected participants’ choices differently across ISIs (<italic>F</italic> <sub>(7, 231)</sub> = 11.12, <italic>p</italic> = 4.11 × 10<sup>−12</sup>; Figure S2), with the strongest effect at intermediate ISIs, where the stimulus was most ambiguous. This suggests that the auditory input actively shapes perception rather than simply response bias.</p>
<p>In the main EEG experiment, each condition comprised three types of trials: the explicit 1-flash trials with a short ISI (30 ms), the explicit 2-flash trials with a long ISI (100 ms), and the bistable trials with the fusion threshold ISI obtained from the psychophysical procedure. Participants exhibited high accuracy rates in the explicit trials for both the F2 and F2B1 conditions (F2 with short ISI: 89.16 ± 11.81%; F2 with long ISI: 95.96 ± 4.31%; F2B1 with short ISI: 95.48 ± 5.86%; F2B1 with long ISI: 89.52 ± 14.91%, mean ± SD), indicating their ability to accurately discriminate between the explicit percepts in both conditions. Regarding the bistable trials with the threshold ISI, the proportions of 1-flash and 2-flash percepts were comparable in both the F2 (<italic>t</italic> <sub>(33)</sub> = 1.85, <italic>p</italic> = 0.07, two-tailed) and F2B1 conditions (<italic>t</italic> (33) = 1.92, <italic>p</italic> = 0.06, two-tailed; <xref rid="fig1" ref-type="fig">Figure 1E</xref>), suggesting that participants experienced a similar level of perceptual ambiguity in the two conditions.</p>
</sec>
<sec id="s2b">
<title>Auditory input extended the temporal window for visual integration by decreasing occipital alpha frequency</title>
<p>The EEG data showed a clear peak in the alpha-band power and a posterior scalp distribution of alpha power during the peri-stimulus period (−600 to 600 ms relative to the first stimulus onset) for all the participants in both F2 and F2B1 conditions (<xref rid="fig2" ref-type="fig">Figure 2A</xref>). These results guided further analysis by confirming the frequency of interest to 8-13 Hz and the region of interest to the posterior electrodes (Oz, O1, O2, POz, PO1, PO2, PO3, PO4, PO5, PO6).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>The relationship between decreased post-stimulus IAFs and perceptual precision.</title><p>(A) <italic>Upper panel</italic>: the power spectrum obtained from all bistable trials (from −600 to 600 ms relative to the onset of the first flash) in F2 and F2B1 conditions, collapsed across all electrodes in all participants, clearly revealed a distinct peak in the alpha band. The gray shading represents ±1 within-subjects SEM. The light gray rectangle represents the chosen alpha frequency band (8-13Hz). <italic>Lower panel</italic>: Topography of absolute alpha-band power (8-13Hz) recorded from 64-channel EEG, averaged over F2 and F2B1 conditions, showed a clear occipital scalp distribution. Black dots indicated the chosen posterior channels. (B) IAFs for F2 and F2B1 bistable trials averaged over the occipital channels. The within-subject findings of the IAFs revealed that the post-stimulus alpha frequency of F2B1 decreased more than that of F2. (C) The between-subject correlation was conducted to examine the relationship between the post-stimulus IAFs difference of F2B1 and F2 in the main EEG experiment and the threshold ISIs difference of F2B1 and F2 in the psychophysical pretest. 95% confidence intervals around the linear fit line are shown by the dashed line. (D) The result is identical to (B), but for explicit short ISI trials. (E) The result is identical to (B), but for explicit long ISI trials.</p></caption>
<graphic xlink:href="578121v2_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Building upon our behavioral observations, we noted a significant extension in the temporal window for visual integration when auditory input was introduced. If we assume that alpha frequency serves as an indicator of the temporal window within the visual cortex, it is plausible to hypothesize that alpha frequency in the F2B1 condition might decrease compared to the F2 condition. To test this hypothesis, we performed a direct comparison of poststimulus instantaneous alpha frequency (IAF) between the F2 and F2B1 conditions by collapsing trials across 1-flash and 2-flash precepts while ensuring an equal number of trials in each condition (See Materials and Methods). The instantaneous frequency was calculated as the temporal derivative of the instantaneous phase, which extracted the alpha-band phase angle time series over the occipital electrodes via the Hilbert transform. Consistent with our hypothesis, in the bistable trials, we found that the frequency of F2B1 was significantly lower than that of F2 after the presentation of auditory stimulus (0-280 ms relative to the first stimulus onset, <italic>p</italic> = 1.00×10<sup>−3</sup>, cluster-based correction, two-tailed; <xref rid="fig2" ref-type="fig">Figure 2B</xref>).</p>
<p>Subsequently, we conducted a between-subject correlation analysis between the poststimulus IAF differences in the F2B1 and F2 conditions and the fusion threshold ISI differences between these conditions, as measured through psychophysics. Interestingly, we observed a significant correlation between the decrease in alpha frequency and the increase in fusion threshold in the F2B1 condition relative to the F2 condition (Pearson correlation: <italic>r</italic> = 0.45, <italic>p</italic> = 7.55 × 10<sup>−3</sup>). Specifically, the greater the reduction in alpha frequency induced by the auditory stimulus, the longer the fusion threshold in the F2B1 condition compared to the F2 condition (<xref rid="fig2" ref-type="fig">Figure 2C</xref>). To ensure the robustness of this correlation, we performed a permutation analysis by randomly shuffling the pairing of post-stimulus IAF differences and fusion threshold ISI differences across participants. This procedure, repeated 1,000 times, generated a null distribution of correlation coefficients expected by chance. The observed correlation coefficient remained significant (Figure S3; <italic>p</italic> = 2.00 × 10<sup>−3</sup>), further validating the association. These findings suggest that the concurrent presentation of auditory input may lead to a decrease in alpha frequency, thereby extending the temporal window of visual integration.</p>
<p>Given the difference in fusion thresholds between the F2 and F2B1 conditions, which could potentially contribute to the observed poststimulus differences between the two conditions, we conducted an additional analysis to address this concern. Specifically, we examined the IAF difference between the two conditions in trials with explicit short ISI and long ISI, respectively. In the explicit trials, ISIs were consistent across participants and conditions, with the only distinguishing factor between F2B1 and F2 being the presence of auditory input in F2B1. Notably, our results revealed that the alpha frequency was consistently lower in F2B1 compared to F2 for both explicit conditions (explicit short ISI: 0-180 ms relative to the first stimulus onset, <italic>p</italic> = 0.02, cluster-based correction; explicit long ISI: 0-370 ms relative to the first stimulus onset, <italic>p</italic> = 1.00×10<sup>−3</sup>, cluster-based correction; <xref rid="fig2" ref-type="fig">Figures 2D</xref> and <xref rid="fig2" ref-type="fig">E</xref>). This control analysis robustly confirmed that the decrease in alpha frequency is indeed attributable to the auditory input, regardless of the variations in stimulus ISI.</p>
</sec>
<sec id="s2c">
<title>Auditory input disrupted the predictive role of prestimulus alpha frequency</title>
<p>Extensive research has demonstrated the significant impact of prestimulus alpha frequency on the outcomes of visual integration. In our study, we sought to investigate whether prestimulus alpha frequency exerted a similar influence on the perceptual outcomes in both the F2 and F2B1 conditions. First, we conducted a within-subject comparison of the instantaneous alpha frequency (IAF) variations between different perceptual outcomes of bistable trials in the F2 and F2B1 conditions, respectively. Our results demonstrated that in the F2 condition, the IAF was significantly higher in the 2-flash trials compared to 1-flash trials (<xref rid="fig3" ref-type="fig">Figure 3A</xref>), both in the pre-stimulus period (from −330 to −30 ms relative to the first stimulus onset, <italic>p</italic> = 0.02, cluster-based correction, two-tailed) and post-stimulus period (from 130 to 540 ms, <italic>p</italic> = 4.00×10<sup>−3</sup>, cluster-based correction, two-tailed). These findings are in line with previous research, indicating that slower alpha frequencies are associated with a wider temporal window, thereby increasing the likelihood that two visual stimuli fall within the same window and are integrated as one percept (<xref ref-type="bibr" rid="c49">Samaha and Postle, 2015</xref>). However, in the F2B1 condition, no significant difference in IAF between different perceptual outcomes was observed (<xref rid="fig3" ref-type="fig">Figure 3B</xref>).</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Relationship between the instantaneous alpha frequency (IAF) and perception.</title><p>(A) IAFs over time were averaged over posterior channels (shown in <xref rid="fig2" ref-type="fig">Fig 2a</xref>) for different perceptual outcomes in the F2 condition. Shaded areas show ±1 within-subjects SEM. Significant time epochs are indicated with black lines (<italic>p</italic> &lt; 0.05; permutation test; cluster corrected). (B) Similar to a, but for F2B1 condition. (C) IAFs during the time of interest (−600 to 600 ms) were averaged separately for F2 and F2B1 conditions with different perceptual outcomes. The error bars represent ±1 SEM. ∗∗<italic>p</italic> &lt; 0.01. ∗∗∗<italic>p</italic> &lt; 0.001.</p></caption>
<graphic xlink:href="578121v2_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>To further compare the different patterns in perception between the two conditions, we averaged the IAF over the posterior electrodes and the entire time of interest (−600 to 600 ms). These mean IAFs were then subjected to a 2 (percepts: 1-flash vs. 2-flash) × 2 (conditions: F2 vs. F2B1) repeated-measures ANOVA. The results revealed a significant main effect of percepts, <italic>F</italic> <sub>(1,33)</sub> = 4.29, <italic>p</italic> = 0.046, indicating that the IAF was significantly higher in the 2-flash percepts compared to the 1-flash percepts. Additionally, there was a marginally significant main effect of conditions, <italic>F</italic> <sub>(1,33)</sub> = 3.40, <italic>p</italic> = 0.07, suggesting a trend towards different IAFs between the F2 and F2B1 conditions. More importantly, the interaction effect was significant, <italic>F</italic> <sub>(1,33)</sub> =9.86, <italic>p</italic> = 3.55×10<sup>−3</sup>. Specifically, in the F2 condition, the frequency of 2-flash percepts was significantly higher than 1-flash percepts (<italic>t</italic> (33) = 5.23, <italic>p</italic> = 3.87×10-3), while in the F2B1 condition, no significant difference between the two percepts was observed (<italic>t</italic> <sub>(33)</sub> = −0.49, <italic>p</italic> = 0.63; <xref rid="fig3" ref-type="fig">Figure 3C</xref>). These results indicate statistically that the influence of IAF on perceptual outcomes differs between the two conditions.</p>
<p>Moreover, to address any potential bias in the calculation of instantaneous alpha frequency (IAF) resulting from the 1/f slope effect, we applied a demodulation process with attenuated 1/f characteristics on the time-domain signal (<xref ref-type="bibr" rid="c48">Samaha and Cohen, 2022</xref>) and repeated the IAF analysis. The observed pattern of results remained consistent (Figure S4). In addition, to rule out the possibility that the instantaneous alpha frequency modulation is attributed to the oscillatory power, we performed a statistical test on the instantaneous alpha power within the time and channels of interest between the two percepts for F2 and F2B1 conditions, respectively. No significant differences between the two perceptual outcomes were found in either the F2 or F2B1 conditions (Figure S5).</p>
</sec>
<sec id="s2d">
<title>Auditory input enhanced the predictive role of prestimulus alpha phase</title>
<p>The spontaneous alpha-band phase has previously been shown to mirror the cyclic alterations in cortical excitability, thereby supporting the concept of perceptual cycles. In light of this, we extended our investigation to explore the influence of prestimulus alpha phase on perceptual outcomes by computing the phase opposition sum (POS), a measure that quantifies the difference in phase distributions between two sets of trials (<xref ref-type="bibr" rid="c59">VanRullen, 2016a</xref>). If the phase of spontaneous alpha oscillations prior to the first flash is predictive of the subsequent perceptual outcome, we should observe a strong phase clustering around a certain phase angle for 1-flash trials and distinct phase clustering around another phase angle for 2-flash trials, resulting in a significant value of POS.</p>
<p>In the F2B1 condition, we indeed observed a significant phase opposition between 1-flash and 2-flash trials, spanning from −460 to 0 ms relative to the first flash onset, within the frequency range of 8 to 13 Hz (<italic>p</italic> = 3.03×10<sup>−3</sup>, cluster-based correction; <xref rid="fig4" ref-type="fig">Figure 4A</xref>, <italic>upper panel</italic>). However, no significant phase effect manifested in the F2 condition (<xref rid="fig4" ref-type="fig">Figure 4A</xref>, <italic>lower panel</italic>). For demonstration purpose, to further visualize the mean phase angle differences across participants, phases at the time-frequency point with maximal POS effect (at 10.28 Hz; −300 ms) at electrode Oz were pooled into 16 bins. In line with the POS analysis, the directions of the preferred phase for 1-flash and 2-flash percepts exhibited significant differences across participants in the F2B1 condition (<italic>F</italic> <sub>(1,66)</sub> = 15.31, <italic>p</italic> = 2.18×10<sup>−4</sup>, <xref rid="fig4" ref-type="fig">Figure 4B</xref>, <italic>upper panel</italic>). Conversely, no significant phase difference between the two percepts was detected in the F2 condition (<italic>F</italic> <sub>(1,66)</sub> = 3.30, <italic>p</italic> = 0.07, <xref rid="fig4" ref-type="fig">Figure 4B</xref>, <italic>lower panel</italic>).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Prestimulus alpha phase difference between 1-flash and 2-flash trials.</title><p>(A) Time-frequency representation of p values (for occipital regions), computed as a proportion of surrogate phase opposition values (distribution of phase opposition values expected under null hypothesis) that exceeded empirically observed phase opposition values for the F2B1 (<italic>upper panel</italic>) and F2 conditions (<italic>lower panel</italic>), respectively. The outlined area indicates significant effects corrected for multiple comparisons using cluster-based correction. The white square indicates the time-frequency point with strongest POS effect in the F2B1 condition. (B) The circular histograms of mean phase angles (at 10.28 Hz; −300 ms) at the occipital channel Oz during 1-flash and 2-flash trials across participants for the F2B1 (<italic>upper panel</italic>) and F2 conditions (<italic>lower panel</italic>), respectively. The horizontal black line indicates the number of participants with the mean phase angle in each bin. The direction of the arrows corresponds to the mean phase angle across participants, and the length of the arrows indicates the extent of phases clustering around the mean. (C) Statistical analysis of the differential phase effects between F2B1 and F2 condition within the entire prestimulus period (−600∼0ms) and alpha-band range (8∼13 Hz). The red line indicates the observed mean POS difference between F2B1 and F2 within this cluster. The gray bars represent the surrogate distribution of mean POS difference expected by chance for this cluster, estimated from shuffled data. Dashed black line indicates the 95<sup>th</sup> percentile value of the surrogate distribution. (D) The relationship between the proportion of two-flash percepts and pre-stimulus phase (at 10.28 Hz; −300 ms) at the occipital channel Oz. Single trials were categorized into 9 phase bins, centered on the preferred phase bin with the highest proportion of 2-flash percepts for each participant (the central bin is removed due to artificial shifting). The error bars represent ±1 SEM.</p></caption>
<graphic xlink:href="578121v2_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Furthermore, we evaluated whether the observed difference in prestimulus POS patterns between F2B1 and F2 was statistically significant using a permutation procedure. Specifically, we computed the mean POS difference between F2B1 and F2 in the frequency range of 8 to 13 Hz and time range from −600 to 0 ms relative to the first flash onset. Subsequently, we compared this mean POS difference value against a distribution of POS difference values expected by chance (see Materials and Methods; <xref rid="fig4" ref-type="fig">Figure 4C</xref>). This analysis confirmed a statistically significant distinction in POS patterns between F2B1 and F2 conditions, <italic>p</italic> = 4.60×10<sup>−3</sup>, indicating a prevailing phase modulation effect on perceptual outcomes in the F2B1 condition.</p>
<p>The relationship between the perceptual performance and prestimulus phase was further assessed by categorizing single trials according to the phase at the optimal time-frequency point (−300 ms, 10.28 Hz, Oz) and calculating the proportion of 2-flash percepts in each of 9 phase bins (<xref rid="fig4" ref-type="fig">Figure 4D</xref>). For each participant, the phase angles were shifted so that the phase corresponding to the highest proportion of 2-flash percepts was aligned to a phase angle of zero. Consequently, due to this artificial alignment, the 2-flash proportion is necessarily maximal at a phase angle of zero; therefore, the zero-phase bin was discarded from further analyses. Most importantly, if the prestimulus phase indeed modulated the perceptual outcomes, we expected that the proportions of 2-flash percepts would peak at the optimal phase angle, gradually decreasing as the phases deviate from this optimal angle. Therefore, we tested for the quadratic main effect for phase bins (8 levels) and their interaction with different conditions (F2B1 vs. F2). There was no significant quadratic effect of phase bins (<italic>F</italic> <sub>(1,33)</sub> = 2.47, <italic>p</italic> = 0.13). Consistent with the observation that phases exerted a more pronounced influence on behavior when auditory input was introduced, a significant quadratic interaction emerged between conditions and phase bins (<italic>F</italic> <sub>(1,33)</sub> = 6.45, <italic>p</italic> = 0.02). Post hoc tests further revealed a significant phase modulation effect only for F2B1 (<italic>F</italic> <sub>(1,33)</sub> = 7.02, <italic>p</italic> = 0.01), but not for F2 condition (<italic>F</italic> &lt; 1).</p>
</sec>
<sec id="s2e">
<title>tACS-modulated alpha frequency causally influences the temporal integration window specifically in the F2 condition</title>
<p>To address the limitations of EEG in providing only correlational evidence, we conducted a follow-up experiment with a new group of participants using transcranial alternating current stimulation (tACS). This approach allowed us to actively modulate the alpha frequency and investigate its causal role in perceptual processes.</p>
<p>During the experiment, continuous tACS was applied to the posterior brain region (Figure S6) while participants performed the same task as in the psychophysical pretest, which required reporting their perception of two flashes across eight ISIs under the F2 and F2B1 conditions. Each participant completed three tACS sessions in a randomized order: low-alpha (8 Hz), high-alpha (13 Hz), and a sham condition with no active stimulation. Psychometric curves were fitted for each tACS session using the proportion of two-flash perceptions across eight ISIs, separately for F2 and F2B1 conditions. From these fitted curves, we calculated the fusion threshold ISI—the ISI at which participants perceived two flashes in 50% of trials—as an estimate of the temporal integration window (<xref rid="fig5" ref-type="fig">Figure 5A</xref> and <xref rid="fig5" ref-type="fig">B</xref>).</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Results of tACS experiment.</title><p>(A) Psychometric curves show the average probability of perceiving two flashes as a function of different ISIs, under three tACS conditions: 13 Hz, sham, and 8 Hz, in the F2 condition. (B) Similar to (A), but for the F2B1 condition. (C) Fusion threshold ISIs from the three tACS sessions in both F2 and F2B1 conditions. Error bars represent ±1 SEM. *p &lt; 0.05.</p></caption>
<graphic xlink:href="578121v2_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>A 3 (tACS sessions: 8 Hz vs. sham vs. 13 Hz) × 2 (stimuli conditions: F2 vs. F2B1) repeated-measures ANOVA on fusion thresholds revealed a significant main effect of conditions, <italic>F</italic> <sub>(1,29)</sub> = 39.58, <italic>p</italic> = 7.19×10<sup>−7</sup>, consistent with the psychophysical pretest, showing that auditory input prolonged the temporal window for visual integration. No significant main effect of tACS sessions was observed, <italic>F</italic> <sub>(1,29)</sub> = 1.25, <italic>p</italic> = 0.27. Crucially, a significant interaction between tACS session and stimulus condition was observed, <italic>F</italic> <sub>(1,29)</sub> = 5.41, <italic>p</italic> = 0.03. Specifically, in the F2 condition, the fusion threshold at 13 Hz was significantly lower than at 8 Hz (<italic>t</italic> <sub>(29)</sub> = 2.09, <italic>p</italic> = 0.045), indicating that higher alpha frequencies shortened the temporal window for perceptual integration. In contrast, no significant differences were observed between different tACS conditions in the F2B1 condition (<italic>F</italic> &lt;1) (<xref rid="fig5" ref-type="fig">Figure 5C</xref>). These findings suggest that alpha oscillations causally modulate the temporal window for visual perception in the F2 condition but not in the F2B1 condition.</p>
</sec>
<sec id="s2f">
<title>Auditory input-induced phase resetting model explains the decrease in alpha frequency and the altered predictive roles of alpha frequency and phase</title>
<p>What could be underlying cause of the decrease in poststimulus alpha frequency observed in F2B1 condition? Could this cause explain the divergent effects of the altered predictive roles of alpha frequency and phase? Previous research has shown that transient auditory stimuli can reset the phase of ongoing oscillations in the visual cortex (<xref ref-type="bibr" rid="c29">Lakatos et al., 2009</xref>, <xref ref-type="bibr" rid="c28">2007</xref>). This, in turn, has a notable impact on multisensory integration processes(<xref ref-type="bibr" rid="c38">Mercier et al., 2015</xref>, <xref ref-type="bibr" rid="c37">2013</xref>). Importantly, this phase resetting has the potential to disrupt the timing and synchronization of periodic oscillations, which could subsequently lead to a shift in oscillation speed.</p>
<p>To test this hypothesis, we introduced a phase-resetting model for examining perceptual processing (<xref rid="fig6" ref-type="fig">Figure 6</xref>). Developed based on perceptual cycles theoretical framework (<xref ref-type="bibr" rid="c60">VanRullen, 2016b</xref>), this model utilized simulations to replicate our key observations. In the context of perceptual cycle theory, both frequency and phase play fundamental roles in shaping perceptual outcomes. Frequency governs the temporal resolution of the visual system—higher frequencies favor the perception of two distinct flashes, while lower frequencies tend to amalgamate them into a single event. The oscillatory phase represents brain states fluctuating between high and low cortical excitability (<xref ref-type="bibr" rid="c15">Engel et al., 2001</xref>; <xref ref-type="bibr" rid="c28">Lakatos et al., 2007</xref>), thereby influencing perceptual processing intensity. Our model differentiates percepts by assessing whether two flash stimuli fall within a single cycle. Good phases near the peak enhance processing efficiency, resulting in clearer perceptions of 1-flash and 2-flash percepts. Conversely, bad phases near the trough lead to less efficient processing and increased perceptual ambiguity. <xref rid="fig6" ref-type="fig">Figure 6</xref> visually illustrates our model. When the second flash aligns with a good phase, efficient processing occurs, leading to a clear perception of 1-flash or 2-flash based on whether they fall within the same or different cycles. In contrast, when the second flash aligns with a bad phase, less efficient processing increases perceptual ambiguity, making both interpretations plausible. For the F2B1 condition, the introduction of auditory input, known to induce delayed responses in the visual cortex relative to visual stimuli (<xref ref-type="bibr" rid="c30">Land et al., 2012</xref>; <xref ref-type="bibr" rid="c42">Oeur et al., 2023</xref>), induces phase resetting of the ongoing oscillations. The specific parameters governing phase resetting are derived from the model proposed by Canavier in 2013(<xref ref-type="bibr" rid="c9">Canavier et al., 2013</xref>), as detailed in the Methods section.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Hypothesized phase-resetting model of perceptual processing.</title><p>(A) The perceptual outcomes depend on the temporal alignment of two stimuli and the phase at which the second flash occurs. When the second flash coincides with good phases, around the peak of the oscillation, effective processing occurs, and the perceptual outcomes are determined based on whether they fall within the same temporal window defined by the alpha cycle. In cases where the two visual stimuli fall in different temporal windows, the 2-flash percept is reported. The introduction of auditory stimuli concurrently with visual stimuli induces phase resetting, elongating the temporal window. Consequently, the second flash, originally falling in different temporal windows, aligns with the first flash, resulting in a 1-flash percept. Conversely, when the second flash aligns with bad phases, around the trough of the oscillation, effective processing is hindered, leading to ambiguity in 1-flash and 2-flash percepts, irrespective of their temporal alignment. (B) <italic>Upper panel</italic>: The frequency of the alpha rhythm is anticipated to modulate perceptual outcomes, with higher alpha frequencies correlating with an increased proportion of 2-flash percepts. <italic>Lower panel</italic>: The phase of the alpha rhythm is expected to dictate perceptual clarity. In instances where the second flash falls in bad phases (e.g., [−π, −1/2π] and [1/2π, π]), perceptual clarity is low, making it challenging to distinguish between 1-flash and 2-flash percepts. Conversely, when the second flash aligns with good phases (e.g., [−1/2π, 1/2π]), perceptual clarity is high, and the perception of 1-flash or 2-flash depends on whether the two stimuli fall within the same alpha cycle or not.</p></caption>
<graphic xlink:href="578121v2_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Building upon the established model, we simulated 1000 trials under two conditions (F2 vs. F2B1). Initial analysis of the model-generated behavioral data yielded results consistent with real participants, notably indicating a prolonged integration window under the F2B1 condition compared to F2 (<xref rid="fig7" ref-type="fig">Figure 7A</xref>). Subsequent analysis of alpha oscillations in the simulated data, using the same methodology as for real data, consistently unveiled a lower alpha frequency under F2B1 compared to F2 (<xref rid="fig7" ref-type="fig">Figure 7B</xref>). For the alpha frequency effects in perceptual outcomes, mirroring our real data, in our simulations, we averaged the IAF over the entire time of interest (artificially defined from −600 to 600 ms). The simulation results highlighted a more pronounced modulation of alpha frequency in perceptual outcomes in the F2 compared to the F2B1 condition (<xref rid="fig7" ref-type="fig">Figure 7C</xref>).</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7.</label>
<caption><title>Simulation results.</title><p>(A) Psychophysical results. Psychometric curves depict the best-fit average probability of perceiving two flashes plotted against different ISIs in simulated F2 and F2B1 conditions. (B) IAFs for simulated F2 and F2B1 trials. (C) IAFs, averaged during the time of interest (−600 to 600 ms), separately for simulated F2 and F2B1 trials with different perceptual outcomes. Error bars represent ±1 within-trials SEM. (D) Statistical analysis of the differential phase effects between F2B1 and F2 condition at stimulus onset (0 ms), prior to the auditory input-induced phase-resetting. The red line indicates the mean POS difference between simulated F2B1 and F2 trials. Dashed black line indicates the 95th percentile value of the surrogate distribution. (E) Phase distribution at the onset of flash 2 (ISI = 50 ms; following the phase-resetting effect). (F) Subjective perceptual sensitivity in distinguishing between 1-flash and 2-flash percepts for simulated F2 and F2B1 trials.</p></caption>
<graphic xlink:href="578121v2_fig7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Furthermore, in line with phase results in our real data, simulated data demonstrated more pronounced phase effects in the F2B1 condition compared to the F2 condition at the onset of flash 1 (<xref rid="fig7" ref-type="fig">Figure 7D</xref>). Since the phase at which the second flash occurs determines perceptual clarity between the two percepts in our model, we further presented the phase distribution of the second flash for the F2 and F2B1 conditions, respectively (<xref rid="fig7" ref-type="fig">Figure 7E</xref>). Notably, auditory input-induced phase resetting made the second flash more likely to fall into the range of a favorable phase (<xref rid="fig7" ref-type="fig">Figure 7E</xref>), leading to higher subjective sensitivity (<xref rid="fig7" ref-type="fig">Figure 7F</xref>), compared to the F2 condition.</p>
<p>Our own findings lend credence to this hypothesis. We observed a higher alpha inter-trial coherence (ITC) in the F2B1 condition compared to the F2 condition (Figures S7A and B). Because an increase in ITC following a stimulus may reflect a stimulus-evoked response, we also computed changes in alpha power after stimulus onset. A stimulus-evoked response, characterized by an additional signal superimposed on ongoing oscillations, would manifest as both an increase in ITC and power following the stimulus, whereas a pure phase-resetting of ongoing oscillations will manifest as an increase in ITC with no accompanying power change or a power decrease (<xref ref-type="bibr" rid="c32">Makeig et al., 2004</xref>; <xref ref-type="bibr" rid="c52">Shah et al., 2004</xref>). Our findings showed no significant difference in alpha power between the two conditions (Figure S7C). Furthermore, we observed no substantial correlation between the magnitude of alpha power and alpha ITC increase after stimulus onset (Figure S7D). Therefore, although we cannot rule out a stimulus-evoked explanation for alpha ITC, we believe the increase in alpha ITC at least partially reflects phase-resetting of spontaneous oscillations in occipital regions.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>In this study, we explored how auditory stimuli influence visual processing, specifically focusing on the temporal window of integration. Behaviorally, we uncovered a prolonged fusion threshold in the presence of auditory stimuli, indicative of an extended temporal window for visual perception induced by cross-modal interactions (<xref rid="fig1" ref-type="fig">Figures 1C</xref> and <xref rid="fig1" ref-type="fig">D</xref>). The analysis of alpha oscillations provided valuable insights, demonstrating that the introduction of auditory stimuli resulted in poststimulus alpha frequency degradation, which correlated with the extended window, affirming the role of alpha oscillations in shaping the temporal dynamics of visual processing (<xref rid="fig2" ref-type="fig">Figure 2C</xref>). Notably, our findings revealed distinct contributions from prestimulus alpha frequency and phase in predicting perceptual outcomes in unimodal and cross-modal conditions (<xref rid="fig3" ref-type="fig">Figures 3</xref> and <xref rid="fig4" ref-type="fig">4</xref>). To elucidate the underlying mechanisms, we employed a computational model based on the phase resetting hypothesis and perceptual cycle theory, successfully replicating key behavioral and neural findings (<xref rid="fig7" ref-type="fig">Figure 7</xref>). The convergence of behavioral, neurophysiological, and computational evidence underscores the interplay between auditory and visual modalities in shaping the temporal dynamics of perception.</p>
<p>Our findings reveal that concurrent auditory input significantly extends the temporal window of visual integration compared to the no-sound condition (<xref rid="fig1" ref-type="fig">Figure 1C</xref>). This is in line with consistent findings from previous studies demonstrating the impact of sound signals on the perceived duration or rate of visual stimuli (<xref ref-type="bibr" rid="c17">Gebhard and Mowbray, 1959</xref>; <xref ref-type="bibr" rid="c56">Shipley, 1964</xref>; <xref ref-type="bibr" rid="c63">Walker and Scott, 1981</xref>; <xref ref-type="bibr" rid="c66">Welch et al., 1986</xref>). Intriguingly, this prolonged temporal window is positively correlated with the decrease in poststimulus alpha frequency induced by auditory stimuli. These findings contribute to the enduring hypothesis associating the human alpha rhythm with temporal windows, positing that higher frequencies correspond to shorter windows and heightened temporal resolution (<xref ref-type="bibr" rid="c10">Cecere et al., 2015</xref>; <xref ref-type="bibr" rid="c14">Cooke et al., 2019</xref>; <xref ref-type="bibr" rid="c26">Keil and Senkowski, 2017</xref>; <xref ref-type="bibr" rid="c49">Samaha and Postle, 2015</xref>). A lengthened integration window, as indicated by a longer alpha cycle, implies that two successive visual flashes are more prone to falling within a single cycle. Consequently, the visual system requires an extended duration to effectively differentiate between the two flashes. This established connection between altered alpha frequency and the resultant temporal window expansion provides a nuanced understanding of how auditory stimulation influences the temporal dynamics of visual perception. Essentially, our findings suggest that auditory stimuli can influence the temporal resolution of visual processing, potentially providing a longer temporal window for the integration of cross-modal information.</p>
<p>Building upon these findings, a critical inquiry arises: how does auditory stimulation contribute to a decrease in alpha frequency? Previous fMRI studies on multisensory perception have shown that auditory stimuli could modulate activity in primary visual cortex(<xref ref-type="bibr" rid="c64">Watkins et al., 2007</xref>, <xref ref-type="bibr" rid="c65">2006</xref>). Neurophysiological evidence further emphasizes that transient auditory stimuli can reset the phase of the ongoing oscillations, particularly in alpha-band, within the visual cortex (<xref ref-type="bibr" rid="c29">Lakatos et al., 2009</xref>; <xref ref-type="bibr" rid="c37">Mercier et al., 2013</xref>; <xref ref-type="bibr" rid="c45">Romei et al., 2012</xref>). These insights suggest that cross-modal auditory stimuli might exert influence on alpha oscillations by resetting the phase in the visual cortex. Our empirical evidence, as indicated by the increased phase coherence in the F2B1 condition according to the ITC analysis, lends support to this hypothesis (Figures S7A and B). To unravel the underlying mechanisms, we developed a computational model that integrates the perceptual cycle theory and auditory-induced phase resetting. As expected, the introduction of auditory-induced phase resetting, causing a delay in the originally achieved phase, led to a prolonged temporal integration window and a decrease in post-stimulus alpha frequency. This implies that cross-modal auditory stimuli may disrupt the original trajectory of periodic signals, impacting the integration of incoming inputs in the visual cortex (<xref ref-type="bibr" rid="c31">Luo et al., 2010</xref>; <xref ref-type="bibr" rid="c45">Romei et al., 2012</xref>; <xref ref-type="bibr" rid="c68">Wutz et al., 2014</xref>). Together, our combined empirical and computational evidence provides a comprehensive understanding of how auditory stimuli influence the temporal dynamics of visual perception by altering alpha frequency and temporal integration windows in the visual cortex.</p>
<p>Moreover, our findings highlight a clear distinction in the predictive role of prestimulus alpha frequency between F2 and F2B1 conditions. Consistent with previous studies (<xref ref-type="bibr" rid="c21">Han et al., 2023</xref>; <xref ref-type="bibr" rid="c49">Samaha and Postle, 2015</xref>; <xref ref-type="bibr" rid="c54">Shen et al., 2019</xref>; <xref ref-type="bibr" rid="c67">Wutz et al., 2018</xref>), we observed that higher alpha frequencies in the F2 condition correlate with a shorter integration window and more rapid sampling, enabling accurate discrimination of temporally close stimuli. In contrast, lower frequencies correspond to a longer integration window and slower sampling, leading to fusion illusions (<xref rid="fig3" ref-type="fig">Figure 3A</xref>). These results align with prior research using similar individual alpha frequency (IAF) analyses (<xref ref-type="bibr" rid="c12">Cohen, 2014a</xref>; <xref ref-type="bibr" rid="c49">Samaha and Postle, 2015</xref>; <xref ref-type="bibr" rid="c54">Shen et al., 2019</xref>; <xref ref-type="bibr" rid="c67">Wutz et al., 2018</xref>), which also reported relatively small changes in alpha frequency across conditions (<xref rid="fig3" ref-type="fig">Figure 3A</xref>). A possible explanation for this small effect lies in the fact that EEG alpha frequency signals represent an average of all neural populations, including both task-relevant and irrelevant groups. This averaging process likely attenuates the effect size due to noise introduced by task-irrelevant neural activity.</p>
<p>In contrast, this frequency-perception link was disrupted in the F2B1 condition (<xref rid="fig3" ref-type="fig">Figure 3B</xref>), where the auditory stimulus appeared to negate the predictive power of alpha frequency in visual integration. This observation aligns with recent null effects reported by Buergers and Noppeney (<xref ref-type="bibr" rid="c6">Buergers and Noppeney, 2022</xref>). Further supporting this interpretation, the tACS results demonstrated that alpha frequency modulation influenced perceptual outcomes only in the F2 condition, underscoring the causal role of alpha frequency in visual integration without auditory interference. Moreover, these findings ruled out the possibility that the auditory beep evoked an alpha response contaminating occipital alpha recordings and masking the alpha frequency-perception relationship in the F2B1 condition. Notably, even when alpha frequency was externally manipulated via tACS, no behavioral differences emerged between high- and low-frequency conditions in the F2B1 condition (<xref rid="fig5" ref-type="fig">Figure 5B</xref>). This suggests that the auditory-induced disruption of the alpha frequency-perception link was not due to neural noise but rather reflected the fundamental influence of auditory input on alpha oscillatory dynamics. We propose that the auditory stimulus induces phase resetting, aligning alpha oscillation phases in a consistent direction and slightly reducing poststimulus alpha frequency (<xref rid="fig2" ref-type="fig">Figure 2B</xref>). Although subtle, this reduction is meaningful: it increases the probability that stimuli will fall within a longer temporal integration window, thereby favoring 1-flash percepts in the F2B1 condition (<xref rid="fig3" ref-type="fig">Figure 3B</xref>). Thus, even if a higher prestimulus alpha frequency might typically predict more 2-flash percepts, the auditory-induced frequency reduction overrides this pattern, diminishing alpha frequency’s predictive role. These findings suggest that concurrent auditory input extends the temporal window by modulating the dynamics of alpha oscillations, ultimately changing perceptual integration in a cross-modal context.</p>
<p>Prior research has shown that phase encodes rapidly changing stimuli effectively (<xref ref-type="bibr" rid="c50">Schyns et al., 2011</xref>), though temporal precision is often compromised by stimulus-evoked neural responses that dominate phase estimates(<xref ref-type="bibr" rid="c22">Harris, 2023</xref>; <xref ref-type="bibr" rid="c59">VanRullen, 2016a</xref>). As a result, prestimulus phase has become a valuable proxy for predicting perception, although its effectiveness has been debated. While some studies consistently support the predictive role of prestimulus phase (<xref ref-type="bibr" rid="c7">Busch et al., 2009</xref>; <xref ref-type="bibr" rid="c19">Gruber et al., 2014</xref>; <xref ref-type="bibr" rid="c35">Mathewson et al., 2009</xref>; <xref ref-type="bibr" rid="c39">Milton and Pleydell-Pearce, 2016</xref>), others report null effects (<xref ref-type="bibr" rid="c4">Benwell et al., 2022</xref>, <xref ref-type="bibr" rid="c5">2017</xref>; <xref ref-type="bibr" rid="c27">Keitel et al., 2022</xref>; <xref ref-type="bibr" rid="c47">Ruzzoli et al., 2019</xref>; <xref ref-type="bibr" rid="c61">van Diepen et al., 2015</xref>). In our study, in the F2B1 condition, the pre-stimulus alpha rhythm exhibited a significant phase opposition effect, whereas this modulation effect was much weaker in the unimodal F2 condition. According to our model, both the frequency and phase of alpha oscillations play distinct roles: frequency determines whether two flashes are perceived as one or two, while phase alignment influences the clarity of that perception. In the F2 condition, flashes falling within the same alpha cycle tend to be perceived as a single flash, while flashes falling in separate cycles favor a 2-flash percept. However, even when both flashes are detected as separate, perception clarity depends on favorable phase alignment: favorable alignment sharpens the distinction, whereas less favorable alignment reduces clarity. In the F2B1 condition, the auditory stimulus induces phase resetting, aligning the second flash within a more favorable phase window, improving perceptual clarity. This mechanism allows the second flash to reliably fall within optimal phase windows, making it easier to distinguish between one- and two-flash outcomes. Therefore, in the cross-modal F2B1 condition, the predictive role of prestimulus phase is enhanced, as the auditory-driven phase resetting sharpens perceptual distinctions by aligning the stimulus to optimal phases.</p>
<p>Previous studies on the influence of oscillatory phase on perception primarily analyzed absolute phase angles within a cycle, categorizing specific phases as favorable or unfavorable for perception(<xref ref-type="bibr" rid="c7">Busch et al., 2009</xref>; <xref ref-type="bibr" rid="c34">Mathewson et al., 2010</xref>; <xref ref-type="bibr" rid="c40">Neuling et al., 2012</xref>; <xref ref-type="bibr" rid="c41">Ng et al., 2012</xref>). This framework, however, creates a potential contradiction: one stimulus could be presented at a favorable phase and another at an unfavorable phase, leading to the erroneous perception of only one stimulus, irrespective of whether they occur in the same or different cycles. Such an explanation conflicts with our behavioral data, which suggest a more nuanced interplay between frequency and phase. Notably, the above-mentioned studies, however, used near-threshold stimuli, raising concerns about their applicability to suprathreshold stimuli, which are presumably perceived with less dependence on specific phase variations (<xref ref-type="bibr" rid="c3">Baumgarten et al., 2015</xref>). In contrast, our model integrates the roles of both frequency and phase. Frequency governs the temporal resolution of the visual system, while phase modulates the clarity with which two perceptual states are distinguished (<xref ref-type="bibr" rid="c57">Ten Oever et al., 2020</xref>). This expanded role of phase as a modulator of perceptual clarity helps reconcile discrepancies in the literature. For example, <xref ref-type="bibr" rid="c6">Buergers and Noppeney (2022)</xref> reported null effects of alpha frequency on sensitivity for discriminating between one-flash and two-flash percepts in both unimodal and cross-modal contexts (<xref ref-type="bibr" rid="c6">Buergers and Noppeney, 2022</xref>). Our model suggests that while frequency may not directly influence sensitivity, alpha phase plays a critical role in modulating perceptual sensitivity. By accounting for both frequency and phase, our framework offers a cohesive explanation for both consistent and null results in prior research, advancing our understanding of oscillatory dynamics in perception.</p>
<p>Additionally, the observed phase and frequency effects appear to be unrelated to fluctuations in oscillatory amplitude, as our analyses have revealed. This indicates that, at least in the alpha band, the phase and frequency of ongoing neural oscillations may exert an influence on stimulus processing that is distinct from amplitude variations. This finding aligns with prior evidence (<xref ref-type="bibr" rid="c21">Han et al., 2023</xref>; <xref ref-type="bibr" rid="c39">Milton and Pleydell-Pearce, 2016</xref>). Moreover, the discernible distinctions in patterns between the phase and frequency of alpha oscillations in cross-modal integration imply that they independently contribute, to some degree, to the modulation of temporal integration processes.</p>
<p>Our findings offer a novel perspective on phase resetting, emphasizing its influence on cross-modal interactions beyond its traditional role in facilitating multisensory integration. For example, prior research has shown that cross-modal phase resetting, such as visual stimuli modulating auditory alpha-band activity, is linked to faster reaction times and enhanced efficiency(<xref ref-type="bibr" rid="c36">Mégevand et al., 2020</xref>; <xref ref-type="bibr" rid="c58">Thorne et al., 2011</xref>). Similarly, auditory-driven phase resetting in the visual cortex has been demonstrated to facilitate audiovisual integration (<xref ref-type="bibr" rid="c37">Mercier et al., 2013</xref>). These studies underscore the critical role of phase resetting in optimizing sensory processing, proposing that its underlying mechanism involves the reorganization of neural oscillations through input from another sensory domain (<xref ref-type="bibr" rid="c51">Senkowski and Engel, 2024</xref>). Supporting this, a study in non-human primates by <xref ref-type="bibr" rid="c28">Lakatos et al. (2007)</xref> found that somatosensory inputs reset oscillatory phases in the auditory cortex by modulating subthreshold membrane potentials, rather than increasing neural firing rates, thereby enhancing responsiveness (<xref ref-type="bibr" rid="c28">Lakatos et al., 2007</xref>). In this study, we reveal a distinct and underexplored consequence of phase resetting. Specifically, we show that auditory inputs to the visual cortex extend the temporal window for visual processing. While this might initially suggest a reduction in the sensory resolution of the visual system, it actually facilitates the seamless integration of auditory and visual inputs. This broader temporal window reflects an adaptive trade-off that enhances cross-modal coherence. Thus, phase resetting not only improves integration efficiency but also dynamically reshapes the temporal properties of sensory modalities to meet task demands, enabling flexible adaptation to complex environments. This aligns with a recent study in animals, which showed that responses in a primary sensory area’s preferred modality (e.g., somatosensory cortex for tactile stimuli) are highly plastic and can adapt to task demands and environmental changes (<xref ref-type="bibr" rid="c23">Kato and Bruno, 2024</xref>).</p>
<p>Please note that our model, based on perceptual cycles and phase reset, offers a speculative hypothesis that necessitates additional empirical evidence for validation. Incorporating studies with variable perceptual clarity or sensitivity would enhance our understanding of the specific role played by phase. Moreover, acknowledging the physiological limitations in our EEG study, we recognize the complexity of phase resetting induced by transient events in the brain. Our model simplifies this intricacy by focusing on sound-induced phase resetting, but further empirical evidence is crucial for validation and refinement. Distinguishing evoked phase locking from pure phase resetting poses challenges, and intracranial recordings with higher resolution could provide a potential solution(<xref ref-type="bibr" rid="c2">Bauer et al., 2020</xref>). In our upcoming studies, we plan to utilize intracranial recordings in future studies to address and overcome this challenge, providing further clarity on the role of phase in perceptual processing.</p>
<p>In summary, our study unveils the impact of simultaneous auditory input on the temporal perception of two visual stimuli. The findings indicate that the introduction of auditory stimuli extends the temporal window of integration, with a notable influence on alpha oscillations. We propose that this effect is driven by auditory input-induced phase resetting in visual areas, which extends the duration of the alpha cycle. Consequently, this elongation strengthens the dominant predictive role of the alpha phase while simultaneously reducing the influence of alpha frequency in multisensory processing. In combination with previous studies investigating similar paradigms, our current findings lend further support to the perceptual cycle theory and offer a novel interpretation for the divergent outcomes observed in previous research on frequency and phase.</p>
</sec>
<sec id="s4">
<title>Materials and methods</title>
<sec id="s4a">
<title>Participants</title>
<p>Thirty-four healthy right-handed participants (23 females; age 20.8 ± 1.9, Mean ± SD) participated in the EEG experiment. Another group of 30 participants participated in the tACS experiment (18 females; age 22.4 ± 2.2). The sample size was pre-specified to ensure at least 80% power to detect experimental effect sizes ranging from moderate to large (Cohen’s d &gt; 0.5). All participants have normal or corrected-to-normal visual acuity and have no history of neurological or psychiatric disease.</p>
</sec>
<sec id="s4b">
<title>Stimuli</title>
<p>The visual stimuli consisted of two identical white circles, each with a radius of 2 degrees, presented against a gray background. These circles were displayed rapidly one after the other, positioned peripherally below the fixation point at an eccentricity of 5 degrees of visual angle. Each visual stimulus had a duration of 10 milliseconds. The auditory stimulus was a 10-millisecond pure tone with a frequency of 3000 Hz and an approximate sound level of 50 decibels. To provide a spatially congruent experience for the participants, the auditory stimuli were delivered through a pair of loudspeakers situated on either side of the monitor. This arrangement created the perception that the auditory cues originated from the center of the screen, closely aligned with the visual stimuli. Visual stimuli were presented using Presentation software (Neurobehavioral Systems; <ext-link ext-link-type="uri" xlink:href="http://www.neurobs.com">http://www.neurobs.com</ext-link>) on a 24-inch high-refresh-rate LCD monitor (resolution: 1920 × 1080, refresh rate: 100 Hz, viewing distance 57 cm) and viewed through a chin-and-forehead rest. The monitor was carefully calibrated using an oscilloscope before the experiment. The study consisted of two conditions: the F2 condition, involving the presentation of two visual stimuli, and the F2B1 condition, where the first visual flash was consistently accompanied by an auditory beep.</p>
</sec>
<sec id="s4c">
<title>Psychophysical procedures</title>
<p>To determine each subject’s fusion threshold for the bistable condition, each participant completed a psychophysical pretest before the main experiment. Prior to the psychophysical pretest, participants completed a practice block consisting solely of explicit short (30 ms) and long trials (100 ms) until accuracy reached at least 90%. During the formal psychophysical pretest, the first flash was presented for a duration of 10 ms, after a variable ISI (eight levels: 30, 40, 50, 60, 70, 80, 90, or 100 ms), the second flash was presented for 10 ms as well. Each ISI comprised 35 trials for both F2 and F2B1 conditions. Participants were then asked to perform a two-alternative forced-choice task in which they had to choose between perceiving one flash or two flashes. A logistic function was used to fit the eight data points (one for each ISI) to a psychometric curve. The fusion threshold ISI, that is, the point at which 1-flash and 2-flash were equally likely to be reported, was calculated by estimating the 50% performance point on the fitted logistic function for each participant. The individual fusion threshold ISI derived from the psychophysical pretest was then utilized as ISI in the bistable trials of the subsequent EEG experiment.</p>
</sec>
<sec id="s4d">
<title>EEG experimental procedures</title>
<p>Participants were instructed to fixate at a central fixation throughout the experiment without moving their eyes. The experimental task was to discriminate one- or two-flash by pressing one of two prespecified buttons on the keyboard using the index and middle fingers of their right hand. The mapping between the two response buttons and the two types of percepts was counterbalanced between participants. Each participant completed 560 experimental trials, including 15% explicit short trials (ISI 30 ms), 15% explicit long trials (ISI 100 ms), and 70% bistable trials (fusion threshold ISI), organized into ten blocks with short breaks in between. Each trial began with a central fixation lasting 500 to 1500 ms, followed by a 10 ms presentation of the first visual stimulus, accompanied by an auditory beep or not. After a variable ISI (30 ms, 100 ms, or the participant’s individual fusion threshold), the second frame was displayed for 10 ms, and participants were required to respond within 2000 ms.</p>
</sec>
<sec id="s4e">
<title>Recording and preprocessing of EEG data</title>
<p>The electroencephalogram (EEG) was recorded at a sampling rate of 1000 Hz using a Neuroscan SynAmps2 system equipped with 64-channel Quick-Caps and Ag/AgCl electrodes. To capture horizontal and vertical electrooculograms, four extra electrodes were placed around the participants’ eyes. The impedances of all electrodes were diligently maintained below 5 kΩ to ensure high signal quality. The signals were online-referenced to an electrode positioned between Cz and CPz. Subsequently, the data underwent offline processing and analysis using FieldTrip (<xref ref-type="bibr" rid="c43">Oostenveld et al. 2011</xref>) (<ext-link ext-link-type="uri" xlink:href="https://www.fieldtriptoolbox.org">www.fieldtriptoolbox.org</ext-link>) and custom MATLAB scripting. Data were filtered to eliminate interference from 50 Hz power lines, down-sampled to 500 Hz, re-referenced to the average reference, epoch from −1300 to 1000 ms. To correct for any baseline drifts, the mean amplitude was subtracted over a time window of −500 to 0 ms relative to the presentation of the first flash. It should be noted that the subtraction of the mean amplitude has no effect on the pre-stimulus alpha oscillations, as it mainly affects only the zero frequency component (<xref ref-type="bibr" rid="c12">Cohen, 2014a</xref>). Before segregating them into different categories, signals containing blinks, muscular movements, and other EEG artifacts were detected and removed through independent component analysis.</p>
</sec>
<sec id="s4f">
<title>tACS experimental procedures</title>
<p>The alternating-current stimulation was administered using a 1 × 1 transcranial electrical stimulator (Soterix Medical, New York, NY) with rubber electrodes embedded in saline-soaked sponges. Electrodes were secured to the scalp with elastic bands. The reference electrode and stimulation electrode were positioned at the vertex (Cz) and posterior occipital area (Oz), respectively, following the international 10-20 EEG system. Each electrode measured 5 × 7 cm². A sinusoidal current was used with a DC offset of 0, and impedance was maintained below 5 kΩ. The current intensity was set at 1.5 mA. Participants completed three 16-minute tACS sessions in randomized order: (1) 8 Hz stimulation (low-alpha), (2) 13 Hz stimulation (high-alpha), and (3) sham stimulation. Sessions were spaced 30 minutes apart. During sham stimulation, the current was ramped up over 30 seconds, then ramped down to zero over the subsequent 30 seconds, after which no further stimulation was applied. The Auto-Sham setting on the tACS controller was used to deliver sham stimulation. This ramping protocol mimicked the somatosensory sensation typically experienced during real transcranial electrical stimulation, particularly during current ramp-up or ramp-down phases. In each session, participants performed the same task as in the psychophysical pre-test, with 20 trials for each ISI condition.</p>
</sec>
<sec id="s4g">
<title>Alpha oscillation analysis of EEG data</title>
<p>In our EEG data analysis, our primary focus was on the bistable trials within both the F2 and F2B1 conditions, unless stated otherwise. Fast Fourier Transform (FFT) was applied to generate a power spectrum for all electrodes and participants, ranging from 1 to 30 Hz. In each trial, the power spectrum was computed over the entire period of interest (−600 to 600 ms, relative to the presentation of the first flash). Subsequently, the grand-level power spectrum was obtained by averaging across all trials, electrodes, and participants, thereby identifying the frequency band where the peak frequency, characterized by the highest power, was located. The power topography map was constructed to depict the most prominent frequency band observed in the power spectrum.</p>
<p>Following established methods (<xref ref-type="bibr" rid="c12">Cohen, 2014a</xref>), we computed instantaneous alpha frequencies (IAF) over time. IAF was determined by selecting occipital electrodes (O1, O2, Oz, PO7, PO5, PO3, POz, PO4, PO6, and PO8) exhibiting maximum alpha power in the posterior region of interest for each participant. Specifically, in the time window of −600 to 600 ms, a plateau-shaped band-pass filter (8 to 13 Hz) with a 15% transition zone was applied to the data. Phase angle time series were extracted using the Hilbert transform, and the temporal derivative of the phase angle time series, indicative of instantaneous frequency (scaled by the sampling rate and 2π), was calculated as the phase varied over time. Previous studies have suggested that noise in the phase angle time series may result in sharp, unphysiological responses in the derivative (<xref ref-type="bibr" rid="c12">Cohen, 2014a</xref>). Therefore, the following disposition was made on the instantaneous frequencies with a median filter of order 10 and a maximum window size of 400 ms. To be more specific, the data were averaged across trials after being median filtered ten times using 10-time windows ranging from 10 to 400 ms. This analysis is theoretically independent of the oscillatory amplitude, except for cases when the amplitude is zero and the phase is indeterminate, as it only considers changes in instantaneous phase. To account for the possibility that differences in trial numbers may lead to discrepancies across conditions, we counterbalanced the number of trials between perceptual outcomes and different conditions. The average instantaneous alpha frequency (IAF) was then calculated for bistable 1-flash and 2-flash trials in F2 and F2B1 conditions.</p>
<p>For the control analysis of instantaneous alpha power, we employed the same filtering and Hilbert transform as utilized in the IAF analysis to extract instantaneous alpha amplitude. The power was then calculated by squaring the amplitude.</p>
<p>To account for the potential effects of the 1/f slope, we reconstructed the time-domain signals that had been demodulated by implementing 1/f attenuation, following the methods outlined in a previous study (<xref ref-type="bibr" rid="c48">Samaha and Cohen, 2022</xref>). Specifically, we utilized the Fast Fourier Transform (FFT) to extract the amplitude and phase spectra from each trial of the original signal. Polynomial fits were then applied to the amplitude spectra to obtain the best-fit values, the inverse of which was multiplied by the amplitude spectrum point-by-point to generate the demodulated amplitude spectrum. To reconstruct the demodulated time-domain signal, we employed the Inverse FFT to combine the phase and amplitude spectra of the original signal into complex values. Next, the demodulated signal underwent a filter with a fixed frequency limit of 8-13 Hz to perform the instantaneous frequency analysis.</p>
<p>Our primary goal was to investigate whether single-trial perception is influenced by the phase of ongoing oscillatory activity. To achieve this, we utilized the phase opposition sum (POS) method (<xref ref-type="bibr" rid="c59">VanRullen, 2016a</xref>) to evaluate the phase difference between the two distinct perceptual outcomes in the F2 and F2B1 conditions. Given that the statistical power of POS is influenced by the absolute trial count within each set of trial, and that reliability of POS can be compromised when dealing with unequal 1-flash and 2-flash trial counts (an inherent feature of all phase-based time-frequency analyses methods) (<xref ref-type="bibr" rid="c62">Vinck et al., 2010</xref>), we balanced the trial counts for both perceptual outcomes in both F2 and F2B1 conditions.</p>
<p>Time-frequency transformations were first generated over occipital channels using fieldtrip (<xref ref-type="bibr" rid="c43">Oostenveld et al., 2011</xref>). Specifically, we used wavelets with logarithmically spaced cycles (ranging from 2 at the lowest frequency to 7 at the highest frequency) to obtain time-frequency representations (complex numbers) at 60 log-spaced frequency points spanning from 2 to 50 Hz. This yields a complex representation of the amplitude, <italic>A</italic>, and the phase, <italic>φ</italic>, for trial <italic>j</italic> at time <italic>t</italic> and frequency <italic>f</italic>:
<disp-formula id="eqn1">
<graphic xlink:href="578121v2_eqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The phase of this representation can be extracted by normalizing the complex vector to the unit length:
<disp-formula id="eqn2">
<graphic xlink:href="578121v2_eqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Inter-Trial Phase Coherence (ITC) measures the phase consistency across trials. We calculated the ITC using the method described previously (<xref ref-type="bibr" rid="c13">Cohen, 2014b</xref>):
<disp-formula id="eqn3">
<graphic xlink:href="578121v2_eqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Where N is the number of trials in one group of trials. Note that the ITC is a scalar rather than a vector and it is always non-negative.</p>
<p>Subsequently, to assess whether trials associated with a specific perceptual outcome (i.e., 1-flash or 2-flash) exhibited differences in phase distribution when compared to trials related to the other perceptual outcome, we computed the POS value using the following formula(<xref ref-type="bibr" rid="c59">VanRullen, 2016a</xref>):
<disp-formula id="eqn4">
<graphic xlink:href="578121v2_eqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Where <italic>ITC<sub>A</sub></italic> and <italic>ITC<sub>B</sub></italic> are the ITC calculated separately for the two subgroups to be compared (i.e., 1flash or 2flash), and <italic>ITC<sub>ALL</sub></italic> is the ITC calculated across all trials regardless of condition.</p>
<p>Notably, when two conditions exhibit phase clustering at specific, distinct phase angles at a given time and frequency, this signifies that these conditions are phase-clustered with higher ITCs than the total ITC, leading to a higher POS value. Conversely, the POS value will be lower if the different conditions do not display stronger phase clustering or if the phases cluster at approximately the same phase angle.</p>
<p>To rigorously evaluate the significance of phase opposition without assuming any specific probability distribution of the POS values, a non-parametric permutation test was conducted. Initially, the POS values were computed for each point in the time-frequency plane from −600 to 200 ms, ranging from 2 to 50 Hz (in logarithmically spaced cycles) for each occipital electrode and subject, and then averaged over all occipital electrodes and subjects. The surrogate POS values were obtained by randomly assigning trials to one or the other condition for each subject while maintaining a constant number of trials in each condition, and then recalculating the grand mean POS values. The p-value of each time-frequency point was calculated as the proportion of grand mean surrogate POS values that exceeded the empirically observed grand mean POS. To ensure statistical rigor, 100,000 surrogates were employed, and a p-value of 1×10<sup>−5</sup> was assigned to the points without more extreme POS values in the surrogates.</p>
</sec>
<sec id="s4h">
<title>Statistical analyses</title>
<p>Cluster-based correction was applied when multiple time-frequency points (<xref rid="fig4" ref-type="fig">Figure 4A</xref>) or time points (<xref rid="fig2" ref-type="fig">Figure 2B</xref>, <xref rid="fig2" ref-type="fig">2D-E</xref>, <xref rid="fig3" ref-type="fig">3A</xref> and S4A) were tested. For multiple comparison correction of time-frequency points, elements that passed a threshold corresponding to a p-value of 0.05 were marked in each surrogate. Neighboring marked elements were identified as clusters. The count of suprathreshold samples within a cluster was used to define the cluster size, and the largest cluster size was entered into a distribution of cluster size, which was expected under the null hypothesis (<xref ref-type="bibr" rid="c33">Maris and Oostenveld, 2007</xref>). The p-value of the cluster was calculated as the proportion of the largest cluster size that exceeded the empirically observed largest cluster size. Regarding multiple comparison correction for time points, paired t-statistics were initially computed between different conditions across participants. Elements that passed a threshold of <italic>p</italic> &lt; 0.05 (two-tailed) were marked to identify temporal clusters. The t-values within a connected cluster were summed up to yield a cluster-level statistic. The p-value of the cluster was determined using a similar shuffling process within each participant.</p>
</sec>
<sec id="s4i">
<title>Simulations of EEG data</title>
<p>Simulations of EEG data were conducted utilizing MATLAB (MathWorks Inc) (for visualization of the simulation procedure, please see Figure S8). The fundamental representation of an oscillator with constant parameters is expressed as:
<disp-formula id="eqn5">
<graphic xlink:href="578121v2_eqn5.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
For each trial, signal (<italic>y<sub>t</sub></italic>) changes over time according to:
<disp-formula id="eqn6">
<graphic xlink:href="578121v2_eqn6.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Where <italic>ε</italic> follows a normal distribution. Aligning with the phase reset hypothesis, which posits that a salient stimulus shifts the phase of ongoing neural oscillation to its optimal excitability phase(Lakatos et al., 2005; <xref ref-type="bibr" rid="c28">Lakatos et al., 2007</xref>; Lakatos et al., 2008; <xref ref-type="bibr" rid="c58">Thorne et al., 2011</xref>; <xref ref-type="bibr" rid="c22">Harris, 2023</xref>), we strategically adjust the stimulus occurrence to synchronize with the good phase range for both experimental conditions. Specifically, we randomly set the initial phase within the good phase range of [−1/2π, 1/2π].</p>
<p>For the F2B1 condition, specifically designed to incorporate sound-induced phase resetting, a phase delay of 25 ms was introduced to the signal after the presentation of a sound stimulus at 0 ms. This delay was randomly varied within the range of 0 to 50 ms.</p>
<p>To simulate behavioral and EEG results, we generated 1000 trials for F2 and F2B1 conditions, respectively, and then implemented eight-level ISIs, ranging evenly from 30 ms to 100 ms. The perceptual outcome depended on the temporal alignment of the two flashes and the phases at which the second flash occurred. Specifically, subjective perceptual outcome was determined based on whether the two flashes occurred within the same alpha cycle or different. The phase at which the second flash occurred played a crucial role in the clarity of differentiating between 1-flash and 2-flash percepts, thereby directly affecting the reported percepts. We assigned a clarity value of 1 for favorable phases [−1/2π, 1/2π] and a clarity value of 0.5 for unfavorable phases [−π, −1/2π] and [1/2π, π]. Then we calculated the proportion of reported 2-flash percepts for each ISI. Applying a logistic function, we fitted the proportions of 2-flash percepts to determine the fusion threshold for each condition. Subsequently, the thresholds were used as ISI in F2 and F2B1 conditions for further frequency and phase analysis, followed the methodology outlined above for the analysis of real EEG data.</p>
<p>Moreover, we calculated the subjective sensitivity (<italic>d’</italic>) for the F2 and F2B1 conditions, following the signal detection theory:
<disp-formula id="eqn7">
<graphic xlink:href="578121v2_eqn7.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the hit rate (HR) represents the proportion of cases where the subjective perceptual outcome is 2-flash (i.e. the two flashes fall in the different alpha cycles) and the reported outcome is also 2-flash. The false alarm rate (FAR) is the proportion of cases where the subjective perceptual outcome should be 1-flash (i.e., two flashes fall in the same alpha cycle), but the reported outcome is 2-flash percept.</p>
</sec>
</sec>
</body>
<back>
<sec id="s5d" sec-type="data-availability">
<title>Data and code availability</title>
<p>The data and code utilized in the study are openly accessible on the website (<ext-link ext-link-type="uri" xlink:href="https://osf.io/2hsqw/">https://osf.io/2hsqw/</ext-link>). They have been made available for reuse or distribution in the public domain, as per the criteria set forth by the institute and in compliance with the ethical committee’s endorsement.</p>
</sec>
<sec id="s5" sec-type="additional-information">
<title>Additional information</title>
<sec id="s5b">
<title>Fundings</title>
<p>This work was supported by grants from the National Natural Science Foundation of China (32000785, 32000741, 31871138, 32071052), the Guangdong Natural Science Foundation (2021A1515011185, 2021A1515011100, 2020A1515110223)</p>
</sec>
<sec id="s5c">
<title>Author contributions</title>
<p>Mengting Xu, Conceptualization, Data curation, Formal analysis, Visualization, Methodology, Writing—original draft, Project administration, Writing—review and editing; Biao Han, Conceptualization, Data curation, Formal analysis, Supervision, Visualization, Methodology, Funding acquisition, Writing—review and editing; Qi Chen, Conceptualization, Supervision, Funding acquisition; Lu Shen, Conceptualization, Data curation, Formal analysis, Supervision, Visualization, Methodology, Funding acquisition, Writing—original draft, Project administration, Writing—review and editing</p>
</sec>
<sec id="s5e" sec-type="ethics-statement">
<title>Ethics</title>
<p>Human subjects: The study was authorized by the Ethics Committee of the School of Psychology, South China Normal University, in line with the Declaration of Helsinki, and each participant provided their informed permission.</p>
</sec>
</sec>
<sec id="suppd1e1522" sec-type="supplementary-material">
<title>Additional files</title>
<supplementary-material id="d1e1513">
<label>Supplementary figures</label>
<media xlink:href="supplements/578121_file03.docx"/>
</supplementary-material>
</sec>
<ref-list>
<title>Reference</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Andersen</surname> <given-names>TS</given-names></string-name>, <string-name><surname>Tiippana</surname> <given-names>K</given-names></string-name>, <string-name><surname>Sams</surname> <given-names>M</given-names></string-name></person-group>. <year>2004</year>. <article-title>Factors influencing audiovisual fission and fusion illusions</article-title>. <source>Brain Res Cogn Brain Res</source> <volume>21</volume>:<fpage>301</fpage>–<lpage>308</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cogbrainres.2004.06.004</pub-id></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bauer</surname> <given-names>A-KR</given-names></string-name>, <string-name><surname>Debener</surname> <given-names>S</given-names></string-name>, <string-name><surname>Nobre</surname> <given-names>AC</given-names></string-name></person-group>. <year>2020</year>. <article-title>Synchronisation of Neural Oscillations and Cross-modal Influences</article-title>. <source>Trends Cogn Sci (Regul Ed)</source> <volume>24</volume>:<fpage>481</fpage>–<lpage>495</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.tics.2020.03.003</pub-id></mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Baumgarten</surname> <given-names>TJ</given-names></string-name>, <string-name><surname>Schnitzler</surname> <given-names>A</given-names></string-name>, <string-name><surname>Lange</surname> <given-names>J</given-names></string-name></person-group>. <year>2015</year>. <article-title>Beta oscillations define discrete perceptual cycles in the somatosensory domain</article-title>. <source>Proc Natl Acad Sci USA</source> <volume>112</volume>:<fpage>12187</fpage>–<lpage>12192</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1501438112</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Benwell</surname> <given-names>CSY</given-names></string-name>, <string-name><surname>Coldea</surname> <given-names>A</given-names></string-name>, <string-name><surname>Harvey</surname> <given-names>M</given-names></string-name>, <string-name><surname>Thut</surname> <given-names>G</given-names></string-name></person-group>. <year>2022</year>. <article-title>Low pre-stimulus EEG alpha power amplifies visual awareness but not visual sensitivity</article-title>. <source>Eur J Neurosci</source> <volume>55</volume>:<fpage>3125</fpage>–<lpage>3140</lpage>. doi:<pub-id pub-id-type="doi">10.1111/ejn.15166</pub-id></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Benwell</surname> <given-names>CSY</given-names></string-name>, <string-name><surname>Tagliabue</surname> <given-names>CF</given-names></string-name>, <string-name><surname>Veniero</surname> <given-names>D</given-names></string-name>, <string-name><surname>Cecere</surname> <given-names>R</given-names></string-name>, <string-name><surname>Savazzi</surname> <given-names>S</given-names></string-name>, <string-name><surname>Thut</surname> <given-names>G</given-names></string-name></person-group>. <year>2017</year>. <article-title>Prestimulus EEG power predicts conscious awareness but not objective visual performance</article-title>. <source>eNeuro</source> <volume>4</volume>. doi:<pub-id pub-id-type="doi">10.1523/ENEURO.0182-17.2017</pub-id></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Buergers</surname> <given-names>S</given-names></string-name>, <string-name><surname>Noppeney</surname> <given-names>U</given-names></string-name></person-group>. <year>2022</year>. <article-title>The role of alpha oscillations in temporal binding within and across the senses</article-title>. <source>Nat Hum Behav</source> <volume>6</volume>:<fpage>732</fpage>–<lpage>742</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41562-022-01294-x</pub-id></mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Busch</surname> <given-names>NA</given-names></string-name>, <string-name><surname>Dubois</surname> <given-names>J</given-names></string-name>, <string-name><surname>VanRullen</surname> <given-names>R</given-names></string-name></person-group>. <year>2009</year>. <article-title>The phase of ongoing EEG oscillations predicts visual perception</article-title>. <source>J Neurosci</source> <volume>29</volume>:<fpage>7869</fpage>–<lpage>7876</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.0113-09.2009</pub-id></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Busch</surname> <given-names>NA</given-names></string-name>, <string-name><surname>VanRullen</surname> <given-names>R</given-names></string-name></person-group>. <year>2010</year>. <article-title>Spontaneous EEG oscillations reveal periodic sampling of visual attention</article-title>. <source>Proc Natl Acad Sci USA</source> <volume>107</volume>:<fpage>16048</fpage>–<lpage>16053</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1004801107</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Canavier</surname> <given-names>CC</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>S</given-names></string-name>, <string-name><surname>Chandrasekaran</surname> <given-names>L</given-names></string-name></person-group>. <year>2013</year>. <article-title>Effect of phase response curve skew on synchronization with and without conduction delays</article-title>. <source>Front Neural Circuits</source> <volume>7</volume>:<fpage>194</fpage>. doi:<pub-id pub-id-type="doi">10.3389/fncir.2013.00194</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cecere</surname> <given-names>R</given-names></string-name>, <string-name><surname>Rees</surname> <given-names>G</given-names></string-name>, <string-name><surname>Romei</surname> <given-names>V</given-names></string-name></person-group>. <year>2015</year>. <article-title>Individual differences in alpha frequency drive crossmodal illusory perception</article-title>. <source>Curr Biol</source> <volume>25</volume>:<fpage>231</fpage>–<lpage>235</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cub.2014.11.034</pub-id></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chakravarthi</surname> <given-names>R</given-names></string-name>, <string-name><surname>Vanrullen</surname> <given-names>R</given-names></string-name></person-group>. <year>2012</year>. <article-title>Conscious updating is a rhythmic process</article-title>. <source>Proc Natl Acad Sci USA</source> <volume>109</volume>:<fpage>10599</fpage>–<lpage>10604</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1121622109</pub-id></mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cohen</surname> <given-names>MX</given-names></string-name></person-group>. <year>2014a</year>. <article-title>Fluctuations in oscillation frequency control spike timing and coordinate neural networks</article-title>. <source>Journal of Neuroscience</source> <volume>34</volume>:<fpage>8988</fpage>–<lpage>8998</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.0261-14.2014</pub-id></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Cohen</surname> <given-names>MX</given-names></string-name></person-group>. <year>2014b</year>. <source>Analyzing Neural Time Series Data: Theory and Practice</source>, <edition>1st ed</edition>. <publisher-name>The MIT Press</publisher-name>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cooke</surname> <given-names>J</given-names></string-name>, <string-name><surname>Poch</surname> <given-names>C</given-names></string-name>, <string-name><surname>Gillmeister</surname> <given-names>H</given-names></string-name>, <string-name><surname>Costantini</surname> <given-names>M</given-names></string-name>, <string-name><surname>Romei</surname> <given-names>V</given-names></string-name></person-group>. <year>2019</year>. <article-title>Oscillatory Properties of Functional Connections Between Sensory Areas Mediate Cross-Modal Illusory Perception</article-title>. <source>J Neurosci</source> <volume>39</volume>:<fpage>5711</fpage>–<lpage>5718</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.3184-18.2019</pub-id></mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Engel</surname> <given-names>AK</given-names></string-name>, <string-name><surname>Fries</surname> <given-names>P</given-names></string-name>, <string-name><surname>Singer</surname> <given-names>W</given-names></string-name></person-group>. <year>2001</year>. <article-title>Dynamic predictions: oscillations and synchrony in top-down processing</article-title>. <source>Nat Rev Neurosci</source> <volume>2</volume>:<fpage>704</fpage>–<lpage>716</lpage>. doi:<pub-id pub-id-type="doi">10.1038/35094565</pub-id></mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fendrich</surname> <given-names>R</given-names></string-name>, <string-name><surname>Corballis</surname> <given-names>PM</given-names></string-name></person-group>. <year>2001</year>. <article-title>The temporal cross-capture of audition and vision</article-title>. <source>Percept Psychophys</source> <volume>63</volume>:<fpage>719</fpage>–<lpage>725</lpage>. doi:<pub-id pub-id-type="doi">10.3758/bf03194432</pub-id></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gebhard</surname> <given-names>JW</given-names></string-name>, <string-name><surname>Mowbray</surname> <given-names>GH</given-names></string-name></person-group>. <year>1959</year>. <article-title>On discriminating the rate of visual flicker and auditory flutter</article-title>. <source>Am J Psychol</source> <volume>72</volume>:<fpage>521</fpage>. doi:<pub-id pub-id-type="doi">10.2307/1419493</pub-id></mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gray</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Emmanouil</surname> <given-names>TA</given-names></string-name></person-group>. <year>2020</year>. <article-title>Individual alpha frequency increases during a task but is unchanged by alpha-band flicker</article-title>. <source>Psychophysiology</source> <volume>57</volume>:<fpage>e13480</fpage>. doi:<pub-id pub-id-type="doi">10.1111/psyp.13480</pub-id></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gruber</surname> <given-names>WR</given-names></string-name>, <string-name><surname>Zauner</surname> <given-names>A</given-names></string-name>, <string-name><surname>Lechinger</surname> <given-names>J</given-names></string-name>, <string-name><surname>Schabus</surname> <given-names>M</given-names></string-name>, <string-name><surname>Kutil</surname> <given-names>R</given-names></string-name>, <string-name><surname>Klimesch</surname> <given-names>W</given-names></string-name></person-group>. <year>2014</year>. <article-title>Alpha phase, temporal attention, and the generation of early event related potentials</article-title>. <source>Neuroimage</source> <volume>103</volume>:<fpage>119</fpage>–<lpage>129</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.08.055</pub-id></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gulbinaite</surname> <given-names>R</given-names></string-name>, <string-name><surname>van Viegen</surname> <given-names>T</given-names></string-name>, <string-name><surname>Wieling</surname> <given-names>M</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>MX</given-names></string-name>, <string-name><surname>VanRullen</surname> <given-names>R</given-names></string-name></person-group>. <year>2017</year>. <article-title>Individual alpha peak frequency predicts 10 hz flicker effects on selective attention</article-title>. <source>J Neurosci</source> <volume>37</volume>:<fpage>10173</fpage>–<lpage>10184</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.1163-17.2017</pub-id></mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Han</surname> <given-names>B</given-names></string-name>, <string-name><surname>Zhang</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Shen</surname> <given-names>L</given-names></string-name>, <string-name><surname>Mo</surname> <given-names>L</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>Q</given-names></string-name></person-group>. <year>2023</year>. <article-title>Task demands modulate pre-stimulus alpha frequency and sensory template during bistable apparent motion perception</article-title>. <source>Cereb Cortex</source> <volume>33</volume>:<fpage>1679</fpage>–<lpage>1692</lpage>. doi:<pub-id pub-id-type="doi">10.1093/cercor/bhac165</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Harris</surname> <given-names>AM</given-names></string-name></person-group>. <year>2023</year>. <article-title>Phase resets undermine measures of phase-dependent perception</article-title>. <source>Trends Cogn Sci (Regul Ed)</source> <volume>27</volume>:<fpage>224</fpage>–<lpage>226</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.tics.2022.12.008</pub-id></mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kato</surname> <given-names>DD</given-names></string-name>, <string-name><surname>Bruno</surname> <given-names>RM</given-names></string-name></person-group>. <year>2024</year>. <article-title>Stability of cross-sensory input to primary somatosensory cortex across experience</article-title>. <source>Neuron</source>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2024.10.020</pub-id></mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kayser</surname> <given-names>C</given-names></string-name>, <string-name><surname>Petkov</surname> <given-names>CI</given-names></string-name>, <string-name><surname>Logothetis</surname> <given-names>NK</given-names></string-name></person-group>. <year>2008</year>. <article-title>Visual modulation of neurons in auditory cortex</article-title>. <source>Cereb Cortex</source> <volume>18</volume>:<fpage>1560</fpage>–<lpage>1574</lpage>. doi:<pub-id pub-id-type="doi">10.1093/cercor/bhm187</pub-id></mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Keil</surname> <given-names>J</given-names></string-name>, <string-name><surname>Müller</surname> <given-names>N</given-names></string-name>, <string-name><surname>Hartmann</surname> <given-names>T</given-names></string-name>, <string-name><surname>Weisz</surname> <given-names>N</given-names></string-name></person-group>. <year>2014</year>. <article-title>Prestimulus beta power and phase synchrony influence the sound-induced flash illusion</article-title>. <source>Cereb Cortex</source> <volume>24</volume>:<fpage>1278</fpage>–<lpage>1288</lpage>. doi:<pub-id pub-id-type="doi">10.1093/cercor/bhs409</pub-id></mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Keil</surname> <given-names>J</given-names></string-name>, <string-name><surname>Senkowski</surname> <given-names>D</given-names></string-name></person-group>. <year>2017</year>. <article-title>Individual Alpha Frequency Relates to the Sound-Induced Flash Illusion</article-title>. <source>Multisens Res</source> <volume>30</volume>:<fpage>565</fpage>–<lpage>578</lpage>. doi:<pub-id pub-id-type="doi">10.1163/22134808-00002572</pub-id></mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Keitel</surname> <given-names>C</given-names></string-name>, <string-name><surname>Ruzzoli</surname> <given-names>M</given-names></string-name>, <string-name><surname>Dugué</surname> <given-names>L</given-names></string-name>, <string-name><surname>Busch</surname> <given-names>NA</given-names></string-name>, <string-name><surname>Benwell</surname> <given-names>CSY</given-names></string-name></person-group>. <year>2022</year>. <article-title>Rhythms in cognition: The evidence revisited</article-title>. <source>Eur J Neurosci</source> <volume>55</volume>:<fpage>2991</fpage>–<lpage>3009</lpage>. doi:<pub-id pub-id-type="doi">10.1111/ejn.15740</pub-id></mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lakatos</surname> <given-names>P</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>CM</given-names></string-name>, <string-name><surname>O’Connell</surname> <given-names>MN</given-names></string-name>, <string-name><surname>Mills</surname> <given-names>A</given-names></string-name>, <string-name><surname>Schroeder</surname> <given-names>CE</given-names></string-name></person-group>. <year>2007</year>. <article-title>Neuronal oscillations and multisensory interaction in primary auditory cortex</article-title>. <source>Neuron</source> <volume>53</volume>:<fpage>279</fpage>–<lpage>292</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2006.12.011</pub-id></mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lakatos</surname> <given-names>P</given-names></string-name>, <string-name><surname>O’Connell</surname> <given-names>MN</given-names></string-name>, <string-name><surname>Barczak</surname> <given-names>A</given-names></string-name>, <string-name><surname>Mills</surname> <given-names>A</given-names></string-name>, <string-name><surname>Javitt</surname> <given-names>DC</given-names></string-name>, <string-name><surname>Schroeder</surname> <given-names>CE</given-names></string-name></person-group>. <year>2009</year>. <article-title>The leading sense: supramodal control of neurophysiological context by attention</article-title>. <source>Neuron</source> <volume>64</volume>:<fpage>419</fpage>–<lpage>430</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2009.10.014</pub-id></mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Land</surname> <given-names>R</given-names></string-name>, <string-name><surname>Engler</surname> <given-names>G</given-names></string-name>, <string-name><surname>Kral</surname> <given-names>A</given-names></string-name>, <string-name><surname>Engel</surname> <given-names>AK</given-names></string-name></person-group>. <year>2012</year>. <article-title>Auditory evoked bursts in mouse visual cortex during isoflurane anesthesia</article-title>. <source>PLoS ONE</source> <volume>7</volume>:<fpage>e49855</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0049855</pub-id></mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Luo</surname> <given-names>H</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Poeppel</surname> <given-names>D</given-names></string-name></person-group>. <year>2010</year>. <article-title>Auditory cortex tracks both auditory and visual stimulus dynamics using low-frequency neuronal phase modulation</article-title>. <source>PLoS Biol</source> <volume>8</volume>:<fpage>e1000445</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pbio.1000445</pub-id></mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Makeig</surname> <given-names>S</given-names></string-name>, <string-name><surname>Debener</surname> <given-names>S</given-names></string-name>, <string-name><surname>Onton</surname> <given-names>J</given-names></string-name>, <string-name><surname>Delorme</surname> <given-names>A</given-names></string-name></person-group>. <year>2004</year>. <article-title>Mining event-related brain dynamics</article-title>. <source>Trends Cogn Sci (Regul Ed)</source> <volume>8</volume>:<fpage>204</fpage>–<lpage>210</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.tics.2004.03.008</pub-id></mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Maris</surname> <given-names>E</given-names></string-name>, <string-name><surname>Oostenveld</surname> <given-names>R</given-names></string-name></person-group>. <year>2007</year>. <article-title>Nonparametric statistical testing of EEG- and MEG-data</article-title>. <source>J Neurosci Methods</source> <volume>164</volume>:<fpage>177</fpage>–<lpage>190</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.jneumeth.2007.03.024</pub-id></mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mathewson</surname> <given-names>KE</given-names></string-name>, <string-name><surname>Fabiani</surname> <given-names>M</given-names></string-name>, <string-name><surname>Gratton</surname> <given-names>G</given-names></string-name>, <string-name><surname>Beck</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Lleras</surname> <given-names>A</given-names></string-name></person-group>. <year>2010</year>. <article-title>Rescuing stimuli from invisibility: Inducing a momentary release from visual masking with pre-target entrainment</article-title>. <source>Cognition</source> <volume>115</volume>:<fpage>186</fpage>–<lpage>191</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cognition.2009.11.010</pub-id></mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mathewson</surname> <given-names>KE</given-names></string-name>, <string-name><surname>Gratton</surname> <given-names>G</given-names></string-name>, <string-name><surname>Fabiani</surname> <given-names>M</given-names></string-name>, <string-name><surname>Beck</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Ro</surname> <given-names>T</given-names></string-name></person-group>. <year>2009</year>. <article-title>To see or not to see: prestimulus alpha phase predicts visual awareness</article-title>. <source>J Neurosci</source> <volume>29</volume>:<fpage>2725</fpage>–<lpage>2732</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.3963-08.2009</pub-id></mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mégevand</surname> <given-names>P</given-names></string-name>, <string-name><surname>Mercier</surname> <given-names>MR</given-names></string-name>, <string-name><surname>Groppe</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Zion Golumbic</surname> <given-names>E</given-names></string-name>, <string-name><surname>Mesgarani</surname> <given-names>N</given-names></string-name>, <string-name><surname>Beauchamp</surname> <given-names>MS</given-names></string-name>, <string-name><surname>Schroeder</surname> <given-names>CE</given-names></string-name>, <string-name><surname>Mehta</surname> <given-names>AD</given-names></string-name></person-group>. <year>2020</year>. <article-title>Crossmodal phase reset and evoked responses provide complementary mechanisms for the influence of visual speech in auditory cortex</article-title>. <source>J Neurosci</source> <volume>40</volume>:<fpage>8530</fpage>–<lpage>8542</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.0555-20.2020</pub-id></mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mercier</surname> <given-names>MR</given-names></string-name>, <string-name><surname>Foxe</surname> <given-names>JJ</given-names></string-name>, <string-name><surname>Fiebelkorn</surname> <given-names>IC</given-names></string-name>, <string-name><surname>Butler</surname> <given-names>JS</given-names></string-name>, <string-name><surname>Schwartz</surname> <given-names>TH</given-names></string-name>, <string-name><surname>Molholm</surname> <given-names>S</given-names></string-name></person-group>. <year>2013</year>. <article-title>Auditory-driven phase reset in visual cortex: human electrocorticography reveals mechanisms of early multisensory integration</article-title>. <source>Neuroimage</source> <volume>79</volume>:<fpage>19</fpage>–<lpage>29</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.04.060</pub-id></mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mercier</surname> <given-names>MR</given-names></string-name>, <string-name><surname>Molholm</surname> <given-names>S</given-names></string-name>, <string-name><surname>Fiebelkorn</surname> <given-names>IC</given-names></string-name>, <string-name><surname>Butler</surname> <given-names>JS</given-names></string-name>, <string-name><surname>Schwartz</surname> <given-names>TH</given-names></string-name>, <string-name><surname>Foxe</surname> <given-names>JJ</given-names></string-name></person-group>. <year>2015</year>. <article-title>Neuro-oscillatory phase alignment drives speeded multisensory response times: an electro-corticographic investigation</article-title>. <source>J Neurosci</source> <volume>35</volume>:<fpage>8546</fpage>–<lpage>8557</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.4527-14.2015</pub-id></mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Milton</surname> <given-names>A</given-names></string-name>, <string-name><surname>Pleydell-Pearce</surname> <given-names>CW</given-names></string-name></person-group>. <year>2016</year>. <article-title>The phase of pre-stimulus alpha oscillations influences the visual perception of stimulus timing</article-title>. <source>Neuroimage</source> <volume>133</volume>:<fpage>53</fpage>–<lpage>61</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.02.065</pub-id></mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Neuling</surname> <given-names>T</given-names></string-name>, <string-name><surname>Rach</surname> <given-names>S</given-names></string-name>, <string-name><surname>Wagner</surname> <given-names>S</given-names></string-name>, <string-name><surname>Wolters</surname> <given-names>CH</given-names></string-name>, <string-name><surname>Herrmann</surname> <given-names>CS</given-names></string-name></person-group>. <year>2012</year>. <article-title>Good vibrations: oscillatory phase shapes perception</article-title>. <source>Neuroimage</source> <volume>63</volume>:<fpage>771</fpage>–<lpage>778</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.07.024</pub-id></mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ng</surname> <given-names>BSW</given-names></string-name>, <string-name><surname>Schroeder</surname> <given-names>T</given-names></string-name>, <string-name><surname>Kayser</surname> <given-names>C</given-names></string-name></person-group>. <year>2012</year>. <article-title>A precluding but not ensuring role of entrained low-frequency oscillations for auditory perception</article-title>. <source>J Neurosci</source> <volume>32</volume>:<fpage>12268</fpage>–<lpage>12276</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.1877-12.2012</pub-id></mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Oeur</surname> <given-names>RA</given-names></string-name>, <string-name><surname>Palaniswamy</surname> <given-names>M</given-names></string-name>, <string-name><surname>Ha</surname> <given-names>M</given-names></string-name>, <string-name><surname>Fernandez-Corazza</surname> <given-names>M</given-names></string-name>, <string-name><surname>Margulies</surname> <given-names>SS</given-names></string-name></person-group>. <year>2023</year>. <article-title>Regional variations distinguish auditory from visual evoked potentials in healthy 4 week old piglets</article-title>. <source>Physiol Meas</source> <volume>44</volume>. doi:<pub-id pub-id-type="doi">10.1088/1361-6579/acb4da</pub-id></mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Oostenveld</surname> <given-names>R</given-names></string-name>, <string-name><surname>Fries</surname> <given-names>P</given-names></string-name>, <string-name><surname>Maris</surname> <given-names>E</given-names></string-name>, <string-name><surname>Schoffelen</surname> <given-names>J-M</given-names></string-name></person-group>. <year>2011</year>. <article-title>FieldTrip: Open source software for advanced analysis of MEG, EEG, and invasive electrophysiological data</article-title>. <source>Comput Intell Neurosci</source> <volume>2011</volume>:<fpage>156869</fpage>. doi:<pub-id pub-id-type="doi">10.1155/2011/156869</pub-id></mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rohe</surname> <given-names>T</given-names></string-name>, <string-name><surname>Ehlis</surname> <given-names>A-C</given-names></string-name>, <string-name><surname>Noppeney</surname> <given-names>U</given-names></string-name></person-group>. <year>2019</year>. <article-title>The neural dynamics of hierarchical Bayesian causal inference in multisensory perception</article-title>. <source>Nat Commun</source> <volume>10</volume>:<fpage>1907</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41467-019-09664-2</pub-id></mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Romei</surname> <given-names>V</given-names></string-name>, <string-name><surname>Gross</surname> <given-names>J</given-names></string-name>, <string-name><surname>Thut</surname> <given-names>G</given-names></string-name></person-group>. <year>2012</year>. <article-title>Sounds reset rhythms of visual cortex and corresponding human visual perception</article-title>. <source>Curr Biol</source> <volume>22</volume>:<fpage>807</fpage>–<lpage>813</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cub.2012.03.025</pub-id></mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ronconi</surname> <given-names>L</given-names></string-name>, <string-name><surname>Oosterhof</surname> <given-names>NN</given-names></string-name>, <string-name><surname>Bonmassar</surname> <given-names>C</given-names></string-name>, <string-name><surname>Melcher</surname> <given-names>D</given-names></string-name></person-group>. <year>2017</year>. <article-title>Multiple oscillatory rhythms determine the temporal organization of perception</article-title>. <source>Proc Natl Acad Sci USA</source> <volume>114</volume>:<fpage>13435</fpage>–<lpage>13440</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1714522114</pub-id></mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ruzzoli</surname> <given-names>M</given-names></string-name>, <string-name><surname>Torralba</surname> <given-names>M</given-names></string-name>, <string-name><surname>Morís Fernández</surname> <given-names>L</given-names></string-name>, <string-name><surname>Soto-Faraco</surname> <given-names>S</given-names></string-name></person-group>. <year>2019</year>. <article-title>The relevance of alpha phase in human perception</article-title>. <source>Cortex</source> <volume>120</volume>:<fpage>249</fpage>–<lpage>268</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cortex.2019.05.012</pub-id></mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Samaha</surname> <given-names>J</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>MX</given-names></string-name></person-group>. <year>2022</year>. <article-title>Power spectrum slope confounds estimation of instantaneous oscillatory frequency</article-title>. <source>Neuroimage</source> <volume>250</volume>:<fpage>118929</fpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2022.118929</pub-id></mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Samaha</surname> <given-names>J</given-names></string-name>, <string-name><surname>Postle</surname> <given-names>BR</given-names></string-name></person-group>. <year>2015</year>. <article-title>The Speed of Alpha-Band Oscillations Predicts the Temporal Resolution of Visual Perception</article-title>. <source>Curr Biol</source> <volume>25</volume>:<fpage>2985</fpage>–<lpage>2990</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cub.2015.10.007</pub-id></mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schyns</surname> <given-names>PG</given-names></string-name>, <string-name><surname>Thut</surname> <given-names>G</given-names></string-name>, <string-name><surname>Gross</surname> <given-names>J</given-names></string-name></person-group>. <year>2011</year>. <article-title>Cracking the code of oscillatory activity</article-title>. <source>PLoS Biol</source> <volume>9</volume>:<fpage>e1001064</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pbio.1001064</pub-id></mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Senkowski</surname> <given-names>D</given-names></string-name>, <string-name><surname>Engel</surname> <given-names>AK</given-names></string-name></person-group>. <year>2024</year>. <article-title>Multi-timescale neural dynamics for multisensory integration</article-title>. <source>Nat Rev Neurosci</source> <volume>25</volume>:<fpage>625</fpage>–<lpage>642</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41583-024-00845-7</pub-id></mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shah</surname> <given-names>AS</given-names></string-name>, <string-name><surname>Bressler</surname> <given-names>SL</given-names></string-name>, <string-name><surname>Knuth</surname> <given-names>KH</given-names></string-name>, <string-name><surname>Ding</surname> <given-names>M</given-names></string-name>, <string-name><surname>Mehta</surname> <given-names>AD</given-names></string-name>, <string-name><surname>Ulbert</surname> <given-names>I</given-names></string-name>, <string-name><surname>Schroeder</surname> <given-names>CE</given-names></string-name></person-group>. <year>2004</year>. <article-title>Neural dynamics and the fundamental mechanisms of event-related brain potentials</article-title>. <source>Cereb Cortex</source> <volume>14</volume>:<fpage>476</fpage>–<lpage>483</lpage>. doi:<pub-id pub-id-type="doi">10.1093/cercor/bhh009</pub-id></mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shams</surname> <given-names>L</given-names></string-name>, <string-name><surname>Kamitani</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Shimojo</surname> <given-names>S</given-names></string-name></person-group>. <year>2002</year>. <article-title>Visual illusion induced by sound</article-title>. <source>Brain Res Cogn Brain Res</source> <volume>14</volume>:<fpage>147</fpage>–<lpage>152</lpage>. doi:<pub-id pub-id-type="doi">10.1016/S0926-6410(02)00069-1</pub-id></mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shen</surname> <given-names>L</given-names></string-name>, <string-name><surname>Han</surname> <given-names>B</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>L</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>Q</given-names></string-name></person-group>. <year>2019</year>. <article-title>Perceptual inference employs intrinsic alpha frequency to resolve perceptual ambiguity</article-title>. <source>PLoS Biol</source> <volume>17</volume>:<fpage>e3000025</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pbio.3000025</pub-id></mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shimojo</surname> <given-names>S</given-names></string-name>, <string-name><surname>Scheier</surname> <given-names>C</given-names></string-name>, <string-name><surname>Nijhawan</surname> <given-names>R</given-names></string-name>, <string-name><surname>Shams</surname> <given-names>L</given-names></string-name>, <string-name><surname>Kamitani</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Watanabe</surname> <given-names>K</given-names></string-name></person-group>. <year>2001</year>. <article-title>Beyond perceptual modality: Auditory effects on visual perception</article-title>. <source>Acoust Sci &amp; Tech</source> <volume>22</volume>:<fpage>61</fpage>–<lpage>67</lpage>. doi:<pub-id pub-id-type="doi">10.1250/ast.22.61</pub-id></mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shipley</surname> <given-names>T</given-names></string-name></person-group>. <year>1964</year>. <article-title>Auditory flutter-driving of visual flicker</article-title>. <source>Science</source> <volume>145</volume>:<fpage>1328</fpage>–<lpage>1330</lpage>. doi:<pub-id pub-id-type="doi">10.1126/science.145.3638.1328</pub-id></mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ten Oever</surname> <given-names>S</given-names></string-name>, <string-name><surname>Meierdierks</surname> <given-names>T</given-names></string-name>, <string-name><surname>Duecker</surname> <given-names>F</given-names></string-name>, <string-name><surname>De Graaf</surname> <given-names>TA</given-names></string-name>, <string-name><surname>Sack</surname> <given-names>AT</given-names></string-name></person-group>. <year>2020</year>. <article-title>Phase-Coded Oscillatory Ordering Promotes the Separation of Closely Matched Representations to Optimize Perceptual Discrimination</article-title>. <source>iScience</source> <volume>23</volume>:<fpage>101282</fpage>. doi:<pub-id pub-id-type="doi">10.1016/j.isci.2020.101282</pub-id></mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Thorne</surname> <given-names>JD</given-names></string-name>, <string-name><surname>De Vos</surname> <given-names>M</given-names></string-name>, <string-name><surname>Viola</surname> <given-names>FC</given-names></string-name>, <string-name><surname>Debener</surname> <given-names>S</given-names></string-name></person-group>. <year>2011</year>. <article-title>Cross-modal phase reset predicts auditory task performance in humans</article-title>. <source>J Neurosci</source> <volume>31</volume>:<fpage>3853</fpage>–<lpage>3861</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.6176-10.2011</pub-id></mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>VanRullen</surname> <given-names>R</given-names></string-name></person-group>. <year>2016a</year>. <article-title>How to Evaluate Phase Differences between Trial Groups in Ongoing Electrophysiological Signals</article-title>. <source>Front Neurosci</source> <volume>10</volume>:<fpage>426</fpage>. doi:<pub-id pub-id-type="doi">10.3389/fnins.2016.00426</pub-id></mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>VanRullen</surname> <given-names>R</given-names></string-name></person-group>. <year>2016b</year>. <article-title>Perceptual Cycles</article-title>. <source>Trends Cogn Sci (Regul Ed)</source> <volume>20</volume>:<fpage>723</fpage>–<lpage>735</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.tics.2016.07.006</pub-id></mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van Diepen</surname> <given-names>RM</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>MX</given-names></string-name>, <string-name><surname>Denys</surname> <given-names>D</given-names></string-name>, <string-name><surname>Mazaheri</surname> <given-names>A</given-names></string-name></person-group>. <year>2015</year>. <article-title>Attention and temporal expectations modulate power, not phase, of ongoing alpha oscillations</article-title>. <source>J Cogn Neurosci</source> <volume>27</volume>:<fpage>1573</fpage>–<lpage>1586</lpage>. doi:<pub-id pub-id-type="doi">10.1162/jocn_a_00803</pub-id></mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vinck</surname> <given-names>M</given-names></string-name>, <string-name><surname>van Wingerden</surname> <given-names>M</given-names></string-name>, <string-name><surname>Womelsdorf</surname> <given-names>T</given-names></string-name>, <string-name><surname>Fries</surname> <given-names>P</given-names></string-name>, <string-name><surname>Pennartz</surname> <given-names>CMA</given-names></string-name></person-group>. <year>2010</year>. <article-title>The pairwise phase consistency: a bias-free measure of rhythmic neuronal synchronization</article-title>. <source>Neuroimage</source> <volume>51</volume>:<fpage>112</fpage>–<lpage>122</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.01.073</pub-id></mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Walker</surname> <given-names>JT</given-names></string-name>, <string-name><surname>Scott</surname> <given-names>KJ</given-names></string-name></person-group>. <year>1981</year>. <article-title>Auditory-visual conflicts in the perceived duration of lights, tones and gaps</article-title>. <source>J Exp Psychol Hum Percept Perform</source> <volume>7</volume>:<fpage>1327</fpage>–<lpage>1339</lpage>. doi:<pub-id pub-id-type="doi">10.1037//0096-1523.7.6.1327</pub-id></mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Watkins</surname> <given-names>S</given-names></string-name>, <string-name><surname>Shams</surname> <given-names>L</given-names></string-name>, <string-name><surname>Josephs</surname> <given-names>O</given-names></string-name>, <string-name><surname>Rees</surname> <given-names>G</given-names></string-name></person-group>. <year>2007</year>. <article-title>Activity in human V1 follows multisensory perception</article-title>. <source>Neuroimage</source> <volume>37</volume>:<fpage>572</fpage>–<lpage>578</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.05.027</pub-id></mixed-citation></ref>
<ref id="c65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Watkins</surname> <given-names>S</given-names></string-name>, <string-name><surname>Shams</surname> <given-names>L</given-names></string-name>, <string-name><surname>Tanaka</surname> <given-names>S</given-names></string-name>, <string-name><surname>Haynes</surname> <given-names>JD</given-names></string-name>, <string-name><surname>Rees</surname> <given-names>G</given-names></string-name></person-group>. <year>2006</year>. <article-title>Sound alters activity in human V1 in association with illusory visual perception</article-title>. <source>Neuroimage</source> <volume>31</volume>:<fpage>1247</fpage>–<lpage>1256</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.01.016</pub-id></mixed-citation></ref>
<ref id="c66"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Welch</surname> <given-names>RB</given-names></string-name>, <string-name><surname>DuttonHurt</surname> <given-names>LD</given-names></string-name>, <string-name><surname>Warren</surname> <given-names>DH</given-names></string-name></person-group>. <year>1986</year>. <article-title>Contributions of audition and vision to temporal rate perception</article-title>. <source>Percept Psychophys</source> <volume>39</volume>:<fpage>294</fpage>–<lpage>300</lpage>. doi:<pub-id pub-id-type="doi">10.3758/bf03204939</pub-id></mixed-citation></ref>
<ref id="c67"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wutz</surname> <given-names>A</given-names></string-name>, <string-name><surname>Melcher</surname> <given-names>D</given-names></string-name>, <string-name><surname>Samaha</surname> <given-names>J</given-names></string-name></person-group>. <year>2018</year>. <article-title>Frequency modulation of neural oscillations according to visual task demands</article-title>. <source>Proc Natl Acad Sci USA</source> <volume>115</volume>:<fpage>1346</fpage>–<lpage>1351</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1713318115</pub-id></mixed-citation></ref>
<ref id="c68"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wutz</surname> <given-names>A</given-names></string-name>, <string-name><surname>Weisz</surname> <given-names>N</given-names></string-name>, <string-name><surname>Braun</surname> <given-names>C</given-names></string-name>, <string-name><surname>Melcher</surname> <given-names>D</given-names></string-name></person-group>. <year>2014</year>. <article-title>Temporal windows in visual processing: “prestimulus brain state” and “poststimulus phase reset” segregate visual transients on different temporal scales</article-title>. <source>J Neurosci</source> <volume>34</volume>:<fpage>1554</fpage>–<lpage>1565</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.3187-13.2014</pub-id></mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.105531.1.sa4</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>van Gaal</surname>
<given-names>Simon</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Amsterdam</institution>
</institution-wrap>
<city>Amsterdam</city>
<country>Netherlands</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study provides <bold>valuable</bold> insights into how auditory stimuli influence the temporal dynamics of visual perception by modulating brain rhythms (oscillations) in the alpha band. The authors present <bold>convincing</bold> evidence that auditory input induces a drop in visual alpha frequency, increasing the time window for audio-visual integration, and subsequently shifting the predictive role from prestimulus alpha frequency to alpha phase. The conclusions are well-supported by the combination of psychophysics, electrophysiological recordings (EEG), non-invasive brain stimulation (tACS), and computational modelling.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.105531.1.sa3</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Is peristimulus alpha (8-14 Hz) frequency and/or phase involved in shaping the length of visual and audiovisual temporal binding windows, as posited by the discrete sampling hypothesis? If so, to what extent and perceptual scenario are they functionally relevant? The authors addressed such questions by collecting EEG data during the completion of the widely-known 2-flash fusion paradigm, administered both in a standard (i.e., visual only, F2) and audiovisual (i.e., 2 flashes and 1 beep, F2B1) fashion. Instantaneous frequency estimation performed over parieto-occipital sensors revealed slower alpha rhythms right after stimulus onset in the F2B1 condition, as compared to the F2, a pattern found to correlate with the difference between modality-specific ISIs (F2B1-F2). Of note, peristimulus alpha frequency differed also between 1 vs 2 flashes reports, although in the visual modality only (i.e., faster alpha oscillations in 2 flash percept vs 1 flash). This pattern of results was reinvigorated in a causal manner via occipital tACS, which was capable of, respectively, narrowing down vs enlarging the temporal binding window of individuals undergoing 13 Hz vs 8 Hz stimulation in the F2 modality alone. To elucidate what the oscillatory signatures of crossmodal integration might be, the authors further focused on the phase of posterior alpha rhythms. Accordingly, the Phase Opposition Sum proved to significantly differ between modalities (F2B1 vs F2) during the prestimulus time window, suggesting that audiovisual signals undergo finer processing based on the ongoing phase of occipital alpha oscillations, rather than the speed at which these rhythms cycle. As a last bit of information, a computational model factoring in the electrophysiological assumptions of both the discrete sampling hypothesis and auditory-induced phase-resetting was devised. Analyses run on such synthetic data were partially able to reproduce the patterns witnessed in the empirical dataset. While faster frequency rates broadly provide a higher probability to detect 2 flashes instead of 1, the occurrence of a concurrent auditory signal in cross-modal trials should cause a transient elongation (i.e. slower frequency rate) of the ongoing alpha cycle due to phase-reset dynamics (as revealed via inter-trial phase clustering), prompting larger ISIs during F2B1 trials. Conversely, the model provides that alpha oscillatory phase might predict how well an observer dissociates sensory information from noise (i.e., perceptual clarity), with the second flash clearly perceived as such as long as it falls within specific phase windows along the alpha cycle.</p>
<p>Strengths:</p>
<p>The authors leveraged complementary approaches (EEG, tACS, and computational modelling), the results thereof not only integrate, but depict an overarching mechanistic scenario elegantly framing phase-resetting dynamics into the broader theoretical architecture posited by the discrete sampling hypothesis. Analyses on brain oscillations (either via frequency sliding and phase opposition sum) mostly appear to be methodologically sound, and very-well supported by tACS results. Under this perspective, the modelling approach serves as a convenient tool to reconcile and shed more light on the pieces of evidence gathered on empirical data, returning an appealing account on how cross-modal stimuli interplay with ongoing alpha rhythms and differentially affect multisensory processing in humans.</p>
<p>Weaknesses:</p>
<p>Some information relative to the task and the analyses is missing. For instance, it is not entirely clear from the text what the number of flashes actually displayed in explicit short trials is (1 or 2?). We believe it is always two, but it should be explicitly stated.</p>
<p>Moreover, the sample size might be an issue. As highlighted by a recent meta-analysis on the matter (Samaha &amp; Romei, 2024), an underpowered sample size may very well drive null-findings relative to tACS data in F2B1 trials, in interplay with broad and un-individualized frequency targets.</p>
<p>Some criticality arises regarding the actual &quot;bistability&quot; of bistable trials, as the statistics relative to the main task (i.e., the actual means and SEMs are missing) broadly point toward a higher proclivity to report 2 instead of 1 flash in both F2B1 and F2 trials. This makes sense to some extent, given that 2 flashes have always been displayed (at least in bistable trials), yet tells about something botched during the pretest titration procedure.</p>
<p>Coming to the analyses on brain waves, one main concern relates to the phase-reset-induced slow-down of posterior alpha rhythms being of true oscillatory nature, rather than a mere evoked response (i.e., not sustained over time). Another question calling for some further scrutiny regards the overlooked pattern linking the temporal extent of the IAF differences between F2 and F2B1 trials with the ISIs across experimental conditions (explicit short, bistable, and explicit long). That is, the wider the ISI, the longer the temporal extent of the IAF difference between sensory modalities. Although neglected by the authors, such a trend speaks in favour of a rather nuanced scenario stemming from not only auditory-induced phase-reset alpha cycle elongation, but also some non-linear and perhaps super-additive contribution of flash-induced phase-resetting. This consideration introduces some of the issues about the computational simulation, which was modelled around the assumption of phase-resetting being triggered by acoustic stimuli alone. Given how appealing the model already is, I wonder whether the authors might refine the model accordingly and integrate the phase-resetting impact of visual stimuli upon synthetic alpha rhythms. Relatedly, I would also suggest the authors to throw in a few more simulations to explore the parameter space and assay, to which quantitative extent the model still holds (e.g. allowing alpha frequency to randomly change within a range between 8 and 13 Hz, or pivoting the phase delay around 10 or 50 ms). As a last remark, I would avoid, or at least tone down, concluding that the results hereby presented might reconcile and/or explain the null effects in Buergers &amp; Noppeney, 2022; as the relationship between IAFs and audiovisual abilities still holds when examining other cross-modal paradigms such as the Sound-Induced Flash-Illusion (Noguchi, 2022), and the aforementioned patterns might be due to other factors, such as a too small sample size (Samaha &amp; Romei, 2024).</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.105531.1.sa2</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The authors used a visual flash discrimination task in which two flashes are presented one after another with different inter-stimulus intervals. Participants either perceive one flash or two flashes. The authors show that the simultaneous presence of an auditory input extends the temporal window of integration, meaning that two flashes presented shortly after one another are more likely to be perceived as a single flash. Auditory inputs are accompanied by a reduction in alpha frequency over visual areas. Prestimulus alpha frequency predicts perceptual outcomes in the absence of auditory stimuli, whereas prestimulus alpha phase becomes the dominant predictor when auditory input is present. A computational model based on phase-resetting theory supports these findings. Additionally, a transcranial stimulation experiment confirms the causal role of alpha frequency in unimodal visual perception but not in cross-modal contexts.</p>
<p>Strengths:</p>
<p>The authors elegantly combined several approaches-from behavior to computational modeling and EEG-to provide a comprehensive overview of the mechanisms involved in visual integration in the presence or absence of auditory input. The methods used are state-of-the-art, and the authors attempted to address possible pitfalls.</p>
<p>Weaknesses:</p>
<p>The use of Bayesian statistics could further strengthen the paper, especially given that a few p-values are close to the significance threshold (lines 162 &amp; 258), but they are interpreted differently in different cases (absence of effect vs. trend).</p>
<p>Overall, these results provide new insights into the role of alpha oscillations in visual processing and offer an interesting perspective on the current debate regarding the roles of alpha phase and frequency in visual perception. More generally, they contribute to our understanding of the neural dynamics of multisensory integration.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.105531.1.sa1</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The authors investigated the impact of an auditory stimulus on visual integration at the behavioral, electrophysiological, and mechanistic levels. Although the role of alpha brain oscillations on visual perception has been widely studied, how the brain dynamics in the visual cortices are influenced by a cross-modal stimulus remains ill-defined. The authors demonstrated that auditory stimulation systematically induced a drop in visual alpha frequency, increasing the time window for audio-visual integration, while in the unimodal condition, visual integration was modulated by small variations within the alpha frequency range. In addition, they only found a role of the phase of alpha brain oscillations on visual perception in the cross-modal condition. Based on the perceptual cycles' theory framework, the authors developed a model allowing them to describe their results according to a phase resetting induced by the auditory stimulation. These results showed that the influence of well-known brain dynamics on one modality can be disrupted by another modality. They provided insights into the importance of investigating cross-modal brain dynamics, and an interesting model that extends the perceptual cycle framework.</p>
<p>Strengths:</p>
<p>The results are supported by a combination of various, established experimental and analysis approaches (e.g., two-flash fusion task, psychometric curves, phase opposition), ensuring strong methodological bases and allowing direct comparisons with related findings in the literature.</p>
<p>The model the authors proposed is an extension and an improvement of the perceptual cycle's framework. Interestingly, this model could then be tested in other experimental approaches.</p>
<p>Weaknesses:</p>
<p>There is an increasing number of studies in cognitive neuroscience showing the importance of considering inter-individual variability. The individual alpha frequency (IAF) varied from 8 to 13 Hz with a huge variability across participants, and studies have shown that the IAF influenced visual perception. Investigating inter-individual variations of the IAF in the reported results would be of great interest, especially for the model.</p>
<p>Although the use of non-invasive brain stimulation to infer causality is a method of great interest, the use of tACS in the presented work is not optimal. Instead of inducing alpha brain oscillations in visual cortices, the use of tACS to activate the auditory cortex instead of the actual auditory stimulation would have presented more interest.</p>
</body>
</sub-article>
<sub-article id="sa4" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.105531.1.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Xu</surname>
<given-names>Mengting</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Han</surname>
<given-names>Biao</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Chen</surname>
<given-names>Qi</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Shen</surname>
<given-names>Lu</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<disp-quote content-type="editor-comment">
<p><bold>Public Reviews:</bold></p>
<p><bold>Reviewer #1 (Public review):</bold></p>
<p>Summary:</p>
<p>Is peristimulus alpha (8-14 Hz) frequency and/or phase involved in shaping the length of visual and audiovisual temporal binding windows, as posited by the discrete sampling hypothesis? If so, to what extent and perceptual scenario are they functionally relevant? The authors addressed such questions by collecting EEG data during the completion of the widely-known 2-flash fusion paradigm, administered both in a standard (i.e., visual only, F2) and audiovisual (i.e., 2 flashes and 1 beep, F2B1) fashion. Instantaneous frequency estimation performed over parieto-occipital sensors revealed slower alpha rhythms right after stimulus onset in the F2B1 condition, as compared to the F2, a pattern found to correlate with the difference between modality-specific ISIs (F2B1-F2). Of note, peristimulus alpha frequency differed also between 1 vs 2 flashes reports, although in the visual modality only (i.e., faster alpha oscillations in 2 flash percept vs 1 flash). This pattern of results was reinvigorated in a causal manner via occipital tACS, which was capable of, respectively, narrowing down vs enlarging the temporal binding window of individuals undergoing 13 Hz vs 8 Hz stimulation in the F2 modality alone. To elucidate what the oscillatory signatures of crossmodal integration might be, the authors further focused on the phase of posterior alpha rhythms. Accordingly, the Phase Opposition Sum proved to significantly differ between modalities (F2B1 vs F2) during the prestimulus time window, suggesting that audiovisual signals undergo finer processing based on the ongoing phase of occipital alpha oscillations, rather than the speed at which these rhythms cycle. As a last bit of information, a computational model factoring in the electrophysiological assumptions of both the discrete sampling hypothesis and auditory-induced phase-resetting was devised. Analyses run on such synthetic data were partially able to reproduce the patterns witnessed in the empirical dataset. While faster frequency rates broadly provide a higher probability to detect 2 flashes instead of 1, the occurrence of a concurrent auditory signal in cross-modal trials should cause a transient elongation (i.e. slower frequency rate) of the ongoing alpha cycle due to phase-reset dynamics (as revealed via inter-trial phase clustering), prompting larger ISIs during F2B1 trials. Conversely, the model provides that alpha oscillatory phase might predict how well an observer dissociates sensory information from noise (i.e., perceptual clarity), with the second flash clearly perceived as such as long as it falls within specific phase windows along the alpha cycle.</p>
<p>Strengths:</p>
<p>The authors leveraged complementary approaches (EEG, tACS, and computational modelling), the results thereof not only integrate, but depict an overarching mechanistic scenario elegantly framing phase-resetting dynamics into the broader theoretical architecture posited by the discrete sampling hypothesis. Analyses on brain oscillations (either via frequency sliding and phase opposition sum) mostly appear to be methodologically sound, and very-well supported by tACS results. Under this perspective, the modelling approach serves as a convenient tool to reconcile and shed more light on the pieces of evidence gathered on empirical data, returning an appealing account on how cross-modal stimuli interplay with ongoing alpha rhythms and differentially affect multisensory processing in humans.</p>
<p>Weaknesses:</p>
<p>Some information relative to the task and the analyses is missing. For instance, it is not entirely clear from the text what the number of flashes actually displayed in explicit short trials is (1 or 2?). We believe it is always two, but it should be explicitly stated.</p>
</disp-quote>
<p>We thank the reviewer for highlighting this important point. In our study, all explicit trials consistently presented two flashes. We will clearly state this detail in the Methods section to avoid any further confusion.</p>
<disp-quote content-type="editor-comment">
<p>Moreover, the sample size might be an issue. As highlighted by a recent meta-analysis on the matter (Samaha &amp; Romei, 2024), an underpowered sample size may very well drive null-findings relative to tACS data in F2B1 trials, in interplay with broad and un-individualized frequency targets.</p>
</disp-quote>
<p>We thank the reviewer for raising this point. First, we would like to clarify that our results do not suggest that the frequency effect is absent in the F2B1 condition; rather, it is relatively attenuated compared to the F2 condition. If the sample size were the primary issue, we would expect to observe a null effect in both conditions. Instead, the stronger frequency modulation in F2 confirms that the sound-induced modulation is present, albeit reduced in the audiovisual context. In our revised manuscript, we will explicitly note that our claim is not that there is no frequency effect in F2B1 but that the effect is weaker relative to F2, and we will also acknowledge the potential limitations associated with sample size and the lack of individualized frequency targeting.</p>
<disp-quote content-type="editor-comment">
<p>Some criticality arises regarding the actual &quot;bistability&quot; of bistable trials, as the statistics relative to the main task (i.e., the actual means and SEMs are missing) broadly point toward a higher proclivity to report 2 instead of 1 flash in both F2B1 and F2 trials. This makes sense to some extent, given that 2 flashes have always been displayed (at least in bistable trials), yet tells about something botched during the pretest titration procedure.</p>
</disp-quote>
<p>We thank the reviewer for pointing out the potential bias toward reporting “two flashes” in the bistable trials. Because our experimental design involves presenting two flashes in both explicit and bistable trials, a slight tendency to report two flashes may naturally arise, especially at threshold levels determined during pretesting. We believe, however, that this bias does not undermine our primary findings. Our psychophysical procedure is designed to align the inter-stimulus interval with each participant’s fusion threshold, aiming for a near 50/50 split between “one-flash” and “two-flash” reports. However, given that two flashes are always presented, participants may be predisposed to report two flashes when uncertain. This reflects a plausible perceptual bias inherent in the bistable design, rather than a systematic flaw. Importantly, this tendency appears at comparable levels in both the F2 and F2B1 conditions, indicating that it does not selectively affect any particular condition. In the revised manuscript, we will include additional descriptive statistics, such as means and standard deviations, to demonstrate that the observed bias remains within an acceptable range and does not compromise our core conclusions regarding the modulatory effect of auditory input on visual integration.</p>
<disp-quote content-type="editor-comment">
<p>Coming to the analyses on brain waves, one main concern relates to the phase-reset-induced slow-down of posterior alpha rhythms being of true oscillatory nature, rather than a mere evoked response (i.e., not sustained over time).</p>
</disp-quote>
<p>We appreciate the reviewer’s concern regarding this issue. First, the sustained decrease in posterior alpha frequency observed in our study—persisting for approximately 280 ms—substantially exceeds the typical duration of an auditory evoked potential (generally 50–200 ms) (Näätänen and Picton, 1987). This extended period of modulation suggests that it is not merely a transient evoked response.</p>
<p>Second, our analysis of alpha power further supports this interpretation. A purely evoked response is usually accompanied by a corresponding increase in signal power; however, our results show no such power increase when comparing the F2B1 condition with the F2 condition.</p>
<p>Moreover, the observed increase in alpha phase resetting—as measured by inter-trial phase coherence (ITC)—does not significantly correlate with changes in alpha power. This dissociation further indicates that the auditory-induced effects are unlikely to be driven solely by evoked potentials, but are more consistent with a reorganization of the intrinsic neural oscillatory activity.</p>
<p>Together, these lines of evidence strongly support the view that the auditory-induced decrease in alpha frequency reflects true changes in ongoing oscillatory dynamics, rather than being merely a transient evoked response.</p>
<disp-quote content-type="editor-comment">
<p>Another question calling for some further scrutiny regards the overlooked pattern linking the temporal extent of the IAF differences between F2 and F2B1 trials with the ISIs across experimental conditions (explicit short, bistable, and explicit long). That is, the wider the ISI, the longer the temporal extent of the IAF difference between sensory modalities. Although neglected by the authors, such a trend speaks in favour of a rather nuanced scenario stemming from not only auditory-induced phase-reset alpha cycle elongation, but also some non-linear and perhaps super-additive contribution of flash-induced phase-resetting. This consideration introduces some of the issues about the computational simulation, which was modelled around the assumption of phase-resetting being triggered by acoustic stimuli alone. Given how appealing the model already is, I wonder whether the authors might refine the model accordingly and integrate the phase-resetting impact of visual stimuli upon synthetic alpha rhythms.</p>
</disp-quote>
<p>We appreciate the reviewer’s insightful comment regarding the potential influence of flash-induced phase resetting on the temporal extent of the IAF differences. We acknowledge that the observation—that wider ISIs are associated with a longer period of IAF differences—hints at a non-linear or even super-additive interaction between auditory- and flash-induced phase resetting mechanisms.</p>
<p>However, the primary focus of our current study is on how auditory stimuli affect alpha oscillatory dynamics. Our experimental design and computational model were specifically optimized to capture auditory-induced phase resetting. Incorporating the additional influence of flash-induced effects would require a significantly more refined experimental framework and a more complex modeling approach. This added complexity could obscure the interpretation of our main findings, which are centered on auditory influences.</p>
<p>In the revised manuscript, we will address this intriguing possibility in the Discussion section. We will acknowledge that while the data hint at a potential visual contribution, our present model deliberately isolates auditory-induced phase resetting to maintain clarity. We also propose that future research, with more precise experimental designs and enhanced modeling techniques, is necessary to fully disentangle and capture the interplay between auditory and flash-induced phase resetting mechanisms.</p>
<disp-quote content-type="editor-comment">
<p>Relatedly, I would also suggest the authors to throw in a few more simulations to explore the parameter space and assay, to which quantitative extent the model still holds (e.g. allowing alpha frequency to randomly change within a range between 8 and 13 Hz, or pivoting the phase delay around 10 or 50 ms).</p>
</disp-quote>
<p>We appreciate the reviewer’s suggestion to further explore our model’s parameter space. In response, we will conduct additional simulations that incorporate variability in alpha frequency—sampling randomly between 8 and 13 Hz—and examine alternative phase delays (e.g., around 10 and 50 ms). By systematically adjusting these parameters, we can more thoroughly evaluate the model’s robustness and delineate its boundaries under a broader range of neurophysiological conditions. We will present these results in the revised manuscript and discuss how they inform our understanding of alpha-driven visual integration in cross-modal contexts.</p>
<disp-quote content-type="editor-comment">
<p>As a last remark, I would avoid, or at least tone down, concluding that the results hereby presented might reconcile and/or explain the null effects in Buergers &amp; Noppeney, 2022; as the relationship between IAFs and audiovisual abilities still holds when examining other cross-modal paradigms such as the Sound-Induced Flash-Illusion (Noguchi, 2022), and the aforementioned patterns might be due to other factors, such as a too small sample size (Samaha &amp; Romei, 2024).</p>
</disp-quote>
<p>We appreciate the reviewer’s suggestion and will revise our claims accordingly. In the revised manuscript, we will clarify that while our study demonstrates a mechanism by which alpha oscillations influence audiovisual integration in certain paradigms, this does not mean that our findings fully reconcile all conflicting results in the literature. We will emphasize that our mechanism may help explain why alpha frequency plays a critical role in some experimental settings, but that factors such as sample size, task parameters, and experimental design differences likely contribute to the divergent results observed across studies. Accordingly, we acknowledge that further research with larger samples and more refined methodologies is necessary to fully reconcile these discrepancies. This more cautious interpretation will be clearly discussed in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public review):</bold></p>
<p>Summary:</p>
<p>The authors used a visual flash discrimination task in which two flashes are presented one after another with different inter-stimulus intervals. Participants either perceive one flash or two flashes. The authors show that the simultaneous presence of an auditory input extends the temporal window of integration, meaning that two flashes presented shortly after one another are more likely to be perceived as a single flash. Auditory inputs are accompanied by a reduction in alpha frequency over visual areas. Prestimulus alpha frequency predicts perceptual outcomes in the absence of auditory stimuli, whereas prestimulus alpha phase becomes the dominant predictor when auditory input is present. A computational model based on phase-resetting theory supports these findings. Additionally, a transcranial stimulation experiment confirms the causal role of alpha frequency in unimodal visual perception but not in cross-modal contexts.</p>
<p>Strengths:</p>
<p>The authors elegantly combined several approaches-from behavior to computational modeling and EEG-to provide a comprehensive overview of the mechanisms involved in visual integration in the presence or absence of auditory input. The methods used are state-of-the-art, and the authors attempted to address possible pitfalls.</p>
<p>Weaknesses:</p>
<p>The use of Bayesian statistics could further strengthen the paper, especially given that a few p-values are close to the significance threshold (lines 162 &amp; 258), but they are interpreted differently in different cases (absence of effect vs. trend).</p>
</disp-quote>
<p>We appreciate the reviewer’s suggestion regarding the use of Bayesian statistics. We agree that a Bayesian framework can offer valuable complementary insights to our analysis by helping to distinguish whether a marginal p-value represents a trend or truly indicates the absence of an effect. To enhance the robustness of our conclusions, we will incorporate supplemental Bayesian analyses in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p>Overall, these results provide new insights into the role of alpha oscillations in visual processing and offer an interesting perspective on the current debate regarding the roles of alpha phase and frequency in visual perception. More generally, they contribute to our understanding of the neural dynamics of multisensory integration.</p>
<p><bold>Reviewer #3 (Public review):</bold></p>
<p>Summary:</p>
<p>The authors investigated the impact of an auditory stimulus on visual integration at the behavioral, electrophysiological, and mechanistic levels. Although the role of alpha brain oscillations on visual perception has been widely studied, how the brain dynamics in the visual cortices are influenced by a cross-modal stimulus remains ill-defined. The authors demonstrated that auditory stimulation systematically induced a drop in visual alpha frequency, increasing the time window for audio-visual integration, while in the unimodal condition, visual integration was modulated by small variations within the alpha frequency range. In addition, they only found a role of the phase of alpha brain oscillations on visual perception in the cross-modal condition. Based on the perceptual cycles' theory framework, the authors developed a model allowing them to describe their results according to a phase resetting induced by the auditory stimulation. These results showed that the influence of well-known brain dynamics on one modality can be disrupted by another modality. They provided insights into the importance of investigating cross-modal brain dynamics, and an interesting model that extends the perceptual cycle framework.</p>
<p>Strengths:</p>
<p>The results are supported by a combination of various, established experimental and analysis approaches (e.g., two-flash fusion task, psychometric curves, phase opposition), ensuring strong methodological bases and allowing direct comparisons with related findings in the literature.</p>
<p>The model the authors proposed is an extension and an improvement of the perceptual cycle's framework. Interestingly, this model could then be tested in other experimental approaches.</p>
<p>Weaknesses:</p>
<p>There is an increasing number of studies in cognitive neuroscience showing the importance of considering inter-individual variability. The individual alpha frequency (IAF) varied from 8 to 13 Hz with a huge variability across participants, and studies have shown that the IAF influenced visual perception. Investigating inter-individual variations of the IAF in the reported results would be of great interest, especially for the model.</p>
</disp-quote>
<p>We appreciate the reviewer’s valuable feedback regarding the importance of inter-individual variability in alpha frequency. In our current study, we have already addressed participant-level variability in our neural data by performing inter-subject correlation analyses, investigating whether individual reductions in alpha frequency correlate with broader temporal integration windows at the behavioral level.</p>
<p>Moreover, our computational model incorporates physiologically realistic distributions for key parameters, including frequency and amplitude, which captures some degree of individual variability. Nevertheless, we acknowledge that a more targeted examination of how different IAF values specifically affect the model’s predictions would be highly valuable. In response, we will expand our simulations to systematically explore a range of IAF values and assess their impact on temporal integration windows and related measures of audiovisual processing. These additional analyses will help clarify the role of inter-individual variability in alpha frequency and further strengthen the mechanistic account offered by our model. We will detail these enhancements and discuss their implications in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p>Although the use of non-invasive brain stimulation to infer causality is a method of great interest, the use of tACS in the presented work is not optimal. Instead of inducing alpha brain oscillations in visual cortices, the use of tACS to activate the auditory cortex instead of the actual auditory stimulation would have presented more interest.</p>
</disp-quote>
<p>We appreciate the reviewer’s suggestion and acknowledge that non-invasive brain stimulation offers promising avenues for inferring causality. In our study, our primary hypothesis focused on the role of occipital alpha oscillations in defining the temporal window for visual integration, and accordingly we targeted visual cortex in our tACS protocol.</p>
<p>We recognize that stimulating the auditory cortex could provide additional insights into auditory contributions to phase resetting. However, accurately targeting the auditory cortex with tACS presents technical challenges. The auditory cortex is located deeper within the temporal lobe, and factors such as variable skull thickness and complex current spread make it difficult to reliably modulate its neural activity compared to the more superficial visual areas. Indeed, recent studies have demonstrated that tACS-induced electric fields in the temporal regions tend to be weaker and less focal—for example, Huang et al. (2017) and Opitz et al. (2016) highlight the limitations in achieving robust stimulation of deeper or anatomically complex brain regions using conventional tACS approaches.</p>
<p>Given these considerations, while we agree that future investigations could benefit from exploring auditory cortex stimulation—either as an alternative or as a complementary approach—the present study remains focused on visual alpha modulation, where our protocol is well validated and yields reliable results. In the revised manuscript, we will clearly discuss these issues and acknowledge the potential, yet technically challenging, possibility of stimulating the auditory cortex in future work to further disentangle the contributions of auditory and visual inputs to cross-modal integration.</p>
</body>
</sub-article>
</article>