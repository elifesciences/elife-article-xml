<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">107162</article-id>
<article-id pub-id-type="doi">10.7554/eLife.107162</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.107162.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories><title-group>
<article-title>A neural mechanism for compositional generalization of structure in humans</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9370-9606</contrib-id>
<name>
<surname>Luettgau</surname>
<given-names>Lennart</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<email>l.luettgau@ucl.ac.uk</email>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Chen</surname>
<given-names>Nan</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Erdmann</surname>
<given-names>Tore</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Veselic</surname>
<given-names>Sebastijan</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Kurth-Nelson</surname>
<given-names>Zeb</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a5">5</xref>
<xref ref-type="author-notes" rid="n1">*</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Moran</surname>
<given-names>Rani</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a6">6</xref>
<xref ref-type="author-notes" rid="n1">*</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Dolan</surname>
<given-names>Raymond J</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>Max Planck UCL Centre for Computational Psychiatry and Ageing Research, University College London</institution></institution-wrap>, <city>London</city>, <country country="GB">United Kingdom</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02704qw51</institution-id><institution>Wellcome Centre for Human Neuroimaging, University College London</institution></institution-wrap>, <city>London</city>, <country country="GB">United Kingdom</country></aff>
<aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>Division of Psychiatry, University College London</institution></institution-wrap>, <city>London</city>, <country country="GB">United Kingdom</country></aff>
<aff id="a4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>Clinical and Movement Neurosciences, Department of Motor Neuroscience, University College London</institution></institution-wrap>, <city>London</city>, <country country="GB">United Kingdom</country></aff>
<aff id="a5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00971b260</institution-id><institution>Google DeepMind</institution></institution-wrap>, <city>London</city>, <country country="GB">United Kingdom</country></aff>
<aff id="a6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/026zzn846</institution-id><institution>School of Biological and Behavioural Sciences, Queen Mary University of London</institution></institution-wrap>, <city>London</city>, <country country="GB">United Kingdom</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Bottini</surname>
<given-names>Roberto</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Trento</institution>
</institution-wrap>
<city>Trento</city>
<country country="IT">Italy</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country country="US">United States</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="equal"><label>*</label><p>Equal contribution</p></fn>
<fn fn-type="coi-statement"><p>Competing interests: Work conducted while ZK-N was employed by Google DeepMind. All other authors declare no conflict of interests.</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-07-28">
<day>28</day>
<month>07</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP107162</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-04-19">
<day>19</day>
<month>04</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-04-19">
<day>19</day>
<month>04</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.09.20.614119"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Luettgau et al</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Luettgau et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-107162-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>A human ability to adapt to the dynamics of novel environments relies on abstracting and generalizing from past experiences. Previous research has focused on how humans generalize from isolated sequential processes, yet we know little about mechanisms that enable adaptation to more complex dynamics, including those that govern much everyday experience. Here, using a novel sequence learning task based on graph factorization, coupled with simultaneous magnetoencephalography (MEG) recordings, we asked how reuse of experiential “building blocks” enables inference and generalization. Behavioral evidence was consistent with participants decomposing task experience into subprocesses, involving abstracting dynamical subprocess structures away from their sensory specifics and transferring these to a new task environment. Neurally this transfer was underpinned by a representational alignment of abstract subprocesses across task phases, evident in an enhanced neural similarity among stimuli that adhered to the same subprocesses, a temporally evolving mapping between predictive representations of subprocesses and a generalization of the dynamic roles that stimuli occupied within graph structures. Decoding strength for dynamical role representations predicted behavioral success in transfer of subprocess knowledge, consistent with a role in supporting behavioral adaptation in new environments. Our findings reveal neural dynamics that support compositional generalization, consistent with a structural scaffolding mechanism that facilitates efficient adaptation within new contexts.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>New correction for multiple comparisons based on cluster-based permutation tests</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>A defining feature of human cognition is an exceptional ability to adapt rapidly to novel contexts. One set of proposals suggests this relies on abstraction and generalization of past experiences (<xref ref-type="bibr" rid="c2">Allen et al., 2020</xref>; <xref ref-type="bibr" rid="c12">Dekker et al., 2022</xref>; <xref ref-type="bibr" rid="c23">Kumar et al., 2022</xref>; <xref ref-type="bibr" rid="c25">Lake et al., 2015</xref>, <xref ref-type="bibr" rid="c26">2017</xref>; <xref ref-type="bibr" rid="c27">Lehnert et al., 2020</xref>; <xref ref-type="bibr" rid="c52">Tsividis et al., 2021</xref>) enabling transfer of past experiential knowledge to entirely new situations (<xref ref-type="bibr" rid="c6">Behrens et al., 2018</xref>; <xref ref-type="bibr" rid="c26">Lake et al., 2017</xref>; <xref ref-type="bibr" rid="c31">Mark et al., 2020</xref>; <xref ref-type="bibr" rid="c47">Shepard, 1987</xref>). Much research has been devoted to understanding how humans detect (<xref ref-type="bibr" rid="c53">Turk-Browne et al., 2008</xref>), generalize (<xref ref-type="bibr" rid="c39">Reber, 1967</xref>) and neurally represent a single dynamical, and sequentially, unfolding process(<xref ref-type="bibr" rid="c16">Garvert et al., 2017</xref>; <xref ref-type="bibr" rid="c18">Henin et al., 2021</xref>; <xref ref-type="bibr" rid="c44">Schapiro et al., 2013</xref>; <xref ref-type="bibr" rid="c48">Sherman et al., 2020</xref>) or do so from piecemeal presentation of a graph structure (<xref ref-type="bibr" rid="c41">Rmus et al., 2022</xref>). Human neural evidence indicates these processes relate to representation of experiential elements in the hippocampal-entorhinal system (<xref ref-type="bibr" rid="c17">Garvert et al., 2023</xref>; <xref ref-type="bibr" rid="c57">Zheng et al., 2024</xref>). However, despite progress in our understanding, we know little regarding how humans abstract from the more complex dynamics of everyday experience.</p>
<p>Computational modeling with artificial neural networks, trained to perform multiple tasks (<xref ref-type="bibr" rid="c20">Johnston &amp; Fusi, 2023</xref>; <xref ref-type="bibr" rid="c56">Yang et al., 2019</xref>), as well as cross-species neural evidence, propose this may be achieved via a low dimensional neural coding of abstract, disentangled, task variables that enables a linear readout of relevant abstracted task dimensions (<xref ref-type="bibr" rid="c7">Bernardi et al., 2020</xref>; <xref ref-type="bibr" rid="c11">Courellis et al., 2024</xref>). Implicated brain structures include the hippocampal-entorhinal system (<xref ref-type="bibr" rid="c3">Baram et al., 2021</xref>; <xref ref-type="bibr" rid="c7">Bernardi et al., 2020</xref>; <xref ref-type="bibr" rid="c11">Courellis et al., 2024</xref>), frontal cortex (<xref ref-type="bibr" rid="c3">Baram et al., 2021</xref>; <xref ref-type="bibr" rid="c7">Bernardi et al., 2020</xref>; <xref ref-type="bibr" rid="c11">Courellis et al., 2024</xref>; <xref ref-type="bibr" rid="c14">Flesch et al., 2022</xref>, <xref ref-type="bibr" rid="c15">2023</xref>; <xref ref-type="bibr" rid="c58">Zhou et al., 2021</xref>) and posterior parietal cortex (<xref ref-type="bibr" rid="c14">Flesch et al., 2022</xref>, <xref ref-type="bibr" rid="c15">2023</xref>). Inference and generalization of knowledge could allow for a computationally efficient reuse or “recycling” of learnt representations in novel contexts akin to the abstraction of structural representations from sensory experiences proposed as implemented within the hippocampal-entorhinal system (<xref ref-type="bibr" rid="c6">Behrens et al., 2018</xref>; <xref ref-type="bibr" rid="c55">Whittington et al., 2020</xref>, <xref ref-type="bibr" rid="c54">2022</xref>).</p>
<p>In previous studies, only a single dynamical process/structure needed to be considered and generalized to new situations. However, our everyday world experience is often the product of more complex environmental dynamics, comprising a <italic>multitude</italic> of simultaneously evolving structural subprocesses. Indeed, despite its ubiquity, we know little about the mechanisms of efficient adaptation to environmental dynamics generated from multiple simultaneous subprocesses (but see <xref ref-type="bibr" rid="c10">Conway &amp; Christiansen, 2006</xref> investigating behavior in response to mixed, but temporally well-separated stimulus sequences produced by two artificial grammars). Previously we found behavioral evidence for generalization of subprocesses that involved parsing complex task experience into component “building blocks”. Based on computational modeling and behavioral evidence, we proposed a cognitive-computational mechanism whereby structural mapping of prior experience facilitates generalization of knowledge to help solve new tasks (<xref ref-type="bibr" rid="c28">Luettgau et al., 2024</xref>). While the latter data extended on previous behavioral findings regarding compositionality (<xref ref-type="bibr" rid="c25">Lake et al., 2015</xref>, <xref ref-type="bibr" rid="c26">2017</xref>; <xref ref-type="bibr" rid="c43">Rubino et al., 2023</xref>), we still lack a neural account of how this might be implemented.</p>
<p>We hypothesized compositional generalization relies on reuse of abstracted structural knowledge to form a representational scaffolding for new experiences. Under this hypothesis, knowledge generalization involves mapping of inferred generative causes of an ongoing experience to support abstraction over concrete events (<xref ref-type="bibr" rid="c31">Mark et al., 2020</xref>; <xref ref-type="bibr" rid="c38">Pesnot Lerousseau &amp; Summerfield, 2024</xref>; <xref ref-type="bibr" rid="c55">Whittington et al., 2020</xref>). We propose humans identify, neurally represent, and abstract the constitutive relational units of experience (“building blocks”). These are subsequently reused as a structural scaffolding for inferring the relational units underlying new experiences, facilitating a mapping of new sensory information to pre-existing structural templates. A structural scaffolding account of compositional generalization entails a prediction that, across different contexts, elements that compose analogous subprocesses would show representational alignment, indicative of a shared abstract representation that enables transfer and reuse of experiential “building blocks”.</p>
<p>While several studies have mapped the spatial location of low-dimensional neural representations of abstract and disentangled task variables to different brain areas – such as the hippocampal-entorhinal system (<xref ref-type="bibr" rid="c3">Baram et al., 2021</xref>; <xref ref-type="bibr" rid="c7">Bernardi et al., 2020</xref>; <xref ref-type="bibr" rid="c11">Courellis et al., 2024</xref>; <xref ref-type="bibr" rid="c34">Nieh et al., 2021</xref>), frontal cortex (<xref ref-type="bibr" rid="c3">Baram et al., 2021</xref>; <xref ref-type="bibr" rid="c7">Bernardi et al., 2020</xref>; <xref ref-type="bibr" rid="c11">Courellis et al., 2024</xref>; <xref ref-type="bibr" rid="c14">Flesch et al., 2022</xref>, <xref ref-type="bibr" rid="c15">2023</xref>; <xref ref-type="bibr" rid="c58">Zhou et al., 2021</xref>) and posterior parietal cortex (<xref ref-type="bibr" rid="c14">Flesch et al., 2022</xref>, <xref ref-type="bibr" rid="c15">2023</xref>) – our understanding of the temporal dynamics of these representations remains limited, particularly with respect to compositional forms of generalization. It is currently unclear at which moment during neural information processing compositional representations are dynamically assembled. Thus, charting the temporal dynamics of the mechanisms supporting generalization can deepen our insight into flexible aspects of cognition while also enabling fine-grained experimental manipulation and intervention.</p>
<p>To address these questions, we developed a sequence learning paradigm based on the graph theoretical concept of graph factorization, emulating environments whose dynamics are the product of multiple simultaneous subprocesses. Product graphs (Cartesian product), wherein the joint dynamics of two or more graph factors create complex product state space dynamics that can be factorized (and simplified) into constitutive factors, provided the test bed for probing neural representation of multiple (independent) simultaneous evolving subprocesses.</p>
<p>Examples of such graph products and their factorizations, from a vast space of possible combinations, are provided in <xref rid="fig1" ref-type="fig">Figure 1A</xref>. Here we invoke a specific understanding of the term <italic>compositional</italic>, inspired by prior usage in cognitive-computational neuroscience (e.g., <xref ref-type="bibr" rid="c4">Barron et al., 2013</xref>; <xref ref-type="bibr" rid="c43">Rubino et al., 2023</xref>; <xref ref-type="bibr" rid="c45">Schwartenbeck et al., 2023</xref>; alternative notions of <italic>compositional</italic> have been suggested in the literature, e.g., recursive operations over hierarchies (<xref ref-type="bibr" rid="c36">O’Donnell et al., 2009</xref>, <xref ref-type="bibr" rid="c37">2011</xref>), hierarchical function composition, or rich forms of semantic composition in language to create complex concepts (<xref ref-type="bibr" rid="c33">Murphy, 1988</xref>)).</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Experimental design</title>
<p><bold>A)</bold> Exemplary product graphs (Cartesian product, right) selected from the vast array of possible graph products that can be constructed from two simpler graph components (left). The graph product of two or more simple graph components results in complex product state spaces, which can be decomposed (and simplified) into their constituting components.</p><p><bold>B)</bold> Graph factors used in prior learning (left) and transfer learning (right)</p><p><bold>C)</bold> During the sequence learning task (both prior and transfer learning), graph factors were combined into compound graphs (product graphs) by merging their images. In both prior learning and transfer learning, participants were presented with sequences of meaningful compound holistic images, such as a cat on a chair or a house with a car. Depicted is an example sequence generated by the product graph of the yellow graph factor and the gold graph factor used during prior learning (panel B, left, top). The example sequence involved a simultaneous traversal in the yellow graph factor and in the gold graph factor, as shown in panel B (left, top). After each sequence presentation (consisting of 8 compound stimuli), participants’ understanding of the temporal dynamics was assessed in two ways, as detailed in <xref rid="fig2" ref-type="fig">Figure 2</xref>.</p><p><bold>D)</bold> During sequence presentations in transfer learning, participants only observed a subset of transitions from the compound graph formed by the green graph factor and the black graph factor, as shown in panel B (right), e.g., the 16 depicted transitions, forming two disjoint subgraphs. The remaining possible compound graph transitions formed a held-out set (see examples in panel F). This allowed us to test participants’ understanding of the subprocesses generating the observed sequences. The same principles applied to prior learning. Depicted are example sequences produced by the subgraphs of the product graph used in transfer learning, involving a simultaneous traversal in the green graph factor and in the black graph factor, as shown in panel B (right). Subgraph sequence 1 (left) was presented two times, after which subgraph sequence 2 (right) was presented twice.</p><p><bold>E)</bold> For illustration of the transfer learning compound graph, we only show the parts of the compound graph for transfer learning that participants experienced during sequence presentation, created from the 4-cycle and 6-bridge graphs shown in panel B (right). Note that the 6-bridge graph did not feature a truly bi-directional edge between the central nodes (7//7’ and 10/10’), but instead had a “refractory” edge, such that it was not possible to transition back and forth within one step between central nodes of the graph. In both phases of the task (prior and transfer learning), the compound graphs consisted of 24 compound images.</p><p><bold>F)</bold> Examples of held-out transitions used in transfer learning between compound images. Note that these transitions entailed some compounds which were observed (as part of other transitions) during sequence presentations.</p></caption>
<graphic xlink:href="614119v2_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Using magnetoencephalography (MEG) we provide evidence for dynamic neural representations supporting compositional generalization. We found that distinct sensory stimuli showed greater neural alignment when they adhered to the same underlying abstract relational dynamics, while stimuli in analogous “dynamical roles” could be successfully decoded across entirely different task phases. Decoding strength for these dynamical roles related to transfer learning success selectively for structural components that were experienced consistently across learning contexts.</p>
</sec>
<sec id="s2">
<title>Results</title>
<p>In brief, participants (<italic>N</italic> = 51) performed a sequence learning task, observing image sequences produced by walks on product graphs constructed from smaller graph factors (<xref rid="fig1" ref-type="fig">Fig. 1A</xref> and <xref rid="fig1" ref-type="fig">B</xref>). The experiment consisted of two phases (prior learning and transfer learning, see task design details in <xref rid="fig1" ref-type="fig">Figure 1</xref> and <xref rid="fig2" ref-type="fig">2</xref>). During both task phases, participants viewed sequences of compound images comprising two elements, depicting meaningful scenes. The compound images used for the sequences were generated from combining images on two different graph factors (<xref rid="fig1" ref-type="fig">Fig. 1B</xref>), which differed between-subjects and across the two task phases.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Behavioral task and transfer learning performance.</title>
<p>A) Example sequence produced by subgraph 1 of the product graph used in transfer learning (reproduced <xref rid="fig1" ref-type="fig">Fig. 1D</xref> left).</p><p>B) The compound image sequence in panel A was generated from a simultaneous traversal of two <italic>graph factors,</italic> by combining their images (reproducing <xref rid="fig1" ref-type="fig">Fig. 1F</xref> for convenience). The example sequence was generated from a 4-state cyclic graph factor and a 6-state bridge graph factor (reproducing <xref rid="fig1" ref-type="fig">Fig. 1B</xref> for convenience).</p><p>C) Exemplar schematic of experience and inference probes during transfer learning, respectively. During both prior and transfer learning, following presentation of an entire compound image sequence, participants were probed to predict upcoming states that adhered to one of the 16 experienced compound image transitions (experience probes, left column). Additionally, an inference probe (right column) tested participants’ ability to infer and accurately predict held-out transitions (<xref rid="fig1" ref-type="fig">Fig. 1C</xref>). In both probe questions, participants saw a compound image and were asked: “Imagine you see this image. What would be the next image?”. Two compound images – correct next compound image (eligible based on the graph structure) and a lure compound image (non-eligible) – were presented as choice options. The lure compound image always matched the correct option on one of the two individual images composing the compound image (e.g., D’12’ -&gt; A’10’ or B’10’). This allowed us to test knowledge of both graph factors separately (in the current example, knowledge that D’ allows a transition to A’ but not B’) (top row: 4-state factor; bottom row: 6-state factor) underlying the observed sequence (and the held-out transitions) separately.</p><p>D) Aggregated probabilities of correct answers during the transfer learning phase, separately for experience (left) and inference probes (right) as a function of probed size (4-state cycle (green) vs 6-state bridge (black)) and condition (4-cycle prior vs 6-bridge prior). Each dot represents the arithmetic mean of experience and inference probe performance for one participant, bars represent the arithmetic mean of the distribution, error bars depict the standard error of the mean and the dashed gray line represents chance level point estimate (probability correct = 0.5).</p><p>E) Posterior density plots for each parameter estimate (posterior mean = black line) for the best-fitting GLM. The dashed vertical line represents a zero effect. In probed size (4-cycle or 6-bridge) and probe type (experience vs inference) effects, parameter estimates below zero indicate higher accuracy in the 4-cycle probes (vs. 6-bridge probes) and experience probes (vs. inference probes), respectively. In the condition effect, parameter estimates below zero indicate higher accuracy in the 4-cycle prior condition (vs. 6-bridge prior condition). The positive interaction effect indicates selectively higher accuracy in 4-cycle probes in the 4-cycle prior condition, and higher accuracy in 6-bridge probes in the 6-cycle prior condition.</p></caption>
<graphic xlink:href="614119v2_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>In a prior learning phase, using a between-subjects design, participants in a 4-cycle condition experienced sequences generated from the product of a 4-state cycle graph factor and a 6-state path-graph factor (<xref rid="fig1" ref-type="fig">Fig. 1B</xref> top panel, left, <xref rid="fig1" ref-type="fig">Fig. 1C</xref> for example sequences). Likewise, participants in a 6-bridge prior condition saw compound image sequences produced by combining a 4-state path-graph factor and a 6-state bridge graph factor (<xref rid="fig1" ref-type="fig">Fig. 1B</xref> bottom panel, left). Each of these graph factors is considered a structural ”building block” underlying participants’ holistic experience.</p>
<p>The prior learning phase was followed by a transfer learning phase, identical for both conditions (<xref rid="fig1" ref-type="fig">Fig. 1D</xref>), but now compound image sequences were composed from entirely novel picture elements. The latter were the product of a 4-state cyclic graph factor and a 6-state bridge graph factor, respectively (<xref rid="fig1" ref-type="fig">Fig. 1B</xref> right). This between group design meant that, for each participant, the structure of only one of the two graph factors (“building blocks”) that generated the compound image sequences was common across the prior and transfer learning phase (e.g., in the 4-state cycle prior condition, the 4-state cycle, but not the 6-state bridge, was present in both prior and transfer learning, <xref rid="fig1" ref-type="fig">Fig. 1B</xref>). Importantly, these graph factors were embedded by entirely different images across both task phases, rendering any learning unlikely based on stimulus similarity.</p>
<p>Our central prediction was that individuals would abstract experienced subprocesses (i.e., graph factors) from prior learning and reuse this knowledge during transfer learning, benefiting from recurrence of a previously experienced subprocess. To test this, in both task phases (i.e., prior and transfer learning), participants experienced sequences of a subset of all possible transitions between compound images (<xref rid="fig1" ref-type="fig">Fig. 1E and F</xref> illustrate this as an example for the transfer learning phase product graph). The remaining possible transitions between compound images (based on transitions on the underlying graph components) formed a held-out set of transitions between compound images (see examples in <xref rid="fig1" ref-type="fig">Fig. 1D</xref>). Leveraging held-out transitions enabled us to test knowledge for unobserved transitions between compound stimuli, at each task phase (i.e., prior and transfer learning). In essence this provided an assay of whether there was reuse of a graph factorization (i.e., knowledge of the individual graph factors producing the experienced compound sequence (<xref rid="fig1" ref-type="fig">Fig. 1E/F</xref>)). For details on the transitions, we refer to the Methods section.</p>
<p>During prior and transfer learning, “experience probes” tasked participants to predict upcoming states that followed one of the compound images from the experienced subgraph (<xref rid="fig2" ref-type="fig">Fig. 2C</xref>, left column). Likewise, in both prior and transfer learning “inference probes’’ (<xref rid="fig2" ref-type="fig">Fig. 2C</xref>, right column) tested for an ability to make accurate predictions about held out set transitions. In both experience and inference probes, participants were tasked to choose between the correct next compound image (correct transition based on the generative graph structure) and a lure (incorrect transition) compound image. The lure compound image always matched the correct compound image with respect to one of the component individual images (e.g., D’12’ -&gt; A’10’ or B’10’), allowing us to test knowledge pertaining to each of the graph factors separately (here, the knowledge that in the 4-state graph factor component D’ is followed by A’ rather than B’). Probe questions were carefully designed in such a way that did not allow to infer the structure from these questions (see Methods for details). Overall, the task allowed us to test if subjects utilize the structural “building blocks” underlying their experience (graph factors, subprocesses). Additionally, we could test whether knowledge of subprocess dynamics is reused compositionally in novel contexts. This is because in our design, despite using entirely different stimulus sets across the task phases, one of the abstract graph factors was consistent for participants in both conditions, allowing reuse of this specific structural knowledge. However, knowledge about the other graph factor that generated experiences in prior learning was irrelevant, enabling control for general learning effects.</p>
<p>In summary, participants viewed sequences of images that were combined from concurrent walks on two underlying graph structures (“building block”). In prior learning, they learned image sequences generated from two graph structures. In a subsequent transfer learning phase, participants saw new image sequences, but one of the two structural “building blocks” that underlie the observed image dynamics remained the same for each participant. Throughout both phases, participants were asked to predict upcoming images and infer never observed transitions. This task feature allowed us to test reuse of prior structural knowledge, which we predicted would reflect in higher accuracy in the consistently encountered “building block” (but not the other, irrelevant “building block”) – providing evidence for a hypothesis that participants generalize components of learned structural dynamics despite changes in component sensory elements.</p>
<sec id="s2a">
<title>Abstracting and reusing subprocesses</title>
<p>A central behavioral prediction was that individuals would abstract experienced subprocesses (i.e., graph factors) from prior learning and reuse this knowledge during transfer learning. Thus, at transfer learning the 4-cycle prior condition subjects should perform better on 4-cycle probes compared to the 6-bridge prior condition and vice versa for the 6-bridge prior condition. This predicts at transfer learning a disordinal interaction where the probability of being correct varies as a function of prior learning condition (4-cycle prior condition vs 6-bridge prior condition) and probed size (probes testing knowledge of 4-state graph factor vs 6-state graph factor) (<xref rid="fig2" ref-type="fig">Fig. 2D</xref>). To model candidate processes that might generate the observed transfer learning behavioral data, we defined four Bayesian multilevel GLMs (GLM1–4, <xref rid="eqn1" ref-type="disp-formula">Eq. 1</xref>-<xref rid="eqn4" ref-type="disp-formula">4</xref>). The most parsimonious model (GLM4, see Methods for model comparison) indicated the effects for probed size and prior learning condition on accuracy were qualified by a three-way interaction effect between these two variables and probe type (experience vs inference). In post-hoc GLMs, we observed non-zero interaction effects between probed size and condition (experience probes: µ<sub>SIZExCOND</sub> = .79, credible interval (CI) = [.42; 1.17], <xref rid="fig2" ref-type="fig">Fig. 2E</xref> top row, third panel; inference probes: µ<sub>SIZExCOND</sub> = .38, CI = [.02; .75], <xref rid="fig2" ref-type="fig">Fig. 2E</xref> bottom row, third panel)</p>
<p>Disentangling these effects using post-hoc contrasts [4-cycle prior condition – 6-bridge prior condition], showed that experience probes performance was higher for 4-cycle probes in the 4-cycle prior condition (vs 6-bridge prior condition; <xref rid="fig2" ref-type="fig">Fig. 2D</xref> left panel, green dots; mean difference of 10,000 posterior samples: .36, CI = [.17; .56]) whereas for 6-bridge probes, performance was superior in the 6-bridge prior condition (vs 4-cycle prior condition; <xref rid="fig2" ref-type="fig">Fig. 2D</xref> left panel, black dots; mean difference of 10,000 posterior samples: -.23, CI = [-.42; -.04]). In inference probes, performance on 4-cycle probes was higher in the 4-cycle prior condition (vs 6-bridge prior condition; <xref rid="fig2" ref-type="fig">Fig. 2D</xref> right panel, green dots; mean difference of 10,000 posterior samples: .38, CI = [.20; .56]). For 6-bridge probes, there was no evidence for a performance difference between conditions (4-cycle prior – 6-bridge prior; <xref rid="fig2" ref-type="fig">Fig. 2D</xref> right panel, black dots; mean difference of 10,000 posterior samples: -.11, CI = [-.26; .04]). Posterior distributions for the other parameter estimates of these GLMs are depicted in <xref rid="fig2" ref-type="fig">Figure 2E</xref>. Splitting behavioral results by performance levels – high performers (&gt;50th percentile of overall prior and transfer learning performance distribution) vs low performers (&lt;=50th percentile) – yielded similar results (<xref rid="figs1" ref-type="fig">Supplementary Fig. 1</xref>).</p>
<p>These findings replicate previous results from a larger cohort using a similar design (<xref ref-type="bibr" rid="c28">Luettgau et al., 2024</xref>). The 6-bridge experience probe behavior utilized here indicates subjects not only extract and generalize subprocess dynamics for cyclical structures (as we previously showed), but also for more complex dynamics (bridge graphs). The observed pattern is not accounted for by general practice or non-specific meta-learning related improvement effects (as such accounts would predict similar performance for both probed sizes across conditions). Instead, the results converge with our previous findings (<xref ref-type="bibr" rid="c28">Luettgau et al., 2024</xref>) showing that participants extract experiential subprocess dynamics and, where there is a generative consistency across both task phases, reuse these during transfer learning.</p>
</sec>
<sec id="s2b">
<title>Structural mapping of subprocesses for compositional generalization</title>
<p>A structural scaffolding account predicts elements of analogous subprocesses, across different experiential contexts, should show representational alignment reflective of a shared abstract representation. To test this and gain insights into the neural dynamics of the proposed mechanism, we recorded MEG signals during localizer tasks from before and after sequence learning (PRE and POST localizer task, <xref rid="fig3" ref-type="fig">Fig. 3A</xref>). We reasoned that the predicted representational alignment of experiential “building blocks” should be reflected in a task-induced (PRE to POST) increase in neural similarity between distinct stimuli as a function of sharing the same (compared to different) underlying relational structure, in this case adhering to identical subprocess dynamics (<xref rid="fig3" ref-type="fig">Fig. 3B</xref>). To test this, we used a feature similarity analysis (akin to representational similarity analysis (RSA) (<xref ref-type="bibr" rid="c22">Kriegeskorte et al., 2008</xref>) on MEG data (<italic>N</italic> = 50, one subject from the behavioral sample was excluded due to MEG artifacts) from PRE and POST localizer task sessions (<xref rid="fig3" ref-type="fig">Fig. 3A</xref>).</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Neural dynamics of structural mapping between subprocesses.</title>
<p>A) Participants performed two stimulus localizer tasks, once before and one after (PRE and POST localizer) the main experimental task (prior and transfer learning). These tasks comprised multiple presentations of all features used in prior and transfer learning (PRE and POST). Additionally, the PRE localizer also contained the compound images used during prior learning (not relevant for this analysis). A feature similarity analysis (akin to RSA) on stimulus-evoked neural activity recorded during the two localizer tasks (PRE and POST localizer) for the two feature sets, comprising the compound images used in prior and transfer learning at time-points from -200 to 800 ms relative to stimulus-onset.</p><p>B) Feature sets in prior learning phase (yellow frame, left) and transfer learning phase (blue frame, right).</p><p>C) The presented theoretical representational dissimilarity matrices (RDM) were regressed onto the empirical neural similarity matrices – separately for the 4-state graph factor features and the 6-state graph factor features. Lighter colors denote higher values. Note that the hypothesized similarity changes are only computed across the two feature sets used in prior learning (yellow) and transfer learning (blue), but not within each set, avoiding confounding task-related changes with feature similarity unrelated to abstract subprocess structure.</p><p>D) Time courses of condition differences (4-cycle prior condition – 6-bridge prior condition) on 4-state graph factor (green) and 6-state graph factor (black) feature similarity changes in the weighted average PCs from PRE to POST localizer. Shaded error bars indicate standard errors of difference. Dark green line represents time points at which feature similarity changes for the condition x graph factor interaction effect were statistically significant, corrected for multiple comparisons at the cluster-level (P<sub>FWE</sub> &lt; 0.05, non-parametric permutation test). Horizontal line indicates a null effect.</p></caption>
<graphic xlink:href="614119v2_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>As an initial step, to denoise sensor-level neural signals, we implemented a dimensionality reduction approach (principal components analysis, PCA, see Methods for details). We conducted the following steps separately for the PRE and POST localizer sessions and for each participant. First, we extracted the minimal number of PCs that accounted for &gt;=80% of the variance of neural activity across sensors for all trials and time points (-200 to 800 ms relative to stimulus onset). Next, for each time point, trial and PC we calculated the neural PC activity (i.e., PC score). By averaging PC activity across all trials presenting the same feature (i.e., element images of graph factors) we obtained an activity index for each PC, feature and time point. We next computed the dissimilarity between each pair of features as the absolute difference between their activity indices. This provided for a Representational Dissimilarity Matrix (RDM) at each time point, and for each PC. Next, for each time point, we calculated an across PC weighted average RDM (with weights being variance explained by each PC relative to the total variance explained by all PCs included in the analysis), resulting in a weighted average RDM for each participant, time point and session (PRE/POST). We then subtracted the POST weighted average RDM from the PRE weighted average RDM for each participant to obtain a PRE-POST difference weighted average RDM. Finally, to quantify feature similarity change at each time point, and for each participant, we computed Kendall’s tau correlation coefficient between theoretical RDMs and PRE-POST differences in neural RDMs. Our theoretical RDMs relate to a hypothesized abstract representation of subprocesses underlying experiences reflecting higher similarity between feature-pairs, where features belong to different learning phases (one from primary, the other from transfer) but share a component size (separate design matrices for the 4-state graph factor and 6-state graph factor, <xref rid="fig3" ref-type="fig">Fig. 3C</xref>).</p>
<p>Within the PRE-POST change in weighted averaged RDMs, across participants we observed a qualitative pattern indicative of increased neural similarity between stimuli that adhered to the same underlying subprocess across task phases. A group-level GLM (including condition, graph factor main effects and a condition x graph factor effect) revealed that highly distinct stimuli adhering to the same abstract relational structure (4-state cycle and 6-state bridge graphs, respectively), manifest a significantly greater neural similarity (<xref rid="fig3" ref-type="fig">Fig. 3D</xref>). For illustration purposes, we computed the average difference between feature similarity metrics for both prior learning conditions (4-cycle prior condition – 6-bridge prior condition), separately for each of the graph factors (see <xref rid="fig3" ref-type="fig">Fig. 3C</xref>). There was a statistically significant interaction effect of condition x graph factor spanning approximately 300 – 680 ms post-stimulus onset (cluster-level <italic>P</italic><sub>FWE</sub> = .004, corrected for multiple comparisons using non-parametric permutation tests, see Methods for details).</p>
<p>Post-hoc tests of condition differences for each graph factor indicated that within the time period where we observed a significant condition x graph factor effect, participants in the 4-cycle prior condition showed higher positive change in feature similarity that mapped on the 4-state cycle graph factor across both task phases, by comparison to participants in the 6-bridge prior condition (who experienced a 4-state path-graph in prior learning, <xref rid="fig3" ref-type="fig">Fig. 3D</xref>, green line, cluster-level <italic>P</italic><sub>FWE</sub>= .040, non-parametric permutation test), and vice versa for the 6-bridge condition (<xref rid="fig3" ref-type="fig">Fig. 3D</xref>, black line; dark green line in <xref rid="fig3" ref-type="fig">Fig. 3D</xref> represents time points at which feature similarity changes for both post-hoc contrasts are significant; cluster-level <italic>P</italic><sub>FWE</sub>= .002, non-parametric permutation test). Performing the former analysis with an unweighted average across the PCs that accounted for &gt;= 80% of the variance (all PCs contribute equally) yielded highly similar results (interaction effect of condition x graph factor from 320 – 690 ms post-stimulus onset; cluster-level <italic>P</italic><sub>FWE</sub> = .007, corrected for multiple comparisons using non-parametric permutation tests).</p>
<p>These results are not explained by participants simply learning to differentiate which of the 10 observed features pertain to the 4- or 6-state graph factors, since this predicts only a main effect of graph factor on neural similarity (features within one graph factor being represented more similarly than across graph factors), but not an interaction effect of condition x graph factor.</p>
<p>The findings indicate a task-induced, learning-related, increase in neural similarity for stimuli conditional on their mapping onto identical abstract subprocesses shared across task phases. This suggests a learning-related representational alignment between stimuli by virtue of adhering to a common abstract template (subprocess structure), supporting a central prediction of a structural scaffolding mechanism.</p>
</sec>
<sec id="s2c">
<title>Abstract representation of dynamical roles in subprocesses</title>
<p>We next tested a more fine-grained prediction of a structural scaffolding account. Under this, we would expect that every element of a specific subprocess would uniformly become similar to every other element of a shared abstract subprocess, but also an emergence of a fine-grained mapping of stimuli that reflected the precise “dynamical roles” they occupy within an underlying graph structure. Thus, we reasoned that if structure and dynamics of previous experiences are repurposed within new contexts, then transitions between stimuli that share the same dynamical roles would exhibit enhanced neural similarity. This predicts a higher decoding accuracy for transitions between entirely different stimuli that share an identical dynamical role. Note this can only be ascertained for the 6-state graph, as this graph alone incorporates stimuli in categorically distinct dynamical roles.</p>
<p>To test this, we focused on MEG data, recorded during prior and transfer learning phases, for compound stimulus presentations that adhered to specific abstract transition types in the 6- state graph factor (<xref rid="fig4" ref-type="fig">Figure 4A</xref>). Within the 6-state graph factor, we categorized these transitions into the three distinct transition types, reflecting their locations within the graph, e.g., transitions between boundary and intermediate graph nodes (1), transitions between intermediate and central graph nodes (2), or transitions between central and central graph nodes (3) respectively (see Methods for details). During prior learning, we trained classifiers on neural activity from stimuli that followed each of these three transition types. In the transfer learning phase, we then tested this classifier generalization to identical transition types, but where this now involved entirely different stimuli. We used two-sample t-tests to ascertain classification accuracy between participant groups who had experienced different graphs during prior learning (4-cycle prior condition experiencing a 6-path graph and 6-bridge prior condition experiencing a 6-bridge graph). This included multiple comparison correction based on nonparametric permutation tests.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Abstract representation of subprocess dynamics.</title>
<p>A) Knowledge reuse of decomposed subprocesses, discovered during prior learning, predicts neural similarities when subprocess dynamics are shared across prior and transfer learning. During prior learning, we trained multivariate classifiers (L1-regularized logistic regressions) to distinguish between different transition types in the 6-state graph factor for 4-cycle prior condition (6-path graph, top) and 6-bridge prior condition (6-bridge graph, bottom). We then tested the classifiers’ generalization ability on entirely new stimuli during transfer learning. Each number denotes a different type of transition, reflecting edges connecting graph nodes, namely boundary (1), intermediate (2), and central (3). During prior learning, classifiers were trained at post-transition stimulus presentations (e.g., in the 6-bridge prior, the classifier for transition type 2 was trained on neural activity recorded during presentations of the ball if preceded by the sandwich; or on the hammer if preceded by the ball). At transfer learning we tested the classifier’s generalization performance for identical transitions, but where this now involved entirely different stimulus sets. Since training and testing were performed on independent datasets this obviates cross-validation. Note that a comparison of classification accuracy across conditions was only possible for the 6-state graph factor, as the 4-state cycle does not provide for a distinction between transition types.</p><p>B) Transfer learning time courses of 6-state graph factor transitions classification accuracy, averaged per condition based on prior experience of either 4-cycle (green) or 6-bridge condition (black). Shaded error bars indicate standard errors of the mean. Black and grey bars above indicate temporal clusters in which classification accuracy differences between conditions (6-bridge prior condition &gt; 4-cycle prior condition) are significantly different (two-sample t-test), corrected for multiple comparisons at the cluster-level (<italic>P<sub>FWE</sub></italic> &lt; 0.05, non-parametric permutation test (first cluster (black): <italic>P<sub>FWE</sub></italic> = .035, two-tailed; second cluster (grey): <italic>P<sub>FWE</sub></italic> = .027, one-tailed). Horizontal lines indicate chance level decoding accuracy (.33).</p><p>C) Spearman correlations between average behavioral accuracy in 6-bridge experience probes and per participant averaged classification accuracy across all timepoints post-image onset where there is a significant condition difference between 4-cycle prior condition and 6-bridge prior condition on classification accuracy (see panel B). Each datapoint represents an individual participant. The 6-bridge prior condition (<italic>rho</italic> = .41, <italic>p</italic> = .041) showed a stronger positive correlation than the 4-cycle prior condition (<italic>rho</italic> = -.16, <italic>p</italic> = .440, correlation difference: <italic>Z</italic> = 1.99<italic>, p =</italic> .046, Fisher <italic>r</italic> to <italic>z</italic>).</p><p>D) Spearman correlations between average behavioral accuracy in 6-bridge inference probes and per participant averaged classification accuracy across all timepoints post-image onset where there is a significant condition difference between 4-cycle prior condition and 6-bridge prior condition on classification accuracy (see panel B). Each datapoint represents an individual participant. There was no evidence for a correlation difference between the 6-bridge prior condition (<italic>rho</italic> &lt; .01, <italic>p</italic> = .996) and the 4- cycle prior condition (<italic>rho</italic> = .09, <italic>p</italic> = .657, correlation difference: <italic>Z</italic> = .32<italic>, p =</italic> .752, Fisher <italic>r</italic> to <italic>z</italic>).</p></caption>
<graphic xlink:href="614119v2_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Following onset of a post-transition compound stimulus presentation, classification accuracy changes were evident between participants who had experienced different graphs during prior learning (6-path graph and 6-bridge graph), spanning two distinct temporal clusters between 135 and 350 ms post stimulus-onset (<xref rid="fig4" ref-type="fig">Figure 4B</xref>, first cluster (black bar): cluster-level corrected <italic>P</italic><sub>FWE</sub>= .035, two-tailed; second cluster (grey bar): <italic>P</italic><sub>FWE</sub>= .027, one-tailed, non-parametric permutation tests). Thus, enhanced neural decodability was evident for stimuli that shared transition types in the 6-bridge prior condition, an effect absent in participants who had experienced the 6-path graph (4-cycle prior condition). This indicates emergence of neural similarity for stimuli whose roles adhere to the same structural dynamics across experiential contexts, supporting a fine-grained prediction of a structural scaffolding account. While our data does not provide for an unequivocal interpretation of these dynamical roles, one possibility is that individuals differentiate transitions along the 6-bridge component based on how they relate to the unique central “bridge” formed between the 2 central nodes (e.g., the transitions between nodes 7 and 10 in <xref rid="fig3" ref-type="fig">Fig 3B</xref>). For example, transitions can be characterized as movement outside bridge nodes (1), arriving to/moving away from bridge nodes (2) and crossing the bridge (3). This representation of dynamical roles might confer benefits to task performance – a possibility we tested next.</p>
</sec>
<sec id="s2d">
<title>Dynamical role generalization and behavioral performance</title>
<p>Having identified a neural signature of subprocess dynamics, during transfer learning we next asked whether dynamical role classification accuracies from the previous analysis (<xref rid="fig4" ref-type="fig">Fig. 4B</xref>) related to behavioral performance. Averaging classification accuracy over time points showed significant condition differences (<xref rid="fig4" ref-type="fig">Fig. 4B</xref>) we found for experience probes a selective positive correlation between average classification accuracy and behavioral performance for the 6- bridge prior condition (6-bridge prior condition: <italic>rho</italic> = .41, <italic>p</italic> = .041, Spearman correlation; 4- cycle prior condition: <italic>rho</italic> = -.16, <italic>p</italic> = .440; correlation difference: <italic>Z</italic> = 1.99<italic>, p =</italic> .046, Fisher <italic>r</italic> to <italic>z</italic>; <xref rid="fig4" ref-type="fig">Fig. 4C</xref>). No such relationship was evident for inference probes (6-bridge prior condition: <italic>rho</italic> &lt; .01, <italic>p</italic> = .996, Spearman correlation; 4-cycle prior condition: <italic>rho</italic> = .09, <italic>p</italic> = .657; correlation difference: <italic>Z</italic> = .32<italic>, p =</italic> .752, Fisher <italic>r</italic> to <italic>z;</italic> <xref rid="fig4" ref-type="fig">Fig. 4D</xref>). These findings are consistent with a notion that dynamical role representations subserved by different task states have behavioral benefits. Speculatively, this knowledge representation might help individuals constrain their predictions for successive states. For example, upon transitioning to a bridge node one can predict that the successor state will involve “the other side of the bridge”. At first sight the correlation results appear inconsistent across experience and inference probes. However, it is important to consider that the MEG classifiers were trained and tested on experienced transitions alone such that the classification accuracy may reflect a neural representation of experienced transitions. Under this reasoning, the MEG classifier would be expected to more closely align with the behavioral accuracy for the experience probes (testing actually experienced transitions) than the inference probes (testing never experienced but only implied transitions on the graph). While the observed direction of the correlation and correlation difference are expected under an account based on prediction of successor states, we caution that this individual difference analysis is low-powered due to the number of participants per condition. Thus, these findings need to be replicated in independent samples to ensure robustness of the findings.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>The philosophical adage of Heraclitus, “you can never step into the same river twice”, reflects much everyday experience of the world. Yet even the most complex experiences tend to share structural similarity with the past, where this often entails a recurrence of experiential subprocesses. These recurrent world properties imply that exploiting regularities derived from past experience should enable agents to effortlessly master the relentless demands of complex and ever-changing environments (Gentner, 1983). More specifically, it has been proposed that agents reuse abstract components (“building blocks”) of past experience as a “scaffolding” to facilitate integration of new information (<xref ref-type="bibr" rid="c1">Al Roumi et al., 2021</xref>; <xref ref-type="bibr" rid="c28">Luettgau et al., 2024</xref>; <xref ref-type="bibr" rid="c38">Pesnot Lerousseau &amp; Summerfield, 2024</xref>). Indeed, growing evidence consistent with a compositional (re-)use of acquired knowledge provides a plausible cognitive mechanism to explain how humans generalize knowledge from prior experiences (<xref ref-type="bibr" rid="c4">Barron et al., 2013</xref>; <xref ref-type="bibr" rid="c25">Lake et al., 2015</xref>, <xref ref-type="bibr" rid="c26">2017</xref>; <xref ref-type="bibr" rid="c28">Luettgau et al., 2024</xref>).</p>
<p>Here, we replicate previous behavioral findings for parsing of subprocesses that generate the dynamics of experience, replicating (<xref ref-type="bibr" rid="c28">Luettgau et al., 2024</xref>), and now provide neural evidence consistent with a proposed abstract representational scaffolding, including providing evidence for temporally resolved neural dynamics that support compositional generalization. The neural realization of such a scaffolding is the subject of computational accounts of hippocampal and entorhinal cortex function, where grid cell activity is proposed as providing a basis set representation of abstract structure inferred from sensory experiences (<xref ref-type="bibr" rid="c6">Behrens et al., 2018</xref>; <xref ref-type="bibr" rid="c31">Mark et al., 2020</xref>; <xref ref-type="bibr" rid="c55">Whittington et al., 2020</xref>, <xref ref-type="bibr" rid="c54">2022</xref>). However, the precise temporal dynamics of such a structure mapping have remained elusive. We hypothesized that compositional generalization in our task is achieved by abstracting, and neurally representing, relational units of prior experience (“building blocks”) to facilitate their flexible use in new contexts. In principle, this could be enabled by mapping new incoming sensory information onto pre-existing structural templates. We conducted three empirical tests of this “structural scaffolding” hypothesis.</p>
<p>We conducted three empirical tests of the structural scaffolding hypothesis and outlined neural dynamics supporting this mechanism. Firstly, we show the neural dynamics for task-induced representational alignment of unrelated stimuli, presented across different task phases and embedded in novel complex dynamics, conditional on these adhering to identical subprocesses. Specifically, we observed a condition-specific, learning-induced, increase in neural similarity between stimuli mapping to the same abstract structural subprocesses around 300 – 680 ms post-stimulus onset, a finding consistent with the notion of task structure generalization (<xref ref-type="bibr" rid="c3">Baram et al., 2021</xref>) and neural state space alignment (<xref ref-type="bibr" rid="c46">Sheahan et al., 2021</xref>). Here, we extend these findings by detailing the associated neural dynamics supporting compositional generalization. The temporal signature of this similarity change signal (peaking around 500 ms post-stimulus onset), echoes previous findings showing emergence of an abstract structural representation purported to account for aberrant inference and delusions in psychopathology (<xref ref-type="bibr" rid="c35">Nour et al., 2021</xref>).</p>
<p>Secondly, we found that stimuli sharing the same dynamical role across different learned structures come to exhibit a neural similarity, where generalizability is positively related to experience probe behavioral performance. While the direction of these brain-behavior correlations are predicted by a structural scaffolding account, we caution this result needs independent replication to ascertain its robustness. We acknowledge that such a brain-behavioral correlation was not present for inference probes. However, we caution that the MEG classifiers were trained and tested on experienced transitions alone – the classification accuracy thus reflects a neural representation of experienced transitions. Considering this, we reason that the MEG classification signal would be expected to more closely align with the behavioral accuracy in the experience probes (testing actually experienced transitions), instead of inference probes (testing never experienced but only implied transitions on the graph).</p>
<p>Thirdly, a behavioral accuracy group difference in predicting successive states for the 6-bridge inference probe performance was of negligible magnitude and did not align with the robust effect observed for experience probes (<xref rid="fig2" ref-type="fig">Fig. 2D</xref>), where the latter replicates and extends a previous finding using a 6-state cycle graph and predicted by computational simulations using successor feature models (<xref ref-type="bibr" rid="c28">Luettgau et al., 2024</xref>). We speculate that the disparity between probe types is likely due to experience probes and inference probes engaging dissociable cognitive processes – the former relying on predictive representations acquired from experience. the latter relying on an ability to perform mental operations on learned representations of independent feature transitions. This may increase the likelihood of errors due to complexities of the inferred state spaces. However, the observed differences could also relate to previously reported effects of explicit knowledge on performance levels (<xref ref-type="bibr" rid="c28">Luettgau et al., 2024</xref>) or be driven by capacity limitations in working memory taxing larger subprocesses more strongly (<xref ref-type="bibr" rid="c8">Collins et al., 2017</xref>; <xref ref-type="bibr" rid="c9">Collins &amp; Frank, 2012</xref>). At the very least our findings indicate striking learning and generalization abilities based on factorization of complex experiences into underlying structural elements, parsing these into distinct subprocesses derived from past experience, and forming a representation of the dynamical roles these features play within distinct subprocesses. These representations, in turn, support prediction of successive features leading to more accurate performance.</p>
<p>Our neural findings suggest that building and maintenance of abstract representations of subprocesses allows factoring out the idiosyncrasies of the complex dynamics of experience. While the principal aim of the present study was to characterize the temporal dynamics of a neural mechanism for compositional generalization of structural knowledge, it is important to consider that MEG recordings reflect an aggregate neural signal. Consequently, our analyses do not support inferences about regional brain sources of the observed signal. A prior literature indicates this type of mapping relates to activity of entorhinal cortex grid cells, where these compute invariant representations of relational structure underlying experience that is abstracted away from its sensory specifics (<xref ref-type="bibr" rid="c6">Behrens et al., 2018</xref>; <xref ref-type="bibr" rid="c21">Kazanina &amp; Poeppel, 2023</xref>; <xref ref-type="bibr" rid="c31">Mark et al., 2020</xref>; <xref ref-type="bibr" rid="c55">Whittington et al., 2020</xref>, <xref ref-type="bibr" rid="c54">2022</xref>) This representational form significantly reduces a learning computational burden by lessening a requirement for inferring the structural components determining experiential dynamics, allowing an attentional focus on the idiosyncrasies of an experience (e.g., which stimulus features are currently behaviorally relevant).</p>
<p>The proposed structural scaffolding mechanism also draws on ideas that organizing information within structured representations, including abstract neural geometries, facilitates few-shot concept learning (<xref ref-type="bibr" rid="c49">Sorscher et al., 2022</xref>). The neural signatures we identify are consistent with the emergence of low dimensional representations of abstract disentangled task variables, leveraged for generalization to new contexts, as previously documented in the hippocampal-entorhinal system (<xref ref-type="bibr" rid="c3">Baram et al., 2021</xref>; <xref ref-type="bibr" rid="c7">Bernardi et al., 2020</xref>; <xref ref-type="bibr" rid="c11">Courellis et al., 2024</xref>; <xref ref-type="bibr" rid="c34">Nieh et al., 2021</xref>), frontal cortex (<xref ref-type="bibr" rid="c7">Bernardi et al., 2020</xref>; <xref ref-type="bibr" rid="c14">Flesch et al., 2022</xref>, <xref ref-type="bibr" rid="c15">2023</xref>; <xref ref-type="bibr" rid="c58">Zhou et al., 2021</xref>) or posterior parietal cortex (<xref ref-type="bibr" rid="c14">Flesch et al., 2022</xref>, <xref ref-type="bibr" rid="c15">2023</xref>). Furthermore, evidence indicates that an encoding of abstract task structure (progress to goal), within rat medial frontal cortex, facilitates learning of complex behavioral sequences (<xref ref-type="bibr" rid="c13">El-Gaby et al., 2023</xref>) and that such representations emerge in artificial neural networks trained to perform multiple tasks (<xref ref-type="bibr" rid="c20">Johnston &amp; Fusi, 2023</xref>; <xref ref-type="bibr" rid="c56">Yang et al., 2019</xref>). One implication of our findings is that a representational scaffolding helps to align neural state spaces that encodes structure across experiential contexts. Within this account, similar state transition dynamics and dynamical roles encountered in distinct experiential contexts, results in stimuli that adhere to these being represented closer in a neural activity space (<xref ref-type="bibr" rid="c7">Bernardi et al., 2020</xref>; <xref ref-type="bibr" rid="c11">Courellis et al., 2024</xref>; <xref ref-type="bibr" rid="c46">Sheahan et al., 2021</xref>), putatively constraining a hypothesis space over abstract structural components that make up new experiences.</p>
<p>An important avenue for future research relates to the neural mechanism that supports an algorithmic implementation of the proposed “structural scaffolding” and how subprocess dynamics are disentangled. One plausible mechanism involves a separation of subprocess representations via preferential reactivation at different positions in the theta cycle, or by preferred reactivation coupled to distinct peaks or troughs in theta oscillations (analogous to a role of theta oscillations in vicarious trial-and-error computations, <xref ref-type="bibr" rid="c40">Redish, 2016</xref>). Our findings hint at such a mechanism by showing successor predictive representations are encoded neurally during transfer learning, finding decoding evidence of successor features from a current state’s neural activity pattern (Supplementary Figure 2 and Supplementary Results). Alternatively, gradual learning, and insight-dependent decomposition of an experienced compound stimulus sequence into underlying subprocesses could be enabled by human replay, extending previous accounts that propose a role in compositionality (<xref ref-type="bibr" rid="c24">Kurth-Nelson et al., 2023</xref>; <xref ref-type="bibr" rid="c45">Schwartenbeck et al., 2023</xref>). We explored the latter possibility but did not detect reliable replay effects within the constraints of our experimental design (see Supplementary Results for discussion). Relatedly, there is the question of how, and under what conditions, the structure of previous experiences map to current experience. In future experiments structural similarity and size of the generalized state spaces of subprocesses in prior and transfer learning phases could be systematically varied to delineate the boundaries of mapping experiential dynamics across contexts. Future neuroimaging (fMRI) studies based on representational similarity analysis (e.g., <xref ref-type="bibr" rid="c29">Luettgau et al., 2022</xref>) or repetition suppression (e.g <xref ref-type="bibr" rid="c5">Barron et al., 2016</xref>; <xref ref-type="bibr" rid="c16">Garvert et al., 2017</xref>, <xref ref-type="bibr" rid="c17">2023</xref>; <xref ref-type="bibr" rid="c30">Luettgau et al., 2020</xref>) could also contribute to pinpointing the precise functional anatomy, including a predicted involvement of the hippocampal-entorhinal system (<xref ref-type="bibr" rid="c3">Baram et al., 2021</xref>; <xref ref-type="bibr" rid="c7">Bernardi et al., 2020</xref>; <xref ref-type="bibr" rid="c11">Courellis et al., 2024</xref>; <xref ref-type="bibr" rid="c34">Nieh et al., 2021</xref>).</p>
<p>A key contribution of our study is that it provides an empirical test of an abstract structural scaffolding as a mechanism supporting human compositional generalization. We show that such a mechanism enables reuse and compositional generalization of abstracted relational units of prior experience (“building blocks”) and highlight the temporal neural dynamics of this proposed mechanism. In the latter account, similar state transition dynamics encountered in highly distinct experiential contexts are represented more closely in neural activity space than dissimilar ones, allowing a sharing of components across distinct experiences. Finally, we note that failures in efficient knowledge decomposition, involving acquisition and reuse of an abstract neural scaffolding, might impact a flexibility of cognition that is considered one of the hallmarks of mental health (<xref ref-type="bibr" rid="c19">Huys et al., 2016</xref>; <xref ref-type="bibr" rid="c51">Story et al., 2024</xref>).</p>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Participants and procedures</title>
<p>Participants were recruited from the local student community at University College London (UCL) via an online recruitment platform between October 2022 and May 2023. Only participants reporting the absence of past or present mental health conditions or neurological conditions were included.</p>
<p>A total of 61 participants were recruited with 51 included in the final behavioral data analysis sample (<italic>N</italic> = 1 discontinued the experiment due to a headache, <italic>N</italic> = 1 excluded due to a technical error, <italic>N</italic> = 1 excluded due to indicating a diagnosis of aphantasia in post-experimental debriefing, <italic>N</italic> = 3 due to repeatedly falling asleep and closing their eyes during the experimental task, <italic>N</italic> = 4 were excluded due to low motivation and indicating that they gave up learning the sequence during the experiment). One additional participant was excluded from MEG data analyses due to a metal artifact, leaving 50 healthy volunteers for the final MEG sample (median age: 23 years, <italic>SD</italic> = 3.69, range = 18 – 36, 9 males), <italic>N</italic> = 25 subjects per condition. We did not perform a formal power calculation to determine the sample size but instead opted to base the sample size on that used in similar MEG studies previously conducted in our lab. Participants received £10.00 per hour as compensation. The study was approved by the University College London Research Ethics Committee (reference number: 3090/004) and conducted in accordance with the Declaration of Helsinki.</p>
<p>After providing informed written consent subjects were prepared for the MEG scan. Participants received written instructions regarding the pre-task localizer session on the presentation screen in the MEG scanner room. Following these instructions, subjects were asked to explain the pre-task localizer. Subsequently, participants received instructions regarding the sequence learning task and then were randomly assigned to one of the two experimental conditions (see Experimental design and behavioral task). Upon completion of the sequence learning task, participants performed a post-learning localizer task. At the end of the experiment participants filled out a sociodemographic questionnaire and a post-experimental questionnaire that assessed strategies used as well as their general understanding of the task, followed by a debriefing regarding the aims and motivation behind the study.</p>
</sec>
<sec id="s4b">
<title>Experimental design and behavioral task</title>
<sec id="s4b1">
<title>PRE localizer</title>
<p>Stimuli representing states in the graphs comprised depictions of everyday objects, landscapes, and animals/humans, arranged to create meaningful holistic scenes (e.g., a boy and a ball, or a cat in a car). Images were selected from Pixabay (<ext-link ext-link-type="uri" xlink:href="https://pixabay.com/">https://pixabay.com/</ext-link>), where two images were manually assembled to form one compound image using Inkscape (<ext-link ext-link-type="uri" xlink:href="https://inkscape.org/">https://inkscape.org/</ext-link>). We used two non-overlapping and unrelated sets of ten images to compose the compound images. The assignment of sets and the positions of the two images used to create the compound images on the underlying graph structures producing the observed sequences were counterbalanced across subjects and conditions. This mitigated a potential confound in learning, as well as choice biases, due to idiosyncrasies inherent in the compound images. The PRE localizer task comprised 5 blocks, involving presentation of 960 or 1020 stimuli (depending on whether participants were allocated to the 4-cycle prior or the 6- bridge prior condition) in the center of the MEG presentation screen (stimulus presentation duration: 650 ms), with an inter-stimulus interval of 583 (±116) ms, drawn from a truncated, discretized gamma distribution (shape = 1.5, scale = 0.5), marked by a blank screen. The 20 distinct features presented during prior and transfer learning phase (10 features per task phase, respectively) with the 12 or 14 compound images (4-cycle prior or the 6-bridge prior condition, respectively) shown during the prior learning phase being presented 30 times each.</p>
<p>Each compound image was presented as foreground to a unique background image (textures) that was randomly assigned to each compound image per participant. This design feature was intended to amplify the dissimilarity between compounds that might share individual features. Participants were instructed to monitor the presented stimuli carefully. Attention to the presented stimuli was assessed based upon 10% pseudo-randomly selected stimulus presentations being used to probe subjects regarding the last presented image. Here, a probe question, “Previous image?” was presented alongside two English words, on the left- and right- hand side to the center of the screen, describing the correct last stimulus or an alternative incorrect stimulus (order randomized across stimulus presentations, duration: 4000 ms). The words describing compound images were selected such that the holistic nature of the scene (instead of the distinct features) was emphasized. Each stimulus (features and compounds) was probed equally often. Participants responded by selecting the left or right response button and if they did not respond within 4000 ms a time out warning message was presented for 1500 ms. Participants were not provided with feedback about the accuracy of their responses but received summary feedback about their overall accuracy during the last block.</p>
</sec>
<sec id="s4b2">
<title>POST localizer</title>
<p>The POST localizer task was identical to the PRE localizer task. However, only the 20 features were presented, but not the compound images shown during the prior learning phase. Thus, during the POST localizer participants were presented with 600 stimuli.</p>
</sec>
<sec id="s4b3">
<title>Sequence learning task</title>
<p>In a sequence learning paradigm (<xref ref-type="bibr" rid="c28">Luettgau et al., 2024</xref>) subjects were presented with sequences of compound images. In a between-subjects design, during prior learning one group of participants (condition 1, 4-state cycle prior) observed sequences of image compositions (12 compound images total, composed from 10 individual features) drawn from the product graph of a cyclic graph factor with 4 states (e.g. A-&gt;B-&gt;C-&gt;D-&gt;A …) and a path-graph factor with 6 states (e.g. 1&lt;-&gt;2&lt;-&gt;3&lt;-&gt;4&lt;-&gt;5&lt;-&gt;6, 4 x 6 factorization). The other group (condition 2, 6-state bridge prior) saw compound image sequences (14 compound images total) produced by a bridge graph factor with 6 states (e.g., 7-&gt;8-&gt;9-&gt;7-&gt;10-&gt;11-&gt;12-&gt;10-&gt;7, …, 4 x 6 factorization) and a path-graph factor with 4 states (e.g., E&lt;-&gt;F&lt;-&gt;G&lt;-&gt;H). Participants observed 54 image sequences during this ‘prior learning’ phase. Each compound image was presented in front of a unique background image (textures) that was randomly assigned to each compound image per participant.</p>
<p>Subsequently, during a transfer learning phase, we tested subjects on entirely new image compositions (16 transitions between compound images from two disjoint subgraphs of the compound graph (8 unique compound images per subgraph), composed from 10 novel individual features, <xref rid="fig1" ref-type="fig">Fig. 1C</xref>) where these were generated from the product graph of a cyclic graph (4 states, e.g. A’-&gt;B’-&gt;C’-&gt;D’-&gt;A’…) and a bridge graph (6 states, e.g., 7’-&gt;8’-&gt;9’-&gt;7’-&gt;10’-&gt;11’-&gt;12’-&gt;10’-&gt;7’, …, 4 x 6 factorization). The presentation of these transitions alternated between two presentations of subgraph sequence 1 (<xref rid="fig1" ref-type="fig">Fig. 1F</xref>, left), and two presentations of subgraph sequence 2 (<xref rid="fig1" ref-type="fig">Fig. 1F</xref>, right). To avoid learning “impossible” transitions between the terminal element of one sequence to the first element of the other we explicitly instructed participants regarding the start of a new sequence presentation. Participants observed 48 image sequences during this transfer learning. Note that the 6-bridge graphs used in prior and transfer learning did not feature a truly bi-directional edge between the central nodes (7//7’ and 10/10’), but rather a “refractory” edge, indicating that it was not possible to transition back and forth within one step between central nodes of the graph.</p>
<p>The nature of the factorization allowed us to present only a subset of 12 or 14 compound stimuli, respectively. Therefore, during both task phases, participants did not experience the full set of all 24 possible image compositions implied by the 4 x 6 graph factorization. A held-out set of transitions between compound stimuli (partially observed during sequence presentations, partially never observed during sequence presentations) provided a context for assessing knowledge of graph factorization.</p>
<p>Each sequence comprised 8 compound image presentations in the center of the screen (stimulus presentation duration: 1000 ms), interleaved by an inter-stimulus interval of 750 ms, marked by a blank screen.</p>
<p>Following each presented sequence, two probe questions asked participants to predict upcoming states. This assessed knowledge of either of transitions between the experienced compound stimuli in the sequence (experience probes), or their ability to infer and predict never experienced transitions between compound images, where the latter are implied by the 4 x 6 graph factorization (inference probes). We reasoned that participants could only attain above chance predictions about never experienced transitions if they had encoded a factorized representation of the true generative state space underlying the observed image compositions.</p>
<p>In each probe question, participants first saw a randomly selected compound image from the experienced sequence, or an entirely new compound image, with a probe question “Imagine you see this image. What would be the next image?” (duration: 3000 ms). Probe questions testing knowledge of never experienced transitions between compound images did not feature unique background images. Following the probed image, two compound images – the correct next image and a lure image – were presented as choice options on the left- and right-hand side next to the screen center. Crucially, on each probe, the lure image was matched with the correct option on one of the two features (e.g., A1 -&gt; B2 or D2), a design feature that allowed us to test knowledge of both graph factors underlying the observed sequence separately, as well as assess knowledge about never experienced transitions between compounds. Each unique compound image in the sequence (and each never experienced transition) was used exclusively to assess knowledge of one of the two graph factors, but not both. The latter was intended to control for a possibility that participants might guess and remember the correct answer for each probe question by observing the same correct option repeatedly presented alongside different, changing lure images – allowing for the inference that the consistent option must be the correct one – even without knowing anything about the compound sequence, or correctly inferring transitions between novel compounds. Each transition within each graph factor was probed equally often in both prior and transfer learning phases.</p>
<p>During each probe question, participants had 4500 ms to select the left or right option by using the left or right button on two button boxes held in both hands. If they failed to respond within this time window, a timeout warning was presented for 1500 ms and the probe question was coded as a missing event. Participants did not receive feedback about whether they answered correctly or not on any given probe question. Between the experience and inference probe questions, there was a blank screen for 5000 ms (inter-probe interval). After the inference probe, the sequences proceeded.</p>
<p>The task comprised 8 blocks, with short breaks after every 14<sup>th</sup> or 12<sup>th</sup> (transfer learning phase) presented sequence and a longer break (5 min) between prior and transfer learning. During these breaks, participants received feedback about their average performance in the experience probe questions up until this trial. As well as assessing whether participants entertained a factorized representation of the graph factors generating the sequence of compound observations, our transfer learning task design allowed us to test a prediction that participants form abstractions of the decomposed or factorized state space, and reuse components of the abstracted generative processes (graph factors) they had encountered in prior learning in an entirely new context, the transfer learning phase. Importantly, the experimental design also implies a second type of transfer learning, other than reusing a graph factor during the second learning phase: Participants could repurpose their knowledge about the experienced transitions (as assessed by experience probes) to infer never experienced transitions on the graph factors (as assessed by inference probes).</p>
</sec>
</sec>
<sec id="s4c">
<title>Behavioral analyses</title>
<p>Data were preprocessed and analyzed in MATLAB 2023b (The MathWorks, Inc., Natick, MA, USA) and RStudio (<xref ref-type="bibr" rid="c42">RStudioTeam, 2019</xref>) (version 4.1.0, RStudio Team, Boston, MA) using custom analysis scripts. We defined Bayesian multilevel generalized linear models (GLM), representing different processes that might have generated the observed choice data using the R package rethinking (<xref ref-type="bibr" rid="c32">McElreath, 2020a</xref>, 2020b). We specified binomial likelihood functions to model the (aggregated) number of correct responses distributed as the proportion of correct probes (binomial distribution parameter <italic>p</italic>) among the number of probes for which a response was recorded (number of probes). We employed sampling-based Bayesian inference to estimate the posterior distribution of linear model parameters comprising different intercept and slope parameters that linearly combine to form the binomial distribution parameter <italic>p</italic>. In the below models, µ denotes average/group level effects (“fixed effects”), α and γ denote individual or individually covarying effects (“random effects”). We coded the probed size effect as –.5 (for 4-cycle probes) and as .5 (for 6-bridge probes). A negative value of the parameter estimate indicates higher accuracy for 4-cycle probes. The probe type effect was coded similarly (experience probes as –.5; inference probes as .5). A negative value of the parameter estimate indicates higher accuracy for experience probes. The condition effect was coded as –.5 (for 4-cycle prior condition) and as .5 (for 6-bridge prior condition). A negative value of the parameter estimate indicates higher accuracy for the 4-cycle prior condition.</p>
<p>For each of the below models, we specified weakly informative prior and hyperprior probability distributions (as indicated in the model specifications). Models were passed to RStan (<xref ref-type="bibr" rid="c50">Stan Development Team, 2020</xref>) using the function “ulam” (rethinking package). We drew 4 x 4000 samples from posterior probability distributions (4 x 1000 warmup samples), using No-U-Turn samplers (NUTS; a variant of Hamiltonian Monte Carlo) in RStan and four independent Markov chains. Quality and reliability of the sampling process were evaluated with the Gelman-Rubin convergence diagnostic measure (<italic>R̂</italic>≈ 1.00) and by visually inspecting Markov chain convergence using trace- and rank-plots. For all models fitted we found <italic>R̂</italic> = 1.00 for all parameters sampled from the posterior distribution. There were no divergent transitions between Markov chains for any of the models reported.</p>
<p>For model comparisons and to find evidence for the best-fitting model for the observed behavioral data, we used the Widely Applicable Information Criterion (WAIC). Parameter estimates were considered non-zero if the Bayesian credible interval (CI) around the parameter did not contain zero.</p>
<p>We defined a model space of four Bayesian multilevel (statistical models, GLM1 – GLM4, <xref rid="eqn1" ref-type="disp-formula">Eq. 1</xref>-4) generalized linear models (cf. <xref ref-type="bibr" rid="c29">Luettgau et al., 2022</xref>, <xref ref-type="bibr" rid="c28">2024</xref>). Both experience and inference probe correct responses were analyzed in a joint model to reduce the number of tests of the same statistical hypothesis and to increase statistical power (a joint model should capture within-subject performance ability and correlations across both probe types more adequately and explicitly than two separate models for both probe types).</p>
<p>To test our main hypothesis, that participants factorized and abstracted structure underlying their experience during prior learning and reused an abstracted graph factor that was consistent across prior and transfer learning, we focused on transfer learning phase behavior. We expected an advantage in predicting 4-cycle graph factor transitions in the 4-cycle prior condition (vs 6-bridge prior condition), and vice versa, enhanced performance in 6-cycle graph factor transitions in the 6-bridge prior condition (vs 4-cycle prior condition). Formally, this pattern of responses should reflect in an interaction effect between condition and probed size. We therefore predicted that the best-fitting model for the observed behavioral data (as found in model comparison) would feature a non-zero interaction effect between condition and probed size, suggesting that this effect captures important unique variance in explaining participants’ choice behavior.</p>
<p>GLM1. Individually varying intercepts model. This model assumes that correct responses are invariant across probed sizes, probe types, and conditions.
<disp-formula id="eqn1">
<graphic xlink:href="614119v2_eqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>Correct</italic> denotes the number of correct probes, distributed as the proportion of correct probes (binomial distribution parameter <italic>p</italic>) among the number of probes for which a response was recorded (number of probes), <italic>n</italic> denotes the parameter estimate for the n-th subject. Note that the model is reparametrized to allow sampling from a standard normal posterior distribution. <italic>α<sub>sigma</sub></italic> denotes the standard deviation of the reparameterized normal distribution of the varying intercepts parameter <italic>α</italic>.</p>
<p>GLM2. Individually varying intercepts, main effect of probe type (<italic>PT</italic>), covarying intercept and probe type effect
<disp-formula id="eqn2">
<graphic xlink:href="614119v2_eqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>MVNormal</italic> is a multivariate normal/Gaussian distribution, the correlation matrix <italic>R<sub>PT</sub></italic> is distributed <italic>as LKJcorr</italic> distribution (Lewandowski-Kurowicka-Joe distribution). We used non-centered parameters for the covariance matrix <italic>S</italic> (Cholesky decomposition) to facilitate estimation using sampling-based inference. j denotes the parameter estimate for the j-th probe type (experience or inference probe). <italic>σ</italic> are the variance parameters for the subject specific intercept parameter and probe type parameter.</p>
<p>GLM3. Individually varying intercepts, main effects of probed size, probe type and condition, interaction effect of probed size x condition (<italic>SIZE x COND</italic>), covarying intercept and probed size, probe type effect
<disp-formula id="eqn3">
<graphic xlink:href="614119v2_eqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>k</italic> denotes the parameter estimate for the k-th condition (4-cycle prior condition or 6-bridge prior condition), i denotes the parameter estimate for the i-th probed size (4-cycle probe or 6-bridge probe) GLM4. Individually varying intercepts, main effects of probed size, probe type and condition, interaction effect of probed size x condition and probed size x probe type x condition (<italic>SIZE x PT x COND</italic>), covarying intercept and probed size, probe type effect
<disp-formula id="eqn4">
<graphic xlink:href="614119v2_eqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
</sec>
<sec id="s4d">
<title>GLM comparison</title>
<p>A multilevel GLM featuring all of the above effects and a three-way interaction effect of probed size x probe type x condition (GLM4) showed slightly better model fits than a multilevel GLM featuring individually varying intercepts, main effects of probed size and probe type, as well as covariation with the individually estimated intercept parameters, a main effect of condition, and an interaction effect of probed size x condition (GLM3) (WAIC values (± standard error): GLM4 = 1015.2 (±21.25), GLM3 = 1020.2 (±22.11)). All other GLMs explained the data less well than GLM4 (WAIC values (± standard error): GLM2 = 1101.4 (±33.04), GLM1 = 1151.9 (±38.60)). Crucially, there was strong model evidence that GLMs featuring varying intercepts alone (e.g., GLM1), representing the alternative hypothesis of participants entertaining a compound representation of their experience, was much worse explaining observed behavioral data.</p>
<p>The model comparison suggests that the effects for probed size and prior learning condition on behavioral accuracy were qualified by a three-way interaction effect between these two variables and probe type (experience vs inference) (GLM4). We thus followed up on this analysis by using post-hoc GLM3 featuring main effects for probed size, and prior learning condition and an interaction effect between these two variables separately for both probe types (excluding the probe type main effect)</p>
</sec>
<sec id="s4e">
<title>MEG acquisition and preprocessing</title>
<p>MEG (magnetoencephalography) was recorded at 1200 Hz using a whole-head 275-channel axial gradiometer MEG system (CTF Omega, VSM MedTech), while participants sat upright. 3 sensors were not recorded across all participants due to excessive baseline noise. Preprocessing was conducted separately for each recording block, identical to previous studies from our laboratory (e.g., <xref ref-type="bibr" rid="c35">Nour et al., 2021</xref>). Sensor data were high-pass filtered at 0.5 Hz to remove slow-drifts. Data were then down sampled to 100 Hz. Noisy segments and sensors were automatically detected and removed before independent component analysis (ICA). ICA (FastICA, <ext-link ext-link-type="uri" xlink:href="http://research.ics.aalto.fi/ica/fastica">http://research.ics.aalto.fi/ica/fastica</ext-link>) was used to decompose the sensor data for each session into 150 temporally independent components and associated sensor topographies. Artifact components (e.g., eye blink and heartbeat interference) were automatically classified by consideration of the spatial topography, time course, kurtosis of the time course and frequency spectrum for all components (<xref ref-type="bibr" rid="c35">Nour et al., 2021</xref>). Artifacts were rejected by subtracting them out of the data. Before cutting the MEG data into individual stimulus presentations, we re-aligned triggers to a photodiode signal that was recorded in response to each stimulus presentation, to ensure high precision of neural time series. All MEG analyses were performed on the filtered, cleaned MEG signal from each sensor at whole-brain sensor level, in units of femtotesla. Note that for each participant different MEG sensors were excluded, based on the identified noise level. Only sensors that were not identified as noisy consistently across localizer or main task runs – depending on the respective analyses – were included. We treated noisy sensors to be missing completely at random.</p>
</sec>
<sec id="s4f">
<title>MEG data analysis</title>
<sec id="s4f1">
<title>Feature similarity analysis</title>
<p>We conducted a feature similarity analysis (inspired by representational similarity analysis (RSA) (<xref ref-type="bibr" rid="c22">Kriegeskorte et al., 2008</xref>)) to investigate task-related changes in abstract graph factor representations from PRE to POST localizer. To this end, for each session we z-scored the pre-processed MEG data over all stimulus presentations, for each sensor and from -200 to 800 ms relative to stimulus-onset. To denoise the data and reduce dimensionality, the z-scored sensor x time x stimulus presentations data was subjected to principal components analysis (resulting in a PC [20] x time x stimulus presentations data matrix, 20 PCs per subject, explaining &gt;= 90% of the variance). We regressed the neural data onto a session-specific design matrix, denoting the stimulus label of each stimulus presentation (dummy coded). We used the resulting [feature x 1] vector of regression weights, as an estimate of the unique PC activation related to each feature. We repeated this procedure for all PCs. We then calculated the pairwise absolute differences between features as distance metric at each time point, for each PC separately. This generated a symmetrical [20 × 20] Representational Dissimilarity Matrix (RDM) at each time point. To retain as much stimulus similarity information contained within the neural data as possible, while discarding noisy components, we used the 20 PC-related RDMs to compute a weighted average RDM for each participant at each time point (in both localizer tasks separately). The weighting of the average RDM was based on explained variance of the PCs included in the analysis. For each participant individually this encompassed the top RDM computed on the PCs that cumulatively explained &gt;= 80% of the variance of the data. To enable an estimate of task-induced PRE-POST changes, we then computed the difference in weighted averaged RDMs (POST minus PRE). We regressed out across set confusion (e.g., prior learning 4-state graph factor and transfer learning 6-state graph factor) to control for general effects of set similarity. Finally, on the residuals of this regression, we computed Kendall’s tau to quantify the variance in feature similarity change at each time point that was uniquely explained by an abstracted representation of the graph factors (separate design matrices for the 4-state graph factor and 6-state graph factor). The feature similarity change was smoothed over time with a 25 ms Gaussian kernel prior to computing Kendall’s tau.</p>
<p>We used nonparametric tests to identify timepoints where there was evidence for a condition (4-cycle prior condition and 6-bridge prior condition) x graph factor (4-factor and 6-factor) interaction effect, based on a group-level GLM (including condition, graph factor main effects and a condition x graph factor effect), correcting for multiple comparisons over time. At each timepoint, we computed the GLM and extracted the <italic>F</italic>-value for the interaction effect. We then identified contiguous clusters of time points where the observed <italic>F</italic>-values exceeded a predefined threshold (critical <italic>F</italic>-value) and computed the sum of <italic>F</italic>-values (<italic>F</italic>-sum) within each cluster. To correct for multiple comparisons, we performed a cluster-based permutation procedure that invovled 1000 permutations. In each permutation, we shuffled the condition labels across participants before recomputing the <italic>F</italic>-values for the interaction effect at each time point, extracting the largest cluster-level <italic>F</italic>-sum from each permutation to build an empirical null distribution. An empirical <italic>p</italic>-value was computed by calculating the proportion of permutations for which the empirical absolute <italic>F</italic>-sum was smaller than or equal to the absolute permuted <italic>F</italic>-sums. A cluster in the observed data was deemed significant family-wise error corrected at the cluster-level if the empirical <italic>p</italic>-value was <italic>P</italic><sub>FWE</sub> &lt; 0.05. Similarly, we conducted permutation tests for the post-hoc tests, comparing the two conditions on the two graph factors (two-sample tests) using the same cluster-based correction approach.</p>
</sec>
<sec id="s4f2">
<title>Decoding of dynamical roles</title>
<p>The following analysis aimed to assess neural evidence for an abstract representation of transitions in the 6-state graph factor.</p>
<p>We investigated different transition types between images on the 6-state graph factor (i.e., the 6-state path-graph factor or the 6-state bridge graph factor) (<xref rid="fig4" ref-type="fig">Figure 4A</xref>). While the 6-state graph factor permits the categorization of transitions into three types, such differential labeling and classification is not possible for the 4-cycle graph factor, where all transitions are structurally identical with respect to the outbound and inbound node. In the 6-state graph factor, we grouped each transition between features into their three distinct types: boundary (1), intermediate (2), and central (3). Boundary transitions represent the transitions at the graph factor’s peripheries, occurring between nodes at extreme ends. Intermediate transitions represent the transitions from boundary nodes towards the center, bridging the boundary and central nodes of the graphs. Center transitions represent transitions within the two central nodes of the graph.</p>
<p>We analyzed neural activity in a window from 250 ms pre- to 1250 ms post-stimulus onset for each post-transition stimulus. The 1250 ms post-stimulus period encompassed the 1000 ms image display duration. Neural activity during stimulus presentations following each transition label was used to train L1-regularized logistic regressions to classify transitions during the prior learning phase (one classifier per transition type, trained in a one-vs-all fashion). Classifiers were then tested for generalization in the transfer learning phase with different stimulus sets used in both phases. No cross-validation was performed since training and testing were on independent datasets.</p>
<p>In the testing phase, we applied the trained classifiers to predict each transition type given the neural activity. To compute classification accuracy, at each sample time point, we selected the classifier with the highest predicted probability and compared the maximum predicted class to the correct ground truth label class.</p>
<p>Further, we conducted two-sample t-tests at each time point to compare classification accuracy between participants in 4-state cycle prior and 6-state bridge prior condition. To correct for multiple comparisons, similarly as described for the RSA, we performed a cluster-based permutation procedure with 1000 permutations. At each timepoint, we computed a two-sample t-test and extracted the <italic>t</italic>-value. We then identified contiguous clusters of time points where the observed <italic>t</italic>-values exceeded a predefined threshold (critical <italic>t</italic>-value) and computed the sum of <italic>t</italic>-values within each cluster. In each permutation, we shuffled the condition labels across participants before recomputing the <italic>t</italic>-values for the condition comparison at each time point. We then identified contiguous clusters of time points where the observed <italic>t</italic>-values exceeded a predefined threshold and used the largest cluster-level <italic>t</italic>-sum from each permutation to build an empirical null distribution. An empirical <italic>p</italic>-value was computed by calculating the proportion of permutations for which the empirical absolute <italic>t</italic>-sum was smaller than or equal to the absolute permuted <italic>t</italic>-sums. A cluster in the observed data was deemed significant family-wise error corrected at the cluster-level if the empirical <italic>p</italic>-value was <italic>P</italic><sub>FWE</sub> &lt; 0.05.</p>
<p>Separately for each prior learning condition, we computed the classification accuracy averaged across the time points showing a significant condition difference. Subsequently, we computed the Spearman correlation coefficient for the condition-averaged classification accuracy at the timepoints of significant condition differences and the 6-bridge probe performance (separately for experience and inference probes) for each condition separately. To assess significant differences between correlation coefficients, they were transformed to z-scores and compared (Fisher’s <italic>r</italic> to <italic>z</italic> transformation).</p>
</sec>
</sec>
</sec>

</body>
<back>
<sec id="s6" sec-type="data-availability">
<title>Data Availability</title>
<p>Behavioral data and MEG data used to generate the results and figures in this paper will be made available on GitHub upon publication.</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>Financial acknowledgments: RJD (Wellcome Investigator Award, 098362/Z/12/Z). The Max Planck UCL Centre is supported by UCL and the Max Planck Society. The Wellcome Centre for Human Neuroimaging (WCHN) is supported by core funding from the Wellcome Trust (203147/Z/16/Z). Open access funding provided by Max Planck Society.</p>
<p>The authors would like to thank all volunteers who took part in the study. We are grateful for the generous support of the imaging support team at UCL WCHN, particularly Daniel Bates, Chloe Carrick, Yasmin Feuozi, and Dimitra Moraiti for thoughtful discussions during scanning times. We would also like to thank Matthew Nour for helpful discussions during the setup of the study and for sharing analysis code. We thank Oliver Vikbladh and Neil Burgess for insightful discussions of task design &amp; results and Leo Chi U Seak for helpful comments on an earlier version manuscript. We thank the members of the Max Planck UCL Centre for Computational Psychiatry and Ageing Research and the DeepMind Neuro-Lab for discussions at various stages of the project. We additionally thank Magda Dubois for creative suggestions of words describing the compound images used in the experimental task.</p>
</ack>
<sec id="d1e1693" sec-type="additional-information">
<title>Additional information</title>
<sec id="s5">
<title>Code Availability</title>
<p>All code used to generate the results and figures in this paper will be made on GitHub upon publication.</p>
</sec>
<sec id="s7">
<title>Contributions</title>
<p>LL, RM, ZK-N, RJD conceived and designed the study. LL and NC acquired the data. LL and NC analyzed the data. TE and SV advised on analyses. RM, ZK-N, RJD supervised analyses. LL and NC drafted the manuscript. All authors read and edited versions of the manuscript and approved the final version of the manuscript.</p>
</sec>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Al Roumi</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Marti</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Amalric</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Dehaene</surname>, <given-names>S.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Mental compression of spatial sequences in human working memory using numerical and geometrical primitives</article-title>. <source>Neuron</source>, <volume>109</volume>(<issue>16</issue>), <fpage>2627</fpage>–<lpage>2639.e4.</lpage> <pub-id pub-id-type="doi">10.1016/j.neuron.2021.06.009</pub-id></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Allen</surname>, <given-names>K. R.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>K. A.</given-names></string-name>, &amp; <string-name><surname>Tenenbaum</surname>, <given-names>J. B</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Rapid trial-and-error learning with simulation supports flexible tool use and physical reasoning</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>117</volume>(<issue>47</issue>), <fpage>29302</fpage>–<lpage>29310</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1912341117</pub-id></mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Baram</surname>, <given-names>A. B.</given-names></string-name>, <string-name><surname>Muller</surname>, <given-names>T. H.</given-names></string-name>, <string-name><surname>Nili</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Garvert</surname>, <given-names>M. M.</given-names></string-name>, &amp; <string-name><surname>Behrens</surname>, <given-names>T. E. J</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Entorhinal and ventromedial prefrontal cortices abstract and generalize the structure of reinforcement learning problems</article-title>. <source>Neuron</source>, <volume>109</volume>(<issue>4</issue>), <fpage>713</fpage>–<lpage>723.e7.</lpage> <pub-id pub-id-type="doi">10.1016/j.neuron.2020.11.024</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barron</surname>, <given-names>H. C.</given-names></string-name>, <string-name><surname>Dolan</surname>, <given-names>R. J.</given-names></string-name>, &amp; <string-name><surname>Behrens</surname>, <given-names>T. E. J</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Online evaluation of novel choices by simultaneous representation of multiple memories</article-title>. <source>Nature Neuroscience</source>, <volume>16</volume>(<issue>10</issue>), <fpage>1492</fpage>– <lpage>1498</lpage>. <pub-id pub-id-type="doi">10.1038/nn.3515</pub-id></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barron</surname>, <given-names>H. C.</given-names></string-name>, <string-name><surname>Garvert</surname>, <given-names>M. M.</given-names></string-name>, &amp; <string-name><surname>Behrens</surname>, <given-names>T. E. J</given-names></string-name></person-group>. (<year>2016</year>). <article-title>Repetition suppression: a means to index neural representations using BOLD?</article-title> <source>Philosophical Transactions of the Royal Society B: Biological Sciences</source>, <volume>371</volume>(<issue>1705</issue>), <fpage>20150355</fpage>. <pub-id pub-id-type="doi">10.1098/rstb.2015.0355</pub-id></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Behrens</surname>, <given-names>T. E. J.</given-names></string-name>, <string-name><surname>Muller</surname>, <given-names>T. H.</given-names></string-name>, <string-name><surname>Whittington</surname>, <given-names>J. C. R.</given-names></string-name>, <string-name><surname>Mark</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Baram</surname>, <given-names>A. B.</given-names></string-name>, <string-name><surname>Stachenfeld</surname>, <given-names>K. L.</given-names></string-name>, &amp; <string-name><surname>Kurth-Nelson</surname>, <given-names>Z</given-names></string-name></person-group>. (<year>2018</year>). <article-title>What Is a Cognitive Map? Organizing Knowledge for Flexible Behavior</article-title>. <source>Neuron</source>, <volume>100</volume>(<issue>2</issue>), <fpage>490</fpage>–<lpage>509</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2018.10.002</pub-id></mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bernardi</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Benna</surname>, <given-names>M. K.</given-names></string-name>, <string-name><surname>Rigotti</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Munuera</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Fusi</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Salzman</surname>, <given-names>C. D</given-names></string-name></person-group>. (<year>2020</year>). <article-title>The Geometry of Abstraction in the Hippocampus and Prefrontal Cortex</article-title>. <source>Cell</source>, <volume>183</volume>(<issue>4</issue>), <fpage>954</fpage>–<lpage>967.e21.</lpage> <pub-id pub-id-type="doi">10.1016/j.cell.2020.09.031</pub-id></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Collins</surname>, <given-names>A. G. E.</given-names></string-name>, <string-name><surname>Ciullo</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Frank</surname>, <given-names>M. J.</given-names></string-name>, &amp; <string-name><surname>Badre</surname>, <given-names>D</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Working memory load strengthens reward prediction errors</article-title>. <source>Journal of Neuroscience</source>, <volume>37</volume>(<issue>16</issue>), <fpage>4332</fpage>–<lpage>4342</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.2700-16.2017</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Collins</surname>, <given-names>A. G. E.</given-names></string-name>, &amp; <string-name><surname>Frank</surname>, <given-names>M. J</given-names></string-name></person-group>. (<year>2012</year>). <article-title>How much of reinforcement learning is working memory, not reinforcement learning? A behavioral, computational, and neurogenetic analysis</article-title>. <source>European Journal of Neuroscience</source>, <volume>35</volume>(<issue>7</issue>), <fpage>1024</fpage>–<lpage>1035</lpage>. <pub-id pub-id-type="doi">10.1111/j.1460-9568.2011.07980.x</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Conway</surname>, <given-names>C. M.</given-names></string-name>, &amp; <string-name><surname>Christiansen</surname>, <given-names>M. H.</given-names></string-name></person-group> (<year>2006</year>). <article-title>Statistical Learning Within and Between Modalities Pitting Abstract Against Stimulus-Specific Representations</article-title>. <source>Psychological Science</source>, <volume>17</volume>(<issue>10</issue>), <fpage>905</fpage>–<lpage>912</lpage>. <pub-id pub-id-type="doi">10.1111/j.1467-9280.2006.01801.x</pub-id></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Courellis</surname>, <given-names>H. S.</given-names></string-name>, <string-name><surname>Minxha</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Cardenas</surname>, <given-names>A. R.</given-names></string-name>, <string-name><surname>Kimmel</surname>, <given-names>D. L.</given-names></string-name>, <string-name><surname>Reed</surname>, <given-names>C. M.</given-names></string-name>, <string-name><surname>Valiante</surname>, <given-names>T. A.</given-names></string-name>, <string-name><surname>Salzman</surname>, <given-names>C. D.</given-names></string-name>, <string-name><surname>Mamelak</surname>, <given-names>A. N.</given-names></string-name>, <string-name><surname>Fusi</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Rutishauser</surname>, <given-names>U</given-names></string-name></person-group>. (<year>2024</year>). <article-title>Abstract representations emerge in human hippocampal neurons during inference</article-title>. <source>Nature</source>, <volume>632</volume>(<issue>8026</issue>), <fpage>841</fpage>–<lpage>849</lpage>. <pub-id pub-id-type="doi">10.1038/s41586-024-07799-x</pub-id></mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dekker</surname>, <given-names>R. B.</given-names></string-name>, <string-name><surname>Otto</surname>, <given-names>F.</given-names></string-name>, &amp; <string-name><surname>Summerfield</surname>, <given-names>C</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Curriculum learning for human compositional generalization</article-title>. <source>PNAS</source> <volume>119</volume>(<issue>41</issue>), <elocation-id>e2205582119</elocation-id> <pub-id pub-id-type="doi">10.1073/pnas.2205582119</pub-id></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>El-Gaby</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Loyd Harris</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>R Whittington</surname>, <given-names>J. C.</given-names></string-name>, <string-name><surname>Bhomick</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Walton</surname>, <given-names>M. E.</given-names></string-name>, <string-name><surname>Akam</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>J Behrens</surname>, <given-names>T. E.</given-names></string-name></person-group> (<year>2023</year>). <article-title>A Cellular Basis for Mapping Behavioural Structure</article-title>. <source>BioRxiv</source>. <pub-id pub-id-type="doi">10.1101/2023.11.04.565609</pub-id></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Flesch</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Juechems</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Dumbalska</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Saxe</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Summerfield</surname>, <given-names>C</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Orthogonal representations for robust context-dependent task performance in brains and neural networks</article-title>. <source>Neuron</source>, <volume>110</volume>(<issue>7</issue>), <fpage>1258</fpage>–<lpage>1270.e11.</lpage> <pub-id pub-id-type="doi">10.1016/j.neuron.2022.01.005</pub-id></mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Flesch</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Saxe</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Summerfield</surname>, <given-names>C</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Continual task learning in natural and artificial agents</article-title>. In <source>Trends in Neurosciences</source> <volume>46</volume>(<issue>3</issue>):<fpage>199</fpage>–<lpage>210</lpage>. <pub-id pub-id-type="doi">10.1016/j.tins.2022.12.006</pub-id></mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Garvert</surname>, <given-names>M. M.</given-names></string-name>, <string-name><surname>Dolan</surname>, <given-names>R. J.</given-names></string-name>, &amp; <string-name><surname>Behrens</surname>, <given-names>T. E</given-names></string-name></person-group>. (<year>2017</year>). <article-title>A map of abstract relational knowledge in the human hippocampal–entorhinal cortex</article-title>. <source>eLife</source>, <volume>6</volume>, <fpage>1</fpage>–<lpage>20</lpage>. <pub-id pub-id-type="doi">10.7554/elife.17086</pub-id></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Garvert</surname>, <given-names>M. M.</given-names></string-name>, <string-name><surname>Saanum</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Schulz</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Schuck</surname>, <given-names>N. W.</given-names></string-name>, &amp; <string-name><surname>Doeller</surname>, <given-names>C. F</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Hippocampal spatio-predictive cognitive maps adaptively guide reward generalization</article-title>. <source>Nature Neuroscience</source>, <volume>26</volume>(<issue>4</issue>), <fpage>615</fpage>–<lpage>626</lpage>. <pub-id pub-id-type="doi">10.1038/s41593-023-01283-x</pub-id></mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Henin</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Turk-Browne</surname>, <given-names>N. B.</given-names></string-name>, <string-name><surname>Friedman</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Dugan</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Flinker</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Doyle</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Devinsky</surname>, <given-names>O.</given-names></string-name>, &amp; <string-name><surname>Melloni</surname>, <given-names>L</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Learning hierarchical sequence representations across human cortex and hippocampus</article-title>. <source>Science Advances</source>, <volume>7</volume>(<issue>8</issue>), <fpage>1</fpage>–<lpage>13</lpage>. <pub-id pub-id-type="doi">10.1126/sciadv.abc4530</pub-id></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huys</surname>, <given-names>Q. J. M.</given-names></string-name>, <string-name><surname>Maia</surname>, <given-names>T. V.</given-names></string-name>, &amp; <string-name><surname>Frank</surname>, <given-names>M. J.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Computational psychiatry as a bridge from neuroscience to clinical applications</article-title>. In <source>Nature Neuroscience</source> <volume>19</volume>(<issue>3</issue>), <fpage>404</fpage>–<lpage>413</lpage>. <pub-id pub-id-type="doi">10.1038/nn.4238</pub-id></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Johnston</surname>, <given-names>W. J.</given-names></string-name>, &amp; <string-name><surname>Fusi</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Abstract representations emerge naturally in neural networks trained to perform multiple tasks</article-title>. <source>Nature Communications</source>, <volume>14</volume>(<issue>1</issue>), <elocation-id>1040</elocation-id>. <pub-id pub-id-type="doi">10.1038/s41467-023-36583-0</pub-id></mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kazanina</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Poeppel</surname>, <given-names>D</given-names></string-name></person-group>. (<year>2023</year>). <article-title>The neural ingredients for a language of thought are available</article-title>. In <source>Trends in Cognitive Sciences</source>, <volume>27</volume>(<issue>11</issue>), <fpage>996</fpage>–<lpage>1007</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2023.07.012</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Mur</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Bandettini</surname>, <given-names>P</given-names></string-name></person-group>. (<year>2008</year>). <article-title>Representational similarity analysis – connecting the branches of systems neuroscience</article-title>. <source>Frontiers in Systems Neuroscience</source>, <volume>2</volume>(<issue>November</issue>), <fpage>1</fpage>–<lpage>28</lpage>. <pub-id pub-id-type="doi">10.3389/neuro.06.004.2008</pub-id></mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Kumar</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Dasgupta</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Marjieh</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Daw</surname>, <given-names>N. D.</given-names></string-name>, <string-name><surname>Cohen</surname>, <given-names>J. D.</given-names></string-name>, &amp; <string-name><surname>Griffiths</surname>, <given-names>T. L.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Disentangling Abstraction from Statistical Pattern Matching in Human and Machine Learning</article-title>. <italic>ArXiv</italic>. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2204.01437">http://arxiv.org/abs/2204.01437</ext-link></mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kurth-Nelson</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Behrens</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Wayne</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Luettgau</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Dolan</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>Y.</given-names></string-name>, &amp; <string-name><surname>Schwartenbeck</surname>, <given-names>P.</given-names></string-name></person-group> (<year>2023</year>). <article-title>Replay and compositional computation</article-title>. In <source>Neuron</source>, <volume>111</volume>(<issue>4</issue>), <fpage>454</fpage>–<lpage>469</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2022.12.028</pub-id></mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lake</surname>, <given-names>B. M.</given-names></string-name>, <string-name><surname>Salakhutdinov</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Tnenbaum</surname>, <given-names>J. B</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Human-level concept learning through probabilistic program induction</article-title>. <source>Science</source>, <volume>350</volume>(<issue>6266</issue>), <fpage>1332</fpage>–<lpage>1338</lpage>. <pub-id pub-id-type="doi">10.1126/science.aab3050</pub-id></mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lake</surname>, <given-names>B. M.</given-names></string-name>, <string-name><surname>Ullman</surname>, <given-names>T. D.</given-names></string-name>, <string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name>, &amp; <string-name><surname>Gershman</surname>, <given-names>S. J</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Building machines that learn and think like people</article-title>. <source>Behavioral and Brain Sciences</source>, <volume>40</volume>, <elocation-id>e253</elocation-id>. <pub-id pub-id-type="doi">10.1017/S0140525X16001837</pub-id></mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lehnert</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Littman</surname>, <given-names>M. L.</given-names></string-name>, &amp; <string-name><surname>Frank</surname>, <given-names>M. J</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Reward-predictive representations generalize across tasks in reinforcement learning</article-title>. <source>PLoS Computational Biology</source>, <volume>16</volume>(<issue>10</issue>), <fpage>1</fpage>–<lpage>27</lpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1008317</pub-id></mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Luettgau</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Erdmann</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Veselic</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Stachenfeld</surname>, <given-names>K. L.</given-names></string-name>, <string-name><surname>Kurth-Nelson</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Moran</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Dolan</surname>, <given-names>R. J</given-names></string-name></person-group>. (<year>2024</year>). <article-title>Decomposing dynamical subprocesses for compositional generalization</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>121</volume>(<issue>46</issue>), <elocation-id>e2408134121</elocation-id>. <pub-id pub-id-type="doi">10.1073/pnas.2408134121</pub-id></mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Luettgau</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Porcu</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Tempelmann</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Jocham</surname>, <given-names>G</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Reinstatement of Cortical Outcome Representations during Higher-Order Learning</article-title>. <source>Cerebral Cortex</source>, <volume>32</volume>(<issue>1</issue>), <fpage>93</fpage>–<lpage>109</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhab196</pub-id></mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Luettgau</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Tempelmann</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Kaiser</surname>, <given-names>L. F.</given-names></string-name>, &amp; <string-name><surname>Jocham</surname>, <given-names>G</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Decisions bias future choices by modifying hippocampal associative memories</article-title>. <source>Nature Communications</source>, <volume>11</volume>, <fpage>3318</fpage>. <pub-id pub-id-type="doi">10.1101/802462</pub-id></mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mark</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Moran</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Parr</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Kennerley</surname>, <given-names>S. W.</given-names></string-name>, &amp; <string-name><surname>Behrens</surname>, <given-names>T. E. J</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Transferring structural knowledge across cognitive maps in humans and models</article-title>. <source>Nature Communications</source>, <volume>11</volume>(<issue>1</issue>), <fpage>1</fpage>–<lpage>12</lpage>. <pub-id pub-id-type="doi">10.1038/s41467-020-18254-6</pub-id></mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>McElreath</surname>, <given-names>R.</given-names></string-name> ().  (R package version 2.00). <string-name><surname>McElreath</surname>, <given-names>R.</given-names></string-name></person-group><year>2020a</year>). <source>rethinking: Statstical rethinking book package</source> (R package version 2.00).  (2020b). <italic>Statistical Rethinking</italic> (<edition>2</edition>nd ed.). <publisher-name>CRC Press</publisher-name>. <pub-id pub-id-type="doi">10.1080/09332480.2017.1302722</pub-id></mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Murphy</surname>, <given-names>G. L</given-names></string-name></person-group>. (<year>1988</year>). <article-title>Comprehending Complex Concepts</article-title>. <source>Cognitive Science</source>, <volume>12</volume>(<issue>4</issue>), <fpage>529</fpage>–<lpage>562</lpage>. <pub-id pub-id-type="doi">10.1207/s15516709cog1204_2</pub-id></mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nieh</surname>, <given-names>E. H.</given-names></string-name>, <string-name><surname>Schottdorf</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Freeman</surname>, <given-names>N. W.</given-names></string-name>, <string-name><surname>Low</surname>, <given-names>R. J.</given-names></string-name>, <string-name><surname>Lewallen</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Koay</surname>, <given-names>S. A.</given-names></string-name>, <string-name><surname>Pinto</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Gauthier</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Brody</surname>, <given-names>C. D.</given-names></string-name>, &amp; <string-name><surname>Tank</surname>, <given-names>D. W</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Geometry of abstract learned knowledge in the hippocampus</article-title>. <source>Nature</source>, <volume>595</volume>(<issue>7865</issue>), <fpage>80</fpage>–<lpage>84</lpage>. <pub-id pub-id-type="doi">10.1038/s41586-021-03652-7</pub-id></mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nour</surname>, <given-names>M. M.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Arumuham</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kurth-Nelson</surname>, <given-names>Z.</given-names></string-name>, &amp; <string-name><surname>Dolan</surname>, <given-names>R. J</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Impaired neural replay of inferred relationships in schizophrenia</article-title>. <source>Cell</source>, <volume>184</volume>(<issue>16</issue>), <fpage>4315</fpage>–<lpage>4328.e17.</lpage> <pub-id pub-id-type="doi">10.1016/j.cell.2021.06.012</pub-id></mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>O’Donnell</surname>, <given-names>T. J.</given-names></string-name>, <string-name><surname>Goodman</surname>, <given-names>N. D.</given-names></string-name>, &amp; <string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name> (). <collab>Fragment Grammars: Exploring Computation and Reuse in Language</collab></person-group><year>2009</year>). . <ext-link ext-link-type="uri" xlink:href="https://www.csail.mit.edu">www.csail.mit.edu</ext-link></mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>O’Donnell</surname>, <given-names>T. J.</given-names></string-name>, <string-name><surname>Snedeker</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name>, &amp; <string-name><surname>Goodman</surname>, <given-names>N. D</given-names></string-name></person-group>. (<year>2011</year>). <article-title>Productivity and Reuse in Language</article-title>. <source>Proceedings of Cognitive Science Conference</source>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pesnot Lerousseau</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Summerfield</surname>, <given-names>C.</given-names></string-name></person-group> (<year>2024</year>). <article-title>Space as a scaffold for rotational generalisation of abstract concepts</article-title>. <source>eLife</source>, <volume>13</volume>. <pub-id pub-id-type="doi">10.7554/eLife.93636</pub-id></mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Reber</surname>, <given-names>A. S</given-names></string-name></person-group>. (<year>1967</year>). <article-title>Implicit Learning of Artificial Grammars 1</article-title>. In <source>Journal of Verbal Learning and Verbal Behavior</source> (Vol. <volume>6</volume>).</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Redish</surname>, <given-names>A. D.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Vicarious trial and error</article-title>. In <source>Nature Reviews Neuroscience</source>, <volume>17</volume>(<issue>3</issue>), <fpage>147</fpage>–<lpage>159</lpage>. <pub-id pub-id-type="doi">10.1038/nrn.2015.30</pub-id></mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rmus</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Ritz</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Hunter</surname>, <given-names>L. E.</given-names></string-name>, <string-name><surname>Bornstein</surname>, <given-names>A. M.</given-names></string-name>, &amp; <string-name><surname>Shenhav</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Humans can navigate complex graph structures acquired during latent learning</article-title>. <source>Cognition</source>, <volume>225</volume>. <pub-id pub-id-type="doi">10.1016/j.cognition.2022.105103</pub-id></mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="software"><person-group person-group-type="author"><collab>RStudioTeam</collab></person-group>. (<year>2019</year>). <source>RStudio: Integrated Development for R</source> (<version>1.2.5033</version>). <publisher-name>RStudio, Inc</publisher-name>. <ext-link ext-link-type="uri" xlink:href="http://www.rstudio.com/">http://www.rstudio.com/</ext-link></mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rubino</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Hamidi</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Wu</surname>, <given-names>C. M</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Compositionality under time pressure</article-title>. <source>Proceedings of the Annual Meeting of the Cognitive Science Society</source>, <volume>45</volume>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schapiro</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Rogers</surname>, <given-names>T. T.</given-names></string-name>, <string-name><surname>Cordova</surname>, <given-names>N. I.</given-names></string-name>, <string-name><surname>Turk-Browne</surname>, <given-names>N. B.</given-names></string-name>, &amp; <string-name><surname>Botvinick</surname>, <given-names>M. M</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Neural representations of events arise from temporal community structure</article-title>. <source>Nature Neuroscience</source>, <volume>16</volume>(<issue>4</issue>), <fpage>486</fpage>–<lpage>492</lpage>. <pub-id pub-id-type="doi">10.1038/nn.3331</pub-id></mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schwartenbeck</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Baram</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Mark</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Muller</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Dolan</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Botvinick</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Kurth-Nelson</surname>, <given-names>Z.</given-names></string-name>, &amp; <string-name><surname>Behrens</surname>, <given-names>T</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Generative replay underlies compositional inference in the hippocampal-prefrontal circuit</article-title>. <source>Cell</source>, <volume>186</volume>(<issue>22</issue>), <fpage>4885</fpage>–<lpage>4897.e14.</lpage> <pub-id pub-id-type="doi">10.1016/j.cell.2023.09.004</pub-id></mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sheahan</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Luyckx</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Nelli</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Teupe</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Summerfield</surname>, <given-names>C</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Neural state space alignment for magnitude generalization in humans and recurrent networks</article-title>. <source>Neuron</source>, <volume>109</volume>(<issue>7</issue>), <fpage>1214</fpage>–<lpage>1226.e8.</lpage> <pub-id pub-id-type="doi">10.1016/j.neuron.2021.02.004</pub-id></mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shepard</surname>, <given-names>R. N</given-names></string-name></person-group>. (<year>1987</year>). <article-title>Toward a Universal Law of Generalization for Psychological Science</article-title>. <source>Science</source>, <volume>237</volume>(<issue>4820</issue>), <fpage>1317</fpage>-<lpage>1323</lpage>. <pub-id pub-id-type="doi">10.1126/science.3629243</pub-id></mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sherman</surname>, <given-names>B. E.</given-names></string-name>, <string-name><surname>Graves</surname>, <given-names>K. N.</given-names></string-name>, &amp; <string-name><surname>Turk-Browne</surname>, <given-names>N. B</given-names></string-name></person-group>. (<year>2020</year>). <article-title>The prevalence and importance of statistical learning in human cognition and behavior</article-title>. <source>Current Opinion in Behavioral Sciences</source>, <volume>32</volume>, <fpage>15</fpage>–<lpage>20</lpage>. <pub-id pub-id-type="doi">10.1016/j.cobeha.2020.01.015</pub-id></mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sorscher</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Ganguli</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Sompolinsky</surname>, <given-names>H</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Neural representational geometry underlies few-shot concept learning</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <pub-id pub-id-type="doi">10.1073/pnas</pub-id></mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="web"><person-group person-group-type="author"><collab>Stan Development Team</collab></person-group>. (<year>2020</year>). <italic>RStan: the R interface to Stan</italic> (R package version 2.19.3.). <ext-link ext-link-type="uri" xlink:href="http://mc-stan.org/">http://mc-stan.org/</ext-link></mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Story</surname>, <given-names>G. W.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Moutoussis</surname>, <given-names>M.</given-names></string-name>, <string-name><given-names>Isabel M.</given-names> <surname>Berwian</surname></string-name>, <string-name><given-names>I. M.</given-names>, <surname>Nolte</surname></string-name>, <string-name><given-names>T.</given-names>, <surname>Bilek</surname></string-name>, <string-name><given-names>E.</given-names>, <surname>Jenifer Z</surname></string-name>. <string-name><surname>Siegel</surname>, <given-names>J. Z.</given-names></string-name>, &amp; <string-name><surname>Dolan</surname>, <given-names>R. J</given-names></string-name></person-group>. (<year>2024</year>). <article-title>A Social Inference Model of Idealization and Devaluation</article-title>. <source>Psychological Review</source>, <volume>131</volume>(<issue>3</issue>), <fpage>749</fpage>–<lpage>780</lpage>. <pub-id pub-id-type="doi">10.1037/rev0000430</pub-id></mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Tsividis</surname>, <given-names>P. A.</given-names></string-name>, <string-name><surname>Loula</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Burga</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Foss</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Campero</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Pouncy</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name>, &amp; <string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Human-Level Reinforcement Learning through Theory-Based Modeling, Exploration, and Planning</article-title>. <source>arXiv</source>, <pub-id pub-id-type="arxiv">2107.12544</pub-id>. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2107.12544">http://arxiv.org/abs/2107.12544</ext-link></mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Turk-Browne</surname>, <given-names>N. B.</given-names></string-name>, <string-name><surname>Isola</surname>, <given-names>P. J.</given-names></string-name>, <string-name><surname>Scholl</surname>, <given-names>B. J.</given-names></string-name>, &amp; <string-name><surname>Treat</surname>, <given-names>T. A</given-names></string-name></person-group>. (<year>2008</year>). <article-title>Multidimensional Visual Statistical Learning</article-title>. <source>Journal of Experimental Psychology: Learning Memory and Cognition</source>, <volume>34</volume>(<issue>2</issue>), <fpage>399</fpage>–<lpage>407</lpage>. <pub-id pub-id-type="doi">10.1037/0278-7393.34.2.399</pub-id></mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Whittington</surname>, <given-names>J. C. R.</given-names></string-name>, <string-name><surname>McCaffary</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Bakermans</surname>, <given-names>J. J. W.</given-names></string-name>, &amp; <string-name><surname>Behrens</surname>, <given-names>T. E. J</given-names></string-name></person-group>. (<year>2022</year>). <article-title>How to build a cognitive map: insights from models of the hippocampal formation</article-title>. <source>arXiv</source> <pub-id pub-id-type="arxiv">2202.01682</pub-id>. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2202.01682">http://arxiv.org/abs/2202.01682</ext-link></mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Whittington</surname>, <given-names>J. C. R.</given-names></string-name>, <string-name><surname>Muller</surname>, <given-names>T. H.</given-names></string-name>, <string-name><surname>Mark</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Barry</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Burgess</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Behrens</surname>, <given-names>T. E. J</given-names></string-name></person-group>. (<year>2020</year>). <article-title>The Tolman-Eichenbaum Machine: Unifying Space and Relational Memory through Generalization in the Hippocampal Formation</article-title>. <source>Cell</source>, <volume>183</volume>(<issue>5</issue>), <fpage>1249</fpage>–<lpage>1263.e23.</lpage> <pub-id pub-id-type="doi">10.1016/j.cell.2020.10.024</pub-id></mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname>, <given-names>G. R.</given-names></string-name>, <string-name><surname>Joglekar</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Song</surname>, <given-names>H. F.</given-names></string-name>, <string-name><surname>Newsome</surname>, <given-names>W. T.</given-names></string-name>, &amp; <string-name><surname>Wang</surname>, <given-names>X. J</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Task representations in neural networks trained to perform many cognitive tasks</article-title>. <source>Nature Neuroscience</source>, <volume>22</volume>(<issue>2</issue>), <fpage>297</fpage>–<lpage>306</lpage>. <pub-id pub-id-type="doi">10.1038/s41593-018-0310-2</pub-id></mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zheng</surname>, <given-names>X. Y.</given-names></string-name>, <string-name><surname>Hebart</surname>, <given-names>M. N.</given-names></string-name>, <string-name><surname>Grill</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Dolan</surname>, <given-names>R. J.</given-names></string-name>, <string-name><surname>Doeller</surname>, <given-names>C. F.</given-names></string-name>, <string-name><surname>Cools</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Garvert</surname>, <given-names>M. M</given-names></string-name></person-group>. (<year>2024</year>). <article-title>Parallel cognitive maps for multiple knowledge structures in the hippocampal formation</article-title>. <source>Cerebral Cortex</source>, <volume>34</volume>(<issue>2</issue>), <elocation-id>bhad485</elocation-id>. <pub-id pub-id-type="doi">10.1093/cercor/bhad485</pub-id></mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Jia</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Montesinos-Cartagena</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Gardner</surname>, <given-names>M. P. H.</given-names></string-name>, <string-name><surname>Zong</surname>, <given-names>W.</given-names></string-name>, &amp; <string-name><surname>Schoenbaum</surname>, <given-names>G</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Evolving schema representations in orbitofrontal ensembles during learning</article-title>. <source>Nature</source>, <volume>590</volume>(<issue>7847</issue>), <fpage>606</fpage>–<lpage>611</lpage>. <pub-id pub-id-type="doi">10.1038/s41586-020-03061-2</pub-id></mixed-citation></ref>
</ref-list>
<app-group>
<app id="s9">
<title>Supplementary Information</title>
<sec id="s9a">
<title>Supplementary Results</title>
<fig id="figs1" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 1.</label>
<caption><title>Transfer learning performance.</title>
<p>Aggregated probabilities of correct answers during the transfer learning phase, separately for both experience (left) and inference probes (right) as a function of probed size (4-state cycle (green) vs 6-state bridge (black)) and condition (4-cycle prior vs 6-bridge prior). Full sample (top row), high performers (&gt;50th percentile, middle row) and low performers (&lt;=50th percentile, bottom row). Each dot represents one participant, bars represent the arithmetic mean of the distribution, error bars depict the standard error of the mean and the dashed gray line represents chance level point estimate (probability correct = 0.5).</p></caption>
<graphic xlink:href="614119v2_figs1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<sec id="s9a1">
<title>Neural successor feature representations</title>
<p>Increased neural similarity for stimuli belonging to identical abstract subprocesses supports a knowledge transfer of relevant structure across experiential contexts. On this basis, we asked about neural dynamics of successor feature representations.</p>
<p>We focused on characterizing neural signals that reflect knowledge representation of experienced subprocess dynamics during transfer learning. If indeed neural activity encodes predictive representations, then we should be able to predict successor features from a current state’s neural activity pattern. To test this, we trained classifiers on neural activity recorded for each individually presented feature during the PRE task localizer phase (<xref rid="fig3" ref-type="fig">Fig. 3A</xref>, see Supplementary Methods for details). Then, as a neural metric of successor feature representation, we tested the classifiers’ generalization ability at transfer learning – generating the predicted probability for the successor features for each compound stimulus presentation, separately for the 4-cycle and 6-bridge graph factor successor features (see Methods for details on the classification scheme). Across several time points post-stimulus onset, we found increased predicted probabilities that were above average pre-stimulus onset predicted probabilities (Supplementary Fig. 2, <italic>N</italic> = 49 due to convergence issues of classifiers in one participant in the 4-cycle prior condition) for successor features pertaining to both graph factors (cluster-level corrected <italic>P</italic><sub>FWE</sub>= .002 and <italic>P</italic><sub>FWE</sub>= .037, non-parametric permutation test; for 4- cycle and 6-bridge graph factor successor features, respectively), consistent with a neural representation of successor features for both experienced subprocesses after stimulus onset.</p>
<fig id="figs2" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 2.</label>
<caption><title>Temporal dynamics of successor state predictions.</title>
<p>Time courses of change in predicted probability of classifiers (reactivation) relative to average pre-stimulus onset baseline during transfer learning across both conditions, related to all stimulus presentations, for the respective successor features of each compound stimulus presentation. We trained multivariate classifiers (L1-regularized logistic regressions, trained excluding the respective other feature in each compound) to distinguish between features on the 4-cycle and 6-bridge graph factor during the PRE localizer tasks and tested the compound-by-compound successor feature predictions on both graph factors separately. Depicted are average changes in predicted probability (subtracting average pre-stimulus onset predicted probability), shaded error bars indicate standard errors of the mean. Horizontal line indicates null effect (0 predicted probability change). Solid lines on top index temporal clusters wherein the predicted probability is statistically significant above 0, corrected for multiple comparisons at the cluster-level (<italic>P<sub>FWE</sub></italic> &lt; 0.05, non-parametric permutation test, one-tailed).</p></caption>
<graphic xlink:href="614119v2_figs2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s9a2">
<title>Replay analyses</title>
<p>Building on work on human replay, as measured with MEG, in our and other research groups (e.g., <xref ref-type="bibr" rid="c59">Huang &amp; Luo, 2024</xref>; <xref ref-type="bibr" rid="c60">Kern et al., 2024</xref>; <xref ref-type="bibr" rid="c62">Kurth-Nelson et al., 2016</xref>; <xref ref-type="bibr" rid="c63">Liu et al., 2019</xref>, <xref ref-type="bibr" rid="c64">2021</xref>; <xref ref-type="bibr" rid="c35">Nour et al., 2021</xref>; <xref ref-type="bibr" rid="c45">Schwartenbeck et al., 2023</xref>) we tested for the presence of two qualitatively distinct types of sequential reactivation (“sequenceness”) using temporally delayed linear modeling (TDLM). Specifically, we tested for different magnitudes of sequenceness that captured transitions between neural representations of compound stimuli (“compound sequenceness”) and condition differences of sequenceness capturing transitions between neural representations of the individual features (“factorized sequenceness”). This analysis aimed at extending previous accounts of replay compositionality (<xref ref-type="bibr" rid="c24">Kurth-Nelson et al., 2023</xref>; <xref ref-type="bibr" rid="c45">Schwartenbeck et al., 2023</xref>). In these analyses we did not detect reliable, above permutation threshold sequenceness effects during a 5-minute rest period between prior and transfer learning, neither for compound stimuli nor for individual features. Such sequenceness effects were also absent during the initial 5-minute resting period before the PRE task localizer. Additionally, we did not observe any evidence for one-step transitions between neural representations of compounds or features at rest.</p>
<p>We also tested an additional hypothesis regarding a potential neural mechanism supporting gradual learning, and insight-dependent, decomposition of the experienced compound stimulus sequence into underlying subprocesses. Specifically, we examined for a trial-by-trial positive linear trend for factorized sequenceness and a trial-by-trial negative linear trend for compound sequenceness during the resting period between the experience and inference probe question (inter-probe intervals). Again, we did not detect significant and reliable sequenceness effects.</p>
<p>The absence of sequential reactivation findings may relate to several factors. Firstly, we We optimized hyper-parameters and classifier performance on visual localizer tasks and tested their generalization on memory reactivation during “no-task” resting periods. The L1-regularization training procedure minimizes an overlap between representations of visually presented stimuli by reducing the magnitude of regression weights for non-influential sensors. Conceivably, this might impede an ability to reliably detect memory reactivation during “no-task” resting periods, rendering quantification of sequential memory reactivation challenging. Secondly, it is possible that the compositional generalization behavior seen in the present task may not rely on “offline” sequential reactivation of experienced task states. The behaviorally relevant information to be learned by participants encompassed one-step transitions between compound states (and features) alone, potentially rendering underpowered any sequential reactivation analyses that relies on multiple-step transitions of reactivated states.</p>
</sec>
</sec>
<sec id="s9b">
<title>Supplementary Methods</title>
<sec id="s9b1">
<title>Successor feature prediction</title>
<p>This analysis aimed at assessing evidence for neural representation of successor features in both subprocesses.</p>
<p>We employed L1-regularized (LASSO) logistic regression classifiers to MEG data recorded during stimulus presentations in the PRE task localizer and transfer learning phase. Individually optimized L1 penalty hyper-parameter values (λ) per participant were obtained using leave-one-run-out cross-validation (5-fold CV, training on four of the localizer blocks and testing classifier performance on the remaining block) individually on neural activity recorded at all individually presented transfer learning phase features during the PRE task localizer. Optimized hyper-parameters were used to train classifiers per participant on the transfer learning phase features presented during the PRE task localizer. Since we employed a one vs all classification scheme and every compound stimulus presented during the transfer learning phase was composed of two features, we reasoned that the classifier representing the other (irrelevant) feature in the compound stimulus would show the highest predicted probability. We sought to control for the confounding influence of the other stimulus (of no interest) contained in the compound stimulus by training and testing classifiers excluding the respective other stimulus, resulting in n * n-1 (10 * 9 = 90) classifiers. We then applied the trained classifiers to test their generalization abilities in the transfer learning phase – generating the predicted probability for each successor feature for each subprocess separately, on each compound stimulus presentation. Since all classifiers showed some level of predicted probability, we used the raw predicted probability as a neural metric of successor state representation (instead of computing the classification accuracy for the next state only). No cross-validation was performed since training and testing were performed on independent datasets.</p>
<p>We analyzed neural activity in a time window from 0 – 800 ms post-stimulus onset for each presented compound stimulus. This interval was chosen since the PRE task localizer presented each stimulus for 650 ms. The 800 ms post-stimulus period was shorter than the 1000 ms image display duration in transfer learning – we therefore make no claims about successor state reactivations that might have potentially occurred between 800 and 1000 ms post-stimulus onset.</p>
<p>To quantify the neural representation of successor features, we subtracted the averaged pre-stimulus onset (-200 – 0 ms) predicted probabilities on a given stimulus presentation from the post-stimulus predicted probabilities – providing a neural metric for feature reactivation. We conducted one-sample t-tests against 0 (null effect) predicted probability, jointly for both prior learning conditions at each time point post-stimulus onset for the 4-cycle and 6-bridge subprocess successor feature representation. We then identified contiguous clusters of time points where the observed <italic>t</italic>-values exceeded a predefined threshold (critical <italic>t</italic>-value) and computed the sum of <italic>t</italic>-values within each cluster. To correct for multiple comparisons, we performed a cluster-based permutation procedure with 1000 permutations. In each permutation, we shuffled the sign of each of the successor feature activations before recomputing the t-values vs 0 at each time point. We then identified contiguous clusters of time points where the observed <italic>t</italic>-values exceeded a predefined threshold and used the largest cluster-level <italic>t</italic>-sum from each permutation to build an empirical null distribution. An empirical <italic>p</italic>-value was computed by counting the number of times the original cluster sum was greater than or equal to the permuted <italic>t</italic>-sums. A cluster in the observed data was deemed significant family-wise error corrected at the cluster-level if the empirical <italic>p</italic>-value was <italic>P</italic><sub>FWE</sub> &lt; 0.05.</p>
</sec>
</sec>
<ref-list>
<title>References</title>
<ref id="c59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname>, <given-names>Q.</given-names></string-name>, &amp; <string-name><surname>Luo</surname>, <given-names>H</given-names></string-name></person-group>. (<year>2024</year>). <article-title>Shared structure facilitates working memory of multiple sequences</article-title>. <source>eLife</source>, <volume>12</volume>. <pub-id pub-id-type="doi">10.7554/eLife.93158</pub-id></mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kern</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Nagel</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Gerchen</surname>, <given-names>M. F.</given-names></string-name>, <string-name><surname>Guersoy</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Meyer-Lin-Denberg</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kirsch</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Dolan</surname>, <given-names>R. J.</given-names></string-name>, <string-name><surname>Gais</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Feld</surname>, <given-names>G. B</given-names></string-name></person-group>. (<year>2024</year>). <article-title>Reactivation strength during cued recall is modulated by graph distance within cognitive maps</article-title>. <source>eLife</source>. <pub-id pub-id-type="doi">10.7554/eLife.93357.3</pub-id></mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kurth-Nelson</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Behrens</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Wayne</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Luettgau</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Dolan</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>Y.</given-names></string-name>, &amp; <string-name><surname>Schwartenbeck</surname>, <given-names>P.</given-names></string-name></person-group> (<year>2023</year>). <article-title>Replay and compositional computation</article-title>. In <source>Neuron</source> <volume>111</volume>(<issue>4</issue>), <fpage>454</fpage>–<lpage>469</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2022.12.028</pub-id></mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kurth-Nelson</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Economides</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Dolan</surname>, <given-names>R. J.</given-names></string-name>, &amp; <string-name><surname>Dayan</surname>, <given-names>P</given-names></string-name></person-group>. (<year>2016</year>). <article-title>Fast Sequences of Non-spatial State Representations in Humans</article-title>. <source>Neuron</source>, <volume>91</volume>(<issue>1</issue>), <fpage>194</fpage>–<lpage>204</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2016.05.028</pub-id></mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Dolan</surname>, <given-names>R. J.</given-names></string-name>, <string-name><surname>Kurth-Nelson</surname>, <given-names>Z.</given-names></string-name>, &amp; <string-name><surname>Behrens</surname>, <given-names>T. E. J</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Human Replay Spontaneously Reorganizes Experience</article-title>. <source>Cell</source>, <volume>178</volume>, <fpage>1</fpage>–<lpage>13</lpage>. <pub-id pub-id-type="doi">10.1016/j.cell.2019.06.012</pub-id></mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Mattar</surname>, <given-names>M. G.</given-names></string-name>, <string-name><surname>Behrens</surname>, <given-names>T. E. J.</given-names></string-name>, <string-name><surname>Daw</surname>, <given-names>N. D.</given-names></string-name>, &amp; <string-name><surname>Dolan</surname>, <given-names>R. J</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Experience replay is associated with efficient nonlocal learning</article-title>. <source>Science</source>, <volume>372</volume>(<issue>6544</issue>), <elocation-id>eabf1357</elocation-id>. <pub-id pub-id-type="doi">10.1126/science.abf1357</pub-id></mixed-citation></ref>
<ref id="c65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nour</surname>, <given-names>M. M.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Arumuham</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kurth-Nelson</surname>, <given-names>Z.</given-names></string-name>, &amp; <string-name><surname>Dolan</surname>, <given-names>R. J</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Impaired neural replay of inferred relationships in schizophrenia</article-title>. <source>Cell</source>, <volume>184</volume>(<issue>16</issue>), <fpage>4315</fpage>–<lpage>4328.e17.</lpage> <pub-id pub-id-type="doi">10.1016/j.cell.2021.06.012</pub-id></mixed-citation></ref>
<ref id="c66"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schwartenbeck</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Baram</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Mark</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Muller</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Dolan</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Botvinick</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Kurth-Nelson</surname>, <given-names>Z.</given-names></string-name>, &amp; <string-name><surname>Behrens</surname>, <given-names>T</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Generative replay underlies compositional inference in the hippocampal-prefrontal circuit</article-title>. <source>Cell</source>, <volume>186</volume>(<issue>22</issue>), <fpage>4885</fpage>–<lpage>4897.e14.</lpage> <pub-id pub-id-type="doi">10.1016/j.cell.2023.09.004</pub-id></mixed-citation></ref>
</ref-list>
</app>
</app-group>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107162.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Bottini</surname>
<given-names>Roberto</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Trento</institution>
</institution-wrap>
<city>Trento</city>
<country>Italy</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study provides <bold>valuable</bold> insights into humans' ability to generalize knowledge of learned graph structures to new experiences that share the same structure but are built from different stimuli. However, the evidence for the authors' claims is <bold>incomplete</bold>, with the main claims of structural generalization and compositionality only partially supported by MEG and behavioral data. This study will be of interest to cognitive neuroscientists studying structure learning and generalization.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107162.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary of the paper:</p>
<p>The paper presents an elegant task designed to investigate humans' ability to generalize knowledge of learned graph structures to new experiences that share the same structure but are built from different stimuli. Using behavior and MEG recordings, the authors test evidence for neural representation and application of structural knowledge.</p>
<p>Review overview:</p>
<p>While the task design is elegant, it isn't clear to me that the data support all the claims made in the paper. I have detailed my concerns below.</p>
<p>Major concerns</p>
<p>(1) The authors claim that their findings reveal &quot;striking learning and generalization abilities based on factorization of complex experiences into underlying structural elements, parsing these into distinct subprocesses derived from past experience, and forming a representation of the dynamical roles these features play within distinct subprocesses.&quot; And &quot;neural dynamics that support compositional generalisation, consistent with a structural scaffolding mechanism that facilitates efficient adaption within new contexts&quot;.</p>
<p>a. First, terms used in these example quotes (but also throughout the paper) do not seem to be well supported by data or the task design. For example, terms such as 'compositional generalisation' and 'building blocks' have important relevance in other papers by (some of) the same authors (e.g., Schwartenbeck et al., 2023), but in the context of this experiment, what is 'composition'? Can the authors demonstrate clear behavioural or neural evidence for compositional use of multiple graph structures, or alternatively remove reference to these terms? In the current paper, it seems to me that the authors are investigating abstract knowledge for singular graph structures (together with the influence of prior learning), as opposed to knowledge for the compound, more complex graph formed from the product of two simpler graphs.</p>
<p>b. While I would like to be convinced that this data provides evidence for the transfer of abstract, structural knowledge, I think the authors either need to provide more convincing evidence or tone down their claims.</p>
<p>Specifically:</p>
<p>(i) Can the increase in neural similarity between stimuli mapping to the same abstract structural sub-process not be explained by temporal proximity in experiencing the transitions (e.g., Cai et al., 2016)? Indeed, behavior seems to be dominated by direct experience of the structure as opposed to applying abstract knowledge of equivalent structures (and, as a result, there is little difference in behavioural performance between experience and inference probes).</p>
<p>(ii) The strongest evidence for neural representation of abstract task structures seems to be the increase in similarity by transition type. But this common code for 'transition type' is only observed for 6-bridge graphs and only for experienced transitions. There was no significant effect in inference probes. Therefore, there doesn't seem to be evidence for the application of a knowledge scaffold to facilitate transfer learning. Instead, the data reflects learning from direct experience and not generalisation.</p>
<p>(iii) The authors frequently suggest that they are providing insight into temporal dynamics, but there is no mention of particular oscillations or particular temporal sequences of neural representation that support task performance.</p>
<p>(2) Regardless of point (b), can the authors provide more convincing evidence for a graph structure being represented per se (regardless of whether this representation is directly experienced or inferred)? From Figure 3C, it seems that the model RDM doesn't account for relative distance within the graph. Do they see evidence for distance coding? Can they reconstruct the graph from representational patterns using MDS?</p>
<p>(3) In general, the figures are not very clear, and the outcome from statistical tests is not graphically shown. The paper would be easier to digest if, for example, Figures 1-2 were made clearer and statistical significance relative to chance were indicated throughout. To give two examples: (i) Figure 1 should clearly indicate what is meant by observed and held-out transitions and whether it is just the transition or also the compound that is new to the participant. (ii) Figure 2D-E could be shown with relevant comparisons and simpler statistical comparisons. Currently, it is hard to follow without carefully reading the legend.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107162.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The authors aimed to investigate the temporal dynamics of how prior experiences shape learning in new complex environments by examining whether the brain reuses abstract structural components from those experiences. They employed a sequence learning task based on graph factorization and recorded neural activity using magnetoencephalography (MEG) to investigate how the underlying graph factors are reused to support learning and inference in a new graph. MEG data was derived from passive stimulus presentation trials, and behavior was assessed through a small number of probe trials testing either experienced or inferred successions in the graph. Representational similarity analysis of the MEG data was performed at a quite aggregated level (the principal components explaining 80% of the variance). The authors report (1) enhanced neural similarity among stimuli that belong to the same graph-factor as well as (2) a correlation between abstract role representations, corresponding to particular positions in the graph, and performance in experience-probes but not in inference-probes.</p>
<p>Strengths &amp; Weaknesses:</p>
<p>(1) The first finding is considered evidence for representational alignment of the graph factors. However, alignment seems to be just one possible arrangement underlying the increased similarity between stimuli of the same vs different graph factors. For instance, a simple categorical grouping of stimuli belonging to the same graph, rather than their structural alignment, could also underlie the reported effect. The wording should be adjusted to avoid overinterpretation.</p>
<p>(2) The second finding of abstract role representations is indeed expected for structural generalisation. While the data presents an interesting indication, its interpretability is constrained by a lack of testing for generalization of the effect to other graph structures (e.g., to rule out graph-specific strategies) as well as the absence of a link to transfer performance in inference-probes. The authors argue that the experienced transitions the classifier was trained on might be more similar in process to the experience-probes than the inference-probes. However, as inference-probes are the key measure of transfer, one could argue that if abstract role representations truly underlie transfer learning, they should be evident in the common neural signal.</p>
<p>(3) The authors write, &quot;we observed a qualitative pattern indicative of increased neural similarity between stimuli that adhered to the same underlying subprocess across task phases. (...) There was a statistically significant interaction effect of condition x graph factor spanning approximately 300 - 680 ms post-stimulus onset&quot;. I conclude there was no significant main effect of graph factor, but the relevant statistics are not reported. The authors should report and discuss the complete statistics.</p>
<p>(4) The RSA is performed on highly aggregated data (the PCs that explained 80% of the variance). Could the authors include their rationale for this choice (e.g. over-analysis of sensor-level data)? In case sensor-level analyses have been conducted as well, maybe there are comparisons or implications of the chosen approach that are useful to mention in the discussion. The authors should provide the average and distribution of the number of PCs underlying their analyses.</p>
<p>(5) While the paper is well-written overall, it would benefit from more explicitly identifying the concrete research question and advancing through the results. The authors state their aim as understanding the &quot;temporal dynamics of compositional generalisation&quot;, revealing &quot;at which moment during neural information processing are they assembled&quot;. They conclude with &quot;providing evidence for temporally resolved neural dynamics that support compositional generalization&quot; and &quot;we show the neural dynamics (...) presented across different task phases...&quot;. It remains somewhat vague what specific insight about the process is provided through the temporal resolution (e.g., is the time window itself meaningful, if so, it should be contextualized; is the temporal resolution critical to dissociate subprocesses). The different task phases -initial learning and transfer- are the necessary conditions to investigate transfer learning, but do not by themselves offer a particularly resolved depiction of the process.</p>
<p>Overall, the findings are congruent with prior research on neural correlates of structural abstraction. They offer an elegant, well-suited task design to study compositional representations, replicating the authors' earlier finding and providing temporal information on structural generalisation in a sequence learning task.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107162.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary</p>
<p>This study investigates how task components can be learned and transferred across different task contexts. The authors designed two consecutive sequence learning tasks, in which complex image sequences were generated from the combination of two graph-based structural &quot;building blocks&quot;. One of these components was shared between the prior and transfer task environments, allowing the authors to test compositional transfer. Behavioral analyses using generalized linear models (GLMs) assessed participants' sensitivity to the underlying structure. MEG data were recorded and analyzed using classifications and feature representational similarity analysis (RSA) to examine whether neural similarity increased for stimuli sharing the same relational structure. The paper aims to uncover the neural dynamics that support compositional transfer during learning.</p>
<p>Strengths and weaknesses</p>
<p>I found the methods and task design of this paper difficult to follow, particularly the way stimuli were constructed and how the experimental sequences were generated from the graph structures. These aspects would be hard to replicate without some clarification. I appreciate the integration of behavioral and neuroimaging data. The overall approach, especially the use of compositional graph structures in sequence learning, is interesting and could be used and revised in further studies in compositionality and transfer learning. I appreciated the authors' careful interpretation of their findings in the discussion. However, I would have liked a similar level of caution in the abstract, which currently overstates some claims.</p>
<p>Major Comments:</p>
<p>(1) While the introduction mentions brain areas implicated in the low-dimensional representation of task knowledge, the current study uses M/EEG and does not include source reconstruction. As a result, the focus is primarily on the temporal dynamics of the signal rather than its spatial origins. Although I am not suggesting that the authors should perform source reconstruction in this study, it would strengthen the paper to introduce the broader M/EEG literature on task-relevant representations and transfer. The same applies to behavioral studies looking at structural similarities and transfer learning. I encourage the authors to integrate relevant literature to better contextualize their results.</p>
<p>Duan, Y., Zhan, J., Gross, J., Ince, R. A. &amp; Schyns, P. G. Pre-frontal cortex guides dimension-reducing transformations in the occipito-ventral pathway for categorization behaviors. Current Biology 34, 3392-3404 (2024).</p>
<p>Luyckx, F., Nili, H., Spitzer, B. &amp; Summerfield, C. Neural structure mapping in human probabilistic reward learning. eLife 8, e42816 (2019). (This is in the references but not in the text).</p>
<p>Zhang, M. &amp; Yu, Q. The representation of abstract goals in working memory is supported by task-congruent neural geometry. PLoS biology 22, e3002461 (2024).</p>
<p>L. Teichmann, T. Grootswagers, T. Carlson, A.N. Rich Decoding digits and dice with magnetoencephalography: evidence for a shared representation of magnitude Journal of cognitive neuroscience, 30 (7) (2018), pp. 999-1010</p>
<p>Garner, K., Lynch, C. R. &amp; Dux, P. E. Transfer of training benefits requires rules we cannot see (or hear). Journal of Experimental Psychology: Human Perception and Performance 42, 1148 (2016).</p>
<p>Holton, E., Braun, L., Thompson, J., Grohn, J. &amp; Summerfield, C. Humans and neural networks show similar patterns of transfer and interference during continual learning (2025).</p>
<p>(2) I found it interesting that the authors chose to perform PCA for dimensionality reduction prior to conducting RSA; however, I haven't seen such an approach in the literature before. It would be helpful to either cite prior studies that have employed a similar method or to include a comparison with more standard approaches, such as sensor-level RSA or sensor-searchlight analysis.</p>
<p>(3) Connected to the previous point, the choice to use absolute distance as a dissimilarity measure is not justified. How does it compare to standard metrics such as correlation distance or Mahalanobis distance? The same applies to the use of Kendall's tau.</p>
<p>(4) The analysis described in the &quot;Abstract representation of dynamical roles in subprocesses&quot; does not appear to convincingly test the stated prediction of a structural scaffolding account. The authors hypothesize that if structure and dynamics from prior experiences are repurposed, then stimuli occupying the same &quot;dynamical roles&quot; across different sequences should exhibit enhanced neural similarity. However, the analysis seems to focus on decoding transitions rather than directly assessing representational similarity. Rather, this approach may reflect shared temporal representation in the sequences without necessarily indicating that the neural system generalizes the abstract function or position of a stimulus within the graph. To truly demonstrate that the brain captures the dynamical role across different stimuli, it would be more appropriate to directly assess whether neural patterns evoked by stimuli, in the same temporal part of the sequence, with shared roles (but different visual identities) are more similar to each other than to those from different roles.</p>
<p>(5) In the following section, the authors correlate decoding accuracy with participants' behavioral performance across different conditions. However, out of the four reported correlations and the additional comparison of differences between conditions, only one correlation and one correlation difference reach significance, and only marginally so. The interpretation of this finding should therefore be more cautious, especially if it is used to support a link between neural representations and behavior. Additionally, it is possible that correlation with a more clearly defined or targeted neural signature, more directly tied to the hypothesized representational content, could yield stronger or more interpretable correlations.</p>
<p>Minor Comments:</p>
<p>During preprocessing, sensors were excluded based on an identified noise level. However, the authors do not specify the threshold used to define this noise level, nor do they report how many sensors were excluded per participant. It would be helpful to have these details. Additionally, it is unclear why the authors opted to exclude sensors rather than removing noise with MaxFiltering or interpolating bad sensors. Finally, the authors should report how many trials were discarded on average (and standard deviation) per participant.</p>
</body>
</sub-article>
</article>