<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">100361</article-id>
<article-id pub-id-type="doi">10.7554/eLife.100361</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.100361.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.3</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Computational and Systems Biology</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>TopOMetry systematically learns and evaluates the latent dimensions of single-cell atlases</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2530-6666</contrib-id>
<name>
<surname>Sidarta-Oliveira</surname>
<given-names>Davi</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7938-4814</contrib-id>
<name>
<surname>Domingos</surname>
<given-names>Ana</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Velloso</surname>
<given-names>Licio A</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>lavellos@unicamp.br</email>
</contrib>
<aff id="a1"><label>1</label><institution>Laboratory of Cell Signaling, Obesity and Comorbidities Research Center, School of Medical Sciences, University of Campinas</institution>, <country>Brazil</country></aff>
<aff id="a2"><label>2</label><institution>Department of Physiology, Anatomy and Genetics, University of Oxford</institution>, <country>United Kingdom</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Park</surname>
<given-names>Jihwan</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Gwangju Institute of Science and Technology</institution>
</institution-wrap>
<city>Gwangju</city>
<country>Republic of Korea</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Choi</surname>
<given-names>Murim</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Seoul National University</institution>
</institution-wrap>
<city>Seoul</city>
<country>Republic of Korea</country>
</aff>
</contrib>
</contrib-group>
<pub-date date-type="original-publication" iso-8601-date="2024-09-30">
<day>30</day>
<month>09</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP100361</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-07-01">
<day>01</day>
<month>07</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-06-04">
<day>04</day>
<month>06</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.03.14.484134"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Sidarta-Oliveira et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Sidarta-Oliveira et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-100361-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>A core task in single-cell data analysis is recovering the latent dimensions encoding the genetic and epigenetic landscapes inhabited by cell types and lineages. However, consensus is lacking for optimal modeling and visualization approaches. Here, we propose these landscapes are ideally modeled as Riemannian manifolds, and present TopOMetry, a computational toolkit based on Laplacian-type operators to learn these manifolds. TopOMetry learns and evaluates dozens of possible representations systematically, eliminating the need to choose a single dimensional reduction method <italic>a priori</italic>. The learned visualizations preserve more original information than current PCA-based standards across single-cell and non-biological datasets. TopOMetry allows users to estimate intrinsic dimensionalities and visualize distortions with the Riemannian metric, among other challenging tasks. Illustrating its hypothesis generation power, TopOMetry suggests the existence of dozens of novel T cell subpopulations consistently found across public datasets that correspond to specific clonotypes. TopOMetry is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/davisidarta/topometry">https://github.com/davisidarta/topometry</ext-link>.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>dimensional reduction</kwd>
<kwd>knowledge-representation</kwd>
<kwd>Laplace-Beltrami</kwd>
<kwd>genomics</kwd>
<kwd>latent models</kwd>
</kwd-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Minor update, including text corrections regarding some of the claims</p></fn>
</fn-group>
<fn-group content-type="external-links">
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://topometry.readthedocs.io/en/latest/">https://topometry.readthedocs.io/en/latest/</ext-link>
</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Analyzing high-dimensional data (i.e., data in which the number of variables per observation exceeds hundreds or thousands) is a challenge shared among fields as diverse as signal processing, economics, and structural chemistry - and, more recently, the life sciences, particularly with the development of single-cell experiments. Single-cell assays have inaugurated a new era in the unbiased molecular sampling of the cellular diversity in biological systems, from cell lines to whole organisms, leading to an ongoing revolution across the life sciences<sup><xref ref-type="bibr" rid="c1">1</xref>,<xref ref-type="bibr" rid="c2">2</xref></sup>. In such high-dimensional data (hd-data), information regarding cellular phenotype (e.g., gene expression, chromatin accessibility, etc.) is individually gathered for every cell, resulting in matrices containing up to millions of cells and dozens of thousands of variables for each. This creates challenges in data analysis, collectively known as the <italic>curse of dimensionality</italic>, and requires sophisticated statistical and geometric methods to allow meaningful exploration and understanding of the latent features underlying the data. These are broadly referred to as <italic>dimensionality reduction</italic> techniques and include matrix decomposition methods, autoencoders, and graph-layout optimization algorithms.</p>
<p>Many dimensionality reduction approaches have been developed and recently reviewed elsewhere<sup><xref ref-type="bibr" rid="c3">3</xref>–<xref ref-type="bibr" rid="c5">5</xref></sup>; here, we will briefly describe the strategies behind these algorithms and outline their current use standards in sc-data. Briefly, there are two main ways to perform dimensionality reduction (DR): i) decomposing matrices; and ii) optimizing graph layouts. Matrix decomposition DR methods embed data into an arbitrary number of latent dimensions and include the classic Principal Component Analysis (PCA)<sup><xref ref-type="bibr" rid="c6">6</xref>,<xref ref-type="bibr" rid="c7">7</xref></sup>, a linear method that involves the eigendecomposition of the covariance matrix. More recent non-linear dimensionality reduction (NLDR) methods are based on manifold-learning techniques and assume that the input data lie on or near a low-dimensional manifold, which is almost always the case in real-world datasets. In particular, spectral methods (i.e., based on the decomposition of Laplacian-type operators), such as Laplacian Eigenmaps (LE)<sup><xref ref-type="bibr" rid="c8">8</xref></sup> and Diffusion Maps (DM)<sup><xref ref-type="bibr" rid="c9">9</xref>,<xref ref-type="bibr" rid="c10">10</xref></sup>, have arisen as robust non-linear alternatives, in which the eigendecomposition of Laplacian-type operators<sup><xref ref-type="bibr" rid="c8">8</xref>,<xref ref-type="bibr" rid="c9">9</xref>,<xref ref-type="bibr" rid="c11">11</xref>–<xref ref-type="bibr" rid="c13">13</xref></sup> yield orthonormal components that encode the latent graph structure of the manifold. The other broad class of DR techniques consists of graph-layout optimization methods. Their approach involves learning a similarity graph from samples, then minimizing a loss function to optimize the layout of this graph in 2 or 3-D for visualization. Graph-layout optimization (GLO) methods include the popular t-Stochastic Neighborhood Embedding (t-SNE)<sup><xref ref-type="bibr" rid="c14">14</xref></sup>, Uniform Manifold Approximation and Projection (UMAP)<sup><xref ref-type="bibr" rid="c15">15</xref>,<xref ref-type="bibr" rid="c16">16</xref></sup>, and Pairwise Manifold Approximation and Projection (PaCMAP)<sup><xref ref-type="bibr" rid="c17">17</xref></sup>, Minimum Distortion Embedding (MDE)<sup><xref ref-type="bibr" rid="c18">18</xref></sup>. Approaches based on autoencoders<sup><xref ref-type="bibr" rid="c19">19</xref></sup> are a recent exception to these two categories.</p>
<p>All these methods attempt to find adequate low-dimensional mappings to high-dimensional data, which are crucial in single-cell analyses. Theoretically, finding latent signals representative of cellular identity is intrinsically related to defining a finite number of cell lineages and types within a given dataset<sup><xref ref-type="bibr" rid="c20">20</xref>,<xref ref-type="bibr" rid="c21">21</xref></sup>. Ideally, in such mappings, moving through continuous topologies in the form of connected populations often correspond to differentiation trajectories or stimulus-response processes<sup><xref ref-type="bibr" rid="c21">21</xref>,<xref ref-type="bibr" rid="c22">22</xref></sup>, while the space between discrete topologies should indicate the correspondence to different main cell types. The connection between this concept and an empirical view of the Waddington epigenetic landscape is direct and has been recently explored<sup><xref ref-type="bibr" rid="c2">2</xref>,<xref ref-type="bibr" rid="c20">20</xref>,<xref ref-type="bibr" rid="c21">21</xref>,<xref ref-type="bibr" rid="c23">23</xref></sup>. Such mappings are indispensable for downstream tasks in sc-data analysis<sup><xref ref-type="bibr" rid="c24">24</xref></sup>, such as clustering, RNA velocity projection<sup><xref ref-type="bibr" rid="c25">25</xref>,<xref ref-type="bibr" rid="c26">26</xref></sup>, batch-correction<sup><xref ref-type="bibr" rid="c27">27</xref>,<xref ref-type="bibr" rid="c28">28</xref></sup>, trajectory inference<sup><xref ref-type="bibr" rid="c29">29</xref></sup>, and pseudotime estimation<sup><xref ref-type="bibr" rid="c21">21</xref>,<xref ref-type="bibr" rid="c30">30</xref></sup>. Current practice involves using the first few principal components (a hyperparameter commonly set by the user) to compute neighborhood graphs for downstream tasks, such as clustering and graph-layout optimization (GLO) algorithm (i.g., t-SNE or UMAP) for visualization. The GLO procedure is rarely performed on the full set of genes/features (or highly-variable features); instead, the default approach is to use it with either the top principal components or other latent dimensions learned by an autoencoder as with <italic>scvi-tools</italic><sup><xref ref-type="bibr" rid="c31">31</xref></sup>. Despite their popularity, there is little evidence to support these currently held standards.</p>
<p>Defining which dimensionality reductions are the best, from both a theoretical and practical perspectives, has remained an active challenge when analyzing sc-data, as generating and evaluating the reliability of these mappings is an extremely challenging task. No known ground truth exists, and real-world data are immensely more complex than any toy datasets that could be generated to investigate the suitability of DR techniques. Some attempts to compare different DR methods have been made<sup><xref ref-type="bibr" rid="c5">5</xref>,<xref ref-type="bibr" rid="c32">32</xref>,<xref ref-type="bibr" rid="c33">33</xref></sup>; however, they often rely on metrics associated with prior clustering results (e.g., the Adjusted Rand Index), thus holding no guarantees that a good-performing method preserves the underlying geometry of the data. Qualitatively assessing the representation of known biological ground truths as visualization landmarks is also challenging, as only a few are known (e.g., the cell cycle as a closed loop); and even when present, they are prone to promote unconscious confirmatory biases and cannot be extended to the entire representation. The current gold standard of experimentally validating some hypotheses drawn from the learned representations cannot be considered a validation of the whole representation <italic>per se</italic> either. Moreover, each algorithm’s own assumptions (often implicit and by construction) regarding data’s statistical and geometrical properties are also disturbingly challenging to assess in practice. For example, the universally used PCA holds the strong assumption that data is uniformly distributed and lies approximately in a series of hyperplanes (the principal components) by definition, which generates misleading results when faced with non-uniform or non-linear structure by missing local information and introducing linear distortions<sup><xref ref-type="bibr" rid="c6">6</xref>,<xref ref-type="bibr" rid="c14">14</xref>,<xref ref-type="bibr" rid="c15">15</xref>,<xref ref-type="bibr" rid="c34">34</xref>–<xref ref-type="bibr" rid="c37">37</xref></sup>. The popular UMAP<sup><xref ref-type="bibr" rid="c15">15</xref></sup>, whereas more extensive by considering that the data is dispersed over or close to a locally connected Riemannian manifold, assumes this distribution is uniform across a manifold, with a locally constant metric. As such, representations of data with non-uniform data sampling could be filled with artifacts without any warning to users. As most downstream analysis and biological conclusions drawn from sc-data rely on the lower-dimensional mappings learned by DR, it is crucial for them to be formally guaranteed to represent latent biology. These should be independent of the data distribution or the underlying geometry, which should be considered unknown even for extensively investigated systems. Regardless, this is not the case when using the current standard approach (i.e., using UMAP or t-SNE on the top Principal Components); in fact, its assumptions likely do not hold true for all datasets, in which case artifactual distortions can be introduced in the learned representations. Any inferences made from these representations are critical and will impact downstream analyses; thus raising concerns about the credibility of the vast literature in which this practice was adopted.</p>
<p>Despite the importance of minimizing assumptions regarding the latent geometry underlying high-dimensional data, an approach that fully yields the power of topological Laplacian-type operators is yet to be proposed. These operators have been widely and successfully used in many applications, from computer vision to natural language processing, but not in single-cell biology. They are particularly advantageous because they approximate the Laplace-Beltrami Operator (LBO) at the limit of large data (i.e., when the number of samples is very large, as in sc-data). We consider the extremely loose assumption that data lies on a Riemannian manifold. It is a fundamental result in mathematics that the LBO encodes all the local geometric information of a Riemannian manifold with an unknown shape<sup><xref ref-type="bibr" rid="c8">8</xref>,<xref ref-type="bibr" rid="c9">9</xref>,<xref ref-type="bibr" rid="c11">11</xref>,<xref ref-type="bibr" rid="c36">36</xref>,<xref ref-type="bibr" rid="c38">38</xref></sup>. The top eigenfunctions of this operator can then be used to approximate the original data<sup><xref ref-type="bibr" rid="c9">9</xref></sup> so that each eigenfunction carries a fundamental harmonic of the data<sup><xref ref-type="bibr" rid="c8">8</xref>,<xref ref-type="bibr" rid="c9">9</xref>,<xref ref-type="bibr" rid="c13">13</xref></sup>. In addition, because current theoretical biology points to an underlying Waddington landscape within the sampled biological system<sup><xref ref-type="bibr" rid="c20">20</xref></sup>, these can be naturally modeled as a Riemannian manifold. We refer to such theoretical manifolds as <italic>phenotypic manifolds</italic>. We reasoned that recovering such manifolds by approximating the LBO would thus render optimal sc-data representations while holding no prior assumptions regarding the underlying data geometry. Here, we show how combining LBO eigenfunctions with existing projection (GLO) techniques yields representations of high-dimensional data that preserve more original information than those learned with current standards (PCA-based) or with GLO alone. This strategy makes the Riemannian metric<sup><xref ref-type="bibr" rid="c36">36</xref></sup> a natural metric for evaluating the distortion of these visualizations, a most critical feature that the field currently lacks. We present TopOMetry, a python toolkit to combinatorially obtain numerous LBO approximations using different computational approaches and systematically evaluate them from a quantitative and qualitative perspective. We show this strategy is remarkably superior to the currently held PCA-based approach or to using stand-alone GLO implementations when analyzing single-cell data.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>A framework to systematically learn and evaluate manifolds in single-cell data</title>
<p>To achieve the task of approximating the LBO to recover the phenotypic manifolds underlying sc-data, we developed TopOMetry (Topologically-Optimized geoMetry), a toolkit that combines and enhances state-of-the-art techniques to approximate the LBO through weighted graph Laplacian-type operators. TopOMetry efficiently obtains the eigenspectra of these operators and uses them to approximate the LBO once again. Users can then visualize its graph representation with any existing graph-layout optimization (GLO) algorithms. This modular approach allows combinatorially evaluation of different options of kernels, decomposition, post-processing, and GLO algorithms. It eliminates the need to choose a single approach <italic>a priori</italic> and allows users to decide which of the possible representations better describe each dataset objectively.</p>
<p>TopOMetry takes as input a data matrix of variables per observation (e.g., genes per cell; <xref rid="fig1" ref-type="fig">Figure 1A</xref>). It then computes a <italic>k</italic>-nearest-neighbors graph and uses it to build a kernel matrix with state-of-the-art similarity functions (the default adaptive bandwidth estimation is related to the local intrinsic dimensionality). TopOMetry includes a new family of manifold-adaptive kernels closely related to the intrinsic dimensionalities of the underlying manifold<sup><xref ref-type="bibr" rid="c39">39</xref></sup>. These kernels are then used to learn Laplacian-type operators, which asymptotically approximate the LBO (<xref rid="fig1" ref-type="fig">Figure 1B</xref>). Next, the eigenspectra of the learned Laplacian-type operators are obtained, allowing the estimation of the data global intrinsic dimensionality (<xref rid="fig1" ref-type="fig">Figure 1C</xref>). The resulting orthonormal eigenbasis is related to a Fourier basis and encodes all latent signals present in the original data<sup><xref ref-type="bibr" rid="c8">8</xref>,<xref ref-type="bibr" rid="c9">9</xref>,<xref ref-type="bibr" rid="c13">13</xref></sup>. Such eigenbasis can then be used to compute a new weighted kernel (referred to as <italic>graph kernel</italic>) to obtain a second LBO approximation encoded as a similarity graph (the associated <italic>topological graph;</italic> <xref rid="fig1" ref-type="fig">Figure 1D</xref>), which can then be visualized with existing GLO algorithms (<xref rid="fig1" ref-type="fig">Figure 1E</xref>). These graphs can also be used for downstream tasks such as clustering, signal filtering, pseudotime estimation and others (<xref rid="fig1" ref-type="fig">Figure 1F</xref>). In TopOMetry, dozens of visualizations obtained from the graphs or directly from the eigenbasis can be obtained with a single line of code. These representations’ preservation of local<sup><xref ref-type="bibr" rid="c40">40</xref></sup> and global structure is then systematically evaluated (<xref rid="fig1" ref-type="fig">Figure 1G</xref>), alleviating practitioners’ choice of a single similarity-learning or GLO method. The top-performing projections can then be qualitatively evaluated using the Riemannian metric to assess the distortion induced by the mapping (<xref rid="fig1" ref-type="fig">Figure 1G</xref>).</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Schematic overview of single-cell data analysis with TopOMetry.</title>
<p>(A) Single-cell experiments are preprocessed into high-dimensional matrices of cells and measured variables (e.g., gene expression, protein content, chromatin accessibility) and require dimensional reduction tools for their analysis. Most tools assume unknown aspects of the underlying geometry (e.g., linearity) or distribution (e.g., uniformity). Instead, relying on the Laplace-Beltrami Operator (LBO) and its eigenfunctions allows learning such geometry assuming only the manifold hypothesis. (B) Approximating the LBO involves constructing a k-nearest-neighbors (kNN) graph using adaptive affinity estimation, which can be done through several kernels so to make the affinity graph insensitive to neighborhood densities. The Laplacian-type operators (particularly the anisotropic diffusion operator) are approximations of the LBO. The resulting matrices can be used for several tasks, such as imputation of missing data, signal filtering and interpolation, and graph sparsification and coarsening. (C) The eigendecompositions of the LBO approximations yield eigenvectors and eigenvalues that are weighted or multiscaled to form a new orthogonal eigenbasis. The eigenvalues can be used to estimate an eigengap or spectral gap to estimate the intrinsic dimensionality of the data. The intrinsic dimensionality can also be estimated using neighborhood-based methods (e.g., FSA and MLE) or <italic>ad-hoc</italic> inspection of eigenvectors for discriminative potential. (D) A second neighborhood graph is learned from the eigenbasis, and its Laplacian-type operators are used to obtain a new LBO approximation, rendering ‘topological graphs’. (E) From a spectral initialization obtained from the topological graph, any graph layout optimization (GLO) can be used on the topological graph or the eigenbasis for visualization. (F) Downstream tasks such as clustering, RNA velocity estimation, and imputation can be performed with the learned topological graphs and layouts. (G) The learned eigenbases and visualizations can be evaluated regarding the preservation of global and local structure, and the Riemannian metric can be used to visualize distortions in layouts to aid biological interpretation.</p></caption>
<graphic xlink:href="484134v3_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>The outlined approach has numerous advantages in comparison to the current standards. First, it holds an extremely loose assumption regarding the underlying data geometry compared to PCA or UMAP (the data lies in or close to a Riemannian manifold). Second, such an assumption is mathematically solid and intrinsically related to the core biological goal in sc-data analysis (i.e., to recover the Waddington landscape or an extended version thereof). Third, it involves the estimation of the manifold local and global dimensionality, which alleviates the similarity-learning process and eliminates the need to guess a number of latent dimensions to keep for downstream analysis (as needed when using PCA or autoencoders). Another major advantage is using the Riemannian metric<sup><xref ref-type="bibr" rid="c36">36</xref></sup> as a “distortion ruler,” allowing qualitative assessment of the distortion present in two-dimensional mappings and the robust estimation of the global and local dimensionality of the underlying manifold. Finally, TopOMetry allows users to obtain and evaluate dozens of possible representations with a single command, eliminating the need to choose a pre-defined method (e.g., UMAP on PCA) and allowing users to pick which performs best for each case. This is the toolkit’s main advantage and represents a fundamental change of paradigm in sc-data analysis: instead of <italic>a priori</italic> electing a single method to be used at all times across all datasets, it allows users to discover which particular model works best for representing each individual dataset before other downstream tasks. Computationally, TopOMetry is easy-to-use and centered around a single python class, the <italic>TopOGraph</italic> object, which orchestrates the analyses (<xref rid="figS1" ref-type="fig">Supplementary Figure 1</xref>).</p>
</sec>
<sec id="s2b">
<title>Representations learned with TopOMetry preserve local and global structures across single-cell datasets</title>
<p>We first performed a qualitative sanity test on TopOMetry by running it on synthetic toy data (<xref rid="figS2" ref-type="fig">Supplementary Figure 2A</xref>). The eigenfunctions of the Laplacian-type operators used in the toolkit pass negative control checks with uniformly distributed noise and square and also positive control checks with normally distributed classes. This is best visualized by coloring sample points by their first eigencomponent or principal component (<xref rid="figS2" ref-type="fig">Supplementary Figure 2B</xref>). The representation of uniformly distributed classes as points or straight lines by the first two non-trivial eigenfunctions is related by their encoding of manifold structure (<xref rid="figS2" ref-type="fig">Supplementary Figure 2B</xref>), which further highlights the power of this approach to discover the true geometry of the data regardless of the sampling distribution. We also reinforce that this approach can unfold curved manifolds, such as the classic ‘S’-shape and the swiss-roll examples (<xref rid="figS2" ref-type="fig">Supplementary Figure 2B-C</xref>), and stress the inadequacy of trying to use PCA to represent non-linear geometries (<xref rid="figS2" ref-type="fig">Supplementary Figure 2B-C</xref>). For an additional test on high-dimensional toy data with ground-truth labels, we obtained embeddings from the MNIST handwritten digits dataset with TopOMetry and existing methods (<xref rid="figS2" ref-type="fig">Supplementary Figure 2D</xref>).</p>
<p>To determine TopOMetry’s performance in real-world sc-data, we curated a diverse set of 20 single-cell datasets from different biological systems with varying numbers of cells and variables per cell across diseases, species, and technologies (<xref rid="tbl1" ref-type="table">Table 1</xref>). The datasets were then processed following current standards in scRNA-seq analysis<sup><xref ref-type="bibr" rid="c24">24</xref></sup>: i, library size normalization; ii, logarithmic transformation; iii, selection of highly variable genes (HVG), and iv) scaling (Z-score normalization, i.e., mean centering and variance clipping). For each dataset, we computed the first 100 principal components and obtained two-dimensional (2-D) projections with three existing DR methods: i, t-SNE<sup><xref ref-type="bibr" rid="c14">14</xref></sup>; ii, UMAP<sup><xref ref-type="bibr" rid="c15">15</xref></sup>; iii, PaCMAP<sup><xref ref-type="bibr" rid="c17">17</xref></sup>. Projections were computed using either the principal components (the current standard) or the full data matrices. We then used TopOMetry to obtain 2-D projections using similar graph-layout optimization (GLO) methods. Each visualization was then scored regarding the preservation of the global and local structure. The Mean Reconstruction Error (MRE) was used for quantifying the preservation of the global structure as recently proposed<sup><xref ref-type="bibr" rid="c41">41</xref></sup>, with PCA being a reference by construction (<xref rid="fig3" ref-type="fig">Figure 3A</xref>). It has been shown that the preservation of global structure is mainly driven by the initialization given to GLO algorithms<sup><xref ref-type="bibr" rid="c42">42</xref></sup>, thus making preservation of local structure a more important factor to consider when choosing between options. The trustworthiness score<sup><xref ref-type="bibr" rid="c40">40</xref></sup> was used to assess the preservation of local structure (<xref rid="fig3" ref-type="fig">Figure 3B</xref>). In addition, we also propose a score based on the correlation of geodesic distances in the high- and low-dimensional spaces (<xref rid="fig3" ref-type="fig">Figure 3C</xref>), drawing from previous approaches<sup><xref ref-type="bibr" rid="c33">33</xref>,<xref ref-type="bibr" rid="c43">43</xref></sup>; however, its high computational cost makes its application impractical for most real-world datasets.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><title>Public single-cell RNA-seq datasets that were used in this study benchmark.</title></caption>
<graphic xlink:href="484134v3_tbl1.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<p>Across all datasets, the eigenbases (<xref rid="fig2" ref-type="fig">Figure 2D</xref>) and 2-D representations (<xref rid="fig2" ref-type="fig">Figure 2E</xref>) that yielded the highest local scores (LS) for all datasets were generated with TopOMetry. Global scores (GS) were as high as PCA for TopOMetry’s eigenbases (<xref rid="figS3" ref-type="fig">Supplementary Figure 3A</xref>) and discretely lower for projections when using TopOMetry compared to GLO on data or top principal components on some datasets, with a maximum difference of 0.06 for the <italic>AgeingMouseBrain</italic> dataset (<xref rid="figS3" ref-type="fig">Supplementary Figure 3B</xref>), further suggesting that the preservation of local structure is a more robust metric to discriminate against different visualizations. We found that PCA yielded lower LS for all datasets (<xref rid="fig2" ref-type="fig">Figure 2D</xref>), as expected from a global and linear method. Strikingly, we also found that projections derived from using GLO methods on the top principal components had lower LS when compared to using GLO alone (<xref rid="fig2" ref-type="fig">Figure 2E</xref>), further suggesting that this practice could be inadequate despite being currently held as a default approach. The opposite happens when using TopOMetry’s Laplacian-type eigenbases to build the neighborhood graphs projected with PaCMAP or the diffusion potential from these eigenbases with MAP, as these approaches achieve higher LS than using GLO alone (<xref rid="fig2" ref-type="fig">Figure 2E</xref>). Within TopOMetry, the variation of LS differed mostly across eigenmap methods, with LE scoring lower than DM and msDM, and little to no variation across different kernel methods (<xref rid="fig2" ref-type="fig">Figure 2E</xref>). These results show the superiority of TopOMetry over the standard workflow or GLO methods alone, and highlight the value of critically evaluating methods before electing one for the downstream analysis approach.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>TopOMetry eigenbases and projections preserve more original structure than the current standards.</title>
<p>(A) Schematic overview of the assessment of global structure in TopOMetry - the global score is calculated by taking the exponential of the difference between an embedding MRE and PCA’s MRE, divided by PCA’s MRE. (B) Schematic overview of the assessment of local structure in TopOMetry with the trustworthiness score - the score penalizes embeddings in which cells that are neighbors in the low-but not in the high-dimensional space. (C) Schematic overview of the assessment of distances preservation in manifolds - the pairwise geodesic distances in the high- and low-dimensional spaces are computed, and Spearman R correlation between the rank of neighbors for each cell is obtained as a score. (D) Annotated heatmap of local scores for TopOMetry’s eigenbases and PCA for 20 single-cell datasets (higher is better). (E) Annotated heatmap of local scores for projections learned using expression data, the first 100 principal components, and TopOMetry’s eigenbases or topological graphs for 20 single-cell datasets (higher is better).</p></caption>
<graphic xlink:href="484134v3_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Estimating intrinsic dimensionalities in toy and single-cell data with TopOMetry.</title>
<p>(A) Eigenspectrum of the eigenvalues for each diffusion component learned for the MNIST dataset of handwritten digits with TopOMetry (left) and the absolute value of their first derivatives (right). (B) Distribution of MNIST samples (individual images) across different classes (digits) across diffusion components (top) and principal components (bottom). (C) Histograms of intrinsic dimensionality estimates for each sample in the MNIST dataset, with varying numbers of k-nearest-neighbors, with the FSA (top) and MLE (bottom) methods. (D) Heatmap of Spearman R correlation between FSA and MLE estimates of intrinsic dimensionalities of MNIST images for varying numbers of k-nearest-neighbors. (E) topoMAP projections of a subset of the MNIST handwritten dataset, colored by classes (numbers). The 100 images with the highest (left) or lowest (right) estimates of intrinsic dimensionality are colored black in the projections and shown on the top of each projection. (F) Eigenspectrum of the eigenvalues for each diffusion component learned for the <italic>PBMC3k</italic> dataset of peripheral blood mononuclear cells (10X Genomics) with TopOMetry (left) and the absolute value of their first derivatives (right). (G) Histograms of intrinsic dimensionality estimates for each cell in the <italic>PBMC3k</italic> dataset, with varying numbers of k-nearest-neighbors, with the FSA (top) and MLE (bottom) methods. (H) Heatmap of Spearman R correlation between FSA and MLE estimates of intrinsic dimensionalities of <italic>PBMC3k</italic> cells for varying numbers of k-nearest-neighbors. (I) topoMAP projections of the <italic>PBMC3k</italic> dataset, colored by the estimates obtained with FSA (top) and MLE (bottom) with 100 nearest-neighbors. (J) topoMAP projection of the <italic>PBMC3k</italic> dataset, colored by annotated cell types. (K) Violin plots of estimates of intrinsic dimensionalities of <italic>PBMC3k</italic> cells with FSA (left) and MLE (right) with 100 nearest-neighbors.</p></caption>
<graphic xlink:href="484134v3_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2c">
<title>Estimating and visualizing intrinsic dimensionalities with TopOMetry</title>
<p>Intrinsic dimensionality (i.d.) can be loosely defined as the minimum number of parameters needed to describe a multiparameter (high-dimensional) system accurately<sup><xref ref-type="bibr" rid="c44">44</xref></sup>. Many definitions of i.d. have been proposed, including local and global i.d.<sup><xref ref-type="bibr" rid="c39">39</xref>,<xref ref-type="bibr" rid="c45">45</xref></sup>, and its accurate estimation remains an active field of research. Estimating the global i.d. of a given dataset is intrinsically related to estimating the dimensionality of its underlying manifold<sup><xref ref-type="bibr" rid="c46">46</xref></sup>, which is crucial when performing dimensional reduction (i.e., to estimate how many components to use in matrix decomposition). Furthermore, local i.d. is used in many signal processing applications as a separate variable to describe the data and provide meaningful information regarding the manifold structure. Noticeably, the similarity kernels employed in TopOMetry’s are related to the FSA (Farahmand-Szepesvári-Audibert) method, a recently adapted estimator of intrinsic dimensionality<sup><xref ref-type="bibr" rid="c39">39</xref></sup>; as they harness the ratio between the distances to median nearest-neighbors (i.e., <italic>k/2</italic>) and to k-nearest-neighbors as a measure of local sampling density. To our knowledge, no tool has ever been proposed to evaluate the i.d. of sc-data specifically, despite its centrality for learning accurate representations. Likewise, we know of no other similarity kernels straightforwardly related to local i.d. estimates.</p>
<p>TopOMetry uses three existing strategies to estimate the i.d. of the data’s underlying manifold: i) analyzing the eigenspectrum of its Laplacian-type operators; ii) inspecting the eigenfunctions to evaluate the separation of known classes; and iii) using two independent state-of-the-art algorithms for i.d. estimation, FSA<sup><xref ref-type="bibr" rid="c39">39</xref></sup>, and MLE<sup><xref ref-type="bibr" rid="c47">47</xref></sup>. The two first strategies estimate the global i.d. and the latter estimates the local i.d. and weights them to estimate the global i.d. We first demonstrate these strategies using the MNIST dataset, comprising images of handwritten digits. In this dataset, TopOMetry found an eigengap at 19 dimensions using the eigenvalues’ first derivatives (<xref rid="fig3" ref-type="fig">Figure 3A</xref>). The corresponding eigenfunctions separate the ground-truth classes well, in contrast to the principal components (<xref rid="fig3" ref-type="fig">Figure 3B</xref>). Local i.d. estimates with both FSA and MLE presented nearly identical distributions across a range of possible kNN (<xref rid="fig3" ref-type="fig">Figure 3C</xref>), and the global estimates obtained with these algorithms are similar to the global i.d. predicted by the eigengap (FSA: 17-18, MLE: 12-14). Furthermore, the estimates obtained with these algorithms are highly correlated (<xref rid="fig3" ref-type="fig">Figure 3D</xref>), reinforcing their reliability. To interrogate whether i.d. estimates translated to actual insights regarding the data, we used a subsample of the dataset and visualized the digits with the highest and lowest i.d. Interestingly, the 100 digits with the highest local i.d. were predominantly 3’s, 5’s, and 8’s written with varying calligraphy, indicating an association between local i.d. and intra-cluster heterogeneity (<xref rid="fig3" ref-type="fig">Figure 3E</xref>, left). Conversely, the 100 digits with the lowest local i.d. were predominantly 2’s, 6’s, and 1’s written with consistent calligraphy, further suggesting this association (<xref rid="fig3" ref-type="fig">Figure 3E</xref>, right).</p>
<p>We next examined the PBMC 3k dataset following the same approach to test whether these results translated to real-world sc-data. This dataset comprises ∼2,700 peripheral blood mononuclear cells (PBMC) from a healthy human donor. Once again, the global estimate obtained with the eigengap method (72) (<xref rid="fig3" ref-type="fig">Figure 3F</xref>) was reasonably similar to those obtained with MLE (122-59) and FSA (122-74) (<xref rid="fig3" ref-type="fig">Figure 3G</xref>). Similar to the MNIST dataset, the estimates of local i.d. obtained with MLE and FSA were also highly correlated (<xref rid="fig3" ref-type="fig">Figure 3H</xref>) but strikingly varied across different regions of the represented manifold (<xref rid="fig3" ref-type="fig">Figure 3I</xref>), which is inhabited by discrete cell types (<xref rid="fig3" ref-type="fig">Figure 3J, K</xref>). In this dataset, we found that megakaryocytes, natural killer (NK) T cells, and dendritic cells (DC) presented the highest local i.d. However, different from the MNIST dataset, in which the images can be directly visualized, the biological implications of higher local i.d. for these cell types in the PBMC 3k dataset remain unclear, requiring further investigative strategies. Nevertheless, estimating the local i.d. during exploratory sc-data analysis mains remarkably advantageous, as it: i, allows discovering that distinct cell types inhabiting discrete regions of the phenotypic manifold present strikingly different dimensionalities; ii, indicates that these cell types will present different distortions in representations learned with dimensional reduction; and iii, estimates the number of latent dimensions needed to fully describe the data, which should be between the average and the upper limit of the local i.d. distribution. Defining such a number is a particularly critical issue in sc-data analysis, as most existing approaches try to denoise the data into an arbitrary number of latent dimensions prior to downstream tasks. Within TopOMetry, such estimates are used to guide the number of eigencomponents users should compute for each specific dataset. We expect that estimating the i.d. of sc-data will greatly assist practitioners during its analysis, allowing more accurate representations and providing additional insights regarding its geometry across various methods and tasks.</p>
</sec>
<sec id="s2d">
<title>TopOMetry allows precise manifold learning of small and large-scale datasets</title>
<p>We next aimed to explore how TopOMetry can be useful in inferring cellular development trajectories. For a first demonstration, we obtained scRNAseq data from the developing murine pancreas<sup><xref ref-type="bibr" rid="c48">48</xref></sup> popularly used in RNA velocity estimation (<xref rid="fig3" ref-type="fig">Figure 3A</xref>) and analyzed it with TopOMetry’s overall top-performing model (<xref rid="fig3" ref-type="fig">Figure 3B</xref>, topoMAP for brevity). The representation learned with this model yielded finer-grained lineages when compared to the default PCA-based UMAP. When scoring cells by their predicted cell cycle phase, our model effectively mapped mitotic cells to a closed-loop structure (<xref rid="fig3" ref-type="fig">Figure 3C</xref>), which provides a better representation of the cell cycle than the homogenous cloud found with the default approach (<xref rid="fig3" ref-type="fig">Figure 3D</xref>). A detailed inspection revealed that the default approach places cells with high S and G2/M scores in an intermediate position of the differentiation lineage apart from the remaining cells undergoing the cell cycle (<xref rid="fig3" ref-type="fig">Figure 3D</xref>, marker). Conversely, the same cells are placed close to other cycling cells in the representation learned with TopOMetry (<xref rid="fig3" ref-type="fig">Figure 3C</xref>, marker), providing an optimal representation of the global structure of the underlying manifold. These results and the fact that the cells are indeed cycling are confirmed by visualizing RNA velocity vectors on the embeddings (<xref rid="fig4" ref-type="fig">Figure 4E-F</xref>). The superiority of our approach over the current standard is further reinforced by the fact that the RNA velocity vector field based on the default approach suggests that epsilon cells give rise to beta cells (<xref rid="fig3" ref-type="fig">Figure 3E</xref>). Lineage tracing studies have shown that this is the exception rather than the norm<sup><xref ref-type="bibr" rid="c49">49</xref></sup>: instead, delta cells represent a transient state that later gives rise to alpha cells, which is faithfully represented by the RNA velocity vector field based on the TopOMetry model (<xref rid="fig3" ref-type="fig">Figure 3F</xref>). Finally, it is also shown that the latent dimensions learned by TopOMetry (the multiscaled diffusion components) are associated with particular regions of the underlying manifold (<xref rid="fig4" ref-type="fig">Figure 4G</xref>) corresponding to specific cellular states. This effectively reconstructs the manifold’s topology one region at a time (i.e., one identity per component). These components can also be used for downstream tasks, such as inferring changes in gene signatures along several developmental axes.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Inferring cellular lineages in small and large datasets with TopOMetry.</title>
<p>(A) UMAP and (B) topoMAP projections of the <italic>Pancreas</italic> dataset showing cellular developmental trajectories in the murine pancreas, colored by annotated cell type. (C) topoMAP and (D) UMAP projections of the same data, colored by inferred scores of different cell-cycle phases. The same projections are also colored by the predicted cell-cycle phase of each cell in (E) and (F), and by the first five diffusion components in (G). Arrows indicate a population of cells that are classified as mitotic but were misplaced in the middle of the differentiation trajectory by the default PCA-based UMAP projection. (H) PCA and (I) PCA-based UMAP projections of the <italic>Mouse Organogenesis Cell Atlas</italic> (MOCA) showing cellular developmental trajectories of whole mouse embryos, colored by annotated subtrajectories from the original study. (J) PCA-based UMAP and (K) topoMAP projections of the MOCA dataset, colored by development stage, annotated trajectories and subtrajectories, and TopOMetry clustering results using the standard Leiden community-detection algorithm. Note how the topoMAP projection and the clustering results from TopOMetry uncover dozens of neuronal subtrajectories that match the developmental stage from which cells were sampled.</p></caption>
<graphic xlink:href="484134v3_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Evaluating distortions in two-dimensional projections with the Riemannian metric.</title>
<p>The Riemannian metric can be used to estimate distortions in two-dimensional visualizations and can be represented by ellipses. If no distortion is present in any preferential direction, the ellipses will have zero eccentricities and correspond to circles. If distortion is present in a preferential direction, the ellipse will be aligned in that direction, and its eccentricity indicates the degree of distortion. (A) Synthetic data comprised of three normally distributed clusters with varying degrees of variance (leftmost), and visualization of the Riemannian metric on two-dimensional visualizations of the data obtained with PCA, UMAP, DM (within TopOMetry), and topoMAP (TopOMetry MAP on DM diffusion potential). (B) Visualization of the Riemannian metric on two-dimensional visualizations of the <italic>PBMC3k</italic> dataset obtained with PCA, UMAP, DM (within TopOMetry), and topoMAP (TopOMetry MAP on DM diffusion potential). (C) topoMAP projections of the <italic>PBMC3k</italic> dataset, colored by the eccentricities of ellipses representing the Riemannian metric across the aforementioned visualizations for each cell. (D) Violin plots of the eccentricities of ellipses representing the Riemannian metric on the aforementioned visualizations of the <italic>PBMC3k</italic> dataset, for each cell type annotation.</p></caption>
<graphic xlink:href="484134v3_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Next, we show how TopOMetry can be used for lineage inference in organism-wide cell atlases to learn detailed cellular hierarchies. For this, we harnessed 1.3 million high-quality pre-filtered single-cell transcriptomes from the mouse embryo during organogenesis<sup><xref ref-type="bibr" rid="c50">50</xref></sup>. Standard processing was performed, and data was then represented with PCA (<xref rid="fig3" ref-type="fig">Figure 3H</xref>) or UMAP on the top 300 PCs (<xref rid="fig3" ref-type="fig">Figure 3I</xref> and <xref rid="fig3" ref-type="fig">3J</xref> - annotations are from the original study). TopOMetry analysis was then performed using its default model (<xref rid="fig3" ref-type="fig">Figure 3K</xref>, topoMAP for brevity), and the Leiden community detection algorithm was employed on its diffusion potential graph. Both approaches successfully mapped major cell types as distinct regions of the manifold without apparent connections between them. However, TopOMetry revealed considerably finer-grained cellular lineages (<xref rid="fig3" ref-type="fig">Figure 3K</xref>) than those represented with UMAP on PCA (<xref rid="fig3" ref-type="fig">Figure 3I</xref>). In total, we found approximately 380 subpopulations, while only 56 were originally described (and labeled as subtrajectories). The majority of these populations were neuronal populations, which is consistent with the expected diversity of the central system. Some of the populations found when clustering with TopOMetry are also suggested by the UMAP on PCA (<xref rid="fig3" ref-type="fig">Figure 3I</xref>) representation, albeit with a less clear trajectory. Hence, it is shown that TopOMetry excels at faithfully representing vast datasets comprising hundreds of coexisting lineages, being ideal for representing whole-organism data and performing lineage inference for its intrinsic relation with the Waddington epigenetic landscape.</p>
</sec>
<sec id="s2e">
<title>TopOMetry augments representations with the Riemannian metric to visualize distortions</title>
<p>A central issue when learning low-dimensional representations from sc-data is the introduction of distortions. Distortion is inevitably introduced when a high-dimensional manifold is embedded into a lower-dimensional space. As an illustrative example, consider the Earth and the planar projections used for making two-dimensional maps (e.g., the Mercator projection): in these maps, there is always some distortion, which can involve distances between points or shapes, angles, and areas within the projection. However, while Earth’s true geometry can be physically visualized from space, the epigenetic manifolds<sup><xref ref-type="bibr" rid="c20">20</xref></sup> of phenotypic identities from which sc-data is sampled are unknown and cannot be visually assessed, which makes it extremely challenging to qualitatively evaluate how the low-dimensional mapping distorted them. The theoretical model of cellular diversity as Riemannian manifolds proposed here allows a direct connection with a unique method for evaluating these distortions: expressing the Riemannian metric of the original manifold<sup><xref ref-type="bibr" rid="c36">36</xref></sup> in any given 2-D mapping. The Riemannian metric (RM) is expressed in 2-D coordinates so that it makes the represented distances and angles approximately equal to their original manifold counterparts. In practice, the RM can be visualized as ellipses whose axes indicate the magnitude and directions in which the manifold was distorted. Visually, these ellipses will have eccentricity equal to one if the distortion is uniform in all directions, rendering a circle with a radius approaching zero in the special case of no distortion (i.e., the representation of a given point fully preserves its geometric properties on the manifold). Such an approach allows users to consider how different regions of the manifold were distorted by the representation and to qualitatively compare them for hypothesis generation, effectively working as a “distortion ruler.”</p>
<p>To illustrate these concepts, we used a toy dataset with three randomly distributed clusters with distinct variances (<xref rid="fig4" ref-type="fig">Figure 4A</xref>) and learned their representations with PCA, DM (within TopOMetry), UMAP, and a TopOMetry model (MAP on the diffusion potential of a diffusion map eigenbasis). The RM was then estimated for each embedding and visualized using ellipses. These ellipses present high eccentricity when using the first two principal components, indicating distortion towards the periphery of the embedding and reasonably high eccentricities across all three clusters when using UMAP. In contrast, when using the first two diffusion components learned with TopOMetry, the distortion was found to be negligible for one of the clusters and to happen along with the components themselves for the other two. This was expected, as each cluster is encoded by a separate diffusion component in this scenario. When using the TopOMetry MAP on DM potential model, we found a distortion pattern similar to that observed within UMAP.</p>
<p>Next, to demonstrate its usability in sc-data analysis, we estimated the RM for representations of the classic PBMC 3k dataset learned with PCA, UMAP, UMAP on PCA, and a TopOMetry model (<xref rid="fig4" ref-type="fig">Figure 4B</xref>). As represented by the ellipses, each representation differently distorts specific regions of the manifold. To allow for a more uniform comparison, we color-coded the eccentricity of ellipses corresponding to each cell across methods and visualized them within the TopOMetry layout (<xref rid="fig4" ref-type="fig">Figure 4C</xref>) and with violin plots (<xref rid="fig4" ref-type="fig">Figure 4D</xref>). As observed, the populations associated with the greatest distortion were reasonably consistent across representations; CD4 T cells, CD14+ monocytes, B lymphocytes, and NK cells. These findings suggest that all representations will preferentially misrepresent some cell types, often at different fashions when comparing different methods and that this could be related to the intrinsic geometry of the underlying manifold. Albeit illustrative, this example is limited by the small number of cells available. As CD4+ T cells were more favorably represented within the TopOMetry model and are known for their extreme diversity, we asked whether analyzing a larger amount of samples (cells) could harbor additional insights into their biology.</p>
</sec>
<sec id="s2f">
<title>TopOMetry reveals novel transcriptionally defined T cell populations</title>
<p>To further investigate CD4+ T cells and distortions of the underlying manifold, we harnessed a public dataset comprising approximately 68,000 PBMCs from a healthy donor (10X Genomics, <italic>PBMC68K</italic> dataset). Representations were obtained with UMAP (using either the top 50 or 300 PCs or the highly-variable genes) and TopOMetry models. Cells were then clustered by the Leiden community detection algorithm using weighted neighborhood graphs learned from; i, the top 50 PCs; ii, the top 300 PCs; and iii, TopOMetry’s diffusion potential. We then used CellTypist<sup><xref ref-type="bibr" rid="c51">51</xref></sup> to predict major cell types and subtypes. Results obtained using 50 PCs were essentially identical to previous reports<sup><xref ref-type="bibr" rid="c52">52</xref></sup> (<xref rid="fig6" ref-type="fig">Figure 6A</xref>), rendering 24 clusters, 16 being T cells, which have been classically described with poor marker genes across different single-cell studies<sup><xref ref-type="bibr" rid="c51">51</xref>,<xref ref-type="bibr" rid="c53">53</xref>–<xref ref-type="bibr" rid="c58">58</xref></sup> (<xref rid="fig6" ref-type="fig">Figure 6B</xref>). However, these findings were inconsistent with what we observed when using 300 PCs, in particular for CD4+ T cells (<xref rid="figS4" ref-type="fig">Supplementary Figures 4A-B</xref>), further suggesting that these putative clusters could be linear distortions. A similar discrepancy was found when using stand-alone UMAP, which suggested the existance of additional T cell clusters (<xref rid="figS4" ref-type="fig">Supplementary Figure 4C</xref>). Strikingly, the results obtained with TopOMetry suggest the existence of 123 clusters in this dataset (<xref rid="fig6" ref-type="fig">Figure 6C</xref>), 116 of them being of T cells (<xref rid="fig6" ref-type="fig">Figure 6C</xref>, <xref rid="figS4" ref-type="fig">Supplementary Figure 4D</xref>), and each presenting specific marker genes (<xref rid="fig6" ref-type="fig">Figure 6D</xref>), in sharp contrast to the classic PCA-based approach. The agreement between clustering results obtained with TopOMetry models or with the HVG data and the disparity of these results in confrontation with those found using the PCA-based workflow was quantitatively confirmed using the adjusted mutual information (AMI) score<sup><xref ref-type="bibr" rid="c59">59</xref></sup> (<xref rid="figS4" ref-type="fig">Supplementary Figure 4E</xref>).</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Uncovering the transcriptional diversity of T cells with TopOMetry.</title>
<p>(A) PCA-based UMAP projections of the <italic>PBMC68k</italic> dataset, comprising approximately 68,000 peripheral blood mononuclear cells from a healthy donor (10X Genomics), colored by clustering results obtained with the standard PCA-based approach (left) or with the diffusion potential of TopOMetry msDM eigenbasis (right). The main cell types and the populations for which the two approaches yield similar clustering results are indicated in the figure. Note that the two approaches only reach disagreeing results for T cells. (B) Dotplot of the top marker gene for each cluster found with the standard PCA-based approach, ranked by logistic regression. Note how clusters corresponding to T cells present poor marker genes. (C) topoMAP projection of the <italic>PBMC68k</italic> dataset, colored by clustering results obtained with the standard PCA-based approach (left) or with the diffusion potential of TopOMetry msDM eigenbasis (right). Note that the clusters of T cells found with the former are randomly spread across the dozens of clusters found with the latter. (D) Dotplot of the top marker gene for each cluster found when clustering with TopOMetry, ranked by logistic regression with identical parameters. Note how clusters corresponding to T cells present highly-specific marker genes. (E) Boxplots of the number of T cell clusters (left) found with different clustering strategies (standard PCA-based, using expression data and with TopOMetry) and their mean size (right), across four datasets of peripheral blood mononuclear cells from human donors: <italic>PBMC68k, Dengue, Lupus</italic>, and <italic>MS_CSF</italic>. (F) PCA-based UMAP and (G) topoMAP projections of lymphoid cells from the <italic>Tissue Immune Cell Atlas</italic> (TICA) dataset, comprised of lymphoid cells across different organs and donors, colored by annotations from the original study (left) and clustering results obtained with TopOMetry (right). Note that the two clustering results reach disagreeing results mostly for CD4+ cell clusters. (H) PCA-based UMAP and (I) topoMAP projections of the TICA dataset, colored by clonal expansion thresholds. (J) PCA-based UMAP and (K) topoMAP projections of the TICA dataset, colored by the 30 clonotypes with the highest amount of cells. The arrows indicate the precise match of these clonotypes to the manifold structure uncovered by TopOMetry. (L) PCA-based UMAP and (M) topoMAP projections of the TICA dataset, colored by the epitopes recognized by each T cell. The arrows indicate populations recognizing specific epitopes that precisely match the manifold structure uncovered by TopOMetry. (N) Heatmap of T cell repertoire overlap between the clusters found in the original study, (O) using expression data and (P) TopOMetry. Note how the original clusters present high repertoire overlap, which is less evident in clusters found using expression data and nearly absent from clusters found with TopOMetry.</p></caption>
<graphic xlink:href="484134v3_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Regarding the identity of the additional clusters, the majority of the discrepant ones were annotated by CellTypist as T central memory (TCM) cells (<xref rid="figS4" ref-type="fig">Supplementary Figure 4F</xref>), although additional clusters corresponding to NK (natural killer) and MAIT (mucosal-associated invariant T) cells were also identified. T regulatory cells were the only T cell subpopulation found across all approaches (<xref rid="figS4" ref-type="fig">Supplementary Figures 4G-I</xref>), in contrast to four other putative subpopulations we identified (marked by expression of <italic>MDN1, C11orf68, IL11RA</italic> and <italic>IL21R</italic>), which were randomly scattered in the PCA-based UMAP embedding, marginally detectable using stand-alone UMAP and clearly identified using TopOMetry (<xref rid="figS4" ref-type="fig">Supplementary Figures 4G-I</xref>) .</p>
<p>To elucidate whether these findings were reproducible across different sets of data and not restricted to this particular example, we harnessed three additional independent scRNAseq datasets of human PBMCs, including healthy controls and patients suffering from dengue virus (DenV, <italic>Dengue</italic> dataset) infection, multiple sclerosis (MS, <italic>MS_CSF</italic> dataset) and systemic lupus erythematosus (SLE, <italic>Lupus</italic> dataset). The analyses performed on the <italic>PBMC68K</italic> dataset were then applied for these three datasets, with identical parameters. We found strikingly consistent results across all three datasets, in which clustering and UMAP results obtained with 50 PCs were inconsistent with those obtained using the original data (HVGs) or TopOMetry (<xref rid="figS5" ref-type="fig">Supplementary Figures 5A-C</xref>). Likewise, specific marker genes were found for the clusters identified with TopOMetry, in contrast to the poorly-defined signatures observed for PCA-derived clusters (<xref rid="figS5" ref-type="fig">Supplementary Figures 5D-F</xref>). In average, 18 clusters of T cells were found using 50PC, in contrast to a mean of 73 identified using the HVGs and of 137 identified using TopOMetry (<xref rid="fig6" ref-type="fig">Figure 6E</xref>). The average number of cells in these clusters was expressively smaller using HVGs (608) and TopOMetry (320) in comparison to using 50 PCs (2489). In addition, the adjusted mutual information score for different clustering strategies followed a similar pattern to that observed with the <italic>PBMC68K</italic> dataset, in which clustering results using the expression data are more similar to TopOMetry than to the standard PCA-based workflow (<xref rid="figS5" ref-type="fig">Supplementary Figure 5G</xref>). Unexpectadly, different TopOMetry models presented a high AMI score, demonstrating their sucessfull convergence towards the LBO to describe the underlying phenotypic manifold.</p>
<p>To explore whether or not the identified T cell subpopulations were functionally distinct from a T cell receptor perspective, we harnessed an additional dataset - the T cell compartment of the Tissue Immune Cell Atlas<sup><xref ref-type="bibr" rid="c51">51</xref></sup>, comprising scRNA-seq and scVDJ-seq from T cells obtained from multiple human donors and tissues, including blood, that were jointly analyzed using the standard PCA-based workflow (<xref rid="fig6" ref-type="fig">Figure 6F</xref>). When analyzing this data with TopOMetry, we found a mismatch between the clusters identified with it and the clusters described in the publication, particularly around CD4+ cells (<xref rid="fig6" ref-type="fig">Figure 6G</xref>, <xref rid="figS6" ref-type="fig">Supplementary Figure 6A</xref> and <xref rid="fig6" ref-type="fig">6B</xref>), in a similar fashion to the previous datasets. T cell clonotypes were identified based on amino-acid sequence similarity using ScirPy<sup><xref ref-type="bibr" rid="c60">60</xref></sup>, and were found to match the clusters found with TopOMetry (<xref rid="figS6" ref-type="fig">Supplementary Figure 6C</xref>) better than the originally described clusters (<xref rid="figS6" ref-type="fig">Supplementary Figure 6D</xref>). When analyzing TCR clonal expansion, we found that subpopulations with larger expansion corresponded to NK and CD8+ cells, as expected and previously described<sup><xref ref-type="bibr" rid="c51">51</xref></sup> (<xref rid="fig6" ref-type="fig">Figure 6H</xref>). However, populations with modest expansion corresponded to the CD4+ T cell clusters identified with TopOMetry (<xref rid="fig6" ref-type="fig">Figure 6H</xref>), suggesting these clusters correspond to specific clonal identities. To further explore this hypothesis, the 30 clonotypes with the most cells were visualized on the original UMAP embedding (<xref rid="fig6" ref-type="fig">Figure 6J</xref>), on which they are sparsely and randomly distributed, and on the TopOMetry embedding (topoMAP, <xref rid="fig6" ref-type="fig">Figure 6K</xref>), on which they are remarkably localized alongside the clusters found with TopOMetry. Consistent with these findings, the clonotype modularity (how densely connected the mRNA-derived neighborhood graph underlying the cells in a given clonotype is) was found to be higher when using TopOMetry in comparison to the standard approach (Suppplementary <xref rid="fig6" ref-type="fig">Figure 6E</xref> and <xref rid="fig6" ref-type="fig">6F</xref>). Next, we cross-referenced the TCR structure to VDJdb, a public database of antigen epitopes<sup><xref ref-type="bibr" rid="c60">60</xref>,<xref ref-type="bibr" rid="c61">61</xref></sup>, and identified two transcriptionally defined clusters which present TCR that bind to SARS-CoV-2 and EBV epitopes (<xref rid="fig6" ref-type="fig">Figures 6L</xref> and <xref rid="fig6" ref-type="fig">6M</xref>); these populations are well-defined in the TopOMetry analyses, but are unindentifiable in the original UMAP. These results suggest that the clusters of T cells identified by TopOMetry correspond to specific clonal populations. This hypothesis is confirmed by analysis of TCR repertoire overlap across clustering results - while the clusters defined in the publication present a high repertoire overlap (<xref rid="fig6" ref-type="fig">Figure 6N</xref>), those identified using HVGs are expressively more well-separated (<xref rid="fig6" ref-type="fig">Figure 6O</xref>), and those obtained with TopOMetry present no overlap at all (<xref rid="fig6" ref-type="fig">Figure 6P</xref>). Indeed, we found that cells belonging to specific clonotypes defined by amino-acid sequence similarity also expressed the transcripts for the TCR chains identified by VDJ-seq (<xref rid="figS6" ref-type="fig">Supplementary Figures 6G-J</xref>). These results confirm that TopOMetry is able to identify clonal populations from mRNA expression alone, and strongly suggest that the T cell clusters found in the other analyzed datasets (for which VDJ data is not available) also correspond to specific clones.</p>
<p>Throghout the analyzed datasets containing T cells, it was noticeable that the major cell populations (CD4+ and CD8+ T, NK and B cells, monocytes and megakaryocytes) were similarly represented by the default workflow using 50 or 300 PCs, stand-alone UMAP and clustering on HVG and TopOMetry. Two main reasons could underlie such discrepancy on the underlying manifold of different cell types: i) high intrinsic dimensionalities (i.d.) and ii) highly non-linear geometry at a local level. To test the former, we used the FSA and MLE i.d. estimation methods, and found that T cells did not present particularly high i.d. in any of the tested datasets (<xref rid="figS7" ref-type="fig">Supplementary Figure 7A</xref>). To test the latter, we computed PCA with up to 300 PCs and calculated the total explained covariance, and found that 50 and 300 PCs explained an average of only 20.09% and 41.89% of the total covariance for these datasets when using the default parameters in <italic>scanpy</italic><sup><xref ref-type="bibr" rid="c52">52</xref></sup>, with an <italic>ad hoc</italic> ‘elbow point’ around 30 PCs (<xref rid="figS7" ref-type="fig">Supplementary Figures 7B-F</xref>), at which only 17.7% of covariance was explained, in average. Remarkably, no HVG selection approach yielded orthogonal bases that explained more than 55% of variance at 300 PCs. Such low values of explained covariance are widely known as a hallmark of highly non-linear systems in the broader machine-learning community, albeit apparently unnoticed within the single-cell niche. Taken together, these findings and the lack of specific marker genes for clusters learned from a PCA-based neighborhood graph strongly suggest that the phenotypic manifolds underlying T cell identity are highly non-linear and poorly approximated by hyperplanes of maximum covariance, and point to the introduction of linear distortion by PCA preprocessing. Accordingly, we found that the distortion was significantly higher in the PCA-based UMAP representations compared to the topoMAP representation across all datasets in T cells (p &lt; 10<sup>-90</sup>, two-sided Wilcoxon test), as represented by ellipse eccentricities when projecting the Riemannian metric (Supplementary Figure G). Thus, it is clear that the CD4+ T cell clusters found with the standard workflow are PCA-derived artifacts rather than real biological subpopulations, and that the clusters found using HVGs or TopOMetry better correspond to the actual biological subpopulations.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Finding low-dimensional spaces encoding the phenotypic manifolds underlying single-cell data is a fundamental task in single-cell analysis and a prerequisite for the performance of most existing algorithms used in downstream analyses (e.g., clustering, marker genes, RNA velocity). However, how to properly find and evaluate such spaces has remained elusive. Here, we draw from recent advances in spectral graph theory and high-dimensional data analysis to show that such spaces are best modeled as Riemannian manifolds in a comprehensive theoretical framework, and present TopOMetry, a robust, user-friendly and efficient toolkit that allows users to fully explore such manifolds in single-cell atlases with minimal assumptions about the data (i.e., the manifold hypothesis<sup><xref ref-type="bibr" rid="c62">62</xref></sup>). A first-of-its-kind, the toolkit addresses numerous gaps in high-dimensional and single-cell data analysis, providing means to estimate intrinsic dimensionalities, learning consistent topological representations<sup><xref ref-type="bibr" rid="c13">13</xref></sup> and evaluating subspaces from a global and local perspective. The ability of learning and evaluating dozens of representations with a single line of code empowers single-cell analysis, as one cannot be sure whether a particular computational algorithm will perform well in any given set of data: extending the conclusions obtained from even dozens of datasets to the vast and exponentially growing corpora of single-cell data would be a dangerous assumption. Instead of relying on the presumed supremacy of any given algorithm or assuming data structures, users are endowed with the capacity of testing different approaches that pursue the same unbiased mathematical goal (LBO approximation) and decide which to adopt based on quantitative and qualitative evaluations. Remarkably, it allows assessing distortion in visualizations for the first time by harnessing the Riemannian metric, addressing current criticism<sup><xref ref-type="bibr" rid="c63">63</xref></sup> on the biological interpretation of embeddings from single-cell data. Its modular design, extensive documentation and its interoperability with the larger python ecosystem for single-cell analyses ought to make its adoption easy and seamless to the majority of users. Similar to any other tool, it presents limitations, the major one being that, in its current form, it does not allow online or inverse learning, although that may be bypassed by the use of recently developed geometric regularized autoencoders<sup><xref ref-type="bibr" rid="c64">64</xref></sup>. Another limitation is the high computational cost of evaluating subspaces, a shared feature of existing tools<sup><xref ref-type="bibr" rid="c33">33</xref>,<xref ref-type="bibr" rid="c43">43</xref></sup>, as it involves operating on dense matrices pairwise distances on memory. We expect that our results will inspire the development of numerous other approaches harnessing the power of Laplacian-type operators and consistent manifold learning for the analysis of sc-data.</p>
<p>The power of the proposed theoretical framework and toolkit are demonstrated throughout the presented examples, identifying developmental trajectories in the murine pancreas that better match existing knowledge, representing the cell cycle as a closed loop, and dissecting numerous neuronal lineages throughout embryonic development. In particular, the identification of approximately 130 novel subpopulations of T cells across datasets sheds unprecedented light on T cell biology, alongside the match between these populations and TCR clones. Diversity is a known hallmark of T cells, but such diversity has remained obscured in scRNA-seq data, leading to a common belief that T cells are not transcriptionally heterogeneous. The results shown herein suggest the opposite, forming a new model in which different clones of T cells are transcriptionally distinct and that clonality can be inferred from transcriptional information alone. Moreover, our findings point to the widespread use of PCA as a universal preprocessing step without any consideration for possible non-linear geometries as the reason previous studies failed to detect them, and these results warrant the community to further assess the extent to which published results have been corrupted by PCA, and to carefully reconsider its use in single-cell analyses. However, this methodological study falls short of further experimental investigation of these subpopulations. Thus, the mechanisms and functions underlying such diversity are yet unclear, and future studies targeting specific T cell subtypes are warranted to further elucidate these populations.</p>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Public data acquisition and availability</title>
<p>Public single-cell RNA-seq datasets (<xref rid="tbl1" ref-type="table">Table 1</xref>) were obtained from various sources and processed following the standard data analysis. The used sources and processing parameters are available in Table 2 alongside additional information for each dataset.</p>
</sec>
<sec id="s4b">
<title>Code availability</title>
<p>TopOMetry is freely accessible as a python library. The source code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/davisidarta/topometry">https://github.com/davisidarta/topometry</ext-link>, and can be easily installed through the python package index (PyPI) at <ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/topometry/">https://pypi.org/project/topometry/</ext-link>. The library is extensively documented at <ext-link ext-link-type="uri" xlink:href="https://topometry.readthedocs.io">https://topometry.readthedocs.io</ext-link>. Code used to generate the exposed examples is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/davisidarta/topometry-manuscript">https://github.com/davisidarta/topometry-manuscript</ext-link>. Code used for the benchmark shown in <xref rid="fig2" ref-type="fig">Figure 2</xref> and <xref rid="figS3" ref-type="fig">Supplementary Figure 3</xref> is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/davisidarta/topometry-dr-benchmark">https://github.com/davisidarta/topometry-dr-benchmark</ext-link>. Any additional information can be requested from the authors and will be promptly made available.</p>
</sec>
<sec id="s4c">
<title>Standard data analysis</title>
<p>Count matrices were used to create AnnData objects within <italic>scanpy</italic><sup><xref ref-type="bibr" rid="c52">52</xref></sup>, which were filtered to recommended thresholds. Data were then processed with the following workflow: i) data were library-size normalized to a factor of 10,000 and variance stabilized by log normalization; ii) highly variable genes (HVGs) were identified and kept for downstream analysis-selection parameters were adjusted so that each dataset had between 1,500 and 4,000 HVGs; iii) HVG-data was then centered and scaled (i.e., standardization or z-score transformation); iv) dimensionality reduced to 50 or 300 dimensions with PCA; v) neighborhoods were computed using UMAP fuzzy simplicial sets using the cosine metric distance; vi) the neighborhood graph was projected with UMAP and t-SNE; and vii) the neighborhood graph was clustered with the Leiden community detection algorithm, with the <italic>resolution</italic> parameter set to 2. These steps correspond to the workflow applied in most manuscripts in which single-cell data is analyzed, being the norm in the field and regarded as the current gold-standard<sup><xref ref-type="bibr" rid="c65">65</xref></sup>. Thus, we refer to these as the standard workflow throughout the manuscript. Unless otherwise stated, this was performed with default parameters within the SCANPY toolkit for single-cell analysis.</p>
<p>When stated that stand-alone UMAP and clustering was performed on HVGs, we refer to the scaled data matrix of <italic>cells vs. HVGs</italic>. In these cases, all analyses were still performed within scanpy, but setting the parameters <italic>use_rep=’X’</italic> and <italic>n_pcs=0</italic> in the <italic>scanpy</italic>.<italic>pp</italic>.<italic>neighbors()</italic> function, which causes the neighborhood graph to be computed on the scaled data instead of top principal components. UMAP projections and Leiden clustering results were then obtained normally using scanpy built-in functions.</p>
<p>Cluster marker genes were found with logistic regression<sup><xref ref-type="bibr" rid="c66">66</xref></sup> by using <italic>scanpy’s</italic> in all demonstrated examples, which calls <italic>scikit-learn</italic><sup><xref ref-type="bibr" rid="c67">67</xref></sup> <italic>LogisticRegression</italic> estimator with default parameters (L2 regularization). The number of maximum iterations was set to 1000 for all examples and clustering results.</p>
</sec>
<sec id="s4d">
<title>Topologically Optimized geoMetry</title>
<sec id="s4d1">
<title>Overview</title>
<p>Fundamentally, TopOMetry learns representations using the discrete approximation of the Laplace-Beltrami Operator (LBO; △<italic>f</italic>), formally defined as the divergence of the gradient:
<disp-formula id="ueqn1">
<graphic xlink:href="484134v3_ueqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>The LBO is a powerful descriptor of data geometry under the manifold assumption, as on a Riemannian manifold (a smooth manifold <italic>M</italic> with a Riemannian metric <italic>g</italic> defined at every point <italic>p</italic> ∈ <italic>M</italic>), the LBO entirely determines the Riemannian metric <italic>g</italic> - and therefore, all topological properties of the manifold. This remarkable feature was previously explored by methods like Laplacian Eigenmaps (LE) and Diffusion Maps (DM)<sup><xref ref-type="bibr" rid="c9">9</xref>,<xref ref-type="bibr" rid="c10">10</xref>,<xref ref-type="bibr" rid="c68">68</xref></sup>, in which Laplacian-type operators obtained from affinity matrices approximate the LBO. The eigendecomposition of these operators is then used to find latent subspaces that completely preserve the geometry of the underlying manifold. This approach has been shown to be particularly robust when using affinity matrices learned with variable bandwidth kernels<sup><xref ref-type="bibr" rid="c68">68</xref></sup>, continuous-k-nearest-neighbors (CkNN)<sup><xref ref-type="bibr" rid="c13">13</xref></sup> or fuzzy simplicial sets<sup><xref ref-type="bibr" rid="c15">15</xref>,<xref ref-type="bibr" rid="c69">69</xref></sup>.</p>
<p>TopOMetry combines and expands these previous approaches into a comprehensive framework that approximates the LBO iteratively to learn faithful low-dimensional representations of high-dimensional data. First, a k-nearest-neighbors (kNN) graph is obtained from the standardized data (the <italic>base kNN graph</italic>), and then used to estimate affinity matrices using different kernels (the <italic>base kernel</italic>). Laplacian-type operators are obtained from these matrices (the ‘geometric’ Laplacian with DM, also referred to as the diffusion operator, and the ‘random-walk’ Laplacian with LE), and their eigenvectors are used to form a new orthogonal basis in which the latent geometry of the original data is preserved. The learned orthogonal bases (the <italic>eigenbases</italic>) can be used for numerous downstream tasks, such as computing specialized neighborhood graphs for graph layout optimization (GLO) algorithms such as t-SNE and PaCMAP. It has been previously shown that multiple eigenvectors can be needed to encode data heterogeneity<sup><xref ref-type="bibr" rid="c43">43</xref>,<xref ref-type="bibr" rid="c70">70</xref>,<xref ref-type="bibr" rid="c71">71</xref></sup>, each encoding a different aspect of data structure, i.e., distinct cellular trajectories, and dozens or hundreds of diffusion components could be needed to describe large-scale, whole-organism single-cell data. Thus, these orthogonal bases in which all latent geometry is encoded are still high-dimensional, and as such, can be described through a second round of LBO approximation. In this step, TopOMetry learns a new kNN graph from these bases, from which new affinity matrices and Laplacian-type operators can be computed - these operators encode the latent geometry on a higher level, and can be used for other downstream tasks such as clustering and GLO. The diffusion potential is used by default for clustering (e.g., with the Leiden community-detection algorithm) and GLO (e.g., with MAP, a simplified version of UMAP), and its eigendecomposition is used as initialization for GLO algorithms. As a result, TopOMetry harnesses LBO approximations at each step of dimensional reduction, offering a pipeline that is completely unsupervised and dependent uniquely on the intrinsic geometry of the underlying manifold, while also allowing the flexibility of testing multiple options of kernels and types of Laplacian operators.</p>
</sec>
</sec>
<sec id="s4e">
<title>Computational implementation</title>
<p>TopOMetry was designed to be easy to use, and as computationally efficient as possible. Popular approximate nearest-neighbor libraries (ANN, e.g., <italic>NMSlib, hnswlib, and annoy</italic>) are seamlessly integrated into the toolkit. Nearly all graph operations are performed on sparse matrices and are highly scalable with multithreading. Each step of the workflow involves the use of a modular class based on <italic>scikit-learn</italic><sup><xref ref-type="bibr" rid="c67">67</xref></sup> transformers, thus allowing users to construct custom-made pipelines from them. The main classes are estimators of neighborhood graphs, affinity kernels (and associated graph operators), eigendecompositions and graph layout optimizations. The analysis is centered on the <italic>TopOGraph</italic> class, which orchestrates these classes into a streamlined workflow (<xref rid="figS1" ref-type="fig">Supplementary Figure 1</xref>). The modular nature of the software allows it to be easily integrated into diverse machine-learning and sc-data analysis workflows. It also includes additional classes and functions for evaluating lower-dimensional spaces, estimating intrinsic dimensionalities, and visualizing results. Some of these functions harness the <italic>TopOGraph</italic> class into high-level APIs that allow users to compute, evaluate and inspect the results of dozens of possible layouts from a single dataset using a single line of code, or to do so using the standard <italic>AnnData</italic> object<sup><xref ref-type="bibr" rid="c52">52</xref></sup>. Extensive documentation and tutorials are available at <ext-link ext-link-type="uri" xlink:href="https://topometry.readthedocs.io/en/latest/">https://topometry.readthedocs.io/en/latest/</ext-link>.</p>
</sec>
<sec id="s4f">
<title>Construction of k-nearest-neighbor graphs</title>
<p>One of the most fundamental aspect of machine-learning algorithms dealing with high dimensional data is the curse of dimensionality: in higher-dimensional spaces (HDS), the capacity of distance metrics to discriminate dissimilarity decays, i.e. as dimensionality increases, the Euclidean distance between the most similar samples tends to approach the distance between the most dissimilar one<sup><xref ref-type="bibr" rid="c42">42</xref></sup>. Thus, the task of accurately and efficiently computing distances between samples in a large HDS is a challenge by itself, and several algorithms and tools have been developed to address it<sup><xref ref-type="bibr" rid="c72">72</xref></sup>. The most commonly used metric in single-cell data analysis is the Euclidean distance, followed by the cosine and the manhattan distances - yet, in principle, any metric distance could be applied. Recent benchmarks<sup><xref ref-type="bibr" rid="c73">73</xref>,<xref ref-type="bibr" rid="c74">74</xref></sup> have achieved initial insight on the suitability of different metrics to estimate distances between single-cells, pointing towards correlation metrics as a favorable choice, although these were limited to only some single-cell RNA sequencing datasets in PCA-based workflows, and further studies are needed. This guided the choice of the cosine distance metric as a default in TopOMetry and in all presented analyses, as it trivially corresponds to the Pearson correlation distance when using standardized data (which is the current standard in single-cell analysis).</p>
<p>TopOMetry can employ <italic>scikit-learn</italic> and various ANN libraries to construct kNN graphs. Guided by a recent benchmark between distance estimation algorithms<sup><xref ref-type="bibr" rid="c75">75</xref></sup>, we defined the Hierarchical Navigable Small Worlds (HNSW)<sup><xref ref-type="bibr" rid="c76">76</xref>,<xref ref-type="bibr" rid="c77">77</xref></sup> as a default. HNSW has been shown to achieve fast and near-optimal results while being useful for computing a variety of distance metrics (e.g. euclidean, cosine, manhattan). Similarly to other non-linear algorithms, the first step of the diffusion basis is to find a k-nearest-neighbors graph (kNN) graph. As previous studies have shown that using only highly variable features (HVF) for computations increases the power of single-cell analysis<sup><xref ref-type="bibr" rid="c65">65</xref>,<xref ref-type="bibr" rid="c78">78</xref></sup>, we estimated distances from the cell by HVF matrix for the shown experiments. As a reference, ∼1,500 to ∼4,000 genes are generally considered a reasonable range of HVFs in single-cell RNA sequencing data analysis.</p>
</sec>
<sec id="s4g">
<title>Affinity estimation</title>
<sec id="s4g1">
<title>Variable bandwidth kernels</title>
<p>The implemented kernels draws from recent advances in kernel operators and expands them to include two other possible kernels. Instead of the classic Gaussian kernel with a fixed ε bandwidth, several studies have described that variable bandwidth kernels<sup><xref ref-type="bibr" rid="c13">13</xref>,<xref ref-type="bibr" rid="c68">68</xref>,<xref ref-type="bibr" rid="c70">70</xref>,<xref ref-type="bibr" rid="c79">79</xref></sup> act as manifold-adaptive estimators, rendering more robust results. These variable bandwidth kernels were adapted into TopOMetry as a bandwidth-adaptive kernel<sup><xref ref-type="bibr" rid="c68">68</xref>,<xref ref-type="bibr" rid="c68">68</xref>,<xref ref-type="bibr" rid="c71">71</xref>,<xref ref-type="bibr" rid="c79">79</xref></sup> in which the distance between two samples (cells) is normalized by each samples’ distance to its median <italic>k-</italic>nearest-neighbor (i.e. the k/2 - nearest-neighbor). As an extension of this concept, we introduce a novel kernel that includes neighborhood expansion procedure, in which the original <italic>k</italic>NN graph is expanded to additional neighbors using a data-derived estimate on neighborhood sparseness. In addition, we introduce a novel adaptively decaying kernel, in which the rate of similarity learning is adaptively adjusted by each cell neighborhood density instead of by a fixed hyperparameter as otherwise proposed by PHATE’s ‘alpha-decaying kernel’<sup><xref ref-type="bibr" rid="c43">43</xref></sup>.</p>
<p>Guided by previous approaches, we first construct a <italic>k</italic>-nearest-neighbors graph for a given dataset, with N samples (cells) and M measures (genes), using a given distance metric as a local similarity measure. Let ℳ⊂ℝ<sup><italic>n</italic></sup> be a Riemannian manifold with unknown sampling distribution <italic>q</italic> (not necessarily uniformly distributed) in ambient dimension <italic>n</italic>. For a given sample <italic>x</italic><sub><italic>i</italic></sub> ∈ <italic>X</italic><sub><italic>n</italic> ×<italic>m</italic></sub> ⊂ ℳ (the manifold hypothesis - data is assumed to be contained in the proximities of the manifold), consider <italic>nbrs</italic> (<italic>x</italic>) to be the ordered set of its k-nearest-neighbors under some distance metric <disp-formula><graphic xlink:href="484134v3_inline1.gif" mime-subtype="gif" mimetype="image"/></disp-formula></p>
<p>Given that the vector of sample observations <italic>x</italic><sub><italic>i</italic></sub>, a scaling factor σ<sub><italic>i</italic></sub> corresponding to the distance of sample <italic>i</italic> to its median nearest-neighboring sample(s) in the high-dimensional space is defined:
<disp-formula id="ueqn2">
<graphic xlink:href="484134v3_ueqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>Drawing from previous work on adaptive bandwidth diffusion kernels, the following kernel function could be initially used to convert distances into affinities:
<disp-formula id="ueqn3">
<graphic xlink:href="484134v3_ueqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>It is of notice that the inverse of the scaling factor σ<sub><italic>i</italic></sub> is employed in the manifold-adaptive FSA method of intrinsic dimensionality estimation<sup><xref ref-type="bibr" rid="c39">39</xref></sup>.</p>
<p>To minimize the impact of the choice of the number of <italic>k</italic> neighbors hyperparameter on the learned graph structure, we harness the potential of the scaling factor σ<sub><italic>i</italic></sub> to carry information regarding the neighborhood density of <italic>x</italic><sub><italic>i</italic></sub>. For this, a new indirect, continuous metric named <italic>pseudomedian</italic>(Ω) is defined for each sample <italic>x</italic><sub><italic>i</italic></sub> as the interpolation of all σ<sub><italic>i</italic></sub> into the new interval:
<disp-formula id="ueqn4">
<graphic xlink:href="484134v3_ueqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>Ω<sub><italic>i</italic></sub> represents a simple, indirect, and yet intrinsic reference from the distribution of <italic>nbrs</italic> (<italic>x</italic><sub><italic>i</italic></sub>) at a given fixed <italic>k</italic>, thus providing information on the neighborhood density of each individual sample and about the discrete graph-building process. A sample with a sparser neighborhood will have a larger value of Ω than one with a dense neighborhood, indicating the relative need for search expansion in the sparser region. This estimate is implemented in the proposed diffusion process as a way to obtain enriched information about <italic>x</italic><sub><italic>i</italic></sub> neighborhood density, and also as a measure to alleviate the impact of a fixed <italic>k</italic> hyperparameter, as the graph search can be extended as a function of maximum Ω to help avoid insufficient sampling at sparser neighborhoods:
<disp-formula id="ueqn5">
<graphic xlink:href="484134v3_ueqn5.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>It is of note that PHATE<sup><xref ref-type="bibr" rid="c43">43</xref></sup> introduced a kernel with variable bandwidth εequipped with a novel alpha-decay, in which α is a hyperparameter that controls the kernel decay rate. This was a first attempt to handle cases in which a sparsely sampled neighborhood can present with distant neighbors that are weighted with a high affinity. Note that α = 2 leads to the classic Gaussian kernel, and ε is a fixed bandwidth
<disp-formula id="ueqn6">
<graphic xlink:href="484134v3_ueqn6.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>We harness the concept of the alpha-decaying kernel to implement an <italic>adaptively-decaying kernel</italic>, in which the rate of decay is related to the neighborhood sampling density distribution
    <disp-formula id="ueqn6a">
        <graphic xlink:href="484134v3_inline2.gif" mime-subtype="gif" mimetype="image"/>
    </disp-formula></p>
<p>In summary, TopOMetry includes the fixed-bandwidth kernel, adapts the <italic>bandwidth-adaptive</italic> kernel, and introduces the <italic>bandwidth-adaptive</italic> kernel <italic>w</italic>ith neighborhood expansion, the <italic>bandwidth-adaptive adaptively-decaying</italic> kernel, and the <italic>bandwidth-adaptive adaptively-decaying</italic> with neighborhood expansion. By default, the <italic>bandwidth-adaptive</italic> kernel is used, due to its simplicity and relation to the FSA i.d. estimator.</p>
</sec>
</sec>
<sec id="s4h">
<title>Continuous k-nearest neighbors</title>
<p>Continuous k-nearest neighbors (CkNN) is a recently introduced<sup><xref ref-type="bibr" rid="c80">80</xref></sup> method that constructs a single unweighted graph from which the underlying manifold’s structure (i.e. topological information) can be retrieved, given any compact Riemannian manifold. In its introductory manuscript, it was also shown that CkNN is the only unweighted graph construction strategy for which the graph Laplacian converges to the Laplace-Beltrami Operator (LBO). Conceptually, CkNN points to the superiority of <italic>consistent homology</italic> over <italic>persistent homology</italic>. However, differently from variable-bandwidth kernels or fuzzy simplicial sets, this is achieved through an unweighted graph rather than through a weighted graph.</p>
<p>CkNN’s goal is to create an unweighted undirected graph from a given set of samples with distances given by a metric <italic>d</italic>. This translates to deciding whether to connect samples with edges. The two traditional approaches for constructing such a graph are a) fixed ϵ-balls (i.e. connect samples <italic>i, j</italic> if <italic>d</italic>(<italic>i, j</italic>) &lt; ϵ); and b) k-Nearest Neighbors (kNN), in which a fixed integer <italic>k</italic> given as a user defined hyperparameter is used to define edges (i.e. connect samples <italic>i, j</italic> if <italic>d</italic>(<italic>i, j</italic>) ≤ <italic>d</italic>(<italic>i</italic>,<italic>i</italic> <sub><italic>k</italic></sub>) or if <italic>d</italic>(<italic>i, j</italic>) ≤ <italic>d</italic>(<italic>j, j</italic><sub><italic>k</italic></sub>); <italic>i</italic><sub><italic>k</italic></sub> and <italic>j</italic><sub><italic>k</italic></sub> being <italic>i</italic> and <italic>j</italic> k-th nearest neighbor, respectively). As shown in CkNN’s manuscript and in its excellent performance within TopOMetry, a less discrete and rather continuous version of kNN circumvents several limitations imposed by these traditional strategies.</p>
<p>CkNN connects samples <italic>i, j</italic> with edges if <inline-formula><inline-graphic xlink:href="484134v3_inline3.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. Here, δ is a unitless scale parameter allowed to continuously vary. Given a finite set of data, there is only a finite set of possible values for δ, which is set within TopOMetry as a user-provided hyperparameter. There are two main advantages to this approach: first, it allows one to interpret the CkNN graph construction as a kernel method, enabling interpreting the graph Laplacian in terms of δ; second, it allows fixing the <italic>k</italic> hyperparameter, enabling the use of <italic>d</italic>(<italic>i, i</italic><sub><italic>k</italic></sub>) as a local density estimate, similarly to the approximation of geodesics with fuzzy simplicial sets and diffusion harmonics. In practice, this captures the natural multiscale topology of data, wielding smooth geometries where data is sparsely sampled and fine-grained details where data is densely sampled.</p>
</sec>
<sec id="s4i">
<title>Fuzzy simplicial sets</title>
<p>The application of 1-skeleton fuzzy simplicial sets as topological <italic>metrics</italic> on TopOMetry draws entirely from previous work, particularly from UMAP<sup><xref ref-type="bibr" rid="c15">15</xref></sup> theory and the work of David Spivak<sup><xref ref-type="bibr" rid="c69">69</xref></sup>. Our innovation is represented by the use of these metrics to construct new orthogonal bases that capture latent topology, and subsequently to construct topological graphs prior to layout optimization. When using this method to learn metrics from some data <italic>X</italic><sub><italic>n</italic> × <italic>m</italic></sub>, it is assumed <italic>X</italic>is uniformly distributed on a locally connected ℳ Riemannian manifold with a locally constant metric <italic>g</italic>. UMAP originally addresses the uniformity assumption by creating a custom distance for each sample by normalizing distances with respect to their k-th nearest-neighbor to effectively approximate geodesics. To merge each of the discrete metric spaces generated per sample into a global informational space, the metric spaces are converted into fuzzy simplicial sets. A consensus metric can then be obtained by taking a fuzzy union across all metric spaces encoded as fuzzy simplicial sets, rendering a single fuzzy simplicial set which is granted to capture relevant topological metrics on ℳ. The Laplace-Beltrami Operator acting on ℳ can then be approximated from the normalized laplacian of this fuzzy graph representation.</p>
<p>The aforementioned approach is grounded on solid category theory and no major modifications to the fuzzy simplicial set algorithms defined and implemented in UMAP were made, aside from improving its computational performance with approximate-nearest-neighbors with HNSW. For brevity, we direct the reader to UMAP’s<sup><xref ref-type="bibr" rid="c15">15</xref></sup> and David Spivak’s<sup><xref ref-type="bibr" rid="c69">69</xref></sup> manuscripts for in-depth descriptions of the involved category theory. A summarized description follows.</p>
<p>Simplicial sets are generalizations of simplicial complexes that provide a combinatorial approach to the study of topological spaces. Let Δbe a category with the finite order sets [<italic>n</italic>] = {1, …, <italic>n</italic>} as objects, and morphisms given by order-preserving maps. Δ<sup><italic>op</italic></sup> denotes a category with the same objects as Δ and morphisms equivalent to those of Δ with reversed direction. Then, a simplicial set is defined as a functor from Δ<sup><italic>op</italic></sup> to <italic>Sets</italic> (the category of sets). Given a simplicial set <italic>X</italic> : Δ<sup><italic>op</italic></sup> → <italic>Sets</italic>, we refer to the set <italic>X</italic>([<italic>n</italic>]) as <italic>X</italic><sub><italic>n</italic></sub>, and to the elements of the set as the <italic>n</italic>-simplices of <italic>X</italic>. In the category of simplicial sets, there’s a direct correspondence between the <italic>n</italic>-simplices of <italic>X</italic>and morphisms of the standard simplices Δ<sup><italic>n</italic></sup> (Δ<sup><italic>n</italic></sup>→ <italic>X</italic>). For each <italic>x</italic> ∈ <italic>X</italic><sub><italic>n</italic></sub> there’s a corresponding morphism <italic>x</italic>: Δ <sub><italic>n</italic></sub> → <italic>X</italic>, and therefore <inline-formula><inline-graphic xlink:href="484134v3_inline4.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. The standard covariant functor |·| : Δ → <italic>Top</italic>(the category of topological spaces) that sends [<italic>n</italic>]to the standard <italic>n</italic>-simplex |Δ<sup><italic>n</italic></sup>| ⊂ ℝ<sup><italic>n</italic>+1</sup> with standard subspace topology is defined as:
<disp-formula id="ueqn7">
<graphic xlink:href="484134v3_ueqn7.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>And because <italic>X</italic> : Δ<sup><italic>op</italic></sup> → <italic>Sets</italic> is a simplicial set, the realization of <italic>X</italic> (|<italic>X</italic>|) is <inline-formula><inline-graphic xlink:href="484134v3_inline5.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, which associates the topological space with the simplicial set. On the other hand, given a topological space Y, the associated simplicial set <italic>S</italic>(<italic>Y</italic>)(the singular set of Y) is defined as<italic>S</italic>(<italic>Y</italic>) : [<italic>n</italic>] → <italic>hom</italic><sub><italic>Top</italic></sub> (|Δ <sup><italic>n</italic></sup>|, <italic>Y</italic>). The theoretical contributions of David Spivak and UMAP’s authors involve exploiting the fact that the realization functor and singular set functors form an adjunction, translating between topological spaces and simplicial sets - for this, a categorical presentation of fuzzy sets was outlined.</p>
<p>A fuzzy set can be defined as a set for which membership is not binary - rather, it is a fuzzy property represented by continuous values in the unit interval <italic>l</italic> (with <italic>l</italic> = (0, 1] ⊆ℝ, and with topology given by intervals of the form [0, <italic>a</italic>) <italic>for a</italic> ∈ (0, 1]). This allows one to define presheafs: a presheaf <italic>P</italic> on <italic>I</italic> is a functor from Δ<sup><italic>op</italic></sup>to <italic>Sets</italic> . A fuzzy set is a presheaf on <italic>I</italic> such that all maps <italic>P</italic>(<italic>a</italic> ≤ <italic>b</italic>) are injections. <italic>P</italic>([0, <italic>a</italic>))is the set of all elements with at least <italic>a</italic> membership strength. With this concept in mind, the category <italic>Fuzz</italic> of fuzzy sets is defined as the full subcategory of sheaves on <italic>I</italic> spanned by fuzzy sets. Consequently, defining fuzzy simplicial sets (FSS) corresponds to considering presheaves of Δto be valued in <italic>Fuzz</italic> instead of <italic>Sets</italic> . The objects of the category of FSS <italic>sFuzz</italic> are thus functors from Δ<sup><italic>op</italic></sup>to <italic>Fuzz</italic>, and its morphisms are given by natural transformations. Conversely, FSS can be viewed as sheafs over the product topology Δ × <italic>I</italic>, allowing one to apply them to a broad category of extended-pseudo-metric spaces. This will be useful as the initial geodesic normalization step involves creating a unique metric space for each sample.</p>
<p>Extended-pseudo-metric-spaces (<italic>X, d</italic>) are defined as sets <italic>X</italic>and maps <italic>d</italic> :<italic>X</italic>×<italic>X</italic>→ ℝ<sub>≥0</sub> ∪ {∞}, being objects of the category <italic>EPMet</italic>, which has non-expansive maps as morphisms. A further subcategory of finite extended-pseudo-metric-spaces is defined as <italic>FinEPMet</italic>. Previously<sup><xref ref-type="bibr" rid="c69">69</xref></sup>, the realization and singular set functors were extended to FSS by the construction of natural extension functors, <italic>Real</italic> and <italic>Sing</italic>, between the categories <italic>sFuzz</italic>and <italic>EPMet. Real</italic>is defined in terms of standard fuzzy simplices <inline-formula><inline-graphic xlink:href="484134v3_inline6.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, similarly to the the classic realization functor <disp-formula><graphic xlink:href="484134v3_inline7.gif" mime-subtype="gif" mimetype="image"/></disp-formula></p>
<p>A morphism <inline-formula><inline-graphic xlink:href="484134v3_inline8.gif" mime-subtype="gif" mimetype="image"/></inline-formula> exists only if <italic>a</italic> ≤ <italic>b</italic>, and is determined by a Δ morphism σ: [<italic>n</italic>] → [<italic>m</italic>]. The action of Real on such a morphism is then given by the non-expansive map <disp-formula><graphic xlink:href="484134v3_inline9.gif" mime-subtype="gif" mimetype="image"/></disp-formula></p>
<p>This map is then extended to a more general simplicial set <italic>X</italic> by defining <inline-formula><inline-graphic xlink:href="484134v3_inline10.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. Once again, similarly to the classical case, the right adjoint functor <italic>Sing</italic>is then defined for a given extended-pseudo-metric space <italic>Y</italic>in terms of its action on the category of product topology Δ × <italic>I</italic>:
<disp-formula id="ueqn8">
<graphic xlink:href="484134v3_ueqn8.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>As only finite metric spaces are of interest in this case, the associated FSS <italic>Fin</italic> – <italic>sFuzz</italic> is considered and the correspondent <italic>FinReal</italic>and <italic>FinSing</italic>are used. Formally, the functor <italic>FinReal</italic> : <italic>Fin</italic> − <italic>sFuzz</italic> → <italic>FinEPMet</italic> is defined by:
<disp-formula id="ueqn9">
<graphic xlink:href="484134v3_ueqn9.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
,where <italic>d</italic><sub><italic>a</italic></sub> (<italic>x</italic><sub><italic>i</italic></sub>, <italic>x</italic> <sub><italic>j</italic></sub>) is equivalent to− <italic>log</italic>(<italic>a</italic>) if <italic>i</italic> ≠ <italic>j</italic> and to 0 otherwise, allowing <inline-formula><inline-graphic xlink:href="484134v3_inline11.gif" mime-subtype="gif" mimetype="image"/></inline-formula> to be defined. Analogously,</p>
<p><italic>FinSing</italic>: <italic>FinEPMet</italic> → <italic>Fin</italic> − <italic>sFuzz</italic> can be defined by:
<disp-formula id="ueqn10">
<graphic xlink:href="484134v3_ueqn10.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>By construction, we have that the functors <italic>FinReal</italic> : <italic>Fin</italic> − <italic>sFuzz</italic> → <italic>FinEPMet</italic> and <italic>FinSing</italic> : <italic>FinEPMet</italic> → <italic>Fin</italic> − <italic>sFuzz</italic>form an adjunction in which <italic>FinReal</italic>is the left adjoint and<italic>FinSing</italic>is the right adjoint.After the trouble of defining fuzzy simplicial sets and their functors, one can merge the rather incompatible metric spaces created during geodesic approximation to preserve topological information from each metric by first translating each to a fuzzy simplicial set with the <italic>FinSing</italic>functor, and then taking a union across all FSS, resulting in a single FSS that is ought to capture the underlying structure of the manifold ℳ. Given a dataset <italic>X</italic> = {<italic>X</italic><sub>1</sub>,…,<italic>X</italic><sub><italic>n</italic></sub>} ∈ ℝ<sup><italic>n</italic></sup> and its associated family of extended-pseudo-metric spaces {(<italic>X, d</italic><sub><italic>i</italic></sub>)}<sub><italic>i</italic>=1…<italic>N</italic></sub> with common carrier set X, it follows that <italic>d</italic><sub><italic>i</italic></sub> (<italic>X</italic><sub><italic>i</italic></sub>,<italic>X</italic><sub><italic>k</italic></sub>) =<italic>d</italic><sub>ℳ</sub> (<italic>X</italic><sub><italic>i</italic></sub>, <italic>X</italic><sub><italic>k</italic></sub>) − ρif <italic>i</italic> = <italic>j</italic>or <italic>i</italic> = <italic>k</italic>, and that <italic>d</italic><sub><italic>i</italic></sub> (<italic>X</italic><sub><italic>i</italic></sub>, <italic>X</italic><sub><italic>k</italic></sub>) = ∞if otherwise. ρis the distance between <italic>X</italic><sub><italic>i</italic></sub> and its nearest neighbor, and <italic>d</italic><sub>ℳ</sub> is the approximate geodesic distance on the manifold ℳ. Then, the fuzzy topological representation of <italic>X</italic> corresponds to the union: <inline-formula><inline-graphic xlink:href="484134v3_inline12.gif" mime-subtype="gif" mimetype="image"/></inline-formula>.</p>
</sec>
<sec id="s4j">
<title>Learning a latent basis from Laplacian-type operators</title>
<p>TopOMetry employs eigendecomposition to learn latent bases from Laplacian-type operators that approximate the LBO. Diffusion Maps (and its multiscale version) result from the eigendecomposition of the diffusion operator. The construction of a diffusion process on a graph from a given kernel function is a classical topic in spectral graph theory. Given a symmetric positive semi-definite affinity matrix <italic>W</italic>, we define the degree matrix <italic>D</italic> as a diagonal matrix composed of the sum of columns of <inline-formula><inline-graphic xlink:href="484134v3_inline13.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. The unnormalized (or ‘combinatorial’) graph Laplacian <italic>L</italic> is given by: <italic>L</italic> = <italic>D</italic> − <italic>W</italic>. Then the normalized (or ‘symmetrized normalized’) graph Laplacian <italic>L</italic><sub><italic>sym</italic></sub> is given by: <italic>L</italic><sub><italic>sym</italic></sub> = <italic>D</italic> <sup>−1/2</sup> <italic>LD</italic> <sup>−1/2</sup>. The random-walk Laplacian <italic>L</italic><sub><italic>rw</italic></sub> is given by: <italic>L</italic><sub><italic>rw</italic></sub> = <italic>D</italic><sup>−1</sup> <italic>L = 1</italic> − <italic>D</italic><sup>−1</sup> <italic>W</italic>. The diffusion operator <italic>P</italic> can be simply defined as <italic>P</italic> = <italic>D</italic><sub><sup>−1</sup></sub> <italic>W</italic>, but can also be parametrized as <italic>P</italic> <sub>(α)</sub> by the α <italic>anisotropy</italic> value, which controls how much the data distribution is allowed to bias the obtained results, so that only the underlying geometry is considered and the LBO is approximated when α = 1. For that, we first obtain an α-normalized <italic>W</italic><sub>(α)</sub> : <italic>W</italic><sub>(α)</sub> = <italic>D</italic> <sup>−α</sup> <italic>W D</italic> <sup>−α</sup> and form a new degree matrix <inline-formula><inline-graphic xlink:href="484134v3_inline14.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, which is used to form the anisotropic diffusion operator <inline-formula><inline-graphic xlink:href="484134v3_inline15.gif" mime-subtype="gif" mimetype="image"/></inline-formula></p>
<p>These operators can then be decomposition using the the generalized eigenvector problem. In classic Laplacian Eigenmaps (LE), the system <italic>Lf</italic> = λ<italic>D f</italic> is solved to obtain a number of <italic>m</italic> eigenvectors, and these are used to map the data into a <italic>m</italic>-dimensional embedding <inline-formula><inline-graphic xlink:href="484134v3_inline16.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. By default TopOMetry uses the random-walk Laplacian <italic>L</italic><sub><italic>rw</italic></sub>, and eigendecomposes it by <italic>L</italic><sub><italic>rw</italic></sub><italic>f</italic> = λ<italic>f</italic>. In LE, the eigenvectors with smallest eigenvalues are used, the first one being dropped as it is trivial. In Diffusion Maps (DM), the eigenvectors with the highest eigenvalues are obtained by solving <italic>P</italic> <sub>(α)</sub><italic>f</italic> = λ<italic>f</italic>.</p>
<p>Most approaches using DM rely on powering the diffusion operator <italic>P</italic> <sub>(α)</sub> by a given number of <italic>t</italic> ‘diffusion steps’<sup><xref ref-type="bibr" rid="c9">9</xref>,<xref ref-type="bibr" rid="c10">10</xref>,<xref ref-type="bibr" rid="c43">43</xref></sup>, which consist of an additional hyperparameter. Instead, we harnessed an adaptation consisting of multiscaling, which avoids setting a fixed number of <italic>t</italic> diffusion steps and renders weighted diffusion distances across all possible timescales<sup><xref ref-type="bibr" rid="c71">71</xref>,<xref ref-type="bibr" rid="c81">81</xref></sup>.</p>
<p>Given a diffusion operator <italic>P</italic> <sub>(α)</sub> with a defined number of <italic>t</italic> steps and a given estimate <italic>M</italic> of the intrinsic dimensionality (number of non-trivial eigenvalues) of spectral decomposition: ℳ, one can achieve the spectral decomposition:
<disp-formula id="ueqn11">
<graphic xlink:href="484134v3_ueqn11.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>In which <inline-formula><inline-graphic xlink:href="484134v3_inline17.gif" mime-subtype="gif" mimetype="image"/></inline-formula> encodes the diffusion distance <italic>D D</italic> between samples <italic>x</italic><sub><italic>i</italic></sub> and <italic>x</italic><sub><italic>j</italic></sub>, <inline-formula><inline-graphic xlink:href="484134v3_inline18.gif" mime-subtype="gif" mimetype="image"/></inline-formula> along the diffusion component ϕ:
<disp-formula id="ueqn12">
<graphic xlink:href="484134v3_ueqn12.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>We next multiscale distances to account for all possible <italic>t</italic> scales, rendering multiscale diffusion distances <italic>msD D</italic> :
<disp-formula id="ueqn13">
<graphic xlink:href="484134v3_ueqn13.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>Which can be reformulated as:
<disp-formula id="ueqn14">
<graphic xlink:href="484134v3_ueqn14.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>The eigenvalues of the resulting decompositions are useful to perform an empiric estimation of the data intrinsic dimensionality during computations, as the numerical values hit the limits of floating-point precision, which is encoded either by a sign-flip or by the decomposition algorithm outputting null outputs for the eigenvalues that pass this limit. We found that this is a useful way to set the key hyperparameter <italic>n_eigs</italic>, which defines a fixed number of latent dimensions to be computed, and recommend putative users to increase this parameter up to a point where such a spectral gap (or an eigengap) can be observed in scree plots. As shown in <xref rid="fig3" ref-type="fig">Figure 3</xref>, the identified spectral gap often corresponds to external estimates of intrinsic dimensionality.</p>
</sec>
<sec id="s4k">
<title>Graph-layout optimization</title>
<p>Graph layout optimization (GLO) are techniques that aim to optimize a lower-dimensional representation (usually in two or three dimensions, for visualization) that preserves most of some properties from the original data by minimizing a given cost function. Differences between these methods are mostly ough to the different methods to learn similarities from distances and to the number and design of cost functions<sup><xref ref-type="bibr" rid="c82">82</xref></sup>. The seminal t-SNE method, for instance, employs t-Student scores to estimate similarities between samples, and minimizes the Kullback–Leibler divergence between the high-dimensional and lower-dimensional representations. UMAP, which followed t-SNE as the <italic>de facto</italic> gold standard for visualization, learns similarities with fuzzy simplicial sets (FSS), and then minimizes the cross-entropy between the high and lower-dimensional representations. PaCMAP has shed additional light on how these methods work by analyzing the asymptotics of cost functions and empirically testing and defining the characteristics of efficiently designed cost functions; it also introduced the use of more than one cost function during the layout optimization process (i.e. initial iterations follow one cost function, intermediate steps another cost function, final steps a third one). MDE generalizes these concepts by situating layout optimization methods as special cases of convex optimization. With the exception of MAP, TopOMetry harnesses pre-existing implementations of layout algorithms in the python programming language, such as t-SNE, TriMAP, PaCMAP and MDE. A detailed description of the main techniques currently included in the framework and used in the benchmark follows:</p>
<sec id="s4k1">
<title>t-Distributed Stochastic Neighborhood Embedding (t-SNE)</title>
<p>t-SNE<sup><xref ref-type="bibr" rid="c14">14</xref></sup> is an improved version of SNE<sup><xref ref-type="bibr" rid="c83">83</xref></sup> (Stochastic Neighborhood Embedding) that offers significantly superior performance when applied to real-world data. SNE first converts high-dimensional distances into conditional probabilities that represent similarities: the similarity between samples <italic>x</italic><sub><italic>i</italic></sub> and <italic>x</italic><sub><italic>j</italic></sub> corresponds to the probability <italic>p</italic> <sub><italic>i</italic>|<italic>j</italic></sub> that <italic>x</italic><sub><italic>j</italic></sub> would have <italic>x</italic><sub><italic>i</italic></sub> as neighbor if neighbors were chosen according to the probability density under a Gaussian centered at <italic>x</italic> <sub><italic>j</italic></sub>.
<disp-formula id="ueqn15">
<graphic xlink:href="484134v3_ueqn15.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>A similar conditional probability <italic>q</italic><sub><italic>i</italic>|<italic>j</italic></sub> can be computed for the points in the low-dimensional embedding. Traditionally, the gaussian employed in <italic>q</italic><sub><italic>i</italic>|<italic>j</italic></sub> is set to <inline-formula><inline-graphic xlink:href="484134v3_inline19.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, and these similarities are defined by:
<disp-formula id="ueqn16">
<graphic xlink:href="484134v3_ueqn16.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>SNE aims to find a low-dimensional representation that minimizes the difference between these two probability distributions by considering the sum of all Kullback-Leibler (KL) divergences between the high- and low-dimensional representation of each data point. Considering <italic>P</italic> <sub><italic>i</italic></sub> as the conditional probability distribution of samples in their ambient high-dimensional space and <italic>Q</italic><sub><italic>i</italic></sub> its low-dimensional counterpart, the sum of KL divergences for all samples is then minimized through gradient descent, with a cost function <italic>C</italic> defined by:
<disp-formula id="ueqn17">
<graphic xlink:href="484134v3_ueqn17.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>The gradient of of this cost function has the form:
<disp-formula id="ueqn18">
<graphic xlink:href="484134v3_ueqn18.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>And its update update with a momentum term (to avoid local minima) is given by:
<disp-formula id="ueqn19">
<graphic xlink:href="484134v3_ueqn19.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
t-SNE’s superiority to SNE is due to two differences: first, the implementation of a symmetrized version of the SNE cost function; second, the use of heavy-tailed distributions to address the crowding problem. Significant advances have also been made regarding the optimization of the t-SNE cost function to avoid local minima and increase performance. To symmetrize the cost function, instead of minimizing the sum of all KL divergences between high-dimensional and low-dimensional probability distributions, a single KL divergence between the joint probabilities distributions P (high-dimensional) and Q (low-dimensional) is used:
<disp-formula id="ueqn20">
<graphic xlink:href="484134v3_ueqn20.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>In t-SNE, a Student t-distribution with one degree of freedom (the same as a Cauchy distribution) is used as a heavy-tailed distribution for the low-dimensional mapping. This defines the joint probabilities <italic>q</italic><sub><italic>i j</italic></sub>:
<disp-formula id="ueqn21">
<graphic xlink:href="484134v3_ueqn21.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>The gradient of the KL divergence between P and Q (computed using the above equation) is given by:
<disp-formula id="ueqn22">
<graphic xlink:href="484134v3_ueqn22.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>With an update with momentum identical to that of SNE.</p>
<p>There are numerous modifications and adaptations of the t-SNE algorithm (e.g. heavy tailing, density preservation, perplexity combination), and these exceed the scope of this manuscript. The version of t-SNE included in TopOMetry relies on the MulticoreTSNE<sup><xref ref-type="bibr" rid="c84">84</xref>,<xref ref-type="bibr" rid="c85">85</xref></sup> package.</p>
</sec>
</sec>
<sec id="s4l">
<title>Uniform Manifold Approximation and Projection (UMAP) and Manifold Approximation and Projection (MAP)</title>
<p>The similarity metric when using the ‘fuzzy’ algorithm in TopOMetry corresponds to this 1-skeleton of the fuzzy simplicial sets, that is, a fuzzy graph (i.e. a fuzzy set of edges). In essence, UMAP’s algorithm consists of only a couple more steps to learn a low-dimensional representation from <italic>X</italic> by constructing fuzzy topological representations of <italic>X</italic> and its putative low-dimensional representation <italic>Y</italic>. First, the fuzzy set of edges is represented by a reference set <italic>A</italic> and a membership strength function µ : <italic>A</italic> → [0, 1]. Using a presheaf representation P, it’s possible to define <italic>A</italic> = ⋃ P<sub><italic>a</italic>∈(0,1]</sub> ([0, <italic>a</italic>)), and µ(<italic>x</italic>) = <italic>sup</italic>{<italic>a</italic> ∈ (0, 1] | <italic>x</italic> ∈P([0, <italic>a</italic>))}.Then, to generate visualizations, the graph layout is optimized by minimizing the cross-entropy <italic>C</italic> between the high-dimensional and low-dimensional fuzzy sets (<italic>A</italic>, µ) <italic>and</italic> (<italic>A, v</italic>)in terms of the reference set <italic>A</italic>:
<disp-formula id="ueqn23">
<graphic xlink:href="484134v3_ueqn23.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>The MAP approach included in TopOMetry corresponds to a near-identical implementation of UMAP’s optimization procedure, but using arbitrary graphs that are directly used for layout optimization (i.e. the manifold has already been approximated), thus only assuming that the cross-entropy optimization finds global near-optima solutions.</p>
</sec>
<sec id="s4m">
<title>Pairwise Controlled Manifold Approximation and Projection (PaCMAP)</title>
<p>PaCMAP holds significant similarities with UMAP and TriMAP, but introduces its own unique insights. The core idea of PaCMAP is establishing robust loss functions that take into account not only a sample’s local neighborhood, but how that neighborhood relates to closely located neighborhoods and with far away points. First, the neighborhood affinity graph from data is built in a manner identical to TriMAP triplet weighting procedure, in which distances between samples are scaled by the distance between the target sample and its 4th to 6th nearest neighbor:
<disp-formula id="ueqn24">
<graphic xlink:href="484134v3_ueqn24.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>Next, pairs of samples are selected as follows:</p>
<list list-type="bullet">
<list-item><p>Near pairs - a sample’s <italic>k</italic>-nearest-neighbors, based on the scaled distance.</p></list-item>
<list-item><p>Mid-near pairs - for each sample <italic>i</italic>, 6 other samples are randomly selected, and the second-closest to <italic>i</italic> is paired to it in a mid-near pair. The number of mid-near pairs to be sampled is <italic>k</italic> times a hyperparameter (<italic>MN_ratio, default 0</italic>.<italic>5)</italic>.</p></list-item>
<list-item><p>Further pairs - uniformly sample non-neighbors of <italic>i</italic>. The number of further pairs to be sampled is <italic>k</italic> times a hyperparameter (<italic>FP_ratio, default 2)</italic>.</p></list-item>
</list>
<p>Given an initialization (PCA in default PaCMAP, LE in TopOMetry), the embedding is then optimized in three different stages, each with different weights for near-pairs, mid-near pairs and further pairs. Consider a sample <italic>i</italic>, its neighbor <italic>j</italic>, its mid-near pair <italic>k</italic> and its further pair <italic>l</italic>. Given the low-dimensional distance <inline-formula><inline-graphic xlink:href="484134v3_inline20.gif" mime-subtype="gif" mimetype="image"/></inline-formula> between samples <italic>a</italic> and <italic>b</italic>, PaCMAP minimizes the loss:
<disp-formula id="ueqn25">
<graphic xlink:href="484134v3_ueqn25.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>Where <italic>w</italic><sub><italic>nb</italic></sub> is a weight given to <italic>i</italic> neighbors, <italic>w</italic><sub><italic>mn</italic></sub> a weight given to its mid-near pairs and <italic>w</italic><sub><italic>fp</italic></sub> a weight given to its further pairs. The optimization is performed in three stages, each with a number of iterations <italic>t</italic> that can be controlled by the user as hyperparameters. In the first stage (i.e. first 100 <italic>t</italic> iterations), <italic>w</italic><sub><italic>nb</italic></sub> = 2,</p>
<p><inline-formula><inline-graphic xlink:href="484134v3_inline21.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, and <italic>w</italic><sub><italic>fp</italic></sub> = 1. In the second stage, <italic>w</italic><sub><italic>nb</italic></sub> = 3,</p>
<p><italic>w</italic> <sub><italic>mn</italic></sub> = 3, and <italic>w</italic><sub><italic>fp</italic></sub> = 1. In the third and last stage, <italic>w</italic><sub><italic>nb</italic></sub> = 1, <italic>w</italic><sub><italic>mn</italic></sub> = 0, and <italic>w</italic><sub><italic>fp</italic></sub> = 1.</p>
<p>The uniqueness and novelty of PaCMAP lies in the fact that local and global structure are balanced throughout the optimization process by the choice of sampling neighbors, mid-near pairs and further pairs simultaneously. When employed in TopOMetry, PaCMAP uses a denoised topological orthogonal basis instead of the raw data; similarly to TriMAP, feeding it the downstream topological graph may be counterproductive due to its peculiar neighborhood sampling process.</p>
</sec>
<sec id="s4n">
<title>Estimation of intrinsic dimensionalities</title>
<p>Intrinsic dimensionalities were estimated using the Maximum-Likelihood Estimator (MLE)<sup><xref ref-type="bibr" rid="c47">47</xref></sup> and the modified FSA<sup><xref ref-type="bibr" rid="c39">39</xref></sup> algorithms. A summary of these methods follow:</p>
</sec>
<sec id="s4o">
<title>Maximum Likelihood Estimator (MLE)</title>
<p>Consider <italic>X</italic> i.i.d. observations representing an embedding of a lower-dimensional sample <italic>X</italic><sub><italic>i</italic></sub> = <italic>g</italic>(<italic>Y</italic><sub><italic>i</italic></sub>), where <italic>Y</italic><sub><italic>i</italic></sub> are sampled from an equally lower-dimensional and unknown density function <italic>f, g</italic> being a continuous and smooth mapping. Given a point <italic>x</italic>, it is assumed that <italic>f</italic>(<italic>x</italic>)is constant in a small sphere <italic>S</italic><sub><italic>x</italic></sub> (<italic>R</italic>) of radius <italic>R</italic> centered on <italic>x</italic>, and the observations are treated as a homogeneous Poisson process in <italic>S</italic> <sub><italic>x</italic></sub> (<italic>R</italic>). Substituting a number of <italic>k</italic>-nearest-neighbors instead of a radius <italic>R</italic>, one can find that the estimate for the intrinsic lower-dimensionality <italic>m</italic><sub><italic>k</italic></sub> (<italic>x</italic>) around <italic>x</italic> is:
<disp-formula id="ueqn26">
<graphic xlink:href="484134v3_ueqn26.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
in which <italic>T</italic><sub><italic>k</italic></sub>(<italic>x</italic>) represents the distance between <italic>x</italic> and its k-nearest-neighbor. The global estimate is obtained by averaging all local i.d. Estimates.</p>
</sec>
<sec id="s4p">
<title>Manifold adaptive dimensionality estimation (FSA)</title>
<p>The FSA (Farahmand, Szepesvári &amp; Audibert) method<sup><xref ref-type="bibr" rid="c39">39</xref>,<xref ref-type="bibr" rid="c86">86</xref></sup> is extremely simple: it uses two neighborhoods around a data point to estimate its local intrinsic dimensionality δ(<italic>x</italic>). In particular, it uses the ratio between the distance <italic>R</italic> from <italic>x</italic> to its <italic>k</italic> and <italic>k/2</italic> nearest neighbors:
<disp-formula id="ueqn27">
<graphic xlink:href="484134v3_ueqn27.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>Note that the ratio <inline-formula><inline-graphic xlink:href="484134v3_inline22.gif" mime-subtype="gif" mimetype="image"/></inline-formula> corresponds to the scaling factor σ used in the bandwidth-adaptive kernel estimator employed in TopOMetry. The median of local estimates<sup><xref ref-type="bibr" rid="c39">39</xref></sup> is then used to represent the global intrinsic dimensionality of the dataset.</p>
</sec>
<sec id="s4q">
<title>Estimating and representing distortions with the Riemannian metric</title>
<p>We draw from the seminal work of Perrault-Joncas and Meila<sup><xref ref-type="bibr" rid="c36">36</xref></sup>, which first used the Riemannian metric to visualize distortions in the data and learn locally isometric embeddings by correcting projections, using fixed bandwidth kernels. In that regard, our contribution is restricted to extending their work using <italic>kNN</italic> graphs and variable bandwidth kernels and to applying these principles to single-cell data.</p>
<p>The Riemannian metric <italic>g</italic> is a symmetric positive definite tensor field that defines an inner product &lt;, &gt;<sub><italic>g</italic></sub> on the tangent space <italic>T</italic><sub><italic>p</italic></sub> <italic>M</italic> for every <italic>p</italic> ∈ <italic>M, M</italic> being a Riemannian manifold. The Laplace-Beltrami operator (LBO) △<italic>f</italic> = ∇ · ∇<italic>f</italic> can be expressed by means of g:
<disp-formula id="ueqn28">
<graphic xlink:href="484134v3_ueqn28.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>Because △<italic>f</italic> is approximated by the random-walk graph Laplacian <italic>L</italic><sub><italic>rw</italic></sub> and the anisotropic diffusion operator <italic>P</italic> <sub>α</sub>, one can then use it to estimate the inverse of the Riemannian metric <italic>g</italic>(<italic>p</italic>)<sup>−1</sup> using an arbitrary coordinate chart or embedding:</p>
<p><inline-formula><inline-graphic xlink:href="484134v3_inline23.gif" mime-subtype="gif" mimetype="image"/></inline-formula> with <italic>i, j</italic> = 1,…, <italic>d</italic>. Computing the inverse of <italic>g</italic> is then straightforward.</p>
<p>The method can then be extended to work with any embedding <italic>f</italic> of the manifold <italic>M</italic>. Consider <italic>d</italic> the manifold intrinsic dimension and <italic>s</italic> the dimension of the embedding space. For for any embedded point <italic>f</italic><sub><italic>p</italic></sub>, there will be a corresponding <italic>s</italic> × <italic>s</italic> matrix <italic>h</italic><sub><italic>p</italic></sub> with rank <italic>d</italic> defining a scalar product and with null space orthogonal to the tangent space <inline-formula><inline-graphic xlink:href="484134v3_inline24.gif" mime-subtype="gif" mimetype="image"/></inline-formula> can be defined so that (<italic>f</italic>(<italic>M</italic>), <italic>h</italic>) is isometric with (<italic>M, g</italic>), corresponding to the embedding Riemannian metric.</p>
<p>The embedding metric <italic>h</italic><sub><italic>p</italic></sub> is given by the pseudoinverse of its dual, <inline-formula><inline-graphic xlink:href="484134v3_inline25.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, where:
<disp-formula id="ueqn29">
<graphic xlink:href="484134v3_ueqn29.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>In practice, using the graph Laplacian <italic>L</italic> to approximate △, we have:
<disp-formula id="ueqn30">
<graphic xlink:href="484134v3_ueqn30.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p><inline-formula><inline-graphic xlink:href="484134v3_inline26.gif" mime-subtype="gif" mimetype="image"/></inline-formula> can then be eigendecomposed, with eigenvalues ordered from largest to smallest, and the embedding metric <italic>h</italic> is given by the pseudoinverse of <inline-formula><inline-graphic xlink:href="484134v3_inline27.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. For each point, the ellipsoid representation can then be obtained using its eigendecomposition. When using two dimensions, the ellipse orientation is given by the arctangent of the ratio between the eigenvectors, and the size of the major and minor axes are given by <inline-formula><inline-graphic xlink:href="484134v3_inline28.gif" mime-subtype="gif" mimetype="image"/></inline-formula> for the largest and smallest λ eigenvalues, respectively, κ being a scaling factor.</p>
</sec>
<sec id="s4r">
<title>Quantitative evaluations</title>
<sec id="s4r1">
<title>Global score</title>
<p>To evaluate preservation of global structure by embeddings and layouts, we elected the PCA resemblance score. It was first introduced in the TriMAP manuscript<sup><xref ref-type="bibr" rid="c41">41</xref></sup> and roughly captures how much a given embedding <bold><italic>Y</italic></bold> performs compared to PCA when it comes to preserving the global structure of the original data <bold><italic>X</italic></bold>. By design, PCA has the lowest possible <italic>Minimum Reconstruction Error</italic> (MRE), defined as:
<disp-formula id="ueqn31">
<graphic xlink:href="484134v3_ueqn31.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>Where || · ||<sub><italic>F</italic></sub> denotes the Frobenius norm. A global score (GS) is then defined by normalizing a given MRE by PCA’s MRE (which by construction is 1):
<disp-formula id="ueqn32">
<graphic xlink:href="484134v3_ueqn32.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>Interestingly, as exposed in the results, the global score remains rather stable and close to 1.0 across all embedding and layout algorithms that were tested, given a PCA or spectral initialization. We empirically show that this score is approximately the same using either PCA or a spectral layout (LE) and implement functions to perform such tests within TopOMetry.</p>
</sec>
</sec>
<sec id="s4s">
<title>Trustworthiness</title>
<p>For evaluating the preservation of local structure from an isomorphic perspective, we harnessed the well-known <italic>trustworthiness</italic><sup><xref ref-type="bibr" rid="c40">40</xref></sup> metric available on the <italic>scikit-learn</italic> machine-learning toolkit. Given a small number of k-nearest-neighbors, this metric is defined as:
<disp-formula id="ueqn33">
<graphic xlink:href="484134v3_ueqn33.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>In which for each sample <italic>i</italic>, <inline-formula><inline-graphic xlink:href="484134v3_inline29.gif" mime-subtype="gif" mimetype="image"/></inline-formula> are its k-nearest-neighbors in the low-dimensional space, and <italic>j</italic> is its <italic>r</italic>(<italic>i, j</italic>)-th nearest-neighbor in the original high-dimensional space. Essentially, this penalizes samples (cells) that are nearest neighbors in the low-dimensional space, but not in the original space, in proportion to their original rank. A score of 0 implies complete loss of local geometry, and a score of 1 implies complete preservation of local geometry, at the rank of <italic>k</italic>.</p>
</sec>
<sec id="s4t">
<title>Geodesic correlation</title>
<p>For evaluating the preservation of local structure from an isometric perspective, we built upon previous approaches that explored geodesic distances and the Spearman correlation between original high-dimensional and downstream low-dimensional distances<sup><xref ref-type="bibr" rid="c43">43</xref>,<xref ref-type="bibr" rid="c87">87</xref></sup>. This task is computationally very intensive, and thus was not performed by default in the benchmark. kNN graphs are built from both the original high-dimensional data matrix and the representations to be scored. Next, the geodesic distances (i.e. the weighted shortest-path pairwise distances) are obtained for each of these graphs, and their distributions are then scored according to the Spearman correlation (R). Cells can then be ranked accordingly to their neighborhood indices - let <italic>n</italic> be the number of cells and <italic>d</italic><sub><italic>i</italic></sub> be the difference between ranks for cell <italic>i</italic> in the original high-dimensional space and in the latent low-dimensional space. Then, we can calculate the Spearman correlation as:
<disp-formula id="ueqn34">
<graphic xlink:href="484134v3_ueqn34.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>The Spearman rank-order correlation coefficient (R) is a nonparametric measure of association between two sets of data, and superior to the Pearson correlation in this case because it assumes only monotonicity, not linearity. Intuitively, this score tells whether increasing distances in the low-dimensional embedding is related to increasing distances in the high-dimensional data: a score of 0 implies no association at all, and a score of 1.0 implies perfect association.</p>
<sec id="s4t1">
<title>Benchmark</title>
<p>For the benchmark presented in <xref rid="fig2" ref-type="fig">Figure 2</xref> and <xref rid="figS3" ref-type="fig">Supplementary Figure 3</xref>, we used the global score and the trustworthiness score. 200 principal components or eigencomponents were used for each non-biological dataset, and 600 principal components or eigencomponents were used for each single-cell dataset. For all datasets, the cosine metric distance was used with a value of 30 nearest-neighbors. All other hyperparameters used in t-SNE, UMAP, PaCMAP and TopOMetry were set to defaults. We restricted the tested GLO techniques to t-SNE, UMAP and PaCMAP due to practical limitations in calculating results for additional methods (e.g., including TriMAP and MDE or the plethora of available options would lead to an unreasonable increase in runtime).</p>
</sec>
<sec id="s4t2">
<title>RNA velocity analysis and lineage inference</title>
<p>For RNA velocity analysis of the murine pancreas development dataset<sup><xref ref-type="bibr" rid="c48">48</xref></sup>, we used the python toolkit <italic>scvelo</italic><sup><xref ref-type="bibr" rid="c26">26</xref></sup>. Analysis was performed with standard parameters to reproduce <italic>scvelo</italic> documentation. TopOMetry analysis was performed using the msDM eigenbasis (obtained with the bandwidth_adaptive kernel) and the MAP projection method was used on the learned diffusion potential from this eigenbasis with standard parameters. RNA velocity was then recomputed using the msDM representation to compute neighborhood graphs using the <italic>scvelo</italic>.<italic>pp</italic>.<italic>moments</italic> function, with all other hyperparameters being identical to the standard analysis.</p>
<p>For the MOCA dataset, TopOMetry msDM eigenbasis was used to decompose the data into 800 eigenvectors (796 positive). Clustering with the Leiden community detection algorithm and projection with MAP were then carried out using the diffusion potential learned from this eigenbasis, using default parameters.</p>
</sec>
<sec id="s4t3">
<title>Analysis of T cell diversity and clonality</title>
<p>The datasets used to explore T cell diversity were cell-type annotated using CellTypist, using the graph connectivities learned from the scaled HVG data matrix for overclustering and majority voting<sup><xref ref-type="bibr" rid="c51">51</xref></sup>. The <italic>Immune_All_High</italic> model was used to annotate main cell types, and the <italic>Immune_All_Low</italic> to annotate subtypes. For quantifying the amount of detected T cell clusters, a threshold of 0.8 prediction probability was used.</p>
<p>All datasets were analyzed following the standard workflow within <italic>scanpy</italic>, using 50 or 300 principal components and with the Leiden clustering algorithm set to <italic>resolution=2</italic>. All other hyperparameters were set to defaults. Marker genes were found using logistic regression<sup><xref ref-type="bibr" rid="c66">66</xref></sup> with <italic>max_iters=1000</italic> and all other hyperparameters set to defaults. TopOMetry analysis was performed using the msDM eigenbasis with the bandwidth-adaptive kernel to calculate a total of 500 eigencomponents for all datasets, from which the diffusion potential was used to compute MAP projections. All other TopOMetry hyperparameters were set to defaults.</p>
<p>For the analysis of the TICA dataset<sup><xref ref-type="bibr" rid="c51">51</xref></sup>, an <italic>AnnData</italic> object containing scRNA-seq and VDJ information for the T cell compartment was obtained from <ext-link ext-link-type="uri" xlink:href="https://www.tissueimmunecellatlas.org/">https://www.tissueimmunecellatlas.org/</ext-link> (<italic>GEX+TCRab data</italic>). We then reanalyzed this data with <italic>scirpy</italic><sup><xref ref-type="bibr" rid="c60">60</xref></sup> following the steps exactly as detailed in its documentation without any change to parameters other than to use TopOMetry latent representations and clustering results. TopOMetry analysis was performed with the same parameters used for all other PBMC datasets.</p>
</sec>
<sec id="s4t4">
<title>Computational Environment</title>
<p>The benchmark presented on <xref rid="fig2" ref-type="fig">Figure 2</xref> and <xref rid="figS3" ref-type="fig">Supplementary Figure 3</xref> was computed on a virtual machine with Intel(R) Xeon(R) Gold 6252 CPU @ 2.10GHz x 128 threads, with a total of 320GB of ERCC DDR4 SDRAM with the 64-bit Ubuntu 18.04.6 LTS distribution of the Linux operating system, provided by the Institute of Biology from the University of Campinas. All other analyses were performed on a six-core Lenovo ThinkPad P52 Intel® Xeon(R) E-2176M CPU @ 2.70GHz</p>
<p>× 12 threads, with a total of 128GB of ERCC DDR4 SDRAM with 64-bit 21.10 Pop!OS distribution of the Linux operating system. Package versions are listed in Methods <xref rid="tbl1" ref-type="table">Table 1</xref>.</p>
</sec>
</sec>
</sec>
<sec id="d1e3305" sec-type="supplementary-material">
<title>Supporting information</title>
<supplementary-material id="d1e3387">
<label>Supplementary Material</label>
<media xlink:href="supplements/484134_file03.pdf"/>
</supplementary-material>
</sec>
</body>
<back>
<sec id="s5">
<title>Funding</title>
<p>DS-O was supported by the grant #2020/04074-2, São Paulo Research Foundation (FAPESP), and LAV was supported by the grant #2013/07607-8, São Paulo Research Foundation (FAPESP).</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>We thank Gustavo B. Bellini, Valcir V. Vargas and Marcos Akira at the Institute of Biology from the University of Campinas for their most kind support with computational infrastructure. We thank Leland McInness, Dmitry Kobak and Akshay Agrawal for their valuable comments regarding some of the ideas presented in the manuscript. We thank Bruno Loyola Barbosa for his kind assistance in testing the early implementations of TopOMetry. We thank Ebru Erbay and Helder Nakaya for their generous feedback during the development of TopOMetry.</p>
</ack>
<sec id="s6">
<title>Author Contributions</title>
<p>DS-O, LAV and AD jointly conceived the idea of harnessing phenotypic topology to visually represent biological hallmarks from single-cell data. DS-O designed and built TopOMetry and conceived and performed all bioinformatic analyses. All authors wrote the manuscript and agreed to the final submitted version.</p>
</sec>
<sec id="s7">
<title>Competing interests</title>
<p>The authors have no competing interests.</p>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shapiro</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Biezuner</surname>, <given-names>T.</given-names></string-name> &amp; <string-name><surname>Linnarsson</surname>, <given-names>S.</given-names></string-name></person-group> <article-title>Single-cell sequencing-based technologies will revolutionize whole-organism science</article-title>. <source>Nat. Rev. Genet</source>. <volume>14</volume>, <fpage>618</fpage>–<lpage>630</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Potter</surname>, <given-names>S. S.</given-names></string-name></person-group> <article-title>Single-cell RNA sequencing for the study of development, physiology and disease</article-title>. <source>Nat. Rev. Nephrol</source>. <volume>14</volume>, <fpage>479</fpage>–<lpage>492</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ma</surname>, <given-names>Y.</given-names></string-name> &amp; <string-name><surname>Zhu</surname>, <given-names>L.</given-names></string-name></person-group> <article-title>A review on dimension reduction</article-title>. <source>Int. Stat. Rev</source>. <volume>81</volume>, <fpage>134</fpage>–<lpage>150</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Anowar</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Sadaoui</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Selim</surname>, <given-names>B.</given-names></string-name></person-group> <article-title>Conceptual and empirical comparison of dimensionality reduction algorithms (PCA, KPCA, LDA, MDS, SVD, LLE, ISOMAP, LE, ICA, t-SNE)</article-title>. <source>Comput. Sci. Rev</source>. <volume>40</volume>, <fpage>100378</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xiang</surname>, <given-names>R.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>A Comparison for Dimensionality Reduction Methods of Single-Cell RNA-seq Data</article-title>. <source>Front. Genet</source>. <volume>12</volume>, (<year>2021</year>).</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>F.R.S K. P.</given-names> <surname>Liii</surname></string-name></person-group>. <article-title>On lines and planes of closest fit to systems of points in space</article-title>. <source>Lond. Edinb. Dublin Philos. Mag. J. Sci</source>. <volume>2</volume>, <fpage>559</fpage>–<lpage>572</lpage> (<year>1901</year>).</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Jolliffe</surname>, <given-names>I. T.</given-names></string-name></person-group> <chapter-title>Principal Component Analysis and Factor Analysis</chapter-title>. <source>in Principal Component Analysis</source> (ed. <person-group person-group-type="editor"><string-name><surname>Jolliffe</surname>, <given-names>I. T.</given-names></string-name></person-group>) <fpage>115</fpage>–<lpage>128</lpage> (<publisher-name>Springer</publisher-name>, <year>1986</year>). doi:<pub-id pub-id-type="doi">10.1007/978-1-4757-1904-8_7</pub-id>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Belkin</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Niyogi</surname>, <given-names>P.</given-names></string-name></person-group> <article-title>Laplacian Eigenmaps for Dimensionality Reduction and Data Representation</article-title>. <source>Neural Comput</source>. <volume>15</volume>, <fpage>1373</fpage>–<lpage>1396</lpage> (<year>2003</year>).</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Coifman</surname>, <given-names>R. R.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Geometric diffusions as a tool for harmonic analysis and structure definition of data: Diffusion maps</article-title>. <source>Proc. Natl. Acad. Sci</source>. <volume>102</volume>, <fpage>7426</fpage>–<lpage>7431</lpage> (<year>2005</year>).</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Coifman</surname>, <given-names>R. R.</given-names></string-name> &amp; <string-name><surname>Lafon</surname>, <given-names>S.</given-names></string-name></person-group> <article-title>Diffusion maps</article-title>. <source>Appl. Comput. Harmon. Anal</source>. <volume>21</volume>, <fpage>5</fpage>–<lpage>30</lpage> (<year>2006</year>).</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Reuter</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Wolter</surname>, <given-names>F.-E.</given-names></string-name>, <string-name><surname>Shenton</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Niethammer</surname>, <given-names>M.</given-names></string-name></person-group> <article-title>Laplace–Beltrami eigenvalues and topological features of eigenfunctions for statistical shape analysis</article-title>. <source>Comput.-Aided Des</source>. <volume>41</volume>, <fpage>739</fpage>–<lpage>755</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Brand</surname>, <given-names>M.</given-names></string-name></person-group> <chapter-title>Continuous nonlinear dimensionality reduction by kernel eigenmaps</chapter-title>. <source>in Proceedings of the 18th international joint conference on Artificial intelligence</source> <fpage>547</fpage>–<lpage>552</lpage> (<publisher-name>Morgan Kaufmann Publishers Inc</publisher-name>., <year>2003</year>).</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Berry</surname>, <given-names>T.</given-names></string-name> &amp; <string-name><surname>Sauer</surname>, <given-names>T.</given-names></string-name></person-group> <article-title>Consistent manifold representation for topological data analysis</article-title>. <source>Found. Data Sci</source>. <volume>1</volume>, <fpage>1</fpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Maaten</surname>, <given-names>L. van der</given-names></string-name> &amp; <string-name><surname>Hinton</surname>, <given-names>G.</given-names></string-name></person-group> <article-title>Visualizing Data using t-SNE</article-title>. <source>J. Mach. Learn. Res</source>. <volume>9</volume>, <fpage>2579</fpage>–<lpage>2605</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>McInnes</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Healy</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Melville</surname>, <given-names>J.</given-names></string-name></person-group> <article-title>UMAP: Uniform manifold approximation and projection for dimension reduction</article-title>. <source>arXiv</source> (<year>2018</year>).</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Becht</surname>, <given-names>E.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Dimensionality reduction for visualizing single-cell data using UMAP</article-title>. <source>Nat. Biotechnol</source>. <volume>37</volume>, <fpage>38</fpage>–<lpage>44</lpage> (<year>2019</year>).</mixed-citation></ref>
    <ref id="c17"><label>17.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Wang</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Huang</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Rudin</surname>, <given-names>C.</given-names></string-name> &amp; <string-name><surname>Shaposhnik</surname>, <given-names>Y.</given-names></string-name></person-group> <article-title>Understanding How Dimension Reduction Tools Work: An Empirical Approach to Deciphering t-SNE, UMAP, TriMAP, and PaCMAP for Data Visualization</article-title>. <source>arXiv</source> (<year>2021</year>) <pub-id pub-id-type="doi">10.48550/arXiv.2012.04456</pub-id>.</mixed-citation></ref>
    <ref id="c18"><label>18.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Agrawal</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Ali</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Boyd</surname>, <given-names>S.</given-names></string-name></person-group> <article-title>Minimum-Distortion Embedding</article-title>. <source>arXiv</source> (<year>2021</year>) <pub-id pub-id-type="doi">10.48550/arXiv.2103.02559</pub-id>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lopez</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Regier</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Cole</surname>, <given-names>M. B.</given-names></string-name>, <string-name><surname>Jordan</surname>, <given-names>M. I.</given-names></string-name> &amp; <string-name><surname>Yosef</surname>, <given-names>N.</given-names></string-name></person-group> <article-title>Deep generative modeling for single-cell transcriptomics</article-title>. <source>Nat. Methods</source> <volume>15</volume>, <fpage>1053</fpage>–<lpage>1058</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname>, <given-names>S.</given-names></string-name></person-group> <article-title>The molecular and mathematical basis of Waddington’s epigenetic landscape: A framework for post-Darwinian biology?</article-title> <source>BioEssays</source> <volume>34</volume>, <fpage>149</fpage>–<lpage>157</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Trapnell</surname>, <given-names>C.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>The dynamics and regulators of cell fate decisions are revealed by pseudotemporal ordering of single cells</article-title>. <source>Nat. Biotechnol</source>. <volume>32</volume>, <fpage>381</fpage>–<lpage>386</lpage> (<year>2014</year>).</mixed-citation></ref>
    <ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Saelens</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Cannoodt</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Todorov</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Saeys</surname>, <given-names>Y.</given-names></string-name></person-group> <article-title>A comparison of single-cell trajectory inference methods |</article-title><source>Nature Biotechnology</source>. <volume>37</volume>, <fpage>547</fpage>–<lpage>554</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wagner</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Regev</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Yosef</surname>, <given-names>N.</given-names></string-name></person-group> <article-title>Revealing the vectors of cellular identity with single-cell genomics</article-title>. <source>Nat. Biotechnol</source>. <volume>34</volume>, <fpage>1145</fpage>–<lpage>1160</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Luecken</surname>, <given-names>M. D.</given-names></string-name> &amp; <string-name><surname>Theis</surname>, <given-names>F. J.</given-names></string-name></person-group> <article-title>Current best practices in single-cell RNA-seq analysis: a tutorial</article-title>. <source>Mol. Syst. Biol</source>. <volume>15</volume>, <fpage>e8746</fpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>La Manno</surname>, <given-names>G.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>RNA velocity of single cells</article-title>. <source>Nature</source> <volume>560</volume>, <fpage>494</fpage>–<lpage>498</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bergen</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Lange</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Peidli</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Wolf</surname>, <given-names>F. A.</given-names></string-name> &amp; <string-name><surname>Theis</surname>, <given-names>F. J.</given-names></string-name></person-group> <article-title>Generalizing RNA velocity to transient cell states through dynamical modeling</article-title>. <source>Nat. Biotechnol</source>. <volume>38</volume>, <fpage>1408</fpage>–<lpage>1414</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stuart</surname>, <given-names>T.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Comprehensive Integration of Single-Cell Data</article-title>. <source>Cell</source> <volume>177</volume>, <fpage>1888</fpage>-<lpage>1902.e21</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Polański</surname>, <given-names>K.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>BBKNN: fast batch alignment of single cell transcriptomes</article-title>. <source>Bioinformatics</source> <elocation-id>btz625</elocation-id> (<year>2019</year>) doi:<pub-id pub-id-type="doi">10.1093/bioinformatics/btz625</pub-id>.</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Saelens</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Cannoodt</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Todorov</surname>, <given-names>H.</given-names></string-name> &amp; <string-name><surname>Saeys</surname>, <given-names>Y.</given-names></string-name></person-group> <article-title>A comparison of single-cell trajectory inference methods</article-title>. <source>Nat. Biotechnol</source>. <volume>37</volume>, <fpage>547</fpage>–<lpage>554</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Haghverdi</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Büttner</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Wolf</surname>, <given-names>F. A.</given-names></string-name>, <string-name><surname>Buettner</surname>, <given-names>F.</given-names></string-name> &amp; <string-name><surname>Theis</surname>, <given-names>F. J.</given-names></string-name></person-group> <article-title>Diffusion pseudotime robustly reconstructs lineage branching</article-title>. <source>Nat. Methods</source> <volume>13</volume>, <fpage>845</fpage>–<lpage>848</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gayoso</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>A Python library for probabilistic analysis of single-cell omics data</article-title>. <source>Nat. Biotechnol</source>. <volume>40</volume>, <fpage>163</fpage>–<lpage>166</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sun</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Zhu</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Ma</surname>, <given-names>Y.</given-names></string-name> &amp; <string-name><surname>Zhou</surname>, <given-names>X.</given-names></string-name></person-group> <article-title>Accuracy, robustness and scalability of dimensionality reduction methods for single-cell RNA-seq analysis</article-title>. <source>Genome Biol</source>. <volume>20</volume>, <fpage>269</fpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Heiser</surname>, <given-names>C. N.</given-names></string-name> &amp; <string-name><surname>Lau</surname>, <given-names>K. S.</given-names></string-name></person-group> <article-title>A Quantitative Framework for Evaluating Single-Cell Data Structure Preservation by Dimensionality Reduction Techniques</article-title>. <source>Cell Rep</source>. <volume>31</volume>, <fpage>107576</fpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hadi</surname>, <given-names>A. S.</given-names></string-name> &amp; <string-name><surname>Ling</surname>, <given-names>R. F.</given-names></string-name></person-group> <article-title>Some Cautionary Notes on the Use of Principal Components Regression</article-title>. <source>Am. Stat</source>. <volume>52</volume>, <fpage>15</fpage>–<lpage>19</lpage> (<year>1998</year>).</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jolliffe</surname>, <given-names>I. T.</given-names></string-name> &amp; <string-name><surname>Cadima</surname>, <given-names>J.</given-names></string-name></person-group> <article-title>Principal component analysis: a review and recent developments</article-title>. <source>Philos. Trans. R. Soc. Math. Phys. Eng. Sci</source>. <volume>374</volume>, <fpage>20150202</fpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Perraul-Joncas</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>Meila</surname>, <given-names>M.</given-names></string-name></person-group> <source>Non-linear dimensionality reduction: Riemannian metric estimation and the problem of geometric discovery</source>. Preprint at <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1305.7255">http://arxiv.org/abs/1305.7255</ext-link> (<year>2013</year>).</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name>, <string-name><surname>Silva</surname>, <given-names>V. de</given-names></string-name> &amp; <string-name><surname>Langford</surname>, <given-names>J. C.</given-names></string-name></person-group> <article-title>A Global Geometric Framework for Nonlinear Dimensionality Reduction</article-title>. <source>Science</source> <volume>290</volume>, <fpage>2319</fpage>–<lpage>2323</lpage> (<year>2000</year>).</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Lee</surname>, <given-names>J. M.</given-names></string-name></person-group> <source>Riemannian manifolds: an introduction to curvature</source>. (<publisher-name>Springer</publisher-name>, <year>1997</year>).</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Benkő</surname>, <given-names>Z.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Manifold-adaptive dimension estimation revisited</article-title>. <source>PeerJ Comput. Sci</source>. <volume>8</volume>, <fpage>e790</fpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Venna</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Kaski</surname>, <given-names>S.</given-names></string-name></person-group> <chapter-title>Neighborhood Preservation in Nonlinear Projection Methods: An Experimental Study</chapter-title>. <source>in Artificial Neural Networks — ICANN 2001</source> (eds. <person-group person-group-type="editor"><string-name><surname>Dorffner</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Bischof</surname>, <given-names>H.</given-names></string-name> &amp; <string-name><surname>Hornik</surname>, <given-names>K.</given-names></string-name></person-group>) <fpage>485</fpage>–<lpage>491</lpage> (<publisher-name>Springer</publisher-name>, <year>2001</year>). doi:<pub-id pub-id-type="doi">10.1007/3-540-44668-0_68</pub-id>.</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Amid</surname>, <given-names>E.</given-names></string-name> &amp; <string-name><surname>Warmuth</surname>, <given-names>M. K.</given-names></string-name></person-group> <article-title>TriMap: large-scale dimensionality reduction using triplets</article-title>. <source>arXiv</source> (<year>2019</year>).</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kobak</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>Linderman</surname>, <given-names>G. C.</given-names></string-name></person-group> <article-title>Initialization is critical for preserving global data structure in both t-SNE and UMAP</article-title>. <source>Nat. Biotechnol</source>. <volume>39</volume>, <fpage>156</fpage>–<lpage>157</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Moon</surname>, <given-names>K. R.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Visualizing structure and transitions in high-dimensional biological data</article-title>. <source>Nat. Biotechnol</source>. <volume>37</volume>, <fpage>1482</fpage>–<lpage>1492</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Fukunaga</surname>, <given-names>K.</given-names></string-name></person-group> <source>Introduction to Statistical Pattern Recognition</source>. (<publisher-name>Academic Press</publisher-name>, <year>1990</year>).</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Camastra</surname>, <given-names>F.</given-names></string-name> &amp; <string-name><surname>Staiano</surname>, <given-names>A.</given-names></string-name></person-group> <article-title>Intrinsic dimension estimation: Advances and open problems</article-title>. <source>Inf. Sci</source>. <volume>328</volume>, <fpage>26</fpage>–<lpage>41</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Campadelli</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Casiraghi</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Ceruti</surname>, <given-names>C.</given-names></string-name> &amp; <string-name><surname>Rozza</surname>, <given-names>A.</given-names></string-name></person-group> <article-title>Intrinsic Dimension Estimation: Relevant Techniques and a Benchmark Framework</article-title>. <source>Math. Probl. Eng</source>. <volume>2015</volume>, <fpage>e759567</fpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Levina</surname>, <given-names>E.</given-names></string-name> &amp; <string-name><surname>Bickel</surname>, <given-names>P.</given-names></string-name></person-group> <chapter-title>Maximum Likelihood Estimation of Intrinsic Dimension</chapter-title>. <source>in Advances in Neural Information Processing Systems</source> (eds. <person-group person-group-type="editor"><string-name><surname>Saul</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Weiss</surname>, <given-names>Y.</given-names></string-name> &amp; <string-name><surname>Bottou</surname>, <given-names>L.</given-names></string-name></person-group>) vol. <volume>17</volume> (<publisher-name>MIT Press</publisher-name>, <year>2004</year>).</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bastidas-Ponce</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Comprehensive single cell mRNA profiling reveals a detailed roadmap for pancreatic endocrinogenesis</article-title>. <source>Development</source> <volume>146</volume>, <fpage>dev173849</fpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Arnes</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Hill</surname>, <given-names>J. T.</given-names></string-name>, <string-name><surname>Gross</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Magnuson</surname>, <given-names>M. A.</given-names></string-name> &amp; <string-name><surname>Sussel</surname>, <given-names>L.</given-names></string-name></person-group> <article-title>Ghrelin Expression in the Mouse Pancreas Defines a Unique Multipotent Progenitor Population</article-title>. <source>PLOS ONE</source> <volume>7</volume>, <fpage>e52026</fpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cao</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>The single-cell transcriptional landscape of mammalian organogenesis</article-title>. <source>Nature</source> <volume>566</volume>, <fpage>496</fpage>–<lpage>502</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Domínguez Conde</surname>, <given-names>C.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Cross-tissue immune cell analysis reveals tissue-specific features in humans</article-title>. <source>Science</source> <volume>376</volume>, <fpage>eabl5197</fpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wolf</surname>, <given-names>F. A.</given-names></string-name>, <string-name><surname>Angerer</surname>, <given-names>P.</given-names></string-name> &amp; <string-name><surname>Theis</surname>, <given-names>F. J.</given-names></string-name></person-group> <article-title>SCANPY: Large-scale single-cell gene expression data analysis</article-title>. <source>Genome Biol</source>. <volume>19</volume>, <fpage>15</fpage>–<lpage>15</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ding</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Characterisation of CD4+ T-cell subtypes using single cell RNA sequencing and the impact of cell number and sequencing depth</article-title>. <source>Sci. Rep</source>. <volume>10</volume>, <fpage>19825</fpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Greene</surname>, <given-names>E.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>New interpretable machine-learning method for single-cell data reveals correlates of clinical response to cancer immunotherapy</article-title>. <source>Patterns</source> <volume>2</volume>, (<year>2021</year>).</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Waickman</surname>, <given-names>A. T.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Temporally integrated single cell RNA sequencing analysis of PBMC from experimental and natural primary human DENV-1 infections</article-title>. <source>PLOS Pathog</source>. <volume>17</volume>, <fpage>e1009240</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nehar-Belaid</surname>, <given-names>D.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Mapping systemic lupus erythematosus heterogeneity at the single-cell level</article-title>. <source>Nat. Immunol</source>. <volume>21</volume>, <fpage>1094</fpage>–<lpage>1106</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wauters</surname>, <given-names>E.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Discriminating mild from critical COVID-19 by innate and adaptive immune single-cell profiling of bronchoalveolar lavages</article-title>. <source>Cell Res</source>. <volume>31</volume>, <fpage>272</fpage>–<lpage>290</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname>, <given-names>Z.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Effects of sex and aging on the immune cell landscape as assessed by single-cell transcriptomic analysis</article-title>. <source>Proc. Natl. Acad. Sci</source>. <volume>118</volume>, (<year>2021</year>).</mixed-citation></ref>
    <ref id="c59"><label>59.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vinh</surname>, <given-names>N. X.</given-names></string-name>, <string-name><surname>Epps</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Bailey</surname>, <given-names>J.</given-names></string-name></person-group> <article-title>Information Theoretic Measures for Clusterings Comparison: Variants, Properties, Normalization and Correction for Chance</article-title>, <source>The Journal of Machine Learning Research</source>. <volume>11</volume>, <fpage>2837</fpage>–<lpage>2854</lpage> (<year>2010</year>)</mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sturm</surname>, <given-names>G.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Scirpy: a Scanpy extension for analyzing single-cell T-cell receptor-sequencing data</article-title>. <source>Bioinformatics</source> <volume>36</volume>, <fpage>4817</fpage>–<lpage>4818</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bagaev</surname>, <given-names>D. V.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>VDJdb in 2019: database extension, new analysis infrastructure and a T-cell receptor motif compendium</article-title>. <source>Nucleic Acids Res</source>. <volume>48</volume>, <fpage>D1057</fpage>–<lpage>D1062</lpage> (<year>2020</year>).</mixed-citation></ref>
    <ref id="c62"><label>62.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>von Rohrscheidt</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Rieck</surname>, <given-names>B.</given-names></string-name></person-group> <article-title>Topological Singularity Detection at Multiple Scales</article-title>. <source>arXiv</source> <pub-id pub-id-type="doi">10.48550/arXiv.2210.00069</pub-id> (<year>2023</year>).</mixed-citation></ref>
<ref id="c63"><label>63.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Chari</surname>, <given-names>T.</given-names></string-name> &amp; <string-name><surname>Pachter</surname>, <given-names>L.</given-names></string-name></person-group> <article-title>The Specious Art of Single-Cell Genomics</article-title>. <source>bioRxiv</source> <pub-id pub-id-type="doi">10.1101/2021.08.25.457696</pub-id> (<year>2022</year>).</mixed-citation></ref>
<ref id="c64"><label>64.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. F.</given-names> <surname>Duque</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Morin</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Wolf</surname></string-name>, &amp; <string-name><given-names>K. R.</given-names> <surname>Moon</surname></string-name></person-group>. <article-title>Geometry Regularized Autoencoders</article-title>. <source>IEEE Trans. Pattern Anal. Mach. Intell</source>. <volume>45</volume>, <fpage>7381</fpage>–<lpage>7394</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c65"><label>65.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Luecken</surname>, <given-names>M. D.</given-names></string-name> &amp; <string-name><surname>Theis</surname>, <given-names>F. J.</given-names></string-name></person-group> <article-title>Current best practices in single-cell RNA-seq analysis: atutorial</article-title>. <source>Mol. Syst. Biol</source>. <volume>15</volume>, <fpage>e8746</fpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c66"><label>66.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ntranos</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Yi</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Melsted</surname>, <given-names>P.</given-names></string-name> &amp; <string-name><surname>Pachter</surname>, <given-names>L.</given-names></string-name></person-group> <article-title>A discriminative learning approach to differential expression analysis for single-cell RNA-seq</article-title>. <source>Nat. Methods</source> <volume>16</volume>, <fpage>163</fpage>–<lpage>166</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c67"><label>67.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Buitinck</surname>, <given-names>L.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>API design for machine learning software: experiences from the scikit-learn project</article-title>. <source>ECML PKDD Workshop: Languages for Data Mining and Machine Learning</source> <fpage>108</fpage>–<lpage>122</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c68"><label>68.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Berry</surname>, <given-names>T.</given-names></string-name> &amp; <string-name><surname>Harlim</surname>, <given-names>J.</given-names></string-name></person-group> <article-title>Variable bandwidth diffusion kernels</article-title>. <source>Appl. Comput. Harmon. Anal</source>. <volume>40</volume>, <fpage>68</fpage>–<lpage>96</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c69"><label>69.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Spivak</surname>, <given-names>D. I.</given-names></string-name></person-group> <source>METRIC REALIZATION OF FUZZY SIMPLICIAL SETS</source>. (<year>2012</year>).</mixed-citation></ref>
<ref id="c70"><label>70.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Haghverdi</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Büttner</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Wolf</surname>, <given-names>F. A.</given-names></string-name>, <string-name><surname>Buettner</surname>, <given-names>F.</given-names></string-name> &amp; <string-name><surname>Theis</surname>, <given-names>F. J.</given-names></string-name></person-group> <article-title>Diffusion pseudotime robustly reconstructs lineage branching</article-title>. <source>Nat. Methods</source> <volume>13</volume>, <fpage>845</fpage>–<lpage>848</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c71"><label>71.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Setty</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Characterization of cell fate probabilities in single-cell data with Palantir</article-title>. <source>Nat. Biotechnol</source>. <volume>37</volume>, <fpage>451</fpage>–<lpage>460</lpage> (<year>2019</year>).</mixed-citation></ref>
    <ref id="c72"><label>72.</label><mixed-citation publication-type="report"><person-group person-group-type="author"><string-name><surname>Yang</surname>, <given-names>L.</given-names></string-name> &amp; <string-name><surname>Jin</surname>, <given-names>R.</given-names></string-name></person-group> <source>Distance Metric Learning: A Comprehensive Survey</source>: <publisher-name>Department of Computer Science and Engineering, Michigan State University</publisher-name>. <year>2006</year></mixed-citation></ref>
<ref id="c73"><label>73.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Skinnider</surname>, <given-names>M. A.</given-names></string-name>, <string-name><surname>Squair</surname>, <given-names>J. W.</given-names></string-name> &amp; <string-name><surname>Foster</surname>, <given-names>L. J.</given-names></string-name></person-group> <article-title>Evaluating measures of association for single-cell transcriptomics</article-title>. <source>Nat. Methods</source> <volume>16</volume>, <fpage>381</fpage>–<lpage>386</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c74"><label>74.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kim</surname>, <given-names>T.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Impact of similarity metrics on single-cell RNA-seq data clustering</article-title>. <source>Brief. Bioinform</source>. <volume>20</volume>, <fpage>2316</fpage>–<lpage>2326</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c75"><label>75.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Aumüller</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Bernhardsson</surname>, <given-names>E.</given-names></string-name> &amp; <string-name><surname>Faithfull</surname>, <given-names>A.</given-names></string-name></person-group> <article-title>ANN-Benchmarks: A benchmarking tool for approximate nearest neighbor algorithms</article-title>. <source>Inf. Syst</source>. <volume>87</volume>, <fpage>101374</fpage> (<year>2020</year>).</mixed-citation></ref>
    <ref id="c76"><label>76.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Malkov</surname>, <given-names>Y. A.</given-names></string-name> &amp; <string-name><surname>Yashunin</surname>, <given-names>D. A.</given-names></string-name></person-group> <article-title>Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs</article-title>. <source>arXiv</source> (<year>2018</year>)  <pub-id pub-id-type="doi">10.48550/arXiv.1603.09320</pub-id>.</mixed-citation></ref>
<ref id="c77"><label>77.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Boytsov</surname>, <given-names>L.</given-names></string-name> &amp; <string-name><surname>Naidan</surname>, <given-names>B.</given-names></string-name></person-group> <chapter-title>Engineering Efficient and Effective Non-metric Space Library</chapter-title>. <source>in Similarity Search and Applications - 6th International Conference, SISAP 2013, A Coruña, Spain, October 2-4, 2013, Proceedings</source> (eds. <person-group person-group-type="editor"><string-name><surname>Brisaboa</surname>, <given-names>N. R.</given-names></string-name>, <string-name><surname>Pedreira</surname>, <given-names>O.</given-names></string-name> &amp; <string-name><surname>Zezula</surname>, <given-names>P.</given-names></string-name></person-group>) vol. <volume>8199</volume> <fpage>280</fpage>–<lpage>293</lpage> (<publisher-name>Springer</publisher-name>, <year>2013</year>).</mixed-citation></ref>
<ref id="c78"><label>78.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yip</surname>, <given-names>S. H.</given-names></string-name>, <string-name><surname>Sham</surname>, <given-names>P. C.</given-names></string-name> &amp; <string-name><surname>Wang</surname>, <given-names>J.</given-names></string-name></person-group> <article-title>Evaluation of tools for highly variable gene discovery from single-cell RNA-seq data</article-title>. <source>Brief. Bioinform</source>. <volume>20</volume>, <fpage>1583</fpage>–<lpage>1589</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c79"><label>79.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Berry</surname>, <given-names>T.</given-names></string-name> &amp; <string-name><surname>Sauer</surname>, <given-names>T.</given-names></string-name></person-group> <article-title>Local kernels and the geometric structure of data</article-title>. <source>Appl. Comput. Harmon. Anal</source>. <volume>40</volume>, <fpage>439</fpage>–<lpage>469</lpage> (<year>2016</year>).</mixed-citation></ref>
    <ref id="c80"><label>80.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Berry</surname>, <given-names>T.</given-names></string-name> &amp; <string-name><surname>Sauer</surname>, <given-names>T.</given-names></string-name></person-group> <article-title>Consistent Manifold Representation for Topological Data Analysis</article-title>. <source>arXiv</source> (<year>2019</year>) <pub-id pub-id-type="doi">10.48550/arXiv.1606.02353</pub-id>.</mixed-citation></ref>
<ref id="c81"><label>81.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nadler</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Lafon</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Coifman</surname>, <given-names>R. R.</given-names></string-name> &amp; <string-name><surname>Kevrekidis</surname>, <given-names>I. G.</given-names></string-name></person-group> <article-title>Diffusion maps, spectral clustering and reaction coordinates of dynamical systems</article-title>. <source>Appl. Comput. Harmon. Anal</source>. <volume>21</volume>, <fpage>113</fpage>–<lpage>127</lpage> (<year>2006</year>).</mixed-citation></ref>
    <ref id="c82"><label>82.</label><mixed-citation publication-type="software"><person-group person-group-type="author"><string-name><surname>Wang</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Huang</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Rudin</surname>, <given-names>C.</given-names></string-name> &amp; <string-name><surname>Shaposhnik</surname>, <given-names>Y.</given-names></string-name></person-group> <article-title>Understanding How Dimension Reduction Tools Work: An Empirical Approach to Deciphering t-SNE, UMAP, TriMAP, and PaCMAP for Data Visualization</article-title>. <source>GitHub</source> <ext-link ext-link-type="uri" xlink:href="https://github.com/YingfanWang/PaCMAP">https://github.com/YingfanWang/PaCMAP</ext-link>. <year>2014</year></mixed-citation></ref>
<ref id="c83"><label>83.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Cook</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Sutskever</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Mnih</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Hinton</surname>, <given-names>G.</given-names></string-name></person-group> <chapter-title>Visualizing Similarity Data with a Mixture of Maps</chapter-title>. <source>in Proceedings of the Eleventh International Conference on Artificial Intelligence and Statistics</source> <fpage>67</fpage>–<lpage>74</lpage> (<publisher-name>PMLR</publisher-name>, <year>2007</year>).</mixed-citation></ref>
<ref id="c84"><label>84.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Ulyanov</surname>, <given-names>D.</given-names></string-name></person-group> <source>Multicore t-SNE</source>. (<year>2021</year>).</mixed-citation></ref>
<ref id="c85"><label>85.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Maaten</surname>, <given-names>L. van der</given-names></string-name></person-group>. <article-title>Accelerating t-SNE using Tree-Based Algorithms</article-title>. <source>J. Mach. Learn. Res</source>. <volume>15</volume>, <fpage>3221</fpage>–<lpage>3245</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c86"><label>86.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Farahmand</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Szepesvári</surname>, <given-names>C.</given-names></string-name> &amp; <string-name><surname>Audibert</surname>, <given-names>J.-Y.</given-names></string-name></person-group> <chapter-title>Manifold-adaptive dimension estimation</chapter-title>. <source>in Proceedings of the 24th international conference on Machine learning</source> <fpage>265</fpage>–<lpage>272</lpage> (<publisher-name>ACM</publisher-name>, <year>2007</year>). doi:<pub-id pub-id-type="doi">10.1145/1273496.1273530</pub-id>.</mixed-citation></ref>
<ref id="c87"><label>87.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Heiser</surname>, <given-names>C. N.</given-names></string-name> &amp; <string-name><surname>Lau</surname>, <given-names>K. S.</given-names></string-name></person-group> <article-title>A Quantitative Framework for Evaluating Single-Cell Data Structure Preservation by Dimensionality Reduction Techniques</article-title>. <source>Cell Rep</source>. <volume>31</volume>, <fpage>107576</fpage> (<year>2020</year>).</mixed-citation></ref>
</ref-list>
<sec id="s8">
<title>Supplementary figures and legends</title>
<fig id="figS1" position="float" fig-type="figure">
<label>Supplementary Figure 1.</label>
<caption><title>Schematic overview of standard and TopOMetry workflows for single-cell analysis.</title>
<p>(A) Schematic overview of the current standard workflow for single-cell analysis, starting from a high-dimensional matrix generated from raw sequencing data, that undergoes quality control (QC) and cell filtering and library-size normalization. High-variable genes are selected and used to compute PCA, from which the top principal components are used to find k-nearest-neighbors (kNN) graphs and affinity matrices that are used for clustering and projection into two-dimensional visualizations. (B) Schematic overview of the TopOMetry workflow, which consists of the same default processing steps, after which kNN graphs and specialized kernels are used to learn Laplacian-type operators that consist of topological affinity matrices. The eigendecomposition of such an operator yields eigenbases that preserve the latent topological information from the original high-dimensional manifold. The eigenbasis can then be used to learn new topological graphs using the same kernels and operators, which are used for clustering or learning two-dimensional projections for visualization through graph-layout optimization techniques. The learned projections are then evaluated for the preservation of global and local structure and the amount of introduced distortion. (C) Schematic overview of the computational implementation of TopOMetry, which is centered around the TopOGraph class.</p></caption>
<graphic xlink:href="484134v3_figS1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS2" position="float" fig-type="figure">
<label>Supplementary Figure 2.</label>
<caption><title>Qualitative evaluation of TopOMetry and existing methods on synthetic and toy data.</title>
<p>(A) Two-dimensional projections obtained with PCA, kernel PCA, and TopOMetry eigenbases for eight synthetic datasets: a circle inside a larger circle, two half moons, gaussian distributions with equal variances, gaussian distributions with different variances, the ‘S’ shape, the ‘swiss-roll’ shape, a uniformly sampled square and Gaussian noise. Sample points are colored by their original classes for the first four datasets and by their distribution on the fifth and sixth. Note how the eigenbases used in TopOMetry do not induce artificial clustering structure in the uniform square and the Gaussian noise, and successfully unfold the (B) The same projections, with samples colored by the value of the first component of the eigenbasis. Note how the first component of PCA and Kernel PCA fails to discriminate discrete submanifolds in the first two datasets and to unfold the ‘swiss-roll’ shape. (C) Three-dimensional visualization of the ‘S’ and ‘swiss-roll’ shapes, colored by the first component of each method. Note how the first component of PCA and Kernel PCA fails to discover the notoriously non-linear geometry. (D) Two-dimensional projections of the MNIST handwritten-digits dataset obtained with PCA, the eigenbases used in TopOMetry, a MAP projection of the diffusion potential of these eigenbases, UMAP on the first 100 principal components, UMAP on the data, t-SNE, PaCMAP and TriMAP. Samples (images) are colored by the digit they correspond to.</p></caption>
<graphic xlink:href="484134v3_figS2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS3" position="float" fig-type="figure">
<label>Supplementary Figure 3.</label>
<caption><title>Preservation of global structure across eigenbases and projections from single-cell datasets.</title>
<p>(A) Global score for TopOMetry eigenbases for each of the 20 datasets used in the benchmark, with varying kernels. (B) Global score for projections obtained with t-SNE, UMAP, and PaCMAP with or without PCA preprocessing and with TopOMetry.</p></caption>
<graphic xlink:href="484134v3_figS3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS4" position="float" fig-type="figure">
<label>Supplementary Figure 4.</label>
<caption><title>Transcriptional diversity of T cells in a healthy human donor.</title>
<p>(A) UMAP projections of the <italic>PBMC68k</italic> dataset obtained using the top 50 principal components (PCs), colored by clustering results obtained from the top 50 PCs, top 300 PCs, gene expression matrix, TopOMetry diffusion potential of the msDM eigenbasis and cell types predicted with CellTypist. (B) UMAP projections of the same data using the top 300 PCs. Note how clusters obtained with 50 PCs do not correspond to the structure uncovered using 300 PCs. (C) UMAP projections of the same data using the gene expression matrix of highly-variable genes. (D) topoMAP (MAP of the diffusion potential of the msDM eigenbasis) projection of the same data. Arrows in (C) and (D) highlight agreeing clustering results when using the gene expression matrix and TopOMetry, which can be detected on the periphery of the UMAP embedding of T cells. (E) Heatmap of adjusted mutual information (AMI) score between clustering results obtained with either approach, including additional TopOMetry eigenbases. The AMI score indicates the agreement between two clustering results when no ground-truth is known. Note how the results obtained with the high-dimensional expression data agree more with those obtained with TopOMetry than with those obtained with PCA. (F) topoMAP embedding of the same data, colored by cell subtypes predicted with CellTypist. Note how the majority of novel cell types uncovered correspond to CD4+ T and NK cells. (G) UMAP projection using the top 50 PCs, colored by gene expression of the canonical markers <italic>CD3E, CD4, CD8A</italic>, and <italic>FOXP3</italic>, and of marker genes for T cell subpopulations found with TopOMetry: <italic>MDN1, C11</italic>orf68, <italic>IL11RA</italic>, and <italic>IL21R</italic>. (H) UMAP projection using the expression data, colored as in (G), and with red circles highlighting the densely localized expression of marker genes of novel T cell subpopulations. (I) topoMAP projection of the same data, likewise colored, with red circles highlighting the densely localized expression of marker genes of novel T cell subpopulations.</p></caption>
<graphic xlink:href="484134v3_figS4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS5" position="float" fig-type="figure">
<label>Supplementary Figure 5.</label>
<caption><title>Transcriptional diversity of T cells across diseases.</title>
<p>(A) Panel of projections of the <italic>Lupus</italic> dataset of peripheral mononuclear blood cells (PBMC) from healthy donors and Systemic Lupus Erythematosus patients, each obtained with UMAP on the first 50 principal components (PCs), UMAP on the expression data and TopOMetry, and colored by clustering results obtained with the first 50 PCs, expression data and TopOMetry. Each row corresponds to a clustering method and each column corresponds to a projection method. (B) Panel of projections of the <italic>Dengue</italic> dataset of PBMC from a dengue fever patient, obtained and colored as in (A). (C) Panel of projections of the <italic>MS_CSF</italic> dataset of mononuclear cells from the peripheral blood and cerebrospinal fluid (CSF) from healthy donors and multiple sclerosis patients, obtained and colored as in (A) and (B). Note how the findings observed in the <italic>PBMC68k</italic> dataset are replicated in a nearly identical fashion for all three datasets: clustering and projecting from expression data yield results that disagree with those obtained with the standard PCA-based approach and agree with those obtained with TopOMetry. The diffusion potential of the msDM eigenbasis was used for topoMAP projection and Leiden clustering in all datasets. (D) Dotplot of the top marker genes for clusters found with 50 PC and with TopOMetry on the <italic>Lupus</italic> dataset, with three genes shown per cluster for the former and one for the latter. (E) Same as in (D), but for the <italic>Dengue</italic> dataset. (F) Same as in (E) and (D), but for the <italic>MS_CSF</italic> dataset. Note how the finding that clusters of T cells found with the standard PCA-based approach present poor marker genes is replicated for all datasets, in sharp contrast to the highly specific marker genes presented by the clusters found with TopOMetry. (G) Heatmaps of adjusted mutual information (AMI) scores indicating agreement between different clustering strategies for the <italic>Lupus, Dengue</italic> and <italic>MS_CSF</italic> datasets, including additional TopOMetry eigenbases. Clustering results obtained with expression data disagree with those obtained using PCA and agree with those obtained using TopOMetry.</p></caption>
<graphic xlink:href="484134v3_figS5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS6" position="float" fig-type="figure">
<label>Supplementary Figure 6.</label>
<caption><title>Transcriptional diversity of T cell clonotypes.</title>
<p>(A) PCA-based UMAP projection of T cells from the TICA dataset, as in the original study, colored by expression of <italic>CD4</italic> and <italic>CD8A</italic>. (B) topoMAP (MAP of the diffusion potential of the msDM eigenbasis) of the TICA dataset, colored by expression of <italic>CD4</italic> and <italic>CD8A</italic>. (C) Clonotype network for T cells with a detectable TCR in this dataset, based on amino acid sequence similarity. Each dot represents an individual clonotype, and its size represents the number of cells belonging to that clonotype. Dots are colored by the clusters from the original study. Note how different clones are grouped together under the same cluster assignment. (D) Same as in (C), but with dots colored by the clusters found with TopOMetry. Note how most clonotypes belong to a single cluster assignment, without overlap. (E) PCA-based UMAP and (F) topoMAP projections of the same data, colored by clonotype modularity. Clonotype modularity was calculated using a neighborhood graph learned from the top 50 principal components (PCs) or the diffusion potential graph. Note how modularities are higher with the latter, indicating a better connection between the manifold learned from RNA-seq and the clonotypes learned from VDJ-seq. (G-J) Violin plots of comparative gene expression between cells belonging to a clone and the rest, detected akin to marker genes using the Wilcoxon test, showing gene expression of the receptor chains that define clonotypes identified by VDJ-seq.</p></caption>
<graphic xlink:href="484134v3_figS6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS7" position="float" fig-type="figure">
<label>Supplementary Figure 7.</label>
<caption><title>PCA introduces linear distortion into the manifold region inhabited by T cells.</title>
<p>(A) Violin plots of intrinsic dimensionality (i.d.) estimates for the <italic>PBMC68k, Lupus, Dengue</italic>, and <italic>MS_CSF</italic> datasets, grouped by cell types predicted with CellTypist. Note how T cells do not present particularly high i.d. Estimates. (B-F) Eigenspectrum (left) and cumulative explained variance (right) of PCA for the <italic>PBMC68k, Lupus, Dengue, MS_CSF</italic>, and TICA datasets. An <italic>ad hoc</italic> ‘elbow point’ is found for all datasets around 30 principal components (PCs), at which PCA explains less than 15% of the data covariance. Such feature is a known hallmark of non-linear data. (G) Boxplot of eccentricities of the ellipses representing the Riemannian metric to evaluate distortions, obtained from T cells from the <italic>PBMC68k, Lupus, Dengue</italic>, and <italic>MS_CSF</italic> datasets. For all datasets, the eccentricities (an indirect measure of induced distortion) were significantly lower in the topoMAP projection when compared to UMAP on the first 50 PCs (p &lt; 10<sup>-90</sup>, two-sided Wilcoxon test).</p></caption>
<graphic xlink:href="484134v3_figS7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100361.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Park</surname>
<given-names>Jihwan</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Gwangju Institute of Science and Technology</institution>
</institution-wrap>
<city>Gwangju</city>
<country>Republic of Korea</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study presents TopOMetry, an <bold>important</bold> novel dimensionality reduction method that addresses a signficant challenge in the analysis of single-cell RNA sequencing data. The authors provide <bold>convincing</bold> evidence of the method's utility across various tasks, including estimating intrinsic dimensionalities and identifying cell types. The work would benefit from more rigorous validation and a reorganization of the text.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100361.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Sidarta-Oliveira et al. present TopOMetry, a novel dimensionality reduction method based on the eigendecomposition of approximated Laplace-Beltrami Operator. Shortly, TopOMetry is an iterative version of the existing spectral methods (e.g., Laplacian Eigenmap or Diffusion map). It approximates the Laplacian operators twice, once in a &quot;phenotypic space&quot; and then once again in the eigenbases space. By doing this the approximated operator will contain more information of the manifold, which allows for more robust and accurate downstream analyses.</p>
<p>Strengths:</p>
<p>(1) The approach was rigorously tested based on synthetic and real single-cell RNA-seq datasets.</p>
<p>(2) The package is well-made and easily scalable to millions of cells.</p>
<p>(3) The comprehensive documentation helps the end-users to run desired analyses.</p>
<p>Weaknesses:</p>
<p>(1) The method is an extension of the current state-of-art methods, not a fundamentally new one.</p>
<p>(2) Considering the target readers, the paper contains a lot of jargon.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100361.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This work introduces a novel framework to systematically learn the latent dimensions of single-cell data, grounded in the theory of the Riemannian manifold. The authors demonstrate how this framework can be applied to various important tasks, such as estimating intrinsic dimensionalities, annotating cell types, etc. They did a great job of tackling an important but not yet established problem in the field and approaching it with a theoretically sound and novel approach. I think after a more rigorous and comprehensive validation, this work could be impactful.</p>
<p>Strengths:</p>
<p>(1) Dimensionality reduction is a routine step in analyzing many high-dimensional data, such as molecular data. While the downstream analysis results depend heavily on this step, existing methods rely on strong assumptions and are sometimes heuristic. The authors present a novel, theoretically grounded approach to address this important problem.</p>
<p>(2) The authors demonstrated its usability in downstream analysis in a comprehensive manner. In particular, they show evidence suggesting novel T-cell subpopulations.</p>
<p>(3) I commend the authors for releasing and maintaining their software well with comprehensive documentation. This significantly increases the usability and accessibility of the method.</p>
<p>Weaknesses:</p>
<p>(1) To encourage the single-cell community to adopt this method, the authors should more clearly demonstrate its advantages over existing methods. There are many single cell analysis algorithms that are proposed in each task and some of them are widely used by biologists. However, the comparison in this work is somewhat limited. For example, Even methods mentioned in the relevant work paragraph (2nd paragraph) on page 2 are not all compared, or the reason why they are not included is not discussed. Also, I am curious how PC dimensions are determined. The choice of 300 PCs on page 11 seems arbitrary. Furthermore, the usefulness of dimension-reduced data also depends a lot on the preceding processing steps, such as highly variable gene selection. I understand it is hard to control all those factors, but I think there is room for improvement.</p>
<p>(2) The paper lacks experiments that validate the results. It would be beneficial to see additional evaluation settings with better-established ground truths to more strongly demonstrate the method's effectiveness.</p>
<p>(3) The effect of various parameters, such as those involved in k-nearest neighbors (KNN) or choosing the appropriate Laplacian operator, is not comprehensively explored. How can we ensure the analysis is not overly sensitive to these parameters?</p>
<p>(4) Batch effects are prevalent in single-cell data. The paper does not adequately address how the proposed method handles this issue.</p>
</body>
</sub-article>
</article>