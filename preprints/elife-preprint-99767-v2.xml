<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">99767</article-id>
<article-id pub-id-type="doi">10.7554/eLife.99767</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.99767.2</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.6</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Physics of Living Systems</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Optimal information gain at the onset of habituation to repeated stimuli</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Nicoletti</surname>
<given-names>Giorgio</given-names>
</name>
<xref ref-type="aff" rid="A1">1</xref>
<xref ref-type="aff" rid="A2">2</xref>
<xref ref-type="aff" rid="A3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Bruzzone</surname>
<given-names>Matteo</given-names>
</name>
<xref ref-type="aff" rid="A4">4</xref>
<xref ref-type="aff" rid="A5">5</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Suweis</surname>
<given-names>Samir</given-names>
</name>
<xref ref-type="aff" rid="A3">3</xref>
<xref ref-type="aff" rid="A5">5</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Maschio</surname>
<given-names>Marco Dal</given-names>
</name>
<xref ref-type="aff" rid="A4">4</xref>
<xref ref-type="aff" rid="A5">5</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Busiello</surname>
<given-names>Daniel Maria</given-names>
</name>
<xref ref-type="aff" rid="A6">6</xref>
<xref ref-type="aff" rid="A3">3</xref>
<email>busiello@pks.mpg.de</email>
</contrib>
<aff id="A1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02s376052</institution-id><institution>ECHO Laboratory, Ecole Polytechnique Federale de Lausanne</institution></institution-wrap>, <city>Lausanne</city>, <country country="CH">Switzerland</country></aff>
<aff id="A2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/009gyvm78</institution-id><institution>Quantitative Life Sciences section, The Abdus Salam International Center for Theoretical Physics (ICTP)</institution></institution-wrap>, <city>Trieste</city>, <country country="IT">Italy</country></aff>
<aff id="A3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00240q980</institution-id><institution>Department of Physics and Astronomy “Galileo Galilei”, University of Padova</institution></institution-wrap>, <city>Padova</city>, <country country="IT">Italy</country></aff>
<aff id="A4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00240q980</institution-id><institution>Department of Biomedical Science, University of Padova</institution></institution-wrap>, <city>Padova</city>, <country country="IT">Italy</country></aff>
<aff id="A5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00240q980</institution-id><institution>Padova Neuroscience Center, University of Padova</institution></institution-wrap>, <city>Padova</city>, <country country="IT">Italy</country></aff>
<aff id="A6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01bf9rw71</institution-id><institution>Max Planck Institute for the Physics of Complex Systems</institution></institution-wrap>, <city>Dresden</city>, <country country="DE">Germany</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Murugan</surname>
<given-names>Arvind</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Chicago</institution>
</institution-wrap>
<city>Chicago</city>
<country>United States of America</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Walczak</surname>
<given-names>Aleksandra M</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>CNRS</institution>
</institution-wrap>
<city>Paris</city>
<country>France</country>
</aff>
</contrib>
</contrib-group>
<pub-date pub-type="epub">
<day>03</day>
<month>02</month>
<year>2025</year>
</pub-date>
<pub-date date-type="original-publication" iso-8601-date="2024-10-25">
<day>25</day>
<month>10</month>
<year>2024</year>
</pub-date>
<pub-date date-type="update" iso-8601-date="2025-05-12">
<day>12</day>
<month>05</month>
<year>2025</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP99767</elocation-id>
<history><date date-type="sent-for-review" iso-8601-date="2024-08-05">
<day>05</day>
<month>08</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-08-08">
<day>08</day>
<month>08</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.48550/arXiv.2301.12812"/>
</event>
<event>
<event-desc>Reviewed preprint v1</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2024-10-25">
<day>25</day>
<month>10</month>
<year>2024</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.99767.1"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.99767.1.sa3">eLife Assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.99767.1.sa2">Reviewer #1 (Public review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.99767.1.sa1">Reviewer #2 (Public review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.99767.1.sa0">Reviewer #3 (Public review):</self-uri>
<self-uri content-type="author-comment" xlink:href="https://doi.org/10.7554/eLife.99767.1.sa4">Author response:</self-uri>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Nicoletti et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Nicoletti et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-99767-v2.pdf"/>
<abstract>
<p>Biological and living systems process information across spatiotemporal scales, exhibiting the hallmark ability to constantly modulate their behavior to ever-changing and complex environments. In the presence of repeated stimuli, a distinctive response is the progressive reduction of the activity at both sensory and molecular levels, known as habituation. In this work, we solve a minimal microscopic model devoid of biological details, where habituation to an external signal is driven by negative feedback provided by a slow storage mechanism. We show that our model recapitulates the main features of habituation, such as spontaneous recovery, potentiation, subliminal accumulation, and input sensitivity. Crucially, our approach enables a complete characterization of the stochastic dynamics, allowing us to compute how much information the system encodes on the input signal. We find that an intermediate level of habituation is associated with a steep increase in information. In particular, we are able to characterize this region of maximal information gain in terms of an optimal trade-off between information and energy consumption. We test our dynamical predictions against experimentally recorded neural responses in a zebrafish larva subjected to repeated looming stimulations, showing that our model captures the main components of the observed neural habituation. Our work makes a fundamental step towards uncovering the functional mechanisms that shape habituation in biological systems from an information-theoretic and thermodynamic perspective.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>

</article-meta>
</front>
<body>
<sec id="s1" sec-type="intro">
<title>Introduction</title>
<p>Sensing mechanisms in biological systems span a wide range of temporal and spatial scales, from cellular to multi-cellular level, forming the basis for decision-making and the optimization of limited resources [<xref ref-type="bibr" rid="c1">1</xref>–<xref ref-type="bibr" rid="c5">5</xref>]. Emergent macroscopic phenomena such as adaptation and habituation reflect the ability of living systems to effectively process the information they collect from their noisy environment [<xref ref-type="bibr" rid="c6">6</xref>–<xref ref-type="bibr" rid="c8">8</xref>]. Prominent examples include the modulation of flagellar motion operated by bacteria according to changes in the local nutrient concentration [<xref ref-type="bibr" rid="c9">9</xref>–<xref ref-type="bibr" rid="c11">11</xref>], the regulation of immune responses through feedback mechanisms [<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c13">13</xref>], the progressive reduction of neural activity in response to repeated looming stimulation [<xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c15">15</xref>], and the maintenance of high sensitivity in varying environments for olfactory or visual sensing in mammalian neurons [<xref ref-type="bibr" rid="c16">16</xref>–<xref ref-type="bibr" rid="c20">20</xref>].</p>
<p>In the last decade, advances in experimental techniques fostered the quest for the core biochemical mechanisms governing information processing. Simultaneous recordings of hundreds of biological signals made it possible to infer distinctive features directly from data [<xref ref-type="bibr" rid="c21">21</xref>–<xref ref-type="bibr" rid="c24">24</xref>]. However, many of these approaches fall short of describing the connection between observed behaviors and underlying microscopic drivers [<xref ref-type="bibr" rid="c25">25</xref>–<xref ref-type="bibr" rid="c28">28</xref>]. To fill this gap, several works focused on the architecture of specific signaling networks, from tumor necrosis factor [<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c13">13</xref>] to chemotaxis [<xref ref-type="bibr" rid="c9">9</xref>, <xref ref-type="bibr" rid="c29">29</xref>], highlighting the essential structural ingredients for their efficient functioning. An observation shared by most of these studies is the key role of a negative feedback mechanism to induce emergent adaptive responses [<xref ref-type="bibr" rid="c30">30</xref>–<xref ref-type="bibr" rid="c33">33</xref>]. Moreover, any information-processing system, biological or not, must obey information-thermodynamic laws that prescribe the necessity of a storage mechanism [<xref ref-type="bibr" rid="c34">34</xref>]. This is an unavoidable feature highlighted in numerous chemical signaling networks [<xref ref-type="bibr" rid="c9">9</xref>, <xref ref-type="bibr" rid="c30">30</xref>] and biochemical realizations of Maxwell Demons [<xref ref-type="bibr" rid="c35">35</xref>, <xref ref-type="bibr" rid="c36">36</xref>]. As the storage of information during processing generally requires energy [<xref ref-type="bibr" rid="c37">37</xref>, <xref ref-type="bibr" rid="c38">38</xref>], sensing mechanisms have to take place out-of-equilibrium [<xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c39">39</xref>–<xref ref-type="bibr" rid="c41">41</xref>]. Recently, the discovery of memory molecules [<xref ref-type="bibr" rid="c42">42</xref>–<xref ref-type="bibr" rid="c44">44</xref>] hinted at the possibility that storing mechanisms might be instantiated directly at the molecular scale. Overall, negative feedback, storage, and out-of-equilibrium conditions seem to be necessary requirements for a system to process environmental information and act accordingly. To quantify the performance of a biological information-processing system, theoretical developments made substantial progress in highlighting thermodynamics limitations and advantages [<xref ref-type="bibr" rid="c16">16</xref>, <xref ref-type="bibr" rid="c45">45</xref>, <xref ref-type="bibr" rid="c46">46</xref>], making a step towards linking information and dissipation from a molecular perspective [<xref ref-type="bibr" rid="c35">35</xref>, <xref ref-type="bibr" rid="c47">47</xref>, <xref ref-type="bibr" rid="c48">48</xref>].</p>
<p>Here, we consider an archetypal yet minimal model for sensing that is inspired by biological networks [<xref ref-type="bibr" rid="c16">16</xref>, <xref ref-type="bibr" rid="c49">49</xref>, <xref ref-type="bibr" rid="c50">50</xref>] and encapsulates all these key ingredients, i.e., negative feedback, storage, and energy dissipation, and study its response to repeated stimuli. Indeed, in the presence of dynamic environments, it is common for a biological system to keep encountering the same stimulus. Under these conditions, a progressive decay in the amplitude of the response is often observed, both at sensory and molecular levels. In general terms, such adaptive behavior is usually named <italic>habituation</italic> and is a common phenomenon recorded in various systems, from biochemical networks [<xref ref-type="bibr" rid="c49">49</xref>, <xref ref-type="bibr" rid="c51">51</xref>, <xref ref-type="bibr" rid="c52">52</xref>] to populations of neurons [<xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c15">15</xref>, <xref ref-type="bibr" rid="c53">53</xref>, <xref ref-type="bibr" rid="c54">54</xref>]. In particular, habituation characterizes many neuronal circuits along the sensory-motor processing pathways in most living organisms, either invertebrates or vertebrates [<xref ref-type="bibr" rid="c53">53</xref>, <xref ref-type="bibr" rid="c54">54</xref>], where inhibitory feedback mechanisms are believed to modulate the stimulus weight [<xref ref-type="bibr" rid="c15">15</xref>, <xref ref-type="bibr" rid="c55">55</xref>]. Most importantly, the first complete characterization of habituating phenomena dates back to 1966 [<xref ref-type="bibr" rid="c56">56</xref>], when different hallmarks of habituation in vertebrate animals were characterized. Despite its widespread occurrence across remarkably different scales, the connection between habituation in the animal kingdom and brainless molecular systems has only recently attracted considerable attention. A limited number of dynamical models have been proposed to explore the similarities and differences between the manifestations of these two, fundamentally distinct, phenomena [<xref ref-type="bibr" rid="c57">57</xref>, <xref ref-type="bibr" rid="c58">58</xref>]. However, dynamical characterizations of habituation still lack a clear identification of the functional role of habituation in regulating information flow, optimal processing, and sensitivity calibration [<xref ref-type="bibr" rid="c59">59</xref>], and in controlling behavior and prediction during complex tasks [<xref ref-type="bibr" rid="c60">60</xref>–<xref ref-type="bibr" rid="c62">62</xref>].</p>
<fig id="fig1" position="float" fig-type="figure">
<label>FIG. 1</label>
<caption><title>Sketch of the model architecture and biological examples at different scales.</title>
<p>(a) A receptor R transitions between an active (<italic>A</italic>) and passive (<italic>P</italic>) state along two pathways, one used for sensing (red) and affected by the environment <italic>h</italic>, and the other (blue) modified by the energy of storage molecules, <italic>σs</italic>, tuned by inhibition strength κ and storage capacity N<sub>S</sub>. Here, <italic>β</italic> = <italic>(κ<sub>B</sub>T</italic>)<sup>−1</sup> encodes the inverse temperature. An active receptor increases the response of a readout population <italic>U</italic> (orange), which in turn stimulates the production of storage units <italic>S</italic> (green) that provide negative feedback to the receptor. (b) In the chemical network underlying chemotactic response, we can identify a similar architecture. The input ligand binds to membrane receptors, decreasing kinase activity and producing phosphate groups whose concentration regulates the receptor methylation level. (c) Similarly, in olfactory sensing, odorant binding induces the activation of adenylyl cyclase (AC). AC stimulates a calcium flux, eventually producing phosphorylase calmodulin kinase II (CAMKII) which phosphorylates and deactivates AC. (d) In neural response, multiple mechanisms take place at different scales. In zebrafish larvae, visual stimulation is projected along the visual stream from the retina to the cortex, a coarse-grained realization of the <italic>R-U</italic> dynamics. Neural habituation emerges upon repeated stimulation, as measured by calcium fluorescence signals (<italic>dF/F</italic><sub>0</sub>) and by the corresponding 2-dimensional PCA of the activity profiles.</p></caption>
<graphic xlink:href="2301.12812v6_fig1.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<p>In this work, we explicitly compute the information shared between readout molecules and external stimulus over time. We find that the information gain peaks at intermediate levels of habituation, uncovering that optimal processing performances are necessarily tangled with maximal activity reduction. This region of optimal information gain can be retrieved by simultaneously minimizing dissipation and maximizing information in the presence of a prolonged stimulation, hinting at an a priori optimality condition for the operations of biological systems. Our results unveil the role of habituation in enhancing processing abilities and open the avenue to understanding the emergence of basic learning mechanisms in simple molecular scenarios.</p>
</sec>
<sec id="s2" sec-type="results">
<title>Results</title>
<sec id="s2-1">
<title>Archetypal model for sensing in biological systems</title>
<p>Several minimal models for adaptation are composed of three building blocks [<xref ref-type="bibr" rid="c9">9</xref>, <xref ref-type="bibr" rid="c29">29</xref>, <xref ref-type="bibr" rid="c49">49</xref>–<xref ref-type="bibr" rid="c51">51</xref>]: one responsible for buffering the input signal; one representing the output; and one usually reminiscent of an internal memory. Here, we start with an analogous archetypal architecture. The three building blocks (or units) are represented by a receptor (<italic>R</italic>), and readout (<italic>U</italic>) and storage (<italic>S</italic>) populations.</p>
<p>To introduce our model in general terms, we consider a time-varying environment <italic>H</italic>, representing an external signal characterized by a probability <italic>p<sub>H</sub></italic> (<italic>h, t</italic>) of being equal to <italic>h</italic> at time <italic>t</italic>. This input signal is read by the receptor unit <italic>R</italic>. The receptor can be either active (<italic>A</italic>), taking the value <italic>r</italic> = 1, or passive (<italic>P</italic>), <italic>r</italic> = 0, with these two states separated by an energetic barrier Δ<italic>E</italic>. The transitions between passive and active states can happen through two different pathways, a “sensing” reaction path (superscript <italic>H</italic>) that is stimulated by the external signal <italic>h</italic>, and a “internal” path (superscript <italic>I</italic>) that mediates the effect of the negative feedback from the storage unit (see <xref ref-type="fig" rid="fig1">Fig. 1a</xref>). We further assume, for simplicity, that the rates follow an effective Arrhenius’ law:
<disp-formula id="FD1">
<alternatives>
<mml:math display="block" id="M1"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>→</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>H</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>β</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>−</mml:mo><mml:mi>Δ</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>R</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>H</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>→</mml:mo><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>H</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>R</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>H</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>→</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mi>Δ</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>R</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>→</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>R</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mi>β</mml:mi><mml:mi>κ</mml:mi><mml:mi>σ</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable></mml:math>
<graphic xlink:href="2301.12812v6_eqn1.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(1)</label>
</disp-formula>
</p>
<p>where the input is modeled as an additional thermodynamic driving with an energy <italic>βh</italic>, and <inline-formula id="ID1">
<alternatives>
<mml:math display="inline" id="I1"><mml:mrow><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>R</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>H</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq1.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> = <inline-formula id="ID2">
<alternatives>
<mml:math display="inline" id="I2"><mml:mrow><mml:mi>g</mml:mi><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>R</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq2.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> = <inline-formula id="ID3">
<alternatives>
<mml:math display="inline" id="I3"><mml:mrow><mml:msubsup><mml:mi>τ</mml:mi><mml:mi>T</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq3.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> sets the timescale of the receptor. In particular, <italic>g</italic> represents the ratio between the timescales of the two pathways, and the inverse temperature <italic>β</italic> = <italic>(κ<sub>B</sub>T</italic>)<sup>−1</sup> encodes the role of the thermal noise, as lower values of P are associated with faster reactions.</p>
<p>The negative feedback depends on the energy provided by the storage, <italic>σs</italic>, where s is the number of active storage molecules. The parameter κ represents the strength of the inhibition, and <italic>N<sub>S</sub></italic> is the storage capacity. For ease of interpretation, we assume that the activation rate of the receptor due to a reference signal <italic>H</italic><sub>ref</sub> is balanced by the deactivation rate provided by the feedback of a fraction <italic>α</italic> = 𣤩<italic>S</italic>⟩/<italic>N<sub>S</sub></italic> of average active storage population:
<disp-formula id="FD2">
<alternatives>
<mml:math display="block" id="M2"><mml:mrow><mml:mo>〈</mml:mo><mml:mrow><mml:mi>log</mml:mi><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>→</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>H</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>→</mml:mo><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>〉</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>β</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>κ</mml:mi><mml:mi>σ</mml:mi><mml:mi>α</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mtext> </mml:mtext><mml:mo>→</mml:mo><mml:mtext> </mml:mtext><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>α</mml:mi><mml:mi>σ</mml:mi></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:math>
<graphic xlink:href="2301.12812v6_eqn2.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(2)</label>
</disp-formula>
</p>
<p>This condition sets the inhibition strength by choosing the inhibiting fraction <italic>α</italic>. At this stage, the reference signal represents the typical environmental stimulus to which the system is exposed. This choice rationalizes the physical meaning of the model parameters, but it does not alter the phenomenology of the system. Crucially, the presence of two different transition pathways, motivated by molecular considerations and pivotal in many energy-consuming biochemical systems [<xref ref-type="bibr" rid="c35">35</xref>, <xref ref-type="bibr" rid="c63">63</xref>, <xref ref-type="bibr" rid="c64">64</xref>], creates an internal non-equilibrium cycle in receptor dynamics. Without the storage population, the internal pathway would not be present and the receptor would satisfy an effective detailed balance.</p>
<p>Whenever active, the receptor drives the production of readout population <italic>U</italic>, which represents the direct response of the system to environmental signals. As such, it is the observable characterizing habituation (see <xref ref-type="fig" rid="fig1">Fig. 1a</xref>). We model its dynamics with a controlled stochastic birth- and-death process [<xref ref-type="bibr" rid="c65">65</xref>–<xref ref-type="bibr" rid="c67">67</xref>]:
<disp-formula id="FD3">
<alternatives>
<mml:math display="block" id="M3"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mo>∅</mml:mo><mml:mi>U</mml:mi></mml:msub><mml:mover><mml:mo>→</mml:mo><mml:mrow><mml:msub><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>u</mml:mi><mml:mo>→</mml:mo><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mover><mml:mi>U</mml:mi><mml:mtext> </mml:mtext><mml:mi>U</mml:mi><mml:mover><mml:mo>→</mml:mo><mml:mrow><mml:msub><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>→</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mover><mml:msub><mml:mo>∅</mml:mo><mml:mi>U</mml:mi></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>u</mml:mi><mml:mo>→</mml:mo><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>V</mml:mi><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>U</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mtext> </mml:mtext><mml:msub><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>→</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>U</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:mtd></mml:mtr></mml:mtable></mml:math>
<graphic xlink:href="2301.12812v6_eqn3.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(3)</label>
</disp-formula>
</p>
<p>where <italic>u</italic> denotes the number of molecules, <inline-formula id="ID4">
<alternatives>
<mml:math display="inline" id="I4"><mml:mrow><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>U</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>τ</mml:mi><mml:mi>U</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq4.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> sets the timescale of readout production, and <italic>V</italic> is the energy needed to produce a readout unit. When the receptor is active, <italic>r</italic> = 1, this energetic cost is reduced by an effective additional driving <italic>μc</italic>. Active receptors transduce the environmental energy into an active pumping in the readout unit, allowing readout population to encode information on the external signal.</p>
<p>Finally, readout units stimulate the production of the storage population <italic>S</italic>. Its number of molecules s follows again a controlled birth-and-death process:
<disp-formula id="FD4">
<alternatives>
<mml:math display="block" id="M4"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mtext> </mml:mtext><mml:msub><mml:mo>∅</mml:mo><mml:mi>S</mml:mi></mml:msub><mml:mover><mml:mo>→</mml:mo><mml:mrow><mml:msub><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>→</mml:mo><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>u</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mover><mml:mi>S</mml:mi><mml:mtext> </mml:mtext><mml:mi>S</mml:mi><mml:mover><mml:mo>→</mml:mo><mml:mrow><mml:msub><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>→</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mover><mml:msub><mml:mo>∅</mml:mo><mml:mi>S</mml:mi></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>→</mml:mo><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>u</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>u</mml:mi><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mi>σ</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>S</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mtext> </mml:mtext><mml:msub><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>→</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>S</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:mtd></mml:mtr></mml:mtable></mml:math>
<graphic xlink:href="2301.12812v6_eqn4.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(4)</label>
</disp-formula>
</p>
<p>where <italic>σ</italic> is the energetic cost of a storage molecule and <inline-formula id="ID5">
<alternatives>
<mml:math display="inline" id="I5"><mml:mrow><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>S</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq5.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> sets the timescale, i.e., <inline-formula id="ID6">
<alternatives>
<mml:math display="inline" id="I6"><mml:mrow><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>S</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>τ</mml:mi><mml:mi>S</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq6.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>. For simplicity, we assume that readout molecules can catalytically activate storage molecules from a passive pool (see <xref ref-type="fig" rid="fig1">Fig. 1a</xref>). Storage units are responsible for encoding the response, playing the role of a finite-time memory.</p>
<p>Our architecture, being devoid of specific biological details, can be adapted to describe systems operating at very different scales (<xref ref-type="fig" rid="fig1">Fig. 1b-d</xref>). However, we emphasize that the proposed model is intentionally oversimplified compared to realistic biochemical or neural systems, yet it contains the minimal ingredients for habituation to emerge naturally. As such, the examples shown in <xref ref-type="fig" rid="fig1">Fig. 1b-d</xref> are meant solely to illustrate the core architecture. In particular, while receptors can be readily identified, the role of readout is played by photo-receptors or calcium concentration for olfactory or visual sensing mechanisms [<xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c15">15</xref>, <xref ref-type="bibr" rid="c17">17</xref>–<xref ref-type="bibr" rid="c20">20</xref>, <xref ref-type="bibr" rid="c59">59</xref>], while storage may represent different molecular mechanisms at a coarse-grained level as, for example, memory molecules sensitive to calcium activity [<xref ref-type="bibr" rid="c42">42</xref>], synaptic depotentiation, and neural populations that regulate neuronal response [<xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c15">15</xref>].</p>
<p>As a final remark, we expect from previous studies [<xref ref-type="bibr" rid="c67">67</xref>] that the presence of multiple timescales in the system will be fundamental in shaping information between the different components. Thus, we employ the biologically plausible assumption that U undergoes the fastest evolution, while S and H are the slowest degrees of freedom [<xref ref-type="bibr" rid="c29">29</xref>, <xref ref-type="bibr" rid="c68">68</xref>]. We have that <italic>τ<sub>u</sub></italic> ≪ <italic>τ<sub>R</sub></italic> ≪ <italic>τ<sub>S</sub></italic> ≈ <italic>τ<sub>H</sub></italic>, where <italic>τ<sub>H</sub></italic> is the timescale of the environment.</p>
</sec>
<sec id="s2-2">
<title>The hallmarks of habituation</title>
<p>Habituation occurs when, upon repeated presentation of the same stimulus, a progressive decrease to an asymptotic level is observed in some parameters [<xref ref-type="bibr" rid="c56">56</xref>, <xref ref-type="bibr" rid="c57">57</xref>]. In our model, the response of the system is represented by the average number of active readout units, 〈U⟩(t). This behavior resembles recent observations on habituation under analogous external conditions in various experimental systems [<xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c15">15</xref>, <xref ref-type="bibr" rid="c49">49</xref>, <xref ref-type="bibr" rid="c51">51</xref>, <xref ref-type="bibr" rid="c52">52</xref>]. However, habituation in its strict sense is not sufficient to encompass the diverse array of emergent features recorded in biological systems. In fact, several other hallmarks are closely associated with habituating behavior [<xref ref-type="bibr" rid="c56">56</xref>–<xref ref-type="bibr" rid="c58">58</xref>]:
<list list-type="order">
<list-item><p>Potentiation of habituation — After a train of stimulations and a subsequent short pause, the response decrement becomes more rapid and/or more pronounced.</p></list-item>
<list-item><p>Spontaneous recovery — If, after response decrement, the stimulus is suppressed for a sufficiently long time, the response recovers at least partially at subsequent stimulations.</p></list-item>
<list-item><p>Subliminal accumulation — The effect of stimulation may accumulate after the habituation level thus delaying the onset of spontaneous recovery.</p></list-item>
<list-item><p>Intensity sensitivity — Other conditions being fixed, the less intense the stimulus, the more rapid and/or pronounced the response decrease.</p></list-item>
<list-item><p>Frequency sensitivity — Other conditions being fixed, more frequent stimulation results in a more rapid and/or more pronounced response decrease.</p></list-item>
</list>
</p>
<fig id="fig2" position="float" fig-type="figure">
<label>FIG. 2</label>
<caption><title>Hallmarks of habituation.</title>
<p>(a) An external signal switch between two values, 〈<italic>H</italic>⟩<sub>min</sub> = 0.1 (background) and 〈<italic>H</italic>⟩<sub>max</sub> = <italic>H</italic><sub>ref</sub> = 10 (stimulus). The inter-stimuli interval is <italic>ΔT</italic> = 100(a.u.) and the duration of each stimulus <italic>T<sub>s</sub></italic> = 100(a.u.). The average readout population (black) follows the stimulation, increasing when the stimulus is presented. The response decreases upon repeated stimulation, signaling the presence of habituation. Conversely, the average storage population (grey) increases over time. The black dashed line represents the time to habituate <italic>t</italic><sup>(hab)</sup> (<xref ref-type="disp-formula" rid="FD6">Eq. (6)</xref>). (b) If the stimulus is paused and presented again after a short time, the system habituates more rapidly, i.e., the number of stimulations to habituate <italic>t</italic><sup>(hab)</sup> is reduced. (c) After waiting a sufficiently long time, the response can be fully recovered. (d) If the stimulation continues beyond habituation, the time to recover the response <italic>t</italic><sup>(recovery)</sup> (<xref ref-type="disp-formula" rid="FD7">Eq. (7)</xref>) increases by an amount <italic>δt</italic> (in red). (e) The relative decrement of the average readout with respect to the initial response, 〈<italic>U</italic>⟩<sup>(in)</sup> , shows that habituation becomes less and less pronounced as we increase 〈<italic>H</italic>⟩<sub>max</sub>. (f) As expected, the initial response increases with 〈<italic>H</italic>⟩<sub>max</sub>. (g) The relative difference between 〈<italic>U</italic>⟩ (<italic>t</italic><sup>(hab)</sup>) and 〈<italic>H</italic>⟩<sup>(in)</sup>, Δ〈<italic>U</italic>⟩, decreases with the stimulus strength. (h) By changing Δ<italic>T</italic> and keeping the stimulus duration <italic>T<sub>s</sub></italic> fixed, we observe that more pronounced and more rapid response decrements are associated with more frequent stimulation. Parameters are reported in the Methods, and these hallmarks are qualitatively independent of their specific choice.</p></caption>
<graphic xlink:href="2301.12812v6_fig2.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<p>These hallmarks have been originally proposed from observations of vertebrate animals, but they are not the sole properties characterizing the most general definition of habituation. However, the list above encompasses the features that can be obtained from a single stimulation, as in our case, and without any ambiguity in the interpretation (for a detailed discussion, we refer to [<xref ref-type="bibr" rid="c56">56</xref>, <xref ref-type="bibr" rid="c57">57</xref>]).</p>
<p>To explore the ability of the proposed archetypal mode to capture the aforementioned hallmarks, we consider the simple case of an exponential input distribution, <italic>p<sub>H</sub></italic>(<italic>h,t</italic>) ~ exp [−<italic>h</italic>/〈<italic>H</italic>⟩ (<italic>t</italic>)] with uncorrelated signals, i.e., 〈<italic>h(t)h(t<sup>′</sup>)⟩</italic> = 〈<italic>H</italic>⟩(t) 〈<italic>H</italic>⟩ (t<sup>′</sup>). The time-dependent average 〈<italic>H</italic>⟩ periodically switches between two values, 〈<italic>H</italic>⟩<sub>min</sub> and 〈<italic>H</italic>⟩<sub>max</sub>, corresponding to a (non-zero) background signal and a (strong) stimulation of the receptor, respectively. The system dynamics is governed by four different operators, <italic>Ŵ<sub>X</sub></italic>, with <italic>X</italic> = <italic>R, U, S, H</italic>, one for each unit and one for the environment. The resulting master equation is:
<disp-formula id="FD5">
<alternatives>
<mml:math display="block" id="M5"><mml:msub><mml:mo>∂</mml:mo><mml:mi>t</mml:mi></mml:msub><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>U</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>U</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>S</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>u</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>H</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>H</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mo>,</mml:mo></mml:math>
<graphic xlink:href="2301.12812v6_eqn5.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(5)</label>
</disp-formula>
</p>
<p>where <italic>P</italic> denotes, in general, the joint propagator <italic>P(u, r, s, h, t</italic>|<italic>u</italic><sub>0</sub>, <italic>r</italic><sub>0</sub>, <italic>s</italic><sub>0</sub>, <italic>h</italic><sub>0</sub>, <italic>t</italic><sub>0</sub>), with <italic>u</italic><sub>0</sub>, <italic>r</italic><sub>0</sub>, <italic>s</italic><sub>0</sub> and <italic>h</italic><sub>0</sub> initial conditions at time <italic>t</italic><sub>0</sub>. By taking advantage of the timescale separation, we can write an exact self-consistent solution to <xref ref-type="disp-formula" rid="FD5">Eq. (5)</xref> at all times <italic>t</italic> (see Methods and Supplementary Information).</p>
<p>In <xref ref-type="fig" rid="fig2">Fig. 2a</xref>, we show that the system exhibits habituation in its strict sense. Here, for simplicity, we consider a train of signals arriving at times <italic>t</italic><sub>1</sub>, … , <italic>t</italic><sub>N</sub>, each lasting a time <italic>T<sub>s</sub></italic> with equal pauses between them of duration <italic>ΔT</italic>. We define the time to habituate, <italic>t</italic><sup>(hab)</sup>, as the first time at which the relative change of our observable, 〈<italic>U</italic>⟩ (<italic>t</italic>), is less than 0.5%, in analogy to [<xref ref-type="bibr" rid="c57">57</xref>]. Clearly, <italic>t</italic><sup>(hab)</sup> is associated with a number of stimuli necessary to habituate, <italic>n</italic><sup>(hab)</sup>, i.e.,
<disp-formula id="FD6">
<alternatives>
<mml:math display="block" id="M6"><mml:mfrac><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:msup><mml:mi>n</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:msup><mml:mi>n</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mo>≡</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>hab</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:msup><mml:mi>n</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>≤</mml:mo><mml:mn>0.005.</mml:mn></mml:math>
<graphic xlink:href="2301.12812v6_eqn6.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(6)</label>
</disp-formula>
</p>
<p>Our results do not qualitatively change when choosing a different threshold. Hallmark 1, potentiation of habituation, corresponds to a reduction of <italic>n</italic><sup>(hab)</sup> after one series of stimulation and recovery. This implies a more rapid decrement in the response and a shorter time to achieve habituation, as we show in <xref ref-type="fig" rid="fig2">Fig. 2b</xref>. Analogously, hallmark 2 is presented in <xref ref-type="fig" rid="fig2">Fig. 2c</xref>, where we show that by suppressing the stimulus for a sufficiently long amount of time, the response spontaneously recovers to the prehabituation level. Furthermore, by stimulating the system beyond <italic>t</italic><sup>(hab)</sup> , we also observe an increase in the amount of time to achieve complete recovery (hallmark 3). We define this recovery period <italic>t</italic><sup>(recovery)</sup> as the first time required to have a response with a relative strength not greater than 1% with respect to the one at the first stimulus, i.e.,
<disp-formula id="FD7">
<alternatives>
<mml:math display="block" id="M7"><mml:mfrac><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>recovery</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>≤</mml:mo><mml:mn>0.01.</mml:mn></mml:math>
<graphic xlink:href="2301.12812v6_eqn7.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(7)</label>
</disp-formula>
</p>
<p>In <xref ref-type="fig" rid="fig2">Fig. 2d</xref>, we show that the recovery period increase by ~ 5% as a consequence of this subliminal accumulation.</p>
<p>Within the same setting, in <xref ref-type="fig" rid="fig2">Fig. 2e-g</xref> we applied stimuli of different strengths 〈<italic>H</italic>⟩<sub>max</sub> to study the sensitivity to input intensity (hallmark 4). When normalized by the initial response 〈<italic>H</italic>⟩<sup>(in)</sup> = 〈<italic>U</italic>⟩(<italic>t</italic><sub>1</sub>), less intense stimuli result in stronger response decrements (see <xref ref-type="fig" rid="fig2">Fig. 2e</xref>). At the same time, as expected, the absolute value of the initial response increases instead (see <xref ref-type="fig" rid="fig2">Fig. 2f</xref>). Hallmark 4 is clearly captured by <xref ref-type="fig" rid="fig2">Fig. 2g</xref>, where we quantify the decrease of the normalized total habituation level, Ɗ〈<italic>U</italic>⟩ = 〈<italic>U</italic>⟩(<italic>t</italic><sup>(hab)</sup>) − 〈<italic>U</italic>⟩<sup>(in)</sup>, when exposed to increasing 〈<italic>H</italic>⟩<sub>max</sub>. The last feature (hallmark 5) is reported in <xref ref-type="fig" rid="fig2">Fig. 2h</xref>, where we keep the duration of the stimulus <italic>T<sub>s</sub></italic> fixed while changing the inter-stimuli interval <italic>ΔT</italic>. By showing the responses up to the habituation time, we clearly notice that more frequent stimulation is associated with a more rapid and more pronounced response decrement.</p>
<p>Summarizing, despite its simplicity and lack of biological details, our model encompasses the minimal ingredients to capture the main hallmarks defining habituation.</p>
</sec>
<sec id="s2-3">
<title>Information from habituation</title>
<p>In our architecture, habituation emerges due to the increase in the storage population, which provides increasing negative feedback to the receptor and thus lowers the number of active readout units 〈<italic>U</italic>⟩ (<italic>t</italic>). Crucially, by solving the master equation in <xref ref-type="disp-formula" rid="FD5">Eq.(5)</xref>, we can also study the evolution of the full probability distribution p<sub><italic>U,S,H</italic></sub>(t). This approach allows us to quantify how the system encodes information on the environment H through its readout population and how it changes during habituation. To this end, we introduce the mutual information between <italic>U</italic> and <italic>H</italic> at time <italic>t</italic> (see Methods):
<disp-formula id="FD8">
<alternatives>
<mml:math display="block" id="M8"><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>H</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>U</mml:mi></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mi>∞</mml:mi></mml:msubsup><mml:mrow><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2301.12812v6_eqn8.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(8)</label>
</disp-formula>
</p>
<p>where <italic>H[p](t)</italic> is the Shannon entropy of the probability distribution <italic>p</italic>, and p<sub><italic>U|H</italic></sub> denotes the conditional probability distribution of <italic>U</italic> given <italic>H</italic>. <italic>I<sub>U,H</sub></italic> measures information in terms of statistical dependencies, i.e., of how factorizable the joint probability distribution <italic>p<sub>U,H</sub></italic> is. It vanishes if and only if <italic>U</italic> and <italic>H</italic> are independent. Notably, the mutual information coincides with the entropy increase of the readout distribution:
<disp-formula id="FD9">
<alternatives>
<mml:math display="block" id="M9"><mml:msub><mml:mi>κ</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>κ</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>H</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>U</mml:mi></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>Δ</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>U</mml:mi></mml:msub></mml:math>
<graphic xlink:href="2301.12812v6_eqn9.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(9)</label>
</disp-formula>
</p>
<p>where 𝕊S<sub><italic>U</italic></sub> is the change in entropy of the readout population due to repeated measurements of the signal [<xref ref-type="bibr" rid="c34">34</xref>].</p>
<p>As in the previous section, we considered a switching signal with 〈<italic>H</italic>⟩<sub>max</sub> = <italic>H</italic><sub>ref</sub>, the typical environmental stimulus strength. In <xref ref-type="fig" rid="fig3">Fig. 3a-b</xref>, we plot the mutual information at the first signal, <inline-formula id="ID7">
<alternatives>
<mml:math display="inline" id="I7"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq7.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, and when the system has habituated, <inline-formula id="ID8">
<alternatives>
<mml:math display="inline" id="I8"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>hab</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq8.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, as a function of <italic>β</italic> and <italic>σ</italic>. Crucially, we find that there exist parameters for which <inline-formula id="ID9">
<alternatives>
<mml:math display="inline" id="I9"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>hab</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq9.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, is larger than <inline-formula id="ID10">
<alternatives>
<mml:math display="inline" id="I10"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq10.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>. This result suggests that the information on H encoded by U in the habituated system is larger than the initial one. We can quantify this effect by introducing the mutual information gain
<disp-formula id="FD10">
<alternatives>
<mml:math display="block" id="M10"><mml:mi>Δ</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>hab</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:math>
<graphic xlink:href="2301.12812v6_eqn10.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(10)</label>
</disp-formula>
</p>
<p>In <xref ref-type="fig" rid="fig3">Fig. 3c</xref>, we show that Δ<italic>I<sub>U, H</sub></italic> displays a peak in an intermediate region of the (<italic>β, σ</italic>) plane. In this region, the corresponding habituation strength
<disp-formula id="FD11">
<alternatives>
<mml:math display="block" id="M11"><mml:mi>Δ</mml:mi><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>hab</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:math>
<graphic xlink:href="2301.12812v6_eqn11.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(11)</label>
</disp-formula>
</p>
<p>attains intermediate values, suggesting that too strong habituation can be detrimental (<xref ref-type="fig" rid="fig3">Fig. 3d</xref>). This behavior is tightly related to the presence of the storage S , which acts as an information reservoir for the system. To rationalize this feature we introduce the feedback information
<disp-formula id="FD12">
<alternatives>
<mml:math display="block" id="M12"><mml:mi>Δ</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:math>
<graphic xlink:href="2301.12812v6_eqn12.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(12)</label>
</disp-formula>
</p>
<p>quantifying how much the simultaneous knowledge of <italic>U</italic> and <italic>S</italic> increases information compared to <italic>U</italic> alone. Indeed, the change in feedback information after habituation, ΔΔ<italic>I<sub>f</sub></italic> = <inline-formula id="ID13">
<alternatives>
<mml:math display="inline" id="I13"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>hab</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq13.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> − <inline-formula id="ID14">
<alternatives>
<mml:math display="inline" id="I14"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq14.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, peaks in the same region of Δ<italic>I<sub>U, H</sub></italic> (<xref ref-type="fig" rid="fig3">Fig. 3e</xref>).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>FIG. 3</label>
<caption><title>Information and thermodynamics of the model during repeated external stimulation, as a function of the inverse temperature <italic>β</italic> and the energetic cost of storage <italic>σ</italic>.</title>
<p>(a-b) The mutual information between readout population and external signal at the first stimulus, <inline-formula id="ID11">
<alternatives>
<mml:math display="inline" id="I11"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq11.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, is typically lower than the one when the system has habituated, <inline-formula id="ID12">
<alternatives>
<mml:math display="inline" id="I12"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>hab</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq12.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>. (c) The change in the mutual information, Δ<italic>I<sub>U,H</sub></italic>, displays a peak in a region of the (<italic>β, σ</italic>) space, where the system exhibits optimal information gain during habituation. (d) This region corresponds to intermediate habituation strength, as measured by Δ〈U⟩. (e) The corresponding increase in the feedback information Δ<italic>I<sub>f</sub></italic> indicates that storage is fostering the gain in Δ<italic>I<sub>U, H</sub></italic>. (f) Habituation promotes a decrease of the internal energy flux Δ<italic>J</italic><sub>int</sub>, suggesting a synergistic energetic advantage of habituation. (g-h) From the dynamical point of view, in the region of maximal information gain (<italic>β</italic> = 3, <italic>σ</italic> = 0.6) the average number of readout units, 〈U⟩, decreases over time, while the average storage population, 〈S⟩, increases. (i-j) Similarly, both the information encoded on <italic>H</italic> by the readout, <italic>I<sub>U,H</sub></italic>, and the feedback information, Δ<italic>I<sub>f</sub></italic>, increase upon repeated stimulations. (k) The absolute value of the internal energy flux, |<italic>J</italic><sub>int</sub>|, decreases upon stimulations, while increasing for repeated pauses when the system moves downhill in energy. Model parameters are as specified in the Methods, 〈<italic>H</italic>⟩<sub>min</sub> = 0.1, and 〈<italic>H</italic>⟩<sub>max</sub> = <italic>H</italic><sub>ref</sub> = 10.</p></caption>
<graphic xlink:href="2301.12812v6_fig3.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<p>For small <italic>σ</italic> we find that <italic>ΔΔI<sub>f</sub></italic> may become negative, indicating that a too strong storage production may ultimately impede the information-theoretic performances of the system. Moreover, producing storage molecules requires energy. We can compute the internal energy flux associated with the storage of information through <italic>S</italic> as
<disp-formula id="FD13">
<alternatives>
<mml:math display="block" id="M13"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>int</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>→</mml:mo><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>     </mml:mtext><mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>→</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math>
<graphic xlink:href="2301.12812v6_eqn13.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(13)</label>
</disp-formula>
</p>
<p>which is the total energy flux to produce the internal populations (<italic>U</italic> and <italic>S</italic>), since U always reaches equilibrium, being the fastest species at play. Its change during habituation is defined as Δ<italic>J</italic><sub>int</sub> = <inline-formula id="ID15">
<alternatives>
<mml:math display="inline" id="I15"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>int</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>hab</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq15.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> − <inline-formula id="ID16">
<alternatives>
<mml:math display="inline" id="I16"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>int</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>in</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq16.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>. In <xref ref-type="fig" rid="fig3">Fig. 3f</xref>, we show that Δ<italic>J</italic><sub>int</sub> is typically smaller than zero, hinting at a synergistic thermodynamic advantage of habituation.</p>
<p>In <xref ref-type="fig" rid="fig3">Fig. 3g-k</xref>, we show the evolution of the system for values of (<italic>β</italic>, <italic>σ</italic>) that lie in the region of maximal information gain. The readout activity decreases in time (<xref ref-type="fig" rid="fig3">Fig. 3g</xref>), due to the habituation driven by the increase of 〈S⟩ (<xref ref-type="fig" rid="fig3">Fig. 3h</xref>). In this region, both <italic>I<sub>U,H</sub></italic> and Δ<italic>I<sub>f</sub></italic> increase over time (<xref ref-type="fig" rid="fig3">Fig. 3i-j</xref>; we note that the increase in <italic>I<sub>U,H</sub></italic> is concomitant to a reduction of the population that is encoding the signal. Although this may seem surprising, we stress that the mean of <italic>U</italic> is not directly related to the factorizability of the joint distribution <italic>p<sub>U,H</sub></italic>). Finally, in <xref ref-type="fig" rid="fig3">Fig. 3k</xref> we show that the absolute value of the internal energy flux |<italic>J</italic><bold>int</bold>| in the presence of the stimulus sharply decreases as well, while increasing during its pauses (the value of <italic>J</italic><bold>int</bold> is negative in the presence of the background signal since the system is moving downhill in energy). This behavior is due to the interplay between storage and readout populations during habituation and signals the fact that the system requires progressively less energy to respond as time passes, while also moving less downhill in energy when the stimulus is paused. This observation suggests that the regime of maximal information gain supports habituation with a concurrent energetic advantage.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>FIG. 4</label>
<caption><title>Optimality at the onset of habituation and dependence on the external signal strength.</title>
<p>(a-b) Contour plots in the (<italic>β, σ</italic>) plane of the stationary mutual information <inline-formula id="ID17">
<alternatives>
<mml:math display="inline" id="I17"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq17.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, and the total dissipation of the system per unit energy, <inline-formula id="ID18">
<alternatives>
<mml:math display="inline" id="I18"><mml:mrow><mml:mi>δ</mml:mi><mml:msubsup><mml:mi>Q</mml:mi><mml:mi>R</mml:mi><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mi>int</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq18.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, in the presence of a constant signal 〈<italic>H</italic>⟩ = <italic>H</italic><sub>ref</sub> = 10. For a given value of <italic>β</italic>, the system can optimize <italic>σ</italic> to the Pareto front (black line) to simultaneously minimize energy consumption and maximize information. Below the front, the system exploits the available energy suboptimally, while the region above the front is physically inaccessible. (b) In the presence of a dynamical input switching between 〈<italic>H</italic>⟩<sub>min</sub> = 0.1 and 〈<italic>H</italic>⟩<sub>max</sub> = <italic>H</italic><sub>ref</sub>, the parameters defining the optimal front capture the region of maximal information gain corresponding to the onset of habituation, where Δ〈<italic>U</italic>⟩ starts to be significantly smaller than zero. The gray area enclosed by the dashed vertical lines indicates the location of the Pareto front for values of <italic>β</italic> <italic>∈</italic> [3 – 3.5]. (c) The Pareto front depends on the strength of the external signal 〈<italic>H</italic>⟩<sub>max</sub>. In particular, for 〈<italic>H</italic>⟩<sub>max</sub> &lt; <italic>H</italic><sub>ref</sub>, at fixed <italic>β</italic> a larger storage cost <italic>σ</italic> is needed. Conversely, for 〈<italic>H</italic>⟩<sub>max</sub> &gt; <italic>H</italic><sub>ref</sub>, an optimal system can harvest more information by producing more storage, thus exhibiting a smaller <italic>σ</italic>. (d) If we allow the system to adapt its inhibition strength <italic>κ</italic> to the stimulus (<xref ref-type="disp-formula" rid="FD16">Eq. (15)</xref>), the Pareto fronts for different external signals collapse into a single optimal curve. Model parameters are specified in the Methods.</p></caption>
<graphic xlink:href="2301.12812v6_fig4.tif" mime-subtype="tif" mimetype="image"/>
</fig>
</sec>
<sec id="s2-4">
<title>The onset of habituation and its functional role</title>
<p>As habituation, information, and their energetic cost appear to be tightly related, we now investigate whether the region of maximal information gain can be retrieved by means of an a priori optimization principle. To do so, we first focus on the case of a constant environment. We assume that the system can tune its internal parameters to optimally respond to the statistics of a prolonged external signal. Thus, we consider a fixed input statistics given by <inline-formula id="ID19">
<alternatives>
<mml:math display="inline" id="I19"><mml:msubsup><mml:mi>p</mml:mi><mml:mi>H</mml:mi><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>~</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>h</mml:mi><mml:mo>/</mml:mo><mml:msup><mml:mi>H</mml:mi><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq19.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, with H<sup>st</sup> the average signal strength.</p>
<p>When the system reaches its steady state, we compute the information that the readout has on the signal, <inline-formula id="ID20">
<alternatives>
<mml:math display="inline" id="I20"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq20.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, (<xref ref-type="fig" rid="fig4">Fig. 4a</xref>) and the total energy consumption. To this end, we must take into account two terms. First, the energy flux in <xref ref-type="disp-formula" rid="FD13">Eq. (13)</xref> represents the rate of change in energy due to the driven storage production. The energy consumption associated with this process per unit energy is <inline-formula id="ID21">
<alternatives>
<mml:math display="inline" id="I21"><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mi>int</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>int</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mo>/</mml:mo><mml:mi>σ</mml:mi></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq21.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>. Second, the inhibition pathway is also driving the receptor out of equilibrium, leading to a dissipation per unit temperature given by
<disp-formula id="FD14">
<alternatives>
<mml:math display="block" id="M14"><mml:mi>δ</mml:mi><mml:msub><mml:mi>Q</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>〈</mml:mo><mml:mrow><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>→</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>H</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>→</mml:mo><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>→</mml:mo><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>H</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>→</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>〉</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>β</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>H</mml:mi><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>κ</mml:mi><mml:mi>σ</mml:mi><mml:mfrac><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mi>S</mml:mi><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:math>
<graphic xlink:href="2301.12812v6_eqn14.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</disp-formula>
</p>
<p>We plot the total energy consumption per unit energy <inline-formula id="ID22">
<alternatives>
<mml:math display="inline" id="I22"><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mtext>tot</mml:mtext></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>δ</mml:mi><mml:msubsup><mml:mi>Q</mml:mi><mml:mi>R</mml:mi><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mi>int</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq22.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> in <xref ref-type="fig" rid="fig4">Fig. 4a</xref>. In order to understand how the system may achieve large values of mutual information while minimizing its intrinsic dissipation, we can maximize the Pareto functional [<xref ref-type="bibr" rid="c69">69</xref>, <xref ref-type="bibr" rid="c70">70</xref>]:
<disp-formula id="FD15">
<alternatives>
<mml:math display="block" id="M15"><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>σ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>γ</mml:mi><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>σ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>γ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mtext>tot</mml:mtext></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>σ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2301.12812v6_eqn15.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(14)</label>
</disp-formula>
</p>
<p>where <italic>γ</italic> ∈ [0,1] sets the strategy implemented by the system. If <italic>γ</italic> ≪ 1, the system prioritizes minimizing dissipation, whereas if <italic>γ</italic> ≈ 1 it acts to preferentially maximize information. The set of (<italic>β, σ</italic>) that maximize <xref ref-type="disp-formula" rid="FD15">Eq. (14)</xref> defines a Pareto optimal front in the <inline-formula id="ID23">
<alternatives>
<mml:math display="inline" id="I23"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mtext>tot</mml:mtext></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq23.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> space (<xref ref-type="fig" rid="fig4">Fig. 4a</xref>). At fixed energy consumption, this front represents the maximum information between the readout and the external input that can be achieved. The region below the front is therefore suboptimal. Instead, the points above the front are inaccessible, as higher values of <inline-formula id="ID24">
<alternatives>
<mml:math display="inline" id="I24"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq24.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> cannot be attained without increasing <inline-formula id="ID25">
<alternatives>
<mml:math display="inline" id="I25"><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mtext>tot</mml:mtext></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq25.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>. We note that, since <italic>β</italic> usually cannot be directly controlled by the system, the Pareto front indicates the optimal <italic>β</italic> to which the system tunes at fixed <italic>B</italic> (see Methods and Supplementary Information for details).</p>
<p>We now consider once more a system receiving a dynamically switching signal with 〈<italic>H</italic>⟩<sub>max</sub> = <italic>H</italic><sup>st</sup>. We first focus on the case <italic>H</italic><bold>ref</bold> = <italic>H</italic><sup>st</sup> , with <italic>H</italic><sub>ref</sub> the reference signal appearing in <xref ref-type="disp-formula" rid="FD55">Eq. (S28)</xref>. Remarkably, we find that the Pareto optimal front in the (<italic>β, ς</italic>) plane qualitatively corresponds to the region of maximal information gain, as we show in <xref ref-type="fig" rid="fig4">Fig. 4b</xref>. This implies that a system that has tuned its internal parameters to respond to a constant signal also learns how to respond optimally to the timevarying input of the same strength, in terms of information gain. Since the region identified by the front leads to intermediate values of Δ〈<italic>U</italic>⟩, it corresponds to the “onset of habituation”, where the system decreases its response enough to reduce the energy dissipation while storing information to increase <italic>I<sub>U,H</sub></italic>. Heuristically, the onset of habituation emerges spontaneously when the system attempts to activate its receptor as little as possible, while producing the minimum amount of storage molecules retaining enough information about the external environment.</p>
<p>In <xref ref-type="fig" rid="fig4">Fig. 4c</xref>, we then study what happens to the optimal front if 〈<italic>H</italic>⟩<sub>max</sub> is larger or smaller than the reference signal. We find that, at low 〈<italic>H</italic>⟩<sub>max</sub> , the Pareto front moves in such a way that a larger storage cost <italic>σ</italic> is needed at fixed <italic>β</italic>. This is expected since at lower signal strengths it is harder for the system to distinguish the input from the background thermal noise. Conversely, when 〈<italic>H</italic>⟩<sub>max</sub> &gt; <italic>H</italic><sub>ref</sub>, an optimal system needs to reduce <italic>σ</italic> to produce more storage and harvest information. Importantly, we find that if 〈<italic>H</italic>⟩<sub>max</sub> remains close to <italic>H</italic><sub>ref</sub>, the optimal front remains close to the onset of habituation and thus lies within the region of maximal information gain.</p>
<p>However, we can achieve a collapse of the optimal front if we allow the system to tune the inhibition strength <italic>κ</italic> to the value of the external signal, i.e.,
<disp-formula id="FD16">
<alternatives>
<mml:math display="block" id="M16"><mml:mi>κ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mi>H</mml:mi><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>max</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mi>H</mml:mi><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>max</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>α</mml:mi><mml:mi>σ</mml:mi></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:math>
<graphic xlink:href="2301.12812v6_eqn16.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(15)</label>
</disp-formula>
</p>
<p>In this way, a stronger input will correspond to a larger <italic>κ</italic>, and thus a stronger inhibition. In <xref ref-type="fig" rid="fig4">Fig. 4d</xref>, we show that the Pareto fronts obtained with this choice collapse into a single curve. Crucially, this front still corresponds to the region of maximal information gain, although the specific values of Δ<italic>I<sub>U,H</sub></italic> naturally depend 〈<italic>H</italic>⟩<sub>max</sub> (see Supplementary Information). Thus, in this scenario, a system that is capable of adapting the negative feedback to its environment is also able to always tune itself to the onset of habituation at different values of the external stimulus and without tinkering with the energy cost σ, where its responses are optimal from an information-theoretic perspective.</p>
</sec>
<sec id="s2-5">
<title>The role of information storage</title>
<p>The presence of a storage mechanism is fundamental in our model. Furthermore, its role in mediating the negative feedback is suggested by several experimental and theoretical observations [<xref ref-type="bibr" rid="c9">9</xref>, <xref ref-type="bibr" rid="c29">29</xref>–<xref ref-type="bibr" rid="c33">33</xref>]. Whenever the storage is eliminated from our model, habituation cannot take place, highlighting its key role in driving the observed dynamics (see Supplementary Information).</p>
<p>In <xref ref-type="fig" rid="fig5">Figure 5a</xref>, we show that the degree of habituation, Δ〈<italic>U</italic>⟩, and the change in the storage population, Δ〈<italic>S</italic>⟩, are deeply related to one another. The more 〈<italic>S</italic>⟩ relaxes between two consecutive signals, the less the readout population reduces its activity. This ascribes to the storage population the role of an effective memory and highlights its dynamical importance for habituation. Moreover, the dependence of the storage dynamics on the interval between consecutive signals, Δ<italic>T</italic>, influences information gain as well. Indeed, increasing Δ<italic>T</italic>, we observe a decrease of the mutual information (<xref ref-type="fig" rid="fig5">Fig. 5b</xref>) on the next stimulus. In the Supplementary Information, we further analyze the impact of different signal and pause durations.</p>
<p>We remark here that the proposed model is fully Markovian in its microscopic components, and the memory that governs readout habituation spontaneously emerges from the interplay among the internal timescales. In particular, recent works have highlighted that the storage needs to evolve on a slower timescale, comparable to that of the external input, in order to generate information in the receptor and in the readout [<xref ref-type="bibr" rid="c67">67</xref>]. To strengthen our conclusions, we remark that an instantaneous negative feedback implemented directly by <italic>U</italic> (bypassing the storage mechanism) would lead to no time-dependent modulations of the readout and thus no habituation (see Supplementary Information). Similarly, a readout population evolving on a timescale comparable to that of the signal cannot effectively mediate the negative feedback on the receptor since its population increase would not lead to habituation (see Supplementary Information). Thus, negative feedback has to be implemented by a separate degree of freedom evolving on a timescale which is slow and comparable to that of external signal.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>FIG. 5</label>
<caption><title>The role of memory in shaping habituation.</title>
<p>(a) The system response depends on the waiting time Δ<italic>T</italic> between two external signals. As Δ<italic>T</italic> increases, the storage decays, and thus memory is lost (green). Consequently, the habituation of the readout population decreases (yellow). (b) As a consequence, the information <italic>I<sub>U,H</sub></italic> that the system has on the signal <italic>H</italic> when the new stimulus arrives decays as well. Model parameters for this figure are <italic>β</italic> = 2.5, <italic>σ</italic> = 0.5 in the unit measure of the energy, and as specified in the Methods.</p></caption>
<graphic xlink:href="2301.12812v6_fig5.tif" mime-subtype="tif" mimetype="image"/>
</fig>
</sec>
<sec id="s2-6">
<title>Minimal features of neural habituation</title>
<p>In neural systems, habituation is typically measured as a progressive reduction of the stimulus-driven neuronal firing rate [<xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c15">15</xref>, <xref ref-type="bibr" rid="c53">53</xref>, <xref ref-type="bibr" rid="c54">54</xref>, <xref ref-type="bibr" rid="c59">59</xref>]. To test whether our minimal model can be used to capture the typical neural habituation dynamics, we measured the response of zebrafish larvae to repeated looming stimulations via volumetric multiphoton imaging [<xref ref-type="bibr" rid="c71">71</xref>]. From a whole-brain recording of ≈ 55000 neurons, we extracted a subpopulation of ≈ 2400 neurons in the optic tectum with a temporal activity profile that is most correlated with the stimulation protocol (see Methods).</p>
<p>Our model can be extended to qualitatively reproduce some features of the progressive decrease in neuronal response amplitudes. We identify a single readout unit with a subpopulation of binary neurons. Then, a fraction of neurons are randomly turned on each time the corresponding readout unit is activated (see Methods). We tune the model parameters to have a comparable number of total active neurons at the first stimulus with respect to the experimental setting. Moreover, we set the pause and signal durations in line with the typical timescales of the looming stimulation. We choose the model parameters <italic>β</italic> and <italic>σ</italic> in such a way that the system operates close to the peak of information gain, with an activity decrease over time that is comparable to the activity decrease in experimental data (see Supplementary Information). In this way, we can focus on the effects of storage and feedback mechanisms without modeling further biological details.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>FIG. 6</label>
<caption><title>Habituation in zebrafish larvae.</title>
<p>(a) Normalized neural activity profile in a zebrafish larva in response to the repeated presentation of visual (looming) stimulation, and comparison with the fraction of active neurons 〈<italic>N</italic><sub>act</sub>⟩ = <italic>N</italic><sub>act</sub>/<italic>N</italic> in our model with stochastic neural activation (see Methods). Stimuli are indicated with colored dots from blue to red as time increases. (b) PCA of experimental data reveals that habituation is captured mostly by the second principal component, while features of the evoked neural response are captured by the first one. Different colors indicate responses to different stimuli. (c) PCA of simulated neural activations. Although we cannot capture the dynamics of the evoked neural response with a switching input, the core features of habituation are correctly captured along the second principal component. Model parameters are <italic>β</italic> = 4.5, <italic>σ</italic> = 0.15 in energy units, and as in the Methods, so that the system is tuned to the onset of habituation.</p></caption>
<graphic xlink:href="2301.12812v6_fig6.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<p>The patterns of the model-generated activity are remarkably similar to the experimental ones (see <xref ref-type="fig" rid="fig6">Fig. 6a</xref>). We performed a 2-dimensional embedding of the the neural activity profiles of all recorded neurons via PCA (explained variance ≈ 70≈) and we plot the temporal evolution in this low-dimensional space (<xref ref-type="fig" rid="fig6">Fig. 6b</xref>). This procedure reveals that the first principal component (PC) accounts for the evoked neural response, while the second PC mostly reflects the habituation dynamics. We perform the same analysis on data generated from the model as explained above. As we see in <xref ref-type="fig" rid="fig6">Fig. 6c</xref>, the second PC encodes habituation, as in experimental data, although the neural response in the first PC is replaced by the switching on/off dynamics of the input. This shows that our model is able to capture the main features of the observed neural habituation, without the need for biological details.</p>
</sec>
</sec>
<sec id="s3" sec-type="discussion">
<title>Discussion</title>
<p>In this work, we studied a minimal architecture that serves as a microscopic and archetypal description of sensing processes across biological scales. Informed by theoretical and experimental observations, we focused on three fundamental mechanisms: a receptor, a readout population, and a storage mechanism that drives negative feedback. Despite its simplicity, we have shown that our model robustly reproduces the hallmarks associated with habituation in the presence of a single type of repeated stimulation, a widespread phenomenon in both biochemical and neural systems. By quantifying the mutual information between the external signal and readout population, we identified a regime of optimal information gain during habituation. Remarkably, the system can spontaneously tune to this region of parameters if it enforces an information-dissipation trade-off. In particular, optimal systems lie at the onset of habituation, characterized by intermediate levels of activity reduction, as both too-strong and too-weak negative feedback are detrimental to information gain. Finally, we found that, by allowing for a storage inhibition strength that can adapt to the environmental signal, this optimality is input-independent and requires no further adjustment of other internal model parameters. Our results suggest that the functional advantages of the onset of habituation are rooted in the interplay between energy dissipation and information gain, and its general features are tightly linked to the internal mechanisms to store information.</p>
<p>Although minimal, our model can capture basic features of neural habituation, where it is generally accepted that inhibitory feedback mechanisms modulate the stimulus weight [<xref ref-type="bibr" rid="c55">55</xref>]. Remarkably, recent works reported the existence of a separate inhibitory neuronal population whose activity increases during habituation [<xref ref-type="bibr" rid="c15">15</xref>]. Our model suggests that this population might play the role of a storage mechanism, allowing the system to habituate to repeated signals. However, in neural systems, a prominent role in encoding both short- and long-term information is also played by synaptic plasticity [<xref ref-type="bibr" rid="c72">72</xref>, <xref ref-type="bibr" rid="c73">73</xref>] as well as by memory molecules [<xref ref-type="bibr" rid="c42">42</xref>–<xref ref-type="bibr" rid="c44">44</xref>], at a biochemical level. A comprehensive analysis of how information is encoded and retrieved will most likely require all these mechanisms at once. Including an explicit connectivity structure with synaptic updates in our model may help in this direction, at the price of analytical tractability. Furthermore, future works may be able to compare our theoretical predictions with experiments in which the modulation of frequency [<xref ref-type="bibr" rid="c15">15</xref>] and intensity of stimulation trigger the observed hallmarks. In this way, we could elucidate the roles and features of internal processes characterizing the system under investigation, along with its information-theoretic performance. Overall, the present results hint at the fact that our minimal architecture may provide crucial insights into the functional advantages of habituation in a wide range of biological systems.</p>
<p>Extensions of these ideas are manifold. The definition of a habituated system relies, in this work as well as in other studies [<xref ref-type="bibr" rid="c57">57</xref>], on the definition of a response threshold. However, some of the hallmarks might disappear when habituation is defined as a phenomenon appearing in a time-periodic steady state. To overcome this issue, it may be necessary to extend the model to more realistic molecular schemes encompassing the presence of additional storage mechanisms. More generally, understanding the information-theoretic performance of real-world biochemical networks exhibiting habituation remains a fascinating perspective to explore. Upon these premises, the possibility of inferring the underlying biochemical structure from observed behaviors is a fascinating direction [<xref ref-type="bibr" rid="c51">51</xref>]. Furthermore, since we focused on repetitions of statistically identical signals, it will be fundamental to characterize the system’s response to diverse environments [<xref ref-type="bibr" rid="c74">74</xref>]. To this end, incorporating multiple receptors or storage populations may be needed to harvest information in complex conditions. In such scenarios, correlations between external signals may help reduce the encoding effort as, intuitively, S is acting as an information reservoir for the system. Moreover, such stored information could be used to make predictions on future stimuli and behavior [<xref ref-type="bibr" rid="c60">60</xref>–<xref ref-type="bibr" rid="c62">62</xref>]. Indeed, living systems do not passively read external signals but often act upon the environment. We believe that both storage mechanisms and their associated negative feedback will remain core modeling ingredients.</p>
<p>Our work paves the way to understanding how information is encoded and guides learning, predictions, and decision-making, a paramount question in many fields. On the one hand, it encapsulates key ingredients to support habituation while still being minimal enough to allow for analytical treatment. On the other hand, it may help the experimental quest for signatures of these physical ingredients in a variety of systems. Ultimately, our results show how habituation - a ubiquitous phenomenon taking place at strikingly different biological scales - may stem from an information-based advantage, shedding light on the optimization principle underlying its emergence and relevance for any biological system.</p>
</sec>
</body>
<back>
<sec id="s4" sec-type="methods">
<title>Methods</title>
<sec id="s4-1">
<sec id="s4-1-1">
<title>Model parameters</title>
<p>In this section, we briefly recall the free parameters of the model and the values we use in numerical simulations, unless otherwise specified. In particular, the energetic barrier (<italic>V</italic> − <italic>cr</italic>) fixes the average values of the readout population both in the passive and active state, namely 〈<italic>U</italic>⟩<sub><italic>P</italic></sub> = <italic>e<sup>−βV</sup></italic> and 〈<italic>U</italic>⟩<sub><italic>A</italic></sub> = <italic>e<sup>−β(V−c)</sup></italic> (see <xref ref-type="disp-formula" rid="FD3">Eq. (3)</xref>). Thus, we can fix hUi〈<italic>U</italic>⟩<sub><italic>A</italic></sub> and 〈<italic>U</italic>⟩<sub><italic>A</italic></sub> in lieu of <italic>V</italic> and <italic>c</italic>. Similarly, as in <xref ref-type="disp-formula" rid="FD55">Eq. (S28)</xref>, we can set the inhibiting storage fraction <italic>α</italic> to fix <italic>κ</italic>. At any rate, we remark that the emerging features of the model are qualitatively independent of the specific choice of these parameters. Furthermore, we typically consider the average of the exponentially distributed signal to be 〈<italic>H</italic>⟩<sub>max</sub> = 10 and 〈<italic>H</italic>⟩<sub>min</sub> = 0.1 (see Supplementary Information for details). Overall, we are left with <italic>β</italic> and <italic>σ</italic> as free parameters. <italic>β</italic> quantifies the amount of thermal noise in the system, and at small <italic>β</italic> the thermal activation of the receptor hinders the effect of the signal and makes the system almost unable to process information. Conversely, if <italic>β</italic> is high, the system must overcome large thermal inertia, increasing the dissipative cost. In this regime of weak thermal noise, we expect that, given a sufficient amount of energy, the system can effectively process information. In <xref ref-type="table" rid="tbl1">Table I</xref>, we summarize the specific parameter values we used throughout the main text. Other values to explore the robustness of the model are discussed in the Supplementary Information.</p>
</sec>
<sec id="s4-1-2">
<title>Timescale separation</title>
<p>We solve our system in a timescale separation framework [<xref ref-type="bibr" rid="c67">67</xref>, <xref ref-type="bibr" rid="c75">75</xref>, <xref ref-type="bibr" rid="c76">76</xref>], where the storage evolves on a timescale that is much slower than all the other internal ones, i.e.,
<disp-formula id="FD17">
<alternatives>
<mml:math display="block" id="M17"><mml:msub><mml:mi>τ</mml:mi><mml:mi>U</mml:mi></mml:msub><mml:mo>≪</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>≪</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>≈</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mo>.</mml:mo></mml:math>
<graphic xlink:href="2301.12812v6_eqn17.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</disp-formula>
</p>
<p>The fact that <italic>τ<sub>S</sub></italic> is the slowest timescale at play is crucial to making these components act as an information reservoir. This assumption is also compatible with biological examples. The main difficulty arises from the presence of the feedback, i.e. the signal influences the receptor and thus the readout population, which in turn impacts the storage population and finally changes the deactivation rate of the receptor - schematically, <italic>H</italic> → <italic>R</italic> → <italic>U</italic> → <italic>S</italic> → <italic>R</italic>, but the causal order does not reflect the temporal one.</p>
<table-wrap id="tbl1" position="float" orientation="portrait">
<label>Table I</label>
<caption><title>Summary of the model parameters and the values used for numerical simulations, unless otherwise specified. The parameters <italic>ft</italic> and <italic>a</italic> qualitatively determine the behavior of the model and are varied throughout the main text.</title></caption>
<alternatives>
<graphic xlink:href="2301.12812v6_tbl1.tif" mime-subtype="tif" mimetype="image"/>
<table frame="vsides" rules="groups">
<thead>
<tr>
<th align="center" valign="top">Parameter</th>
<th align="center" valign="top">Description</th>
<th align="center" valign="top">Value</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top"><italic>M<sub>s</sub></italic></td>
<td align="center" valign="top">Maximum number of storage units</td>
<td align="center" valign="top">30</td>
</tr>
<tr>
<td align="center" valign="top">Δ<italic>E</italic></td>
<td align="center" valign="top">Receptor energetic barrier</td>
<td align="center" valign="top">1</td>
</tr>
<tr>
<td align="center" valign="top">〈<italic>U</italic>⟩<sub><italic>P</italic></sub></td>
<td align="center" valign="top">Average readout with passive receptor</td>
<td align="center" valign="top">150</td>
</tr>
<tr>
<td align="center" valign="top">〈<italic>U</italic>⟩<sub><italic>A</italic></sub></td>
<td align="center" valign="top">Average readout with active receptor</td>
<td align="center" valign="top">0.5</td>
</tr>
<tr>
<td align="center" valign="top"><inline-formula id="ID26">
<alternatives>
<mml:math display="inline" id="I26"><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>S</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq26.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula></td>
<td align="center" valign="top">Inverse timescale of the storage</td>
<td align="center" valign="top">1</td>
</tr>
<tr>
<td align="center" valign="top"><italic>g</italic></td>
<td align="center" valign="top">Receptor’s pathways timescale ratio</td>
<td align="center" valign="top">1</td>
</tr>
<tr>
<td align="center" valign="top"><italic>α</italic></td>
<td align="center" valign="top">Inhibiting storage fraction</td>
<td align="center" valign="top">2/3</td>
</tr>
<tr>
<td align="center" valign="top"><italic>H</italic><sub>ref</sub></td>
<td align="center" valign="top">Reference signal</td>
<td align="center" valign="top">10</td>
</tr>
<tr>
<td align="center" valign="top"><italic>β</italic></td>
<td align="center" valign="top">Inverse temperature</td>
<td align="center" valign="top">-</td>
</tr>
<tr>
<td align="center" valign="top"><italic>σ</italic></td>
<td align="center" valign="top">Storage energy cost</td>
<td align="center" valign="top">-</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>We start with the master equation for the propagator <italic>P</italic> (<italic>u, r, s, h, t</italic>|<italic>u</italic><sub>0</sub>, <italic>r</italic><sub>0</sub>, <italic>s</italic><sub>0</sub>, <italic>h</italic><sub>0</sub>, <italic>t</italic><sub>0</sub>),
<disp-formula id="FD18">
<alternatives>
<mml:math display="block" id="M18"><mml:msub><mml:mo>∂</mml:mo><mml:mi>t</mml:mi></mml:msub><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>U</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>U</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>S</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>u</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>H</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>H</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mo>.</mml:mo></mml:math>
<graphic xlink:href="2301.12812v6_eqn18.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</disp-formula>
</p>
<p>We rescale the time by <italic>τ<sub>S</sub></italic> and introduce two small parameters to control the timescale separation analysis, <italic>ϵ</italic> = <italic>τ<sub>U</sub></italic>/<italic>τ<sub>R</sub></italic> and <italic>δ</italic> = <italic>τ<sub>R</sub></italic>/<italic>τ<sub>H</sub></italic>. Since <italic>τ<sub>S</sub></italic>/<italic>τ<sub>H</sub></italic> = O(1), we set it to 1 without loss of generality. We then write <italic>P</italic> = <italic>P</italic><sup>(0)</sup> + <italic>ϵP</italic><sup>(1)</sup> and expand the master equation to find <inline-formula id="ID27">
<alternatives>
<mml:math display="inline" id="I27"><mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>Π</mml:mi></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq27.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, with <inline-formula id="ID28">
<alternatives>
<mml:math display="inline" id="I28"><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>U</mml:mi></mml:msub><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq28.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>. We obtain that n obeys the following equation:
<disp-formula id="FD19">
<alternatives>
<mml:math display="block" id="M19"><mml:msub><mml:mo>∂</mml:mo><mml:mi>t</mml:mi></mml:msub><mml:mo>∏</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>δ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>S</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>u</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>H</mml:mi></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>∏</mml:mo><mml:mo>.</mml:mo></mml:math>
<graphic xlink:href="2301.12812v6_eqn19.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</disp-formula>
</p>
<p>Yet again, Π = Π<sup>(0)</sup> + δΠ<sup>(1)</sup> allows us to write Π<sup>(0)</sup> = <inline-formula id="ID29">
<alternatives>
<mml:math display="inline" id="I29"><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq29.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> at order <italic>O(δ</italic><sup>−1</sup>), where <inline-formula id="ID30">
<alternatives>
<mml:math display="inline" id="I30"><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq30.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>. Expanding first in <italic>ϵ</italic> and then in <italic>δ</italic> sets a hierarchy among timescales. Crucially, due to the feedback present in the system, we cannot solve the next order explicitly to find <italic>F</italic>. Indeed, after a marginalization over <italic>r</italic>, we find <italic>∂<sub>t</sub>F</italic> = [<italic>Ŵ<sub>H</sub></italic> + <italic>Ŵ<sub>S</sub></italic> (<italic>ū</italic>(<italic>s, h</italic>))] <italic>F</italic>, at order <italic>O</italic>(1), where <italic>ū(s, h)</italic> = <inline-formula id="ID31">
<alternatives>
<mml:math display="inline" id="I31"><mml:mstyle displaystyle="true"><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mi>u</mml:mi></mml:mstyle><mml:mtext>  </mml:mtext><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq31.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>. Hence, the evolution operator for <italic>F</italic> depends manifestly on <italic>s</italic>, and the equation cannot be self-consistently solved. To tackle the problem, we first discretize time, considering a small interval, i.e., <italic>t</italic> = <italic>t</italic><sub>0</sub> + Δ<italic>t</italic> with Δ<italic>t</italic> ≪ <italic>τ<sub>u</sub></italic> and thus <italic>ū(s, h)</italic> ≈ <italic>u</italic><sub>0</sub>. We thus find <italic>F</italic>(<italic>s, h,t</italic>|<italic>s</italic><sub>0</sub>, <italic>h</italic><sub>0</sub>, <italic>t</italic><sub>0</sub>) = <italic>P</italic>(<italic>s, t</italic>|<italic>s</italic><sub>0</sub>, <italic>t</italic><sub>0</sub>)<italic>P<sub>H</sub></italic>(<italic>h, t</italic>|<italic>h</italic><sub>0</sub>, <italic>t</italic><sub>0</sub>) in the domain <italic>t</italic> ∈ [<italic>t</italic><sub>0</sub>, <italic>t</italic><sub>0</sub> + Δ<italic>t</italic>], since <italic>H</italic> evolves independently from the system (see also Supplementary Information for analytical steps).</p>
<p>Iterating the procedure for multiple time steps, we end up with a recursive equation for the joint probability <italic>p<sub>U,R,S,H</sub></italic> (<italic>u, r, s, h, t</italic><sub>0</sub> + Δ<italic>t</italic>). We are interested in the following marginalization
<disp-formula id="FD20">
<alternatives>
<mml:math display="block" id="M20"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mn>1</mml:mn></mml:munderover><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mi>∞</mml:mi></mml:msubsup><mml:mrow><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mi>u</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mi>∞</mml:mi></mml:munderover><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>→</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msup><mml:mi>u</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>u</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math>
<graphic xlink:href="2301.12812v6_eqn20.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</disp-formula>
</p>
<p>where <italic>P(s<sup>‣</sup>, t</italic> → <italic>s,t</italic> + Δ<italic>t</italic>) is the propagator of the storage at fixed readout. This is the Chapman-Kolmogorov equation in the timescale separation approximation. Notice that this solution requires the knowledge of <italic>p<sub>U,S</sub></italic> at the previous time-step and it has to be solved iteratively.</p>
</sec>
<sec id="s4-1-3">
<title>Explicit solution for the storage propagator</title>
<p>To find a numerical solution to our system, we first need to compute the propagator <italic>P(s</italic><sub>0</sub>, <italic>t</italic><sub>0</sub> → <italic>s,t</italic>). Formally, we have to solve the master equation
<disp-formula id="FD21">
<alternatives>
<mml:math display="block" id="M21"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mo>∂</mml:mo><mml:mi>t</mml:mi></mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>→</mml:mo><mml:mi>s</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>S</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mi>σ</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>→</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>         </mml:mtext><mml:mo>+</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>→</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>         </mml:mtext><mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>→</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mi>σ</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math>
<graphic xlink:href="2301.12812v6_eqn21.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</disp-formula>
</p>
<p>where we used the shorthand notation <italic>P(s</italic><sub>0</sub> → <italic>s</italic>) = (<italic>s</italic><sub>0</sub>, <italic>t</italic><sub>0</sub> → <italic>s, t</italic>). Since our formula has to be iterated for small timesteps, i.e., <italic>t</italic> − <italic>t</italic><sub>0</sub> = Δ<italic>t</italic> ≪ 1, we can write the propagator as follows
<disp-formula id="FD22">
<alternatives>
<mml:math display="block" id="M22"><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>→</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mo>|</mml:mo><mml:mi>U</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>ν</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>ν</mml:mi></mml:msub><mml:msup><mml:mi>a</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>ν</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>ν</mml:mi></mml:msub><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math>
<graphic xlink:href="2301.12812v6_eqn22.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</disp-formula>
</p>
<p>where <italic>w<sub>v</sub></italic> and <italic>λ<sub>v</sub></italic> are respectively eigenvectors and eigenvalues of the transition matrix <italic>Ŵ<sub>S</sub></italic> (<italic>u</italic><sub>0</sub>),
<disp-formula id="FD23">
<alternatives>
<mml:math display="block" id="M23"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>S</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mi>σ</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mtext>  if </mml:mtext><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>S</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>j</mml:mi><mml:mtext>    if </mml:mtext><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mi>j</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>S</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mtext>    otherwise</mml:mtext></mml:mtd></mml:mtr></mml:mtable></mml:math>
<graphic xlink:href="2301.12812v6_eqn23.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</disp-formula>
</p>
<p>and the coefficients <italic>a<sup>(v)</sup></italic> are such that
<disp-formula id="FD24">
<alternatives>
<mml:math display="block" id="M24"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mo>|</mml:mo><mml:mi>U</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>→</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mo>|</mml:mo><mml:mi>U</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>ν</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>ν</mml:mi></mml:msub><mml:msup><mml:mi>a</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>ν</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mstyle><mml:mo>=</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:math>
<graphic xlink:href="2301.12812v6_eqn24.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</disp-formula>
</p>
<p>Since eigenvalues and eigenvectors of <italic>Ŵ<sub>S</sub></italic>(<italic>u</italic><sub>0</sub>) might be computationally expensive to find, we employ another simplification. As Δ<italic>t</italic> → 0, we can restrict the matrix only to jumps to the n-th nearest neighbors of the initial state (<italic>s</italic><sub>0</sub>, <italic>t</italic><sub>0</sub>), assuming that all other states are left unchanged in small time intervals. We take <italic>n</italic> = 2 and check the accuracy of this approximation against the full simulation for a limited number of timesteps.</p>
</sec>
<sec id="s4-1-4">
<title>Mean-field relationship</title>
<p>We note that hUi and hSi satisfies the following mean-field relationship:
<disp-formula id="FD25">
<alternatives>
<mml:math display="block" id="M25"><mml:mfrac><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mi>S</mml:mi><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:math>
<graphic xlink:href="2301.12812v6_eqn25.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S1)</label>
</disp-formula>
</p>
<p>where <italic>f</italic><sub>0</sub>(<italic>x</italic>) is an analytical function of its argument (see Supplementary Information). <xref ref-type="disp-formula" rid="FD25">Eq. (S1)</xref> clearly states that only the fraction of active storage units is relevant to determining the habituation dynamics.</p>
</sec>
<sec id="s4-1-5">
<title>Mutual information</title>
<p>Once we have <italic>p<sub>U</sub></italic> (<italic>u, t</italic>) (obtained marginalizing <italic>p<sub>U,S</sub></italic> over <italic>s</italic>) for a given <italic>p<sub>H</sub></italic> (<italic>h, t</italic>), we can compute the mutual information
<disp-formula id="FD26">
<alternatives>
<mml:math display="block" id="M26"><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>H</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>U</mml:mi></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mi>∞</mml:mi></mml:msubsup><mml:mrow><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:math>
<graphic xlink:href="2301.12812v6_eqn26.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</disp-formula>
</p>
<p>where <italic><bold>H</bold></italic> is the Shannon entropy. For the sake of simplicity, we consider that the external signal follows an exponential distribution <italic>p<sub>H</sub></italic>(<italic>h,t</italic>) = <italic>λ</italic>(<italic>t</italic>)<italic>e</italic><sup><italic>−λ(t)h</italic></sup>. Notice that, in order to determine such quantity, we need the conditional probability <italic>p<sub>U|H</sub></italic>(<italic>u, t</italic>). In the Supplementary Information, we show how all the necessary joint and conditional probability distributions can be computed from the dynamical evolution derived above.</p>
<p>We also highlight here that the timescale separation implies <italic>I<sub>S,H</sub></italic> = 0, since
<disp-formula id="FD27">
<alternatives>
<mml:math display="block" id="M27"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>u</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>     </mml:mtext><mml:mo>=</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>u</mml:mi></mml:munder><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>r</mml:mi></mml:munder><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>     </mml:mtext><mml:mo>=</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math>
<graphic xlink:href="2301.12812v6_eqn27.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</disp-formula>
</p>
<p>Although it may seem surprising, this is a direct consequence of the fact that <italic>S</italic> is only influenced by <italic>H</italic> through the stationary state of <italic>U</italic>. Crucially, the presence of the feedback is still fundamental in promoting habituation. Indeed, we can always write the mutual information between the signal <italic>H</italic> and both the readout <italic>U</italic> and the storage S together as <italic>I<sub>(U,S),H</sub></italic> = <italic>ΔI<sub>f</sub></italic> + <italic>I<sub>U,H</sub></italic>, where Δ<italic>I<sub>f</sub></italic> = <italic>I<sub>(U,S),H</sub></italic> − <italic>I<sub>U,H</sub></italic> = <italic>I<sub>(U,H), S</sub></italic> − <italic>I<sub>U,S</sub></italic>. Since Δ<italic>I<sub>f</sub></italic> &gt; 0 (by standard information-theoretic inequalities), the storage is increasing the information of the two populations together on the external signal. Overall, although <italic>S</italic> and <italic>H</italic> are independent in this limit, the feedback is paramount in shaping how the system responds to the external signal and stores information about it.</p>
</sec>
<sec id="s4-1-6">
<title>Pareto optimization</title>
<p>We perform a Pareto optimization at stationarity in the presence of a prolonged stimulation. We seek the optimal values of (<italic>β, σ</italic>) by maximizing the functional in <xref ref-type="disp-formula" rid="FD15">Eq. (14)</xref> of the main text. Hence, we maximize the information between the readout and the signal, simultaneously minimizing the dissipation of the receptor induced by both the signal and feedback process and the dissipation associated with storage production, as discussed in the main text. The dissipative contributions have been computed per unit energy to be comparable with the mutual information. In the Supplementary Information, we detailed the derivation of the Pareto front and investigate the robustness of this optimization strategy.</p>
</sec>
<sec id="s4-1-7">
<title>Recording of whole brain neuronal activity in zebrafish larvae</title>
<p>Acquisitions of the zebrafish brain activity were carried out in one Elavl3:H2BGCaMP6s larvae at 5 days post fertilization raised at 28°C on a 12 h light/12 h dark cycle according to the approval by the Ethical Committee of the University of Padua (61/2020 dal Maschio). The subject was embedded in 2 percent agarose gel and brain activity was recorded using a multiphoton system with a custom 3D volumetric acquisition module. Data were acquired at 30 frames per second covering an effective field of view of about 450 × 900μm with a resolution of 512 × 1024 pixels. The volumetric module acquires a volume of about 180 – 200μm in thickness encompassing 30 planes separated by about 7μm, at a rate of 1 volume per second, sufficient to track the slow dynamics associated with the fluorescence-based activity reporter GCaMP6s. Visual stimulation was presented in the form of a looming stimulus with 150s intervals, centered with the fish eye (see Supplementary Information). Neurons identification and anatomical registrations were performed as described in [<xref ref-type="bibr" rid="c71">71</xref>].</p>
</sec>
<sec id="s4-1-8">
<title>Data analysis</title>
<p>The acquired temporal series were first processed using an automatic pipeline, including motion artifact correction, temporal filtering with a 3s rectangular window, and automatic segmentation. The obtained dataset was manually curated to resolve segmentation errors or to integrate cells not detected automatically. We fit the activity profiles of about 55000 cells with a linear regression model using a set of base functions representing the expected responses to each stimulation event. These base functions have been obtained by convolving the exponentially decaying kernel of the GCaMP signal lifetime with square waveforms characterizing the presentation of the corresponding visual stimulus. The resulting score coefficients of the fit were used to extract the cells whose score fell within the top 5% of the distribution, resulting in a population of ≈ 2400 neurons whose temporal activity profile correlates most with the stimulation protocol. The resulting fluorescence signals <italic>F<sup>(i)</sup></italic> were processed by removing a moving baseline to account for baseline drifting and fast oscillatory noise [<xref ref-type="bibr" rid="c77">77</xref>]. See Supplementary Information.</p>
</sec>
<sec id="s4-1-9">
<title>Model for neural activity</title>
<p>Here, we describe how our framework is modified to mimic neural activity. Each readout unit, <italic>u</italic>, is interpreted as a population of <italic>N</italic> neurons, i.e., a region dedicated to the sensing of a specific input. When a readout population is activated at time <italic>t</italic>, each of its <italic>N</italic> neurons fires with a probability <italic>p</italic>. We set <italic>N</italic> = 20 and <italic>p</italic> = 0.5. <italic>N</italic> has been set to have the same number of observed neurons in data and simulations, while <italic>p</italic> only controls the dispersal of the points in <xref ref-type="fig" rid="fig6">Fig. 6c</xref>, thus not altering the main message. The dynamics of each readout unit follows our dynamical model. Due to habituation, some of the readout units activated by the first stimulus will not be activated by subsequent stimuli. Although the evoked neural response cannot be captured by this extremely simple model, its archetypal ingredients (dissipation, storage, and feedback) are informative enough to reproduce the low-dimensional habituation dynamics found in experimental data.</p>
</sec>
</sec>
</sec>
<sec id="s5">
<title>Supplementary Information</title>
<sec id="s5-1">
<title>S1. Detailed Solution of the Master Equation</title>
<p>Consider the transition rates introduced in the main text:
<disp-formula id="FD28">
<alternatives>
<mml:math display="block" id="M28"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>→</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>H</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>β</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>−</mml:mo><mml:mi>Δ</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mtext>  </mml:mtext><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mo>→</mml:mo><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>H</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>→</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mi>Δ</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mtext>   </mml:mtext><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>→</mml:mo><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mi>β</mml:mi><mml:mi>κ</mml:mi><mml:mi>σ</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>u</mml:mi><mml:mo>→</mml:mo><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>V</mml:mi><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>U</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mtext> </mml:mtext><mml:msub><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>→</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>U</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>→</mml:mo><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mi>σ</mml:mi></mml:mrow></mml:msup><mml:mi>u</mml:mi><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>S</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mtext>  </mml:mtext><mml:msub><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>→</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>S</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math>
<graphic xlink:href="2301.12812v6_eqn28.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</disp-formula>
</p>
<p>We set a reflective boundary for the storage at <italic>s</italic> = <italic>N<sub>S</sub></italic>, corresponding to the maximum amount of storage molecules in the system. Moreover, for the sake of simplicity, we take <inline-formula id="ID32">
<alternatives>
<mml:math display="inline" id="I32"><mml:mrow><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>I</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>R</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq32.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>. Retracing the steps of the Methods, the master equation governing the evolution of the propagator of all variables, <italic>P</italic>(<italic>u, r, s, h, t</italic>|<italic>u</italic><sub>0</sub>, <italic>r</italic><sub>0</sub>, <italic>s</italic><sub>0</sub>, <italic>h</italic><sub>0</sub>, <italic>t</italic><sub>0</sub>), is:
<disp-formula id="FD29">
<alternatives>
<mml:math display="block" id="M29"><mml:msub><mml:mo>∂</mml:mo><mml:mi>t</mml:mi></mml:msub><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>U</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>U</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>S</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>u</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>H</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>H</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mo>.</mml:mo></mml:math>
<graphic xlink:href="2301.12812v6_eqn29.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S2)</label>
</disp-formula>
</p>
<p>We solve this equation employing a timescale separation, i.e., <italic>τ<sub>U</sub></italic> ≪ <italic>τ<sub>R</sub></italic> ≪ <italic>τ<sub>S</sub></italic> ~ <italic>τ<sub>H</sub></italic>, where <inline-formula id="ID33">
<alternatives>
<mml:math display="inline" id="I33"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>X</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>X</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq33.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> for <italic>X = U, R, S</italic> and <italic>τ<sub>H</sub></italic> is the typical timescale of the signal dynamics. Motivated by several biological examples, we assumed that the readout population undergoes the fastest dynamics, while storage and signal evolution are the slowest ones. Defining <italic>∊</italic> = <italic>τ<sub>U</sub></italic>/<italic>τ<sub>R</sub></italic> and <italic>δ</italic> = <italic>τ<sub>R</sub></italic>/<italic>τ<sub>H</sub></italic>, and setting <italic>τ<sub>S</sub></italic>/<italic>τ<sub>H</sub></italic> = 1 without loss of generality, we have:
<disp-formula id="FD30">
<alternatives>
<mml:math display="block" id="M30"><mml:msub><mml:mo>∂</mml:mo><mml:mi>t</mml:mi></mml:msub><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>ε</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>δ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>U</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mi>δ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>S</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>u</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>H</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>H</mml:mi></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mo>.</mml:mo></mml:math>
<graphic xlink:href="2301.12812v6_eqn30.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S3)</label>
</disp-formula>
</p>
<p>We propose a solution in the following form, <italic>P</italic> = <italic>P</italic><sup>(0)</sup> + <italic>∊P</italic><sup>(1)</sup>. By inserting this expression in the equation above, and solving order by order in <italic>∊</italic>, at order <italic>∊</italic><sup>−1</sup>, we have that:
<disp-formula id="FD31">
<alternatives>
<mml:math display="block" id="M31"><mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∏</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2301.12812v6_eqn31.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S4)</label>
</disp-formula>
</p>
<p>where <italic>p</italic><sup>st</sup> solves the master equation for the readout evolution at a fixed <italic>r</italic>:
<disp-formula id="FD32">
<alternatives>
<mml:math display="block" id="M32"><mml:mn>0</mml:mn><mml:mo>=</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mi>α</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>u</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2301.12812v6_eqn32.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S5)</label>
</disp-formula>
</p>
<p>with <italic>α(r)</italic> = <italic>e<sup>−α(V − cr)</sup></italic>. Hence,
<disp-formula id="FD33">
<alternatives>
<mml:math display="block" id="M33"><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>α</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mfrac><mml:mrow><mml:mi>α</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>u</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mo>!</mml:mo></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:math>
<graphic xlink:href="2301.12812v6_eqn33.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S6)</label>
</disp-formula>
</p>
<p>At order <italic>∊</italic><sup>0</sup>, we find the equation for Π, also reported in the Methods:
<disp-formula id="FD34">
<alternatives>
<mml:math display="block" id="M34"><mml:msub><mml:mo>∂</mml:mo><mml:mi>t</mml:mi></mml:msub><mml:mo>∏</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>δ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>S</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>u</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>H</mml:mi></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>∏</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:math>
<graphic xlink:href="2301.12812v6_eqn34.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S7)</label>
</disp-formula>
</p>
<p>To solve this equation, we propose a solution of the form Π = Π<sup>(0)</sup> + <italic>δ</italic>Π<sup>(1)</sup>. Hence, again, at order <italic>δ</italic><sup>−1</sup>, we have that <inline-formula id="ID34">
<alternatives>
<mml:math display="inline" id="I34"><mml:mrow><mml:msup><mml:mi>Π</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq34.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, where <inline-formula id="ID35">
<alternatives>
<mml:math display="inline" id="I35"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq35.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> satisfy the steady-state equation for the fastest degree of freedom, with all the others fixed. In the case, it is just the solution of the rate equation for the receptor:
<disp-formula id="FD35">
<alternatives>
<mml:math display="block" id="M35"><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>→</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>→</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>→</mml:mo><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2301.12812v6_eqn35.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S8)</label>
</disp-formula>
</p>
<p>where <inline-formula id="ID36">
<alternatives>
<mml:math display="inline" id="I36"><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>→</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>→</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>→</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>H</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq36.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, and the same for the reverse reaction. At order <italic>δ</italic><sup>−1</sup>, we have an equation for <italic>F</italic>:
<disp-formula id="FD36">
<alternatives>
<mml:math display="block" id="M36"><mml:msub><mml:mo>∂</mml:mo><mml:mi>t</mml:mi></mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>S</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>u</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>H</mml:mi></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math>
<graphic xlink:href="2301.12812v6_eqn36.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S9)</label>
</disp-formula>
</p>
<p>As already explained in the Methods, due to the feedback, this equation cannot be solved explicitly. Indeed, the operator governing the evolution of F is:
<disp-formula id="FD37">
<alternatives>
<mml:math display="block" id="M37"><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>H</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>u</mml:mi></mml:munder><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>H</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>S</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>u</mml:mi></mml:munder><mml:mrow><mml:mi>u</mml:mi><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>H</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>S</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2301.12812v6_eqn37.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S10)</label>
</disp-formula>
</p>
<p>with <inline-formula id="ID37">
<alternatives>
<mml:math display="inline" id="I37"><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:msub><mml:mo>∑</mml:mo><mml:mi>r</mml:mi></mml:msub><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq37.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> and using the linearity of <italic>Ŵ<sub>S</sub>(u)</italic>. In order to solve this equation, we shall assume that <italic>ū(s, h)</italic> = <italic>u</italic><sub>0</sub>, bearing in mind that this approximation holds if <italic>t</italic> is small enough, i.e., <italic>t</italic> = <italic>t</italic><sub>0</sub> + Δ<italic>t</italic> with Δ<italic>t</italic> ≪ <italic>τ<sub>u</sub></italic>. Therefore, for a small interval, we have:
<disp-formula id="FD38">
<alternatives>
<mml:math display="block" id="M38"><mml:msub><mml:mo>∂</mml:mo><mml:mi>t</mml:mi></mml:msub><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>S</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>H</mml:mi></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2301.12812v6_eqn38.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S11)</label>
</disp-formula>
</p>
<p>Overall, we end up with the following joint probability of the model at time <italic>t</italic><sub>0</sub> + Δ<italic>t</italic>:
<disp-formula id="FD39">
<alternatives>
<mml:math display="block" id="M39"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mtext>             </mml:mtext><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mstyle displaystyle="true"><mml:mrow><mml:mo>∫</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:msub><mml:mi>P</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>   </mml:mtext><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math>
<graphic xlink:href="2301.12812v6_eqn39.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S12)</label>
</disp-formula>
</p>
<p>where ∫ <italic>dh</italic><sub>0</sub><italic>P<sub>H</sub></italic>(<italic>h, t</italic><sub>0</sub> + Δ<italic>t</italic>|<italic>h</italic><sub>0</sub>, <italic>t</italic><sub>0</sub>)<italic>p<sub>U,S,H</sub></italic>(<italic>u</italic><sub>0</sub>, <italic>s</italic><sub>0</sub>, <italic>h</italic><sub>0</sub>, <italic>t</italic><sub>0</sub>) = <italic>p<sub>U,S</sub></italic>(<italic>u</italic><sub>0</sub>, <italic>s</italic><sub>0</sub>, <italic>t</italic><sub>0</sub>)<italic>p<sub>H</sub></italic>(<italic>h, t</italic><sub>0</sub> + Δ<italic>t</italic>) since <italic>H</italic> at time <italic>t</italic><sub>0</sub> + Δ<italic>t</italic> is independent of <italic>S</italic> and <italic>U</italic>. When propagating the evolution through intervals of duration Δ<italic>t</italic>, we also assume that <italic>H</italic> evolves independently since it is an external variable, while affecting the evolution of the other degrees of freedom. This structure reflects into the equation above. For simplicity, we prescribe <italic>p<sub>H</sub></italic>(<italic>h, t</italic>) to be an exponential distribution, <italic>p<sub>H</sub></italic>(<italic>h, t</italic>) = <italic>λ(t)e<sup>−λ(t)h</sup></italic>, and solve iteratively <xref ref-type="disp-formula" rid="FD39">Eq. (S12)</xref> from <italic>t</italic><sub>0</sub> to a given <italic>T</italic> in steps of duration Δ<italic>t</italic>, as indicated above. This complex iterative solution arises from the timescale separation because of the cyclic feedback structure: {<italic>S, H</italic>} → <italic>R</italic> → <italic>U</italic> → <italic>S</italic>. This solution corresponds explicitly to
<disp-formula id="FD40">
<alternatives>
<mml:math display="block" id="M40"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mn>1</mml:mn></mml:munderover><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mi>∞</mml:mi></mml:msubsup><mml:mrow><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mi>u</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mi>∞</mml:mi></mml:munderover><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>→</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msup><mml:mi>u</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>u</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>s</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math>
<graphic xlink:href="2301.12812v6_eqn40.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S13)</label>
</disp-formula>
</p>
<p>where <italic>P</italic>(<italic>s</italic><sup>′</sup>, <italic>t</italic> → <italic>s, t</italic> + Δ<italic>t</italic>) is the propagator of the storage at fixed readout. This is the Chapman-Kolmogorov equation in the time-scale separation approximation. Notice that this solution requires the knowledge of <italic>p<sub>U,S</sub></italic> at the previous time-step and it has to be solved iteratively. Both <italic>p<sub>U</sub></italic> and <italic>p<sub>S</sub></italic> can be obtained by an immediate marginalization.</p>
<p>As detailed in the Methods, the propagator <italic>P</italic>(<italic>s</italic><sub>0</sub>, <italic>t</italic><sub>0</sub> → <italic>s, t</italic>), when restricted to small time intervals, can be obtained by solving the birth-and-death process for storage molecules at fixed readout, limiting the state space only to n nearest neighbors (we checked that our results are robust increasing n for the selected simulation time step).</p>
</sec>
<sec id="s5-2">
<title>S2. Information-Theoretic Quantities</title>
<p>By direct marginalization of <xref ref-type="disp-formula" rid="FD40">Eq. (S13)</xref>, we obtain the evolution of <italic>p<sub>U</sub></italic> (<italic>u, t</italic>) and <italic>p<sub>S</sub></italic> (<italic>s, t</italic>) for a given <italic>p<sub>H</sub></italic> (<italic>h, t</italic>). Hence, we can compute the mutual information as follows:
<disp-formula id="FD41">
<alternatives>
<mml:math display="block" id="M41"><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>H</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>U</mml:mi></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mi>∞</mml:mi></mml:msubsup><mml:mrow><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:mtext> </mml:mtext><mml:msub><mml:mi>p</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>Δ</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>U</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>B</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:math>
<graphic xlink:href="2301.12812v6_eqn41.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S14)</label>
</disp-formula>
</p>
<p>where <italic><bold>H</bold></italic>[<italic>pX</italic>] is the Shannon entropy of <italic>X</italic>, and Δ<italic>𝕊<sub>U</sub></italic> is the reduction in the entropy of <italic>U</italic> due to repeated measurement (see main text). Notice that, in order to determine such quantity, we need the conditional probability <italic>p<sub>U|H</sub></italic>(<italic>u, t</italic>). This distribution represent the probability that, at a given time, the system jumps at a value <italic>u</italic> in the presence of a given signal <italic>h</italic>. In order to compute it, we can write
<disp-formula id="FD42">
<alternatives>
<mml:math display="block" id="M42"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mn>1</mml:mn></mml:munderover><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math>
<graphic xlink:href="2301.12812v6_eqn42.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S15)</label>
</disp-formula>
</p>
<p>by definition. The only dependence on <italic>h</italic> enters in <inline-formula id="ID38">
<alternatives>
<mml:math display="inline" id="I38"><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq38.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> through the <italic>e<sup>βh</sup></italic> dependence in the rates.</p>
<p>Analogously, all the other mutual information can be obtained. As we showed in the Methods, although <italic>I<sub>S,H</sub></italic> = 0 due to the time-scale separation, the presence of the feedback is still fundamental to effectively process information about the signal. This effect can be quantified through the feedback information Δ<italic>I</italic><sub>f</sub> = <italic>I</italic><sub>(<italic>U,S</italic>), H</sub> − <italic>I<sub>U,H</sub></italic> &gt; 0, as it captures how much the knowledge of <italic>S</italic> and <italic>U</italic> together helps to encode information about the signal with respect to <italic>U</italic> alone. In terms of system entropy, we equivalently have:
<disp-formula id="FD43">
<alternatives>
<mml:math display="block" id="M43"><mml:msub><mml:mi>k</mml:mi><mml:mi>B</mml:mi></mml:msub><mml:mi>Δ</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>Δ</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>U</mml:mi></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:math>
<graphic xlink:href="2301.12812v6_eqn43.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S16)</label>
</disp-formula>
</p>
<p>that highlights how much the effect of <italic>S</italic> (feedback) reduces the entropy of the system due to repeated measurements. In practice, in order to evaluate <italic>I<sub>(U,S),H</sub></italic>, we exploit the following equality:
<disp-formula id="FD44">
<alternatives>
<mml:math display="block" id="M44"><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>H</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mi>∞</mml:mi></mml:msubsup><mml:mrow><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle><mml:mo>.</mml:mo></mml:math>
<graphic xlink:href="2301.12812v6_eqn44.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S17)</label>
</disp-formula>
</p>
<p>for which we need <italic>p<sub>U,S|H</sub></italic>. It can be obtained by noting that
<disp-formula id="FD45">
<alternatives>
<mml:math display="block" id="M45"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:mo>∫</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>r</mml:mi></mml:munder><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:mstyle></mml:math>
<graphic xlink:href="2301.12812v6_eqn45.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S18)</label>
</disp-formula>
</p>
<p>from which we immediately see that
<disp-formula id="FD46">
<alternatives>
<mml:math display="block" id="M46"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mn>1</mml:mn></mml:munderover><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math>
<graphic xlink:href="2301.12812v6_eqn46.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S19)</label>
</disp-formula>
</p>
<p>that can be easily computed at any given time <italic>t</italic>.</p>
</sec>
<sec id="s5-3">
<title>S3. Mean-Field Relation between Average Readout and Storage</title>
<p>Fixing all model parameters, the average value of storage, 〈<italic>S</italic>⟩, and readout, 〈<italic>U</italic>⟩, is numerically determined by solving iteratively the system, as shown above. However, an analytical relation between these two quantities can be found starting from the definition of 〈<italic>U</italic>⟩:
<disp-formula id="FD47">
<alternatives>
<mml:math display="block" id="M47"><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mi>u</mml:mi><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mi>u</mml:mi><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>P</mml:mi><mml:mi>S</mml:mi><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mi>u</mml:mi><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>P</mml:mi><mml:mi>S</mml:mi><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math>
<graphic xlink:href="2301.12812v6_eqn47.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S20)</label>
</disp-formula>
</p>
<p>Then, inserting the expression for the stationary probability that we know analytically:
<disp-formula id="FD48">
<alternatives>
<mml:math display="block" id="M48"><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>s</mml:mi></mml:munder><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>〉</mml:mo></mml:mrow><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>〈</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>〉</mml:mo></mml:mrow><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>P</mml:mi><mml:mi>S</mml:mi><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math>
<graphic xlink:href="2301.12812v6_eqn48.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S21)</label>
</disp-formula>
</p>
<p>where <inline-formula id="ID39">
<alternatives>
<mml:math display="inline" id="I39"><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:msub><mml:mi>P</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:mo>≡</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq39.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> has a complicated expression involving the hypergeometric function <sub>2</sub><italic>F</italic><sub>1</sub> in terms of model parameters and only the fraction of active <italic>S</italic>, <italic>ρ<sub>S</sub></italic> = <italic>s/N<sub>S</sub></italic> (the explicit derivation of this formula is not shown here). Then, we have:
<disp-formula id="FD49">
<alternatives>
<mml:math display="block" id="M49"><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>s</mml:mi></mml:munder><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mi>V</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mi>f</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>ρ</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>V</mml:mi><mml:mo>−</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>P</mml:mi><mml:mi>S</mml:mi><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math>
<graphic xlink:href="2301.12812v6_eqn49.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S22)</label>
</disp-formula>
</p>
<p>Since we do not have an analytical expression for <inline-formula id="ID40">
<alternatives>
<mml:math display="inline" id="I40"><mml:msubsup><mml:mi>P</mml:mi><mml:mi>S</mml:mi><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq40.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, we employ the mean-field approximation, reducing all the correlation functions to products of averages:
<disp-formula id="FD50">
<alternatives>
<mml:math display="block" id="M50"><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>V</mml:mi><mml:mo>−</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mi>V</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mi>f</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>β</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2301.12812v6_eqn50.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S23)</label>
</disp-formula>
</p>
<p>where <inline-formula id="ID41">
<alternatives>
<mml:math display="inline" id="I41"><mml:msub><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>〈</mml:mo><mml:mi>S</mml:mi><mml:mo>〉</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq41.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>. This clearly shows that, given a set of model parameters, 〈<italic>U</italic>⟩ and the average fraction of storage molecules, <inline-formula id="ID42">
<alternatives>
<mml:math display="inline" id="I42"><mml:msub><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>S</mml:mi></mml:msub></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq42.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> are related. In particular, introducing the change of parameters presented in the Methods, we have the following collapse:
<disp-formula id="FD51">
<alternatives>
<mml:math display="block" id="M51"><mml:mfrac><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mi>A</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mi>A</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mi>P</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2301.12812v6_eqn51.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S24)</label>
</disp-formula>
</p>
<p>where 〈<italic>U</italic>⟩<sub><italic>A</italic></sub> and 〈<italic>U</italic>⟩<sub><italic>P</italic></sub> are respectively the average of <italic>U</italic> fixing <italic>r</italic> = 1 (active receptor) and <italic>r</italic> = 0 (passive receptor). It is also possible to perform an expansion of <italic>f</italic><sub>0</sub> which numerically results to be very precise:
<disp-formula id="FD52">
<alternatives>
<mml:math display="block" id="M52"><mml:mfrac><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mi>A</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mi>A</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mi>P</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>z</mml:mi></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>H</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>g</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mo>/</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>β</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mrow><mml:mi>H</mml:mi><mml:mo>/</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:math>
<graphic xlink:href="2301.12812v6_eqn52.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S25)</label>
</disp-formula>
</p>
<p>where <inline-formula id="ID43">
<alternatives>
<mml:math display="inline" id="I43"><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>β</mml:mi><mml:mi>Δ</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>g</mml:mi><mml:mtext>  </mml:mtext><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>β</mml:mi><mml:msub><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>S</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mi>α</mml:mi><mml:mi>λ</mml:mi><mml:mi>H</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq43.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>. Since all these relations just depend on the average fraction of storage molecules, it is natural to ask what happens when <inline-formula id="ID44">
<alternatives>
<mml:math display="inline" id="I44"><mml:msub><mml:mi>N</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>→</mml:mo><mml:msub><mml:msup><mml:mi>N</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mi>S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>n</mml:mi><mml:msub><mml:mi>N</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq44.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>. Fixing all the remaining parameters, both 〈<italic>U</italic>⟩ and <inline-formula id="ID45">
<alternatives>
<mml:math display="inline" id="I45"><mml:msub><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>S</mml:mi></mml:msub></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq45.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> will change, still satisfying the mutual relation presented above. Let us consider, for <inline-formula id="ID46">
<alternatives>
<mml:math display="inline" id="I46"><mml:msub><mml:msup><mml:mi>N</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mi>S</mml:mi></mml:msub></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq46.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, the stationary solution that has the same fraction of S, i.e., <inline-formula id="ID47">
<alternatives>
<mml:math display="inline" id="I47"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>S</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:msup><mml:mi>N</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mi>S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>S</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq47.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>. As a consequence of the scaling relation, <inline-formula id="ID48">
<alternatives>
<mml:math display="inline" id="I48"><mml:msub><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:msup><mml:mi>N</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>≠</mml:mo><mml:msub><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:msub></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq48.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>. Considering 〈<italic>U</italic>⟩ ≈ 0 in both settings, we can ask ourselves what is the factor <italic>γ</italic> such that <inline-formula id="ID49">
<alternatives>
<mml:math display="inline" id="I49"><mml:mi>γ</mml:mi><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mi>A</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mi>U</mml:mi><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mi>A</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:msup><mml:mi>N</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:msub></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq49.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>. Since <italic>u</italic> only enters linearly in the dynamics of the storage, and the mutual relation only depends on the fraction of active <italic>S</italic>, we guess that <italic>γ</italic> = 1/<italic>n</italic>, as numerically observed. As stated in the main text, we can finally conclude that the storage fraction is the most relevant quantity in our model to determine the effect of the feedback and characterize the dynamical evolution. This observation makes our conclusions more robust, as they do not depend on the specific choice for the storage reservoir since there always exists a scaling relation connecting 〈<italic>U</italic>⟩ and <inline-formula id="ID50">
<alternatives>
<mml:math display="inline" id="I50"><mml:msub><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>S</mml:mi></mml:msub></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq50.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>. As such, changing the value of the model parameters we fixed, will only affect the number of active molecules without modifying the main results presented in this work.</p>
</sec>
<sec id="s5-4">
<title>S4. Model Features and Robustness of Optimality</title>
<p>In this section, we show how different choices of model parameters and the external signal features impact the results presented in the main text. In <xref ref-type="table" rid="tbl2">Table S2</xref> we summarize for convenience the parameters of the model. We recall that, for analytical ease, we take the environment to be an exponentially distributed signal,
<disp-formula id="FD53">
<alternatives>
<mml:math display="block" id="M53"><mml:msub><mml:mi>p</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>λ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>h</mml:mi><mml:mi>λ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:math>
<graphic xlink:href="2301.12812v6_eqn53.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S26)</label>
</disp-formula>
</p>
<p>where <italic>λ</italic> is its inverse characteristic scale. In particular, we describe the case in which no signal is present by setting <italic>λ</italic> to be large, so that the typical realizations of <italic>H</italic> would be too small to activate the receptors. On the other hand, when <italic>λ</italic> is small, the values of <italic>h</italic> appearing in the rates of the model are large enough to activate the receptor and thus allow the system to sense the signal. In the dynamical case, we take <italic>λ</italic>(<italic>t</italic>) to be a square wave, so that 〈<italic>H</italic>⟩ = 1/<italic>λ</italic> alternates between two values 〈<italic>H</italic>⟩<sub>min</sub> - the input signal - and 〈<italic>H</italic>⟩<sub>max</sub> - the background. We denote with <italic>T</italic><sub>on</sub> the duration of 〈<italic>H</italic>⟩<sub>max</sub>, and with ΄<italic>T</italic> the one of 〈<italic>H</italic>⟩<sub>min</sub>, i.e., the pause between two subsequent signals. In practice, this mimics an on-off dynamics, where the stochastic signal is present when its average is 〈<italic>H</italic>⟩<sub>max</sub>.</p>
<table-wrap id="tbl2" position="float" orientation="portrait">
<label>TABLE S2</label>
<caption><title>Summary of the model parameters and the values used for numerical simulations, unless otherwise specified. The parameters <italic>β</italic> and <italic>σ</italic> qualitatively determine the behavior of the model and are varied.</title></caption>
<alternatives>
<graphic xlink:href="2301.12812v6_tbl2.tif" mime-subtype="tif" mimetype="image"/>
<table frame="vsides" rules="groups">
<thead>
<tr>
<th align="center" valign="top">Model parameter</th>
<th align="center" valign="top">Description</th>
<th align="center" valign="top">Typical value</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top"><italic>M<sub>S</sub></italic></td>
<td align="center" valign="top">Maximum number of storage units</td>
<td align="center" valign="top">30</td>
</tr>
<tr>
<td align="center" valign="top">Δ<italic>E</italic></td>
<td align="center" valign="top">Receptor energetic barrier</td>
<td align="center" valign="top">1</td>
</tr>
<tr>
<td align="center" valign="top">〈<italic>U</italic>⟩<sub><italic>P</italic></sub></td>
<td align="center" valign="top">Average readout with passive receptor</td>
<td align="center" valign="top">150</td>
</tr>
<tr>
<td align="center" valign="top">〈<italic>U</italic>⟩<sub>A</sub></td>
<td align="center" valign="top">Average readout with active receptor</td>
<td align="center" valign="top">0.5</td>
</tr>
<tr>
<td align="center" valign="top"><inline-formula id="ID51">
<alternatives>
<mml:math display="inline" id="I51"><mml:mrow><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>S</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq51.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula></td>
<td align="center" valign="top">Inverse timescale of the storage</td>
<td align="center" valign="top">1</td>
</tr>
<tr>
<td align="center" valign="top"><italic>g</italic></td>
<td align="center" valign="top">Receptor’s pathways timescale ratio</td>
<td align="center" valign="top">1</td>
</tr>
<tr>
<td align="center" valign="top"><italic>α</italic></td>
<td align="center" valign="top">Inhibiting storage fraction</td>
<td align="center" valign="top">2/3</td>
</tr>
<tr>
<td align="center" valign="top"><italic>H</italic><sub>ref</sub></td>
<td align="center" valign="top">Reference signal</td>
<td align="center" valign="top">10</td>
</tr>
<tr>
<td align="center" valign="top">〈<italic>H</italic>⟩<sub>max</sub></td>
<td align="center" valign="top">Average signal strength</td>
<td align="center" valign="top">10</td>
</tr>
<tr>
<td align="center" valign="top">〈<italic>H</italic>⟩<sub>min</sub></td>
<td align="center" valign="top">Average background strength</td>
<td align="center" valign="top">0.1</td>
</tr>
<tr>
<td align="center" valign="top">Δ<italic>T</italic></td>
<td align="center" valign="top">Duration of the pause between two signals</td>
<td align="center" valign="top">100Δ<italic>t</italic></td>
</tr>
<tr>
<td align="center" valign="top">Ton</td>
<td align="center" valign="top">Duration of a signal</td>
<td align="center" valign="top">100Δ<italic>t</italic></td>
</tr>
<tr>
<td align="center" valign="top">Δ<italic>t</italic></td>
<td align="center" valign="top">Timestep used in simulations</td>
<td align="center" valign="top">5·10<sup>−4</sup></td>
</tr>
<tr>
<td align="center" valign="top"><italic>β</italic></td>
<td align="center" valign="top">Inverse temperature</td>
<td align="center" valign="top">-</td>
</tr>
<tr>
<td align="center" valign="top"><italic>σ</italic></td>
<td align="center" valign="top">Storage energy cost</td>
<td align="center" valign="top">-</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<fig id="fig7" position="float" fig-type="figure">
<label>FIG. S7</label>
<caption><title>Effects of the external signal strength and thermal noise level on sensing.</title>
<p>(a) At fixed <italic>σ</italic> = 0.1 and constant 〈<italic>H</italic>⟩, the system captures less information as 〈<italic>H</italic>⟩ decreases and it needs to operate at high <italic>β</italic> to sense the signal. In particular, as <italic>β</italic> increases, <italic>I<sub>U,H</sub></italic> becomes larger. (b) In the dynamical case, outside the optimal curve (black dashed line), at high <italic>β</italic> and high <italic>σ</italic>, storage is not produced and no negative feedback is present. The system does not display habituation, and <italic>I<sub>U,H</sub></italic> is smaller than on the optimal curve. (c) In the opposite regime, at low <italic>β</italic> and <italic>σ</italic>, the system is dominated by thermal noise. As a consequence, the average readout 〈<italic>U</italic>⟩ is high even when the external signal is not present (〈<italic>H</italic>⟩ = 〈<italic>H</italic>⟩<sub>min</sub> = 0.1), and it captures only a small amount of information <italic>I<sub>U,H</sub></italic>, which is masked by thermal activation. Simulation parameters are as in <xref ref-type="table" rid="tbl2">Table S2</xref>.</p></caption>
<graphic xlink:href="2301.12812v6_fig7.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<sec id="s5-4-1">
<title>1. Effects of the external signal strength and thermal noise level</title>
<p>In <xref ref-type="fig" rid="fig7">Figure S7a</xref>, we study the behavior of the model in the presence of a static exponential signal, with average 〈<italic>H</italic>⟩. We focus on the case of low <italic>σ</italic>, so that the production of storage is favored. As 〈<italic>H</italic>⟩ decreases, <italic>I<sub>U,H</sub></italic> decreases as well. Hence, as expected, information acquired through sensing depends on the strength of the external signal that coincides with the energy input driving receptor activation. However, the system does not display for all parameters an emergent information dynamics, memory, and habituation. In <xref ref-type="fig" rid="fig7">Figure S7b</xref>, we see that, when the temperature is low but <italic>σ</italic> is high, the system does not show habituation and Δ<italic>I<sub>U,H</sub></italic> = 0. On the other hand, when thermal noise dominates (<xref ref-type="fig" rid="fig7">Figure S7c</xref>), even when the external signal is small, the system produces a large readout population due to random thermal activation. As a consequence, these random activations hinder the signal-driven ones, thus the system does not effectively sense the external signal even when present and <italic>I<sub>U,H</sub></italic> is always small. It is important to remind here that, as we see in the main text, <italic>I<sub>U,H</sub></italic> is not monotonic at fixed <italic>σ</italic> and as a function of <italic>β</italic>. This is due to the fact that low temperatures typically favor sensing and habituation, but they also intrinsically suppress readout production. Thus, at high <italic>β</italic>, <italic>σ</italic> needs to be small to effectively store information since thermal noise is negligible. Vice versa, a small <italic>σ</italic> is detrimental at high temperatures since the system produces storage as a consequence of thermal noise. This complex interplay is captured by the Pareto optimization, which gives us an effective relation between <italic>β</italic> and <italic>σ</italic> to maximize storage while minimizing dissipation.</p>
</sec>
<sec id="s5-4-2">
<title>2. Stationary behavior of the model with a constant signal</title>
<p>In this section, we detail the behavior of the model when exposed to a static signal. As in the main text, we take
<disp-formula id="FD54">
<alternatives>
<mml:math display="block" id="M54"><mml:msub><mml:mi>p</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>h</mml:mi><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:math>
<graphic xlink:href="2301.12812v6_eqn54.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S27)</label>
</disp-formula>
</p>
<p>with 〈<italic>H</italic>⟩ = 1/<italic>λ</italic><sup>st</sup> = <italic>H</italic><sup>st</sup>.</p>
<p>We first consider the case where the system does not adapt its inhibition strength <italic>κ</italic>, i.e., we set
<disp-formula id="FD55">
<alternatives>
<mml:math display="block" id="M55"><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>α</mml:mi><mml:mi>σ</mml:mi></mml:mrow></mml:mfrac></mml:math>
<graphic xlink:href="2301.12812v6_eqn55.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S28)</label>
</disp-formula>
</p>
<p>where <italic>H</italic><sub>ref</sub> is the reference signal, and <italic>α</italic> the fraction of storage population needed to inhibit the receptor on average (see <xref ref-type="table" rid="tbl2">Table S2</xref>). In <xref ref-type="fig" rid="fig8">Figure S8</xref> we plot as a function of <italic>α</italic> and <italic>σ</italic> the behavior of the stationary average readout population 〈<italic>U</italic>⟩<sup>st</sup>, the average storage population 〈<italic>S</italic>⟩<sup>st</sup>, the mutual information between readout and the signal <inline-formula id="ID52">
<alternatives>
<mml:math display="inline" id="I52"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq52.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, and the total energy consumption <inline-formula id="ID53">
<alternatives>
<mml:math display="inline" id="I53"><mml:mrow><mml:mi>δ</mml:mi><mml:msubsup><mml:mi>Q</mml:mi><mml:mi>R</mml:mi><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mi>int</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq53.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, where
<disp-formula id="FD56">
<alternatives>
<mml:math display="block" id="M56"><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mi>int</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mrow><mml:mrow><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>int</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup></mml:mrow><mml:mo>/</mml:mo><mml:mi>σ</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>→</mml:mo><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>→</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math>
<graphic xlink:href="2301.12812v6_eqn56.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S29)</label>
</disp-formula>
</p>
<p>with <inline-formula id="ID56">
<alternatives>
<mml:math display="inline" id="I56"><mml:msub><mml:mi>τ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>S</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq56.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>. As shown in the main text, however, we can achieve a collapse of the Pareto fronts at different external signals if we allow the system to tune the inhibition strength as
<disp-formula id="FD57">
<alternatives>
<mml:math display="block" id="M57"><mml:mi>k</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mi>H</mml:mi><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo>〈</mml:mo><mml:mi>H</mml:mi><mml:mo>〉</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>α</mml:mi><mml:mi>σ</mml:mi></mml:mrow></mml:mfrac></mml:math>
<graphic xlink:href="2301.12812v6_eqn57.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S30)</label>
</disp-formula>
</p>
<p>so that a stronger input will correspond to a larger <italic>κ</italic>, and thus a stronger inhibition. In <xref ref-type="fig" rid="fig9">Figure S9</xref> we show the behavior of the same stationary quantities in this case, and for a large range of <italic>H</italic><sup>st</sup>.</p>
<fig id="fig8" position="float" fig-type="figure">
<label>FIG. S8</label>
<caption><p>Behavior of the stationary average readout population 〈<italic>U</italic>⟩<sup>st</sup>, the average storage population 〈<italic>S</italic>⟩<sup>st</sup>, the mutual information between readout and the signal <inline-formula id="ID54">
<alternatives>
<mml:math display="inline" id="I54"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq54.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, and the total energy consumption <inline-formula id="ID55">
<alternatives>
<mml:math display="inline" id="I55"><mml:mrow><mml:mi>δ</mml:mi><mml:msubsup><mml:mi>Q</mml:mi><mml:mi>R</mml:mi><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mi>int</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq55.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, as a function of <italic>β</italic> and <italic>σ</italic> and in the presence of a static signal with average <italic>H</italic><sup>st</sup>. The value of <italic>κ</italic> is fixed by a reference signal as in <xref ref-type="disp-formula" rid="FD55">Eq. (S28)</xref>. The dashed black line indicates the corresponding Pareto front. Simulation parameters are as in <xref ref-type="table" rid="tbl2">Table S2</xref>.</p></caption>
<graphic xlink:href="2301.12812v6_fig8.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<fig id="fig9" position="float" fig-type="figure">
<label>FIG. S9</label>
<caption><p>Behavior of the stationary average readout population 〈<italic>U</italic>⟩<sup>st</sup>, the average storage population 〈<italic>S</italic>⟩<sup>st</sup>, the mutual information between readout and the signal <inline-formula id="ID57">
<alternatives>
<mml:math display="inline" id="I57"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq57.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, and the total energy consumption <inline-formula id="ID58">
<alternatives>
<mml:math display="inline" id="I58"><mml:mrow><mml:mi>δ</mml:mi><mml:msubsup><mml:mi>Q</mml:mi><mml:mi>R</mml:mi><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mi>int</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq58.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, as a function of <italic>β</italic> and <italic>σ</italic> and in the presence of a static signal with average <italic>H</italic><sup>st</sup>. The value of <italic>κ</italic> is tuned so that it follows the average value of the external signal, <xref ref-type="disp-formula" rid="FD57">Eq. (S30)</xref>. The dashed black line indicates the corresponding Pareto front. Simulation parameters are as in <xref ref-type="table" rid="tbl2">Table S2</xref>.</p></caption>
<graphic xlink:href="2301.12812v6_fig9.tif" mime-subtype="tif" mimetype="image"/>
</fig>
</sec>
<sec id="s5-4-3">
<title>3. Static and dynamical optimality</title>
<p>We now study the dynamical behavior of the model under a repeated external signal, for different values of 〈<italic>H</italic>⟩<sub>max</sub>. In particular, given an observable <italic>O</italic>, we define its change under a repeated signal, Δ<italic>O</italic>, as the difference between the maximal response to the signal after several repetitions, once the system has habituated, and the maximal response to the first signal. In <xref ref-type="fig" rid="fig10">Figure S10b</xref> we plot, as a function of <italic>β</italic> and <italic>σ</italic>, the mutual information gain Δ<italic>I<sub>U,H</sub></italic>, the feedback information gain ΔΔ<italic>I<sub>f</sub></italic>, the habituation strength Δ〈<italic>U</italic>⟩, and the change in the internal energy flux Δ<italic>J</italic><sub>int</sub>, when as before κ is fixed by a reference signal <italic>H</italic><sub>ref</sub>. As in the main text, we see in particular that Δ〈<italic>U</italic>⟩ is maximal in the region where the change in the mutual information Δ<italic>I<sub>U,H</sub></italic> and the feedback information ΔΔ<italic>I<sub>f</sub></italic> are both small, suggesting that a strong habituation fueled by a large number of storage molecules with low energy cost is ultimately detrimental for information processing. Furthermore, in this region the change in the internal energy flux, <italic>J<sub>int</sub></italic>, is large. For completeness, in <xref ref-type="fig" rid="fig11">Figure S11</xref> we plot all relevant dynamical quantities at different signal strength 〈<italic>H</italic>⟩<sub>max</sub> in the case of a fixed <italic>κ</italic> with a reference signal (<xref ref-type="disp-formula" rid="FD55">Eq. (S28)</xref>), whereas in <xref ref-type="fig" rid="fig12">Figure S12</xref> we focus on an adaptive <italic>κ</italic> (<xref ref-type="disp-formula" rid="FD57">Eq. (S30)</xref>).</p>
<fig id="fig10" position="float" fig-type="figure">
<label>FIG. S10</label>
<caption><title>Dynamical optimality under a repeated external signal.</title>
<p>(a) Schematic definition of how we study the dynamical evolution of relevant observables, by comparing the maximal response to a first signal with the one to a signal after the system has habituated. (b) Behavior of the increase in readout information, Δ<italic>I<sub>U,H</sub></italic>, in feedback information, ΔΔ<italic>I<sub>f</sub></italic>, in average readout population, Δ〈<italic>U</italic>⟩, and in the internal energy flux, Δ<italic>J</italic><sub>int</sub>. The value of <italic>κ</italic> is fixed by a reference signal as in <xref ref-type="disp-formula" rid="FD55">Eq. (S28)</xref>. The dashed black line indicates the corresponding Pareto front. Simulation parameters are as in <xref ref-type="table" rid="tbl2">Table S2</xref>.</p></caption>
<graphic xlink:href="2301.12812v6_fig10.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<fig id="fig11" position="float" fig-type="figure">
<label>FIG. S11</label>
<caption><p>Behavior of the change in average readout population Δ〈<italic>U</italic>⟩, readout information gain Δ<italic>I<sub>U,H</sub></italic>, change in internal energy flux Δ<italic>J</italic><sub>int</sub>, feedback information gain, ΔΔ<italic>I<sub>f</sub></italic>, final readout information after habituation <inline-formula id="ID59">
<alternatives>
<mml:math display="inline" id="I59"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>hab</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq59.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, as a function of <italic>σ</italic> and a and in the presence of a switching signal with average 〈<italic>H</italic>⟩<sub>max</sub>. The value of <italic>κ</italic> is fixed by a reference signal as in <xref ref-type="disp-formula" rid="FD55">Eq. (S28)</xref>. The dashed black line indicates the corresponding Pareto front. Simulation parameters are as in <xref ref-type="table" rid="tbl2">Table S2</xref>.</p></caption>
<graphic xlink:href="2301.12812v6_fig11.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<fig id="fig12" position="float" fig-type="figure">
<label>FIG. S12</label>
<caption><p>Behavior of the change in average readout population Δ〈<italic>U</italic>⟩, readout information gain Δ<italic>J<sub>U,H</sub></italic>, change in internal energy flux Δ<italic>J</italic><sub>int</sub>, feedback information gain, ΔΔ<italic>I<sub>f</sub></italic>, final readout information after habituation <inline-formula id="ID60">
<alternatives>
<mml:math display="inline" id="I60"><mml:mrow><mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>hab</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq60.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, as a function of <italic>β</italic> and <italic>σ</italic> and in the presence of a switching signal with average 〈<italic>H</italic>⟩<sub>max</sub>. The value of <italic>κ</italic> is tuned so that it follows the average value of the external signal as in <xref ref-type="disp-formula" rid="FD57">Eq. (S30)</xref>. The dashed black line indicates the corresponding Pareto front. Simulation parameters are as in <xref ref-type="table" rid="tbl2">Table S2</xref>.</p></caption>
<graphic xlink:href="2301.12812v6_fig12.tif" mime-subtype="tif" mimetype="image"/>
</fig>
</sec>
<sec id="s5-4-4">
<title>4. Interplay between information storage and signal duration</title>
<p>In the main text and insofar, we have always considered the case <italic>T</italic><sub>on</sub> = Δ<italic>t</italic>. We now study the effect of the signal duration and the pause length on sensing (<xref ref-type="fig" rid="fig13">Figure S13</xref>). If the system only receives short signals between long pauses, the slow storage build-up does not reach a high level of fraction of active molecules. As a consequence, the negative feedback on the receptor is less effective and habituation is suppressed (<xref ref-type="fig" rid="fig13">Figure S13a</xref>). Therefore, the peak of Δ<italic>I<sub>U,H</sub></italic> in the (<italic>β, σ</italic>) plane takes place below the optimal curve, as <italic>σ</italic> needs to be smaller than in the static case to boost storage production during the brief periods in which the signal is present. On the other hand, in <xref ref-type="fig" rid="fig13">Figure S13b</xref> we consider the case of a long signal with short pauses. In this scenario, the slow dynamical evolution of the storage can reach large values of number of molecules at larger values of <italic>σ</italic>, thus moving the optimal dynamical region slightly above the Pareto-like curve. The case of a short signal is comparable to the durations of the looming stimulations in the experimental setting, which can be used to tune the parameters of the model to the peak of information gain.</p>
<fig id="fig13" position="float" fig-type="figure">
<label>FIG. S13</label>
<caption><title>Effect of the signal duration on habituation.</title>
<p>(a) If the system only receives the signal for a short time (<italic>T</italic><sub>on</sub> = 50Δ<italic>t</italic> &lt; Δ<italic>T</italic> = 200Δ<italic>t</italic>) it does not have enough time to reach a high level of storage molecules. As a consequence, both Δ<italic>U</italic> and Δ<italic>I<sub>U,H</sub></italic> are smaller, and thus habituation is less effective. (b) If the system receives long signals with brief pauses (<italic>T</italic><sub>on</sub> = 200Δ<italic>t</italic> &gt; Δ<italic>T</italic> = 50Δ<italic>t</italic>), instead, the habituation mechanism promotes information storage and thus a reduction in the readout activity. The dashed black line indicates the corresponding Pareto front. Simulation parameters are as in <xref ref-type="table" rid="tbl2">Table S2</xref>.</p></caption>
<graphic xlink:href="2301.12812v6_fig13.tif" mime-subtype="tif" mimetype="image"/>
</fig>
</sec>
</sec>
<sec id="s5-5">
<title>S5. The Necessity of Storage</title>
<p>Here, we discuss in detail the necessity of slow storage implementing the negative feedback to have habituation. We will first investigate the possibility that negative feedback, necessary for any kind of habituative behaviors, is implemented directly through the readout population that undergoes a fast dynamics. We will analytically show that this limit leads to the absence of habituation, hinting at the necessity of having a slow dynamical feedback in the system (Sec. S5 1). Then, we will study the system in the scenario in which <italic>U</italic> applies the feedback, bypassing the storage S , but it acts as a slow variable. Solving the Master Equation through our iterative numerical method, we show that, also in this case, habituation disappears (Sec. S5 2). These results suggest that not only the feedback must be applied by a slow variable, but that such a slow variable must have a role different from the readout population, in line with recent observations in neural systems [<xref ref-type="bibr" rid="c15">15</xref>]. The model proposed in the main text is indeed minimal in this respect, other than compatible with biological examples.</p>
<sec id="s5-5-1">
<title>1. Dynamical feedback cannot be implemented by a fast readout</title>
<p>If the storage is directly implemented by the readout population, the transition rates get modified as follows:
<disp-formula id="FD58">
<alternatives>
<mml:math display="block" id="M58"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>→</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>H</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>β</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>−</mml:mo><mml:mi>Δ</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>H</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mtext>  </mml:mtext><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>→</mml:mo><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>H</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>R</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>→</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>C</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mi>Δ</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>R</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mtext>   </mml:mtext><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>→</mml:mo><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>C</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>β</mml:mi><mml:mi>θ</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>R</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>u</mml:mi><mml:mo>→</mml:mo><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>V</mml:mi><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>U</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mtext> </mml:mtext><mml:msub><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>→</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>U</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math>
<graphic xlink:href="2301.12812v6_eqn58.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S31)</label>
</disp-formula>
</p>
<p>At this level, <italic>θ</italic> is a free parameter playing the same role as <italic>κ</italic>/<italic>N<sub>S</sub></italic> in the complete model with the storage. We start again from the master equation for the propagator <italic>P</italic>(<italic>u, r, h, t</italic>|<italic>u</italic><sub>0</sub>, <italic>r</italic><sub>0</sub>, <italic>h</italic><sub>0</sub>, <italic>t</italic><sub>0</sub>):
<disp-formula id="FD59">
<alternatives>
<mml:math display="block" id="M59"><mml:msub><mml:mo>∂</mml:mo><mml:mi>t</mml:mi></mml:msub><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>U</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>U</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>H</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>H</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mo>,</mml:mo></mml:math>
<graphic xlink:href="2301.12812v6_eqn59.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S32)</label>
</disp-formula>
</p>
<p>where <italic>τ<sub>U</sub></italic> ≪ <italic>τ<sub>R</sub></italic> ≪ <italic>τ<sub>R</sub></italic>, since we are assuming, as before, that <italic>U</italic> is the fastest variable. Here, <italic>∊</italic> = <italic>τ<sub>U</sub></italic>/<italic>τ<sub>R</sub></italic> and <italic>δ</italic> = <italic>τ<sub>R</sub></italic>/<italic>τ<sub>H</sub></italic>. Notice that now <italic>Ŵ<sub>R</sub></italic> depends also on <italic>u</italic>. We can solve the system again by resorting to a timescale separation and scaling the time by the slowest timescale, <italic>τ<sub>H</sub></italic>. We have:
<disp-formula id="FD60">
<alternatives>
<mml:math display="block" id="M60"><mml:msub><mml:mo>∂</mml:mo><mml:mi>t</mml:mi></mml:msub><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>ε</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>δ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>U</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mi>δ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>H</mml:mi></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mo>.</mml:mo></mml:math>
<graphic xlink:href="2301.12812v6_eqn60.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S33)</label>
</disp-formula>
</p>
<p>We now expand the propagator at first order in <italic>∊</italic>, <italic>P</italic> = <italic>P</italic><sup>(0)</sup> + <italic>∊P</italic><sup>(1)</sup>. Then, the order <italic>∊</italic><sup>−1</sup> of the master equation gives, as above, <inline-formula id="ID61">
<alternatives>
<mml:math display="inline" id="I61"><mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>Π</mml:mi></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq61.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>(<italic>r, h, t</italic>|<italic>r</italic><sub>0</sub>, <italic>h</italic><sub>0</sub>, <italic>t</italic><sub>0</sub>). At order <italic>∊</italic><sup>0</sup>, <xref ref-type="disp-formula" rid="FD60">Eq. (S33)</xref> leads to
<disp-formula id="FD61">
<alternatives>
<mml:math display="block" id="M61"><mml:msub><mml:mo>∂</mml:mo><mml:mi>t</mml:mi></mml:msub><mml:mo>∏</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mi>δ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>u</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>H</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>∏</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:math>
<graphic xlink:href="2301.12812v6_eqn61.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S34)</label>
</disp-formula>
</p>
<p>To solve this, we expand the propagator as Π = Π<sup>(0)</sup> + <italic>δ</italic>Π<sup>(1)</sup> and, at order <italic>δ</italic><sup>−1</sup>, we obtain:
<disp-formula id="FD62">
<alternatives>
<mml:math display="block" id="M62"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>u</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mo>∏</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math>
<graphic xlink:href="2301.12812v6_eqn62.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S35)</label>
</disp-formula>
</p>
<p>This is a 2 × 2 effective matrix acting on Π<sup>(0)</sup>, where the only rate affected by <italic>u</italic> is <inline-formula id="ID62">
<alternatives>
<mml:math display="inline" id="I62"><mml:mrow><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>A</mml:mi><mml:mo>→</mml:mo><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>C</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq62.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>, which multiplies the active states, i.e., <italic>r</italic> = 1. This equation can be analytically computed and the solution of <xref ref-type="disp-formula" rid="FD62">Eq. (S35)</xref> is:
<disp-formula id="FD63">
<alternatives>
<mml:math display="block" id="M63"><mml:msup><mml:mo>∏</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>|</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>β</mml:mi><mml:mi>Δ</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>Θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>β</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>β</mml:mi><mml:mi>Δ</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>Θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:math>
<graphic xlink:href="2301.12812v6_eqn63.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S36)</label>
</disp-formula>
</p>
<p>with log(Θ) = e<sup><italic>−β(V − c)</italic></sup> (<italic>e<sup>βθ</sup></italic> − 1). Clearly, <inline-formula id="ID63">
<alternatives>
<mml:math display="inline" id="I63"><mml:msubsup><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq63.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> does not depend on <italic>u</italic> since we summed over the fast variable. Going on with the computation, at order <italic>δ</italic><sup>0</sup> , we obtain:
<disp-formula id="FD64">
<alternatives>
<mml:math display="block" id="M64"><mml:msub><mml:mo>∂</mml:mo><mml:mi>t</mml:mi></mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>H</mml:mi></mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2301.12812v6_eqn64.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S37)</label>
</disp-formula>
</p>
<p>So that the full propagator results to be:
<disp-formula id="FD65">
<alternatives>
<mml:math display="block" id="M65"><mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2301.12812v6_eqn65.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S38)</label>
</disp-formula>
</p>
<p>From this expression, we can find the joint probability distribution, following the same steps as before:
<disp-formula id="FD66">
<alternatives>
<mml:math display="block" id="M66"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2301.12812v6_eqn66.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S39)</label>
</disp-formula>
</p>
<p>As expected, since <italic>U</italic> relaxes instantaneously, the feedback is instantaneous as well. As a consequence, the timedependent behavior of the system is solely driven by the external signal <italic>H</italic>, with a fixed amplitude that takes into account the effect of the feedback only on average. This means that there will be no dynamic reduction of activity and, as such, no habituation in this scenario. This was somehow expected, since all variables are faster than the external signal and, as a consequence, the feedback cannot be implemented over time. The first conclusion is that the variable implementing the feedback has to evolve together with <italic>H</italic>.</p>
</sec>
<sec id="s5-5-2">
<title>2. Effective dynamical feedback requires an additional population</title>
<p>We now assume that the feedback is, again, implemented by <italic>U</italic>, but it acts as a slow variable. Formally, we take <italic>τ<sub>R</sub></italic> ≪ <italic>τ<sub>U</sub></italic> ≈ <italic>τ<sub>H</sub></italic>. Rescaling the time by the slowest timescale, <italic>τ<sub>H</sub></italic> (works the same for <italic>τ<sub>U</sub></italic>), we have:
<disp-formula id="FD67">
<alternatives>
<mml:math display="block" id="M67"><mml:msub><mml:mo>∂</mml:mo><mml:mi>t</mml:mi></mml:msub><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>H</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>U</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>U</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mi>ε</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>H</mml:mi></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mi>P</mml:mi></mml:math>
<graphic xlink:href="2301.12812v6_eqn67.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S40)</label>
</disp-formula>
</p>
<p>with <italic>∊</italic> = <italic>τ<sub>R</sub></italic>/<italic>τ<sub>H</sub></italic>. We now expand the propagator at first order in <italic>∊</italic>, <italic>P</italic> = <italic>P</italic><sup>(0)</sup> + <italic>∊P</italic><sup>(1)</sup>. Then, the order <italic>∊</italic><sup>−1</sup> of the master equation is simply <italic>Ŵ<sub>R</sub>P</italic><sup>(0)</sup> = 0, whose solution gives <inline-formula id="ID64">
<alternatives>
<mml:math display="inline" id="I64"><mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>Π</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq64.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula>. At order <italic>∊</italic><sup>0</sup>:
<disp-formula id="FD68">
<alternatives>
<mml:math display="block" id="M68"><mml:msub><mml:mo>∂</mml:mo><mml:mi>t</mml:mi></mml:msub><mml:mo>∏</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>H</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>U</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>r</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>U</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>H</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>∏</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:math>
<graphic xlink:href="2301.12812v6_eqn68.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S41)</label>
</disp-formula>
</p>
<p>The only dependence on <italic>r</italic> in <italic>Ŵ<sub>U</sub>(r)</italic>. is through the production rate of <italic>U</italic>. Indeed, the effective transition matrix governing the birth-and-death process of readout molecules is characterized by:
<disp-formula id="FD69">
<alternatives>
<mml:math display="block" id="M69"><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>u</mml:mi><mml:mo>→</mml:mo><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mi>V</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>β</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>|</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>Γ</mml:mi><mml:mi>U</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:math>
<graphic xlink:href="2301.12812v6_eqn69.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S42)</label>
</disp-formula>
</p>
<p>This rate depends only on <italic>h</italic>, but <italic>h</italic> evolves in time. Therefore, we should scan all possible (infinite) values that h takes and build an infinite dimensional transition matrix. In order to solve the system, imagine that we are looking at the interval [<italic>t</italic><sub>0</sub>, <italic>t</italic><sub>0</sub> + Δ<italic>t</italic>]. Then, we can employ the following approximation if Δ<italic>t</italic> ≪ <italic>τ<sub>H</sub></italic>:
<disp-formula id="FD70">
<alternatives>
<mml:math display="block" id="M70"><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>u</mml:mi><mml:mo>→</mml:mo><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:mi>u</mml:mi><mml:mo>→</mml:mo><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2301.12812v6_eqn70.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S43)</label>
</disp-formula>
</p>
<p>Using this simplification, we need to solve the following equation:
<disp-formula id="FD71">
<alternatives>
<mml:math display="block" id="M71"><mml:msub><mml:mo>∂</mml:mo><mml:mi>t</mml:mi></mml:msub><mml:mo>∏</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>H</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>U</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>r</mml:mi></mml:munder><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>U</mml:mi><mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>H</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>∏</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:math>
<graphic xlink:href="2301.12812v6_eqn71.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S44)</label>
</disp-formula>
</p>
<p>The explicit solution in the interval <italic>t</italic> ∈ [<italic>t</italic><sub>0</sub>, <italic>t</italic><sub>0</sub> + Δ<italic>t</italic>] can be found to be:
<disp-formula id="FD72">
<alternatives>
<mml:math display="block" id="M72"><mml:mo>∏</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mi>P</mml:mi><mml:mi>U</mml:mi><mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2301.12812v6_eqn72.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S45)</label>
</disp-formula>
</p>
<p>with <inline-formula id="ID65">
<alternatives>
<mml:math display="inline" id="I65"><mml:msubsup><mml:mi>P</mml:mi><mml:mi>U</mml:mi><mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow></mml:msubsup></mml:math>
<inline-graphic xlink:href="2301.12812v6_ieq65.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</inline-formula> a propagator. The full propagator at time <italic>t</italic><sub>0</sub> + Δ<italic>t</italic> is then:
<disp-formula id="FD73">
<alternatives>
<mml:math display="block" id="M73"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>P</mml:mi><mml:mi>U</mml:mi><mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math>
<graphic xlink:href="2301.12812v6_eqn73.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S46)</label>
</disp-formula>
</p>
<p>Integrating over the initial conditions, we finally obtain:
<disp-formula id="FD74">
<alternatives>
<mml:math display="block" id="M74"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mo>|</mml:mo><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:mo>∫</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:msubsup><mml:mi>P</mml:mi><mml:mi>U</mml:mi><mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math>
<graphic xlink:href="2301.12812v6_eqn74.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S47)</label>
</disp-formula>
</p>

<p>To numerically integrate this equation, we make two approximations. The first one is that we solve the dynamics in all intervals in which the signal does not evolve, where <italic>P<sub>H</sub></italic> is a delta function peaked at the initial condition. For all time points in which the signal changes, this amounts to considering the signal at the previous instant, a good approximation as long Δ<italic>t</italic> ≪ <italic>τ<sub>H</sub></italic>, particularly when the time dependence of the signal is a square wave, as in our case.</p>
<p>The second approximation is to compute the propagator of <italic>P<sub>U</sub></italic>. As explained in the Methods of the main text, we restrict our computation to the transitions between <italic>n</italic> nearest neighbors in the <italic>U</italic> space. In the case of transitions only among next-nearest neighbors, we have the following dynamics:
<disp-formula id="FD75">
<alternatives>
<mml:math display="block" id="M75"><mml:msub><mml:mo>∂</mml:mo><mml:mi>t</mml:mi></mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mrow><mml:mtext>nn</mml:mtext></mml:mrow></mml:msup><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2301.12812v6_eqn75.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S48)</label>
</disp-formula>
</p>
<p>with the transition matrix:
<disp-formula id="FD76">
<alternatives>
<mml:math display="block" id="M76"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mn>12</mml:mn></mml:mrow><mml:mrow><mml:mtext>nn</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>→</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>Γ</mml:mi><mml:mn>0</mml:mn><mml:mi>U</mml:mi></mml:msubsup><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mn>13</mml:mn></mml:mrow><mml:mrow><mml:mtext>nn</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>→</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mn>21</mml:mn></mml:mrow><mml:mrow><mml:mtext>nn</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>→</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>→</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow></mml:msubsup><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mn>23</mml:mn></mml:mrow><mml:mrow><mml:mtext>nn</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>→</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>Γ</mml:mi><mml:mn>0</mml:mn><mml:mi>U</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mn>31</mml:mn></mml:mrow><mml:mrow><mml:mtext>nn</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>→</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mn>32</mml:mn></mml:mrow><mml:mrow><mml:mtext>nn</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>→</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>Γ</mml:mi><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>→</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow></mml:msubsup></mml:mtd></mml:mtr></mml:mtable></mml:math>
<graphic xlink:href="2301.12812v6_eqn76.tif" mime-subtype="tif" mimetype="image"/></alternatives>
</disp-formula>
</p>
<p>the diagonal is fixed to satisfy the conservation of normalization, as usual. The solution is:
<disp-formula id="FD77">
<alternatives>
<mml:math display="block" id="M77"><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>ν</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>ν</mml:mi></mml:msub><mml:msup><mml:mi>a</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>ν</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>ν</mml:mi></mml:msub><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math>
<graphic xlink:href="2301.12812v6_eqn77.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S49)</label>
</disp-formula>
</p>
<p>where <italic>w<sub>v</sub></italic> and <italic>κ<sub>v</sub></italic> are respectively eigenvectors and eigenvalues of the transition matrix <italic>W</italic><sup>nn</sup>. The coefficients <italic>a<sup>(v)</sup></italic> have to be evaluated according to the condition at time <italic>t</italic><sub>0</sub>:
<disp-formula id="FD78">
<alternatives>
<mml:math display="block" id="M78"><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mtext>st</mml:mtext></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>ν</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>ν</mml:mi></mml:msub><mml:msup><mml:mi>a</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>ν</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mstyle><mml:mo>=</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:msub></mml:math>
<graphic xlink:href="2301.12812v6_eqn78.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S50)</label>
</disp-formula>
</p>
<p>where <italic>δ<sub>u,u0</sub></italic> is the Kroenecker’s delta. To evaluate the information content of this model, we also need:
<disp-formula id="FD79">
<alternatives>
<mml:math display="block" id="M79"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mi>p</mml:mi><mml:mi>U</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>U</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:mo>∫</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:msubsup><mml:mi>P</mml:mi><mml:mi>U</mml:mi><mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:msub><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>   </mml:mtext><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:msubsup><mml:mi>P</mml:mi><mml:mi>U</mml:mi><mml:mrow><mml:mtext>eff</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:msub><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>U</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math>
<graphic xlink:href="2301.12812v6_eqn79.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S51)</label>
</disp-formula>
</p>
<p>In <xref ref-type="fig" rid="fig14">Figure S14</xref> we show that, in this model, <italic>U</italic> does not display habituation. Rather, it increases upon repeated stimuli, acting as the storage in the main text. On the other hand, the probability of the receptor being active does habituate. This suggests that habituation can only occur in fast variables modulated by slow variables.</p>
<p>It is straightforward to intuitively understand why a direct feedback from <italic>U</italic>, with this population undergoing a slow dynamics, cannot lead to habituation. Indeed, at a fixed distribution of the external signal, the stationary solution of 〈<italic>U</italic>⟩ i already takes into account the effect of the negative feedback. Hence, if the system starts with a very low readout population (no signal), the dynamics induced by a switching signal can only bring 〈<italic>U</italic>⟩ to its steady state with intervals in which the population will grow and intervals in which it decreases. Naively speaking, the dynamics of 〈<italic>U</italic>⟩ i becomes similar to the one of the storage in the complete model, since it is actually playing the same role of storing information in this simplified context.</p>
<fig id="fig14" position="float" fig-type="figure">
<label>FIG. S14</label>
<caption><p>Dynamics of a system where <italic>U</italic> evolves on the same timescale of <italic>H</italic>, and implements directly a negative feedback on the receptor. In this model, 〈<italic>U</italic>⟩ (in red) increases upon repeated stimulation rather than decreasing, responding to changes in 〈<italic>H</italic>⟩ (in gray) as the storage of the full model. On the other hand, the probability of the receptor being active, <italic>p<sub>R</sub></italic>(<italic>r</italic> = 1) (black), shows signs of habituation.</p></caption>
<graphic xlink:href="2301.12812v6_fig14.tif" mime-subtype="tif" mimetype="image"/>
</fig>
</sec>
</sec>
<sec id="s5-6">
<title>S6. Experimental Setup</title>
<p>Acquisitions of the zebrafish brain activity were carried out in Elavl3:H2BGCaMP6s larvae at 5 days post fertilization raised at 28° <italic>C</italic> on a 12 h light/12 h dark cycle according to the approval by the Ethical Committee of the University of Padua (61/2020 dal Maschio). Larvae were embedded in 2 percent agarose gel and their brain activity was recorded using a multiphoton system with a custom 3D volumetric acquisition module. Briefly, the imaging path is based on an 8-kHz galvo-resonant commercial 2P design (Bergamo I Series, Thorlabs, Newton, NJ, United States) coupled to a Ti:Sapphire source (Chameleon Ultra II, Coherent) tuned to 920nm for imaging GCaMP6 signals and modulated by a Pockels cell(Conoptics). The fluorescence collection path includes a 705 nm long-pass main dichroic and a 495<italic>nm</italic> long-pass dichroic mirror transmitting the fluorescence light toward a GaAsP PMT detector (H7422PA-40, Hamamatsu) equipped with EM525/50 emission filter. Data were acquired at 30 frames per second, using a water dipping Nikon CFI75 LWD 16X W objective covering an effective field of view of about 450 × 900μm with a resolution of 512 × 1024 pixels. The volumetric module is based on an electrically tunable lens (Optotune) moving continuously according to a saw-tooth waveform synchronized with the frame acquisition trigger. An entire volume of about 180 − 200<italic>um</italic> in thickness encompassing 30 planes separated by about 7<italic>um</italic> is acquired at a rate of 1 volume per second, sufficient to track the relative slow dynamics associated with the fluorescence-based activity reporter GCaMP6s.</p>
<p>As for the visual stimulation, looming stimuli were generated using Stytra and presented monocularly on a 50×50<italic>mm</italic> screen using a DPL4500 projector by Texas Instruments. The dark looming dot was presented 10 times with 150s interval, centered with the fish eye and with a l/v parameter of 8.3 s, reaching at the end of the stimulation a visual angle of 79.4<sup>°</sup> corresponding to an angular expansion rate of 9.5<sup>°</sup>/s. The acquired temporal series were first processed using an automatic pipeline, including motion artifact correction, temporal filtering with a rectangular window 3 second long, and automatic segmentation using Suite2P. Then, the obtained dataset was manually curated to resolve segmentation errors or to integrate cells not detected automatically. We fit the activity profiles of about 52,000 cells with a linear regression model (scikit-learn Python Library) using a set of base functions representing the expected responses to each of the stimulation events, obtained convolving an exponentially decaying kernel of the GCaMP signal lifetime with square waveforms characterized by an amplitude different from zero only during the presentation of the corresponding visual stimulus. The resulting coefficients were divided for the mean squared error of the fit to obtain a set of scores. The cells, whose score fell within the top 5 of the distribution, were considered for the dimensionality reduction analysis.</p>
<p>The resulting fluorescence signals <italic>F<sup>(i)</sup></italic>, for <italic>i</italic> = 1, … , <italic>N</italic><sub>cells</sub>, were processed by removing a moving baseline to account for baseline drifting and fast oscillatory noise [<xref ref-type="bibr" rid="c77">77</xref>]. Briefly, for each time point <italic>t</italic>, we selected a window [<italic>t</italic> − <italic>τ</italic><sub>2</sub>,<italic>t</italic>] and evaluated the minimum smoothed fluorescence,
<disp-formula id="FD80">
<alternatives>
<mml:math display="block" id="M80"><mml:msubsup><mml:mi>F</mml:mi><mml:mn>0</mml:mn><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>min</mml:mi><mml:mrow><mml:mi>u</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msubsup><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:math>
<graphic xlink:href="2301.12812v6_eqn80.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S52)</label>
</disp-formula>
</p>
<p>Then, the relative change in fluorescence signal,
<disp-formula id="FD81">
<alternatives>
<mml:math display="block" id="M81"><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>F</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msubsup><mml:mi>F</mml:mi><mml:mn>0</mml:mn><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mi>F</mml:mi><mml:mn>0</mml:mn><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac></mml:math>
<graphic xlink:href="2301.12812v6_eqn81.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S53)</label>
</disp-formula>
</p>
<p>is smoothed with an exponential moving average. Thus, the neural activity profile for the <italic>i</italic>-th cell that we use in the main text is given by
<disp-formula id="FD82">
<alternatives>
<mml:math display="block" id="M82"><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mi>t</mml:mi></mml:msubsup><mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>w</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>τ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>τ</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mi>t</mml:mi></mml:msubsup><mml:mrow><mml:mi>w</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>τ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>τ</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>w</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mi>t</mml:mi><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:math>
<graphic xlink:href="2301.12812v6_eqn82.tif" mime-subtype="tif" mimetype="image"/></alternatives>
<label>(S54)</label>
</disp-formula>
</p>
<p>In accordance with the previous literature [<xref ref-type="bibr" rid="c77">77</xref>], we set <italic>τ</italic><sub>0</sub> = 0.2 s, <italic>τ</italic><sub>1</sub> = 0.75 s, and <italic>τ</italic><sub>2</sub> = 3 s. The qualitative nature of the low-dimensional activity in the PCA space is not altered by other sensible choices of these parameters.</p>
</sec>
</sec>
<ack>
<title>Acknowledgments</title>
<p>G.N., S.S., and D.M.B. acknowledge Amos Maritan for fruitful discussions. D.M.B. thanks Paolo De Los Rios for insightful comments. G.N. and D.M.B. acknowledge the Max Planck Institute for the Physics of Complex Systems for hosting G.N. during several stages of this work. G.N. acknowledges funding provided by the Swiss National Science Foundation through its Grant CRSII5_186422. D.M.B. is funded by the STARS@UNIPD grant with the project “ActiveInfo”.</p>
</ack>
<ref-list>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G.</given-names> <surname>Tkacik</surname></string-name> and <string-name><given-names>W.</given-names> <surname>Bialek</surname></string-name></person-group>, <article-title>Information processing in living systems</article-title>, <source>Annual Review of Condensed Matter Physics</source> <volume>7</volume>, <fpage>89</fpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>E. U.</given-names> <surname>Azeloglu</surname></string-name> and <string-name><given-names>R.</given-names> <surname>Iyengar</surname></string-name></person-group>, <article-title>Signaling networks: information flow, computation, and decision making</article-title>, <source>Cold Spring Harbor perspectives in biology</source> <volume>7</volume>, <elocation-id>a005934</elocation-id> (<year>2015</year>).</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>F. S.</given-names> <surname>Gnesotto</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Mura</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Gladrow</surname></string-name>, and <string-name><given-names>C. P.</given-names> <surname>Broedersz</surname></string-name></person-group>, <article-title>Broken detailed balance and non-equilibrium dynamics in living systems: a review</article-title>, <source>Reports on Progress in Physics</source> <volume>81</volume>, <elocation-id>066601</elocation-id> (<year>2018</year>).</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Whiteley</surname></string-name>, <string-name><given-names>S. P.</given-names> <surname>Diggle</surname></string-name>, and <string-name><given-names>E. P.</given-names> <surname>Greenberg</surname></string-name></person-group>, <article-title>Progress in and promise of bacterial quorum sensing research</article-title>, <source>Nature</source> <volume>551</volume>, <fpage>313</fpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>T. J.</given-names> <surname>Perkins</surname></string-name> and <string-name><given-names>P. S.</given-names> <surname>Swain</surname></string-name></person-group>, <article-title>Strategies for cellular decision-making</article-title>, <source>Molecular systems biology</source> <volume>5</volume>, <fpage>326</fpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>I.</given-names> <surname>Nemenman</surname></string-name></person-group>, <article-title>Information theory and adaptation</article-title>, <source>Quantitative biology: from molecular to cellular systems</source> <volume>4</volume>, <fpage>73</fpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>T.</given-names> <surname>Nakajima</surname></string-name></person-group>, <article-title>Biologically inspired information theory: Adaptation through construction of external reality models by living systems</article-title>, <source>Progress in Biophysics and Molecular Biology</source> <volume>119</volume>, <fpage>634</fpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D. E.</given-names> <surname>Koshland</surname> <suffix>Jr</suffix></string-name>, <string-name><given-names>A.</given-names> <surname>Goldbeter</surname></string-name>, and <string-name><given-names>J. B.</given-names> <surname>Stock</surname></string-name></person-group>, <article-title>Amplification and adaptation in regulatory and sensory systems</article-title>, <source>Science</source> <volume>217</volume>, <fpage>220</fpage> (<year>1982</year>).</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Y.</given-names> <surname>Tu</surname></string-name>, <string-name><given-names>T. S.</given-names> <surname>Shimizu</surname></string-name>, and <string-name><given-names>H. C.</given-names> <surname>Berg</surname></string-name></person-group>, <article-title>Modeling the chemotactic response of escherichia coli to time-varying stimuli</article-title>, <source>Proceedings of the National Academy of Sciences</source> <volume>105</volume>, <fpage>14855</fpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Y.</given-names> <surname>Tu</surname></string-name></person-group>, <article-title>The nonequilibrium mechanism for ultrasensitivity in a biological switch: Sensing by maxwell’s demons</article-title>, <source>Proceedings of the National Academy of Sciences</source> <volume>105</volume>, <fpage>11737</fpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H.</given-names> <surname>Mattingly</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Kamino</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Machta</surname></string-name>, and <string-name><given-names>T.</given-names> <surname>Emonet</surname></string-name></person-group>, <article-title>Escherichia coli chemotaxis is information limited</article-title>, <source>Nature Physics</source> <volume>17</volume>, <fpage>1426</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R.</given-names> <surname>Cheong</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Rhee</surname></string-name>, <string-name><given-names>C. J.</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Nemenman</surname></string-name>, and <string-name><given-names>A.</given-names> <surname>Levchenko</surname></string-name></person-group>, <article-title>Information transduction capacity of noisy biochemical signaling networks</article-title>, <source>science</source> <volume>334</volume>, <fpage>354</fpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H.</given-names> <surname>Wajant</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Pfizenmaier</surname></string-name>, and <string-name><given-names>P.</given-names> <surname>Scheurich</surname></string-name></person-group>, <article-title>Tumor necrosis factor signaling</article-title>, <source>Cell Death &amp; Differentiation</source> <volume>10</volume>, <fpage>45</fpage> (<year>2003</year>).</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>E.</given-names> <surname>Marquez-Legorreta</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Constantin</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Piber</surname></string-name>, <string-name><given-names>I. A.</given-names> <surname>Favre-Bulle</surname></string-name>, <string-name><given-names>M. A.</given-names> <surname>Taylor</surname></string-name>, <string-name><given-names>A. S.</given-names> <surname>Blevins</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Giacomotto</surname></string-name>, <string-name><given-names>D. S.</given-names> <surname>Bassett</surname></string-name>, <string-name><given-names>G. C.</given-names> <surname>Vanwalleghem</surname></string-name>, and <string-name><given-names>E. K.</given-names> <surname>Scott</surname></string-name></person-group>, <article-title>Brain-wide visual habituation networks in wild type and fmr1 zebrafish</article-title>, <source>Nature Communications</source> <volume>13</volume>, <fpage>895</fpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H.</given-names> <surname>Fotowat</surname></string-name> and <string-name><given-names>F.</given-names> <surname>Engert</surname></string-name></person-group>, <article-title>Neural circuits underlying habituation of visually evoked escape behaviors in larval zebrafish</article-title>, <source>eLife</source> <volume>12</volume>, <elocation-id>e82916</elocation-id> (<year>2023</year>).</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G.</given-names> <surname>Lan</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Sartori</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Neumann</surname></string-name>, <string-name><given-names>V.</given-names> <surname>Sourjik</surname></string-name>, and <string-name><given-names>Y.</given-names> <surname>Tu</surname></string-name></person-group>, <article-title>The energy-speed-accuracy trade-off in sensory adaptation</article-title>, <source>Nature physics</source> <volume>8</volume>, <fpage>422</fpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Menini</surname></string-name></person-group>, <article-title>Calcium signalling and regulation in olfactory neurons</article-title>, <source>Current opinion in neurobiology</source> <volume>9</volume>, <fpage>419</fpage> (<year>1999</year>).</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Kohn</surname></string-name></person-group>, <article-title>Visual adaptation: physiology, mechanisms, and functional benefits</article-title>, <source>Journal of neurophysiology</source> <volume>97</volume>, <fpage>3155</fpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>N. A.</given-names> <surname>Lesica</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Jin</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Weng</surname></string-name>, <string-name><given-names>C.-I.</given-names> <surname>Yeh</surname></string-name>, <string-name><given-names>D. A.</given-names> <surname>Butts</surname></string-name>, <string-name><given-names>G. B.</given-names> <surname>Stanley</surname></string-name>, and <string-name><given-names>J.-M.</given-names> <surname>Alonso</surname></string-name></person-group>, <article-title>Adaptation to stimulus contrast and correlations during natural visual stimulation</article-title>, <source>Neuron</source> <volume>55</volume>, <fpage>479</fpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Benucci</surname></string-name>, <string-name><given-names>A. B.</given-names> <surname>Saleem</surname></string-name>, and <string-name><given-names>M.</given-names> <surname>Carandini</surname></string-name></person-group>, <article-title>Adaptation maintains population homeostasis in primary visual cortex</article-title>, <source>Nature neuroscience</source> <volume>16</volume>, <fpage>724</fpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>E.</given-names> <surname>Schneidman</surname></string-name>, <string-name><given-names>M. J.</given-names> <surname>Berry</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Segev</surname></string-name>, and <string-name><given-names>W.</given-names> <surname>Bialek</surname></string-name></person-group>, <article-title>Weak pairwise correlations imply strongly correlated network states in a neural population</article-title>, <source>Nature</source> <volume>440</volume>, <fpage>1007</fpage> (<year>2006</year>).</mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G.</given-names> <surname>Tkacik</surname></string-name>, <string-name><given-names>O.</given-names> <surname>Marre</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Amodei</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Schneidman</surname></string-name>, <string-name><given-names>W.</given-names> <surname>Bialek</surname></string-name>, and <string-name><given-names>M. J.</given-names> <surname>Berry</surname></string-name></person-group>, <article-title>Searching for collective behavior in a large network of sensory neurons</article-title>, <source>PLoS computational biology</source> <volume>10</volume>, <elocation-id>e1003408</elocation-id> (<year>2014</year>).</mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Z. D.</given-names> <surname>Kurtz</surname></string-name>, <string-name><given-names>C. L.</given-names> <surname>Müller</surname></string-name>, <string-name><given-names>E. R.</given-names> <surname>Miraldi</surname></string-name>, <string-name><given-names>D. R.</given-names> <surname>Littman</surname></string-name>, <string-name><given-names>M. J.</given-names> <surname>Blaser</surname></string-name>, and <string-name><given-names>R. A.</given-names> <surname>Bonneau</surname></string-name></person-group>, <article-title>Sparse and compositionally robust inference of microbial ecological networks</article-title>, <source>PLoS computational biology</source> <volume>11</volume>, <elocation-id>e1004226</elocation-id> (<year>2015</year>).</mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K.</given-names> <surname>Tunstrøm</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Katz</surname></string-name>, <string-name><given-names>C. C.</given-names> <surname>Ioannou</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Huepe</surname></string-name>, <string-name><given-names>M. J.</given-names> <surname>Lutz</surname></string-name>, and <string-name><given-names>I. D.</given-names> <surname>Couzin</surname></string-name></person-group>, <article-title>Collective states, multistability and transitional behavior in schooling fish</article-title>, <source>PLoS computational biology</source> <volume>9</volume>, <elocation-id>e1002915</elocation-id> (<year>2013</year>).</mixed-citation></ref>
<ref id="c25"><label>[25]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G.</given-names> <surname>Nicoletti</surname></string-name> and <string-name><given-names>D. M.</given-names> <surname>Busiello</surname></string-name></person-group>, <article-title>Mutual information disentangles interactions from changing environments</article-title>, <source>Physical Review Letters</source> <volume>127</volume>, <fpage>228301</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c26"><label>[26]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G.</given-names> <surname>Nicoletti</surname></string-name> and <string-name><given-names>D. M.</given-names> <surname>Busiello</surname></string-name></person-group>, <article-title>Mutual information in changing environments: non-linear interactions, out-of-equilibrium systems, and continuously-varying diffusivities</article-title>, <source>Physical Review E</source> <volume>106</volume>, <elocation-id>014153</elocation-id> (<year>2022</year>).</mixed-citation></ref>
<ref id="c27"><label>[27]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R.</given-names> <surname>De Smet</surname></string-name> and <string-name><given-names>K.</given-names> <surname>Marchal</surname></string-name></person-group>, <article-title>Advantages and limitations of current network inference methods</article-title>, <source>Nature Reviews Microbiology</source> <volume>8</volume>, <fpage>717</fpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c28"><label>[28]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G.</given-names> <surname>Nicoletti</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Maritan</surname></string-name>, and <string-name><given-names>D. M.</given-names> <surname>Busiello</surname></string-name></person-group>, <article-title>Information-driven transitions in projections of under-damped dynamics</article-title>, <source>Physical Review E</source> <volume>106</volume>, <elocation-id>014118</elocation-id> (<year>2022</year>).</mixed-citation></ref>
<ref id="c29"><label>[29]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Celani</surname></string-name>, <string-name><given-names>T. S.</given-names> <surname>Shimizu</surname></string-name>, and <string-name><given-names>M.</given-names> <surname>Vergassola</surname></string-name></person-group>, <article-title>Molecular and functional aspects of bacterial chemotaxis</article-title>, <source>Journal of Statistical Physics</source> <volume>144</volume>, <fpage>219</fpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c30"><label>[30]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Kollmann</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Løvdok</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Bartholomé</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Timmer</surname></string-name>, and <string-name><given-names>V.</given-names> <surname>Sourjik</surname></string-name></person-group>, <article-title>Design principles of a bacterial signalling network</article-title>, <source>Nature</source> <volume>438</volume>, <fpage>504</fpage> (<year>2005</year>).</mixed-citation></ref>
<ref id="c31"><label>[31]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>W. H.</given-names> <surname>de Ronde</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Tostevin</surname></string-name>, and <string-name><given-names>P. R.</given-names> <surname>Ten Wolde</surname></string-name></person-group>, <article-title>Effect of feedback on the fidelity of information transmission of time-varying signals</article-title>, <source>Physical Review E</source> <volume>82</volume>, <elocation-id>031914</elocation-id> (<year>2010</year>).</mixed-citation></ref>
<ref id="c32"><label>[32]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names> <surname>Selimkhanov</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Taylor</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Yao</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Pilko</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Albeck</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Hoffmann</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Tsimring</surname></string-name>, and <string-name><given-names>R.</given-names> <surname>Wollman</surname></string-name></person-group>, <article-title>Accurate information transmission through dynamic biochemical signaling networks</article-title>, <source>Science</source> <volume>346</volume>, <fpage>1370</fpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c33"><label>[33]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>N.</given-names> <surname>Barkai</surname></string-name> and <string-name><given-names>S.</given-names> <surname>Leibler</surname></string-name></person-group>, <article-title>Robustness in simple biochemical networks</article-title>, <source>Nature</source> <volume>387</volume>, <fpage>913</fpage> (<year>1997</year>).</mixed-citation></ref>
<ref id="c34"><label>[34]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. M.</given-names> <surname>Parrondo</surname></string-name>, <string-name><given-names>J. M.</given-names> <surname>Horowitz</surname></string-name>, and <string-name><given-names>T.</given-names> <surname>Sagawa</surname></string-name></person-group>, <article-title>Thermodynamics of information</article-title>, <source>Nature physics</source> <volume>11</volume>, <fpage>131</fpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c35"><label>[35]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names> <surname>Flatt</surname></string-name>, <string-name><given-names>D. M.</given-names> <surname>Busiello</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Zamuner</surname></string-name>, and <string-name><given-names>P.</given-names> <surname>De Los Rios</surname></string-name></person-group>, <article-title>Abc transporters are billion-year-old maxwell demons</article-title>, <source>Communications Physics</source> <volume>6</volume>, <fpage>205</fpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c36"><label>[36]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Bilancioni</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Esposito</surname></string-name>, and <string-name><given-names>N.</given-names> <surname>Freitas</surname></string-name></person-group>, <article-title>A chemical reaction network implementation of a maxwell demon</article-title>, <source>The Journal of Chemical Physics</source> <fpage>159</fpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c37"><label>[37]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>C. H.</given-names> <surname>Bennett</surname></string-name></person-group>, <article-title>The thermodynamics of computation — a review</article-title>, <source>International Journal of Theoretical Physics</source> <volume>21</volume>, <fpage>905</fpage> (<year>1982</year>).</mixed-citation></ref>
<ref id="c38"><label>[38]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>T.</given-names> <surname>Sagawa</surname></string-name> and <string-name><given-names>M.</given-names> <surname>Ueda</surname></string-name></person-group>, <article-title>Minimal energy cost for thermodynamic information processing: measurement and information erasure</article-title>, <source>Physical review letters</source> <volume>102</volume>, <fpage>250602</fpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c39"><label>[39]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D.</given-names> <surname>Hartich</surname></string-name>, <string-name><given-names>A. C.</given-names> <surname>Barato</surname></string-name>, and <string-name><given-names>U.</given-names> <surname>Seifert</surname></string-name></person-group>, <article-title>Nonequilibrium sensing and its analogy to kinetic proofreading</article-title>, <source>New Journal of Physics</source> <volume>17</volume>, <elocation-id>055026</elocation-id> (<year>2015</year>).</mixed-citation></ref>
<ref id="c40"><label>[40]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Skoge</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Naqvi</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Meir</surname></string-name>, and <string-name><given-names>N. S.</given-names> <surname>Wingreen</surname></string-name></person-group>, <article-title>Chemical sensing by nonequilibrium cooperative receptors</article-title>, <source>Physical review letters</source> <volume>110</volume>, <fpage>248102</fpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c41"><label>[41]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>I.</given-names> <surname>Lestas</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Vinnicombe</surname></string-name>, and <string-name><given-names>J.</given-names> <surname>Paulsson</surname></string-name></person-group>, <article-title>Fundamental limits on the suppression of molecular fluctuations</article-title>, <source>Nature</source> <volume>467</volume>, <fpage>174</fpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c42"><label>[42]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S. J.</given-names> <surname>Coultrap</surname></string-name> and <string-name><given-names>K. U.</given-names> <surname>Bayer</surname></string-name></person-group>, <article-title>Camkii regulation in information processing and storage</article-title>, <source>Trends in neurosciences</source> <volume>35</volume>, <fpage>607</fpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c43"><label>[43]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>P. W.</given-names> <surname>Frankland</surname></string-name> and <string-name><given-names>S. A.</given-names> <surname>Josselyn</surname></string-name></person-group>, <article-title>In search of the memory molecule</article-title>, <source>Nature</source> <volume>535</volume>, <fpage>41</fpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c44"><label>[44]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names> <surname>Lisman</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Schulman</surname></string-name>, and <string-name><given-names>H.</given-names> <surname>Cline</surname></string-name></person-group>, <article-title>The molecular basis of camkii function in synaptic and behavioural memory</article-title>, <source>Nature Reviews Neuroscience</source> <volume>3</volume>, <fpage>175</fpage> (<year>2002</year>).</mixed-citation></ref>
<ref id="c45"><label>[45]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>P.</given-names> <surname>Sartori</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Granger</surname></string-name>, <string-name><given-names>C. F.</given-names> <surname>Lee</surname></string-name>, and <string-name><given-names>J. M.</given-names> <surname>Horowitz</surname></string-name></person-group>, <article-title>Thermodynamic costs of information processing in sensory adaptation</article-title>, <source>PLoS computational biology</source> <volume>10</volume>, <elocation-id>e1003974</elocation-id> (<year>2014</year>).</mixed-citation></ref>
<ref id="c46"><label>[46]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. C.</given-names> <surname>Barato</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Hartich</surname></string-name>, and <string-name><given-names>U.</given-names> <surname>Seifert</surname></string-name></person-group>, <article-title>Efficiency of cellular information processing</article-title>, <source>New Journal of Physics</source> <volume>16</volume>, <fpage>103024</fpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c47"><label>[47]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>T. E.</given-names> <surname>Ouldridge</surname></string-name>, <string-name><given-names>C. C.</given-names> <surname>Govern</surname></string-name>, and <string-name><given-names>P. R.</given-names> <surname>ten Wolde</surname></string-name></person-group>, <article-title>Thermodynamics of computational copying in biochemical systems</article-title>, <source>Physical Review X</source> <volume>7</volume>, <elocation-id>021004</elocation-id> (<year>2017</year>).</mixed-citation></ref>
<ref id="c48"><label>[48]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>E.</given-names> <surname>Penocchio</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Avanzini</surname></string-name>, and <string-name><given-names>M.</given-names> <surname>Esposito</surname></string-name></person-group>, <article-title>Information thermodynamics for deterministic chemical reaction networks</article-title>, <source>The Journal of Chemical Physics</source> <fpage>157</fpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c49"><label>[49]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D.</given-names> <surname>Tadres</surname></string-name>, <string-name><given-names>P. H.</given-names> <surname>Wong</surname></string-name>, <string-name><given-names>T.</given-names> <surname>To</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Moehlis</surname></string-name>, and <string-name><given-names>M.</given-names> <surname>Louis</surname></string-name></person-group>, <article-title>Depolarization block in olfactory sensory neurons expands the dimensionality of odor encoding</article-title>, <source>Science Advances</source> <volume>8</volume>, <elocation-id>eade7209</elocation-id> (<year>2022</year>).</mixed-citation></ref>
<ref id="c50"><label>[50]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>W.</given-names> <surname>Ma</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Trusina</surname></string-name>, <string-name><given-names>H.</given-names> <surname>El-Samad</surname></string-name>, <string-name><given-names>W. A.</given-names> <surname>Lim</surname></string-name>, and <string-name><given-names>C.</given-names> <surname>Tang</surname></string-name></person-group>, <article-title>Defining network topologies that can achieve biochemical adaptation</article-title>, <source>Cell</source> <volume>138</volume>, <fpage>760</fpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c51"><label>[51]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S. J.</given-names> <surname>Rahi</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Larsch</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Pecani</surname></string-name>, <string-name><given-names>A. Y.</given-names> <surname>Katsov</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Mansouri</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Tsaneva-Atanasova</surname></string-name>, <string-name><given-names>E. D.</given-names> <surname>Sontag</surname></string-name>, and <string-name><given-names>F. R.</given-names> <surname>Cross</surname></string-name></person-group>, <article-title>Oscillatory stimuli differentiate adapting circuit topologies</article-title>, <source>Nature methods</source> <volume>14</volume>, <fpage>1010</fpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c52"><label>[52]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Jalaal</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Schramma</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Dode</surname></string-name>, <string-name><given-names>H.</given-names> <surname>de Maleprade</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Raufaste</surname></string-name>, and <string-name><given-names>R. E.</given-names> <surname>Goldstein</surname></string-name></person-group>, <article-title>Stress-induced dinoflagellate bioluminescence at the single cell level</article-title>, <source>Physical Review Letters</source> <volume>125</volume>, <elocation-id>028102</elocation-id> (<year>2020</year>).</mixed-citation></ref>
<ref id="c53"><label>[53]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. S.</given-names> <surname>Malmierca</surname></string-name>, <string-name><given-names>M. V.</given-names> <surname>Sanchez-Vives</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Escera</surname></string-name>, and <string-name><given-names>A.</given-names> <surname>Bendixen</surname></string-name></person-group>, <article-title>Neuronal adaptation, novelty detection and regularity encoding in audition</article-title>, <source>Frontiers in Systems Neuroscience</source> <volume>8</volume>, <pub-id pub-id-type="doi">10.3389/fnsys.2014.00111</pub-id> (<year>2014</year>).</mixed-citation></ref>
<ref id="c54"><label>[54]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>W. L.</given-names> <surname>Shew</surname></string-name>, <string-name><given-names>W. P.</given-names> <surname>Clawson</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Pobst</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Karimipanah</surname></string-name>, <string-name><given-names>N. C.</given-names> <surname>Wright</surname></string-name>, and <string-name><given-names>R.</given-names> <surname>Wessel</surname></string-name></person-group>, <article-title>Adaptation to sensory input tunes visual cortex to criticality</article-title>, <source>Nature Physics</source> <volume>11</volume>, <fpage>659</fpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c55"><label>[55]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>L.-A.</given-names> <surname>Lamiré</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Haesemeyer</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Engert</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Granato</surname></string-name>, and <string-name><given-names>O.</given-names> <surname>Randlett</surname></string-name></person-group>, <article-title>Inhibition drives habituation of a larval zebrafish visual response</article-title>, <source>bioRxiv</source>, <fpage>2022</fpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c56"><label>[56]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R. F.</given-names> <surname>Thompson</surname></string-name> and <string-name><given-names>W. A.</given-names> <surname>Spencer</surname></string-name></person-group>, <article-title>Habituation: a model phenomenon for the study of neuronal substrates of behavior</article-title>., <source>Psychological review</source> <volume>73</volume>, <fpage>16</fpage> (<year>1966</year>).</mixed-citation></ref>
<ref id="c57"><label>[57]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>L.</given-names> <surname>Eckert</surname></string-name>, <string-name><given-names>M. S.</given-names> <surname>Vidal-Saez</surname></string-name>, <string-name><given-names>Z.</given-names> <surname>Zhao</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Garcia-Ojalvo</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Martinez-Corral</surname></string-name>, and <string-name><given-names>J.</given-names> <surname>Gunawardena</surname></string-name></person-group>, <article-title>Biochemically plausible models of habituation for single-cell learning</article-title>, <source>Current Biology</source> (<year>2024</year>).</mixed-citation></ref>
<ref id="c58"><label>[58]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Smart</surname></string-name>, <string-name><given-names>S. Y.</given-names> <surname>Shvartsman</surname></string-name>, and <string-name><given-names>M.</given-names> <surname>Mönnigmann</surname></string-name></person-group>, <article-title>Minimal motifs for habituating systems</article-title>, <source>Proceedings of the National Academy of Sciences</source> <volume>121</volume>, <elocation-id>e2409330121</elocation-id> (<year>2024</year>).</mixed-citation></ref>
<ref id="c59"><label>[59]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names> <surname>Benda</surname></string-name></person-group>, <article-title>Neural adaptation</article-title>, <source>Current Biology</source> <volume>31</volume>, <fpage>R110</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c60"><label>[60]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D.</given-names> <surname>Bueti</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Bahrami</surname></string-name>, <string-name><given-names>V.</given-names> <surname>Walsh</surname></string-name>, and <string-name><given-names>G.</given-names> <surname>Rees</surname></string-name></person-group>, <article-title>Encoding of temporal probabilities in the human brain</article-title>, <source>Journal of Neuroscience</source> <volume>30</volume>, <fpage>4343</fpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c61"><label>[61]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. J.</given-names> <surname>Sederberg</surname></string-name>, <string-name><given-names>J. N.</given-names> <surname>MacLean</surname></string-name>, and <string-name><given-names>S. E.</given-names> <surname>Palmer</surname></string-name></person-group>, <article-title>Learning to make external sensory stimulus predictions using internal correlations in populations of neurons</article-title>, <source>Proceedings of the National Academy of Sciences</source> <volume>115</volume>, <fpage>1105</fpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c62"><label>[62]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S. E.</given-names> <surname>Palmer</surname></string-name>, <string-name><given-names>O.</given-names> <surname>Marre</surname></string-name>, <string-name><given-names>M. J.</given-names> <surname>Berry</surname></string-name>, and <string-name><given-names>W.</given-names> <surname>Bialek</surname></string-name></person-group>, <article-title>Predictive information in a sensory population</article-title>, <source>Proceedings of the National Academy of Sciences</source> <volume>112</volume>, <fpage>6908</fpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c63"><label>[63]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>P.</given-names> <surname>De Los Rios</surname></string-name> and <string-name><given-names>A.</given-names> <surname>Barducci</surname></string-name></person-group>, <article-title>Hsp70 chaperones are non-equilibrium machines that achieve ultra-affinity by energy consumption</article-title>, <source>eLife</source> <volume>3</volume>, <elocation-id>e02218</elocation-id> (<year>2014</year>).</mixed-citation></ref>
<ref id="c64"><label>[64]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R. D.</given-names> <surname>Astumian</surname></string-name></person-group>, <article-title>Kinetic asymmetry allows macromolecular catalysts to drive an information ratchet</article-title>, <source>Nature communications</source> <volume>10</volume>, <fpage>3837</fpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c65"><label>[65]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names> <surname>Yan</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Hilfinger</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Vinnicombe</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Paulsson</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Kinetic uncertainty relations for the control of stochastic reaction networks</article-title>, <source>Physical review letters</source> <volume>123</volume>, <fpage>108101</fpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c66"><label>[66]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Hilfinger</surname></string-name>, <string-name><given-names>T. M.</given-names> <surname>Norman</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Vinnicombe</surname></string-name>, and <string-name><given-names>J.</given-names> <surname>Paulsson</surname></string-name></person-group>, <article-title>Constraints on fluctuations in sparsely characterized biological systems</article-title>, <source>Physical review letters</source> <volume>116</volume>, <elocation-id>058101</elocation-id> (<year>2016</year>).</mixed-citation></ref>
<ref id="c67"><label>[67]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G.</given-names> <surname>Nicoletti</surname></string-name> and <string-name><given-names>D. M.</given-names> <surname>Busiello</surname></string-name></person-group>, <article-title>Information propagation in multilayer systems with higher-order interactions across timescales</article-title>, <source>Physical Review X</source> <volume>14</volume>, <elocation-id>021007</elocation-id> (<year>2024</year>).</mixed-citation></ref>
<ref id="c68"><label>[68]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>V.</given-names> <surname>Ngampruetikorn</surname></string-name>, <string-name><given-names>D. J.</given-names> <surname>Schwab</surname></string-name>, and <string-name><given-names>G. J.</given-names> <surname>Stephens</surname></string-name></person-group>, <article-title>Energy consumption and cooperation for optimal sensing</article-title>, <source>Nature communications</source> <volume>11</volume>, <fpage>1</fpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c69"><label>[69]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>L. F.</given-names> <surname>Seoane</surname></string-name> and <string-name><given-names>R.</given-names> <surname>Solé</surname></string-name></person-group>, <article-title>Phase transitions in pareto optimal complex networks</article-title>, <source>Physical Review E</source> <volume>92</volume>, <elocation-id>032807</elocation-id> (<year>2015</year>).</mixed-citation></ref>
<ref id="c70"><label>[70]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G.</given-names> <surname>Nicoletti</surname></string-name> and <string-name><given-names>D. M.</given-names> <surname>Busiello</surname></string-name></person-group>, <article-title>Tuning transduction from hidden observables to optimize information harvesting</article-title>, <source>Physical review letters</source> <volume>133</volume>, <fpage>158401</fpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c71"><label>[71]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Bruzzone</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Chiarello</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Albanesi</surname></string-name>, <string-name><given-names>M. E.</given-names> <surname>Miletto Petrazzini</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Megighian</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Lodovichi</surname></string-name>, and <string-name><given-names>M.</given-names> <surname>Dal Maschio</surname></string-name></person-group>, <article-title>Whole brain functional recordings at cellular resolution in zebrafish larvae with 3d scanning multiphoton microscopy</article-title>, <source>Scientific reports</source> <volume>11</volume>, <fpage>11048</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c72"><label>[72]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>L. F.</given-names> <surname>Abbott</surname></string-name> and <string-name><given-names>S. B.</given-names> <surname>Nelson</surname></string-name></person-group>, <article-title>Synaptic plasticity: taming the beast</article-title>, <source>Nature neuroscience</source> <volume>3</volume>, <fpage>1178</fpage> (<year>2000</year>).</mixed-citation></ref>
<ref id="c73"><label>[73]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S. J.</given-names> <surname>Martin</surname></string-name>, <string-name><given-names>P. D.</given-names> <surname>Grimwood</surname></string-name>, and <string-name><given-names>R. G.</given-names> <surname>Morris</surname></string-name></person-group>, <article-title>Synaptic plasticity and memory: an evaluation of the hypothesis</article-title>, <source>Annual review of neuroscience</source> <volume>23</volume>, <fpage>649</fpage> (<year>2000</year>).</mixed-citation></ref>
<ref id="c74"><label>[74]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names> <surname>Hidalgo</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Grilli</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Suweis</surname></string-name>, <string-name><given-names>M. A.</given-names> <surname>Munoz</surname></string-name>, <string-name><given-names>J. R.</given-names> <surname>Banavar</surname></string-name>, and <string-name><given-names>A.</given-names> <surname>Maritan</surname></string-name></person-group>, <article-title>Information-based fitness and the emergence of criticality in living systems</article-title>, <source>Proceedings of the National Academy of Sciences</source> <volume>111</volume>, <fpage>10095</fpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c75"><label>[75]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D. M.</given-names> <surname>Busiello</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Gupta</surname></string-name>, and <string-name><given-names>A.</given-names> <surname>Maritan</surname></string-name></person-group>, <article-title>Coarse-grained entropy production with multiple reservoirs: Unraveling the role of time scales and detailed balance in biology-inspired systems</article-title>, <source>Physical Review Research</source> <volume>2</volume>, <elocation-id>043257</elocation-id> (<year>2020</year>).</mixed-citation></ref>
<ref id="c76"><label>[76]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names> <surname>Bo</surname></string-name> and <string-name><given-names>A.</given-names> <surname>Celani</surname></string-name></person-group>, <article-title>Multiple-scale stochastic processes: decimation, averaging and beyond</article-title>, <source>Physics reports</source> <volume>670</volume>, <fpage>1</fpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c77"><label>[77]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H.</given-names> <surname>Jia</surname></string-name>, <string-name><given-names>N. L.</given-names> <surname>Rochefort</surname></string-name>, <string-name><given-names>X.</given-names> <surname>Chen</surname></string-name>, and <string-name><given-names>A.</given-names> <surname>Konnerth</surname></string-name></person-group>, <article-title>In vivo two-photon imaging of sensory-evoked dendritic calcium signals in cortical neurons</article-title>, <source>Nature protocols</source> <volume>6</volume>, <fpage>28</fpage> (<year>2011</year>).</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.99767.2.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Murugan</surname>
<given-names>Arvind</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Chicago</institution>
</institution-wrap>
<city>Chicago</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This manuscript presents a <bold>valuable</bold> minimal model of habituation which is quantified by information theoretic measures. The results here could be of use in interpreting habituation behavior in a range of biological systems. The evidence presented is <bold>solid</bold>, and uses simulations of the minimal model to recapitulate several hallmarks of habituation from a simple model.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.99767.2.sa2</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>In this study, the authors aim to investigate habituation, the phenomenon of increasing reduction in activity following repeated stimuli, in the context of its information theoretic advantage. To this end, they consider a highly simplified three-species reaction network where habituation is encoded by a slow memory variable that suppresses the receptor and therefore the readout activity. Using analytical and numerical methods, they show that in their model the information gain, the difference between the mutual information between the signal and readout after and before habituation, is maximal for intermediate habituation strength. Furthermore, they demonstrate that the Pareto front corresponding to an optimization strategy that maximizes the mutual information between signal and readout in the steady-state and minimizes dissipation in the system also exhibits similar intermediate habituation strength. Finally, they briefly compare predictions of their model to whole-brain recordings of zebrafish larvae under visual stimulation.</p>
<p>The author's simplified model serves as a good starting point for understanding habituation in different biological contexts as the model is simple enough to allow for some analytic understanding but at the same time exhibits most basic properties of habituation in sensory systems. Furthermore, the author's finding of maximal information gain for intermediate habituation strength via an optimization principle is, in general, interesting. However, the following points remain unclear:</p>
<p>(1) How general is their finding that the optimal Pareto front coincides with the region of maximal information gain? For instance, what happens if the signal H_st (H_max) isn't very strong? Does it matter that in this case, H_st only has a minor influence on delta Q_R? In the binary switching case, what happens if H_max is rather different from H_st (and not just 20% off)? Or in a case where the adapted value corresponds to the average of H_max and H_min?</p>
<p>(2) The comparison to experimental data isn't very convincing. For instance, is PCA performed simultaneously on both the experimental data set and on the model or separately? What are the units of the PCs in Fig. 6(b,c)? Given that the model parameters are chosen so that the activity decrease in the model is similar to the one in the data (i.e., that they show similar habituation in terms of the readout), isn't it expected that the dynamics in the PC1/2 space look very similar?</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.99767.2.sa1</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>The authors use a generic model framework to study the emergence of habituation and its functional role from information-theoretic and energetic perspectives. Their model features a receptor, readout molecules, and a storage unit, and as such, can be applied to a wide range of biological systems. Through theoretical studies, the authors find that habituation (reduction in average activity) upon exposure to repeated stimuli should occur at intermediate degrees to achieve maximal information gain. Parameter regimes that enable these properties also result in low dissipation, suggesting that intermediate habituation is advantageous both energetically and for the purpose of retaining information about the environment.</p>
<p>A major strength of the work is the generality of the studied model. The presence of three units (receptor, readout, storage) operating at different time scales and executing negative feedback can be found in many domains of biology, with representative examples well discussed by the authors (e.g. Figure 1b). A key takeaway demonstrated by the authors that has wide relevance is that large information gain and large habituation cannot be attained simultaneously. When energetic considerations are accounted for, large information gain and intermediate habituation appear to be the favorable combination.</p>
<p>Comments on the revision:</p>
<p>The authors have adequately addressed the points I raised during the initial review. The text has been clarified at multiple instances, and the treatment of energy expenditure is now more rigorous. The manuscript is much improved both in terms of readability and scientific content.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.99767.2.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Nicoletti</surname>
<given-names>Giorgio</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Bruzzone</surname>
<given-names>Matteo</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Suweis</surname>
<given-names>Samir</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Maschio</surname>
<given-names>Marco Dal</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Busiello</surname>
<given-names>Daniel Maria</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>The following is the authors’ response to the original reviews</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Public Review):</bold></p>
<p>Summary:</p>
<p>The manuscript by Nicoletti et al. presents a minimal model of habituation, a basic form of non-associative learning, addressing both from dynamical and information theory aspects of how habituation can be realized. The authors identify that negative feedback provided with a slow storage mechanism is sufficient to explain habituation.</p>
<p>Strengths:</p>
<p>The authors combine the identification of the dynamical mechanism with information-theoretic measures to determine the onset of habituation and provide a description of how the system can gain maximum information about the environment.</p>
</disp-quote>
<p>We thank the reviewer for highlighting the strength of our work and for their comments, which we believe have been instrumental in significantly improving our work and its scope. Below, we address all their concerns.</p>
<disp-quote content-type="editor-comment">
<p>Weaknesses:</p>
<p>I have several main concerns/questions about the proposed model for habituation and its plausibility. In general, habituation does not only refer to a decrease in the responsiveness upon repeated stimulation but as Thompson and Spencer discussed in Psych. Rev. 73, 16-43 (1966), there are 10 main characteristics of habituation, including (i) spontaneous recovery when the stimulus is withheld after response decrement; dependence on the frequency of stimulation such that (ii) more frequent stimulation results in more rapid and/or more pronounced response decrement and more rapid spontaneous recovery; (iii) within a stimulus modality, the less intense the stimulus, the more rapid and/or more pronounced the behavioral response decrement; (iv) the effects of repeated stimulation may continue to accumulate even after the response has reached an asymptotic level (which may or may not be zero, or no response). This effect of stimulation beyond asymptotic levels can alter subsequent behavior, for example, by delaying the onset of spontaneous recovery.</p>
<p>These are only a subset of the conditions that have been experimentally observed and therefore a mechanistic model of habituation, in my understanding, should capture the majority of these features and/or discuss the absence of such features from the proposed model.</p>
</disp-quote>
<p>We are really grateful to the reviewer for pointing out these aspects of habituation that we overlooked in the previous version of our manuscript. Indeed, our model is able to capture most of these 10 observed behaviors, specifically: 1) habituation; 2) spontaneous recovery; 3) potentiation of habituation; 4) frequency sensitivity; 5) intensity sensitivity; 6) subliminal accumulation. Here, we are following the same terminology employed in Eckert et al., Current Biology 34, 5646–5658 (2024), the paper highlighted by the reviewer. We have dedicated a section of the revised version of the manuscript to these hallmarks, substantiating the validity of our framework as a minimal model to have habituation. We remark that these are the sole hallmarks that can be discussed by considering one single external stimulus and that can be identified without ambiguity in a biochemical context. This observation is again in line with Eckert et al., Current Biology 34, 5646–5658 (2024).</p>
<p>In the revised version, we employ the same strategy of the aforementioned work to determine when the system can be considered “habituated”. Indeed, we introduce a response threshold that is now discussed in the manuscript. We also included a note in the discussions stating that, since any biochemical model will eventually reach a steady state, subliminal accumulation, for example, can only be seen with the use of a threshold. The introduction of different storage mechanisms, ideally more detailed at a molecular level, can shed light on this conceptual gap. This is an interesting direction of research.</p>
<disp-quote content-type="editor-comment">
<p>Furthermore, the habituated response in steady-state is approximately 20% less than the initial response, which seems to be achieved already after 3-4 pulses, the subsequent change in response amplitude seems to be negligible, although the authors however state &quot;after a large number of inputs, the system reaches a time-periodic steady-state&quot;. How do the authors justify these minimal decreases in the response amplitude? Does this come from the model parametrization and is there a parameter range where more pronounced habituation responses can be observed?</p>
</disp-quote>
<p>The reviewer is correct, but this is solely a consequence of the specific set of parameters we selected. We made this choice solely for visualization purposes in the previous version. In the revised version, in the section discussing the hallmarks of habituation, we also show other parameter choices when the response decrement is more pronounced. Moreover, we remark that the contour plot of \Delta⟨U&gt; clearly shows that the decrement can largely exceed the 20% threshold presented in the previous version.</p>
<p>In the revised version, also in light of the works highlighted by the reviewer, we decided to move the focus of the manuscript to the information-theoretic advantage of habituation. As such, we modified several parts of the main text. Also, in the region of optimal information gain, habituation is at an intermediate level. For this reason, we decided to keep the same parameter choice as the previous version in Figure 2.</p>
<p>We stated that the time-periodic steady-state is reached “after a large number of stimuli” from a mathematical perspective. However, by using a habituation threshold, as done in Eckert et al., Current Biology 34, 5646–5658 (2024), we can state that the system is habituated after a few stimuli for each set of parameters. This aspect is highlighted in the revised version of the manuscript (see also the point above).</p>
<disp-quote content-type="editor-comment">
<p>The same is true for the information content (Figure 2f) - already at the first pulse, IU, H ~ 0.7 and only negligibly increases afterwards. In my understanding, during learning, the mutual information between the input and the internal state increases over time and the system extracts from these predictions about its responses. In the model presented by the authors, it seems the system already carries information about the environment which hardly changes with repeated stimulus presentation. The complexity of the signal is also limited, and it is very hard to clarify from the presented results, whether the proposed model can actually explain basic features of habituation, as mentioned above.</p>
</disp-quote>
<p>As for the response decrement of the readout, we can certainly choose a set of parameters for which the information gain is higher. In the revised version, we also report the information at the first stimulation and when the system is habituated to give a better idea of the range of these quantities. At any rate, as the referee correctly points out, it is difficult to give an intuitive interpretation of the information in our minimal model.</p>
<p>It is also important to remark that, since the readout population and the receptor both undergo fast dynamics (with appropriate timescales as discussed in the text), we are not observing the transient gain of information associated with the first stimulus. As such, the mutual information presents a discontinuous behavior that resembles the dynamics of the readout, thereby starting at a non-zero value already at the first stimulus.</p>
<disp-quote content-type="editor-comment">
<p>Additionally, there have been two recent models on habituation and I strongly suggest that the authors discuss their work in relation to recent works (bioRxiv 2024.08.04.606534; arXiv:2407.18204).</p>
</disp-quote>
<p>We thank the reviewer for pointing out these relevant references. In the revised version, we highlighted that we discuss the information-theoretic aspects of habituation, while the aforementioned references focus on the dynamics of this phenomenon.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Recommendations for the authors):</bold></p>
<p>I would also like to note here the simplification of the proposed biological model - in particular, that the receptor can be in an active/passive state, as well as proposing the Nf-kB signaling module as a possible molecular realization. Generally, a large number of cell surface receptors including RTKs of GPCRs have much more complex dynamics including autocatalytic activation that generally leads to bistability, and the Nf-kB has been demonstrated to have oscillatory even chaotic dynamics (works of Savas Tsay, Mogens Jensen and others). Considering this, the authors should at least discuss under which conditions these TNF-Alpha signaling could potentially serve as a molecular realisation for habituation.</p>
</disp-quote>
<p>We thank the reviewer for bringing this to our attention. In the previous version, we reported the TNF signaling network only to show a similar coarse-grained modular structure. However, following a suggestion of reviewer #2, we decided to change Figure 1 to include a simplified molecular scheme of chemotaxis rather than TNF signaling, to avoid any source of confusion about this issue.</p>
<disp-quote content-type="editor-comment">
<p>Also, a minor point: Figures 2d-e are cited before 2a-c.</p>
</disp-quote>
<p>We apologize for the oversight. The structure of the Figures and their order is now significantly different, and they are now cited in the correct order.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public review):</bold></p>
<p>In this study, the authors aim to investigate habituation, the phenomenon of increasing reduction in activity following repeated stimuli, in the context of its information-theoretic advantage. To this end, they consider a highly simplified three-species reaction network where habituation is encoded by a slow memory variable that suppresses the receptor and therefore the readout activity. Using analytical and numerical methods, they show that in their model the information gain, the difference between the mutual information between the signal and readout after and before habituation, is maximal for intermediate habituation strength. Furthermore, they demonstrate that the Pareto front corresponds to an optimization strategy that maximizes the mutual information between signal and readout in the steady state, minimizes some form of dissipation, and also exhibits similar intermediate habituation strength. Finally, they briefly compare predictions of their model to whole-brain recordings of zebrafish larvae under visual stimulation.</p>
<p>The author's simplified model might serve as a solid starting point for understanding habituation in different biological contexts as the model is simple enough to allow for some analytic understanding but at the same time exhibits all basic properties of habituation in sensory systems. Furthermore, the author's finding of maximal information gain for intermediate habituation strength via an optimization principle is, in general, interesting. However, the following points remain unclear or are weakly explained:</p>
</disp-quote>
<p>We thank the reviewer for deeming our work interesting and for considering it a solid starting point for understanding habituation in biological systems.</p>
<disp-quote content-type="editor-comment">
<p>(1) Is it unclear what the meaning of the finding of maximal information gain for intermediate habituation strength is for biological systems? Why is information gain as defined in the paper a relevant quantity for an organism/cell? For instance, why is a system with low mutual information after the first stimulus and intermediate mutual information after habituation better than one with consistently intermediate mutual information? Or, in other words, couldn't the system try to maximize the mutual information acquired over the whole time series, e.g., the time series mutual information between the stimulus and readout?</p>
</disp-quote>
<p>This is a delicate aspect to discuss and we thank the referee for the comment. In the revised version, we report information gain, initial and final information, highlighting that both gain and final information are higher in regions where habituation is present. They have qualitatively similar behavior and highlight a clear information-theoretic advantage of this dynamical phenomenon. An important point is that, to determine the optimal Pareto front, we consider a prolonged stimulus and its associated steady-state information. Therefore, from the optimization point of view, there is no notion of “information gain” or “final information”, which are intrinsically dynamical quantities. As a result, the fact that optimal curve lies in the region of optimal information gain is a-priori not expected and hints at the potential crucial role of this feature. In the revised version, we elucidate this aspect with several additional analyses.</p>
<p>We would like to add that, from a naive perspective, while the first stimulation will necessarily trigger a certain (non-zero) mutual information, multiple observations of the same stimulus have to reflect into accumulated information that consequently drives the onset of observed dynamical behaviors, such as habituation.</p>
<disp-quote content-type="editor-comment">
<p>(2) The model is very similar to (or a simplification of previous models) for adaptation in living systems, e.g., for adaptation in chemotaxis via activity-dependent methylation and demethylation. This should be made clearer.</p>
</disp-quote>
<p>We apologize for having missed this point. Our choice has been motivated by the fact that we wanted to avoid confusion between the usual definition of (perfect) adaptation and habituation. However, we now believe that this is not the case for the revised manuscript, and we now include chemotaxis as an example in Figure 1.</p>
<disp-quote content-type="editor-comment">
<p>(3) It remains unclear why this optimization principle is the most relevant one. While it makes sense to maximize the mutual information between stimulus and readout, there are various choices for what kind of dissipation is minimized. Why was \delta Q_R chosen and not, for instance, \dot{\Sigma}_int or the sum of both? How would the results change in that case? And how different are the results if the mutual information is not calculated for the strong stimulation input statistics but for the background one?</p>
</disp-quote>
<p>We thank the reviewer for the suggestion. We agree that a priori, there is no reason to choose \delta Q_R or a function of the internal energy flux J_int (that, in the revised version, we are using in place of \dot\Sigma_int following the suggestion of reviewer #3). The rationale was to minimize \delta Q_R since this dissipation is unavoidable and stems from the presence of the storage inhibiting the receptor through the internal pathway. Indeed, considering the existence of two different pathways implementing sensing and feedback, the presence of any input will result in a dissipation produced by the receptor. This energy consumption is reflected in \delta Q_R.</p>
<p>In the revised version, we now include in the optimization principle two energy contributions (see Eq. (14) of the revised manuscript): \delta Q_R and E_int, which is the energy consumption associated with the driven storage production per unit energy. All Figures have been updated accordingly. The results remain similar, as \delta Q_R still represents the main contribution, especially at high \beta.</p>
<p>Furthermore, in the revised version, we include examples of the Pareto optimization for different values of input strength. As detailed both in the main text and the Supplementary Information, changing the value of ⟨H⟩ moves the Pareto frontier in the (\beta, \sigma) space, since the signal needs to be strong enough for the system to distinguish it from the intrinsic thermal noise (controlled by beta). We also show that if the system is able to tune the inhibition strength \kappa, the Pareto frontiers at different ⟨H⟩ collapse into a single curve. This shows that, although the values of, e.g., the mutual information, depend on ⟨H⟩, the qualitative behavior of the system in this regime is effectively independent of it. We also added more details about this in the Supplementary Information.</p>
<disp-quote content-type="editor-comment">
<p>(4) The comparison to the experimental data is not too strong of an argument in favor of the model. Is the agreement between the model and the experimental data surprising? What other behavior in the PCA space could one have expected in the data? Shouldn't the 1st PC mostly reflect the &quot;features&quot;, by construction, and other variability should be due to progressively reduced activity levels?</p>
</disp-quote>
<p>The agreement between data and model is not surprising - we agree on this - since the data exhibit habituation. However, we believe that the fact that our minimal model is able to capture the features of a complex neural system just by looking at the PCs, without any explicit biological details, is non-trivial. We also stress that the 1st PC only reflects the feature that captures most of the variance of the data and, as such, it is difficult to have a-priori expectations on what it should represent. In the case of the data generated from the model, most of the variance of the activity comes from the switching signal, and similar considerations can be made for the looming stimulations in the data. We updated the manuscript to clarify this point.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Recommendations for the authors):</bold></p>
<p>(1) The abstract makes it sound like a new finding is that habituation is due to a slow, negative feedback mechanism. But, as mentioned in the introduction, this is a well-known fact.</p>
</disp-quote>
<p>We agree with the reviewer. We have revised the abstract.</p>
<disp-quote content-type="editor-comment">
<p>(2) Figure 2c Why does the range of Delta Delta I_f include negative values if the corresponding region is shaded (right-tilted stripes)?</p>
</disp-quote>
<p>The negative values in the range are those attained in the shaded region with right-tilted stripes. We decided to include them in the colorbar for clarity, since Delta Delta I_f is also plotted in the region where it attains negative values.</p>
<disp-quote content-type="editor-comment">
<p>(3) What does the Pareto front look like if the optimization is done for input statistics given by ⟨H⟩_min?</p>
</disp-quote>
<p>In the revised version, we include examples of the Pareto optimization for different values of input strength. As detailed both in the main text and the Supplementary Information, changing the value of ⟨H⟩ moves the Pareto frontier in the (\beta, \sigma) space, since the strength of the signal is crucial for the system to discriminate input and thermal noise (see also the answers above).</p>
<p>In particular, in Figure 4 we explicitly compare the results of the Pareto optimization (which is done with a static input of a given statistics) with the dynamics of the model for different values of ⟨H⟩ in two scenarios, i.e., adaptive and non-adaptive inhibition strength (see answers above for details).</p>
<p>We also remark that ⟨H⟩_min represents the background signal that the system is not trying to capture, which is why we never used it for optimization.</p>
<disp-quote content-type="editor-comment">
<p>(4) From the main text, it is rather difficult to understand how the comparison to the experimental data was performed. How was the PCA done exactly? What are the &quot;features&quot; of the evoked neural response?</p>
</disp-quote>
<p>The PCA on data is performed starting from the single-neuron calcium dynamics. To perform a far comparison, we reconstruct a similar but extremely simplified dynamics using our model as explained in Methods to perform the PCA on analogous simulated data. We added a comment on this in the revised version. While these components capture most of the variance in the data, their specific interpretation is usually out of reach and we believe that it lies beyond the scope of this theoretical work. We also remark that the model does not contain all these biological details - a strong aspect in our opinion - and, as such, it cannot capture specific biological features.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #3 (Public review):</bold></p>
<p>The authors use a generic model framework to study the emergence of habituation and its functional role from information-theoretic and energetic perspectives. Their model features a receptor, readout molecules, and a storage unit, and as such, can be applied to a wide range of biological systems. Through theoretical studies, the authors find that habituation (reduction in average activity) upon exposure to repeated stimuli should occur at intermediate degrees to achieve maximal information gain. Parameter regimes that enable these properties also result in low dissipation, suggesting that intermediate habituation is advantageous both energetically and for the purpose of retaining information about the environment.</p>
<p>A major strength of the work is the generality of the studied model. The presence of three units (receptor, readout, storage) operating at different time scales and executing negative feedback can be found in many domains of biology, with representative examples well discussed by the authors (e.g. Figure 1b). A key takeaway demonstrated by the authors that has wide relevance is that large information gain and large habituation cannot be attained simultaneously. When energetic considerations are accounted for, large information gain and intermediate habituation appear to be a favorable combination.</p>
</disp-quote>
<p>We thank the reviewer for this positive assessment of our work and its generality.</p>
<disp-quote content-type="editor-comment">
<p>While the generic approach of coarse-graining most biological detail is appealing and the results are of broad relevance, some aspects of the conducted studies, the problem setup, and the writing lack clarity and should be addressed:</p>
<p>(1) The abstract can be further sharpened. Specifically, the &quot;functional role&quot; mentioned at the end can be made more explicit, as it was done in the second-to-last paragraph of the Introduction section (&quot;its functional advantages in terms of information gain and energy dissipation&quot;). In addition, the abstract mentions the testing against experimental measurements of neural responses but does not specify the main takeaways. I suggest the authors briefly describe the main conclusions of their experimental study in the abstract.</p>
</disp-quote>
<p>We thank the reviewer for raising this point. In the revised version, we have changed the abstract to reflect the reviewer’s points and the new structure and results of the manuscript.</p>
<disp-quote content-type="editor-comment">
<p>(2) Several clarifications are needed on the treatment of energy dissipation.</p>
<p>-   When substituting the rates in Eq. (1) into the definition of δQ_R above Eq. (10), &quot;σ&quot; does not appear on the right-hand side. Does this mean that one of the rates in the lower pathway must include σ in its definition? Please clarify.</p>
</disp-quote>
<p>We apologize to the reviewer for this typo. Indeed, \sigma sets the energy scale of feedback and, as such, it appears in the energetic driving given by the feedback on the receptor, i.e., in Eq. (1) together with \kappa. This typo has been corrected in the revised manuscript, and all subsequent equations are consistent.</p>
<disp-quote content-type="editor-comment">
<p>-   I understand that the production of storage molecules has an associated cost σ and hence contributes to dissipation. The dependence of receptor dissipation on ⟨H⟩, however, is not fully clear. If the environment were static and the memory block was absent, the term with ⟨H⟩ would still contribute to dissipation. What would be the nature of this dissipation?</p>
</disp-quote>
<p>In the spirit of building a paradigmatic minimal model with a thermodynamic meaning, we considered H to act as an external thermodynamic driving. Since this driving acts on a different pathway with respect to the one affected by the storage, the receptor is driven out of equilibrium by its presence.</p>
<p>By eliminating the memory block, we would also be necessarily eliminating the presence of the pathway associated with the storage effect (“internal pathway” in the manuscript), since its presence is solely due to the existence of a storage population. Therefore, in this case, the receptor would be a 2-state, 1-pathway system and, as such, it would always satisfy an effective detailed balance. As a consequence, the definition of \delta Q_R reported in the manuscript would not hold anymore and the receptor would not exhibit any dissipation. Thus, in a static environment and without a memory block, no receptor dissipation would be present. We would also like to stress that our choice to model two different pathways has been motivated by the observation that the negative feedback acts along a different pathway in several biochemical and biological examples. We made some changes to the model description in the revised version and we hope that this aspect has been clarified.</p>
<disp-quote content-type="editor-comment">
<p>-   Similarly, in Eq. (9) the authors use the ratio of the rates Γ_{s → s+1} and Γ_{s+1 → s} in their expression for internal dissipation. The first-rate corresponds to the synthesis reaction of memory molecules, while the second corresponds to a degradation reaction. Since the second reaction is not the microscopic reverse of the first, what would be the physical interpretation of the log of their ratio? Since the authors already use σ as the energy cost per storage unit, why not use σ times the rate of producing S as a metric for the dissipation rate?</p>
</disp-quote>
<p>We agree with the referee that the reverse reaction we considered is not the microscopic reverse of the storage production. In the case of a fast readout population, we employed a coarse-grained view to compute this entropy production. To be more precise, we gladly welcomed the referee’s suggestion in the revised version and modified the manuscript accordingly. As suggested, we now employ the energy flux associated with the storage production to estimate the internal dissipation (see new Fig. 3).</p>
<p>In the revised version, we also use this quantity in the optimization procedure in combination with \deltaQ_R (see new Fig. 4) to have a complete characterization of the system’s energy consumption. The conclusions are qualitatively identical to before, but we believe that now they are more solid from a theoretical perspective. For this important advance in the robustness and quality of our work, we are profoundly grateful to the referee.</p>
<disp-quote content-type="editor-comment">
<p>(3) Impact of the pre-stimulus state. The plots in Figure 2 suggest that the environment was static before the application of repeated stimuli. Can the authors comment on the impact of the pre-stimulus state on the degree of habituation and its optimality properties? Specifically, would the conclusions stay the same if the prior environment had stochastic but aperiodic dynamics?</p>
</disp-quote>
<p>The initial stimulus is indeed stochastic with an average constant in time and mimics the background (small) signal. We apply the (strong) stimulation when the system already reached a stationary state with respect to the background. As it can be appreciated in Fig. 2 of the revised version, the model response depends on the pre-stimulus level, since it sets the storage concentration before the stimulation arrives and, as such, the subsequent habituation dynamics. This dependence is important from a dynamical perspective. The information-theoretic picture has been developed, as said above, by letting the system relax before the first stimulus. This eliminates this arbitrary dependence and provides a clearer idea of the functional advantages of habituation. Moreover, the optimization procedure is performed in a completely different setting, with no pre-stimulus at all, since we only have one prolonged stimulation. We hope that the revised version is clearer on all these points.</p>
<disp-quote content-type="editor-comment">
<p>(4) Clarification about the memory requirement for habituation. Figure 4 and the associated section argue for the essential role that the storage mechanism plays in habituation. Indeed, Figure 4a shows that the degree of habituation decreases with decreasing memory. The graph also shows that in the limit of vanishingly small Δ⟨S⟩, the system can still exhibit a finite degree of habituation. Can the authors explain this limiting behavior; specifically, why does habituation not vanish in the limit Δ⟨S⟩ -&gt; 0?</p>
</disp-quote>
<p>We apologize for the lack of clarity and we thank the reviewer for spotting this issue. In Figure 4 (now Figure 5 in the revised manuscript) Δ⟨S⟩ is not exactly zero, but equal to 0.15% at the final point. It appeared as 0% in the plot due to an unwanted rounding in the plotting function that we missed. This has been fixed in the revised version, thank you.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #3 (Recommendations for the authors):</bold></p>
<p>(1) Page 2 | &quot;Figure 1b-e&quot; should be &quot;Figure 1b-d&quot; since there is no panel (e) in Figure 1.</p>
<p>(2) Figure 1a | In the top schematic, the symbol &quot;k&quot; is used, while in the rest of the text, the proportionality constant is denoted by κ.</p>
</disp-quote>
<p>We thank the reviewer for pointing this out. Figure 1 has been revised and the panels are now consistent. The proportionality constant (the inhibition strength) has also been fixed.</p>
<disp-quote content-type="editor-comment">
<p>(3) Figure 1a | I find the upper part of the schematic for Storage hard to perceive. I understand the lower part stands for the degradation reaction for storage molecules. The upper part stands for the synthesis reaction catalyzed by the readout population. I think the bolded upper arrow would explain it sufficiently well; the left/right arrows, together with the crossed green circle make that part of the figure confusing. Consider simplifying.</p>
</disp-quote>
<p>We decided to remove the left/right arrows, as suggested by the reviewer, as we agree that they were unnecessarily complicating the schematic. We hope that the revised version will be easier to understand.</p>
<disp-quote content-type="editor-comment">
<p>(4)Page 3 | It would be helpful to tell what the temporal statistics of the input signal $p_H(h,t)$ is, i.e. &lt;h(t) h(t')&gt;. Looking at the example trajectory in Figure 1a, consecutive signal values do not seem correlated.</p>
</disp-quote>
<p>We agree with the reviewer that this is an important detail and worth mentioning. We now explicitly state that consecutive values are not correlated, for simplicity.</p>
<disp-quote content-type="editor-comment">
<p>(5)Figure 2 | I believe the label &quot;EXTERNAL INPUT&quot; refers to the *average* external input, not one specific realization (similar to panels (d) and (e) that report on average metrics). I suggest you indicate this in the label, or, what may be even better, add one particular realization of the stochastic input to the same graph.</p>
</disp-quote>
<p>We thank the reviewer for spotting this. We now write that what we show is the average external signal. We prefer this solution rather than showing a realization of the stochastic input, since it is more consistent with the rest of the plots, where we always show average quantities. We also note that Figure 2 is now Figure 3 in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p>(6)Figure 2d | The expression of Δ⟨U⟩ is the negative of the definition in Eq. (5). It should be corrected.</p>
</disp-quote>
<p>In the revised version, both the definitions in Figure 2 (now Figure 3) and in the text (now Eq. (11)) are consistent.</p>
<disp-quote content-type="editor-comment">
<p>(7) Figure 3(d-e) caption | &quot;where ⟨U⟩ starts to be significantly smaller than zero.&quot; There, it should be Δ⟨U⟩ instead of ⟨U⟩.</p>
</disp-quote>
<p>Thanks again, we corrected this typo.</p>
</body>
</sub-article>
</article>