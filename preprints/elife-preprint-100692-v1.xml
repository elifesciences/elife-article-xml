<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">100692</article-id>
<article-id pub-id-type="doi">10.7554/eLife.100692</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.100692.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>Physics of Living Systems</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Inferring the time-varying coupling of dynamical systems with temporal convolutional autoencoders</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Calderon</surname>
<given-names>Josuan</given-names>
</name>
<xref ref-type="aff" rid="A1">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Berman</surname>
<given-names>Gordon J</given-names>
</name>
<xref ref-type="aff" rid="A1">1</xref>
<xref ref-type="aff" rid="A2">2</xref>
<email xlink:href="mailto:gordon.berman@emory.edu">gordon.berman@emory.edu</email>
</contrib>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Nourmohammad</surname>
<given-names>Armita</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Washington</institution>
</institution-wrap>
<city>Seattle</city>
<country>United States of America</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Walczak</surname>
<given-names>Aleksandra M</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>CNRS</institution>
</institution-wrap>
<city>Paris</city>
<country>France</country>
</aff>
</contrib>
</contrib-group>
<aff id="A1"><label>1</label><institution>Department of Physics, Emory University</institution>, <addr-line>Atlanta</addr-line>, <addr-line>GA</addr-line>, <addr-line>30322</addr-line>, <country>United States</country></aff>
<aff id="A2"><label>2</label><institution>Department of Biology, Emory University</institution>, <addr-line>Atlanta</addr-line>, <addr-line>GA</addr-line>, <addr-line>30322</addr-line>, <country>United States</country></aff>
<pub-date pub-type="epub">
<day>06</day>
<month>06</month>
<year>2024</year>
</pub-date>
<pub-date date-type="original-publication" iso-8601-date="2024-11-12">
<day>12</day>
<month>11</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP100692</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-06-27">
<day>27</day>
<month>06</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-06-05">
<day>05</day>
<month>06</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.48550/arXiv.2406.03212"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Calderon &amp; Berman</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Calderon &amp; Berman</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-100692-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Most approaches for assessing causality in complex dynamical systems fail when the interactions between variables are inherently non-linear and non-stationary. Here we introduce Temporal Autoencoders for Causal Inference (TACI), a methodology that combines a new surrogate data metric for assessing causal interactions with a novel two-headed machine learning architecture to identify and measure the direction and strength of time-varying causal interactions. Through tests on both synthetic and real-world datasets, we demonstrate TACI’s ability to accurately quantify dynamic causal interactions across a variety of systems. Our findings display the method’s effectiveness compared to existing approaches and also highlight our approach’s potential to build a deeper understanding of the mechanisms that underlie time-varying interactions in physical and biological systems.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="s1" sec-type="intro">
<title>Introduction</title>
<p>Rather than being static in time, interactions between parts of a complex system continuously ebb and flow, with one variable driving another at one point, just to see the relationship reverse or lessen or disappear at a later point in time. Real-world signals are seldom stationary and well-behaved, and their causal linkages and interactions frequently appear, disappear, and reappear, possibly changing in strength over time. Examples of such systems abound in neuroscience [<xref ref-type="bibr" rid="R1">1</xref>, <xref ref-type="bibr" rid="R2">2</xref>], ecology [<xref ref-type="bibr" rid="R3">3</xref>], finance, [<xref ref-type="bibr" rid="R4">4</xref>–<xref ref-type="bibr" rid="R6">6</xref>], and climate [<xref ref-type="bibr" rid="R7">7</xref>–<xref ref-type="bibr" rid="R9">9</xref>].</p>
<p>Despite the ubiquity of these dynamically altering interactions, however, most methods for assessing causality in complex dynamical systems have difficulty measuring how the direction and extent of interactions between variables in a system alter in time. This difficulty arises from several inherent characteristics of complex systems and the limitations of existing causal assessment methodologies. Most of these methods, including Granger Causality (GC) [<xref ref-type="bibr" rid="R10">10</xref>], often assume that the dynamical system should be approximately stationary, meaning their statistical properties do not change over time. Other common assumptions, such as linearity and time invariance are also often violated in real-world complex systems. These constraints significantly limit the applicability and accuracy of these approaches in many scenarios [<xref ref-type="bibr" rid="R11">11</xref>–<xref ref-type="bibr" rid="R16">16</xref>].</p>
<p>In addition, in systems where variables are strongly coupled and synchronized, some of these causality inference methods struggle to accurately infer the coupling strength and direction of causality [<xref ref-type="bibr" rid="R16">16</xref>]. This issue extends to scenarios of intermediate coupling, where the variables are neither weakly nor strongly linked. Additionally, the presence of noise in the system leads to a decrease in cross-mapping fidelity, revealing further limitations [<xref ref-type="bibr" rid="R17">17</xref>, <xref ref-type="bibr" rid="R18">18</xref>]. Although the lack of correlation is neither necessary nor sufficient to demonstrate causation [<xref ref-type="bibr" rid="R19">19</xref>, <xref ref-type="bibr" rid="R20">20</xref>], correlation does play an important role in many statistical methods as the basis for hypothesis tests for causality. Mirage correlations can appear in the simplest nonlinear systems [<xref ref-type="bibr" rid="R21">21</xref>]. Variables that may be positively correlated at some point in time can become anti-correlated some moments after or even lose all coherence. However, most causality methods do not adequately account for the fact that sudden changes in correlation over time between variables may indicate a change in the underlying temporal causal relationships.</p>
<p>In an attempt to overcome some of these limitations, here we introduce a new methodology for probing timevarying causal interactions using a new metric for assessing causal interactions combined with a novel machine learning architecture for causal inference, which we call Temporal Autoencoders for Causal Inference (TACI). We show the method’s effectiveness on synthetic and real-world data sets, both in an absolute sense and in comparison to extant methods, particularly focused on how to find time-varying causal structure in complex dynamical systems.</p>
</sec>
<sec id="s2">
<title>Overview of Methodology</title>
<p>In our methodology, we adopt a two-fold approach towards developing a causal inference method that accurately assesses causality between variables x(t) and y(t) in the Granger sense for nonlinear systems with timevarying interactions. The first aspect of our approach is to use a novel surrogate data comparison metric - the Comparative Surrogate Granger Index (CSGI) – that measures the relative improvement in prediction accuracy when including both variables vs. one of them and a randomized version of the other. The other aspect is to use a two-headed Temporal Convolutional Network architecture to robustly capture the space of potential nonlinear mappings between variables across the entire time series. As will be observed, the CSGI with linear autoregressive models works well to identify causal interactions in situations where relatively straightforward mappings exist between variables, but the more complicated neural network model is more effective when the mappings are more non-linear.</p>
<sec id="s2-1">
<title>Comparative Surrogate Granger Index (CSGI)</title>
<p>Informally, Granger Causality (GC) defines a causal interaction from <italic>x(t)</italic> to <italic>y(t)</italic> to be when knowing the full history of both <italic>x(t)</italic> and <italic>y(t)</italic> provides a better prediction about the future of <italic>y(t)</italic> than knowing just the history of <italic>y(t)</italic> alone. While there are many variations on this methodology [<xref ref-type="bibr" rid="R22">22</xref>–<xref ref-type="bibr" rid="R24">24</xref>], the typical form used is to compare two models of similar type (e.g., linear autoregressive models, feedforward neural networks, etc.) based on their ability to predict the future state of <italic>y(t)</italic>. More explicitly, the comparison is between
<disp-formula id="FD1">
<alternatives>
<mml:math id="M1" display="block"><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2406.03212v1_eqn1.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
<label>(1)</label>
</disp-formula>
</p>
<p>and
<disp-formula id="FD2">
<alternatives>
<mml:math id="M2" display="block"><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:math>
<graphic xlink:href="2406.03212v1_eqn2.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
<label>(2)</label>
</disp-formula>
</p>
<p>Usually, an F-test is used to determine whether the latter model is preferred over the former.</p>
<p>This form, however, suffers from two limitations. First, the comparison is a binary one – the second model is “significantly” better than the first or it is not – thus, differences in the strength of coupling can not be detected, just the presence or absence. Second, because the F-test and similar methods incorporate strong assumptions about the underlying dynamics of the system, statistical statements deriving from these tests are often not robust under resampling or re-parameterization. In addition, because the model complexities for the two models being compared are inevitably quite different, with one typically having twice as many parameters as the other, the F-test often fails to detect causal interactions properly.</p>
<p>A common strategy for ameliorating these limitations is to compare not
<disp-formula id="FD3">
<alternatives>
<mml:math id="M3" display="block"><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2406.03212v1_eqn3.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
</disp-formula>
</p>
<p>and
<disp-formula id="FD4">
<alternatives>
<mml:math id="M4" display="block"><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:math>
<graphic xlink:href="2406.03212v1_eqn4.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
</disp-formula>
</p>
<p>but rather
<disp-formula id="FD5">
<alternatives>
<mml:math id="M5" display="block"><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="2406.03212v1_eqn5.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
</disp-formula>
</p>
<p>and
<disp-formula id="FD6">
<alternatives>
<mml:math id="M6" display="block"><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:math>
<graphic xlink:href="2406.03212v1_eqn6.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
</disp-formula>
</p>
<p>where <italic>x</italic><sup>(<italic>s</italic>)</sup> is a <italic>surrogate</italic> data set that shares similar statistical properties to <italic>x</italic>(<italic>t</italic>) but is shuffled in some manner (e.g., shuffling values to preserve the distribution of values or shuffling phases of the time series’ Fourier Transform to preserve the frequency profile), or even a completely randomized time series. Typically, this comparison is accomplished through the Extended Granger Causality Index (EGCI) [<xref ref-type="bibr" rid="R22">22</xref>, <xref ref-type="bibr" rid="R25">25</xref>]. If ε<sub>y</sub> (<italic>t</italic>) are the residuals for fitting the future of <italic>y</italic>(<italic>t</italic>) on the past of <italic>y</italic>(<italic>t</italic>) and ε<sub><italic>xy</italic></sub> (<italic>t</italic>) are the residuals for fitting the future of <italic>y</italic>(<italic>t</italic>) on the pasts of both <italic>x</italic>(<italic>t</italic>) and <italic>y</italic>(<italic>t</italic>), then the EGCI is given by ratio between the relative reduction in residual variance when the past of <italic>x</italic>(<italic>t</italic>) is included in the model:
<disp-formula id="FD7">
<alternatives>
<mml:math id="M7" display="block"><mml:mtext>EGCI=1</mml:mtext><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>var</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ε</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>var</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ε</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:math>
<graphic xlink:href="2406.03212v1_eqn7.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
<label>(3)</label>
</disp-formula>
</p>
<p><italic>y</italic>(<italic>t</italic>) is thus said to cause <italic>x</italic>(<italic>t</italic>) if the EGCI using the actual values of <italic>x</italic>(<italic>t</italic>) is significantly higher than the EGCI found substituting <italic>x</italic>(<italic>t</italic>) for <italic>x</italic><sup>(<italic>s</italic>)</sup> (<italic>t</italic>).</p>
<p>Our approach attempts to assess directly the relative increase in variance explained for the predictive model when using <italic>x</italic>(<italic>t</italic>) vs. <italic>x</italic><sup>(<italic>s</italic>)</sup> (<italic>t</italic>). Specifically, if <inline-formula id="ID1">
<alternatives>
<mml:math display="inline" id="I1"><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math>
<inline-graphic xlink:href="2406.03212v1_ieq1.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
</inline-formula> is the fraction of variance explained about the future of <italic>y</italic>(<italic>t</italic>) using the pasts of <italic>x</italic>(<italic>t</italic>) and <italic>y</italic>(<italic>t</italic>) in the model and <inline-formula id="ID2">
<alternatives>
<mml:math display="inline" id="I2"><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mi>y</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math>
<inline-graphic xlink:href="2406.03212v1_ieq2.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
</inline-formula> is the fraction of variance explained using <italic>x</italic><sup>(<italic>s</italic>)</sup> (<italic>t</italic>) and <italic>y</italic>(<italic>t</italic>), then we define the Comparative Surrogate Granger Index (CSGI), χ<sub><italic>x→y</italic></sub>, to be defined via
<disp-formula id="FD8">
<alternatives>
<mml:math id="M8" display="block"><mml:msub><mml:mtext>χ</mml:mtext><mml:mrow><mml:mi>x</mml:mi><mml:mo>→</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mi>y</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mi>y</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:math>
<graphic xlink:href="2406.03212v1_eqn8.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
<label>(4)</label>
</disp-formula>
</p>
<p>This metric’s advantages over the EGCI are that it is able to measure small changes in causal interactions and that it explicitly measures the difference in predictive power between using actual data and using surrogate data to predict the future. In this article, we will be measuring χ<sub><italic>x→y</italic></sub> and χ<sub><italic>y→x</italic></sub> for all pairs of variables to assess whether there is causal coupling between two variables, whether it is uni- or bi-directional, and the relative strength of the coupling.</p>
</sec>
<sec id="s2-2">
<title>Temporal Autoencoders for Causal Inference</title>
<p>While one advance in our methodology is the use of the CSGI in the previous section, the other novel contribution is the use of a new artificial neural network architecture to calculate the functions f and g that are used to predict the future of y(t). The original (and still most common) models ([<xref ref-type="bibr" rid="R10">10</xref>]) for f and g are auto-regressive linear models of the form
<disp-formula id="FD9">
<alternatives>
<mml:math id="M9" display="block"><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>k</mml:mi></mml:munderover><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mo>,</mml:mo></mml:math>
<graphic xlink:href="2406.03212v1_eqn9.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
<label>(5)</label>
</disp-formula>
</p>
<p>where <italic>x</italic><sup>(<italic>s</italic>)</sup>(<italic>t</italic>) can be substituted for <italic>x</italic>(<italic>t</italic>) when using the surrogate approach. While this relatively simple approach shows impressive performance in a variety of scenarios, these models fail to accurately predict known causal interactions for couplings that have weak to moderate coupling and are governed by nonlinear dynamics that are not well approximated by linear models [<xref ref-type="bibr" rid="R26">26</xref>, <xref ref-type="bibr" rid="R27">27</xref>]. This inability is typically because the systems fail to satisfy separability. In other words, all information about a causative factor has to be inherent to that specific variable and can be omitted by removing that variable from the model, as is the case for purely stochastic or linear systems [<xref ref-type="bibr" rid="R16">16</xref>]. For systems with strongly nonlinear deterministic components, however, this assumption fails, and, accordingly, so do the predictions from auto-regressive linear GC [<xref ref-type="bibr" rid="R13">13</xref>, <xref ref-type="bibr" rid="R27">27</xref>]. In addition, because these linear models have difficulty predicting information across multiple timescales, they often have difficulty detecting subtle shifts in causality as a function of time.</p>
<p>In recent years, a solution has been to replace the linear model in (5) with deep neural networks of varying architectures that, due to their expressive nature, excel in approximating complex functions [<xref ref-type="bibr" rid="R28">28</xref>]. These methods include the use of Variational Autoencoders to estimate causal effects [<xref ref-type="bibr" rid="R29">29</xref>], Causal Generative Neural Networks to learn functional causal models [<xref ref-type="bibr" rid="R30">30</xref>], Neural Granger to estimate non-linearly dependencies based on Granger causality principles [<xref ref-type="bibr" rid="R24">24</xref>], and the Temporal Causal Discovery Framework (TCDF) to address time delay causal relationships [<xref ref-type="bibr" rid="R31">31</xref>]. These methods, however, are often unwieldy to train, are prone to overfitting, and are susceptible to inaccuracies in the presence of a significant amount of noise.</p>
<p>In this paper, we introduce a novel neural network architecture for causality using a two-headed Temporal Convolutional Network (TCN) autoencoder (<xref ref-type="fig" rid="fig1">Fig. 1</xref>). TCNs, the primary building block of our approach, are a specialized type of neural network that integrates causal inference into convolutional architectures. First introduced for video-based action segmentation [<xref ref-type="bibr" rid="R32">32</xref>], TCNs quickly became popular due to their ability to extend most of the convolutional advantages of regular CNNs – including sparsity and translational equivariance – into the time domain through a series of dilated and causal convolutional layers. A key characteristic of this framework is its simplicity, relatively long memory, and ability to outperform most convolutional architectures in autoregressive prediction tasks [<xref ref-type="bibr" rid="R33">33</xref>].</p>
<fig id="fig1" position="float" fig-type="figure">
<label>FIG.1.</label>
<caption><p>Schematic of the Temporal Autoencoders for Causal Inference (TACI) Networks. We use a two-headed network consisting of Temporal Convolutional Networks that interact through a shared latent space to predict a time-shifted version of one of the two input time series. For each pair of variables we wish to examine (here, <italic>X</italic> and <italic>Y</italic>), we train two networks for each causal direction: one using <italic>X</italic> and <italic>Y</italic> as inputs and another using <italic>X</italic> and a randomized version of <italic>Y</italic>. We consider an interaction from <italic>Y</italic>→<italic>X</italic> to be causal if the network using the actual value of <italic>Y</italic> predicts the future of <italic>X</italic> better than the network using the surrogate version of <italic>Y</italic>. In this particular case, we show the approach applied to two different variables from the Lorenz system.</p></caption>
<graphic xlink:href="2406.03212v1_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Our approach, which we call Temporal Autoencoders for Causal Inference (TACI) is a neural network that consists of a two-headed TCN autoencoder, where two TCNs are used to encode time series x(t) and y(t), and a third is used for decoding an equivalently long time series describing the future trajectory of y(t) (shifted by some time, T) from a relatively low-dimensional latent space that is derived from the outputs of the first two autoencoders. A more detailed description of our model and our training methodology can be found in <italic>Materials and methods</italic>. Code is available here: <ext-link ext-link-type="uri" xlink:href="https://github.com/bermanlabemory/Temporal-Autoencoders-For-Causal-Inference-TACI">https://github.com/bermanlabemory/Temporal-Autoencoders-For-Causal-Inference-TACI</ext-link>.</p>
<p>For each comparison of interest, we train four versions of this network: one using <italic>x</italic>(<italic>t</italic>) and <italic>y</italic>(<italic>t</italic>) as input time series to predict the future of <italic>x</italic>(<italic>t</italic>), another that is the same except for replacing <italic>x</italic>(<italic>t</italic>) with the surrogate data <italic>x</italic><sup>(<italic>s</italic>)</sup> (<italic>t</italic>), another pair of the networks that are structured the same except with <italic>x</italic> and <italic>y</italic> reversed in each case. Given these four trained networks, we can then make predictions for the future of the appropriate variable and calculate the fraction of variance explained over a moving window (i.e., <inline-formula id="ID3">
<alternatives>
<mml:math display="inline" id="I3"><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math>
<inline-graphic xlink:href="2406.03212v1_ieq3.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
</inline-formula> or <inline-formula id="ID4">
<alternatives>
<mml:math display="inline" id="I4"><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mi>y</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math>
<inline-graphic xlink:href="2406.03212v1_ieq4.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
</inline-formula>). From these values, we can then apply <xref ref-type="disp-formula" rid="FD4">Eqn. (4)</xref> to calculate the CSGI values χ<sub><italic>x→y</italic></sub> and χ<sub><italic>y→x</italic></sub>, which we will use to assess causal inference between these two variables.</p>
</sec>
<sec id="s2-3">
<title>Other Methods We Compare Against</title>
<p>Alongside comparing GC with linear autoregressive models, which we will refer to here as Surrogate Linear Granger Causality (SLGC), we will also test against two other commonly used methods: Convergent Cross Mapping and Transfer Entropy.</p>
<sec id="s2-3-1">
<title>Convergent Cross Mapping (CCM)</title>
<p>Convergent Cross Mapping (CCM) was introduced to determine causation in systems that could be modeled as relatively noiseless deterministic dynamical systems [<xref ref-type="bibr" rid="R16">16</xref>]. The core concept of this approach is that according to Takens’ Embedding Theorem, if <italic>x</italic>(<italic>t</italic>) and <italic>y</italic>(<italic>t</italic>) are two variables of a deterministic dynamical system, one can reconstruct <italic>x</italic>(<italic>t</italic>) from a delay embedding of <italic>y</italic>(<italic>t</italic>) if and only if the time derivative of <italic>x</italic>(<italic>t</italic>) explicitly depends on <italic>y</italic>(<italic>t</italic>) [<xref ref-type="bibr" rid="R34">34</xref>–<xref ref-type="bibr" rid="R36">36</xref>]. Thus, if it is possible to predict <italic>x</italic>(<italic>t</italic>) from an embedding of <italic>y</italic>(<italic>t</italic>) alone, we would say that <italic>y</italic> has a causal interaction with <italic>x</italic>. Practically, these predictions are calculated by predicting <italic>x</italic>(<italic>t</italic>) from <italic>y</italic>(<italic>t</italic>) (and vice versa) and computing the correlation coefficient between the actual and predicted values [<xref ref-type="bibr" rid="R16">16</xref>], with correlations near one implying a strong casual influence and correlations near zero implying no or little influence. Here, we used Scikit Convergent Cross Mapping (skccm), a Python-based-library implementation of CCM for causal discovery [<xref ref-type="bibr" rid="R37">37</xref>].</p>
</sec>
<sec id="s2-3-2">
<title>Transfer Entropy</title>
<p>Transfer entropy (TE) is a metric that quantifies a reduction in uncertainty in predicting the future of one variable given the past of another using formalism from information theory [<xref ref-type="bibr" rid="R38">38</xref>]. Specifically, we can measure the transfer entropy from <italic>y</italic>(<italic>t</italic>) to <italic>x</italic>(<italic>t</italic>) at a given distance in the future, τ, (<italic>T</italic><sub><italic>Y</italic>→<italic>X</italic></sub> (τ)) via
<disp-formula id="FD10">
<alternatives>
<mml:math id="M10" display="block"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>Y</mml:mi><mml:mo>→</mml:mo><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>τ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>    </mml:mtext><mml:mo>−</mml:mo><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>          </mml:mtext><mml:mrow> <mml:mrow><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math>
<graphic xlink:href="2406.03212v1_eqn10.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
<label>(6)</label>
</disp-formula>
</p>
<p>where <italic>H</italic>(<italic>X</italic>|<italic>Y</italic>) is the Shannon entropy of the conditional probability distribution <italic>p</italic>(<italic>X</italic>|<italic>Y</italic>). This quantity is zero if adding information about the past of <italic>y</italic>(<italic>t</italic>) results in no reduction in our future guesses for <italic>x</italic>(<italic>t</italic>), and if it is non-zero, the quantity can be interpreted as the rate of information flowing from Y to X. Practically, we calculate TE for our systems using the Java Information Dynamics Toolkit (JIDT or Infodynamics Toolkit) [<xref ref-type="bibr" rid="R39">39</xref>].</p>
</sec>
</sec>
</sec>
<sec id="s3" sec-type="results">
<title>Results</title>
<sec id="s3-1">
<title>Artificial Test Systems</title>
<p>To test the validity of our approach, we applied the methodology to a variety of different deterministic and stochastic dynamical system models with known causal interactions, finding that TACI performs well across all cases. In particular, we are interested in cases where the coupling changes in time, which we will explore in detail for the Coupled Hénon Maps system.</p>
<sec id="s3-1-1">
<title>The Rössler-Lorenz System</title>
<p>Our first example case is a system of coupled chaotic attractors, where the Lorenz system <inline-formula id="ID5">
<alternatives>
<mml:math display="inline" id="I5"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<inline-graphic xlink:href="2406.03212v1_ieq5.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
</inline-formula> [<xref ref-type="bibr" rid="R40">40</xref>] is driven by a Rossler oscillator <inline-formula id="ID6">
<alternatives>
<mml:math display="inline" id="I6"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<inline-graphic xlink:href="2406.03212v1_ieq6.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
</inline-formula>[<xref ref-type="bibr" rid="R41">41</xref>]:
<disp-formula id="FD11">
<alternatives>
<mml:math id="M11" display="block"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>6</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>6</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mn>0.2</mml:mn><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mn>3</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>6</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0.2</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mn>5.7</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>10</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>28</mml:mn><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>y</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:msubsup><mml:mi>x</mml:mi><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mn>3</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mn>8</mml:mn><mml:mn>3</mml:mn></mml:mfrac><mml:msub><mml:mi>y</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math>
<graphic xlink:href="2406.03212v1_eqn11.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
<label>(7)</label>
</disp-formula>
</p>
<p>where the constant <italic>C</italic> controls the coupling strength of the system, and the driving severely distorts the behavior of the Lorenz attractor as <italic>C</italic> increases [<xref ref-type="bibr" rid="R42">42</xref>]. Synchronization between <inline-formula id="ID7">
<alternatives>
<mml:math display="inline" id="I7"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover></mml:math>
<inline-graphic xlink:href="2406.03212v1_ieq7.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
</inline-formula> and <inline-formula id="ID8">
<alternatives>
<mml:math display="inline" id="I8"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover></mml:math>
<inline-graphic xlink:href="2406.03212v1_ieq8.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
</inline-formula> starts near <italic>C</italic> = 2.14, making the two systems’ behavior effectively coupled above this point despite the lack of an explicit coupling term, making traditional formal notions of causality ill-posed (<xref ref-type="fig" rid="fig2">Fig. 2A</xref>) [<xref ref-type="bibr" rid="R43">43</xref>]. The solutions to the differential equations were generated by using a fourth-order Runge-Kutta method. C was chosen between 0 and 5, computing a time series of length 300,000 (<italic>dt</italic> = 0.1) after a burn-in time of 30,000 time points at each coupling strength.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>FIG.2.</label>
<caption><p>Causal inference in the Rössler-Lorenz System. <bold>A</bold>) 2-dimensional projections of the Rössler attractor (left) and the Lorenz system (right three plots) as <italic>C</italic> increases. Mathematically, there is only coupling from <italic>X</italic> → <italic>Y</italic>, but starting near <italic>C</italic> = 2.14, the two systems become synchronized, making finding the causal interactions an ill-posed problem. <bold>B-E</bold>) Results from applying the four methods to the system. Note that only TACI accurately predicts the unidirectional coupling in the regime above <italic>C</italic> &gt; 0 and before synchronization occurs. Error bars are generated using a bootstrapping procedure (see Materials and Methods).</p></caption>
<graphic xlink:href="2406.03212v1_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>As seen in <xref ref-type="fig" rid="fig2">Figure 2B-E</xref>, TACI is the only method of the four tried here that accurately predicts the unidirectional coupling from <inline-formula id="ID9">
<alternatives>
<mml:math display="inline" id="I9"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover></mml:math>
<inline-graphic xlink:href="2406.03212v1_ieq9.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
</inline-formula> to <inline-formula id="ID10">
<alternatives>
<mml:math display="inline" id="I10"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover></mml:math>
<inline-graphic xlink:href="2406.03212v1_ieq10.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
</inline-formula>. SLGC (<xref ref-type="fig" rid="fig2">Fig. 2B</xref>) fails to predict any coupling whatsoever between the variables, and CCM and TE (<xref ref-type="fig" rid="fig2">Figs. 2C-D</xref>) predict bidirectional coupling (albeit with somewhat more information flowing from <inline-formula id="ID11">
<alternatives>
<mml:math display="inline" id="I11"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover><mml:mo>→</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover></mml:math>
<inline-graphic xlink:href="2406.03212v1_ieq11.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
</inline-formula> than in the reverse). TACI, in contrast, predicts only unidirectional coupling until the point of synchronization (<italic>C</italic> ≈ 2.14), after which, it predicts no effective causation in either direction.</p>
</sec>
<sec id="s3-1-2">
<title>Coupled Bi-directional Two-Species Model</title>
<p>In contrast to the Röossler-Lorenz System, the bidirectional two-species model [<xref ref-type="bibr" rid="R44">44</xref>], is calculated in discrete time, and it exhibits (unsurprisingly) bi-directional coupling:
<disp-formula id="FD12">
<alternatives>
<mml:math id="M12" display="block"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>3.8</mml:mn><mml:mo>−</mml:mo><mml:mn>3.8</mml:mn><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>C</mml:mi><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>3.5</mml:mn><mml:mo>−</mml:mo><mml:mn>3.5</mml:mn><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mn>5</mml:mn><mml:mi>C</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math>
<graphic xlink:href="2406.03212v1_eqn12.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
<label>(8)</label>
</disp-formula>
</p>
<p>where <italic>C</italic> once again is the coupling strength, noting that the coupling strength is five times larger from <italic>x → y</italic> than in the reverse direction. In this system, separability is not satisfied (i.e., information about <italic>y</italic> is redundantly present in <italic>x</italic> and vice versa). Despite the fact this model is deterministic and dynamically coupled, it shows alternating periods of positive, negative, and zero correlation [<xref ref-type="bibr" rid="R16">16</xref>]. For values of <italic>C</italic> ∈ [0, 0.35], we created a bivariate time series of length 300,000 (after a burn-in of 30,000 time points). The initial conditions were generated with random starting points drawn from the uniform distribution (0.01, 0.99).</p>
<p>Applying the four methods to these data (<xref ref-type="fig" rid="fig3">Fig. 3</xref>), we find that both TE and TACI correctly identify both the bi-directional aspect of the coupling and the increased causal link from <italic>x</italic> → <italic>y</italic> compared to <italic>y</italic> → <italic>x</italic>. CCM identifies the bi-directionality correctly, but it does not identify the relative strength of the couplings, and SLGC is unable to identify any causal link from <italic>y</italic> → <italic>x</italic>.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>FIG.3.</label>
<caption><p>Causal inference in the bidirectional species system. <bold>A-D</bold>) Results from applying the four methods to the bidirectional species system. Error bars are generated using a bootstrapping procedure (see Materials and Methods).</p></caption>
<graphic xlink:href="2406.03212v1_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s3-1-3">
<title>Coupled Autoregressive Models</title>
<p>Coupled autoregressive models are an extension of basic autoregressive models, intended to represent the dynamics of systems where multiple time series influence each other. In these models, the value of a variable at a given time point is not only a function of its own previous values but also depends on the past values of other variables in the system. Here, we study the following system consisting of two bidirectionally coupled autoregressive processes of the first order:
<disp-formula id="FD13">
<alternatives>
<mml:math id="M13" display="block"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>0.2</mml:mn><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>0.7</mml:mn><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math>
<graphic xlink:href="2406.03212v1_eqn13.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
<label>(9)</label>
</disp-formula>
</p>
<p>where <italic>C</italic> is the strength of the coupling between <italic>x</italic> and <italic>y</italic> , and ε<sub><italic>x</italic></sub>(<italic>t</italic>) and ε<sub><italic>y</italic></sub> (<italic>t</italic>) are drawn from a normal (Gaussian) distribution with a mean of 0 and <inline-formula id="ID12">
<alternatives>
<mml:math display="inline" id="I12"><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:math>
<inline-graphic xlink:href="2406.03212v1_ieq12.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
</inline-formula>. Higher values of <italic>C</italic> represent stronger couplings from <italic>x</italic> → <italic>y</italic>, and for <italic>C</italic> = 0, the system is unidirectional (only the past of <italic>y</italic> has an impact on the future of <italic>x</italic>). We examined values of <italic>C</italic> ∈ [0, 0.6] and created sets of bivariate time series of length L = 300,000 for each value of <italic>C</italic> (after a burnin time of 30,000 points). The initial conditions of the system were generated from the normal distribution with zero mean and unit variance.</p>
<p><xref ref-type="fig" rid="fig4">Fig. 4</xref> shows that SLGC does very well at identifying the onset of bi-directionality for <italic>C</italic> &gt; 0, with the coupling of <italic>x</italic> → <italic>y</italic> monotonically increasing with <italic>C</italic>. This fact is perhaps not surprising, as SLGC is based on precisely such linear systems. TACI also does a comparable job at detecting bi-directionality, even roughly predicting the switchover between <italic>x</italic> → <italic>y</italic> and <italic>y</italic> → <italic>x</italic> coupling strengths at <italic>C</italic> = 0.5. CCM, however, does not predict any coupling from <italic>y</italic> → <italic>x</italic> at <italic>C</italic> = 0, and TE does not predict any significant coupling from <italic>y</italic> → <italic>x</italic> across all values of <italic>C</italic>.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>FIG.4.</label>
<caption><p>Causal inference in the coupled autoregressive models system. <bold>A-D</bold>) Results from applying the four methods to the coupled autoregressive models system. Error bars are generated using a bootstrapping procedure (see Materials and Methods).</p></caption>
<graphic xlink:href="2406.03212v1_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig5" position="float" fig-type="figure">
<label>FIG.5.</label>
<caption><p>Causal inference in the coupled Hénon Maps system. <bold>A-D</bold>) Results from applying the four methods to the coupled Hénon Maps system. Here, only TACI accurately predicts univariate coupling across all values of <italic>C</italic> prior to synchronization. Error bars are generated using a bootstrapping procedure (see Materials and Methods).</p></caption>
<graphic xlink:href="2406.03212v1_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s3-1-4">
<title>Coupled Hénon Maps</title>
<p>Our last stationary example, the Hénon map, is a well-known example of a discrete-time dynamical system that exhibits chaotic behavior that was first developed as a simplified version of the Poincaré map of the Lorenz model [<xref ref-type="bibr" rid="R44">44</xref>], and in its chaotic regime, it is characterized by an attractor with a warped horseshoe shape. Here we consider a case of two Hénon maps, <inline-formula id="ID13">
<alternatives>
<mml:math display="inline" id="I13"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover></mml:math>
<inline-graphic xlink:href="2406.03212v1_ieq13.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
</inline-formula> and <inline-formula id="ID14">
<alternatives>
<mml:math display="inline" id="I14"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover></mml:math>
<inline-graphic xlink:href="2406.03212v1_ieq14.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
</inline-formula>, with unidirectional coupling [<xref ref-type="bibr" rid="R45">45</xref>]:
<disp-formula id="FD14">
<alternatives>
<mml:math id="M14" display="block"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1.4</mml:mn><mml:mo>−</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>0.3</mml:mn><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1.4</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>y</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>    </mml:mtext><mml:mo>+</mml:mo><mml:mn>0.3</mml:mn><mml:msub><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math>
<graphic xlink:href="2406.03212v1_eqn14.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
<label>(10)</label>
</disp-formula>
</p>
<p>where <italic>C</italic> controls the strength of the coupling from <inline-formula id="ID15">
<alternatives>
<mml:math display="inline" id="I15"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover></mml:math>
<inline-graphic xlink:href="2406.03212v1_ieq15.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
</inline-formula> to <inline-formula id="ID16">
<alternatives>
<mml:math display="inline" id="I16"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover></mml:math>
<inline-graphic xlink:href="2406.03212v1_ieq16.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
</inline-formula>. For coupling strengths above <italic>C</italic> &gt; 0.65, the systems start to show evidence of intermittent synchronizations. This on-off behavior becomes a fully synchronized state after <italic>C</italic> &gt; 0.7 [<xref ref-type="bibr" rid="R46">46</xref>]. For <italic>C</italic> ε [0,0.9], we generated sequences of length 300,000 (after a burn-in period of 30,000) and analyzed data from <italic>x</italic><sub>1</sub> and <italic>y</italic><sub>1</sub> for each of the methods. TACI is the only method out of the four that correctly identifies the uni-directional coupling between from <inline-formula id="ID17">
<alternatives>
<mml:math display="inline" id="I17"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover></mml:math>
<inline-graphic xlink:href="2406.03212v1_ieq17.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
</inline-formula> to <inline-formula id="ID18">
<alternatives>
<mml:math display="inline" id="I18"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover></mml:math>
<inline-graphic xlink:href="2406.03212v1_ieq18.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
</inline-formula> (but not from <inline-formula id="ID19">
<alternatives>
<mml:math display="inline" id="I19"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover></mml:math>
<inline-graphic xlink:href="2406.03212v1_ieq19.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
</inline-formula> to <inline-formula id="ID20">
<alternatives>
<mml:math display="inline" id="I20"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover></mml:math>
<inline-graphic xlink:href="2406.03212v1_ieq20.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
</inline-formula>), although SLGC is very close, it is statistically significantly different from zero at intermediate values of <italic>C</italic>. TE and CCM both predict bi-directional interactions, albeit with weaker coupling from <inline-formula id="ID21">
<alternatives>
<mml:math display="inline" id="I21"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover></mml:math>
<inline-graphic xlink:href="2406.03212v1_ieq21.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
</inline-formula> to <inline-formula id="ID22">
<alternatives>
<mml:math display="inline" id="I22"><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover></mml:math>
<inline-graphic xlink:href="2406.03212v1_ieq22.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
</inline-formula> than in the reverse direction.</p>
</sec>
<sec id="s3-1-5">
<title>Non-stationary Coupled Hénon Maps</title>
<p>TACI is the only method that performed well across all four artificial test cases, but the challenge remains as to whether it can identify patterns in data that change over time. To test this idea, we generated time series from the coupled Hénon maps in (10) but with timevarying couplings, <italic>C</italic><sub><italic>xy</italic></sub>(<italic>t</italic>) and <italic>C</italic><sub><italic>yx</italic></sub>(<italic>t</italic>):
<disp-formula id="FD15">
<alternatives>
<mml:math id="M15" display="block"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1.4</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>    </mml:mtext><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>0.3</mml:mn><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1.4</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>    </mml:mtext><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>x</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>y</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>0.3</mml:mn><mml:msub><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math>
<graphic xlink:href="2406.03212v1_eqn15.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
<label>(11)</label>
</disp-formula>
</p>
<p>Here, the two coupling terms are similar to the coupling term, <italic>C</italic>, in (10) but with time-varying values and potentially allowing for coupling from <italic>y</italic> to <italic>x</italic>.</p>
<p>We performed four different tests to see how TACI performs when causal interactions alter with time: <italic>(i)</italic> setting <italic>C<sub>yx</sub></italic>(<italic>t</italic>) = 0 and toggling <italic>C<sub>xy</sub></italic> (<italic>t</italic>) between 0 and 0.6, <italic>(ii)</italic> initially setting <italic>C<sub>yx</sub></italic>(<italic>t</italic>) = 0 and <italic>C<sub>xy</sub></italic> (<italic>t</italic>) = 0.6 and then switching the two half-way through the run, <italic>(iii)</italic> setting <italic>C<sub>yx</sub></italic> (<italic>t</italic>) = 0 and toggling <italic>C<sub>xy</sub></italic>(<italic>t</italic>) between 0 and 0.6 but with pulses of <italic>C<sub>xy</sub></italic> (<italic>t</italic>) = 0.6 being set to different time widths, and <italic>(iv)</italic> setting <italic>C<sub>yx</sub></italic> (<italic>t</italic>) = 0 and stepping <italic>C<sub>xy</sub></italic> (<italic>t</italic>) from 0 to 0.4 and back down again in steps of 0.1.</p>
<p>Other than the coupling changes, all time series were generated in an identical manner to the previous section. It is important to note that the network for TACI was only trained once on the entire time series, not specifically for each testing window. Thus, by creating a robust model, our network is able to identify complex causal dynamics that change in time without having to constantly fit new models, as would be the case for SLGC, CCM, and TE.</p>
<p>In <xref ref-type="fig" rid="fig6">Fig. 6</xref>, we show that TACI performs well in the first three of these scenarios, ably identifying when eliminations of causal interactions occur, as well as when <italic>C<sub>yx</sub></italic>(<italic>t</italic>) = 0 and <italic>C<sub>xy</sub></italic>(<italic>t</italic>) flip. In addition, <xref ref-type="fig" rid="fig7">Fig. 7</xref> shows that the TACI network is able to identify how coupling strengths change with time.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>FIG.6.</label>
<caption><p>TACI applied to coupled non-stationary Hénon Maps. <bold>A</bold>) A plot of the TACI inference when applied to the coupled Hénon Maps system where the coupling from <italic>X</italic> → <italic>Y</italic> is set to either <italic>C<sub>xy</sub></italic> = 0.6 (blue bar above the plot) or <italic>C<sub>xy</sub></italic> = 0 (no bar above the plot). <bold>B</bold>) Same as <bold>A</bold> but with a toggle from <italic>C<sub>xy</sub></italic> = 0.6 to <italic>C<sub>yx</sub></italic> = 0.6 (where the blue and red bars above the plot flip). <bold>C</bold>) Same as <bold>A</bold> but with multiple pulses of <italic>C<sub>xy</sub></italic> = 0.6 of varying sizes. Error bars are generated using a bootstrapping procedure (see Materials and Methods).</p></caption>
<graphic xlink:href="2406.03212v1_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig7" position="float" fig-type="figure">
<label>FIG.7.</label>
<caption><p>TACI applied to coupled non-stationary Hénon Maps with ramped couplings. <bold>A</bold>) Inferred causal coupling as a function of time during the simulation. <bold>B</bold> Time series of how the coupling from X to Y was stepped up and then down. Error bars are generated using a bootstrapping procedure (see Materials and Methods).</p></caption>
<graphic xlink:href="2406.03212v1_fig7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p><italic>a. Summary of Results on Artificial Test Systems</italic> Among the methods tested, only TACI is able to robustly infer known causal interactions between variables without incorrectly predicting non-existent interactions. TACI consistently differentiates between unidirectional and bidirectional coupling in low, moderate, and strong settings. Additionally, it accurately detects instances when the time series become synchronized in all tested scenarios. TACI excels in identifying complex causal dynamics that evolve over time, such as those observed in pulse systems with time-varying coupling. Given these successes in artificial systems, we will now apply the method to two real-world examples.</p>
</sec>
</sec>
<sec id="s3-2">
<title>Jena Climate Dataset</title>
<p>The first data set we will test our model on is the “Jena Climate Dataset”, a detailed collection of weather measurements recorded by the Max Planck Institute for Biogeochemistry from a weather station located in Jena, Germany [<xref ref-type="bibr" rid="R47">47</xref>]. The dataset spans nearly eight years – from January 10, 2009, to December 31, 2016 – and includes 14 distinct meteorological features recorded every 10 minutes. These features include a wide range of atmospheric conditions, from temperature to relative humidity to vapor pressure deficit (see <xref ref-type="table" rid="tbl1">Table I</xref> for details). Several example time series are shown in <xref ref-type="fig" rid="fig8">Fig. 8</xref>.</p>
<fig id="fig8" position="float" fig-type="figure">
<label>FIG.8.</label>
<caption><p>Time series of Temperature, Dew Point, Relative Humidity, and Vapor Pressure Deficit from the Jena Climate Dataset.</p></caption>
<graphic xlink:href="2406.03212v1_fig8.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<table-wrap id="tbl1" position="float" orientation="portrait">
<label>TABLE I.</label>
<caption><title>Summary of Jena Climate Dataset Features</title></caption>
<alternatives>
<graphic xlink:href="2406.03212v1_tbl1.tif" mime-subtype="tiff" mimetype="image"/>
<table frame="void" rules="none">
<tbody>
<tr>
<td align="left" valign="top">Feature</td>
<td align="center" valign="top">Description</td>
</tr>
<tr>
<td align="left" valign="top">Date/Time</td>
<td align="center" valign="top">Date-time reference</td>
</tr>
<tr>
<td align="left" valign="top">p (mbar)</td>
<td align="center" valign="top">Atmospheric pressure stated millibars</td>
</tr>
<tr>
<td align="left" valign="top">T (degC)</td>
<td align="center" valign="top">Temperature in Celsius</td>
</tr>
<tr>
<td align="left" valign="top">Tpot (K)</td>
<td align="center" valign="top">Temperature in Kelvin</td>
</tr>
<tr>
<td align="left" valign="top"><italic>T<sub>dew</sub></italic> (C)</td>
<td align="center" valign="top">Dew Point Temperature in Celsius</td>
</tr>
<tr>
<td align="left" valign="top"><italic>R<sub>H</sub></italic> (%)</td>
<td align="center" valign="top">Relative Humidity in percentage</td>
</tr>
<tr>
<td align="left" valign="top">VPmax (mbar)</td>
<td align="center" valign="top">Saturation vapor pressure</td>
</tr>
<tr>
<td align="left" valign="top">VPact (mbar)</td>
<td align="center" valign="top">Vapor pressure</td>
</tr>
<tr>
<td align="left" valign="top">VPdef (mbar)</td>
<td align="center" valign="top">Vapor pressure deficit</td>
</tr>
<tr>
<td align="left" valign="top">sh (g/kg)</td>
<td align="center" valign="top">Specific humidity</td>
</tr>
<tr>
<td align="left" valign="top">H<sub>2</sub>O C (mmol/mol)</td>
<td align="center" valign="top">Water vapor concentration</td>
</tr>
<tr>
<td align="left" valign="top">rho (g/m<sup>3</sup>)</td>
<td align="center" valign="top">Air density</td>
</tr>
<tr>
<td align="left" valign="top">wv (m/s)</td>
<td align="center" valign="top">Wind speed</td>
</tr>
<tr>
<td align="left" valign="top">max. wv (m/s)</td>
<td align="center" valign="top">Maximum wind speed</td>
</tr>
<tr>
<td align="left" valign="top">wd (deg)</td>
<td align="center" valign="top">Wind direction in degrees</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>A key advantage of these data is that some of the interactions are known already due to empirical models of atmospheric dynamics, providing a good test case for our method on real data. One example is the relationship between relative humidity (<italic>R<sub>H</sub></italic>), the dew point (<italic>T<sub>dew</sub></italic>), and the temperature (T), which is given by
<disp-formula id="FD16">
<alternatives>
<mml:math id="M16" display="block"><mml:msub><mml:mi>R</mml:mi><mml:mi>H</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>100</mml:mn><mml:mi>exp</mml:mi><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mn>17.625</mml:mn><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>243.04</mml:mn></mml:mrow></mml:mfrac></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mfrac><mml:mrow><mml:mn>17.625</mml:mn><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>+</mml:mo><mml:mn>243.04</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:math>
<graphic xlink:href="2406.03212v1_eqn16.tif" mime-subtype="tiff" mimetype="image"/></alternatives>
<label>(12)</label>
</disp-formula>
</p>
<p>where <italic>T<sub>dew</sub></italic> and <italic>T</italic> are in degrees Celsius and <italic>R<sub>H</sub></italic> is a percentage [<xref ref-type="bibr" rid="R48">48</xref>]. Calculating the partial derivative of <italic>R<sub>H</sub></italic> with respect to <italic>T</italic> (keeping <italic>T<sub>dew</sub></italic> fixed), we find that we should expect stronger interactions to occur from <italic>T</italic> to <italic>R<sub>H</sub></italic> at lower temperatures (<xref ref-type="fig" rid="fig9">Fig. 9A</xref>). After training our TACI model from each of the variables in the data set onto <italic>T</italic> , we indeed find that causal interactions peak during epochs when the temperature drops (<xref ref-type="fig" rid="fig9">Fig. 9B</xref>), showing that our method can accurately find temporal variations in causal interactions in messy real-world data.</p>
<fig id="fig9" position="float" fig-type="figure">
<label>FIG.9.</label>
<caption><p>Causal interactions with relative humidity from the Jena Climate Dataset. <bold>A</bold>) Empirical relationship between relative humidity and air temperature (assumes <italic>T<sub>dew</sub></italic> = 10). Note the large negative partial derivative at low values of <italic>T</italic>. <bold>B</bold>) TACI predictions for causal interactions for how the other 13 variables in <xref ref-type="table" rid="tbl1">Table I</xref> affect relative humidity as a function of time across the eight years of the dataset (gray lines, mean trajectory is the black line). Note how causal influence peaks consistently when the temperature (<bold>C</bold>) is at its nadir, just as predicted by the plot in <bold>A</bold>.</p></caption>
<graphic xlink:href="2406.03212v1_fig9.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s3-3">
<title>Electrocorticography in Non-Human Primates</title>
<p>Lastly, we used electrocorticography (ECoG) data from non-human primates to test whether our methodology can detect time-varying interactions between brain regions from these electrophysiological signals. These data exhibit extraordinarily complex dynamics that shift in time as an animal changes its state: from sleep to wake, from satiated to hungry, from attending from one object to another, and so on [<xref ref-type="bibr" rid="R2">2</xref>]. These alterations are often subtle, and, thus, understanding how different regions of the brain drive one another’s activity requires a method that can detect how slight variations in the relationship between variables lead to changing interactions across time.</p>
<p>Here, we analyzed publicly available ECoG data from a single monkey (<italic>Macaca fuscata</italic>) [<xref ref-type="bibr" rid="R49">49</xref>–<xref ref-type="bibr" rid="R51">51</xref>]. These recordings consisted of 128 channels of data that recorded activity from a hemisphere of the monkey’s brain that covered the visual, temporal, parietal, motor, prefrontal, and somatosensory cortices, sampling at 1kHz (details can be found in [<xref ref-type="bibr" rid="R49">49</xref>]). Data were collected during both awake and anesthetized states to examine neural activity across different consciousness levels. To generate an anesthetized state, the monkey was chair-restrained and propofol was injected intravenously. The recording sessions were structured into four distinct phases: an initial phase where the monkey is awake with eyes open, a subsequent phase where the monkey is awake but with its eyes covered, a phase where the monkey is under deep anesthesia, induced to reach a state of loss of consciousness, and a final stage where the monkey recovers from anesthesia with its eyes covered. The depth of anesthesia was assessed by monitoring the monkey’s responsiveness to tactile stimulation and the presence of slow wave oscillations in the ECoG signal [<xref ref-type="bibr" rid="R49">49</xref>].</p>
<p>Previous studies analyzing these data for changes in causal interactions using Spectral Granger Causality [<xref ref-type="bibr" rid="R49">49</xref>] or CCM [<xref ref-type="bibr" rid="R50">50</xref>], but each was only able to analyze data at the level of the four phases described in the previous paragraph (each requiring training a separate model, as well). Specifically, we trained TACI on one monkey (George in [<xref ref-type="bibr" rid="R51">51</xref>]) with a sequence length of 50 to account for the extended autocorrelation time observed in the time series (average of 53). Approximately 53 minutes of data corresponding to the four previously outlined phases were utilized for this purpose. The training was conducted over 300 epochs or until the point of convergence. Further details of the parameters used can be found in <xref ref-type="table" rid="tbl2">Table II</xref></p>
<table-wrap id="tbl2" position="float" orientation="portrait">
        <label>TABLE II.</label>
        <caption><title>Parameters used in the TACI model training and prediction phases (ranges indicate the parameter range used across the examples in this chapter)</title></caption>
        <alternatives>
            <graphic xlink:href="2406.03212v1_tbl2.tif" mime-subtype="tiff" mimetype="image"/>
            <table frame="hsides" rules="groups">
                <thead>
                    <tr>
                        <th align="left" valign="top">Parameter</th>
                        <th align="left" valign="top">Description</th>
                        <th align="left" valign="top">Value</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td align="left" valign="top">nb_filters</td>
                        <td align="left" valign="top">Number of filters in TCN layers.</td>
                        <td align="left" valign="top">32</td>
                    </tr>
                    <tr>
                        <td align="left" valign="top">kernel_size</td>
                        <td align="left" valign="top">Size of the kernel in TCN layers.</td>
                        <td align="left" valign="top">32</td>
                    </tr>
                    <tr>
                        <td align="left" valign="top">dilations</td>
                        <td align="left" valign="top">Dilation rates for TCN layers.</td>
                        <td align="left" valign="top">[1, 2, 4, …, 32]</td>
                    </tr>
                    <tr>
                        <td align="left" valign="top">nb_stacks</td>
                        <td align="left" valign="top">Number of stacked TCN layers.</td>
                        <td align="left" valign="top">1</td>
                    </tr>
                    <tr>
                        <td align="left" valign="top">ts_dimension</td>
                        <td align="left" valign="top">Dimensionality of the time series.</td>
                        <td align="left" valign="top">1</td>
                    </tr>
                    <tr>
                        <td align="left" valign="top">dropout_rate_tcn</td>
                        <td align="left" valign="top">Dropout rate for TCN layers.</td>
                        <td align="left" valign="top">[0.0, … , 0.5]</td>
                    </tr>
                    <tr>
                        <td align="left" valign="top">dropout_rate_hidden Dropout rate for hidden layers.</td>
                        <td align="left" valign="top">[0.0, … , 0.5]</td>
                    </tr>
                    <tr>
                        <td align="left" valign="top">conv_kernel_mit</td>
                        <td align="left" valign="top">Kernel initializer for convolutional layers.</td>
                        <td align="left" valign="top">‘he_normal’</td>
                    </tr>
                    <tr>
                        <td align="left" valign="top">latent_sample_rate</td>
                        <td align="left" valign="top">Downsampling rate in the latent space.</td>
                        <td align="left" valign="top">2</td>
                    </tr>
                    <tr>
                        <td align="left" valign="top">act_funct</td>
                        <td align="left" valign="top">Activation function used in layers.</td>
                        <td align="left" valign="top">‘elu’</td>
                    </tr>
                    <tr>
                        <td align="left" valign="top">epochs</td>
                        <td align="left" valign="top">Number of training epochs.</td>
                        <td align="left" valign="top">300</td>
                    </tr>
                    <tr>
                        <td align="left" valign="top">batch_size</td>
                        <td align="left" valign="top">Batch size for training.</td>
                        <td align="left" valign="top">512</td>
                    </tr>
                    <tr>
                        <td align="left" valign="top">shuffle</td>
                        <td align="left" valign="top">Whether to shuffle the data during training.</td>
                        <td align="left" valign="top">[True or False]</td>
                    </tr>
                    <tr>
                        <td align="left" valign="top">scaling_method</td>
                        <td align="left" valign="top">Method used for scaling the input data.</td>
                        <td align="left" valign="top">Z score</td>
                    </tr>
                    <tr>
                        <td align="left" valign="top">loss_funct</td>
                        <td align="left" valign="top">Loss function used for training.</td>
                        <td align="left" valign="top">‘mse’</td>
                    </tr>
                    <tr>
                        <td align="left" valign="top">noise</td>
                        <td align="left" valign="top">Standard deviation of Gaussian noise added.</td>
                        <td align="left" valign="top">[0.0, … , 0.5]</td>
                    </tr>
                    <tr>
                        <td align="left" valign="top">window_len</td>
                        <td align="left" valign="top">Size of the rolling window for predictions.</td>
                        <td align="left" valign="top">value</td>
                    </tr>
                    <tr>
                        <td align="left" valign="top">seq_length</td>
                        <td align="left" valign="top">Length of sequences used for training/prediction.</td>
                        <td align="left" valign="top">[10, … , 100]</td>
                    </tr>
                    <tr>
                        <td align="left" valign="top">lag</td>
                        <td align="left" valign="top">Lag between x(t) and y(t) for prediction.</td>
                        <td align="left" valign="top">[10, … , 100]</td>
                    </tr>
                </tbody>
            </table>
        </alternatives>
    </table-wrap>
<p>Finally, to compare with these previous studies, while we calculated the causal interactions between each pair of electrodes, we will present many of the results as the average result between pairs of electrodes assigned to the same region of the cortex. Here, we will be using the eight coarse-grained regions defined in [<xref ref-type="bibr" rid="R50">50</xref>]: the medial prefrontal cortex (mPFC), lateral prefrontal cortex (lPFC), pre-motor cortex (PMC), motor and somatosensory cortex (MSC), temporal cortex (TC), parietal cortex (PC), higher visual cortex (HVC), and lower visual cortex (LVC).</p>
<p><xref ref-type="fig" rid="fig10">Fig. 10</xref> shows time-averaged values of correlation (A), TACI-derived causal interactions (B), and Directionality (C), which we define as the difference in CSGI values in one direction vs. the other, for epochs of time before, during, and after anaesthetization. For correlation, we measure the average Pearson correlation coefficient between all the electrodes assigned to the various regions. Note that the diagonal terms do not necessarily have to be equal to one here, as electrodes within a region are not perfectly correlated with one another. There are only minimal changes in brain region interactions across the three time windows when measuring correlation, but large differences emerge when analyzing the data using TACI. Specifically, we see that almost all interactions disappear during the anesthetized period, with the interactions beginning to re-emerge during the recovery period. These results differ from the results from CCM in [<xref ref-type="bibr" rid="R50">50</xref>], where they claimed that while some interactions decreased, others strengthened (this effect is seen in our Directionality measurements, however). Also interesting are the nearly vertical lines in <xref ref-type="fig" rid="fig10">Fig. 10B</xref>, implying that certain regions like the mPFC might be affected broadly by signals from various parts of the cortex - a finding that agrees with the commonly held notion that the mPFC’s role often involves higher-level cognitive function [<xref ref-type="bibr" rid="R52">52</xref>]. Again, it should be noted that only one TACI network was trained per pair of interactions across all time epochs, unlike the other methods we describe, which must find interactions separately during each measurement period.</p>
<fig id="fig10" position="float" fig-type="figure">
<label>FIG.10.</label>
<caption><p>Interactions between brain regions in ECoG data. Each plot here shows the average interaction between all electrodes within each of the 8 coarse-grained regions described in the text. The left matrices are from before the anesthesia was administered, the middle matrices are from when the monkey was anesthetized, and the right plots are from the recovery period. <bold>A</bold> is the Pearson correlation between the signals, <bold>B</bold> is the TACI-derived inference of causal interaction, and <bold>C</bold> displays the TACI Directionality – the difference between the CSGI score in one direction minus the CSGI score in the other direction.</p></caption>
<graphic xlink:href="2406.03212v1_fig10.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Lastly, taking advantage of the aforementioned property of TACI, we took a finer-grained look at how interactions between a pair of regions might change with time during the experiment, specifically the mPFC and the PC. In <xref ref-type="fig" rid="fig11">Fig. 11</xref>, we show how these regions’ interactions alter with time. Using our approach, we observe how the coupling slowly decays upon administration of the propofol and how it rapidly increases a few minutes into the recovery period. Also interesting is that while during the awake periods, PC consistently has a casual interaction towards mPFC, the reverse interaction has significant temporal fluctuations whose study might lead to insights into how these brain regions drive each other during cognitive tasks.</p>
<fig id="fig11" position="float" fig-type="figure">
<label>FIG.11.</label>
<caption><p>Causal interactions across time between Parietal and medial Prefrontal Cortices. Plot of the average TACI-derived interactions between PC and mPFC over the course of the anesthesia experiment. Error bars are the standard errors of the mean across all electrode interactions, and the dashed lines represent change points in the experimental protocol (labeled above the axes).</p></caption>
<graphic xlink:href="2406.03212v1_fig11.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
</sec>
<sec id="s4" sec-type="discussion">
<title>Discussion</title>
<p>In this article, we introduce a new methodology for probing time-varying causal interactions in complex dynamical systems using a novel machine learning architecture for causal inference, Temporal Autoencoders for Causal Inference (TACI), combined with a novel metric for assessing causal interactions using surrogate data. A particular advantage of our approach is being able to train a single model that captures the dynamics of the time series across all points in time, allowing for timevarying interactions to be found without retraining, a computationally expensive endeavor for most artificial neural networks. We found that our method performed well compared to other methods in the field on synthetic data sets with known causal interactions, including those with time-varying couplings between variables. We also found that our method was able to identify known interactions between variables in a climate data set and was able to discover subtle temporal fluctuations in coupling in non-human primate ECoG data.</p>
<p>Our approach, while novel, is not without its limitations. One of the primary concerns is the extensive training time and the resource-intensive nature of the model. Implementing TACI, especially on large datasets, requires significant computational power and time. We envision that several technical improvements in the network architecture and training will allow for the method to be sped-up considerably, however. Another concern is the potential for overfitting due to TACI’s considerable modeling capacity. While the framework is designed to capture the nuanced dynamics of causal relationships over time, like most other causal network models, this method can fit data too closely if not trained properly, resulting in models that perform exceptionally well on training data but generalize poorly to unseen data. Furthermore, TACI incorporates elements of the Granger causality approach, which means it also inherits some of its problems. Granger causality assumes that the causal variable contains unique information about the future values of the effect variable, which might not always hold true in complex systems where numerous latent factors influence outcomes. Lastly, but importantly, as our approach is based solely on observational data, TACI only attempts to provide hypotheses about causal relationships between variables or to infer important relationships between variables when perturbation experiments are impossible or unethical to perform.</p>
<p>These limitations withstanding, however, the results presented in this chapter provide evidence that our approach will be broadly applicable to complicated data sets with time-varying causal structure, with particular promise for neural data, where we hope to build our understanding of how parts of the brain shift their interactions as behavioral states and needs alter in the world.</p>
</sec>
<sec id="s5" sec-type="materials|methods">
<title>Materials and Methods</title>
<p>At its core, TACI uses a two-headed autoencoder architecture implemented in a two-step process aiming to facilitate the prediction of future states and the inference of causal relationships between different time series datasets. In the first application, the two-headed autoencoder is utilized to process the original time series data, <italic>x</italic>(<italic>t</italic>) and <italic>y</italic>(<italic>t</italic>). The encoder segments of this autoencoder independently process <italic>x</italic>(<italic>t</italic>) and <italic>y</italic>(<italic>t</italic>), capturing and encoding their temporal dynamics and features into latent representations. These representations are then merged in the bottleneck, combining the distilled information from both time series into a unified latent space that encapsulates potential causal interactions. From this combined latent representation, the decoder works to reconstruct or predict the future trajectory of <italic>y</italic>(<italic>t</italic>), shifted by a time <italic>τ</italic>. The second application involves replacing <italic>x</italic>(<italic>t</italic>) with the surrogate data <italic>x</italic><sup>(<italic>s</italic>)</sup> (<italic>t</italic>). This surrogate data is generated to mimic the statistical properties of <italic>x</italic>(<italic>t</italic>) but is designed to break any potential causal link between <italic>x</italic>(<italic>t</italic>) and <italic>y</italic>(<italic>t</italic>)</p>
<p>This two-step process is essential for figuring out how these variables are linked to one another. The model can validate the presence of a causal relationship by comparing the predictive accuracy of the decoder when using the original <italic>x</italic>(<italic>t</italic>) versus the surrogate <italic>x</italic><sup>(<italic>s</italic>)</sup> (<italic>t</italic>). A significant drop in accuracy with the surrogate data suggests that the original <italic>x</italic>(<italic>t</italic>) contains specific information causally linked to the future states of <italic>y</italic>(<italic>t</italic>).</p>
<sec id="s5-1">
<title>Architecture</title>
<p>In the TACI architecture, the concept of a two-headed encoder is employed to simultaneously process two distinct time series datasets, denoted as <italic>x</italic>(<italic>t</italic>) and <italic>y</italic>(<italic>t</italic>). This design allows for the independent yet parallel analysis of each time series, enabling the model to capture and encode their individual characteristics and temporal dynamics before merging their representations during the bottleneck process. The input sequences are selected to be greater in length than the autocorrelation time of each variable. This ensures that the sequences capture meaningful temporal dependencies and dynamics. A GaussianNoise layer is added to enhance the model’s ability to generalize and prevent overfitting.</p>
<p>The most important part of the encoder includes the use of a Temporal Convolutional Network (TCN) layer. Thus, capturing the long-term dependencies within each time series. This layer utilizes several key parameters: <italic>“nb fitters”</italic> sets the number of convolutional filters, <italic>“kerneLsize”</italic> affects the temporal extent of each convolution, <italic>“dilatiois”</italic> allows the model to efficiently gather information across various temporal distances. Additionally, <italic>“Dropout”</italic> layers are used to decrease overfitting by randomly dropping units during the training phase. Following the TCN, a <italic>Conv1D</italic> layer continues to process the data for each series, allowing the network to change dimensionality while preserving temporal resolution. An <italic>AveragePooling1D</italic> layer may then downsample the <italic>Conv1D</italic> layer’s output by pooling across the temporal dimension. This operation reduces the sequence length, emphasizing significant features and further decreasing data dimensionality. The data is subsequently processed by a series of <italic>Dense</italic> layers that compress it into a dense, lower-dimensional latent representation. The size of these layers decreases in each successive layer, concentrating the information into a more compact form.</p>
<p>The bottleneck stage starts once the two-headed encoder has finished processing and compressing the input sequences into a lower-dimensional latent space representation. The Bottleneck merges these latent representations through an element-wise multiplication operation. By combining the representations in this manner, the model effectively captures the potential interactions and dependencies between the time series, which are essential for uncovering causal relationships.</p>
<p>Once the latent representations are merged in the Bottleneck, this combined representation is forwarded to the Decoder. The Decoder’s task is to predict the future trajectory of the target time series. The first step in the Decoder is to progressively upscale the combined latent representation. This is achieved through a series of <italic>Dense</italic> layers, where each layer aims to increase the dimensionality of the data. The number and size of these layers are determined by the complexity of the data and the level of compression achieved by the Encoder. After the initial upscaling, an <italic>UpSampling1D</italic> layer is used to increase the sequence length to its original size, effectively reversing the pooling operation performed in the Encoder. A TCN layer is used to ensure that the reconstructed data maintains its temporal integrity and dynamics. This layer mirrors the TCN configuration in the Encoder, utilizing the same parameters for <italic>“nb fitters”‘, “knrneLszie”</italic>, and <italic>“dilations”</italic> to capture the temporal dependencies and patterns necessary for accurate prediction. Lastly, a Dense output layer produces the final prediction of the future states of the target time series.</p>
</sec>
<sec id="s5-2">
<title>Training and Prediction</title>
<p>As discussed earlier, the training phase of the TACI model involves four distinct configurations of the network. Central to this phase is the use of the Mean Squared Error (MSE) as the loss function, which facilitates the optimization of predictions for future trajectories against actual observed values. The Adam optimizer [<xref ref-type="bibr" rid="R53">53</xref>] is employed for its adaptive learning rate capabilities. Training is performed across 300 epochs to give the model enough time for the parameters to adjust and converge toward optimal solutions. The parameters controlling the batch size and data shuffling are finely tuned to balance computational efficiency and the promotion of model generalization. Callbacks such as ReduceLROn-Plateau, EarlyStopping, and ModelCheckpoint are employed in this phase for optimizing the training process by adjusting learning rates, preventing overfitting, and preserving the best model state, respectively.</p>
<p>Surrogate data were created by drawing random values from a uniform distribution between zero and one until a time series the length of the original one was generated. An alternative method would have been to create a surrogate time series by first converting the original series into the frequency domain through a Fourier transform. Then, we could apply random phase shifts, making sure the amplitude spectrum remained unaltered. This randomness is crucial to breaking any specific temporal dependencies present in the original series. Following this process, an inverse Fourier transform could be employed to reconstruct the series back into the time domain. This step generates a new time series that mirrors the original in terms of its overall power distribution but only has random contingencies with its partner data set. In practice, however, we found that this latter methodology did not result in more accurate results in training TACI, so we focused on the initially described method for generating surrogate data in this study.</p>
<p>After training is completed, the model moves on to the prediction phase, where the focus shifts to evaluating the trained model. In the first step of the prediction phase, the pre-trained models are loaded, each representing a unique configuration designed in the training phase to capture and analyze the causal dynamics between the time series datasets <italic>x</italic>(<italic>t</italic>) and <italic>y</italic>(<italic>t</italic>). At the same time, the full original dataset is divided into sequences with the same length and structure as the models were trained on. The prediction process occurs over defined rolling windows to allow for a temporal exploration of the dataset, enabling the models to make predictions for future states of the time series within each window. The models’ accuracy in forecasting future time series states is quantitatively evaluated for each rolling window using the R<sup>2</sup> metric. To enhance the reliability and confidence of these assessments, 100 bootstrap samples are generated for each window. The causal inference for each rolling window can be determined using the CSGI <xref ref-type="disp-formula" rid="FD4">Eq. 4</xref>. Through this calculation, the model not only quantifies the strength and direction of the causal relationship but also shows its variation over time, providing a dynamic and temporal perspective on causal inference.</p>
<p>For each interval, a bootstrap strategy is implemented. This strategy involves creating a set number of surrogate samples by randomly resampling within the interval. These samples are then used to evaluate the model’s predictions, which are generated under two conditions: one using the actual interactions between the time series and another using the surrogate data. By employing <xref ref-type="disp-formula" rid="FD4">Equation 4</xref>, it’s possible to derive scores from which we compute both the mean and standard deviation. These computations provide insight into the average performance and variability of the model’s predictions across the bootstrap samples. The utilization of bootstrap methods significantly enhances the analytical depth by ensuring that the derived error bars and confidence intervals are supported by a solid statistical foundation. These statistics play a vital role in establishing the error bars in the plotted figures. By repeating this procedure across all intervals, the method provides a comprehensive view of how model performance fluctuates over time and under different conditions.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>Both authors were supported by the Human Frontier Science Program (RGY0076/2018) and the Simons Foundation (707102 &amp; 876207), and JC was supported by the NSF Physics of Living Systems Student Research Network (PHY-1806833). GJB would like to acknowledge the Aspen Center for Physics, where many of the initial ideas for this work were generated.</p>
</ack>
<ref-list>
<ref id="R1"><label>[1]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhao</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Billings</surname> <given-names>SA</given-names></string-name>, <string-name><surname>Wei</surname> <given-names>HL</given-names></string-name>, <string-name><surname>Sarrigiannis</surname> <given-names>PG</given-names></string-name></person-group>. <article-title>A Parametric Method to Measure Time-Varying Linear and Nonlinear Causality With Applications to EEG Data</article-title>. <source>IEEE Transactions on Biomedical Engineering</source>. <year>2013</year>;<volume>60</volume>(<issue>11</issue>):<fpage>3141</fpage>-<lpage>3148</lpage>. doi:<pub-id pub-id-type="doi">10.1109/TBME.2013.2269766</pub-id>.</mixed-citation></ref>
<ref id="R2"><label>[2]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Buzsáki</surname> <given-names>G</given-names></string-name></person-group>. <source>Rhythms of the Brain</source>. <publisher-loc>Oxford, UK</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>; <year>2006</year>.</mixed-citation></ref>
<ref id="R3"><label>[3]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><collab>of Scientific Unions Scientific Committee on Oceanic Research IC, of Scientific Unions Scientific Committee on Oceanic Research Canadian National Committee IC</collab></person-group>. <source>Proceedings of the Joint Oceanographic Assembly 1982 General Symposia: Dalhousie University, Halifax, Nova Scotia, Canada</source>. <publisher-name>Canadian National Committee for the Scientific Committee on Oceanic Research</publisher-name> . . . ; <year>1983</year>.</mixed-citation></ref>
<ref id="R4"><label>[4]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jammazi</surname> <given-names>R</given-names></string-name>, <string-name><surname>Ferrer</surname> <given-names>R</given-names></string-name>, <string-name><surname>Jareño</surname> <given-names>F</given-names></string-name>, <string-name><surname>Shahzad</surname> <given-names>SJH</given-names></string-name></person-group>. <article-title>Time-varying causality between crude oil and stock markets: What can we learn from a multiscale perspective?</article-title> <source>International Review of Economics &amp; Finance</source>. <year>2017</year>;<volume>49</volume>:<fpage>453</fpage>-<lpage>483</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.iref.2017.03.007</pub-id>.</mixed-citation></ref>
<ref id="R5"><label>[5]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Emirmahmutoglu</surname> <given-names>F</given-names></string-name>, <string-name><surname>Denaux</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Topcu</surname> <given-names>M</given-names></string-name></person-group>. <article-title>Time-varying causality between renewable and non-renewable energy consumption and real output: Sectoral evidence from the United States</article-title>. <source>Renewable and Sustainable Energy Reviews</source> <year>2021</year>;<volume>149</volume>:<elocation-id>e111326</elocation-id>. doi:<pub-id pub-id-type="doi">10.1016/j.rser.2021.111326</pub-id>.</mixed-citation></ref>
<ref id="R6"><label>[6]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hammoudeh</surname> <given-names>S</given-names></string-name>, <string-name><surname>Ajmi</surname> <given-names>AN</given-names></string-name>, <string-name><surname>Mokni</surname> <given-names>K</given-names></string-name></person-group>. <article-title>Relationship between green bonds and financial and environmental variables: A novel time-varying causality</article-title>. <source>Energy Economics</source>. <year>2020</year>;<volume>92</volume>:<elocation-id>e104941</elocation-id>. doi:<pub-id pub-id-type="doi">10.1016/j.eneco.2020.104941</pub-id>.</mixed-citation></ref>
<ref id="R7"><label>[7]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Latif</surname> <given-names>M</given-names></string-name>, <string-name><surname>Kleeman</surname> <given-names>R</given-names></string-name>, <string-name><surname>Eckert</surname> <given-names>C</given-names></string-name></person-group>. <article-title>Greenhouse Warming, Decadal Variability, or El Niño? An Attempt to Understand the Anomalous 1990s</article-title>. <source>Journal of Climate</source>. <year>1997</year>;<volume>10</volume>(<issue>9</issue>):<fpage>2221</fpage> - <lpage>2239</lpage>. <pub-id pub-id-type="doi">10.1175/1520-0442(1997)010&lt;2221:GWDVOE&gt;2.0.CO;2</pub-id>.</mixed-citation></ref>
<ref id="R8"><label>[8]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname> <given-names>X</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>D</given-names></string-name>, <string-name><surname>Zhou</surname> <given-names>W</given-names></string-name></person-group>. <article-title>Decadal variability of twentieth-century El Ninño and La Ninña occurrence from observations and IPCC AR4 coupled models</article-title>. <source>Geophysical Research Letters</source>. <year>2009</year>;<volume>36</volume>(<issue>11</issue>). doi:<pub-id pub-id-type="doi">10.1029/2009GL037929</pub-id>.</mixed-citation></ref>
<ref id="R9"><label>[9]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jajcay</surname> <given-names>N</given-names></string-name>, <string-name><surname>Kravtsov</surname> <given-names>S</given-names></string-name>, <string-name><surname>Sugihara</surname> <given-names>G</given-names></string-name>, <string-name><surname>Tsonis</surname> <given-names>AA</given-names></string-name>, <string-name><surname>Palus</surname> <given-names>M</given-names></string-name></person-group>. <article-title>Synchronization and causality across time scales in El Ninño Southern Oscillation</article-title>. <source>NPJ Climate and Atmospheric Science</source>. <year>2018</year>;<volume>1</volume>(<issue>1</issue>):<fpage>33</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41612-018-0043-7</pub-id>.</mixed-citation></ref>
<ref id="R10"><label>[10]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Granger</surname> <given-names>CWJ</given-names></string-name></person-group>. <article-title>Investigating Causal Relations by Econometric Models and Cross-spectral Methods</article-title>. <source>Econometrica</source>. <year>1969</year>;<volume>37</volume>(<issue>3</issue>):<fpage>424</fpage>-<lpage>438</lpage>.</mixed-citation></ref>
<ref id="R11"><label>[11]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Runge</surname> <given-names>J</given-names></string-name>, <string-name><surname>Nowack</surname> <given-names>P</given-names></string-name>, <string-name><surname>Kretschmer</surname> <given-names>M</given-names></string-name>, <string-name><surname>Flaxman</surname> <given-names>S</given-names></string-name>, <string-name><surname>Sejdinovic</surname> <given-names>D</given-names></string-name></person-group>. <article-title>Detecting and quantifying causal associations in large nonlinear time series datasets</article-title>. <source>Science Advances</source>. <year>2019</year>;<volume>5</volume>(<issue>11</issue>):<elocation-id>eaau4996</elocation-id>. doi:<pub-id pub-id-type="doi">10.1126/sciadv.aau4996</pub-id>.</mixed-citation></ref>
<ref id="R12"><label>[12]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nauta</surname> <given-names>M</given-names></string-name>, <string-name><surname>Bucur</surname> <given-names>D</given-names></string-name>, <string-name><surname>Seifert</surname> <given-names>C</given-names></string-name></person-group>. <article-title>Causal Discovery with Attention-Based Convolutional Neural Networks</article-title>. <source>Machine Learning and Knowledge Extraction</source>. <year>2019</year>;<volume>1</volume>(<issue>1</issue>):<fpage>312</fpage>-<lpage>340</lpage>. doi:<pub-id pub-id-type="doi">10.3390/make1010019</pub-id>.</mixed-citation></ref>
<ref id="R13"><label>[13]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stokes</surname> <given-names>PA</given-names></string-name>, <string-name><surname>Purdon</surname> <given-names>PL</given-names></string-name></person-group>. <article-title>A study of problems encountered in Granger causality analysis from a neuroscience perspective</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2017</year>;<volume>114</volume>(<issue>34</issue>):<elocation-id>E7063-E7072</elocation-id>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1704663114</pub-id>.</mixed-citation></ref>
<ref id="R14"><label>[14]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McCrorie</surname> <given-names>JR</given-names></string-name>, <string-name><surname>Chambers</surname> <given-names>MJ</given-names></string-name></person-group>. <article-title>Granger causality and the sampling of economic processes</article-title>. <source>Journal of Econometrics</source>. <year>2006</year>;<volume>132</volume>(<issue>2</issue>):<fpage>311</fpage>-<lpage>336</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.jeconom.2005.02.002</pub-id>.</mixed-citation></ref>
<ref id="R15"><label>[15]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yuan</surname> <given-names>AE</given-names></string-name>, <string-name><surname>Shou</surname> <given-names>W</given-names></string-name></person-group>. <article-title>Data-driven causal analysis of observational biological time series</article-title>. <source>eLife</source>. <year>2022</year>;<volume>11</volume>:<elocation-id>e72518</elocation-id>. doi:<pub-id pub-id-type="doi">10.7554/eLife.72518</pub-id>.</mixed-citation></ref>
<ref id="R16"><label>[16]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sugihara</surname> <given-names>G</given-names></string-name>, <string-name><surname>May</surname> <given-names>R</given-names></string-name>, <string-name><surname>Ye</surname> <given-names>H</given-names></string-name>, <string-name><surname>hao Hsieh</surname> <given-names>C</given-names></string-name>, <string-name><surname>Deyle</surname> <given-names>E</given-names></string-name>, <string-name><surname>Fogarty</surname> <given-names>M</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Detecting Causality in Complex Ecosystems</article-title>. <source>Science</source>. <year>2012</year>;<volume>338</volume>(<issue>6106</issue>):<fpage>496</fpage>-<lpage>500</lpage>. doi:<pub-id pub-id-type="doi">10.1126/science.1227079</pub-id>.</mixed-citation></ref>
<ref id="R17"><label>[17]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Monster</surname>, <given-names>Dan</given-names></string-name> and <string-name><surname>Fusaroli</surname>, <given-names>Riccardo</given-names></string-name> and <string-name><surname>Tylen</surname>, <given-names>Kristian</given-names></string-name> and <string-name><surname>Roepstorff</surname>, <given-names>Andreas</given-names></string-name> and <string-name><surname>Sherson</surname>, <given-names>Jacob F.</given-names></string-name></person-group> <article-title>Causal inference from noisy time-series data — Testing the Convergent Cross-Mapping algorithm in the presence of noise and external influence</article-title>. <source>Future Generation Computer Systems</source>. <year>2017</year>;<volume>73</volume>:<fpage>52</fpage>-<lpage>62</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.future.2016.12.009</pub-id>.</mixed-citation></ref>
<ref id="R18"><label>[18]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ye</surname> <given-names>H</given-names></string-name>, <string-name><surname>Deyle</surname> <given-names>ER</given-names></string-name>, <string-name><surname>Gilarranz</surname> <given-names>LJ</given-names></string-name>, <string-name><surname>Sugihara</surname> <given-names>G</given-names></string-name></person-group>. <article-title>Distinguishing time-delayed causal interactions using convergent cross mapping</article-title>. <source>Scientific Reports</source>. <year>2015</year>;<volume>5</volume>(<issue>1</issue>):<fpage>14750</fpage>. doi:<pub-id pub-id-type="doi">10.1038/srep14750</pub-id>.</mixed-citation></ref>
<ref id="R19"><label>[19]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hsieh</surname> <given-names>Ch</given-names></string-name>, <string-name><surname>Glaser</surname> <given-names>SM</given-names></string-name>, <string-name><surname>Lucas</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>Sugihara</surname> <given-names>G</given-names></string-name></person-group>. <article-title>Distinguishing random environmental fluctuations from ecological catastrophes for the North Pacific Ocean</article-title>. <source>Nature</source>. <year>2005</year>;<volume>435</volume>(<issue>7040</issue>):<fpage>336</fpage>-<lpage>340</lpage>.</mixed-citation></ref>
<ref id="R20"><label>[20]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>May</surname> <given-names>RM</given-names></string-name>, <string-name><surname>Levin</surname> <given-names>SA</given-names></string-name>, <string-name><surname>Sugihara</surname> <given-names>G</given-names></string-name></person-group>. <article-title>Ecology for bankers</article-title>. <source>Nature</source>. <year>2008</year>;<volume>451</volume>(<issue>7181</issue>):<fpage>893</fpage>-<lpage>894</lpage>.</mixed-citation></ref>
<ref id="R21"><label>[21]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mysterud</surname> <given-names>A</given-names></string-name>, <string-name><surname>Stenseth</surname> <given-names>NC</given-names></string-name>, <string-name><surname>Yoccoz</surname> <given-names>NG</given-names></string-name>, <string-name><surname>Langvatn</surname> <given-names>R</given-names></string-name>, <string-name><surname>Steinheim</surname> <given-names>G</given-names></string-name></person-group>. <article-title>Nonlinear effects of large-scale climatic variability on wild and domestic herbivores</article-title>. <source>Nature</source>. <year>2001</year>;<volume>410</volume>(<issue>6832</issue>):<fpage>1096</fpage>-<lpage>1099</lpage>.</mixed-citation></ref>
<ref id="R22"><label>[22]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Rangarajan</surname> <given-names>G</given-names></string-name>, <string-name><surname>Feng</surname> <given-names>J</given-names></string-name>, <string-name><surname>Ding</surname> <given-names>M</given-names></string-name></person-group>. <article-title>Analyzing multiple nonlinear time series with extended Granger causality</article-title>. <source>Physics Letters A</source>. <year>2004</year>;<volume>324</volume>(<issue>1</issue>):<fpage>26</fpage>-<lpage>35</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.physleta.2004.02.032</pub-id>.</mixed-citation></ref>
<ref id="R23"><label>[23]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Marinazzo</surname> <given-names>D</given-names></string-name>, <string-name><surname>Pellicoro</surname> <given-names>M</given-names></string-name>, <string-name><surname>Stramaglia</surname> <given-names>S</given-names></string-name></person-group>. <article-title>Kernel Method for Nonlinear Granger Causality</article-title>. <source>Phys Rev Lett</source>. <year>2008</year>;<volume>100</volume>:<fpage>144103</fpage>. doi:<pub-id pub-id-type="doi">10.1103/PhysRevLett.100.144103</pub-id>.</mixed-citation></ref>
<ref id="R24"><label>[24]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tank</surname> <given-names>A</given-names></string-name>, <string-name><surname>Covert</surname> <given-names>I</given-names></string-name>, <string-name><surname>Foti</surname> <given-names>N</given-names></string-name>, <string-name><surname>Shojaie</surname> <given-names>A</given-names></string-name>, <string-name><surname>Fox</surname> <given-names>EB</given-names></string-name></person-group>. <article-title>Neural Granger Causality</article-title>. <source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source>. <year>2021</year>; p. <fpage>1</fpage>-<lpage>1</lpage>. doi:<pub-id pub-id-type="doi">10.1109/tpami.2021.3065601</pub-id>.</mixed-citation></ref>
<ref id="R25"><label>[25]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schiatti</surname> <given-names>L</given-names></string-name>, <string-name><surname>Nollo</surname> <given-names>G</given-names></string-name>, <string-name><surname>Rossato</surname> <given-names>G</given-names></string-name>, <string-name><surname>Faes</surname> <given-names>L</given-names></string-name></person-group>. <article-title>Extended Granger causality: a new tool to identify the structure of physiological networks</article-title>. <source>Physiological Measurement</source>. <year>2015</year>;<volume>36</volume>(<issue>4</issue>):<fpage>827</fpage>. doi:<pub-id pub-id-type="doi">10.1088/0967-3334/36/4/827</pub-id>.</mixed-citation></ref>
<ref id="R26"><label>[26]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Granger</surname> <given-names>CWJ</given-names></string-name></person-group>. <article-title>Investigating Causal Relations by Econometric Models and Cross-spectral Methods</article-title>. <source>Econometrica</source>. <year>1969</year>;<volume>37</volume>(<issue>3</issue>):<fpage>424</fpage>-<lpage>438</lpage>.</mixed-citation></ref>
<ref id="R27"><label>[27]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Pearl</surname> <given-names>J</given-names></string-name></person-group>. <source>Causality: Models, Reasoning and Inference</source>. <edition>2nd</edition> ed. <publisher-loc>USA</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>; <year>2009</year>.</mixed-citation></ref>
<ref id="R28"><label>[28]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Goodfellow</surname> <given-names>I</given-names></string-name>, <string-name><surname>Bengio</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Courville</surname> <given-names>A</given-names></string-name></person-group>. <source>Deep Learning</source>. <publisher-name>MIT Press</publisher-name>; <year>2016</year>.</mixed-citation></ref>
<ref id="R29"><label>[29]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Louizos</surname> <given-names>C</given-names></string-name>, <string-name><surname>Shalit</surname> <given-names>U</given-names></string-name>, <string-name><surname>Mooij</surname> <given-names>J</given-names></string-name>, <string-name><surname>Sontag</surname> <given-names>D</given-names></string-name>, <string-name><surname>Zemel</surname> <given-names>R</given-names></string-name>, <string-name><surname>Welling</surname> <given-names>M</given-names></string-name></person-group>. <source>Causal Effect Inference with Deep Latent-Variable Models</source>; <year>2017</year>.</mixed-citation></ref>
<ref id="R30"><label>[30]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Goudet</surname> <given-names>O</given-names></string-name>, <string-name><surname>Kalainathan</surname> <given-names>D</given-names></string-name>, <string-name><surname>Caillou</surname> <given-names>P</given-names></string-name>, <string-name><surname>Guyon</surname> <given-names>I</given-names></string-name>, <string-name><surname>Lopez-Paz</surname> <given-names>D</given-names></string-name>, <string-name><surname>Sebag</surname> <given-names>M</given-names></string-name></person-group>. <source>Causal Generative Neural Networks</source>; <year>2018</year>.</mixed-citation></ref>
<ref id="R31"><label>[31]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nauta</surname> <given-names>M</given-names></string-name>, <string-name><surname>Bucur</surname> <given-names>D</given-names></string-name>, <string-name><surname>Seifert</surname> <given-names>C</given-names></string-name></person-group>. <article-title>Causal Discovery with Attention-Based Convolutional Neural Networks</article-title>. <source>Machine Learning and Knowledge Extraction</source>. <year>2019</year>;<volume>1</volume>(<issue>1</issue>):<fpage>312</fpage>-<lpage>340</lpage>. doi:<pub-id pub-id-type="doi">10.3390/make1010019</pub-id>.</mixed-citation></ref>
<ref id="R32"><label>[32]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Lea</surname> <given-names>C</given-names></string-name>, <string-name><surname>Vidal</surname> <given-names>R</given-names></string-name>, <string-name><surname>Reiter</surname> <given-names>A</given-names></string-name>, <string-name><surname>Hager</surname> <given-names>GD</given-names></string-name></person-group>. <chapter-title>Temporal Convolutional Networks: A Unified Approach to Action Segmentation</chapter-title>. In: <person-group person-group-type="editor"><string-name><surname>Hua</surname> <given-names>G</given-names></string-name>, <string-name><surname>Jégou</surname> <given-names>H</given-names></string-name></person-group>. <source>Computer Vision – ECCV 2016 Workshops</source>. <publisher-loc>Cham</publisher-loc>: <publisher-name>Springer International Publishing</publisher-name>; <year>2016</year>. p. <fpage>47</fpage>-<lpage>54</lpage>.</mixed-citation></ref>
<ref id="R33"><label>[33]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Bai</surname> <given-names>S</given-names></string-name>, <string-name><surname>Kolter</surname> <given-names>JZ</given-names></string-name>, <string-name><surname>Koltun</surname> <given-names>V</given-names></string-name></person-group>. <article-title>An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling</article-title>. <source>arXiv</source>. <year>2018</year>.</mixed-citation></ref>
<ref id="R34"><label>[34]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dixon</surname> <given-names>PA</given-names></string-name>, <string-name><surname>Milicich</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Sugihara</surname> <given-names>G</given-names></string-name></person-group>. <article-title>Episodic Fluctuations in Larval Supply</article-title>. <source>Science</source>. <year>1999</year>;<volume>283</volume>(<issue>5407</issue>):<fpage>1528</fpage>-<lpage>1530</lpage>. doi:<pub-id pub-id-type="doi">10.1126/science.283.5407.1528</pub-id>.</mixed-citation></ref>
<ref id="R35"><label>[35]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Takens</surname> <given-names>F</given-names></string-name></person-group>. <chapter-title>Detecting strange attractors in turbulence</chapter-title>. In: <person-group person-group-type="editor"><string-name><surname>Rand</surname> <given-names>D</given-names></string-name>, <string-name><surname>Young</surname> <given-names>LS</given-names></string-name></person-group>. <source>Dynamical Systems and Turbulence, Warwick 1980</source>. <publisher-loc>Berlin, Heidelberg</publisher-loc>: <publisher-name>Springer Berlin Heidelberg</publisher-name>; <year>1981</year>. p. <fpage>366</fpage>-<lpage>381</lpage>.</mixed-citation></ref>
<ref id="R36"><label>[36]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Deyle</surname> <given-names>ER</given-names></string-name>, <string-name><surname>Sugihara</surname> <given-names>G</given-names></string-name></person-group>. <article-title>Generalized Theorems for Nonlinear State Space Reconstruction</article-title>. <source>PLOS ONE</source>. <year>2011</year>;<volume>6</volume>(<issue>3</issue>):<fpage>1</fpage>-<lpage>8</lpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0018295</pub-id>.</mixed-citation></ref>
<ref id="R37"><label>[37]</label><mixed-citation publication-type="software"><person-group person-group-type="author"><collab>NickC1</collab></person-group>. <article-title>skccm: State-space Reconstruction by k- Nearest Neighbors Convergent Cross Mapping</article-title>. <source>GitHub</source> <year>2018</year> <ext-link ext-link-type="uri" xlink:href="https://github.com/nickc1/skccm/blob/master/skccm/skccm.py">https://github.com/nickc1/skccm/blob/master/skccm/skccm.py</ext-link>. </mixed-citation></ref>
<ref id="R38"><label>[38]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schreiber</surname> <given-names>T</given-names></string-name></person-group>. <article-title>Measuring Information Transfer</article-title>. <source>Phys Rev Lett</source>. <year>2000</year>;<volume>85</volume>:<fpage>461</fpage>-<lpage>464</lpage>. doi:<pub-id pub-id-type="doi">10.1103/PhysRevLett.85.461</pub-id>.</mixed-citation></ref>
<ref id="R39"><label>[39]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lizier</surname> <given-names>JT</given-names></string-name></person-group>. <article-title>JIDT: An information-theoretic toolkit for studying the dynamics of complex systems</article-title>. <source>Frontiers in Robotics and AI</source>. <year>2014</year>;<volume>1</volume>:<fpage>11</fpage>. doi:<pub-id pub-id-type="doi">10.3389/frobt.2014.00011</pub-id>.</mixed-citation></ref>
<ref id="R40"><label>[40]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lorenz</surname> <given-names>EN</given-names></string-name></person-group>. <article-title>Deterministic Nonperiodic Flow</article-title>. <source>Journal of the Atmospheric Sciences</source>. <year>1963</year>;<volume>20</volume>(<issue>2</issue>):<fpage>130</fpage>-<lpage>141</lpage>. <pub-id pub-id-type="doi">10.1175/1520-0469(1963)020&lt;0130:DNF&gt;2.0.CO;2</pub-id>.</mixed-citation></ref>
<ref id="R41"><label>[41]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rössler</surname> <given-names>OE</given-names></string-name></person-group>. <article-title>An Equation for Continuous Chaos</article-title>. <source>Physics Letters A</source>. <year>1976</year>;<volume>57</volume>(<issue>5</issue>):<fpage>397</fpage>-<lpage>398</lpage>. doi:<pub-id pub-id-type="doi">10.1016/0375-9601(76)90101-8</pub-id>.</mixed-citation></ref>
<ref id="R42"><label>[42]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Quyen</surname> <given-names>MLV</given-names></string-name>, <string-name><surname>Martinerie</surname> <given-names>J</given-names></string-name>, <string-name><surname>Adam</surname> <given-names>C</given-names></string-name>, <string-name><surname>Varela</surname> <given-names>FJ</given-names></string-name></person-group>. <article-title>Nonlinear analyses of interictal EEG map the brain interdependences in human focal epilepsy</article-title>. <source>Physica D: Nonlinear Phenomena</source>. <year>1999</year>;<volume>127</volume>(<issue>3</issue>):<fpage>250</fpage>-<lpage>266</lpage>. doi:<pub-id pub-id-type="doi">10.1016/S0167-2789(98)00258-9</pub-id>.</mixed-citation></ref>
<ref id="R43"><label>[43]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Quiroga</surname> <given-names>RQ</given-names></string-name>, <string-name><surname>Arnhold</surname> <given-names>J</given-names></string-name>, <string-name><surname>Grassberger</surname> <given-names>P</given-names></string-name></person-group>. <article-title>Learning driver-response relationships from synchronization patterns</article-title>. <source>Phys Rev E</source>. <year>2000</year>;<volume>61</volume>:<fpage>5142</fpage>-<lpage>5148</lpage>. doi:<pub-id pub-id-type="doi">10.1103/PhysRevE.61.5142</pub-id>.</mixed-citation></ref>
<ref id="R44"><label>[44]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hénon</surname> <given-names>M</given-names></string-name></person-group>. <article-title>A two-dimensional mapping with a strange attractor</article-title>. <source>Communications in Mathematical Physics</source>. <year>1976</year>;<volume>50</volume>(<issue>1</issue>):<fpage>69</fpage>-<lpage>77</lpage>. doi:<pub-id pub-id-type="doi">10.1007/BF01608556</pub-id>.</mixed-citation></ref>
<ref id="R45"><label>[45]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Paluš</surname> <given-names>M</given-names></string-name>, <string-name><surname>Vejmelka</surname> <given-names>M</given-names></string-name></person-group>. <article-title>Directionality of coupling from bivariate time series: How to avoid false causalities and missed connections</article-title>. <source>Phys Rev E</source>. <year>2007</year>;<volume>75</volume>:<fpage>056211</fpage>. doi:<pub-id pub-id-type="doi">10.1103/PhysRevE.75.056211</pub-id>.</mixed-citation></ref>
<ref id="R46"><label>[46]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schiff</surname> <given-names>SJ</given-names></string-name>, <string-name><surname>So</surname> <given-names>P</given-names></string-name>, <string-name><surname>Chang</surname> <given-names>T</given-names></string-name>, <string-name><surname>Burke</surname> <given-names>RE</given-names></string-name>, <string-name><surname>Sauer</surname> <given-names>T</given-names></string-name></person-group>. <article-title>Detecting dynamical interdependence and generalized synchrony through mutual prediction in a neural ensemble</article-title>. <source>Phys Rev E</source>. <year>1996</year>;<volume>54</volume>:<fpage>6708</fpage>-<lpage>6724</lpage>. doi:<pub-id pub-id-type="doi">10.1103/PhysRevE.54.6708</pub-id>.</mixed-citation></ref>
<ref id="R47"><label>[47]</label><mixed-citation publication-type="web"><source>Jena Climate Dataset</source> <ext-link ext-link-type="uri" xlink:href="https://www.bgc-jena.mpg.de/wetter/">https://www.bgc-jena.mpg.de/wetter/</ext-link>. <year>2024</year></mixed-citation></ref>
<ref id="R48"><label>[48]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lawrence</surname> <given-names>MG</given-names></string-name></person-group>. <article-title>The Relationship between Relative Humidity and the Dewpoint Temperature in Moist Air: A Simple Conversion and Applications</article-title>. <source>Bulletin of the American Meteorological Society</source>. <year>2005</year>;<volume>86</volume>(<issue>2</issue>):<fpage>225</fpage>-<lpage>234</lpage>. doi:<pub-id pub-id-type="doi">10.1175/BAMS-86-2-225</pub-id>.</mixed-citation></ref>
<ref id="R49"><label>[49]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yanagawa</surname> <given-names>T</given-names></string-name>, <string-name><surname>Chao</surname> <given-names>ZC</given-names></string-name>, <string-name><surname>Hasegawa</surname> <given-names>N</given-names></string-name>, <string-name><surname>Fujii</surname> <given-names>N</given-names></string-name></person-group>. <article-title>Large-Scale Information Flow in Conscious and Unconscious States: an ECoG Study in Monkeys</article-title>. <source>PLOS ONE</source>. <year>2013</year>;<volume>8</volume>(<issue>11</issue>):<fpage>null</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0080845</pub-id>.</mixed-citation></ref>
<ref id="R50"><label>[50]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tajima</surname> <given-names>S</given-names></string-name>, <string-name><surname>Yanagawa</surname> <given-names>T</given-names></string-name>, <string-name><surname>Fujii</surname> <given-names>N</given-names></string-name>, <string-name><surname>Toyoizumi</surname> <given-names>T</given-names></string-name></person-group>. <article-title>Untangling Brain-Wide Dynamics in Consciousness by Cross-Embedding</article-title>. <source>PLoS Comput Biol</source>. <year>2015</year>;<volume>11</volume>(<issue>11</issue>):<elocation-id>e1004537</elocation-id>. doi:<pub-id pub-id-type="doi">10.1371/journal.pcbi.1004537</pub-id>.</mixed-citation></ref>
<ref id="R51"><label>[51]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nagasaka</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Shimoda</surname> <given-names>K</given-names></string-name>, <string-name><surname>Fujii</surname> <given-names>N</given-names></string-name></person-group>. <article-title>Multidimensional Recording (MDR) and Data Sharing: An Ecological Open Research and Educational Platform for Neuroscience</article-title>. <source>PLOS ONE</source>. <year>2011</year>;<volume>6</volume>(<issue>7</issue>):<fpage>1</fpage>-<lpage>7</lpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0022561</pub-id>.</mixed-citation></ref>
<ref id="R52"><label>[52]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Anastasiades</surname> <given-names>PG</given-names></string-name>, <string-name><surname>Carter</surname> <given-names>AG</given-names></string-name></person-group>. <article-title>Circuit organization of the rodent medial prefrontal cortex</article-title>. <source>Trends in Neurosciences</source>. <year>2021</year>;<volume>44</volume>(<issue>7</issue>):<fpage>550</fpage>-<lpage>563</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.tins.2021.03.006</pub-id>.</mixed-citation></ref>
<ref id="R53"><label>[53]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Kingma</surname> <given-names>DP</given-names></string-name>, <string-name><surname>Ba</surname> <given-names>J</given-names></string-name></person-group>. <article-title>Adam: A method for stochastic optimization</article-title>. <source>arXiv</source>. <year>2014</year>;.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100692.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Nourmohammad</surname>
<given-names>Armita</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Washington</institution>
</institution-wrap>
<city>Seattle</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>important</bold> work presents a novel approach to infer causal relations in non-stationary time series data. To do so, the authors introduce a novel machine-learning model of Temporal Autoencoders for Causal Inference to identify and measure the direction and strength of time-varying causal interactions. The authors provide <bold>solid</bold> evidence for their claims through thorough numerical validation and comprehensive exploration of the method on both synthetic and real-world datasets. This is a timely contribution that may have theoretical and practical implications for diverse real-life applications.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100692.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The authors make a new contribution with careful computational validation/exploration of their method on synthetic and real-world datasets. Overall, I find their results significant and their presentation compelling.</p>
<p>Strengths:</p>
<p>The authors provide extensive computational validation of their approach to synthetic and real-world datasets of increasing complexity.</p>
<p>Weaknesses:</p>
<p>The authors should provide a comparison of their approach to other state-of-the-art neural network-based methods. Without this, it is difficult to tell which aspects of their approach (novel coupling metric, or network architecture) are most important for their results.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100692.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This paper introduces a new methodology for probing time-varying causal interactions in complex dynamical systems using a novel machine-learning architecture of Temporal Autoencoders for Causal Inference (TACI) combined with a novel metric (CSGI) for assessing causal interactions using surrogate data. This is a timely contribution in the field of causal inference from temporal data which has been largely restricted to stationary time series so far. However, the benchmarking of the proposed methods could be improved.</p>
<p>Strength:</p>
<p>The method's capacity to uncover piecewise time-varying non-linear dynamic systems is demonstrated on synthetic datasets as well as on two real-world applications on climate and brain activity data. A particular advantage of the approach is to train a single model capturing the dynamics of the whole time series, thereby allowing for time-varying interactions to be found without retraining over different time periods.</p>
<p>Weaknesses:</p>
<p>(1) It is not clear why the new metric Comparative Surrogate Granger Index CSGI (Eq.6) should be better than the Extended Granger Causality Index EGCI (Eq.5), which can also be used to compare the information about y(t) contained in the actual data x(t) versus in a randomized surrogate x^s(t), as implemented in the proposed metric (Eq.6).</p>
<p>(2) The benchmarking of the new approach TACI against earlier metrics (ie Surrogate Linear Granger, Convergent Cross Mapping, and Transfer Entropy) should be revised:</p>
<p>(a) The details of the computation should be provided to clarify how the different metrics are estimated notably between multidimensional variables [for instance to estimate Ty-&gt;x for x=(x_1,x_2,x_3) and y=(y_1,y_2,y_3)].</p>
<p>(b) Reliable implementations of the different metrics should be used, as some of the reported results do not seem right. In particular, the unidirectional examples, Eq.9 (Figure 2) and Eq.12 (Figure 5), are expected to lead to vanishing transfer entropies from Y to X, ie Ty-&gt;x =0, for all values of the coupling parameter below the synchronization threshold. This can be verified by computing transfer entropies as conditional mutual information using MIIC R package, i.e. Ty-&gt;x = I(x(t);y(t-1)|x(t-1)).</p>
<p>(c) Besides, some reported benchmarks focus on peculiar non-linear systems displaying somewhat &quot;pathological&quot; behaviors. For instance, the two Hénon maps with unidirectional coupling Eq.12 (Figure 5) lead to an equality between the two variables, i.e. y(t)=x(t) for all t, above the synchronization threshold C&gt;0.7. This leads mathematically to zero transfer entropy upon synchronization, as I(x(t);y(</p>
<p>
d) By contrast, Eq.9 (Fig.2) leads to strongly coupled, yet non-identical variables above the synchronization threshold. This strong coupling can be shown to yield non-vanishing transfer entropies in both directions, as observed in Figure 2c, and does not correspond to &quot;incorrect prediction of non-existent interactions&quot;, as stated in the &quot;Summary of Results on Artiﬁcial Test Systems&quot;. Clearly synchronized variables do interact and their bidirectional transfer entropies are actually consistent with a non-causal (or bidirectional) relationship. Only a vanishing transfer entropy in one direction implies a causal relation (in the opposite direction). Likewise, vanishing transfer entropies in both directions imply either independent variables or a spurious dependency between them due to an unobserved common cause L, i.e. X&lt;--(L)--&gt;Y. This is usually represented with a bidirected edge (X&lt;--&gt;Y), which is different from a bidirectional relation corresponding to two opposite unidirectional edges (ie X--&gt;Y and X&lt;--Y). It is therefore surprising that TACI metric vanishes in both directions upon synchronization in this case (Eq.9, Figure 2), as one would expect to learn variable y(t) more reliably using the actual data x(</p>
<p>
e) In order to assess TACI performance on non-stationary time series, it might be more informative to benchmark it on datasets displaying intermittency rather than synchrony. In particular, the change of causal directions over time, presented as one of the motivations for the new approach, should be more thoroughly benchmarked in the paper. For instance, it would be nice to demonstrate the tracking of the spontaneous reversal of causal relation in a simple 'toggle switch' regulatory network between two mutually repressing genes + expression noise. This is something that causal inference methods assuming stationarity cannot do.</p>
<p>(3) Concerning the real-world applications, the analysis of the electrocorticography (ECoG) data does not seem to be in strong disagreement with the general trends of the original more detailed study by Tajima et al 2015. Could the authors better delineate what are the common versus conflicting findings between the two approaches? The main difference appears to be the near loss of interaction in the anesthetized state, which might be linked to TACI's tendency to report no interaction between synchronized variables as discussed in d) above. Does the anesthetized state correspond to a global synchrony of the brain regions? This could be easily validated by a more direct analysis of synchrony.</p>
</body>
</sub-article>
</article>