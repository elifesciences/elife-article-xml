<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">93158</article-id>
<article-id pub-id-type="doi">10.7554/eLife.93158</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.93158.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Shared structure facilitates working memory of multiple sequences via neural replay</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4592-9270</contrib-id>
<name>
<surname>Huang</surname>
<given-names>Qiaoli</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8349-9796</contrib-id>
<name>
<surname>Luo</surname>
<given-names>Huan</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>School of Psychological and Cognitive Sciences, Peking University</institution></aff>
<aff id="a2"><label>2</label><institution>PKU-IDG/McGovern Institute for Brain Research, Peking University</institution></aff>
<aff id="a3"><label>3</label><institution>Beijing Key Laboratory of Behavior and Mental Health, Peking University</institution></aff>
<aff id="a4"><label>4</label><institution>Max Planck Institute for Human Cognitive and Brain Sciences</institution>, Leipzig, <country>Germany</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Peelen</surname>
<given-names>Marius V</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Radboud University Nijmegen</institution>
</institution-wrap>
<city>Nijmegen</city>
<country>Netherlands</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Colgin</surname>
<given-names>Laura L</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Texas at Austin</institution>
</institution-wrap>
<city>Austin</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>Address for Correspondence: Qiaoli Huang Max Planck Institute for Human Cognitive and Brain Sciences, Leipzig, Germany Stephanstraße 1A, 04103, Leipzig, Germany, <email>qiaolihuang0818@gmail.com</email>; Huan Luo, School of Psychological and Cognitive Sciences, Peking University PKU-IDG/McGovern Institute for Brain Science, Peking University <email>huan.luo@pku.edu.cn</email></corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2023-12-15">
<day>15</day>
<month>12</month>
<year>2023</year>
</pub-date>
<volume>12</volume>
<elocation-id>RP93158</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-10-11">
<day>11</day>
<month>10</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-07-19">
<day>19</day>
<month>07</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.07.18.549616"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2023, Huang &amp; Luo</copyright-statement>
<copyright-year>2023</copyright-year>
<copyright-holder>Huang &amp; Luo</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-93158-v1.pdf"/>
<abstract>
<title>Abstract</title><p>Daily experiences often involve the processing of multiple sequences, such as speech processing and spatial navigation, yet storing them challenges the limited capacity of working memory (WM). To achieve efficient memory storage, relational structures shared by sequences would be leveraged to reorganize and compress information. Here, participants memorized a sequence of items with different colors and spatial locations and later reproduced the full color and location sequences, one after another. Crucially, we manipulated the consistency between location and color sequence trajectories. First, sequences with consistent trajectories demonstrate improved memory performance and a trajectory correlation between the reproduced color and location sequences. Interestingly, color sequence undergoes spontaneous forward neural replay when recalling trajectory-consistent location sequence. These results reveal that shared common structure is spontaneously leveraged to integrate and facilitate WM of multiple sequences through neural replay and imply a role of common cognitive map in efficient information organization in WM.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>cognitive map</kwd>
<kwd>sequence</kwd>
<kwd>working memory</kwd>
<kwd>replay</kwd>
<kwd>common trajectory</kwd>
</kwd-group>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>A well-known feature of working memory (WM) is its limited capacity (<xref ref-type="bibr" rid="c4">Baddeley, 2000</xref>; <xref ref-type="bibr" rid="c16">Cowan, 2001</xref>), which constrains the amount of information that can be temporarily retained for future behavior. The limited capacity is posited to come in the form of discrete slots (<xref ref-type="bibr" rid="c61">W. Zhang &amp; Luck, 2008</xref>) or continuous distribution resources (<xref ref-type="bibr" rid="c7">Bays &amp; Husain, 2008</xref>; <xref ref-type="bibr" rid="c36">Ma et al., 2014</xref>). Meanwhile, in daily experiences, memorized items do not exist independently but are always part of a common framework or share the same structure, which could be leveraged to compress information and overcome the WM capacity challenge (<xref ref-type="bibr" rid="c11">Brady et al., 2011</xref>). For example, while shopping at a supermarket, numerous items could be grouped into a few categories, such as drinks, vegetables, fruits, and meats, to facilitate memory. Other types of abstract associations such as relational regularities could also mediate WM organization (<xref ref-type="bibr" rid="c2">Al Roumi et al., 2021</xref>; <xref ref-type="bibr" rid="c38">Mathy &amp; Feldman, 2012</xref>). In addition, computational modeling suggests that higher-order structures (e.g., summaries and relative relations) reduce memory uncertainty by constraining individual-item representations (<xref ref-type="bibr" rid="c12">Brady &amp; Tenenbaum, 2013</xref>; <xref ref-type="bibr" rid="c19">Ding et al., 2017</xref>).</p>
<p>Cognitive maps provide a general structure framework for organizing information in different tasks and across various domains(<xref ref-type="bibr" rid="c54">Whittington et al., 2020</xref>). They were first identified as representations of physical maps during navigation, but recently have been shown to also support other higher-level processes, such as conceptual knowledge, reasoning, planning, and decision-making (<xref ref-type="bibr" rid="c8">Behrens et al., 2018</xref>; <xref ref-type="bibr" rid="c9">Bellmund et al., 2018</xref>; <xref ref-type="bibr" rid="c40">O’keefe &amp; Nadel, 1978</xref>). Two major neural signatures of cognitive maps, grid-like code (<xref ref-type="bibr" rid="c15">Constantinescu et al., 2016</xref>; <xref ref-type="bibr" rid="c20">Doeller et al., 2010</xref>; <xref ref-type="bibr" rid="c26">Hafting et al., 2005</xref>; <xref ref-type="bibr" rid="c43">Park et al., 2021</xref>) and neural replay in the hippocampal-entorhinal system (<xref ref-type="bibr" rid="c22">D. J. Foster &amp; Wilson, 2006</xref>; <xref ref-type="bibr" rid="c34">Liu et al., 2019</xref>; <xref ref-type="bibr" rid="c35">Liu, Mattar, et al., 2021</xref>; <xref ref-type="bibr" rid="c49">Schuck &amp; Niv, 2019</xref>; <xref ref-type="bibr" rid="c51">Skaggs &amp; McNaughton, 1996</xref>), are identified in both spatial and non-spatial tasks. Neural replay denotes a time-compressed dynamic reactivation sequence in forward or backward direction, which is posited to not just repeat past experience, but reflect an internal model of the world (<xref ref-type="bibr" rid="c29">Kurth-Nelson et al., 2023</xref>; <xref ref-type="bibr" rid="c41">Ólafsdóttir et al., 2018</xref>).</p>
<p>Essentially, these higher-level processes can be described as mental explorations of a sequence of states within an abstract map, similar to trace a route on a physical map, implicating a common substrate for cognitive maps across domains. In line with the hypothesis, a recent study revealed the conjoined cognitive maps in the rodent hippocampus (i.e., physical space and abstract task variables) (<xref ref-type="bibr" rid="c39">Nieh et al., 2021</xref>), and alignment of different feature maps has also been found to speed learning performance (<xref ref-type="bibr" rid="c1">Aho et al., 2022</xref>). Furthermore, the generalization of cognitive maps is distance-dependent when searching for correlated rewards across domains (<xref ref-type="bibr" rid="c57">Wu et al., 2020</xref>). As such, cognitive maps might also be used to reorganize memory information across domains to overcome capacity bottlenecks in WM.</p>
<p>Here we sought to examine whether cognitive maps shared by multiple features in WM could be naturally leveraged and combined across domains to overcome WM storage limits. To address the question, participants were asked to memorize a color sequence presented at a list of spatial locations and later reproduce both the color and location sequences within two rings, respectively. In other words, subjects need to retain in WM two sequences of features, i.e., color and location, both of which could be characterized as sequence trajectories on their respective rings. Crucially, we manipulate the consistency between color and location sequence trajectories in the ring map. Specifically, for the aligned condition, the color and location sequence share a common spatial trajectory, i.e., separated by the same distance between successive items between maps (<xref rid="fig1" ref-type="fig">Figure 1B</xref>), whereas for the misaligned condition, they have distinct relative trajectories (<xref rid="fig1" ref-type="fig">Figure 1C</xref>). We hypothesize that humans would naturally detect and combine the structure shared by the two sequences to facilitate memory formation, even though it is unsupervised and non-mandatory, as proposed by efficient coding theory (<xref ref-type="bibr" rid="c3">Attneave, 1954</xref>).</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Experimental paradigm</title>
<p><bold>(A)</bold> Participants were presented with a sequence of disks of different colors and at different locations. They were asked to memorize both the location and color of the sequence and later reproduce the full location and color sequences one after another by clicking the corresponding positions on the respective report rings. During the “recall location” phase, a grey ring appeared and participants prepared for subsequent location recall without motor movement, to ensure memory decoding without motor interventions. During the following “response period”, subjects serially selected memorized spatial locations on a “location ring”. Next, a color ring appeared (“recall color”) for subjects to be ready for subsequent color recall. They then clicked the remembered colors on a “color ring” (“response period”). <bold>(B)</bold> Aligned trajectory condition (AT) wherein the trajectory distances between consecutive items (i.e., 1<sup>st</sup> to 2<sup>nd</sup>, 2<sup>nd</sup> to 3<sup>rd</sup>) of location and color sequences are identical, although the two sequences occupy different locations within their respective rings. <bold>(C)</bold> Misaligned condition (MAT), wherein the trajectory distances between consecutive items are different for location and color sequences.</p></caption>
<graphic xlink:href="549616v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To preview our findings, we provide converging behavioral and neuronal evidence for spontaneously leveraging common structures in a map to facilitate working memory. Behavioral results reveal that sequences with consistent color-location trajectories show enhanced memory precision and a significant correlation between reproduced color and location sequence trajectories. Interestingly, neural decoding of memory contents reveals that color sequences undergo temporally compressed and forward neural replay in a spontaneous manner when subjects recall location sequence that shares common underlying trajectory. Further neural decoding for the common trajectory reveals that previously formed segments of sequence trajectory are reactivated along with the newly formed trajectory segments to construct the full trajectory, which is associated with trajectory memory in behavior and neural replay. Taken together, our findings demonstrate that to make efficient use of limited capacity, the spontaneous integration of multiple sequences based on shared structures would result in spontaneous neural replay of the associated sequence and enhanced corresponding memory performance.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Experimental procedure and behavior performance</title>
<p>Thirty-three human participants performed a visual sequence WM task while their brain activities were recorded using EEG. As shown in <xref rid="fig1" ref-type="fig">Figure 1A</xref>, at the beginning of each trial, three disks with different spatial locations and colors were sequentially presented. Participants were required to concurrently remember their locations and colors as well as their orders, i.e., one location sequence and one color sequence. After a 2-second memory delay, a grey ring (location ring) was presented to instruct participants to prepare for subsequent location sequence recall without making motor responses (<xref rid="fig1" ref-type="fig">Figure 1A</xref>, “recall location” period). This is to ensure memory signals are decoded without explicit motor interventions. Next, a cursor appeared at the center of the screen (“response period”), and participants clicked the three spatial locations on a “location ring” in their correct order. Upon completion of location recall, participants were instructed to prepare for color sequence recall (“recall color”), and they clicked three locations on the color ring based on the color sequence (“response period”). One key aspect was manipulating the consistency between location and color trajectories so that the two sequences share or do not share a common structure in a cognitive map. Specifically, in the aligned trajectory condition (<italic>AT</italic> condition), despite the location and color sequences occupying different positions within their respective rings, their trajectory distances (between 1<sup>st</sup> and 2<sup>nd</sup> items and between 2<sup>nd</sup> and 3<sup>rd</sup>) were the same (<xref rid="fig1" ref-type="fig">Figure 1B</xref>). In other words, by rotating certain angles, the three points in the two rings can exactly match, and the rotated angles varied from trial to trial, which allowed us to separately decode location sequence and color sequence in the following analysis. In contrast, the location and color sequences in the misaligned trajectory condition (<italic>MAT</italic> condition) differed both in positions and trajectory distances within rings (<xref rid="fig1" ref-type="fig">Figure 1C</xref>).</p>
</sec>
<sec id="s2b">
<title>Aligned color-location trajectory improves memory performance</title>
<p>We first estimated memory precision for color and location sequences by calculating the reciprocal of circular standard deviation of response error (circular difference between reported location (color) and correct location (color)) across trials (1 ∕ σ) (<xref ref-type="bibr" rid="c6">Bays et al., 2009</xref>). As shown in <xref rid="fig2" ref-type="fig">Figure 2A</xref>, a 2-way repeated ANOVA (alignment (AT vs. MAT) × task (location vs. color)) revealed significant main effects for alignment (F<sub>(1,32)</sub> = 4.279, p = 0.047, η<sub>p</sub><sup>2</sup> = 0.118) and task (F<sub>(1,32)</sub> = 139.382, p &lt; 0.001, η<sub>p</sub><sup>2</sup> = 0.813), but nonsignificant interaction effect (F<sub>(1,32)</sub> = 0.618, p = 0.438, η<sub>p</sub><sup>2</sup> = 0.019). Specifically, AT condition had better memory performance than MAT condition, supporting our hypothesis that shared structure facilitates memory of multiple sequences. Moreover, location memory performed better than color memory. Further comparison revealed that the aligned condition mainly enhanced color memory (paired-t test, t<sub>(32)</sub> = 2.446, p = 0.020, Cohen’s d = 0.426) but not location (paired-t test, t<sub>(32)</sub> = 1.538, p = 0.134, Cohen’s d = 0.268). Better location vs. color memory performance indicates that alignment operation is less effective in improving memory (i.e., location sequence) that is already very robust (<xref ref-type="bibr" rid="c57">Wu et al., 2020</xref>). In terms of serial position in sequence, color sequences demonstrated better memory performance under AT versus MAT conditions, especially for the 2<sup>nd</sup> and 3<sup>rd</sup> items (paired-t test, 1<sup>st</sup>: t<sub>(32)</sub> = −0.315, p = 0.755, Cohen’s d = 0.055; 2<sup>nd</sup>: t<sub>(32)</sub> = 4.069, p &lt; 0.001, Cohen’s d = 0.709; 3<sup>rd</sup>: t<sub>(32)</sub> = 2.583, p = 0.015, Cohen’s d = 0.450) (<xref rid="fig2" ref-type="fig">Figure 2B</xref>). Meanwhile, the location sequences exhibited similar performance for all positions (paired-t test, 1<sup>st</sup>: t<sub>(32)</sub> = 0.972, p = 0.338, Cohen’s d = 0.169; 2<sup>nd</sup>: t<sub>(32)</sub> = 1.245, p = 0.222, Cohen’s d = 0.216; 3<sup>rd</sup>: t<sub>(32)</sub> = 1.290, p = 0.206, Cohen’s d = 0.225) (<xref rid="fig2" ref-type="fig">Figure 2C</xref>). Overall, behavioral findings demonstrate an improvement in WM performance with a common trajectory across feature domains, and indicate that the aligned trajectories (1<sup>st</sup>-2<sup>nd</sup>, 2<sup>nd</sup>-3<sup>rd</sup>) may be applied to reduce the memory uncertainty for the 2<sup>nd</sup> and 3<sup>rd</sup> colors.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Behavioral performance</title>
<p><bold>(A)</bold> Memory precision performance of location (black) and color (green) sequences for AT (dark color) and MAT (light color) conditions. Horizontal line in the boxplots denotes the median; box outlines denote the 25<sup>th</sup> and 75<sup>th</sup> percentiles; whiskers denote 1.5 × the interquartile range. Extreme values are denoted by crosses. (*: p &lt; 0.05; **: p &lt; 0.01; ***: p &lt; 0.001). <bold>(B)</bold> Memory precision of 1<sup>st</sup> (purple), 2<sup>nd</sup> (turquoise) and 3<sup>rd</sup> (blue) items of location sequence, for AT (dark color) and MAT (light color) condtions. <bold>(C)</bold> Memory precision of 1<sup>st</sup> (purple), 2<sup>nd</sup> (turquoise) and 3<sup>rd</sup> (blue) items of color sequence, for AT (dark color) and MAT (light color) condtions. <bold>(D)</bold> Grand average (mean ± SEM) correlation coefficients of recalled trajectory error between location and color sequences, for 1<sup>st</sup>-to-2<sup>nd</sup> trajectory (brown), 2<sup>nd</sup>-to-3<sup>rd</sup> trajectory (brickred), and 1<sup>st</sup>-to-3<sup>rd</sup> trajectory (orange), under AT (dark color) and MAT (light color) conditions. Dots indicate individual participant. <bold>(E)</bold> Scatterplot of 1<sup>st</sup>-to-2<sup>nd</sup> trajectory memory error for location sequence (X-axis) and Color sequence (Y-axis) under AT condition. Note that the trajectory error of all trials within each subject was divided into 4 bins according to the location trajectory error, resulting in 33 (subject number)*4 (bins) dots in the plot. The brown line represents the best linear fit. <bold>(F)</bold> Same as E, but for 2<sup>nd</sup>-to-3<sup>rd</sup> trajectory. <bold>(G)</bold> Same as E, but for 1<sup>st</sup>-to-3<sup>rd</sup> trajectory.</p></caption>
<graphic xlink:href="549616v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2c">
<title>Aligned color-location trajectory elicits color-location correlation in recalled trajectories</title>
<p>We further investigated whether the location-color trajectory alignment was truly leveraged in the memory process. Note that participants reproduced the color and location sequences by clicking three positions on the respective rings, i.e., reproducing two spatial trajectories, one for location and one for color (<xref rid="fig1" ref-type="fig">Figure 1A</xref>, reporting period). We therefore could examine the correlation between the reported location and color trajectories in their maps to determine whether the AT condition would result in a correlated pattern based on the reported sequences.</p>
<p>Specifically, we first calculated trajectory error (the circular difference between the reported trajectory and the true trajectory) for location and color features, and then accessed the correlation between the (signed) trajectory error of location and color features, for each subject. As shown in <xref rid="fig2" ref-type="fig">Figure 2D</xref>, AT condition showed significant correlations for both 1<sup>st</sup>-2<sup>nd</sup> (one-sample t-test, t <sub>(32)</sub> = 5.022, p &lt; 0.001) and 2<sup>nd</sup>-3<sup>rd</sup> (one-sample t-test, t <sub>(32)</sub> = 3.113, p = 0.004) trajectories, but not for 1<sup>st</sup>-3<sup>rd</sup> trajectory (one-sample t-test, t <sub>(32)</sub> = 1.579, p = 0.124). In contrast, the MAT condition did not display any significant correlation (one-sample t-test; 1<sup>st</sup>-2<sup>nd</sup>: t <sub>(32)</sub> = 1.361, p = 0.183; 2<sup>nd</sup>-3<sup>rd</sup>: t <sub>(32)</sub> = 0.490, p = 0.628; 1<sup>st</sup>-3<sup>rd</sup>: t <sub>(32)</sub> = −0.582, p =0.565).</p>
<p>At the group level, motivated by a previous study (<xref ref-type="bibr" rid="c32">H. H. Li et al., 2021</xref>), we quantified the trajectory correlations by first binning all trials based on the location trajectory error and then extracting the color trajectory error for each bin, for each subject. As shown in <xref rid="fig2" ref-type="fig">Figure 2 EFG</xref>, a significant correlation was observed for the 1<sup>st</sup>-2<sup>nd</sup> (r = 0.270, p = 0.002) and 2<sup>nd</sup>-3<sup>rd</sup> trajectory (r = 0.276, p = 0.003), but not for the 1<sup>st</sup>-3<sup>rd</sup> trajectory (r = 0.070, p = 0.426). Similarly, the MAT condition did not exhibit any location-color correlation in trajectories (1<sup>st</sup>-2<sup>nd</sup>: r = 0.097, p = 0.277; 2<sup>nd</sup>-3<sup>rd</sup>: r = 0.025, p = 0.790; 1<sup>st</sup>-3<sup>rd</sup>: r = −0.065, p = 0.443; also see <xref ref-type="fig" rid="figS1">Supplementary Figure 1ABC</xref>), which excludes the possibility that the reported trajectory correlation was solely due to systematic response bias.</p>
<p>Together, behavioral findings indicate that memory facilitation arises from an automatic alignment of recalled trajectories across feature domains to compress information. In other words, instead of memorizing two 3-item sequences independently, subjects may just maintain two starting points and a common trajectory.</p>
</sec>
<sec id="s2d">
<title>Neural decoding of location and color features during sequence presentation</title>
<p>We employed a time-resolved inverted encoding model (IEM) (<xref ref-type="bibr" rid="c13">Brouwer &amp; Heeger, 2009</xref>, <xref ref-type="bibr" rid="c14">2011</xref>) on EEG signals to examine the neural representation of location and color. Specifically, the slope of the reconstructed channel response was estimated to quantify the time-resolved decoding performance for the 1<sup>st</sup>, 2<sup>nd</sup>, and 3<sup>rd</sup> location and color, respectively (see details in Materials and methods) at each time point. We first focused on the encoding period when the 3-disk sequence was physically presented.</p>
<p>As shown in <xref rid="fig3" ref-type="fig">Figure 3A</xref>, the location of each of the 3 disks could be successfully decoded from EEG signals for both AT (1<sup>st</sup> location: 0.03–0.56 s, 1.14–1.26 s, 1.55–1.84 s; 2<sup>nd</sup> location: 1.56– 2.10 s, 2.65–2.92 s, 3.12–3.35 s; 3<sup>rd</sup> location: 3.06–3.50 s; corrected cluster p &lt; 0.001) and MAT conditions (1<sup>st</sup> location: 0.03–0.52 s, 1.15–1.39 s, 1.58–1.84 s,; 2<sup>nd</sup> location: 1.52–2.10 s, 3.11– 3.36 s; 3<sup>rd</sup> location: 3.06–3.54 s; corrected cluster p &lt; 0.001) during stimulus presentation period. Similarly, color information could also be decoded for both AT (1<sup>st</sup> color: 0.09–0.50 s, corrected cluster p &lt;0.001;2<sup>nd</sup> color: 1.57–2.01 s, corrected cluster p &lt;0.001; 3<sup>rd</sup> color: 3.11–3.49 s, corrected cluster p = 0.002) and MAT conditions (1<sup>st</sup> color: 0.04–0.45 s; 2<sup>nd</sup> color: 1.57–1.91 s, corrected cluster p &lt;0.001; 3<sup>rd</sup> color: 3.11–3.55 s; corrected cluster p &lt;0.001) (<xref rid="fig3" ref-type="fig">Figure 3B</xref>). It is noteworthy that location and color features were generated with the constraint that they could not occupy the same position within their respective rings. This thereby ensured the independent decoding of location and color features from the same neural signals. Moreover, the color feature exhibited weaker decoding strength than location, also consistent with behavioral results (<xref rid="fig2" ref-type="fig">Figure 2A</xref>).</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Neural representation of memory contents during encoding period</title>
<p><bold>(A)</bold> Grand average (mean ± SEM) neural decoding (slope of channel response) of location information for the 1<sup>st</sup> (purple), 2<sup>nd</sup> (turquoise) and 3<sup>rd</sup> (blue) disk as a function of time during the encoding period, for AT (left panel) and MAT conditions (right panel). Horizontal lines with corresponding colors denote significant time ranges (cluster-based permutation test, cluster-defining threshold p &lt; 0.001, corrected significance level p &lt; 0.001) <bold>(B)</bold> Same as A, but for color feature decoding.</p></caption>
<graphic xlink:href="549616v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2e">
<title>Spontaneous replay of color sequence during location recall</title>
<p>After confirming location and color representations during encoding period, we next examined the neuronal correlates of sequence memory during retrieval. We are particularly interested in the “recall location” period, during which subjects need to remain still without making motor responses but at the same time prepare for subsequent location recall (see <xref rid="fig1" ref-type="fig">Figure 1A</xref>, and upper panel of <xref rid="fig4" ref-type="fig">Figure 4</xref>). During this period, subjects need to maintain two sequences: the location sequence which is immediately task-relevant, and the color sequence which is not task-relevant right now but will be recalled later. Behavioral analysis indicates the correlation between recalled location and color trajectories for AT condition (<xref rid="fig2" ref-type="fig">Figure 2</xref>), which suggests an active combination of common trajectories across features. As a result, we sought neural evidence for the reintegration between the color sequence and the location sequence for AT condition during this period.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Spontaneous color sequence replay during “recall location”</title>
<p><bold>(A)</bold> Grand average (mean ± SEM) decoding performance for 1<sup>st</sup> (purple), 2<sup>nd</sup> (turquoise) and 3<sup>rd</sup> (blue) locations as a function of time during “recall locaiton” period, for AT (left panel) and MAT conditions (right panel). <bold>(B)</bold> Grand average (mean ± SEM) decoding performance for 1<sup>st</sup> (purple), 2<sup>nd</sup> (turquoise) and 3<sup>rd</sup> (blue) colors as a function of time during “recall locaiton” period, for AT (left panel) and MAT conditions (right panel). (Horizontal solid line: cluster-based permutation test, cluster-defining threshold p &lt; 0.05, corrected significance level p &lt; 0.05; Horizontal dashed line: marginal significance, cluster-defining threshold p &lt; 0.1, 0.05 &lt; cluster p &lt; 0.1) <bold>(C)</bold> Grand average decoding performance within the respective significant time range, for 1<sup>st</sup> (purple), 2<sup>nd</sup> (turquoise) and 3<sup>rd</sup> (blue) colors, under AT (dark color) and MAT (lignt color) conditions. <bold>(D)</bold> Cross-correlation coefficient, calculated to quantify the extent of the neural representations of adjecent two items followed a forward (positive y) or backward (negative y) transition as a funciton of time lag, between 1<sup>st</sup> and 2<sup>nd</sup> colors (brown color) and between 2<sup>nd</sup> and 3<sup>rd</sup> (brickred color) colors, and their average (grey color). Dashed vertical line denotes the peak of the averaged cross-correlation time courses. Dashed horizontal lines denote the nonparametric statistical significance threshold (p &lt; 0.05, permutation test). <bold>(E)</bold> Left panel: theoretical transition pattern for 3-item forward replay, i.e., 1<sup>st</sup>-2<sup>nd</sup>-3<sup>rd</sup>, characterized by cross-correlation at certain time lag. Right panel: empirical transitional pattern (actual cross-correlation matrix) at 130 ms time lag. A significant correlation was found between the two matrices (r = 0.690, p = 0.040), further confirming the forward replay of color sequence.</p></caption>
<graphic xlink:href="549616v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>As shown in <xref rid="fig4" ref-type="fig">Figure 4A</xref> (left panel), the currently task-relevant location sequence during AT condition displayed strong decoding performance for the 1<sup>st</sup> location (0.11–0.46 s, corrected cluster p = 0.003), weak but significant decoding performance for the 3<sup>rd</sup> location (0.27–0.41 s, corrected cluster p = 0.011), but not for the 2<sup>nd</sup> location. Moreover, The MAT condition (<xref rid="fig4" ref-type="fig">Figure 4A</xref>, right panel) showed the similar location decoding profiles (1<sup>st</sup> location: 0.11–0.46 s, corrected cluster p &lt; 0.001; 3<sup>rd</sup> location: 0.13–0.35 s, corrected cluster p = 0.002). The primacy effect might be due to the fact that the 1<sup>st</sup> location is the first to be recalled afterwards, and therefore it denotes either the most task-relevant feature or motor preparation. In fact, similar position effect has also been observed for color sequence during the color recalling period (<xref rid="figS2" ref-type="fig">Supplementary Figure 2</xref>).</p>
<p>Most importantly, we asked whether the “recall location” period also contains color sequence information, which is not task-relevant at the moment but will be recalled later. As shown in the left panel of <xref rid="fig4" ref-type="fig">Figure 4B</xref>, we observed significant reactivation of color sequence for AT condition. Specifically, the color sequence undergoes a temporally compressed, forward reply (1<sup>st</sup> color: 0.10–0.16 s, corrected cluster p = 0.048; 2<sup>nd</sup> color: 0.21–0.27 s, corrected cluster p = 0.046; 3<sup>rd</sup> color: 0.31–0.38 s, corrected cluster p = 0.089). In contrast, the MAT condition did not display any neural reactivation of the color sequence (<xref rid="fig4" ref-type="fig">Figure 4B</xref>, right panel). Direct comparison between AT and MAT conditions showed a significant reactivation difference (2-way repeated ANOVA, F<sub>(1,32)</sub> = 14.213, p = 0.001, η <sup>2</sup> = 0.308). Further analysis (<xref rid="fig4" ref-type="fig">Figure 4C</xref>) reveals that the AT-MAT difference is mainly due to the 1<sup>st</sup> (paired test, t<sub>(32)</sub> = 3.151, p = 0.003, Cohen’s d = 0.548) and 2<sup>nd</sup> items (t<sub>(32)</sub> = 1.914, p = 0.065, Cohen’s d = 0.334).</p>
<p>We next used a “sequenceness” approach (<xref ref-type="bibr" rid="c31">Kurth-Nelson et al., 2016</xref>; <xref ref-type="bibr" rid="c34">Liu et al., 2019</xref>) to characterize the sequential replay profile. Specifically, we calculated the cross-correlation coefficients between consecutive items, and then performed a permutation test to examine the statistical significance of the sequential replay profile by shuffling color labels across participants. <xref rid="fig4" ref-type="fig">Figure 4D</xref> shows a significant temporal lag around 110 ms and 140 ms for the 1<sup>st</sup>-2<sup>nd</sup> and 2<sup>nd</sup>-3<sup>rd</sup> color pairs, respectively, indicating a forward replay profile with temporal compression within approximately 130 ms (peak of the average of the two cross-correlation time courses).</p>
<p>Moreover, motivated by previous studies (<xref ref-type="bibr" rid="c33">Liu, Dolan, et al., 2021</xref>; <xref ref-type="bibr" rid="c35">Liu, Mattar, et al., 2021</xref>), we first constructed the theoretical transitional pattern for the 3-item sequence by assuming a Δt temporal lag between consecutive items (i.e., cross-correlation matrix). As shown in <xref rid="fig4" ref-type="fig">Figure 4E</xref> (left panel), the 1<sup>st</sup> item at time T could predict the reactivation of 2<sup>nd</sup> item at T+Δt, and the 2<sup>nd</sup> item at time T could predict the appearance of 3<sup>rd</sup> item at T+Δt. We then calculated the actual cross-correlation matrix (empirical transitional pattern) at 130 ms time lag which denotes the time lag of consecutive items in our findings (see <xref rid="fig4" ref-type="fig">Figure 4D</xref>, grey line), resulting in a 3 × 3 matrix (<xref rid="fig4" ref-type="fig">Figure 4E</xref>, right panel). A significant correlation was found between the empirical cross-correlation matrix and the theoretical transitional pattern (r = 0.690, p = 0.040), further confirming the forward replay of color sequence.</p>
<p>Taken together, when subjects prepare to reproduce location sequence during “recall location”, the currently task-irrelevant color sequence that shares a common trajectory with location sequence demonstrates a spontaneous sequential replay profile. Together with the color-location trajectory correlation in behavior, the findings suggest that replay-based neural mechanisms in WM mediate sequence combinations based on common structures.</p>
</sec>
<sec id="s2f">
<title>Neural representation of common trajectory and its behavioral relevance</title>
<p>After supporting multi-sequence association based on common structure, we further directly accessed the neural representations of the common trajectory structure. Specifically, a linear support vector machine (SVM) was employed to decode the 1<sup>st</sup>-to-2<sup>nd</sup> and 2<sup>nd</sup>-to-3<sup>rd</sup> trajectory distance, with the 1<sup>st</sup>-to-3<sup>rd</sup> trajectory as a control. Since there are only 8 possible circular distances between every two locations on a ring, the chance level of decoding performance is 0.125. As shown in <xref rid="fig5" ref-type="fig">Figure 5A</xref>, the neural representation of the 1<sup>st</sup>-to-2<sup>nd</sup> trajectory appeared right after the presentation of the 2<sup>nd</sup> item for AT condition (1.55–2.11 s, corrected cluster p &lt;0.001), but not after the onset of the 1<sup>st</sup> item. This is to be expected since the relationship between the 1<sup>st</sup> and 2<sup>nd</sup> items along the trajectory can only be established when the 2<sup>nd</sup> item occurs. Similarly, the 2<sup>nd</sup>-to-3<sup>rd</sup> trajectory could be decoded only after the appearance of the 3<sup>rd</sup> item (3.10–3.48 s, corrected cluster p &lt; 0.001) and (<xref rid="fig5" ref-type="fig">Figure 5B</xref>). In contrast, the control condition, i.e., the 1<sup>st</sup>-3<sup>rd</sup> trajectory, showed nonsignificant neural representation (<xref rid="fig5" ref-type="fig">Figure 5C</xref>), which was consistent with the nonsignificant color-location trajectory correlation in behavior. Interestingly, as shown in <xref rid="fig5" ref-type="fig">Figure 5A</xref>, in addition to emerging right after the 2<sup>nd</sup> item, the 1<sup>st</sup>-to-2<sup>nd</sup> trajectory appeared again right after the 3<sup>rd</sup> item (3.19–3.48 s, corrected cluster p = 0.006). Therefore, when the color and location sequences share the same trajectory (i.e., AT condition), brain activities tend to co-represent the previously formed 1<sup>st</sup>-to-2<sup>nd</sup> trajectory (reactivation) and the newly formed 2<sup>nd</sup>-to-3<sup>rd</sup> trajectory, which may help to establish the full trajectory. Notably, AT condition entails the same trajectory for the color and location sequences, while MAT condition involves different trajectories for location and color, and no significant reactivation for 1<sup>st</sup>-to-2<sup>nd</sup> location trajectory representations was observed (see <xref ref-type="fig" rid="figS1">Supplementary Figure 1DEF</xref>).</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><p><bold>(A)</bold> Grand average (mean ± SEM) neural decoding of 1<sup>st</sup>-to-2<sup>nd</sup> as a function of time during the encoding period, for AT condition. <bold>(B)</bold> Same as A, but for 2<sup>nd</sup>-to-3<sup>rd</sup> trajectory. <bold>(C)</bold> Same as A, but for 1<sup>st</sup>-to-3<sup>rd</sup> trajectory. <bold>(D)</bold> Participants were divided into two groups (higher-correlation group and lower-correlation group), based on their 1<sup>st</sup>-to-2<sup>nd</sup> color-location trajectory memory behavioral correlation. Grand average (mean ± SEM) neural decoding of 1<sup>st</sup>-to-2<sup>nd</sup> trajectory as a function of time, for higher-correlation group (N =16; left panel) and lower-correlation group (N = 16; right panel). (Horizontal solid line: cluster-based permutation test, cluster-defining threshold p &lt; 0.05, corrected significance level p &lt; 0.05).</p></caption>
<graphic xlink:href="549616v1_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Then, we were interested in whether the common trajectory reactivation was associated with behavior performance. Specifically, we divided all participants into two groups based on their 1<sup>st</sup>-to-2<sup>nd</sup> color-location trajectory memory correlations in behavior (<xref rid="fig2" ref-type="fig">Figure 2D</xref>) and then calculated the corresponding neural representation of the 1<sup>st</sup>-to-2<sup>nd</sup> trajectory, respectively. As shown in <xref rid="fig5" ref-type="fig">Figure 5D</xref>, both the higher-correlation and lower-correlation groups displayed significant neural decoding of the 1<sup>st</sup>-to-2<sup>nd</sup> trajectory right after the 2<sup>nd</sup> item (higher group: 1.56– 1.99 s, corrected cluster p &lt;0.001; lower group: 1.64–1.97 s, corrected cluster p &lt;0.001). Interestingly, only the higher-correlation group exhibited a significant reactivation of the 1<sup>st</sup>-to-2<sup>nd</sup> trajectory after the onset of the 3<sup>rd</sup> item (3.25–3.47 s, corrected cluster p = 0.018; Higher group vs. Lower group: bootstrap test, p = 0.068). Moreover, we were curious about the correlation between the common trajectory representation and latter forward replay pattern. Therefore, based on the average of trajectory neural representation (1<sup>st</sup>-2<sup>nd</sup> and 2<sup>nd</sup>-3<sup>rd</sup> trajectories) during presentation of the 3<sup>rd</sup> item when common trajectory reactivation was observed, we divided all participants into two groups, and observed higher trajectory representation group was accompanied with clearer forward replay (see <xref rid="figS3" ref-type="fig">Supplementary Figure 3</xref>). These findings provided direct evidence of the active involvement of common structure in organizing WM information across domains.</p>
<p>Taken together, when color and location sequences share the same trajectory (AT condition), the previously formed 1<sup>st</sup>-to-2<sup>nd</sup> trajectory is reactivated along with the newly formed 2<sup>nd</sup>-to-3<sup>rd</sup> trajectory. The co-occurrence of individual segments may contribute to the consolidation of a common sequence structure shared by color and location sequences. Importantly, the common structure representation could potentially predict neural replay and color-location correlation in memory performance, which further corroborates its importance in efficiently integrating sequences across domains in WM.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Identifying the underlying structure to facilitate efficient information storage in WM is crucial to human intelligence. Here, we asked whether common structures shared across different feature domains would be spontaneously employed to facilitate memory of multiple sequences. Since both location and color features could be characterized by positions along a continuous ring, we systematically manipulated the trajectory consistency between the location and color sequences. Our results indicate that color-location trajectory alignment conditions are associated with better memory performance than misaligned conditions, and the memory benefit is attributed to structure-induced constraints on individual items that decrease representational uncertainty. We also provide novel neural evidence supporting that spontaneous neural replay are essential for consolidating multiple sequences with a common underlying structure. That is to say, the employment of common structure can effectively associate two independent sequences and induce spontaneous forward replay to consolidate corresponding information.</p>
<p>Events in daily experiences are not isolated but are always linked to each other. Therefore, instead of treating individual events as independent information, a more efficient way is to seek the link between seemingly unrelated events, i.e., “connecting the dots” in the WM system. Here the trajectories for both location and color sequences are defined in a ring coordinate system, providing an abstract-level cognitive map for memory formation. Our results demonstrate that subjects spontaneously realign sequence trajectories across features to facilitate memory of two sequences. In other words, instead of memorizing two 3-item sequences, subjects could just maintain two starting points and a common trajectory, an apparently more efficient way. Not that the trajectory alignment manipulation differs from the Gestalt principles of perceptual organization such as proximity and similarity principles (<xref ref-type="bibr" rid="c25">Goldstone &amp; Medin, 1994</xref>), and it instead reflects a higher-order relationship between maps. Moreover, the alignment manipulation could not be accounted for by associative memory (<xref ref-type="bibr" rid="c1">Aho et al., 2022</xref>; <xref ref-type="bibr" rid="c45">Roads &amp; Love, 2020</xref>), since the rotational orientation for alignments between the two maps differed on a trial-by-trial basis. As a consequence, participants could not predict the color sequence solely based on the location sequence in each trial. Finally, our study is also different from recent works on structure learning and generalization (<xref ref-type="bibr" rid="c18">Dekker et al., 2022</xref>; <xref ref-type="bibr" rid="c24">Garvert et al., 2017</xref>; <xref ref-type="bibr" rid="c35">Liu, Mattar, et al., 2021</xref>; <xref ref-type="bibr" rid="c44">Ren et al., 2022</xref>; <xref ref-type="bibr" rid="c47">Schapiro et al., 2013</xref>), as our task does not involve pre-exposure training or task-related rewards.</p>
<p>The fact that without task requirement, participants still spontaneously extracted underlying common structure and leveraged it to organize multiple item storage reflects the intelligence of our brain to achieve efficient information coding (<xref ref-type="bibr" rid="c3">Attneave, 1954</xref>). Indeed, the common structure we manipulated here is inspired by the theories of cognitive map (<xref ref-type="bibr" rid="c8">Behrens et al., 2018</xref>; <xref ref-type="bibr" rid="c9">Bellmund et al., 2018</xref>; <xref ref-type="bibr" rid="c40">O’keefe &amp; Nadel, 1978</xref>), which have argued that reasoning in abstract domains follows similar computational principles as in spatial domains. This theory has been supported by accumulated neuroscientific evidence suggesting common neural substrates for knowledge representation across domains (<xref ref-type="bibr" rid="c15">Constantinescu et al., 2016</xref>; <xref ref-type="bibr" rid="c24">Garvert et al., 2017</xref>; <xref ref-type="bibr" rid="c43">Park et al., 2021</xref>; <xref ref-type="bibr" rid="c48">Schuck et al., 2016</xref>; <xref ref-type="bibr" rid="c52">Solomon et al., 2019</xref>; <xref ref-type="bibr" rid="c53">Theves et al., 2019</xref>). In line with these evidence, recent behavioral studies further prove the integration of information representation across domains based on common computing principles. For example, learning process is accelerated when two different feature maps are aligned (<xref ref-type="bibr" rid="c1">Aho et al., 2022</xref>), and distance-dependent generalization is observed across two different domains in order to search for correlated rewards (<xref ref-type="bibr" rid="c57">Wu et al., 2020</xref>). Here, we extend the functional role of cognitive map in efficiently organizing information across domains in human working memory and reveal replay-based neural mechanisms in facilitating multiple sequence storage based on common structures.</p>
<p>Neural replay refers to the sequential reactivation in the same or reversed order as previous experience. It was first observed in the rodent hippocampus and mainly for spatial navigation (<xref ref-type="bibr" rid="c55">Wilson &amp; McNaughton, 1994</xref>), but has recently been found in many higher-level non-spatial tasks in human brains (<xref ref-type="bibr" rid="c30">Kurth-Nelson et al., 2016</xref>; <xref ref-type="bibr" rid="c34">Liu et al., 2019</xref>; <xref ref-type="bibr" rid="c35">Liu, Mattar, et al., 2021</xref>; <xref ref-type="bibr" rid="c46">Schapiro et al., 2018</xref>; <xref ref-type="bibr" rid="c49">Schuck &amp; Niv, 2019</xref>; <xref ref-type="bibr" rid="c59">H. Zhang et al., 2018</xref>). In fact, neural replay has been posited to represent abstract structure (<xref ref-type="bibr" rid="c28">Huang et al., 2021</xref>; <xref ref-type="bibr" rid="c34">Liu et al., 2019</xref>), structure-based inference (<xref ref-type="bibr" rid="c35">Liu, Mattar, et al., 2021</xref>), and generalization (<xref ref-type="bibr" rid="c5">Barry &amp; Love, 2022</xref>). Here, when subjects prepare to recall location sequences (“location recall”), neural replay occurs for color sequences but not for location sequences, supporting the spontaneous nature of neural replay, since color features are not task-relevant right now. The results also exclude other interpretations, such as motor preparation, eye movements, attentional sampling, sequential rehearsal, etc., since if that is the case, we would expect a similar neural replay profile for location sequences that are to be serially recalled soon. Furthermore, color neural replay only appears for the color-location aligned sequence (AT condition) but not for the misaligned sequences (MAT condition), implicating that neural replay serves to consolidate sequences that share a common structure. Therefore, our findings demonstrate new roles of neural replay in structure representation, that is, mediating structure alignment between sequences in the WM system.</p>
<p>It is posited that structure and content are represented in a factorized manner (<xref ref-type="bibr" rid="c8">Behrens et al., 2018</xref>; <xref ref-type="bibr" rid="c10">Bengio et al., 2013</xref>), and sequence structure representation that is independent of attached contents guides the replay of new experiences (<xref ref-type="bibr" rid="c34">Liu et al., 2019</xref>). Factorization representation is thought to help fast generalization of a previously learned structure to new contents (<xref ref-type="bibr" rid="c50">Sheahan et al., 2021</xref>; <xref ref-type="bibr" rid="c62">Zhou et al., 2020</xref>). Indeed, the ability to spontaneously perceive relational structures is posited to signify the major distinction between human and nonhuman primates (<xref ref-type="bibr" rid="c17">Dehaene et al., 2015</xref>; <xref ref-type="bibr" rid="c60">H. Zhang et al., 2022</xref>). Meanwhile, previous modelling work also suggests that higher-order structures incorporated in WM would serve as constraints on individual-item representations to reduce representational uncertainty (<xref ref-type="bibr" rid="c12">Brady &amp; Tenenbaum, 2013</xref>; <xref ref-type="bibr" rid="c19">Ding et al., 2017</xref>). In this work, we provide evidence that not only structure is dissociated from content representation, i.e., factorization coding, but that the abstract structures can also be aligned in a spontaneous manner, i.e., linking structures, which together contribute to efficient representation of memory information.</p>
</sec>
<sec id="s4">
<title>Materials and methods</title>
<sec id="s4a">
<title>Participants</title>
<p>Thirty-six participants (18 males, age ranging from 17 to 25 years) were recruited to accomplish our multi-sequence working memory task. Three participants were removed, since they could not finish the whole experiment. No statistical methods were used to predetermine sample sizes, but our sample sizes are similar to previous studies (<xref ref-type="bibr" rid="c32">Li et al., 2021</xref>; <xref ref-type="bibr" rid="c56">Wolff et al., 2017</xref>). All participants had normal or corrected-to-normal vision with no history of neurological disorders. They were naïve to the purpose of the experiments, and provided written informed consent prior to the start of the experiment. This study was approved by the Research Ethics Committee at Peking University, and carried out in accordance with the Declaration of Helsinki.</p>
</sec>
<sec id="s4b">
<title>Stimuli and tasks</title>
<p>Participants sat in a dark room, 60 cm in front of a Display++ monitor with 100 Hz refresh rate and a resolution of 1920 × 1080, and their head stabilized on a chin rest. At the beginning of trial, three disks (1.5° × 1.5° visual angle) were sequentially presented at different locations of the screen, with different colors. The spatial location of each disk was independently drawn from a fixed set of 9 locations, which were evenly distributed on an imaginary circle with radius of 7° visual angle from central fixation and spaced 40° from the nearest locations, with a small random jitter (± 1° – ± 3°) added to each. The color of the each disk was also independently selected from a fixed set of 9 colors, which were evenly distributed along a circle in Commission Internationale de l’Eclairage (CIE) L*a*b* space, and equidistant from the gray point at L* = 50, a* = 0, and b* = 0 (<xref ref-type="bibr" rid="c13">Brouwer &amp; Heeger, 2009</xref>), and spaced by 40°, with a small random jitter (± 1° – ± 3°). Each disk was presented for 1 s, with 0.5 s interval between two adjacent disks. After 2 s delay during which only the fixation point remained on screen, a grey ring appeared for 0.5 s with the same radius (7° visual angle) from central fixation to instruct participants to recall three spatial locations without any movement. Then, a cursor appeared at fixation, and participants should report the remembered locations sequentially in their presented order by using a mouse to click on the grey location ring. After delivering three spatial location responses, a color ring was presented for 0.5 s (7° visual angle in radius) to instruct participants to the recall three colors without any movement. Similarly, a cursor then appeared, and participants were asked to report the remembered colors sequentially in their presented order by clicking on the color ring.</p>
<p>Note that even though color and location were different features, their values were both chosen from nine positions/values based on their respective ring (0° –320° in 40° increments), with the constraint that the color value and location value for the same item can’t be the same. In order to investigate whether common structure would organize multiple information storage in different domains, we modulated trajectory consistency. Specifically, in the aligned trajectory condition (AT), both the 1<sup>st</sup>-to-2<sup>nd</sup> and 2<sup>nd</sup>-to-3<sup>rd</sup> disk trajectory distances in location domain were the same to that in color domain. In other words, by rotating certain degree, the whole trajectory (from the 1<sup>st</sup> to 3<sup>rd</sup> point) was matched in the location and color maps. At the same time, we varied the rotated degree to align the two maps on a trial-by-trial basis, such that we could not predict color sequence solely based on location sequence. This manipulation was critical to independently decode color sequence and location sequence. In misaligned trajectory condition (MAT), the whole trajectories in the two maps were different, which meant we couldn’t rotate one map to exactly match the other map. Trials from AT and MAT conditions were interleaved, aiming to investigate the spontaneous information organization process in a more natural way. In each trial three locations were chosen independently from 9 values (0° –320° in 40° increments, each occurred 36 times with random order), but with a constraint that they should at least differ by 40°. The same rule was applied to three colors. Moreover, the color and location value from the same object were also constrained to be different. Participants should complete 648 trials in total, which was divided into two sessions on two separate days, separated by at most one week. It took approximately 3 hours to accomplish one session (including breaks).</p>
</sec>
<sec id="s4c">
<title>EEG acquisition and preprocessing</title>
<p>The EEG data was recorded using a 64-channel EasyCap and two BrainAmp amplifiers (BrainProducts). Horizontal electrooculography (EOG) was recorded by an additional electrode around the participants’ right eye. The impedances of all electrodes were kept below 10 k. The EEG data was preprocessed offline using FieldTrip software (<xref ref-type="bibr" rid="c42">Oostenveld et al., 2011</xref>). Specifically, the data was first referenced to the average value of all channels, band-pass filtered between 2 and 50 Hz, and down-sampled to 100 Hz. The data was then baseline-corrected, by selecting the time range from 300 ms to 100 ms before the presentation of the 1<sup>st</sup> disk in each trial as baseline to be subtracted. Then, independent component analysis (ICA) was performed independently for each participant to remove eye-movement and artifact components, and the remaining components were back-projected onto the EEG electrode space. To further identify artifacts, we calculated the variance (collapsed over channels and time) for each trial. Trials with excessive variances were removed. Note that following decoding approach was based on the whole electrodes, except that location decoding in the encoding period was based on the posterior electrodes (P7, P5, P3, P1, Pz, P4, P6, P8, PO7, PO3, POz, PO4, PO8, O1, Oz and O2), considering eye movement was not strictly controlled in the present study.</p>
</sec>
</sec>
<sec id="s5">
<title>Data analysis</title>
<sec id="s5a">
<title>Behavioral performance analysis</title>
<p>For each spatial location and color, the response error was first quantified by the circular difference between the reported location (color) and the true target location (color) in each trial. The memory precision was then estimated by calculating the reciprocal of circular standard deviation of response error. To explore the similarity of the perceived trajectory in spatial location and color domains, we calculated the circular correlation of the perceived trajectory (trajectory memory error) between the two domains for each participant. Trajectory response error was quantified by the circular difference between the reported trajectory and the true trajectory, e.g., the 1<sup>st</sup>-to-2<sup>nd</sup> trajectory error in location was calculated by the difference between the 1<sup>st</sup> location error and 2<sup>nd</sup> location error. In group level, we quantified the circular correlations of trajectory error by first sorting trials into four bins based on their location trajectory error for each participant, then binning the trials, computing the color trajectory error for each bin, and pooling the data across participants.</p>
</sec>
<sec id="s5b">
<title>Time-resolved location and color decoding</title>
<p>Similar as previous studies (<xref ref-type="bibr" rid="c13">Brouwer &amp; Heeger, 2009</xref>, <xref ref-type="bibr" rid="c14">2011</xref>; <xref ref-type="bibr" rid="c28">Huang et al., 2021</xref>), in order to assess the time-resolved location and color information from the EEG signals, we implemented the inverted encoding model (IEM) to reconstruct the location and color information from the neural activities at each time point. The IEM assumes that the response in each sensor could be approximated as a linear sum of underlying neural populations encoding different values of the feature-of-interest (i.e., tuning channels). Here, the number of location and color tuning channels were both set to 9. Following previous work (<xref ref-type="bibr" rid="c21">Ester et al., 2015</xref>; <xref ref-type="bibr" rid="c58">Yu et al., 2020</xref>), the idealized feature tuning curves of nine channels were defined as nine half-wave rectified sinusoids centered at different location (color) values (0°, 40°, 80°, and so on) and raised to the 8<sup>th</sup> power.</p>
<p>We began by modeling the response of each EEG sensor as a linear sum of nine information channels, characterized by <italic>B</italic><sub>1</sub> = <italic>WC</italic><sub>1</sub>, in the training data set, where <italic>B</italic><sub>1</sub> (m sensors × n trials) represents the observed response at each sensor, <italic>C</italic><sub>1</sub> (k channels × n trials) represents the predicted channel responses, <italic>W</italic> (m sensors × k channels) represents the weight matrix that characterizes the linear mapping from ‘channel space’ to ‘sensor space’. Therefore, given <italic>B</italic><sub>1</sub>, and <italic>C</italic><sub>1</sub>, the weight matrix <italic>W</italic> (m sensors × k channels) was calculated by using least-squares regression <inline-formula><alternatives><inline-graphic xlink:href="549616v1_inline1.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. Finally, the channel responses (<italic>C</italic><sub>2</sub>) for the test data set (<italic>B</italic><sub>2</sub>) could be extracted using the estimated <inline-formula><alternatives><inline-graphic xlink:href="549616v1_inline2.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, by <inline-formula><alternatives><inline-graphic xlink:href="549616v1_inline3.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>.</p>
<p>Regarding the division of training and test set, a leave one-out cross-validation was implemented, such that data from all but one block was acted as <italic>B</italic><sub>1</sub> to estimate <inline-formula><alternatives><inline-graphic xlink:href="549616v1_inline4.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, while data from the remaining block was acted as <italic>B</italic><sub>2</sub> to estimate <inline-formula><alternatives><inline-graphic xlink:href="549616v1_inline5.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. This procedure ensures the independence between training set and testing set. The entire analysis was repeated until all blocks could be held out as a test set. The observed channel responses <inline-formula><alternatives><inline-graphic xlink:href="549616v1_inline6.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> were then circularly shifted to a common center (0°) in reference to the location/color-of-interest in each trial, and averaged across trials for further analysis.</p>
<p>Consistent with previous studies (<xref ref-type="bibr" rid="c23">J. J. Foster et al., 2017</xref>; <xref ref-type="bibr" rid="c28">Huang et al., 2021</xref>), decoding performance was characterized by the slope of the estimated channel responses at each time by flipping the reconstructed curves across the center, averaging both sides, and performing linear regression. We further smoothed the slope time courses with a Gaussian kernel (s.d. = 40 ms) (<xref ref-type="bibr" rid="c28">Huang et al., 2021</xref>; <xref ref-type="bibr" rid="c56">Wolff et al., 2017</xref>).</p>
</sec>
<sec id="s5c">
<title>Forward sequence measure</title>
<p>Following previous studies (<xref ref-type="bibr" rid="c27">Huang et al., 2018</xref>; <xref ref-type="bibr" rid="c30">Kurth-Nelson et al., 2016</xref>; <xref ref-type="bibr" rid="c34">Liu et al., 2019</xref>), cross-correlation was applied to examine whether the color reactivation pattern tended to follow certain order, e.g., a forward (1<sup>st</sup>-2<sup>nd</sup>-3<sup>rd</sup>) or reverse order (3<sup>rd</sup>-2<sup>nd</sup>-1<sup>st</sup>). If it was a forward sequence, the decoded performance of the 1<sup>st</sup> item at time T should be correlated with the decoding performance of 2<sup>nd</sup> item at time T + Δt, and correlated with the decoding performance of 3<sup>rd</sup> item at time T + 2*Δt, where Δt defines a lag between neural representations of two consecutive items. We first calculated the cross-correlation between the 1<sup>st</sup> and 2<sup>nd</sup> items and between 2<sup>nd</sup> and 3<sup>rd</sup> items at each time lag. Then we subtracted the reverse direction (2<sup>nd</sup>-1<sup>st</sup>; 3<sup>rd</sup>-2<sup>nd</sup>) from the forward direction (1<sup>st</sup>-2<sup>nd</sup>; 2<sup>nd</sup>-3<sup>rd</sup>) respectively at each time-lag, in order to exclude the autocorrelation effect (<xref ref-type="bibr" rid="c30">Kurth-nelson et al., 2016</xref>). The resulted cross-correlation time courses were then averaged to determine the time lag for two consecutive items, here, the time point of the peak of the averaged cross-correlation time course. As mentioned above, for a forward replay pattern, at time lag Δt, we would expect to observe significant transition from the 1<sup>st</sup> to 2<sup>nd</sup> items, and from the 2<sup>nd</sup> to 3<sup>rd</sup> items, while nonsignificant transition/correlation for the rest pairs, characterized by a theoretical forward transition pattern in <xref rid="fig4" ref-type="fig">Figure 4E</xref> (left panel). Meanwhile, the actual cross-correlation matrix can be estimated by computing the correlation coefficients for every pair (1<sup>st</sup>-1<sup>st</sup>, 1<sup>st</sup>-2<sup>nd</sup>, 1<sup>st</sup>-3<sup>rd</sup>; 2<sup>nd</sup>-1<sup>st</sup>, 2<sup>nd</sup>-2<sup>nd</sup>, 2<sup>nd</sup>-3<sup>rd</sup>; 3<sup>rd</sup>-1<sup>st</sup>, 3<sup>rd</sup>-2<sup>nd</sup>, 3<sup>rd</sup>-3<sup>rd</sup>) at the defined time lag (<xref rid="fig4" ref-type="fig">Figure 4D</xref>). Finally, we quantified the similarity between the observed transition pattern and theoretical forward transition pattern.</p>
</sec>
<sec id="s5d">
<title>Time-resolved trajectory decoding</title>
<p>We implemented a linear support vector machine (SVM) to decode trajectory distance. Considering there were eight possible distances between every two items, i.e., ±160°, ±120°, ±80°, ±40° (chance level is 1/8), an eight-way decoder (One-VS-rest multiclass classifier) was used to decode trajectory. A 5-fold cross-validation scheme was used, and the classification accuracy was averaged across the folds. We repeated this process 10 times with each containing a new random partition of data into 5 folds, and then computed their mean accuracy. Note that color and location sequences shared the same trajectory distances in AT condition, while MAT condition involved different trajectories for location and color. The trajectory decoding in MAT condition was based on the trajectory distance in location domain, considering location information showed much stronger representation than color information (<xref rid="fig2" ref-type="fig">Figure 2</xref>).</p>
</sec>
<sec id="s5e">
<title>Statistical analysis</title>
<p>To determine statistical significance of decoding performance time courses, we performed cluster-based permutation test (FieldTrip, cluster-based permutation test, 1000 permutations) (<xref ref-type="bibr" rid="c37">Maris &amp; Oostenveld, 2007</xref>). We first identified clusters of contiguous significant time points (p &lt; 0.05 or p &lt; 0.001(during encoding period), two-tailed) from the calculated statistics (one-sample t-test, against 0 (slope value of the reconstructed channel response) for location/color decoding, or against 0.125 (classifier chance level) for trajectory distance decoding), and cluster-level statistics was calculated by computing the size of the clusters. Next, a Monte-Carlo randomization procedure was conducted to estimate the significance probabilities for each cluster. Specifically, 0 (for location/color decoding) or 0.125 (for trajectory decoding) with the same sample size was generated and shuffled with the original data 1000 times, and the cluster-level statistics were then calculated from the surrogate data to estimate the significance probabilities for each original cluster.</p>
<p>To determine statistical significance of cross-correlation coefficient (forward direction minus reverse direction), we performed a permutation test by shuffling color labels across participants 1000 times and followed the same procedure to calculate the cross-correlation time courses of the surrogate data, from which the 0.05 threshold level was estimated.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>This work was supported by the National Science and Technology Innovation STI2030-Major Project (2021ZD0204103 to H.L.), National Natural Science Foundation of China (31930052 to H.L.), and Humboldt Research Fellowship for Postdocs to Q.H.. We thank Christian F. Doeller and Muzhi Wang for his helpful comments.</p>
</ack>
<ref-list>
<title>Reference</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Aho</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Roads</surname>, <given-names>B. D.</given-names></string-name>, &amp; <string-name><surname>Love</surname>, <given-names>B. C.</given-names></string-name> (<year>2022</year>). <article-title>System alignment supports cross-domain learning and zero-shot generalisation</article-title>. <source>Cognition</source>, <volume>227</volume>(<issue>November 2021</issue>), 105200. <pub-id pub-id-type="doi">10.1016/j.cognition.2022.105200</pub-id></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Al Roumi</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Marti</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Amalric</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Dehaene</surname>, <given-names>S.</given-names></string-name> (<year>2021</year>). <article-title>Mental compression of spatial sequences in human working memory using numerical and geometrical primitives</article-title>. <source>Neuron</source>, <volume>109</volume>(<issue>16</issue>), <fpage>2627</fpage>–<lpage>2639.e4</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2021.06.009</pub-id></mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Attneave</surname>, <given-names>F.</given-names></string-name> (<year>1954</year>). <article-title>Some informational aspects of visual perception</article-title>. <source>Psychological Review</source>, <volume>61</volume>(<issue>3</issue>), <fpage>183</fpage>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Baddeley</surname>, <given-names>A.</given-names></string-name> (<year>2000</year>). <article-title>The episodic buffer: A new component of working memory?</article-title> <source>Trends in Cognitive Sciences</source>, <volume>4</volume>(<issue>11</issue>), <fpage>417</fpage>–<lpage>423</lpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Barry</surname>, <given-names>D. N.</given-names></string-name>, &amp; <string-name><surname>Love</surname>, <given-names>B. C.</given-names></string-name> (<year>2022</year>). <article-title>A neural network account of memory replay and knowledge consolidation</article-title>. <source>Cerebral Cortex</source>, <fpage>1</fpage>–<lpage>13</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhac054</pub-id></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Bays</surname>, <given-names>P. M.</given-names></string-name>, <string-name><surname>Catalao</surname>, <given-names>R. F.</given-names></string-name>, &amp; <string-name><surname>Husain</surname>, <given-names>M.</given-names></string-name> (<year>2009</year>). <article-title>The precision of visual working memory is set by allocation of a shared resource</article-title>. <source>Journal of Vision</source>, <volume>9</volume>(<issue>10</issue>), <fpage>7</fpage>–<lpage>7</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Bays</surname>, <given-names>P. M.</given-names></string-name>, &amp; <string-name><surname>Husain</surname>, <given-names>M.</given-names></string-name> (<year>2008</year>). <article-title>Dynamic shifts of limited working memory resources in human vision</article-title>. <source>Science</source>, <volume>321</volume>(<issue>5890</issue>), <fpage>851</fpage>–<lpage>854</lpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Behrens</surname>, <given-names>T. E. J.</given-names></string-name>, <string-name><surname>Muller</surname>, <given-names>T. H.</given-names></string-name>, <string-name><surname>Whittington</surname>, <given-names>J. C. R.</given-names></string-name>, <string-name><surname>Mark</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Baram</surname>, <given-names>A. B.</given-names></string-name>, <string-name><surname>Stachenfeld</surname>, <given-names>K. L.</given-names></string-name>, &amp; <string-name><surname>Kurth-Nelson</surname>, <given-names>Z.</given-names></string-name> (<year>2018</year>). <article-title>What Is a Cognitive Map? Organizing Knowledge for Flexible Behavior</article-title>. <source>Neuron</source>, <volume>100</volume>(<issue>2</issue>), <fpage>490</fpage>–<lpage>509</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2018.10.002</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Bellmund</surname>, <given-names>J. L. S.</given-names></string-name>, <string-name><surname>Gärdenfors</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Moser</surname>, <given-names>E. I.</given-names></string-name>, &amp; <string-name><surname>Doeller</surname>, <given-names>C. F.</given-names></string-name> (<year>2018</year>). <article-title>Navigating cognition: Spatial codes for human thinking</article-title>. <source>In Science</source> (Vol. <volume>362</volume>, Issue <issue>6415</issue>). <pub-id pub-id-type="doi">10.1126/science.aat6766</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Bengio</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Mesnil</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Dauphin</surname>, <given-names>Y.</given-names></string-name>, &amp; <string-name><surname>Rifai</surname>, <given-names>S.</given-names></string-name> (<year>2013</year>). <article-title>Better mixing via deep representations</article-title>. <source>International Conference on Machine Learning</source>, <fpage>552</fpage>–<lpage>560</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Brady</surname>, <given-names>T. F.</given-names></string-name>, <string-name><surname>Konkle</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Alvarez</surname>, <given-names>G. A.</given-names></string-name> (<year>2011</year>). <article-title>A review of visual memory capacity: Beyond individual items and toward structured representations</article-title>. <source>Journal of Vision</source>, <volume>11</volume>(<issue>5</issue>), <fpage>1</fpage>–<lpage>34</lpage>. <pub-id pub-id-type="doi">10.1167/11.5.1</pub-id></mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Brady</surname>, <given-names>T. F.</given-names></string-name>, &amp; <string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name> (<year>2013</year>). <article-title>A probabilistic model of visual working memory: Incorporating higher order regularities into working memory capacity estimates</article-title>. <source>Psychological Review</source>, <volume>120</volume>(<issue>1</issue>), <fpage>85</fpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>Brouwer</surname>, <given-names>G. J.</given-names></string-name>, &amp; <string-name><surname>Heeger</surname>, <given-names>D. J.</given-names></string-name> (<year>2009</year>). <article-title>Decoding and reconstructing color from responses in human visual cortex</article-title>. <source>Journal of Neuroscience</source>, <volume>29</volume>(<issue>44</issue>), <fpage>13992</fpage>–<lpage>14003</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.3577-09.2009</pub-id></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Brouwer</surname>, <given-names>G. J.</given-names></string-name>, &amp; <string-name><surname>Heeger</surname>, <given-names>D. J.</given-names></string-name> (<year>2011</year>). <article-title>Cross-orientation suppression in human visual cortex</article-title>. <source>Journal of Neurophysiology</source>, <volume>106</volume>(<issue>5</issue>), <fpage>2108</fpage>–<lpage>2119</lpage>. <pub-id pub-id-type="doi">10.1152/jn.00540.2011</pub-id></mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Constantinescu</surname>, <given-names>A. O.</given-names></string-name>, <string-name><surname>O’Reilly</surname>, <given-names>J. X.</given-names></string-name>, &amp; <string-name><surname>Behrens</surname>, <given-names>T. E.</given-names></string-name> (<year>2016</year>). <article-title>Organizing conceptual knowledge in humans with a gridlike code</article-title>. <source>Science</source>, <volume>352</volume>(<issue>6292</issue>), <fpage>1464</fpage>–<lpage>1468</lpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Cowan</surname>, <given-names>N.</given-names></string-name> (<year>2001</year>). <article-title>The magical number 4 in short-term memory: A reconsideration of mental storage capacity</article-title>. <source>Behavioral and Brain Sciences</source>, <volume>24</volume>(<issue>1</issue>), <fpage>87</fpage>–<lpage>114</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Dehaene</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Meyniel</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Wacongne</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>Pallier</surname>, <given-names>C.</given-names></string-name> (<year>2015</year>). <article-title>The neural representation of sequences: From transition probabilities to algebraic patterns and linguistic trees</article-title>. <source>Neuron</source>, <volume>88</volume>(<issue>1</issue>), <fpage>2</fpage>–<lpage>19</lpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Dekker</surname>, <given-names>R. B.</given-names></string-name>, <string-name><surname>Otto</surname>, <given-names>F.</given-names></string-name>, &amp; <string-name><surname>Summerfield</surname>, <given-names>C.</given-names></string-name> (<year>2022</year>). <article-title>Curriculum learning for human compositional generalization</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>119</volume>(<issue>41</issue>), <fpage>e2205582119</fpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Ding</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Cueva</surname>, <given-names>C. J.</given-names></string-name>, <string-name><surname>Tsodyks</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Qian</surname>, <given-names>N.</given-names></string-name> (<year>2017</year>). <article-title>Visual perception as retrospective Bayesian decoding from high- to low-level features</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>114</volume>(<issue>43</issue>), <fpage>E9115</fpage>–<lpage>E9124</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1706906114</pub-id></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Doeller</surname>, <given-names>C. F.</given-names></string-name>, <string-name><surname>Barry</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Burgess</surname>, <given-names>N.</given-names></string-name> (<year>2010</year>). <article-title>Evidence for grid cells in a human memory network</article-title>. <source>Nature</source>, <volume>463</volume>(<issue>7281</issue>), <fpage>657</fpage>–<lpage>661</lpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Ester</surname>, <given-names>E. F.</given-names></string-name>, <string-name><surname>Sprague</surname>, <given-names>T. C.</given-names></string-name>, &amp; <string-name><surname>Serences</surname>, <given-names>J. T.</given-names></string-name> (<year>2015</year>). <article-title>Parietal and Frontal Cortex Encode Stimulus-Specific Mnemonic Representations during Visual Working Memory</article-title>. <source>Neuron</source>, <volume>87</volume>(<issue>4</issue>), <fpage>893</fpage>–<lpage>905</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2015.07.013</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Foster</surname>, <given-names>D. J.</given-names></string-name>, &amp; <string-name><surname>Wilson</surname>, <given-names>M. A.</given-names></string-name> (<year>2006</year>). <article-title>Reverse replay of behavioural sequences in hippocampal place cells during the awake state</article-title>. <source>Nature</source>, <volume>440</volume>(<issue>7084</issue>), <fpage>680</fpage>–<lpage>683</lpage>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Foster</surname>, <given-names>J. J.</given-names></string-name>, <string-name><surname>Bsales</surname>, <given-names>E. M.</given-names></string-name>, <string-name><surname>Jaffe</surname>, <given-names>R. J.</given-names></string-name>, &amp; <string-name><surname>Awh</surname>, <given-names>E.</given-names></string-name> (<year>2017</year>). <article-title>Alpha-Band Activity Reveals Spontaneous Representations of Spatial Position in Visual Working Memory</article-title>. <source>Current Biology</source>, <volume>27</volume>(<issue>20</issue>), <fpage>3216</fpage>–<lpage>3223.e6</lpage>. <pub-id pub-id-type="doi">10.1016/j.cub.2017.09.031</pub-id></mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Garvert</surname>, <given-names>M. M.</given-names></string-name>, <string-name><surname>Dolan</surname>, <given-names>R. J.</given-names></string-name>, &amp; <string-name><surname>Behrens</surname>, <given-names>T. E.</given-names></string-name> (<year>2017</year>). <article-title>A map of abstract relational knowledge in the human hippocampal–entorhinal cortex</article-title>. <source>Elife</source>, <volume>6</volume>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Goldstone</surname>, <given-names>R. L.</given-names></string-name>, &amp; <string-name><surname>Medin</surname>, <given-names>D. L.</given-names></string-name> (<year>1994</year>). <article-title>Time course of comparison. <italic>Journal of Experimental Psychology: Learning</italic></article-title>, <source>Memory, and Cognition</source>, <volume>20</volume>(<issue>1</issue>), <fpage>29</fpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>Hafting</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Fyhn</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Molden</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Moser</surname>, <given-names>M.-B.</given-names></string-name>, &amp; <string-name><surname>Moser</surname>, <given-names>E. I.</given-names></string-name> (<year>2005</year>). <article-title>Microstructure of a spatial map in the entorhinal cortex</article-title>. <source>Nature</source>, <volume>436</volume>(<issue>7052</issue>), <fpage>801</fpage>–<lpage>806</lpage>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>Huang</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Jia</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Han</surname>, <given-names>Q.</given-names></string-name>, &amp; <string-name><surname>Luo</surname>, <given-names>H.</given-names></string-name> (<year>2018</year>). <article-title>Fast-backward replay of sequentially memorized items in humans</article-title>. <source>ELife</source>, <volume>7</volume>, <fpage>1</fpage>–<lpage>21</lpage>. <pub-id pub-id-type="doi">10.7554/eLife.35164</pub-id></mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><string-name><surname>Huang</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Luo</surname>, <given-names>H.</given-names></string-name> (<year>2021</year>). <article-title>Sequence structure organizes items in varied latent states of working memory neural network</article-title>. <source>ELife</source>, <volume>10</volume>, <fpage>1</fpage>–<lpage>21</lpage>. <pub-id pub-id-type="doi">10.7554/elife.67589</pub-id></mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><string-name><surname>Kurth-Nelson</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Behrens</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Wayne</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Luettgau</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Dolan</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>Y.</given-names></string-name>, &amp; <string-name><surname>Schwartenbeck</surname>, <given-names>P.</given-names></string-name> (<year>2023</year>). <article-title>Replay and compositional computation</article-title>. <source>Neuron</source>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>Kurth-Nelson</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Economides</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Dolan</surname>, <given-names>R. J.</given-names></string-name>, &amp; <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name> (<year>2016</year>). <article-title>Fast sequences of non-spatial state representations in humans</article-title>. <source>Neuron</source>, <volume>91</volume>(<issue>1</issue>), <fpage>194</fpage>–<lpage>204</lpage>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>Kurth-nelson</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Economides</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Dolan</surname>, <given-names>R. J.</given-names></string-name>, <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Kurth-nelson</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Economides</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Dolan</surname>, <given-names>R. J.</given-names></string-name>, &amp; <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name> (<year>2016</year>). <article-title>Fast Sequences of Non-spatial State Representations in Humans Article Fast Sequences of Non-spatial State Representations in Humans</article-title>. <source>Neuron</source>, <volume>91</volume>(<issue>1</issue>), <fpage>194</fpage>–<lpage>204</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2016.05.028</pub-id></mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><string-name><surname>Li</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Huang</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Han</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Mi</surname>, <given-names>Y.</given-names></string-name>, &amp; <string-name><surname>Luo</surname>, <given-names>H.</given-names></string-name> (<year>2021</year>). <article-title>Temporally coherent perturbation of neural dynamics during retention alters human multi-item working memory</article-title>. <source>Progress in Neurobiology</source>, <fpage>102023</fpage>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><string-name><surname>Liu</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Dolan</surname>, <given-names>R. J.</given-names></string-name>, <string-name><surname>Higgins</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Penagos</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Woolrich</surname>, <given-names>M. W.</given-names></string-name>, <string-name><surname>Ólafsdóttir</surname>, <given-names>H. F.</given-names></string-name>, <string-name><surname>Barry</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Kurth-Nelson</surname>, <given-names>Z.</given-names></string-name>, &amp; <string-name><surname>Behrens</surname>, <given-names>T. E.</given-names></string-name> (<year>2021</year>). <article-title>Temporally delayed linear modelling (TDLM) measures replay in both animals and humans</article-title>. <source>Elife</source>, <volume>10</volume>, <fpage>e66917</fpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Liu</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Dolan</surname>, <given-names>R. J.</given-names></string-name>, <string-name><surname>Kurth-Nelson</surname>, <given-names>Z.</given-names></string-name>, &amp; <string-name><surname>Behrens</surname>, <given-names>T. E. J.</given-names></string-name> (<year>2019</year>). <article-title>Human Replay Spontaneously Reorganizes Experience</article-title>. <source>Cell</source>, <volume>178</volume>(<issue>3</issue>), <fpage>640</fpage>–<lpage>652.e14</lpage>. <pub-id pub-id-type="doi">10.1016/j.cell.2019.06.012</pub-id></mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>Liu</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Mattar</surname>, <given-names>M. G.</given-names></string-name>, <string-name><surname>Behrens</surname>, <given-names>T. E. J.</given-names></string-name>, <string-name><surname>Daw</surname>, <given-names>N. D.</given-names></string-name>, &amp; <string-name><surname>Dolan</surname>, <given-names>R. J.</given-names></string-name> (<year>2021</year>). <article-title>Experience replay is associated with efficient nonlocal learning</article-title>. <source>Science</source>, <volume>372</volume>(<issue>6544</issue>).</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><string-name><surname>Ma</surname>, <given-names>W. J.</given-names></string-name>, <string-name><surname>Husain</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Bays</surname>, <given-names>P. M.</given-names></string-name> (<year>2014</year>). <article-title>Changing concepts of working memory</article-title>. <source>Nature Neuroscience</source>, <volume>17</volume>(<issue>3</issue>), <fpage>347</fpage>–<lpage>356</lpage>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><string-name><surname>Maris</surname>, <given-names>E.</given-names></string-name>, &amp; <string-name><surname>Oostenveld</surname>, <given-names>R.</given-names></string-name> (<year>2007</year>). <article-title>Nonparametric statistical testing of EEG-and MEG-data</article-title>. <source>Journal of Neuroscience Methods</source>, <volume>164</volume>(<issue>1</issue>), <fpage>177</fpage>–<lpage>190</lpage>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><string-name><surname>Mathy</surname>, <given-names>F.</given-names></string-name>, &amp; <string-name><surname>Feldman</surname>, <given-names>J.</given-names></string-name> (<year>2012</year>). <article-title>What’s magic about magic numbers? Chunking and data compression in short-term memory</article-title>. <source>Cognition</source>, <volume>122</volume>(<issue>3</issue>), <fpage>346</fpage>–<lpage>362</lpage>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><string-name><surname>Nieh</surname>, <given-names>E. H.</given-names></string-name>, <string-name><surname>Schottdorf</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Freeman</surname>, <given-names>N. W.</given-names></string-name>, <string-name><surname>Low</surname>, <given-names>R. J.</given-names></string-name>, <string-name><surname>Lewallen</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Koay</surname>, <given-names>S. A.</given-names></string-name>, <string-name><surname>Pinto</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Gauthier</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Brody</surname>, <given-names>C. D.</given-names></string-name>, &amp; <string-name><surname>Tank</surname>, <given-names>D. W.</given-names></string-name> (<year>2021</year>). <article-title>Geometry of abstract learned knowledge in the hippocampus</article-title>. <source>Nature</source>, <volume>595</volume>(<issue>7865</issue>), <fpage>80</fpage>–<lpage>84</lpage>. <pub-id pub-id-type="doi">10.1038/s41586-021-03652-7</pub-id></mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="book"><string-name><surname>O’keefe</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Nadel</surname>, <given-names>L.</given-names></string-name> (<year>1978</year>). <source>The hippocampus as a cognitive map</source>. <publisher-loc>Oxford</publisher-loc>: <publisher-name>Clarendon Press</publisher-name>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><string-name><surname>Ólafsdóttir</surname>, <given-names>H. F.</given-names></string-name>, <string-name><surname>Bush</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Barry</surname>, <given-names>C.</given-names></string-name> (<year>2018</year>). <article-title>The role of hippocampal replay in memory and planning</article-title>. <source>Current Biology</source>, <volume>28</volume>(<issue>1</issue>), <fpage>R37</fpage>–<lpage>R50</lpage>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><string-name><surname>Oostenveld</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Fries</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Maris</surname>, <given-names>E.</given-names></string-name>, &amp; <string-name><surname>Schoffelen</surname>, <given-names>J.-M.</given-names></string-name> (<year>2011</year>). <article-title>FieldTrip: Open source software for advanced analysis of MEG, EEG, and invasive electrophysiological data</article-title>. <source>Computational Intelligence and Neuroscience</source>, <volume>2011</volume>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><string-name><surname>Park</surname>, <given-names>S. A.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>D. S.</given-names></string-name>, &amp; <string-name><surname>Boorman</surname>, <given-names>E. D.</given-names></string-name> (<year>2021</year>). <article-title>Inferences on a multidimensional social hierarchy use a grid-like code</article-title>. <source>Nature Neuroscience</source>, <volume>24</volume>(<issue>9</issue>), <fpage>1292</fpage>–<lpage>1301</lpage>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><string-name><surname>Ren</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Luo</surname>, <given-names>H.</given-names></string-name> (<year>2022</year>). <article-title>Dynamic emergence of relational structure network in human brains</article-title>. <source>BioRxiv</source>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><string-name><surname>Roads</surname>, <given-names>B. D.</given-names></string-name>, &amp; <string-name><surname>Love</surname>, <given-names>B. C.</given-names></string-name> (<year>2020</year>). <article-title>Learning as the unsupervised alignment of conceptual systems</article-title>. <source>Nature Machine Intelligence</source>, <volume>2</volume>(<issue>1</issue>), <fpage>76</fpage>–<lpage>82</lpage>. <pub-id pub-id-type="doi">10.1038/s42256-019-0132-2</pub-id></mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><string-name><surname>Schapiro</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>McDevitt</surname>, <given-names>E. A.</given-names></string-name>, <string-name><surname>Rogers</surname>, <given-names>T. T.</given-names></string-name>, <string-name><surname>Mednick</surname>, <given-names>S. C.</given-names></string-name>, &amp; <string-name><surname>Norman</surname>, <given-names>K. A.</given-names></string-name> (<year>2018</year>). <article-title>Human hippocampal replay during rest prioritizes weakly learned information and predicts memory performance</article-title>. <source>Nature Communications</source>, <volume>9</volume>(<issue>1</issue>), <fpage>1</fpage>–<lpage>11</lpage>. <pub-id pub-id-type="doi">10.1038/s41467-018-06213-1</pub-id></mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><string-name><surname>Schapiro</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Rogers</surname>, <given-names>T. T.</given-names></string-name>, <string-name><surname>Cordova</surname>, <given-names>N. I.</given-names></string-name>, <string-name><surname>Turk-Browne</surname>, <given-names>N. B.</given-names></string-name>, &amp; <string-name><surname>Botvinick</surname>, <given-names>M. M.</given-names></string-name> (<year>2013</year>). <article-title>Neural representations of events arise from temporal community structure</article-title>. <source>Nature Neuroscience</source>, <volume>16</volume>(<issue>4</issue>), <fpage>486</fpage>–<lpage>492</lpage>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><string-name><surname>Schuck</surname>, <given-names>N. W.</given-names></string-name>, <string-name><surname>Cai</surname>, <given-names>M. B.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>R. C.</given-names></string-name>, &amp; <string-name><surname>Niv</surname>, <given-names>Y.</given-names></string-name> (<year>2016</year>). <article-title>Human orbitofrontal cortex represents a cognitive map of state space</article-title>. <source>Neuron</source>, <volume>91</volume>(<issue>6</issue>), <fpage>1402</fpage>–<lpage>1412</lpage>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><string-name><surname>Schuck</surname>, <given-names>N. W.</given-names></string-name>, &amp; <string-name><surname>Niv</surname>, <given-names>Y.</given-names></string-name> (<year>2019</year>). <article-title>Sequential replay of nonspatial task states in the human hippocampus</article-title>. <source>Science</source>, <volume>364</volume>(<issue>6447</issue>). <pub-id pub-id-type="doi">10.1126/science.aaw5181</pub-id></mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><string-name><surname>Sheahan</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Luyckx</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Nelli</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Teupe</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Summerfield</surname>, <given-names>C.</given-names></string-name> (<year>2021</year>). <article-title>Neural state space alignment for magnitude generalization in humans and recurrent networks</article-title>. <source>Neuron</source>, <fpage>1</fpage>–<lpage>13</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2021.02.004</pub-id></mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><string-name><surname>Skaggs</surname>, <given-names>W. E.</given-names></string-name>, &amp; <string-name><surname>McNaughton</surname>, <given-names>B. L.</given-names></string-name> (<year>1996</year>). <article-title>Replay of neuronal firing sequences in rat hippocampus during sleep following spatial experience</article-title>. <source>Science</source>, <volume>271</volume>(<issue>5257</issue>), <fpage>1870</fpage>–<lpage>1873</lpage>.</mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><string-name><surname>Solomon</surname>, <given-names>E. A.</given-names></string-name>, <string-name><surname>Lega</surname>, <given-names>B. C.</given-names></string-name>, <string-name><surname>Sperling</surname>, <given-names>M. R.</given-names></string-name>, &amp; <string-name><surname>Kahana</surname>, <given-names>M. J.</given-names></string-name> (<year>2019</year>). <article-title>Hippocampal theta codes for distances in semantic and temporal spaces</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>116</volume>(<issue>48</issue>), <fpage>24343</fpage>–<lpage>24352</lpage>.</mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><string-name><surname>Theves</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Fernandez</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Doeller</surname>, <given-names>C. F.</given-names></string-name> (<year>2019</year>). <article-title>The hippocampus encodes distances in multidimensional feature space</article-title>. <source>Current Biology</source>, <volume>29</volume>(<issue>7</issue>), <fpage>1226</fpage>–<lpage>1231</lpage>.</mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><string-name><surname>Whittington</surname>, <given-names>J. C.</given-names></string-name>, <string-name><surname>Muller</surname>, <given-names>T. H.</given-names></string-name>, <string-name><surname>Mark</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Barry</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Burgess</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Behrens</surname>, <given-names>T. E.</given-names></string-name> (<year>2020</year>). <article-title>The Tolman-Eichenbaum machine: Unifying space and relational memory through generalization in the hippocampal formation</article-title>. <source>Cell</source>, <volume>183</volume>(<issue>5</issue>), <fpage>1249</fpage>–<lpage>1263</lpage>.</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><string-name><surname>Wilson</surname>, <given-names>M. A.</given-names></string-name>, &amp; <string-name><surname>McNaughton</surname>, <given-names>B. L.</given-names></string-name> (<year>1994</year>). <article-title>Reactivation of hippocampal ensemble memories during sleep</article-title>. <source>Science</source>, <volume>265</volume>(<issue>5172</issue>), <fpage>676</fpage>–<lpage>679</lpage>.</mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><string-name><surname>Wolff</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Jochim</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Akyürek</surname>, <given-names>E. G.</given-names></string-name>, &amp; <string-name><surname>Stokes</surname>, <given-names>M. G.</given-names></string-name> (<year>2017</year>). <article-title>Dynamic hidden states underlying working-memory-guided behavior</article-title>. <source>Nature Neuroscience</source>, <volume>20</volume>(<issue>6</issue>), <fpage>864</fpage>–<lpage>871</lpage>. <pub-id pub-id-type="doi">10.1038/nn.4546</pub-id></mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><string-name><surname>Wu</surname>, <given-names>C. M.</given-names></string-name>, <string-name><surname>Schulz</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Garvert</surname>, <given-names>M. M.</given-names></string-name>, <string-name><surname>Meder</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Schuck</surname>, <given-names>N. W.</given-names></string-name> (<year>2020</year>). <article-title>Similarities and differences in spatial and nonspatial cognitive maps</article-title>. <source>PLoS Computational Biology</source>, <volume>16</volume>(<issue>9</issue>), <fpage>1</fpage>–<lpage>28</lpage>. <pub-id pub-id-type="doi">10.1371/JOURNAL.PCBI.1008149</pub-id></mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><string-name><surname>Yu</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Teng</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Postle</surname>, <given-names>B. R.</given-names></string-name> (<year>2020</year>). <article-title>Different states of priority recruit different neural representations in visual working memory</article-title>. <source>PLoS Biology</source>, <volume>18</volume>(<issue>6</issue>), <fpage>1</fpage>–<lpage>21</lpage>. <pub-id pub-id-type="doi">10.1371/journal.pbio.3000769</pub-id></mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><string-name><surname>Zhang</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Fell</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Axmacher</surname>, <given-names>N.</given-names></string-name> (<year>2018</year>). <article-title>Electrophysiological mechanisms of human memory consolidation</article-title>. <source>Nature Communications</source>, <volume>9</volume>(<issue>1</issue>). <pub-id pub-id-type="doi">10.1038/s41467-018-06553-y</pub-id></mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><string-name><surname>Zhang</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Zhen</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Yu</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Long</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Jiang</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Fang</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Sigman</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Dehaene</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Wang</surname>, <given-names>L.</given-names></string-name> (<year>2022</year>). <article-title>Working Memory for Spatial Sequences: Developmental and Evolutionary Factors in Encoding Ordinal and Relational Structures</article-title>. <source>The Journal of Neuroscience : The Official Journal of the Society for Neuroscience</source>, <volume>42</volume>(<issue>5</issue>), <fpage>850</fpage>–<lpage>864</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.0603-21.2021</pub-id></mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><string-name><surname>Zhang</surname>, <given-names>W.</given-names></string-name>, &amp; <string-name><surname>Luck</surname>, <given-names>S. J.</given-names></string-name> (<year>2008</year>). <article-title>Discrete fixed-resolution representations in visual working memory</article-title>. <source>Nature</source>, <volume>453</volume>(<issue>7192</issue>), <fpage>233</fpage>–<lpage>235</lpage>.</mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><string-name><surname>Zhou</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Jia</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Montesinos-Cartagena</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Gardner</surname>, <given-names>M. P. H.</given-names></string-name>, <string-name><surname>Zong</surname>, <given-names>W.</given-names></string-name>, &amp; <string-name><surname>Schoenbaum</surname>, <given-names>G.</given-names></string-name> (<year>2020</year>). <article-title>Evolving schema representations in orbitofrontal ensembles during learning</article-title>. <source>Nature</source>, <issue>March</issue>. <pub-id pub-id-type="doi">10.1038/s41586-020-03061-2</pub-id></mixed-citation></ref>
</ref-list>
<sec id="s6">
<title>Supplementary</title>
<fig id="figS1" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 1</label>
<caption><p><bold>(A)</bold> Scatterplot of 1<sup>st</sup>-to-2<sup>nd</sup> trajectory memory error for location sequence (X-axis) and Color sequence (Y-axis) under MAT condition. Note that the trajectory error of all trials within each subject was divided into 4 bins according to the location trajectory error, resulting in 33 (subject number)*4 (bins) dots in the plot. The brown line represents the best linear fit. <bold>(B)</bold> Same as A, but for 2<sup>nd</sup>-to-3<sup>rd</sup> trajectory. <bold>(C)</bold> Same as A, but for 1<sup>st</sup>-to-3<sup>rd</sup> trajectory. <bold>(D)</bold> Grand average (mean ± SEM) neural decoding of 1<sup>st</sup>-to-2<sup>nd</sup> as a function of time during the encoding period, for MAT condition. <bold>(E)</bold> Same as A, but for 2<sup>nd</sup>-to-3<sup>rd</sup> trajectory. <bold>(F)</bold> Same as A, but for 1<sup>st</sup>-to-3<sup>rd</sup> trajectory.</p></caption>
<graphic xlink:href="549616v1_figS1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS2" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 2</label>
<caption><p>(A) Left panel: grand average (mean ± SEM) time courses of the decoding performance for the 1<sup>st</sup> (purple), 2<sup>nd</sup> (turquoise) and 3<sup>rd</sup> (blue) WM colors during color recalling period. Right panel: grand average (mean ± SEM) time courses of the decoding performance in MAT condition. (B) Left panel: grand average (mean ± SEM) time courses of the decoding performance for the 1<sup>st</sup>, 2<sup>nd</sup> and 3<sup>rd</sup> WM locations during color recalling period. Right panel: grand average (mean ± SEM) time courses of the decoding performance in MAT condition. (Horizontal solid line: cluster-based permutation test, cluster-defining threshold p &lt; 0.05, corrected significance level p &lt; 0.05; Horizontal dashed line: marginal significance, cluster-defining threshold p &lt; 0.1, 0.05 &lt; cluster p &lt; 0.1)</p></caption>
<graphic xlink:href="549616v1_figS2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS3" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 3</label>
<caption><p>Participants were divided into two groups based on the average of trajectory decoding performance within the respective significant time range. <bold>(A)</bold> Grand average (mean ± SEM) time courses of the decoding performance for the 1<sup>st</sup>, 2<sup>nd</sup> and 3<sup>rd</sup> colors during location recalling period for high trajectory representation group. <bold>(B)</bold> Left panel: theoretical transition pattern for 3-item forward replay. Right panel: empirical transitional pattern (actual cross-correlation matrix) at 130 ms time lag definde in <xref rid="fig4" ref-type="fig">Figure 4D</xref>. A significant correlation was found between the two matrices (r = 0.715, p = 0.030), further confirming the forward replay of color sequence for high trajectory representation group. <bold>(C)</bold> Same as A, but for low trajectory representation group. <bold>(D)</bold> Same as B, but for low trajectory representation group, nonsignificant correlation between the two matrices was observed (r = 0.230, p = 0.553). (Horizontal solid line: time window with significnat activation (t-test, p &lt; 0.05, without correction across time)</p></caption>
<graphic xlink:href="549616v1_figS3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.93158.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Peelen</surname>
<given-names>Marius V</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Radboud University Nijmegen</institution>
</institution-wrap>
<city>Nijmegen</city>
<country>Netherlands</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>valuable</bold> study uses a novel experimental design to elegantly demonstrate how we exploit stimulus structure to overcome working memory capacity limits. While the behavioural evidence is <bold>convincing</bold>, the neural evidence is <bold>incomplete</bold>, as it only provides partial support for the proposed information compression mechanism. This study will be of interest to cognitive neuroscientists studying structure learning and memory.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.93158.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>
Huang and Luo investigated whether regularities between stimulus features can be exploited to facilitate the encoding of each set of stimuli in visual working memory, improving performance. They recorded both behavioural and neural (EEG) data from human participants during a sequential delayed response task involving three items with two properties: location and colour. In the key condition ('aligned trajectory'), the distance between locations of successively presented stimuli was identical to their 'distance' in colour space, permitting a compression strategy of encoding only the location and colour of the first stimulus and the relative distance of the second and third stimulus (as opposed to remembering 3 locations and 3 colours, this would only require remembering 1 location, 1 colour, and 2 distances). Participants recalled the location and colour of each item after a delay.</p>
<p>Consistent with the compression account, participants' location and colour recall errors were correlated and were overall lower compared to a non-compressible condition ('misaligned trajectory'). Multivariate analysis of the neural data permitted decoding of the locations and colours during encoding. Crucially, the relative distance could also be decoded - a necessary ingredient for the compression strategy.</p>
<p>Strengths:</p>
<p>
The main strength of this study is a novel experimental design that elegantly demonstrates how we exploit stimulus structure to overcome working memory capacity limits. The behavioural results are robust and support the main hypothesis of compressed encoding across a number of analyses. The simple and well-controlled design is suited to neuroimaging studies and paves the way for investigating the neural basis of how environmental structure is detected and represented in memory. Prior studies on this topic have primarily studied behaviour only (e.g., Brady &amp; Tenenbaum, 2013).</p>
<p>Weaknesses:</p>
<p>
The main weakness of the study is that the EEG results do not make a clear case for compression or demonstrate its neural basis. If the main aim of this strategy is to improve memory maintenance, it seems that it should be employed during the encoding phase. From then on, the neural representation in memory should be in the compressed format. The only positive evidence for this occurs in the late encoding phase (the re-activation of decoding of the distance between items 1 and 2, Fig. 5A), but the link to behaviour seems fairly weak (p=0.068). Stronger evidence would be showing decoding of the compressed code during memory maintenance or recall, but this is not presented. On the contrary, during location recall (after the majority of memory maintenance is already over), colour decoding re-emerges, but in the un-compressed item-by-item code (Fig. 4B). The authors suggest that compression is consolidated at this point, but its utility at this late stage is not obvious.</p>
<p>Impact:</p>
<p>
This important study elegantly demonstrates that the use of shared structure can improve capacity-limited visual working memory. The paradigm and approach explicitly link this field to recent findings on the role of replay in structure learning and will therefore be of interest to neuroscientists studying both topics.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.93158.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>
In this study, the authors wanted to test if using a shared relational structure by a sequence of colors in locations can be leveraged to reorganize and compress information.</p>
<p>Strength:</p>
<p>
They applied machine learning to EEG data to decode the neural mechanism of reinstatement of visual stimuli at recall. They were able to show that when the location of colors is congruent with the semantically expected location (for example, green is closer to blue-green than purple) the related color information is reinstated at the probed location. This reinstatement was not present when the location and color were not semantically congruent (meaning that x displacement in color ring location did not displace colors in the color space to the same extent) and semantic knowledge of color relationship could not be used for reducing the working memory load or to benefit encoding and retrieval in short term memory.</p>
<p>Weakness:</p>
<p>
The experiment and results did not address any reorganization of information or neural mechanism of working memory (that would be during the gap between encoding and retrieval). There was also a lack of evidence to rule out that the current observation can be addressed by schematic abstraction instead of the utilization of a cognitive map.</p>
<p>
The likely impact of the initial submission of the study would be in the utility of the methods that would be helpful for studying a sequence of stimuli at recall. The paper was discussed in a narrow and focused context, referring to limited studies on cognitive maps and replay. The bigger picture and long history of studying encoding and retrieval of schema-congruent and schema-incongruent events is not discussed.</p>
</body>
</sub-article>
</article>