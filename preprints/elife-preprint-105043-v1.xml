<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">105043</article-id>
<article-id pub-id-type="doi">10.7554/eLife.105043</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.105043.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>Computational and Systems Biology</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Fast and slow synaptic plasticity enables concurrent control and learning</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2307-2109</contrib-id>
<name>
<surname>Bicknell</surname>
<given-names>Brendan A</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>b.bicknell@ucl.ac.uk</email>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8713-9328</contrib-id>
<name>
<surname>Latham</surname>
<given-names>Peter E</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>Gatsby Computational Neuroscience Unit, University College London</institution></institution-wrap>, <city>London</city>, <country country="GB">United Kingdom</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Naud</surname>
<given-names>Richard</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Ottawa</institution>
</institution-wrap>
<city>Ottawa</city>
<country>Canada</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Poirazi</surname>
<given-names>Panayiota</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>FORTH Institute of Molecular Biology and Biotechnology</institution>
</institution-wrap>
<city>Heraklion</city>
<country>Greece</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-03-24">
<day>24</day>
<month>03</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP105043</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-11-20">
<day>20</day>
<month>11</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-09-06">
<day>06</day>
<month>09</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.09.06.611710"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Bicknell &amp; Latham</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Bicknell &amp; Latham</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-105043-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>During many tasks the brain receives real-time feedback about performance. What should it do with that information, at the synaptic level, so that tasks can be performed as well as possible? The conventional answer is that it should learn by incrementally adjusting synaptic strengths. We show, however, that learning on its own is severely suboptimal. To maximize performance, synaptic plasticity should also operate on a much faster timescale – essentially, the synaptic weights should act as a control signal. We propose a normative plasticity rule that embodies this principle. In this, fast synaptic weight changes greedily suppress downstream errors, while slow synaptic weight changes implement statistically optimal learning. This enables near-perfect task performance immediately, efficient task execution on longer timescales, and confers robustness to noise and other perturbations. Applied in a cerebellar microcircuit model, the theory explains longstanding experimental observations and makes novel testable predictions.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>

</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>The standard view of learning is that synaptic strengths are adjusted to minimize some loss – typically the performance on a task, or set of tasks (<xref ref-type="bibr" rid="c72">Richards and Kording 2023</xref>; <xref ref-type="bibr" rid="c15">Bredenberg and Savin 2023</xref>). From this perspective, given the complexity of the nervous system and the range of tasks it must perform, conventional wisdom is that synaptic strengths change slowly. This makes sense for tasks with a discrete set of responses: Do I lick left or right in response to a stimulus? Is that grating oriented to the right or left of vertical? However, for naturalistic tasks with continuous output, such as reaching for an object, feedback about performance could be used to adjust weights on much faster timescales. In fact, for sufficiently fast feedback compared to the timescale over which the world changes, fast weight changes could, at least in principle, enable near-perfect performance.</p>
<p>Here we propose that synapses can maximize task performance by adjusting weights on two timescales. On fast timescales, synapses can use real-time feedback to suppress immediate errors. As long as the world changes relatively smoothly over time, if feedback at one moment indicates that neural output is too high or low, synaptic strengths can be transiently decreased or increased to compensate. On slow timescales, synapses can use the same feedback signal for statistically optimal learning.</p>
<p>We first illustrate the main concept with a toy model, demonstrating how two timescales of plasticity can work in concert. We then consider a more realistic model of a neuron, where synapses dynamically integrate input and feedback to extract useful learning signals from noisy observations. We derive synaptic update rules for this model by framing synaptic plasticity as an optimal control problem. This leads to substantial improvements over classical gradient-based learning. We then generalize the theory to incorporate small populations of neurons and delayed feedback transmitted via spikes. Applied to a model of temporal processing in the cerebellum, our theory provides normative explanations for common experimental observations, and makes novel testable predictions. Altogether, these results provide a principled account of how the brain can exploit multiple timescales of plasticity for efficient online adaptation and learning.</p>
</sec>
<sec id="s2">
<title>Results</title>
<p>We propose that neurons can optimize their performance by having two separate timescales of synaptic plasticity. To illustrate the general idea, consider a simple online linear regression problem. We model a single neuron that must learn to transform a set of time-varying input rates, <italic>ν</italic><sub><italic>i</italic></sub>(<italic>t</italic>), into a target output, <italic>y</italic>*(<italic>t</italic>). The output of the neuron is given by
<disp-formula id="eqn1">
<graphic xlink:href="611710v1_eqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
with parameters <italic>w</italic><sub><italic>i</italic></sub> denoting its tunable synaptic weights. The classical solution to this problem is to discretize time and iteratively modify the weights using the delta rule (<xref ref-type="bibr" rid="c84">Widrow and Hoff 1960</xref>),
<disp-formula id="eqn2">
<graphic xlink:href="611710v1_eqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where Δ<italic>w</italic><sub><italic>i</italic></sub> ≡ <italic>w</italic><sub><italic>i</italic></sub>(<italic>t</italic> + Δ<italic>t</italic>) − <italic>w</italic><sub><italic>i</italic></sub>(<italic>t</italic>). This eventually minimizes the output error provided the learning rate, <italic>η</italic>, is small.</p>
<p>The delta rule is attractive because it is generally effective and it is biologically plausible – each synapse requires access only to its own local input rate, <italic>ν</italic><sub><italic>i</italic></sub>, and a global error feedback signal, <italic>y</italic> − <italic>y</italic>*. If, however, <italic>ν</italic><sub><italic>i</italic></sub> and target output, <italic>y</italic>*, change smoothly over time, temporal correlations can be exploited to dramatically improve performance. To exploit temporal correlations, we endow the synaptic weights with independent fast and slow components,
<disp-formula id="eqn3">
<graphic xlink:href="611710v1_eqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The role of the fast weights, <italic>δw</italic><sub><italic>i</italic></sub>, is to transiently adjust neuronal output to suppress immediate errors – errors that can be predicted if <italic>y</italic>* changes slowly. The role of the slow weights, <italic>w</italic><sub><italic>i</italic></sub>, is to adapt, on a much slower timescale, to the true weights, thereby reducing the need for ongoing fast-weight corrections (<xref rid="fig1" ref-type="fig">Fig. 1a</xref>).</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1:</label>
<caption><title>A theory of fast and slow synaptic plasticity.</title>
<p><bold>a)</bold> Left: A synapse must make online adjustments to its strength by integrating local signals, such as its own input and error feedback. We propose that these signals can be optimally exploited through two timescales of plasticity. ‘Fast weights’, <italic>δw</italic><sub><italic>i</italic></sub>, fluctuate rapidly to suppress downstream error, whereas ‘slow weights’, <italic>w</italic><sub><italic>i</italic></sub>, converge gradually to the values required of a given task. Right: In the toy-model simulation from panel (b), as the slow weights find the solution, fast-weight fluctuations are reduced. Shown are example weight trajectories from one randomly selected synapse out of 20. <bold>b)</bold> In an illustrative online regression task, a neuron must learn to match its output to a time-varying target (gray dashed line). With a classical delta rule (black line), weights adapt over time to eventually correct the output. With two timescales of plasticity (purple line), fast weights can pin the output to the target from the outset, while slow weights evolve in the background to learn the task.</p></caption>
<graphic xlink:href="611710v1_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>For the model described by <xref ref-type="disp-formula" rid="eqn1">equation (1)</xref>, a simple implementation of this strategy is to observe the error at discrete times <italic>t</italic>, and then update all of the fast weights uniformly via
<disp-formula id="eqn4">
<graphic xlink:href="611710v1_eqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where Δ<italic>δw</italic><sub><italic>i</italic></sub> ≡ <italic>δw</italic><sub><italic>i</italic></sub>(<italic>t</italic> + Δ<italic>t</italic>) − <italic>δw</italic><sub><italic>i</italic></sub>(<italic>t</italic>) and <inline-formula><inline-graphic xlink:href="611710v1_inline1.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is the expected input rate per synapse (computed via a time average, or assumed as a known parameter). Summed over synapses, the fast weights subtract the observed error from the output, and straightforward algebra gives us
<disp-formula id="eqn5">
<graphic xlink:href="611710v1_eqn5.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the approximation is good if there are a large number of synapses and Δ<italic>t</italic> is small relative to how fast the target and input firing rates change (<italic>Methods: Online linear regression</italic>).</p>
<p>While suppressing error with rapidly fluctuating weights is effective, continually making these shortterm adjustments is likely to be energetically costly. This can be addressed by allowing the slow weights to learn. Intuitively, the closer the output is to the target, the less work will be needed to correct it. Seeking to make long-term adjustments to the slow weights, such that, ultimately, <inline-formula><inline-graphic xlink:href="611710v1_inline2.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, leads to local updates,
<disp-formula id="eqn6">
<graphic xlink:href="611710v1_eqn6.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <inline-formula><inline-graphic xlink:href="611710v1_inline3.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is a small learning rate (<italic>Methods: Online linear regression</italic>). This is similar to the usual delta rule, but with the fast weights subtracted off: it’s not hard to see that <inline-formula><inline-graphic xlink:href="611710v1_inline4.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. Slow-weight learning is thus driven by a modified error signal that represents what would have been observed in the absence of all of the fast corrections, isolating the contribution of <inline-formula><inline-graphic xlink:href="611710v1_inline4a.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. This coupling between the two update rules makes them compatible: so long as the slow weights know what the fast weights are doing, greedily suppressing error does not come at the expense of learning – even though the error is a crucial teaching signal.</p>
<p>In simulations of this simple strategy, the weights that solve the regression problem can be learned just as efficiently as in the classical case, but with the striking difference that the output is pinned to the target from the outset (<xref rid="fig1" ref-type="fig">Fig. 1b</xref>). Thus, a neuron, or indeed an animal, could accurately execute a task even while it is still being learned. Below we develop a control theory framework that generalizes this to more realistic scenarios.</p>
<sec id="s2a">
<title>Synaptic plasticity as optimal control</title>
<p>We now apply this idea to a more realistic setting: a model neuron driven by multiple spike trains and subject to intrinsic noise. Similar to the regression problem above, the neuron must tune its synaptic weights to drive a downstream output, <italic>y</italic>, to match a time-varying target, <italic>y</italic>*. The target could represent, for instance, the movement of a limb, but in this analysis we will take it to be an abstract, time-varying one-dimensional signal. We assume there are <italic>N</italic> synapses, and each one has access to two sources of information: the presynaptic spikes it receives, and an error signal.</p>
<p>The dynamics of the model neuron are described by equations for the total synaptic current, <italic>I</italic>, and firing rate, <italic>r</italic>,
<disp-formula id="eqn7a">
<graphic xlink:href="611710v1_eqn7a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn7b">
<graphic xlink:href="611710v1_eqn7b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where a dot denotes a time derivative. In these equations, <italic>τ</italic><sub><italic>I</italic></sub> ∼ 5 ms and <italic>τ</italic><sub><italic>r</italic></sub> ∼ 50 ms denote the synaptic and rate-modulation time constants, <italic>w</italic><sub><italic>i</italic></sub> denotes the weight of synapse <italic>i</italic>, and each <italic>x</italic><sub><italic>i</italic></sub> is an independent Poisson spike train represented by a sum of delta functions,
<disp-formula id="eqn8">
<graphic xlink:href="611710v1_eqn8.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>t</italic><sub><italic>i,k</italic></sub> is the time of the <italic>k</italic><sup>th</sup> spike arriving at synapse <italic>i</italic>. The parameter <italic>α</italic> sets the scale of firing rate response to synaptic current, and the final terms, <italic>ξ</italic><sub><italic>I</italic></sub> and <italic>ξ</italic><sub><italic>r</italic></sub>, denote zero-mean, unit-variance Gaussian white noise processes: ⟨<italic>ξ</italic><sub><italic>I</italic></sub>(<italic>t</italic>)<italic>ξ</italic><sub><italic>I</italic></sub>(<italic>t</italic>′)⟩ = <italic>δ</italic>(<italic>t</italic> − <italic>t</italic>′), and similarly for <italic>ξ</italic><sub><italic>r</italic></sub>. Functionally, a barrage of input spikes is linearly filtered to drive the firing rate of the neuron.</p>
<p>The downstream output of the neuron, <italic>y</italic>, is driven by the firing rate of the neuron and white noise,
<disp-formula id="eqn9">
<graphic xlink:href="611710v1_eqn9.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The time constant, <italic>τ</italic><sub><italic>y</italic></sub> (taken to be ∼100 ms), determines how quickly the output responds to changes in firing rate, and the final term is, as above, zero-mean, unit-variance Gaussian white noise.</p>
<p>We develop the theory using a teacher-student learning framework: the target, <italic>y</italic>*, is generated by simulating <xref ref-type="disp-formula" rid="eqn7a">equations (7)</xref> and <xref ref-type="disp-formula" rid="eqn9">(9)</xref>, except with no noise and with a set of target weights, denoted <inline-formula><inline-graphic xlink:href="611710v1_inline4b.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, in place of <italic>w</italic><sub><italic>i</italic></sub>. The target weights drift slowly around a mean value, <italic>µ</italic><sub><italic>w</italic></sub>, with time constant <italic>τ</italic><sub><italic>w</italic></sub> ∼ 10<sup>3</sup> s, modeling environmental variability or ongoing changes in the rest of the brain (<xref ref-type="bibr" rid="c2">Aitchison et al. 2021</xref>). We assume, for simplicity, that an instantaneous, continuous error signal is provided to all synapses, such as by diffuse transmission of a neuromodulator (<xref ref-type="bibr" rid="c52">Magee and Grienberger 2020</xref>); below we will relax this assumption, and incorporate delayed feedback communicated by spikes. The error signal is modeled as
<disp-formula id="eqn10">
<graphic xlink:href="611710v1_eqn10.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>ξ</italic><sub><italic>f</italic></sub> is zero-mean, unit-variance Gaussian white noise.</p>
<p>The full derivation of the plasticity rule is provided in <italic>Methods: Derivation of the Bayesian plasticity rule</italic>. Here we outline the general approach and main results. Similar to the analysis above, we decompose the synaptic weights into independent fast and slow components, <inline-formula><inline-graphic xlink:href="611710v1_inline5.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, as in <xref ref-type="disp-formula" rid="eqn3">equation (3)</xref>. Framing synaptic plasticity as an optimal control problem, we find that by deriving fast-weight dynamics that minimize the error we simultaneously obtain a highly effective slow-weight learning rule.</p>
<p>To derive the fast-weight rule, we consider a typical control strategy: using past error signals (equa-tion (10)), compute a control variable, <inline-formula><inline-graphic xlink:href="611710v1_inline6.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, such that applying it as an input to the system (in our case, at the level of synaptic currents) will minimize future output error. Analogous to the toy model above, rather than invoke an external control system for this purpose, we assume everything is implemented locally at individual synapses.</p>
<p>Suppose that each synapse can compute such an error-minimizing control, <inline-formula><inline-graphic xlink:href="611710v1_inline6a.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. Setting the fast weights uniformly as
<disp-formula id="eqn11">
<graphic xlink:href="611710v1_eqn11.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
with <italic>ν</italic> denoting the expected input rate per synapse, then leads to <inline-formula><inline-graphic xlink:href="611710v1_inline7.gif" mime-subtype="gif" mimetype="image"/></inline-formula>.</p>
<p>We would like to choose <inline-formula><inline-graphic xlink:href="611710v1_inline8.gif" mime-subtype="gif" mimetype="image"/></inline-formula> to minimize the squared error, (<italic>y</italic> − <italic>y</italic>*)<sup>2</sup>. However, there is a cost to making the squared error very small: <inline-formula><inline-graphic xlink:href="611710v1_inline9.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, and thus <italic>δw</italic><sub><italic>i</italic></sub>, will undergo large fluctuations. To navigate the tradeoff between minimizing the squared error while making sure the fast-weight fluctuations aren’t so large, we find <inline-formula><inline-graphic xlink:href="611710v1_inline10.gif" mime-subtype="gif" mimetype="image"/></inline-formula> via
<disp-formula id="eqn12">
<graphic xlink:href="611710v1_eqn12.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>T</italic> is the task duration and the expectation, 𝔼 […], is over the noise. The parameter <italic>λ</italic><sub><italic>u</italic></sub> is the ‘cost of control’; making it larger reduces fluctuations in the fast weights but increases the squared error between <italic>y</italic> and <italic>y</italic>*; making it smaller has the opposite effect. The quadratic loss in <xref ref-type="disp-formula" rid="eqn12">equation (12)</xref>, along with the Gaussian white noise in the dynamical equations, means that <inline-formula><inline-graphic xlink:href="611710v1_inline11.gif" mime-subtype="gif" mimetype="image"/></inline-formula> can be computed as a solution to the classic linear-quadratic-Gaussian (LQG) control problem. This approach results in a dynamical system that performs a Bayes-optimal estimate of unobserved states (such as the true underlying error, <italic>y</italic> −<italic>y</italic>*), and uses that to construct an optimal linear controller (<xref ref-type="bibr" rid="c20">Crassidis and Junkins 2011</xref>).</p>
<p>The resulting equations predict how synapses should process input and feedback for optimal plasticity. For ease of intuition, we present the results here with some simplifying approximations. The results without approximations, given by <xref ref-type="disp-formula" rid="eqn76a">equation (76)</xref>, are used in simulations, although the approximate equations below provide comparable performance (<xref rid="figS1" ref-type="fig">Fig. S1</xref>).</p>
<p>To set the fast weights, <italic>u</italic> is computed by processing the error feedback signal, <italic>f</italic> (<xref ref-type="disp-formula" rid="eqn10">equation (10)</xref>), via
<disp-formula id="eqn13a">
<graphic xlink:href="611710v1_eqn13a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn13b">
<graphic xlink:href="611710v1_eqn13b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
(<italic>Methods</italic>, <xref ref-type="disp-formula" rid="eqn80a">equations (80a)</xref> and <xref ref-type="disp-formula" rid="eqn92">(92)</xref>). <xref ref-type="disp-formula" rid="eqn13a">Equation (13a)</xref> filters the noisy feedback to compute an online estimate, <inline-formula><inline-graphic xlink:href="611710v1_inline12.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, of the true error, <italic>δ</italic> = <italic>y</italic> − <italic>y</italic>*, using an optimal feedback gain, 𝒦. The control variable is designed to negate the estimated error, with the magnitude of corrections determined by the optimal control gain, ℒ (<xref ref-type="disp-formula" rid="eqn13b">equation (13b)</xref>). The gains 𝒦 and ℒ depend on the model parameters, reflecting both the integrative dynamics of the neuron and downstream output, and the statistics of the noise.</p>
<p>How do the fast weights evolve in this scenario? Taking a time derivative of <xref ref-type="disp-formula" rid="eqn11">equation (11)</xref>, and substituting <xref ref-type="disp-formula" rid="eqn13a">equations (13a)</xref> and <xref ref-type="disp-formula" rid="eqn13b">(13b)</xref>, leads to
<disp-formula id="eqn14">
<graphic xlink:href="611710v1_eqn14.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The fast weights are thus a low-pass filtered version of the negative of the error signal, which is the optimal strategy in the presence of noise. To see how this relates to the toy-model strategy above, we use the fact that when the control cost, <italic>λ</italic><sub><italic>u</italic></sub>, and feedback noise variance, <inline-formula><inline-graphic xlink:href="611710v1_inline13.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, are small, the optimal gains ℒ and 𝒦 are large (<italic>Methods</italic>, <xref ref-type="disp-formula" rid="eqn87">equations (87)</xref> and <xref ref-type="disp-formula" rid="eqn91">(91)</xref>). In this regime, the last term on the right-hand side of <xref ref-type="disp-formula" rid="eqn14">equation (14)</xref> dominates the dynamics; if we consider discrete updates with a time step Δ<italic>t</italic>, <xref ref-type="disp-formula" rid="eqn14">equation (14)</xref> becomes
<disp-formula id="eqn15">
<graphic xlink:href="611710v1_eqn15.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where we used <xref ref-type="disp-formula" rid="eqn10">equation (10)</xref> for <italic>f</italic>. Choosing the control cost to ensure that the product 𝒦ℒ obeys the relationship <inline-formula><inline-graphic xlink:href="611710v1_inline14.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and ignoring the noise, we recover the fast-weight updates for the toy model (<xref ref-type="disp-formula" rid="eqn4">equation (4)</xref>). Details aside, the key principle is the same: observe the current error, then greedily adjust weights to compensate.</p>
<p>What about the slow weights – should they even be updated? And if so, how? To answer the first question, we note that much of the error being controlled by the fast weights is due to mismatch between the slow weights, <inline-formula><inline-graphic xlink:href="611710v1_inline15.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, and the target weights, <inline-formula><inline-graphic xlink:href="611710v1_inline16.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. Which makes sense: in the absence of noise, when <inline-formula><inline-graphic xlink:href="611710v1_inline17.gif" mime-subtype="gif" mimetype="image"/></inline-formula> the weights do not need to be adjusted. That can be seen for the toy model in the right panel of <xref rid="fig1" ref-type="fig">Fig. 1a</xref>; for the more realistic model it’s shown explicitly in <italic>Methods</italic>, <xref ref-type="disp-formula" rid="eqn48a">equation (48a)</xref>. This tells us that the closer the slow weights are to their target values, the smaller the required control signal. Thus, given there is always a maximum control that can be applied, pushing the slow weights towards the target weights will improve performance.</p>
<p>A simple approach to updating the slow weights would be to use a modified delta rule, similar to <xref ref-type="disp-formula" rid="eqn6">equation (6)</xref>. However, in this more realistic setting, the delta rule is suboptimal for two reasons. First, the error feedback signal, <italic>f</italic>, is noisy, which leads to noisy weight fluctuations, and even instability unless the learning rate is very small. Second, as pointed out by <xref ref-type="bibr" rid="c2">Aitchison et al. (2021)</xref>, efficient weight updates should depend on uncertainty, with more uncertain weights updated more rapidly.</p>
<p>Qualitatively at least, the first problem can be fixed by filtering the feedback signal, <italic>f</italic>, and the second by scaling the learning rate by the uncertainty. Determining exactly how to design the filter and how much to scale, is, however, somewhat nontrivial. Fortunately, the analysis used to derive the update rule for the fast weights leads naturally to a rule for updating the slow weights that addresses these problems.</p>
<p>As shown in <italic>Methods: Derivation of the Bayesian learning rule</italic> (see in particular <xref ref-type="disp-formula" rid="eqn80a">equation (80)</xref>), the update rule for the slow weights is
<disp-formula id="eqn16a">
<graphic xlink:href="611710v1_eqn16a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn16b">
<graphic xlink:href="611710v1_eqn16b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn16c">
<graphic xlink:href="611710v1_eqn16c.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The first term on the right-hand side of <xref ref-type="disp-formula" rid="eqn16a">equation (16a)</xref> looks very similar to the delta rule. However, there are three notable differences. First, the term proportional to <inline-formula><inline-graphic xlink:href="611710v1_inline18.gif" mime-subtype="gif" mimetype="image"/></inline-formula> leads to relaxation to the target-weight mean in the absence of feedback. This reflects the fact that, as mentioned above, the weights drift on a timescale of <italic>τ</italic><sub><italic>w</italic></sub>, so without feedback the mean, <italic>µ</italic><sub><italic>w</italic></sub>, becomes the optimal estimate of the weight. Second, the raw error feedback signal, <italic>f</italic>, is replaced by a prediction error, <inline-formula><inline-graphic xlink:href="611710v1_inline19.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. Because <inline-formula><inline-graphic xlink:href="611710v1_inline20.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is just a filtered version of <italic>f</italic> (<xref ref-type="disp-formula" rid="eqn13a">equation (13a)</xref>), <inline-formula><inline-graphic xlink:href="611710v1_inline21.gif" mime-subtype="gif" mimetype="image"/></inline-formula> reflects deviations of the error signal about its time-averaged value. Third, and most important, the effective learning rate is proportional to <italic>z</italic><sub><italic>i</italic></sub>, which plays the role of an eligibility trace, so is different for every synapse. <xref ref-type="disp-formula" rid="eqn16c">Equation (16c)</xref> tells us that <italic>z</italic><sub><italic>i</italic></sub> increases with the variable <inline-formula><inline-graphic xlink:href="611710v1_inline22.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, which reflects weight uncertainty, so the higher the uncertainty the higher the learning rate – as expected. Determining the dependence of <inline-formula><inline-graphic xlink:href="611710v1_inline23.gif" mime-subtype="gif" mimetype="image"/></inline-formula> on the firing rate is not completely straightforward, but we show in <italic>Methods</italic> (see in particular <xref ref-type="disp-formula" rid="eqn99">equation (99)</xref>) that it scales as <inline-formula><inline-graphic xlink:href="611710v1_inline24.gif" mime-subtype="gif" mimetype="image"/></inline-formula> where, recall, <italic>ν</italic><sub><italic>i</italic></sub> is the rate of input to synapse <italic>i</italic>. This too is expected, at least qualitatively: the higher the firing rate, the more certain a synapse is about its value, and the lower the learning rate.</p>
<p>Mathematically, <xref ref-type="disp-formula" rid="eqn16a">equations (16a)</xref> and <xref ref-type="disp-formula" rid="eqn16b">(16b)</xref> represent the evolving mean and variance of a posterior distribution over target weights, similar to the approach introduced by <xref ref-type="bibr" rid="c2">Aitchison et al. (2021)</xref>. This is the best estimate that can be formed by the synapse, given the observed data, and therefore the most efficient learning rule for <inline-formula><inline-graphic xlink:href="611710v1_inline25.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. To highlight this qualitative difference from classical counterparts, and make connections to previous work, we will refer to our plasticity rule and its generalizations as ‘Bayesian plasticity’, in line with <xref ref-type="bibr" rid="c2">Aitchison et al. (2021)</xref>.</p>
<p>Using the teacher-student task, we compared our plasticity rule to a classical gradient-based rule for a neuron with 1000 synapses. The results are shown in <xref rid="fig2" ref-type="fig">Fig. 2</xref>. The classical approach is a generalized delta rule based on the Real-Time Recurrent Learning algorithm (<xref ref-type="bibr" rid="c85">Williams and Zipser 1989</xref>; <xref ref-type="bibr" rid="c66">Pearlmutter 1995</xref>), which is the canonical approach for online learning in dynamic models. We included simulations of the full Bayesian rule, as well as versions using the slow and fast components alone. Learning with the Bayesian slow-weight rule alone is already superior to the classical rule, both in terms of total output error (<xref rid="fig2" ref-type="fig">Fig. 2a</xref>) and the speed of convergence of the weights towards their target values (<xref rid="fig2" ref-type="fig">Fig. 2b</xref>). Output error is reduced further still when the fast weights are included, due to suppression of noise and compensation for weight mismatch at early stages of learning. Moreover, weight convergence in this case is almost indistinguishable from when slow-weight learning is implemented in isolation. Although a similarly low level of error is obtained using the fast weights alone, this requires much larger control currents (<xref rid="fig2" ref-type="fig">Fig. 2c</xref>), and no memory of the task is actually retained in the weights. With some small modifications (<italic>Methods: Feedback delays</italic>), our rule also accounts for time lags in the feedback signal, representing communication delays in the brain. In this case, slow-weight learning is virtually unaffected and fast-weight control remains effective for delays on the order of the downstream time constant (<xref rid="fig2" ref-type="fig">Fig. 2d</xref>).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Synaptic plasticity as optimal control.</title>
<p><bold>a)</bold> Performance comparison between the classical gradient-based rule (black) and Bayesian rule without fast weights (blue), with plastic fast weights and frozen slow weights (red), and with plastic slow and fast weights (purple). Bars denote root-mean-squared error (RMSE) between output, <italic>y</italic>, and target output, <italic>y</italic>*, averaged over the entire task. Data points denote different random seeds. The dashed line gives the average error when slow weights are set to their target values at every point in time. The learning rate for the classical rule and control cost for the Bayesian rule were selected via grid search to minimize output error. <bold>b)</bold> The Bayesian rules yield faster convergence of weights to their target values compared to the classical rule, quantified as RMSE between weight vectors. Shaded areas are standard deviation from 10 random seeds. <bold>c)</bold> Root-mean-squared output error versus fast weight fluctuations, the latter computed as the root-mean-squared fast weight divided by root-mean-squared slow weight (averages taken over entire task). The size of the fast weight fluctuations were controlled by the cost parameter <italic>λ</italic><sub><italic>u</italic></sub> (see <xref ref-type="disp-formula" rid="eqn12">equation (12)</xref>). In the full plasticity rule (purple), even small fluctuations of ∼ 10% lead to a large reduction in error. Without slow-weight learning (red), much more control is needed for a similar level of performance. Points denote the average over seeds for a fixed <italic>λ</italic><sub><italic>u</italic></sub>; the shaded ellipses denote standard deviation across seeds. <bold>d)</bold> Control is effective for feedback delays shorter than the output time constant (here, <italic>τ</italic><sub><italic>y</italic></sub> = 100 ms). Shaded areas are standard deviation from 10 random seeds.</p></caption>
<graphic xlink:href="611710v1_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2b">
<title>Control and learning with spiking feedback</title>
<p>So far we have considered a continuous feedback signal, representing diffuse transmission of a neuromodulator. But many important feedback pathways in the brain communicate via spikes; we now generalize the theory to incorporate these signals. Our modeling choices are specifically motivated by the sparse climbing-fiber inputs to cerebellar Purkinje cells, which provide instructive signals that drive plasticity at parallel-fiber synapses (<xref ref-type="bibr" rid="c41">Hull and Regehr 2022</xref>; <xref ref-type="bibr" rid="c77">Silva et al. 2024</xref>). However, the general formulation is applicable to other scenarios, such as dendritic spikes in cortical neurons that are triggered by feedback connections (<xref ref-type="bibr" rid="c49">Larkum 2013</xref>; <xref ref-type="bibr" rid="c71">Richards and Lillicrap 2019</xref>; <xref ref-type="bibr" rid="c31">Fişek et al. 2023</xref>).</p>
<p>We model the spiking feedback signal, <italic>f</italic><sub><italic>S</italic></sub>, as an inhomogeneous Poisson process with rate
<disp-formula id="eqn17">
<graphic xlink:href="611710v1_eqn17.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Concretely, <italic>f</italic><sub><italic>S</italic></sub> comprises a series of delta functions centered at spike times that are generated with instantaneous rate <italic>γ</italic>(<italic>t</italic>). The synapses ‘see’ the spikes, and can use those to update synaptic strength. The parameters <italic>γ</italic><sub>0</sub> and <italic>ρ</italic> set the spontaneous rate of feedback and steepness of the nonlinear response to output error (representing, for instance, the transfer function of an error-coding neuron).</p>
<p>With spiking feedback, the standard formalism cannot be used for estimating the error and target weights. Instead, similar to <xref ref-type="bibr" rid="c27">Eden et al. (2004)</xref> and <xref ref-type="bibr" rid="c69">Pfister et al. (2010)</xref>, we derived a recursive Bayesian algorithm. The details are provided in <italic>Methods: Spiking feedback</italic>, with the full plasticity rule described by <xref ref-type="disp-formula" rid="eqn117a">equation (117)</xref>. This has a similar structure to the rule discussed above (<xref ref-type="disp-formula" rid="eqn13a">equations (13)</xref> and <xref ref-type="disp-formula" rid="eqn16a">(16)</xref>). Incoming feedback spikes are optimally filtered to form an estimate, <inline-formula><inline-graphic xlink:href="611710v1_inline26.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, of the continuous-valued output error (<xref rid="fig3" ref-type="fig">Fig. 3a</xref>). This is used to set the fast weights via an optimal control gain as before. For the slow weights, <inline-formula><inline-graphic xlink:href="611710v1_inline27.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is transformed into an estimate of the instantaneous feedback rate, <inline-formula><inline-graphic xlink:href="611710v1_inline28.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, and combined with an eligibility trace, <italic>z</italic><sub><italic>i</italic></sub>, to drive learning,</p>
<p>
<disp-formula id="eqn18">
<graphic xlink:href="611710v1_eqn18.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The eligibility trace, which evolves similarly to <xref ref-type="disp-formula" rid="eqn16c">equation (16c)</xref>, records the recent activity level of the synapse. Qualitatively, the slow weights of recently active synapses tend to decrease in steps when feedback spikes arrive and increase gradually in between. This process eventually reaches a steady state where the observed feedback rate is equal to the predicted rate, which happens when the target weights have been accurately estimated.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3:</label>
<caption><title>Control and learning with spiking feedback.</title>
<p><bold>a)</bold> When feedback is communicated via noisy spiking activity, optimal plasticity requires the synapse to infer the true underlying continuous error signal. The estimated error is then used to drive both control and learning. Fast weights seek to improve performance by canceling the estimated error (lower panel), while slow weights seek to reduce the error permanently. <bold>b)</bold> Performance depends on the rate of feedback. High feedback spike rates increase the precision of error estimates, thereby enhancing learning and control. A population of neurons acting on multiple independent feedback signals (dashed purple trace) can compensate for very low individual feedback rates. Shaded areas are standard deviation from 10 random seeds.</p></caption>
<graphic xlink:href="611710v1_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We compare the Bayesian rules to a spiking-feedback version of the classical rule used in the continuous model above (<italic>Methods</italic>, <xref ref-type="disp-formula" rid="eqn38">equation (38)</xref>). Notably, the classical spike-based rule conforms to the standard model of Purkinje cell plasticity (<xref ref-type="bibr" rid="c42">Ito 2001</xref>; <xref ref-type="bibr" rid="c19">Coesmans et al. 2004</xref>): synaptic input alone leads to long-term potentiation (LTP), whereas the conjunction of synaptic input and feedback spikes are required for long-term depression (LTD).</p>
<p>Simulations with the spiking-feedback model were consistent with those of the continuous model, recapitulating all of the previously observed advantages of Bayesian plasticity (<xref rid="fig3" ref-type="fig">Figs. 3b</xref> and <xref ref-type="fig" rid="figS2">S2</xref>). Learning in this case is substantially harder, requiring an order of magnitude more time to reach equivalent levels of performance, primarily because spikes occur rarely. The spontaneous feedback rate, <italic>γ</italic><sub>0</sub>, is therefore a key determinant of performance, with higher rates leading to faster learning and lower output error (<xref rid="figS2" ref-type="fig">Fig. S2</xref>).</p>
<p>Not only does a low feedback rate make learning hard, it also makes fast-weight updates less effective. This is not surprising, since online corrections can only be reliably made soon after receiving an error-encoding spike. However, we found performance can be boosted by distributing the task and feedback across multiple neurons. We explored this by simulating <italic>M</italic> = 20 neurons, each as described by <xref ref-type="disp-formula" rid="eqn7a">equation (7)</xref>. For ease of comparison with the single-neuron simulations, we placed 50 synapses on each of the <italic>M</italic> neurons to give the same total number of synapses. The firing rates in the population model, <italic>r</italic><sub><italic>m</italic></sub>, are summed to drive a common downstream output, modifying <xref ref-type="disp-formula" rid="eqn9">equation (9)</xref>,
<disp-formula id="eqn19">
<graphic xlink:href="611710v1_eqn19.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Each neuron receives a separate Poisson feedback signal, with spikes generated independently from the common error-dependent rate <italic>γ</italic>(<italic>t</italic>). Because the collected feedback spikes now provide a denser error signal, effective control can be achieved at the population level even when <italic>γ</italic><sub>0</sub> is small (<xref rid="fig3" ref-type="fig">Fig. 3b</xref>, dashed line).</p>
</sec>
<sec id="s2c">
<title>Fast and slow synaptic plasticity in the cerebellum</title>
<p>Our theory was derived in a setting where the target weights are defined explicitly and the target output is guaranteed to be realizable by the model. To validate our results in a biological setting and, cucially, to make experimentally testable predictions, we apply it to a cerebellar learning problem.</p>
<p>Our population model can be mapped onto the structure of a cerebellar microzone – a group of Purkinje cells receiving correlated climbing-fiber input and whose outputs converge on common down-stream targets (<xref rid="fig4" ref-type="fig">Fig. 4a</xref>) (Apps et al. 2018). As an abstraction of microzone processing, we consider a population of 20 neurons that must learn to transform patterns of synaptic input into time-varying outputs (<xref rid="fig4" ref-type="fig">Fig. 4b</xref>). The inputs come from parallel fiber spikes, assumed to be driven by time-varying patterns of granule cell activity (<xref ref-type="bibr" rid="c59">Medina et al. 2000</xref>; <xref ref-type="bibr" rid="c35">Gilmer et al. 2023</xref>). The output represents a downstream motor signal, or a predicted motor output (<xref ref-type="bibr" rid="c86">Wolpert et al. 1998</xref>). Feedback is provided by sparse climbing-fiber spikes, with <italic>γ</italic><sub>0</sub> = 2 spikes/s, leading to firing rates close to that observed <italic>in vivo</italic> (<xref ref-type="bibr" rid="c5">Armstrong and Rawson 1979</xref>).</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4:</label>
<caption><title>Fast and slow plasticity in the cerebellum.</title>
<p><bold>a)</bold> Schematic of the cerebellar microzone model. A group of Purkinje cells receiving synaptic input from parallel fibers project to a common downstream output. Each Purkinje cell receives feedback spikes from a separate climbing fiber, signaling the error between actual and target outputs. <bold>b)</bold> Schematic of the learning task. Ten patterns of temporally organized parallel-fiber input must be mapped by a population of Purkinje cells to time-varying target outputs. <bold>c)</bold> Example outputs early and late in learning, replicating the results from the toy model in <xref ref-type="fig" rid="fig1">Fig. 1b</xref>. <bold>d)</bold> Performance during early (100 − 200 s) and late (5000 − 5100 s) stages of learning. Bars denote RMSE between output and target output, averaged over 100 s. <bold>e)</bold> Left: After training on 10 input-output mappings, half of the target outputs were changed. Right: Bayesian plasticity confers faster recovery than the classical approach. With fast weights, the output is largely insensitive to the perturbation. Error curves have been smoothed with a moving average filter of width 10 s. Shaded areas are standard deviations from simulations pooled over 10 random training seeds × 10 perturbations.</p></caption>
<graphic xlink:href="611710v1_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We defined 10 pairs of input-output patterns {<bold><italic>ν</italic></bold><sub><italic>p</italic></sub>(<italic>t</italic>), <inline-formula><inline-graphic xlink:href="611710v1_inline29.gif" mime-subtype="gif" mimetype="image"/></inline-formula>; <italic>p</italic> = 1, …, 10}, each lasting 1 s (<xref rid="fig4" ref-type="fig">Fig. 4b</xref>). The input patterns comprised time-varying vectors of synaptic input rates, <bold><italic>ν</italic></bold><sub><italic>p</italic></sub>, realized with Poisson spiking. We used 2000 synapses in total, distributed equally across the 20 Purkinje cells. The target output trajectories were defined as random wavelets with shapes that drift on a slow timescale of ∼10<sup>4</sup> s (analogous to the target-weight drift in the teacher-student task). Input-output pairs were presented in a continuous stream in random order for 500 s. While all of the models can eventually solve this task, the Bayesian models learn much faster, and control via the fast weights can pin the output to the target from the outset (<xref rid="fig4" ref-type="fig">Fig. 4c,d</xref>).</p>
<p>So far we have focused on learning a particular input-output mapping. What happens when the desired input-output mapping changes? To address this, we tested the response of the trained models to changes in the target outputs. As above, we trained on 10 input-output mappings, but after training we changed 5 of the outputs (<xref rid="fig4" ref-type="fig">Fig. 4e</xref>). An efficient response requires synapses to adapt selectively to learn the new input-output pairs, without disrupting previously learned pairs. We find that Bayesian plasticity is much more robust than the classical approach, enabling rapid recovery over a few tens of pattern presentations. With fast-weight updates, the output error is almost unaffected by the perturbation. And in the background, the slow weights gradually converge to their new target values, reducing the magnitude of ongoing control currents and updating the stored memory of the task.</p>
</sec>
<sec id="s2d">
<title>Signatures of fast and slow synaptic plasticity</title>
<p>We use the cerebellar learning task to make experimental predictions for the control and learning components of our theory. In the cerebellar model, the control signal depends strongly on climbing-fiber input, transiently adjusting activity whenever a feedback spike arrives. To measure the size of this effect in our model, we plotted the firing rates of neurons relative to the time of their associated climbing-fiber spikes. These simulations show a pronounced dip in firing rates after a climbing-fiber spike, but only when there are fast-weight updates; the dip disappears both for classical and Bayesian updates of slow weights only (<xref rid="fig5" ref-type="fig">Fig. 5a</xref>). Such patterns of activity – climbing-fiber-induced ‘spike pauses’ – have been widely observed <italic>in vivo</italic> (<xref ref-type="bibr" rid="c7">Bell and Grimm 1969</xref>; <xref ref-type="bibr" rid="c11">Bloedel and Roberts 1971</xref>; <xref ref-type="bibr" rid="c76">Sato et al. 1992</xref>; <xref ref-type="bibr" rid="c6">Barmack and Yakhnitsa 2003</xref>; <xref ref-type="bibr" rid="c36">Han et al. 2020</xref>). However, while widely observed, their computational significance has remained unclear; our model provides a novel, normative explanation that spike pauses are a strategy for suppressing downstream error. Moreover, it makes two experimentally testable predictions: the duration of the dip increases with the time constant of downstream dynamics, <italic>τ</italic><sub><italic>y</italic></sub>, and the magnitude of the dip decreases with feedback delays (<xref rid="fig5" ref-type="fig">Fig. 5b</xref>). Both predictions could be tested by manipulating output dynamics experimentally, or exploiting the fact that feedback delays vary across different regions of the cerebellum (<xref ref-type="bibr" rid="c80">Suvrathan et al. 2016</xref>; <xref ref-type="bibr" rid="c43">Jayabal et al. 2022</xref>).</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5:</label>
<caption><title>Signatures of fast and slow synaptic plasticity.</title>
<p><bold>a)</bold> Suppression of Purkinje-cell firing rates after climbing-fiber input is a signature of fast-weight updates. The solid lines denote averages of firing rates aligned to climbing-fiber feedback spikes during the cerebellar learning task. Shaded areas are the standard deviation of the average firing rate change of 20 neurons × 10 random seeds. <bold>b)</bold> The duration and magnitude of the predicted firing rate suppression vary systematically with the time constant of the downstream output and the feedback delay. <bold>c)</bold> A standard experimental protocol can discriminate between classical and Bayesian plasticity. After training on the cerebellar learning task, synapses were stimulated with conjunctions of parallel-fiber input bursts and climbing-fiber feedback spikes (50 repetitions at 2 reps/s). <bold>d)</bold> Left: The Bayesian rules produce LTD over a narrower range of PF-CF intervals than the classical rule, and also exhibit greater variability across synapses. Right: The variability is due to the adaptive learning rate: in the Bayesian rules, unlike the classical rule, the magnitude of weight changes depend on the average rate of input during the task. Solid lines denote synaptic weight changes measured at the end of the protocol, averaged over 100 tested synapses. Shaded areas are standard deviation.</p></caption>
<graphic xlink:href="611710v1_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Our model also makes predictions about the slow-weight dynamics. For that we used the trained models to simulate a common experimental plasticity protocol. In this protocol, synapses are repeatedly stimulated with a short burst of parallel fiber spikes, followed by one or more climbing-fiber spikes (here repeated 50 times at 2 repetitions/s) (<xref rid="fig5" ref-type="fig">Fig. 5c</xref>). In experiments, LTP is generally observed at zero or negative intervals between parallel and climbing-fiber stimulation, but switches to LTD for sufficiently positive intervals or sufficiently many climbing-fiber spikes (<xref ref-type="bibr" rid="c83">Wang et al. 2000</xref>; <xref ref-type="bibr" rid="c75">Safo and Regehr 2008</xref>; <xref ref-type="bibr" rid="c56">Mathy et al. 2009</xref>; <xref ref-type="bibr" rid="c80">Suvrathan et al. 2016</xref>; Bouvier et al. 2018). All of our models reproduced these observations, and have qualitatively similar behavior as the parameters of the plasticity protocol are varied (<xref rid="figS3" ref-type="fig">Fig. S3</xref>). However, the Bayesian rules yielded sharper tuning to the interval, and, importantly, greater variability across synapses (<xref rid="fig5" ref-type="fig">Fig. 5d</xref>). The source of this variability is the adaptive learning rate of Bayesian plasticity: the magnitude of slow-weight changes during the protocol depends on the average rate of input received during the task. Our theory can therefore be discriminated from the standard model by combining well-established plasticity protocols with recording or manipulation of input rates. While this may be possible <italic>in vivo</italic> in the near future with optogenetics and voltage imaging (Fan et al. 2023), <italic>in vitro</italic>, we predict that preconditioning a synapse with a long train of parallel fiber spikes can block subsequent plasticity induction by driving down its intrinsic learning rate.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>We proposed that synaptic plasticity should operate at two timescales: a fast timescale to suppress immediate errors, and a slow timescale to learn. This multiscale plasticity rule significantly outperforms online gradient-based learning, confers robustness to noise and other perturbations, and means that neurons can accurately perform a task almost immediately – well before learning has stored a longer-term solution in the weights.</p>
<sec id="s3a">
<title>Fast weights for feedback control</title>
<p>Our theory frames synaptic plasticity as an optimal control problem. This is a natural framework for any system where real-time feedback is available to guide the dynamics. While there is a long tradition of using control theory to understand neural function (<xref ref-type="bibr" rid="c81">Todorov 2004</xref>; <xref ref-type="bibr" rid="c58">McNamee and Wolpert 2019</xref>), our work is most closely related to recent studies that have also connected fast control mechanisms with slower processes of learning. In one approach, fast feedback was used to drive spiking network dynamics to a regime that enables local learning of complex tasks (<xref rid="c13" ref-type="bibr">Bourdoukan and Denève 2015</xref>; <xref rid="c25" ref-type="bibr">Denève et al. 2017</xref>; <xref ref-type="bibr" rid="c3">Alemi et al. 2018</xref>). In another, the Deep Feedback Control theory uses feedback to drive network output to a target steady-state, and then exploits credit assignment signals implicit within the controller to gradually tune feedforward weights (<xref ref-type="bibr" rid="c60">Meulemans et al. 2021</xref>; <xref ref-type="bibr" rid="c61">Meulemans et al. 2022</xref>; <xref ref-type="bibr" rid="c73">Rossbroich and Zenke 2023</xref>). In a recurrent network model of motor adaptation, <xref ref-type="bibr" rid="c30">Feulner et al. (2022)</xref> notably used the same error feedback signal for both control and learning, finding network dynamics resembling data from monkeys. Our theory differs markedly from all of these approaches, however, as the control signals in our models can be computed and implemented by individual synapses. Thus, in place of complex network-level control structures, we are positing a novel processing role for intracellular signaling at the synapse (<xref ref-type="bibr" rid="c9">Bhalla 2014</xref>; <xref ref-type="bibr" rid="c8">Benna and Fusi 2016</xref>; <xref ref-type="bibr" rid="c88">Zenke et al. 2017</xref>). Exploiting this local layer of processing could allow the brain to operate much more efficiently: physically, it reduces the amount of wiring and neurons needed for high performance; algorithmically, neurons make dual use of the feedback signals they receive.</p>
<p>The fast mechanism we propose differs from typical forms of short-term plasticity (<xref ref-type="bibr" rid="c89">Zucker and Regehr 2002</xref>; <xref ref-type="bibr" rid="c1">Abbott and Regehr 2004</xref>). Namely, in our model, fast weight changes depend strongly on error feedback, rather than presynaptic spike patterns alone. How could this be implemented biologically? If error signals are carried by a neuromodulator, as assumed in our continuous-feedback model, there are a range of candidate pathways. Neuromodulators including acetylcholine (<xref ref-type="bibr" rid="c57">McGehee et al. 1995</xref>; <xref ref-type="bibr" rid="c34">Gil et al. 1997</xref>), serotonin (<xref ref-type="bibr" rid="c29">Feng et al. 2001</xref>), dopamine (<xref ref-type="bibr" rid="c38">Higley and Sabatini 2010</xref>), norepinephrine (<xref ref-type="bibr" rid="c18">Cheun and Yeh 1992</xref>), among others (<xref ref-type="bibr" rid="c54">Marder 2012</xref>; <xref ref-type="bibr" rid="c63">Nadim and Bucher 2014</xref>), are all capable of selectively regulating synaptic transmission and the magnitudes of postsynaptic currents. In common with our model, these effects are transient, can be bidirectional, and are distinct from influences on membrane excitability and long-term plasticity. Alternatively, feedback signals might be processed by closely apposed glia. For instance, astrocytes would be well-placed to perform the computations we describe: they are known to integrate a variety of molecular signals and dynamically fine-tune both both pre and postsynaptic properties (<xref ref-type="bibr" rid="c68">Perea et al. 2009</xref>; <xref rid="c23" ref-type="bibr">De Pittà et al. 2016</xref>; <xref ref-type="bibr" rid="c64">Papouin et al. 2017</xref>).</p>
<p>In our cerebellar model, we assume that the fast fluctuations are driven by climbing fiber input. At a functional level, decades of past experiments are in striking agreement with our theory: when a climbing fiber spike is received by a Purkinje cell, there is a brief pause in output firing. Previous functional explanations for spike pauses include precise temporal or multiplexed coding (<xref ref-type="bibr" rid="c79">Steuber et al. 2007</xref>; <xref ref-type="bibr" rid="c24">De Schutter and Steuber 2009</xref>; <xref ref-type="bibr" rid="c36">Han et al. 2020</xref>), encoding dendritic spike rates (<xref ref-type="bibr" rid="c21">Davie et al. 2008</xref>), and transmitting teaching signals to downstream neurons (<xref ref-type="bibr" rid="c55">Mathews et al. 2012</xref>). While not mutually exclusive, we offer the simple explanation that if climbing fibers are indeed signaling error, then pauses are an effective mechanism for making short-term corrections. Our modeling predicts this mechanism would be most apparent in experiments focused on regions and modalities with short feedback delays, such as those receiving signals from the spinal cord for postural maintenance, or proprioceptive feedback from the periphery. It will be interesting to investigate how feedback control of cerebellar output could also support the function of more complex, nested motor-control loops (<xref ref-type="bibr" rid="c86">Wolpert et al. 1998</xref>; <xref ref-type="bibr" rid="c74">Rotondo et al. 2023</xref>), and cognitive computations more generally (<xref ref-type="bibr" rid="c40">Hull 2020</xref>; <xref ref-type="bibr" rid="c47">Kostadinov and Häusser 2022</xref>; <xref ref-type="bibr" rid="c67">Pemberton et al. 2023</xref>).</p>
</sec>
<sec id="s3b">
<title>Slow weights for learning</title>
<p>Optimizing weights for control on fast timescales also leads to highly efficient learning on slow timescales. The rule that arises naturally in our framework works efficiently by maintaining a Bayesian estimate of the target synaptic weight and its uncertainty – the best a synapse can do, given a sequence of noisy local observations. Updating weights slowly in line with this evolving estimate gradually reduces the magnitude of corrections that need to be applied via the fast weights.</p>
<p>Bayesian approaches to plasticity were explored in much earlier work, both in machine learning (Bun-tine and Weigend 1991; <xref ref-type="bibr" rid="c51">MacKay 1992</xref>) and neuroscience (<xref ref-type="bibr" rid="c22">Dayan and Kakade 2000</xref>), but have only recently begun to be broadly exploited (<xref ref-type="bibr" rid="c12">Blundell et al. 2015</xref>; <xref ref-type="bibr" rid="c37">Hernández-Lobato and Adams 2015</xref>; <xref ref-type="bibr" rid="c45">Kappel et al. 2015</xref>; <xref rid="c46" ref-type="bibr">Kirkpatrick et al. 2017</xref>; <xref ref-type="bibr" rid="c26">Drugowitsch et al. 2019</xref>; <xref ref-type="bibr" rid="c39">Hiratani and Latham 2020</xref>; <xref ref-type="bibr" rid="c2">Aitchison et al. 2021</xref>; <xref ref-type="bibr" rid="c44">Jegminat et al. 2022</xref>; <xref ref-type="bibr" rid="c53">Malkin et al. 2024</xref>). <xref ref-type="bibr" rid="c2">Aitchison et al. (2021)</xref>, in particular, were the first to develop a Bayesian theory of local synaptic plasticity. In common with our slow-weight rule, they found that tracking weight uncertainty leads to an adaptive learning rate, yielding superior performance to a simple online delta rule. As well as the novel connection to control, the slow-weight component of our theory generalizes their results in two important directions. First, <xref ref-type="bibr" rid="c2">Aitchison et al. (2021)</xref> assume that data seen by a synapse comprises independent samples, approximating away any history dependence. By contrast, our dynamic model and learning rule accounts for, and crucially exploits, the temporal correlations inherent in neural signals. Second, our theory incorporates sources of spiking feedback and communication delays, making Bayesian plasticity more widely applicable as a theory of learning in the brain. Simulating our more realistic model, we outlined how this theory could be tested (<xref rid="fig5" ref-type="fig">Fig. 5</xref>): if synapses have evolved to use local data as efficiently as possible, then adding a pre-conditioning train of input to common <italic>in vitro</italic> plasticity protocols should unmask the characteristic adaptive learning rate.</p>
</sec>
<sec id="s3c">
<title>Outlook</title>
<p>Our general framework can be used to make predictions about plasticity in other cells and circuits, including more complex scenarios than we have studied here. For instance, while we have focused on linear neural dynamics – a suitable approximation for cerebellar Purkinje cells (<xref ref-type="bibr" rid="c50">Llinás and Sugimori 1980</xref>; <xref ref-type="bibr" rid="c16">Brunel et al. 2004</xref>; <xref ref-type="bibr" rid="c82">Walter and Khodakhah 2006</xref>) – the theory could be adapted to account for nonlinear integration in cortical and hippocampal neurons (<xref ref-type="bibr" rid="c70">Poirazi et al. 2003</xref>; <xref ref-type="bibr" rid="c65">Payeur et al. 2021</xref>; <xref ref-type="bibr" rid="c10">Bicknell and Häusser 2021</xref>). This could be achieved with a straightforward modification of the Kalman filtering approach that we used, for which there are already established theoretical tools for nonlinear filtering and control (<xref ref-type="bibr" rid="c20">Crassidis and Junkins 2011</xref>; <xref ref-type="bibr" rid="c48">Kutschireiter et al. 2020</xref>). At the network level, combining fast and slow plasticity with recurrent connectivity would be a challenging, but likely very fruitful, direction. It has previously been shown, for instance, that the concerted action of multiple plasticity rules can enhance memory formation and stability (<xref ref-type="bibr" rid="c87">Zenke et al. 2015</xref>).</p>
<p>Finally, to derive our fast and slow plasticity rules, the synapses had to know the underlying equations that transform synaptic drive to the output. How this is learned is an interesting, and important, problem. It is likely that some of the learning can be accomplished on much slower, even evolutionary, timescales (<xref ref-type="bibr" rid="c33">Friedrich et al. 2021</xref>). On shorter timescales, <xref ref-type="bibr" rid="c62">Moore et al. (2024)</xref> proposed an elegant solution: learn the optimal controller from data without ever learning the underlying equations. Applying this formalism, they demonstrated that a wide range of neurophysiological data can be explained by modeling individual neurons as optimal feedback controllers. Incorporating similar ideas to study nonlinear computations in hierarchical and recurrent neural circuits is an important avenue for future work.</p>
</sec>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Online linear regression</title>
<p>Using the simple linear regression model described by <xref ref-type="disp-formula" rid="eqn1">equation (1)</xref>, we illustrated how concurrent fast and slow updates to synaptic weights can be exploited to optimize task performance. Here we provide the derivation of the plasticity rules for that model (<xref ref-type="disp-formula" rid="eqn4">equations (4)</xref> and <xref ref-type="disp-formula" rid="eqn6">(6)</xref>).</p>
<p>We consider a discrete-time setting where the inputs, output and weights are updated at small intervals, Δ<italic>t</italic>. Decomposing synaptic weights into fast and slow components, <xref ref-type="disp-formula" rid="eqn1">equation (1)</xref> becomes
<disp-formula id="eqn20">
<graphic xlink:href="611710v1_eqn20.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
After observing the local inputs, <italic>ν</italic><sub><italic>i</italic></sub>, and error, <italic>y</italic> − <italic>y</italic>*, at time <italic>t</italic>, synapses update their fast and slow weight components in parallel,
<disp-formula id="eqn21a">
<graphic xlink:href="611710v1_eqn21a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn21b">
<graphic xlink:href="611710v1_eqn21b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The role of the fast weights, <italic>δw</italic><sub><italic>i</italic></sub>, is to greedily suppress the current error, so that <italic>y</italic> approximately matches <italic>y</italic>* – independent of the setting of the slow weights. We achieve this by choosing the fast-weight updates to be proportional to the negative of the error,
<disp-formula id="eqn22">
<graphic xlink:href="611710v1_eqn22.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>N</italic> is the total number of synapses and <inline-formula><inline-graphic xlink:href="611710v1_inline30.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is the expected input rate. Using this expression, and inserting <xref ref-type="disp-formula" rid="eqn21a">equation (21)</xref> into <xref ref-type="disp-formula" rid="eqn20">equation (20)</xref>, at the next time step we have
<disp-formula id="eqn23">
<graphic xlink:href="611710v1_eqn23.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
To derive the approximate expression in the second line, we replaced <italic>ν</italic><sub><italic>i</italic></sub>(<italic>t</italic> +Δ<italic>t</italic>) by <italic>ν</italic><sub><italic>i</italic></sub>(<italic>t</italic>), which is valid if Δ<italic>t</italic> is small compared to the timescale over which the firing rates change, and dropped the term <inline-formula><inline-graphic xlink:href="611710v1_inline31.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, which is valid if the slow weight updates are small. The first term is just <italic>y</italic>(<italic>t</italic>) (see <xref ref-type="disp-formula" rid="eqn20">equation (20)</xref>); approximating Σ<sub><italic>i</italic></sub> <italic>ν</italic><sub><italic>i</italic></sub> by its expectation then gives
<disp-formula id="eqn24">
<graphic xlink:href="611710v1_eqn24.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Thus, with mild assumptions, the fast-weight updates given in <xref ref-type="disp-formula" rid="eqn22">equation (22)</xref> force the output to closely match the target at all times.</p>
<p>While the fast-weight updates ensure low output error, this comes at the cost of ongoing, and potentially large, fluctuations in weights. Those fluctuations can be seen in the right panel of <xref rid="fig1" ref-type="fig">Fig. 1a</xref>, especially at early times before the slow weights have been updated. We address this with a local rule for the slow weights that permanently pushes <italic>y</italic> closer to <italic>y</italic>*, thereby reducing the need for ongoing corrections. To that end, at each time step, we adjust the slow weights with the aim of minimizing the loss
<disp-formula id="eqn25">
<graphic xlink:href="611710v1_eqn25.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The loss is minimized by making updates in steps proportional to the negative of the gradient
<disp-formula id="eqn26">
<graphic xlink:href="611710v1_eqn26.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
For the last line we used the fact that the fast weights do not depend on the synapse index, so <italic>Σ</italic><sub><italic>j</italic></sub> <italic>δw</italic><sub><italic>j</italic></sub><italic>ν</italic><sub><italic>j</italic></sub> = <italic>δw</italic><sub><italic>i</italic></sub> <italic>Σ</italic><sub><italic>j</italic></sub> <italic>ν</italic><sub><italic>j</italic></sub> ≈ <italic>Nνδw</italic><sub><italic>i</italic></sub>. This leads to a local slow-weight update rule
<disp-formula id="eqn27">
<graphic xlink:href="611710v1_eqn27.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <inline-formula><inline-graphic xlink:href="611710v1_inline32.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is a small learning rate. <xref ref-type="disp-formula" rid="eqn22">Equations (22)</xref> and <xref ref-type="disp-formula" rid="eqn27">(27)</xref> for the fast and slow updates correspond to <xref ref-type="disp-formula" rid="eqn4">equations (4)</xref> and <xref ref-type="disp-formula" rid="eqn6">(6)</xref> in the main text.</p>
</sec>
<sec id="s4b">
<title>Classical online learning</title>
<p>For the model described by <xref ref-type="disp-formula" rid="eqn7a">equations (7)</xref> and <xref ref-type="disp-formula" rid="eqn9">(9)</xref>, with either continuous feedback (<xref ref-type="disp-formula" rid="eqn10">equation (10)</xref>) or spiking feedback (<xref ref-type="disp-formula" rid="eqn17">equation (17)</xref>), we compared our Bayesian plasticity rules to classical, gradient-based counterparts. The classical rules are based on the Real Time Recurrent Learning algorithm (RTRL; <xref ref-type="bibr" rid="c85">Williams and Zipser 1989</xref>; <xref ref-type="bibr" rid="c66">Pearlmutter 1995</xref>), which is the canonical online, gradient-based learning rule for dynamic models. While typically employed in recurrent neural networks, here we apply it to a single-neuron model, adapted slightly to enable fair comparisons with alternatives.</p>
<p>For continuous feedback, we aim to minimize the squared output error, (<italic>y</italic> − <italic>y</italic>*)<sup>2</sup>. However, unlike the simple model, here we need to account for history dependence – the output at any given time depends on inputs that were received in the past. To account for this, we start by considering a loss integrated over a time horizon, <italic>h</italic>, in which the weights are held fixed,
<disp-formula id="eqn28">
<graphic xlink:href="611710v1_eqn28.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The derivative of the loss with respect to the weight of synapse <italic>i</italic> over that period is
<disp-formula id="eqn29">
<graphic xlink:href="611710v1_eqn29.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The second factor in the integral is a dynamic quantity, which can be computed by taking derivatives of <xref ref-type="disp-formula" rid="eqn7a">equations (7)</xref> and <xref ref-type="disp-formula" rid="eqn9">(9)</xref> with respect to <italic>w</italic><sub><italic>i</italic></sub>. This gives the linear system
<disp-formula id="eqn30a">
<graphic xlink:href="611710v1_eqn30a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn30b">
<graphic xlink:href="611710v1_eqn30b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn30c">
<graphic xlink:href="611710v1_eqn30c.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
for the sensitivities <inline-formula><inline-graphic xlink:href="611710v1_inline33.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="611710v1_inline34.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. <xref ref-type="disp-formula" rid="eqn30a">Equation (30)</xref> is solved from the initial condition <italic>s</italic><sub><italic>I,i</italic></sub>(<italic>t</italic><sub>0</sub>), <italic>s</italic><sub><italic>I,i</italic></sub>(<italic>t</italic><sub>0</sub>), <italic>s</italic><sub><italic>I,i</italic></sub>(<italic>t</italic><sub>0</sub>) = 0. An exact gradient-descent weight update could then be applied at time <italic>t</italic><sub>0</sub> + <italic>h</italic> as
<disp-formula id="eqn31">
<graphic xlink:href="611710v1_eqn31.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>η</italic> is the learning rate. Functionally, <italic>s</italic><sub><italic>y,i</italic></sub> plays the role of an eligibility trace by recording the recent impact of the synapse on the output.</p>
<p>Formally, after the weights have been updated, the sensitivities should then be reset to the zero initial condition to track activity over the next time interval. However, assuming weight changes are slow compared to the model dynamics, the RTRL rule is commonly run as a fully online approximation by taking <italic>h</italic> → 0, giving a differential equation for the weight dynamics, and neglecting the reset of the sensitivities (<xref ref-type="bibr" rid="c66">Pearlmutter 1995</xref>). We take this approach here and make two further modifications. First, we replace the term (<italic>y</italic> − <italic>y</italic>*) with its noisy observation, <italic>f</italic>. Second, we append an additional weight decay term to account for the slow drift of the target weights (see <xref ref-type="bibr" rid="c2">Aitchison et al. (2021)</xref> and the derivation of the Bayesian rule below for motivation). This leads to classical online updates for each synapse
<disp-formula id="eqn32">
<graphic xlink:href="611710v1_eqn32.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
For spiking feedback, we use the same approach, but with a different loss function. In this case the output error is communicated via a Poisson process with rate <italic>γ</italic>(<italic>t</italic>), as described by <xref ref-type="disp-formula" rid="eqn17">equation (17)</xref>. To handle the random and discrete nature of spiking feedback, we work with spike probabilities.</p>
<p>Over a time horizon <italic>h</italic>, the feedback spike count, denoted <italic>n</italic>, will be distributed as
<disp-formula id="eqn33">
<graphic xlink:href="611710v1_eqn33.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Updates to the weights should seek to match this distribution to the one that would arise if all of the weights were set correctly. We express this in terms of a ‘target rate’, <italic>γ</italic>*, which defines a target distribution, <italic>P</italic> (<italic>n</italic>|<italic>γ</italic>*), via <xref ref-type="disp-formula" rid="eqn33">equation (33)</xref>.</p>
<p>We use the cross-entropy loss between target and actual distributions to derive the updates; this is given by
<disp-formula id="eqn34">
<graphic xlink:href="611710v1_eqn34.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The derivative of the loss with respect to weight <italic>w</italic><sub><italic>i</italic></sub> is, using <inline-formula><inline-graphic xlink:href="611710v1_inline35.gif" mime-subtype="gif" mimetype="image"/></inline-formula>,
<disp-formula id="eqn35">
<graphic xlink:href="611710v1_eqn35.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
As before, we use <xref ref-type="disp-formula" rid="eqn30a">equation (30)</xref> to compute the <inline-formula><inline-graphic xlink:href="611710v1_inline36.gif" mime-subtype="gif" mimetype="image"/></inline-formula> term, accounting for the history dependence.</p>
<p>Similar to the continuous feedback model, we define weight updates to be proportional to the negative of the loss gradient, and then take <italic>h</italic> → 0 to yield a continJuous-time expression. Expanding <xref ref-type="disp-formula" rid="eqn35">equation (35)</xref> to first order in <italic>h</italic>, approximating the integrals as <inline-formula><inline-graphic xlink:href="611710v1_inline37.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, and exponentials as <italic>e</italic><sup>−<italic>hγ</italic></sup> ≈ 1 − <italic>hγ</italic>, only the <italic>n</italic> = 0 and <italic>n</italic> = 1 terms survive from the sum. Some straightforward algebra then leads to
<disp-formula id="eqn36">
<graphic xlink:href="611710v1_eqn36.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Thus, the spiking-feedback analogue of <xref ref-type="disp-formula" rid="eqn31">equation (31)</xref> is
<disp-formula id="eqn37">
<graphic xlink:href="611710v1_eqn37.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>η</italic><sub><italic>S</italic></sub> is the learning rate.</p>
<p>Taking <italic>h</italic> → 0, and approximating the unobserved rate <italic>γ</italic> with feedback spikes, <italic>f</italic><sub><italic>S</italic></sub>, leads to a continuous-time learning rule
<disp-formula id="eqn38">
<graphic xlink:href="611710v1_eqn38.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where we have appended a weight decay term as before.</p>
<p>Finally, to set <italic>γ</italic>*, we use the fact that when the weights are set correctly, the error comprises Gaussian fluctuations about zero due to noise. With the exponential nonlinearity in the feedback rate function (<xref ref-type="disp-formula" rid="eqn17">equation (17)</xref>), the expected rate is the mean of a log-normal variable, giving
<disp-formula id="eqn39">
<graphic xlink:href="611710v1_eqn39.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <inline-formula><inline-graphic xlink:href="611710v1_inline38.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is the stationary variance of the output noise. The stationary variance can be computed numerically in terms of the model parameters via the Lyapunov equation
<disp-formula id="eqn40">
<graphic xlink:href="611710v1_eqn40.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
In <xref ref-type="disp-formula" rid="eqn40">equation (40)</xref>, <bold>A</bold> is a matrix encoding the model dynamics (see <xref ref-type="disp-formula" rid="eqn70">equation (70)</xref>, below), and <bold>Λ</bold><sub>noise</sub> is diagonal matrix comprising noise variances <inline-formula><inline-graphic xlink:href="611710v1_inline39.gif" mime-subtype="gif" mimetype="image"/></inline-formula> on the diagonal. The relevant term <inline-formula><inline-graphic xlink:href="611710v1_inline40.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is found at the last row and last column of <bold>Σ</bold><sub>noise</sub>.</p>
<p>In all simulations, learning rates for the classical rules were selected via grid search to minimize output error.</p>
</sec>
<sec id="s4c">
<title>Derivation of the Bayesian plasticity rule</title>
<sec id="s4c1">
<title>Problem setting</title>
<p>Given the model dynamics described by <xref ref-type="disp-formula" rid="eqn7a">equations (7)</xref> and <xref ref-type="disp-formula" rid="eqn9">(9)</xref>, we consider a general task in which the goal is choose weights, <italic>w</italic><sub><italic>i</italic></sub>, to match the output, <italic>y</italic>, to a time-varying target, <italic>y</italic>*. We assume <italic>y</italic>* is generated via deterministic dynamics identical to <italic>y</italic>, using a set of target weights <inline-formula><inline-graphic xlink:href="611710v1_inline41.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. Following <xref ref-type="bibr" rid="c2">Aitchison et al. (2021)</xref>, to represent environmental variability or ongoing changes in the local circuit, we assume the mapping between input and target output drifts slowly over time, modeled as random drift of the target weights about a constant mean, <italic>µ</italic><sub><italic>w</italic></sub>,
<disp-formula id="eqn41">
<graphic xlink:href="611710v1_eqn41.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The drift timescale, <italic>τ</italic><sub><italic>w</italic></sub> ∼ 1000 s, is orders of magnitude slower than the neuronal and output dynamics.</p>
<p>The above assumptions about the relationship of target weights to <italic>y</italic>*, and the drift described by <xref ref-type="disp-formula" rid="eqn41">equation (41)</xref>, are exact in the teacher-student learning paradigm. In the cerebellar learning simulations, target weights are instead defined implicitly as weight values that would solve the task.</p>
</sec>
<sec id="s4c2">
<title>Error minimization from the perspective of a single synapse</title>
<p>As in the simple online linear regression model, we decompose the weights into independent slow and fast components, <inline-formula><inline-graphic xlink:href="611710v1_inline42.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. The fast weights, <italic>δw</italic><sub><italic>i</italic></sub>, will be responsible for suppressing error, while the slow weights, <inline-formula><inline-graphic xlink:href="611710v1_inline43.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, gradually converge to the target weights, thereby reducing the magnitude of ongoing corrections. However, with the more realistic dynamics described by <xref ref-type="disp-formula" rid="eqn7a">equations (7)</xref> and <xref ref-type="disp-formula" rid="eqn9">(9)</xref>, writing down the plasticity rule is considerably more challenging. That’s because the mapping from the weights, <italic>w</italic><sub><italic>i</italic></sub>, to the output, <italic>y</italic>, is more complicated: rather than a simple sum, as in <xref ref-type="disp-formula" rid="eqn1">equation (1)</xref>, there are several differential equations separating the weights from the output (<xref ref-type="disp-formula" rid="eqn7a">equations (7)</xref> and <xref ref-type="disp-formula" rid="eqn9">(9)</xref>).</p>
<p>To derive learning rules in this more complicated setting, we start by introducing a set of variables equal to the difference between actual and target quantities,
<disp-formula id="eqn42a">
<graphic xlink:href="611710v1_eqn42a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn42b">
<graphic xlink:href="611710v1_eqn42b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn42c">
<graphic xlink:href="611710v1_eqn42c.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
From <xref ref-type="disp-formula" rid="eqn7a">equations (7)</xref> and <xref ref-type="disp-formula" rid="eqn9">(9)</xref>, these evolve via
<disp-formula id="eqn43a">
<graphic xlink:href="611710v1_eqn43a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn43b">
<graphic xlink:href="611710v1_eqn43b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn43c">
<graphic xlink:href="611710v1_eqn43c.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The target weights, <inline-formula><inline-graphic xlink:href="611710v1_inline44.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, are unknown, so on the surface these equations don’t seem especially useful. However, the synapses have access to the feedback, <italic>f</italic>, which is a noisy version of <italic>δ</italic><sub><italic>y</italic></sub> (see <xref ref-type="disp-formula" rid="eqn10">equation (10)</xref>). Thus, they can use these equations to estimate <inline-formula><inline-graphic xlink:href="611710v1_inline45.gif" mime-subtype="gif" mimetype="image"/></inline-formula> based on the mismatch between <italic>δ</italic><sub><italic>y</italic></sub> and <italic>f</italic>, and update the actual weights, <italic>w</italic><sub><italic>j</italic></sub>, with the aim of making <italic>δ</italic><sub><italic>y</italic></sub> as small as possible.</p>
<p>However, there’s a problem: <italic>δ</italic><sub><italic>y</italic></sub> depends on the activity of all the synapses; information that any one synapse doesn’t have. To remedy this, we’ll work from the perspective of synapse <italic>i</italic>, and model <italic>δ</italic><sub><italic>y</italic></sub> in terms of local variables.</p>
<p>Decomposing synaptic weights into slow and fast components, the sum in <xref ref-type="disp-formula" rid="eqn43a">equation (43a)</xref> can be expanded as
<disp-formula id="eqn44">
<graphic xlink:href="611710v1_eqn44.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The first term depends only on synapse <italic>i</italic>, so it’s local. The second term represents a source of error due to the other <italic>N</italic> − 1 unobserved synapses. For Poisson input and large <italic>N</italic>, this can be approximated as Gaussian white noise (<xref ref-type="bibr" rid="c32">Fourcaud and Brunel 2002</xref>),
<disp-formula id="eqn45">
<graphic xlink:href="611710v1_eqn45.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
As above, <italic>ν</italic> denotes the expected input rate per synapse.</p>
<p>For the third term in <xref ref-type="disp-formula" rid="eqn44">equation (44)</xref>, we view the sum over fast weights as approximating a single scalar control variable, denoted <italic>u</italic>, later to be chosen to minimize output error. Assuming that all of the synapses can compute <italic>u</italic> locally, by setting the fast weights uniformly as
<disp-formula id="eqn46">
<graphic xlink:href="611710v1_eqn46.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
the third term in <xref ref-type="disp-formula" rid="eqn44">equation (44)</xref> can be expressed as
<disp-formula id="eqn47">
<graphic xlink:href="611710v1_eqn47.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the approximation is good in the large <italic>N</italic> limit. Inserting <xref ref-type="disp-formula" rid="eqn45">equations (45)</xref> and <xref ref-type="disp-formula" rid="eqn47">(47)</xref> into <xref ref-type="disp-formula" rid="eqn44">equation (44)</xref>, and inserting that into <xref ref-type="disp-formula" rid="eqn43a">equation (43)</xref>, we arrive at a set of equations that uses only information local to synapse <italic>i</italic>,
<disp-formula id="eqn48a">
<graphic xlink:href="611710v1_eqn48a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn48b">
<graphic xlink:href="611710v1_eqn48b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn48c">
<graphic xlink:href="611710v1_eqn48c.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<xref ref-type="disp-formula" rid="eqn48a">Equation (48)</xref> is a model of the error that the synapse can use to guide plasticity. In our rule, the synapse learns by updating its slow weight, <inline-formula><inline-graphic xlink:href="611710v1_inline46.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, to be equal to an evolving estimate of the target, <inline-formula><inline-graphic xlink:href="611710v1_inline47.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, while choosing <italic>u</italic>, and thereby the fast weight, <italic>δw</italic><sub><italic>i</italic></sub>, to cancel out the remaining error.</p>
</sec>
</sec>
<sec id="s4d">
<title>Optimal control solution</title>
<p>Because the noise in <xref ref-type="disp-formula" rid="eqn48a">equation (48)</xref> is Gaussian and we want to minimize the squared error, (<italic>y</italic> − <italic>y</italic>*)<sup>2</sup>, the problem of finding the optimal <italic>u</italic> reduces to the well-known linear-quadratic-Gaussian (LQG) control problem (<xref ref-type="bibr" rid="c20">Crassidis and Junkins 2011</xref>). In this setting, the optimal control, denoted <inline-formula><inline-graphic xlink:href="611710v1_inline48.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, satisfies
<disp-formula id="eqn49">
<graphic xlink:href="611710v1_eqn49.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Note that this includes a control cost, <italic>λ</italic><sub><italic>u</italic></sub><italic>u</italic><sup>2</sup>, which limits the size of <inline-formula><inline-graphic xlink:href="611710v1_inline49.gif" mime-subtype="gif" mimetype="image"/></inline-formula>; without that cost, <inline-formula><inline-graphic xlink:href="611710v1_inline50.gif" mime-subtype="gif" mimetype="image"/></inline-formula> would diverge. In general, LQG control employs a Bayesian filter to estimate unobserved model variables, and then uses those estimates to construct the controller.</p>
<p>To solve <xref ref-type="disp-formula" rid="eqn49">equation (49)</xref> using standard methods, we first need to express our model for the error (<xref ref-type="disp-formula" rid="eqn48a">equation (48)</xref>) and feedback signal (<xref ref-type="disp-formula" rid="eqn10">equation (10)</xref>) in a canonical linear state space form. We start by combining the model variables into a single vector,
<disp-formula id="eqn50">
<graphic xlink:href="611710v1_eqn50.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Then, we express the control variable as a vector, <bold>u</bold><sub><italic>i</italic></sub>, and make a change of variables that will clean up an offset term,
<disp-formula id="eqn51">
<graphic xlink:href="611710v1_eqn51.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Introducing the vector
<disp-formula id="eqn52">
<graphic xlink:href="611710v1_eqn52.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
the dynamics of <bold>Φ</bold><sub><italic>i</italic></sub> and feedback, <italic>f</italic>, can be expressed together as
<disp-formula id="eqn53a">
<graphic xlink:href="611710v1_eqn53a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn53b">
<graphic xlink:href="611710v1_eqn53b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where
<disp-formula id="eqn54a">
<graphic xlink:href="611710v1_eqn54a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn54b">
<graphic xlink:href="611710v1_eqn54b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and <bold><italic>ξ</italic></bold>′ is Gaussian white noise with covariance matrix
<disp-formula id="eqn55">
<graphic xlink:href="611710v1_eqn55.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
With this set up, the control problem in <xref ref-type="disp-formula" rid="eqn49">equation (49)</xref> can be written
<disp-formula id="eqn56">
<graphic xlink:href="611710v1_eqn56.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <bold>HH</bold> is an outer product.</p>
<p>Although the control variable, <bold>v</bold><sub><italic>i</italic></sub>, is now a vector instead of a scalar, <italic>u</italic>, the optimal solution will still only have one non-zero component (the second one). This is because multiplication by <bold>B</bold> in <xref ref-type="disp-formula" rid="eqn53a">equation (53a)</xref> means that only the second component of <bold>v</bold><sub><italic>i</italic></sub> will influence the output, so the control cost term in <xref ref-type="disp-formula" rid="eqn56">equation (56)</xref> will force the other components to be zero. The scalar <inline-formula><inline-graphic xlink:href="611710v1_inline51.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is recovered from <inline-formula><inline-graphic xlink:href="611710v1_inline52.gif" mime-subtype="gif" mimetype="image"/></inline-formula> by selecting the second component and then reversing the variable change in <xref ref-type="disp-formula" rid="eqn51">equation (51)</xref>,
<disp-formula id="eqn57">
<graphic xlink:href="611710v1_eqn57.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the subscript 2 denotes the second component of the vector.</p>
<p>Nevertheless, <xref ref-type="disp-formula" rid="eqn56">equation (56)</xref> is still not identical to <xref ref-type="disp-formula" rid="eqn49">equation (49)</xref>, because the variable change in <xref ref-type="disp-formula" rid="eqn51">equation (51)</xref> has shifted the quantity <inline-formula><inline-graphic xlink:href="611710v1_inline53.gif" mime-subtype="gif" mimetype="image"/></inline-formula> from the first term in the integral to the second term. This means <italic>λ</italic><sub><italic>u</italic></sub> parameterizes a slightly different control cost. We will ignore this detail, however, as it doesn’t influence any of our modeling choices or the interpretation of results.</p>
<p>Note also that we have written the control variable with a subscript <italic>i</italic>, since at this stage the solution depends on local variables. We will later make approximations that remove this dependence, so that the control variables are the same for all synapses, as assumed in <xref ref-type="disp-formula" rid="eqn46">equation (46)</xref>.</p>
<p>Ignoring biological constraints, LQG theory gives the solution to the problem defined by <xref ref-type="disp-formula" rid="eqn50">equations (50)</xref>–<xref ref-type="disp-formula" rid="eqn56">(56)</xref> as
<disp-formula id="eqn58a">
<graphic xlink:href="611710v1_eqn58a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn58b">
<graphic xlink:href="611710v1_eqn58b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The vector <inline-formula><inline-graphic xlink:href="611710v1_inline54.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is a Bayesian (Kalman filter) estimate of the values of the unobserved variables in <xref ref-type="disp-formula" rid="eqn50">equation (50)</xref>. <bold>K</bold><sub><italic>i</italic></sub> and <bold>L</bold><sub><italic>i</italic></sub> are optimal feedback and control gains, given by
<disp-formula id="eqn59a">
<graphic xlink:href="611710v1_eqn59a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn59b">
<graphic xlink:href="611710v1_eqn59b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <bold>P</bold><sub><italic>i</italic></sub> and <bold>S</bold><sub><italic>i</italic></sub> are determined by a pair of matrix Riccati equations (<xref ref-type="bibr" rid="c20">Crassidis and Junkins 2011</xref>),
<disp-formula id="eqn60a">
<graphic xlink:href="611710v1_eqn60a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn60b">
<graphic xlink:href="611710v1_eqn60b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The equation for <bold>P</bold><sub><italic>i</italic></sub>, a covariance matrix representing uncertainty about the estimate <inline-formula><inline-graphic xlink:href="611710v1_inline55.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, is solved forwards in time from an initial condition, whereas the equation for <bold>S</bold><sub><italic>i</italic></sub>, used to compute the optimal control, is solved backwards in time from a terminal condition.</p>
<p>While these equations are exact, they are far from biologically plausible. In the next several sections we remedy that by making several approximations.</p>
</sec>
<sec id="s4e">
<title>Control gain approximation</title>
<p>Solving <xref ref-type="disp-formula" rid="eqn60b">equation (60b)</xref> backwards in time poses a problem for online implementation, because the dynamics matrix, <bold>C</bold><sub><italic>i</italic></sub> (<xref ref-type="disp-formula" rid="eqn54a">equation (54a)</xref>), depends on the synaptic input, <italic>x</italic><sub><italic>i</italic></sub>, which cannot be known in advance. We therefore simply drop the term <italic>x</italic><sub><italic>i</italic></sub> from the matrix <bold>C</bold><sub><italic>i</italic></sub>. With this approximation and sufficiently large <italic>T</italic>, <xref ref-type="disp-formula" rid="eqn60b">equation (60b)</xref> relaxes to a steady state that is independent of the terminal condition and synapse index. The steady-state matrix <bold>S</bold> is then defined implicitly as the positive-semidefinite solution to the algebraic Riccati equation
<disp-formula id="eqn61">
<graphic xlink:href="611710v1_eqn61.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <bold>C</bold> is the same as <bold>C</bold><sub><italic>i</italic></sub> but with <italic>x</italic><sub><italic>i</italic></sub> set to zero.</p>
<p>Writing <xref ref-type="disp-formula" rid="eqn61">equation (61)</xref> in component form, and using the fact that <bold>S</bold> is positive-semidefinite, straight-forward algebra shows that the first row and column of <bold>S</bold> are all zero. Consequently, because of the structure of <bold>B</bold> (<xref ref-type="disp-formula" rid="eqn54b">equation (54b)</xref>), the only nonzero elements of <bold>L</bold><sub><italic>i</italic></sub> are the second through fourth elements of the second row. That in turn implies that only the second element of <inline-formula><inline-graphic xlink:href="611710v1_inline56.gif" mime-subtype="gif" mimetype="image"/></inline-formula> (<xref ref-type="disp-formula" rid="eqn58b">equation (58b)</xref>) is nonzero. That element is given by
<disp-formula id="eqn62">
<graphic xlink:href="611710v1_eqn62.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <bold>ℒ</bold> is proportional to the second through fourth elements of the second row of <bold>S</bold>,
<disp-formula id="eqn63">
<graphic xlink:href="611710v1_eqn63.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and <inline-formula><inline-graphic xlink:href="611710v1_inline57.gif" mime-subtype="gif" mimetype="image"/></inline-formula> consists of the second through fourth elements of <inline-formula><inline-graphic xlink:href="611710v1_inline58.gif" mime-subtype="gif" mimetype="image"/></inline-formula>,
<disp-formula id="eqn64">
<graphic xlink:href="611710v1_eqn64.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
We can now use <xref ref-type="disp-formula" rid="eqn58b">equation (58b)</xref> to derive an explicit expression for the control variable, <inline-formula><inline-graphic xlink:href="611710v1_inline59.gif" mime-subtype="gif" mimetype="image"/></inline-formula>,
<disp-formula id="eqn65">
<graphic xlink:href="611710v1_eqn65.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
In the approximation in the last line, we ignored the second term, which will allow us to make the controller independent of <italic>i</italic>, and makes little difference to performance in practice.</p>
<p>We solve <xref ref-type="disp-formula" rid="eqn61">equation (61)</xref> numerically to obtain the control gain for simulations. An analytical approximation is provided in <xref ref-type="disp-formula" rid="eqn91">equation (91)</xref> below, for the simpler version of the plasticity rule presented in the main text; that approximation also works well in practice (<xref rid="figS1" ref-type="fig">Fig. S1</xref>).</p>
</sec>
<sec id="s4f">
<title>Feedback gain approximation</title>
<p>Although we now have all the ingredients for a local online plasticity rule, we also approximate the feedback gain <bold>K</bold><sub><italic>i</italic></sub> for the sake of interpretability.</p>
<p>We first unpack <xref ref-type="disp-formula" rid="eqn60a">equation (60a)</xref> by partitioning the state-estimate covariance matrix into blocks,
<disp-formula id="eqn66">
<graphic xlink:href="611710v1_eqn66.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where, to highlight the functional roles that each block will play in the plasticity rule, we introduced the variables
<disp-formula id="eqn67a">
<graphic xlink:href="611710v1_eqn67a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn67b">
<graphic xlink:href="611710v1_eqn67b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn67c">
<graphic xlink:href="611710v1_eqn67c.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the numeric subscripts on the right-hand side denote the range of row and column indices for each each block. The variable <inline-formula><inline-graphic xlink:href="611710v1_inline60.gif" mime-subtype="gif" mimetype="image"/></inline-formula> represents the uncertainty about the target weight, <bold>z</bold><sub><italic>i</italic></sub> represents the covariance between the target weight and error vector (see <xref ref-type="disp-formula" rid="eqn64">equation (64)</xref>), which will act as an eligibility trace in the plasticity rule, and <bold>Σ</bold><sub><italic>i</italic></sub> represents the uncertainty about the estimate of the error vector.</p>
<p>Defining
<disp-formula id="eqn68">
<graphic xlink:href="611710v1_eqn68.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and using the definitions in <xref ref-type="disp-formula" rid="eqn70">equations (70)</xref> and <xref ref-type="disp-formula" rid="eqn71">(71)</xref>, <xref ref-type="disp-formula" rid="eqn60a">equation (60a)</xref> can be expanded to give the dynamics of each of the blocks as
<disp-formula id="eqn69a">
<graphic xlink:href="611710v1_eqn69a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn69b">
<graphic xlink:href="611710v1_eqn69b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn69c">
<graphic xlink:href="611710v1_eqn69c.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <bold>0</bold><sub>(3<italic>×</italic>2)</sub> denotes a 3 × 2 matrix of zeros, <bold>A</bold> is the lower right (2 : 4) × (2 : 4) block of <bold>C</bold><sub><italic>i</italic></sub>,
<disp-formula id="eqn70">
<graphic xlink:href="611710v1_eqn70.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and <bold>Λ</bold> is the lower right (2 : 4) × (2 : 4) block of <bold>Λ</bold>′,
<disp-formula id="eqn71">
<graphic xlink:href="611710v1_eqn71.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Because <xref ref-type="disp-formula" rid="eqn69a">equations (69a)</xref> and <xref ref-type="disp-formula" rid="eqn69b">(69b)</xref> track uncertainty related to the target weight, their temporal dynamics are strongly dependent on the local synaptic input, <italic>x</italic><sub><italic>i</italic></sub> – this is what that couples the weight to the observed feedback. By contrast, <xref ref-type="disp-formula" rid="eqn69c">equation (69c)</xref> tracks the uncertainty of <bold><italic>δ</italic></bold><sub><italic>i</italic></sub>, which is dominated by uncertainty about the activity of unobserved synapses, so depends only weakly on <italic>x</italic><sub><italic>i</italic></sub>. Mathematically, this is reflected in the fourth term of <xref ref-type="disp-formula" rid="eqn69c">equation (69c)</xref> being dominated by the order-<italic>N</italic> synaptic noise term in <bold>Λ</bold> (see <xref ref-type="disp-formula" rid="eqn45">equations (45)</xref> and <xref ref-type="disp-formula" rid="eqn71">(71)</xref>). We can, therefore, ignore the <italic>x</italic><sub><italic>i</italic></sub>-dependent term in <xref ref-type="disp-formula" rid="eqn69c">equation (69c)</xref>. Then, <bold>Σ</bold><sub><italic>i</italic></sub> relaxes to a steady state that is independent of the synapse index. That steady state is the solution to the algebraic Riccati equation,
<disp-formula id="eqn72">
<graphic xlink:href="611710v1_eqn72.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
We use <xref ref-type="disp-formula" rid="eqn72">equation (72)</xref> in place of (69c). But to capture the most important dependence on input, <italic>x</italic><sub><italic>i</italic></sub>, we solve <xref ref-type="disp-formula" rid="eqn69a">equations (69a)</xref> and <xref ref-type="disp-formula" rid="eqn69b">(69b)</xref> individually for each synapse.</p>
<p>Finally, we can express <bold>K</bold><sub><italic>i</italic></sub>, <xref ref-type="disp-formula" rid="eqn59a">equation (59a)</xref>, in terms of the quantities in <xref ref-type="disp-formula" rid="eqn69a">equation (69)</xref>. Using the fact that <bold>K</bold><sub><italic>i</italic></sub> is proportional to the fourth column of <bold>P</bold><sub><italic>i</italic></sub> (see <xref ref-type="disp-formula" rid="eqn52">equation (52)</xref> for <bold>H</bold>), the first component is given by
<disp-formula id="eqn73">
<graphic xlink:href="611710v1_eqn73.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
which is used to update the estimate of the target weight, <inline-formula><inline-graphic xlink:href="611710v1_inline61.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. The remaining three components, used update the estimate of the error vector, <inline-formula><inline-graphic xlink:href="611710v1_inline62.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, are given by the constant vector
<disp-formula id="eqn74">
<graphic xlink:href="611710v1_eqn74.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
</sec>
<sec id="s4g">
<title>Computations that should be performed by a synapse</title>
<p>Bringing everything together, we express the plasticity rule as a system of differential equations that optimally process local signals to enable concurrent control and learning.</p>
<p>Unpacking the error estimate from <xref ref-type="disp-formula" rid="eqn58a">equation (58a)</xref>, expressing the feedback gain via <xref ref-type="disp-formula" rid="eqn72">equations (72)</xref> and <xref ref-type="disp-formula" rid="eqn74">(74)</xref>, and approximating <inline-formula><inline-graphic xlink:href="611710v1_inline63.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, which is valid because<underline><sup>1</sup></underline> is orders of magnitude smaller than other terms on the diagonal of <bold>A</bold>, we get
<disp-formula id="eqn75">
<graphic xlink:href="611710v1_eqn75.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The only remaining issue is that the control variable, <inline-formula><inline-graphic xlink:href="611710v1_inline64.gif" mime-subtype="gif" mimetype="image"/></inline-formula> (<xref ref-type="disp-formula" rid="eqn65">equation (65)</xref>), still depends on the synapse index via <inline-formula><inline-graphic xlink:href="611710v1_inline65.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. As discussed when introducing the fast weights in <xref ref-type="disp-formula" rid="eqn46">equation (46)</xref>, we would like this to be identical for all synapses. To address this, we need only make the obvious choice of setting <inline-formula><inline-graphic xlink:href="611710v1_inline66.gif" mime-subtype="gif" mimetype="image"/></inline-formula> equal to its estimated target <inline-formula><inline-graphic xlink:href="611710v1_inline67.gif" mime-subtype="gif" mimetype="image"/></inline-formula> at all times. This makes the <italic>i</italic>-dependent term in the brackets in <xref ref-type="disp-formula" rid="eqn75">equation (75)</xref> vanish, and so too the <italic>i</italic>-dependence of <inline-formula><inline-graphic xlink:href="611710v1_inline68.gif" mime-subtype="gif" mimetype="image"/></inline-formula> (assuming the system has been running long enough that initial conditions are forgotten).</p>
<p>Setting <inline-formula><inline-graphic xlink:href="611710v1_inline69.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, thereby dropping the synapse index on <inline-formula><inline-graphic xlink:href="611710v1_inline70.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="611710v1_inline71.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, and unpacking the rest of <xref ref-type="disp-formula" rid="eqn58a">equations (58a)</xref> and <xref ref-type="disp-formula" rid="eqn69a">(69)</xref> leads to
<disp-formula id="eqn76a">
<graphic xlink:href="611710v1_eqn76a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn76b">
<graphic xlink:href="611710v1_eqn76b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn76c">
<graphic xlink:href="611710v1_eqn76c.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn76d">
<graphic xlink:href="611710v1_eqn76d.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Altogether, this gives synaptic weights
<disp-formula id="eqn77">
<graphic xlink:href="611710v1_eqn77.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
</sec>
<sec id="s4h">
<title>Plasticity rule approximation for <italic>τ</italic><sub><italic>I</italic></sub>, <italic>τ</italic><sub><italic>r</italic></sub> ≪ <italic>τ</italic><sub><italic>y</italic></sub></title>
<p>Control is most effective when the downstream time constant is large. This regime also permits a simple approximation of the plasticity rule that makes parameter dependencies explicit. We use these equations in the main text for ease of intuition (<xref ref-type="disp-formula" rid="eqn13a">equations (13a)</xref> – <xref ref-type="disp-formula" rid="eqn16b">(16b)</xref>). Here we provide the details of the approximation.</p>
<p>Starting from <xref ref-type="disp-formula" rid="eqn76a">equations (76a)</xref> and <xref ref-type="disp-formula" rid="eqn76d">(76d)</xref>, we express the components of the vectors <inline-formula><inline-graphic xlink:href="611710v1_inline72.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <bold>z</bold><sub><italic>i</italic></sub> using <italic>I, r</italic> and <italic>y</italic> subscripts. Assuming <italic>τ</italic><sub><italic>I</italic></sub>, <italic>τ</italic><sub><italic>r</italic></sub> ≪ <italic>τ</italic><sub><italic>y</italic></sub>, and using <xref ref-type="disp-formula" rid="eqn70">equation (70)</xref> for <bold>A</bold>, we treat the <italic>I</italic> and <italic>r</italic> components as reacting instantaneously to their inputs,
<disp-formula id="eqn78a">
<graphic xlink:href="611710v1_eqn78a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn78b">
<graphic xlink:href="611710v1_eqn78b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn78c">
<graphic xlink:href="611710v1_eqn78c.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn78d">
<graphic xlink:href="611710v1_eqn78d.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the subscripts on 𝒦 indicate their components,
<disp-formula id="eqn79">
<graphic xlink:href="611710v1_eqn79.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
With these approximations, <xref ref-type="disp-formula" rid="eqn76a">equation (76)</xref> becomes
<disp-formula id="eqn80a">
<graphic xlink:href="611710v1_eqn80a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn80b">
<graphic xlink:href="611710v1_eqn80b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn80c">
<graphic xlink:href="611710v1_eqn80c.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn80d">
<graphic xlink:href="611710v1_eqn80d.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where
<disp-formula id="eqn81">
<graphic xlink:href="611710v1_eqn81.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
is a weighted sum of the three components of the Kalman gain (<xref ref-type="disp-formula" rid="eqn74">equation (74)</xref>). <xref ref-type="disp-formula" rid="eqn80a">Equation (80)</xref> has been copied to the main-text <xref ref-type="disp-formula" rid="eqn13a">equations (13)</xref> and <xref ref-type="disp-formula" rid="eqn16a">(16)</xref> with some minor cosmetic changes; to clean up the presentation, there we have dropped the <italic>y</italic> subscripts, explicitly denoted <inline-formula><inline-graphic xlink:href="611710v1_inline73.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, and made a sign change for the eligibility trace variable, <italic>z</italic><sub><italic>i</italic></sub> ≡ −<italic>z</italic><sub><italic>y,i</italic></sub>.</p>
<p>To compute 𝒦, we note first of all that
<disp-formula id="eqn82">
<graphic xlink:href="611710v1_eqn82.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the second equality comes from <xref ref-type="disp-formula" rid="eqn74">equation (74)</xref> and we have defined
<disp-formula id="eqn83">
<graphic xlink:href="611710v1_eqn83.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
To derive an explicit expression for <bold><italic>τ</italic></bold> · <bold>Σ</bold> · <bold>h</bold>, we operate on both sides of <xref ref-type="disp-formula" rid="eqn72">equation (72)</xref> with <bold><italic>τ</italic></bold>, giving us
<disp-formula id="eqn84">
<graphic xlink:href="611710v1_eqn84.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Then, combining the fact that <bold><italic>τ</italic></bold> · <bold>A</bold> = −<bold>h</bold> with <xref ref-type="disp-formula" rid="eqn82">equation (82)</xref>, we arrive at
<disp-formula id="eqn85">
<graphic xlink:href="611710v1_eqn85.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Where
<disp-formula id="eqn86">
<graphic xlink:href="611710v1_eqn86.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Solving <xref ref-type="disp-formula" rid="eqn85">equation (85)</xref> gives the scalar feedback gain explicitly as
<disp-formula id="eqn87">
<graphic xlink:href="611710v1_eqn87.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
For the control gain, we make use of the duality of state-estimation and control for the LQG problem (<xref ref-type="bibr" rid="c20">Crassidis and Junkins 2011</xref>), which means that knowing the parameters of the equation for <inline-formula><inline-graphic xlink:href="611710v1_inline74.gif" mime-subtype="gif" mimetype="image"/></inline-formula> (<xref ref-type="disp-formula" rid="eqn80a">equation (80a)</xref>) allows us to easily write down the Riccati equation needed to compute the corresponding controller. The analogue of <xref ref-type="disp-formula" rid="eqn61">equation (61)</xref>, now for the scalar variable <italic>s</italic>, and with equivalent scalar parameters <inline-formula><inline-graphic xlink:href="611710v1_inline75.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <italic>h</italic> = 1, in place of <bold>C, B</bold> and <bold>H</bold>, is
<disp-formula id="eqn88">
<graphic xlink:href="611710v1_eqn88.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Defining
<disp-formula id="eqn89">
<graphic xlink:href="611710v1_eqn89.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
as the analogue of <xref ref-type="disp-formula" rid="eqn59b">equation (59b)</xref> then leads to
<disp-formula id="eqn90">
<graphic xlink:href="611710v1_eqn90.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and thus a scalar control gain
<disp-formula id="eqn91">
<graphic xlink:href="611710v1_eqn91.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Here we have used the notation <inline-formula><inline-graphic xlink:href="611710v1_inline76.gif" mime-subtype="gif" mimetype="image"/></inline-formula> to signify that the control cost parameter is not identical to <italic>λ</italic><sub><italic>u</italic></sub>, used above, and is fit separately in simulations of the approximate rule.</p>
<p>Inserting the optimal control
<disp-formula id="eqn92">
<graphic xlink:href="611710v1_eqn92.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
into <xref ref-type="disp-formula" rid="eqn80a">equation (80a)</xref> yields the plasticity rule corresponding to <xref ref-type="disp-formula" rid="eqn13a">equations (13)</xref> and <xref ref-type="disp-formula" rid="eqn16a">(16)</xref> in the main text.</p>
</sec>
<sec id="s4i">
<title>Steady-state learning rate</title>
<p>Using the approximate plasticity rule given in <xref ref-type="disp-formula" rid="eqn16a">equation (16)</xref>, we can derive an expression for how the steady-state learning rate of a Bayesian synapse depends on key parameters, and especially on the firing rate.</p>
<p>The first observation is that because 𝒦 is typically large, after a spike <italic>z</italic><sub><italic>i</italic></sub> decays rapidly, and so whenever a new spike arrives it’s effectively zero. Thus, assuming for the moment that <italic>σ</italic><sub><italic>i</italic></sub> is constant, <xref ref-type="disp-formula" rid="eqn16c">equation (16c)</xref> tells us that when a spike occurs at time <italic>t</italic> = 0, <italic>z</italic><sub><italic>i</italic></sub>(<italic>t</italic>) is given by (for times <italic>t &gt;</italic> 0)
<disp-formula id="eqn93">
<graphic xlink:href="611710v1_eqn93.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Inserting this into <xref ref-type="disp-formula" rid="eqn16a">equations (16a)</xref> and <xref ref-type="disp-formula" rid="eqn16b">(16b)</xref>, and assuming for the moment that both are constant on a timescale of <italic>τ</italic><sub><italic>y</italic></sub><italic>/𝒦</italic>, we see that when a spike occurs they change by
<disp-formula id="eqn94a">
<graphic xlink:href="611710v1_eqn94a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn94b">
<graphic xlink:href="611710v1_eqn94b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the subscript ‘spike’ indicates that these are changes in response to a spike.</p>
<p>In the large 𝒦 limit, both <inline-formula><inline-graphic xlink:href="611710v1_inline77.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="611710v1_inline78.gif" mime-subtype="gif" mimetype="image"/></inline-formula> are small, justifying our assumption that <italic>w</italic><sub><italic>i</italic></sub> and <inline-formula><inline-graphic xlink:href="611710v1_inline79.gif" mime-subtype="gif" mimetype="image"/></inline-formula> are approximately constant during a spike. The noise term in <xref ref-type="disp-formula" rid="eqn94a">equation (94a)</xref> arises because the feedback error, <italic>f</italic>, has a white noise component (see <xref ref-type="disp-formula" rid="eqn10">equation (10)</xref>), so fluctuates around the relevant signal, <italic>y</italic> − <italic>y</italic>*.</p>
<p>Because <xref ref-type="disp-formula" rid="eqn94a">equation (94a)</xref> tells us the weight change per pre-synaptic spike, we can identify the term in front of <inline-formula><inline-graphic xlink:href="611710v1_inline80.gif" mime-subtype="gif" mimetype="image"/></inline-formula> as the effective learning rate,
<disp-formula id="eqn95">
<graphic xlink:href="611710v1_eqn95.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
To derive an explicit expression for <inline-formula><inline-graphic xlink:href="611710v1_inline81.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, we need the steady state value of <italic>σ</italic><sub><italic>i</italic></sub>. Using <xref ref-type="disp-formula" rid="eqn16b">equation (16b)</xref>, that’s given by
<disp-formula id="eqn96">
<graphic xlink:href="611710v1_eqn96.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where we used <xref ref-type="disp-formula" rid="eqn93">equation (93)</xref> for the time course of <italic>z</italic><sub><italic>i</italic></sub>(<italic>t</italic>) after a spike and, recall, <italic>ν</italic><sub><italic>i</italic></sub> is the input firing rate to synapse <italic>i</italic>. Note the slight abuse of notation: above, and in what follows in this section, <inline-formula><inline-graphic xlink:href="611710v1_inline82.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is the steady state variance; to reduce clutter we don’t make this explicit. Solving <xref ref-type="disp-formula" rid="eqn96">equation (96)</xref> gives us
<disp-formula id="eqn97">
<graphic xlink:href="611710v1_eqn97.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
For typical parameter values (see <xref rid="tbl1" ref-type="table">Table 1</xref>), and using the definitions in <xref ref-type="disp-formula" rid="eqn86">equations (86)</xref> and <xref ref-type="disp-formula" rid="eqn87">(87)</xref>, we find that the second term inside the square root is large (∼ 10<sup>3</sup> − 10<sup>4</sup>) as long as input rates, <italic>ν</italic><sub><italic>i</italic></sub>, are greater than ∼ 0.1 spikes/s. <xref ref-type="disp-formula" rid="eqn97">Equation (97)</xref> thus simplifies to</p>
<p>
<disp-formula id="eqn98">
<graphic xlink:href="611710v1_eqn98.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Inserting this into <xref ref-type="disp-formula" rid="eqn95">equation (95)</xref>, we arrive at
<disp-formula id="eqn99">
<graphic xlink:href="611710v1_eqn99.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Notably, this scaling with input rate is consistent with the results of <xref ref-type="bibr" rid="c2">Aitchison et al. (2021)</xref>, which they demonstrated was consistent with experiments.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><title>Model and simulation parameters.</title></caption>
<graphic xlink:href="611710v1_tbl1.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
</sec>
<sec id="s4j">
<title>Spiking feedback</title>
<p>We now consider the case where feedback is communicated via spikes. The spiking feedback signal, <italic>f</italic><sub><italic>S</italic></sub>, is modeled as an inhomogeneous Poisson processes with rate <italic>γ</italic>, as described by <xref ref-type="disp-formula" rid="eqn17">equation (17)</xref>. The derivation is essentially the same as for the continuous feedback case above; the difference is that it’s not a textbook problem, so we have to do it ourselves. The approach, though, is relatively standard: we compute the time evolution of the mean and covariance of <bold>Φ</bold><sub><italic>i</italic></sub> conditioned on feedback spikes. These correspond to <inline-formula><inline-graphic xlink:href="611710v1_inline83.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <bold>P</bold><sub><italic>i</italic></sub> above, but their time evolution is, of course, different because of the spiking feedback.</p>
</sec>
<sec id="s4k">
<title>Model discretization and notation</title>
<p>To model feedback spikes, we discretize time into bins of size Δ<italic>t</italic>, and assume that there are either zero or one spike in each bin; this assumption is valid because we will eventually take the limit Δ<italic>t</italic> → 0. Our first step is to turn <xref ref-type="disp-formula" rid="eqn53a">equation (53a)</xref> into discrete time updates rather than differential equations.</p>
<p>Discrete time variables are distinguished from their continuous versions with a <italic>t</italic> subscript, and several quantities are rescaled by the time step to reduce clutter. We define
<disp-formula id="eqn100a">
<graphic xlink:href="611710v1_eqn100a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn100b">
<graphic xlink:href="611710v1_eqn100b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn100c">
<graphic xlink:href="611710v1_eqn100c.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn100d">
<graphic xlink:href="611710v1_eqn100d.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The synaptic inputs <italic>x</italic><sub><italic>i,t</italic></sub> are implemented as discrete-time delta functions, taking the value 1<italic>/</italic>Δ<italic>t</italic> when there is a spike and zero otherwise. The discrete-time version of <xref ref-type="disp-formula" rid="eqn53a">equation (53a)</xref> is, then, given by
<disp-formula id="eqn101">
<graphic xlink:href="611710v1_eqn101.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
For Poisson feedback with the rate determined by <xref ref-type="disp-formula" rid="eqn17">equation (17)</xref>, the analogue of <xref ref-type="disp-formula" rid="eqn53b">equation (53b)</xref> is an expression for the probability of observing a feedback spike given <bold>Φ</bold><sub><italic>i</italic></sub>. Assuming small Δ<italic>t</italic>, and treating spikes as Bernoulli random variables <italic>f</italic><sub><italic>S,t</italic></sub> ∈ {0, 1}, this is given by
<disp-formula id="eqn102">
<graphic xlink:href="611710v1_eqn102.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
with <bold>H</bold> = (0, 0, 0, 1), as above (see <xref ref-type="disp-formula" rid="eqn52">equation (52)</xref>).</p>
<p>Using <xref ref-type="disp-formula" rid="eqn101">equations (101)</xref> and <xref ref-type="disp-formula" rid="eqn102">(102)</xref> as the model for feedback observations, we aim to infer a distribution over the unobserved states, <bold>Φ</bold><sub><italic>i,t</italic></sub>, conditioned on the history of local data seen by the synapse. The data is denoted
<disp-formula id="eqn103">
<graphic xlink:href="611710v1_eqn103.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The distribution is modeled as a Gaussian with conditional mean and covariance
<disp-formula id="eqn104a">
<graphic xlink:href="611710v1_eqn104a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn104b">
<graphic xlink:href="611710v1_eqn104b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
</sec>
<sec id="s4l">
<title>Recursive Bayesian filter</title>
<p>We use standard Bayesian recursion to derive explicit expressions for the mean and covariance of <bold>Φ</bold><sub><italic>i</italic></sub>. Our approach is similar to that of <xref ref-type="bibr" rid="c27">Eden et al. (2004)</xref> and <xref ref-type="bibr" rid="c69">Pfister et al. (2010)</xref>.</p>
<p>At each time step, we first update the distribution over <bold>Φ</bold><sub><italic>i,t</italic></sub> using observation <italic>f</italic><sub><italic>S,t</italic></sub>, via Bayes theorem, and then predict <bold>Φ</bold><sub><italic>i,t</italic>+Δ<italic>t</italic></sub> from the model dynamics,
<disp-formula id="eqn105a">
<graphic xlink:href="611710v1_eqn105a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn105b">
<graphic xlink:href="611710v1_eqn105b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The first equation holds for our model because <italic>f</italic><sub><italic>S,t</italic></sub> only depends on <bold>Φ</bold><sub><italic>i,t</italic></sub>, and <bold>Φ</bold><sub><italic>i,t</italic></sub> only depends on the input and weight from previous time steps. We use assumed density filtering for the update step, approximating the left-hand side of <xref ref-type="disp-formula" rid="eqn105a">equation (105a)</xref> as Gaussian by matching the mean and covariance of the right-hand side.</p>
<p>When <italic>f</italic><sub><italic>S,t</italic></sub> = 1, the approximation is exact, giving a Gaussian
<disp-formula id="eqn106">
<graphic xlink:href="611710v1_eqn106.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The normalizer is given by
<disp-formula id="eqn107">
<graphic xlink:href="611710v1_eqn107.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
After some straightforward algebra, the updated mean and covariance are found to be
<disp-formula id="eqn108a">
<graphic xlink:href="611710v1_eqn108a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn108b">
<graphic xlink:href="611710v1_eqn108b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
When <italic>f</italic><sub><italic>S,t</italic></sub> = 0,
<disp-formula id="eqn109">
<graphic xlink:href="611710v1_eqn109.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
which leads to, again after some straightforward algebra,
<disp-formula id="eqn110a">
<graphic xlink:href="611710v1_eqn110a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn110b">
<graphic xlink:href="611710v1_eqn110b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Putting both cases together, we arrive at
<disp-formula id="eqn111a">
<graphic xlink:href="611710v1_eqn111a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn111b">
<graphic xlink:href="611710v1_eqn111b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
which characterizes the posterior distribution on the left-hand side of the update step in <xref ref-type="disp-formula" rid="eqn105a">equation (105a)</xref>.</p>
<p>Next, having completed the update step, we perform the prediction step in <xref ref-type="disp-formula" rid="eqn105b">equation (105b)</xref> by evaluating the integral. The second factor in the integral is Gaussian by assumption, following from the previous update. The first factor, describing the state transition probability, is also Gaussian, following from the dynamics of <xref ref-type="disp-formula" rid="eqn53a">equation (53a)</xref>. This means the left-hand side of <xref ref-type="disp-formula" rid="eqn105b">equation (105b)</xref> is Gaussian with
<disp-formula id="eqn112a">
<graphic xlink:href="611710v1_eqn112a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn112b">
<graphic xlink:href="611710v1_eqn112b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Substituting <xref ref-type="disp-formula" rid="eqn111a">equations (111a)</xref> and <xref ref-type="disp-formula" rid="eqn111b">(111b)</xref> into these expressions, and using the definitions in <xref ref-type="disp-formula" rid="eqn104a">equations (104a)</xref> and <xref ref-type="disp-formula" rid="eqn104b">(104b)</xref>, gives a discrete-time estimator
<disp-formula id="eqn113a">
<graphic xlink:href="611710v1_eqn113a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn113b">
<graphic xlink:href="611710v1_eqn113b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Expanding to first order in Δ<italic>t</italic>, using <xref ref-type="disp-formula" rid="eqn100a">equations (100a)</xref>–<xref ref-type="disp-formula" rid="eqn100d">(100d)</xref>, and taking Δ<italic>t</italic> → 0 gives the continuous-time version:
<disp-formula id="eqn114a">
<graphic xlink:href="611710v1_eqn114a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn114b">
<graphic xlink:href="611710v1_eqn114b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Here, the discrete-time feedback <italic>f</italic><sub><italic>S,t</italic></sub> has converged to a sum of delta functions <italic>f</italic><sub><italic>S</italic></sub>, and
<disp-formula id="eqn115">
<graphic xlink:href="611710v1_eqn115.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
is the estimated feedback rate.</p>
<p><xref ref-type="disp-formula" rid="eqn114a">equations (114a)</xref> and <xref ref-type="disp-formula" rid="eqn114b">(114b)</xref> correspond to <xref ref-type="disp-formula" rid="eqn58a">equations (58a)</xref> and <xref ref-type="disp-formula" rid="eqn60a">(60a)</xref> in the continuous feedback case, with <italic>ρ</italic><bold>P</bold><sub><italic>i</italic></sub> · <bold>H</bold> playing the role of feedback gain <bold>K</bold><sub><italic>i</italic></sub>, and <inline-formula><inline-graphic xlink:href="611710v1_inline84.gif" mime-subtype="gif" mimetype="image"/></inline-formula> playing the role of the prediction error. Whereas the optimal gain scales with the precision of feedback observations in the continuous case, here it scales with the steepness of the feedback rate function.</p>
<p>As above, the feedback gain can be approximated by partitioning the covariance matrix <bold>P</bold><sub><italic>i</italic></sub> (see <xref ref-type="disp-formula" rid="eqn66">equation (66)</xref>), and ignoring the minor contribution of <italic>x</italic><sub><italic>i</italic></sub> to the lower-right block,
<disp-formula id="eqn116a">
<graphic xlink:href="611710v1_eqn116a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn116b">
<graphic xlink:href="611710v1_eqn116b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn116c">
<graphic xlink:href="611710v1_eqn116c.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
A key difference between these equations and <xref ref-type="disp-formula" rid="eqn69a">equation (69)</xref> is that in the latter <bold>Σ</bold><sub><italic>i</italic></sub> relaxes to a steady state, whereas here it depends dynamically on the estimate of the feedback rate <inline-formula><inline-graphic xlink:href="611710v1_inline85.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. Intuitively, the higher the feedback rate, the more uncertainty about the error is reduced.</p>
<p>The rest of the derivation proceeds identically to the continuous case. Unpacking <xref ref-type="disp-formula" rid="eqn114a">equation (114a)</xref> into the original notation, and setting <inline-formula><inline-graphic xlink:href="611710v1_inline86.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, yields an error estimate, <inline-formula><inline-graphic xlink:href="611710v1_inline87.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, covariance, <bold>Σ</bold>, and feedback rate estimate, <inline-formula><inline-graphic xlink:href="611710v1_inline88.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, that are all independent of the synapse index. The control gain is computed identically to that above (<xref ref-type="disp-formula" rid="eqn61">equations (61)</xref> and <xref ref-type="disp-formula" rid="eqn65">(65)</xref>), yielding a control variable <inline-formula><inline-graphic xlink:href="611710v1_inline89.gif" mime-subtype="gif" mimetype="image"/></inline-formula>.</p>
<p>Putting everything together, the plasticity rule for spiking feedback is
<disp-formula id="eqn117a">
<graphic xlink:href="611710v1_eqn117a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn117b">
<graphic xlink:href="611710v1_eqn117b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn117c">
<graphic xlink:href="611710v1_eqn117c.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn117d">
<graphic xlink:href="611710v1_eqn117d.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn117e">
<graphic xlink:href="611710v1_eqn117e.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn117f">
<graphic xlink:href="611710v1_eqn117f.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
with weights set via <xref ref-type="disp-formula" rid="eqn77">equation (77)</xref> as before.</p>
</sec>
<sec id="s4m">
<title>Feedback delays</title>
<p>In the brain, error feedback cannot be provided instantaneously to a neuron due to communication and sensory processing delays, typically on the order of ∼ 10 − 100 ms. We model this constraint by introducing a lag of time <italic>τ</italic> into the feedback signal, modifying <xref ref-type="disp-formula" rid="eqn10">equation (10)</xref> to become
<disp-formula id="eqn118">
<graphic xlink:href="611710v1_eqn118.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Similarly, for the spiking feedback model, <xref ref-type="disp-formula" rid="eqn17">equation (17)</xref> becomes
<disp-formula id="eqn119">
<graphic xlink:href="611710v1_eqn119.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
For the slow weights, the learning rules can be adapted by simply feeding lagged copies of the input and weight parameters into the governing equations, such that the Bayesian filter estimate reflects the unobserved states as they were at time <italic>t</italic> − <italic>τ</italic>. Working through the details, the only change required to the learning rules is to replace <italic>x</italic><sub><italic>i</italic></sub>(<italic>t</italic>) with <italic>x</italic><sub><italic>i</italic></sub>(<italic>t</italic> − <italic>τ</italic>) in <xref ref-type="disp-formula" rid="eqn76d">equation (76d)</xref>, and similarly in the spiking feedback case. Such a lagged copy of the input could be maintained at the synapse via simple chemical signaling cascades, as shown by <xref ref-type="bibr" rid="c43">Jayabal et al. (2022)</xref>. As long as the assumed target-weight drift is slow relative to the feedback delay, <italic>τ</italic><sub><italic>w</italic></sub> ≫ <italic>τ</italic>, this simple modification of the learning rule maintains consistent performance in the presence of delays.</p>
<p>For the fast weights, we employ the Smith predictor technique to build a controller that accounts for the delay (<xref ref-type="bibr" rid="c78">Smith 1959</xref>). Conceptually, we need to compute a control signal at time <italic>t</italic> that will cancel the current error, but we only have an estimate from feedback observations of the error as it was at time <italic>t</italic> − <italic>τ</italic>. We therefore use the known model dynamics and recent history of applied control signals to predict the current error by propagating the estimate <bold><italic>δ</italic></bold> forward in time. We use this to construct the controller
<disp-formula id="eqn120">
<graphic xlink:href="611710v1_eqn120.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and thus the fast-weight rule
<disp-formula id="eqn121">
<graphic xlink:href="611710v1_eqn121.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the control gain ℒ is the same as that above.</p>
<p>Writing <inline-formula><inline-graphic xlink:href="611710v1_inline90.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, the predicted error can be computed via
<disp-formula id="eqn122">
<graphic xlink:href="611710v1_eqn122.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The first term propagates <inline-formula><inline-graphic xlink:href="611710v1_inline91.gif" mime-subtype="gif" mimetype="image"/></inline-formula> forward in time via a matrix exponential that encodes the deterministic dynamics of the error vector. The second term is a convolution that accounts for the influence of past controls – propagating the corrections applied by the controller at each time <italic>s</italic> (whose effects have not yet been observed) to the current time <italic>t</italic>.</p>
<p>The convolution can be simplified by considering an online implementation. Denoting the integral by <bold>U</bold>(<italic>t</italic>), differentiation gives
<disp-formula id="eqn123">
<graphic xlink:href="611710v1_eqn123.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
which only requires knowing the most recently applied control and a single lagged variable from the past.</p>
</sec>
<sec id="s4n">
<title>Multiple neurons</title>
<p>In <xref rid="fig3" ref-type="fig">Fig. 3C</xref> and <xref rid="fig4" ref-type="fig">Fig. 4</xref>, we simulated a small feedforward network of <italic>M</italic> neurons. In this model, each of the neurons has identical dynamics, as described by <xref ref-type="disp-formula" rid="eqn7a">equations (7a)</xref> and <xref ref-type="disp-formula" rid="eqn7b">(7b)</xref>, but receives independent synaptic input and noise. Noise variances were scaled by a factor 1<italic>/M</italic> relative to the single neuron simulations, for ease of comparison (see <xref rid="tbl1" ref-type="table">Table 1</xref> for parameters). A common downstream output is driven by the sum over firing rates, <italic>r</italic><sub><italic>m</italic></sub>, described by <xref ref-type="disp-formula" rid="eqn19">equation (19)</xref>. A spiking feedback signal, <italic>f</italic><sub>S,<italic>m</italic></sub>, is generated independently for each neuron using the Poisson rate function in <xref ref-type="disp-formula" rid="eqn17">equation (17)</xref>.</p>
<p>In the plasticity rule, the current, rate and synaptic noise terms in <xref ref-type="disp-formula" rid="eqn71">equation (71)</xref> are scaled by <italic>M</italic> to reflect the contribution of all neurons to the error. The fast weight rule (<xref ref-type="disp-formula" rid="eqn46">equation (46)</xref>) also needs to be modified to account for the fact that the feedback signals, and therefore error estimates, differ across neurons. Ignoring locality constraints, the optimal strategy would be to combine the error estimates computed by each of the <italic>M</italic> neurons, <inline-formula><inline-graphic xlink:href="611710v1_inline92.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, and their uncertainties, <bold>Σ</bold><sub><italic>m</italic></sub>, as a precision-weighted average,
<disp-formula id="eqn124">
<graphic xlink:href="611710v1_eqn124.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and use that to construct a single global control variable, <inline-formula><inline-graphic xlink:href="611710v1_inline93.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. We use a local approximation of this strategy, by replacing the precision weighting in <xref ref-type="disp-formula" rid="eqn124">equation (124)</xref> with a scaled identity matrix,
<disp-formula id="eqn125">
<graphic xlink:href="611710v1_eqn125.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
In <xref ref-type="disp-formula" rid="eqn125">equation (125)</xref>, <inline-formula><inline-graphic xlink:href="611710v1_inline94.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is the control variable computed locally by neuron <italic>m</italic>, and <italic>β</italic> ∈ [0, 1] is a free parameter (fitted in pilot simulations to minimize task output error). When feedback rates are very low, a small number of neurons would dominate the sum in <xref ref-type="disp-formula" rid="eqn124">equation (124)</xref> at any given time (error estimates are most precise immediately following a feedback spike, but relax to small, uncertain baseline values soon afterwards), so <italic>β</italic> should be small. In the limit of very high feedback rates, all terms would be weighted equally, so <italic>β</italic> ≈ 1. Intuitively, <italic>β</italic> interpolates between sparse and dense feedback regimes. Using this approximation leads to scaled fast weights
<disp-formula id="eqn126">
<graphic xlink:href="611710v1_eqn126.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
</sec>
<sec id="s4o">
<title>Simulation details</title>
<sec id="s4o1">
<title>Online linear regression</title>
<p>For the simulations in <xref rid="fig1" ref-type="fig">Fig. 1</xref>, the model neuron was driven with sinusoidal inputs and required to learn weights that would produce a time-varying, periodic target output. We used <italic>N</italic> = 20 synapses and a period <italic>T</italic><sub>period</sub> = 1 s.</p>
<p>Input rates were defined as
<disp-formula id="eqn127">
<graphic xlink:href="611710v1_eqn127.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The target output was generated as
<disp-formula id="eqn128">
<graphic xlink:href="611710v1_eqn128.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
With <inline-formula><inline-graphic xlink:href="611710v1_inline95.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. Learning rules were as described by <xref ref-type="disp-formula" rid="eqn2">equations (2)</xref>, <xref ref-type="disp-formula" rid="eqn4">(4)</xref> and <xref ref-type="disp-formula" rid="eqn6">(6)</xref>, with learning rates <inline-formula><inline-graphic xlink:href="611710v1_inline96.gif" mime-subtype="gif" mimetype="image"/></inline-formula>.</p>
</sec>
</sec>
<sec id="s4p">
<title>Teacher-student task</title>
<p>In <xref rid="fig2" ref-type="fig">Figs. 2</xref> and <xref rid="fig3" ref-type="fig">3</xref>, simulations were initialized by independently drawing target weights <inline-formula><inline-graphic xlink:href="611710v1_inline97.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, input rates <italic>ν</italic><sub><italic>i</italic></sub> ∼ uniform(0, <italic>ν</italic><sub>max</sub>), slow weights <inline-formula><inline-graphic xlink:href="611710v1_inline98.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, and setting fast weights <italic>δw</italic><sub><italic>i</italic></sub> = 0. The weight uncertainties <inline-formula><inline-graphic xlink:href="611710v1_inline98a.gif" mime-subtype="gif" mimetype="image"/></inline-formula> were initialized with value <inline-formula><inline-graphic xlink:href="611710v1_inline98b.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. Input spikes were generated at each time step by drawing binary variables <italic>x</italic><sub><italic>i</italic></sub> ∼ Bernoulli(<italic>ν</italic><sub><italic>i</italic></sub>Δ<italic>t</italic>). Feedback spikes were generated similarly in the spiking-feedback case, using the rate function in <xref ref-type="disp-formula" rid="eqn17">equation (17)</xref>, and also enforcing a hard maximum of 200 spikes<italic>/</italic>s for stability. Target weights drifted slowly about the mean <italic>µ</italic><sub><italic>w</italic></sub>, as described by the Euler discretization of <xref ref-type="disp-formula" rid="eqn41">equation (41)</xref>. Actual weights were updated according to the Euler discretization of <xref ref-type="disp-formula" rid="eqn76a">equation (76)</xref> in the continuous case, <xref ref-type="disp-formula" rid="eqn117a">equation (117)</xref> in the spiking-feedback case, and analogously for the classical rules. Performance was quantified by computing the root-mean-squared error between output and target output over all time points in the simulation, thus measuring both learning speed and steady-state error.</p>
</sec>
<sec id="s4q">
<title>Cerebellar learning task</title>
<p>The cerebellar learning task in <xref rid="fig4" ref-type="fig">Fig. 4</xref> requires mapping time-varying patterns of synaptic input to associated target outputs. Unlike the teacher-student task, the target outputs are generated as random wavelets, rather than through explicit target weights.</p>
<p>Input patterns of duration <italic>T</italic><sub>pattern</sub> = 1 s were constructed in a similar manner to <xref ref-type="bibr" rid="c10">Bicknell and Häusser (2021)</xref>. A synapse was selected to be active on a given pattern with probability <italic>p</italic><sub>active</sub> = 0.5. If active, its time-dependent presynaptic firing rate in that pattern was defined by drawing a peak time <italic>t</italic><sub>peak,<italic>i</italic></sub> ∼ Uniform(0, <italic>T</italic><sub>pattern</sub>), maximum amplitude <italic>ν</italic><sub>max,<italic>i</italic></sub> ∼ Uniform(90, 110) (spikes/s) and centering a Gaussian bump of activity within the pattern interval,
<disp-formula id="eqn129">
<graphic xlink:href="611710v1_eqn129.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
with width parameter <italic>σ</italic><sub><italic>ν</italic></sub> = 0.1 s. Input spikes were generated stochastically each pattern presentation using this rate function.</p>
<p>For the target outputs, we generated random trajectories that drift slowly over time and could be stitched together in random order to yield a single continuous target (analogous to composing different sequences of motor actions). This was implemented using truncated Fourier series with random coefficients that drift via Ornstein-Uhlenbeck processes. Different trajectories are forced to agree at the endpoints by using a common constant offset and multiplying the time-dependent parts by a bump function. Specifically, the drifting target output for pattern <italic>p</italic> was defined via
<disp-formula id="eqn130a">
<graphic xlink:href="611710v1_eqn130a.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn130b">
<graphic xlink:href="611710v1_eqn130b.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn130c">
<graphic xlink:href="611710v1_eqn130c.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn130d">
<graphic xlink:href="611710v1_eqn130d.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
with initial coefficients <italic>a</italic><sub><italic>p,n</italic></sub>, <inline-formula><inline-graphic xlink:href="611710v1_inline99.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. We used parameters <italic>N</italic><sub>modes</sub> = 3, which sets the maximum temporal frequency, and <italic>τ</italic><sub><italic>w</italic></sub> = 10<sup>4</sup> s, equal to the weight drift parameter in the spiking-feedback teacher-student task.</p>
</sec>
<sec id="s4r">
<title>Plasticity protocol</title>
<p>For the simulated plasticity experiments in <xref rid="fig5" ref-type="fig">Fig. 5</xref>, we used models that had been trained on the cerebellar learning task. We applied the protocol to 100 synapses using the classical and Bayesian learning rules, initializing with the trained weights and uncertainties. The classical learning rate, <italic>η</italic>, and control cost, <italic>λ</italic><sub><italic>u</italic></sub>, were set at the values that minimized output error during the task. For most simulations, the protocol consisted of repeated pairings of parallel fiber input bursts (5 spikes at 10 ms intervals) and single climbing fiber spikes at a given delay. The numbers of spikes were varied in a subset of simulations (<xref rid="figS3" ref-type="fig">Fig. S3c,d</xref>). The pairing was repeated 50 times at 500 ms intervals. Plasticity effects were computed at the end of the protocol as the change in slow-weights (or classical weights) from their initial trained values.</p>
</sec>
</sec>
</body>
<back>
<sec id="s6">
<title>Supplementary Figures</title>
<fig id="figS1" position="float" fig-type="figure">
<label>Figure S1:</label>
<caption><title>Approximation of the Bayesian learning rule.</title>
<p>Comparison of the full Bayesian rule, given by <xref ref-type="disp-formula" rid="eqn76a">equation (76)</xref>, and the approximation presented for ease of interpretation in <xref ref-type="disp-formula" rid="eqn13a">equations (13)</xref> and <xref ref-type="disp-formula" rid="eqn16a">(16)</xref>, in terms of output error (<bold>a</bold>) and weight error (<bold>b)</bold>. The approximation is valid whenever the output time constant dominates the model dynamics, <italic>τ</italic><sub><italic>r</italic></sub>, <italic>τ</italic><sub><italic>I</italic></sub> ≪ <italic>τ</italic><sub><italic>y</italic></sub>. Here we use parameters <italic>τ</italic><sub><italic>I</italic></sub> = 1 ms, <italic>τ</italic><sub><italic>r</italic></sub> = 10 ms, and <italic>τ</italic><sub><italic>y</italic></sub> = 100 ms.</p></caption>
<graphic xlink:href="611710v1_figS1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS2" position="float" fig-type="figure">
<label>Figure S2:</label>
<caption><title>Simulations with spiking feedback.</title>
<p>Results from the spiking feedback model are consistent with the continuous feedback model (<xref rid="fig2" ref-type="fig">Fig. 2</xref>), although learning takes longer and performance depends strongly on the spontaneous feedback rate <italic>γ</italic><sub>0</sub>. <bold>a)</bold> Performance as a function of feedback rate (replotted from <xref rid="fig3" ref-type="fig">Fig. 3</xref> for context). Shaded areas are s.d. from 10 random seeds. <bold>b)</bold> Detailed comparison between learning rules with <italic>γ</italic><sub>0</sub> = 64 spikes/s. <bold>c)</bold> Control remains effective in the presence of feedback delays. Shaded areas are s.d. from 10 random seeds. <bold>d)</bold> Weights converge to their target values more quickly with increasing rates of feedback.</p></caption>
<graphic xlink:href="611710v1_figS2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS3" position="float" fig-type="figure">
<label>Figure S3:</label>
<caption><title>Parameter dependence of simulated plasticity experiments.</title>
<p>The LTP/LTD curve produced using the protocol in <xref rid="fig5" ref-type="fig">Fig. 5c</xref> depends systematically on the parameters of the model and protocol. <bold>a)</bold> Tuning to the PF-CF interval becomes broader as the output time constant <italic>τ</italic><sub><italic>y</italic></sub> increases. <bold>b)</bold> Peaks in the LTP and LTD lobes of the curve are shifted in proportion to the feedback delay. <bold>c)</bold> The magnitude of plasticity increases with the number of spikes in the parallel fiber burst. <bold>d)</bold> LTD is amplified and shifted to earlier PF-CF intervals with increasing numbers of climbing fiber spikes.</p></caption>
<graphic xlink:href="611710v1_figS3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<ack>
<title>Acknowledgments</title>
<p>This work was supported by the Gatsby Charitable Foundation and the Wellcome Trust (110114/Z/15/Z). The authors acknowledge the use of the UCL Myriad High Performance Computing Facility (Myriad@UCL), and associated support services, in the completion of this work.</p>
</ack>
<sec id="d1e4589" sec-type="additional-information">
<title>Additional information</title>
<sec id="s5">
<title>Code availability</title>
<p>Simulation code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/babicknell/SynControl">https://github.com/babicknell/SynControl</ext-link></p>
</sec>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Abbott</surname>, <given-names>L.</given-names></string-name> and <string-name><surname>Regehr</surname>, <given-names>W.G.</given-names></string-name></person-group> (<year>2004</year>). <article-title>Synaptic computation</article-title>. <source>Nature</source> <volume>431</volume>, <fpage>796</fpage>–<lpage>803</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Aitchison</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Jegminat</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Menendez</surname>, <given-names>J.A.</given-names></string-name>, <string-name><surname>Pfister</surname>, <given-names>J.-P.</given-names></string-name>, <string-name><surname>Pouget</surname>, <given-names>A.</given-names></string-name>, and <string-name><surname>Latham</surname>, <given-names>P.E.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Synaptic plasticity as Bayesian inference</article-title>. <source>Nat. Neurosci</source>. <volume>24</volume>, <fpage>565</fpage>–<lpage>571</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Alemi</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Machens</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Deneve</surname>, <given-names>S.</given-names></string-name>, and <string-name><surname>Slotine</surname>, <given-names>J.-J.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Learning nonlinear dynamics in efficient, balanced spiking networks using local plasticity rules</article-title>. <source>Proc. AAAI Conf. Artif. Intell</source>. <volume>32</volume>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Apps</surname>, <given-names>R.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2018</year>). <article-title>Cerebellar modules and their role as operational cerebellar processing units</article-title>. <source>The Cerebellum</source> <volume>17</volume>, <fpage>654</fpage>–<lpage>682</lpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Armstrong</surname>, <given-names>D.</given-names></string-name> and <string-name><surname>Rawson</surname>, <given-names>J.</given-names></string-name></person-group> (<year>1979</year>). <article-title>Activity patterns of cerebellar cortical neurones and climbing fibre afferents in the awake cat</article-title>. <source>J. Physiol</source>. <volume>289</volume>, <fpage>425</fpage>–<lpage>448</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barmack</surname>, <given-names>N.H.</given-names></string-name> and <string-name><surname>Yakhnitsa</surname>, <given-names>V.</given-names></string-name></person-group> (<year>2003</year>). <article-title>Cerebellar climbing fibers modulate simple spikes in Purkinje cells</article-title>. <source>J. Neurosci</source>. <volume>23</volume>, <fpage>7904</fpage>–<lpage>7916</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bell</surname>, <given-names>C.C.</given-names></string-name> and <string-name><surname>Grimm</surname>, <given-names>R.</given-names></string-name></person-group> (<year>1969</year>). <article-title>Discharge properties of Purkinje cells recorded on single and double microelectrodes</article-title>. <source>J. Neurophysiol</source>. <volume>32</volume>, <fpage>1044</fpage>–<lpage>1055</lpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Benna</surname>, <given-names>M.K.</given-names></string-name> and <string-name><surname>Fusi</surname>, <given-names>S.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Computational principles of synaptic memory consolidation</article-title>. <source>Nat. Neurosci</source>. <volume>19</volume>, <fpage>1697</fpage>–<lpage>1706</lpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bhalla</surname>, <given-names>U.S.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Molecular computation in neurons: a modeling perspective</article-title>. <source>Curr. Opin. Neurobiol</source>. <volume>25</volume>, <fpage>31</fpage>–<lpage>37</lpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bicknell</surname>, <given-names>B.A.</given-names></string-name> and <string-name><surname>Häusser</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2021</year>). <article-title>A synaptic learning rule for exploiting nonlinear dendritic computation</article-title>. <source>Neuron</source> <volume>109</volume>, <fpage>4001</fpage>–<lpage>4017</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bloedel</surname>, <given-names>J.R.</given-names></string-name> and <string-name><surname>Roberts</surname>, <given-names>W.J.</given-names></string-name></person-group> (<year>1971</year>). <article-title>Action of climbing fibers in cerebellar cortex of the cat</article-title>. <source>J. Neurophysiol</source>. <volume>34</volume>, <fpage>17</fpage>–<lpage>31</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Blundell</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Cornebise</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Kavukcuoglu</surname>, <given-names>K.</given-names></string-name>, and <string-name><surname>Wierstra</surname>, <given-names>D.</given-names></string-name></person-group> (<year>2015</year>). <article-title>Weight uncertainty in neural network</article-title>. <conf-name>Proc. Int. Conf. Mach. Learn</conf-name>. <fpage>1613</fpage>–<lpage>1622</lpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bourdoukan</surname>, <given-names>R.</given-names></string-name> and <string-name><surname>Denève</surname>, <given-names>S.</given-names></string-name></person-group> (<year>2015</year>). <article-title>Enforcing balance allows local supervised learning in spiking recurrent networks</article-title>. <source>Adv. Neural Inf. Process. Syst</source>. <volume>28</volume>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bouvier</surname>, <given-names>G.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2018</year>). <article-title>Cerebellar learning using perturbations</article-title>. <source>eLife</source> <volume>7</volume>, <elocation-id>e31599</elocation-id>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Bredenberg</surname>, <given-names>C.</given-names></string-name> and <string-name><surname>Savin</surname>, <given-names>C.</given-names></string-name></person-group> (<year>2023</year>). <article-title>Desiderata for normative models of synaptic plasticity</article-title>. <source>arXiv</source>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brunel</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Hakim</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Isope</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Nadal</surname>, <given-names>J.-P.</given-names></string-name>, and <string-name><surname>Barbour</surname>, <given-names>B.</given-names></string-name></person-group> (<year>2004</year>). <article-title>Optimal information storage and the distribution of synaptic weights: perceptron versus Purkinje cell</article-title>. <source>Neuron</source> <volume>43</volume>, <fpage>745</fpage>–<lpage>757</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Buntine</surname>, <given-names>W.L.</given-names></string-name> and <string-name><surname>Weigend</surname>, <given-names>A.S.</given-names></string-name></person-group> (<year>1991</year>). <article-title>Bayesian backpropagation</article-title>. <source>Complex Syst</source>. <volume>5</volume>, <fpage>603</fpage>–<lpage>643</lpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cheun</surname>, <given-names>J.</given-names></string-name> and <string-name><surname>Yeh</surname>, <given-names>H.</given-names></string-name></person-group> (<year>1992</year>). <article-title>Modulation of GABAA receptor-activated current by norepinephrine in cerebellar Purkinje cells</article-title>. <source>Neuroscience</source> <volume>51</volume>, <fpage>951</fpage>–<lpage>960</lpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Coesmans</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Weber</surname>, <given-names>J.T.</given-names></string-name>, <string-name><surname>De Zeeuw</surname>, <given-names>C.I.</given-names></string-name>, and <string-name><surname>Hansel</surname>, <given-names>C.</given-names></string-name></person-group> (<year>2004</year>). <article-title>Bidirectional parallel fiber plas-ticity in the cerebellum under climbing fiber control</article-title>. <source>Neuron</source> <volume>44</volume>, <fpage>691</fpage>–<lpage>700</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Crassidis</surname>, <given-names>J.</given-names></string-name> and <string-name><surname>Junkins</surname>, <given-names>J.</given-names></string-name></person-group> (<year>2011</year>). <source>Optimal estimation of dynamic systems</source>, <edition>2nd</edition> ed. <publisher-name>Chapman &amp; Hall</publisher-name>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Davie</surname>, <given-names>J.T.</given-names></string-name>, <string-name><surname>Clark</surname>, <given-names>B.A.</given-names></string-name>, and <string-name><surname>Häusser</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2008</year>). <article-title>The origin of the complex spike in cerebellar Purkinje cells</article-title>. <source>J. Neurosci</source>. <volume>28</volume>, <fpage>7599</fpage>–<lpage>7609</lpage>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name> and <string-name><surname>Kakade</surname>, <given-names>S.</given-names></string-name></person-group> (<year>2000</year>). <article-title>Explaining away in weight space</article-title>. <source>Adv. Neural Inf. Process. Syst</source>. <volume>13</volume>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>De Pittà</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Brunel</surname>, <given-names>N.</given-names></string-name>, and <string-name><surname>Volterra</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Astrocytes: Orchestrating synaptic plasticity?</article-title> <source>Neuroscience</source> <volume>323</volume>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>De Schutter</surname>, <given-names>E.</given-names></string-name> and <string-name><surname>Steuber</surname>, <given-names>V.</given-names></string-name></person-group> (<year>2009</year>). <article-title>Patterns and pauses in Purkinje cell simple spike trains: experiments, modeling and theory</article-title>. <source>Neuroscience</source> <volume>162</volume>, <fpage>816</fpage>–<lpage>826</lpage>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Denève</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Alemi</surname>, <given-names>A.</given-names></string-name>, and <string-name><surname>Bourdoukan</surname>, <given-names>R.</given-names></string-name></person-group> (<year>2017</year>). <article-title>The brain as an efficient and robust adaptive learner</article-title>. <source>Neuron</source> <volume>94</volume>, <fpage>969</fpage>–<lpage>977</lpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Drugowitsch</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Mendonça</surname>, <given-names>A.G.</given-names></string-name>, <string-name><surname>Mainen</surname>, <given-names>Z.F.</given-names></string-name>, and <string-name><surname>Pouget</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Learning optimal decisions with confidence</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A</source>. <volume>116</volume>, <fpage>24872</fpage>–<lpage>24880</lpage>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eden</surname>, <given-names>U.T.</given-names></string-name>, <string-name><surname>Frank</surname>, <given-names>L.M.</given-names></string-name>, <string-name><surname>Barbieri</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Solo</surname>, <given-names>V.</given-names></string-name>, and <string-name><surname>Brown</surname>, <given-names>E.N.</given-names></string-name></person-group> (<year>2004</year>). <article-title>Dynamic analysis of neural encoding by point process adaptive filtering</article-title>. <source>Neural Comput</source>. <volume>16</volume>, <fpage>971</fpage>–<lpage>998</lpage>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fan</surname>, <given-names>L.Z.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2023</year>). <article-title>All-optical physiology resolves a synaptic basis for behavioral timescale plasticity</article-title>. <source>Cell</source> <volume>186</volume>, <fpage>543</fpage>–<lpage>559</lpage>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Feng</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Cai</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Zhao</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Yan</surname>, <given-names>Z.</given-names></string-name></person-group> (<year>2001</year>). <article-title>Serotonin receptors modulate GABAA receptor channels through activation of anchored protein kinase C in prefrontal cortical neurons</article-title>. <source>J. Neurosci</source>. <volume>21</volume>, <fpage>6502</fpage>–<lpage>6511</lpage>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Feulner</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Perich</surname>, <given-names>M.G.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>L.E.</given-names></string-name>, <string-name><surname>Clopath</surname>, <given-names>C.</given-names></string-name>, and <string-name><surname>Gallego</surname>, <given-names>J.A.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Feedback-based motor control can guide plasticity and drive rapid learning</article-title>. <source>bioRxiv</source>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fişek</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Herrmann</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Egea-Weiss</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Cloves</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Bauer</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>T.-Y.</given-names></string-name>, <string-name><surname>Russell</surname>, <given-names>L.E.</given-names></string-name>, and <string-name><surname>Häusser</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2023</year>). <article-title>Cortico-cortical feedback engages active dendrites in visual cortex</article-title>. <source>Nature</source>, <volume>617</volume> <fpage>769</fpage>–<lpage>776</lpage>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fourcaud</surname>, <given-names>N.</given-names></string-name> and <string-name><surname>Brunel</surname>, <given-names>N.</given-names></string-name></person-group> (<year>2002</year>). <article-title>Dynamics of the firing probability of noisy integrate-and-fire neurons</article-title>. <source>Neural Comput</source>. <volume>14</volume>, <fpage>2057</fpage>–<lpage>2110</lpage>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Friedrich</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Golkar</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Farashahi</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Genkin</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Sengupta</surname>, <given-names>A.</given-names></string-name>, and <string-name><surname>Chklovskii</surname>, <given-names>D.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Neural optimal feedback control with local learning rules</article-title>. <source>Adv. Neural Inf. Process. Syst</source>. <volume>34</volume>, <fpage>16358</fpage>–<lpage>16370</lpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gil</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Connors</surname>, <given-names>B.W.</given-names></string-name>, and <string-name><surname>Amitai</surname>, <given-names>Y.</given-names></string-name></person-group> (<year>1997</year>). <article-title>Differential regulation of neocortical synapses by neuromodulators and activity</article-title>. <source>Neuron</source> <volume>19</volume>, <fpage>679</fpage>–<lpage>686</lpage>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gilmer</surname>, <given-names>J.I.</given-names></string-name>, <string-name><surname>Farries</surname>, <given-names>M.A.</given-names></string-name>, <string-name><surname>Kilpatrick</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Delis</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Cohen</surname>, <given-names>J.D.</given-names></string-name>, and <string-name><surname>Person</surname>, <given-names>A.L.</given-names></string-name></person-group> (<year>2023</year>). <article-title>An emergent temporal basis set robustly supports cerebellar time-series learning</article-title>. <source>J. Neurophysiol</source>. <volume>129</volume>, <fpage>159</fpage>–<lpage>176</lpage>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Han</surname>, <given-names>K.-S.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>C.H.</given-names></string-name>, <string-name><surname>Khan</surname>, <given-names>M.M.</given-names></string-name>, <string-name><surname>Guo</surname>, <given-names>C.</given-names></string-name>, and <string-name><surname>Regehr</surname>, <given-names>W.G.</given-names></string-name></person-group> (<year>2020</year>). <article-title>Climbing fiber synapses rapidly and transiently inhibit neighboring Purkinje cells via ephaptic coupling</article-title>. <source>Nat. Neurosci</source>. <volume>23</volume>, <fpage>1399</fpage>–<lpage>1409</lpage>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Hernández-Lobato</surname>, <given-names>J.M.</given-names></string-name> and <string-name><surname>Adams</surname>, <given-names>R.</given-names></string-name></person-group> (<year>2015</year>). <article-title>Probabilistic backpropagation for scalable learning of bayesian neural networks</article-title>. <conf-name>Proc. Intl. Conf. Mach. Learn</conf-name>. <fpage>1861</fpage>–<lpage>1869</lpage>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Higley</surname>, <given-names>M.J.</given-names></string-name> and <string-name><surname>Sabatini</surname>, <given-names>B.L.</given-names></string-name></person-group> (<year>2010</year>). <article-title>Competitive regulation of synaptic Ca<sup>2+</sup> influx by D2 dopamine and A2A adenosine receptors</article-title>. <source>Nat. Neurosci</source>. <volume>13</volume>, <fpage>958</fpage>–<lpage>966</lpage>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hiratani</surname>, <given-names>N.</given-names></string-name> and <string-name><surname>Latham</surname>, <given-names>P.E.</given-names></string-name></person-group> (<year>2020</year>). <article-title>Rapid Bayesian learning in the mammalian olfactory system</article-title>. <source>Nat. Commun</source>. <volume>11</volume>, <fpage>3845</fpage>.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hull</surname>, <given-names>C.</given-names></string-name></person-group> (<year>2020</year>). <article-title>Prediction signals in the cerebellum: beyond supervised motor learning</article-title>. <source>eLife</source> <volume>9</volume>, <elocation-id>e54073</elocation-id>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hull</surname>, <given-names>C.</given-names></string-name> and <string-name><surname>Regehr</surname>, <given-names>W.G.</given-names></string-name></person-group> (<year>2022</year>). <article-title>The cerebellar cortex</article-title>. <source>Annu. Rev. Neurosci</source>. <volume>45</volume>, <fpage>151</fpage>–<lpage>175</lpage>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ito</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2001</year>). <article-title>Cerebellar long-term depression: characterization, signal transduction, and functional roles</article-title>. <source>Physiol. Rev</source>. <volume>81</volume>, <fpage>1143</fpage>–<lpage>1195</lpage>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Jayabal</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Bhasin</surname>, <given-names>B.J.</given-names></string-name>, <string-name><surname>Suvrathan</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>DiSanto</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Goldman</surname>, <given-names>M.S.</given-names></string-name>, and <string-name><surname>Raymond</surname>, <given-names>J.L.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Experience adaptively tunes the timing rules for associative plasticity</article-title>. <source>bioRxiv</source>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jegminat</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Surace</surname>, <given-names>S.C.</given-names></string-name>, and <string-name><surname>Pfister</surname>, <given-names>J.-P.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Learning as filtering: Implications for spike-based plasticity</article-title>. <source>PLoS Comput. Biol</source>. <volume>18</volume>, <fpage>e1009721</fpage>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kappel</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Habenschuss</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Legenstein</surname>, <given-names>R.</given-names></string-name>, and <string-name><surname>Maass</surname>, <given-names>W.</given-names></string-name></person-group> (<year>2015</year>). <article-title>Network plasticity as Bayesian inference</article-title>. <source>PLoS Comput. Biol</source>. <volume>11</volume>, <fpage>e1004485</fpage>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kirkpatrick</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2017</year>). <article-title>Overcoming catastrophic forgetting in neural networks</article-title>. <source>Proc. Natl. Acad. Sci</source>. <volume>114</volume>, <fpage>3521</fpage>–<lpage>3526</lpage>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kostadinov</surname>, <given-names>D.</given-names></string-name> and <string-name><surname>Häusser</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Reward signals in the cerebellum: origins, targets, and functional implications</article-title>. <source>Neuron</source> <volume>110</volume>, <fpage>1290</fpage>–<lpage>1303</lpage>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kutschireiter</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Surace</surname>, <given-names>S.C.</given-names></string-name>, and <string-name><surname>Pfister</surname>, <given-names>J.-P.</given-names></string-name></person-group> (<year>2020</year>). <article-title>The Hitchhiker’s guide to nonlinear filtering</article-title>. <source>J. Math. Psychol</source>. <volume>94</volume>, <fpage>102307</fpage>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Larkum</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2013</year>). <article-title>A cellular mechanism for cortical associations: an organizing principle for the cerebral cortex</article-title>. <source>Trends Neurosci</source>. <volume>3</volume>, <fpage>141</fpage>–<lpage>151</lpage>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Llinás</surname>, <given-names>R.</given-names></string-name> and <string-name><surname>Sugimori</surname>, <given-names>M.</given-names></string-name></person-group> (<year>1980</year>). <article-title>Electrophysiological properties of in vitro Purkinje cell somata in mammalian cerebellar slices</article-title>. <source>J. Physiol</source>. <volume>305</volume>, <fpage>171</fpage>–<lpage>195</lpage>.</mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>MacKay</surname>, <given-names>D.J.</given-names></string-name></person-group> (<year>1992</year>). <article-title>A practical Bayesian framework for backpropagation networks</article-title>. <source>Neural Comput</source>. <volume>4</volume>, <fpage>448</fpage>–<lpage>472</lpage>.</mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Magee</surname>, <given-names>J.C.</given-names></string-name> and <string-name><surname>Grienberger</surname>, <given-names>C.</given-names></string-name></person-group> (<year>2020</year>). <article-title>Synaptic plasticity forms and functions</article-title>. <source>Annu, Rev. Neurosci</source>. <volume>43</volume>, <fpage>95</fpage>–<lpage>117</lpage>.</mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Malkin</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>O’Donnell</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Houghton</surname>, <given-names>C.J.</given-names></string-name>, and <string-name><surname>Aitchison</surname>, <given-names>L.</given-names></string-name></person-group> (<year>2024</year>). <article-title>Signatures of Bayesian inference emerge from energy-efficient synapses</article-title>. <source>eLife</source> <volume>12, RP92595</volume>.</mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Marder</surname>, <given-names>E.</given-names></string-name></person-group> (<year>2012</year>). <article-title>Neuromodulation of neuronal circuits: back to the future</article-title>. <source>Neuron</source> <volume>76</volume>, <fpage>1</fpage>–<lpage>11</lpage>.</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mathews</surname>, <given-names>P.J.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>K.H.</given-names></string-name>, <string-name><surname>Peng</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Houser</surname>, <given-names>C.R.</given-names></string-name>, and <string-name><surname>Otis</surname>, <given-names>T.S.</given-names></string-name></person-group> (<year>2012</year>). <article-title>Effects of climbing fiber driven inhibition on Purkinje neuron spiking</article-title>. <source>J. Neurosci</source>. <volume>32</volume>, <fpage>17988</fpage>–<lpage>17997</lpage>.</mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mathy</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Ho</surname>, <given-names>S.S.</given-names></string-name>, <string-name><surname>Davie</surname>, <given-names>J.T.</given-names></string-name>, <string-name><surname>Duguid</surname>, <given-names>I.C.</given-names></string-name>, <string-name><surname>Clark</surname>, <given-names>B.A.</given-names></string-name>, and <string-name><surname>Häusser</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2009</year>). <article-title>Encoding of oscillations by axonal bursts in inferior olive neurons</article-title>. <source>Neuron</source> <volume>62</volume>, <fpage>388</fpage>–<lpage>399</lpage>.</mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McGehee</surname>, <given-names>D.S.</given-names></string-name>, <string-name><surname>Heath</surname>, <given-names>M.J.</given-names></string-name>, <string-name><surname>Gelber</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Devay</surname>, <given-names>P.</given-names></string-name>, and <string-name><surname>Role</surname>, <given-names>L.W.</given-names></string-name></person-group> (<year>1995</year>). <article-title>Nicotine enhancement of fast excitatory synaptic transmission in CNS by presynaptic receptors</article-title>. <source>Science</source> <volume>269</volume>, <fpage>1692</fpage>–<lpage>1696</lpage>.</mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McNamee</surname>, <given-names>D.</given-names></string-name> and <string-name><surname>Wolpert</surname>, <given-names>D.M.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Internal models in biological control</article-title>. <source>Annu. Rev. Control Robot. Auton. Syst</source>. <volume>2</volume>, <fpage>339</fpage>–<lpage>364</lpage>.</mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Medina</surname>, <given-names>J.F.</given-names></string-name>, <string-name><surname>Garcia</surname>, <given-names>K.S.</given-names></string-name>, <string-name><surname>Nores</surname>, <given-names>W.L.</given-names></string-name>, <string-name><surname>Taylor</surname>, <given-names>N.M.</given-names></string-name>, and <string-name><surname>Mauk</surname>, <given-names>M.D.</given-names></string-name></person-group> (<year>2000</year>). <article-title>Timing mechanisms in the cerebellum: testing predictions of a large-scale computer simulation</article-title>. <source>J. Neurosci</source>. <volume>20</volume>, <fpage>5516</fpage>–<lpage>5525</lpage>.</mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Meulemans</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Tristany Farinha</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>García Ordóñez</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Vilimelis Aceituno</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Sacramento</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Grewe</surname>, <given-names>B.F.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Credit assignment in neural networks through deep feedback control</article-title>. <source>Adv. Neural Inf. Process. Syst</source>. <volume>34</volume>, <fpage>4674</fpage>–<lpage>4687</lpage>.</mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Meulemans</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Zucchet</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Kobayashi</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Von Oswald</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Sacramento</surname>, <given-names>J.</given-names></string-name></person-group> (<year>2022</year>). <article-title>The least-control principle for local learning at equilibrium</article-title>. <source>Adv. Neural Inf. Process. Syst</source>. <volume>35</volume>, <fpage>33603</fpage>–<lpage>33617</lpage>.</mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Moore</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Genkin</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Tournoy</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Pughe-Sanford</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Steveninck</surname>, <given-names>R.R. van</given-names></string-name>, and <string-name><surname>Chklovskii</surname>, <given-names>D.B.</given-names></string-name></person-group> (<year>2024</year>). <article-title>The neuron as a direct data-driven controller</article-title>. <source>Proc. Natl. Acad. Sci. U.S.A</source>. <volume>121</volume>, <fpage>e2311893121</fpage>.</mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nadim</surname>, <given-names>F.</given-names></string-name> and <string-name><surname>Bucher</surname>, <given-names>D.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Neuromodulation of neurons and synapses</article-title>. <source>Curr. Opin. Neurobiol</source>. <volume>29</volume>, <fpage>48</fpage>–<lpage>56</lpage>.</mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Papouin</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Dunphy</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Tolman</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Foley</surname>, <given-names>J.C.</given-names></string-name>, and <string-name><surname>Haydon</surname>, <given-names>P.G.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Astrocytic control of synaptic function</article-title>. <source>Philos. Trans. R. Soc. B</source> <volume>372</volume>, <fpage>20160154</fpage>.</mixed-citation></ref>
<ref id="c65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Payeur</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Guerguiev</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Zenke</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Richards</surname>, <given-names>B.A.</given-names></string-name>, and <string-name><surname>Naud</surname>, <given-names>R.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Burst-dependent synaptic plasticity can coordinate learning in hierarchical circuits</article-title>. <source>Nat. Neurosci</source>. <volume>24</volume>, <fpage>1010</fpage>–<lpage>1019</lpage>.</mixed-citation></ref>
<ref id="c66"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pearlmutter</surname>, <given-names>B.A.</given-names></string-name></person-group> (<year>1995</year>). <article-title>Gradient calculations for dynamic recurrent neural networks: A survey</article-title>. <source>IEEE Trans. Neural Netw</source>. <volume>6</volume>, <fpage>1212</fpage>–<lpage>1228</lpage>.</mixed-citation></ref>
<ref id="c67"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Pemberton</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Chadderton</surname>, <given-names>P.</given-names></string-name>, and <string-name><surname>Costa</surname>, <given-names>R.P.</given-names></string-name></person-group> (<year>2023</year>). <article-title>Cerebellar-driven cortical dynamics enable task acquisition, switching and consolidation</article-title>. <source>bioRxiv</source>.</mixed-citation></ref>
<ref id="c68"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Perea</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Navarrete</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Araque</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2009</year>). <article-title>Tripartite synapses: astrocytes process and control synaptic information</article-title>. <source>Trends Neurosci</source>. <volume>32</volume>, <fpage>421</fpage>–<lpage>431</lpage>.</mixed-citation></ref>
<ref id="c69"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pfister</surname>, <given-names>J.P.</given-names></string-name>, <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name>, and <string-name><surname>Lengyel</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2010</year>). <article-title>Synapses with short-term plasticity are optimal estimators of presynaptic membrane potentials</article-title>. <source>Nat. Neurosci</source>. <volume>13</volume>, <fpage>1271</fpage>–<lpage>1275</lpage>.</mixed-citation></ref>
<ref id="c70"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Poirazi</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Brannon</surname>, <given-names>T.</given-names></string-name>, and <string-name><surname>Mel</surname>, <given-names>B.W.</given-names></string-name></person-group> (<year>2003</year>). <article-title>Pyramidal neuron as two-layer neural network</article-title>. <source>Neuron</source> <volume>37</volume>, <fpage>989</fpage>–<lpage>999</lpage>.</mixed-citation></ref>
<ref id="c71"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Richards</surname>, <given-names>B.A.</given-names></string-name> and <string-name><surname>Lillicrap</surname>, <given-names>T.P.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Dendritic solutions to the credit assignment problem</article-title>. <source>Curr. Opin, Neurobiol</source>. <volume>54</volume>, <fpage>28</fpage>–<lpage>36</lpage>.</mixed-citation></ref>
<ref id="c72"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Richards</surname>, <given-names>B.A.</given-names></string-name> and <string-name><surname>Kording</surname>, <given-names>K.P.</given-names></string-name></person-group> (<year>2023</year>). <article-title>The study of plasticity has always been about gradients</article-title>. <source>J. Physiol</source>. <volume>601</volume>, <fpage>3141</fpage>–<lpage>3149</lpage>.</mixed-citation></ref>
<ref id="c73"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rossbroich</surname>, <given-names>J.</given-names></string-name> and <string-name><surname>Zenke</surname>, <given-names>F.</given-names></string-name></person-group> (<year>2023</year>). <article-title>Dis-inhibitory neuronal circuits can control the sign of synaptic plasticity</article-title>. <source>Adv. Neural Inf. Process. Syst</source>. <volume>37</volume>.</mixed-citation></ref>
<ref id="c74"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Rotondo</surname>, <given-names>A.P.</given-names></string-name>, <string-name><surname>Raman</surname>, <given-names>D.V.</given-names></string-name>, and <string-name><surname>O’Leary</surname>, <given-names>T.</given-names></string-name></person-group> (<year>2023</year>). <article-title>How cerebellar architecture and dense activation patterns facilitate online learning in dynamic tasks</article-title>. <source>bioRxiv</source>.</mixed-citation></ref>
<ref id="c75"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Safo</surname>, <given-names>P.</given-names></string-name> and <string-name><surname>Regehr</surname>, <given-names>W.G.</given-names></string-name></person-group> (<year>2008</year>). <article-title>Timing dependence of the induction of cerebellar LTD</article-title>. <source>Neuropharmacology</source> <volume>54</volume>, <fpage>213</fpage>–<lpage>218</lpage>.</mixed-citation></ref>
<ref id="c76"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sato</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Miura</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Fushiki</surname>, <given-names>H.</given-names></string-name>, and <string-name><surname>Kawasaki</surname>, <given-names>T.</given-names></string-name></person-group> (<year>1992</year>). <article-title>Short-term modulation of cerebellar Purk-inje cell activity after spontaneous climbing fiber input</article-title>. <source>J. Neurophysiol</source>. <volume>68</volume>, <fpage>2051</fpage>–<lpage>2062</lpage>.</mixed-citation></ref>
<ref id="c77"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Silva</surname>, <given-names>N.T.</given-names></string-name>, <string-name><surname>Ramírez-Buriticá</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Pritchett</surname>, <given-names>D.L.</given-names></string-name>, and <string-name><surname>Carey</surname>, <given-names>M.R.</given-names></string-name></person-group> (<year>2024</year>). <article-title>Climbing fibers provide essential instructive signals for associative learning</article-title>. <source>Nat. Neurosci</source>. <volume>27</volume>, <fpage>940</fpage>–<lpage>951</lpage>.</mixed-citation></ref>
<ref id="c78"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Smith</surname>, <given-names>O.J.</given-names></string-name></person-group> (<year>1959</year>). <article-title>A controller to overcome dead time</article-title>. <source>iSA journal</source> <volume>6</volume>, <fpage>28</fpage>–<lpage>33</lpage>.</mixed-citation></ref>
<ref id="c79"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Steuber</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Mittmann</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Hoebeek</surname>, <given-names>F.E.</given-names></string-name>, <string-name><surname>Silver</surname>, <given-names>R.A.</given-names></string-name>, <string-name><surname>De Zeeuw</surname>, <given-names>C.I.</given-names></string-name>, <string-name><surname>Häusser</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>De Schutter</surname>, <given-names>E.</given-names></string-name></person-group> (<year>2007</year>). <article-title>Cerebellar LTD and pattern recognition by Purkinje cells</article-title>. <source>Neuron</source> <volume>54</volume>, <fpage>121</fpage>–<lpage>136</lpage>.</mixed-citation></ref>
<ref id="c80"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Suvrathan</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Payne</surname>, <given-names>H.L.</given-names></string-name>, and <string-name><surname>Raymond</surname>, <given-names>J.L.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Timing rules for synaptic plasticity matched to behavioral function</article-title>. <source>Neuron</source> <volume>92</volume>, <fpage>959</fpage>–<lpage>967</lpage>.</mixed-citation></ref>
<ref id="c81"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Todorov</surname>, <given-names>E.</given-names></string-name></person-group> (<year>2004</year>). <article-title>Optimality principles in sensorimotor control</article-title>. <source>Nat. Neurosci</source>. <volume>7</volume>, <fpage>907</fpage>–<lpage>915</lpage>.</mixed-citation></ref>
<ref id="c82"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Walter</surname>, <given-names>J.T.</given-names></string-name> and <string-name><surname>Khodakhah</surname>, <given-names>K.</given-names></string-name></person-group> (<year>2006</year>). <article-title>The linear computational algorithm of cerebellar Purkinje cells</article-title>. <source>J. Neurosci</source>. <volume>26</volume>, <fpage>12861</fpage>–<lpage>12872</lpage>.</mixed-citation></ref>
<ref id="c83"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname>, <given-names>S.S.-H.</given-names></string-name>, <string-name><surname>Denk</surname>, <given-names>W.</given-names></string-name>, and <string-name><surname>Häusser</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2000</year>). <article-title>Coincidence detection in single dendritic spines mediated by calcium release</article-title>. <source>Nat. Neurosci</source>. <volume>3</volume>, <fpage>1266</fpage>–<lpage>1273</lpage>.</mixed-citation></ref>
<ref id="c84"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Widrow</surname>, <given-names>B.</given-names></string-name> and <string-name><surname>Hoff</surname>, <given-names>M.E.</given-names></string-name></person-group> (<year>1960</year>). <article-title>Adaptive switching circuits</article-title>. <source>IRE WESCON convention record</source> <volume>4</volume>, <fpage>96</fpage>–<lpage>104</lpage>.</mixed-citation></ref>
<ref id="c85"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Williams</surname>, <given-names>R.J.</given-names></string-name> and <string-name><surname>Zipser</surname>, <given-names>D.</given-names></string-name></person-group> (<year>1989</year>). <article-title>A learning algorithm for continually running fully recurrent neural networks</article-title>. <source>Neural Comput</source>. <volume>1</volume>, <fpage>270</fpage>–<lpage>280</lpage>.</mixed-citation></ref>
<ref id="c86"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wolpert</surname>, <given-names>D.M.</given-names></string-name>, <string-name><surname>Miall</surname>, <given-names>R.C.</given-names></string-name>, and <string-name><surname>Kawato</surname>, <given-names>M.</given-names></string-name></person-group> (<year>1998</year>). <article-title>Internal models in the cerebellum</article-title>. <source>Trends Cog. Sci</source>. <volume>2</volume>, <fpage>338</fpage>–<lpage>347</lpage>.</mixed-citation></ref>
<ref id="c87"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zenke</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Agnes</surname>, <given-names>E.J.</given-names></string-name>, and <string-name><surname>Gerstner</surname>, <given-names>W.</given-names></string-name></person-group> (<year>2015</year>). <article-title>Diverse synaptic plasticity mechanisms orchestrated to form and retrieve memories in spiking neural networks</article-title>. <source>Nat. Comms</source>. <volume>6</volume>, <fpage>6922</fpage>.</mixed-citation></ref>
<ref id="c88"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Zenke</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Poole</surname>, <given-names>B.</given-names></string-name>, and <string-name><surname>Ganguli</surname>, <given-names>S.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Continual learning through synaptic intelligence</article-title>. <conf-name>Int. Conf. Mach. Learn</conf-name>. <fpage>3987</fpage>–<lpage>3995</lpage>.</mixed-citation></ref>
<ref id="c89"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zucker</surname>, <given-names>R.S.</given-names></string-name> and <string-name><surname>Regehr</surname>, <given-names>W.G.</given-names></string-name></person-group> (<year>2002</year>). <article-title>Short-term synaptic plasticity</article-title>. <source>Annu. Rev. Physiol</source>. <volume>64</volume>, <fpage>355</fpage>– <lpage>405</lpage>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.105043.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Naud</surname>
<given-names>Richard</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Ottawa</institution>
</institution-wrap>
<city>Ottawa</city>
<country>Canada</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This paper provides an <bold>important</bold> proposal for why learning can be much faster and more accurate if synapses have a fast component that immediately corrects errors, as well as a slower component that corrects behavior averaged over a longer timescale. It is <bold>convincingly</bold> shown that integrating these two learning timescales improves performance compared to classical strategies, particularly in terms of robustness and generalization when learning new target signals. However, the biological plausibility and justification for the proposed rapid learning mechanism require further elaboration and supporting mechanistic examples.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.105043.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This paper proposes a new set of local synaptic plasticity rules that differs from classic rules in two regards: First, working under the assumption that signals coming into synapses change smoothly over time and thus have temporal correlations such that immediate activity is positively correlated with subsequent activity, it proposes both fast plasticity that immediately corrects errors as well as slower plasticity. Second, it derives these rules from optimal, Bayesian control theory principles that, even without the fast component of plasticity, are shown to provide more accurate performance than classic, non-Bayesian plasticity rules. As a proof of principle, it applies these to a simple cerebellar learning example that demonstrates how the proposed rules lead to learning performance that exceeds that achieved with classic cerebellar learning rules. The work also provides a potential normative explanation for post-climbing fiber spike pauses in Purkinje cell firing and proposes testable predictions for cerebellar experiments. Overall, I found the idea to be compelling and potentially broadly applicable across many systems. Further, I thought the work was a rare, very beautiful display of the application of optimal control theory to fundamental problems in neuroscience. My comments are all relatively minor and more expressions of interest than criticism.</p>
<p>Comments:</p>
<p>(1) The algorithm assumes, reasonably, that inputs are relatively smooth. However, I was wondering if this could make additional experimental predictions for the system being exceptionally noisy or otherwise behaving in signature ways if one were able to train a real biological network to match a rapidly changing or non-smooth function that does not align with the underlying assumptions of the model.</p>
<p>(2) The algorithm assumes that one can, to a good approximation, replace individual input rates by their across-synapse average. How sensitive is the learning to this assumption, as one might imagine scenarios where a neuron is sensitive to different inputs for different tasks or contexts so that a grand average might not be correct? Or, the functional number of inputs driving the output might be relatively low or otherwise highly fluctuating and less easily averaged over.</p>
<p>(3) On the cerebellar example, it is nice that the Bayesian example provides a narrower PF-CF interval for plasticity than the classical rules, but the window is not nearly as narrow as the Suvrathan et al. 2016 paper cited by the authors. Maybe this is something special about that system having well-defined, delayed feedback, but (optional) further comments or insights would be welcome if available.</p>
<p>(4) In the discussion, I appreciated the comparison with the Deneve work which has fast and slow feedback components. I was curious whether, although non-local, there were also conceptual similarities with FORCE learning in which there is also an immediate correction of activity through fast changing of synaptic weights, which then aids the slow long-term learning of synaptic weights.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.105043.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Bricknell and Latham investigate the computational benefits of a dual-learning algorithm that combines a rapid, millisecond-scale weight adjustment mechanism with a conventional, slower gradient descent approach. A feedback error signal drives both mechanisms at the synaptic level.</p>
<p>Strengths:</p>
<p>Integrating these two learning timescales is intriguing and demonstrates improved performance compared to classical strategies, particularly in terms of robustness and generalization when learning new target signals.</p>
<p>Weaknesses:</p>
<p>The biological plausibility and justification for the proposed rapid learning mechanism require further elaboration and supporting mechanistic examples.</p>
</body>
</sub-article>
</article>