<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">94165</article-id>
<article-id pub-id-type="doi">10.7554/eLife.94165</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.94165.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Progressively shifting patterns of co-modulation among premotor cortex neurons carry dynamically similar signals during action execution and observation</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Zhao</surname>
<given-names>Zhonghao</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4315-8161</contrib-id>
<name>
<surname>Schieber</surname>
<given-names>Marc H.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Biomedical Engineering, University of Rochester</institution>, Rochester, NY, 14627</aff>
<aff id="a2"><label>2</label><institution>Department of Neurology, University of Rochester</institution>, Rochester, NY, 14642</aff>
<aff id="a3"><label>3</label><institution>Department of Neuroscience, University of Rochester</institution>, Rochester, NY 14642</aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Gallego</surname>
<given-names>Juan Alvaro</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Imperial College London</institution>
</institution-wrap>
<city>London</city>
<country>United Kingdom</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Makin</surname>
<given-names>Tamar R</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Cambridge</institution>
</institution-wrap>
<city>Cambridge</city>
<country>United Kingdom</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>Corresponding Author: Marc H. Schieber E-mail: <email>mschiebe@ur.rochester.edu</email></corresp>
<fn id="n1"><p><bold>Conflict of interest:</bold> The authors declare no conflicts of interest.</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-01-10">
<day>10</day>
<month>01</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP94165</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-11-06">
<day>06</day>
<month>11</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-11-06">
<day>06</day>
<month>11</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.11.06.565833"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Zhao &amp; Schieber</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Zhao &amp; Schieber</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-94165-v1.pdf"/>
<abstract>
<title>Abstract</title><p>Many neurons in the premotor cortex show firing rate modulation whether the subject performs an action or observes another individual performing the same action. Although such “mirror neurons” have been thought to have highly congruent discharge during execution and observation, many if not most show non-congruent activity. Studies of such neuronal populations have shown that the most prevalent patterns of co-modulation—captured as neural trajectories—pass through subspaces which are shared in part, but in part are visited exclusively during either execution or observation. These studies focused on reaching movements for which the neural trajectories show comparatively simple dynamical motifs. But the neural dynamics of hand movements are more complex. We developed a novel approach to examine prevalent patterns of co-modulation during execution and observation of a task that involved reaching, grasping and manipulation. Rather than following neural trajectories in subspaces that contain their entire time course, we identified time series of instantaneous subspaces, sampled trajectory segments at the times of selected behavioral events, and projected each segment into the series of instantaneous subspaces. We found that instantaneous neural subspaces were partially shared between execution and observation in only one of three monkeys and were otherwise exclusive to one context or the other. Nevertheless, the patterns during execution and observation could be aligned with canonical correlation, indicating that though distinct, neural representations during execution and observation show dynamical similarity that may enable the nervous system to recognize particular actions whether performed by the subject or by another individual.</p>
</abstract>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Although the premotor (PM) and primary motor cortex (M1) are generally thought to be involved in the planning and execution of movement, many neurons in these cortical motor areas have been found to discharge not only when the subject executes a movement, but also when the subject observes a similar movement being performed by another individual. Such neurons have been found in the ventral premotor cortex (PMv) (Bonini et al., 2014; <xref ref-type="bibr" rid="c11">Gallese et al., 1996</xref>), dorsal premotor cortex (PMd) (<xref ref-type="bibr" rid="c4">Cisek &amp; Kalaska, 2004</xref>; <xref ref-type="bibr" rid="c22">Papadourakis &amp; Raos, 2019</xref>), and M1 (<xref ref-type="bibr" rid="c7">Dushanova &amp; Donoghue, 2010</xref>; Kraskov et al., 2014a; <xref ref-type="bibr" rid="c34">Vigneswaran et al., 2013</xref>).</p>
<p>Early studies of these neurons emphasized those with “congruent” discharge during execution and observation conditions. Congruent neurons discharged during the same type of grasp (<xref ref-type="bibr" rid="c11">Gallese et al., 1996</xref>; <xref ref-type="bibr" rid="c26">Rizzolatti et al., 1996</xref>), or retained the same preferred direction (<xref ref-type="bibr" rid="c7">Dushanova &amp; Donoghue, 2010</xref>; Kilner &amp; Lemon, 2013) during both execution and observation. Emphasis on such congruent neurons led to the notion that they mediate understanding of observed actions by mirroring their own activity during execution (<xref ref-type="bibr" rid="c6">di Pellegrino et al., 1992</xref>; <xref ref-type="bibr" rid="c25">Rizzolatti and Craighero, 2004</xref>).</p>
<p>Even early studies also reported, however, many other “noncongruent” neurons that also discharged during execution and during observation, but differently in the two contexts (<xref ref-type="bibr" rid="c11">Gallese et al., 1996</xref>). For example, of the pyramidal tract neurons (PTNs) in PMv and M1 that show modulation during both execution and observation, half show substantially lower firing rates during observation than during execution (<xref ref-type="bibr" rid="c16">Kraskov et al., 2009</xref>; <xref ref-type="bibr" rid="c34">Vigneswaran et al., 2013</xref>; <xref ref-type="bibr" rid="c17">Kraskov et al., 2014</xref>). In many studies roughly half or more of the neurons modulated during both execution and observation are noncongruent (<xref ref-type="bibr" rid="c7">Dushanova and Donoghue, 2010</xref>; <xref ref-type="bibr" rid="c17">Kraskov et al., 2014</xref>; <xref ref-type="bibr" rid="c20">Mazurek et al., 2018</xref>; <xref ref-type="bibr" rid="c13">Jiang et al., 2020</xref>). Of PMv neurons modulated during both execution and observation, over the time course of behavioral trials only ∼20% showed brief periods with strictly congruent firing rates (<xref ref-type="bibr" rid="c24">Pomper et al., 2023</xref>). And in PMd, the proportion of congruent MNs may not be different from that expected by chance alone (<xref ref-type="bibr" rid="c22">Papadourakis and Raos, 2019</xref>). That so many neurons are active differentially during action execution versus observation calls into question the extent to which the representation of movements by these neuron populations actually matches in the two contexts. Although many authors apply the term “mirror neurons” strictly to highly congruent neurons, like many others, we will refer to all neurons modulated during both contexts—execution and observation—as mirror neurons (MNs).</p>
<p>Addressing this issue at the population level is complex because of the wide variety of firing rate modulation found in individual neurons at different times in the course of behavioral trials, as well as among neurons in a recorded population. Different movements may be represented more accurately by the temporal evolution of co-modulation in populations of neurons than by the temporal pattern of discharge in single neurons. Patterns of co-modulation can be considered in a high-dimensional neural-state space where the firing rate of each neuron is a separate, orthogonal dimension. The instantaneous, simultaneous firing rates of all <italic>N</italic> neurons then is a point in this space, which traces out a trajectory over time. Neural population trajectories do not visit all regions of the <italic>N</italic>-dimensional state-space, however. Dimensionality reduction techniques can be used to identify a small set of latent dimensions—a subspace—that captures the most prevalent patterns of co-modulation among the population of <italic>N</italic> neurons. (<xref ref-type="bibr" rid="c29">Shenoy et al., 2013</xref>; <xref ref-type="bibr" rid="c5">Cunningham and Yu, 2014</xref>)</p>
<p>Studies of neural trajectories underlying action execution that focused on reaching movements made with the arm have revealing that rotational motifs in a low-dimensional subspace capture much of the neural population’s firing rate variance (<xref ref-type="bibr" rid="c3">Churchland et al., 2012</xref>). While similar rotational dynamics were found in M1 during repetitive cycling movements, the population trajectory of supplementary motor area neurons progressed as a helix through an additional dimension during successive cycles (<xref ref-type="bibr" rid="c28">Russo et al., 2020</xref>). The M1 neural trajectories underlying grasping movements made with the hand are still more complex, however (<xref ref-type="bibr" rid="c32">Suresh et al., 2020</xref>). The latent subspaces that capture the predominant patterns of condition-dependent co- modulation of M1 neurons during execution, for example, shift progressively over the time course of behavioral trials involving reaching to, grasping, and manipulating (RGM) various objects at various locations (<xref ref-type="bibr" rid="c27">Rouse and Schieber, 2018</xref>). Relatively few studies have examined the trajectories of neural populations that are active during both execution and observation (<xref ref-type="bibr" rid="c20">Mazurek et al., 2018</xref>; <xref ref-type="bibr" rid="c12">Jerjian et al., 2020</xref>; <xref ref-type="bibr" rid="c13">Jiang et al., 2020</xref>; <xref ref-type="bibr" rid="c23">Pezzulo et al., 2022</xref>).</p>
<p>In the present work, we examined the latent subspaces that capture the predominant patterns of co-modulation among populations of mirror neurons in the premotor cortex (PM MNs) during RGM movements, testing three hypotheses. First, we asked whether PM MN populations show progressive shifts in the latent dimensions (subspaces) that capture their condition-dependent patterns of co-modulation over the time course of both execution and observation trials, as illustrated schematically in <xref rid="fig1" ref-type="fig">Figure 1A</xref>. We developed a novel approach in which segments of the neural trajectories from behaviorally well-defined times are projected into the instantaneous subspaces at other times over the course of the same behavioral trials (<xref rid="fig1" ref-type="fig">Figure 1B</xref>). Because each of these subspaces is instantaneous, the projected trajectory segments capture condition- dependent variance in the neural activity while minimizing time-dependent (condition- independent) variance. We then evaluated the separation of the projected trajectory segments in each instantaneous subspace and the extent to which the segments could be decoded. We reasoned that the closer a given instantaneous subspace is to the subspace at the time from which the trajectory segments were taken, the greater the separation of trajectory segments representing different movements should be, and the better the decoding of those movements from the trajectory segments. Using this approach we examined the progressive evolution of the condition-dependent subspace over execution and over observation trials. We then asked whether the activity of the PM MN population progresses through similar subspaces during execution and observation. And third, we asked whether the execution and observation trajectory segments could be aligned (<xref rid="fig1" ref-type="fig">Figure 1C</xref>), indicating a corresponding structure in the distinct latent dynamic representations of execution and observation RGM movements by the same PM MN population.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><p>Conceptual approach. <bold>A.</bold> We hypothesized that the condition-dependent subspace of PM MN activity shifts progressively through the time course of behavioral trials both during execution (orange) and during observation (green). <bold>B.</bold> Trajectory segments (orange, green) were projected into time series of instantaneous subspaces (gray). <bold>C.</bold> Trajectory segments (latent dynamics) from execution and observation can be aligned even if they occupy distinct (orthogonal) subspaces.</p></caption>
<graphic xlink:href="565833v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2">
<title>Results</title>
<p>We recorded spiking activity as each of three monkeys executed the RGM task, and then as each monkey observed the same RGM task being performed by an experimenter (<xref rid="fig2" ref-type="fig">Figure 2A</xref>). Additional details of the behavioral task are described in the Methods. Three sessions were recorded from each of the three monkeys, F, R, and T (a 10 kg male, 6 kg female, and 10 kg male, respectively). The numbers of successful execution trials (Exe) and observation trials (Obs) involving each of the four objects—sphere, button, coaxial cylinder, and perpendicular cylinder—are given in <xref rid="tbl1" ref-type="table">Table 1</xref>.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><p>The reach-grasp-manipulate (RGM) task. <bold>A.</bold> In separate blocks of trials monkeys reached to, grasped, and manipulated four different objects themselves (Exe), and then observed a human perform the same task (Obs). <bold>B.</bold> The times of eight behavioral events from Start-of-trial to End-of-trial divided each trial into seven epochs from Initial hold to Reward. For analyses the data were aligned separately on, and trajectories were sampled at, the times of four selected events—Instruction onset (I), Go cue (G), Movement onset (M), and Hold (H).</p></caption>
<graphic xlink:href="565833v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><title>Numbers of trials in each session.</title><p>For each of the three sessions from each of the three monkeys, numbers of trials involving each of the four objects (sphere, button, coaxial cylinder, perpendicular cylinder are given in parentheses separately for execution and for observation.</p></caption>
<graphic xlink:href="565833v1_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>Using object and task time period as factors, we performed two-way ANOVA on the firing rate of each sorted unit (see Methods). Because unit firing rates almost always differed during execution and observation, we performed such ANOVAs separately on execution trials and observation trials. A unit was included for subsequent analysis if it showed significant firing rate modulation during both execution and observation. Although most studies have focused on neurons from either PMv or PMd, we combined units from these two cortical areas because neurons in each area have been shown to be modulated during both reaching and grasping (<xref ref-type="bibr" rid="c31">Stark et al., 2007</xref>). <xref rid="tbl2" ref-type="table">Table 2</xref> gives the numbers of PM (PMv +PMd) units identified in each session as being modulated during both execution and observation.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2.</label>
<caption><title>Numbers of mirror neurons in each session.</title><p>For each of the three sessions from each of the three monkeys, numbers of PM MNs are given in the format of Total(PMv, PMd).</p></caption>
<graphic xlink:href="565833v1_tbl2.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3.</label>
<caption><title>Alignment summary across sessions.</title><p>For each set of trajectory segments, across-session means ± standard deviations are given for the 1<sup>st</sup> and 2<sup>nd</sup> alignment correlation coefficients (CC1, CC2), as well as for the WSDs (d1, d2) between the Exe-Obs and Exe-Exe bootstrapped marginal distributions.</p></caption>
<graphic xlink:href="565833v1_tbl3.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<sec id="s2a">
<title>Instantaneous subspaces change during both execution and observation</title>
<p>Whereas a large fraction of condition-dependent neural variance during reaching movements without grasping can be captured by a two-dimensional subspace (<xref ref-type="bibr" rid="c3">Churchland et al., 2012</xref>; <xref ref-type="bibr" rid="c1">Ames et al., 2014</xref>), condition-dependent activity in movements that involve grasping evolves through more complex subspaces as the movements progress (<xref ref-type="bibr" rid="c32">Suresh et al., 2020</xref>). In part, this may reflect the greater complexity of controlling the 24 degrees of freedom in the hand and wrist as compared to the 4 in the elbow and shoulder (<xref ref-type="bibr" rid="c30">Sobinov and Bensmaia, 2021</xref>). Consistent with this complexity, over the time course of behavioral trials that entail concurrent reaching, grasping and manipulation (RGM), the condition-dependent activity of primary motor cortex (M1) neurons evolves through progressively changing neural subspaces (<xref ref-type="bibr" rid="c27">Rouse and Schieber, 2018</xref>).</p>
<p>Initially, we therefore asked whether the condition-dependent activity of mirror neurons in the premotor cortex likewise occupied shifting subspaces over the time course of RGM movements. To approach this question, for each recording session we applied PCA to identify the 2- dimensional subspace of condition-dependent activity at four behavioral time points readily defined across trials, sessions, and monkeys: onset of the instruction (I), go cue (G), onset of movement (M), and beginning of the hold (H). These subspaces consistently captured &gt; 70% of the condition-dependent variance. (Note that because each subspace is instantaneous, no time- dependent variance is captured. And because here averaged across trials for each of the four target objects, noise variance was eliminated) Likewise for each session, we clipped four 100 ms segments of the high-dimensional PM mirror neuron population trial averaged trajectory beginning at the time of I, G, M, and H, for trials involving each of the four objects. We then projected each trajectory segment into each of these four instantaneous subspaces. This process was repeated separately for execution trials and for observation trials in each session. We reasoned that if the instantaneous subspace shifted little or not at all, then a given set of trajectory segments would have a similar projection into each instantaneous subspace, whereas if the subspace shifted these projections would change.</p>
<p>Projections from an example session are illustrated in <xref rid="fig3" ref-type="fig">Figure 3</xref>. The trajectory segments for each of the four objects (sphere – purple, button – cyan, coaxial cylinder – magenta, perpendicular cylinder – yellow) sampled at different times (rows) have been projected into each of the four instantaneous subspaces (columns). Each set of trajectory segments thus is projected into its corresponding subspace along the main diagonal, showing that during execution (<xref rid="fig3" ref-type="fig">Figure 3A</xref>), the trajectory segments for the four objects are close together at the time of instruction onset (I), are more separated at the time of the go cue (G), have separated further still at movement onset (M), and are less separated at the time of the hold (H). Off-diagonal frames along the rows (same trajectory segments, different instantaneous subspaces) show less separation, indicating that each set of trajectory segments was most separated at the time near which it was clipped. Along the columns (different trajectory segments, same instantaneous subspaces), off-diagonal trajectory segments likewise show less separation, again indicating that each instantaneous subspace provided the greatest separation of the corresponding trajectory segments. These changes indicate that the condition-dependent subspace of this PM MN population changed as execution trials progressed in time, as illustrated schematically in <xref rid="fig1" ref-type="fig">Figure 1A</xref>.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><p>Trajectory segments projected into instantaneous subspaces<bold>. A.</bold> Using execution data from an example session (T_20220603), trajectory segments averaged across trials involving each of the four objects (sphere – purple, button – cyan, coaxial cylinder – magenta, perpendicular cylinder – yellow) were sampled immediately following each of four behavioral events (rows: Instruction onset, Go cue, Movement onset, Hold). Each set of these four segments then was projected into the instantaneous subspace present at four different times (columns: I, G, M, H). <bold>B.</bold> The same process was performed using observation data from the same session. The PC1 vs PC2 scales at lower left apply to all frames in both <bold>A</bold> and <bold>B</bold>. <bold>C and D.</bold> Cumulative separation values (CS, seem Methods) calculated for each of the frames in <bold>A and B</bold>, respectively, are shown as color matrices. <bold>E</bold> and <bold>F</bold> show CS values averaged across all 9 sessions for execution and observation, respectively.</p></caption>
<graphic xlink:href="565833v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>During observation trials from the same session (<xref rid="fig3" ref-type="fig">Figure 3B</xref>), projections of the trajectory segments showed similar changes. In general less separation was evident for observation than for execution, reflecting the commonly described lower firing rates of MNs during observation (<xref ref-type="bibr" rid="c9">Ferroni et al., 2021</xref>). Nevertheless, projecting each set of trajectory segments into the instantaneous subspace at the corresponding time (main diagonal) provided the greatest separation. In contrast to execution, where the greatest separation was obtained for the Movement trajectory segments projected into the M subspace, for observation the Hold segments projected into the H subspace showed the greatest separation. Overall, however, the condition-dependent subspace of the PM MN population also changed as observation trials progressed in time, as illustrated schematically in <xref rid="fig1" ref-type="fig">Figure 1A</xref>.</p>
<p>To quantify these changes in the separation of the trajectory segments from trials involving the four different objects, we calculated the cumulative separation (C<italic>S</italic>, the summed pointwise distance between all pairwise combinations of the four object trajectory segments, see Methods) for each set of four segments projected into each of the four instantaneous subspaces. <italic>CS</italic> values of for execution are illustrated in the color matrix of <xref rid="fig3" ref-type="fig">Figure 3C</xref>; for observation, <xref rid="fig3" ref-type="fig">Figure 3D</xref>. For both execution and observation, the highest <italic>CS</italic> values lie on the main diagonal, increasing in temporal order from Instruction to Go to Movement to Hold, with the exception that for execution the separation for Hold was less than for Movement. <xref rid="fig3" ref-type="fig">Figure 3E</xref> and <xref rid="fig3" ref-type="fig">3F</xref> show averaged CS matrices across all sessions from the three monkeys, demonstrating that the features seen in the example session were relatively consistent across sessions. During both execution and observation, the instantaneous subspace of the PM MN population changes over the time course of the behavioral trials.</p>
</sec>
<sec id="s2b">
<title>Instantaneous subspaces shift progressively through the time series of execution trials</title>
<p>We developed a novel approach to evaluate the instantaneous subspace shifting on a more continuous basis. For each session we first identified the instantaneous 3-dimensional neural subspaces at 50 ms intervals throughout the time course of execution trials. We then projected the Instruction, Go, Movement, and Hold trajectory segments from individual trials involving four objects into each of the instantaneous 3D subspaces in the time series. At each time point, we trained a separate LSTM decoder to classify individual trials according to which of the four objects was involved in that trial. We expected that the projection of trajectory segments would be decoded best near the time at which the trajectory segments were sampled. We reasoned that if at other times a given instantaneous subspace was very similar to that found at the time from which the segments were sampled, then the projection of the segments into that instantaneous subspace would be decoded almost as well. But if the other instantaneous subspace was dissimilar, then the projection into that subspace would be decoded poorly.</p>
<p><xref rid="fig4" ref-type="fig">Figure 4</xref> shows the resulting classification accuracy as a function of trial time for the 100 ms execution segments that were sampled beginning at the times of the Instruction, Go cue, Movement onset, or Hold, each projected into the time series of instantaneous execution subspaces from the same session. Solid curves indicate classification accuracy averaged across 10-fold cross-validation; the surrounding shaded areas indicate ± 1 standard deviation from that average; and different colors represent the three sessions from the same monkey, with black being their average. Horizontal lines indicate the range of classification accuracies that would have been obtained had the instantaneous subspaces been chosen randomly, which we estimated for each set of trajectory segments by bootstrapping—projecting the trajectory segments into a randomly selected 3D space, training an LSTM decoder, and classifying single trials, repeated 500 times (<xref ref-type="bibr" rid="c21">Natraj et al., 2022</xref>).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><p>Classification accuracy for <italic>execution trajectory segments</italic> projected into instantaneous<italic>execution subspaces</italic><bold>. A.</bold> Instruction trajectory segments. <bold>B.</bold> Go segments. <bold>C.</bold> Movement segments. <bold>D.</bold> Hold segments. In each frame, the short horizontal orange bars at the top of the vertical lines indicate the 100 ms during which each set of trajectory segments was sampled; the horizontal purple bar at lower left represents 500 ms. Results in 50 ms steps have been aligned separated at the times of the instruction onset (I), go cue (G), movement onset (M), and hold (H). Solid curves indicate mean classification accuracy of 10-fold cross-validation as a function of time, with the shaded areas indicating 1 standard deviation. Colors red, green, and blue represent sessions 1, 2, and 3 from each monkey, with black being their average. Horizontal black lines indicate the mean (solid) ± 3 standard deviations (dashed) classification accuracy obtained by projecting each set of trajectory segments into 500 randomly selected 3D spaces.</p></caption>
<graphic xlink:href="565833v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>As might have been expected based on the trajectory separations illustrated in <xref rid="fig3" ref-type="fig">Figure 3</xref>, classification accuracy peaked at a time point within or near the duration of the corresponding 100 millisecond trajectory segments, again indicating that the subspaces differed at times I, G, M, and H. Classification accuracy decreased progressively at times preceding and following each of these peaks. In monkey F (top row), for example, mean classification of the Instruction trajectory segments (<xref rid="fig4" ref-type="fig">Figure 4A</xref>) initially was close to 0.25, rose to 0.47 around the time of the instruction onset, and then fell back to 0.25. Mean accuracy for the Go segments (<xref rid="fig4" ref-type="fig">Figure 4B</xref>) began close to chance, rose gradually during the delay epoch to peak at 0.70 around the time of the Go cue, and decreased thereafter. For the Movement (<xref rid="fig4" ref-type="fig">Figure 4C</xref>) and Hold (<xref rid="fig4" ref-type="fig">Figure 4D</xref>) segments, classification accuracy started near 0.5 and peaked at 0.94 and 0.99 near the time of those events, respectively. Similar trends were seen for monkeys R (middle row) and T (bottom row). For each monkey classification accuracy for each of the four sets of trajectory segments—Instruction, Go, Movement, and Hold—as a function of time was quite consistent.</p>
<p>Although classification accuracy consistently peaked near the time of the behavioral event immediately after which each set of trajectory segments was sampled, the decline in accuracy before and after the peak differed depending on the behavioral event. Peak classification accuracy for Instruction segments was modest, beginning to rise from mean chance levels ∼100 ms before the instruction onset and quickly falling back thereafter. Note that the early rise indicates that towards the end of the initial hold epoch, the PM mirror neuron subspace already was shifting in anticipation of the appearance of the instruction. At times outside of this brief peak, however, the instantaneous subspace was no more similar to that at the time of instruction onset than could be expected from chance alone.</p>
<p>In contrast, classification accuracy of the Go trajectory segments was elevated above mean chance levels for more of the RGM trial duration. Though exceeding 3 standard deviations from mean chance only late in the delay epoch, Go classification accuracy rose steadily through the delay epoch, peaked near the go cue, then fell back to near mean chance levels during the reaction (time G to M) and movement (time M to H) epochs. In monkeys F and R this rise began during the 500 ms instruction epoch, but only exceeded chance upper bound shortly before the Go cue. In monkey T, however, classification accuracy of the Go segments increased abruptly after the instruction onset, exceeding upper bound, and then continuing to increase through the instruction and delay epochs. We infer that as the instruction and delay epochs progressed, the instantaneous subspace thus shifted gradually, becoming progressively closer to that at the time of the Go cue.</p>
<p>Similarly, classification accuracy for the Movement trajectory segments increased gradually through the delay, and reaction epochs (G - M), peaking near the time of movement onset and then decreasing during the movement epoch (M – H). In monkey T, an abrupt increase occurred shortly after instruction onset, though classification accuracy did not exceed chance upper bound until after the Go cue. By the time of the Go cue, however, the instantaneous subspace already was close to that at the time of Movement onset.</p>
<p>Classification accuracy of the Hold trajectory segments increased relatively late in execution trials. During the delay and reaction epochs the instantaneous subspaces were no more similar than chance to that at the beginning of the hold epoch. Classification accuracy of the Hold trajectory segments began to increase only after Movement onset, rising through the movement epoch, peaking near the beginning of the hold epoch and decreasing thereafter.</p>
<p>To summarize, the instantaneous subspace of PM mirror neurons evoked by the appearance of the instruction was relatively short-lived, and not similar to the instantaneous subspaces later in execution trials. In contrast, as the instruction and delay epochs proceeded, the instantaneous subspace became increasingly similar to those found at the time of the Go cue and then movement onset. And then as the movement epoch proceeded, the instantaneous subspace became increasingly similar to that at the beginning of the final hold. Overall, the most prominent patterns of co-modulation among PM mirror neurons, represented by their instantaneous state-space, shifted continually as execution of RGM trials progressed.</p>
</sec>
<sec id="s2c">
<title>Instantaneous subspaces also shift progressively during observation</title>
<p>Did the instantaneous PM mirror neuron subspace also shift continually during observation trials? We projected Instruction, Go, Movement, and Hold trajectory segments from observation trials into the time series of instantaneous subspaces identified for observation trials, again quantifying classification accuracy at each time point using the same approach above.</p>
<p>Classification accuracy as a function of time during observation trials is shown in <xref rid="fig5" ref-type="fig">Figure 5</xref>.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><p>Classification accuracy for <italic>observation trajectory segments</italic> projected into instantaneous <italic>observation subspaces</italic><bold>. A.</bold> Instruction trajectory segments. <bold>B.</bold> Go segments. <bold>C.</bold> Movement segments. <bold>D.</bold> Hold segments. The format of each frame is the same as that described for <xref rid="fig4" ref-type="fig">Figure 4</xref>.</p></caption>
<graphic xlink:href="565833v1_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>For the Instruction trajectory segments, the brief peak of classification accuracy occurring around the time of instruction onset (I) during observation trials was quite like that found during execution trials. For the Go cue, Movement onset, and final Hold segments, however, classification accuracy tended to be lower, and the peaks near the time of these behavioral events (G, M, and H) tended to be comparatively short lived, particularly in monkey F.</p>
<p>In monkeys R and T, however, during observation as during execution, classification accuracy of the Go and Movement trajectory segments rose through the delay epoch (in monkey T again beginning abruptly after instruction onset), peaked near the time of the go cue (G) or movement onset (M), respectively, and then fell back to near chance levels during the reaction and movement epochs. In all three monkeys, classification accuracy of the Hold trajectory segments, during observation as during execution, began to increase from mean chance levels only after movement onset, rising through the movement epoch, peaking near the beginning of the hold epoch and decreasing thereafter. During observation, the progressive shifts in the instantaneous subspace from instruction, to go cue, to movement onset, to hold, though smaller, were similar to that found during execution.</p>
</sec>
<sec id="s2d">
<title>Do PM mirror neurons progress through the same subspaces during execution and observation?</title>
<p>Having found that PM mirror neuron populations show similar progressive shifts in their instantaneous neural subspace during execution and observation of RGM trials, we asked whether this continual progression passes through the same or similar instantaneous subspaces. To address this question, we cross-projected the Instruction, Go, Movement, and Hold trajectory segments from execution trials into the time series of instantaneous subspaces from observation trials (<xref rid="fig6" ref-type="fig">Figure 6</xref>), and cross-projected the trajectory segments from observation trials into the instantaneous subspaces from execution trials (<xref rid="fig7" ref-type="fig">Figure 7</xref>), again quantifying classification accuracy with separate LSTM decoders and 10-fold cross validation.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><p>Classification accuracy for <italic>execution trajectory segments</italic> projected into instantaneous <italic>observation subspaces</italic><bold>. A.</bold> Instruction trajectory segments. <bold>B.</bold> Go segments. <bold>C.</bold> Movement segments. <bold>D.</bold> Hold segments. The format of each frame is the same as that described for <xref rid="fig4" ref-type="fig">Figure 4</xref>.</p></caption>
<graphic xlink:href="565833v1_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7.</label>
<caption><p>Classification accuracy for <italic>observation trajectory segments</italic> projected into instantaneous <italic>execution subspaces</italic><bold>. A.</bold> Instruction trajectory segments. <bold>B.</bold> Go segments. <bold>C.</bold> Movement segments. <bold>D.</bold> Hold segments. The format of each frame is the same as that described for <xref rid="fig4" ref-type="fig">Figure 4</xref>.</p></caption>
<graphic xlink:href="565833v1_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>In neither monkey F or monkey R did either of these cross-projections show peaks of classification accuracy near the times of the behavioral events at which the trajectory segments were taken, as were previously seen in <xref rid="fig4" ref-type="fig">Figure 4</xref> and <xref rid="fig5" ref-type="fig">Figure 5</xref>. Furthermore, at no time point did the classification accuracy in either cross-projection of the Instruction, Go, Movement, or Hold trajectory segments in either monkey F or monkey R exceed that expected from chance alone.</p>
<p>Only in monkey T did these cross-projections provide some classification accuracy beyond that expected from chance alone. In both cross-projections, the Instruction trajectory segments showed a brief peak shortly after instruction onset which was smaller (∼0.5) than the corresponding peak found with either self-projection (∼0.7). In both cross-projections, classification accuracy of both the Go and Movement segments rose shortly after instruction onset and remained elevated through the instruction and delay epochs, though exceeding chance only inconsistently. At no time point did the classification accuracy in either cross- projection of the Hold trajectory segments exceed that expected from chance alone upper bound. In neither cross-projection for monkey T did classification accuracy of the Go, Movement, or Hold trajectory segments show a peak near the time of the corresponding behavioral event. We infer that, although in monkey T the instantaneous subspaces through which PM mirror neuron population trajectories shifted showed some degree of similarity during execution and observation trials, in general, PM mirror neurons progressively shifted through different subspaces during execution versus observation.</p>
</sec>
<sec id="s2e">
<title>Execution-observation trajectory alignment</title>
<p>Having found little evidence that execution trajectory segments have decodable projections in instantaneous observation subspaces or vice versa, we asked whether execution and observation trajectory segments, each in their own instantaneous subspace, could be aligned. Such alignment would indicate that neural representations of trials involving the four objects were similarly related to one another during execution and observation, even though they occurred in different subspaces. For example, even though the set of recorded neurons changes from day to day altering the neural state space, the neural trajectories obtained from recordings made on different days during the same during center-out reaching movements can be aligned, indicating corresponding neural representations on both days (<xref ref-type="bibr" rid="c10">Gallego et al., 2020</xref>).</p>
<p>We therefore applied canonical correlation analysis (CCA, see Methods) to align the trajectories of observation trials with those of execution trials in the same recording session. For example, trial-averaged Hold trajectory segments in their original execution and observation subspaces before alignment are shown in <xref rid="fig8" ref-type="fig">Figure 8A</xref>, and after alignment in <xref rid="fig8" ref-type="fig">Figure 8B</xref>. In the original execution subspace, the order of the trajectory segments from lower left to upper right is yellow-cyan-magenta-purple, whereas the order in the observation subspace is purple- cyan-yellow-magenta. But after alignment, both execution and observation trajectories are ordered yellow-cyan-magenta-purple.</p>
<fig id="fig8" position="float" orientation="portrait" fig-type="figure">
<label>Figure 8.</label>
<caption><p>Alignment of execution and observation trajectory segments. <bold>A.</bold> Hold trajectory segments from execution trials are shown in the original instantaneous execution subspace at time H (left), and from observation trials in the original instantaneous observation subspace also at time H (right). <bold>B.</bold> After alignment, both execution (left) and observation (right) segments have been projection into the original execution subspace. Colors indicate trajectory segments from trials involving the sphere – purple, button – cyan, coaxial cylinder – magenta, perpendicular cylinder – yellow.</p></caption>
<graphic xlink:href="565833v1_fig8.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We aligned the Instruction trajectory segments from execution and observation trials and used a bootstrapping approach to evaluate the variability of this alignment. For each of 500 iterations, we randomly selected with replacement 20 execution trials and 20 observation trials involving each of the 4 objects. We projected these Instruction trajectory segments into the instantaneous subspace that provided the maximal LSTM classification accuracy using all execution or all observation trials, respectively. We then applied CCA to align the trajectories of those 80 execution trials and 80 observation trials. This process was repeated separately for Go, Movement, and Hold segments.</p>
<p>The red scatter plots and marginal histograms in <xref rid="fig9" ref-type="fig">Figure 9</xref> illustrate the resulting distributions of bootstrapped correlation coefficients in the two CCA dimensions for one session. The aligned Instruction and Go trajectory segments were highly correlated in the 1<sup>st</sup> CCA dimension (mean bootstrapped r = 0.95 and 0.96, respectively), but not in the 2<sup>nd</sup> CCA dimension (mean bootstrapped r = 0.19 and 0.22, respectively). The Movement and Hold trajectory segments showed slightly less correlation in the 1<sup>st</sup> dimension (mean bootstrapped r = 0.73 and 0.89, respectively), but increased correlation in the 2<sup>nd</sup> dimension (mean bootstrapped r = 0.38 and 0.55, respectively). Overall, the alignment of the execution and observation trajectories thus increased for the Movement and Hold segments as compared to the Instruction and Go segments, becoming highest for the Hold segments.</p>
<fig id="fig9" position="float" orientation="portrait" fig-type="figure">
<label>Figure 9.</label>
<caption><p>Alignment of latent dynamics (trajectory segments)<bold>. A.</bold> Instruction trajectory segments. <bold>B.</bold> Go segments. <bold>C.</bold> Movement segments. <bold>D.</bold> Hold segments. Two-dimensional and marginal distributions are shown of the 1<sup>st</sup> versus 2<sup>nd</sup> correlation coefficients from 500 repetitions of aligning each set of trajectory segments separately. Values for alignment of execution and observation segments from the same session (F_20200804) are shown in red; values for alignment of execution segments from two sessions two days apart (F_20200804, F_20200806) are shown in gray. Wasserstein distances between the marginal distributions in the 1<sup>st</sup> and 2<sup>nd</sup> dimensions are given as d1 and d2 at the upper left of each plot.</p></caption>
<graphic xlink:href="565833v1_fig9.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="fig10" position="float" orientation="portrait" fig-type="figure">
<label>Figure 10.</label>
<caption><p>Recording array locations in <bold>A.</bold> Monkey F. <bold>B.</bold> Monkey R. <bold>C.</bold> Monkey T. PCD – precentral dimple; AS – arcuate sulcus; CS – central sulcus; r – rostral; m – medial. Scale bars apply to all three monkeys.</p></caption>
<graphic xlink:href="565833v1_fig10.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>For comparison, we performed similar alignment of trajectory using execution trials from two different sessions from the same monkey recorded 2 days apart. The gray scatter plots and marginal histograms in <xref rid="fig9" ref-type="fig">Figure 9</xref> illustrate the results of this execution-execution alignment. The aligned Instruction trajectory segments were moderately correlated in the 1<sup>st</sup> CCA dimension (mean bootstrapped r = 0.76), but not in the 2<sup>nd</sup> CCA dimension (mean bootstrapped r = 0.19).</p>
<p>The Go, Movement and Hold trajectory segments were highly correlations in the 1<sup>st</sup> CCA dimension (mean bootstrapped r = 0.95, 0.91, and 0.93, respectively) and also showed increased correlations in the 2<sup>nd</sup> CCA dimension (mean bootstrapped r = 0.48, 0.79, and 0.78 respectively). Execution-execution alignment thus was no better than execution-observation alignment at the time of Instruction onset, but increased progressively thereafter, becoming greatest around the time of movement onset. At the time of instruction onset, execution- execution and execution-observation alignments were comparable, but the execution-execution alignment outcompeted execution-observation one gradually with the most prominent difference at movement epoch, which we termed ‘dynamical similarity’.</p>
<p>To quantify these differences in each CCA dimension, we calculated the Wasserstein distance (WSD, see Methods) between the marginal distributions. WSD values for the two dimensions (d1, d2) are given in the upper left corner of each panel in <xref rid="fig9" ref-type="fig">Figure 9</xref>. In this example, execution and observation neural trajectories from the same session (red), while showing better alignment for Movement and Hold than for Instruction and Go cue segments, did not align quite as well as execution neural trajectories from two different sessions.</p>
<p>To determine whether the examples of <xref rid="fig9" ref-type="fig">Figure 9</xref> were representative across the sessions from all three monkeys we compiled the correlation and WSD values across all sessions. Table 4 presents the average ± standard deviation for each mean bootstrapped correlation coefficient and WSD average across all sessions.</p>
<p>For execution-observation alignments within sessions CC1 did not vary significantly among the four trajectory segments (p = 0.16, h = 5.08, Kruskal-Wallis test), whereas CC2 did (p = 0.0035, h = 13.58, Kruskal-Wallis test). Post-hoc testing showed that CC2 was higher for Movement than Instruction trajectory segments, and higher for Hold than for either Instruction or Go segments (Dunn tests: M – I, p = 0.032; H – I, p = 0.0005; H – G, p = 0.014). Execution- observation alignment thus increased for trajectory segments later in the trials becoming highest for the Hold segments.</p>
<p>As for execution-observation alignments, CC1 for execution-execution alignments did not vary among the four trajectory segments (p = 0.15, h = 5.27, Kruskal-Wallis tests), whereas CC2 did (p = 5.30e-05, h = 22.4, Kruskal-Wallis test). Post-hoc testing showed that CC2 was higher for the Movement trajectory segments than for the Instruction or Go segments and higher for the Hold segments than for the Instruction segments (Dunn tests: M – I, p = 0.00001; M – G, p = 0.004; H – I, p = 0.001). While showing higher CC2 values than execution-observation alignment, execution-execution alignment also increased for trajectory segments later in the trial. But whereas execution-observation alignment was greatest for the Hold, execution- execution alignment was greatest for the Movement trajectory segments.</p>
<p>The WSDs for CC1 did not vary among the Instruction, Go, Movement, and Hold trajectory segments (p = 0.073, h = 6.96, Kruskal-Wallis test), whereas the WSDs for CC2 did (p = 0.00015, h = 20.3, Kruskal-Wallis test). Post-hoc testing showed that the WSDs for CC2 differed for all pairwise combinations of segments except G – H (Dunn tests, p &lt; 0.05). The quantitative difference in execution-observation versus execution-execution alignment thus increased as trials progressed, becoming greatest for the Movement segments.</p>
<p>In summary, CCA showed that the neural trajectory segments during execution and observation were less well aligned than trajectory segments during two execution sessions. However, the alignment of neural representations during execution and observation, like that during two execution sessions, increased as behavioral trials progressed.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>We developed a novel approach to examine the progressive shifting of the neural state over the time course of behavioral trials involving reach, grasp, and manipulation. Rather than examining neural trajectories in fixed subspaces that captured their entire time course, we sampled brief (100 ms) segments of the neural trajectories at the times of four well-defined behavioral events and then projected these trajectory segments into each of a time series of instantaneous subspaces.</p>
<p>Using this approach, we found that PM MN populations recruit progressively shifting subspaces as monkeys both execute and observe RGM movements. The progressive shifting of the instantaneous subspace found here during execution trials resembles that found previously using fractional overlap of condition-dependent variance in M1 neuron populations (<xref ref-type="bibr" rid="c27">Rouse and Schieber, 2018</xref>). Although the progressive shifting described here is equivalent to progressive <italic>rotation of the subspace</italic>, we use the word ‘shift’ to contrast with the <italic>rotation of the neural trajectory</italic> in a fixed subspace described in other studies, particularly those using jPCA (<xref ref-type="bibr" rid="c3">Churchland et al., 2012</xref>; <xref ref-type="bibr" rid="c28">Russo et al., 2020</xref>).</p>
<p>Here, we found that progressive shifting of the condition-dependent subspace of PM MNs occurred as well when the monkey observed RGM trials performed by an experimenter. The instantaneous subspaces during execution and during observation were distinct, however. Yet despite this difference, execution and observation trajectory segments could be aligned, particularly the Movement and Hold segments, indicating corresponding representations of the four different RGM movements in the two behavioral contexts.</p>
<p>Corresponding representations of action execution and observation during task epochs with higher neural firing rates have been found previously in PMd MNs and in PMv MNs using representational similarity analysis (<xref ref-type="bibr" rid="c22">Papadourakis and Raos, 2019</xref>). Our approach, however, enabled a more continuous examination of the temporal evolution of this correspondence. We used the classification accuracy of LSTM decoding as a measure of the similarity of each instantaneous subspace to the subspace at the time trajectory segments were sampled. While the values obtained at most time points were less than 3 standard deviations from the mean of random subspaces, we nevertheless found the systematic temporal evolution of classification accuracy to be informative about the progressive shifting of the instantaneous subspace over the course of the trial.</p>
<sec id="s3a">
<title>Features of subspace shifting during execution and observation</title>
<p>Projection of trajectory segments sampled in the 100 ms following instruction onset (at time I) showed a short-lived peak, reminiscent of the short bursts of “signal” discharge known to occur in a substantial fraction of PMd neurons following an instructional stimulus (<xref ref-type="bibr" rid="c35">Weinrich et al., 1984</xref>; <xref ref-type="bibr" rid="c4">Cisek and Kalaska, 2004</xref>). These peaks in each monkey were quite similar in their time course for execution and observation. They began to rise from their baseline ∼100 ms before instruction onset, indicating that the instantaneous subspace already was shifting toward the subspace that could be anticipated at the time the instruction would appear. This early shift indicates that the anticipatory activity often seen in single neurons is not entirely non-specific (<xref ref-type="bibr" rid="c19">Mauritz and Wise, 1986</xref>), but rather represents a positioning of the neural population to receive the anticipated instruction. This peak declined rapidly after instruction onset, reaching baseline levels before the end of the Instruction epoch, except in monkey T where classification accuracy remained slightly above baseline through the delay and reaction epochs. The instantaneous subspace thus quickly shifted away from the Instruction subspace that was present just after instruction onset.</p>
<p>The firing rates of MNs in both PMv and PMd have been shown previously to modulate during preparatory delay periods in anticipation of a Go cue (<xref ref-type="bibr" rid="c4">Cisek and Kalaska, 2004</xref>; <xref ref-type="bibr" rid="c18">Maranesi et al., 2014</xref>). The present findings provide additional insight into this delay epoch activity. As the 500 ms instruction epoch ended, shifting of the subspace came to differ in execution versus observation contexts. During execution trials, the instantaneous subspace in all three monkeys began to shift toward both the subspace which would be present at time G and that which would be present at time M. This progressed steadily through the delay period. In monkey T, this progressive shift additionally was preceded by an abrupt shift in the subspace ∼100 ms after instruction onset. This abrupt shift rendered the instantaneous subspace in monkey T partially similar to the I, G, and M subspaces simultaneously. After time G, the instantaneous subspace in each monkey shifted toward that at time M, and after time M, toward that at time H. In contrast to the subspaces at times G and M, the instantaneous subspace did not begin to shift toward that present at time H during the delay epoch, beginning instead until just before movement onset.</p>
<p>During observation trials, the shift of the instantaneous subspace toward that present at the time of the Instruction was quite similar to that found during execution trials. In contrast, the progressive shifts toward the Go, Movement, and Hold subspaces during observation were short-lived compared to those during execution. Nevertheless, these shifts began ∼100 ms or more prior to each of the four events in all three monkeys, indicating that during observation the PM MN population predicted rather than responded to the behavior performed by the experimenter. Although in monkey T an abrupt shift toward the Go and Movement subspaces again occurred ∼100 ms after instruction onset, progressive shifts toward these subspaces did not progress through the delay epoch, and instead began only shortly before each event, with progressive shifts away from each event subspace occurring as rapidly as away from the Instruction subspace. Likewise, the progressive shift of the instantaneous subspace toward the Hold subspace did not begin until after movement onset when the experimenter’s movement was already underway, though still predictive of the Hold per se.</p>
<p>During execution of a reaching task, condition-dependent subspaces are orthogonal during the preparatory delay versus movement epochs (<xref ref-type="bibr" rid="c14">Kaufman et al., 2014</xref>; <xref ref-type="bibr" rid="c8">Elsayed et al., 2016</xref>). In contrast, our findings suggest that in the present RGM task the condition-dependent subspace during the preparatory delay epoch was not entirely orthogonal to that during the movement epoch. Rather, the condition-dependent subspace shifted progressively closer to the Movement subspace as the delay and reaction epochs proceeded. This difference may reflect differences in reaching without grasping versus the present RGM movements. These previous studies, however, specifically identified preparatory and movement subspaces optimized to be orthogonal to one another, while the present approach did not.</p>
</sec>
<sec id="s3b">
<title>Distinct representations of execution and observation</title>
<p>Mirror neurons originally were thought to provide highly congruent neural representations of action execution and action observation. Our cross projections of execution trajectory segments into instantaneous observation subspaces and vice versa (<xref rid="fig6" ref-type="fig">Figures 6</xref> &amp; 7) indicate, however, that the condition-dependent subspaces traversed by PM MNs during the present RGM trials were distinct during execution and observation. The present findings are consistent with recent studies that have emphasized the considerable fraction of neurons with non-congruent activity in these two contexts, as well as differences in neural population activity during action execution versus action observation (<xref ref-type="bibr" rid="c13">Jiang et al., 2020</xref>; <xref ref-type="bibr" rid="c24">Pomper et al., 2023</xref>). As more situations have been investigated, the number of conditions needed to define a true mirror neuron in the strict sense of being entirely congruent has grown, making the duration of such congruence brief and/or its likelihood comparable to chance (<xref ref-type="bibr" rid="c22">Papadourakis and Raos, 2019</xref>; <xref ref-type="bibr" rid="c24">Pomper et al., 2023</xref>). True mirror neurons in the strictly congruent sense thus become something akin to grandmother cells (<xref ref-type="bibr" rid="c2">Bowers et al., 2019</xref>). While small numbers of such neurons might exist, their rarity precludes analysis of substantial populations, and we therefore have considered all neurons modulated significantly during both action execution and action observation as mirror neurons.</p>
<p>Two of the present monkeys, F and R, showed no appreciable cross projection of either execution trajectories into observation subspaces or observation trajectories into execution subspaces, indicating that the subspaces during execution and observation were orthogonal to one another. For both cross projections, however, monkey T’s PM MNs did show a brief peak in classification accuracy ∼100 ms after instruction onset for cross-projected Instruction segments, and for cross-projected Go or Movement segments an abrupt increase in classification accuracy after instruction onset followed by a plateau sustained into the reaction epoch. No peaks were present, however, near the time of the go cue, movement onset or hold. Nevertheless, these findings suggest that the condition-dependent instantaneous subspaces in monkey T were shared partially during execution and observation. Although monkey T might be considered the outlier, we note that nearly twice as many PM MNs were recorded in monkey T as compared to monkey F or R. These findings in monkey T of a shared subspace containing part of the condition-dependent PM MN activity, with other activity in distinct (orthogonal) execution or observation subspaces are consistent with a recent study examining the subspaces containing the entire temporal trajectories of PMd/M1 MNs during center-out reaching movements (<xref ref-type="bibr" rid="c13">Jiang et al., 2020</xref>).</p>
<p>That neural representations of execution versus observation are distinct is not surprising given that the brain clearly is able to distinguish the same action performed in the two contexts. Nevertheless, we found that trajectory segments—which represent the predominant modes of co-modulation among PM MNs—could be aligned during execution and observation. The alignment between execution and observation segments from the same session was not as strong as alignment between execution segments from two different session. The weaker alignment of execution-observation trajectory segments may have resulted simply from the lower firing rates of PM MNs typically found during observation as compared to execution trials (<xref ref-type="bibr" rid="c9">Ferroni et al., 2021</xref>). Like execution-execution alignment, however, execution-observation alignment became stronger as trials progressed from Instruction, to Go, to Movement, to Hold, reflecting distinct neural representations for the two behavioral contexts with dynamical similarity.</p>
</sec>
<sec id="s3c">
<title>The role of mirror neuron populations</title>
<p>Although we did not track extraocular movements, video monitoring demonstrated that our monkeys remained attentive, actively scanning the visual environment throughout the blocks of observation trials. Though perhaps not following the experimenter’s movements closely with eye movements, the present results in and of themselves demonstrate that during observation trials the PM MN population was processing information on both the sequential epochs of the behavioral task (<xref ref-type="bibr" rid="c20">Mazurek et al., 2018</xref>), as well as the object to which the experimenter’s actions were directed on each trial. Moreover, ∼100-200 ms before the Instruction onset, the Go cue, or Movement onset, when the experimenter had not yet begun to move, the instantaneous subspace of PM MNs began to shift toward the subspace that would be present at the time of each of those behavioral events. Though during observation such predictive activity is less intense and relatively short-lived compared to execution, these findings are consistent with the notion that the PM MN population predictively represents the sequence of behavioral events during observation trials (<xref ref-type="bibr" rid="c15">Kilner et al., 2007</xref>; <xref ref-type="bibr" rid="c18">Maranesi et al., 2014</xref>; <xref ref-type="bibr" rid="c9">Ferroni et al., 2021</xref>).</p>
<p>Yet if the representations of executed versus observed actions are distinct, how can the PM MN population nevertheless predictively represent that the same action is being performed by the subject and by another individual? Two features of population activity may provide such representation. First, the similar structure of the execution and observation population activity revealed by alignment of their latent dynamics through CCA may constitute a neural representation of the same action independent of the actor. Second, whereas the present analyses as well as others have focused on the condition-dependent variance in MN population activity (<xref ref-type="bibr" rid="c13">Jiang et al., 2020</xref>), still other studies that have not separated the condition-dependent versus condition-independent variance in neural activity have described more similar neural dynamics during execution and observation (<xref ref-type="bibr" rid="c20">Mazurek et al., 2018</xref>; <xref ref-type="bibr" rid="c12">Jerjian et al., 2020</xref>; <xref ref-type="bibr" rid="c23">Pezzulo et al., 2022</xref>). We speculate that while condition-dependent activity may represent particular movement types within a class of actions in a manner that differs depending on the actor, the condition-independent variance may provide a neural representation of a class of actions independent of the actor. Testing this hypothesis experimentally may require neural data from the same individuals performing and observing substantially different classes of actions.</p>
</sec>
</sec>
<sec id="s4">
<title>Methods</title>
<p>Three Rhesus monkeys, F, R and T (an 11 kg male, a 6 kg female, and a 10 kg male, <italic>Macaca mulatta</italic>) were used in the present study. All procedures for the care and use of these non- human primates followed the Guide for the Care and Use of Laboratory Animals and were approved by the University Committee on Animal Resources at the University of Rochester, Rochester, New York.</p>
<sec id="s4a">
<title>Execution trials</title>
<p>Each monkey was trained to perform a Reach-Grasp-Manipulate (RGM) task (<xref rid="fig2" ref-type="fig">Figure 2</xref>). Prior to each trial a ring of blue LEDs was illuminated around the pole supporting a center object and a 4 kHz tone began, both signaling the end of an inter-trial interval and the opportunity to begin a new trial. The monkey initiated the following sequence by pulling the center object for an initial hold epoch of variable duration (500-1000 ms). A ring of blue LEDs around the pole supporting one of four peripheral objects then was illuminated instructing the monkey as to the target object for the current trial. After 500 ms these instruction LEDs were extinguished, and the monkey was required to wait for a preparatory delay epoch lasting 500-2000 ms. At the end of this preparatory delay epoch, the blue LEDs for the center object were extinguished and the 4 kHz tone ceased, providing a “Go” cue. The monkey then reached to, grasped, and manipulated the remembered target object: turning a sphere, pushing a button, pulling a coaxial cylinder, or pulling a perpendicular cylinder. Once the instructed object had been manipulated, a ring of green LEDs around the object illuminated (indicating successful manipulation of the object) and the ring of blue LEDs for that object also illuminated (indicating correct object). The monkey then was required to hold the instructed object in its manipulated position for a final hold epoch of 1000 ms, after which the blue LEDs were extinguished. (The green LEDs extinguished whenever the monkey released the object.) After a 300 ms delay, the monkey received a liquid reward on each successful trial.</p>
<p>The selection and sequence of target objects in successive trials was controlled by custom software (Unified Task Control System, Gil Rivlis), which also 1) generated behavior event marker codes (<xref rid="fig2" ref-type="fig">Figure 2B</xref>), and 2) arranged trials involving the four different objects in a pseudorandom block design. The behavior event marker codes marked the times at which specific behavioral events occurred: Start of trial, Instruction onset, Instruction offset, Go cue (delay epoch ended), Movement onset, Hold began, Hold ended, End of trial. One trial involving each of the four different objects was presented sequentially in a block. Once a block had been completed, the sequence of the four objects was shuffled randomly for the next block. To prevent the monkey from skipping more difficult objects, if the monkey failed to complete a trial successfully the same target was repeated until the monkey succeeded.</p>
</sec>
<sec id="s4b">
<title>Observation trials</title>
<p>In a separate block of trials, the monkey observed an experimenter performing the same RGM task. The experimenter occasionally made errors intentionally. The monkey received a reward each time the experimenter performed a successful trial, but not when the experimenter made an error, which kept the monkey attentive to the experimenter’s performance. Although extraocular movements were not recorded or controlled, video monitoring verified that the monkey remained alert and attentive throughout blocks of observation trials.</p>
</sec>
<sec id="s4c">
<title>Neuron Recording</title>
<p>The three monkeys each were implanted with Floating Microelectrode Arrays (FMAs, Microprobes for Life Sciences), in the ventral premotor cortex (PMv) and in the dorsal premotor cortex (PMd). In monkey F, 32-channel FMAs were used; in monkeys R and T, 16-channel FMAs were used. Monkeys F and R each had a total of 64 recording electrodes implanted in PMd and 64 in PMv, whereas monkey T had 64 in PMd, but only 48 in PMv. Broadband signals were recorded simultaneously from all 128 electrodes using a Nomad/Trellis data acquisition system (Ripple, Salt Lake City, UT), which also recorded the behavioral event marker codes generated by the behavioral control system. In each recording session, data were collected during similar numbers of successful trials involving each target object during execution and then during observation, as summarized in <xref rid="tbl2" ref-type="table">Table 2</xref>. Off-line, spike waveforms were extracted and sorted using custom software. Sorted units were classified as definite single units, probably single units, multi-units, or noise based on their signal-to-noise ratio and estimated false-positive fraction using previously published criteria (Rouse and Schieber, 2016).</p>
</sec>
<sec id="s4d">
<title>Mirror Neuron Identification</title>
<p>Each definite single unit, probable single unit or multi-unit was tested for task-related modulation. Because a given neuron’s firing rates during execution and observation trials almost always differed (<xref ref-type="bibr" rid="c9">Ferroni et al., 2021</xref>; <xref ref-type="bibr" rid="c24">Pomper et al., 2023</xref>), we tested each unit for modulation using data from these two contexts separately. Spike counts from each successful behavioral trial were extracted during eleven 200 ms periods: i) before instruction onset, ii) after instruction onset, iii) before instruction offset, iv) after instruction offset (delay began), v) before delay ended, vi) after delay ended (reaction time began), vii) before movement onset, viii) after movement onset (movement time began), ix) before movement ended, x) after movement ended (final hold began), xi) hold ended. We then conducted two-way rmANOVAs on these spike counts using object and time period as factors. We considered a unit task-related if it showed a significant main effect of either i) object or ii) time period, or a significant iii) interaction effect. Any unit modulated significantly both during execution and during observation was considered to be a mirror neuron. Because each unit thus had six opportunities to show significance, we used a corrected significance criterion of p&lt;0.0083 (=0.05/6).</p>
</sec>
<sec id="s4e">
<title>Data analysis</title>
<p>Spike times for each neuron were binned (bin width = 1 ms), smoothed with a Gaussian kernel (σ = 50 ms) and square-root transformed to render variance similar from low to high firing rates. The activity of each neuron was time-aligned to four behavior events and truncated before and after using the median delay, reaction, and movement times per object and per session as follows: i) instruction onset (I)—500 ms before, 500 ms after; ii) go cue (G)—median delay duration before, half the median reaction time after; iii) movement onset (M)—half the median reaction time before, 200 ms after; and iv) start of final hold (H)—200 ms before, 200 ms after. These four snippets of neural activity were concatenated for each trial. Neural activity then was stored as a three-dimensional tensor (<italic>N</italic> x <italic>K</italic> x <italic>T</italic>, where <italic>N</italic> is number of neurons, <italic>K</italic> the number of trials, and <italic>T</italic> the number of time points) for each of four target objects.</p>
</sec>
<sec id="s4f">
<title>Instantaneous subspace identification</title>
<p>Instantaneous neural subspaces were identified separately using principal component analysis (PCA) of trial-averaged neural activity for each of the four objects at each 50 ms time step.</p>
<p>Because three dimensions capture all the variance of four points, three principal component dimensions defined each subspace. Each subspace can be considered a filter that provides a matrix, <italic>W</italic>, which can project high-dimensional neural activity into the low-dimensional subspace. Since subspaces favored different co-modulation patterns, they can be considered as a set of filters.</p>
</sec>
<sec id="s4g">
<title>Trajectory visualization and separation</title>
<p>We projected 100 ms segments of neural activity into each instantaneous subspace by multiplying the neural activity, <italic>X</italic>(<italic>t</italic>), by the transforming matrix for the <italic>i</italic><sup><italic>t</italic>ℎ</sup> subspace, <italic>W</italic><sub><italic>i</italic></sub> ,which yielded low dimensional trajectories, <italic>L</italic>(<italic>t</italic>) = <italic>X</italic>(<italic>t</italic>)<italic>W</italic><sub><italic>i</italic></sub> (<italic>t</italic> ∈ <italic>T</italic>). This process was repeated for each instantaneous subspace in the time domain of interest (<italic>t</italic> ∈ <italic>T</italic>).</p>
<p>To quantify the separation between the four trial-averaged trajectories from trials involving different objects in a given instantaneous subspace, we calculated their “cumulative separation” (<italic>CS</italic>) as:
<disp-formula>
<graphic xlink:href="565833v1_ueqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>d</italic><sub><italic>ij</italic></sub>(<italic>t</italic>) is the Euclidean distance between the <italic>i</italic><sup><italic>t</italic>ℎ</sup> and <italic>j</italic><sup><italic>t</italic>ℎ</sup> trajectories at time point <italic>t</italic>. We summed the 6 pairwise distances between the 4 trajectory segments across time points and normalized by the number of time points, <italic>T</italic>. The larger the <italic>CS</italic>, the greater the separation of the trajectory segments.</p>
</sec>
<sec id="s4h">
<title>Subspace Comparisons</title>
<p>As illustrated schematically in <xref rid="fig1" ref-type="fig">Figures 1B</xref>, the same segment of high-dimensional neural activity projected into different instantaneous subspaces can generate low-dimensional trajectories of varying separation. The degree of separation will depend on the similarity of the subspaces into which the neural activity is projected. To quantify this separation, we projected trajectory segments into time series of instantaneous subspaces and trained a separate long short-term memory (LSTM) classifier for each subspace in the time series. Using MATLAB’s Deep Learning Toolbox, each classifier was trained on 40% of the trials available (using equal numbers of trials involving each of the four objects). The remaining 60% of the available trials were decoded by the trained classifier. This process was repeated 10 times and the mean ± standard deviation fraction correct across the 10 folds was reported as the classification accuracy at that time. Classification accuracy was plotted as a function of trial time.</p>
</sec>
<sec id="s4i">
<title>Similarity of aligned dynamics</title>
<p>We used Canonical Correlation Alignment (CCA) to compare the similarity of latent dynamics (Gallego et al., 2018, <xref ref-type="bibr" rid="c10">2020</xref>; Safaie et al., 2022). In brief, given latent dynamics in two original spaces, <italic>L</italic><sub><italic>A</italic></sub> and <italic>L</italic><sub><italic>B</italic></sub>, CCA finds a linear transformation such that the “aligned” latent dynamics, <inline-formula><inline-graphic xlink:href="565833v1_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="565833v1_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, are maximumly correlated in each dimension of a common subspace. Larger canonical correlations (CCs) indicate a higher degree of similarity.</p>
<p>We calculated the CCs between execution and observation trials from the same session and compared them to the CCs between execution trials from two different sessions. We used a bootstrapping approach to assess the variability of the resulting correlation coefficients. We randomly selected 20 trials involving each target object (totaling 80 trials) in each data set with replacement, extracted data from each trial during one of four task intervals (instruction, go cue, movement, and hold), and performed CCA. With 500 iterations, we obtained a distribution of the CCs between the two data sets in each of two dimensions.</p>
</sec>
<sec id="s4j">
<title>Wasserstein distance</title>
<p>We used Wasserstein distance to quantify the distance between two bootstrapped CC distributions. The Wasserstein distance (WSD), sometimes called the “earth-mover’s distance” or the “optimal transport plan” quantifies the distance between two probability distributions, irrespective of their underlying statistics (<xref ref-type="bibr" rid="c33">Vallender, 1974</xref>). Intuitively, the two distributions A and B can be considered to be two mounds of dirt. Distribution A can be transformed into B by moving dirt, which requires work, i.e. the product of an incremental mass of the dirt and the distance that increment must be moved, summed across all increments. The Wasserstein distance between A and B is the minimum possible total work. We used the SciPy stats.wasserstein_distance function to compute the WSD between the execution-observation CC distribution and the execution-execution CC for each CCA dimension. WSD was calculated separately for Instruction, Go, Movement, and Hold trajectory segments.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>The authors thank John Housel and Jennifer Gardinier for technical assistance, Gil Rivlis for custom task-control and stimulation control software. This work was supported by grant R01NS102343 (MHS) from the National Institute of Neurological Disorders and Stroke.</p>
</ack>
<ref-list>
<title>REFERNCES</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Ames</surname> <given-names>KC</given-names></string-name>, <string-name><surname>Ryu</surname> <given-names>SI</given-names></string-name>, <string-name><surname>Shenoy</surname> <given-names>KV</given-names></string-name> (<year>2014</year>) <article-title>Neural dynamics of reaching following incorrect or absent motor preparation</article-title>. <source>Neuron</source> <volume>81</volume>:<fpage>438</fpage>–<lpage>451</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Bowers</surname> <given-names>JS</given-names></string-name>, <string-name><surname>Martin</surname> <given-names>ND</given-names></string-name>, <string-name><surname>Gale</surname> <given-names>EM</given-names></string-name> (<year>2019</year>) <article-title>Researchers Keep Rejecting Grandmother Cells after Running the Wrong Experiments: The Issue Is How Familiar Stimuli Are Identified</article-title>. <source>Bioessays</source> <volume>41</volume>:<fpage>e1800248</fpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Churchland</surname> <given-names>MM</given-names></string-name>, <string-name><surname>Cunningham</surname> <given-names>JP</given-names></string-name>, <string-name><surname>Kaufman</surname> <given-names>MT</given-names></string-name>, <string-name><surname>Foster</surname> <given-names>JD</given-names></string-name>, <string-name><surname>Nuyujukian</surname> <given-names>P</given-names></string-name>, <string-name><surname>Ryu</surname> <given-names>SI</given-names></string-name>, <string-name><surname>Shenoy</surname> <given-names>KV</given-names></string-name> (<year>2012</year>) <article-title>Neural population dynamics during reaching</article-title>. <source>Nature</source> <volume>487</volume>:<fpage>51</fpage>–<lpage>56</lpage>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Cisek</surname> <given-names>P</given-names></string-name>, <string-name><surname>Kalaska</surname> <given-names>JF</given-names></string-name> (<year>2004</year>) <article-title>Neural correlates of mental rehearsal in dorsal premotor cortex</article-title>. <source>Nature</source> <volume>431</volume>:<fpage>993</fpage>–<lpage>996</lpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Cunningham</surname> <given-names>JP</given-names></string-name>, <string-name><surname>Yu</surname> <given-names>BM</given-names></string-name> (<year>2014</year>) <article-title>Dimensionality reduction for large-scale neural recordings</article-title>. <source>Nat Neurosci</source> <volume>17</volume>:<fpage>1500</fpage>–<lpage>1509</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>di Pellegrino</surname> <given-names>G</given-names></string-name>, <string-name><surname>Fadiga</surname> <given-names>L</given-names></string-name>, <string-name><surname>Fogassi</surname> <given-names>L</given-names></string-name>, <string-name><surname>Gallese</surname> <given-names>V</given-names></string-name>, <string-name><surname>Rizzolatti</surname> <given-names>G</given-names></string-name> (<year>1992</year>) <article-title>Understanding motor events: a neurophysiological study</article-title>. <source>Experimental Brain Research</source> <volume>91</volume>:<fpage>176</fpage>–<lpage>180</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Dushanova</surname> <given-names>J</given-names></string-name>, <string-name><surname>Donoghue</surname> <given-names>J</given-names></string-name> (<year>2010</year>) <article-title>Neurons in primary motor cortex engaged during action observation</article-title>. <source>Eur J Neurosci</source> <volume>31</volume>:<fpage>386</fpage>–<lpage>398</lpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Elsayed</surname> <given-names>GF</given-names></string-name>, <string-name><surname>Lara</surname> <given-names>AH</given-names></string-name>, <string-name><surname>Kaufman</surname> <given-names>MT</given-names></string-name>, <string-name><surname>Churchland</surname> <given-names>MM</given-names></string-name>, <string-name><surname>Cunningham</surname> <given-names>JP</given-names></string-name> (<year>2016</year>) <article-title>Reorganization between preparatory and movement population responses in motor cortex</article-title>. <source>Nat Commun</source> <volume>7</volume>:<fpage>13239</fpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Ferroni</surname> <given-names>CG</given-names></string-name>, <string-name><surname>Albertini</surname> <given-names>D</given-names></string-name>, <string-name><surname>Lanzilotto</surname> <given-names>M</given-names></string-name>, <string-name><surname>Livi</surname> <given-names>A</given-names></string-name>, <string-name><surname>Maranesi</surname> <given-names>M</given-names></string-name>, <string-name><surname>Bonini</surname> <given-names>L</given-names></string-name> (<year>2021</year>) <article-title>Local and system mechanisms for action execution and observation in parietal and premotor cortices</article-title>. <source>Curr Biol</source> <volume>31</volume>:<fpage>2819</fpage>–<lpage>2830</lpage> e2814.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Gallego</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Perich</surname> <given-names>MG</given-names></string-name>, <string-name><surname>Chowdhury</surname> <given-names>RH</given-names></string-name>, <string-name><surname>Solla</surname> <given-names>SA</given-names></string-name>, <string-name><surname>Miller</surname> <given-names>LE</given-names></string-name> (<year>2020</year>) <article-title>Long-term stability of cortical population dynamics underlying consistent behavior</article-title>. <source>Nat Neurosci</source> <volume>23</volume>:<fpage>260</fpage>–<lpage>270</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Gallese</surname> <given-names>V</given-names></string-name>, <string-name><surname>Fadiga</surname> <given-names>L</given-names></string-name>, <string-name><surname>Fogassi</surname> <given-names>L</given-names></string-name>, <string-name><surname>Rizzolatti</surname> <given-names>G</given-names></string-name> (<year>1996</year>) <article-title>Action recognition in the premotor cortex</article-title>. <source>Brain</source> <volume>119</volume>:<fpage>593</fpage>–<lpage>609</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Jerjian</surname> <given-names>SJ</given-names></string-name>, <string-name><surname>Sahani</surname> <given-names>M</given-names></string-name>, <string-name><surname>Kraskov</surname> <given-names>A</given-names></string-name> (<year>2020</year>) <article-title>Movement initiation and grasp representation in premotor and primary motor cortex mirror neurons</article-title>. <source>Elife</source> <volume>9</volume>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>Jiang</surname> <given-names>X</given-names></string-name>, <string-name><surname>Saggar</surname> <given-names>H</given-names></string-name>, <string-name><surname>Ryu</surname> <given-names>SI</given-names></string-name>, <string-name><surname>Shenoy</surname> <given-names>KV</given-names></string-name>, <string-name><surname>Kao</surname> <given-names>JC</given-names></string-name> (<year>2020</year>) <article-title>Structure in Neural Activity during Observed and Executed Movements Is Shared at the Neural Population Level, Not in Single Neurons</article-title>. <source>Cell Rep</source> <volume>32</volume>:<fpage>108006</fpage>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Kaufman</surname> <given-names>MT</given-names></string-name>, <string-name><surname>Churchland</surname> <given-names>MM</given-names></string-name>, <string-name><surname>Ryu</surname> <given-names>SI</given-names></string-name>, <string-name><surname>Shenoy</surname> <given-names>KV</given-names></string-name> (<year>2014</year>) <article-title>Cortical activity in the null space: permitting preparation without movement</article-title>. <source>Nat Neurosci</source> <volume>17</volume>:<fpage>440</fpage>–<lpage>448</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Kilner</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Friston</surname> <given-names>KJ</given-names></string-name>, <string-name><surname>Frith</surname> <given-names>CD</given-names></string-name> (<year>2007</year>) <article-title>Predictive coding: an account of the mirror neuron system</article-title>. <source>Cogn Process</source> <volume>8</volume>:<fpage>159</fpage>–<lpage>166</lpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Kraskov</surname> <given-names>A</given-names></string-name>, <string-name><surname>Dancause</surname> <given-names>N</given-names></string-name>, <string-name><surname>Quallo</surname> <given-names>MM</given-names></string-name>, <string-name><surname>Shepherd</surname> <given-names>S</given-names></string-name>, <string-name><surname>Lemon</surname> <given-names>RN</given-names></string-name> (<year>2009</year>) <article-title>Corticospinal neurons in macaque ventral premotor cortex with mirror properties: a potential mechanism for action suppression?</article-title> <source>Neuron</source> <volume>64</volume>:<fpage>922</fpage>–<lpage>930</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Kraskov</surname> <given-names>A</given-names></string-name>, <string-name><surname>Philipp</surname> <given-names>R</given-names></string-name>, <string-name><surname>Waldert</surname> <given-names>S</given-names></string-name>, <string-name><surname>Vigneswaran</surname> <given-names>G</given-names></string-name>, <string-name><surname>Quallo</surname> <given-names>MM</given-names></string-name>, <string-name><surname>Lemon</surname> <given-names>RN</given-names></string-name> (<year>2014</year>) <article-title>Corticospinal mirror neurons</article-title>. <source>Philos Trans R Soc Lond B Biol Sci</source> <volume>369</volume>:<fpage>20130174</fpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Maranesi</surname> <given-names>M</given-names></string-name>, <string-name><surname>Livi</surname> <given-names>A</given-names></string-name>, <string-name><surname>Fogassi</surname> <given-names>L</given-names></string-name>, <string-name><surname>Rizzolatti</surname> <given-names>G</given-names></string-name>, <string-name><surname>Bonini</surname> <given-names>L</given-names></string-name> (<year>2014</year>) <article-title>Mirror neuron activation prior to action observation in a predictable context</article-title>. <source>J Neurosci</source> <volume>34</volume>:<fpage>14827</fpage>–<lpage>14832</lpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Mauritz</surname> <given-names>KH</given-names></string-name>, <string-name><surname>Wise</surname> <given-names>SP</given-names></string-name> (<year>1986</year>) <article-title>Premotor cortex of the rhesus monkey: neuronal activity in anticipation of predictable environmental events</article-title>. <source>Experimental Brain Research</source> <volume>61</volume>:<fpage>229</fpage>–<lpage>244</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Mazurek</surname> <given-names>KA</given-names></string-name>, <string-name><surname>Rouse</surname> <given-names>AG</given-names></string-name>, <string-name><surname>Schieber</surname> <given-names>MH</given-names></string-name> (<year>2018</year>) <article-title>Mirror Neuron Populations Represent Sequences of Behavioral Epochs During Both Execution and Observation</article-title>. <source>J Neurosci</source> <volume>38</volume>:<fpage>4441</fpage>–<lpage>4455</lpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Natraj</surname> <given-names>N</given-names></string-name>, <string-name><surname>Silversmith</surname> <given-names>DB</given-names></string-name>, <string-name><surname>Chang</surname> <given-names>EF</given-names></string-name>, <string-name><surname>Ganguly</surname> <given-names>K</given-names></string-name> (<year>2022</year>) <article-title>Compartmentalized dynamics within a common multi-area mesoscale manifold represent a repertoire of human hand movements</article-title>. <source>Neuron</source> <volume>110</volume>:<fpage>154</fpage>-+.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Papadourakis</surname> <given-names>V</given-names></string-name>, <string-name><surname>Raos</surname> <given-names>V</given-names></string-name> (<year>2019</year>) <article-title>Neurons in the Macaque Dorsal Premotor Cortex Respond to Execution and Observation of Actions</article-title>. <source>Cereb Cortex</source> <volume>29</volume>:<fpage>4223</fpage>–<lpage>4237</lpage>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Pezzulo</surname> <given-names>G</given-names></string-name>, <string-name><surname>Donnarumma</surname> <given-names>F</given-names></string-name>, <string-name><surname>Ferrari-Toniolo</surname> <given-names>S</given-names></string-name>, <string-name><surname>Cisek</surname> <given-names>P</given-names></string-name>, <string-name><surname>Battaglia-Mayer</surname> <given-names>A</given-names></string-name> (<year>2022</year>) <article-title>Shared population-level dynamics in monkey premotor cortex during solo action, joint action and action observation</article-title>. <source>Prog Neurobiol</source> <volume>210</volume>:<fpage>102214</fpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Pomper</surname> <given-names>JK</given-names></string-name>, <string-name><surname>Shams</surname> <given-names>M</given-names></string-name>, <string-name><surname>Wen</surname> <given-names>S</given-names></string-name>, <string-name><surname>Bunjes</surname> <given-names>F</given-names></string-name>, <string-name><surname>Thier</surname> <given-names>P</given-names></string-name> (<year>2023</year>) <article-title>Non-shared coding of observed and executed actions prevails in macaque ventral premotor mirror neurons</article-title>. <source>Elife</source> <volume>12</volume>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Rizzolatti</surname> <given-names>G</given-names></string-name>, <string-name><surname>Craighero</surname> <given-names>L</given-names></string-name> (<year>2004</year>) <article-title>The mirror-neuron system</article-title>. <source>Annual Review of Neuroscience</source> <volume>27</volume>:<fpage>169</fpage>–<lpage>192</lpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>Rizzolatti</surname> <given-names>G</given-names></string-name>, <string-name><surname>Fadiga</surname> <given-names>L</given-names></string-name>, <string-name><surname>Gallese</surname> <given-names>V</given-names></string-name>, <string-name><surname>Fogassi</surname> <given-names>L</given-names></string-name> (<year>1996</year>) <article-title>Premotor cortex and the recognition of motor actions</article-title>. <source>Brain Research Cognitive Brain Rese</source>:<fpage>131</fpage>–<lpage>141</lpage>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>Rouse</surname> <given-names>AG</given-names></string-name>, <string-name><surname>Schieber</surname> <given-names>MH</given-names></string-name> (<year>2018</year>) <article-title>Condition-Dependent Neural Dimensions Progressively Shift during Reach to Grasp</article-title>. <source>Cell Rep</source> <volume>25</volume>:<fpage>3158</fpage>–<lpage>3168</lpage> e3153.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><string-name><surname>Russo</surname> <given-names>AA</given-names></string-name>, <string-name><surname>Khajeh</surname> <given-names>R</given-names></string-name>, <string-name><surname>Bittner</surname> <given-names>SR</given-names></string-name>, <string-name><surname>Perkins</surname> <given-names>SM</given-names></string-name>, <string-name><surname>Cunningham</surname> <given-names>JP</given-names></string-name>, <string-name><surname>Abbott</surname> <given-names>LF</given-names></string-name>, <string-name><surname>Churchland</surname> <given-names>MM</given-names></string-name> (<year>2020</year>) <article-title>Neural Trajectories in the Supplementary Motor Area and Motor Cortex Exhibit Distinct Geometries, Compatible with Different Classes of Computation</article-title>. <source>Neuron</source> <volume>107</volume>:<fpage>745</fpage>–<lpage>758</lpage> e746.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><string-name><surname>Shenoy</surname> <given-names>KV</given-names></string-name>, <string-name><surname>Sahani</surname> <given-names>M</given-names></string-name>, <string-name><surname>Churchland</surname> <given-names>MM</given-names></string-name> (<year>2013</year>) <article-title>Cortical control of arm movements: a dynamical systems perspective</article-title>. <source>Annu Rev Neurosci</source> <volume>36</volume>:<fpage>337</fpage>–<lpage>359</lpage>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>Sobinov</surname> <given-names>AR</given-names></string-name>, <string-name><surname>Bensmaia</surname> <given-names>SJ</given-names></string-name> (<year>2021</year>) <article-title>The neural mechanisms of manual dexterity</article-title>. <source>Nat Rev Neurosci</source> <volume>22</volume>:<fpage>741</fpage>–<lpage>757</lpage>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>Stark</surname> <given-names>E</given-names></string-name>, <string-name><surname>Asher</surname> <given-names>I</given-names></string-name>, <string-name><surname>Abeles</surname> <given-names>M</given-names></string-name> (<year>2007</year>) <article-title>Encoding of reach and grasp by single neurons in premotor cortex is independent of recording site</article-title>. <source>J Neurophysiol</source> <volume>97</volume>:<fpage>3351</fpage>–<lpage>3364</lpage>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><string-name><surname>Suresh</surname> <given-names>AK</given-names></string-name>, <string-name><surname>Goodman</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Okorokova</surname> <given-names>EV</given-names></string-name>, <string-name><surname>Kaufman</surname> <given-names>M</given-names></string-name>, <string-name><surname>Hatsopoulos</surname> <given-names>NG</given-names></string-name>, <string-name><surname>Bensmaia</surname> <given-names>SJ</given-names></string-name> (<year>2020</year>) <article-title>Neural population dynamics in motor cortex are different for reach and grasp</article-title>. <source>Elife</source> <volume>9</volume>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><string-name><surname>Vallender</surname> <given-names>S</given-names></string-name> (<year>1974</year>) <article-title>Calculation of the Wasserstein distance between probability distributions on the line</article-title>. <source>Theory of Probability &amp; Its Applications</source> <volume>18</volume>:<fpage>784</fpage>–<lpage>786</lpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Vigneswaran</surname> <given-names>G</given-names></string-name>, <string-name><surname>Philipp</surname> <given-names>R</given-names></string-name>, <string-name><surname>Lemon</surname> <given-names>RN</given-names></string-name>, <string-name><surname>Kraskov</surname> <given-names>A</given-names></string-name> (<year>2013</year>) <article-title>M1 corticospinal mirror neurons and their role in movement suppression during action observation</article-title>. <source>Curr Biol</source> <volume>23</volume>:<fpage>236</fpage>–<lpage>243</lpage>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>Weinrich</surname> <given-names>M</given-names></string-name>, <string-name><surname>Wise</surname> <given-names>SP</given-names></string-name>, <string-name><surname>Mauritz</surname> <given-names>KH</given-names></string-name> (<year>1984</year>) <article-title>A neurophysiological study of the premotor cortex in the rhesus monkey</article-title>. <source>Brain</source> <volume>107</volume>:<fpage>385</fpage>–<lpage>414</lpage>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94165.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Gallego</surname>
<given-names>Juan Alvaro</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Imperial College London</institution>
</institution-wrap>
<city>London</city>
<country>United Kingdom</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>valuable</bold> study reports on the characteristics of premotor cortical population activity during the execution and observation of a moderately complex reaching and grasping task. By using new variants of well-established techniques to analyse neural population activity, the authors provide <bold>solid</bold> evidence that while the geometry of neural population activity changes between execution and observation, their dynamics are largely preserved. While these observations are novel and robust barring the need for additional controls, the authors should do additional work to define the functional implications of their findings.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94165.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary and strengths. This paper starts with an exceptionally fair and balanced introduction to a topic, the mirror neuron literature, which is often debated and prone to controversies even in the choice of the terminology. In my opinion, the authors made an excellent job in this regard, and I really appreciated it. Then, they propose a novel method to look at population dynamics to compare neural selectivity and alignment between execution and observation of actions performed with different types of grip.</p>
<p>Weakness. Unfortunately, the goal and findings within this well-described framework are less clear to me. The authors aimed to investigate, using a novel analytic approach, whether and to what extent a match exists between population codes and neural dynamics when a monkey performs an action or observes it performed by an experimenter. This motivation stems from the fact that the general evidence in the literature is that the match between visual and motor selectivity of mirror neuron responses is essentially at a chance level. While the approach devised by the author is generally well-described and understandable, the main result obtained confirms this general finding of a lack of matching between the two contexts in 2 out of the three monkeys. Nevertheless, the authors claim that the patterns associated with execution and observation can be re-aligned with canonical correlation, indicating that these distinct neural representations show dynamical similarity that may enable the nervous system to recognize particular actions. This final conclusion is hardly acceptable to me, and constitutes my major concern, at least without a more explicit explanation: how do we know that this additional operation can be performed by the brain? Is this a computational trick to artificially align something that is naturally non-aligned, or can it capture something real and useful?</p>
<p>
Based on the accumulated evidence on space-constrained coding of others' actions by mirror neurons (e.g., Caggiano et al. 2009; Maranesi et al. 2017), recent evidence also cited by the authors (Pomper et al. 2023), and the most recent views supported even by the first author of the original discovery (i.e., Vittorio Gallese, see Bonini et al. 2022 on TICS), it seems that one of the main functions of these cells, especially in monkeys, might be to prepare actions and motor responses during social interaction rather than recognizing the actions of others - something that visual brain areas could easily do better than motor ones in most situations. In this perspective, and given the absence of causal evidence so far, the lack of visuo-motor congruence is a potentially relevant feature of the mechanism rather than something to be computationally cracked at all costs.</p>
<p>Specific comments on Results/Methods:</p>
<p>
I can understand, based on the authors' hypothesis, that they employed an ANOVA to preliminarily test whether and which of the recorded neurons fit their definition of &quot;mirror neurons&quot;. However, given the emphasis on the population level, and the consolidated finding of highly different execution and observation responses, I think it could be interesting to apply the same analysis on (at least also) the whole recorded neuronal population, without any preselection-based on a single neuron statistic. Such preselection of mirror neurons could influence the results of EXE-OBS comparisons since all the neurons activated only during EXE or OBS are excluded. Related to this point, the authors could report the total number of recorded neurons per monkey/session, so that also the fraction of neurons fitting their definition of mirror neuron is explicit.</p>
<p>
Furthermore, the comparison of the dynamics of the classification accuracy in figures 4 and 5, and therefore the underlying assumption of subspaces shift in execution and observation, respectively, reveal substantial similarities between monkeys despite the different contexts, which are clearly greater than the similarities among neural subspaces shifts across task epochs: to me, this suggests that the main result is driven by the selected neural populations in different monkeys/implants rather than by an essential property of the neuronal dynamics valid across animals. Could the author comment on this issue? This could easily explain the &quot;strange&quot; result reported in figure 6 for monkey T.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94165.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>In this work, the authors set out to identify time-varying subspaces in the premotor cortical activity of monkeys as they executed/observed a reach-grasp-hold movement of 4 different objects. Then, they projected the neural activity to these subspaces and found evidence of shifting subspaces in the time course of a trial in both conditions, executing and observing. These shifting subspaces appear to be distinct in execution and observation trials. However, correlation analysis of neural dynamics reveals the similarity of dynamics in these distinct subspaces. Taken together, Zhao and Schieber speculate that the condition-dependent activity studied here provides a representation of movement that relies on the actor.</p>
<p>
This work addresses an interesting question. The authors developed a novel approach to identify instantaneous subspaces and decoded the object type from the projected neural dynamics within these subspaces. As interesting as these results might be, I have a few suggestions and questions to improve the manuscript:</p>
<p>
1- Repeating the analyses in the paper, e.g., in Fig5, using non-MN units only or the entire population, and demonstrating that the results are specific to MNs would make the whole study much more compelling.</p>
<p>
2- The method presented here is similar and perhaps related to principal angles (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.2307/2005662">https://doi.org/10.2307/2005662</ext-link>). It would be interesting to confirm these results with principal angles. For instance, instead of using the decoding performance as a proxy for shifting subspaces, principal angles could directly quantify the 'shift' (similar to Gallego et al, Nat Comm, 2018). Relatedly, why the decoding of the 'object type' is used to establish the progressive shifting of the subspaces? I would be interested to see the authors' argument. The object type should be much more decodable during movement or hold, than instruction, which is probably why the chance-level decoding performance (horizontal lines) is twice the instruction segment for the movement segment.</p>
<p>
3- Why aren't execution and observation subspaces compared together directly? Especially given that there are both types of trials in the same session with the same recorded population of neurons. Using instantaneous subspaces, or the principal angles between manifolds during exec trials vs obs trials.</p>
<p>
4- The definition of the instantaneous subspaces is a critical point in the manuscript. I think it is slightly unclear: based on the Methods section #715-722 and the main text #173-#181, I gather that the subspaces are based on trial averaged neural activity for each of the 4 objects, separately. So for each object and per timepoint, a vector of size (1, n) -n neurons- is reduced to a vector of (1, 2 or 3 -the main text says 2, methods say 3-) which would be a single point in the low-d space. Is this description accurate? This should be clarified in the manuscript.</p>
<p>
5- Isn't the process of projecting segments of neural dynamics and comparing the results equivalent to comparing the projection matrices in the first place? If so, that might have been a more intuitive avenue to follow.</p>
<p>
6- Lines #385-#389: This process seems unnecessarily complicated. Also, given the number of trials available, this sometimes doesn't make sense. E.g. Monkey R exec has only 8 trials of one of the objects, so bootstrapping 20 trials 500 times would be spurious. Why not, as per Gallego et al, Nat Neurosci 2020 and Safaie et al, Nat 2023 which are cited, concatenate the trials?</p>
<p>
7- Related to the CCA analysis, what behavioural epoch has been used here, the same as the previous analyses, i.e. 100ms? how many datapoint is that in time? Given that CCA is essentially a correlation value, too few datapoints make it rather meaningless. If that's the case, I encourage using, let's say, one window combined of I and G until movement, and one window of movement and hold, such that they are both easier to interpret. Indeed low values of exec-exec in CC2 compared to Gallego et al, Nat Neurosci, 2020 might be a sign of a methodological error.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94165.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>
In their study, Zhao et al. investigated the population activity of mirror neurons (MNs) in the premotor cortex of monkeys either executing or observing a task consisting of reaching to, grasping, and manipulating various objects. The authors proposed an innovative method for analyzing the population activity of MNs during both execution and observation trials. This method enabled to isolate the condition-dependent variance in neural data and to study its temporal evolution over the course of single trials. The method proposed by the authors consists of building a time series of &quot;instantaneous&quot; subspaces with single time step resolution, rather than a single subspace spanning the entire task duration. As these subspaces are computed on an instant time basis, projecting neural activity from a given task time into them results in latent trajectories that capture condition-dependent variance while minimizing the condition-independent one. The authors then analyzed the time evolution of these instantaneous subspaces and revealed that a progressive shift is present in subspaces of both execution and observation trials, with slower shifts during the grasping and manipulating phases compared to the initial preparation phase. Finally, they compared the instantaneous subspaces between execution and observation trials and observed that neural population activity did not traverse the same subspaces in these two conditions. However, they showed that these distinct neural representations can be aligned with Canonical Correlation Analysis, indicating dynamic similarities of neural data when executing and observing the task. The authors speculated that such similarities might facilitate the nervous system's ability to recognize actions performed by oneself or another individual.</p>
<p>Strengths:</p>
<p>
Unlike other areas of the brain, the analysis of neural population dynamics of premotor cortex MNs is not well established. Furthermore, analyzing population activity recorded during non-trivial motor actions, distinct from the commonly used reaching tasks, serves as a valuable contribution to computational neuroscience. This study holds particular significance as it bridges both domains, shedding light on the temporal evolution of the shift in neural states when executing and observing actions. The results are moderately robust, and the proposed analytical method could potentially be used in other neuroscience contexts.</p>
<p>Weaknesses:</p>
<p>
While the overall clarity is satisfactory, the paper falls short in providing a clear description of the mathematical formulas for the different methods used in the study. Moreover, it was not immediately clear why the authors did not consider a (relatively) straightforward metric to quantity the progressive shift of the instantaneous subspaces, such as computing the angle between consecutive subspaces, rather than choosing a (in my opinion) more cumbersome metric based on classification of trajectory segments representing different movements.</p>
<p>Specific comments:</p>
<p>
In the methods, it is stated that instantaneous subspaces are found with 3 PCs. Why does it say 2 here? Another doubt on how instantaneous subspaces are computed: in the methods you state that you apply PCA on trial-averaged activity at each 50ms time step. From the next sentence, I gather that you apply PCA on an Nx4 data matrix (N being the number of neurons, and 4 being the trial-averaged activity of the four objects) every 50 ms. Is this right? It would help to explicitly specify the dimensions of the data matrix that goes into PCA computation.</p>
<p>It would help to include some equations in the methods section related to the LSTM decoding. Just to make sure I understood correctly: after having identified the instantaneous subspaces (every 50 ms), you projected the Instruction, Go, Movement, and Holding segments from individual trials (each containing 100 samples, since they are sampled from a 100ms window) onto each instantaneous subspace. So you have four trajectories for each subspace. In the methods, it is stated that a single LSTM classifier is trained for each subspace. Do you also have a separate classifier for each trajectory segment? What is used as input to the classifier? Each trajectory segment should be a 100x3 matrix once projected in an instantaneous subspace. Is that what (each of) the LSTMs take as input? And lastly, what is the LSTM trained to predict exactly? Just a label indicating the type of object that was manipulated in that trial? I apologize if I overlooked any detail, but I believe a clearer explanation of the LSTM, preferably with mathematical formulas, would greatly help readers understand this section.</p>
</body>
</sub-article>
</article>