<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">87126</article-id>
<article-id pub-id-type="doi">10.7554/eLife.87126</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.87126.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Conflicts are represented in a cognitive space to reconcile domain-general and domain-specific cognitive control</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0516-8772</contrib-id>
<name>
<surname>Yang</surname>
<given-names>Guochun</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8869-6636</contrib-id>
<name>
<surname>Wu</surname>
<given-names>Haiyan</given-names>
</name>
<xref ref-type="aff" rid="a5">5</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Li</surname>
<given-names>Qi</given-names>
</name>
<xref ref-type="aff" rid="a6">6</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1366-8926</contrib-id>
<name>
<surname>Liu</surname>
<given-names>Xun</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Fu</surname>
<given-names>Zhongzheng</given-names>
</name>
<xref ref-type="aff" rid="a7">7</xref>
<xref ref-type="aff" rid="a8">8</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Jiang</surname>
<given-names>Jiefeng</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<aff id="a1"><label>1</label><institution>CAS Key Laboratory of Behavioral Science, Institute of Psychology</institution>, Beijing 100101, <country>China</country></aff>
<aff id="a2"><label>2</label><institution>Department of Psychology, University of Chinese Academy of Sciences</institution>, Beijing 100101, <country>China</country></aff>
<aff id="a3"><label>3</label><institution>Department of Psychological and Brain Sciences, University of Iowa</institution>, Iowa City, IA 52242, <country>USA</country></aff>
<aff id="a4"><label>4</label><institution>Cognitive Control Collaborative, University of Iowa</institution>, Iowa City, IA 52242, <country>USA</country></aff>
<aff id="a5"><label>5</label><institution>Centre for Cognitive and Brain Sciences and Department of Psychology, University of Macau</institution>, Taipa, Macau 999078, <country>China</country></aff>
<aff id="a6"><label>6</label><institution>Beijing Key Laboratory of Learning and Cognition, School of Psychology, Capital Normal University</institution>, Beijing 100048, <country>China</country></aff>
<aff id="a7"><label>7</label><institution>Department of Neurosurgery, Cedars-Sinai Medical Center</institution>, Los Angeles, CA 90048, <country>USA</country></aff>
<aff id="a8"><label>8</label><institution>Division of Humanities and Social Sciences, California Institute of Technology</institution>, Pasadena, CA 91125, <country>USA</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Badre</surname>
<given-names>David</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country>United States of America</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>Correspondence: <email>liux@psych.ac.cn</email></corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2023-05-09">
<day>09</day>
<month>05</month>
<year>2023</year>
</pub-date>
<volume>12</volume>
<elocation-id>RP87126</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-02-21">
<day>21</day>
<month>02</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-02-14">
<day>14</day>
<month>02</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.02.13.528292"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2023, Yang et al</copyright-statement>
<copyright-year>2023</copyright-year>
<copyright-holder>Yang et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-87126-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Cognitive control resolves conflict between task-relevant and -irrelevant information to enable goal-directed behavior. As conflict can arise from different sources (e.g., sensory input, internal representations), how a finite set of cognitive control processes can effectively address huge array of conflict remains a major challenge. We hypothesize that different conflict can be parameterized and represented as distinct points in a (low-dimensional) cognitive space, which can then be resolved by a limited set of cognitive control processes working along the dimensions. To test this hypothesis, we designed a task with five types of conflict that could be conceptually parameterized along one dimension. Over two experiments, both human performance and fMRI activity patterns in the right dorsolateral prefrontal (dlPFC) support that different types of conflict are organized in a cognitive space. The findings suggest that cognitive space can be a dimension reduction tool to effectively organize neural representations of conflict for cognitive control.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>cognitive control</kwd>
<kwd>cognitive space</kwd>
<kwd>domain-general</kwd>
<kwd>domain-specific</kwd>
<kwd>conflict</kwd>
</kwd-group>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Cognitive control enables humans to behave purposefully by modulating neural processing to resolve conflict between task-relevant and task-irrelevant information. For example, when naming the color of the word “BLUE” printed in red ink, we are likely to be distracted by the word meaning, because reading a word is highly automatic in daily life. To keep our attention on the color, we need to mobilize the cognitive control processes to resolve the conflict between the color and word by boosting/suppressing the processing of color/word meaning. As task-relevant and task-irrelevant information can come from different sources, the sources of conflict and how they should be resolved can vary greatly<sup><xref rid="c1" ref-type="bibr">1</xref></sup>. For example, conflict may occur between items of sensory information, such as between a red light and a police officer signaling cars to pass. Alternatively, conflict may occur between sensory and motor information, such as when a voice on the left asks you to turn right. The large variety of conflict sources implies that there may be unlimited number of conflicts. A key unsolved question in cognitive control is how our brain efficiently resolves a nearly infinite number of different types of conflict.</p>
<p>A first step to addressing this question is to examine the commonalities and/or dissociations across different types of conflict that can be categorized into different <italic>domains</italic>. Examples of the domains of conflict include experimental paradigm<sup><xref rid="c2" ref-type="bibr">2</xref>,<xref rid="c3" ref-type="bibr">3</xref></sup>, sensory modality<sup><xref rid="c4" ref-type="bibr">4</xref>,<xref rid="c5" ref-type="bibr">5</xref></sup>, or conflict type regarding the dimensional overlap of conflict processes<sup><xref rid="c6" ref-type="bibr">6</xref>,<xref rid="c7" ref-type="bibr">7</xref></sup>.</p>
<p>Two solutions to resolving a wide range of conflict types are proposed. They differ based on whether the same cognitive control mechanisms are applied across domains. On the one hand, the <italic>domain-general</italic> cognitive control theories posit that the frontoparietal cortex adaptively encodes task information and can thus flexibly implement control strategies for different types of conflict. This is supported by the generalizable control adjustment (i.e., encountering a conflict trial from one type can facilitate conflict resolution of another type)<sup><xref rid="c2" ref-type="bibr">2</xref>,<xref rid="c8" ref-type="bibr">8</xref></sup> and similar neural patterns<sup><xref rid="c9" ref-type="bibr">9</xref>,<xref rid="c10" ref-type="bibr">10</xref></sup> across distinct conflict tasks. A broader domain-general view holds that the frontoparietal brain regions/networks are widely involved in multiple control demands well beyond the conflict domain<sup><xref rid="c11" ref-type="bibr">11</xref>,<xref rid="c12" ref-type="bibr">12</xref></sup>, which explains the remarkable flexibility in human behaviors. However, since domain-general processes are by definition likely shared by different tasks, when we need to handle multiple task demands at the same time, the efficiency of both tasks would be impaired due to resource competition or interference<sup><xref rid="c13" ref-type="bibr">13</xref></sup>. Therefore, the domain-general processes is evolutionarily less advantageous for humans to deal with the diverse situations requiring high efficiency<sup><xref rid="c14" ref-type="bibr">14</xref></sup>. On the other hand, the <italic>domain-specific</italic> theories argue that different types of conflict are handled by distinct cognitive control processes (e.g., where and how information processing should be modulated)<sup><xref rid="c15" ref-type="bibr">15</xref>,<xref rid="c16" ref-type="bibr">16</xref></sup>. However, according to the domain-specific view, the potentially unlimited conflict situations require a large variety of preexisting control processes, which is biologically implausible<sup><xref rid="c17" ref-type="bibr">17</xref></sup>.</p>
<p>To reconcile the two theories, researchers recently proposed that cognitive control might be a mixture of domain-general and domain-specific processes. For instance, Freitas et al.<sup><xref rid="c18" ref-type="bibr">18</xref></sup> found that trial-by-trial adjustment of control can generalize across two conflict domains to different degrees, leading to domain-general (strong generalization) or domain-specific (weak or no generalization) conclusions depending on the task settings of the consecutive conflict. Similarly, different brain networks may show domain-generality (i.e., representing multiple conflicts) or domain-specificity (i.e., representing individual conflicts separately)<sup><xref rid="c7" ref-type="bibr">7</xref>,<xref rid="c19" ref-type="bibr">19</xref></sup>. Even within the same brain area (e.g., medial frontal cortex), Fu et al.<sup><xref rid="c20" ref-type="bibr">20</xref></sup> found that the neural population activity can be factorized into orthogonal dimensions encoding both domain-general and domain-specific conflict information, which can be selectively read out by downstream brain regions. While the mixture view provides an explanation for the contradictory findings<sup><xref rid="c21" ref-type="bibr">21</xref></sup>, it suffers the same criticism as domain-specific cognitive control theories, as it still requires unlimited cognitive control processes to fully cover all possible conflicts.</p>
<p>A key to reconciling domain-general and domain-specific cognitive control is to organize the nearly infinite possible types of conflict using a system with limited, dissociable dimensions. A construct with a similar function is the <italic>cognitive space</italic><sup><xref rid="c22" ref-type="bibr">22</xref></sup>, which extends the idea of cognitive map<sup><xref rid="c23" ref-type="bibr">23</xref></sup> to the representation of abstract information. Critically, the cognitive space view holds that the representations of different abstract information are organized continuously and the locations of representations in the cognitive space are determined by the similarity among the represented information<sup><xref rid="c22" ref-type="bibr">22</xref></sup>.</p>
<p>In the human brain, it has been shown that abstract<sup><xref rid="c23" ref-type="bibr">23</xref>,<xref rid="c24" ref-type="bibr">24</xref></sup> and social<sup><xref rid="c25" ref-type="bibr">25</xref></sup> information can be represented in a cognitive space. For example, social hierarchies with two independent scores (e.g., popularity and competence) can be represented in a 2D cognitive space (one dimension for each score), such that each social item can be located by its score in the two dimensions<sup><xref rid="c25" ref-type="bibr">25</xref></sup>. In the field of cognitive control, recent studies have begun to conceptualize different control states within a cognitive space<sup><xref rid="c26" ref-type="bibr">26</xref></sup>. For example, Fu et al.<sup><xref rid="c20" ref-type="bibr">20</xref></sup> mapped different conflict conditions to locations in a low/high dimensional cognitive space to demonstrate the domain-general/domain-specific problems; Grahek et al.<sup><xref rid="c27" ref-type="bibr">27</xref></sup> used a cognitive space model of cognitive control settings to explain behavioral changes in the speed-accuracy tradeoff. However, the cognitive spaces proposed in these studies were only applicable to a limited number of control states involved in their designs. Therefore, it remains unclear whether there is a cognitive space that can explain an unlimited number of control states, similar to that of the spatial location<sup><xref rid="c22" ref-type="bibr">22</xref></sup> and non-spatial knowledge<sup><xref rid="c23" ref-type="bibr">23</xref></sup>. A challenge to answering this question lies in how to construct control states with continuous levels of similarity. Our recent work<sup><xref rid="c28" ref-type="bibr">28</xref></sup> showed that it is possible to manipulate continuous conflict similarity by using a mixture of two independent conflict types with varying ratios, which can be used to further examine the behavioral and neural evidence for the cognitive space view. It is also unclear how the cognitive space of cognitive control is encoded in the brain, although that of spatial locations and non-spatial abstract knowledge has been relatively well investigated in the medial temporal lobe, medial prefrontal and orbitofrontal system<sup><xref rid="c22" ref-type="bibr">22</xref>,<xref rid="c23" ref-type="bibr">23</xref></sup>. Recent research has suggested that the abstract task structure could be encoded and implemented by the frontoparietal network<sup><xref rid="c29" ref-type="bibr">29</xref>,<xref rid="c30" ref-type="bibr">30</xref></sup>, but whether a similar neural system encodes the cognitive space of cognitive control remains untested.</p>
<p>We hypothesize that different types of conflict are represented as points in a cognitive space. The dimensions in the cognitive space of conflict can be the aforementioned <italic>domains</italic>, in which domain-specific cognitive control processes are defined. For a specific type of conflict, its location in the cognitive space can be parameterized using a limited number of coordinates, which reflect how much control is needed for each of the domain-specific cognitive control processes. The cognitive space can also represent different types of conflict with low dimensionality<sup><xref rid="c26" ref-type="bibr">26</xref>,<xref rid="c31" ref-type="bibr">31</xref></sup>. Different domains can be represented conjunctively in a single cognitive space to achieve domain-general cognitive control, as conflict from different sources can be resolved using the same set of cognitive control processes. We further hypothesize that the cognitive space representing different types of conflict may be located in the frontoparietal network due to its essential roles in conflict resolution<sup><xref rid="c20" ref-type="bibr">20</xref>,<xref rid="c32" ref-type="bibr">32</xref></sup> and abstract task representation<sup><xref rid="c30" ref-type="bibr">30</xref></sup>.</p>
<p>In this study, we adjusted the paradigm from our previous study<sup><xref rid="c28" ref-type="bibr">28</xref></sup> by including transitions of trials from five different conflict types, which enabled us to test if these conflict types are organized in a cognitive space (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>). Specifically, on each trial, an arrow, pointing either upwards or downwards, was presented on one of the 10 possible locations on the screen. Participants were required to respond to the pointing direction of the arrow (up or down) by pressing either the left or right key. Importantly, conflict from two sources can occur in this task. On one hand, the vertical location of the arrow can be incongruent with the direction (e.g., an up-pointing arrow on the lower half of the screen), resulting spatial Stroop conflict<sup><xref rid="c6" ref-type="bibr">6</xref>,<xref rid="c33" ref-type="bibr">33</xref></sup>. On the other hand, the horizontal location of the arrow can be incongruent with the response key (e.g., an arrow requiring left response presented on the right side of the screen), thus causing Simon conflict<sup><xref rid="c33" ref-type="bibr">33</xref>,<xref rid="c34" ref-type="bibr">34</xref></sup>. As the arrow location rotates from the horizontal axis to the vertical axis, spatial Stroop conflict increases, and Simon conflict decreases. Therefore, the 10 possible locations of the arrow give rise to five conflict types with unique blend of spatial Stroop and Simon conflict<sup><xref rid="c28" ref-type="bibr">28</xref></sup>. As the increase in spatial Stroop conflict is perfectly correlated with the decrease in Simon conflict, we can use a 1D cognitive space to represent all five conflict types.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Fig. 1.</label>
<caption><title>Experimental design.</title>
<p>(A) The left panel shows the orthogonal stimulus-response mappings of the two participant groups. In each group the stimuli were only displayed at two quadrants of the circular locations. One group were asked to respond with the left button to the upward arrow and with the right button to the downward arrow presented in the to-left and bottom-right quadrants, and the other group vice versa. The right panel shows the time course of one example trial. The stimuli were displayed for 600 ms, preceded and followed by fixation crosses that lasted for 1400 ms in total. (B) Examples of the five types of conflict, each containing congruent and incongruent conditions. The arrows were presented at locations along five orientations with isometric polar angles, in which the vertical location introduces the spatial Stroop conflict, and the horizontal location introduces the Simon conflict. Dashed lines are shown only to indicate the location of arrows and were not shown in the experiments. (C) The definition of the angular difference between two conflict types and the conflict similarity. The angle θ is determined by the acute angle between two lines that cross the stimuli and the central fixation. Therefore, stimuli of the same conflict type form the smallest angle of 0, and stimuli between Conflict 1 and Conflict 5 form the largest angle of 90°, and others are in between. Conflict similarity is defined by the cosine value of θ.</p></caption>
<graphic xlink:href="528292v1_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>One way to parameterize (i.e., defining a coordinate system) the cognitive space is to encode each conflict type by the angle of the axis connecting its two possible stimulus locations (<xref rid="fig1" ref-type="fig">Fig. 1B</xref>). Within this cognitive space, the similarity between two conflict types can be quantified as the cosine value of their angular difference (<xref rid="fig1" ref-type="fig">Fig. 1C</xref>). If the conflict types are organized as a cognitive space in the brain, the similarity between conflict types in the cognitive space should be reflected in both the behavior and similarity in the neural representations of conflict types. Our data from two experiments using this experimental design support both predictions: using behavioral data, we found that the influence of congruency (i.e., whether the task-relevant and task-irrelevant information indicate the same response) from the previous trial to the next trial increases with the conflict similarity between the two trials. Using fMRI data, we found that more similar conflict showed higher multivariate pattern similarity in the right dorsolateral prefrontal cortex (dlPFC).</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Conflict type similarity modulated behavioral congruency sequence effect (CSE)</title>
<sec id="s2a1">
<title>Experiment 1</title>
<p>We conducted a behavioral experiment (n = 33, 18 females) to examine how CSEs across different conflict types are influenced by their similarity. First, we validated the experimental design by testing the congruency effects. All five conflict types showed robust congruency effects such that the incongruent trials were slower and less accurate than the congruent trials (Note S1; <xref rid="figS1" ref-type="fig">Fig. S1 A/B</xref>). To test the influence of similarity between conflict types on behavior, we examined the CSE in consecutive trials. Specifically, the CSE was quantified as the interaction between previous and current trial congruency and can reflect how (in)congruency on the previous trial influences cognitive control on the current trial<sup><xref rid="c35" ref-type="bibr">35</xref>,<xref rid="c36" ref-type="bibr">36</xref></sup>. It has been shown that the CSE diminishes if the two consecutive trials have different conflict types<sup><xref rid="c37" ref-type="bibr">37</xref>-<xref rid="c39" ref-type="bibr">39</xref></sup>. Similarly, we tested whether the size of CSE increases as a function of conflict similarity between consecutive trials. To this end, we organized trials based on a 5 (previous trial conflict type) × 5 (current trial conflict type) × 2 (previous trial congruency) × 2 (current trial congruency) factorial design, with the first two and the last two factors capturing between-trial conflict similarity and the CSE, respectively. The cells in the 5 × 5 matrix were mapped to different similarity levels according to the angular difference between the two conflict types (<xref rid="fig1" ref-type="fig">Fig. 1C</xref>). As shown in <xref rid="fig2" ref-type="fig">Fig. 2</xref>, the CSE, measured in both reaction time (RT) and error rate (ER), scaled with conflict similarity.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Fig. 2.</label>
<caption><title>The conflict similarity modulation on the behavioral CSE in Experiment 1.</title>
<p>(A) RT and (B) ER are plotted as a function of congruency types on trial n−1 and trial n. Each column shows one similarity level, as indicated by the defined angular difference between two conflict types. Error bars are standard errors. C = congruent; I = incongruent; RT = reaction time; ER = error rate.</p></caption>
<graphic xlink:href="528292v1_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>To test the modulation of conflict similarity on the CSE, we constructed a linear mixed effect model to predict RT/ER in each cell of the factorial design using a predictor encoding the interaction between the CSE and conflict similarity (see Methods). The results showed a significant effect of conflict similarity (RT: <italic>β =</italic> 0.10 ± 0.01, <italic>t</italic>(1978) = 15.82, <italic>p</italic> &lt; .001, <italic>η</italic><sub><italic>p</italic></sub><sup>2</sup> = .120; ER: <italic>β =</italic> 0.15 ± 0.02, <italic>t</italic>(1978) = 7.84, <italic>p</italic> &lt; .001, <italic>η</italic><sub><italic>p</italic></sub><sup>2</sup> = .085, <xref rid="figS2" ref-type="fig">Fig. S2B/E</xref>). In other words, the CSE increased with the conflict similarity between two consecutive trials. The conflict similarity modulation effect remained significant after regressing out the influence of physical proximity between the stimuli of consecutive trials (Note S2). As a control analysis, we also compared this approach to a two-stage analysis that first calculated the CSE for each previous × current trial conflict type condition and then tested the modulation of conflict similarity on the CSEs<sup><xref rid="c28" ref-type="bibr">28</xref></sup>. The two-stage analysis also showed a strong effect of conflict similarity (RT: <italic>β =</italic> 0.58 ± 0.04, <italic>t</italic>(493) = 14.74, <italic>p</italic> &lt; .001, <italic>η</italic><sub><italic>p</italic></sub><sup>2</sup> = .383; ER: <italic>β =</italic> 0.36 ± 0.05, <italic>t</italic>(493) = 7.01, <italic>p</italic> &lt; .001, <italic>η</italic><sub><italic>p</italic></sub><sup>2</sup> = .321, <xref rid="figS2" ref-type="fig">Fig. S2A/D</xref>). Importantly, individual modulation effects of conflict similarity were positively correlated between the two approaches (RT: <italic>r =</italic> 0.48; ER: <italic>r =</italic> 0.86, both <italic>p</italic>s &lt; 0.003, one-tailed), indicating the consistency of the estimated conflict similarity effects across the two approaches.</p>
</sec>
<sec id="s2a2">
<title>Experiment 2</title>
<sec id="s2a2a">
<title>Behavioral results</title>
<p>We next conducted an fMRI experiment using a shorter version of the same task with a different sample (n = 35, 17 females) to seek neural evidence of how different conflict types are organized. Using behavioral data, we first validated the experimental design by testing congruency effects in each of the five conflict types (Note S1; <xref rid="figS1" ref-type="fig">Fig. S1 C/D</xref>). We then tested the modulation of conflict similarity on the behavioral CSE using the linear mixed effect model as in Experiment 1 (except the two-stage method). Results showed a significant effect of conflict similarity modulation (RT: <italic>β =</italic> 0.24 ± 0.04, <italic>t</italic>(1148) = 6.36, <italic>p</italic> &lt; .001, <italic>η</italic> <sub><italic>p</italic></sub><sup>2</sup> = .096; ER: <italic>β =</italic> 0.33 ± 0.06, <italic>t</italic>(1206) = 5.81, <italic>p</italic> &lt; .001, <italic>η</italic><sub><italic>p</italic></sub><sup>2</sup> = .124, <xref rid="figS2" ref-type="fig">Fig. S2C/F</xref>), thus replicating the results of Experimental 1 and setting the stage for fMRI analysis. As in Experiment 1, the conflict similarity modulation effect remained significant after regressing out the influence of physical proximity between the stimuli of consecutive trials (Note S2).</p>
</sec>
</sec>
</sec>
<sec id="s2b">
<title>Brain activations modulated by conflict type dissimilarity with univariate analyses</title>
<p>In the fMRI analysis, we first replicated the classic congruency effect by searching for brain regions showing higher univariate activation in incongruent than congruent conditions (GLM1, see Methods). Consistent with the literature<sup><xref rid="c20" ref-type="bibr">20</xref>,<xref rid="c40" ref-type="bibr">40</xref></sup>, this effect was observed in the pre-supplementary motor area (pre-SMA) and anterior cingulate cortex (ACC) areas (<xref rid="fig3" ref-type="fig">Fig. 3</xref>, <xref ref-type="table" rid="tblS1">Table S1</xref>). We then tested the encoding of conflict type as a cognitive space by identifying brain regions with activation levels parametrically covarying with the coordinates (i.e., axial angle relative to the horizontal axis) in the hypothesized cognitive space. As shown in <xref rid="fig1" ref-type="fig">Fig. 1B</xref>, change in the angle corresponds to change in spatial Stroop and Simon conflicts in opposite directions. Accordingly, in the left middle frontal gyrus (MFG), fMRI activation scaled with the increase in spatial Stroop conflict, whereas the right inferior parietal sulcus (IPS) and the right dorsomedial prefrontal cortex (dmPFC) displayed positive correlation between fMRI activation and Simon conflict (<xref rid="fig3" ref-type="fig">Fig. 3</xref>, <xref rid="figS3" ref-type="fig">Fig. S3</xref>, <xref ref-type="table" rid="tblS1">Table S1</xref>).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Fig. 3.</label>
<caption><title>The congruency effect and parametric modulation effect detected by uni-voxel analyses.</title>
<p>Results displayed are thresholded with voxel-wise one-tailed <italic>p</italic> &lt; .005 and cluster-size &gt; 20 voxels. The congruency effect denotes the higher activation in incongruent than congruent condition. The positive parametric modulation effect (I_pm – C_pm) denotes the higher activation when the conflict type contained a higher ratio of Simon conflict component (bottom left panel). The negative parametric modulation effect [converted to positive with – (I_pm – C_pm)] denotes the higher activation when the conflict type contained a higher ratio of spatial Stroop conflict component (bottom right panel). I = incongruent; C = congruent; pm = parametric modulator.</p></caption>
<graphic xlink:href="528292v1_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>To further test if the univariate results explain the conflict similarity modulation of the behavioral CSE (slope in <xref rid="figS2" ref-type="fig">Fig. S2C</xref>), we conducted brain-behavioral correlation analyses for regions identified above. Regions with higher spatial Stroop/Simon modulation effects were expected to trigger higher behavioral conflict similarity modulation effect on the CSE. However, none of the three regions (i.e., left MFG, right IPS and right dmPFC, <xref rid="fig3" ref-type="fig">Fig. 3</xref>) were positively correlated with the behavioral performance, all <italic>p</italic><sub><italic>FDR</italic></sub> &gt;.762, one-tailed. In addition, since the conflict type difference covaries with the orientation of the arrow location at the individual level (e.g., the stimulus in a higher level of Simon conflict is always closer to the horizontal axis, see <xref rid="figS4" ref-type="fig">Fig. S4</xref>), the univariate modulation effects may not reflect purely conflict type difference. To further tease these factors apart, we used multivariate analyses.</p>
</sec>
<sec id="s2c">
<title>Multivariate patterns of the right dlPFC encodes the conflict similarity</title>
<p>The hypothesis that the brain encodes conflict types in a cognitive space predicts that similar conflict types will have similar neural representations. To test this prediction, we computed the representational similarity matrix (RSM) that encoded correlations of blood-oxygen-level dependent (BOLD) signal patterns between each pair of conflict type (conflict 1, 2, 3, 4 and 5, as shown in <xref rid="fig1" ref-type="fig">Fig. 1B</xref>) × congruency (congruent, incongruent) × arrow direction (up, down) × run × subject combinations for each of the 360 cortical regions from the Multi-Modal Parcellation (MMP) cortical atlas<sup><xref rid="c41" ref-type="bibr">41</xref>,<xref rid="c42" ref-type="bibr">42</xref></sup>. The RSM was then submitted to a linear mixed-effect model as the dependent variable to test whether the representational similarity in each region was modulated by various experimental variables (e.g., conflict type, spatial orientation, stimulus, response, etc., see Methods). The linear mixed-effect model was used to de-correlate conflict type and spatial orientation leveraging the between-subject manipulation of stimulus locations (<xref rid="figS4" ref-type="fig">Fig. S4</xref>).</p>
<p>To validate this method, we applied this analysis to test the effects of response/stimulus features and found that representational similarity of the BOLD signal significantly covaried with whether two response/spatial location/arrow directions were the same most strongly in bilateral motor/visual/somatosensory areas, respectively (<xref rid="figS5" ref-type="fig">Fig. S5</xref>). We then identified the cortical regions encoding conflict type as a cognitive space by testing whether their RSMs can be explained by the similarity between conflict types. Specifically, we applied three independent criteria: (1) the cortical regions should exhibit a statistically significant positive conflict similarity effect on the RSM; (2) the conflict similarity effect should be stronger in incongruent than congruent trials to reflect flexible adjustment of cognitive control demand when conflict is present; and (3) the conflict similarity effect should be positively correlated with the behavioral conflict similarity modulation effect on the CSE (see <italic>Behavioral Results</italic> of Experiment 2). The first criterion revealed several cortical regions encoding the conflict similarity, including the 8C area (a subregion of dlPFC<sup><xref rid="c42" ref-type="bibr">42</xref></sup>), a47r, TPOJ3 and V3CD in the right hemisphere, and the 6r, 7Am, 24dd, VMV1, VMV2, 7Pl, 23c and 25 areas in the left hemisphere (<italic>p</italic><sub><italic>FDR</italic></sub>s &lt; 0.05, with raw <italic>ps</italic> &lt; 0.001, one-tailed, <xref rid="fig4" ref-type="fig">Fig. 4A</xref>). We next tested whether these regions were related to cognitive control by comparing the strength of conflict similarity effect between incongruent and congruent conditions (criterion 2). Results revealed that the left lateral area 7P (7P1), left ventromedial visual area 1 (VMV1), left dorsal area 24d (24dd), right Brodmann area 8C (8C), and right V3CD met this criterion, <italic>p</italic><sub><italic>FDR</italic></sub>s &lt; .01, one-tailed (<xref rid="tbl1" ref-type="table">Table 1</xref>, <xref rid="fig4" ref-type="fig">Fig. 4B</xref>), suggesting that the representation of conflict type was strengthened when conflict was present (e.g., <xref rid="fig4" ref-type="fig">Fig. 4D</xref>). The inter-subject brain-behavioral correlation analysis (criterion 3) showed that the strength of conflict similarity effect on RSM scaled with the modulation of conflict similarity on the CSE (slope in <xref rid="figS2" ref-type="fig">Fig. S2C</xref>) in right 8C (<italic>r</italic> = 0.43, <italic>p</italic><sub><italic>FDR</italic></sub> = .027, one-tailed, <xref rid="fig4" ref-type="fig">Fig. 4C</xref>) but not in the other regions (all <italic>p</italic><sub><italic>FDR</italic></sub> &gt; .632, one-tailed). In addition, we did not find evidence supporting the encoding of congruency in the right 8C area (see Note S5), suggesting that the right 8C area specifically represents conflict similarity. In sum, we found converging evidence supporting that the right dlPFC (8C area) encoded conflict similarity, which further supports the hypothesis that conflict types are represented in a cognitive space.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><title>Summary statistics of regions showing larger encoding strength in incongruent than congruent conditions for the conflict type and orientation effects.</title></caption>
<graphic xlink:href="528292v1_tbl1.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<fig id="fig4" position="float" fig-type="figure">
<label>Fig. 4.</label>
<caption><title>The conflict type effect.</title>
<p>(A) Brain regions surviving the FDR-correction (<italic>p</italic><sub>FDR</sub> &lt; 0.05 and <italic>p</italic> &lt; 0.001) across the 360 regions (criterion 1). Labeled regions are those meeting the criterion 2. (B) The regions showing stronger encoding of conflict type in the incongruent than congruent conditions (criterion 2). ** <italic>p</italic><sub>FDR</sub> &lt; .01, *** <italic>p</italic><sub>FDR</sub> &lt; .001. (C) The brain-behavior correlation of the right 8C (criterion 3). (D) Illustration of the different encoding strength of conflict type similarity in incongruent versus congruent conditions of right 8C. l = left; r = right.</p></caption>
<graphic xlink:href="528292v1_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2d">
<title>Multivariate patterns of visual and oculomotor areas encode stimulus orientation</title>
<p>To tease apart the representation of conflict type from that of perceptual information, we tested the modulation of the spatial orientations of stimulus locations on RSM using the aforementioned RSA. We also applied three independent criteria: (1) the cortical regions should exhibit a statistically significant orientation effect on the RSM; (2) the conflict similarity effect should be stronger in incongruent than congruent trials; and (3) the orientation effect should not interact with the CSE, since the orientation effect was dissociated from the conflict similarity effect and was not expected to influence cognitive control. We observed increasing fMRI representational similarity between trials with more similar orientations of stimulus location in the occipital cortex, such as right V1, bilateral V2 and V3, right V4, left area temporoparietooccipital junction 3 (TPOJ3) and right PHT areas (FDR corrected <italic>p</italic>s &lt; 0.05 and raw <italic>p</italic>s &lt; 0.001). We also found the same effect in several oculomotor related regions, including the left frontal eye field (FEF), anterior 6m (6ma), area intraparietal 2 (IP2), right parietal area F (PF) and bilateral 5m, as well as other regions (<xref rid="fig5" ref-type="fig">Fig. 5A</xref>). Then we tested if any of these brain regions were related to the conflict representation by comparing their encoding strength between incongruent and congruent conditions. Results showed that the right V1, bilateral V2, left FEF, left IP2, right hippocampus (H) and right PF encoded stronger orientation effect in the incongruent than the congruent condition, <italic>p</italic><sub><italic>FDR</italic></sub>s &lt; .05, one-tailed (<xref ref-type="table" rid="tbl1">Table1</xref>, <xref rid="fig5" ref-type="fig">Fig. 5B</xref>). We then tested if any of these regions was related to the behavioral performance, and results showed that none of them positively correlated with the behavioral conflict similarity modulation effect, all <italic>p</italic><sub><italic>FDR</italic></sub> &gt; .675, one-tailed. Thus all regions are consistent with the criterion 3. Like the right 8C area, none of the reported areas directly encoded congruency (see Note S5). Taken together, we found that the visual and oculomotor regions encoded orientations of stimulus location in a continuous manner and that the encoding strength was stronger when conflict was present.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Fig. 5.</label>
<caption><title>The axial orientation effect.</title>
<p>(A) Brain regions surviving the FDR-correction (<italic>p</italic><sub>FDR</sub> &lt; 0.05 and <italic>p</italic> &lt; 0.001) across the 360 regions (criterion 1). Labeled regions are those meeting the criterion 2. (B) The regions showing stronger encoding of orientation in the incongruent than congruent conditions (criterion 2). * <italic>p</italic><sub>FDR</sub> &lt; .05, ** <italic>p</italic><sub>FDR</sub> &lt; .01, *** <italic>p</italic><sub>FDR</sub> &lt; .001.</p></caption>
<graphic xlink:href="528292v1_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>To explore the relation between conflict type and orientation representations, we conducted representational connectivity (i.e., the similarity between two RSMs of two regions)<sup><xref rid="c43" ref-type="bibr">43</xref></sup> analyses and found that among the orientation effect regions, the right V1 and bilateral V2 showed significant representational connectivity with the right 8C compared to the controlled regions (including those encoding orientation effect but not showing larger encoding strength in incongruent than congruent conditions, as well as three other regions encoding none of our defined effects in the main RSA, see Methods). Compared with the largest connectivity strength in the controlled regions (i.e., the left V3, <italic>β =</italic> 0.1447 ± 0.0069), we found higher connectivity in the left V2, <italic>β =</italic> 0.1645 ± 0.0060, <italic>t</italic>(34) = 4.86, right V1, <italic>β =</italic> 0.1628 ± 0.0065, <italic>t</italic>(34) = 4.54, and right V2, <italic>β =</italic> 0.1678 ± 0.0074, <italic>t</italic>(34) = 5.65, all <italic>p</italic><sub><italic>FDR</italic></sub> &lt; .001, one-tailed (<xref rid="figS6" ref-type="fig">Fig. S6</xref>).</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Understanding how different types of conflict are resolved is essential to answer how cognitive control achieves adaptive behavior. However, the dichotomy between domain-general and/or domain-specific processes presents a dilemma<sup><xref rid="c15" ref-type="bibr">15</xref>,<xref rid="c21" ref-type="bibr">21</xref></sup>. Reconciliation of the two views also suffers from the inability to fully address how infinite conflict can be resolved by a limited set of cognitive control processes. In this study, we hypothesized that this issue can be addressed if conflict is organized as a cognitive space. Leveraging the well-known dissociation between the spatial Stroop and Simon conflict<sup><xref rid="c44" ref-type="bibr">44</xref>-<xref rid="c46" ref-type="bibr">46</xref></sup>, we designed five conflict types that are systematically different from each other. The cognitive space hypothesis predicted that the representational proximity/distance between two conflict types scales with their similarities/dissimilarities, which was tested at both behavioral and neural levels. Behaviorally, we found that the CSEs were linearly modulated by conflict similarity between consecutive trials, replicating and extending our previous study<sup><xref rid="c28" ref-type="bibr">28</xref></sup>. BOLD activity patterns in the right dlPFC further showed that the representational similarity between conflict types was modulated by their conflict similarity, and that strength of the modulation was positively associated with the modulation of conflict similarity on the behavioral CSE. We also observed that activity in three brain regions (right IPS, right dlPFC and left MFG) was parametrically modulated by the conflict type difference, though they did not directly explain the behavioral results. Additionally, we found that the visual regions encoded the spatial orientation of the stimulus location, which might provide the essential concrete information to determine the conflict type. Together, these results support the hypothesis that the conflicts are organized in a cognitive space that enables a limited set of cognitive control processes to resolve infinite possible types of conflict.</p>
<p>Conventionally, the domain-general view of control suggests a common representation for different types of conflict (<xref rid="fig6" ref-type="fig">Fig. 6</xref>, left), while the domain-specific view suggests dissociated representations for different types (<xref rid="fig6" ref-type="fig">Fig. 6</xref>, right). Previous research on this topic often adopts a binary manipulation of conflict<sup><xref rid="c21" ref-type="bibr">21</xref></sup> (i.e., each domain only has one conflict type) and thus is not suitable to test the cognitive space hypothesis. Here, we parametrically manipulated the similarity of conflict in different conflict types and demonstrated that the two theories can be reconciled as a cognitive space<sup><xref rid="c22" ref-type="bibr">22</xref></sup> (<xref rid="fig6" ref-type="fig">Fig. 6</xref>, middle). Specifically, the cognitive space provides a solution to use a single cognitive space organization to encode different types of conflict that are close (domain-general) or distant (domain-specific) to each other. It also shows the potential for how unlimited conflict types can be coded using limited resources (i.e., as different points in a low-dimensional cognitive space). Moreover, geometry can also emerge in the cognitive space<sup><xref rid="c20" ref-type="bibr">20</xref></sup>, which will allow for decomposition of a conflict type (e.g., how much conflict in each of the dimensions in the cognitive space) so that it can be mapped into the limited set of cognitive control processes. Such geometry enables fast learning of cognitive control settings from similar conflict types by providing a measure of similarity (e.g., as distance in space).</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Fig. 6.</label>
<caption><title>Illustration of the hypothesized dimensionalities of different representations.</title>
<p>The shade of the red color indicates the degree of dimensionality (i.e., how many dimensions are needed to represent different states). The dimensionality of domain-general representation is extremely low, with all representations compressed to one dot. The dimensionality of domain-specific representation is extremely high, with each control state encoded in a unique and orthogonal dimension. The dimensionality of the organized representation is modest, enabling distant states to be separated but also allowing close states to share representations. The solid arrows show the axes of different dimensions. The dashed arrows indicate how the representational dimensionality can be reduced by projecting the independent dimensions to a common dimension.</p></caption>
<graphic xlink:href="528292v1_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>If the dimensionality of the cognitive space of conflict is extremely high, the cognitive space solution would suffer the same criticism as the domain-specificity theory. We argue that the dimensionality is manageable for the human brain, as task information unrelated to differentiating conflicts can be removed. For example, the Simon conflict can be represented in a space consisting of spatial location, stimulus information and responses. Thus, the dimensionality of the cognitive space of conflict should not exceed the number of represented features. The dimensionality can be further reduced, as humans selectively represent a small number of features when learning task representations (e.g., spatial information is reduced to the horizontal dimension from the 3D space we live in)<sup><xref rid="c47" ref-type="bibr">47</xref></sup>. The reduced dimensionality does not only require less effort to represent the conflict, but also facilitates generalization of cognitive control settings among different conflict types<sup><xref rid="c26" ref-type="bibr">26</xref></sup>.</p>
<p>Although our finding of cognitive space in the right dlPFC differs from other cognitive space studies<sup><xref rid="c24" ref-type="bibr">24</xref>,<xref rid="c25" ref-type="bibr">25</xref>,<xref rid="c48" ref-type="bibr">48</xref></sup> that highlighted the orbitofrontal and hippocampus regions, it is consistent with the cognitive control literature. The prefrontal cortex has long been believed to be a key region of cognitive control representation<sup><xref rid="c49" ref-type="bibr">49</xref>-<xref rid="c51" ref-type="bibr">51</xref></sup> and is widely engaged in multiple task demands<sup><xref rid="c12" ref-type="bibr">12</xref>,<xref rid="c52" ref-type="bibr">52</xref></sup>. However, it is not until recently that the multivariate representation in this region has been examined. For instance, Vaidya et al.<sup><xref rid="c29" ref-type="bibr">29</xref></sup> reported that frontal regions presented latent states that are organized hierarchically. Freund et al.<sup><xref rid="c32" ref-type="bibr">32</xref></sup> showed that dlPFC encoded the target and congruency in a typical color-word Stroop task. Taken together, we suggest that the right dlPFC might flexibly encode a variety of cognitive spaces to meet the dynamic task demands. In addition, we found no such representation in the left dlPFC (Note S6), indicating a possible lateralization. Previous studies showed that the left dlPFC was related to the expectancy-related attentional set up-regulation, while the right dlPFC was related to the online adjustment of control<sup><xref rid="c53" ref-type="bibr">53</xref>,<xref rid="c54" ref-type="bibr">54</xref></sup>, which is consistent with our findings. Moreover, the right PFC also represents a composition of single rules<sup><xref rid="c55" ref-type="bibr">55</xref></sup>, which may explain how the spatial Stroop and Simon types can be jointly encoded in a single space.</p>
<p>We found that participants with stronger conflict representation as cognitive space in right dlPFC have also adjusted their conflict control to a greater extent based on the conflict similarity (<xref rid="fig4" ref-type="fig">Fig 4C</xref>). The finding suggests that the cognitive space organization of conflict guides cognitive control to adjust behavior. Previous studies have shown that participants may adopt different strategies to represent a task, with the model-based strategies benefitting goal-related behaviors more than the model-free strategies<sup><xref rid="c56" ref-type="bibr">56</xref></sup>. Similarly, we propose that the cognitive space could serve as a mental model to assist fast learning and efficient organization of cognitive control settings. With the organization of a cognitive space, a new conflict can be quickly assigned a location in the cognitive space, which will facilitate the development of cognitive control settings for this conflict by interpolating nearby conflicts and/or projecting the location to axes representing different cognitive control processes. On the other hand, without a cognitive space, there would be no measure of similarity between conflict on different trials, hence limiting the ability of fast learning of cognitive control setting from similar trials.</p>
<p>The cognitive space in the right dlPFC appears to be an abstraction of concrete information from the visual regions. We found that the right V1 and bilateral V2 encoded the spatial orientation of the target location (<xref rid="fig5" ref-type="fig">Fig. 5</xref>) and showed strong representational connectivity with the right dlPFC (<xref rid="figS6" ref-type="fig">Fig. S6</xref>), suggesting that there might be information exchange between these regions. We speculate that the representation of spatial orientation may have provided the essential perceptual information to determine the conflict type (<xref rid="fig1" ref-type="fig">Fig. 1</xref>) and thus served as the critical input for the cognitive space. The conflict type representation further incorporates the stimulus-response mapping rules to the spatial orientation representation, so that vertically symmetric orientations can be recognized as the same conflict type (<xref rid="figS4" ref-type="fig">Fig. S4</xref>). In other words, the representation of conflict type involves the compression of perceptual information<sup><xref rid="c57" ref-type="bibr">57</xref></sup>, which is consistent with the idea of a low-dimensional representation of cognitive control<sup><xref rid="c26" ref-type="bibr">26</xref>,<xref rid="c31" ref-type="bibr">31</xref></sup>. The compression and abstraction processes might be why the frontoparietal regions are the top of hierarchy of information processing<sup><xref rid="c58" ref-type="bibr">58</xref></sup> and why the frontoparietal regions are widely engaged in multiple task demands<sup><xref rid="c59" ref-type="bibr">59</xref></sup>.</p>
<p>With conventional univariate analyses, we observed that the overall congruency effect was located at the medial frontal regions (i.e., pre-SMA and ACC), which is consistent with previous studies<sup><xref rid="c20" ref-type="bibr">20</xref>,<xref rid="c40" ref-type="bibr">40</xref></sup>. Beyond that, we also found regions that can be parametrically modulated by conflict type difference, including right IPS, right dlPFC (modulated by Simon difference) and left MFG (modulated by spatial Stroop difference). The lateralization of these regions is consistent with a previous finding<sup><xref rid="c19" ref-type="bibr">19</xref></sup>, which highlighted the difference of Stroop and Simon types with brain activities at different hemispheres. The scaling of brain activities based on conflict difference is potentially important to the representational organization of different types of conflict. However, we didn’t observe their brain-behavioral relevance. One possible reason is that the conflict (dis)similarity is a combination of (dis)similarity of spatial Stroop and Simon conflicts, but each univariate region only reflects difference along a single conflict domain. Also likely, the representational geometry is more of a multivariate problem than what univariate activities can capture<sup><xref rid="c60" ref-type="bibr">60</xref></sup>. Future studies may adopt approaches such as repetition suppression induced fMRI adaptation<sup><xref rid="c26" ref-type="bibr">26</xref></sup> to test the role of univariate activities in task representations.</p>
<p>One limitation of this study needs to be noted. To parametrically manipulate the conflict similarity levels, we adopted the spatial Stroop-Simon paradigm that enables parametrical combinations of spatial Stroop and Simon conflicts. However, since this paradigm is a two-alternative forced choice design, the behavioral CSE is not a pure measure of adjusted control but could be partly confounded by bottom-up factors such as feature integration<sup><xref rid="c61" ref-type="bibr">61</xref></sup>. Future studies may replicate our findings with a multiple-choice design with confound-free trial sequences<sup><xref rid="c62" ref-type="bibr">62</xref></sup>.</p>
<p>In sum, we showed that the cognitive control can be organized in an abstract cognitive space that is represented in the right dlPFC and guides cognitive control to adjust goal-directed behavior. The cognitive space hypothesis reconciles the long-standing debate between the domain-general and domain-specific views of cognitive control and provides a parsimonious and more broadly applicable framework for understanding how our brains efficiently and flexibly represents multiple task settings.</p>
</sec>
<sec id="s4">
<title>Materials and Methods</title>
<sec id="s4a">
<title>Subjects</title>
<p>In Experiment 1, we enrolled thirty-three college students (19-28 years old, average of 21.5 ± 2.3 years old; 19 males). In Experiment 2, thirty-six college students were recruited, and one subject was excluded due to not following task instructions. The final sample of Experiment 2 consisted of thirty-five participants (19-29 years old, average of 22.3 ± 2. 5 years old; 17 males). The sample sizes were determined based on our previous study<sup><xref rid="c28" ref-type="bibr">28</xref></sup>. All participants reported no history of psychiatric or neurological disorders and were right-handed, with normal or corrected-to-normal vision. The experiments were approved by the Institutional Review Board of the Institute of Psychology, Chinese Academy of Science. Informed consent was obtained from all subjects.</p>
</sec>
<sec id="s4b">
<title>Method Details</title>
<sec id="s4b1">
<title>Experiment 1</title>
<sec id="s4b1a">
<title>Experimental Design</title>
<p>We adopted a modified spatial Stroop-Simon task<sup><xref rid="c28" ref-type="bibr">28</xref></sup> (<xref rid="fig1" ref-type="fig">Fig. 1</xref>). The task was programmed with the E-prime 2.0 (Psychological Software Tools, Inc.). The stimulus was an upward or downward black arrow (visual angle of ∼ 1°) displayed on a 17-inch LCD monitor with a viewing distance of ∼60 cm. The arrow appeared inside a grey square at one of ten locations with the same distance from the center of the screen, including two horizontal (left and right), two vertical (top and bottom), and six corner (orientations of 22.5°, 45°and 67.5°) locations. The distance from the arrow to the screen center was approximately 3°. To dissociate orientation of stimulus locations and conflict types (see below), participants were randomly assigned to two sets of stimulus locations (one included top-right and bottom-left quadrants, and the other included top-left and bottom-right quadrants).</p>
<p>Each trial started with a fixation cross displayed in the center for 100−300 ms, followed by the arrow for 600 ms and another fixation cross for 1100−1300 ms (the total trial length was fixed at 2000 ms). Participants were instructed to respond to the pointing direction of the arrow by pressing a left or right button and to ignore its location. The mapping between the arrow orientations and the response buttons was counterbalanced across participants. The task design introduced two possible sources of conflict: on one hand, the direction of the arrow is either congruent or incongruent with the vertical location of the arrow, thus introducing a spatial Stroop conflict<sup><xref rid="c33" ref-type="bibr">33</xref>,<xref rid="c63" ref-type="bibr">63</xref></sup>, which contains the dimensional overlap between task-relevant stimulus and task-irrelevant stimulus<sup><xref rid="c1" ref-type="bibr">1</xref></sup>; on the other hand, the response (left or right button) is either congruent or incongruent with the horizontal location of the arrow, thus introducing a Simon conflict<sup><xref rid="c33" ref-type="bibr">33</xref>,<xref rid="c34" ref-type="bibr">34</xref></sup>, which contains the dimensional overlap between task-irrelevant stimulus and response<sup><xref rid="c1" ref-type="bibr">1</xref></sup>. Therefore, the five polar orientations of the stimulus location (from 0 to 90°) defined five unique combinations of spatial Stroop and Simon conflicts, with more similar orientations having more similar composition of conflict. More generally, the spatial orientation of the arrow location relative to the center of the screen forms a cognitive space of different blending of spatial Stroop and Simon conflict.</p>
<p>The formal task consisted of 30 runs of 101 trials each, divided into three sessions of ten runs each. The participants completed one session each time and all three sessions within one week. Before each session, the participants performed training blocks of 20 trials repeatedly until the accuracy reached 90% in the most recent block. The trial sequences of the formal task were pseudo-randomly generated to ensure that each of the task conditions and their transitions occurred with equal number of trials.</p>
</sec>
</sec>
<sec id="s4b2">
<title>Experiment 2</title>
<sec id="s4b2a">
<title>Experimental Design</title>
<p>The apparatus, stimuli and procedure were identical to Experiment 1 except for the changes below. The stimuli were back projected onto a screen (with viewing angle being ∼3.9° between the arrow and the center of the screen) behind the subject and viewed via a surface mirror mounted onto the head coil. Due to the time constraints of fMRI scanning, the trial numbers decreased to a total of 340, divided into two runs with 170 trials each. To obtain a better hemodynamic model fitting, we generated two pseudo-random sequences optimized with a genetic algorithm<sup><xref rid="c64" ref-type="bibr">64</xref></sup> conducted by the NeuroDesign package<sup><xref rid="c65" ref-type="bibr">65</xref></sup> (see Note S3 for more detail). In addition, we added 6 seconds of fixation before each run to allow the stabilization of the hemodynamic signal, and 20 seconds after each run to allow the signal to drop to the baseline.</p>
<p>Before scanning, participants performed two practice sessions. The first one contained 10 trials of center-displayed arrow and the second one contained 32 trials using the same design as the main task. They repeated both sessions until their performance accuracy for each session reached 90%, after which the scanning began.</p>
</sec>
</sec>
</sec>
<sec id="s4c">
<title>fMRI Image acquisition and preprocessing</title>
<p>Functional imaging was performed on a 3T GE scanner (Discovery MR750) using echo-planar imaging (EPI) sensitive to BOLD contrast [in-plane resolution of 3.5 × 3.5 mm<sup>2</sup>, 64 × 64 matrix, 37 slices with a thickness of 3.5 mm and no interslice skip, repetition time (TR) of 2000 ms, echo-time (TE) of 30 ms, and a flip angle of 90°]. In addition, a sagittal T1-weighted anatomical image was acquired as a structural reference scan, with a total of 256 slices at a thickness of 1.0 mm with no gap and an in-plane resolution of 1.0 × 1.0 mm <sup>2</sup>.</p>
<p>Before preprocessing, the first three volumes of the functional images were removed due to the instability of the signal at the beginning of the scan. The anatomical and functional data were preprocessed with the fMRIprep 20.2.0<sup><xref rid="c66" ref-type="bibr">66</xref></sup> (RRID:SCR_016216), which is based on Nipype 1.5.1<sup><xref rid="c67" ref-type="bibr">67</xref></sup> (RRID:SCR_002502). Specifically, BOLD runs were slice-time corrected using 3dTshift from AFNI 20160207<sup><xref rid="c68" ref-type="bibr">68</xref></sup> (RRID:SCR_005927). The BOLD time-series were resampled to the MNI152NLin2009cAsym space without smoothing. For a more detailed description of preprocessing, see Note S4. After preprocessing, we resampled the functional data to a spatial resolution of 3 × 3 × 3 mm<sup>3</sup>. All analyses were conducted in volumetric space, and surface maps are produced with Connectome Workbench (<ext-link ext-link-type="uri" xlink:href="https://www.humanconnectome.org/software/connectome-workbench">https://www.humanconnectome.org/software/connectome-workbench</ext-link>) for display purpose only.</p>
</sec>
<sec id="s4d">
<title>Quantification and Statistical Analysis</title>
<sec id="s4d1">
<title>Behavioral analysis</title>
<sec id="s4d1a">
<title>Experiment 1</title>
<p>RT and ER were the two dependent variables analyzed. As for RTs, we excluded the first trial of each block (0.9%, for CSE analysis only), error trials (3.8%), trials with RTs beyond three <italic>SD</italic>s or shorter than 200 ms (1.3%) and post-error trials (3.4%). For the ER analysis, the first trial of each block and trials after an error were excluded. To exclude the possible influence of response repetition, we centered the RT and ER data within the response repetition and response alternation conditions separately by replacing condition-specific mean with the global mean for each subject.</p>
<p>To examine the modulation of conflict similarity on the CSE, we organized trials based on a 5 (previous trial conflict type) × 5 (current trial conflict type) × 2 (previous trial congruency) × 2 (current trial congruency) factorial design. As conflict similarity is commutive between conflict types, we expected the previous by current trial conflict type factorial design to be a symmetrical (e.g., a conflict 1-conflict 2 sequence in theory has the same conflict similarity modulation effect as a conflict 2-conflict 1 sequence), resulting a total of 15 conditions left for the first two factors of the design (i.e., previous × current trial conflict type). For each previous × current trial conflict type condition, the conflict similarity between the two trials can be quantified as the cosine of their angular difference. In the current design, there were five possible angular difference levels (0, 22.5°, 42.5°, 67.5° and 90°, see <xref rid="fig1" ref-type="fig">Fig. 1C</xref>). We further coded the previous by current trial congruency conditions (hereafter abbreviated as CSE conditions) as CC, CI, IC and II, with the first and second letter encoding the congruency (C) or incongruency (I) on the previous and current trial, respectively. As the CSE is operationalized as the interaction between previous and current trial congruency, it can be rewritten as a contrast of (CI – CC) – (II – IC). In other words, the load of CSE on CI, CC, II and IC conditions is 1, –1, –1 and 1, respectively. To estimate the modulation of conflict similarity on the CSE, we built a regressor by calculating the Kronecker product of the conflict similarity scores of the 15 previous × current trial conflict similarity conditions and the CSE loadings of previous × current trial congruency conditions. This regressor was regressed against RT and ER data separately, which were normalized across participants and CSE conditions. The regression was performed using a linear mixed-effect model, with the intercept and the slope of the regressor for the modulation of conflict similarity on the CSE as random effects (across both participants and the four CSE conditions). As a control analysis, we built a similar two-stage model<sup><xref rid="c28" ref-type="bibr">28</xref></sup>. In the first stage, the CSE [i.e., (CI – CC) – (II – IC)] for each of the previous × current trial conflict similarity condition was computed. In the second stage, CSE was used as the dependent variable and was predicted using conflict similarity across the 15 previous × current trial conflict type conditions. The regression was also performed using a linear mixed effect model with the intercept and the slope of the regressor for the modulation of conflict similarity on the CSE as random effects (across participants).</p>
</sec>
<sec id="s4d1b">
<title>Experiment 2</title>
<p>Behavioral data was analyzed using the same linear mixed effect model as Experiment 1, with all the CC, CI, IC and II trials as the dependent variable. In addition, to test if fMRI activity patterns may explain the behavioral representations differently in congruent and incongruent conditions, we conducted the same analysis to measure behavioral modulation of conflict similarity on the CSE using congruent (CC and IC) and incongruent (CI and II) trials separately.</p>
</sec>
</sec>
</sec>
<sec id="s4e">
<title>Estimation of fMRI activity with univariate general linear model (GLM)</title>
<p>To estimate voxel-wise fMRI activity for each of the experimental conditions, the preprocessed fMRI data of each run were analyzed with the GLM. We conducted three GLMs for different purposes. GLM1 aimed to validate the design of our study by replicating the engagement of frontoparietal activities in conflict processing documented in previous studies<sup><xref rid="c7" ref-type="bibr">7</xref>,<xref rid="c19" ref-type="bibr">19</xref></sup>, and to explore the cognitive space related regions that were parametrically modulated by the conflict type. Preprocessed functional images were smoothed using a 6-mm FWHM Gaussian kernel. We included incongruent and congruent conditions as main regressors and appended a parametric modulator for each condition. The modulation parameters for Conf 1, Conf 2, Conf 3, Conf 4, and Conf 5 trials were −2, −1, 0, 1 and 2, respectively. In addition, we also added event-related nuisance regressors, including error/missed trials, outlier trials (slower than three SDs of the mean or faster than 200 ms) and trials within two TRs of significant head motion (i.e., outlier TRs, defined as standard DVARS &gt; 1.5 or FD &gt; 0.9 mm from previous TR)<sup><xref rid="c41" ref-type="bibr">41</xref></sup>. On average there were 1.2 outlier TRs for each run. These regressors were convolved with a canonical hemodynamic response function (HRF) in SPM 12 (<ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm">http://www.fil.ion.ucl.ac.uk/spm</ext-link>). We further added volume-level nuisance regressors, including the six head motion parameters, the global signal, the white matter signal, the cerebrospinal fluid signal, and outlier TRs. Low-frequency signal drifts were filtered using a cutoff period of 128 s. The two runs were regarded as different sessions and incorporated into a single GLM to get more power. This yielded two beta maps (i.e., a main effect map and a parametric modulation map) for the incongruent and congruent conditions, respectively and for each subject. At the group level, paired t-tests were conducted between incongruent and congruent conditions, one for the main effect and the other for the parametric modulation effect. Since the spatial Stroop and Simon conflict change in the opposite direction to each other, a positive modulation effect would reflect a higher brain activation when there is more Simon conflict, and a negative modulation effect would reflect a higher brain activation for more spatial Stroop conflict. To avoid confusion, we converted the modulation effect of spatial Stroop to positive by using a contrast of [– (I_pm – C_pm)] throughout the results presentation. Results were thresholded by 3dclust function in AFNI <sup><xref rid="c69" ref-type="bibr">69</xref></sup> with voxel-wise <italic>p</italic> &lt; .005 and cluster-size &gt; 20 voxels, which was supposed to produce a desirable balance between Type I and II error rates<sup><xref rid="c70" ref-type="bibr">70</xref></sup>. To visualize the parametric modulation effects, we conducted a similar GLM (GLM2), except we used incongruent and congruent conditions from each conflict type as separate regressors with no parametric modulation. Then we extracted beta coefficients for each regressor and each participant with regions observed in GLM1 as regions of interest, and finally got the incongruent−congruent contrasts for each conflict type at the individual level. We reported the results in <xref rid="fig3" ref-type="fig">Fig. 3</xref>, <xref ref-type="table" rid="tblS1">Table S1</xref>, and <xref rid="figS3" ref-type="fig">Fig. S3</xref>. Visualization of the uni-voxel results was made by the MRIcron (<ext-link ext-link-type="uri" xlink:href="https://www.mccauslandcenter.sc.edu/mricro/mricron/">https://www.mccauslandcenter.sc.edu/mricro/mricron/</ext-link>).</p>
<p>The GLM3 aimed to prepare for the representational similarity analysis (see below). There were several differences compared to GLM1. The unsmoothed functional images after preprocessing were used. This model included 20 event-related regressors, one for each of the 5 (conflict type) × 2 (congruency condition) × 2 (arrow direction) conditions. The event-related nuisance regressors were similar to GLM1, but with additional regressors of response repetition and post-error trials to account for the nuisance inter-trial effects. To fully expand the variance, we conducted one GLM analysis for each run. After this procedure, a voxel-wise fMRI activation map was obtained per condition, run and subject.</p>
</sec>
<sec id="s4f">
<title>Representational similarity analysis (RSA)</title>
<p>To measure the neural representation of conflict similarity, we adopted the RSA. RSAs were conducted on each of the 360 cortical regions of a volumetric version of the MMP cortical atlas<sup><xref rid="c42" ref-type="bibr">42</xref></sup>. To de-correlate the factors of conflict type and orientation of stimulus location, we leveraged the between-subject manipulation of stimulus locations and conducted RSA in a cross-subject fashion (<xref rid="figS4" ref-type="fig">Fig. S4</xref>)<sup><xref rid="c60" ref-type="bibr">60</xref>,<xref rid="c71" ref-type="bibr">71</xref></sup>. The beta estimates from GLM3 were noise-normalized by dividing the original beta coefficients by the square root of the covariance matrix of the error terms<sup><xref rid="c72" ref-type="bibr">72</xref></sup>. For each cortical region, we calculated the Pearson’s correlations between fMRI activity patterns for each run and each subject, yielding a 1400 (20 conditions × 2 runs × 35 participants) × 1400 RSM. The correlations were calculated in a cross -voxel manner using the fMRI activation maps obtained from GLM3 described in the previous section. Similar to the behavioral analyses, we assumed the conflict similarity between two trials is commutive and hence collapsed the RSM along the diagonal and converted the lower triangle into a vector, which was then z-transformed and submitted to a linear mixed effect model as the dependent variable. The linear mixed effect model also included regressors of conflict similarity and orientation similarity. Importantly, conflict similarity was based on how Simon and spatial Stroop conflict are combined and hence was calculated by first rotating all subject’s stimulus location to the top-right and bottom-left quadrants, whereas orientation was calculated using original stimulus locations. As a result, the regressors representing conflict similarity and orientation similarity were de-correlated. Similarity between two conditions was measured as the cosine value of the angular difference. Other regressors included a target similarity regressor (i.e., whether the arrow directions were identical), a response similarity regressor (i.e., whether the correct responses were identical); a spatial Stroop distractor regressor (i.e., vertical distance between two stimulus locations); a Simon distractor regressor (i.e., horizontal distance between two stimulus locations). Additionally, we also included three regressors denoting the similarity of Run (i.e., whether two conditions are within the same run), Subject (i.e., whether two conditions are within the same subject), and Group (i.e., whether two conditions are within the same subject group, according to the stimulus-response mapping). We also added two regressors including ROI-mean fMRI activations for each condition of the pair to remove the possible uni-voxel influence on the RSM. A last term was the intercept. The intercept and slopes of the regressors were set as random effects at the subject level. Individual effects for each regressor were also extracted from the model for statistical inference and brain-behavioral correlation analyses. In brain-behavioral analyses, only the RT was used as behavioral measure to be consistent with the fMRI results, where the error trials were regressed out.</p>
<p>The statistical significance of these beta estimates was determined with one-sample t-tests (one-tailed). Multiple comparison correction was applied with false discovery rate (FDR) approach<sup><xref rid="c73" ref-type="bibr">73</xref></sup> across all cortical regions (<italic>p</italic><sub>FDR</sub> &lt; 0.05), together with a threshold of 0.001 for each region. To test if the representation strengths are different between congruent and incongruent conditions, we also conducted the RDM analyses using only congruent and incongruent trials separately. Individual effects were extracted from each model and tested using a paired t-test. To visualize the difference, we plotted the effect-related patterns (the predictor multiplied by the slope, plus the residual) as a function of the similarity levels (<xref rid="fig4" ref-type="fig">Fig. 4D</xref>).</p>
</sec>
<sec id="s4g">
<title>Representational connectivity analysis</title>
<p>To explore the possible relevance between the conflict type and the orientation effects, we conducted representational connectivity<sup><xref rid="c43" ref-type="bibr">43</xref></sup> between regions showing evidence encoding conflict similarity and orientation similarity. Similar to the RSA mentioned above, the z-transformed RSM vector of each region were extracted and submitted to a mixed linear model, with the RSM of the conflict type region (i.e., the right 8C) as the dependent variable, and the RSM of one of the orientation regions (e.g., bilateral V2) as the predictor. Intercept and the slope of the regressor were set as random effects at the subject level, and individual coefficients of the slope were extracted for further statistical analysis. The mixed effect model was conducted for each pair of regions, respectively. Considering there might be strong intrinsic correlations across the RSMs induced by the nuisance factors, such as the within-subject similarity, we added two sets of regions as control. First, we selected regions without showing any effects of interest (i.e., <italic>q</italic><sub>FDR</sub> &gt; 0.05 for all the conflict type, orientation, congruency, target, response, spatial Stroop distractor and Simon distractor effects). Second, we selected regions of orientation effect meeting the first but not the second criterion, to account for the potential correlation between regions of the two partly orthogonal regressors (<xref rid="figS6" ref-type="fig">Fig. S6</xref>). Existence of representational connectivity was defined by a higher connectivity slope than any of the control regions with paired-t tests.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgement</title>
<p>We thank Eliot Hazeltine for valuable comments on a previous version of this manuscript. The work was supported by the National Natural Science Foundation of China and the German Research Foundation (NSFC 62061136001/DFG TRR-169) to X.L. and China Postdoctoral Science Foundation (2019M650884) to G.Y.</p>
</ack>
<ref-list>
<title>Reference</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>Kornblum</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Hasbroucq</surname>, <given-names>T.</given-names></string-name>, and <string-name><surname>Osman</surname>, <given-names>A.</given-names></string-name> (<year>1990</year>). <article-title>Dimensional overlap: cognitive basis for stimulus-response compatibility--a model and taxonomy</article-title>. <source>Psychol. Rev</source>. <volume>97</volume>, <fpage>253</fpage>–<lpage>270</lpage>. <pub-id pub-id-type="doi">10.1037/0033-295x.97.2.253</pub-id>.</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Freitas</surname>, <given-names>A.L.</given-names></string-name>, <string-name><surname>Bahar</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>S.</given-names></string-name>, and <string-name><surname>Banai</surname>, <given-names>R.</given-names></string-name> (<year>2007</year>). <article-title>Contextual adjustments in cognitive control across tasks</article-title>. <source>Psychol. Sci</source>. <volume>18</volume>, <fpage>1040</fpage>–<lpage>1043</lpage>. <pub-id pub-id-type="doi">10.1111/j.1467-9280.2007.02022.x</pub-id>.</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>Magen</surname>, <given-names>H.</given-names></string-name>, and <string-name><surname>Cohen</surname>, <given-names>A.</given-names></string-name> (<year>2007</year>). <article-title>Modularity beyond perception: evidence from single task interference paradigms</article-title>. <source>Cogn. Psychol</source>. <volume>55</volume>, <fpage>1</fpage>–<lpage>36</lpage>. <pub-id pub-id-type="doi">10.1016/j.cogpsych.2006.09.003</pub-id>.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Yang</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Nan</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Zheng</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Wu</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>Q.</given-names></string-name>, and <string-name><surname>Liu</surname>, <given-names>X.</given-names></string-name> (<year>2017</year>). <article-title>Distinct cognitive control mechanisms as revealed by modality-specific conflict adaptation effects</article-title>. <source>J. Exp. Psychol. Hum. Percept. Perform</source>. <volume>43</volume>, <fpage>807</fpage>–<lpage>818</lpage>. <pub-id pub-id-type="doi">10.1037/xhp0000351</pub-id>.</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Hazeltine</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Lightman</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Schwarb</surname>, <given-names>H.</given-names></string-name>, and <string-name><surname>Schumacher</surname>, <given-names>E.H.</given-names></string-name> (<year>2011</year>). <article-title>The boundaries of sequential modulations: evidence for set-level control</article-title>. <source>J. Exp. Psychol. Hum. Percept. Perform</source>. <volume>37</volume>, <fpage>1898</fpage>–<lpage>1914</lpage>. <pub-id pub-id-type="doi">10.1037/a0024662</pub-id>.</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Liu</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Banich</surname>, <given-names>M.T.</given-names></string-name>, <string-name><surname>Jacobson</surname>, <given-names>B.L.</given-names></string-name>, and <string-name><surname>Tanabe</surname>, <given-names>J.L.</given-names></string-name> (<year>2004</year>). <article-title>Common and distinct neural substrates of attentional control in an integrated Simon and spatial Stroop task as assessed by event-related fMRI</article-title>. <source>NeuroImage</source> <volume>22</volume>, <fpage>1097</fpage>–<lpage>1106</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2004.02.033</pub-id>.</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Jiang</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Egner</surname>, <given-names>T.</given-names></string-name> (<year>2014</year>). <article-title>Using neural pattern classifiers to quantify the modularity of conflict-control mechanisms in the human brain</article-title>. <source>Cereb Cortex</source> <volume>24</volume>, <fpage>1793</fpage>–<lpage>1805</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bht029</pub-id>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Kan</surname>, <given-names>I.P.</given-names></string-name>, <string-name><surname>Teubner-Rhodes</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Drummey</surname>, <given-names>A.B.</given-names></string-name>, <string-name><surname>Nutile</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Krupa</surname>, <given-names>L.</given-names></string-name>, and <string-name><surname>Novick</surname>, <given-names>J.M.</given-names></string-name> (<year>2013</year>). <article-title>To adapt or not to adapt: the question of domain-general cognitive control</article-title>. <source>Cognition</source> <volume>129</volume>, <fpage>637</fpage>–<lpage>651</lpage>. <pub-id pub-id-type="doi">10.1016/j.cognition.2013.09.001</pub-id>.</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Peterson</surname>, <given-names>B.S.</given-names></string-name>, <string-name><surname>Kane</surname>, <given-names>M.J.</given-names></string-name>, <string-name><surname>Alexander</surname>, <given-names>G.M.</given-names></string-name>, <string-name><surname>Lacadie</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Skudlarski</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Leung</surname>, <given-names>H.C.</given-names></string-name>, <string-name><surname>May</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Gore</surname>, <given-names>J.C.</given-names></string-name> (<year>2002</year>). <article-title>An event-related functional MRI study comparing interference effects in the Simon and Stroop tasks</article-title>. <source>Brain Res. Cogn. Brain Res</source>. <volume>13</volume>, <fpage>427</fpage>–<lpage>440</lpage>. <pub-id pub-id-type="doi">10.1016/s0926-6410(02)00054-x</pub-id>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Wu</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Spagna</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Schulz</surname>, <given-names>K.P.</given-names></string-name>, <string-name><surname>Hof</surname>, <given-names>P.R.</given-names></string-name>, and <string-name><surname>Fan</surname>, <given-names>J.</given-names></string-name> (<year>2020</year>). <article-title>Supramodal Mechanisms of the Cognitive Control Network in Uncertainty Processing</article-title>. <source>Cereb. Cortex</source> <volume>30</volume>, <fpage>6336</fpage>–<lpage>6349</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhaa189</pub-id> %J Cerebral Cortex.</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>Assem</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Glasser</surname>, <given-names>M.F.</given-names></string-name>, <string-name><surname>Van Essen</surname>, <given-names>D.C.</given-names></string-name>, and <string-name><surname>Duncan</surname>, <given-names>J.</given-names></string-name> (<year>2020</year>). <article-title>A Domain-General Cognitive Core Defined in Multimodally Parcellated Human Cortex</article-title>. <source>Cereb. Cortex</source> <volume>30</volume>, <fpage>4361</fpage>–<lpage>4380</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhaa023</pub-id>.</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>Cole</surname>, <given-names>M.W.</given-names></string-name>, <string-name><surname>Reynolds</surname>, <given-names>J.R.</given-names></string-name>, <string-name><surname>Power</surname>, <given-names>J.D.</given-names></string-name>, <string-name><surname>Repovs</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Anticevic</surname>, <given-names>A.</given-names></string-name>, and <string-name><surname>Braver</surname>, <given-names>T.S.</given-names></string-name> (<year>2013</year>). <article-title>Multi-task connectivity reveals flexible hubs for adaptive task control</article-title>. <source>Nat. Neurosci</source>. <volume>16</volume>, <fpage>1348</fpage>–<lpage>1355</lpage>. <pub-id pub-id-type="doi">10.1038/nn.3470</pub-id>.</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Musslick</surname>, <given-names>S.</given-names></string-name>, and <string-name><surname>Cohen</surname>, <given-names>J.D.</given-names></string-name> (<year>2021</year>). <article-title>Rationalizing constraints on the capacity for cognitive control</article-title>. <source>Trends Cogn Sci</source> <volume>25</volume>, <fpage>757</fpage>–<lpage>775</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2021.06.001</pub-id>.</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="book"><string-name><surname>Cosmides</surname>, <given-names>L.</given-names></string-name>, and <string-name><surname>Tooby</surname>, <given-names>J.</given-names></string-name> (<year>1994</year>). <chapter-title>Origins of domain specificity: The evolution of functional organization</chapter-title>. <source>In Mapping the mind: Domain specificity in cognition and culture</source>, <person-group person-group-type="editor"><string-name><given-names>L.A.</given-names> <surname>Hirschfeld</surname></string-name>, and <string-name><given-names>S.A.</given-names> <surname>Gelman</surname></string-name>, eds</person-group>. (<publisher-name>Cambridge University Press</publisher-name>).</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Egner</surname>, <given-names>T.</given-names></string-name> (<year>2008</year>). <article-title>Multiple conflict-driven control mechanisms in the human brain</article-title>. <source>Trends Cogn. Sci</source>. <volume>12</volume>, <fpage>374</fpage>–<lpage>380</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2008.07.001</pub-id>.</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>Kim</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Chung</surname>, <given-names>C.</given-names></string-name>, and <string-name><surname>Kim</surname>, <given-names>J.</given-names></string-name> (<year>2012</year>). <article-title>Conflict adjustment through domain-specific multiple cognitive control mechanisms</article-title>. <source>Brain Res</source>. <volume>1444</volume>, <fpage>55</fpage>–<lpage>64</lpage>. <pub-id pub-id-type="doi">10.1016/j.brainres.2012.01.023</pub-id>.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><surname>Abrahamse</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Braem</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Notebaert</surname>, <given-names>W.</given-names></string-name>, and <string-name><surname>Verguts</surname>, <given-names>T.</given-names></string-name> (<year>2016</year>). <article-title>Grounding cognitive control in associative learning</article-title>. <source>Psychol. Bull</source>. <volume>142</volume>, <fpage>693</fpage>–<lpage>728</lpage>. <pub-id pub-id-type="doi">10.1037/bul0000047</pub-id>.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><string-name><surname>Freitas</surname>, <given-names>A.L.</given-names></string-name>, and <string-name><surname>Clark</surname>, <given-names>S.L.</given-names></string-name> (<year>2015</year>). <article-title>Generality and specificity in cognitive control: conflict adaptation within and across selective-attention tasks but not across selective-attention and Simon tasks</article-title>. <source>Psychol. Res</source>. <volume>79</volume>, <fpage>143</fpage>–<lpage>162</lpage>. <pub-id pub-id-type="doi">10.1007/s00426-014-0540-1</pub-id>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><surname>Li</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Qi</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Cole</surname>, <given-names>M.W.</given-names></string-name>, and <string-name><surname>Liu</surname>, <given-names>X.</given-names></string-name> (<year>2017</year>). <article-title>Conflict detection and resolution rely on a combination of common and distinct cognitive control networks</article-title>. <source>Neurosci. Biobehav. Rev</source>. <volume>83</volume>, <fpage>123</fpage>–<lpage>131</lpage>. <pub-id pub-id-type="doi">10.1016/j.neubiorev.2017.09.032</pub-id>.</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><string-name><surname>Fu</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Beam</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Chung</surname>, <given-names>J.M.</given-names></string-name>, <string-name><surname>Reed</surname>, <given-names>C.M.</given-names></string-name>, <string-name><surname>Mamelak</surname>, <given-names>A.N.</given-names></string-name>, <string-name><surname>Adolphs</surname>, <given-names>R.</given-names></string-name>, and <string-name><surname>Rutishauser</surname>, <given-names>U.</given-names></string-name> (<year>2022</year>). <article-title>The geometry of domain-general performance monitoring in the human medial frontal cortex</article-title>. <source>Science</source> <volume>376</volume>, <fpage>eabm9922</fpage>. <pub-id pub-id-type="doi">10.1126/science.abm9922</pub-id>.</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Braem</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Abrahamse</surname>, <given-names>E.L.</given-names></string-name>, <string-name><surname>Duthoo</surname>, <given-names>W.</given-names></string-name>, and <string-name><surname>Notebaert</surname>, <given-names>W.</given-names></string-name> (<year>2014</year>). <article-title>What determines the specificity of conflict adaptation? A review, critical analysis, and proposed synthesis</article-title>. <source>Front. Psychol</source>. <volume>5</volume>, <fpage>1134</fpage>. <pub-id pub-id-type="doi">10.3389/fpsyg.2014.01134</pub-id>.</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>Bellmund</surname>, <given-names>J.L.S.</given-names></string-name>, <string-name><surname>Gardenfors</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Moser</surname>, <given-names>E.I.</given-names></string-name>, and <string-name><surname>Doeller</surname>, <given-names>C.F.</given-names></string-name> (<year>2018</year>). <article-title>Navigating cognition: Spatial codes for human thinking</article-title>. <source>Science</source> <volume>362</volume>. <pub-id pub-id-type="doi">10.1126/science.aat6766</pub-id>.</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Behrens</surname>, <given-names>T.E.J.</given-names></string-name>, <string-name><surname>Muller</surname>, <given-names>T.H.</given-names></string-name>, <string-name><surname>Whittington</surname>, <given-names>J.C.R.</given-names></string-name>, <string-name><surname>Mark</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Baram</surname>, <given-names>A.B.</given-names></string-name>, <string-name><surname>Stachenfeld</surname>, <given-names>K.L.</given-names></string-name>, and <string-name><surname>Kurth-Nelson</surname>, <given-names>Z.</given-names></string-name> (<year>2018</year>). <article-title>What Is a Cognitive Map? Organizing Knowledge for Flexible Behavior</article-title>. <source>Neuron</source> <volume>100</volume>, <fpage>490</fpage>–<lpage>509</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2018.10.002</pub-id>.</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><surname>Schuck</surname>, <given-names>N.W.</given-names></string-name>, <string-name><surname>Cai</surname>, <given-names>M.B.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>R.C.</given-names></string-name>, and <string-name><surname>Niv</surname>, <given-names>Y.</given-names></string-name> (<year>2016</year>). <article-title>Human Orbitofrontal Cortex Represents a Cognitive Map of State Space</article-title>. <source>Neuron</source> <volume>91</volume>, <fpage>1402</fpage>–<lpage>1412</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2016.08.019</pub-id>.</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Park</surname>, <given-names>S.A.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>D.S.</given-names></string-name>, <string-name><surname>Nili</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Ranganath</surname>, <given-names>C.</given-names></string-name>, and <string-name><surname>Boorman</surname>, <given-names>E.D.</given-names></string-name> (<year>2020</year>). <article-title>Map Making: Constructing, Combining, and Inferring on Abstract Cognitive Maps</article-title>. <source>Neuron</source> <volume>107</volume>, <fpage>1226</fpage>–<lpage>1238 e1228</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2020.06.030</pub-id>.</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><string-name><surname>Badre</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Bhandari</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Keglovits</surname>, <given-names>H.</given-names></string-name>, and <string-name><surname>Kikumoto</surname>, <given-names>A.</given-names></string-name> (<year>2021</year>). <article-title>The dimensionality of neural representations for control</article-title>. <source>Curr Opin Behav Sci</source> <volume>38</volume>, <fpage>20</fpage>–<lpage>28</lpage>. <pub-id pub-id-type="doi">10.1016/j.cobeha.2020.07.002</pub-id>.</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><string-name><surname>Grahek</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Leng</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Fahey</surname>, <given-names>M.P.</given-names></string-name>, <string-name><surname>Yee</surname>, <given-names>D.</given-names></string-name>, and <string-name><surname>Shenhav</surname>, <given-names>A.</given-names></string-name> (<year>2022</year>). <source>Empirical and Computational Evidence for Reconfiguration Costs During Within-Task Adjustments in Cognitive Control. In</source> <volume>44</volume>.</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><string-name><surname>Yang</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Xu</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Nan</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Wu</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>Q.</given-names></string-name>, and <string-name><surname>Liu</surname>, <given-names>X.</given-names></string-name> (<year>2021</year>). <article-title>The congruency sequence effect is modulated by the similarity of conflicts</article-title>. <source>J. Exp. Psychol. Learn. Mem. Cogn</source>. <volume>47</volume>, <fpage>1705</fpage>–<lpage>1719</lpage>. <pub-id pub-id-type="doi">10.1037/xlm0001054</pub-id>.</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><string-name><surname>Vaidya</surname>, <given-names>A.R.</given-names></string-name>, <string-name><surname>Jones</surname>, <given-names>H.M.</given-names></string-name>, <string-name><surname>Castillo</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Badre</surname>, <given-names>D.</given-names></string-name> (<year>2021</year>). <article-title>Neural representation of abstract task structure during generalization</article-title>. <source>Elife</source> <volume>10</volume>, <fpage>1</fpage>–<lpage>26</lpage>. <pub-id pub-id-type="doi">10.7554/eLife.63226</pub-id>.</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><string-name><surname>Vaidya</surname>, <given-names>A.R.</given-names></string-name>, and <string-name><surname>Badre</surname>, <given-names>D.</given-names></string-name> (<year>2022</year>). <article-title>Abstract task representations for inference and control</article-title>. <source>Trends Cogn Sci</source> <volume>26</volume>, <fpage>484</fpage>–<lpage>498</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2022.03.009</pub-id>.</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><string-name><surname>MacDowell</surname>, <given-names>C.J.</given-names></string-name>, <string-name><surname>Tafazoli</surname>, <given-names>S.</given-names></string-name>, and <string-name><surname>Buschman</surname>, <given-names>T.J.</given-names></string-name> (<year>2022</year>). <article-title>A Goldilocks theory of cognitive control: Balancing precision and efficiency with low-dimensional control states</article-title>. <source>Curr Opin Neurobiol</source> <volume>76</volume>, <fpage>102606</fpage>. <pub-id pub-id-type="doi">10.1016/j.conb.2022.102606</pub-id>.</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><string-name><surname>Freund</surname>, <given-names>M.C.</given-names></string-name>, <string-name><surname>Bugg</surname>, <given-names>J.M.</given-names></string-name>, and <string-name><surname>Braver</surname>, <given-names>T.S.</given-names></string-name> (<year>2021</year>). <article-title>A Representational Similarity Analysis of Cognitive Control during Color-Word Stroop</article-title>. <source>J. Neurosci</source>. <volume>41</volume>, <fpage>7388</fpage>–<lpage>7402</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.2956-20.2021</pub-id>.</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><string-name><surname>Lu</surname>, <given-names>C.H.</given-names></string-name>, and <string-name><surname>Proctor</surname>, <given-names>R.W.</given-names></string-name> (<year>1995</year>). <article-title>The influence of irrelevant location information on performance: A review of the Simon and spatial Stroop effects</article-title>. <source>Psychon Bull Rev</source> <volume>2</volume>, <fpage>174</fpage>–<lpage>207</lpage>. <pub-id pub-id-type="doi">10.3758/BF03210959</pub-id>.</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><string-name><surname>Simon</surname>, <given-names>J.R.</given-names></string-name>, and <string-name><surname>Small</surname>, <given-names>A.M.</given-names>, <suffix>Jr</suffix></string-name>. (<year>1969</year>). <article-title>Processing auditory information: interference from an irrelevant cue</article-title>. <source>J. Appl. Psychol</source>. <volume>53</volume>, <fpage>433</fpage>–<lpage>435</lpage>. <pub-id pub-id-type="doi">10.1037/h0028034</pub-id>.</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><string-name><surname>Egner</surname>, <given-names>T.</given-names></string-name> (<year>2007</year>). <article-title>Congruency sequence effects and cognitive control</article-title>. <source>Cogn. Affect. Behav. Neurosci</source>. <volume>7</volume>, <fpage>380</fpage>–<lpage>390</lpage>. <pub-id pub-id-type="doi">10.3758/cabn.7.4.380</pub-id>.</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><string-name><surname>Schmidt</surname>, <given-names>J.R.</given-names></string-name>, and <string-name><surname>Weissman</surname>, <given-names>D.H.</given-names></string-name> (<year>2014</year>). <article-title>Congruency sequence effects without feature integration or contingency learning confounds</article-title>. <source>PLoS One</source> <volume>9</volume>, <fpage>e102337</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0102337</pub-id>.</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><string-name><surname>Torres-Quesada</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Funes</surname>, <given-names>M.J.</given-names></string-name>, and <string-name><surname>Lupianez</surname>, <given-names>J.</given-names></string-name> (<year>2013</year>). <article-title>Dissociating proportion congruent and conflict adaptation effects in a Simon-Stroop procedure</article-title>. <source>Acta Psychol. (Amst</source>.) <volume>142</volume>, <fpage>203</fpage>–<lpage>210</lpage>. <pub-id pub-id-type="doi">10.1016/j.actpsy.2012.11.015</pub-id>.</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><string-name><surname>Akcay</surname>, <given-names>C.</given-names></string-name>, and <string-name><surname>Hazeltine</surname>, <given-names>E.</given-names></string-name> (<year>2011</year>). <article-title>Domain-specific conflict adaptation without feature repetitions</article-title>. <source>Psychon Bull Rev</source> <volume>18</volume>, <fpage>505</fpage>–<lpage>511</lpage>. <pub-id pub-id-type="doi">10.3758/s13423-011-0084-y</pub-id>.</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><string-name><surname>Egner</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Delano</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Hirsch</surname>, <given-names>J.</given-names></string-name> (<year>2007</year>). <article-title>Separate conflict-specific cognitive control mechanisms in the human brain</article-title>. <source>NeuroImage</source> <volume>35</volume>, <fpage>940</fpage>–<lpage>948</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.11.061</pub-id>.</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><string-name><surname>Botvinick</surname>, <given-names>M.M.</given-names></string-name>, <string-name><surname>Cohen</surname>, <given-names>J.D.</given-names></string-name>, and <string-name><surname>Carter</surname>, <given-names>C.S.</given-names></string-name> (<year>2004</year>). <article-title>Conflict monitoring and anterior cingulate cortex: an update</article-title>. <source>Trends Cogn. Sci</source>. <volume>8</volume>, <fpage>539</fpage>–<lpage>546</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2004.10.003</pub-id>.</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><string-name><surname>Jiang</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>S.F.</given-names></string-name>, <string-name><surname>Guo</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Fernandez</surname>, <given-names>C.</given-names></string-name>, and <string-name><surname>Wagner</surname>, <given-names>A.D.</given-names></string-name> (<year>2020</year>). <article-title>Prefrontal reinstatement of contextual task demand is predicted by separable hippocampal patterns</article-title>. <source>Nat Commun</source> <volume>11</volume>, <fpage>2053</fpage>. <pub-id pub-id-type="doi">10.1038/s41467-020-15928-z</pub-id>.</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><string-name><surname>Glasser</surname>, <given-names>M.F.</given-names></string-name>, <string-name><surname>Coalson</surname>, <given-names>T.S.</given-names></string-name>, <string-name><surname>Robinson</surname>, <given-names>E.C.</given-names></string-name>, <string-name><surname>Hacker</surname>, <given-names>C.D.</given-names></string-name>, <string-name><surname>Harwell</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Yacoub</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Ugurbil</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Andersson</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Beckmann</surname>, <given-names>C.F.</given-names></string-name>, <string-name><surname>Jenkinson</surname>, <given-names>M.</given-names></string-name>, <etal>et al.</etal> (<year>2016</year>). <article-title>A multi-modal parcellation of human cerebral cortex</article-title>. <source>Nature</source> <volume>536</volume>, <fpage>171</fpage>–<lpage>178</lpage>. <pub-id pub-id-type="doi">10.1038/nature18933</pub-id>.</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Mur</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Bandettini</surname>, <given-names>P.</given-names></string-name> (<year>2008</year>). <article-title>Representational similarity analysis - connecting the branches of systems neuroscience</article-title>. <source>Front Syst Neurosci</source> <volume>2</volume>, <fpage>4</fpage>. <pub-id pub-id-type="doi">10.3389/neuro.06.004.2008</pub-id>.</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><string-name><surname>Li</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Nan</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>K.</given-names></string-name>, and <string-name><surname>Liu</surname>, <given-names>X.</given-names></string-name> (<year>2014</year>). <article-title>Independent processing of stimulus-stimulus and stimulus-response conflicts</article-title>. <source>PLoS One</source> <volume>9</volume>, <fpage>e89249</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0089249</pub-id>.</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><string-name><surname>Wang</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Zheng</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>H.</given-names></string-name>, and <string-name><surname>Liu</surname>, <given-names>X.</given-names></string-name> (<year>2014</year>). <article-title>Temporal and spectral profiles of stimulus-stimulus and stimulus-response conflict processing</article-title>. <source>NeuroImage</source> <volume>89</volume>, <fpage>280</fpage>–<lpage>288</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.11.045</pub-id>.</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><string-name><surname>Liu</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Park</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Gu</surname>, <given-names>X.</given-names></string-name>, and <string-name><surname>Fan</surname>, <given-names>J.</given-names></string-name> (<year>2010</year>). <article-title>Dimensional overlap accounts for independence and integration of stimulus-response compatibility effects</article-title>. <source>Atten. Percept. Psychophys</source>. <volume>72</volume>, <fpage>1710</fpage>–<lpage>1720</lpage>. <pub-id pub-id-type="doi">10.3758/APP.72.6.1710</pub-id>.</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><string-name><surname>Niv</surname>, <given-names>Y.</given-names></string-name> (<year>2019</year>). <article-title>Learning task-state representations</article-title>. <source>Nat Neurosci</source> <volume>22</volume>, <fpage>1544</fpage>–<lpage>1553</lpage>. <pub-id pub-id-type="doi">10.1038/s41593-019-0470-8</pub-id>.</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><string-name><surname>Constantinescu</surname>, <given-names>A.O.</given-names></string-name>, <string-name><surname>O’Reilly</surname>, <given-names>J.X.</given-names></string-name>, and <string-name><surname>Behrens</surname>, <given-names>T.E.J.</given-names></string-name> (<year>2016</year>). <article-title>Organizing conceptual knowledge in humans with a gridlike code</article-title>. <source>Science</source> <volume>352</volume>, <fpage>1464</fpage>–<lpage>1468</lpage>. <pub-id pub-id-type="doi">10.1126/science.aaf0941</pub-id>.</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><string-name><surname>Miller</surname>, <given-names>E.K.</given-names></string-name>, and <string-name><surname>Cohen</surname>, <given-names>J.D.</given-names></string-name> (<year>2001</year>). <article-title>An integrative theory of prefrontal cortex function</article-title>. <source>Annu. Rev. Neurosci</source>. <volume>24</volume>, <fpage>167</fpage>–<lpage>202</lpage>. <pub-id pub-id-type="doi">10.1146/annurev.neuro.24.1.167</pub-id>.</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><string-name><surname>Milner</surname>, <given-names>B.</given-names></string-name> (<year>1963</year>). <article-title>Effects of Different Brain Lesions on Card Sorting - Role of Frontal Lobes</article-title>. <source>Arch Neurol-Chicago</source> <volume>9</volume>, <fpage>90</fpage>-&amp;. DOI <pub-id pub-id-type="doi">10.1001/archneur.1963.00460070100010</pub-id>.</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><string-name><surname>Mansouri</surname>, <given-names>F.A.</given-names></string-name>, <string-name><surname>Buckley</surname>, <given-names>M.J.</given-names></string-name>, and <string-name><surname>Tanaka</surname>, <given-names>K.</given-names></string-name> (<year>2007</year>). <article-title>Mnemonic function of the dorsolateral prefrontal cortex in conflict-induced behavioral adjustment</article-title>. <source>Science</source> <volume>318</volume>, <fpage>987</fpage>–<lpage>990</lpage>. <pub-id pub-id-type="doi">10.1126/science.1146384</pub-id>.</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><string-name><surname>Duncan</surname>, <given-names>J.</given-names></string-name> (<year>2010</year>). <article-title>The multiple-demand (MD) system of the primate brain: mental programs for intelligent behaviour</article-title>. <source>Trends Cogn. Sci</source>. <volume>14</volume>, <fpage>172</fpage>–<lpage>179</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2010.01.004</pub-id>.</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><string-name><surname>Vanderhasselt</surname>, <given-names>M.A.</given-names></string-name>, <string-name><surname>De Raedt</surname>, <given-names>R.</given-names></string-name>, and <string-name><surname>Baeken</surname>, <given-names>C.</given-names></string-name> (<year>2009</year>). <article-title>Dorsolateral prefrontal cortex and Stroop performance: tackling the lateralization</article-title>. <source>Psychon Bull Rev</source> <volume>16</volume>, <fpage>609</fpage>–<lpage>612</lpage>. <pub-id pub-id-type="doi">10.3758/PBR.16.3.609</pub-id>.</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><string-name><surname>Friehs</surname>, <given-names>M.A.</given-names></string-name>, <string-name><surname>Klaus</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Singh</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Frings</surname>, <given-names>C.</given-names></string-name>, and <string-name><surname>Hartwigsen</surname>, <given-names>G.</given-names></string-name> (<year>2020</year>). <article-title>Perturbation of the right prefrontal cortex disrupts interference control</article-title>. <source>NeuroImage</source> <volume>222</volume>, <fpage>117279</fpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117279</pub-id>.</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><string-name><surname>Reverberi</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Gorgen</surname>, <given-names>K.</given-names></string-name>, and <string-name><surname>Haynes</surname>, <given-names>J.D.</given-names></string-name> (<year>2012</year>). <article-title>Compositionality of rule representations in human prefrontal cortex</article-title>. <source>Cereb Cortex</source> <volume>22</volume>, <fpage>1237</fpage>–<lpage>1246</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhr200</pub-id>.</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><string-name><surname>Rmus</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Ritz</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Hunter</surname>, <given-names>L.E.</given-names></string-name>, <string-name><surname>Bornstein</surname>, <given-names>A.M.</given-names></string-name>, and <string-name><surname>Shenhav</surname>, <given-names>A.</given-names></string-name> (<year>2022</year>). <article-title>Humans can navigate complex graph structures acquired during latent learning</article-title>. <source>Cognition</source> <volume>225</volume>, <fpage>105103</fpage>. <pub-id pub-id-type="doi">10.1016/j.cognition.2022.105103</pub-id>.</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="other"><string-name><surname>Flesch</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Juechems</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Dumbalska</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Saxe</surname>, <given-names>A.</given-names></string-name>, and <string-name><surname>Summerfield</surname>, <given-names>C.</given-names></string-name> (<year>2022</year>). <article-title>Orthogonal representations for robust context-dependent task performance in brains and neural networks</article-title>. <source>Neuron</source>. <pub-id pub-id-type="doi">10.1016/j.neuron.2022.01.005</pub-id>.</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><string-name><surname>Gilbert</surname>, <given-names>C.D.</given-names></string-name>, and <string-name><surname>Li</surname>, <given-names>W.</given-names></string-name> (<year>2013</year>). <article-title>Top-down influences on visual processing</article-title>. <source>Nat Rev Neurosci</source> <volume>14</volume>, <fpage>350</fpage>–<lpage>363</lpage>. <pub-id pub-id-type="doi">10.1038/nrn3476</pub-id>.</mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="journal"><string-name><surname>Duncan</surname>, <given-names>J.</given-names></string-name> (<year>2013</year>). <article-title>The structure of cognition: attentional episodes in mind and brain</article-title>. <source>Neuron</source> <volume>80</volume>, <fpage>35</fpage>–<lpage>50</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2013.09.015</pub-id>.</mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="journal"><string-name><surname>Freund</surname>, <given-names>M.C.</given-names></string-name>, <string-name><surname>Etzel</surname>, <given-names>J.A.</given-names></string-name>, and <string-name><surname>Braver</surname>, <given-names>T.S.</given-names></string-name> (<year>2021</year>). <article-title>Neural Coding of Cognitive Control: The Representational Similarity Analysis Approach</article-title>. <source>Trends Cogn. Sci</source>. <volume>25</volume>, <fpage>622</fpage>–<lpage>638</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2021.03.011</pub-id>.</mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="journal"><string-name><surname>Hommel</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Proctor</surname>, <given-names>R.W.</given-names></string-name>, and <string-name><surname>Vu</surname>, <given-names>K.P.</given-names></string-name> (<year>2004</year>). <article-title>A feature-integration account of sequential effects in the Simon task</article-title>. <source>Psychol. Res</source>. <volume>68</volume>, <fpage>1</fpage>–<lpage>17</lpage>. <pub-id pub-id-type="doi">10.1007/s00426-003-0132-y</pub-id>.</mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="journal"><string-name><surname>Braem</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Bugg</surname>, <given-names>J.M.</given-names></string-name>, <string-name><surname>Schmidt</surname>, <given-names>J.R.</given-names></string-name>, <string-name><surname>Crump</surname>, <given-names>M.J.C.</given-names></string-name>, <string-name><surname>Weissman</surname>, <given-names>D.H.</given-names></string-name>, <string-name><surname>Notebaert</surname>, <given-names>W.</given-names></string-name>, and <string-name><surname>Egner</surname>, <given-names>T.</given-names></string-name> (<year>2019</year>). <article-title>Measuring Adaptive Control in Conflict Tasks</article-title>. <source>Trends Cogn. Sci</source>. <volume>23</volume>, <fpage>769</fpage>–<lpage>783</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2019.07.002</pub-id>.</mixed-citation></ref>
<ref id="c63"><label>63.</label><mixed-citation publication-type="journal"><string-name><surname>MacLeod</surname>, <given-names>C.M.</given-names></string-name> (<year>1991</year>). <article-title>Half a century of research on the Stroop effect: an integrative review</article-title>. <source>Psychol. Bull</source>. <volume>109</volume>, <fpage>163</fpage>–<lpage>203</lpage>.</mixed-citation></ref>
<ref id="c64"><label>64.</label><mixed-citation publication-type="journal"><string-name><surname>Wager</surname>, <given-names>T.D.</given-names></string-name>, and <string-name><surname>Nichols</surname>, <given-names>T.E.</given-names></string-name> (<year>2003</year>). <article-title>Optimization of experimental design in fMRI: a general framework using a genetic algorithm</article-title>. <source>NeuroImage</source> <volume>18</volume>, <fpage>293</fpage>–<lpage>309</lpage>. <pub-id pub-id-type="doi">10.1016/S1053-8119(02)00046-0</pub-id>.</mixed-citation></ref>
<ref id="c65"><label>65.</label><mixed-citation publication-type="journal"><string-name><surname>Durnez</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Blair</surname>, <given-names>R.</given-names></string-name>, and <string-name><surname>Poldrack</surname>, <given-names>R.A.</given-names></string-name> (<year>2018</year>). <article-title>Neurodesign: Optimal Experimental Designs for Task fMRI</article-title>. <source>BioRxiv</source>, <volume>119594</volume>. <pub-id pub-id-type="doi">10.1101/119594</pub-id>.</mixed-citation></ref>
<ref id="c66"><label>66.</label><mixed-citation publication-type="journal"><string-name><surname>Esteban</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Markiewicz</surname>, <given-names>C.J.</given-names></string-name>, <string-name><surname>Blair</surname>, <given-names>R.W.</given-names></string-name>, <string-name><surname>Moodie</surname>, <given-names>C.A.</given-names></string-name>, <string-name><surname>Isik</surname>, <given-names>A.I.</given-names></string-name>, <string-name><surname>Erramuzpe</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kent</surname>, <given-names>J.D.</given-names></string-name>, <string-name><surname>Goncalves</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>DuPre</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Snyder</surname>, <given-names>M.</given-names></string-name>, <etal>et al.</etal> (<year>2019</year>). <article-title>fMRIPrep: a robust preprocessing pipeline for functional MRI</article-title>. <source>Nat. Methods</source> <volume>16</volume>, <fpage>111</fpage>–<lpage>116</lpage>. <pub-id pub-id-type="doi">10.1038/s41592-018-0235-4</pub-id>.</mixed-citation></ref>
<ref id="c67"><label>67.</label><mixed-citation publication-type="journal"><string-name><surname>Gorgolewski</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Burns</surname>, <given-names>C.D.</given-names></string-name>, <string-name><surname>Madison</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Clark</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Halchenko</surname>, <given-names>Y.O.</given-names></string-name>, <string-name><surname>Waskom</surname>, <given-names>M.L.</given-names></string-name>, and <string-name><surname>Ghosh</surname>, <given-names>S.S.</given-names></string-name> (<year>2011</year>). <article-title>Nipype: a flexible, lightweight and extensible neuroimaging data processing framework in python</article-title>. <source>Front. Neuroinform</source>. <volume>5</volume>, <fpage>13</fpage>. <pub-id pub-id-type="doi">10.3389/fninf.2011.00013</pub-id>.</mixed-citation></ref>
<ref id="c68"><label>68.</label><mixed-citation publication-type="journal"><string-name><surname>Jenkinson</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Bannister</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Brady</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Smith</surname>, <given-names>S.</given-names></string-name> (<year>2002</year>). <article-title>Improved Optimization for the Robust and Accurate Linear Registration and Motion Correction of Brain Images</article-title>. <source>NeuroImage</source> <volume>17</volume>, <fpage>825</fpage>–<lpage>841</lpage>. <pub-id pub-id-type="doi">10.1006/nimg.2002.1132</pub-id>.</mixed-citation></ref>
<ref id="c69"><label>69.</label><mixed-citation publication-type="journal"><string-name><surname>Cox</surname>, <given-names>R.W.</given-names></string-name>, and <string-name><surname>Hyde</surname>, <given-names>J.S.</given-names></string-name> (<year>1997</year>). <article-title>Software tools for analysis and visualization of fMRI data</article-title>. <source>NMR Biomed</source>. <volume>10</volume>, <fpage>171</fpage>–<lpage>178</lpage>. <pub-id pub-id-type="doi">10.1002/(sici)1099-1492(199706/08)10:4/5&lt;171::Aid-nbm453&gt;3.0.Co;2-l</pub-id>.</mixed-citation></ref>
<ref id="c70"><label>70.</label><mixed-citation publication-type="journal"><string-name><surname>Lieberman</surname>, <given-names>M.D.</given-names></string-name>, and <string-name><surname>Cunningham</surname>, <given-names>W.A.</given-names></string-name> (<year>2009</year>). <article-title>Type I and Type II error concerns in fMRI research: re-balancing the scale</article-title>. <source>Soc. Cogn. Affect. Neurosci</source>. <volume>4</volume>, <fpage>423</fpage>–<lpage>428</lpage>. <pub-id pub-id-type="doi">10.1093/scan/nsp052</pub-id>.</mixed-citation></ref>
<ref id="c71"><label>71.</label><mixed-citation publication-type="journal"><string-name><surname>van Baar</surname>, <given-names>J.M.</given-names></string-name>, <string-name><surname>Chang</surname>, <given-names>L.J.</given-names></string-name>, and <string-name><surname>Sanfey</surname>, <given-names>A.G.</given-names></string-name> (<year>2019</year>). <article-title>The computational and neural substrates of moral strategies in social decision-making</article-title>. <source>Nat. Commun</source>. <volume>10</volume>, <fpage>1483</fpage>. <pub-id pub-id-type="doi">10.1038/s41467-019-09161-6</pub-id>.</mixed-citation></ref>
<ref id="c72"><label>72.</label><mixed-citation publication-type="journal"><string-name><surname>Nili</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Wingfield</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Walther</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Su</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Marslen-Wilson</surname>, <given-names>W.</given-names></string-name>, and <string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name> (<year>2014</year>). <article-title>A toolbox for representational similarity analysis</article-title>. <source>PLoS Comput. Biol</source>. <volume>10</volume>, <fpage>e1003553</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1003553</pub-id>.</mixed-citation></ref>
<ref id="c73"><label>73.</label><mixed-citation publication-type="journal"><string-name><surname>Genovese</surname>, <given-names>C.R.</given-names></string-name>, <string-name><surname>Lazar</surname>, <given-names>N.A.</given-names></string-name>, and <string-name><surname>Nichols</surname>, <given-names>T.</given-names></string-name> (<year>2002</year>). <article-title>Thresholding of statistical maps in functional neuroimaging using the false discovery rate</article-title>. <source>NeuroImage</source> <volume>15</volume>, <fpage>870</fpage>–<lpage>878</lpage>. <pub-id pub-id-type="doi">10.1006/nimg.2001.1037</pub-id>.</mixed-citation></ref>
</ref-list>
<sec id="s5">
<title>Supplementary Notes</title>
<sec id="s5a">
<title>Note S1. Behavioral congruency effects</title>
<p>To test the congruency effects for the five conflict types, we conducted 5 (conflict type) × 2 (congruency) repeated-measure ANOVAs with RT and ER from both experiments. The results are displayed in <xref rid="figS1" ref-type="fig">Supplementary Fig. 1</xref>.</p>
<sec id="s5a1">
<title>Experiment 1</title>
<p>For the RT, we observed a significant main effect of Congruency, <italic>F</italic>(1, 32) = 407.70, <italic>p</italic> &lt; .001, <italic>η</italic><sub><italic>p</italic></sub><sup>2</sup> = .93, a significant main effect of Conflict Type, <italic>F</italic>(4, 128) = 6.32, <italic>p</italic> &lt; .001, <italic>η</italic><sub><italic>p</italic></sub><sup>2</sup> = .16, and an interaction between Conflict Type and Congruency, <italic>F</italic>(4, 128) = 27.86, <italic>p</italic> &lt; .001, <italic>η</italic><sub><italic>p</italic></sub><sup>2</sup> = .47. Simple effect analyses showed that participants responded more slowly in incongruent conditions than in congruent conditions for all conflict types, <italic>p</italic><sub><italic>FDR</italic></sub><italic>s</italic> &lt; .001. Additionally, the congruency effect of the Type 2, 3 and 4 were significantly larger than that of the Type 1, and the congruency effect of the Type 2 and 3 were significantly larger than that of the Type 5, <italic>p</italic><sub><italic>FDR</italic></sub>s &lt; .05.</p>
<p>Similar results were found with the ER. We observed a significant main effect of Congruency, <italic>F</italic>(1, 32) = 56.83, <italic>p</italic> &lt; .001, <italic>η</italic><sub><italic>p</italic></sub><sup>2</sup> = .64, a significant main effect of Conflict Type, <italic>F</italic>(4, 128) = 6.29, <italic>p</italic> &lt; .001, <italic>η</italic><sub><italic>p</italic></sub><sup>2</sup> = .16, and an interaction between Conflict Type and Congruency, <italic>F</italic>(4, 128) = 13.23, <italic>p</italic> &lt; .001, <italic>η</italic><sub><italic>p</italic></sub><sup>2</sup> = .29. Simple effect analyses showed that participants were more error-prone in incongruent conditions than in congruent conditions for all conflict types, <italic>p</italic><sub><italic>FDR</italic></sub><italic>s</italic> &lt; .001. The congruency effect of the Type 2, 3 and 4 were significantly larger than that of the Type 1, and the congruency effect of the Type 3 and 4 were significantly larger than that of the Type 5, <italic>p</italic><sub><italic>FDR</italic></sub>s &lt; .05.</p>
</sec>
<sec id="s5a2">
<title>Experiment 2</title>
<p>For the RT, We observed a significant main effect of Congruency, <italic>F</italic>(1, 34) = 149.71, <italic>p</italic> &lt; .001, <italic>η</italic><sub><italic>p</italic></sub><sup>2</sup> = .81, a significant main effect of Conflict Type, <italic>F</italic>(4, 136) = 10.11, <italic>p</italic> &lt; .001, <italic>η</italic><sub><italic>p</italic></sub><sup>2</sup> = .23, and an interaction between Conflict Type and Congruency, <italic>F</italic>(4, 136) = 7.63, <italic>p</italic> &lt; .001, <italic>η</italic><sub><italic>p</italic></sub><sup>2</sup> = .18. Simple effect analyses showed that participants responded more slowly in incongruent conditions than in congruent conditions for all conflict types, <italic>p</italic><sub><italic>FDR</italic></sub>s &lt; .001. The congruency effect of the Type 4 condition was larger than that of Type 1, and Type 3 and Type 4 were significantly larger than that of the Type 5, <italic>p</italic><sub><italic>FDR</italic></sub>s &lt; .05.</p>
<p>For the ER, we only observed a significant main effect of Congruency, <italic>F</italic>(1, 34) = 29.80, <italic>p</italic> &lt; .001, <italic>η</italic><sub><italic>p</italic></sub><sup>2</sup> = .47. All the types showed a larger error rate in incongruent than congruent conditions (<italic>p</italic><sub><italic>FDR</italic></sub>s &lt; .001), except that the Type 1 only showed a marginal significance (<italic>p</italic><sub><italic>FDR</italic></sub> = .062).</p>
<p>In sum, we observed strong behavioral congruency effects in both experiments. The findings indicate that these conflict conditions indeed engaged cognitive control<sup><xref rid="sc1" ref-type="bibr">1</xref></sup>.</p>
</sec>
</sec>
<sec id="s5b">
<title>Note S2. Modulation of conflict similarity on behavioral CSEs cannot be explained by the physical proximity</title>
<p>In our design, the conflict similarity might be confounded by the physical proximity between stimulus (i.e., the arrow) of two consecutive trials. That is, when arrows of the two trials appear at the same quadrant, a higher conflict similarity also indicates a higher physical proximity (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>). Although the opposite is true if arrows of the two trials appear at different quadrants, it is possible the behavioral effects can be biased by the within quadrant trials. To examine if the physical distance has confounded the conflict similarity modulation effect, we conducted an additional analysis.</p>
<p>We defined the physical angular difference across two trials as the difference of their polar angles relative to the origin. Therefore, the physical angular difference could vary from 0 to 180°. For each CSE conditions (i.e., CC, CI, IC and II), we grouped the trials based on their physical angular distances, and then averaged trials with the same previous by current conflict type transition but different orders (e.g., Conf 2−Conf 3 and Conf 3−Conf 2) within each subject. The data were submitted to a mixed-effect model with the conflict similarity, physical proximity (i.e., the opposite of the physical angular difference) as fixed-effect predictors, and subject and CSE condition as random effects. Results showed significant conflict similarity modulation effects in both Experiment 1 (RT: <italic>β</italic> = 0.09 ± 0.01, <italic>t</italic>(7812) = 13.74, <italic>p</italic> &lt; .001, <italic>η</italic><sub><italic>p</italic></sub><sup>2</sup> = .025; ER: <italic>β</italic> = 0.09 ± 0.01, <italic>t</italic>(7812) = 7.66, <italic>p</italic> &lt; .001, <italic>η</italic><sub><italic>p</italic></sub><sup>2</sup> = .018) and Experiment 2 (RT: <italic>β</italic> = 0.21 ± 0.02, <italic>t</italic>(3956) = 9.88, <italic>p</italic> &lt; .001, <italic>η</italic><sub><italic>p</italic></sub><sup>2</sup> = .043; ER: <italic>β</italic> = 0.20 ± 0.03, <italic>t</italic>(4201) = 6.11, <italic>p</italic> &lt; .001, <italic>η</italic><sub><italic>p</italic></sub><sup>2</sup> = .038). Thus, the observed modulation of conflict similarity on behavioral CSEs cannot be explained by physical proximity.</p>
</sec>
<sec id="s5c">
<title>Note S3. The fMRI sequence generation approach</title>
<p>Two sequences of 170 trials each were generated independently with the NeuroDesign package <sup><xref rid="sc2" ref-type="bibr">2</xref></sup>. Each sequence was initialized as 10 consecutive sub-blocks of each condition (incongruent and congruent) for each conflict type (Conf 1, Conf 2, Conf 3, Conf 4 and Conf 5). The contrasts of interest were the main effect of congruency (i.e., [1 −1 1 −1 1 −1 1 −1 1 −1]) and the parametric effect (i.e., [−2 −2 −1 −1 0 0 1 1 2 2]). The order was optimized after 5000 cycles of crossover, mutation, immigration, fitness, and natural selection. The final number of trials for different conflict types varied from 64 to 73.</p>
</sec>
<sec id="s5d">
<title>Note S4. fMRI data preprocessing</title>
<p>Results included in this manuscript come from preprocessing performed using fMRIPrep 20.2.0 (RRID:SCR_016216)<sup><xref rid="sc3" ref-type="bibr">3</xref></sup>, which is based on Nipype 1.5.1 (RRID:SCR_002502)<sup><xref rid="sc4" ref-type="bibr">4</xref></sup>.</p>
<sec id="s5d1">
<title>Anatomical data preprocessing</title>
<p>The T1-weighted (T1w) image was corrected for intensity non-uniformity (INU) with N4BiasFieldCorrection<sup><xref rid="sc5" ref-type="bibr">5</xref></sup>, distributed with ANTs 2.3.3 (RRID:SCR_004757)<sup><xref rid="sc6" ref-type="bibr">6</xref></sup>, and used as T1w-reference throughout the workflow. The T1w-reference was then skull-stripped with a Nipype implementation of the antsBrainExtraction.sh workflow (from ANTs), using OASIS30ANTs as target template. Brain tissue segmentation of cerebrospinal fluid (CSF), white-matter (WM) and gray-matter (GM) was performed on the brain-extracted T1w using fast (FSL 5.0.9, RRID:SCR_002823)<sup><xref rid="sc7" ref-type="bibr">7</xref></sup>. Volume-based spatial normalization to one standard space (MNI152NLin2009cAsym) was performed through nonlinear registration with antsRegistration (ANTs 2.3.3), using brain-extracted versions of both T1w reference and the T1w template. The following template was selected for spatial normalization: ICBM 152 Nonlinear Asymmetrical template version 2009c [RRID:SCR_008796; TemplateFlow ID: MNI152NLin2009cAsym]<sup><xref rid="sc8" ref-type="bibr">8</xref></sup>.</p>
</sec>
<sec id="s5d2">
<title>Functional data preprocessing</title>
<p>For each of the 5 BOLD runs found per subject (across all tasks and sessions), the following preprocessing was performed. First, a reference volume and its skull-stripped version were generated using a custom methodology of fMRIPrep. Susceptibility distortion correction (SDC) was omitted. The BOLD reference was then co-registered to the T1w reference using flirt (FSL 5.0.9)<sup><xref rid="sc9" ref-type="bibr">9</xref></sup> with the boundary-based registration<sup><xref rid="sc10" ref-type="bibr">10</xref></sup> cost-function. Co-registration was configured with nine degrees of freedom to account for distortions remaining in the BOLD reference. Head-motion parameters with respect to the BOLD reference (transformation matrices, and six corresponding rotation and translation parameters) are estimated before any spatiotemporal filtering using mcflirt (FSL 5.0.9)<sup><xref rid="sc11" ref-type="bibr">11</xref></sup>. BOLD runs were slice-time corrected using 3dTshift from AFNI 20160207 (RRID:SCR_005927)<sup><xref rid="sc11" ref-type="bibr">11</xref></sup>. The BOLD time-series (including slice-timing correction when applied) were resampled onto their original, native space by applying the transforms to correct for head-motion. These resampled BOLD time-series will be referred to as preprocessed BOLD in original space, or just preprocessed BOLD. The BOLD time-series were resampled into standard space, generating a preprocessed BOLD run in MNI152NLin2009cAsym space. First, a reference volume and its skull-stripped version were generated using a custom methodology of fMRIPrep. Several confounding time-series were calculated based on the preprocessed BOLD: framewise displacement (FD), DVARS and three region-wise global signals. FD was computed using two formulations following Power (absolute sum of relative motions)<sup><xref rid="sc11" ref-type="bibr">11</xref></sup> and Jenkinson (relative root mean square displacement between affines, Jenkinson et al.<sup><xref rid="sc9" ref-type="bibr">9</xref></sup>). FD and DVARS are calculated for each functional run, both using their implementations in Nipype (following the definitions by Power et al.<sup><xref rid="sc11" ref-type="bibr">11</xref></sup>). The three global signals are extracted within the CSF, the WM, and the whole-brain masks. Additionally, a set of physiological regressors were extracted to allow for component-based noise correction (CompCor)<sup><xref rid="sc12" ref-type="bibr">12</xref></sup>. Principal components are estimated after high-pass filtering the preprocessed BOLD time-series (using a discrete cosine filter with 128s cut-off) for the two CompCor variants: temporal (tCompCor) and anatomical (aCompCor). tCompCor components are then calculated from the top 2% variable voxels within the brain mask. For aCompCor, three probabilistic masks (CSF, WM and combined CSF+WM) are generated in anatomical space. The implementation differs from that of Behzadi et al. in that instead of eroding the masks by 2 pixels on BOLD space, the aCompCor masks are subtracted a mask of pixels that likely contain a volume fraction of GM. This mask is obtained by thresholding the corresponding partial volume map at 0.05, and it ensures components are not extracted from voxels containing a minimal fraction of GM. Finally, these masks are resampled into BOLD space and binarized by thresholding at 0.99 (as in the original implementation). Components are also calculated separately within the WM and CSF masks. For each CompCor decomposition, the k components with the largest singular values are retained, such that the retained components time series are sufficient to explain 50 percent of variance across the nuisance mask (CSF, WM, combined, or temporal). The remaining components are dropped from consideration. The head-motion estimates calculated in the correction step were also placed within the corresponding confounds file. The confound time series derived from head motion estimates and global signals were expanded with the inclusion of temporal derivatives and quadratic terms for each<sup><xref rid="sc12" ref-type="bibr">12</xref></sup>. Frames that exceeded a threshold of 0.5 mm FD or 1.5 standardised DVARS were annotated as motion outliers. All resamplings can be performed with a single interpolation step by composing all the pertinent transformations (i.e. head-motion transform matrices, susceptibility distortion correction when available, and co-registrations to anatomical and output spaces). Gridded (volumetric) resamplings were performed using antsApplyTransforms (ANTs), configured with Lanczos interpolation to minimize the smoothing effects of other kernels<sup><xref rid="sc13" ref-type="bibr">13</xref></sup>. Non-gridded (surface) resamplings were performed using mri_vol2surf (FreeSurfer).</p>
<p>Many internal operations of fMRIPrep use Nilearn 0.6.2 (RRID:SCR_001362)<sup><xref rid="sc14" ref-type="bibr">14</xref></sup>, mostly within the functional processing workflow. For more details of the pipeline, see the section corresponding to workflows in fMRIPrep’s documentation.</p>
</sec>
</sec>
<sec id="s5e">
<title>Note S5. The multivariate representations of conflict type and orientation are different from the congruency effect</title>
<p>An explanation to the stronger encoding of conflict type in incongruent than congruent condition (<xref rid="fig3" ref-type="fig">Fig. 3B/D</xref>) in right 8C area may be the encoding of congruency. To test this possibility, we first tested the univariate congruency effect (incongruent minus congruent) using the parametric modulating GLM1 that was used to estimate fMRI activation levels of conflict type × congruency conditions. We observed no univariate congruency effect in the right 8C region, <italic>t</italic>(34) = −0.03, <italic>p</italic> = .513, one-tailed. We further tested the possibility that the congruency effect may be manifested in behavioral relevance. To this end, we extracted the congruency effect (incongruent minus congruent) on encoding strength of conflict similarity for each subject from the mixed-effect model based on the cross-subject RSA (see the <italic>Representational similarity analysis</italic> of Methods in the main text) and correlated it with the behavioral congruency effect, averaged across the five conflict types (i.e., the main effect reported in the Note S1). No significant correlation was observed (<italic>r</italic> = 0.14, <italic>p</italic> = .380, one-tailed). Taken together, these results suggested that the neural encoding strength of conflict type does not reflect the level of cognitive control engagement, but the dynamic adjustment of cognitive control instead.</p>
<p>Similarly, we tested whether those regions with stronger encoding of orientation in incongruent than congruent condition (i.e., bilateral V2, left FEF, left IP2, right V1, right H and right PF) reflects the congruency effect. We observed no uni-voxel congruency effect in any of these regions, all <italic>p</italic><sub><italic>FDR</italic></sub> &gt; .998, one-tailed. In addition, the orientation effect was not correlated to the behavioral congruency in any of the regions, all <italic>p</italic><sub><italic>FDR</italic></sub> &gt; .608, one-tailed. Together with our finding that there was no correlation between the strength of orientation encoding and the conflict similarity modulation on behavioral CSEs in any of these regions (see the <italic>Multivariate patterns of visual and oculomotor areas encode stimulus orientation</italic> of Results in the main text), these results indicate that the encoding of orientation effect did not reflect the encoding of congruency or conflict type. Instead, we speculate that the encoding of orientations provides perceptual information to determine the conflict type.</p>
</sec>
<sec id="s5f">
<title>Note S6. The lateralization of conflict type representation</title>
<p>We observed the right 8C but not the left 8C represented the conflict type similarity. A further test is to show if there is a lateralization. We tested several regions of the left dlPFC, including the i6-8, 8Av, 8C, p9-46v, 46, 9-46d, a9-46v<sup><xref rid="sc15" ref-type="bibr">15</xref></sup>. We found that none of these regions show the representation of conflict type, all <italic>p</italic><sub><italic>FDR</italic></sub> &gt; .99. These results indicate that the conflict type is specifically represented in the right dlPFC.</p>
</sec>
</sec>
<sec id="s6">
<title>Supplementary Figures</title>
<fig id="figS1" position="float" fig-type="figure">
<label>Fig. S1.</label>
<caption><p>The congruency effects of Experiment 1 (A and B) and Experiment 2 (C and D). Error bars denote the standard errors of mean. Conf 1 to 5 denotes the five conflict types. Small insets on top of panel A denote an example of stimuli positions for each conflict type. RT = reaction time; ER = error rate.</p></caption>
<graphic xlink:href="528292v1_figS1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS2" position="float" fig-type="figure">
<label>Fig. S2.</label>
<caption><p>The conflict similarity modulation on performance of Experiment 1 (A, B, D and E) and Experiment 2 (C and F), respectively. A and D are scatter plots of CSE [i.e., (CI−CC) − (II−IC)] for RT and ER as a function of the cosine similarity, respectively. In B, C, E and F, the cosine similarity and RT / ER are normalized across conflict similarity levels within each of the four CSE conditions (i.e., CC, II, CI and IC). Conflict similarity for CC and II conditions are reversed (multiplied by −1), such that for all the four CSE conditions, higher conflict similarity is expected to be associated with worse performance (see <italic>Behavioral analysis</italic> in Methods). Each dot represents a subject. The thin colored lines in B, C, E and F are the fitted lines for each of the four CSE conditions, and the thick black lines are the fitted lines collapsing across all CSE conditions. For panel C and F some similarity levels are missing because of the limited trial numbers in the experimental design in Experiment 2. CSE = congruency sequence effect; RT = reaction time; ER = error rate; CI = congruent (trial n−1)-incongruent (trial n); IC = incongruent-congruent; CC = congruent-congruent; II = incongruent-incongruent.</p></caption>
<graphic xlink:href="528292v1_figS2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS3" position="float" fig-type="figure">
<label>Fig. S3.</label>
<caption><p>Neural congruency effect (I−C) by GLM2 [see the <italic>Estimation of fMRI activity with univariate general linear model (GLM)</italic> of Methods in the main text], plotted as a function of conflict type in different cortical ROIs. The ROIs were selected because they show a statistically significant congruency effects or parametric modulation effects when analyzed using the univariate GLM1.The pre-SMA and ACC showed overall congruency effects regardless of the conflict type (upper panel); the right IPS and right dmPFC were positively modulated by the conflict type and the left MFG was negatively modulated by the conflict type (lower panel). Conf 1 to 5 denotes the five conflict types, from the spatial Stroop to the Simon. Pre-SMA = pre-supplementary motor area; ACC = anterior cingulate cortex; IPS = inferior parietal sulcus; dmPFC = dorsomedial prefrontal cortex; MFG = middle frontal gyrus.</p></caption>
<graphic xlink:href="528292v1_figS3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS4" position="float" fig-type="figure">
<label>Fig. S4.</label>
<caption><p>The cross-subject RSA model and the rationale. The RSM is calculated as the Pearson’s correlation between each pair of conditions and the 35 subjects. For 17 subjects, the stimuli were displayed on the top-left and bottom-right quadrants, and they were asked to respond with left hand to the upward arrow and right hand to the downward arrow. For the other 18 subjects, the stimuli were displayed on the top-right and bottom-left quadrants, and they were asked to respond with left hand to the downward arrow and right hand to the upward arrow. Within each subject, the conflict type and orientation regressors were perfectly covaried. For instance, the same conflict type will always be on the same orientation. To de-correlate conflict type and orientation effects, we conducted the RSA across subjects from different groups. For example, the dashed ellipses highlight the conditions that are orthogonal to each other on the orientation representation, response, and Simon distractor, when their conflict type, target and spatial Stroop distractor are the same. The dashed boxes show the possible target locations for different conditions. RSM = representational similarity matrix.</p></caption>
<graphic xlink:href="528292v1_figS4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS5" position="float" fig-type="figure">
<label>Fig. S5.</label>
<caption><p>The cortical regions showing different effects in the main RSA. (A) The target effect reflects the above chance encoding of upward and downward arrow directions, and is most strongly encoded in the visual, memory and semantic regions, possibly because producing a goal-direct response to the stimulus require processing in all these regions. (B) the response effect reflects the above chance encoding of left and right responses, and is most strongly encoded in motor regions. (C) the spatial Stroop distractor effect reflects the above chance encoding of vertical location of the stimulus, and is most strongly encoded in left visual regions. (D) the Simon distractor effect reflects the above chance encoding of horizontal locations of the stimulus, and is most strongly encoded at the right visual regions, among others. All <italic>p</italic>-values are FDR-corrected (<italic>p</italic><sub><italic>FDR</italic></sub> &lt; 0.05 and raw <italic>p</italic> &lt; 0.001) across the 360 cortical ROIs. Brighter colors denote stronger effects as indicated by the opposite of log-transformed <italic>p</italic> values.</p></caption>
<graphic xlink:href="528292v1_figS5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS6" position="float" fig-type="figure">
<label>Fig. S6.</label>
<caption><p>The representational connectivity between the right 8C area and the cortical regions showing significant encoding of orientation. The black bars represent regions showing both the overall orientation effect and higher encoding of orientation in incongruent than congruent conditions; the grey bars are regions showing only the overall orientation effect but not higher encoding of orientation in incongruent than congruent conditions; and the white bars are regions not showing any of the effects of interest (i.e., <italic>q</italic><sub><italic>FDR</italic></sub> &gt; 0.05 for all the conflict type, orientation, congruency, target, response, spatial Stroop distractor and Simon distractor effects). The grey and white bars show controlled regions. Error bars are the standard error of the mean. The dashed line indicates the 95% confidence interval of the highest connectivity of controlled regions (i.e., left V3). l = left, r = right.</p></caption>
<graphic xlink:href="528292v1_figS6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s7">
<title>Supplementary Tables</title>
<table-wrap id="tblS1" orientation="portrait" position="float">
<label>Table S1.</label>
<caption><p>Brain activations for the uni-voxel parametric analysis in GLM1 (voxel-wise one-tailed <italic>p</italic> &lt; .005, cluster &gt; 20)</p></caption>
<graphic xlink:href="528292v1_tblS1.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
</sec>
<ref-list>
<title>Supplementary References</title>
<ref id="sc1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>Freund</surname> <given-names>MC</given-names></string-name>, <string-name><surname>Etzel</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Braver</surname> <given-names>TS.</given-names></string-name> <article-title>Neural Coding of Cognitive Control: The Representational Similarity Analysis Approach</article-title>. <source>Trends Cogn Sci</source> <volume>25</volume>, <fpage>622</fpage>–<lpage>638</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="sc2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Durnez</surname> <given-names>J</given-names></string-name>, <string-name><surname>Blair</surname> <given-names>R</given-names></string-name>, <string-name><surname>Poldrack</surname> <given-names>RA.</given-names></string-name> <article-title>Neurodesign: Optimal Experimental Designs for Task fMRI</article-title>. <source>BioRxiv</source>, <volume>119594</volume> (<year>2018</year>).</mixed-citation></ref>
<ref id="sc3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>Esteban</surname> <given-names>O</given-names></string-name>, <etal>et al.</etal> <article-title>fMRIPrep: a robust preprocessing pipeline for functional MRI</article-title>. <source>Nat Methods</source> <volume>16</volume>, <fpage>111</fpage>–<lpage>116</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="sc4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Gorgolewski</surname> <given-names>K</given-names></string-name>, <etal>et al.</etal> <article-title>Nipype: a flexible, lightweight and extensible neuroimaging data processing framework in python</article-title>. <source>Front Neuroinform</source> <volume>5</volume>, <fpage>13</fpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="sc5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Tustison</surname> <given-names>NJ</given-names></string-name>, <etal>et al.</etal> <article-title>N4ITK: improved N3 bias correction</article-title>. <source>IEEE Trans Med Imaging</source> <volume>29</volume>, <fpage>1310</fpage>–<lpage>1320</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="sc6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Avants</surname> <given-names>BB</given-names></string-name>, <string-name><surname>Epstein</surname> <given-names>CL</given-names></string-name>, <string-name><surname>Grossman</surname> <given-names>M</given-names></string-name>, <string-name><surname>Gee</surname> <given-names>JC.</given-names></string-name> <article-title>Symmetric diffeomorphic image registration with cross-correlation: evaluating automated labeling of elderly and neurodegenerative brain</article-title>. <source>Med Image Anal</source> <volume>12</volume>, <fpage>26</fpage>–<lpage>41</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="sc7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Zhang</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Brady</surname> <given-names>M</given-names></string-name>, <string-name><surname>Smith</surname> <given-names>S.</given-names></string-name> <article-title>Segmentation of brain MR images through a hidden Markov random field model and the expectation-maximization algorithm</article-title>. <source>IEEE Trans Med Imaging</source> <volume>20</volume>, <fpage>45</fpage>–<lpage>57</lpage> (<year>2001</year>).</mixed-citation></ref>
<ref id="sc8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Fonov</surname> <given-names>VS</given-names></string-name>, <string-name><surname>Evans</surname> <given-names>AC</given-names></string-name>, <string-name><surname>McKinstry</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Almli</surname> <given-names>CR</given-names></string-name>, <string-name><surname>Collins</surname> <given-names>DL.</given-names></string-name> <article-title>Unbiased nonlinear average age-appropriate brain templates from birth to adulthood</article-title>. <source>NeuroImage</source> <volume>47</volume>, (<year>2009</year>).</mixed-citation></ref>
<ref id="sc9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Jenkinson</surname> <given-names>M</given-names></string-name>, <string-name><surname>Smith</surname> <given-names>S.</given-names></string-name> <article-title>A global optimisation method for robust affine registration of brain images</article-title>. <source>Med Image Anal</source> <volume>5</volume>, <fpage>143</fpage>–<lpage>156</lpage> (<year>2001</year>).</mixed-citation></ref>
<ref id="sc10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Greve</surname> <given-names>DN</given-names></string-name>, <string-name><surname>Fischl</surname> <given-names>B.</given-names></string-name> <article-title>Accurate and robust brain image alignment using boundary-based registration</article-title>. <source>NeuroImage</source> <volume>48</volume>, <fpage>63</fpage>–<lpage>72</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="sc11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>Jenkinson</surname> <given-names>M</given-names></string-name>, <string-name><surname>Bannister</surname> <given-names>P</given-names></string-name>, <string-name><surname>Brady</surname> <given-names>M</given-names></string-name>, <string-name><surname>Smith</surname> <given-names>S.</given-names></string-name> <article-title>Improved Optimization for the Robust and Accurate Linear Registration and Motion Correction of Brain Images</article-title>. <source>NeuroImage</source> <volume>17</volume>, <fpage>825</fpage>–<lpage>841</lpage> (<year>2002</year>).</mixed-citation></ref>
<ref id="sc12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>Behzadi</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Restom</surname> <given-names>K</given-names></string-name>, <string-name><surname>Liau</surname> <given-names>J</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>TT.</given-names></string-name> <article-title>A component based noise correction method (CompCor) for BOLD and perfusion based fMRI</article-title>. <source>NeuroImage</source> <volume>37</volume>, <fpage>90</fpage>–<lpage>101</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="sc13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Lanczos</surname> <given-names>C.</given-names></string-name> <article-title>Evaluation of Noisy Data</article-title>. <source>Journal of the Society for Industrial and Applied Mathematics Series B Numerical Analysis</source> <volume>1</volume>, <fpage>76</fpage>–<lpage>85</lpage> (<year>1964</year>).</mixed-citation></ref>
<ref id="sc14"><label>14.</label><mixed-citation publication-type="journal"><string-name><surname>Abraham</surname> <given-names>A</given-names></string-name>, <etal>et al.</etal> <article-title>Machine learning for neuroimaging with scikit-learn</article-title>. <source>Front Neuroinform</source> <volume>8</volume>, <fpage>14</fpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="sc15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Freund</surname> <given-names>MC</given-names></string-name>, <string-name><surname>Bugg</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Braver</surname> <given-names>TS.</given-names></string-name> <article-title>A Representational Similarity Analysis of Cognitive Control during Color-Word Stroop</article-title>. <source>J Neurosci</source> <volume>41</volume>, <fpage>7388</fpage>–<lpage>7402</lpage> (<year>2021</year>).</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.87126.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Badre</surname>
<given-names>David</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Useful</kwd>
</kwd-group>
</front-stub>
<body>
<p>Yang et al. investigate whether distinct sources of conflict are represented in a common cognitive space. The study uses an interesting task that mixes two different sources of difficulty and reports that the brain appears to represent these sources as a mixture on a continuum, in the prefrontal areas involved in resolving task difficulty. While these results are <bold>useful</bold>, they overlap with previous findings, leave open several design and logical concerns, and rely on novel statistical analyses that may require further validation, so they are currently <bold>incomplete</bold>.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.87126.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>People can perform a wide variety of different tasks, and a long-standing question in cognitive neuroscience is how the properties of different tasks are represented in the brain. The authors develop an interesting task that mixes two different sources of difficulty, and find that the brain appears to represent this mixture on a continuum, in the prefrontal areas involved in resolving task difficulty. While these results are interesting and in several ways compelling, they overlap with previous findings and rely on novel statistical analyses that may require further validation.</p>
<p>Strengths</p>
<p>
1. The authors present an interesting and novel task for combining the contributions of stimulus-stimulus and stimulus-response conflict. While this mixture has been measured in the multi-source interference task (MSIT), this task provides a more graded mixture between these two sources of difficulty</p>
<p>2. The authors do a good job triangulating regions that encoding conflict similarity, looking for the conjunction across several different measures of conflict encoding</p>
<p>3. The authors quantify several salient alternative hypothesis and systematically distinguish their core results from these alternatives</p>
<p>4. The question that the authors tackle is of central theoretical importance to cognitive control, and they make an interesting an interesting contribution to this question</p>
<p>Concerns</p>
<p>
1. It's not entirely clear what the current task can measure that is not known from the MSIT, such as the additive influence of conflict sources in Fu et al. (2022), Science. More could be done to distinguish the benefits of this task from MSIT.</p>
<p>2. The evidence from this previous work for mixtures between different conflict sources make the framing of 'infinite possible types of conflict' feel like a strawman. The authors cite classic work (e.g., Kornblum et al., 1990) that develops a typology for conflict which is far from infinite, and I think few people would argue that every possible source of difficulty will have to be learned separately. Such an issue is addressed in theories like 'Expected Value of Control', where optimization of control policies can address unique combinations of task demands.</p>
<p>3. Wouldn't a region that represented each conflict source separately still show the same pattern of results? The degree of Stroop vs Simon conflict is perfectly negatively correlated across conditions, so wouldn't a region that *just* tracks Stoop conflict show these RSA patterns? The authors show that overall congruency is not represented in DLPFC (which is surprising), but they don't break it down by whether this is due to Stroop or Simon congruency (I'm not sure their task allows for this).</p>
<p>4. The authors use a novel form of RSA that concatenates patterns across conditions, runs and subjects into a giant RSA matrix, which is then used for linear mixed effects analysis. This appears to be necessary because conflict type and visual orientation are perfectly confounded within the subject (although, if I understand, the conflict type x congruence interaction wouldn't have the same concern about visual confounds, which shouldn't depend on congruence). This is an interesting approach but should be better justified, preferably with simulations validating the sensitivity and specificity of this method and comparing it to more standard methods.</p>
<p>A chief concern is that the same pattern contributes to many entries in the DV, which has been addressed in previous work using row-wise and column-wise random effects (Chen et al., 2017, Neuroimage). It would also be informative to know whether the results hold up to removing within-run similarity, which can bias similarity measures (Walther et al., 2016, Neuroimage).</p>
<p>Another concern is the extent to which across-subject similarity will only capture consistent patterns across people, making this analysis very similar to a traditional univariate analysis (and unlike the traditional use of RSA to capture subject-specific patterns).</p>
<p>5. Finally, the authors should confirm all their results are robust to less liberal methods of multiplicity correction. For univariate analysis, they should report the effects from the standard p &lt; .001 cluster forming threshold for univariate analysis (or TFCE). For multivariate analyses, FDR can be quite liberal. The authors should consider whether their mixed-effects analyses allow for group-level randomization, and consider (relatively powerful) Max-Stat randomization tests (Nichols &amp; Holmes, 2002, Hum Brain Mapp).</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.87126.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary, general appraisal</p>
<p>This study examines the construct of &quot;cognitive spaces&quot; as they relate to neural coding schemes present in response conflict tasks. The authors utilize a novel paradigm, in which subjects must map the direction of a vertically oriented arrow to either a left or right response. Different types of conflict (spatial Stroop, Simon) are parametrically manipulated by varying the spatial location of the arrow (a task-irrelevant feature). The vertical eccentricity of the arrow either agrees or conflicts with the arrow's direction (spatial Stroop), while the horizontal eccentricity of the arrow agrees or conflicts with the side of the response (Simon). A neural coding model is postulated in which the stimuli are embedded in a cognitive space, organized by distances that depend only on the similarity of congruency types (i.e., where conditions with similar relative proportions of spatial-Stroop versus Simon congruency are represented with similar activity patterns). The authors conduct a behavioral and fMRI study to provide evidence for such a representational coding scheme. The behavioral findings replicate the authors' prior work in demonstrating that conflict-related cognitive control adjustments (the congruency sequence effect) shows strong modulation as a function of the similarity between conflict types. With the fMRI neural activity data, the authors report univariate analyses that identified activation in left prefrontal and dorsomedial frontal cortex modulated by the amount of Stroop or Simon conflict present, and multivariate representational similarity analyses (RSA) that identified right lateral prefrontal activity encoding conflict similarity and correlated with the behavioral effects of conflict similarity.</p>
<p>
This study tackles an important question regarding how distinct types of conflict, which have been previously shown to elicit independent forms of cognitive control adjustments, might be encoded in the brain within a computationally efficient representational format. The ideas postulated by the authors are interesting ones and the utilized methods are rigorous. However, the study has critical limitations that are due to a lack of clarity regarding theoretical hypotheses, serious confounds in the experimental design, and a highly non-standard (and problematic) approach to RSA. Without addressing these issues it is hard to evaluate the contribution of the authors findings to the computational cognitive neuroscience literature.</p>
<p>The primary theoretical question and its implications are unclear.</p>
<p>The paper would greatly benefit from more clearly specifying potential alternative hypotheses and discussing their implications. Consider, for example, the case of parallel conflict monitors. Say that these conflict monitors are separately tuned for Stroop and Simon conflict, and are located within adjacent patches of cortex that are both contained within a single cortical parcel (e.g., as defined by the Glasser atlas used by the authors for analyses). If RSA was conducted on the responses of such a parcel to this task, it seems highly likely that an activation similarity matrix would be observed that is quite similar (if not identical) to the hypothesized one displayed in Figure 1. Yet it would seem like the authors are arguing that the &quot;cognitive space&quot; representation is qualitatively and conceptually distinct from the &quot;parallel monitor&quot; coding scheme. Thus, it seems that the task and analytic approach is not sufficient to disambiguate these different types of coding schemes or neural architectures.</p>
<p>The authors also discuss a fully domain-general conflict monitor, in which different forms of conflict are encoded within a single dimension. Yet this alternative hypothesis is also not explicitly tested nor discussed in detail. It seems that the experiment was designed to orthogonalize the &quot;domain-general&quot; model from the &quot;cognitive space&quot; model, by attempting to keep the overall conflict uniform across the different stimuli (i.e., in the design, the level of Stroop congruency parametrically trades off with the level of Simon congruency). But in the behavioral results (Fig. S1), the interference effects were found to peak when both Stroop and Simon congruency are present (i.e., Conf 3 and 4), suggesting that the &quot;domain-general&quot; model may not be orthogonal to the &quot;cognitive space&quot; model. One of the key advantages of RSA is that it provides the ability to explicitly formulate, test and compare different coding models to determine which best accounts for the pattern of data. Thus, it would seem critical for the authors to set up the design and analyses so that an explicit model comparison analysis could be conducted, contrasting the domain-general, domain-specific, and cognitive space accounts.</p>
<p>
Relatedly, the reasoning for the use of the term &quot;cognitive space&quot; is unclear. The mere presence of graded coding for two types of conflict seems to be a low bar for referring to neural activity patterns as encoding a &quot;cognitive space&quot;. It is discussed that cognitive spaces/maps allow for flexibility through inference and generalization. But no links were made between these cognitive abilities and the observed representational structure. Additionally, no explicit tests of generality (e.g., via cross-condition generalization) were provided. Finally, although the design elicits strong CSE effects, it seems somewhat awkward to consider CSE behavioral patterns as a reflection of the kind of abilities supported by a cognitive map (if this is indeed the implication that was intended). In fact, CSE effects are well-modeled by simpler &quot;model-free&quot; associative learning processes, that do not require elaborate representations of abstract structures.</p>
<p>More generally, it seems problematic that Stroop and Simon conflict in the paradigm parametrically trade-off against each other. A more powerful design would have de-confounded Stroop and Simon conflict so that each could be separately estimation via (potentially orthogonal) conflict axes. Additionally, incorporating more varied stimulus sets, locations, or responses might have enabled various tests of generality, as implied by a cognitive space account.</p>
<p>Serious confounds in the design render the results difficult to interpret.</p>
<p>As much prior neuroimaging and behavioral work has established, &quot;conflict&quot; per se is perniciously correlated with many conceptually different variables. Consequently, it is very difficult to distinguish these confounding variables within aggregate measures of neural activity like fMRI. For example, conflict is confounded with increased time-on-task with longer RT, as well as conflict-driven increases in coding of other task variables (e.g., task-set related coding; e.g., Ebitz et al. 2020 bioRxiv). Even when using much higher resolution invasive measures than fMRI (i.e., eCoG), researchers have rightly been wary of making strong conclusions about explicit encoding of conflict (Tang et al, 2019; eLife). As such, the researchers would do well to be quite cautious and conservative in their analytic approach and interpretation of results.</p>
<p>This issue is most critical in the interpretation of the fMRI results as reflecting encoding of conflict types. A key limitation of the design, that is acknowledged by the authors is that conflict is fully confounded within-subject by spatial orientation. Indeed, the limited set of stimulus-response mappings also cast doubt on the underlying factors that give rise to the CSE modulations observed by the authors in their behavioral results. The CSE modulations are so strong - going from a complete absence of current x previous trial-type interaction in the cos(90) case all the way to a complete elimination of any current trial conflict when the prior trial was incongruent in the cos(0) case - that they cause suspicion that they are actually driven by conflict-related control adjustments rather than sequential dependencies in the stimulus-response mappings that can be associatively learned.</p>
<p>To their credit, the authors recognize this confound, and attempt to address it analytically through the use of a between-subject RSA approach. Yet the solution is itself problematic, because it doesn't actually deconfound conflict from orientation. In particular, the RSA model assumes that whatever components of neural activity encode orientation produce this encoding within the same voxel-level patterns of activity in each subject. If they are not (which is of course likely), then orthogonalization of these variables will be incomplete. Similar issues underlie the interpretation target/response and distractor coding. Given these issues, perhaps zooming out to a larger spatial scale for the between-subject RSA might be warranted. Perhaps whole-brain at the voxel level with a high degree of smoothing, or even whole-brain at the parcel level (averaging per parcel). For this purpose, Schaefer atlas parcels might be more useful than Glasser, as they more strongly reflect functional divisions (e.g., motor strip is split into mouth/hand divisions; visual cortex is split into central/peripheral visual field divisions). Similarly, given the lateralization of stimuli, if a within-parcel RSA is going to be used, it seems quite sensible to pool voxels across hemispheres (so effectively using 180 parcels instead of 360).</p>
<p>The strength of the results is difficult to interpret due to the non-standard analysis method.</p>
<p>The use of a mixed-level modeling approach to summarize the empirical similarity matrix is an interesting idea, but nevertheless is highly non-standard within RSA neuroimaging methods. More importantly, the way in which it was implemented makes it potentially vulnerable to a high degree of inaccuracy or bias. In this case, this bias is likely to be overly optimistic (high false positive rate).</p>
<p>A key source of potential bias comes from the fact that the off-diagonal cells are not independent (e.g., the correlation between subject A and B is strongly dependent on the correlation between subject A and C). For appropriate degrees of freedom calculation, the model must take this into account somehow. As fitted, the current models do not seem to handle this appropriately. That being said, it may be possible to devise an appropriate test via mixed-level models. In fact, Chen et al. have a series of three recent Neuroimage articles that extensively explore this question (all entitled &quot;Untangling the relatedness among correlations&quot;) - adopting one of the methods described in the papers, seems much safer, if possible.</p>
<p>Another potential source of bias is in treating the subject-level random effect coefficients (as predicted by the mixed-level model) as independent samples from a random variable (in the t-tests). The more standard method for inference would be to use test statistics derived from the mixed-model fixed effects, as those have degrees of freedom calculations that are calibrated based on statistical theory.</p>
<p>No numerical or formal defense was provided for this mixed-level model approach. As a result, the use of this method seems quite problematic, as it renders the strength of the observed results difficult to interpret. Instead, the authors are encouraged using a previously published method of conducting inference with between-subject RSA, such as the bootstrapping methods illustrated in Kragel et al. (2018; Nat Neurosci), or in potentially adopting one of the Chen et al. methods mentioned above, that have been extensively explored in terms of statistical properties.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.87126.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Yang and colleagues investigated whether information on two task-irrelevant features that induce response conflict is represented in a common cognitive space. To test this, the authors used a task that combines the spatial Stroop conflict and the Simon effect. This task reliably produces a beautiful graded congruency sequence effect (CSE), where the cost of congruency is reduced after incongruent trials. The authors measured fMRI to identify brain regions that represent the graded similarity of conflict types, the congruency of responses, and the visual features that induce conflicts.</p>
<p>Using several theory-driven exclusion criteria, the authors identified the right dlPFC (right 8C), which shows 1) stronger encoding of graded similarity of conflicts in incongruent trials and 2) a positive correlation between the strength of conflict similarity type and the CSE on behavior. The dlPFC has been shown to be important for cognitive control tasks. As the dlPFC did not show a univariate parametric modulation based on the higher or lower component of one type of conflict (e.g., having more spatial Stroop conflict or less Simon conflict), it implies that dissimilarity of conflicts is represented by a linear increase or decrease of neural responses. Therefore, the similarity of conflict is represented in multivariate neural responses that combine two sources of conflict.</p>
<p>The strength of the current approach lies in the clear effect of parametric modulation of conflict similarity across different conflict types. The authors employed a clever cross-subject RSA that counterbalanced and isolated the targeted effect of conflict similarity, decorrelating orientation similarity of stimulus positions that would otherwise be correlated with conflict similarity. A pattern of neural response seems to exist that maps different types of conflict, where each type is defined by the parametric gradation of the yoked spatial Stroop conflict and the Simon conflict on a similarity scale. The similarity of patterns increases in incongruent trials and is correlated with CSE modulation of behavior. However, several potential caveats need to be considered.</p>
<p>One caveat to consider is that the main claim of recruitment of an organized &quot;cognitive space&quot; for conflict representation is solely supported by the exclusion criteria mentioned earlier. To further support the involvement of organized space in conflict representation, other pieces of evidence need to be considered. One approach could be to test the accuracy of out-of-sample predictions to examine the continuity of the space, as commonly done in studies on representational spaces of sensory information. Another possible approach could involve rigorously testing the geometric properties of space, rather than fitting RSM to all conflict types. For instance, in Fig 6, both the organized and domain-specific cognitive maps would similarly represent the similarity of conflict types expressed in Fig1c (as evident from the preserved order of conflict types). The RSM suggests a low-dimensional embedding of conflict similarity, but the underlying dimension remains unclear.</p>
<p>Another important factor to consider is how learning within the confined task space, which always negatively correlates the two types of conflicts within each subject, may have influenced the current results. Is statistical dependence of conflict information necessary to use the organized cognitive space to represent conflicts from multiple sources? Answering this question would require a paradigm that can adjust multiple sources of conflicts parametrically and independently. Investigating such dependencies is crucial in order to better understand the adaptive utility of the observed cognitive space of conflict similarity.</p>
<p>Taken together, this study presents an exciting possibility that information requiring high levels of cognitive control could be flexibly mapped into cognitive map-like representations that both benefit and bias our behavior. Further characterization of the representational geometry and generalization of the current results look promising ways to understand representations for cognitive control.</p>
</body>
</sub-article>
</article>