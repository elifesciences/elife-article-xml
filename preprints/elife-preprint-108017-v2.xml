<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">108017</article-id>
<article-id pub-id-type="doi">10.7554/eLife.108017</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.108017.2</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories><title-group>
<article-title>Visual Working Memory Guides Attention Rhythmically</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0166-5349</contrib-id>
<name>
<surname>Lu</surname>
<given-names>Jiachen</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
<xref ref-type="aff" rid="a2">b</xref>
<xref ref-type="aff" rid="a3">c</xref>
<xref ref-type="author-notes" rid="n1">*</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Cai</surname>
<given-names>Yaochun</given-names>
</name>
<xref ref-type="aff" rid="a2">b</xref>
<xref ref-type="aff" rid="a3">c</xref>
<xref ref-type="aff" rid="a4">d</xref>
<xref ref-type="aff" rid="a5">e</xref>
<xref ref-type="author-notes" rid="n1">*</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0449-934X</contrib-id>
<name>
<surname>Zhang</surname>
<given-names>Xilin</given-names>
</name>
<xref ref-type="aff" rid="a2">b</xref>
<xref ref-type="aff" rid="a3">c</xref>
<xref ref-type="aff" rid="a4">d</xref>
<xref ref-type="aff" rid="a5">e</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>a</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05ar8rn06</institution-id><institution>Research Center of Adolescent Psychology and Behavior, School of Education, Guangzhou University</institution></institution-wrap>, <city>Guangzhou</city>, <country country="CN">China</country></aff>
<aff id="a2"><label>b</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01kq0pv72</institution-id><institution>Key Laboratory of Brain, Cognition and Education Sciences, Ministry of Education, South China Normal University</institution></institution-wrap>, <city>Guangzhou</city>, <country country="CN">China</country></aff>
<aff id="a3"><label>c</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01kq0pv72</institution-id><institution>School of Psychology, South China Normal University</institution></institution-wrap>, <city>Guangzhou</city>, <country country="CN">China</country></aff>
<aff id="a4"><label>d</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01kq0pv72</institution-id><institution>Center for Studies of Psychological Application, Guangdong Key Laboratory of Mental Health and Cognitive Science, South China Normal University</institution></institution-wrap>, <city>Guangzhou</city>, <country country="CN">China</country></aff>
<aff id="a5"><label>e</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01kq0pv72</institution-id><institution>Philosophy and Social Science Laboratory of Reading and Development in Children and Adolescents, Ministry of Education, South China Normal University</institution></institution-wrap>, <city>Guangzhou</city>, <country country="CN">China</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Wang</surname>
<given-names>Shuo</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Washington University in St. Louis</institution>
</institution-wrap>
<city>St. Louis</city>
<country country="US">United States</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Luo</surname>
<given-names>Huan</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Peking University</institution>
</institution-wrap>
<city>Beijing</city>
<country country="CN">China</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label><email>ljcps@gzhu.edu.cn</email>; <email>xlzhang@m.scnu.edu.cn</email></corresp>
<fn id="n1" fn-type="equal"><label>*</label><p>These authors contributed equally</p></fn>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-08-20">
<day>20</day>
<month>08</month>
<year>2025</year>
</pub-date>
<pub-date date-type="update" iso-8601-date="2025-09-23">
<day>23</day>
<month>09</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP108017</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-06-18">
<day>18</day>
<month>06</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-06-21">
<day>21</day>
<month>06</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.06.18.660380"/>
</event>
<event>
<event-desc>Reviewed preprint v1</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2025-08-20">
<day>20</day>
<month>08</month>
<year>2025</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.108017.1"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.108017.1.sa2">eLife Assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.108017.1.sa1">Reviewer #1 (Public review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.108017.1.sa0">Reviewer #2 (Public review):</self-uri>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Lu et al</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Lu et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-108017-v2.pdf"/>
<abstract>
<title>Abstract</title>
<p>How does internal representation held in visual working memory (VWM), known as the attentional template, guide attention? A longstanding debate concerns whether only one (Single-Item-Template theory) or multiple (Multiple-Item-Template theory) items serve as attentional templates simultaneously. Here we propose a Rhythmic-Item-Template hypothesis, successfully reconciling these seemingly contradictory theories. Using the classical VWM-guided attention task, we found that two VWM items alternately dominate behavioral guidance in theta-rhythmic (4–8 Hz), with anti-correlated activation states in time, and more importantly, this rhythmic oscillation was not driven by the retro-cue processing. Neural recordings revealed that occipital alpha-oscillation (8–14 Hz) governed item-specific prioritization and its amplitude closely tracked subjects’ behavioral guidance, while frontal theta-oscillations phase-led and coupled with occipital alpha-oscillations during the item transition. Our Rhythmic-Item-Template results not only resolve previous Single-Item-Template versus Multiple-Item-Template debate but also advance our understanding of how distributed brain rhythms coordinate flexible resource allocation in multi-item memory systems.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>visual working memory</kwd>
<kwd>attention</kwd>
<kwd>rhythmic-item-template</kwd>
<kwd>theta-oscillation</kwd>
<kwd>alpha-oscillation</kwd>
</kwd-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Revised some details in Figure 1 and Figure 4.
Added a comparison with the study by Paters et al. (2021) in the Discussion section.
Added a part regarding the research limitations in the Discussion section.
Revised the description in the Methods section to make it clearer.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>The capacity of visual working memory (VWM) to guide attention through multiple internal templates remains contested<sup><xref ref-type="bibr" rid="c1">1</xref></sup>. While VWM can store several items<sup><xref ref-type="bibr" rid="c2">2</xref>–<xref ref-type="bibr" rid="c4">4</xref></sup>, behavioral studies conflict: some suggest only one item dominantly guides attention at any moment<sup><xref ref-type="bibr" rid="c5">5</xref>,<xref ref-type="bibr" rid="c6">6</xref></sup>, whereas others report parallel guidance by multiple templates<sup><xref ref-type="bibr" rid="c7">7</xref>,<xref ref-type="bibr" rid="c8">8</xref></sup>. Hollingworth and Beck<sup><xref ref-type="bibr" rid="c9">9</xref></sup> revealed that distractors matching either of two target colors elicited equivalent attentional capture, supporting dual templates. However, attenuated capture magnitude compared to single-item conditions exposed a critical paradox: if multiple templates coexist, why does their behavioral efficacy diminish? Three hypotheses emerge: (1) transient dominance of a single item suppresses others, (2) independent but weakened template influences, or (3) rhythmic alternation between items via theta-band oscillations (4 – 8 Hz). Critically, the third hypothesis posits that limited attentional resources are dynamically allocated through cyclical prioritization rather than static competition—a mechanism aligning with the oscillatory nature of neural processes<sup><xref ref-type="bibr" rid="c10">10</xref>,<xref ref-type="bibr" rid="c11">11</xref></sup>.</p>
<p>This oscillatory framework is rooted in attention’s discrete temporal dynamics. When monitoring two locations, human attention rhythmically samples each location at 4–10 Hz, with asynchronous peaks between sites — a “sequential attentional spotlight”<sup><xref ref-type="bibr" rid="c12">12</xref></sup>. Neural recordings demonstrate that alpha-band suppression (8–14 Hz), reflecting attentional engagement, alternates between objects every ∼200 ms (theta rhythm<sup><xref ref-type="bibr" rid="c13">13</xref></sup>). These findings imply a conserved theta-rhythmic mechanism for resolving representational competition, whether for external stimuli or internal VWM representations. Recent studies extend this to VWM: multi-item retention exhibits 6 – 10 Hz oscillatory patterns<sup><xref ref-type="bibr" rid="c14">14</xref>–<xref ref-type="bibr" rid="c16">16</xref></sup>, yet debates persist about whether these rhythms reflect true prioritization dynamics or spatiotemporal confounds <sup><xref ref-type="bibr" rid="c17">17</xref>,<xref ref-type="bibr" rid="c18">18</xref></sup>.</p>
<p>Moreover, Previous evidence for rhythmic memory processing primarily stems from behavioral measures, lacking direct neural evidence of stimulus-specific modulation. While alpha oscillations (8 – 14 Hz) in visual cortex track VWM item prioritization<sup><xref ref-type="bibr" rid="c19">19</xref>–<xref ref-type="bibr" rid="c21">21</xref></sup>, they likely enhance signal-to-noise ratios through selective neural recruitment rather than directly governing task goals<sup><xref ref-type="bibr" rid="c22">22</xref>–<xref ref-type="bibr" rid="c24">24</xref></sup>. Conversely, frontal theta oscillations (4 – 8 Hz) coordinate goal-directed behaviors and task switching<sup><xref ref-type="bibr" rid="c25">25</xref>,<xref ref-type="bibr" rid="c26">26</xref></sup> , exerting top-down control over sensory regions via phase synchronization<sup><xref ref-type="bibr" rid="c27">27</xref>,<xref ref-type="bibr" rid="c28">28</xref></sup>. Critically, fronto-posterior network coupling mediates control shifts in VWM: increased frontal theta power predicts contralateral occipital alpha suppression during priority transitions<sup><xref ref-type="bibr" rid="c29">29</xref>–<xref ref-type="bibr" rid="c31">31</xref></sup>. This supports a mechanistic hypothesis: frontal theta oscillations rhythmically drive spatially distributed alpha oscillations through cross-frequency coupling, dynamically activating multiple VWM items in theta-rhythmic cycles.</p>
<p>To test this theoretical proposition, we designed and conducted three experiments using a memory - search paradigm that effectively rules out strategic control<sup><xref ref-type="bibr" rid="c32">32</xref></sup>. Experiment 1, with dense temporal sampling, revealed 7 Hz anti - phasic oscillations in attentional capture between two VWM items. Experiment 2, by implementing individualized temporal analysis to eliminate retrospective cueing artifacts, replicated the 7 Hz behavioral rhythm. To further explore the neural mechanisms and comprehensively validate our theoretical hypothesis, we carried out Experiment 3, in which electroencephalography (EEG) was employed to record and analyze brain electrical activity with high temporal resolution. EEG results demonstrated that activation in the occipital alpha band was closely associated with behavioral performance and exhibited significant phase coupling with prefrontal theta oscillations. Additionally, during the memory maintenance phase, the coupling strength of alpha - theta between the bilateral visual cortex and the prefrontal cortex alternated in a theta - rhythmic pattern in leading. These results collectively establish frontally driven theta - alpha coupling as a mechanism for rhythmically allocating attentional access to multiple VWM items, reconciling the divergence between single - and dual - template theories through a dynamic, oscillation - based model.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<label>Experiment 1:</label>
<title>Theta-rhythmic oscillation of visual working memory</title>
<p>25 participants engaged in Experiment 1. As shown in <xref rid="fig1" ref-type="fig">Figure 1C</xref>, subjects were asked to remember two memory items that appeared simultaneously. During the memory retention interval, a cue randomly instructed to one of the items, directing internal attention towards the cued stimulus. To examine the time-course of VWM, the response interface appeared at various time intervals following the cue, with a high temporal resolution (stimulus onset asynchrony, SOA: starting at 233 ms and increasing in increments of 33 ms up to 867 ms). The response interface required participants to complete either a search task (80% of trials) or a recall task (20% of trials). In the search task, participants were asked to search a target square (with a gap at the top/bottom) while disregarding a distractor square (with a gap on the left/right). To ensure the search target and the memory item did not share the same spatial location, the target and distractor were positioned vertically relative to the participants’ point of gaze. Only one of the target and distractor matched the color of memory items, or neither did. The attentional capture effect was measured as the difference in response time between the distractor matching the memory items and the target matching the memory items. In the recall task, participants were asked to determine whether a presented color corresponded to one of the memory items, thereby assessing the accuracy of item retention.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption>
<p>A: Hypothetical models illustrating the activation patterns of two memory items during the memory retention phase. Hypothesis 1 posits a single template, Hypothesis 2 suggests multiple templates, and Hypothesis 3 proposes dynamic templates. B: Behavioral results, showing the attentional capture effect size (calculated as the difference in response time between the distractor matching the memory items and the target matching the memory items) and memory accuracy for the two memory items. C: Experimental procedure. A cue stimulus randomly indicated one of the two memory items. In 80% of the trials, participants performed a search task to identify the item with a gap facing upward or downward. In 20% of the trials, participants performed a recall task to determine whether the probed item matched one of the two memory colors.</p></caption>
<graphic xlink:href="660380v2_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Initially, we calculated the recall accuracy for both memory items, as depicted in <xref rid="fig1" ref-type="fig">Figure 1B</xref>. The recall accuracy for cued items (t(24) = 91.60; p &lt; 0.001, Cohen’s d = 37.39) and uncued items (t(24) = 70.74; p &lt; 0.001, Cohen’s d = 28.88) significantly exceeded the chance level (0.5), demonstrating effective memory retention for both item types. Subsequently, we examined the attentional capture effects associated with these memory items. The analysis revealed that the magnitude of the attentional capture was significantly above zero for both cued items (t(24) = 6.16; p &lt; 0.001, Cohen’s d = 2.51) and uncued items (t(24) = 8.02; p &lt; 0.001, Cohen’s d = 3.27), indicating that both items effectively captured attention. These findings align with previous studies<sup><xref ref-type="bibr" rid="c9">9</xref></sup>, confirming that human brain is capable of retaining multiple memory items simultaneously, with each item significantly influencing attentional processes.</p>
<p>With respect to the central question of our study, we found clear evidence for memory item sampling as a preferred template. As shown in <xref rid="fig2" ref-type="fig">Figure 2A</xref>, we examined the attentional capture effects of cued and uncued items separately for different temporal SOA conditions. It was found that the capture effects of these two items alternated in dominance rather than remaining stable (F(1, 19) = 4.67, p &lt; 0.001, η2 = 0.16). Specifically, the capture effect of cued items was significantly greater than that of uncued items at SOAs of 267ms (t(24) = 2.72, p = 0.03, Cohen’s d = 1.11), 667ms (t(24) = 2.37, p = 0.03, Cohen’s d = 0.97) and 833ms (t(24) = 3.53, p = 0.002, Cohen’s d = 1.44), while the capture effect of uncued items was significantly greater than that of cued items at SOAs of 333ms (t(24) = 2.97, p = 0.007, Cohen’s d = 1.21), 367ms (t(24) = 2.14, p = 0.04, Cohen’s d = 0.87), 433ms (t(24 )= 2.49, p = 0.02, Cohen’s d = 1.02), 467ms (t(24)=2.37, p = 0.03, Cohen’s d = 0.97) and 567ms (t(24)=2.72, p = 0.02, Cohen’s d = 1.11).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption>
<p>A: Line graph. The attentional capture effect size for the cued and uncued items across different time intervals (SOA), calculated as the difference in response time between the invalid and valid conditions. B: Spectrum plot. The red line represents the amplitude of the values from A at different frequencies; the gray line indicates the 95th percentile from the permutation test; *: p &lt; 0.05. C: Phase-locking value (PLV). The red line shows the PLV values at 7 Hz for the cued and uncued items, representing the average phase difference across all participants; gray circles indicate the 0-95 percentile range from the permutation test; blue hollow circles represent the phase differences for individual participants between the two items.</p></caption>
<graphic xlink:href="660380v2_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>In addition, as shown in <xref rid="fig2" ref-type="fig">Figure 2B</xref>, the Fourier transformation was applied to the time course of the item-based benefit to determine the temporal frequency of these fluctuations. The item-based benefit was calculated as the difference in capture effects between the cued and uncued item for equidistant time intervals ranging from 200 ms to 833 ms. The amplitude spectrum analysis of frequencies ranging from 1 Hz to 15 Hz (<xref rid="fig2" ref-type="fig">Figure 2B</xref>) revealed a significant peak at 7 Hz (p &lt; 0.05, FDR corrected). This finding implies that the rhythmic fluctuations in attentional capture associated with VWM are likely driven by an oscillatory mechanism within the theta frequency range, supporting the proposed sampling frequency in VWM.</p>
<p>Consistent with the hypothesis that only a single memory item serves as a prioritized template at any given moment, the speed at which cued and uncued items are accessed should exhibit a negative correlation, as demonstrated in previous research on visuospatial and object-based attention<sup><xref ref-type="bibr" rid="c12">12</xref>,<xref ref-type="bibr" rid="c33">33</xref></sup>. To investigate the possibility that attention within VWM alternates between items, we analyzed the Fourier coefficients at 7 Hz corresponding to the attentional capture effects for both cued and uncued items and subsequently calculated their phase-locking values (PLV<sup><xref ref-type="bibr" rid="c33">33</xref></sup>). As shown in <xref rid="fig2" ref-type="fig">Figure 2C</xref>, the phase-locking between the 7 Hz rhythms of the two items was found to be significant (PLV = 0.402, p &lt; 0 .05), displaying an average phase angle difference of 118° (95% CI from 48° to 188°). This anti-phase relationship between the oscillations supports the notion that internal attention alternately samples items in working memory.</p>
</sec>
<sec id="s2b">
<label>Experiment 2:</label>
<title>Behavioral oscillation without cueing</title>
<p>17 participants took part in Experiment 2, which closely replicated the design of Experiment 1 with one critical modification: no retro-cue was presented after the two memory items. Instead, the probe appeared directly after one of three fixed stimulus-onset asynchronies (SOAs: 233 : 33 : 867 ms; see <xref rid="fig3" ref-type="fig">Figure 3A</xref>). This adjustment was implemented to rule out the possibility that working memory oscillations were driven by cue processing rather than intrinsic maintenance mechanisms.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><p>A: Experimental procedure. Two memory items are presented simultaneously without any post-cue prompts. In 80% of the trials, participants performed a search task to identify the item with a gap facing upward or downward. In 20% of the trials, participants performed a recall task to determine whether the probed item matched one of the two memory colors. B: Behavioral results, showing the attentional capture effect size and memory accuracy for the two memory items.</p></caption>
<graphic xlink:href="660380v2_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>As illustrated in <xref rid="fig3" ref-type="fig">Figure 3B</xref>, the recall accuracy for both the left memory item (t(16) = 53.40, p &lt; 0.001, Cohen’s d = 13.35) and the right memory item (t(16) = 51.10, p &lt; 0.001, Cohen’s d = 12.78) significantly exceeded the chance level (0.5), suggesting effective retention of the memory items by participants. Furthermore, our analysis of the attentional capture effect of both memory items revealed that the effect size was notably higher than zero for both the left item (t(16) = 3.24, p = 0.005, Cohen’s d = 0.81) and the right item (t(16) = 3.21, p = 0.005, Cohen’s d = 0.80), demonstrating that both memory items were effective in capturing attention.</p>
<p>Since no retro-cue was presented in Experiment 2, the data lacked a fixed temporal reference point across participants. Thus, unlike in Experiment 1 (where capture effects were group-averaged before Fourier analysis), we performed Fourier transforms individually for each participant before grand-averaging. Specifically, we computed the item-based benefit for each participant by subtracting the capture effect of the right memory item from that of the left item, evaluated at equidistant time intervals (233 – 867 ms). For each participant, we conducted amplitude spectrum analysis (1–15 Hz) on these time series. The resulting spectra were then grand-averaged across participants (blue line, <xref rid="fig4" ref-type="fig">Figure 4</xref>). To assess whether spectral power exceeded chance levels, we generated a null distribution by (1) randomly shuffling each participant’s time series, (2) recomputing the Fourier transform, and (3) repeating this procedure 1,000 times. The median amplitude of these surrogate data served as the chance baseline. A paired-samples T-test comparing the original amplitudes against this null distribution revealed significant oscillatory power at 7 Hz (p &lt; 0.05, FDR corrected).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>The red line represents the average across all participants of the Fourier transforms of the differences in capture effects between left and right memory items at the individual level.</title>
<p>The gray area represents values below the group average of medians derived from 1000 permutations, with each permutation involving Fourier transforms for each participant. *: p &lt; 0.05.</p></caption>
<graphic xlink:href="660380v2_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2c">
<label>Experiment 3:</label>
<title>Neural mechanisms of visual working memory oscillations</title>
<p>In Experiment 3, 27 participants were recruited, with 3 participants excluded due to excessive artifacts in EEG data. This experiment differed from Experiment 1 in that the search task and the cue were presented at a fixed interval of 1500 ms, while the interval between the memory task and the probe varied randomly between 200 ms and 2000 ms (see <xref rid="fig5" ref-type="fig">Figure 5B</xref>). All other aspects of the experiment remained consistent with those of Experiment 1. Additionally, EEG data were recorded simultaneously from participants.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><p>A: Behavioral results, showing the attentional capture effect size and memory accuracy for the two memory items. B: Experimental procedure. A cue stimulus randomly indicated one of the two memory items. In 80% of the trials, participants performed a search task to identify the item with a gap facing upward or downward. In 20% of the trials, participants performed a recall task to determine whether the probed item matched one of the two memory colors.</p></caption>
<graphic xlink:href="660380v2_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>First, we calculated the recall accuracy for both memory items. As shown in <xref rid="fig5" ref-type="fig">Figure 5A</xref>, cued (t(23) = 45.70, p &lt; 0.001, Cohen’s d = 19.06) and uncued items (t(23) = 23.56, p &lt; 0.001, Cohen’s d = 9.82) were both recalled correctly at a significantly greater level than the chance level (0.5), indicating successful retention of both types of items. Additionally, we analyzed the attentional capture effects of the two memory items. The findings revealed that the attentional capture effects for cued (t(23) = 6.45, p &lt; 0.001, Cohen’s d = 2.69) and uncued items (t(23) = 5.61, p &lt; 0.001, Cohen’s d = 2.34) were significantly greater than zero, indicating that both types of memory items effectively captured attention.</p>
<p>Subsequently, an individual time-frequency analysis was conducted on the EEG data during the memory retention phase before the search task. This analysis delved into the temporal and spectral dynamics across frequencies from 1 to 30 Hz and time intervals from -500 to 2000 ms for each participant. Consistent with prior studies<sup><xref ref-type="bibr" rid="c34">34</xref></sup> <sup><xref ref-type="bibr" rid="c19">19</xref></sup>, pronounced alpha band activity (8 - 14 Hz) was observed in regions contralateral (PO7/8) to the memorized items (see <xref rid="fig6" ref-type="fig">Figure 6</xref>).</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><p>A: Time-frequency results of the contralateral occipital lobe (PO7/8) for cued items, showing significant alpha band activation (8-14 Hz) during the memory retention phase. B: Time-frequency results of the contralateral occipital electrodes (PO7/8) for uncued items, with a similar activation pattern to that observed for cued items.</p></caption>
<graphic xlink:href="660380v2_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To evaluate the impact of alpha band activity on attentional capture, correlation coefficients between behavioral performance and alpha power were calculated. Specifically, the correlation between the alpha power contralateral to the items 200 milliseconds before the onset of the search task and the capture effect of the item was analyzed. As shown in <xref rid="fig7" ref-type="fig">Figure 7</xref>, a significant positive correlation was found for the cued item (r = 0.43, p = 0.03) , indicating that stronger alpha band activity correlated with an enhanced capture effect. These findings imply that alpha activation patterns prior to the onset of search stimulus can predict the effectiveness of VWM in guiding the search. Essentially, the alpha band may reflect the priority state within VWM, aligning with findings from previous research<sup><xref ref-type="bibr" rid="c19">19</xref>,<xref ref-type="bibr" rid="c35">35</xref></sup>.</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7.</label>
<caption><title>The attentional capture effect size of cued items was positively correlated with the mean amplitude of the alpha band activity during the last 200 ms of the memory retention phase, which occurs 200 ms before the onset of the search target.</title></caption>
<graphic xlink:href="660380v2_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2d">
<title>Time (ms)</title>
<p>Analysis of power differences between cued and uncued items unveiled a distinct pattern of alpha inhibition followed by rebound activation within the first 200 ms, as illustrated in <xref rid="fig8" ref-type="fig">Figure 8</xref>. Remarkably, this alternation in alpha band power persisted throughout the memory retention phase and showed a significant rhythm of approximately 4 Hz (<xref rid="fig10" ref-type="fig">Figure 10A</xref>, p &lt; 0 .05).</p>
<fig id="fig8" position="float" orientation="portrait" fig-type="figure">
<label>Figure 8.</label>
<caption><title>Time-frequency results, showing the difference in contralateral electrode activity (PO7/PO8) for same-color and same-location items under cued and uncued conditions.</title></caption>
<graphic xlink:href="660380v2_fig8.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Notably, both this study and prior research have identified that the alpha band decodes the preferred memory template. Intriguingly, an observation common to our study and earlier work is that the alternating frequency of this preferred template aligns with the theta rhythm range (4-7 Hz). To explore the potential impact of theta oscillations in different brain regions on alpha oscillations in regions contralateral to the memorized items, we employed the weighted phase lag index (wPLI) to measure the interaction between alpha oscillations at PO7 and PO8 and theta oscillations in other brain regions. The findings, illustrated in <xref rid="fig9" ref-type="fig">Figure 9A</xref>, indicated significant coupling between PO7/8 and the prefrontal regions. Additionally, wPLI calculations revealed significant coupling for theta oscillations in the prefrontal cortex (Fz) and alpha oscillations in the visual regions. Fascinatingly, by assessing the alpha-theta coupling strength between the posterior regions contralateral to the two items (PO7/8) and the prefrontal regions (Fz) on a moment-to-moment basis during the memory retention period, we found that the coupling strength of the two items alternated in lead. To further define the temporal frequency characteristics of these alternations, Fourier transformation was applied to the differences in wPLI associated with the two items. An amplitude spectrum analysis across frequencies from 1 Hz to 50 Hz (<xref rid="fig10" ref-type="fig">Figure 10B</xref>) identified a significant peak at 4 Hz (p &lt; 0.05, FDR corrected), underscoring the rhythmic interconnection between these neural activities.</p>
<fig id="fig9" position="float" orientation="portrait" fig-type="figure">
<label>Figure 9.</label>
<caption><p>A: Topographical maps. Cross-frequency coupling between the alpha phase at the white electrode points and the theta phase at other electrode points (the left two maps), and the theta phase at the white electrode points and the alpha phase at other electrode points (the right map) during the memory retention phase. B: Functional connectivity map. Cross-frequency coupling between the alpha phase at the contralateral electrodes (PO7/PO8) of the two memory items (red lines represent the cued item; black lines represent the uncued item) and the theta phase at the frontal electrode (Pz) during the memory retention phase.</p></caption>
<graphic xlink:href="660380v2_fig9.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="fig10" position="float" orientation="portrait" fig-type="figure">
<label>Figure 10.</label>
<caption><p>A: Spectrum results. Power spectrum of the difference in contralateral alpha power between the two memory items during the retention phase across 0-50 Hz. B: Spectrum results. Power spectrum of the difference in cross-frequency coupling (wPLI) between the alpha phase at contralateral electrodes (PO7/PO8) and the theta phase at the frontal electrode (Fz) across 0-50 Hz during the retention phase. The gray shaded area represents the 0-95th percentile range from the permutation test; *: p &lt; 0.05.</p></caption>
<graphic xlink:href="660380v2_fig10.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>This study employed the function of VWM as a preferred template to automatically capture attention and integrated EEG techniques to systematically investigate the mechanisms underlying the representation of two memory items that occurred simultaneously or in close temporal proximity during the memory retention phase. Our findings revealed several key insights. Firstly, we observed that the ability of the memory items to capture attention alternated over time, displaying opposite trends (Experiment 1). This indicates that the preference for the memory items alternated rather than occurring simultaneously. Power analysis showed alternating rhythms within the 4-7 Hz range (Experiment 1-3), corresponding to theta oscillations. Secondly, during the memory retention phase, the strength of alpha band oscillations, induced by cued and uncued items, alternated in dominance throughout the retention period. Thirdly, we observed strong rhythmic alternations in the coupling strength between the alpha band of both posterior regions and the theta band of the prefrontal region. The coupling exhibited a leading frequency of approximately 4 Hz. In conclusion, our findings suggest that memory is maintained by alternately processing multiple items within the theta rhythm, rather than continuously entangling a single object. Furthermore, the posterior alpha oscillations reflect the prioritization of memory items and exhibit a close association with theta oscillations in the prefrontal cortex.</p>
<p>Traditional research on working memory has often adopted a static viewpoint, positing that its performance remains constant throughout the retention phase. This perspective, however, is challenged by the findings of the present study, which investigates the ability of two memory items to capture attention under various Stimulus-Onset Asynchrony (SOA) conditions. Interestingly, the study reveals that the attentional capture abilities of these memory items alternate in dominance. Spectral analysis of the SOA function identified significant rhythmic fluctuations at 7 Hz, with opposing trends. This pattern suggests that, in scenarios requiring the maintenance of two working memory items for a task, these items alternately serve as the dominant template during the retention phase.</p>
<p>This discovery aligns with the existing literature on the rhythmic processing of external stimuli. Specifically, it has been well-documented that attention oscillates within the theta rhythm (4-8 Hz) across various task types, including those based on spatial attention <sup><xref ref-type="bibr" rid="c36">36</xref>,<xref ref-type="bibr" rid="c37">37</xref></sup>, feature attention<sup><xref ref-type="bibr" rid="c38">38</xref></sup>, and object attention<sup><xref ref-type="bibr" rid="c10">10</xref>,<xref ref-type="bibr" rid="c33">33</xref>,<xref ref-type="bibr" rid="c39">39</xref></sup>. Moreover, rhythmic attentional modulation has been observed in auditory attention<sup><xref ref-type="bibr" rid="c40">40</xref>,<xref ref-type="bibr" rid="c41">41</xref></sup> , in the effects of top-down predictions on brightness perception<sup><xref ref-type="bibr" rid="c42">42</xref></sup>, and in the process of visual feature binding<sup><xref ref-type="bibr" rid="c43">43</xref></sup>. These findings collectively highlight that attention operates within a theta rhythm, extending beyond external stimuli to include the internal processing of memory information<sup><xref ref-type="bibr" rid="c15">15</xref>,<xref ref-type="bibr" rid="c16">16</xref></sup>.</p>
<p>Similar to the present study, Peters et al. <sup><xref ref-type="bibr" rid="c15">15</xref></sup> had participants memorize four spatial positions forming the endpoints of two objects (one cued), and their results showed that after the two objects disappeared, attention fluctuated at the theta rhythm between their original positions with an inverse correlation; in contrast, the present study explores the manner of memory maintenance indirectly by leveraging the guiding effect of working memory on attention, effectively avoiding the influence of spatial positions—while Peters et al.’s study, which directly examined differences in probe positions, clearly demonstrates that attention undergoes rhythmic changes at the two spatial locations and persists after the objects vanish, it hardly clarifies the rhythmicity of working memory performance, whereas the present study directly investigates such performance using the attention-capture effect of working memory, revealing that when maintaining multiple memory items, their attention-capturing capabilities alternate in dominance, i.e., multiple working memory items alternately become priority templates in a rhythmic manner.</p>
<p>The concept of a dynamic template mechanism emerges as a novel resolution to the ongoing debate between the single-template and multi-template hypotheses in working memory research<sup><xref ref-type="bibr" rid="c1">1</xref>,<xref ref-type="bibr" rid="c6">6</xref>,<xref ref-type="bibr" rid="c44">44</xref></sup>. his mechanism proposes that when maintaining multiple memory items, an individual represents these items through a single, dynamically shifting template, with each moment guided by a single item—a process that is spontaneous and not triggered by a retro-cue prompting a specific memory item. As observed in my Study 2, even in the presence of retro-cues, multiple memory items still begin with a particular item (consistent with individual habits) and sequentially become priority templates at the theta rhythm.This flexible approach not only aligns with the observed phenomenon of multiple memory items capturing attention, but also provides a new perspective on the discourse on how working memory operates, bridging a critical gap in the existing literature.</p>
<p>The current study reveals that during the memory retention phase, the dominance of posterior lateralized alpha oscillation alternates between two memory items and significantly correlates with behavioral outcomes. This finding aligns with extensive evidence suggesting that alpha oscillations are crucial in modulating visual processing, going beyond mere sensory involvement to encompass functional roles in sensory gating and top-down control of preparatory activity<sup><xref ref-type="bibr" rid="c23">23</xref>,<xref ref-type="bibr" rid="c36">36</xref>,<xref ref-type="bibr" rid="c45">45</xref>,<xref ref-type="bibr" rid="c46">46</xref></sup>. Notably, alpha band activity modulation is essential for prioritizing both incoming sensory data and stored memory content<sup><xref ref-type="bibr" rid="c47">47</xref>,<xref ref-type="bibr" rid="c48">48</xref></sup>. A seminal example is a study in which subjects memorized two sequentially presented items, demonstrating the capability of posterior lateralized alpha oscillations to differentiate the memory item relevant to the current task, thereby elucidating the role of oscillations in managing the priority of concurrent task-relevant items <sup><xref ref-type="bibr" rid="c35">35</xref></sup>.</p>
<p>It’s critical to acknowledge that the investigation of posterior alpha oscillations in working memory, including the design of Experiment 3 in this study’s, often involves spatial differentiation of items<sup><xref ref-type="bibr" rid="c35">35</xref></sup>. Such spatial segregation allows alpha power modulations to be attributed to specific items through lateralization, achieved by presenting items in distinct hemifields. This methodological choice, driven by the spatial specificity of neurons encoding working memory items, serves as a pragmatic experimental strategy rather than implying that memory item prioritization solely depends on alpha oscillation lateralization<sup><xref ref-type="bibr" rid="c49">49</xref>,<xref ref-type="bibr" rid="c50">50</xref></sup>. For example, de Vries et al.<sup><xref ref-type="bibr" rid="c19">19</xref></sup> discovered that posterior, rather than lateralized, alpha oscillations could delineate memory items related to forthcoming tasks.</p>
<p>The findings of this study, revealing strong phase coupling between posterior alpha oscillations and theta oscillations in the prefrontal lobe, contribute to the expanding literature on the intricate interplay between different brain oscillation frequencies and their roles in cognitive functions. The association of prioritization processes with theta oscillations in the frontal cortex is well-documented<sup><xref ref-type="bibr" rid="c30">30</xref>,<xref ref-type="bibr" rid="c35">35</xref>,<xref ref-type="bibr" rid="c51">51</xref>,<xref ref-type="bibr" rid="c52">52</xref></sup>, underscoring the critical role of frontal cortex in orchestrating goal-directed behavior<sup><xref ref-type="bibr" rid="c53">53</xref></sup>, managing multiple objectives<sup><xref ref-type="bibr" rid="c54">54</xref></sup>, and facilitating task switching<sup><xref ref-type="bibr" rid="c55">55</xref></sup>.</p>
<p>Particularly during working memory tasks, the frontal cortices play a critical role in processing and maintaining abstract goal-related representations and task-specific information. This is supported by the evidence of mixed selectivity in frontal neurons<sup><xref ref-type="bibr" rid="c56">56</xref></sup> and their coordination of sensory areas based on this information<sup><xref ref-type="bibr" rid="c57">57</xref>,<xref ref-type="bibr" rid="c58">58</xref></sup>. For instance, fMRI studies have highlighted enhanced connectivity between frontal regions and posterior task-related sensory areas specific to working memory representations and those prioritized by maintenance cues (retrospective cues<sup><xref ref-type="bibr" rid="c59">59</xref>,<xref ref-type="bibr" rid="c60">60</xref></sup>), with this increased connectivity correlating with improved performance of cued memory representations<sup><xref ref-type="bibr" rid="c46">46</xref>,<xref ref-type="bibr" rid="c61">61</xref></sup>.</p>
<p>Such evidence underscores the ability of the frontal cortex to selectively coordinate the activation of visual cortical working memory representations relevant to the current task. As outlined in a review by de Vries et al.<sup><xref ref-type="bibr" rid="c30">30</xref></sup>, alpha modulation facilitates the flexible tracking of changes in the state of VWM. This top-down control over the current state of VWM is accomplished through prefrontal theta oscillations, which in turn orchestrate alpha oscillations via a broad spectrum of cross-frequency interactions, highlighting a sophisticated mechanism of cognitive control and memory prioritization.</p>
<p>Although the present study successfully revealed the phenomenon of dynamic attentional templates through high-density behavioral sampling and preliminarily explored the underlying mechanisms using high-temporal-precision EEG technology—specifically, that prefrontal theta oscillations and visual cortical alpha oscillations play indispensable roles in this process—there are still some limitations. First, despite its high temporal resolution, the EEG technique used in this study makes it difficult to precisely localize the brain regions influencing dynamic templates due to the brain’s volume conduction effect<sup><xref ref-type="bibr" rid="c62">62</xref></sup>. Second, the sample size of the current study is small, which may render the results vulnerable to interference from extreme cases<sup><xref ref-type="bibr" rid="c63">63</xref></sup>. Additionally, the present study referenced previous research by using the wPLI index as a measure of cross-frequency coupling strength<sup><xref ref-type="bibr" rid="c31">31</xref>,<xref ref-type="bibr" rid="c64">64</xref>–<xref ref-type="bibr" rid="c66">66</xref></sup> (this index quantifies the stability of phase differences), yet the phases of different oscillations inherently change over time. However, this is fair to the two memory items in the present study, as their presentation times were balanced. The study found that the wPLI values of the two items alternately dominated over time, consistent with the pattern of behavioral data, which is hardly explicable by coincidence. Future research could employ more precise techniques (e.g., MEG devices) to accurately capture activities in different brain regions while maintaining high temporal precision. Furthermore, rhythmic transcranial magnetic stimulation (TMS) could be used to modulate rhythms in various brain regions, altering the oscillation frequencies of working memory to provide causal evidence for this phenomenon.</p>
<p>In conclusion, our study aligns with the evolving understanding that oscillatory neural mechanisms underpin the complex interplay between attention and working memory. It builds on the premise that external attentional processes are intricately linked with neural oscillations, while also highlighting the crucial role of internal attention in modulating working memory representations through rhythmic activity. Our findings support a framework in which internal attention is mediated by a dynamic interaction between prefrontal theta oscillations, serving as a top-down control mechanism, and posterior alpha oscillations, which are instrumental in the selective inhibition or facilitation of memory items. This synthesis not only challenges conventional static views of working memory but also proposes a refined model of cognitive processing, where memory maintenance and attentional prioritization are orchestrated within a rhythmic neural symphony.</p>
</sec>
<sec id="s4">
<title>Materials and methods</title>
<sec id="s4a">
<title>Participants</title>
<p>A total of 25 participants (9 males, aged 22 ± 1.9 years) took part in Experiment 1, 17 subjects (6 males, aged 19 ± 1.5 years) participated in Experiment 2, and 27 subjects (12 males, aged 21 ± 2.0 years) were involved in Experiment 3. All participants had normal or corrected-to-normal vision and no history of psychiatric or neurological disorders. The experiments were conducted in accordance with the Declaration of Helsinki and received ethical approval from the Research Ethics Committee at South China Normal University (approval date: 2021-04-01). Before the start of the experiment, all participants provided written informed consent. Participants completed the experiment in a dark, quiet and isolated room, with their heads fixed on a head rest and their eyes looking directly at the centre of the screen at a distance of 57 cm from the display.</p>
</sec>
<sec id="s4b">
<title>Stimuli</title>
<p>The same stimuli were used for all three experiments. The memory stimuli were a square in 6 colours: cyan (RGB: 5, 200, 200), red (RGB: 200, 80, 40), yellow (RGB: 200, 200, 5), blue (RGB: 5, 200, 200), purple (RGB: 112, 48, 160), and green (RGB: 50, 200, 50), each with a visual angle of 1.2 × 1.2°. The search stimuli were colored outlined squares (1.2 × 1.2°, 0.2° line thickness), with a 1.2° gap on the top, bottom, left side, or right side. The color of the search stimulus was consistent with that of the memory stimulus. The cue stimulus is a black square with side length 1.2°. The shape and color of the detection stimulus are consistent with those of the memory stimuli.</p>
<p>The experiments were programmed using the Psychtoolbox in Matlab 2019b. All stimuli were presented on a 17-inch CRT monitor with a resolution of 1024 × 768, a refresh rate of 60 Hz, and a gray background (RGB: 128, 128, 128).</p>
</sec>
<sec id="s4c">
<title>Tasks</title>
<sec id="s4c1">
<title>Experiment 1</title>
<p>Each trial began with a 500 ms fixation point, followed by a 1000 ms memory array. In the memory array, two differently colored memory stimuli were presented to the left and right at a distance of 3° from the centre of the screen. After a 250ms fixation point, the cue array was presented for 50 ms, with the cue appearing randomly on the left or right at a distance of 3° from the centre of the screen. After a pseudo-random SOA (233 ms : 33 ms : 867 ms), either the search array (80% of trials) or the memory detection array (20% of trials) was presented for 2500 ms. In the search array, two search stimuli were presented directly above or below the screen center, 6° away from it; one had a gap facing up or down (the target), and the other had a gap facing left or right (the distractor). Participants were instructed to respond by pressing the “A” key (for an upward-facing gap) or the “Z” key (for a downward-facing gap). In the memory detection array, a detection stimulus was presented at the screen center for 2500 ms. Participants were asked to press the “N” key (if it belonged) or the “M” key (if it did not belong) to determine whether the detection stimulus belonged to either of the memory stimuli in the memory array, regardless of the cue. After responding, participants moved on to the next trial, with a 1000ms interval between trials. To familiarize participants with the task, 15 practice trials were conducted before the formal experiment. Participants completed 30 blocks over four days within one week, with each block containing 150 trials (120 trials for search tasks and 30 trials for memory detection tasks).</p>
</sec>
<sec id="s4c2">
<title>Experiment 2</title>
<p>Each trial began with a 500 ms fixation point, followed by a 1000 ms memory array. In the memory array, two memory stimuli of different colors were presented on the left and right sides, 3° away from the center of the screen. After a pseudo-random SOA (233 ms : 33 ms : 867 ms), either the search array (80% of trials) or the memory detection array (20% of trials) was presented for 2500 ms. Participants’ tasks in the search array and memory detection array were consistent with those in Experiment 1. Over the course of one week (completed across four days), participants finished 30 blocks, with each block consisting of 150 trials (120 for search tasks and 30 for memory detection tasks).</p>
</sec>
<sec id="s4c3">
<title>Experiment 3</title>
<p>In Experiment 3, high temporal precision EEG technology was employed, which eliminated the need for dense SOA manipulation when investigating dynamic features. Additionally, to enable a longer memory retention time window during analysis, the interval between the cue array and the search array was fixed at 2000 ms. Furthermore, to encourage active maintenance of memory content during the retention phase, the interval between the cue array and the memory detection array was randomly varied between 200 ms and 2000 ms. Consistent with Experiment 1, 20% of the trials involved the memory detection array, and 80% involved the search array. The tasks for both the memory detection array and the search array were the same as in Experiment 1, and both were presented for 2500 ms. Participants were required to complete 4 blocks, with each block consisting of 150 trials.</p>
</sec>
</sec>
<sec id="s4d">
<title>EEG recordings and preprocessing</title>
<p>EEG data was recorded using a cap with 64 electrodes arranged according to the international 10–20 system (Brain Products, Munich, Germany). The frontal electrode FCz was utilized as the online reference point, and the AFz electrode was employed as the ground. All electrodes were amplified using a 0.01–70 Hz online band-pass filter and continuously sampled at a rate of 1000 Hz per channel.</p>
<p>The offline continuous EEG data was preprocessed using EEGLAB, an open-source toolbox within the MATLAB environment. Initially, re-reference was conducted by using the bilateral mastoids TP9 and TP10. Next, all EEG signals underwent a 0.1 Hz high-pass filter, a 30 Hz low-pass filter, and a 50 Hz notch filter. Subsequently, independent component analysis (ICA) was applied to each participant;s data to eliminate components related to eye movements and artifacts. The remaining components after this process were then projected back into the channel space. We extracted data from -500 ms to 2000 ms relative to cue stimulus presentation in Experiment 3.</p>
</sec>
<sec id="s5">
<title>Data analysis</title>
<sec id="s5a">
<title>Behavioral performance analysis</title>
<p>We utilized the difference in reaction times (ΔRT) between the invalid trials (where the color of the memory item matched that of the interfering item) and the valid trials (where the color of the memory item matched that of the target item) extracted from the search array as the capture effects.</p>
<p>Subsequently, we employed a one-sample t-test to separately examine whether the memory accuracy rates of the two memory items in the three experiments were significantly higher than the guessing level (50%), and whether the capture effects of the two memory items were significantly greater than 0. In this process, the memory accuracy rates and capture effects in Experiment 1 and Experiment 2 were the results of averaging all the SOA (stimulus onset asynchrony) conditions.</p>
<p>For Experiment 1, we concentrated on exploring how the capture effect of the two memory items on attention evolved over time. To accomplish this, we carried out a repeated-measures analysis of variance (ANOVA) with a 2 (cued item vs. uncued item) × 20 (all SOAs) design. Post-hoc comparisons were conducted using paired-sample t-tests to thoroughly investigate the potential changes in the capture effect of the memory items on attention.</p>
<p>In order to obtain the frequency spectrum of memory-based attention capture over time, we analyzed the difference in capture effects between the cued and uncued items across all SOAs at evenly spaced temporal intervals. Subsequently, we performed a fast Fourier transform (FFT) to estimate the spectral composition, which yielded power values across 14 frequency bins ranging from 1 Hz to 14 Hz. Regarding the phase relationship of 7-Hz oscillations between the cued and uncued items, we conducted separate Fourier transforms for these conditions as previously described. Then, we calculated the angular difference between the phase angles of the 7-Hz oscillations for each condition. This angular difference was projected onto the unit circle in the complex plane and averaged across all participants. The length and angle of the resulting vector represented the phase-locking value (PLV <sup><xref ref-type="bibr" rid="c67">67</xref></sup>) and the mean phase difference. To evaluate the statistical significance, a non-parametric approach was adopted to estimate the probability of the observed data under the null hypothesis. In 1000 permutation samples, each time-course was shuffled before the analysis, generating one mean amplitude spectrum for the memory-based capture effect, and one mean phase difference between the cued and uncued conditions for each permutation sample. To control the false discovery rate at 5%, the individual frequency p-values in the amplitude spectrum were adjusted according to the number of frequency bins, following the method of Benjamini and Hochberg<sup><xref ref-type="bibr" rid="c68">68</xref></sup>.</p>
<p>For Experiment 2, since Experiment 2 adopted a modified approach due to the absence of retro-cues. In this experiment, we compared the left and right memory items instead of the cued/uncued items. The item-based attentional benefit was calculated for each participant by subtracting the right-item capture effect from the left-item effect at equidistant intervals (233-867 ms). Individual FFTs (1-15 Hz) were performed on these difference scores before conducting a grand average across all participants. To determine the significance thresholds, we generated null distributions by randomly shuffling each participant’s time series 1000 times, recomputing the FFTs for each permutation, and using the median amplitude as the chance baseline. A paired-samples t-test comparing the original amplitudes against this the chance baseline revealed significant 7-Hz oscillatory power (p &lt; 0.05, FDR corrected), as depicted in <xref rid="fig4" ref-type="fig">Figure 4</xref>.</p>
</sec>
<sec id="s5b">
<title>Time-frequency decomposition</title>
<p>We used the short-time Fourier transform (STFT) function in Matlab 2019b to Fourier transform the baseline-corrected segments to obtain the power information, where the frequency was set to 30 frequency points of equal length from 1 to 30 Hz and the sliding window was a 200 ms hanning window. The frequency-specific power at each time point was calculated as the square of the amplitude of the complex signal resulting from the convolution, determined by the sum of the squares of the real and imaginary parts. Based on findings from previous studies indicating that memory stimuli can be characterized by alpha oscillations in the contralateral occipital lobes<sup><xref ref-type="bibr" rid="c19">19</xref></sup>, we therefore extracted alpha band data (8-14 Hz) from PO7 and PO8. We separately averaged the power of the contralateral side for the cued and uncued items. As illustrated in <xref rid="fig8" ref-type="fig">Figure 8</xref>, to compare the power induced by cued items with that induced by uncued items during the memory retention phase, we extracted the contralateral power for each color during memory retention. The power when cued was subtracted from the power when uncued. Finally, we averaged the results across all memory colors and participants.</p>
</sec>
<sec id="s5c">
<title>Interregional connectivity</title>
<p>We computed the weighted phase lag index (wPLI) between the alpha band phase at electrodes PO7 and PO8 and the theta band phase at other electrode. The wPLI assesses phase-based functional connectivity by measuring the degree of phase clustering between sites<sup><xref ref-type="bibr" rid="c69">69</xref></sup> , while mitigating the influence of random phase lag, thereby controlling for volume conduction artifacts<sup><xref ref-type="bibr" rid="c70">70</xref></sup>. The results revealed that both electrodes PO7 and PO8 exhibited the strongest phase coupling with electrodes in the prefrontal region. Following this, we calculated the wPLI between the theta band at electrode Fz in the prefrontal region and the alpha band at other electrodes to confirm the specificity of cross-frequency coupling between the prefrontal regions and visual cortex. Finally we extracted the wPLI between the electrodes PO7/8 in the contralateral visual region relative to the cued and uncued items respectively, and the Fz electrode at the forehead.</p>
</sec>
<sec id="s5d">
<title>The correlation between neural activation and behavior</title>
<p>As shown in <xref rid="fig6" ref-type="fig">Figure 6</xref>, a clear activation of the alpha band was observed during the memory retention phase. To investigate whether this activation was related to behavioral performance, we calculated the alpha activation strength in the 200 ms preceding the search task. Specifically, we computed the average amplitude within the 8-14 Hz frequency range during the 1800-2000 ms time window of the retention phase, contralateral to the cue. This was then correlated with the capture effect size of the cued items using Pearson’s correlation, as shown in <xref rid="fig7" ref-type="fig">Figure 7</xref>.</p>
</sec>
<sec id="s5e">
<title>Frequency spectrum analysis</title>
<p>As shown in <xref rid="fig8" ref-type="fig">Figure 8</xref>, the alpha power (8-14 Hz) induced by cued and uncued items alternated in dominance during the memory retention phase. To quantify this rhythmic alternation, we conducted a spectral analysis following these steps: First, we computed the power difference between cued and uncued items within the 8-14 Hz range during the retention phase. These differences were then downsampled to 100 Hz using a 10 ms window for averaging, generating a one-dimensional time series spanning the 0-2000 ms retention period. This time series was subsequently subjected to amplitude spectrum analysis across frequencies from 1 Hz to 50 Hz using Fourier transformation.</p>
<p>To assess the statistical significance of the observed spectral features, we employed a permutation test. Specifically, we randomly shuffled the temporal order of the time series of power differences between cued and uncued items—thereby preserving the amplitude distribution of the data while eliminating temporal correlations in the original sequence—and repeated the Fourier transform and spectral analysis for each shuffled time series. This permutation process was replicated 1000 times to generate a null distribution of spectral power values. A frequency component in the original data was considered statistically significant if its power ranked within the top 5% of the corresponding null distribution (p &lt; 0.05).</p>
<p>We applied the same analytical pipeline to investigate differences in the weighted phase-lag index (wPLI) between the contralateral regions of the two items and the prefrontal cortex during the retention phase. Specifically, wPLI differences (i.e., the difference between the two conditions) were computed, downsampled to 100 Hz using a 10 ms window for averaging to generate a time series spanning 0-2000 ms, and then subjected to amplitude spectrum analysis (1-50 Hz) using Fourier transformation. Significance was assessed via the identical permutation test procedure described above (randomly shuffling the temporal order of the difference time series).</p>
</sec>
</sec>
</sec>
</body>
<back>
<sec id="s8" sec-type="data-availability">
<title>Data and Code Availability</title>
<p>All analyses were conducted using custom code in MATLAB and the EEGlab toolbox for EEG data analysis. The code and processed data used for the final analyses are available at <ext-link ext-link-type="uri" xlink:href="https://osf.io/34cex/">https://osf.io/34cex/</ext-link>. Raw data for this study can be requested from the Lead Contact, and the authors confirm that all reasonable requests will be fulfilled.</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>We acknowledge the subjects for their contribution to this study. This work was supported by National Natural Science Foundation of China (32271099), Research Center for Brain Cognition and Human Development of Guangdong Province (2024B0303390003), Striving for the First-Class, Improving Weak Links and Highlighting Features (SIH) Key Discipline for Psychology in South China Normal University, and National Outstanding Youth Science Fund Project of National Natural Science Foundation of China (32022032).</p>
</ack>
<sec id="additional-info" sec-type="additional-information">
<title>Additional information</title>
<sec id="s6">
<title>Author contributions</title>
<p>J. L., Conceptualization, Formal analysis, Investigation, Visualization, Methodology, Writing original draft; Y. C., Investigation, Visualization, Methodology, Writing original draft; X. Z., Conceptualization, Resources, Supervision, Funding acquisition, Investigation, Methodology, Writing original draft, Project administration.</p>
</sec>
<sec id="s7" sec-type="ethics-statement">
<title>Ethics</title>
<p>All experiments were carried out in accordance with the Declaration of Helsinki. All participants provided written informed consent prior to the start of the experiment, which was approved by the Research Ethics Committee at South China Normal University (2021-04-01).</p>
</sec>
</sec>
<ref-list>
<title>Reference</title>
<ref id="c1"><label>1</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Frătescu</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Van Moorselaar</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>Mathôt</surname>, <given-names>S</given-names></string-name></person-group>. <article-title>Can you have multiple attentional templates? Large-scale replications of Van Moorselaar, Theeuwes, and Olivers (2014) and Hollingworth and Beck (2016)</article-title>. <source>Attention, Perception, Psychophysics</source> <volume>81</volume>, <fpage>2700</fpage>–<lpage>2709</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c2"><label>2</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Constantinidis</surname>, <given-names>C.</given-names></string-name> &amp; <string-name><surname>Klingberg</surname>, <given-names>T</given-names></string-name></person-group>. <article-title>The neuroscience of working memory capacity and training</article-title>. <source>Nat Rev Neurosci</source> <volume>17</volume>, <fpage>438</fpage>–<lpage>449</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nrn.2016.43</pub-id> (<year>2016</year>).</mixed-citation></ref>
<ref id="c3"><label>3</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cowan</surname>, <given-names>N</given-names></string-name></person-group>. <article-title>The magical number 4 in short-term memory: a reconsideration of mental storage capacity</article-title>. <source>Behav Brain Sci</source> <volume>24</volume>, <fpage>87</fpage>–<lpage>114</lpage>, doi:<pub-id pub-id-type="doi">10.1017/s0140525x01003922</pub-id> (<year>2001</year>).</mixed-citation></ref>
<ref id="c4"><label>4</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Oberauer</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Farrell</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Jarrold</surname>, <given-names>C.</given-names></string-name> &amp; <string-name><surname>Lewandowsky</surname>, <given-names>S</given-names></string-name></person-group>. <article-title>What limits working memory capacity?</article-title> <source>Psychological bulletin</source> <volume>142</volume>, <issue>758</issue> (<year>2016</year>).</mixed-citation></ref>
<ref id="c5"><label>5</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Büsel</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Pomper</surname>, <given-names>U.</given-names></string-name> &amp; <string-name><surname>Ansorge</surname>, <given-names>U</given-names></string-name></person-group>. <article-title>Capture of attention by target-similar cues during dual-color search reflects reactive control among top-down selected attentional control settings</article-title>. <source>Psychonomic Bulletin Review</source> <volume>26</volume>, <fpage>531</fpage>–<lpage>537</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c6"><label>6</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Olivers</surname>, <given-names>C. N.</given-names></string-name>, <string-name><surname>Peters</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Houtkamp</surname>, <given-names>R.</given-names></string-name> &amp; <string-name><surname>Roelfsema</surname>, <given-names>P. R</given-names></string-name></person-group>. <article-title>Different states in visual working memory: When it guides attention and when it does not</article-title>. <source>Trends in cognitive sciences</source> <volume>15</volume>, <fpage>327</fpage>–<lpage>334</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c7"><label>7</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kerzel</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>Witzel</surname>, <given-names>C</given-names></string-name></person-group>. <article-title>The allocation of resources in visual working memory and multiple attentional templates</article-title>. <source>J Exp Psychol Hum Percept Perform</source> <volume>45</volume>, <fpage>645</fpage>–<lpage>658</lpage>, doi:<pub-id pub-id-type="doi">10.1037/xhp0000637</pub-id> (<year>2019</year>).</mixed-citation></ref>
<ref id="c8"><label>8</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kristjánsson</surname>, <given-names>T.</given-names></string-name> &amp; <string-name><surname>Kristjánsson</surname>, <given-names>Á</given-names></string-name></person-group>. <article-title>Foraging through multiple target categories reveals the flexibility of visual working memory</article-title>. <source>Journal of experimental psychology: human perception performance</source> <volume>183</volume>, <fpage>108</fpage>–<lpage>115</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c9"><label>9</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hollingworth</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Beck</surname>, <given-names>V. M</given-names></string-name></person-group>. <article-title>Memory-based attention capture when multiple items are maintained in visual working memory</article-title>. <source>Journal of experimental psychology: human perception performance</source> <volume>42</volume>, <issue>911</issue> (<year>2016</year>).</mixed-citation></ref>
<ref id="c10"><label>10</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fiebelkorn</surname>, <given-names>I. C.</given-names></string-name>, <string-name><surname>Pinsk</surname>, <given-names>M. A.</given-names></string-name> &amp; <string-name><surname>Kastner</surname>, <given-names>S</given-names></string-name></person-group>. <article-title>A dynamic interplay within the frontoparietal network underlies rhythmic spatial attention</article-title>. <source>Neuron</source> <volume>99</volume>, <fpage>842</fpage>–<lpage>853.e848</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c11"><label>11</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>VanRullen</surname>, <given-names>R</given-names></string-name></person-group>. <article-title>How to evaluate phase differences between trial groups in ongoing electrophysiological signals</article-title>. <source>Frontiers in neuroscience</source> <volume>10</volume>, <fpage>426</fpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c12"><label>12</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Landau</surname>, <given-names>A. N.</given-names></string-name> &amp; <string-name><surname>Fries</surname>, <given-names>P</given-names></string-name></person-group>. <article-title>Attention samples stimuli rhythmically</article-title>. <source>Curr Biol</source> <volume>22</volume>, <fpage>1000</fpage>–<lpage>1004</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.cub.2012.03.054</pub-id> (<year>2012</year>).</mixed-citation></ref>
<ref id="c13"><label>13</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jia</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Fang</surname>, <given-names>F.</given-names></string-name> &amp; <string-name><surname>Luo</surname>, <given-names>H</given-names></string-name></person-group>. <article-title>Sequential sampling of visual objects during sustained attention</article-title>. <source>PLoS Biol</source> <volume>15</volume>, <fpage>e2001903</fpage>, doi:<pub-id pub-id-type="doi">10.1371/journal.pbio.2001903</pub-id> (<year>2017</year>).</mixed-citation></ref>
<ref id="c14"><label>14</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chota</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Leto</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>van Zantwijk</surname>, <given-names>L.</given-names></string-name> &amp; <string-name><surname>Van der Stigchel</surname>, <given-names>S</given-names></string-name></person-group>. <article-title>Attention rhythmically samples multi-feature objects in working memory</article-title>. <source>Sci Rep</source> <volume>12</volume>, <fpage>14703</fpage>, doi:<pub-id pub-id-type="doi">10.1038/s41598-022-18819-z</pub-id> (<year>2022</year>).</mixed-citation></ref>
<ref id="c15"><label>15</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Peters</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Kaiser</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Rahm</surname>, <given-names>B.</given-names></string-name> &amp; <string-name><surname>Bledowski</surname>, <given-names>C.</given-names></string-name></person-group> <article-title>Object-based attention prioritizes working memory contents at a theta rhythm</article-title><source>. journal of Experimental Psychology: General</source> <volume>150</volume>, <fpage>1250</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c16"><label>16</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pomper</surname>, <given-names>U.</given-names></string-name> &amp; <string-name><surname>Ansorge</surname>, <given-names>U</given-names></string-name></person-group>. <article-title>Theta-Rhythmic Oscillation of Working Memory Performance</article-title>. <source>Psychol Sci</source> <volume>32</volume>, <fpage>1801</fpage>–<lpage>1810</lpage>, doi:<pub-id pub-id-type="doi">10.1177/09567976211013045</pub-id> (<year>2021</year>).</mixed-citation></ref>
<ref id="c17"><label>17</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Jia</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Han</surname>, <given-names>Q.</given-names></string-name> &amp; <string-name><surname>Luo</surname>, <given-names>H</given-names></string-name></person-group>. <article-title>Fast-backward replay of sequentially memorized items in humans</article-title>. <source>eLife</source> <volume>7</volume>, <elocation-id>e35164</elocation-id>, doi:<pub-id pub-id-type="doi">10.7554/eLife.35164</pub-id> (<year>2018</year>).</mixed-citation></ref>
<ref id="c18"><label>18</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Dolan</surname>, <given-names>R. J.</given-names></string-name>, <string-name><surname>Kurth-Nelson</surname>, <given-names>Z.</given-names></string-name> &amp; <string-name><surname>Behrens</surname>, <given-names>T. E. J</given-names></string-name></person-group>. <article-title>Human Replay Spontaneously Reorganizes Experience</article-title>. <source>Cell</source> <volume>178</volume>, <fpage>640</fpage>–<lpage>652.e614,</lpage> doi:<pub-id pub-id-type="doi">10.1016/j.cell.2019.06.012</pub-id> (<year>2019</year>).</mixed-citation></ref>
<ref id="c19"><label>19</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>De Vries</surname>, <given-names>I. E.</given-names></string-name>, <string-name><surname>Van Driel</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Olivers</surname>, <given-names>C. N</given-names></string-name></person-group>. <article-title>Posterior α EEG dynamics dissociate current from future goals in working memory-guided visual search</article-title>. <source>Journal of Neuroscience</source> <volume>37</volume>, <fpage>1591</fpage>–<lpage>1603</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c20"><label>20</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pavlov</surname>, <given-names>Y. G.</given-names></string-name> &amp; <string-name><surname>Kotchoubey</surname>, <given-names>B</given-names></string-name></person-group>. <article-title>Oscillatory brain activity and maintenance of verbal and visual working memory: A systematic review</article-title>. <source>Psychophysiology</source> <volume>59</volume>, <fpage>e13735</fpage>, doi:<pub-id pub-id-type="doi">10.1111/psyp.13735</pub-id> (<year>2022</year>).</mixed-citation></ref>
<ref id="c21"><label>21</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wolff</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Jochim</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Akyurek</surname>, <given-names>E. G.</given-names></string-name> &amp; <string-name><surname>Stokes</surname>, <given-names>M. G</given-names></string-name></person-group>. <article-title>Dynamic hidden states underlying working-memory-guided behavior</article-title>. <source>Nat Neurosci</source> <volume>20</volume>, <fpage>864</fpage>–<lpage>871</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nn.4546</pub-id> (<year>2017</year>).</mixed-citation></ref>
<ref id="c22"><label>22</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Benedek</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Schickel</surname>, <given-names>R. J.</given-names></string-name>, <string-name><surname>Jauk</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Fink</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Neubauer</surname>, <given-names>A. C</given-names></string-name></person-group>. <article-title>Alpha power increases in right parietal cortex reflects focused internal attention</article-title>. <source>Neuropsychologia</source> <volume>56</volume>, <fpage>393</fpage>–<lpage>400</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2014.02.010</pub-id> (<year>2014</year>).</mixed-citation></ref>
<ref id="c23"><label>23</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Klimesch</surname>, <given-names>W.</given-names></string-name></person-group> <article-title>alpha-band oscillations, attention, and controlled access to stored information</article-title>. <source>Trends Cogn Sci</source> <volume>16</volume>, <fpage>606</fpage>–<lpage>617</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.tics.2012.10.007</pub-id> (<year>2012</year>).</mixed-citation></ref>
<ref id="c24"><label>24</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Peylo</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Hilla</surname>, <given-names>Y.</given-names></string-name> &amp; <string-name><surname>Sauseng</surname>, <given-names>P</given-names></string-name></person-group>. <article-title>Cause or consequence? Alpha oscillations in visuospatial attention</article-title>. <source>Trends Neurosci</source> <volume>44</volume>, <fpage>705</fpage>–<lpage>713</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.tins.2021.05.004</pub-id> (<year>2021</year>).</mixed-citation></ref>
<ref id="c25"><label>25</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Helfrich</surname>, <given-names>R. F.</given-names></string-name>, <string-name><surname>Huang</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>G.</given-names></string-name> &amp; <string-name><surname>Knight</surname>, <given-names>R. T</given-names></string-name></person-group>. <article-title>Prefrontal cortex modulates posterior alpha oscillations during top-down guided visual perception</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>114</volume>, <fpage>9457</fpage>–<lpage>9462</lpage>, doi:<pub-id pub-id-type="doi">10.1073/pnas.1705965114</pub-id> (<year>2017</year>).</mixed-citation></ref>
<ref id="c26"><label>26</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Josselyn</surname>, <given-names>S. A.</given-names></string-name> &amp; <string-name><surname>Tonegawa</surname>, <given-names>S</given-names></string-name></person-group>. <article-title>Memory engrams: Recalling the past and imagining the future</article-title>. <source>Science</source> <volume>367</volume>, <fpage>eaaw4325</fpage>, doi:<pub-id pub-id-type="doi">10.1126/science.aaw4325</pub-id> (<year>2020</year>).</mixed-citation></ref>
<ref id="c27"><label>27</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Berger</surname>, <given-names>B.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Dynamic regulation of interregional cortical communication by slow brain oscillations during working memory</article-title>. <source>Nat Commun</source> <volume>10</volume>, <fpage>4242</fpage>, doi:<pub-id pub-id-type="doi">10.1038/s41467-019-12057-0</pub-id> (<year>2019</year>).</mixed-citation></ref>
<ref id="c28"><label>28</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van Driel</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Gunseli</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Meeter</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Olivers</surname>, <given-names>C. N</given-names></string-name></person-group>. <article-title>Local and interregional alpha EEG dynamics dissociate between memory for search and memory for recognition</article-title>. <source>Neuroimage</source> <volume>149</volume>, <fpage>114</fpage>–<lpage>128</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c29"><label>29</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Audrain</surname>, <given-names>S. P.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Frequency-specific neural synchrony in autism during memory encoding, maintenance and recognition</article-title>. <source>Brain Commun</source> <volume>2</volume>, <fpage>fcaa094</fpage>, doi:<pub-id pub-id-type="doi">10.1093/braincomms/fcaa094</pub-id> (<year>2020</year>).</mixed-citation></ref>
<ref id="c30"><label>30</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>de Vries</surname>, <given-names>I. E. J.</given-names></string-name>, <string-name><surname>Slagter</surname>, <given-names>H. A.</given-names></string-name> &amp; <string-name><surname>Olivers</surname>, <given-names>C. N. L</given-names></string-name></person-group>. <article-title>Oscillatory Control over Representational States in Working Memory</article-title>. <source>Trends Cogn Sci</source> <volume>24</volume>, <fpage>150</fpage>–<lpage>162</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.tics.2019.11.006</pub-id> (<year>2020</year>).</mixed-citation></ref>
<ref id="c31"><label>31</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>de Vries</surname>, <given-names>I. E. J.</given-names></string-name>, <string-name><surname>van Driel</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Karacaoglu</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Olivers</surname>, <given-names>C. N. L</given-names></string-name></person-group>. <article-title>Priority Switches in Visual Working Memory are Supported by Frontal Delta and Posterior Alpha Interactions</article-title>. <source>Cereb Cortex</source> <volume>28</volume>, <fpage>4090</fpage>–<lpage>4104</lpage>, doi:<pub-id pub-id-type="doi">10.1093/cercor/bhy223</pub-id> (<year>2018</year>).</mixed-citation></ref>
<ref id="c32"><label>32</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Soto</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Humphreys</surname>, <given-names>G. W.</given-names></string-name> &amp; <string-name><surname>Rotshtein</surname>, <given-names>P</given-names></string-name></person-group>. <article-title>Dissociating the neural mechanisms of memory-based guidance of visual selection</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>104</volume>, <fpage>17186</fpage>–<lpage>17191</lpage>, doi:<pub-id pub-id-type="doi">10.1073/pnas.0703706104</pub-id> (<year>2007</year>).</mixed-citation></ref>
<ref id="c33"><label>33</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fiebelkorn</surname>, <given-names>I. C.</given-names></string-name>, <string-name><surname>Saalmann</surname>, <given-names>Y. B.</given-names></string-name> &amp; <string-name><surname>Kastner</surname>, <given-names>S</given-names></string-name></person-group>. <article-title>Rhythmic sampling within and between objects despite sustained attention at a cued location</article-title>. <source>Current biology</source> <volume>23</volume>, <fpage>2553</fpage>–<lpage>2558</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c34"><label>34</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>VanRullen</surname>, <given-names>R.</given-names></string-name> &amp; <string-name><surname>Macdonald</surname>, <given-names>J. S</given-names></string-name></person-group>. <article-title>Perceptual echoes at 10 Hz in the human brain</article-title>. <source>Current biology</source> <volume>22</volume>, <fpage>995</fpage>–<lpage>999</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c35"><label>35</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>de Vries</surname>, <given-names>I. E. J.</given-names></string-name>, <string-name><surname>van Driel</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Olivers</surname>, <given-names>C. N. L</given-names></string-name></person-group>. <article-title>Decoding the status of working memory representations in preparation of visual selection</article-title>. <source>Neuroimage</source> <volume>191</volume>, <fpage>549</fpage>–<lpage>559</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.02.069</pub-id> (<year>2019</year>).</mixed-citation></ref>
<ref id="c36"><label>36</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jensen</surname>, <given-names>O.</given-names></string-name> &amp; <string-name><surname>Mazaheri</surname>, <given-names>A</given-names></string-name></person-group>. <article-title>Shaping functional architecture by oscillatory alpha activity: gating by inhibition</article-title>. <source>Front Hum Neurosci</source> <volume>4</volume>, <issue>186</issue>, doi:<pub-id pub-id-type="doi">10.3389/fnhum.2010.00186</pub-id> (<year>2010</year>).</mixed-citation></ref>
<ref id="c37"><label>37</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jiang</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>He</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Zhang</surname>, <given-names>J</given-names></string-name></person-group>. <article-title>The adaptive flexibility of rhythmic attentional sampling in attending to multiple targets</article-title>. <source>J Exp Psychol Gen</source> <volume>153</volume>, <fpage>26</fpage>–<lpage>37</lpage>, doi:<pub-id pub-id-type="doi">10.1037/xge0001468</pub-id> (<year>2024</year>).</mixed-citation></ref>
<ref id="c38"><label>38</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Re</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Inbar</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Richter</surname>, <given-names>C. G.</given-names></string-name> &amp; <string-name><surname>Landau</surname>, <given-names>A. N</given-names></string-name></person-group>. <article-title>Feature-Based Attention Samples Stimuli Rhythmically</article-title>. <source>Curr Biol</source> <volume>29</volume>, <fpage>693</fpage>–<lpage>699.e694,</lpage> doi:<pub-id pub-id-type="doi">10.1016/j.cub.2019.01.010</pub-id> (<year>2019</year>).</mixed-citation></ref>
<ref id="c39"><label>39</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Helfrich</surname>, <given-names>R. F.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Neural Mechanisms of Sustained Attention Are Rhythmic</article-title>. <source>Neuron</source> <volume>99</volume>, <fpage>854</fpage>–<lpage>865.e855,</lpage> doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2018.07.032</pub-id> (<year>2018</year>).</mixed-citation></ref>
<ref id="c40"><label>40</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ho</surname>, <given-names>H. T.</given-names></string-name>, <string-name><surname>Burr</surname>, <given-names>D. C.</given-names></string-name>, <string-name><surname>Alais</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>Morrone</surname>, <given-names>M. C</given-names></string-name></person-group>. <article-title>Auditory perceptual history is propagated through alpha oscillations</article-title>. <source>Current Biology</source> <volume>29</volume>, <fpage>4208</fpage>–<lpage>4217.e4203</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c41"><label>41</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ho</surname>, <given-names>H. T.</given-names></string-name>, <string-name><surname>Leung</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Burr</surname>, <given-names>D. C.</given-names></string-name>, <string-name><surname>Alais</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>Morrone</surname>, <given-names>M. C</given-names></string-name></person-group>. <article-title>Auditory sensitivity and decision criteria oscillate at different frequencies separately for the two ears</article-title>. <source>Current Biology</source> <volume>27</volume>, <fpage>3643</fpage>–<lpage>3649.e3643</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c42"><label>42</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Han</surname>, <given-names>B.</given-names></string-name> &amp; <string-name><surname>VanRullen</surname>, <given-names>R</given-names></string-name></person-group>. <article-title>The rhythms of predictive coding? Pre-stimulus phase modulates the influence of shape perception on luminance judgments</article-title>. <source>Sci Rep</source> <volume>7</volume>, <fpage>43573</fpage>, doi:<pub-id pub-id-type="doi">10.1038/srep43573</pub-id> (<year>2017</year>).</mixed-citation></ref>
<ref id="c43"><label>43</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nakayama</surname>, <given-names>R.</given-names></string-name> &amp; <string-name><surname>Motoyoshi</surname>, <given-names>I</given-names></string-name></person-group>. <article-title>Attention Periodically Binds Visual Features As Single Events Depending on Neural Oscillations Phase-Locked to Action</article-title>. <source>J Neurosci</source> <volume>39</volume>, <fpage>4153</fpage>–<lpage>4161</lpage>, doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2494-18.2019</pub-id> (<year>2019</year>).</mixed-citation></ref>
<ref id="c44"><label>44</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van Moorselaar</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Theeuwes</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Olivers</surname>, <given-names>C. N</given-names></string-name></person-group>. <article-title>In competition for the attentional template: Can multiple items within visual working memory guide attention?</article-title> <source>Journal of Experimental Psychology: Human Perception Performance</source> <volume>40</volume>, <fpage>1450</fpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c45"><label>45</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname>, <given-names>X.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Alpha oscillatory activity is causally linked to working memory retention</article-title>. <source>PLoS Biology</source> <volume>21</volume>, <fpage>e3001999</fpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c46"><label>46</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gazzaley</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Nobre</surname>, <given-names>A. C</given-names></string-name></person-group>. <article-title>Top-down modulation: bridging selective attention and working memory</article-title>. <source>Trends Cogn Sci</source> <volume>16</volume>, <fpage>129</fpage>–<lpage>135</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.tics.2011.11.014</pub-id> (<year>2012</year>).</mixed-citation></ref>
<ref id="c47"><label>47</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gresch</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Behnke</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>van Ede</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Nobre</surname>, <given-names>A. C.</given-names></string-name> &amp; <string-name><surname>Boettcher</surname>, <given-names>S. E. P</given-names></string-name></person-group>. <article-title>Neural dynamics of reselecting visual and motor contents in working memory after external interference</article-title>. <source>J Neurosci</source> <volume>45</volume>, doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2347-24.2025</pub-id> (<year>2025</year>).</mixed-citation></ref>
<ref id="c48"><label>48</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Van Diepen</surname>, <given-names>R. M.</given-names></string-name>, <string-name><surname>Foxe</surname>, <given-names>J. J.</given-names></string-name> &amp; <string-name><surname>Mazaheri</surname>, <given-names>A</given-names></string-name></person-group>. <article-title>The functional role of alpha-band activity in attentional processing: the current zeitgeist and future outlook</article-title>. <source>Curr Opin Psychol</source> <volume>29</volume>, <fpage>229</fpage>–<lpage>238</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.copsyc.2019.03.015</pub-id> (<year>2019</year>).</mixed-citation></ref>
<ref id="c49"><label>49</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Foster</surname>, <given-names>J. J.</given-names></string-name>, <string-name><surname>Bsales</surname>, <given-names>E. M.</given-names></string-name>, <string-name><surname>Jaffe</surname>, <given-names>R. J.</given-names></string-name> &amp; <string-name><surname>Awh</surname>, <given-names>E</given-names></string-name></person-group>. <article-title>Alpha-Band Activity Reveals Spontaneous Representations of Spatial Position in Visual Working Memory</article-title>. <source>Curr Biol</source> <volume>27</volume>, <fpage>3216</fpage>–<lpage>3223.e3216,</lpage> doi:<pub-id pub-id-type="doi">10.1016/j.cub.2017.09.031</pub-id> (<year>2017</year>).</mixed-citation></ref>
<ref id="c50"><label>50</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gresch</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Boettcher</surname>, <given-names>S. E.</given-names></string-name>, <string-name><surname>Gohil</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>van Ede</surname>, <given-names>F.</given-names></string-name> &amp; <string-name><surname>Nobre</surname>, <given-names>A. C</given-names></string-name></person-group>. <article-title>Neural dynamics of shifting attention between perception and working-memory contents</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>121</volume>, <fpage>e2406061121</fpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c51"><label>51</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Quentin</surname>, <given-names>R.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Differential Brain Mechanisms of Selection and Maintenance of Information during Working Memory</article-title>. <source>J Neurosci</source> <volume>39</volume>, <fpage>3728</fpage>–<lpage>3740</lpage>, doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2764-18.2019</pub-id> (<year>2019</year>).</mixed-citation></ref>
<ref id="c52"><label>52</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wallis</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Stokes</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Cousijn</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Woolrich</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Nobre</surname>, <given-names>A. C</given-names></string-name></person-group>. <article-title>Frontoparietal and Cingulo-opercular Networks Play Dissociable Roles in Control of Working Memory</article-title>. <source>J Cogn Neurosci</source> <volume>27</volume>, <fpage>2019</fpage>–<lpage>2034</lpage>, doi:<pub-id pub-id-type="doi">10.1162/jocn_a_00838</pub-id> (<year>2015</year>).</mixed-citation></ref>
<ref id="c53"><label>53</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Miller</surname>, <given-names>E. K.</given-names></string-name> &amp; <string-name><surname>Cohen</surname>, <given-names>J. D</given-names></string-name></person-group>. <article-title>An integrative theory of prefrontal cortex function</article-title>. <source>Annu Rev Neurosci</source> <volume>24</volume>, <fpage>167</fpage>–<lpage>202</lpage>, doi:<pub-id pub-id-type="doi">10.1146/annurev.neuro.24.1.167</pub-id> (<year>2001</year>).</mixed-citation></ref>
<ref id="c54"><label>54</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mansouri</surname>, <given-names>F. A.</given-names></string-name>, <string-name><surname>Koechlin</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Rosa</surname>, <given-names>M. G.</given-names></string-name> &amp; <string-name><surname>Buckley</surname>, <given-names>M</given-names></string-name></person-group>. <article-title>Managing competing goals—a key role for the frontopolar cortex</article-title>. <source>Nature Reviews Neuroscience</source> <volume>18</volume>, <fpage>645</fpage>–<lpage>657</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c55"><label>55</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Monsell</surname>, <given-names>S.</given-names></string-name></person-group> <article-title>Task switching</article-title>. <source>Trends Cogn Sci</source> <volume>7</volume>, <fpage>134</fpage>–<lpage>140</lpage>, doi:<pub-id pub-id-type="doi">10.1016/s1364-6613(03)00028-7</pub-id> (<year>2003</year>).</mixed-citation></ref>
<ref id="c56"><label>56</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fusi</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>E. K.</given-names></string-name> &amp; <string-name><surname>Rigotti</surname>, <given-names>M</given-names></string-name></person-group>. <article-title>Why neurons mix: high dimensionality for higher cognition</article-title>. <source>Curr Opin Neurobiol</source> <volume>37</volume>, <fpage>66</fpage>–<lpage>74</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.conb.2016.01.010</pub-id> (<year>2016</year>).</mixed-citation></ref>
<ref id="c57"><label>57</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Christophel</surname>, <given-names>T. B.</given-names></string-name>, <string-name><surname>Klink</surname>, <given-names>P. C.</given-names></string-name>, <string-name><surname>Spitzer</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Roelfsema</surname>, <given-names>P. R.</given-names></string-name> &amp; <string-name><surname>Haynes</surname>, <given-names>J. D</given-names></string-name></person-group>. <article-title>The Distributed Nature of Working Memory</article-title>. <source>Trends Cogn Sci</source> <volume>21</volume>, <fpage>111</fpage>–<lpage>124</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.tics.2016.12.007</pub-id> (<year>2017</year>).</mixed-citation></ref>
<ref id="c58"><label>58</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sreenivasan</surname>, <given-names>K. K.</given-names></string-name>, <string-name><surname>Curtis</surname>, <given-names>C. E.</given-names></string-name> &amp; <string-name><surname>D’Esposito</surname>, <given-names>M</given-names></string-name></person-group>. <article-title>Revisiting the role of persistent neural activity during working memory</article-title>. <source>Trends Cogn Sci</source> <volume>18</volume>, <fpage>82</fpage>–<lpage>89</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.tics.2013.12.001</pub-id> (<year>2014</year>).</mixed-citation></ref>
<ref id="c59"><label>59</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nelissen</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Stokes</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Nobre</surname>, <given-names>A. C.</given-names></string-name> &amp; <string-name><surname>Rushworth</surname>, <given-names>M. F</given-names></string-name></person-group>. <article-title>Frontal and parietal cortical interactions with distributed visual representations during selective attention and action selection</article-title>. <source>J Neurosci</source> <volume>33</volume>, <fpage>16443</fpage>–<lpage>16458</lpage>, doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2625-13.2013</pub-id> (<year>2013</year>).</mixed-citation></ref>
<ref id="c60"><label>60</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Van Ede</surname>, <given-names>F.</given-names></string-name> &amp; <string-name><surname>Nobre</surname>, <given-names>A. C</given-names></string-name></person-group>. <article-title>Turning attention inside out: How working memory serves behavior</article-title>. <source>Annual review of psychology</source> <volume>74</volume>, <fpage>137</fpage>–<lpage>165</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c61"><label>61</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kuo</surname>, <given-names>B. C.</given-names></string-name>, <string-name><surname>Yeh</surname>, <given-names>Y. Y.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>A. J.</given-names></string-name> &amp; <string-name><surname>D’Esposito</surname>, <given-names>M</given-names></string-name></person-group>. <article-title>Functional connectivity during top-down modulation of visual short-term memory representations</article-title>. <source>Neuropsychologia</source> <volume>49</volume>, <fpage>1589</fpage>–<lpage>1596</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2010.12.043</pub-id> (<year>2011</year>).</mixed-citation></ref>
<ref id="c62"><label>62</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van den Broek</surname>, <given-names>S. P.</given-names></string-name>, <string-name><surname>Reinders</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Donderwinkel</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Peters</surname>, <given-names>M. J.</given-names></string-name></person-group> <article-title>Volume conduction effects in EEG and MEG</article-title>. <source>Electroencephalogr Clin Neurophysiol</source> <volume>106</volume>, <fpage>522</fpage>–<lpage>534</lpage>, doi:<pub-id pub-id-type="doi">10.1016/s0013-4694(97)00147-8</pub-id> (<year>1998</year>).</mixed-citation></ref>
<ref id="c63"><label>63</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Button</surname>, <given-names>K. S.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Power failure: why small sample size undermines the reliability of neuroscience</article-title>. <source>Nat Rev Neurosci</source> <volume>14</volume>, <fpage>365</fpage>–<lpage>376</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nrn3475</pub-id> (<year>2013</year>).</mixed-citation></ref>
<ref id="c64"><label>64</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Delgado-Sallent</surname>, <given-names>C.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Atypical, but not typical, antipsychotic drugs reduce hypersynchronized prefrontal-hippocampal circuits during psychosis-like states in mice: Contribution of 5-HT2A and 5-HT1A receptors</article-title>. <source>Cerebral Cortex</source> <volume>32</volume>, <fpage>3472</fpage>–<lpage>3487</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c65"><label>65</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Siebenhühner</surname>, <given-names>F.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Genuine cross-frequency coupling networks in human resting-state electrophysiological recordings</article-title>. <source>PLoS Biology</source> <volume>18</volume>, <fpage>e3000685</fpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c66"><label>66</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname>, <given-names>F.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Cross-Species Investigation on Resting State Electroencephalogram</article-title>. <source>Brain Topogr</source> <volume>32</volume>, <fpage>808</fpage>–<lpage>824</lpage>, doi:<pub-id pub-id-type="doi">10.1007/s10548-019-00723-x</pub-id> (<year>2019</year>).</mixed-citation></ref>
<ref id="c67"><label>67</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lachaux</surname>, <given-names>J. P.</given-names></string-name>, <string-name><surname>Rodriguez</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Martinerie</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Varela</surname>, <given-names>F. J</given-names></string-name></person-group>. <article-title>Measuring phase synchrony in brain signals</article-title>. <source>Hum Brain Mapp</source> <volume>8</volume>, <fpage>194</fpage>–<lpage>208</lpage> (<year>1999</year>).</mixed-citation></ref>
<ref id="c68"><label>68</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Benjamini</surname>, <given-names>Y.</given-names></string-name> &amp; <string-name><surname>Hochberg</surname>, <given-names>Y</given-names></string-name></person-group>. <article-title>Controlling the false discovery rate: a practical and powerful approach to multiple testing</article-title>. <source>Journal of the Royal statistical society: series B</source> <volume>57</volume>, <fpage>289</fpage>–<lpage>300</lpage> (<year>1995</year>).</mixed-citation></ref>
<ref id="c69"><label>69</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Cohen</surname>, <given-names>M. X</given-names></string-name></person-group>. <source>Analyzing neural time series data: theory and practice</source>. (<publisher-name>MIT press</publisher-name>, <year>2014</year>).</mixed-citation></ref>
<ref id="c70"><label>70</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stam</surname>, <given-names>C. J.</given-names></string-name>, <string-name><surname>Nolte</surname>, <given-names>G.</given-names></string-name> &amp; <string-name><surname>Daffertshofer</surname>, <given-names>A</given-names></string-name></person-group>. <article-title>Phase lag index: assessment of functional connectivity from multi channel EEG and MEG with diminished bias from common sources</article-title>. <source>Hum Brain Mapp</source> <volume>28</volume>, <fpage>1178</fpage>–<lpage>1193</lpage>, doi:<pub-id pub-id-type="doi">10.1002/hbm.20346</pub-id> (<year>2007</year>).</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108017.2.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Wang</surname>
<given-names>Shuo</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Washington University in St. Louis</institution>
</institution-wrap>
<city>St. Louis</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>valuable</bold> study reports evidence that items maintained in working memory can bias attention in an oscillatory manner, with the attentional capture effect fluctuating at theta frequency. The study provides <bold>incomplete</bold> evidence that this dynamic attentional bias is associated with oscillatory neural mechanisms, particularly in the alpha and theta bands, as measured by EEG. The study will be relevant for researchers studying attention, working memory, and neural oscillations, particularly those interested in how memory and perception interact over time.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108017.2.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary</p>
<p>In the presented paper, Lu and colleagues focus on how items held in working memory bias someone's attention. In a series of three experiments, they utilized a similar paradigm in which subjects were asked to maintain two colored squares in memory for a short and variable time. After this delay, they either tested one of the memory items or asked subjects to perform a search task.</p>
<p>In the search task, items could share colors with the memory items, and the authors were interested in how these would capture attention, using reaction time as a proxy. The behavioral data suggest that attention oscillates between the two items. At different maintenance intervals, the authors observed that items in memory captured different amounts of attention (attentional capture effect).</p>
<p>This attentional bias fluctuates over time at approximately the theta frequency range of the EEG spectrum. This part of the study is a replication of Peters and colleagues (2020).</p>
<p>Next, the authors used EEG recordings to better understand the neural mechanisms underlying this process. They present results suggesting that this attentional capture effect is positively correlated with the mean amplitude of alpha power. Furthermore, they show that the weighted phase lag index (wPLI) between the alpha and theta bands across different electrodes also fluctuates at the theta frequency.</p>
<p>Strengths</p>
<p>The authors focus on an interesting and timely topic: how items in working memory can bias our attention. This line of research could improve our understanding of the neural mechanisms underlying working memory, specifically how we maintain multiple items and how these interact with attentional processes. This approach is intriguing because it can shed light on neuronal mechanisms not only through behavioral measures but also by incorporating brain recordings, which is definitely a strength.</p>
<p>
Subjects performed several blocks of experiments, ranging from 4 to 30, over a few days depending on the experiment. This makes the results - especially those from behavioral experiments 2 and 3, which included the most repetitions - particularly robust.</p>
<p>Weaknesses</p>
<p>One of the main EEG results is based on the weighted phase lag index (wPLI) between oscillations in the alpha and theta bands. In my opinion, this is problematic, as wPLI measures the locking of oscillations at the same frequency. It quantifies how reliably the phase difference stays the same over time. If these oscillations have different frequencies, the phase difference cannot remain consistent. Even worse, modeling data show that even very small fluctuations in frequency between signals make wPLI artificially small (Cohen, 2015).</p>
<p>In response authors stated : &quot;Additionally, the present study referenced previous research by using the wPLI index as a measure of cross-frequency coupling strength31,64-66&quot;</p>
<p>
Unfortunately, after checking those publications, we can see that in paper 31 there is no mention of &quot;wPLI&quot; or &quot;PLV.&quot; In 64 and 65, the authors use wPLI, but only to measure same-frequency coherence, whereas cross-frequency coupling is computed by phase-amplitude coupling or cross-frequency coupling also known as n:m-PS. In 66, I cannot find any cross-frequency results, only cross-species analysis. This is very problematic, as it indicates that the authors included references in their rebuttal without verifying their relevance.</p>
<p>
31 de Vries, I. E. J., van Driel, J., Karacaoglu, M. &amp; Olivers, C. N. L. Priority Switches in Visual Working Memory are Supported by Frontal Delta and Posterior Alpha Interactions. Cereb Cortex 28, 4090-4104, doi:10.1093/cercor/bhy223 (2018).64 Delgado-Sallent, C. et al. Atypical, but not typical, antipsychotic drugs reduce hypersynchronized prefrontal-hippocampal circuits during psychosis-like states in mice: Contribution of 5-HT2A and 5-HT1A receptors. Cerebral Cortex 32, 870 3472-3487 (2022). 65 Siebenhühner, F. et al. Genuine cross-frequency coupling networks in human resting-state electrophysiological recordings. PLoS Biology 18, e3000685 (2020). 66 Zhang, F. et al. Cross-Species Investigation on Resting State Electroencephalogram. Brain Topogr 32, 808-824, doi:10.1007/s10548-019-00723-x (2019).</p>
<p>Another result from the electrophysiology data shows that the attentional capture effect is positively correlated with the mean amplitude of alpha power. In the presented scatter plot, it seems that this result is driven by one outlier. Unfortunately, Pearson correlation is very sensitive to outliers, and the entire analysis can be driven by an extreme case. I extracted data from the plot and obtained a Pearson correlation of 0.4, similar to what the authors report. However, the Spearman correlation, which is robust against outliers, was only 0.13 (p = 0.57) indicating a non-significant relationship.</p>
<p>Cohen, M. X. (2015). Effects of time lag and frequency matching on phase based connectivity. Journal of Neuroscience Methods, 250, 137-146</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108017.2.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Lu</surname>
<given-names>Jiachen</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0166-5349</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Cai</surname>
<given-names>Yaochun</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Zhang</surname>
<given-names>Xilin</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0449-934X</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>The following is the authors’ response to the original reviews.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Public review):</bold></p>
</disp-quote>
<p>Thank you very much for your recognition of our work and for pointing out the shortcomings. We have made revisions one by one and provided corresponding explanations regarding the issues you raised.</p>
<disp-quote content-type="editor-comment">
<p>Weaknesses:</p>
<p>One of the main EEG results is based on the weighted phase lag index (wPLI) between oscillations in the alpha and theta bands. In my opinion, this is problematic, as wPLI measures the locking of oscillations at the same frequency. It quantifies how reliably the phase difference stays the same over time. If these oscillations have different frequencies, the phase difference cannot remain consistent. Even worse, modeling data show that even very small fluctuations in frequency between signals make wPLI artificially small (Cohen, 2015).</p>
</disp-quote>
<p>thank you for raising the question regarding the application of wPLI between the alpha and theta bands, which indeed deserves further explanation. In our study, we referred to some relevant previous literatures and adopted their approach of using wPLI to measure cross-frequency coupling strength, as this index itself can reflect the stability of phase differences. We have also considered the point you mentioned that the phase differences of oscillations with different frequencies are difficult to remain consistent. However, in this study, the presentation times of the two memory items are the same, which is fair to both from this perspective. Moreover, the study observed that the wPLI values of these two items alternately dominate over time, and this changing pattern is consistent with the regularity of behavioral data. It seems hard to explain this as a mere coincidence.</p>
<p>The corresponding discussion has been added to the revised part of the paper：“the present study referenced previous research by using the wPLI index as a measure of cross-frequency coupling strength31,64-66 (this index quantifies the stability of phase differences), yet the phases of different oscillations inherently change over time. However, this is fair to the two memory items in the present study, as their presentation times were balanced. The study found that the wPLI values of the two items alternately dominated over time, consistent with the pattern of behavioral data, which is hardly explicable by coincidence”</p>
<disp-quote content-type="editor-comment">
<p>Another result from the electrophysiology data shows that the attentional capture effect is positively correlated with the mean amplitude of alpha power. In the presented scatter plot, it seems that this result is driven by one outlier. Unfortunately, Pearson correlation is very sensitive to outliers, and the entire analysis can be driven by an extreme case. I extracted data from the plot and obtained a Pearson correlation of 0.4, similar to what the authors report. However, the Spearman correlation, which is robust against outliers, was only 0.13 (p = 0.57), indicating a non-significant relationship.</p>
</disp-quote>
<p>you mentioned that the correlation between the attentional capture effect and the mean amplitude of alpha power in the electrophysiological data might be influenced by an outlier, and you also compared the results of Pearson and Spearman correlation coefficients, which we fully agree with.</p>
<p>It is true that the small sample size of the current study makes the results vulnerable to interference from extreme data. Regarding this point, I have already explained it in the limitations section of the discussion in the revised manuscript:“the sample size of the current study is small, which may render the results vulnerable to interference from extreme cases”</p>
<disp-quote content-type="editor-comment">
<p>The behavioral data are interesting, but in my opinion, they closely replicate Peters and colleagues (2020) using a different paradigm. In that study, participants memorized four spatial positions that formed the endpoints of two objects, and one object was cued. Similarly, reaction times fluctuated at theta frequency, and there was an anti-phase relationship between the two objects. The main novelty of the present study is that this bias can be transferred to an unrelated task. While the current study extends Peters and colleagues' findings to a different task context, the lack of a thorough, direct comparison with Peters et al. limits the clarity of the novel insights provided.</p>
</disp-quote>
<p>thank you very much for your attention to the behavioral data and its relevance to the study by Peters et al. (2020). We have noticed that there are similarities in some results between the two studies, which also indicates the stability of the relevant phenomena from one aspect.</p>
<p>However, we would also like to further explain the differences between this study and the study by Peters et al. In the study by Peters et al., participants memorized four spatial positions that formed the endpoints of two objects (one of which was cued), and their results showed that after the two objects disappeared, attention fluctuated at the theta rhythm between their original positions with an inverse correlation. In contrast, the present study explores the manner of memory maintenance indirectly by leveraging the guiding effect of working memory on attention, effectively avoiding the influence of spatial positions.</p>
<p>The study by Peters et al. directly examined differences in probe positions, clearly demonstrating that attention undergoes rhythmic changes at the two spatial locations and persists after the objects vanish, but it hardly clarifies the rhythmicity of working memory performance. Whereas the present study directly investigates such performance using the attention-capture effect of working memory, revealing that when maintaining multiple memory items, their attention-capturing capabilities alternate in dominance, i.e., multiple working memory items alternately become priority templates in a rhythmic manner. This is also some new attempts in the research perspective and method of this study.</p>
<p>The corresponding discussion has been added to the revised part of the paper</p>
<p>“Similar to the present study, Peters et al. had participants memorize four spatial positions forming the endpoints of two objects (one cued), and their results showed that after the two objects disappeared, attention fluctuated at the theta rhythm between their original positions with an inverse correlation; in contrast, the present study explores the manner of memory maintenance indirectly by leveraging the guiding effect of working memory on attention, effectively avoiding the influence of spatial positions—while Peters et al.’s study, which directly examined differences in probe positions, clearly demonstrates that attention undergoes rhythmic changes at the two spatial locations and persists after the objects vanish, it hardly clarifies the rhythmicity of working memory performance, whereas the present study directly investigates such performance using the attention-capture effect of working memory, revealing that when maintaining multiple memory items, their attention-capturing capabilities alternate in dominance, i.e., multiple working memory items alternately become priority templates in a rhythmic manner.”</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public review):</bold></p>
<p>The information provided in the current version of the manuscript is not sufficient to assess the scientific significance of the study.</p>
</disp-quote>
<p>thank you very much for pointing out the multiple issues in our manuscript. Due to several revisions of this work, including experimental adjustments, there have been some inconsistencies in details. We appreciate you identifying them one by one.  We have made corresponding revisions based on your comments:</p>
<disp-quote content-type="editor-comment">
<p>(1) In many cases, the details of the experiments or behavioral tasks described in the main text are not consistent with those provided in the Materials and Methods section. Below, I list only a few of these discrepancies as examples:</p>
<p>a) For Experiment 1, the Methods section states that the detection stimulus was presented for 2000 ms (lines 494 and 498), but Figure 1 in the main text indicates a duration of 1500 ms.</p>
</disp-quote>
<p>we greatly appreciate you catching this inconsistency. We have made unified revisions by referring to the final implemented experimental procedures.  Corresponding revisions have been made in the paper：</p>
<disp-quote content-type="editor-comment">
<p>b) For Experiment 2, not only is the range of SOAs mentioned in the Methods section inconsistent with that shown in the main text and the corresponding figure, but the task design also differs between sections.</p>
</disp-quote>
<p>Thank you for bringing this discrepancy to our attention. We have made unified revisions by referring to the final implemented experimental procedures. The correct SOAs are 233：33：867 ms.</p>
<p>Corresponding revisions have been made in the paper：</p>
<disp-quote content-type="editor-comment">
<p>c) For Experiment 3, the main text indicates that EEG recordings were conducted, but in the Methods section, the EEG recording appears to have been part of Experiment 2 (lines 538-540).</p>
</disp-quote>
<p>we’re grateful for you noticing this mix-up. In fact, only Experiment 3 is an EEG experiment, and we have made corresponding corrections in the &quot;Methods&quot; section. Corresponding revisions have been made in the paper: “The remaining components after this process were then projected back into the channel space. We extracted data from -500 ms to 2000 ms relative to cue stimulus presentation in Experiment 3.”</p>
<disp-quote content-type="editor-comment">
<p>(2) The results described in the text often do not match what is shown in the corresponding figure. For example:</p>
<p>a) In lines 171-178, the SOAs at which a significant difference was found between the two conditions do not appear to match those shown in Figure 2A.</p>
</disp-quote>
<p>Many thanks for spotting this error. The previous results missed one SOA time, namely 33 ms, leading to a 33 ms difference in time. We have corrected it in the revised manuscript.</p>
<p>Corresponding revisions have been made in the paper：“Specifically, the capture effect of cued items was significantly greater than that of uncued items at SOAs of 267ms (t(24) = 2.72, p = 0.03, Cohen's d = 1.11), 667ms (t(24) = 2.37, p = 0.03, Cohen's d= 0.97) and 833ms (t(24) = 3.53, p = 0.002, Cohen's d = 1.44), while the capture effect of uncued items was significantly greater than that of cued items at SOAs of 333ms (t(24) = 2.97, p = 0.007, Cohen's d = 1.21), 367ms (t(24) = 2.14, p = 0.04, Cohen's d = 0.87), 433ms (t(24 )= 2.49, p = 0.02, Cohen's d = 1.02), 467ms (t(24)=2.37, p = 0.03, Cohen's d = 0.97) and 567ms (t(24)=2.72, p = 0.02, Cohen's d = 1.11). ”</p>
<disp-quote content-type="editor-comment">
<p>(b) In Figure 4, the figure legend (lines 225-228) does not correspond to the content shown in the figure.</p>
</disp-quote>
<p>we appreciate you pointing out this oversight. When adjusting the color scheme during the revision of the manuscript, we neglected to revise the legend, which has now been corrected in the revised manuscript.</p>
<p>Corresponding revisions have been made in the paper：“Figure 4. The red line represents the average across all participants of the Fourier transforms of the differences in capture effects between left and right memory items at the individual level. The gray area represents values below the group average of medians derived from 1000 permutations, with each permutation involving Fourier transforms for each participant. *: p &lt; 0.05.”</p>
<disp-quote content-type="editor-comment">
<p>(c) In Figure 9, not sufficient information is provided within the figure or in the text, making it difficult to understand. Consequently, the results described in the text cannot be clearly linked to the figure.</p>
</disp-quote>
<p>Thank you for drawing our attention to this issue. We have revised Figure 9 and its legend in the revised manuscript to make them clearer and easier to understand.</p>
<p>Corresponding revisions have been made in the paper</p>
<disp-quote content-type="editor-comment">
<p>(3) Insufficient information is provided regarding the data analysis procedures, particularly the permutation tests used for the data presented in Figures 2B, 4, and 10. The results shown in these figures are critical for the main conclusions drawn in the manuscript.</p>
</disp-quote>
<p>we’re thankful for you highlighting this gap. In the revised manuscript, we have provided a more detailed explanation in the &quot;Methods&quot; section, especially regarding the content related to frequency analysis, to make the expression clearer.</p>
<p>Corresponding revisions have been made in the paper：“As shown in Figure 8, the alpha power (8-14 Hz) induced by cued and uncued items alternated in dominance during the memory retention phase. To quantify this rhythmic alternation, we conducted a spectral analysis following these steps: First, we computed the power difference between cued and uncued items within the 8-14 Hz range during the retention phase. These differences were then downsampled to 100 Hz using a 10 ms window for averaging, generating a one-dimensional time series spanning the 0-2000 ms retention period. This time series was subsequently subjected to amplitude spectrum analysis across frequencies from 1 Hz to 50 Hz using Fourier transformation.</p>
<p>To assess the statistical significance of the observed spectral features, we employed a permutation test. Specifically, we randomly shuffled the temporal order of the time series of power differences between cued and uncued items—thereby preserving the amplitude distribution of the data while eliminating temporal correlations in the original sequence—and repeated the Fourier transform and spectral analysis for each shuffled time series. This permutation process was replicated 1000 times to generate a null distribution of spectral power values. A frequency component in the original data was considered statistically significant if its power ranked within the top 5% of the corresponding null distribution (p &lt; 0.05).</p>
<p>We applied the same analytical pipeline to investigate differences in the weighted phase-lag index (wPLI) between the contralateral regions of the two items and the prefrontal cortex during the retention phase. Specifically, wPLI differences (i.e., the difference between the two conditions) were computed, downsampled to 100 Hz using a 10 ms window for averaging to generate a time series spanning 0-2000 ms, and then subjected to amplitude spectrum analysis (1-50 Hz) using Fourier transformation. Significance was assessed via the identical permutation test procedure described above (randomly shuffling the temporal order of the difference time series).”</p>
</body>
</sub-article>
</article>