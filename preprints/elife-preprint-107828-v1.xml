<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">107828</article-id>
<article-id pub-id-type="doi">10.7554/eLife.107828</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.107828.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories><title-group>
<article-title>A Python Toolbox for Representational Similarity Analysis</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9326-2090</contrib-id>
<name>
<surname>van den Bosch</surname>
<given-names>Jasper JF</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>jasper.j.f.vandenbosch@gmail.com</email>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7940-7473</contrib-id>
<name>
<surname>Golan</surname>
<given-names>Tal</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0948-8976</contrib-id>
<name>
<surname>Peters</surname>
<given-names>Benjamin</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1034-6860</contrib-id>
<name>
<surname>Taylor</surname>
<given-names>JohnMark</given-names>
</name>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4883-4376</contrib-id>
<name>
<surname>Shahbazi</surname>
<given-names>Mahdiyar</given-names>
</name>
<xref ref-type="aff" rid="a5">5</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7979-5509</contrib-id>
<name>
<surname>Lin</surname>
<given-names>Baihan</given-names>
</name>
<xref ref-type="aff" rid="a6">6</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3939-3003</contrib-id>
<name>
<surname>Charest</surname>
<given-names>Ian</given-names>
</name>
<xref ref-type="aff" rid="a7">7</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0264-8532</contrib-id>
<name>
<surname>Diedrichsen</surname>
<given-names>Jörn</given-names>
</name>
<xref ref-type="aff" rid="a8">8</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7433-9005</contrib-id>
<name>
<surname>Kriegeskorte</surname>
<given-names>Nikolaus</given-names>
</name>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1749-9058</contrib-id>
<name>
<surname>Mur</surname>
<given-names>Marieke</given-names>
</name>
<xref ref-type="aff" rid="a8">8</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2491-5710</contrib-id>
<name>
<surname>Schütt</surname>
<given-names>Heiko H</given-names>
</name>
<xref ref-type="aff" rid="a9">9</xref>
<email>heiko.schutt@uni.lu</email>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/024mrxd33</institution-id><institution>School of Psychology, University of Leeds</institution></institution-wrap>, <city>Leeds</city>, <country country="GB">United Kingdom</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05tkyf982</institution-id><institution>Department of Cognitive and Brain Sciences, Ben-Gurion University of the Negev</institution></institution-wrap>, <city>Beersheba</city>, <country country="IL">Israel</country>.</aff>
<aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01nrxwf90</institution-id><institution>School of Informatics, University of Edinburgh</institution></institution-wrap>, <city>Edinburgh</city>, <country country="GB">United Kingdom</country> .</aff>
<aff id="a4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hj8s172</institution-id><institution>Zuckerman Mind Brain Behavior Institute, Columbia University</institution></institution-wrap>, <city>New York</city>, <country country="US">United States</country>.</aff>
<aff id="a5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03vek6s52</institution-id><institution>Department of Organismic and Evolutionary Biology, Harvard University</institution></institution-wrap>, <city>Cambridge</city>, <country country="US">United States</country>.</aff>
<aff id="a6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04a9tmd77</institution-id><institution>Hasso Plattner Institute for Digital Health, Icahn School of Medicine at Mount Sinai</institution></institution-wrap>, <city>New York</city>, <country country="US">United States</country>.</aff>
<aff id="a7"><label>7</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0161xgx34</institution-id><institution>Département de Psychologie, Université de Montréal</institution></institution-wrap>, <city>Montreal</city>, <country country="CA">Canada</country>.</aff>
<aff id="a8"><label>8</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02grkyz14</institution-id><institution>Centre for Brain and Mind, Western University</institution></institution-wrap>, <city>London</city>, <country country="CA">Canada</country>.</aff>
<aff id="a9"><label>9</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/036x5ad56</institution-id><institution>Department of Behavioural and Cognitive Sciences, Université du Luxembourg</institution></institution-wrap>, <city>Luxembourg</city>, <country country="LU">Luxembourg</country>.</aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Bottini</surname>
<given-names>Roberto</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Trento</institution>
</institution-wrap>
<city>Trento</city>
<country country="IT">Italy</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country country="US">United States</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-09-23">
<day>23</day>
<month>09</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP107828</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-07-12">
<day>12</day>
<month>07</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-05-27">
<day>27</day>
<month>05</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.05.22.655542"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, van den Bosch et al</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>van den Bosch et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-107828-v1.pdf"/>
<abstract>
<p>Representational similarity analysis (RSA) is a method to characterize neural representations and evaluate computational models based on neural representational geometries. Here we present a wave of recent methodological advances, including improved measures of representational distances, evaluators for representational models, and statistical inference methods, which are available to the community in a new open-source toolbox in Python. The rsatoolbox enables neuroscientists to explore neural representational geometries and to evaluate neural network models, connecting theory to experiment in the new era of big models and big data.</p>
</abstract>
<funding-group>
<award-group id="funding-1">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/00cwqg982</institution-id>
<institution>Biotechnology and Biological Sciences Research Council</institution>
</institution-wrap>
</funding-source>
<award-id>BB/X008428/1</award-id>
</award-group>
</funding-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="s1">
<label>1</label><title>Introduction</title>
<p>Neuroscience now has many methods to measure brain activity with ever increasing precision and coverage. Recently, these improved methods have begun to be used to collect large datasets of brain responses to natural stimuli [e.g. <xref ref-type="bibr" rid="c1">1</xref>–<xref ref-type="bibr" rid="c6">6</xref>]. These large datasets aim to constrain the complex computational models we need to capture the complexity of brain processing in our complex world [<xref ref-type="bibr" rid="c7">7</xref>–<xref ref-type="bibr" rid="c9">9</xref>]. Recent advances in deep learning and AI [<xref ref-type="bibr" rid="c10">10</xref>–<xref ref-type="bibr" rid="c13">13</xref>] now allows to develop complex models that can perform cognitive tasks at scale. To connect our complex models to the large datasets poses a new set of statistical challenges. Here we present an integrated methodology implemented in an open-source Python toolbox that addresses these challenges.</p>
<p>The evaluation of models with neural activity measurements is usually based on comparisons of internal representations, i.e. whether internal activities computed from the input are similar. The data for such comparisons are matrices of activities with dimensions for the conditions and the measurement channels (fMRI Voxels, MEG/EEG channels, neurons, electrodes/multiunit activities, features in a model, etc.). We can compare these activity matrices, whether or not our brains and/or models represent the condition in a meaningful way. Representing something would imply that these activity patterns are used for some computation [<xref ref-type="bibr" rid="c14">14</xref>–<xref ref-type="bibr" rid="c16">16</xref>], or at very least provide information about the conditions.</p>
<p>We focus on a particular method for comparing representations called representational similarity analysis [RSA 17]. See <xref rid="s3c" ref-type="sec">section 3.3</xref> for alternative approaches. RSA compares models or brains based on the dissimilarities between the response patterns elicited by the different conditions. These dissimilarities determine how well a downstream area could decode which condition was presented and the geometry of the activity patterns [<xref ref-type="bibr" rid="c18">18</xref>]. Critically, RSA allows us to compare activity matrices without creating a mapping between features and response channels. In practice, RSA entails four steps: First, we pre-process data to estimate the activity pattern for each stimulus or condition. Second, we compute the dissimilarity between each pair of conditions for both the data and the model. A matrix of dissimilarity values across all conditions is called a Representational Dissimilarity Matrix (RDM). Third, we compare the RDMs. Fourth, we perform statistical inference to estimate the uncertainty about our results. RSA is historically rooted in the use of multidimensional scaling (MDS) to infer the geometry of mental representations on the basis of behavioral data [<xref ref-type="bibr" rid="c19">19</xref>, <xref ref-type="bibr" rid="c20">20</xref>] and in the concept of second-order isomorphism, which posits that relationships among cognitive representations are isomorphic to relationships among the things in the world that they represent [<xref ref-type="bibr" rid="c21">21</xref>, <xref ref-type="bibr" rid="c22">22</xref>].</p>
<p>RSA has enabled numerous and impactful research studies. The abstraction from measurement channels inherent to RSA has allowed us to compare brains across species [<xref ref-type="bibr" rid="c18">18</xref>, <xref ref-type="bibr" rid="c23">23</xref>] and age groups [<xref ref-type="bibr" rid="c24">24</xref>]; across measurement modalities [<xref ref-type="bibr" rid="c25">25</xref>–<xref ref-type="bibr" rid="c27">27</xref>], and across stimulus modalities (e.g. orthographic and visual [<xref ref-type="bibr" rid="c28">28</xref>], orthographic and phonological [<xref ref-type="bibr" rid="c29">29</xref>], natural sounds [<xref ref-type="bibr" rid="c30">30</xref>]). RSA has been employed across many fields of study as diverse as linguistics [<xref ref-type="bibr" rid="c31">31</xref>] anthropology [<xref ref-type="bibr" rid="c32">32</xref>] and computational psychiatry [<xref ref-type="bibr" rid="c33">33</xref>], but particularly in neuroscience to study perception [e.g. 34–37] and memory [<xref ref-type="bibr" rid="c38">38</xref>–<xref ref-type="bibr" rid="c40">40</xref>]. Although RSA has predominantly been popular in human neuroimaging, there is a growing body of literature with RSA on neural recordings [<xref ref-type="bibr" rid="c41">41</xref>–<xref ref-type="bibr" rid="c46">46</xref>]. Another promising avenue is that of relating Artificial Neural Network models to brain data using RSA [<xref ref-type="bibr" rid="c25">25</xref>, <xref ref-type="bibr" rid="c44">44</xref>, <xref ref-type="bibr" rid="c47">47</xref>–<xref ref-type="bibr" rid="c57">57</xref>], but see [<xref ref-type="bibr" rid="c58">58</xref>]. RSA has been related to other analysis perspectives such as neural tuning curves [<xref ref-type="bibr" rid="c59">59</xref>], linear encoding models [<xref ref-type="bibr" rid="c60">60</xref>, <xref ref-type="bibr" rid="c61">61</xref>], generalized shape metrics [<xref ref-type="bibr" rid="c62">62</xref>], kernel based methods [<xref ref-type="bibr" rid="c63">63</xref>], and pattern component modeling [<xref ref-type="bibr" rid="c64">64</xref>].</p>
<p>Since its inception many improvements were added to RSA, which make the method more powerful, but require more complex implementations. First, statistical considerations [<xref ref-type="bibr" rid="c65">65</xref>, <xref ref-type="bibr" rid="c66">66</xref>] provide strong arguments in favor of other measures of dissimilarity for the construction of RDMs than the classical correlation distance [<xref ref-type="bibr" rid="c17">17</xref>]. In particular, (squared) euclidean distances, Mahalanobis distances that take noise covariances into account, and cross-validated distances that remove the positive bias contained in distances computed from noisy signals are now standard [<xref ref-type="bibr" rid="c65">65</xref>]. Second, new metrics have been proposed for comparing RDMs: It has been proposed to use a distance on the Riemannian manifold of positive semi-definite matrices [<xref ref-type="bibr" rid="c67">67</xref>]. It has been proposed to use transformations of the distances that focus the analysis more on topology [<xref ref-type="bibr" rid="c68">68</xref>, <xref ref-type="bibr" rid="c69">69</xref>]. Finally, whitened cosine similarity and correlation were proposed to compensate for the correlations between distances in the RDM [<xref ref-type="bibr" rid="c70">70</xref>]. Third, the methodology for statistical inference in RSA has crystallized: In RSA, we usually want to generalize over conditions as well as subjects, which requires complex bootstrap methods for accurate inference [<xref ref-type="bibr" rid="c71">71</xref>]. Additionally, model evaluation for flexible models is now possible by using cross-validation techniques [<xref ref-type="bibr" rid="c72">72</xref>]. Although the basic principles of RSA are straightforward to implement, many of the improvements to RSA are not. Thus, a wider adoption of the improvements requires a standardized and validated implementation of the best practices for RSA.</p>
<p>Here, we present our new <italic>rsatoolbox</italic>, which fills this gap with an implementation in Python that includes the new developments. We choose Python [<xref ref-type="bibr" rid="c73">73</xref>], because the neuroscience community has adopted Python as a programming language of choice. Python’s open-source nature and the batteries-included philosophy have led to a number of key tools, like NiBabel [<xref ref-type="bibr" rid="c74">74</xref>], the NIPY ecosystem [<xref ref-type="bibr" rid="c75">75</xref>], MNE [<xref ref-type="bibr" rid="c76">76</xref>], fMRIprep [<xref ref-type="bibr" rid="c77">77</xref>], or Neurodata without borders [NWB; 78–80] and others [<xref ref-type="bibr" rid="c81">81</xref>–<xref ref-type="bibr" rid="c83">83</xref>]. Therefore, it makes sense for our new library to plug into this growing ecosystem of Python tools for neuroscientists.</p>
<p>The body of this manuscript follows the workflow of a typical RSA analysis with new developments, their validation, best practice recommendations and a guide for how these can be performed using the rsatoolbox with examples. Afterwards we discuss the current state and outlook on how the toolbox may be extended in the future, integration into the wider context of Python packages for neuroscience and compare to alternative approaches for comparisons of brains and models.</p>
</sec>
<sec id="s2">
<label>2</label><title>Representational similarity analysis step by step</title>
<sec id="s2a">
<title>Step 1: Importing data and estimating activity patterns</title>
<p>Data to be analyzed with RSA varies widely in its dimensions and how it is annotated. To bridge the gap between these varied data formats, the first analysis step is to bring the raw data into a common input structure, the <italic>Dataset</italic> class (see <xref rid="fig2" ref-type="fig">Fig. 2</xref> for an overview). This class then provides methods for selection and organization and serves as a standardized input format for the rest of the toolbox.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Fig. 1</label>
<caption><title>Processing flow for representational similarity analysis (RSA).</title>
<p>Experimental stimuli or conditions are presented to both the subjects and the model we want to test. Using an estimator for the representational dissimilarity matrix (RDM), we compute the dissimilarities between all pairs of stimuli. These matrices can then be compared using an RDM comparator. Uncertainty estimates for the comparison results can be obtained from bootstrap resampling.</p></caption>
<graphic xlink:href="655542v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Fig. 2</label>
<caption><title>Preprocessing workflow.</title>
<p>RSA can be applied to data from a wide variety of sources. Neural data recorded from any species, in any modality such as single-cell recordings, calcium imaging, magnetoencephalography (MEG), electroencephalography (EEG), local field potentials (LFP), and functional magnetic resonance imaging (fMRI). RSAtoolbox integrates with a range of popular analysis tools to help prepare and import data patterns as well as residuals. This is in the form of i/o functions to read various data formats as well as utilities to make it easier to navigate a dataset. For examples applied to fMRI data, see the <ext-link ext-link-type="uri" xlink:href="https://rsatoolbox.readthedocs.io/en/stable/demo_fmri_spm.html">SPM demo</ext-link>, the <ext-link ext-link-type="uri" xlink:href="https://rsatoolbox.readthedocs.io/en/stable/demo_fmri_nilearn.html">nilearn demo</ext-link>, or a bare-bones <ext-link ext-link-type="uri" xlink:href="https://rsatoolbox.readthedocs.io/en/stable/demo_fmri_patterns.html">NumPy patterns demo</ext-link>.</p></caption>
<graphic xlink:href="655542v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The main content of a Dataset object is a matrix of activity data, with rows corresponding to individual measurements and columns to measurement channels like voxels, sensors, or neurons. Additionally, the object contains annotations, including the condition each measurement corresponds to and optional additional annotations about the measurements and channels. To use cross-validated distance estimates (see section 2.3), multiple independent estimates for the activity pattern for each condition are necessary. To enable this approach, the Dataset class can contain multiple measurements for the same condition. While Dataset objects can be created simply from a NumPy array and lists of annotations, we provide some modality-specific functions that assist in importing data and processing it in a manner optimized for RSA for ease of use.</p>
<p>Additional to the response strengths, some analyses require an estimate of the signal covariance across measurement channels, i.e. of ‘noise correlations‘. There are two main reasons to take this covariance into account: First, it aligns the distance estimates better with statistical discriminability (as discussed more below). Second, it can improve the reliability of distance estimates because channels with high variance or strong correlations with other channels are given lower weights for the computation of distances [<xref ref-type="bibr" rid="c65">65</xref>].</p>
<p>Given that different measurement modalities require different steps for estimating activity patterns and their noise covariance, we briefly provide separate recommendations for neural spiking data, fast averaged data like EEG, MEG or local field potentials, fMRI data, and behavioral data.</p>
<sec id="s2aa">
<title>Neural recordings/spiking data</title>
<p>For neural data, we aim to extract a spike rate for each neuron and each condition. The simplest method to do so is to count spikes in a fixed time window after stimulus presentation. It is possible to add further preprocessing like temporal smoothing, artifact removal or similar adjustments as they are deemed necessary for the specific brain area and recording technique. We generally advise against subtracting baselines, because they regularly result in negative spike rates which breaks a central assumption of many methods adapted to spike rate distributions. The main exception are brain areas with strong, slow drifts of the average spike rate, whose effect can be substantially reduced by subtracting an individual baseline for each trial.</p>
<p>Spike rates are typically more variable if the mean response is higher, i.e. they are not homoscedastic. The classic assumption is Poisson noise, which has variance proportional to the mean response [<xref ref-type="bibr" rid="c84">84</xref>]. More modern takes acknowledge that the rates can be more or less variable than expected from a Poisson distribution and follow more complex distributions in general [<xref ref-type="bibr" rid="c85">85</xref>–<xref ref-type="bibr" rid="c88">88</xref>]. The standard Euclidean and Mahalanobis distances are thus a bad fit for spike rate data. We provide two approaches to this problem: First, the spike rates can be transformed such that they are better approximated by a homoscedastic noise model. The most common transformation is a square root transform [<xref ref-type="bibr" rid="c89">89</xref>]. Second, we can use different distance measures that take the difference in variance into account. For this purpose we provide the symmetrized KL-divergence between Poisson distributions (see below). For this approach, the spike rates are not transformed.</p>
<p>Noise correlation between neurons is weaker and less problematic than noise correlation between channels in other modalities; therefore, RSA on spiking data does not strictly require taking the noise covariance matrix into account. If this is desired nonetheless, the estimate for the covariance is usually based on the variance of individual responses around the mean response for each condition. This can be computed from the Dataset object in the toolbox, such that no separate noise estimate needs to be extracted unless you wish to use an alternative noise covariance estimate.</p>
<p>When the temporal evolution of processing is of interest, all processing in the RSA toolbox can be repeated for different time points. To do so, we simply compute datasets for each time point we want to test by adjusting the window we count spikes over or taking a different time point from a kernel density estimate of spike rate. This can be done at equal time steps after stimulus onset to get a curve of results over time. To enable this the rsatoolbox provides a <italic>TemporalDataset</italic> class. Alternatively, the analysis can be focused on particular phases of the response, for example the initial onset response and the sustained activity. The latter approach typically results in much fewer, more targeted analyses.</p>
</sec>
<sec id="s2ab">
<title>Electroencephalography and Magnetoencephalography</title>
<p>For Electroencephalography (EEG), Magnetoencephalography (MEG), or their combination (M/EEG), RSA analyses are based on the average responses at the sensor or source level to the respective conditions. Using standard toolboxes (e.g., MNE-Python, [<xref ref-type="bibr" rid="c76">76</xref>]) we first preprocess data (filtering, artifact removal, etc.), optionally project it into source space, and segment it into epochs time-locked to the stimulus onset. We can then estimate pattern response strengths for the different conditions as averages over epochs.</p>
<p>Noise covariance estimates for EEG or MEG can be critical, because both sensor measurements and source estimates exhibit strong spatial correlations. Sensors may also vary substantially in their sensitivity and response magnitudes of different sensor types vary by orders of magnitude (i.e., gradiometers, magnetometers, EEG channels). Estimates for the covariances between channels or source level estimates can be obtained from resting state or baseline data or from the deviations of the raw EEG-MEG signals around the mean response to the stimuli. For computing these covariances, standard methods are available, for example in MNE-Python [<xref ref-type="bibr" rid="c76">76</xref>, <xref ref-type="bibr" rid="c90">90</xref>, <xref ref-type="bibr" rid="c91">91</xref>]. The noise covariance can also be estimated within the rsatoolbox using the residuals around the condition mean patterns obtained from the epoched data. Which of these estimates performs best is data set dependent. The covariance of the raw signal, especially during a baseline, can be different from the covariance of the average signal during stimulus presentation, but we usually have more data points to estimate the covariance of the raw signal. As for fMRI, it is almost always advisable to regularize the covariance estimates, i.e. to use shrinkage estimates, or to use a diagonal matrix to perform univariate normalization.</p>
<p>The simplest analysis for M/EEG data performs RSA on a single time point or the average within a single time window. For instance, this approach can be applied to focus the analysis on classical components of event-related potentials. M/EEG data also lends itself well to time-resolved analysis of representational geometries (“RDM movie”). For this purpose, we compute a dataset for each time point we want to test and repeat the analysis on each dataset using the <italic>TemporalDataset</italic> class.</p>
</sec>
<sec id="s2ac">
<title>Local field potentials</title>
<p>(LFPs) can be handled like EEG or MEG data. After preprocessing the data, the average response at a time point relative to stimulus onset specifies a response strength estimate that is a good basis for an RSA analysis.</p>
</sec>
<sec id="s2ad">
<title>Functional magnetic resonance imaging</title>
<p>fMRI experiments are usually acquired in different imaging runs, which provide a natural way of breaking up the data set into independent partitions for cross-validation [<xref ref-type="bibr" rid="c92">92</xref>]. The standard approach for estimating fMRI activity patterns is a mass-univariate general linear model (first-level GLM), which can be used both for event-related and blocked designs [<xref ref-type="bibr" rid="c93">93</xref>]. In a GLM, the response to each condition is usually modeled with a single regressor per imaging run. Recently, there are also methods to estimate beta coefficients for each stimulus presentation instead [<xref ref-type="bibr" rid="c94">94</xref>, <xref ref-type="bibr" rid="c95">95</xref>]. Such single trial estimates can be more accurate, but are correlated within a run such that we usually recommend to average them within a run before entering them into the RSA analysis. The resultant regression coefficients (beta-weights) constitute the activity patterns elicited by the condition.</p>
<p>fMRI voxels differ substantially in their signal-to-noise ratio and can be strongly correlated over space. Thus, we recommend to <italic>pre-whiten</italic> the noise of the activity estimates before RSA [<xref ref-type="bibr" rid="c65">65</xref>]. The easiest way to do this is to divide the beta-weights of each voxel by the estimate of the noise standard deviation from the GLM (univariate prewhitening). A more advanced approach is to also take into account the noise covariance between voxels (multivariate prewhitening). For computational efficiency reasons, we implement prewhitening as part of the distance calculation as a Mahalanobis distance, i.e. we pass the original beta weights and the covariance matrix to the distance calculation instead of prewhitening the estimates.</p>
<p>To estimate the noise covariance among voxels efficiently, we require access to the full residual time-series from the first-level GLM, which are not saved by default in different neuroimaging packages. Our toolbox therefore contains a series of functions (<bold>rsa.io</bold>) to efficiently import and prewhiten the beta-weights from different neuroimaging packages. These functions account for package-specific GLM-related data structures. Currently, our code supports the import of GLMs performed in Statistical Parametric Mapping [SPM, 96] or in nilearn using the standard naming conventions of BIDS [Brain Imaging Data Structure, 97].</p>
</sec>
<sec id="s2ae">
<title>Behavioral data</title>
<p>Many behavioral paradigms are suitable for RSA if they can be applied to a varied set of stimuli. Direct similarity judgments are experiments where the participant makes an explicit judgment about the perceived similarity of stimuli. This includes paradigms where a discrete choice is made, such as the same-different task [<xref ref-type="bibr" rid="c98">98</xref>], match-to-sample [<xref ref-type="bibr" rid="c99">99</xref>], or the odd-one-out task [<xref ref-type="bibr" rid="c100">100</xref>]. To convert such data into an RDM, there are two broad approaches: The simpler one is to count the number of choices that speak in favor of a pair of objects being dissimilar from each other. This approach works for judgments about a single dissimilarity and also for triplet tasks were we count how often a pair of stimuli was chosen to be more dissimilar than another one. Typically, this will not result in a valid distance matrix initially, but can be projected onto the cone of valid distance matrices. Another drawback of the simple approach is that it requires (many) judgments for each individual dissimilarity in the matrix. Collecting this amount of data becomes infeasible quickly with growing number of conditions. This motivates the more complex approach of training an embedding model that predicts the behavioural choices [<xref ref-type="bibr" rid="c100">100</xref>, <xref ref-type="bibr" rid="c101">101</xref>] These models place each condition on a number of “embedding” dimensions and predict the behavioural choices based on the distances in this embedding space. This approach allows us to fill in distances for which we have no data and additionally yields scores on the embedding dimensions that can be made interpretable.</p>
<p>Other tasks ask observers to judge similarities on continuous scales. The simplest such task is the drag-and-rate task, where observers are asked to place stimulus pairs on a continuous dissimilarity scale [<xref ref-type="bibr" rid="c102">102</xref>, <xref ref-type="bibr" rid="c103">103</xref>]. For an overview of direct similarity judgment methods, see [<xref ref-type="bibr" rid="c104">104</xref>]. For larger datasets the number of combinations may rule out pair-wise trials; the inverse MDS task or “multiple arrangement” provides an alternative where a larger subset of stimuli are arranged with respect to each other in a single space [<xref ref-type="bibr" rid="c105">105</xref>]. Data from many arrangements is pooled by iteratively scaling the partially filled RDMs with respect to the dissimilarity of pairs of items they have in common, and then averaging them. This paradigm has been applied to a number of RSA studies, including those with objects [<xref ref-type="bibr" rid="c106">106</xref>], scenes [<xref ref-type="bibr" rid="c1">1</xref>], faces [<xref ref-type="bibr" rid="c34">34</xref>] and videos [<xref ref-type="bibr" rid="c107">107</xref>, <xref ref-type="bibr" rid="c108">108</xref>]. Similarity judgments collected using any of these tasks can be imported directly using the library’s tools for reading table data.</p>
<p>Another approach is to obtain indirect measures of perceptual similarity; where one or several independent variables are measured when the participant perceives the stimuli. One example would be the reaction time in an RSVP task such as the Attentional Blink [<xref ref-type="bibr" rid="c109">109</xref>]. In another example, participants wrote sentence captions for displayed images; the corresponding high-dimensional embeddings of which were then used as patterns to calculate a semantic RDM [<xref ref-type="bibr" rid="c110">110</xref>]. Others have used mouse tracking patterns [<xref ref-type="bibr" rid="c111">111</xref>]. Such indirect data can be imported as Dataset for subsequent calculation of the dissimilarity measure.</p>
</sec>
</sec>
<sec id="s2b">
<title>Step 2: Estimating representational geometries</title>
<p>The activity patterns for the experimental conditions form the basis for estimating the representational geometries. The geometry is defined by a distance matrix: a square matrix, containing the distance for each pair of activity patterns. However, different distance measures can be used which vary in the ways they handle (1) the variation of the activity patterns along the population-mean dimension, (2) the correlated noise in the multivariate activity space, and (3) the positive bias associated with naive measurements of distances caused by measurement noise. These three complications are addressed in turn in the next three sub-sections. Our new toolbox offers a wide variety of representational dissimilarity estimators. <xref rid="tbl1" ref-type="table">Table 1</xref> gives an overview of some important representational dissimilarity estimators. An RDM is computed by calling calc_rdm on the Dataset object, with the chosen dissimilarity estimator specified in the string argument method (e.g. method=‘euclidean’, ‘correlation’, ‘mahalanobis’, ‘poisson’, ‘crossnobis’).</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1</label>
<caption><title>Methods for estimating RDMs.</title><p>See text for details and recommendations for choosing from this list. <bold>r</bold><sub>1</sub> and <bold>r</bold><sub>2</sub> are the two response patterns, <bold>r̄</bold><sub>1</sub><italic><sub>/</sub></italic><sub>2</sub> are standardized versions of them, Σ is an estimate of the noise covariance, <bold>r</bold><italic><sup>i</sup></italic> is the response pattern in the i-th of <italic>N<sub>r</sub></italic> runs, i.e. sets of measurements that are assumed to be independent from the other <italic>N<sub>r</sub></italic> 1 sets. log of a vector here refers to the vectors of logarithms of each entry. * add a square root transform.</p></caption>
<graphic xlink:href="655542v1_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<sec id="s2b1">
<label>2.0.1</label><title>Euclidean distances</title>
<p>The simplest distance to use is the Euclidean distance in the multivariate response space and this is an entirely valid choice. One can also use the squared Euclidean distance, which has the advantage that distances add over orthogonal dimensions. This additivity makes it particularly simple to model distances that arise from multiple underlying dimensions or parts of a model.</p>
</sec>
<sec id="s2b2">
<title>Correlation and mean-removed distances: normalizing population-mean activity and pattern variance</title>
<p>The population-mean dimension is the axis in the multivariate response space defined by the all-1 vector. Passing through the origin, this axis is at equal angles to all the axes corresponding to the measurement channels (e.g. neurons, voxels, electrophysiological sources). We refer to this axis as the population-mean dimension because computing the regional-mean by averaging activity across channels amounts to projection onto this axis (up to a scaling factor related to the number of responses). Regional-mean activation is usually studied using univariate analyses, for example in fMRI studies. To make the multivariate pattern analyses orthogonal and complementary to univariate regional-mean analyses, we may choose to remove the mean from each pattern estimate. In fMRI, an additional motivation for removing the regional mean is that each voxel averages many neurons’ response, and so the neural population mean dimension is overrepresented in the fMRI activity pattern estimates [<xref ref-type="bibr" rid="c66">66</xref>]. Instead of computing Euclidean distances on the activity patterns, we may therefore compute Euclidean distances after removing the mean from each pattern. Of course we may be losing distinctions between experimental conditions if we remove the mean and this needs to be kept in mind when interpreting the results.</p>
<p>A popular way to measure representational distance is the Pearson correlation distance (method=‘correlation’), which is defined as 1 − <italic>r</italic>, where <italic>r</italic> is the Pearson correlation between the two pattern estimates across the measurement channels. The Pearson correlation distance equals half the squared Euclidean distance measured after normalizing each activity pattern. The normalization of each pattern involves removal of the mean and scaling to unit variance. While removing the mean may be well motivated (as explained in the previous paragraph), scaling the pattern to unit variance can cause confusion. Two patterns of small activity values, which are close in terms of Euclidean distance, can appear quite distinct [<xref ref-type="bibr" rid="c65">65</xref>]. For example, patterns that contain only noise because they are elicited by stimuli that do not drive any significant response will have <italic>r</italic> ≈ 0, and so the correlation distance will be large: 1 − <italic>r</italic> ≈ 1. The patterns, thus, have a high correlation distance, although the corresponding conditions cannot be decoded from them. This caveat needs to be kept in mind when using the correlation distance.</p>
</sec>
<sec id="s2b3">
<title>Mahalanobis and symmetrized-KL Poisson distance: measuring distances relative to the noise</title>
<p>If we are interested in the discriminability of the representational patterns to downstream decoders, then we should measure the distance relative to the noise in the activity patterns. <xref rid="fig3" ref-type="fig">Figure 3a</xref> shows a case in which two measurement channels are negatively correlated. If two conditions (blue and green) differ along this direction, then the distance should be smaller, to reflect the fact that a downstream decoder will have lower accuracy.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Fig. 3</label>
<caption><title>Impact of correlated noise across channels (a) and measurements (b,c) on distance estimation.</title>
<p><bold>A</bold>. Mean activity patterns for 3 conditions (red, green blue) plotted in the space of 2 measurement channels. In the raw data space (left), the two channels are negatively correlated across individual measurements (dots). After spatial pre-whitening (arrow), the correlation is removed. The distances in prewhitened space now reflect discriminability of the different conditions across measurements. <bold>B</bold>. Normal (red) and cross-validated (blue) estimation of four squared Euclidean distances (x-axis). When the noise is independently and identically distributed (iid) across measurements, the bias is constant for all squared distances and the rank-ordering of the distances is preserved. <bold>C</bold> Same as B, but the pair of condition with distance 2 has correlated (<italic>r</italic> = 0.5) measurement noise. This induces a negative bias in the distance estimate, also changing the rank-ordering of the distances. Cross-validated distances (blue) remove this bias.</p></caption>
<graphic xlink:href="655542v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>If the noise distribution is multivariate normal, we can use an inverse square-root of the noise covariance matrix to transform the patterns into a whitened space, in which the noise is isotropic across measurement channels (<xref rid="fig3" ref-type="fig">Figure 3a</xref>). The distances in this new space are the Mahalanobis distances (method=‘mahalanobis’) between the original patterns. This procedure is especially adequate for fMRI data, for which the measurement noise is well approximated by a multivariate normal distribution, and for which there is often considerable correlation between measurement channels (voxels). For such data, multivariate pre-whitening has been shown to increase the reliability of the distance estimators [<xref ref-type="bibr" rid="c65">65</xref>].</p>
<p>For other measurement modalities, the noise may be non-normal and/or heteroscedastic. In this case, a variance-stabilizing transform can be used before measuring distances [<xref ref-type="bibr" rid="c15">15</xref>, <xref ref-type="bibr" rid="c59">59</xref>]. For example, if we have neural data and assume Poisson noise, we can use a square-root transform on the spike rates to stabilize the variance. An important general approach to measuring the distance in terms of condition discriminability is the symmetrized Kullback-Leibler (KL) divergence. Each condition is represented by the distribution of patterns (reflecting the structured noise) in the multivariate activity space. The symmetrized KL divergence reflects the degree to which a response pattern drawn from either condition is decodable (in terms of expected log odds). The RSA3 Toolbox implements the symmetrized-KL dissimilarity estimator for Poisson noise (method=‘poisson’), which is applicable to patterns of neural firing rates. This is a close analogue of using the squared Mahalanobis distance for fMRI data, which is the symmetrized KL divergence between two Gaussian distributions with equal covariance matrix.</p>
</sec>
<sec id="s2b4">
<title>Removing the positive bias of distance estimates</title>
<p>When applied to noisy activity estimates, all distance estimators considered so far are positively biased in the sense that they tend to overestimate distances between the true noise-free activity patterns. Measurement noise perturbs response patterns in random directions. In high-dimensional space most of the noise is orthogonal to the line connecting the two patterns and thus tends to increases the distance between them.</p>
<p>If the measurement noise is independent and identical across conditions, the bias for squared distances is the same for all pairs of conditions (<xref rid="fig3" ref-type="fig">Figure 3b</xref>). However, if the noise variance varies across conditions, or if measurements for different conditions are correlated, the bias can be uneven across distances, such that even the rank ordering of the distances is affected (<xref rid="fig3" ref-type="fig">Figure 3c</xref>).</p>
<p>The bias can be removed by using crossvalidated distance estimates if repeated independent measurements of each pattern are available [<xref ref-type="bibr" rid="c65">65</xref>, <xref ref-type="bibr" rid="c112">112</xref>–<xref ref-type="bibr" rid="c114">114</xref>]. These distance estimators multiply differences from different independent partitions of the data, which cancels the positive bias on average. This statement implies that if the true distance is zero, the mean cross-validated estimate is also zero (<xref rid="fig4" ref-type="fig">Figure 4b</xref>).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Fig. 4</label>
<caption><title>Choosing an appropriate dissimilarity estimator and RDM comparator.</title>
<p>This Euler diagram shows which combination of RDM estimator and RDM comparator promises the most powerful model-comparative inferential analyses in different scenarios, and when a different experimental design is needed. To find the right combination of RDM estimator (italics) and RDM comparator (bold), answer the three questions (black, blue, red). For each question, a yes (Y) indicates that the answer is inside the set, and a no (N) indicates that the answer is outside the set. See text for details. The diagram is the minimum-contour-length iso-Euler diagram.</p></caption>
<graphic xlink:href="655542v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To achieve unbiasedness, the cross-validated estimator must sometimes result in negative values to average out positive estimation errors. Because distances are by definition non-negative, we use the term representational <italic>dissimilarity</italic> instead as a more general concept encompassing all the estimators we might want to use to characterize the representational geometry. Importantly, negative dissimilarities should not be excluded or replaced by zeros, but rather included in the subsequent analyses to ensure unbiased inference (see below). The only exception to this rule are analyses that require a valid distance matrix to function, such as visualization using metric multidimensional scaling.</p>
<p>The RSA3 Toolbox implements crossvalidated estimators for a variety of distance measures, including the squared Eucidean and squared Mahalanobis (crossnobis) distance and the symmetrized KL-divergence for poisson distributions. The crossnobis estimator (method=‘crossnobis’) is closely related to linear decoding analyses using the Fisher linear discriminant. In essence, it measures the distance after projection of test data points onto the Fisher linear discriminant dimension estimated with a set of training data points. Similarly, the symmetrized KL-divergence can be crossvalidated by using a different part of the data to estimate the probabilities used for weighting than for estimating the log-likelihood ratio (method=‘poisson_cv’).</p>
</sec>
<sec id="s2b5">
<title>Transformations on RDMs</title>
<p>Some research suggests that applying a non-linear transform to the distances can be advantageous. This enables the use of unsquared euclidean distances, which have stronger relationships to statistical measures of independence like the Hilbert-Schmidt independence criterion [<xref ref-type="bibr" rid="c115">115</xref>] and distance correlations [<xref ref-type="bibr" rid="c116">116</xref>]. Also a geo-topological transform can enable a stronger focus on the topological structure of the representation rather than its geometry [<xref ref-type="bibr" rid="c69">69</xref>].</p>
<p>We implement this with a general transformation function that allows the application of any transformation to the RDM and a specialized function for taking the square root and applying the geo-topological transform. One should apply analogous transformations to any pair of RDMs that one wants to compare.</p>
</sec>
</sec>
<sec id="s2c">
<title>Step 3: Comparing RDMs</title>
<p>To draw these conclusions, we first need to choose a measure for the similarity of RDMs. Then we need to estimate how variable these similarity values are and how well a model could perform in principle. Once we have those estimates we can perform frequentist statistical inferences that test whether a model could be true, predicts anything about the data RDM, and for each other model, whether it significantly outperforms this other model.</p>
<sec id="s2c1">
<title>RDM comparators</title>
<p>To compare RDMs to each other, in principle any measure of similarity for symmetric matrices or vectors can be used. However, different <italic>RDM comparators</italic> will weigh different aspects of RDMs differently. Most RDM comparators also have some aspects of RDMs that they are entirely invariant to, which is desired when those aspects are deemed irrelevant for the research question. Beyond that, a different weighting of the RDM dimensions will still lead to different evaluations - that is, different RDM comparators maybe more sensitive to measurement noise or differences between subjects. We give an overview of the possible RDM comparators in the toolbox in <xref rid="tbl2" ref-type="table">Table 2</xref>.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2</label>
<caption><title>Methods for comparing two RDMs to evaluate predictions of representational geometries.</title><p>The column labeled “function” specifies the name to be passed to the compare function to compute the similarity. In the formulae, <bold>d</bold><italic><sub>k</sub></italic> for <italic>k</italic> = 1, 2 are the two vectorized RDMs, <italic>d<sub>k,i</sub></italic> is the <italic>i</italic>-th scalar dissimilarity of <bold>d</bold><italic><sub>k</sub></italic>,<bold>d̄</bold><sup/><italic>k</italic> is the centered version of <bold>d</bold><italic><sub>k</sub></italic> (with the mean subtracted from each dissimilarity), <bold>d</bold>°<italic>k</italic> is the rank transformed version of <bold>d</bold><italic><sub>k</sub></italic> and <bold>D</bold><italic><sub>k</sub></italic> are their transforms into positive definite matrices as described in the text. <italic>n</italic> is the number of dissimilarities, <italic>n<sub>b</sub></italic> = <italic><sup>√</sup>n<sub>b</sub></italic><sub>1</sub><italic>n<sub>b</sub></italic><sub>2</sub> is the normalization for <italic>τ<sub>b</sub></italic> where <italic>n<sub>b</sub></italic><sub>1</sub> and <italic>n<sub>b</sub></italic><sub>2</sub> are the numbers of ordered pairs in the two compared distance vectors. <bold>V</bold> is the <italic>n n</italic> covariance matrix of the dissimilarity estimate errors. Citations: 1. [<xref ref-type="bibr" rid="c114">114</xref>] 2. [<xref ref-type="bibr" rid="c17">17</xref>] 3. [<xref ref-type="bibr" rid="c70">70</xref>] 4. [<xref ref-type="bibr" rid="c71">71</xref>] 5. [<xref ref-type="bibr" rid="c113">113</xref>] 6. [<xref ref-type="bibr" rid="c67">67</xref>] 7. [<xref ref-type="bibr" rid="c117">117</xref>] .</p></caption>
<graphic xlink:href="655542v1_tbl2.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3</label>
<caption><title>Symbols used</title></caption>
<graphic xlink:href="655542v1_tbl3.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>Generally, we want to ignore the overall scale of the RDM to make our inference independent of the overall signal strength, which often varies across subjects, sessions, and measurement modalities. Thus, we want all our RDM comparators to be invariant to an overall rescaling of the RDM. Formally, <italic>sim</italic>(<bold>d</bold><sub>1</sub>, <bold>d</bold><sub>2</sub>) = <italic>sim</italic>(<italic>a</italic><bold>d</bold><sub>1</sub><italic>, b</italic><bold>d</bold><sub>2</sub>), for all <italic>a, b</italic> ∈ ℝ<sup>+</sup>.</p>
<sec id="s2c1a">
<title>Cosine Similarity</title>
<p>The simplest measure of similarity that ignores the scale is the <italic>cosine similarity</italic> of the vectorized RDMs. This similarity is the inner product of the vectorized RDMs after dividing each by their norm. This normalization explicitly removes the dependence on the scale of the RDMs. However, the cosine similarity is sensitive to the average distance value, i.e. adding a constant to all distances changes cosine similarities. In particular, the bias introduced by estimating distances from noisy data reduces the cosine similarity below 1, even if the bias is constant and all representations become more similar if a constant is added to all distances in all representations. Thus, the cosine similarity should only be used for cross-validated or noise free dissimilarity estimates.</p>
</sec>
<sec id="s2c1b">
<title>Pearson Correlation</title>
<p>To remove the assumption that a model-predicted distance of 0 corresponds to a measured dissimilarity of 0, we can use the Pearson correlation coefficient <italic>r</italic> between RDMs. Like the cosine similarity, the correlation is the inner product of the vectorized RDMs after normalization. But the normalization includes mean subtraction as well as division by the norm. It is thus equivalent to the cosine similarity after subtracting the average dissimilarity.</p>
</sec>
<sec id="s2c1c">
<title>Whitened RDM similarities</title>
<p>Cosine similarity and Pearson correlation are adequate measures of similarity of two vectors when the individual elements of the vectors are independent. The entries of a RDM are not independent, because all dissimilarities involving the same condition are based on the same measurements of that condition. For squared Euclidean, Mahalanobis, and Crossnobis dissimilarities, we can derive the covariance matrix <italic>V</italic> of all the dissimilarities analytically [<xref ref-type="bibr" rid="c70">70</xref>]. This estimate can then be used to “whiten” - i.e. to de-correlate - the dimensions of the RDM (see <xref rid="tbl2" ref-type="table">Table 2</xref>). We have shown that model comparison using these whitened versions of the cosine similarity of Pearson correlations outperforms model comparison using traditional methods [<xref ref-type="bibr" rid="c70">70</xref>].</p>
<p>Interestingly, the whitened cosine similarity is equivalent to the linear centered kernel alignment (CKA) [<xref ref-type="bibr" rid="c63">63</xref>], if the measurement noise within each condition is assumed to be iid. This equivalent formulation can be computed faster as it avoids the inversion of <italic>V</italic> . Our implementation uses this equivalent formulation for faster computation.</p>
</sec>
<sec id="s2c1d">
<title>Rank correlation coefficients</title>
<p>We can drop the assumption of a linear relationship between RDMs by using rank correlation coefficients like Kendall’s <italic>τ</italic> or Spearman’s <italic>ρ</italic>. For this lowest bar for a relationship, Kendall’s <italic>τ<sub>a</sub></italic> or <italic>ρ<sub>a</sub></italic> are preferred over the standard Spearman’s <italic>ρ</italic> or Kendall’s <italic>τ<sub>b</sub></italic>and <italic>τ<sub>c</sub></italic> because the latter all favor models that predict RDMs with tied ranks. The recommended option is <italic>ρ<sub>a</sub></italic>, which is as computationally efficient as Spearman’s <italic>ρ</italic> and like Kendall’s <italic>τ<sub>a</sub></italic> correctly handles models that predict tied dissimilarities. The rank correlation coefficient <italic>ρ<sub>a</sub></italic> is the expectation of Spearman’s <italic>ρ</italic> under random tie breaking (using a closed-form solution).</p>
<p>Rank correlations are helpful if our models only predict the order of distances not a particular distance. For example, just that distances within a category should be smaller than the ones between categories.</p>
</sec>
<sec id="s2c1e">
<title>Bures similarity and distance</title>
<p>Two alternative comparators for positive definite matrices are the Bures similarity and distance [<xref ref-type="bibr" rid="c117">117</xref>]. These metrics are equivalent to generalized shape metrics [<xref ref-type="bibr" rid="c62">62</xref>], which allow an orthogonal rotation to align the shapes with each other before measuring their distance. As these measures are based on the centered kernel matrices instead of distance matrices, we need to convert the distance matrices to kernel matrices first. Fortunately, distance matrices and centered kernel matrices contain equivalent information and the transformation between them is a simple linear map, such that this is not an issue.</p>
</sec>
<sec id="s2c1f">
<title>Riemannian manifold similarity</title>
<p>Yet another measure of similarity for positive definite matrices is known as the Riemannian manifold distance [<xref ref-type="bibr" rid="c67">67</xref>]. This distance ensures that applying the same invertible linear map to the two activity matrices does not change their distance. Additionally, the original publication showed promisingly high reliability of this measure. Main drawbacks are slight stability issues for close to singular distance matrices and a relatively long computation time.</p>
</sec>
<sec id="s2c1g">
<title>Toolbox implementation</title>
<p>All comparison methods are implemented in rsatoolbox.rdm. They can each be accessed by passing a method argument to rsatoolbox.rdm.compare or by using a specific function rsatoolbox.rdm.compare_[comparison]. The comparison functions each take two RDMs objects as input and return a matrix of all pairwise comparisons.</p>
</sec>
</sec>
<sec id="s2c2">
<title>Choosing an appropriate combination of RDM estimator and RDM comparator</title>
<p>We should choose the combination of RDM estimator and RDM comparator that promises the greatest power for inferential model comparisons. The best choice depends on the answers to three questions (<xref rid="fig4" ref-type="fig">Fig. 4</xref>):
<list list-type="simple">
<list-item><p><bold>(1) Do the models make ratio-scale dissimilarity predictions?</bold> If yes (black set), we can gain power by using a ratio-scale RDM comparator. Such a comparator measures to what extent the measured dissimilarities are proportional to the model-predicted dissimilarities, taking 0 dissimilarity predictions to mean that the measured dissimilarity should also be 0. If the answer no (the model does not make ratio-scale predictions; outside the black set), we can evaluate the model on the basis of the ranks of its dissimilarity predictions, using a rank correlation coefficient. The <italic>ρ<sub>a</sub></italic> coefficient is an appropriate and computationally efficient choice.</p></list-item>
<list-item><p><bold>(2) Are the errors of the pattern estimates for different conditions independent and identically distributed (i.i.d.) within each partition?</bold> If yes (blue set), then a biased distance estimator (without crossvalidation) will get the ranks right, as the noise-induced bias will be constant across squared distances (<xref rid="fig3" ref-type="fig">Fig 3b</xref>). If no (outside blue set), different levels of error variance between conditions and dependency in the error variance between conditions can compromise the dissimilarity ranks when using a biased RDM estimator (<xref rid="fig3" ref-type="fig">Fig 3c</xref>), so an unbiased (crossvalidated) RDM estimator is needed.</p></list-item>
<list-item><p><bold>(3) Are there multiple independent pattern estimates from repetitions of each condition?</bold> If yes (red set), it is possible to use a crossvalidated RDM estimator and thus obtain unbiased distance estimates. If no (outside red set), we do not have the repeated measurements needed for crossvalidation and can only obtain biased distance estimates.</p></list-item>
</list>
In case the answers to questions (2) and (3) are both no (outside both red and blue sets), there is no way to correctly estimate even the ranks of the dissimilarities, so it is best to use a different experimental design. In the central intersection of all three conditions, both approaches work with different advantages: The combination of the crossnobis estimator and the whitened unbiased cosine similarity comparator promises an interpretable 0 point and no bias, whereas the combination of the Mahalanobis distance and whitened Pearson correlation comparator promises slightly lower variance [<xref ref-type="bibr" rid="c70">70</xref>]. Which of these two choices affords more power in model adjudication depends on the model predicted RDMs (if the placement of the 0 point on the distance scale differs between models this fact favors the crossnobis estimator) and the proportion of data that must be held out in crossvalidation for the crossnobis estimator (more favors the biased estimators)</p>
</sec>
</sec>
<sec id="s2d">
<title>Step 4: Inferential model comparisons</title>
<p>Our inference about our models usually aims for two things: First, we want to compare each model to the data and judge how well the model captures the representational geometry we observe in the data. In particular, does it capture any aspect of the representational structure at all? How good is the fit given the level of measurement noise? Second, we want to compare models, i.e., draw conclusions about whether the difference between two models could have happened due to chance even if the two models were in truth equally good.</p>
<sec id="s2d1">
<title>Model specification: Selecting a model type and defining the RDM model</title>
<p>To evaluate hypotheses we need to capture those hypotheses into models. In the rsatoolbox we conceptualize models as objects with two main functions: First, they can predict an RDM for the set of conditions we want to analyze, potentially based on parameters. Second, they provide a fitter method to find the best parameters for a given dataset. This setup is very broad, encompassing all parametric models of representational similarity.</p>
<p>The prediction function is implemented as functions of the model object in two flavors, predict_rdm returns the RDM object including descriptors. predict directly returns a ’naked’ RDM vector, which allows for slightly faster evaluations, if the descriptor annotations are not needed.</p>
<p>There are different methods for defining a model depending on what kind of flexibility is needed for the model. The first choice is whether any flexibility is required.</p>
<p>If the hypotheses can be captured by <italic>fixed models</italic>, i.e. with models that have no free parameters and predict a single fixed RDM, this simplifies the inference substantially as cross-validation is not needed then.</p>
<p>However, there are situations that require flexible models. In particular, many models contain some flexibility as to how their activity patterns are distorted by the measurement process, i.e. a flexible measurement model. A common example of this is the size of voxel averaging regions, which is typically unknown and distorts the RDM [<xref ref-type="bibr" rid="c41">41</xref>]. In such cases, we require a proper flexible model whose parameters are fit to the data, because model performance may otherwise depend primarily on luck with the parameter assignment [<xref ref-type="bibr" rid="c41">41</xref>].</p>
<p>To enable this kind of fitting, the rsatoolbox provides two broad approaches:</p>
<p>First, <italic>selection</italic> and <italic>interpolation</italic> models can be used for arbitrary relationships between parameters and RDMs, as long as the range of RDMs can be represented by a small selection of RDMs or by a one dimensional manifold of RDMs. These models work well for these cases and fitting is extremely stable. Thus, these models are recommended for situations similar to the fitting of voxel sizes.</p>
<p>The other approach is a weighted model, which aims to capture the weighting of feature dimensions or model components. The central idea here is that squared euclidean distances are additive for orthogonal axes, i.e. two conditions with squared distance <inline-formula><inline-graphic xlink:href="655542v1_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula> along a first dimension and <inline-formula><inline-graphic xlink:href="655542v1_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula> along a second dimension will have total squared distance <inline-formula><inline-graphic xlink:href="655542v1_inline3.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. This connection allows us to combine the distances from different parts of a model into an overall distance. When we do not know how the two distances are weighted relative to each other, we can add a weight to each distance. The overall squared distance RDM is then simply the weighted sum of the component RDMs.</p>
<sec id="s2d1a">
<title>Fixed models</title>
<p>are models that predict a single RDM without any parameter. These models are the simplest and most frequently used type in RSA. To formally fit the model object architecture, these models have a dummy_fitter function that are always None and ignore any optional parameter to their prediction functions. To homogenize the analysis we generally expect these fixed model objects, not RDM objects as input to the inference methods described below.</p>
</sec>
<sec id="s2d1b">
<title>Selection models</title>
<p>are models that are given a set of RDMs and predict that the true RDM is one of these RDMs. These models give a coarse simple method to implement an arbitrarily complex set of potential RDMs. Their prediction takes the index of the selected RDM as an input and they allow only one particular fitting function, which evaluates each RDM from the set on the training data and simply returns the index of the best performing RDM.</p>
</sec>
<sec id="s2d1c">
<title>Interpolation models</title>
<p>interpret a given set of RDMs as the interpolation points for a piece-wise linear manifold of RDMs. This allows an approximate model for any one dimensional manifold of RDMs, i.e. any set of RDMs that is created by changing a single parameter. These models can be fit efficiently with another specialized fitting function, that first finds the best performing RDM in the set and then uses a bisection method for one dimensional optimization to find the best RDMs in the linear segments next to the start RDM. Bisection for one dimensional optimization converges quickly even without any gradient information.</p>
</sec>
<sec id="s2d1d">
<title>Linear weighted models</title>
<p>predict the RDM as a weighted sum of a set of basis RDMs. This type of combination primarily appears for feature reweighting models, which assume that there are underlying (groups of) features, whose relative contributions to the representational dissimilarities are unknown to the experimenter. If features are independently scaled by <italic>w<sub>i</sub></italic> the resulting euclidean RDM is the sum of feature RDMs weighted by <italic>w</italic><sup>2</sup>. Based on this observation, we usually want to impose a positivity constraint on the weights as there is no possible feature weighting that would push conditions together that are separated along a particular feature. Linear models require a separate real parameter for each basis RDM. Thus, they often require regularization to be applied successfully. To accommodate these different fitting and regularization methods we provide different fitting functions. In particular we provide linear algebra based methods that fit the RDM based on euclidean, cosine or correlation similarities (described below) and optimization based methods to include the positivity constraint and <italic>L</italic><sub>1</sub> and elastic net regularization.</p>
</sec>
<sec id="s2d1e">
<title>Arbitrary custom fitted models</title>
<p>These model types capture only a small selection of possible RDM models although they already expand the model zoo substantially beyond what earlier toolboxes provided. If users are keen to implement other model types our toolbox can be expanded easily. As long as the new model object implements the prediction and fitting methods, it can be used in all inference methods we provide in the toolbox.</p>
</sec>
</sec>
<sec id="s2d2">
<title>Model identification and evaluation</title>
<p>All flexible model types (i.e. all but the fixed model type) have parameters that need to be fitted to data. Fitting a model’s parameters to the data is known as model identification because it identifies the particular instance of the model (i.e. the settings of the parameters) that fit best. Because a fitted model is always somewhat overfitted to the fitting data, the goodness of fit on the data used for fitting is not an unbiased measure of model performance. Model evaluation therefore requires a test of the fitted model on data not used in model fitting. To make good use of limited data, we perform model fitting and performance evaluation in crossvalidation. This approach yields good estimates of the performance each fitted model achieves on new data, i.e. of the model’s generalization performance. The resulting performance estimates can also be compared between models that have different degrees of flexibility (e.g. a fixed model, a low-parametric model, and a high-parametric model).</p>
<p>We need to decide what type of generalization performance to require. If all our models are fixed, there is no fitting, and thus no overfitting to account for and cross-validation is not needed at all. In a case study of the tactile representations of the five digits of the right hand in the brain of a patient, we might fit and evaluate the models on separate brain-activity data sets in which each of the five fingers has been stimulated (same subject, same conditions). In a group study of sensory representations of digits, we might want our models to generalize to new subjects. We would then evaluate each model on data from different subjects acquired during stimulation of the same five fingers (different subjects, same conditions). In a case study of visual representations of face images in a single prosopagnosia patient, we might want our models to generalize to new face images (just like computer vision models must work on new stimuli) to test to what extent they can account for the representations underlying face perception in the patient (same subject, different conditions). Finally, in a group study of 24 people’s visual representations of object images, we might want our models to generalize to new subjects and new images simultaneously (different subjects, different conditions). The RSA3 toolbox supports model evaluation for all these types of generalization. The type of generalization should always be reported and carefully considered in interpreting the results.</p>
<sec id="s2d2a">
<title>Cross-validation</title>
<p>Once we use flexible models, we need to worry about overfitting, as more flexible models will fit data used for fitting their parameters better, even if that flexibility does not correspond to any real effect. This is a well known problem for statistical model comparisons of any kind and many correction methods for this problem exist. For RSA, the most common technique to solve this problem is cross-validation, where we split the data into groups, which are in turn used for evaluation, while all other data are used as a training set to fit the model parameters. This yields an estimate of model performance that does not overly favor flexible models anymore.</p>
<p>For RSA the overfitting argument applies to both subjects and stimuli. For cross-validation the question is how far the model should generalize. For example, if we use some stimuli for fitting and others for evaluation, good model performance requires the model to generalize to new stimuli. This is a separate question from the generalization we aim for with our bootstrapping procedures. By bootstrapping we aimed for our inference to generalize to new subjects or stimuli. In some situations our models may require subject or stimulus specific parameters, but we can consistently find parameters for each separate subject or stimulus set that work. If we ask our models to generalize to new subjects or stimuli, we do most likely want our inferences to generalize to new samples along that factor, too though.</p>
<p>In our toolbox we implement cross-validation in two steps: We first split the dataset into the cross-validation folds (see inference.sets_*) and then apply the cross-validation function (inference.crossval). Furthermore, the bootstrapping functions do contain additional parameters to implement cross-validation within the bootstrap (inference.eval_bootstrap_*).</p>
</sec>
</sec>
<sec id="s2d3">
<title>Model-comparative inference</title>
<p>To compare different models to each other, we need to estimate how uncertain our experimental results are. For our purposes, this uncertainty is quantified by a covariance matrix of the model evaluations over repetitions of the experiment. A key question for computing this covariance is how far we want our results to generalize, i.e. which aspects we assume to vary over the repetitions of the experiment. This generalization of our inference is different from the generalization we ask our models to perform and test with crossvalidation.</p>
<sec id="s2d3a">
<title>Inter-subject variability</title>
<p>The simplest type of generalization for RSA is to generalize to new subjects performing the same task with the same stimuli, because all evaluations we use are averages across subjects. The covariance of this average model performance then simply is <underline><sup>1</sup></underline> times the covariance of model evaluations over subjects for which we can use the standard sample estimates. In this situation, simple t-tests and rank-sum tests provide adequate tests to test whether two models perform significantly differently well. These tests are by far the most common type of inference used for RSA.</p>
</sec>
<sec id="s2d3b">
<title>Two-factor bootstrap</title>
<p>In most cases we also want to generalize to new stimuli used for evaluation [<xref ref-type="bibr" rid="c71">71</xref>, <xref ref-type="bibr" rid="c118">118</xref>]. As our model evaluations are not means across stimuli, we cannot easily compute the covariance of the model performances if we sampled new stimuli. Instead, we can resort to bootstrapping methods. If we want to generalize only to new stimuli, standard bootstrapping across conditions produces accurate estimates of the variance due to a random choice of conditions. Technically, bootstrapping subjects also reproduces the covariance due to the random sampling of subjects. There is no advantage of using the bootstrap over the direct formula for this variability though such that bootstrapping is not used for the variability due to subject choice in practice.</p>
<p>Once we want to generalize across both subjects and conditions, a naive bootstrap approach yields substantially too large variance estimates [<xref ref-type="bibr" rid="c71">71</xref>] due to roughly triple counting measurement noise and any other variance that is not due to the subject or stimulus choices. To counteract this effect, we can use a correction formula that results in fairly good variance estimates for this two factor bootstrap.</p>
<p>In the toolbox the bootstrap methods are available in the inference submodule as eval_bootstrap_* functions.</p>
<p>The bootstrap is compatible with crossvalidation to correct for overfitting of flexible models [<xref ref-type="bibr" rid="c71">71</xref>]. We refer to the combination as bootstrap wrapped crossvalidation. Due to the bootstrap resampling we usually cannot keep the crossvalidation folds constant across bootstrap samples, which requires another correction [<xref ref-type="bibr" rid="c71">71</xref>]. This functionality is available through the eval_dual_bootstrap function in the toolbox.</p>
</sec>
<sec id="s2d3c">
<title>Statistical tests</title>
<p>Once we have estimated the model performances and our uncertainty about them, we can use this information for frequentist statistical tests that test whether two models perform differently well, whether a model performs above chance and whether a model performs worse than the noise ceiling. In our toolbox, we mostly recommend using t-tests based on the means and the covariance of model performances, which can be estimated for different generalizations as discussed above. In the toolbox, this functionality is implemented as functions that apply to the results objects that all evaluation functions yield as outputs as these tests do not require much computation. The toolbox also supports classic rank based tests. One should note that these tests are based exclusively on the variance due to subjects and cannot be used to take the variance due to condition choice into account.</p>
</sec>
</sec>
<sec id="s2d4">
<title>Visualizing model comparisons</title>
<p>Visualization has an important role because it is needed to help researchers make sense of a complex set of results. Theoretical progress depends on comparing many models. The toolbox offers the functions plot_model_comparison and map_model_comparison, which visualize the quantitative and inferential results, revealing: (1) how well each model performs, (2) which other models each model significantly dominates, (3) which models explain significant variance, (4) which models leave significant explainable variance unexplained (do not approach the noise ceiling), (5) how similar the predictions made by the models are to each other, and (6) how similar activity patterns are to each other across multiple brain regions.</p>
<p><xref rid="fig5" ref-type="fig">Fig. 5</xref> shows simulation results visualized with the two visualization functions. All statistical tests are adjusted for multiple testing, controlling either the false-discovery rate or the familywise error rate. The <bold>bar plot</bold> (plot_model_comparison, <xref rid="fig5" ref-type="fig">Fig. 5a</xref>) integrates points (1) to (4). This provides an essential basic visualization integrating quantitative and inferential results. Key elements include the <italic>noise ceiling</italic> (gray bar), the “<italic>dew drops</italic>” (white and gray half circles indicating significant differences of model performance from 0 and from the lower bound of the noise ceiling, respectively), and the “<italic>model-dominance wings</italic>”, which show which other models each model dominates. The toolbox gives different options for visualizing the pairwise inferential comparisons. One option is “<italic>non-significance cliques</italic>”, which communicates all pairwise comparisons in terms of a minimal set of model cliques within which no differences are significant. Another option is “<italic>double arrows</italic>”, which communicates all pairwise comparisons by a minimal set of double arrows. Each of a set of horizontal double arrows indicates that all models to the left of it are significantly different from all models on the right of it. This approach is visually efficient (few elements) when the researcher chooses to plot the bars in ascending or descending order of model performance. These practical advances become important when a larger number of models is compared. For example, for just 40 models, there are 780 pairwise comparisons.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Fig. 5</label>
<caption><title>Visualization of model-comparative inference results.</title>
<p>Results of inferential analysis of simulated data. Ground-truth model is convolutional layer 2 (conv2) of AlexNet. All layers of AlexNet (blue to red) serve as candidate models. <bold>(a) Bar plot of RDM prediction accuracies.</bold> Model comparisons two-tailed, false-discovery rate controlled at <italic>q &lt;</italic> 0.01 (36 model-pair comparisons). Inference by bootstrap resampling (1,000 samples) of subjects. Error bars are 95% confidence intervals. One-sided comparisons of each model performance against 0 (white “dew drops” at the bottom indicate significant difference from 0) and against the lower-bound estimate of the noise ceiling (gray bar, gray dew drops indicate significant difference from the noise ceiling) are Bonferroni-corrected for 9 models. “Model-dominance wings” (top) indicate, for each model (dot in model color), which other models it significantly dominates (downward tick marks). <bold>(b) Model map.</bold> Same results as (<bold>a</bold>), but deviations of model predictions from the data are used to map the models around the data RDM with a modified multidimensional scaling (MDS). Inter-RDM distances measured by the Pearson correlation distance. MDS constrained to represent the deviations from the data RDM exactly (same information as in <bold>a</bold>) and the deviations among model RDMs (not shown in <bold>a</bold>) approximately.</p></caption>
<graphic xlink:href="655542v1_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Fig. 6</label>
<caption><title>Library overview</title>
<p>Structure of the library with key elements listed. The columns display the sub packages of rsatoolbox; corresponding from left-to-right with the typical order in which they come into play during an analysis. Light gray grouping boxes represent modules annotated with the respective module name. White boxes are key functions (lowercase) and classes (capitalized nouns).</p></caption>
<graphic xlink:href="655542v1_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The <bold>model map</bold> (function map_model_comparison, <xref rid="fig5" ref-type="fig">Fig. 5b</xref> contains all the information in the bar plot, points (1)-(4) above, but also shows approximately how similar the predictions of different models are to each other (5). Distances in this map reflect deviations among the RDMs. The central black dot is the data RDM. The noise ceiling becomes a “<italic>noise halo</italic>”. The best model (conv2 here) is, by definition, shown straight above the data RDM. The analysis correctly identified the true model (conv2) in this simulated data set. Gray arcs connect models that are not significantly different. Conv2 is not statistically distinct from the noise halo (vertical gray arc). The arrangement is computed with multidimensional scaling (MDS) using the metric stress criterion. However, the deviations of the model RDMs from the data RDM (radii) are constrained to be exactly represented. The scale bar shows the length corresponding to 0.2 Pearson correlation distance units, and its error bar shows the full range of %-errors incurred by mapping into 2D. We will refine this visualization by adding a radial scale (to replace the scale bar) and different options for the cost function that the mapping minimizes.</p>
</sec>
</sec>
<sec id="s2e">
<title>Step 5: Multiple testing across space and time</title>
<p>In some scenarios we do not have a specific hypothesis about where in the brain or when in time experimental effects may occur. This requires a more exploratory approach: instead of applying the above analysis steps to data from a particular brain region or time window of interest, we may opt to systematically scan brain space or time in search for effects. This exploratory approach involves repeated inference across spatial locations or time points. Below, we describe how the toolbox facilitates such analyses.</p>
<sec id="s2ea">
<title>Searchlight inferential mapping</title>
<p>In the spatial domain, a popular approach uses a “searchlight” to scan the brain for experimental effects [<xref ref-type="bibr" rid="c119">119</xref>, <xref ref-type="bibr" rid="c120">120</xref>]. A searchlight is a small analysis volume that covers a local neighborhood in brain space. The searchlight is systematically moved across the brain, centering it on each location in turn. This process repeats the analysis at each location and yields an inferential map showing where in the brain representational effects occur. This method promotes the discovery of brain regions that encode information about the experimental conditions (e.g., [<xref ref-type="bibr" rid="c112">112</xref>]) or whose representational content can be explained by a conceptual or computational model (e.g., [<xref ref-type="bibr" rid="c121">121</xref>, <xref ref-type="bibr" rid="c122">122</xref>]). Searchlight inferential mapping can also be applied on the cortical surface for better spatial selectivity and increased sensitivity to local information content [<xref ref-type="bibr" rid="c123">123</xref>]. The toolbox supports both volume and surface-based searchlight mapping.</p>
</sec>
<sec id="s2eb">
<title>Representational dynamics</title>
<p>In the temporal domain, it is common to use a sliding window approach to examine representational dynamics [<xref ref-type="bibr" rid="c38">38</xref>, <xref ref-type="bibr" rid="c42">42</xref>, <xref ref-type="bibr" rid="c124">124</xref>–<xref ref-type="bibr" rid="c126">126</xref>]. In this approach, the researcher defines a temporal search window and slides the window along the time axis of the data. For each time window, spatial response patterns are extracted from sensor or source space. This process repeats the analysis at each time point and yields an inferential time course showing when in time representational effects occur. This method, sometimes referred to as a (spatio)temporal searchlight or sliding window analysis, is useful for investigating dynamic changes in representational content, such as when representational distinctions emerge [<xref ref-type="bibr" rid="c38">38</xref>, <xref ref-type="bibr" rid="c124">124</xref>, <xref ref-type="bibr" rid="c127">127</xref>] or when a model best aligns with neural data [<xref ref-type="bibr" rid="c25">25</xref>, <xref ref-type="bibr" rid="c55">55</xref>, <xref ref-type="bibr" rid="c125">125</xref>, <xref ref-type="bibr" rid="c128">128</xref>].</p>
<p>The rsatoolbox does not contain internal methods to handle correct inference with many correlated results over space or time. There are well established methods for this kind of multiple comparisons problem (MCP) as implemented for example in Nipype [<xref ref-type="bibr" rid="c75">75</xref>] or MNEpython [<xref ref-type="bibr" rid="c76">76</xref>]. For analyses of representational geometries over time, we recommend applying such external MCP correction tools on the uncorrected similarity results obtained from our toolbox.</p>
</sec>
</sec>
</sec>
<sec id="s3">
<label>3</label><title>Discussion</title>
<p>This paper presents a new toolbox that implements RSA in Python, along with a third wave of methodological progress [<xref ref-type="bibr" rid="c70">70</xref>, <xref ref-type="bibr" rid="c71">71</xref>]. The toolbox consolidates previous developments and brings the following advances:
<list list-type="simple">
<list-item><p>1. <bold>Whitened RDM comparators.</bold> Whitened RDM comparators (whitened versions of the cosine and Pearson RDM correlation for biased and unbiased dissimilarity estimators) generalize the linear centered kernel alignment [<xref ref-type="bibr" rid="c63">63</xref>] to unbiased distance estimators, approximate a likelihood-based criterion for model selection, and provide near-optimal sensitivity to subtle differences between models [<xref ref-type="bibr" rid="c70">70</xref>].</p></list-item>
<list-item><p>2. <bold>Model-comparative inference generalizing to the populations of subjects and conditions.</bold> Fixed or parameterized models can now be compared with an inference procedure that generalizes to populations of subjects and/or conditions [<xref ref-type="bibr" rid="c71">71</xref>, <xref ref-type="bibr" rid="c129">129</xref>]. The key innovation is a new 2-factor bootstrap procedure for inference on parameterized models [<xref ref-type="bibr" rid="c71">71</xref>]. Models are fitted and evaluated in crossvalidation avoiding bias caused by overfitting to either subjects or conditions, while the inference can treat subject, condition, or both as random effects. The new procedure is substantially more powerful than the earlier double bootstrap [<xref ref-type="bibr" rid="c113">113</xref>, <xref ref-type="bibr" rid="c129">129</xref>] and has been validated with simulated and real data (Calcium imaging and fMRI) [<xref ref-type="bibr" rid="c71">71</xref>]. The new inference framework supports the novel whitened RDM comparators as well as a range of other RDM comparators, including rank-correlation coefficients, which are less sensitive, but have the advantage that they require weaker assumptions for valid inference.</p></list-item>
<list-item><p>3. <bold>Dissimilarity estimators for neural data.</bold> We introduce several dissimilarity estimators specifically designed for neural data (based on the Poisson distribution). In particular, the Poisson symmetrized-KL-divergence estimator and its crossvalidated variant provide improved RDM estimates on the basis of neural recording data.</p></list-item>
<list-item><p>4. <bold>Efficient rank-based model evaluation.</bold> We introduce Kendall’s <italic>ρ<sub>a</sub></italic> [<xref ref-type="bibr" rid="c130">130</xref>], a rarely used Spearman-type alternative to Kendall’s <italic>τ<sub>a</sub></italic>, which like the latter correctly treats models that predict ties [<xref ref-type="bibr" rid="c113">113</xref>], but is much faster to compute. The efficiency of <italic>ρ<sub>a</sub></italic> is essential when we are comparing many models or mapping inferential results across the brain with searchlight RSA.</p></list-item>
<list-item><p>5. <bold>Model refutation by comparison to the lower bound of the noise ceiling.</bold> Inferential model comparisons to the lower bound of the noise ceiling are now available</p></list-item>
<list-item><p>6. <bold>Better visualization of model comparisons.</bold> To more concisely present inferential results of all pairwise model comparisons, novel alternatives to “Nili bars” [<xref ref-type="bibr" rid="c113">113</xref>] include “Golan wings” and “double arrows” (<xref rid="fig5" ref-type="fig">Fig. 5</xref>) or “cliques” of models whose performance does not differ significantly. Furthermore comparisons to the noise ceiling and to 0 or chance-level performance are visualized using “dew drops” or “icicles”. The new options can more efficiently summarize all model-comparative inferential results, which becomes essential as the number of models grows.</p></list-item>
<list-item><p>7. <bold>Model map of performance, inferential comparisons, and model relationships.</bold> A novel “model map” (<xref rid="fig5" ref-type="fig">Fig. 5</xref>) visualizes the descriptive and inferential model comparisons in a 2D diagram, with the data RDM at the center within a noise halo (in place of the noise ceiling). Radial distance of each model exactly represents model prediction error, and the polar angles of the models approximately reflect the similarities among the models’ predicted RDMs. Connections between points link models whose performance does not differ significantly, defining all pairwise model-comparative inferential results.</p></list-item>
</list>
</p>
<sec id="s3a">
<label>3.1</label><title>Future plans</title>
<p>We will continue to maintain and further develop the rsatoolbox and invite others to include any coming developments into the toolbox.</p>
<p>There are a number of features that could be added to further improve convenience of use. In line with other analysis tools in the neuroscience ecosystem, we plan to encapsulate the toolbox into a RSAtoolbox BIDS app, and to provide a fully functional container image with a simple interface that can be slotted into existing data processing pipelines. In order to further support the reproducibility of projects based on rsatoolbox, such containers or apps will annotate the steps taken in a standard format [<xref ref-type="bibr" rid="c131">131</xref>, <xref ref-type="bibr" rid="c132">132</xref>]. Encapsulation will also require support for a larger variety of data formats for import.</p>
<p>Additionally, better visualizations will always remain a welcome addition. We will extend the model map into a 3D interactive visualization. We will develop a visualization that summarizes the relationships among multiple data RDMs estimates from neural populations in different brain regions and multiple model RDMs in a 2D or 3D map. Such a visualization will be extremely useful for giving the researcher a sense of the transformations of representational geometries across stages of representation in brains and models and about the global relationships between model and brain representations.</p>
<p>Finally, we expect that new additions and variations to RSA will still be developed. Whenever that happens, we aim to extend the toolbox to include such new additions. Such new developments could include: New methods for constructing RDMs, new methods for comparing RDMs, new methods to perform statistical inference, new APIs to handle different data inputs or outputs, and many more.</p>
</sec>
<sec id="s3b">
<label>3.2</label><title>Software development philosophy</title>
<p>To enable future additions and extensions to the toolbox and integrate it well with other tools in neuroscience, we converged on a number of principles for the development of the rsatoolbox:</p>
<p>We build our toolbox to include all commonly needed functionalities for RSA analyses, going from the preprocessed data to the final inference. To enable extensions, we aim to make the code as modular and reusable as possible. This will allow users to easily replace elements of their pipeline, and contribute new developments to the tool-box. As a standard for inclusion, we require all core statistical methods implemented in releases of the toolbox to be described and evaluated in peer-reviewed publications. More experimental approaches can be implemented in non-main branches, such that this criterion does not impede the speed of development, while providing a clear and transparent quality standard for the main release.</p>
<p>To enable community-driven development, we follow best practices in version control (Github), code review, continuous Integration [<xref ref-type="bibr" rid="c133">133</xref>], packaging (PyPi), and documentation (readthedocs). Users can submit queries, feature requests and bug reports by raising Issues on Github, which are closely tracked. These measures ensure accurate and reproducible analysis and enables discussions to reach a consensus about the best implementation for a given feature. Additionally, we document the current best practices in our documentation: Auto-generated API documentation is generated from in-code docstrings and key functionality is accompanied by narrative documentation as well as full demos in Jupyter Notebooks. The full documentation is then build and hosted at readthedocs (<ext-link ext-link-type="uri" xlink:href="https://rsatoolbox.readthedocs.io/">https://rsatoolbox.readthedocs.io/</ext-link>). Such complete, accessible documentation is key to the ease of use of software.</p>
<p>The library is shared under the MIT License (<ext-link ext-link-type="uri" xlink:href="https://opensource.org/licenses/">https://opensource.org/licenses/</ext-link> MIT), because of its simplicity, permissiveness and compatibility with other opensource software licenses.</p>
<p>There have been some earlier attempts at software that enables RSA methods: There is an initial RSA library for MATLAB [<xref ref-type="bibr" rid="c113">113</xref>]. In addition, some steps of RSA analysis like pattern extraction and the calculation of simple RDMs are part of many neuroscience packages, like: pyMVPA [<xref ref-type="bibr" rid="c134">134</xref>], CosmoMVPA [<xref ref-type="bibr" rid="c135">135</xref>], MVPA-light [<xref ref-type="bibr" rid="c136">136</xref>]) and NeuroRA [<xref ref-type="bibr" rid="c137">137</xref>]. Furthermore, a Bayes approach to RSA is available in BrainIAK [<xref ref-type="bibr" rid="c138">138</xref>]. However, a comprehensive library that incorporates new developments was missing.</p>
</sec>
<sec id="s3c">
<label>3.3</label><title>Other approaches to comparing representations</title>
<p>There are three commonly used alternative methods for comparing representations, which have some underlying relationships with RSA, but are usually viewed as distinct approaches [<xref ref-type="bibr" rid="c61">61</xref>]:</p>
<p><italic>Encoding models</italic> are explicit models to predict one representation from another [<xref ref-type="bibr" rid="c139">139</xref>, <xref ref-type="bibr" rid="c140">140</xref>]. The advantage of this approach is that it yields explicit predictions for the responses to new conditions, which can be evaluated just as any other prediction of data would be. The first drawback of this approach is the complexity of the encoding model. Even linear models become so flexible in high dimensions that even our largest datasets are insufficient to strongly constrain the parameters of the encoding model. Thus, regularization, dimensionality reduction and similar techniques are necessary to make good predictions [141, e.g.] and these seemingly minor choices can substantially change the results. Furthermore, fitting the encoding models can become computationally expensive and there is some debate about the adequate level of flexibility encoding models should have [<xref ref-type="bibr" rid="c15">15</xref>]. The second main drawback of encoding models is that they yield asymmetric results, i.e. prediction of a first model from a second model may work well while prediction from the first one to the second works barely above chance. This can be acceptable behavior when we predict neural data from a model, but for comparisons between models or between data sets this is a clear disadvantage [<xref ref-type="bibr" rid="c62">62</xref>]. Nonetheless, encoding models remain a popular and sensible option for the evaluation of models that predict brain data.</p>
<p>In Pattern Component Modelling [PCM, 64] the feature weights are instead treated as random variables. PCM evaluates the likelihood of the RM given the distribution of activity profiles; the response of a measurement channel to each of the conditions. In effect the RM is described by the second moment of these activity profiles. PCM excels at model selection, but requires strong assumptions on the generative model. It arguably also lacks an intuitively understandable component statistic.</p>
<p>In machine learning, comparisons are more usually made based on the kernel matrices of representations [63, centered kernel alignment]. Due to the strong connection between kernel and distances matrices [<xref ref-type="bibr" rid="c70">70</xref>], these methods can be seen as part of the same family of methods. Indeed, we implement centered kernel alignment (CKA, the main measure of this class) in our toolbox.</p>
<p>Beyond these main approaches there a few additional ones that do not fall into one of these categories. Two methods that differ from methods that are invariance to rotation of the neural space are the Soft Matching Distance [<xref ref-type="bibr" rid="c142">142</xref>] a metric sensitive to the tuning of individual neurons, and tuning reorientation [<xref ref-type="bibr" rid="c143">143</xref>], a measure of alignment complexity.</p>
<p>Which metrics are best used under what circumstances is still debated [<xref ref-type="bibr" rid="c144">144</xref>, <xref ref-type="bibr" rid="c145">145</xref>] and researchers are actively testing and comparing methods against each other. Thus, we follow an inclusive strategy for our toolbox and will in the future keep integrating new promising metrics.</p>
</sec>
<sec id="s3d">
<label>3.4</label><title>Conclusion</title>
<p>Our new <italic>rsatoolbox</italic> implements all state-of-the-art methods of representational similarity analysis and constitutes the open-source development project where this methodology will be further developed. It has data reading functions to import behavioral, EEG/MEG and fMRI data into structured objects. RDMs can then be computed from these and subsequently manipulated along various keys and dimensions. These RDMs can then be compared and used to evaluate models with proper statistics. Visualization functions make it easy to plot the RDMs and results. Thus, rsatoolbox gives researchers access to some of the latest methods in RSA, without a steep learning curve, while potentially making their analyses faster. By building a community project we aim for RSAtoolbox to be the standard starting point of any RSA analysis.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>Many thanks to everyone who has contributed ideas, code, documentation, or feedback to rsatoolbox. JB is supported by a UKRI BBSRC grant (BB/X008428/1) awarded to Faisal Mushtaq. We thank all the contributors to open-source software without which we could not have made rsatoolbox, in particular Python, NumPy, scipy, cython, conda-forge and many others.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Allen</surname>, <given-names>E. J.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>A massive 7T fMRI dataset to bridge cognitive neuroscience and artificial intelligence</article-title>. <source>Nature neuroscience</source> <volume>25</volume>, <fpage>116</fpage>–<lpage>126</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hebart</surname>, <given-names>M. N.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>THINGS-data, a multimodal collection of large-scale datasets for investigating object representations in human brain and behavior</article-title>. <source>eLife</source> <volume>12</volume> (<year>2023</year>).</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kupers</surname>, <given-names>E. R.</given-names></string-name>, <string-name><surname>Knapen</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Merriam</surname>, <given-names>E. P.</given-names></string-name> &amp; <string-name><surname>Kay</surname>, <given-names>K. N</given-names></string-name></person-group>. <article-title>Principles of intensive human neuroimaging</article-title>. <source>Trends in neurosciences</source> <volume>47</volume>, <fpage>856</fpage>–<lpage>864</lpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>de Vries</surname>, <given-names>S. E. J.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>A large-scale standardized physiological survey reveals functional organization of the mouse visual cortex</article-title>. <source>Nature neuroscience</source> <volume>23</volume>, <fpage>138</fpage>–<lpage>151</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>International Brain</given-names> <surname>Laboratory</surname></string-name> <etal>et al.</etal></person-group> <article-title>Standardized and reproducible measurement of decision-making in mice</article-title>. <source>eLife</source> <volume>10</volume> (<year>2021</year>).</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Papale</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Self</surname>, <given-names>M. W.</given-names></string-name> &amp; <string-name><surname>Roelfsema</surname>, <given-names>P. R</given-names></string-name></person-group>. <article-title>An extensive dataset of spiking activity to reveal the syntax of the ventral stream</article-title>. <source>Neuron</source> <volume>113</volume>, <fpage>539</fpage>–<lpage>553.e5</lpage> (<year>2025</year>).</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Churchland</surname>, <given-names>A. K.</given-names></string-name> &amp; <string-name><surname>Abbott</surname>, <given-names>L. F</given-names></string-name></person-group>. <article-title>Conceptual and technical advances define a key moment for theoretical neuroscience</article-title>. <source>Nature neuroscience</source> <volume>19</volume>, <fpage>348</fpage>–<lpage>349</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Douglas</surname>, <given-names>P. K</given-names></string-name></person-group>. <article-title>Cognitive computational neuroscience</article-title>. <source>Nature neuroscience</source> <volume>21</volume>, <fpage>1148</fpage>–<lpage>1160</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Naselaris</surname>, <given-names>T.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Cognitive computational neuroscience: A new conference for an emerging discipline</article-title>. <source>Trends in cognitive sciences</source> <volume>22</volume>, <fpage>365</fpage>–<lpage>367</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krizhevsky</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Sutskever</surname>, <given-names>I.</given-names></string-name> &amp; <string-name><surname>Hinton</surname>, <given-names>G. E</given-names></string-name></person-group>. <article-title>ImageNet classification with deep convolutional neural networks</article-title>. <source>Communications of the ACM</source> <volume>60</volume>, <fpage>84</fpage>–<lpage>90</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>LeCun</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Bengio</surname>, <given-names>Y.</given-names></string-name> &amp; <string-name><surname>Hinton</surname>, <given-names>G.</given-names></string-name></person-group> <article-title>Deep learning</article-title>. <source>Nature</source> <volume>521</volume>, <fpage>436</fpage>–<lpage>444</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hosseini</surname>, <given-names>E. A.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Artificial neural network language models predict human brain responses to language even after a developmentally realistic amount of training</article-title>. <source>Neurobiology of language (Cambridge, Mass.)</source> <volume>5</volume>, <fpage>43</fpage>–<lpage>63</lpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Dapello</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Simulating a primary visual cortex at the front of CNNs improves robustness to image perturbations</article-title>. <source>bioRxiv</source> 2020.06.16.154542 (<year>2020</year>).</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Baker</surname>, <given-names>B.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>What makes representations “useful”?</article-title> <source>Cognitive Computational Neuroscience</source> <volume>2021</volume> (<year>2021</year>).</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Diedrichsen</surname>, <given-names>J</given-names></string-name></person-group>. <article-title>Peeling the Onion of Brain Representations</article-title>. <source>Annual review of neuroscience</source> <volume>42</volume>, <fpage>407</fpage>–<lpage>432</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Thagard</surname>, <given-names>P.</given-names></string-name></person-group> <article-title>Cognitive Science</article-title>. <source>Stanford Encyclopedia of Philosophy Archive</source> <ext-link ext-link-type="uri" xlink:href="https://plato.stanford.edu/archives/win2023/entries/cognitive-science/">https://plato.stanford.edu/archives/win2023/entries/cognitive-science/</ext-link> (<year>2023</year>).</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Mur</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Bandettini</surname>, <given-names>P</given-names></string-name></person-group>. <article-title>Representational similarity analysis - connecting the branches of systems neuroscience</article-title>. <source>Frontiers in systems neuroscience</source> <volume>2</volume>, <fpage>4</fpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Kievit</surname>, <given-names>R. A</given-names></string-name></person-group>. <article-title>Representational geometry: integrating cognition, computation, and the brain</article-title>. <source>Trends in cognitive sciences</source> <volume>17</volume>, <fpage>401</fpage>–<lpage>412</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Torgerson</surname>, <given-names>W. S.</given-names></string-name></person-group> <source>Theory and methods of scaling</source> (<publisher-name>Wiley, Oxford, England</publisher-name>, <year>1958</year>).</mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shepard</surname>, <given-names>R. N</given-names></string-name></person-group>. <article-title>The analysis of proximities: Multidimensional scaling with an unknown distance function. I</article-title>. <source>Psychometrika</source> <volume>27</volume>, <fpage>125</fpage>–<lpage>140</lpage> (<year>1962</year>).</mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shepard</surname>, <given-names>R. N.</given-names></string-name> &amp; <string-name><surname>Chipman</surname>, <given-names>S</given-names></string-name></person-group>. <article-title>Second-order isomorphism of internal representations: Shapes of states</article-title>. <source>Cognitive psychology</source> <volume>1</volume>, <fpage>1</fpage>–<lpage>17</lpage> (<year>1970</year>).</mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Edelman</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Grill-Spector</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Kushnir</surname>, <given-names>T.</given-names></string-name> &amp; <string-name><surname>Malach</surname>, <given-names>R</given-names></string-name></person-group>. <article-title>Toward direct visualization of the internal shape representation space by fMRI</article-title>. <source>Psychobiology</source> <volume>26</volume>, <fpage>309</fpage>–<lpage>321</lpage> (<year>1998</year>).</mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Uhrig</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Jarraya</surname>, <given-names>B.</given-names></string-name> &amp; <string-name><surname>Dehaene</surname>, <given-names>S</given-names></string-name></person-group>. <article-title>Representation of numerical and sequential patterns in macaque and human brains</article-title>. <source>Current biology: CB</source> <volume>25</volume>, <fpage>1966</fpage>–<lpage>1974</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cohen</surname>, <given-names>M. A.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Representational similarity precedes category selectivity in the developing ventral visual pathway</article-title>. <source>NeuroImage</source> <volume>197</volume>, <fpage>565</fpage>–<lpage>574</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c25"><label>[25]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cichy</surname>, <given-names>R. M.</given-names></string-name>, <string-name><surname>Pantazis</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>Oliva</surname>, <given-names>A</given-names></string-name></person-group>. <article-title>Similarity-Based Fusion of MEG and fMRI Reveals Spatio-Temporal Dynamics in Human Cortex During Visual Object Recognition</article-title>. <source>Cerebral cortex</source> <volume>26</volume>, <fpage>3563</fpage>–<lpage>3579</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c26"><label>[26]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kaneshiro</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Perreau Guimaraes</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Kim</surname>, <given-names>H.-S.</given-names></string-name>, <string-name><surname>Norcia</surname>, <given-names>A. M.</given-names></string-name> &amp; <string-name><surname>Suppes</surname>, <given-names>P</given-names></string-name></person-group>. <article-title>A Representational Similarity Analysis of the dynamics of object processing using single-trial EEG classification</article-title>. <source>PloS one</source> <volume>10</volume>, <fpage>e0135697</fpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c27"><label>[27]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ejaz</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Hamada</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Diedrichsen</surname>, <given-names>J</given-names></string-name></person-group>. <article-title>Hand use predicts the structure of representations in sensorimotor cortex</article-title>. <source>Nature neuroscience</source> <volume>18</volume>, <fpage>1034</fpage>–<lpage>1040</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c28"><label>[28]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Devereux</surname>, <given-names>B. J.</given-names></string-name>, <string-name><surname>Clarke</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Marouchos</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Tyler</surname>, <given-names>L. K</given-names></string-name></person-group>. <article-title>Representational similarity analysis reveals commonalities and differences in the semantic processing of words and objects</article-title>. <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source> <volume>33</volume>, <fpage>18906</fpage>–<lpage>18916</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c29"><label>[29]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhao</surname>, <given-names>L.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Orthographic and phonological representations in the fusiform cortex</article-title>. <source>Cerebral cortex (New York, N.Y.: 1991)</source> <volume>27</volume>, <fpage>5197</fpage>–<lpage>5210</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c30"><label>[30]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Giordano</surname>, <given-names>B. L.</given-names></string-name>, <string-name><surname>McAdams</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Zatorre</surname>, <given-names>R. J.</given-names></string-name>, <string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Belin</surname>, <given-names>P</given-names></string-name></person-group>. <article-title>Abstract encoding of auditory objects in cortical activity patterns</article-title>. <source>Cerebral cortex</source> <volume>23</volume>, <fpage>2025</fpage>–<lpage>2037</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c31"><label>[31]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Majewska</surname>, <given-names>O.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Semantic data set construction from human clustering and spatial arrangement</article-title>. <source>Computational linguistics (Association for Computational Linguistics)</source> <volume>47</volume>, <fpage>69</fpage>–<lpage>116</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c32"><label>[32]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Levitan</surname>, <given-names>C. A.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Cross-cultural color-odor associations</article-title>. <source>PloS one</source> <volume>9</volume>, <fpage>e101651</fpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c33"><label>[33]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pauli</surname>, <given-names>R.</given-names></string-name> &amp; <string-name><surname>Lockwood</surname>, <given-names>P. L</given-names></string-name></person-group>. <article-title>The computational psychiatry of antisocial behaviour and psychopathy</article-title>. <source>Neuroscience and biobehavioral reviews</source> <volume>145</volume>, <issue>104995</issue> (<year>2023</year>).</mixed-citation></ref>
<ref id="c34"><label>[34]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dobs</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Isik</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Pantazis</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>Kanwisher</surname>, <given-names>N</given-names></string-name></person-group>. <article-title>How face perception unfolds over time</article-title>. <source>Nature communications</source> <volume>10</volume>, <fpage>1258</fpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c35"><label>[35]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Haushofer</surname> <given-names>J.</given-names></string-name>, <string-name><surname>Livingstone</surname> <given-names>M. S.</given-names></string-name> &amp; <string-name><surname>Kanwisher</surname> <surname>N.</surname></string-name>, </person-group> <article-title>Multivariate patterns in object-selective cortex dissociate perceptual and physical shape similarity</article-title>. <source>PLoS biology</source> <volume>6</volume>, <elocation-id>e187</elocation-id> (<year>2008</year>).</mixed-citation></ref>
<ref id="c36"><label>[36]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schurger</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Pereira</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Treisman</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Cohen</surname>, <given-names>J. D</given-names></string-name></person-group>. <article-title>Reproducibility distinguishes conscious from nonconscious neural representations</article-title>. <source>Science</source> <volume>327</volume>, <fpage>97</fpage>–<lpage>99</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c37"><label>[37]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Proklova</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Kaiser</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>Peelen</surname>, <given-names>M. V</given-names></string-name></person-group>. <article-title>Disentangling representations of object shape and object category in human visual cortex: The animate-inanimate distinction</article-title>. <source>Journal of cognitive neuroscience</source> <volume>28</volume>, <fpage>680</fpage>–<lpage>692</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c38"><label>[38]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carlson</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Tovar</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Alink</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Kriegeskorte</surname>, <given-names>N</given-names></string-name></person-group>. <article-title>Representational dynamics of object vision: the first 1000 ms</article-title>. <source>Journal of vision</source> <volume>13</volume> (<year>2013</year>).</mixed-citation></ref>
<ref id="c39"><label>[39]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xue</surname>, <given-names>G.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Greater neural pattern similarity across repetitions is associated with better memory</article-title>. <source>Science</source> <volume>330</volume>, <fpage>97</fpage>–<lpage>101</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c40"><label>[40]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wimber</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Alink</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Charest</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Anderson</surname>, <given-names>M. C</given-names></string-name></person-group>. <article-title>Retrieval induces adaptive forgetting of competing memories via cortical pattern suppression</article-title>. <source>Nature neuroscience</source> <volume>18</volume>, <fpage>582</fpage>–<lpage>589</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c41"><label>[41]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Diedrichsen</surname>, <given-names>J</given-names></string-name></person-group>. <article-title>Inferring brain-computational mechanisms with models of activity measurements</article-title>. <source>Philosophical transactions of the Royal Society of London. Series B, Biological sciences</source> <volume>371</volume>, <issue>20160278</issue> (<year>2016</year>).</mixed-citation></ref>
<ref id="c42"><label>[42]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Freiwald</surname>, <given-names>W. A.</given-names></string-name> &amp; <string-name><surname>Tsao</surname>, <given-names>D. Y</given-names></string-name></person-group>. <article-title>Functional compartmentalization and viewpoint generalization within the macaque face-processing system</article-title>. <source>Science (New York)</source> <volume>330</volume>, <fpage>845</fpage>–<lpage>851</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c43"><label>[43]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ringach</surname>, <given-names>D</given-names></string-name></person-group>. <article-title>The geometry of masking in neural populations</article-title>. <source>Nature communications</source> <volume>10</volume>, <fpage>4879</fpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c44"><label>[44]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yamins</surname>, <given-names>D. L. K.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Performance-optimized hierarchical models predict neural responses in higher visual cortex</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source> <volume>111</volume>, <fpage>8619</fpage>–<lpage>8624</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c45"><label>[45]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Sadeh</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Clopath</surname>, <given-names>C</given-names></string-name></person-group>. <article-title>Contribution of behavioural variability to representational drift</article-title>. <source>bioRxiv</source> (<year>2022</year>).</mixed-citation></ref>
<ref id="c46"><label>[46]</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Takeda</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Abe</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Kitazono</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Oizumi</surname>, <given-names>M</given-names></string-name></person-group>. <article-title>Unsupervised alignment reveals structural commonalities and differences in neural representations of natural scenes across individuals and brain areas</article-title>. <conf-name>ICLR 2024 Workshop on Representational Alignment</conf-name> (<year>2024</year>).</mixed-citation></ref>
<ref id="c47"><label>[47]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Khaligh-Razavi</surname>, <given-names>S.-M.</given-names></string-name> &amp; <string-name><surname>Kriegeskorte</surname>, <given-names>N</given-names></string-name></person-group>. <article-title>Deep supervised, but not unsupervised, models may explain IT cortical representation</article-title>. <source>PLoS computational biology</source> <volume>10</volume>, <fpage>e1003915</fpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c48"><label>[48]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mehrer</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Spoerer</surname>, <given-names>C. J.</given-names></string-name>, <string-name><surname>Kriegeskorte</surname>, <given-names>T. C.</given-names></string-name>, <string-name><surname>Nikolaus</surname></string-name> &amp; <string-name><surname>Kietzmann</surname></string-name></person-group>. <article-title>Individual differences among deep neural network models</article-title>. <source>Nature Communications</source> <volume>11</volume> (<year>2020</year>).</mixed-citation></ref>
<ref id="c49"><label>[49]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kriegeskorte</surname>, <given-names>N</given-names></string-name></person-group>. <article-title>Deep neural networks: A new framework for modeling biological vision and brain information processing</article-title>. <source>Annual review of vision science</source> <volume>1</volume>, <fpage>417</fpage>–<lpage>446</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c50"><label>[50]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yamins</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>DiCarlo</surname>, <given-names>J</given-names></string-name></person-group>. <article-title>Using goal-driven deep learning models to understand sensory cortex</article-title>. <source>Nature neuroscience</source> <volume>19</volume>, <fpage>356</fpage>–<lpage>365</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c51"><label>[51]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname>, <given-names>Y.</given-names></string-name> &amp; <string-name><surname>Vaziri-Pashkam</surname>, <given-names>M</given-names></string-name></person-group>. <article-title>Limits to visual representational correspondence between convolutional neural networks and the human brain</article-title>. <source>Nature communications</source> <volume>12</volume>, <fpage>2065</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c52"><label>[52]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Konkle</surname>, <given-names>T.</given-names></string-name> &amp; <string-name><surname>Alvarez</surname>, <given-names>G. A</given-names></string-name></person-group>. <article-title>A self-supervised domain-general learning framework for human ventral stream representation</article-title>. <source>Nature communications</source> (<year>2022</year>).</mixed-citation></ref>
<ref id="c53"><label>[53]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cichy</surname>, <given-names>R. M.</given-names></string-name> &amp; <string-name><surname>Kaiser</surname>, <given-names>D</given-names></string-name></person-group>. <article-title>Deep neural networks as scientific models</article-title>. <source>Trends in cognitive sciences</source> <volume>23</volume>, <fpage>305</fpage>–<lpage>317</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c54"><label>[54]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Storrs</surname>, <given-names>K. R.</given-names></string-name>, <string-name><surname>Anderson</surname>, <given-names>B. L.</given-names></string-name> &amp; <string-name><surname>Fleming</surname>, <given-names>R. W</given-names></string-name></person-group>. <article-title>Unsupervised learning predicts human perception and misperception of gloss</article-title>. <source>Nature human behaviour</source> <volume>5</volume>, <fpage>1402</fpage>– <lpage>1417</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c55"><label>[55]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kietzmann</surname>, <given-names>T. C.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Recurrence is required to capture the representational dynamics of the human visual system</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>116</volume>, <fpage>21854</fpage>–<lpage>21863</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c56"><label>[56]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Groen</surname>, <given-names>I. I.</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Distinct contributions of functional and deep neural network features to representational similarity of scenes in human brain and behavior</article-title>. <source>eLife</source> <volume>7</volume> (<year>2018</year>).</mixed-citation></ref>
<ref id="c57"><label>[57]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Doerig</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>The neuroconnectionist research programme</article-title>. <source>Nature reviews. Neuroscience</source> <volume>24</volume>, <fpage>431</fpage>–<lpage>450</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c58"><label>[58]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Golan</surname>, <given-names>T.</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Deep neural networks are not a single hypothesis but a language for expressing computational hypotheses</article-title>. <source>The behavioral and brain sciences</source> <volume>46</volume>, <fpage>e392</fpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c59"><label>[59]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Wei</surname>, <given-names>X.-X.</given-names></string-name></person-group> <article-title>Neural tuning and representational geometry</article-title>. <source>arXiv</source> (<year>2021</year>).</mixed-citation></ref>
<ref id="c60"><label>[60]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Douglas</surname>, <given-names>P. K.</given-names></string-name></person-group> <article-title>Interpreting encoding and decoding models</article-title>. <source>Current opinion in neurobiology</source> <volume>55</volume>, <fpage>167</fpage>–<lpage>179</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c61"><label>[61]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Diedrichsen</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Kriegeskorte</surname>, <given-names>N</given-names></string-name></person-group>. <article-title>Representational models: A common framework for understanding encoding, pattern-component, and representational-similarity analysis</article-title>. <source>PLoS computational biology</source> <volume>13</volume>, <fpage>e1005508</fpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c62"><label>[62]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Williams</surname>, <given-names>A. H.</given-names></string-name>, <string-name><surname>Kunz</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Kornblith</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Linderman</surname>, <given-names>S. W</given-names></string-name></person-group>. <article-title>Generalized shape metrics on neural representations</article-title>. <source>Advances in neural information processing systems</source> <volume>34</volume>, <fpage>4738</fpage>–<lpage>4750</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c63"><label>[63]</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Kornblith</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Norouzi</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>H.</given-names></string-name> &amp; <string-name><surname>Hinton</surname>, <given-names>G. E</given-names></string-name></person-group>. <article-title>Similarity of neural network representations revisited</article-title>. <conf-name>International Conference on Machine Learning</conf-name>, <fpage>3519</fpage>–<lpage>3529</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c64"><label>[64]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Diedrichsen</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Ridgway</surname>, <given-names>G. R.</given-names></string-name>, <string-name><surname>Friston</surname>, <given-names>K. J.</given-names></string-name> &amp; <string-name><surname>Wiestler</surname>, <given-names>T</given-names></string-name></person-group>. <article-title>Comparing the similarity and spatial structure of neural representations: a pattern-component model</article-title>. <source>NeuroImage</source> <volume>55</volume>, <fpage>1665</fpage>–<lpage>1678</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c65"><label>[65]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Walther</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Reliability of dissimilarity measures for multi-voxel pattern analysis</article-title>. <source>NeuroImage</source> <volume>137</volume>, <fpage>188</fpage>–<lpage>200</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c66"><label>[66]</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>Bossio</given-names> <surname>Botero</surname></string-name>, <string-name><given-names>V.</given-names> <surname>&amp; Kriegeskorte</surname></string-name></person-group>, N. <article-title>When do measured representational distances reflect the neural representational geometry</article-title> (<year>2024</year>). <comment>In prep</comment>.</mixed-citation></ref>
<ref id="c67"><label>[67]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shahbazi</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Shirali</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Aghajan</surname>, <given-names>H.</given-names></string-name> &amp; <string-name><surname>Nili</surname>, <given-names>H</given-names></string-name></person-group>. <article-title>Using distance on the Riemannian manifold to compare representations in brain and in models</article-title>. <source>NeuroImage</source> <volume>239</volume>, <fpage>118271</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c68"><label>[68]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Brown</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Farivar</surname>, <given-names>R.</given-names></string-name></person-group> <article-title>The Topology of Representational Geometry</article-title>. <source>bioRxiv</source> <elocation-id>2024.02.16.579506</elocation-id> (<year>2024</year>).</mixed-citation></ref>
<ref id="c69"><label>[69]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Lin</surname>, <given-names>B.</given-names></string-name> &amp; <string-name><surname>Kriegeskorte</surname>, <given-names>N</given-names></string-name></person-group>. <article-title>The Topology and Geometry of Neural Representations</article-title>. <source>arXiv</source> (<year>2023</year>).</mixed-citation></ref>
<ref id="c70"><label>[70]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Diedrichsen</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Comparing representational geometries using whitened unbiased-distance-matrix similarity. <italic>Neurons, Behavior</italic></article-title>, <source>Data analysis, and Theory</source> <volume>5</volume> (<year>2021</year>).</mixed-citation></ref>
<ref id="c71"><label>[71]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schütt</surname>, <given-names>H. H.</given-names></string-name>, <string-name><surname>Kipnis</surname>, <given-names>A. D.</given-names></string-name>, <string-name><surname>Diedrichsen</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Kriegeskorte</surname>, <given-names>N</given-names></string-name></person-group>. <article-title>Statistical inference on representational geometries</article-title>. <source>eLife</source> <volume>12</volume>, <elocation-id>e82566</elocation-id> (<year>2023</year>). <pub-id pub-id-type="doi">10.7554/eLife.82566</pub-id></mixed-citation></ref>
<ref id="c72"><label>[72]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Diedrichsen</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Yokoi</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Arbuckle</surname>, <given-names>S. A</given-names></string-name></person-group>. <article-title>Pattern component modeling: A flexible approach for understanding the representational structure of brain activity patterns</article-title>. <source>NeuroImage</source> <volume>180</volume>, <fpage>119</fpage>–<lpage>133</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c73"><label>[73]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van Rossum</surname>, <given-names>G.</given-names></string-name> &amp; <string-name><surname>de Boer</surname>, <given-names>J</given-names></string-name></person-group>. <article-title>Interactively testing remote servers using the Python programming language</article-title>. <source>CWi Quarterly</source> <volume>4</volume>, <fpage>283</fpage>–<lpage>303</lpage> (<year>1991</year>).</mixed-citation></ref>
<ref id="c74"><label>[74]</label><mixed-citation publication-type="software"><person-group person-group-type="author"><string-name><surname>Brett</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>nipy/nibabel</article-title>. <version>5.2.1</version>. <source>Zenodo</source> (<year>2024</year>).</mixed-citation></ref>
<ref id="c75"><label>[75]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gorgolewski</surname>, <given-names>K.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Nipype: a flexible, lightweight and extensible neuroimaging data processing framework in python</article-title>. <source>Frontiers in neuroinformatics</source> <volume>5</volume>, <issue>13</issue> (<year>2011</year>).</mixed-citation></ref>
<ref id="c76"><label>[76]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gramfort</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>MEG and EEG data analysis with MNE-Python</article-title>. <source>Frontiers in neuroscience</source> <volume>7</volume>, <fpage>267</fpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c77"><label>[77]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Esteban</surname>, <given-names>O.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>fMRIPrep: a robust preprocessing pipeline for functional MRI</article-title>. <source>Nature methods</source> <volume>16</volume>, <fpage>111</fpage>–<lpage>116</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c78"><label>[78]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Teeters</surname>, <given-names>J. L.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Neurodata Without Borders: Creating a common data format for neurophysiology</article-title>. <source>Neuron</source> <volume>88</volume>, <fpage>629</fpage>–<lpage>634</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c79"><label>[79]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Rübel</surname> <given-names>O.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>NWB:N 2.0: An Accessible Data Standard for Neurophysiology</article-title>. <source>BioRxiv</source> <fpage>523035</fpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c80"><label>[80]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rübel</surname>, <given-names>O.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>The Neurodata Without Borders ecosystem for neurophysio-logical data science</article-title>. <source>eLife</source> <volume>11</volume>, <elocation-id>e78362</elocation-id> (<year>2022</year>). <pub-id pub-id-type="doi">10.7554/eLife.78362</pub-id></mixed-citation></ref>
<ref id="c81"><label>[81]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Harris</surname>, <given-names>C. R.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Array programming with NumPy</article-title>. <source>Nature</source> <volume>585</volume>, <fpage>357</fpage>–<lpage>362</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c82"><label>[82]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Garyfallidis</surname>, <given-names>E.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Dipy, a library for the analysis of diffusion MRI data</article-title>. <source>Frontiers in neuroinformatics</source> <volume>8</volume>, <fpage>8</fpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c83"><label>[83]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Abraham</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Machine learning for neuroimaging with scikit-learn</article-title>. <source>Frontiers in neuroinformatics</source> <volume>8</volume>, <issue>14</issue> (<year>2014</year>).</mixed-citation></ref>
<ref id="c84"><label>[84]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Moore</surname>, <given-names>G. P.</given-names></string-name>, <string-name><surname>Perkel</surname>, <given-names>D. H.</given-names></string-name> &amp; <string-name><surname>Segundo</surname>, <given-names>J. P</given-names></string-name></person-group>. <article-title>Statistical analysis and functional interpretation of neuronal spike data</article-title>. <source>Annual review of physiology</source> <volume>28</volume>, <fpage>493</fpage>–<lpage>522</lpage> (<year>1966</year>).</mixed-citation></ref>
<ref id="c85"><label>[85]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Maimon</surname>, <given-names>G.</given-names></string-name> &amp; <string-name><surname>Assad</surname>, <given-names>J. A</given-names></string-name></person-group>. <article-title>Beyond Poisson: increased spike-time regularity across primate parietal cortex</article-title>. <source>Neuron</source> <volume>62</volume>, <fpage>426</fpage>–<lpage>440</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c86"><label>[86]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shinomoto</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Shima</surname>, <given-names>K.</given-names></string-name> &amp; <string-name><surname>Tanji</surname>, <given-names>J</given-names></string-name></person-group>. <article-title>Differences in spiking patterns among cortical neurons</article-title>. <source>Neural computation</source> <volume>15</volume>, <fpage>2823</fpage>–<lpage>2842</lpage> (<year>2003</year>).</mixed-citation></ref>
<ref id="c87"><label>[87]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goris</surname>, <given-names>R. L. T.</given-names></string-name>, <string-name><surname>Movshon</surname>, <given-names>J. A.</given-names></string-name> &amp; <string-name><surname>Simoncelli</surname>, <given-names>E. P.</given-names></string-name></person-group> <article-title>Partitioning neuronal variability</article-title>. <source>Nature neuroscience</source> <volume>17</volume>, <fpage>858</fpage>–<lpage>865</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c88"><label>[88]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goris</surname>, <given-names>R. L. T.</given-names></string-name>, <string-name><surname>Coen-Cagli</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>K. D.</given-names></string-name>, <string-name><surname>Priebe</surname>, <given-names>N. J.</given-names></string-name> &amp; <string-name><surname>Lengyel</surname>, <given-names>M</given-names></string-name></person-group>. <article-title>Response sub-additivity and variability quenching in visual cortex</article-title>. <source>Nature reviews. Neuroscience</source> <volume>25</volume>, <fpage>237</fpage>–<lpage>252</lpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c89"><label>[89]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yu</surname>, <given-names>B. M.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity</article-title>. <source>Advances in Neural Information Processing Systems</source> <volume>21</volume> (<year>2008</year>).</mixed-citation></ref>
<ref id="c90"><label>[90]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Engemann</surname>, <given-names>D. A.</given-names></string-name> &amp; <string-name><surname>Gramfort</surname>, <given-names>A</given-names></string-name></person-group>. <article-title>Automated model selection in covariance estimation and spatial whitening of MEG and EEG signals</article-title>. <source>NeuroImage</source> <volume>108</volume>, <fpage>328</fpage>–<lpage>342</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c91"><label>[91]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pernet</surname>, <given-names>C.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Issues and recommendations from the OHBM COBIDAS MEEG committee for reproducible EEG and MEG research</article-title>. <source>Nature neuro-science</source> <volume>23</volume>, <fpage>1473</fpage>–<lpage>1483</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c92"><label>[92]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Alink</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Walther</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Krugliak</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>van den Bosch</surname>, <given-names>J. J. F.</given-names></string-name> &amp; <string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name></person-group> <article-title>Mind the drift - improving sensitivity to fMRI pattern information by accounting for temporal pattern drift</article-title>. <source>bioRxiv</source> <elocation-id>032391</elocation-id> (<year>2015</year>).</mixed-citation></ref>
<ref id="c93"><label>[93]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Worsley</surname>, <given-names>K. J.</given-names></string-name> &amp; <string-name><surname>Friston</surname>, <given-names>K. J</given-names></string-name></person-group>. <article-title>Analysis of fMRI time-series revisited–again</article-title>. <source>NeuroImage</source> <volume>2</volume>, <fpage>173</fpage>–<lpage>181</lpage> (<year>1995</year>).</mixed-citation></ref>
<ref id="c94"><label>[94]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Prince</surname>, <given-names>J. S.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Improving the accuracy of single-trial fMRI response estimates using GLMsingle</article-title>. <source>eLife</source> <volume>11</volume> (<year>2022</year>).</mixed-citation></ref>
<ref id="c95"><label>[95]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mumford</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Turner</surname>, <given-names>B. O.</given-names></string-name>, <string-name><surname>Ashby</surname>, <given-names>F. G.</given-names></string-name> &amp; <string-name><surname>Poldrack</surname>, <given-names>R. A</given-names></string-name></person-group>. <article-title>NeuroImage Deconvolving BOLD activation in event-related designs for multivoxel pattern classi fi cation analyses</article-title>. <source>NeuroImage</source> <volume>59</volume>, <fpage>2636</fpage>–<lpage>2643</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c96"><label>[96]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Friston</surname>, <given-names>K.</given-names></string-name></person-group> in Statistical parametric mapping: The analysis of functional brain images (eds <person-group person-group-type="editor"><string-name><surname>Penny</surname> <given-names>W. D.</given-names></string-name>, <string-name><surname>Friston</surname> <given-names>K. J.</given-names></string-name>, <string-name><surname>Ashburner</surname> <given-names>J. T.</given-names></string-name>, <string-name><surname>Kiebel</surname> <given-names>S. J.</given-names></string-name> &amp; <string-name><surname>Nichols</surname> <given-names>T. E.</given-names></string-name></person-group>) <source>Statistical parametric mapping: The analysis of functional brain images</source> (<publisher-name>Academic Press</publisher-name>, <year>2011</year>).</mixed-citation></ref>
<ref id="c97"><label>[97]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gorgolewski</surname>, <given-names>K. J.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments</article-title>. <source>Scientific data</source> <volume>3</volume>, <fpage>160044</fpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c98"><label>[98]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Op de Beeck</surname>, <given-names>H.</given-names></string-name> <string-name><surname>Wagemans</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Vogels</surname>, <given-names>R.</given-names></string-name></person-group> <article-title>Inferotemporal neurons represent low-dimensional configurations of parameterized shapes</article-title>. <source>Nature neuroscience</source> <volume>4</volume>, <fpage>1244</fpage>–<lpage>1252</lpage> (<year>2001</year>).</mixed-citation></ref>
<ref id="c99"><label>[99]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kiani</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Esteky</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Mirpour</surname>, <given-names>K.</given-names></string-name> &amp; <string-name><surname>Tanaka</surname>, <given-names>K</given-names></string-name></person-group>. <article-title>Object category structure in response patterns of neuronal population in monkey inferior temporal cortex</article-title>. <source>Journal of neurophysiology</source> <volume>97</volume>, <fpage>4296</fpage>–<lpage>4309</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c100"><label>[100]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hebart</surname>, <given-names>M. N.</given-names></string-name>, <string-name><surname>Zheng</surname>, <given-names>C. Y.</given-names></string-name>, <string-name><surname>Pereira</surname>, <given-names>F.</given-names></string-name> &amp; <string-name><surname>Baker</surname>, <given-names>C. I</given-names></string-name></person-group>. <article-title>Revealing the multidimensional mental representations of natural objects underlying human similarity judgements</article-title>. <source>Nature human behaviour</source> <volume>4</volume>, <fpage>1173</fpage>–<lpage>1185</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c101"><label>[101]</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Zheng</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Pereira</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Baker</surname>, <given-names>C.</given-names></string-name> &amp; <string-name><surname>Hebart</surname>, <given-names>M</given-names></string-name></person-group>. <article-title>Revealing interpretable object representations from human behavior</article-title>. <conf-name>International Conference on Learning Representations</conf-name> (<year>2019</year>).</mixed-citation></ref>
<ref id="c102"><label>[102]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ratan Murty</surname>, <given-names>N. A.</given-names></string-name> <string-name><surname>Bashivan</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Abate</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>DiCarlo</surname>, <given-names>J. J.</given-names></string-name> &amp; <string-name><surname>Kanwisher</surname>, <given-names>N.</given-names></string-name></person-group> <article-title>Computational models of category-selective brain regions enable high-throughput tests of selectivity</article-title>. <source>Nature communications</source> <volume>12</volume>, <fpage>5540</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c103"><label>[103]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Golan</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Guo</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Schütt</surname>, <given-names>H. H.</given-names></string-name> &amp; <string-name><surname>Kriegeskorte</surname>, <given-names>N</given-names></string-name></person-group>. <article-title>Distinguishing representational geometries with controversial stimuli: Bayesian experimental design and its application to face dissimilarity judgments</article-title>. <source>arXiv</source> (<year>2022</year>).</mixed-citation></ref>
<ref id="c104"><label>[104]</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Styrnal</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Kaniuth</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Stoinski</surname>, <given-names>L.</given-names></string-name> &amp; <string-name><surname>Hebart</surname>, <given-names>M. N</given-names></string-name></person-group>. <article-title>What do similarity tasks actually measure? A systematic comparison of eight tasks</article-title>. <conf-name>Workshop on concepts, actions, and objects: Functional and neural perspectives</conf-name> (<year>2024</year>).</mixed-citation></ref>
<ref id="c105"><label>[105]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Mur</surname>, <given-names>M</given-names></string-name></person-group>. <article-title>Inverse MDS: Inferring dissimilarity structure from multiple item arrangements</article-title>. <source>Frontiers in psychology</source> <volume>3</volume>, <issue>245</issue> (<year>2012</year>).</mixed-citation></ref>
<ref id="c106"><label>[106]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mur</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Human Object-Similarity Judgments Reflect and Transcend the Primate-IT Object Representation</article-title>. <source>Frontiers in psychology</source> <volume>4</volume>, <issue>128</issue> (<year>2013</year>).</mixed-citation></ref>
<ref id="c107"><label>[107]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dima</surname>, <given-names>D. C.</given-names></string-name>, <string-name><surname>Tomita</surname>, <given-names>T. M.</given-names></string-name>, <string-name><surname>Honey</surname>, <given-names>C. J.</given-names></string-name> &amp; <string-name><surname>Isik</surname>, <given-names>L</given-names></string-name></person-group>. <article-title>Social-affective features drive human representations of observed actions</article-title>. <source>eLife</source> <volume>11</volume> (<year>2022</year>).</mixed-citation></ref>
<ref id="c108"><label>[108]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dima</surname>, <given-names>D. C.</given-names></string-name>, <string-name><surname>Hebart</surname>, <given-names>M. N.</given-names></string-name> &amp; <string-name><surname>Isik</surname>, <given-names>L</given-names></string-name></person-group>. <article-title>A data-driven investigation of human action representations</article-title>. <source>Scientific reports</source> <volume>13</volume>, <fpage>5171</fpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c109"><label>[109]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lindh</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Sligte</surname>, <given-names>I. G.</given-names></string-name>, <string-name><surname>Assecondi</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Shapiro</surname>, <given-names>K. L.</given-names></string-name> &amp; <string-name><surname>Charest</surname>, <given-names>I</given-names></string-name></person-group>. <article-title>Conscious perception of natural images is constrained by category-related visual features</article-title>. <source>Nature communications</source> <volume>10</volume>, <fpage>4106</fpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c110"><label>[110]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Faghel-Soubeyrand</surname>, <given-names>S.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Neural computations in prosopagnosia</article-title>. <source>Cerebral cortex (New York, N.Y.: 1991)</source> <volume>34</volume>, <fpage>bhae211</fpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c111"><label>[111]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Koenig-Robert</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Quek</surname>, <given-names>G. L.</given-names></string-name>, <string-name><surname>Grootswagers</surname>, <given-names>T.</given-names></string-name> &amp; <string-name><surname>Varlet</surname>, <given-names>M</given-names></string-name></person-group>. <article-title>Movement trajectories as a window into the dynamics of emerging neural representations</article-title>. <source>Scientific reports</source> <volume>14</volume>, <issue>11499</issue> (<year>2024</year>).</mixed-citation></ref>
<ref id="c112"><label>[112]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Formisano</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Sorger</surname>, <given-names>B.</given-names></string-name> &amp; <string-name><surname>Goebel</surname>, <given-names>R</given-names></string-name></person-group>. <article-title>Individual faces elicit distinct response patterns in human anterior temporal cortex</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source> <volume>104</volume>, <fpage>20600</fpage>–<lpage>20605</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c113"><label>[113]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nili</surname>, <given-names>H.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>A toolbox for representational similarity analysis</article-title>. <source>PLoS computational biology</source> <volume>10</volume>, <fpage>e1003553</fpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c114"><label>[114]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Diedrichsen</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Provost</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Zareamoghaddam</surname>, <given-names>H</given-names></string-name></person-group>. <article-title>On the distribution of cross-validated Mahalanobis distances</article-title>. <source>arXiv</source> (<year>2016</year>).</mixed-citation></ref>
<ref id="c115"><label>[115]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gretton</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Herbrich</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Smola</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Bousquet</surname>, <given-names>O.</given-names></string-name> &amp; <string-name><surname>Scholkopf</surname>, <given-names>B</given-names></string-name></person-group>. <article-title>Kernel methods for measuring independence</article-title>. <source>Journal of machine learning research: JMLR</source> <volume>6</volume>, <fpage>2075</fpage>–<lpage>2129</lpage> (<year>2005</year>).</mixed-citation></ref>
<ref id="c116"><label>[116]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Székely</surname>, <given-names>G. J.</given-names></string-name>, <string-name><surname>Rizzo</surname>, <given-names>M. L.</given-names></string-name> &amp; <string-name><surname>Bakirov</surname>, <given-names>N. K</given-names></string-name></person-group>. <article-title>Measuring and testing dependence by correlation of distances</article-title>. <source>Annals of statistics</source> <volume>35</volume>, <fpage>2769</fpage>–<lpage>2794</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c117"><label>[117]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Harvey</surname>, <given-names>S. E.</given-names></string-name>, <string-name><surname>Larsen</surname>, <given-names>B. W.</given-names></string-name> &amp; <string-name><surname>Williams</surname>, <given-names>A. H</given-names></string-name></person-group>. <article-title>Duality of Bures and shape distances with implications for comparing neural representations</article-title>. <source>arXiv</source> (<year>2023</year>).</mixed-citation></ref>
<ref id="c118"><label>[118]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yarkoni</surname>, <given-names>T</given-names></string-name></person-group>. <article-title>The generalizability crisis</article-title>. <source>The Behavioral and brain sciences</source> <volume>45</volume> (<year>2022</year>).</mixed-citation></ref>
<ref id="c119"><label>[119]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Goebel</surname>, <given-names>R.</given-names></string-name> &amp; <string-name><surname>Bandettini</surname>, <given-names>P</given-names></string-name></person-group>. <article-title>Information-based functional brain mapping</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source> <volume>103</volume>, <fpage>3863</fpage>–<lpage>3868</lpage> (<year>2006</year>).</mixed-citation></ref>
<ref id="c120"><label>[120]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Bandettini</surname>, <given-names>P</given-names></string-name></person-group>. <article-title>Analyzing for information, not activation, to exploit high-resolution fMRI</article-title>. <source>NeuroImage</source> <volume>38</volume>, <fpage>649</fpage>–<lpage>662</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c121"><label>[121]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Devereux</surname>, <given-names>B. J.</given-names></string-name>, <string-name><surname>Clarke</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Tyler</surname>, <given-names>L. K</given-names></string-name></person-group>. <article-title>Integrated deep visual and semantic attractor neural networks predict fMRI pattern-information along the ventral object processing pathway</article-title>. <source>Scientific reports</source> <volume>8</volume>, <issue>10636</issue> (<year>2018</year>).</mixed-citation></ref>
<ref id="c122"><label>[122]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tucciarelli</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Wurm</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Baccolo</surname>, <given-names>E.</given-names></string-name> &amp; <string-name><surname>Lingnau</surname>, <given-names>A</given-names></string-name></person-group>. <article-title>The representational space of observed actions</article-title>. <source>eLife</source> <volume>8</volume> (<year>2019</year>).</mixed-citation></ref>
<ref id="c123"><label>[123]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Oosterhof</surname>, <given-names>N. N.</given-names></string-name>, <string-name><surname>Wiestler</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Downing</surname>, <given-names>P. E.</given-names></string-name> &amp; <string-name><surname>Diedrichsen</surname>, <given-names>J</given-names></string-name></person-group>. <article-title>A comparison of volume-based and surface-based multi-voxel pattern analysis</article-title>. <source>NeuroImage</source> <volume>56</volume>, <fpage>593</fpage>–<lpage>600</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c124"><label>[124]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cichy</surname>, <given-names>R. M.</given-names></string-name>, <string-name><surname>Pantazis</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>Oliva</surname>, <given-names>A</given-names></string-name></person-group>. <article-title>Resolving human object recognition in space and time</article-title>. <source>Nature neuroscience</source> <volume>17</volume>, <fpage>455</fpage>–<lpage>462</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c125"><label>[125]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Clarke</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Devereux</surname>, <given-names>B. J.</given-names></string-name>, <string-name><surname>Randall</surname>, <given-names>B.</given-names></string-name> &amp; <string-name><surname>Tyler</surname>, <given-names>L. K</given-names></string-name></person-group>. <article-title>Predicting the time course of individual objects with MEG</article-title>. <source>Cerebral cortex (New York, N.Y.: 1991)</source> <volume>25</volume>, <fpage>3602</fpage>–<lpage>3612</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c126"><label>[126]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Grootswagers</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Wardle</surname>, <given-names>S. G.</given-names></string-name> &amp; <string-name><surname>Carlson</surname>, <given-names>T. A</given-names></string-name></person-group>. <article-title>Decoding dynamic brain patterns from evoked responses: A tutorial on multivariate pattern analysis applied to time series neuroimaging data</article-title>. <source>Journal of cognitive neuroscience</source> <volume>29</volume>, <fpage>677</fpage>–<lpage>697</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c127"><label>[127]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hebart</surname>, <given-names>M. N.</given-names></string-name>, <string-name><surname>Bankson</surname>, <given-names>B. B.</given-names></string-name>, <string-name><surname>Harel</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Baker</surname>, <given-names>C. I.</given-names></string-name> &amp; <string-name><surname>Cichy</surname>, <given-names>R. M</given-names></string-name></person-group>. <article-title>The representational dynamics of task and object processing in humans</article-title>. <source>eLife</source> <volume>7</volume> (<year>2018</year>).</mixed-citation></ref>
<ref id="c128"><label>[128]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jozwik</surname>, <given-names>K. M.</given-names></string-name>, <string-name><surname>Kietzmann</surname>, <given-names>T. C.</given-names></string-name>, <string-name><surname>Cichy</surname>, <given-names>R. M.</given-names></string-name>, <string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Mur</surname>, <given-names>M</given-names></string-name></person-group>. <article-title>Deep neural networks and visuo-semantic models explain complementary components of human ventral-stream representational dynamics</article-title>. <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source> <volume>43</volume>, <fpage>1731</fpage>–<lpage>1741</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c129"><label>[129]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Storrs</surname>, <given-names>K. R.</given-names></string-name>, <string-name><surname>Khaligh-Razavi</surname>, <given-names>S.-M.</given-names></string-name> &amp; <string-name><surname>Kriegeskorte</surname>, <given-names>N</given-names></string-name></person-group>. <article-title>Noise ceiling on the crossvalidated performance of reweighted models of representational dissimilarity: Addendum to Khaligh-Razavi &amp; Kriegeskorte</article-title> (<year>2014</year>). <source>bioRxiv</source> 2020.03.23.003046 (2020).</mixed-citation></ref>
<ref id="c130"><label>130.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Kendall</surname> <given-names>M. G.</given-names></string-name></person-group> <source>Rank correlation methods</source>. <publisher-name>Griffin</publisher-name> (<year>1948</year>).</mixed-citation></ref>
<ref id="c131"><label>[131]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name> &amp; <string-name><surname>Gorgolewski</surname>, <given-names>K. J</given-names></string-name></person-group>. <article-title>Making big data open: data sharing in neuroimaging</article-title>. <source>Nature neuroscience</source> <volume>17</volume>, <fpage>1510</fpage>–<lpage>1517</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c132"><label>[132]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Keator</surname>, <given-names>D. B.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Towards structured sharing of raw and derived neuroimaging data across existing resources</article-title>. <source>NeuroImage</source> <volume>82</volume>, <fpage>647</fpage>–<lpage>661</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c133"><label>[133]</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Humble</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Farley</surname>, <given-names>D</given-names></string-name></person-group>. <source>Continuous Delivery: Reliable Software Releases through Build, Test, and Deployment Automation</source> (<publisher-name>Pearson Education</publisher-name>, <year>2010</year>).</mixed-citation></ref>
<ref id="c134"><label>[134]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hanke</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>PyMVPA: A python toolbox for multivariate pattern analysis of fMRI data</article-title>. <source>Neuroinformatics</source> <volume>7</volume>, <fpage>37</fpage>–<lpage>53</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c135"><label>[135]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Oosterhof</surname>, <given-names>N. N.</given-names></string-name>, <string-name><surname>Connolly</surname>, <given-names>A. C.</given-names></string-name> &amp; <string-name><surname>Haxby</surname>, <given-names>J. V</given-names></string-name></person-group>. <article-title>CoSMoMVPA: Multi-Modal Multivariate Pattern Analysis of Neuroimaging Data in Matlab/GNU Octave</article-title>. <source>Frontiers in neuroinformatics</source> <volume>10</volume>, <issue>27</issue> (<year>2016</year>).</mixed-citation></ref>
<ref id="c136"><label>[136]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Treder</surname>, <given-names>M. S</given-names></string-name></person-group>. <article-title>MVPA-Light: A Classification and Regression Toolbox for Multi-Dimensional Data</article-title>. <source>Frontiers in neuroscience</source> <volume>14</volume>, <issue>289</issue> (<year>2020</year>).</mixed-citation></ref>
<ref id="c137"><label>[137]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lu</surname>, <given-names>Z.</given-names></string-name> &amp; <string-name><surname>Ku</surname>, <given-names>Y</given-names></string-name></person-group>. <article-title>NeuroRA: A python toolbox of representational analysis from multi-modal neural data</article-title>. <source>Frontiers in neuroinformatics</source> <volume>14</volume>, <issue>563669</issue> (<year>2020</year>).</mixed-citation></ref>
<ref id="c138"><label>[138]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cai</surname>, <given-names>M. B.</given-names></string-name>, <string-name><surname>Schuck</surname>, <given-names>N. W.</given-names></string-name>, <string-name><surname>Pillow</surname>, <given-names>J. W.</given-names></string-name> &amp; <string-name><surname>Niv</surname>, <given-names>Y</given-names></string-name></person-group>. <article-title>Representational structure or task structure? Bias in neural representational similarity analysis and a Bayesian method for reducing bias</article-title>. <source>PLoS computational biology</source> <volume>15</volume>, <fpage>e1006299</fpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c139"><label>[139]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van Gerven</surname>, <given-names>M. A. J</given-names></string-name></person-group>. <article-title>A primer on encoding models in sensory neuroscience</article-title>. <source>Journal of mathematical psychology</source> <volume>76</volume>, <fpage>172</fpage>–<lpage>183</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c140"><label>[140]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Naselaris</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Kay</surname>, <given-names>K. N.</given-names></string-name>, <string-name><surname>Nishimoto</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Gallant</surname>, <given-names>J. L.</given-names></string-name></person-group> <article-title>Encoding and decoding in fMRI</article-title>. <source>NeuroImage</source> <volume>56</volume>, <fpage>400</fpage>–<lpage>410</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c141"><label>[141]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Conwell</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Prince</surname>, <given-names>J. S.</given-names></string-name>, <string-name><surname>Kay</surname>, <given-names>K. N.</given-names></string-name>, <string-name><surname>Alvarez</surname>, <given-names>G. A.</given-names></string-name> &amp; <string-name><surname>Konkle</surname>, <given-names>T</given-names></string-name></person-group>. <article-title>A large-scale examination of inductive biases shaping high-level visual representation in brains and machines</article-title>. <source>Nature communications</source> <volume>15</volume>, <fpage>9383</fpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c142"><label>[142]</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Khosla</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Williams</surname>, <given-names>A. H</given-names></string-name></person-group>. <article-title>Soft Matching Distance: A metric on neural representations that captures single-neuron tuning</article-title>. <conf-name>Proceedings of UniReps: the First Workshop on Unifying Representations in Neural Models</conf-name> <fpage>326</fpage>–<lpage>341</lpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c143"><label>[143]</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Prince</surname>, <given-names>J. S.</given-names></string-name>, <string-name><surname>Conwell</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Alvarez</surname>, <given-names>G. A.</given-names></string-name> &amp; <string-name><surname>Konkle</surname>, <given-names>T</given-names></string-name></person-group>. <article-title>A case for sparse positive alignment of neural systems</article-title>. <conf-name>ICLR 2024 Workshop on Representational Alignment</conf-name> (<year>2024</year>).</mixed-citation></ref>
<ref id="c144"><label>[144]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Conwell</surname>, <given-names>C.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Battle of the Brain-Model-Mapping Metrics</article-title>. <source>Cognitive Computational Neuroscience</source> <volume>2024</volume> (<year>2024</year>).</mixed-citation></ref>
<ref id="c145"><label>[145]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Feather</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Leclerc</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Mądry</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>McDermott</surname>, <given-names>J. H</given-names></string-name></person-group>. <article-title>Model metamers reveal divergent invariances between biological and artificial neural networks</article-title>. <source>Nature neuroscience</source> <volume>26</volume>, <fpage>2017</fpage>–<lpage>2034</lpage> (<year>2023</year>).</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107828.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Bottini</surname>
<given-names>Roberto</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Trento</institution>
</institution-wrap>
<city>Trento</city>
<country>Italy</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study presents a new toolbox for Representational Similarity Analysis, representing a <bold>valuable</bold> contribution to the neuroscience community. The authors offer a well-integrated platform that brings together a range of state-of-the-art methodological advances within a <bold>convincing</bold> framework, with strong potential to enable more rigorous and insightful analyses of neural data across multiple subfields.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107828.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary</p>
<p>This manuscript presents an updated version of rsatoolbox, a Python package for performing Representational Similarity Analysis (RSA) on neural data. The authors provide a comprehensive and well-integrated framework that incorporates a range of state-of-the-art methodological advances. The updated version extends the toolbox's capabilities.</p>
<p>The paper outlines a typical RSA workflow in five steps:</p>
<p>(1) Importing data and estimating activity patterns.</p>
<p>(2) Estimating representational geometries (computing RDMs).</p>
<p>(3) Comparing RDMs.</p>
<p>(4) Performing inferential model comparisons.</p>
<p>(5) Handling multiple testing across space and time.</p>
<p>For each step, the authors describe methodological advances and best practices implemented in the toolbox, including improved measures of representational distances, evaluators for representational models, and statistical inference methods.</p>
<p>While the relative impact of the manuscript is somewhat limited to the new contributions in this update (which are nonetheless very useful), the general toolbox - here thoroughly described and discussed - remains an invaluable contribution to the field and is well-received by the cognitive and computational neuroscience communities.</p>
<p>Strengths:</p>
<p>A key strength of the work is the breadth and integration of the implemented methods. The updated version introduces several new features, such as additional comparators and dissimilarity estimators, that closely follow recent methodological developments in the field. These enhancements build on an already extensive set of functionalities, offering seamless support for RSA analyses across a wide variety of data sources, including deep neural networks, fMRI, EEG, and electrophysiological recordings.</p>
<p>The toolbox also integrates effectively with the broader open-source ecosystem, providing compatibility with BIDS formats and outputs from widely used neuroscience software. This integration will make it easier for researchers to incorporate rsatoolbox into existing workflows. The documentation is extensive, and the scope of functionality - from dissimilarity estimation to statistical inference - is impressive.</p>
<p>For researchers already familiar with RSA, rsatoolbox offers a coherent environment that can streamline analyses, promote methodological consistency, and encourage best practices.</p>
<p>Weaknesses:</p>
<p>While I enjoyed reading the manuscript - and even more so exploring the toolbox - I have some comments for the authors. None of these points is strictly major, and I leave it to the authors' discretion whether to act on them, but addressing them could make the manuscript an even more valuable resource for those approaching RSA.</p>
<p>(1) While several estimators and comparators are implemented, Figure 4 appears to suggest that only a subset should be used in practice. This raises the question of whether the remaining options are necessary, and under what circumstances they might be preferable. Although it is likely that different measures are suited to different scenarios, this is not clearly explained in the manuscript. As presented, a reader following the manuscript's guidance might rely on only a few of the available comparators and estimators without understanding the rationale. It would be helpful if the authors could provide practical examples illustrating when one measure might be preferred over another, and how different measures behave under varying conditions-for instance, in what situations the user should choose manifold similarity versus Bures similarity?</p>
<p>(2) The comparison to other RSA tools is minimal, making it challenging to place rsatoolbox in the broader landscape of available resources. Although the authors mention some existing RSA implementations, they do not provide a detailed comparison of features or performance between their toolbox and alternatives.</p>
<p>(3) Finally, given the growing interest in comparing neural network models with brain data, a more detailed discussion of how the toolbox can be applied to common questions in this area would be a valuable addition.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107828.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The manuscript, &quot;A Python Toolbox for Representational Similarity Analysis&quot;, presents an overview of the RSAToolbox, including a review of the methods it implements (some of which are more recently developed) and recommendations for constructing RSA analysis pipelines. It is encouraging to see that this toolbox, which has existed in both Python and other forms, continues to be actively developed and maintained.</p>
<p>Strengths:</p>
<p>The authors do a nice job reviewing the history of RSA analysis while introducing the methods within the toolbox. It is helpful that the authors discuss when and how to apply specific measures to different data types (e.g., why Euclidean or Mahalanobis distances are suboptimal for spike data). The manuscript strikes a valuable balance between theoretical background and hands-on instruction. The inclusion of decision-making aids, such as the Euler diagram for selecting similarity measures, and well-maintained demo scripts (available on GitHub), enhance the manuscript's utility as a practical guide.</p>
<p>Overall, this paper will be particularly useful to researchers new to RSA and those interested in performing a rigorous analysis using this framework. The manuscript and accompanying toolbox provide everything a researcher needs to get started, provided they take the time to engage with the methodological details and references offered</p>
<p>Weaknesses:</p>
<p>While the links to the demos in the figure legend did not work for me, it was easy to locate the current demos online, and it's encouraging to see that they are actively maintained. One small issue is that a placeholder (&quot;XXX&quot;) remains in the description of Figure 3b and should be corrected.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107828.1.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>van den Bosch</surname>
<given-names>Jasper JF</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9326-2090</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Golan</surname>
<given-names>Tal</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7940-7473</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Peters</surname>
<given-names>Benjamin</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0948-8976</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Taylor</surname>
<given-names>JohnMark</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1034-6860</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Shahbazi</surname>
<given-names>Mahdiyar</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4883-4376</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Lin</surname>
<given-names>Baihan</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7979-5509</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Charest</surname>
<given-names>Ian</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3939-3003</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Diedrichsen</surname>
<given-names>Jörn</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0264-8532</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Kriegeskorte</surname>
<given-names>Nikolaus</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7433-9005</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Mur</surname>
<given-names>Marieke</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1749-9058</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Schütt</surname>
<given-names>Heiko H</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2491-5710</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>We thank the reviewers for their valuable feedback. We will prepare a revision of the manuscript based on these suggestions and comments. We are sure these revisions will improve the paper.</p>
<p>The only major point we wish to clarify is that this is the first and only manuscript describing the toolbox; it is not a version update. Although it shares a similar name with its 2015 MATLAB predecessor (Nili et al., PLoS Comput Biol), rsatoolbox was designed from scratch. Also, they have no code or structural overlap beyond implementing some similar methods.</p>
<p>Developed publicly since 2019, rsatoolbox reflects a decade of research in RSA methodology across multiple labs and incorporates new dissimilarity metrics, RDM comparators, inferential procedures, and visualization methods. Importantly, although we cite several papers describing methods implemented in the toolbox, this is the first manuscript to present the toolbox as a whole, its design principles, and the unified analytical framework it offers.</p>
<p>We are sorry about the forgotten placeholder and the links not working. The links work for us in the pdf at least and we will certainly fix the placeholder as soon as possible.</p>
</body>
</sub-article>
</article>