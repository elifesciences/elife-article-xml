<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">98317</article-id>
<article-id pub-id-type="doi">10.7554/eLife.98317</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.98317.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Genetics and Genomics</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Poseidon – A framework for archaeogenetic human genotype data management</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3448-5715</contrib-id>
<name>
<surname>Schmid</surname>
<given-names>Clemens</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9104-0395</contrib-id>
<name>
<surname>Ghalichi</surname>
<given-names>Ayshin</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4485-8570</contrib-id>
<name>
<surname>Lamnidis</surname>
<given-names>Thiseas C.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0004-9297-1644</contrib-id>
<name>
<surname>Mudiyanselage</surname>
<given-names>Dhananjaya B. A.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2475-2007</contrib-id>
<name>
<surname>Haak</surname>
<given-names>Wolfgang</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1017-9150</contrib-id>
<name>
<surname>Schiffels</surname>
<given-names>Stephan</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Max Planck Institute for Evolutionary Anthropology</institution>, Leipzig, <country>Germany</country></aff>
<aff id="a2"><label>2</label><institution>International Max Planck Research School for the Science of Human History, Max Planck Institute for Geoanthropology</institution>, Jena, <country>Germany</country></aff>
<aff id="a3"><label>3</label><institution>Saarland University</institution>, Saarbrücken, <country>Germany</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Carmi</surname>
<given-names>Shai</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>The Hebrew University of Jerusalem</institution>
</institution-wrap>
<city>Jerusalem</city>
<country>Israel</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Perry</surname>
<given-names>George H</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Pennsylvania State University</institution>
</institution-wrap>
<city>University Park</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label> Corresponding author; email: <email>stephan_schiffels@eva.mpg.de</email></corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-06-19">
<day>19</day>
<month>06</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP98317</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-04-12">
<day>12</day>
<month>04</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-04-16">
<day>16</day>
<month>04</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.04.12.589180"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Schmid et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Schmid et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-98317-v1.pdf"/>
<abstract>
<label>1</label>
<title>Abstract</title>
<p>The study of ancient human genomes, archaeo- or palaeogenetics, has accelerated in the last ten years, with now thousands of new ancient genomes being released each year. Operating at the interface of genetics, anthro-pology and archaeology, this data includes features from all three fields, including rich meta- and context-data, for example regarding spatiotemporal provenience. While archives and standards for genetic sequencing data al-ready exist, no such infrastructure exists for combined genetic and meta-data that could ensure FAIR principles across the field. Here, we present Poseidon, a framework for open and FAIR data handling in archaeogenetics, including a specified package format, software tools, and public, community-maintained online archives. Poseidon emphasises human- and machine-readable data storage, the development of convenient and interoperable command line software, and a high degree of source granularity to elevate the original data publication to the main unit of long-term curation.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>ancient DNA</kwd>
<kwd>data management</kwd>
<kwd>FAIR data</kwd>
</kwd-group>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>We have added Supplementary Files to the paper.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<label>2</label>
<title>Introduction</title>
<p>The technology to extract and sequence DNA from human remains thousands of years old has revolutionised the study of the human past. This is documented by groundbreaking new insights, from our evolutionary relationships to distant relatives like Neanderthals [<xref ref-type="bibr" rid="c1">1</xref>, <xref ref-type="bibr" rid="c2">2</xref>] to prehistoric [<xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c4">4</xref>] and historic migrations [<xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c6">6</xref>]. Since the sequencing of the first ancient modern human genome in 2010 [<xref ref-type="bibr" rid="c7">7</xref>], hundreds of studies have been published, accompanied by massive datasets of ancient human DNA sequences. A drop in sequencing costs and new technologies like hybridisation capture [<xref ref-type="bibr" rid="c8">8</xref>, <xref ref-type="bibr" rid="c4">4</xref>, <xref ref-type="bibr" rid="c9">9</xref>] have in fact lead to an acceleration of new published ancient genomes, with data now coming out faster than individual researchers typically can keep track of and co-analyze. Recently, the threshold of genome-wide data for 10,000 ancient human individuals has been surpassed [<xref ref-type="bibr" rid="c10">10</xref>].</p>
<p>To make all this new data publicly available, researchers can partly rely on existing infrastructure for the archival and distribution of modern genetic data, such as the Sequence Read Archive (SRA) [<xref ref-type="bibr" rid="c11">11</xref>], the European Nucleotide Archive (ENA) [<xref ref-type="bibr" rid="c12">12</xref>] or other INSDC databases (<ext-link ext-link-type="uri" xlink:href="https://www.insdc.org">https://www.insdc.org</ext-link>). However, this infrastructure has not been prepared to also capture the rich context-data ranging from archaeological field observations to radiocarbon dating that accompanies ancient samples. Nor is there a standardised archive yet for derived genotype data that is routinely used to substantiate most if not all of the conclusions in archaeogenetic papers. This raises multiple concrete issues:</p>
<list list-type="bullet">
<list-item><p>Ancient individuals only constitute meaningful observations if their spatiotemporal provenience is known. Current practice renders it difficult to maintain the connection between archaeological context and sampled genomic data, as this information is generally kept separately.</p></list-item>
<list-item><p>Specific results of typical archaeogenetic analyses (e.g. PCA, F-Statistics, kinship estimation) can only be fully reproduced with genotype-level data. But current practice is not to include this data with a publication, be it for its unwieldy size or the lack of a central repository to easily share it.</p></list-item>
<list-item><p>Meta-analyses involving large amounts of data require tedious curation. Despite the fact that archaeogenetic genotype data is largely standardized, and common practices for reporting processing steps, data quality indicators, as well as spatial and temporal sample origin have emerged, combining information from different papers is still hindered by severe structural variation.</p></list-item>
</list>
<p>A major project addressing some of these problems in human archaeogenetics is the Allen Ancient DNA Resource (AADR), which is a curated dataset of public ancient DNA data assembled by the Reich Lab at Harvard University [<xref ref-type="bibr" rid="c13">13</xref>]. While the AADR clearly fills a gap in the field, there continues to be a need for open standardization and the creation of a community-maintained archive. Both standard and archive should be well-specified to be human and machine-readable, fully open and transparent, and permanently downloadable with their entire version history. They should be geared towards scientific practice and include well-documented interfaces for research software. To ensure fairness, i.e. equal access for users and contributors from different backgrounds, and long-term reliability, they should be as independent as possible from specific institutions, key persons [<xref ref-type="bibr" rid="c14">14</xref>] or infrastructure providers, and ideally controlled by the community-of-practice as a whole.</p>
<p>Here, we present ‘<italic>Poseidon</italic>’ (<ext-link ext-link-type="uri" xlink:href="https://www.poseidon-adna.org">https://www.poseidon-adna.org</ext-link>), a computational framework including an open data format, software, and community-maintained archives, to enable this standardised and FAIR handling of archaeogenetic data. The name <italic>Poseidon</italic> is inspired by the notion of a <italic>sea of data</italic> benefiting from structure and governance. We imagine Poseidon to simplify a variety of concrete workflows and mitigate technical challenges practitioners in the field of human archaeogenetics regularly face:</p>
<sec id="s1a">
<title>Data storage</title>
<p>Archaeogenetic samples/ancient individuals (we often use these terms synonymously below, see Supplementary Text 8 for a definition) can only be effectively analysed with context data. The Poseidon package format allows one to store archaeogenetic genotype data with arbitrary spatiotemporal or archaeological information on a per-sample level. The package format enforces human- and machine-readability for the context data to enable its computational co-analysis with the genomic data, while also maintaining a high level of flexibility and extensibility to accommodate arbitrary additional variables.</p>
</sec>
<sec id="s1b">
<title>Data acquisition</title>
<p>Research in archaeogenetics is strongly dependent on incorporating published reference data. Poseidon features public archives with per-article packages that can be downloaded through an open web API. The packages include genotypes, context data and machine-readable citation information. To ensure computational reproducibility, Poseidon supports version tracking for these packages, with old versions directly available through the web interface. Beyond hosting data, the web infrastructure also provides options to report issues and suggest transparent data updates.</p>
</sec>
<sec id="s1c">
<title>Data analysis</title>
<p>Working with common software tools in human archaeogenetics (e.g. smartpca [<xref ref-type="bibr" rid="c16">16</xref>, <xref ref-type="bibr" rid="c17">17</xref>], ADMIXTURE [<xref ref-type="bibr" rid="c18">18</xref>], qpAdm [<xref ref-type="bibr" rid="c4">4</xref>, <xref ref-type="bibr" rid="c19">19</xref>]) requires frequent merging, sub-setting and file format conversion for the samples of interest. The Poseidon core team develops the software tool <italic>trident</italic> to simplify these operations both with Poseidon packages and unpackaged genotype data. The unified package format allows for new analysis tools with flexible data detection, low-memory stream processing and on-the-fly aggregation of widely used genome-wide statistics as demonstrated in the <italic>xerxes</italic> software tool also developed by the core team.</p>
</sec>
<sec id="s1d">
<title>Data publication</title>
<p>For each sample, human archaeogenetic papers should include genotypes, context information and quality-control data, so e.g. estimates for the aDNA damage or contamination. Poseidon offers a standardized and reusable way to share this data directly with the publication and/or through our public archives.</p>
</sec>
</sec>
<sec id="s2">
<label>3</label>
<title>Overview</title>
<p>Poseidon consists of three major components: A data format, software, and public archives (see <xref rid="fig1" ref-type="fig">Figure 1</xref>). At the foundation stands a data format to store genotype data together with context information. The software implements this specification, relies on and validates its promises, and builds convenient, useful functionality on top of it, both for individual users and for our cloud infrastructure. Finally, the public archives store data using the data format and employ the software for validation, modification and book-keeping.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1:</label>
<caption><p>Schematic overview of the core components of the Poseidon framework. The Poseidon package specification forms the foundation on which various open source software tools and the Minotaur workflow are based. They, in turn, underpin and enable the public Poseidon data archives.</p></caption>
<graphic xlink:href="589180v2_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The Poseidon schema (Supplementary Text 1) defines the structure and format of a Poseidon package (<xref rid="fig2" ref-type="fig">Figure 2</xref>). This includes the general layout and purpose of the main files, the POSEIDON.yml, the .janno and the .ssf file, and detailed definitions of the variables within them, both regarding semantics and syntax (Supplementary Text 2). The short definitions in the schema are explained in more detail on the Poseidon website, which also serves as a central hub for all components of the framework.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2:</label>
<caption><p>Schematic overview of the Poseidon package structure. The POSEIDON.yml file defines the package and interlinks the additional data files for genotype, context- and bibliography information in a relational structure.</p></caption>
<graphic xlink:href="589180v2_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The Poseidon software suite enables users to create, download, inspect, subset, merge and analyse Poseidon packages (Supplementary Text 3-7). It is mostly implemented in Haskell [<xref ref-type="bibr" rid="c20">20</xref>], a purely functional programming language, and split over multiple command line tools openly available as statically compiled executables for the major desktop and server operating systems. The main tool, <italic>trident</italic>, provides data handling functionality, including the code necessary for the client-server infrastructure of the public archives. The <italic>xerxes</italic> software implements commonly used genome-wide allele-frequency statistics, <italic>qjanno</italic> allows for SQL-like queries on .janno files and the <italic>janno</italic> R package offers a .janno file interface for the R programming language.</p>
<p>Using these tools, we conceived and implemented three public data archives for sharing and maintaining published (ancient) human DNA data packaged in the Poseidon format: The Poseidon Community Archive (PCA), the Poseidon Minotaur Archive (PMA) and the Poseidon AADR Archive (PAA). They already store considerable amounts of public genotype data (<xref rid="fig4" ref-type="fig">Figure 4</xref>, <xref rid="fig5" ref-type="fig">Figure 5</xref> and Supplementary Text 8). Each of these archives is at their base represented by a public repository on GitHub, versioned with Git and capable of holding large genotype data files through an integration with Git’s Large File Storage (LFS) functionality. This setup allows for community driven maintenance through Git pull requests (<xref rid="fig3" ref-type="fig">Figure 3</xref>). A custom webserver mirrors the data from GitHub with an explicit version history, and allows to query the archive data and download packages in the browser, from the command line and through web-frontends. While the PCA focuses on author-submitted genotype data, the PMA only accepts data that went through a specific standardized genotype data processing pipeline, the Minotaur workflow, with a semi-automatic interface on GitHub and a processing queue currently hosted on computational infrastructure at the Max Planck Institute for Evolutionary Anthropology (MPI-EVA). Finally, the PAA stores releases of the AADR dataset in Poseidon format, after a light-weight curation step to ensure format compatibility.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3:</label>
<caption><p>Schematic overview of the most common interaction pathways between the archaeogenetic community of practice and the Poseidon infrastructure. Community members share data either by preparing .ssf files as build-instructions for the Minotaur workflow or by directly submitting packages to the Community Archive. The data in the archives can then in turn be downloaded from the archives through the Poseidon webserver and its API.</p></caption>
<graphic xlink:href="589180v2_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4:</label>
<caption><p>Spatiotemporal distribution of ancient individuals in the PCA and PAA (AADR v54.1.p1) public Poseidon archives. See Supplementary Text 8 for an explanation of how individuals were counted. The map shows the qualitative presence and absence of samples from both archives in a 5<sup><italic>°</italic></sup>-resolution grid. Especially highlighted are areas and time periods for which the PCA includes samples from currently 13 author-submitted Poseidon packages.</p></caption>
<graphic xlink:href="589180v2_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5:</label>
<caption><p>Multiple charts to compare the current content of the PCA and PAA (AADR v54.1.p1) public Poseidon archives. See Supplementary Text 8 for an explanation of how individuals were counted and more in-depth descriptions of each chart. A) Stacked barchart of publications and how they are distributed across packages in PCA and PAA. Publications represented in multiple packages are counted towards the shaded area to get a correct total, B) Barcode plot of individuals available in each archive per publication through time, C) Stacked barchart of individuals and how they were added to the archives, D) Sankey diagram of individuals matching across PCA and PAA, highlighting individuals unique to each archive on the right, E) Stacked barchart of dating information per individual available in the archives, F) Stacked barchart of spatial coordinate coverage in the archives.</p></caption>
<graphic xlink:href="589180v2_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s3">
<label>4</label>
<title>Structure</title>
<p>The following sections explain the different components of Poseidon in detail: The Poseidon package, the software tools, and the public archives including the Minotaur processing workflow. The underlying repositories with specifications and code are available on GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/poseidon-framework">https://github.com/poseidon-framework</ext-link>) and, each in a current version, at a long-term archive: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.17605/OSF.IO/ZUQGB">https://doi.org/10.17605/OSF.IO/ZUQGB</ext-link></p>
<sec id="s3a">
<label>4.1</label>
<title>The Poseidon Package specification (v2.7.1)</title>
<p>The core idea of Poseidon is to organize genotype data together with relevant meta- and context data in a structured yet flexible, human- and machine-readable format. This format is the Poseidon package, defined in a semantically versioned [<xref ref-type="bibr" rid="c21">21</xref>] specification, openly available online (<ext-link ext-link-type="uri" xlink:href="https://github.com/poseidon-framework/poseidon-schema">https://github.com/poseidon-framework/poseidon-schema</ext-link>), and also part of this publication as Supplementary Text 1. A Poseidon package must contain a POSEIDON.yml file and genotype data in PLINK or EIGENSTRAT format. It should additionally contain a .janno file to store sample-wise context information and a .bib file for literature references. Optionally, it can also contain an .ssf file with information on the underlying raw sequencing data, an unstructured README.md file for arbitrary meta information and a CHANGELOG.md file to document changes to the package.</p>
<fig id="ufig1" position="float" fig-type="figure">
<graphic xlink:href="589180v2_ufig1.tif" mimetype="image" mime-subtype="tiff"/>
<graphic xlink:href="589180v2_ufig1a.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p><bold>Example 1:</bold> A typical, neither minimal nor maximal, POSEIDON.yml file.</p>
<p>A Poseidon package is defined by a POSEIDON.yml file, using the YAML markup language (<ext-link ext-link-type="uri" xlink:href="https://yaml.org">https://yaml.org</ext-link>) with a set of predefined fields, which stores some general information and, most importantly, relative paths to the other files in the package (see Example 1). A full list of the specified fields is provided as part of the schema, but only <monospace>poseidonVersion</monospace> (the schema version the package adheres to), <monospace>title</monospace> (a short package name), and <monospace>genotypeData</monospace> (context information for and relative paths to the genotype data files) are mandatory. Besides its function to define the package, the POSEIDON.yml also enables software to easily crawl for packages in a file system.</p>
<p>At the time of writing, Poseidon supports genotype data for single nucleotide polymorphisms (SNPs) in two common file formats: a binary-encoded format as introduced by the plink software package (PLINK) [<xref ref-type="bibr" rid="c22">22</xref>] and a plain-text, human-readable format defined for the eigensoft software tools (EIGENSTRAT) [<xref ref-type="bibr" rid="c17">17</xref>]. Both formats are structurally similar, and split into three files: A genotype table (.bed/.geno); a SNP file (.bim/.snp), defining the SNPs in the genotype table; and an individual file (.fam/.ind) for the respective samples. In the future,</p>
<p>Poseidon may add support for other formats, e.g. the more flexible vcf file format [<xref ref-type="bibr" rid="c23">23</xref>]. Arbitrary SNP sets are allowed and supported, but special keywords are reserved for the commonly used Affymetrix <italic>HumanOrigins</italic> array [<xref ref-type="bibr" rid="c24">24</xref>], and the so-called <italic>1240k</italic> in-solution hybridization capture reagent [<xref ref-type="bibr" rid="c25">25</xref>].</p>
<p>The .janno file accompanies the genotype data to provide context for each sample. It is designed as a tabular, tab-separated text file with a set of predefined columns. Each row corresponds to one entry in the individual file (.fam/.ind), featuring at least the following mandatory columns: <monospace>Poseidon_ID</monospace> (a sample identifier), <monospace>Genetic_Sex</monospace> (Female, Male, Unknown) and <monospace>Group_Name</monospace> (one or multiple group identifiers). Other, optional columns include standard information on the spatiotemporal provenience of a given sample, its genetic data quality metrics, and which major laboratory procedures it was subjected to. Supplementary Text 2 includes documentation for all specified columns of the .janno file. One particular column documents the scientific publication(s) within which the genetic or contextual data for a given sample was originally reported. This is a list column with BibTeX keys, which, in turn, must be specified in the .bib file of the Poseidon package, thus ensuring that each sample can be properly cited.</p>
<p>The .ssf file is similarly structured as the .janno file and stores sequencing source data, i.e. meta-information about the raw sequencing data behind the genotypes in a Poseidon package. The rows in this table correspond to sequencing entities, typically the set of unprocessed reads sequenced from DNA libraries or even multiple runs/lanes of the same library. At the time of writing, the specified columns mostly focus on how to download a given dataset from the INSDC databases such as ENA or SRA (<ext-link ext-link-type="uri" xlink:href="https://www.insdc.org">https://www.insdc.org</ext-link>). The .ssf file does not have any mandatory variables, but entries can be linked to the package with the list column <monospace>poseidon IDs</monospace> in a many-to-many relationship.</p>
</sec>
<sec id="s3b">
<label>4.2</label>
<title>Software tools</title>
<p>The following software tools were developed to work with Poseidon packages and other infrastructure of the Poseidon ecosystem. They can be considered reference implementations of the Poseidon schema, but are by no means exclusive nor comprehensive. The Poseidon schema is defined as an independent, versioned entity, and software developers can easily implement other tools in addition to what we as the Poseidon core team currently offer.</p>
<p>All Poseidon software is open-source (MIT-License) and available on GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/poseidon-framework">https://github.com/poseidon-framework</ext-link>). That is also where users should report issues.</p>
<sec id="s3b1">
<label>4.2.1</label>
<title>trident (v1.4.1.0)</title>
<p><italic>trident</italic> is a command line software tool to create, download, inspect, merge, and subset Poseidon packages – and therefore the central tool of the Poseidon framework. It is implemented in Haskell as one executable for the <italic>poseidon-hs</italic> library and can be installed from source with the build systems cabal [<xref ref-type="bibr" rid="c26">26</xref>] or stack [<xref ref-type="bibr" rid="c27">27</xref>]. To ease installation we provide pre-compiled, static binary executables for Linux, Windows and macOS. We also maintain a package recipe under <italic>poseidon-trident</italic> on the bioconda channel [<xref ref-type="bibr" rid="c28">28</xref>], enabling installation of <italic>trident</italic> through the conda (<ext-link ext-link-type="uri" xlink:href="https://docs.anaconda.com">https://docs.anaconda.com</ext-link>) package management system.</p>
<p><italic>trident</italic> includes multiple sub-commands for different operations on and with Poseidon packages – Supplementary Text 3 gives a detailed overview including all specific arguments. It supports two mechanisms to obtain Poseidon packages: A user can create them from genotype data with <monospace>trident init</monospace> or download them from our community-maintained archives with <monospace>trident fetch</monospace>. The most involved and technically complex sub-command in <italic>trident</italic> is <monospace>trident forge</monospace>, which allows users to both subset and merge Poseidon packages. To simplify the process of package maintenance, <monospace>trident genoconvert</monospace> converts the genotype data between the formats Poseidon supports and <monospace>trident rectify</monospace> automates some common tasks such as checksum and version updates. For package inspection, <italic>trident</italic> includes <monospace>trident list</monospace>, which returns lists of packages, groups, or samples for a given package selection (either locally, or remotely by accessing the web API for the community-maintained online archives). <monospace>trident summarise</monospace> compiles some basic summary statistics about a package collection and <monospace>trident survey</monospace> gives an overview to which degree .janno files in a package collection are filled with data, i.e. the level of completeness for context information. The last and arguably the most important inspection subcommand is <monospace>trident validate</monospace>, which parses all components of a package to report violations of the Poseidon schema. This ensures the structural integrity of Poseidon packages and maintains machine-readability.</p>
<fig id="ufig2" position="float" fig-type="figure">
<graphic xlink:href="589180v2_ufig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p><bold>Example 2:</bold> A basic <italic>trident</italic> command line workflow to explore the community archive, download relevant packages and create a new package from the downloaded data, as well as a local/private data collection. <monospace>trident list</monospace> queries the webserver (<monospace>--remote</monospace>), and returns a tab separated (<monospace>--raw</monospace>) table of individuals/samples (<monospace>--individuals</monospace>) available in the public Community Archive (PCA). This list can then be filtered with standard command line tools (here <monospace>grep</monospace>). With <monospace>trident fetch</monospace> two packages are selected for download (<monospace>-f …</monospace>) into the current working directory (<monospace>-d .</monospace>). These two packages as well as an additional, local package collection (<monospace>-d ../myData/</monospace>) can then be read into <monospace>forge</monospace> to create a new package <monospace>newPac</monospace>, specifying (<monospace>-f …</monospace>) the groups <monospace>Finland Levanluhta</monospace>, <monospace>VolgaOka IA</monospace> and the local sample <monospace>mySample</monospace>.</p>
<p>A simple <italic>trident</italic> workflow could look like Example 2. The first two commands here require interaction with the Poseidon webserver. This server software is, in fact, also implemented in Haskell as a part of <italic>poseidon-hs</italic> and can be started with a hidden (and for most end users irrelevant) <italic>trident</italic> sub-command <monospace>trident serve</monospace>. On the client side <monospace>trident list</monospace> and <monospace>trident fetch</monospace> use this API and interact, by default, with the endpoints at <ext-link ext-link-type="uri" xlink:href="https://server.poseidon-adna.org">https://server.poseidon-adna.org</ext-link>. A different server can be set with <monospace>--remoteURL</monospace>. More about the available endpoints below.</p>
<p>The <monospace>forge</monospace> sub-command is the technically most involved operation in <italic>trident</italic>. It discovers all Poseidon packages under a list of base directories (<monospace>-d</monospace>), reads them and their components into dedicated in-memory data structures, parses the query language in <monospace>-f</monospace> (or from a file with <monospace>--forgeFile</monospace>) to decide which entities (individuals, groups, packages) should be selected, and ultimately generates the new package including genotypes and context data in a single, low-memory stream processing run. All components of the Poseidon package format (i.e. the POSEIDON.yml file, the genotype data, the .janno, the .ssf, and the .bib file) are modelled in <italic>poseidonhs</italic> as algebraic data types with dedicated parsers. Corrupted files are rejected upon reading, including cross-file compatibility checks within each package (e.g. bibtex keys mentioned in the .janno file must be specified in the .bib file). The query language supported by <monospace>trident forge</monospace> in <monospace>-f</monospace> is a flexible domain-specific language (DSL) to describe arbitrary positive and negative entity selection scenarios. For the stream processing of genotype data in binary PLINK and EIGENSTRAT format, <italic>poseidon-hs</italic> relies on the the sequencing-formats library (<ext-link ext-link-type="uri" xlink:href="https://github.com/stschiff/sequence-formats">https://github.com/stschiff/sequence-formats</ext-link>), which allows <italic>trident</italic> to read, filter and write data from a large amount of files at once, while also unifying SNPs to a consensus by recoding alleles on-the-fly. Varying SNP sets in multiple packages can be merged using either an intersection or a union operation.</p>
</sec>
<sec id="s3b2">
<label>4.2.2</label>
<title>xerxes (v1.0.1.0)</title>
<p><italic>xerxes</italic> is another command line software tool based on the <italic>poseidon-hs</italic> Haskell library. While <italic>trident</italic> is meant for data management, <italic>xerxes</italic> is intended for basic, every-day data analysis operations. Its most advanced and stable sub-command <monospace>xerxes fstats</monospace> makes extensive use of the genotype data stream processing introduced above to implement commonly used genome-wide statistics. These are F-Statistics (<italic>F</italic><sub>2</sub>, <italic>F</italic><sub>3</sub> and <italic>F</italic><sub>4</sub>, see Example 3, in several variants differing in bias-correction and normalisation) [<xref ref-type="bibr" rid="c24">24</xref>], <italic>F</italic><sub>ST</sub> [<xref ref-type="bibr" rid="c29">29</xref>], heterozygosity, and pairwise nucleotide mismatch rates for assessing pairwise relatedness. All statistics are evaluated with error-estimation using weighted block-Jackknife [<xref ref-type="bibr" rid="c30">30</xref>]. See Supplementary Text 4 for the <italic>xerxes</italic> user guide and Supplementary Text 5 for a whitepaper documenting the mathematical underpinnings of the implemented algorithms.</p>
<fig id="ufig3" position="float" fig-type="figure">
<graphic xlink:href="589180v2_ufig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p><bold>Example 3:</bold> Calculating two <italic>F</italic><sub>4</sub> statistics with <italic>xerxes</italic>, reproducing an analysis of Lamnidis et al. 2018 [<xref ref-type="bibr" rid="c31">31</xref>]. We assume the base directory (<monospace>-d .</monospace>) to include Poseidon packages with the groups <monospace>Mbuti</monospace>, <monospace>Nganasan</monospace>, <monospace>Lithuanian</monospace>,</p>
<p><monospace>Finland_Levanluhta</monospace> and <monospace>Russia_Bolshoy</monospace>. These happen to be described in the Community Archive packages <monospace>2018_Lamnidis_Fennoscandia</monospace> [<xref ref-type="bibr" rid="c31">31</xref>], <monospace>2014_LazaridisNature</monospace> [<xref ref-type="bibr" rid="c3">3</xref>] and <monospace>2012_PattersonGenetics</monospace> [<xref ref-type="bibr" rid="c24">24</xref>], but xerxes will find those automatically if they are stored below the base directory. The individual statistics are specified with <monospace>--stats</monospace> and a dedicated domain specific language. For complex analyses <italic>xerxes</italic> offers a more powerful configuration file interface with the <monospace>--statConfig</monospace> argument.</p>
<fig id="ufig4" position="float" fig-type="figure">
<graphic xlink:href="589180v2_ufig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p><bold>Example 4:</bold> An example of a configuration file for <italic>xerxes</italic>, specifying a total of 12 statistics of <italic>F</italic><sub>ST</sub> and <italic>F</italic><sub>4</sub> to be computed for all combinations of listed populations. In addition, the example features adhoc group definitions in the <monospace>groupDefs</monospace> section, which shows how to exclude individuals from a group using the minus-sign. More complex features of these configuration files include frequency-ascertainment, and selection of entire packages to act as groups.</p>
<p>We highlight three <italic>xerxes</italic> features that stand out: First, the user interface provides for a powerful way to specify families of statistics using combinatorical expansions. For example, users can specify in a configuration file (Example 4) that <italic>F</italic><sub>ST</sub> should be computed between all combinations of two lists of populations, and multiple such families can be requested simultaneously. Second, statistics can be easily adapted with custom group-definitions, in which individuals, groups or entire packages (similar to the <monospace>trident forge</monospace> selection language) can be excluded or included. If a specific individual turns out to be an outlier that should not be included in the computation of allele frequencies of its group, one can define a custom group and exclude that individual on the fly, without the need to change the underlying genotype definition files. Third, users do not have to specify the exact packages that their populations or individuals reside in, but can pass a base directory with dozens or hundreds of packages, and <italic>xerxes</italic> will automatically select only the relevant packages, involving the groups or individuals needed, thereby reducing memory- and run-time overhead: Similar to <monospace>trident forge</monospace>, <italic>xerxes</italic> uses stream-processing to merge the relevant genotype-files without the need to load large genotype matrices into memory. This is particularly important for dense genotyping data sets, for example involving tens of millions of SNPs as with the 1000 Genomes dataset [<xref ref-type="bibr" rid="c32">32</xref>].</p>
</sec>
<sec id="s3b3">
<label>4.2.3</label>
<title>qjanno (v1.0.0.0)</title>
<p><italic>qjanno</italic> is a command line tool implemented in Haskell to run SQL queries on .janno files (or arbitrary delimiter-separated text files) and therefore to conveniently subject the context data provided with Poseidon packages to a wide range of data transformations. It was built on top of a hard fork of v0.3.3 of the qsh package (<ext-link ext-link-type="uri" xlink:href="https://github.com/itchyny/qhs">https://github.com/itchyny/qhs</ext-link>, MIT-License). See Supplementary Text 6 for the <italic>qjanno</italic> user guide.</p>
<p>On startup, <italic>qjanno</italic> creates an SQLite [<xref ref-type="bibr" rid="c33">33</xref>] database in memory. It then reads the requested, well-structured text files, attributes each column a type and writes the contents of the files to tables in the in-memory database. It finally sends the user-provided SQL query to the database, waits for the result, parses it and returns it on the command line. The query gets pre-parsed to extract file names and then forwarded to an SQLite database server via the Haskell library sqlite-simple (<ext-link ext-link-type="uri" xlink:href="https://github.com/nurpax/sqlite-simple">https://github.com/nurpax/sqlite-simple</ext-link>). That means <italic>qjanno</italic> can parse and understand most SQLite3 syntax (see Example 5 and 6) with some minor exceptions (e.g. PRAGMA functions).</p>
<fig id="ufig5" position="float" fig-type="figure">
<graphic xlink:href="589180v2_ufig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p><bold>Example 5:</bold> A simple <italic>qjanno</italic> query on the command line. It extracts the columns <monospace>Poseidon_ID</monospace> and <monospace>Country</monospace> of the file <monospace>2018_Lamnidis_Fennoscandia.janno</monospace> and returns all rows where <monospace>Country</monospace> is not <monospace>‘Finland’</monospace>.</p>
<p><italic>qjanno</italic> does not have a complete understanding of the .janno-file structure, and mostly treats it like a normal .tsv file. But .janno files are still given special consideration with a number of pseudo-functions, which allow to search Poseidon packages and .janno files recursively to load them together into one database table (see Example 6).</p>
<fig id="ufig6" position="float" fig-type="figure">
<graphic xlink:href="589180v2_ufig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p><bold>Example 6:</bold> Another <italic>qjanno</italic> query. With <monospace>‘FROM d(.)’</monospace> <italic>qjanno</italic> searches all latest versions of Poseidon packages under the current working directory, reads their .janno files and appends them to a common database table. This table is then grouped by the <monospace>Date_Type</monospace> column (<italic>C14, contextual, modern</italic>). The output features a row-count for each group in a new summary column <monospace>n</monospace>.</p>
</sec>
<sec id="s3b4">
<label>4.2.4</label>
<title>janno R package (v1.0.0)</title>
<p>The <italic>janno</italic> R package simplifies loading and handling .janno files in R and the popular tidyverse [<xref ref-type="bibr" rid="c34">34</xref>] R package ecosystem. It provides a dedicated R S3 class <monospace>janno</monospace> that inherits from the <monospace>tibble</monospace> class to allow tidy reading and manipulating the context information in a Poseidon package (see Example 7). Supplementary Text 7 features its user guide.</p>
<fig id="ufig7" position="float" fig-type="figure">
<graphic xlink:href="589180v2_ufig7.tif" mimetype="image" mime-subtype="tiff"/>
<graphic xlink:href="589180v2_ufig7a.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p><bold>Example 7:</bold> A small R workflow enabled by the <italic>janno</italic> R package. The code is equivalent to the <italic>qjanno</italic> Example 6. <monospace>read_janno()</monospace> discovers and reads all .janno files under the current working directory into an object of classs <monospace>janno</monospace>. The dplyr verbs <monospace>group_by</monospace> and <monospace>summarise</monospace> can then be applied to this object to count the rows per <monospace>Date_Type</monospace> group.</p>
<p>As <italic>trident</italic> and <italic>qjanno</italic> (with <monospace>-d …</monospace>/<monospace>d(…)</monospace>), the package’s <monospace>read_janno()</monospace> function searches .janno files re-cursively under a given directory and loads them into a single data frame. The reading process includes validation according to the Poseidon schema. String list columns in .janno files are translated to true list columns in R. Beyond basic functionality (<monospace>print()</monospace>, <monospace>write_janno()</monospace>), the package features one more major function for <monospace>janno</monospace> objects: <monospace>process_age()</monospace>. This function processes the age information in the <monospace>Date_*</monospace> columns of the .janno file to derive a set of new columns useful for further chronological analysis via radiocarbon calibration: <monospace>Date_BC_AD_Prob</monospace> is a list column with the complete post-calibration probability distribution, <monospace>Date BC AD Median Derived</monospace> is the median of this distribution and <monospace>Date_BC_AD_Sample</monospace> stores <italic>n</italic> random samples drawn from it. The radiocarbon calibration is implemented with the <italic>Bchron</italic> R package [<xref ref-type="bibr" rid="c35">35</xref>].</p>
</sec>
</sec>
<sec id="s3c">
<label>4.3</label>
<title>Public archives</title>
<p>With a standardized, versioned data format, Poseidon does not require central infrastructure. Its software tools work independently and users can apply them locally on their own data. But Poseidon was also developed to mitigate the issue of increasingly tedious data preparation for future research projects. To that end, the Poseidon ecosystem includes three public, openly curated archives, which share implementation and infrastructure, but differ in their goals, mode of maintenance, and data content. See the <xref rid="fig4" ref-type="fig">Figures 4</xref> and <xref rid="fig5" ref-type="fig">5</xref> for an overview of the current data content in the archives. Supplementary Text 8 explains this comparison in more detail.</p>
<sec id="s3c1">
<label>4.3.1</label>
<title>Technical infrastructure</title>
<p>All archives are hosted in dedicated Git repositories on GitHub (e.g. <ext-link ext-link-type="uri" xlink:href="https://github.com/poseidon-framework/community-archive">https://github.com/poseidon-framework/community-archive</ext-link> for the PCA), where each individual package is stored in a directory named after the package. This setup has a number of advantages: Git provides version control down to the individual lines of each meta- and context data file, Git and GitHub together include co-working features that allow users to submit new packages and suggest concrete changes to existing ones, and GitHub is a comparatively affordable host with advanced automation features. Git is by default not suitable for large, binary files, but GitHub offers large file storage with the Git LFS extension. The archives make use of this for all .bed and .bim files. Each change in the public archives is automatically validated using GitHub Actions on their cloud infrastructure, running a number of scripts on the new state, including <monospace>trident validate</monospace>, to ensure continuous structural integrity.</p>
<p>As already introduced above for <monospace>trident list --remote</monospace> and <monospace>trident fetch</monospace>, the data in the public archives is not just available on GitHub, but also and more conveniently via a web API provided by an open web server running <monospace>trident serve</monospace>. This service is hosted by the scientific IT service provider of the Max Planck Society (Gesellschaft für wissenschaftliche Datenverarbeitung mbH Göttingen, <ext-link ext-link-type="uri" xlink:href="https://gwdg.de">https://gwdg.de</ext-link>). Once per day the server fetches the latest changes to the archives on GitHub and incorporates new packages and package versions. It does so through a Git-integrated bookkeeping mechanism using the hidden <italic>trident</italic> subcommands <monospace>chronicle</monospace> and <monospace>timetravel</monospace>. Note that the server also provides outdated package versions (for the community archive starting from 2023-06-12) to maintain computational reproducibility. Here are the endpoints the server supports:</p>
<list list-type="bullet">
<list-item><p><ext-link ext-link-type="uri" xlink:href="https://server.poseidon-adna.org/packages">https://server.poseidon-adna.org/packages</ext-link> returns a JSON list of all packages</p></list-item>
<list-item><p><ext-link ext-link-type="uri" xlink:href="https://server.poseidon-adna.org/groups">https://server.poseidon-adna.org/groups</ext-link> returns a JSON list of all groups</p></list-item>
<list-item><p><ext-link ext-link-type="uri" xlink:href="https://server.poseidon-adna.org/individuals">https://server.poseidon-adna.org/individuals</ext-link> returns a JSON list of all samples/individuals</p></list-item>
<list-item><p>https://server.poseidon-adna.org/zip_file/&lt;package_name&gt; returns a complete zip file of the package with the given name</p></list-item>
</list>
<p>The most important arguments for these are <monospace>?archive</monospace> to select the archive that should be queried, <monospace>?additionalJannoColumns</monospace> to add more detailed information to the <monospace>/individuals</monospace> response and <monospace>?package_version</monospace> to select a specific package version with <monospace>/zip_file</monospace>.</p>
</sec>
<sec id="s3c2">
<label>4.3.2</label>
<title>The Community Archive</title>
<p>The Poseidon Community Archive (PCA) stores author-submitted, article-wise Poseidon packages. It focuses on packages prepared by the authors of the respective publication, containing the exact genotype data used for the paper, to ensure a maximum of computational reproducibility. Author submissions are also ideal for the context data in the .janno file, because the respective domain-experts are generally most knowledgeable on data quality and the spatiotemporal origin of their samples.</p>
<p>For historical reasons the PCA does not only contain author submissions, though. To kickstart the public archive development in 2020, we prepopulated it with packages derived from in-house data and previous versions of the AADR, which have since then been further modified and edited, as is transparent in the version history of these packages. This legacy data will remain in the PCA to maintain established workflows. Authors and other community members can take ownership, update entries if need be, and thus have the possibility to (further) improve the quality of these datasets. A contributing guide on the Poseidon webpage explain the details of how to submit a new paper-associated dataset or suggest changes to an existing one. Each submission passes through a checklist-based review process and is eventually confirmed by the Poseidon core team. Contributors and original and intermediate authors are credited via publication keys and corresponding .bib entries, as well as a dedicated <monospace>Contributor</monospace> list in the package-defining POSEIDON.yml file.</p>
</sec>
<sec id="s3c3">
<label>4.3.3</label>
<title>The AADR Archive</title>
<p>The Poseidon AADR Archive (PAA) stores releases of the AADR dataset [<xref ref-type="bibr" rid="c13">13</xref>] reworked into Poseidon packages. It thus deviates from the PCA and the PMA in multiple important ways: It is not organized by individual publications, includes the versioning of the original provider on top of our own versioning, and relies to a lesser degree on community contributions. The cleaning and repackaging process is documented in an extra repository (<ext-link ext-link-type="uri" xlink:href="https://github.com/poseidon-framework/aadr2poseidon">https://github.com/poseidon-framework/aadr2poseidon</ext-link>) and mostly has the following goals: i) Creation of a version of the AADR that follows the Poseidon package standard and is thus directly compatible with <monospace>trident</monospace> and other Poseidon tooling, ii) increasing the machine-readability of the AADR, especially regarding the sample age information, and iii) providing clean .bib files with all references of publications in the AADR for convenient citation management.</p>
</sec>
<sec id="s3c4">
<label>4.3.4</label>
<title>The Minotaur Archive</title>
<p>The Poseidon Minotaur Archive (PMA) mirrors the PCA in that it stores publication-wise packages, often the very same as the PCA. However, Packages in the PMA do not rely on author-submitted genotype data, but instead include genotypes consistently reprocessed from raw sequencing data, run through the Minotaur workflow (see below). The motivation for this bioinformatic reprocessing is to generate an internally consistent dataset, which optimises cross-package comparability, rather than per-author reproducibility of individual packages – like the AADR.</p>
<p>The submission of packages to the PMA is less direct as for the PCA and involves the preparation of a per-package recipe to parameterize the relevant processing run. Package recipes are archived in a dedicated GitHub repository, where targeted GitHub Actions guide users through the necessary steps to create and submit a new recipe.</p>
</sec>
</sec>
<sec id="s3d">
<label>4.4</label>
<title>The Minotaur workflow</title>
<p>The reproducibility of our processing behind the PMA is achieved with a semi-automatic computational workflow to generate Poseidon packages from raw sequencing data: the Minotaur workflow. The entry point for this processing pipeline is a <italic>package recipe</italic>, a collection of files containing all the information required to download, validate, and process the raw reads into a Poseidon package. Each recipe must contain an .ssf file, a .tsv file formatted like a valid input .tsv for nf-core/eager [<xref ref-type="bibr" rid="c36">36</xref>], a .config file outlining the nf-core/eager configuration parameters for processing, a .sh script that adapts the .tsv file to the local cluster at the time of processing, and finally a .txt file listing all the versions of scripts used when creating the recipe, to ensure reproducibility.</p>
<p>Contributors are able to request packages via GitHub issues on the dedicated minotaur-recipes repository (<ext-link ext-link-type="uri" xlink:href="https://github.com/poseidon-framework/minotaur-recipes">https://github.com/poseidon-framework/minotaur-recipes</ext-link>), and actively prepare package recipes by providing a configured .ssf file. This .ssf file gets validated through GitHub Actions, and then complemented to a full recipe with all the required files. Each recipe submission passes through a checklist-based review process and is finally confirmed by the Poseidon core team. This approach is designed to standardise and streamline the processing through the Minotaur workflow, while still allowing enough flexibility in its configuration to account for the heterogeneity present in raw sequencing data.</p>
<p>The minotaur-recipes repository is mirrored in the computational cluster of MPI-EVA, where the actual processing takes place. In the future, we may outsource this processing to a publicly accessible cloud service to make it fully independent from a particular institution. The raw data is downloaded there, and processed through nf-core/eager with the parameters specified in the .config file of the package recipe. By default, this processing includes adapter trimming and read-pair collapsing, aligning to the human reference, removal or PCR duplicates, masking of the ends of reads to mitigate aDNA damage artefacts, and genotyping. Changes to processing parameters are permitted, and can be specified, explained and recorded in the package recipe. The genotypes generated from this processing are then turned into a Poseidon package, whose .janno file is populated with descriptive statistics generated during the processing.</p>
<p>All the code responsible for this pipeline can be found at <ext-link ext-link-type="uri" xlink:href="https://github.com/poseidon-framework/poseidon-eager">https://github.com/poseidon-framework/poseidon-eager</ext-link>. The resulting Poseidon package is finally uploaded to the PMA, where it again undergoes review before being added to the archive. During the review process, missing information for the package is filled in either manually, or pulled from the Community Archive, if appropriate.</p>
</sec>
</sec>
<sec id="s4">
<label>5</label>
<title>Discussion</title>
<p>Archaeogenetic research, as many other fast growing, data-driven fields, is challenged by data heterogeneity, a lack of systematically applied standards, and from difficulties to discover published data. Poseidon addresses these issues on multiple levels: First, Poseidon provides a standardised, yet flexible data format for day-to-day scientific data analysis, large scale automation, and tidy data storage. Our design choice to build Poseidon around the notion of packages, together with integration of bibliography information (the .bib file), emphasises good citation practice, with any downstream merging necessarily resulting in complete bibliography files listing all original source papers. Second, the Poseidon software, such as <italic>trident</italic>, to discover, validate, update, merge, subset and analyse such packages, complements the standard to ease adoption. Third, perhaps the most ambitious component of Poseidon, our public archives, make use of the standard and its versioning feature to host published data and make it findable and transparently maintainable via GitHub community features.</p>
<p>This multi-layer architecture, with loosely coupled components, allows for a variety of adoption paths or starting points for users and data analysts: The package format alone can serve as a useful storage format for local work, even without using the software or archives. The software can help to create and work with such packages locally, even without the cloud-features and server-access. Finally, our archives can be seen as a transparent hub to download and discover data, even without our software or adoption of the package format. In light of our developing research field and its position between disciplines, we designed the Poseidon package definition to allow for flexibility, e.g. by allowing arbitrary non-schema columns, as for example used in the PAA to incorporate some fields specific to that data source. Furthermore, we have placed the standard definition itself on GitHub to enable its long-term use as a “living standard”, which can be modified and developed further given emerging use-cases and practice from the community, after open discussion and review.</p>
<p>While the Poseidon package format combines various standard formats (e.g. YAML, .tsv, EIGENSTRAT) into its own package specification, opportunities exist to integrate it with larger systems in the Linked Open Data (LOD) world [<xref ref-type="bibr" rid="c37">37</xref>]. For example, many of the concepts used in our meta-data definitions exist already in public ontologies, which could be more tightly integrated into our format in the future. Specifically, for example, our <monospace>Country</monospace> field in the .janno file definition could link to entities in Wikidata [<xref ref-type="bibr" rid="c38">38</xref>] or other comparable LOD databases. Our decision for a light-weight flat-file setup has given us leeway to adjust the system exactly to our preferences and the requirements of the field, but integration with the Web of Data thus remains an open tasks for the future. To find partners to establish this uplink in future versions Poseidon is part of the NFDI4Objects initiative (<ext-link ext-link-type="uri" xlink:href="https://www.nfdi4objects.net">https://www.nfdi4objects.net</ext-link>).</p>
<p>Regarding infrastructure, Poseidon is currently very much dependent on GitHub. Following the example of other research data standards [<xref ref-type="bibr" rid="c39">39</xref>], all code, data, and issue-tracking is stored there, relying extensively on GitHub’s CI system (‘GitHub Actions’) for automatic code compilation and data validation. The lock-in into GitHub’s proprietary platform is slightly mitigated by the open Git format used for code- and data storage, but this is still a serious dependency, including factual drawbacks like a strict bandwidth limitation for large file data downloads.</p>
<p>Beyond these technical questions, finally, Poseidon is also exposed to some of the broader social challenges of scientific data management: Guiding the growth of a healthy community of developers, contributors and maintainers is not trivial. Poseidon currently depends on a small core team consisting of the authors of this paper. A growing number of active collaborators will require committing to a suitable governance system [<xref ref-type="bibr" rid="c40">40</xref>]. The work of the core team is currently funded by their employing institution, which also provides computational infrastructure and computing hours. If this commitment gets reduced in the middle-to long-term future, funding may become an increasingly pressing issue – a challenge shared by many research data management projects [<xref ref-type="bibr" rid="c41">41</xref>].</p>
<p>Critically the long-term success of Poseidon depends on scientists and generally practitioners in the field of archaeogenetics to reroute resources, not least time, into its development and maintenance, if they consider it valuable for their research and publications. With emerging initiatives like the HAAM Community (<ext-link ext-link-type="uri" xlink:href="https://haam-community.github.io">https://haam-community.github.io</ext-link>) and various working groups recently embracing Poseidon-based workflows and first papers referencing it explicitly ([<xref ref-type="bibr" rid="c42">42</xref>, <xref ref-type="bibr" rid="c43">43</xref>] and other forthcoming work) we indeed see positive signals towards wider adoption. Regardless of whether this development subsists and a community forms around Poseidon, the Poseidon data format and the software developed for it will remain permanently and openly available for future reference.</p>
</sec>
<sec id="d1e1288" sec-type="supplementary-material">
<title>Supporting information</title>
<supplementary-material id="d1e1379">
<label>Supplementary Text 1 - Package specification</label>
<media xlink:href="supplements/589180_file02.pdf"/>
</supplementary-material>
<supplementary-material id="d1e1386">
<label>Supplementary Text 2 - Janno details</label>
<media xlink:href="supplements/589180_file03.pdf"/>
</supplementary-material>
<supplementary-material id="d1e1393">
<label>Supplementary Text 3- Trident</label>
<media xlink:href="supplements/589180_file04.pdf"/>
</supplementary-material>
<supplementary-material id="d1e1400">
<label>Supplementary Text 4 - Xerxes</label>
<media xlink:href="supplements/589180_file05.pdf"/>
</supplementary-material>
<supplementary-material id="d1e1408">
<label>Supplementary Text 5 - Xerxes Whitepaper</label>
<media xlink:href="supplements/589180_file06.pdf"/>
</supplementary-material>
<supplementary-material id="d1e1415">
<label>Supplementary Text 6 - Qjanno</label>
<media xlink:href="supplements/589180_file07.pdf"/>
</supplementary-material>
<supplementary-material id="d1e1422">
<label>Supplementary Text 7 - Janno R package</label>
<media xlink:href="supplements/589180_file08.pdf"/>
</supplementary-material>
<supplementary-material id="d1e1429">
<label>Supplementary Text 8 - Archive Comparison</label>
<media xlink:href="supplements/589180_file09.pdf"/>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<label>6</label>
<title>Acknowledgements</title>
<p>This project has received funding from the Department of Archaeogenetics at the Max Planck Institute for Evolutionary Anthropology (MPI-EVA), the International Max Planck Research School for the Science of Human History at the Max Planck Institute for Geoanthropology (MPI-GEA), NFDI4Objects, so the the National research data infrastructure initiative by the German National Science foundation (DFG), and the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation program (grant agreement number 851511). The data processing with the Minotaur workflow heavily relies on computational facilities of MPI-EVA. We gratefully acknowledge insightful discussions with many current and former members of our department at MPI-EVA, most notably Selina Carlhoff, Luca Traverso, and Harald Ringbauer. Special thanks go to Michelle O’Reilly (MPI-GEA) who designed the Poseidon logo, specified the main colour palette for the website and revised the schematic overview <xref rid="fig1" ref-type="fig">Figures 1</xref> and <xref rid="fig2" ref-type="fig">2</xref>.</p>
</ack>
<sec id="s5">
<title>Supplementary Texts</title>
<list list-type="bullet">
<list-item><p>Supplementary Text 1: Poseidon package specification v2.7.1</p></list-item>
<list-item><p>Supplementary Text 2: .janno file details</p></list-item>
<list-item><p>Supplementary Text 3: Guide for <italic>trident</italic> v1.4.1.0</p></list-item>
<list-item><p>Supplementary Text 4: Guide for <italic>xerxes</italic> v1.0.1.0</p></list-item>
<list-item><p>Supplementary Text 5: <italic>xerxes</italic> theoretical background</p></list-item>
<list-item><p>Supplementary Text 6: Guide for <italic>qjanno</italic> v1.0.0.0</p></list-item>
<list-item><p>Supplementary Text 7: Guide for the <italic>janno</italic> R package v1.0.0</p></list-item>
<list-item><p>Supplementary Text 8: Comparison of the public archive content</p></list-item>
</list>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="journal"><string-name><given-names>Matthias</given-names> <surname>Meyer</surname></string-name> <etal>et al.</etal> “<article-title>A high-coverage genome sequence from an archaic Denisovan individual</article-title>”. <source>In: Science</source> <volume>338</volume>.<issue>6104</issue> (<year>2012</year>), pp. <fpage>222</fpage>–<lpage>226</lpage>. doi:<pub-id pub-id-type="doi">10.1126/science.1224344</pub-id>.</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="journal"><string-name><given-names>Kay</given-names> <surname>Prüfer</surname></string-name> <etal>et al.</etal> “<article-title>The complete genome sequence of a Neanderthal from the Altai Mountains</article-title>”. <source>In: Nature</source> <volume>505</volume>.<issue>7481</issue> (<year>2014</year>), pp. <fpage>43</fpage>–<lpage>49</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nature12886</pub-id>.</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><string-name><given-names>Iosif</given-names> <surname>Lazaridis</surname></string-name> <etal>et al.</etal> “<article-title>Ancient human genomes suggest three ancestral populations for present-day Europeans</article-title>”. <source>In: Nature</source> <volume>513</volume>.<issue>7518</issue> (<year>2014</year>), pp. <fpage>409</fpage>–<lpage>413</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nature13673</pub-id>.</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="journal"><string-name><given-names>Wolfgang</given-names> <surname>Haak</surname></string-name> <etal>et al.</etal> “<article-title>Massive migration from the steppe was a source for Indo-European languages in Europe</article-title>”. <source>In: Nature</source> <volume>522</volume>.<issue>7555</issue> (<year>2015</year>), pp. <fpage>207</fpage>–<lpage>211</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nature14317</pub-id>.</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="journal"><string-name><given-names>Ashot</given-names> <surname>Margaryan</surname></string-name> <etal>et al.</etal> “<article-title>Population genomics of the Viking world</article-title>”. <source>In: Nature</source> <volume>585</volume>.<issue>7825</issue> (<year>2020</year>), pp. <fpage>390</fpage>– <lpage>396</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41586-020-2688-8</pub-id>.</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="journal"><string-name><given-names>Joscha</given-names> <surname>Gretzinger</surname></string-name> <etal>et al.</etal> “<article-title>The Anglo-Saxon migration and the formation of the early English gene pool</article-title>”. <source>Nature</source> (<year>2022</year>), pp. <fpage>1</fpage>–<lpage>8</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41586-022-05247-2</pub-id>.</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="journal"><string-name><given-names>Morten</given-names> <surname>Rasmussen</surname></string-name> <etal>et al.</etal> “<article-title>Ancient human genome sequence of an extinct Palaeo-Eskimo</article-title>”. <source>In: Nature</source> <volume>463</volume>.<issue>7282</issue> (<year>2010</year>), pp. <fpage>757</fpage>–<lpage>762</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nature08835</pub-id>.</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="journal"><string-name><given-names>Qiaomei</given-names> <surname>Fu</surname></string-name> <etal>et al.</etal> “<article-title>DNA analysis of an early modern human from Tianyuan Cave, China</article-title>”. <source>In: Proceedings of the National Academy of Sciences of the United States of America</source> <volume>110</volume>.<issue>6</issue> (<year>2013</year>), pp. <fpage>2223</fpage>–<lpage>2227</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1221359110</pub-id>.</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="journal"><string-name><given-names>Nadin</given-names> <surname>Rohland</surname></string-name> <etal>et al.</etal> “<article-title>Three assays for in-solution enrichment of ancient human DNA at more than a million SNPs</article-title>”. <source>In: Genome research</source> <volume>32</volume>.<issue>11-12</issue> (<year>2022</year>), pp. <fpage>2068</fpage>–<lpage>2078</lpage>. doi:<pub-id pub-id-type="doi">10.1101/gr.276728.122</pub-id>.</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="journal"><string-name><given-names>Ewen</given-names> <surname>Callaway</surname></string-name>. “<article-title>‘Truly gobsmacked’: Ancient-human genome count surpasses 10, 000</article-title>”. <source>In: Nature</source> <volume>617</volume>.<issue>7959</issue> (<year>2023</year>), pp. <fpage>20</fpage>–<lpage>20</lpage>. doi:<pub-id pub-id-type="doi">10.1038/d41586-023-01403-4</pub-id>.</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="journal"><string-name><given-names>Kenneth</given-names> <surname>Katz</surname></string-name> <etal>et al.</etal> “<article-title>The Sequence Read Archive: a decade more of explosive growth</article-title>”. <source>In: Nucleic Acids Research</source> <volume>50</volume>.<issue>D1</issue> (<year>2021</year>), pp. <fpage>D387</fpage>–<lpage>D390</lpage>. doi:<pub-id pub-id-type="doi">10.1093/nar/gkab1053</pub-id>.</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="journal"><string-name><given-names>Josephine</given-names> <surname>Burgin</surname></string-name> <etal>et al.</etal> “<article-title>The European Nucleotide Archive in 2022</article-title>”. <source>In: Nucleic Acids Research</source> <volume>51</volume>.<issue>D1</issue> (<year>2022</year>), pp. <fpage>D121</fpage>–<lpage>D125</lpage>. doi:<pub-id pub-id-type="doi">10.1093/nar/gkac1051</pub-id>.</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="journal"><string-name><given-names>Swapan</given-names> <surname>Mallick</surname></string-name> <etal>et al.</etal> “<article-title>The Allen Ancient DNA Resource (AADR) a curated compendium of ancient human genomes</article-title>”. <source>In: Scientific Data</source> <volume>11</volume>.<issue>1</issue> (<year>2024</year>). doi:<pub-id pub-id-type="doi">10.1038/s41597-024-03031-7</pub-id>.</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="book"><string-name><given-names>Elgun</given-names> <surname>Jabrayilzade</surname></string-name> <etal>et al.</etal> “<chapter-title>Bus factor in practice</chapter-title>”. <source>In: Proceedings of the 44th International Conference on Software Engineering: Software Engineering in Practice</source>. <publisher-name>ACM</publisher-name>, <year>2022</year>. doi:<pub-id pub-id-type="doi">10.1145/3510457.3513082</pub-id>.</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="journal"><string-name><given-names>Mark D.</given-names> <surname>Wilkinson</surname></string-name> <etal>et al.</etal> “<article-title>The FAIR Guiding Principles for scientific data management and stewardship</article-title>”. <source>In: Scientific Data</source> <volume>3</volume>.<issue>1</issue> (<year>2016</year>). doi:<pub-id pub-id-type="doi">10.1038/sdata.2016.18</pub-id>.</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="journal"><string-name><given-names>Alkes L</given-names> <surname>Price</surname></string-name> <etal>et al.</etal> “<article-title>Principal components analysis corrects for stratification in genome-wide association studies</article-title>”. <source>In: Nature Genetics</source> <volume>38</volume>.<issue>8</issue> (<year>2006</year>), pp. <fpage>904</fpage>–<lpage>909</lpage>. doi:<pub-id pub-id-type="doi">10.1038/ng1847</pub-id>.</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="journal"><string-name><given-names>Nick</given-names> <surname>Patterson</surname></string-name>, <string-name><given-names>Alkes L.</given-names> <surname>Price</surname></string-name>, and <string-name><given-names>David</given-names> <surname>Reich</surname></string-name>. “<article-title>Population Structure and Eigenanalysis</article-title>”. <source>In: PLoS Genetics</source> <volume>2</volume>.<issue>12</issue> (<year>2006</year>), <fpage>e190</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pgen.0020190</pub-id>.</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="journal"><string-name><given-names>David H.</given-names> <surname>Alexander</surname></string-name>, <string-name><given-names>John</given-names> <surname>Novembre</surname></string-name>, and <string-name><given-names>Kenneth</given-names> <surname>Lange</surname></string-name>. “<article-title>Fast model-based estimation of ancestry in unrelated individuals</article-title>”. <source>In: Genome Research</source> <volume>19</volume>.<issue>9</issue> (<year>2009</year>), pp. <fpage>1655</fpage>–<lpage>1664</lpage>. doi:<pub-id pub-id-type="doi">10.1101/gr.094052.109</pub-id>.</mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="journal"><string-name><given-names>Iosif</given-names> <surname>Lazaridis</surname></string-name> <etal>et al.</etal> “<article-title>Genetic origins of the Minoans and Mycenaeans</article-title>”. <source>In: Nature</source> <volume>548</volume>.<issue>7666</issue> (<year>2017</year>), pp. <fpage>214</fpage>–<lpage>218</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nature23310</pub-id>.</mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="report"><string-name><given-names>Simon</given-names> <surname>Marlow</surname></string-name>, <collab>Haskell community</collab>,<article-title>Haskell 2010 Language Report</article-title>. [Online; accessed <date-in-citation content-type="access-date">2024-03-05</date-in-citation>]. Haskell.org, <year>2010</year>.</mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="software"><string-name><given-names>Tom</given-names> <surname>Preston-Werner</surname></string-name>. <data-title>Semantic Versioning</data-title>. <source>https://semver.org/</source> [Online; accessed <date-in-citation content-type="access-date">2024-03-19</date-in-citation>]. <year>2013</year>.</mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="journal"><string-name><given-names>Shaun</given-names> <surname>Purcell</surname></string-name> <etal>et al.</etal> “<article-title>PLINK: A Tool Set for Whole-Genome Association and Population-Based Linkage Analyses</article-title>”. <source>In: The American Journal of Human Genetics</source> <volume>81</volume>.<issue>3</issue> (<year>2007</year>), pp. <fpage>559</fpage>–<lpage>575</lpage>. doi:<pub-id pub-id-type="doi">10.1086/519795</pub-id>.</mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="journal"><string-name><given-names>Petr</given-names> <surname>Danecek</surname></string-name> <etal>et al.</etal> “<article-title>The variant call format and VCFtools</article-title>”. <source>In: Bioinformatics</source> <volume>27</volume>.<issue>15</issue> (<year>2011</year>), pp. <fpage>2156</fpage>– <lpage>2158</lpage>. doi:<pub-id pub-id-type="doi">10.1093/bioinformatics/btr330</pub-id>.</mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="journal"><string-name><given-names>Nick</given-names> <surname>Patterson</surname></string-name> <etal>et al.</etal> “<article-title>Ancient Admixture in Human History</article-title>”. <source>In: Genetics</source> <volume>192</volume>.<issue>3</issue> (<year>2012</year>), pp. <fpage>1065</fpage>–<lpage>1093</lpage>. doi:<pub-id pub-id-type="doi">10.1534/genetics.112.145037</pub-id>.</mixed-citation></ref>
<ref id="c25"><label>[25]</label><mixed-citation publication-type="journal"><string-name><given-names>Iain</given-names> <surname>Mathieson</surname></string-name> <etal>et al.</etal> “<article-title>Genome-wide patterns of selection in 230 ancient Eurasians</article-title>”. <source>In: Nature</source> <volume>528</volume>.<issue>7583</issue> (<year>2015</year>), pp. <fpage>499</fpage>–<lpage>503</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nature16152</pub-id>.</mixed-citation></ref>
<ref id="c26"><label>[26]</label><mixed-citation publication-type="confproc"><string-name><given-names>Isaac</given-names> <surname>Jones</surname></string-name>. “<article-title>The Haskell cabal: A common architecture for building applications and libraries</article-title>”. <conf-name>6th Symposium on Trends in Functional Programming</conf-name>. <year>2005</year>, pp. <fpage>340</fpage>–<lpage>354</lpage>.</mixed-citation></ref>
<ref id="c27"><label>[27]</label><mixed-citation publication-type="book"><string-name><given-names>Stefania Loredana</given-names> <surname>Nita</surname></string-name> and <string-name><given-names>Marius</given-names> <surname>Mihailescu</surname></string-name>. “<chapter-title>Haskell Stack</chapter-title>”. <source>In: Haskell Quick Syntax Reference</source>. <publisher-name>Apress</publisher-name>, <year>2019</year>, pp. <fpage>165</fpage>–<lpage>171</lpage>. doi:<pub-id pub-id-type="doi">10.1007/978-1-4842-4507-1_23</pub-id>.</mixed-citation></ref>
<ref id="c28"><label>[28]</label><mixed-citation publication-type="journal"><string-name><given-names>Björn</given-names> <surname>Grüning</surname></string-name> <etal>et al.</etal> “<article-title>Bioconda: sustainable and comprehensive software distribution for the life sciences</article-title>”. <source>In: Nature Methods</source> <volume>15</volume>.<issue>7</issue> (<year>2018</year>), pp. <fpage>475</fpage>–<lpage>476</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41592-018-0046-7</pub-id>.</mixed-citation></ref>
<ref id="c29"><label>[29]</label><mixed-citation publication-type="journal"><string-name><given-names>G</given-names> <surname>Bhatia</surname></string-name> <etal>et al.</etal> “<article-title>Estimating and interpreting FST: The impact of rare variants</article-title>”. <source>In: Genome research</source> <volume>23</volume>.<issue>9</issue> (<year>2013</year>), pp. <fpage>1514</fpage>–<lpage>1521</lpage>. doi:<pub-id pub-id-type="doi">10.1101/gr.154831.113</pub-id>.</mixed-citation></ref>
<ref id="c30"><label>[30]</label><mixed-citation publication-type="journal"><string-name><given-names>Frank M T A</given-names> <surname>Busing</surname></string-name>, <string-name><given-names>Erik</given-names> <surname>Meijer</surname></string-name>, and <string-name><given-names>Rien</given-names> <surname>Van Der Leeden</surname></string-name>. “<article-title>Delete-m Jackknife for Unequal m</article-title>”. <source>In: Statistics and computing</source> <volume>9</volume>.<issue>1</issue> (<year>1999</year>), pp. <fpage>3</fpage>–<lpage>8</lpage>. doi:<pub-id pub-id-type="doi">10.1023/A:1008800423698</pub-id>.</mixed-citation></ref>
<ref id="c31"><label>[31]</label><mixed-citation publication-type="journal"><string-name><given-names>Thiseas C.</given-names> <surname>Lamnidis</surname></string-name> <etal>et al.</etal> “<article-title>Ancient Fennoscandian genomes reveal origin and spread of Siberian ancestry in Europe</article-title>”. <source>In: Nature Communications</source> <volume>9</volume>.<issue>1</issue> (<year>2018</year>). doi:<pub-id pub-id-type="doi">10.1038/s41467-018-07483-5</pub-id>.</mixed-citation></ref>
<ref id="c32"><label>[32]</label><mixed-citation publication-type="journal"><collab>1000 Genomes Project Consortium et al</collab>. “<article-title>A global reference for human genetic variation</article-title>”. <source>In: Nature</source> <volume>526</volume>.<issue>7571</issue> (<year>2015</year>), pp. <fpage>68</fpage>–<lpage>74</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nature15393</pub-id>.</mixed-citation></ref>
<ref id="c33"><label>[33]</label><mixed-citation publication-type="journal"><string-name><given-names>Kevin P.</given-names> <surname>Gaffney</surname></string-name> <etal>et al.</etal> “<article-title>SQLite: Past, Present, and Future</article-title>”. <source>In: Proc. VLDB Endow</source>. <volume>15</volume>.<issue>12</issue> (<year>2022</year>), pp. <fpage>3535</fpage>–<lpage>3547</lpage>. doi:<pub-id pub-id-type="doi">10.14778/3554821.3554842</pub-id>.</mixed-citation></ref>
<ref id="c34"><label>[34]</label><mixed-citation publication-type="journal"><string-name><given-names>Hadley</given-names> <surname>Wickham</surname></string-name> <etal>et al.</etal> “<article-title>Welcome to the Tidyverse</article-title>”. <source>In: Journal of Open Source Software</source> <volume>4</volume>.<issue>43</issue> (<year>2019</year>), p. <fpage>1686</fpage>. doi:<pub-id pub-id-type="doi">10.21105/joss.01686</pub-id>.</mixed-citation></ref>
<ref id="c35"><label>[35]</label><mixed-citation publication-type="journal"><string-name><given-names>John</given-names> <surname>Haslett</surname></string-name> and <string-name><given-names>Andrew</given-names> <surname>Parnell</surname></string-name>. “<article-title>A Simple Monotone Process with Application to Radiocarbon-Dated Depth Chronologies</article-title>”. <source>In: Journal of the Royal Statistical Society Series C: Applied Statistics</source> <volume>57</volume>.<issue>4</issue> (<year>2008</year>), pp. <fpage>399</fpage>–<lpage>418</lpage>. doi:<pub-id pub-id-type="doi">10.1111/j.1467-9876.2008.00623.x</pub-id>.</mixed-citation></ref>
<ref id="c36"><label>[36]</label><mixed-citation publication-type="journal"><string-name><given-names>James A. Fellows</given-names> <surname>Yates</surname></string-name> <etal>et al.</etal> “<article-title>Reproducible, portable, and efficient ancient genome reconstruction with nf-core/eager</article-title>”. <source>In: PeerJ</source> <volume>9</volume> (<year>2021</year>), <fpage>e10947</fpage>. doi:<pub-id pub-id-type="doi">10.7717/peerj.10947</pub-id>.</mixed-citation></ref>
<ref id="c37"><label>[37]</label><mixed-citation publication-type="book"><string-name><given-names>Christian</given-names> <surname>Bizer</surname></string-name>, <string-name><given-names>Tom</given-names> <surname>Heath</surname></string-name>, and <string-name><given-names>Tim</given-names> <surname>Berners-Lee</surname></string-name>. “<chapter-title>Linked Data - The Story So Far</chapter-title>”. <source>In: Linking the World’s Information</source>. <publisher-name>ACM</publisher-name>, <year>2023</year>, pp. <fpage>115</fpage>–<lpage>143</lpage>. doi:<pub-id pub-id-type="doi">10.1145/3591366.3591378</pub-id>.</mixed-citation></ref>
<ref id="c38"><label>[38]</label><mixed-citation publication-type="journal"><string-name><given-names>Denny</given-names> <surname>Vrandečić</surname></string-name> and <string-name><given-names>Markus</given-names> <surname>Krötzsch</surname></string-name>. “<article-title>Wikidata: a free collaborative knowledgebase</article-title>”. <source>In: Communications of the ACM</source> <volume>57</volume>.<issue>10</issue> (<year>2014</year>), pp. <fpage>78</fpage>–<lpage>85</lpage>. doi:<pub-id pub-id-type="doi">10.1145/2629489</pub-id>.</mixed-citation></ref>
<ref id="c39"><label>[39]</label><mixed-citation publication-type="journal"><string-name><given-names>Robert</given-names> <surname>Crystal-Ornelas</surname></string-name> <etal>et al.</etal> “<article-title>A Guide to Using GitHub for Developing and Versioning Data Standards and Reporting Formats</article-title>”. <source>In: Earth and Space Science</source> <volume>8</volume>.<issue>8</issue> (<year>2021</year>). doi:<pub-id pub-id-type="doi">10.1029/2021ea001797</pub-id>.</mixed-citation></ref>
<ref id="c40"><label>[40]</label><mixed-citation publication-type="journal"><string-name><given-names>Dany</given-names> <surname>Di Tullio</surname></string-name> and <string-name><given-names>D. Sandy</given-names> <surname>Staples</surname></string-name>. “<article-title>The Governance and Control of Open Source Software Projects</article-title>”. <source>In: Journal of Management Information Systems</source> <volume>30</volume>.<issue>3</issue> (<year>2013</year>), pp. <fpage>49</fpage>–<lpage>80</lpage>. doi:<pub-id pub-id-type="doi">10.2753/mis0742-1222300303</pub-id>.</mixed-citation></ref>
<ref id="c41"><label>[41]</label><mixed-citation publication-type="journal"><string-name><given-names>Margreet</given-names> <surname>Bloemers</surname></string-name> and <string-name><given-names>Annalisa</given-names> <surname>Montesanti</surname></string-name>. “<article-title>The FAIR Funding Model: Providing a Framework for Research Funders to Drive the Transition toward FAIR Data Management and Stewardship Practices</article-title>”. <source>In: Data Intelligence</source> <volume>2</volume>.<issue>1–2</issue> (<year>2020</year>), pp. <fpage>171</fpage>–<lpage>180</lpage>. doi:<pub-id pub-id-type="doi">10.1162/dint_a_00039</pub-id>.</mixed-citation></ref>
<ref id="c42"><label>[42]</label><mixed-citation publication-type="journal"><string-name><given-names>Sanni</given-names> <surname>Peltola</surname></string-name> <etal>et al.</etal> “<article-title>Genetic admixture and language shift in the medieval Volga-Oka interfluve</article-title>”. <source>In: Current Biology</source> <volume>33</volume>.<issue>1</issue> (<year>2023</year>), <fpage>174</fpage>–<lpage>182</lpage>.e10. doi:<pub-id pub-id-type="doi">10.1016/j.cub.2022.11.036</pub-id>.</mixed-citation></ref>
<ref id="c43"><label>[43]</label><mixed-citation publication-type="journal"><string-name><given-names>Selina</given-names> <surname>Carlhoff</surname></string-name> <etal>et al.</etal> “<article-title>Genomic portrait and relatedness patterns of the Iron Age Log Coffin culture in northwestern Thailand</article-title>”. <source>In: Nature Communications</source> <volume>14</volume>.<issue>1</issue> (<year>2023</year>). doi:<pub-id pub-id-type="doi">10.1038/s41467-023-44328-2</pub-id>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.98317.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Carmi</surname>
<given-names>Shai</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>The Hebrew University of Jerusalem</institution>
</institution-wrap>
<city>Jerusalem</city>
<country>Israel</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Compelling</kwd>
<kwd>Exceptional</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This paper describes an <bold>important</bold> software framework for the curation, retrieval, and analysis of ancient human genomic data and their associated metadata, overcoming long-standing coordination and harmonization issues in ancient human genomics. The resource is built on <bold>compelling</bold> and sometimes <bold>exceptional</bold> principles of software engineering and reproducibility, and the authors make an excellent case that their resource will be of practical use to many researchers studying human history using DNA. The main issues include natural uncertainties regarding future funding and maintenance of this resource, as well as deviation from established standards in other areas of genomics.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.98317.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>The authors describe a framework for working with genotype data and associated metadata, specifically geared towards ancient DNA. The Poseidon framework aims to address long-standing data coordination issues in ancient population genomics research. These issues can usefully be thought of as two primary, separate problems:</p>
<p>(1) The genotype merging problem. Often, genotype calls made by a new study are not made publicly available, or they are only made available in an ad-hoc fashion without consistency in formatting between studies. Other users will typically want to combine genotypes from many previously published studies with their own newly produced genotypes, but a lack of coordination and standards means that this is challenging and time-consuming.</p>
<p>(2) The metadata problem. All genomes need informative metadata to be usable in analyses, and this is even more true for ancient genomes which have temporal and often cultural dimensions to them. In the ancient DNA literature, metadata is often only made available in inconsistently formatted supplementary tables, such that reuse requires painstakingly digging through these to compile, curate and harmonise metadata across many studies.</p>
<p>Poseidon aims to solve both of these problems at the same time, and additionally provide a bit of population genetics analysis functionality. The framework is a quite impressive effort, that clearly has taken a lot of work and thought. It displays a great deal of attention to important aspects of software engineering and reproducibility. How much usage it will receive beyond the authors themselves remains to be seen, as there is always a barrier to entry for any new sophisticated framework. But in any case, it clearly represents a useful contribution to the human ancient genomics community.</p>
<p>The paper is quite straightforward in that it mainly describes the various features of the framework, both the way in which data and metadata are organised, and the various little software tools provided to interact with the data. This is all well-described and should serve as a useful introduction for any users of the framework, and I have no concerns with the presentation of the paper. Perhaps it gets a bit too detailed for my taste at times, but it's up to the authors how they want to write the paper.</p>
<p>I thus have no serious concerns with the paper. I do have some thoughts and comments on the various choices made in the design of the framework, and how these fit into the broader ecosystem of genomics data. I wouldn't necessarily describe much of what follows as criticism of what the authors have done - the authors are of course free to design the framework and software that they want and think will be useful. And the authors clearly have done more than basically anyone else in the field to tackle these issues. But I still put forth the points below to provide some kind of wider discussion within the context of ancient genomics data management and its future.</p>
<p>* * *</p>
<p>The authors state that there is no existing archive for genotype data. This is not quite true. There is the European Variation Archive (EVA, <ext-link ext-link-type="uri" xlink:href="https://www.ebi.ac.uk/eva/">https://www.ebi.ac.uk/eva/</ext-link>), which allows archiving of VCFs and is interlinked to raw data in the ENA/SRA/DDBJ. If appropriately used, the EVA and associated mainstream infrastructure could in principle be put to good use by the ancient genomics community. In practice, it's basically not used at all by the ancient genomics community, and partly this is because EVA doesn't quite provide exactly what's needed (in particular with regards to metadata fields). Poseidon aims to provide a much more custom-tailored solution for the most common use cases within the human ancient DNA field, but it could be argued that such a solution is only needed because the ancient genomics community has largely neglected the mainstream infrastructure. In some sense, by providing such a custom-tailored solution that is largely independent of the mainstream infrastructure, I feel like efforts such as Poseidon (and AADR) - while certainly very useful - might risk contributing to further misaligning the ancient genomics community from the rest of the genomics community, rather than bringing it closer. But the authors cannot really be blamed for that - they are simply providing a resource that will be useful to people given the current state of things.</p>
<p>The BioSamples database (<ext-link ext-link-type="uri" xlink:href="https://www.ebi.ac.uk/biosamples/">https://www.ebi.ac.uk/biosamples/</ext-link>) is an attempt to provide universal sample IDs across the life sciences and is used by the archives for sequence reads (ENA/SRA/DDBJ). Essentially every published ancient sample already has a BioSample accession, because this is required for the submission of sequence reads to ENA/SRA/DDBJ. It would thus have seemed natural to make BioSamples IDs a central component of Poseidon metadata, so as to anchor Poseidon to the mainstream infrastructure, but this is not really done. There are some links being made to ENA in the .ssf &quot;sequence source&quot; files used by the Poseidon package, including sample accessions, but this seems more ad-hoc.</p>
<p>The package uses PLINK and EIGENSTRAT file formats to represent genotypes, which in my view are not particularly good formats for long-term and rigorous data management in genomics. These file formats cannot appropriately represent multiallelic loci, haplotype phase, or store information on genotype qualities, coverage, etc. The standard in the rest of genomics is VCF, a much more robust and flexible format with better software built around it. Insisting on keeping using these arguably outdated formats is one way in which the ancient genomics community risks disaligning itself from the mainstream.</p>
<p>I could not find any discussion of reference genomes: knowing the reference genome coordinate system is essential to using any genotype file. For comparison, in the EVA archive, every VCF dataset has a &quot;Genome Assembly&quot; metadata field specifying the accession number of the reference genome used. It would seem to me like a reference genome field should be part of a Poseidon package too. In practice, the authors likely use some variant of the hg19 / GRCh37 human reference, which is still widely used in ancient genomics despite being over a decade out of date. Insisting on using an outdated reference genome is one way in which the ancient genomics community is disaligning itself from the mainstream, and it complicates comparisons to data from other sub-fields of genomics.</p>
<p>A fundamental issue contributing to the genome merging problem, not unique to ancient DNA, is that genotype files are typically filtered to remove sites that are not polymorphic within the given study - this means that files from two different studies will often contain different and not fully overlapping sets of sites, greatly complicating systematic merging. I don't see any discussion of how Poseidon deals with this. In practice, it seems the authors are primarily concerned with data on the commonly used 1240k array set, such that the set of SNPs is always well-defined. But does Poseidon deal with the more general problem of non-overlapping sites between studies, or is this issue simply left to the user to worry about? This would be of relevance to whole-genome sequencing data, and there are certainly plenty of whole-genome datasets of great interest to the research community (including archaic human genomes, etc).</p>
<p>In principle, it seems the framework could be species-agnostic and thus be useful more generally beyond humans (perhaps it would be enough to add just one more &quot;species&quot; metadata field?). It is of course up to the authors to decide how broadly they want to cater.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.98317.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Schmid et al. provide details of their new data management tool Poseidon which is intended to standardise archaeogenetic genotype data and combine it with the associated standardised metadata, including bibliographic references, in a way that conforms to FAIR principles. Poseidon also includes tools to perform standard analyses of genotype files, and the authors pitch it as the potential first port of call for researchers who are planning on using archaeogenetic data in their research. In fact, Poseidon is already up and running and being used by researchers working in ancient human population genetics. To some extent, it is already on its way to becoming a fundamental resource.</p>
<p>Strengths:</p>
<p>A similar ancient genomics resource (The Ancient Allen Database) exists, but Poseidon is several steps ahead in terms of integration and standardisation of metadata, its intrinsic analytical tools, its flexibility, and its ambitions towards being independent and entirely community-driven. It is clear that a lot of thought has gone into each aspect of what is a large and dynamic package of tools and overall it is systematic and well thought through.</p>
<p>Weaknesses:</p>
<p>The main weakness of the plans for Poseidon, which admirably the authors openly acknowledge, is in how to guarantee it is maintained and updated over the long term while also shifting to a fully independent model. The software is currently hosted by the MPI, although the authors do set out plans to move it to a more independent venue. However, the core team comprising the authors is funded by the MPI, and so the MPI is also the main funder of Poseidon. The authors do state their ambition to move towards a community-driven independent model, but the details of how this would happen are a bit vague. The authors imagine that authors of archaeogenetic papers would upload data themselves, thereby making all authors of archaeogenetics papers the voluntary community who would take on the responsibility of maintaining Poseidon. Archaeogeneticists generally are committed enough to their field that there is a good chance such a model would work but it feels haphazard to rely on goodwill alone. Given there needs to be a core team involved in maintaining Poseidon beyond just updating the database, from the paper as it stands it is difficult to see how Poseidon might be weaned off MPI funding/primary involvement and what the alternative is. However, the same anxieties always surround these sorts of resources when they are first introduced. The main aim of the paper is to introduce and explain the resource rather than make explicit plans for its future and so this is a minor weakness of the paper overall.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.98317.1.sa3</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Schmid</surname>
<given-names>Clemens</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3448-5715</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Ghalichi</surname>
<given-names>Ayshin</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9104-0395</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Lamnidis</surname>
<given-names>Thiseas C.</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4485-8570</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Mudiyanselage</surname>
<given-names>Dhananjaya B. A.</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0004-9297-1644</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Haak</surname>
<given-names>Wolfgang</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2475-2007</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Schiffels</surname>
<given-names>Stephan</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1017-9150</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>We thank the editors and reviewers for their thorough engagement with the manuscript and their well-informed comments on the Poseidon framework. We are pleased to note that they consider Poseidon a promising and timely attempt to resolve important issues in the archaeogenetics community. We also agree with the main challenges they raise, specifically the lack of long-term, independent infrastructure funding at the time of writing, and various aspects of Poseidon that bear the potential to further consolidate a de-facto alienation of the aDNA community from the wider field of genomics.</p>
<p>Poseidon is indeed dependent on the Department of Archaeogenetics at MPI-EVA. For the short to middle-term future (3-5 years) we consider this dependency beneficial, providing a reliable anchor point and direct integration with one of the most proficient data-producing institutions in archaeogenetics. For the long term, as stated in the discussion section of the manuscript, we hope for a snowball effect in the dissemination and adoption of Poseidon to establish it as a valuable community resource that automatically attracts working time and infrastructure donations. To kickstart this process we have already intensified our active community outreach and teach Poseidon explicitly to (early career) practitioners in the field. We are aware of options to apply for independent infrastructure funding, for example through the German National Research Data Infrastructure (NFDI) initiative, and we plan to explore them further.</p>
<p>As the reviewers have noted, key decisions in Poseidon’s data storage mechanism have been influenced by the special path archaeogenetics has taken compared to other areas of genomics. The founding goal of the framework was to integrate immediately with established workflows in the field. Nevertheless we appreciate the concrete suggestions on how to connect Poseidon better with the good practices that emerged elsewhere. We will explicitly address the European Variation Archive in a revised version of the manuscript, deliberate embedding the BioSamples ID of the INSDC databases more prominently in the .janno file, prioritise support for VCF next to EIGENSTRAT and PLINK and add an option to clearly document the relevant human reference genome on a per-sample level. In the revised version of the text we will also explain the treatment of non-overlapping SNPs between studies by trident’s forge algorithm and how we imagine the interplay of different call sets in the Poseidon framework in general.</p>
<p>Beyond these bigger concerns we will also consider and answer the various more detailed recommendations thankfully shared by the reviewers, not least the question how we imagine Poseidon to be used by archaeologists and for archaeological data.</p>
</body>
</sub-article>
</article>