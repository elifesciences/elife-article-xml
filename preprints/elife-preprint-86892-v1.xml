<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">86892</article-id>
<article-id pub-id-type="doi">10.7554/eLife.86892</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.86892.1</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Judging the difficulty of perceptual decisions</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Löffler</surname>
<given-names>Anne</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="author-notes" rid="n1">†</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2572-4748</contrib-id>
<name>
<surname>Zylberberg</surname>
<given-names>Ariel</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n1">†</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Shadlen</surname>
<given-names>Michael N.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2011-2790</contrib-id>
<name>
<surname>Wolpert</surname>
<given-names>Daniel M.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Zuckerman Mind Brain Behavior Institute, Columbia University</institution>, New York, NY 10027, <country>USA</country></aff>
<aff id="a2"><label>2</label><institution>Department of Neuroscience, Columbia University</institution>, New York, NY 10027, <country>USA</country></aff>
<aff id="a3"><label>3</label><institution>Kavli Institute for Brain Science, Columbia University</institution>, NY 10027, <country>USA</country></aff>
<aff id="a4"><label>4</label><institution>Howard Hughes Medical Institute, Columbia University</institution>, NY 10027, <country>USA</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Wyart</surname>
<given-names>Valentin</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Inserm</institution>
</institution-wrap>
<city>Paris</city>
<country>France</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label><bold>For correspondence:</bold> <email>wolpert@columbia.edu</email> (DMW)</corresp>
<fn id="n1" fn-type="equal"><label>†</label><p>These authors contributed equally to this work</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2023-05-05">
<day>05</day>
<month>05</month>
<year>2023</year>
</pub-date>
<volume>12</volume>
<elocation-id>RP86892</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-02-13">
<day>13</day>
<month>02</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-02-14">
<day>14</day>
<month>02</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.02.13.528254"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2023, Löffler et al</copyright-statement>
<copyright-year>2023</copyright-year>
<copyright-holder>Löffler et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-86892-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Deciding how difficult it is going to be to perform a task allows us to choose between tasks, allocate appropriate resources, and predict future performance. To be useful for planning, difficulty judgments should not require completion of the task. Here we examine the processes underlying difficulty judgments in a perceptual decision making task. Participants viewed two patches of dynamic random dots, which were colored blue or yellow stochastically on each appearance. Stimulus coherence (the probability, <italic>p</italic><sub>blue</sub>, of a dot being blue) varied across trials and patches thus establishing difficulty, (<italic>p</italic><sub>blue</sub> – 0.5|. Participants were asked to indicate for which patch it would be easier to decide the dominant color. Accuracy in difficulty decisions improved with the difference in the stimulus difficulties, whereas the reaction times were not determined solely by this quantity. For example, when the patches shared the same difficulty, reaction times were shorter for easier stimuli. A comparison of several models of difficulty judgment suggested that participants compare the absolute accumulated evidence from each stimulus and terminate their decision when they differed by a set amount. The model predicts that when the dominant color of each stimulus is known, reaction times should depend only on the difference in difficulty, which we confirm empirically. We also show that this model is preferred to one that compares the confidence one would have in making each decision. The results extend evidence accumulation models, used to explain choice, reaction time and confidence to prospective judgments of difficulty.</p>
</abstract>
<counts>
<page-count count="29"/>
</counts>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>D.M.W is a consultant to CTRL-Labs Inc., in the Reality Labs Division of Meta. This entity did not support or influence this work. The authors declare no other competing interests.</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Estimating the difficulty of different tasks we might perform allows us to decide which task to engage in <xref ref-type="bibr" rid="c4"><italic><bold>Bennett-Pierre et al.</bold></italic> (<italic><bold>2018</bold></italic>)</xref>; <xref ref-type="bibr" rid="c42"><italic><bold>Wisniewski et al.</bold></italic> (<italic><bold>2015</bold></italic>)</xref>, allocate the necessary amount of effort or cognitive control <xref ref-type="bibr" rid="c36"><italic><bold>Shenhav et al.</bold></italic> (<italic><bold>2013</bold></italic>)</xref>; <xref ref-type="bibr" rid="c11"><italic><bold>Dunn et al.</bold></italic> (<italic><bold>2019</bold></italic>)</xref>, and predict our ability to perform the task successfully <xref ref-type="bibr" rid="c28"><italic><bold>Morgan et al</bold></italic>. (<italic><bold>2014</bold></italic>)</xref>; <xref ref-type="bibr" rid="c37"><italic><bold>Siedlecka et al.</bold></italic> (<italic><bold>2016</bold></italic>)</xref>; <xref ref-type="bibr" rid="c13"><italic><bold>Fleming et al.</bold></italic> (<italic><bold>2016</bold></italic>)</xref>; <xref ref-type="bibr" rid="c29"><italic><bold>Moskowitz et al</bold></italic>. (<italic><bold>2020</bold></italic>)</xref>. The need for difficulty estimation arises in a wide variety of human endeavors, from attempting different recipes and hiking routes to learning different languages. For example, consider a musician who is deciding which piece to learn to improve her skills. If the piece is too easy, she is likely to be bored, while if the piece is too difficult she may be frustrated, learning very little in either case. To make the correct choice, she must accurately estimate the difficulty of each potential piece given her current abilities. Attempting to learn each piece would lead to accurate estimates of their difficulty, yet this defies the purpose, since the difficulty estimation was sought to decide if the piece was worth learning in the first place. Alternatively, she could allocate a fixed period of time or learn the first few bars of each piece, or use cues like the length, key or tempo of each piece to estimate their difficulty.</p>
<p>Past studies of difficultyjudgments have mainly relied on complex tasks, like 5<sup>th</sup> grade students judging the difficulty of remembering a sentence <xref ref-type="bibr" rid="c39"><italic><bold>Stein et al.</bold></italic> (<italic><bold>1982</bold></italic>)</xref> or physics teachers evaluating the difficulty of different exam questions <xref ref-type="bibr" rid="c12"><italic><bold>Fakcharoenphol et al.</bold></italic> (<italic><bold>2015</bold></italic>)</xref>. This line of research highlights the important role that cues and heuristics play in estimating task difficulty <xref ref-type="bibr" rid="c41"><italic><bold>Vangsness and Young</bold></italic> (<italic><bold>2019</bold></italic>)</xref>. While the use of complex naturalistic tasks ensures that difficulty estimates are realistic, their complexity precludes quantitative modeling and thus the identification of the inference process underlying the formation of difficulty judgments.</p>
<p>Tasks that require consideration of multiple samples of evidence presented sequentially over time have advanced our understanding of the computational and neurophysiological underpinnings of decision making. In such tasks, the signal-to-noise ratio of the samples is varied across trials, and on each trial we can obtain the objective measures of choice (correct vs. incorrect) and reaction time. However, metacognitive judgments about the decision process itself, such as confidence and difficulty are also of interest. Decision confidence is often defined as the probability that a choice, just made, is correct or appropriate <xref ref-type="bibr" rid="c32"><italic><bold>Peirce and Jastrow</bold></italic> (<italic><bold>1884</bold></italic>)</xref>; <italic><bold>Kiani and Shadlen</bold></italic> (<italic><bold>2009</bold></italic>). Similarly, difficulty can be considered a metacognitive judgment, like confidence. In fact, confidence in a decision one has made can be converted to difficulty (the signal-to-noise ratio) if one knows how long it took to reach the decision <italic><bold>Kiani et al.</bold></italic> (<italic><bold>2014</bold></italic>). In this case confidence and difficulty are retrospective metacognitive judgments that emphasize, respectively, the probability of having chosen correctly and the effort that was required.</p>
<p>Difficulty estimation, can be prospective or retrospective, and can even be independent of task performance <xref ref-type="bibr" rid="c9"><italic><bold>Desender et al.</bold></italic> (<italic><bold>2017</bold></italic>)</xref>. For example, the musician may learn a piece and then judge its difficulty (a retrospective estimate), use her prior knowledge about the composer (a prospective estimate), or learn the first few bars and extrapolate its difficulty to the rest of the piece (both prospective and retrospective). Our interest is in prospective judgments of difficulty, for which confidence in the outcome of the decision can be viewed only as a prediction, governed by an assessment of difficulty and introspection about one’s own acumen.</p>
<p>Here we address how a subjective sense of difficulty is constructed from a sequence of evidence samples obtained from the environment, and how this difficulty decision is terminated. In our main experiment, human participants were presented with two visual stimuli (two flickering blue and yellow patches of dots) and had to report for which one it would be less difficult to make a decision about the dominant color. Our results show that judgments of difficulty obey a sequential sampling process similar to one that would be used to make a single decision about perceptual category. However, rather that accumulating evidence for color, difficulty judgments rely on tracking the difference in the absolute accumulated evidence for color judgments for the two stimuli.</p>
</sec>
<sec id="s2">
<title>Results</title>
<p>Participants performed variants of a perceptual task that required binary decisions about either one or two patches of dynamic random dot displays. In some blocks they reported the dominant color of one patch (Color judgment) or which of the two patches it would be easier to make a color judgment about (Difficulty judgment). The task was performed as a response time version (Experiment 1). We then evaluate models that explain the difficulty judgements and RTs. The best model makes a prediction, that we test in a second experiment.</p>
<sec id="s2a">
<title>Color judgments in a reaction time task (Experiment 1a)</title>
<p>Participants were first exposed to a colorjudgment task in which they were asked to decide whether the dominant color of a patch of dynamic random dots was yellow or blue (<xref ref-type="fig" rid="fig1">Figure 1 a</xref>) over a range of difficulties <xref ref-type="bibr" rid="c26"><italic><bold>Mante et al.</bold></italic> (<italic><bold>2013</bold></italic>)</xref>; <xref ref-type="bibr" rid="c3"><italic><bold>Bakkour et al</bold></italic>. (<italic><bold>2019</bold></italic></xref>); <xref ref-type="bibr" rid="c21"><italic><bold>Kang et al.</bold></italic> (<italic><bold>2021</bold></italic>)</xref>. The difficulty of the color choice was conferred by the probability that a dot would be colored blue (<italic>p</italic><sub>blue</sub>) or yellow (1-<italic>p</italic><sub>blue</sub>) on each frame. Therefore, the signed quantity <italic>C</italic><sup>±</sup> = 2(<italic>p</italic><sub>blue</sub> - 0.5), termed the color coherence, takes on positive values for blue dominant stimuli. We refer to the unsigned quantity <italic>C</italic> = |<italic>C</italic><sup>±</sup>| as color strength and this took on 6 different levels {0, 0.128, 0.256, 0.384, 0.512, 0.64}. The color strength determines the difficulty of the task with smaller strengths being more difficult. This task served to familiarize the participant with the task and instill the intuition that some decisions are more difficult than others. Only participants who performed above a set criterion (see <xref ref-type="sec" rid="s4">Methods</xref>) were invited to perform the main experiment. We refer to this task as a color judgment.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><p>Reaction time color and difflcultyjudgment tasks (Experiment 1). <bold>(a)</bold> Schematic of the color judgment task. Participants judged the dominant color of a single random-dot stimulus consisting of blue and yellow dots. <bold>(b)</bold> Proportion of correct choices (<italic>top</italic>) and reaction time (<italic>bottom</italic>) as a function of color strength. Solid lines show the average of fits of a standard drift diffusion model to each participants choices and RTs. Values of the fit parameters are shown in <xref ref-type="table" rid="tblS1">Table S1</xref>. Data points show mean ± 1 SEM from 20 participants. <bold>(c)</bold> Schematic of the difficulty judgment task. Participants decided for which of the two stimuli it was easier to judge the dominant color, regardless of whether that stimulus was blue or yellow dominant. <bold>(d)</bold> Proportion of trials in which stimulus 1 (S1) was chosen as the easier stimulus (top) and reaction times (bottom) as a function of the strength of S1 (abscissa) and S2 (colors). Open circles identify conditions where both patches have the same color strength (also plotted in inset). Data points show mean ± 1 SEM from 20 participants.</p></caption>
<graphic xlink:href="528254v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p><xref ref-type="fig" rid="fig1">Figure 1 b</xref> shows choice accuracy and reaction times (RTs) averaged across (<italic>N</italic> = 20) participants for color judgments. Participants’ choices and RTs varied according to color strength. As expected, participants chose the correct color more often, and they responded faster, when the strength increased. The data are well described by a standard drift-diffusion model (black lines) that explains the choice and RT by applying a stopping bound to the accumulation of the noisy color evidence (see <xref ref-type="sec" rid="s4">Methods</xref>). We refer to the accumulation of color evidence (blue minus yellow) as the color decision-variable, <italic>DV</italic>.</p>
</sec>
<sec id="s2b">
<title>Difficulty judgments in a reaction time task (Experiment 1b)</title>
<p>The main experiment required participants to make difficulty judgments (<xref ref-type="fig" rid="fig1">Figure 1 c</xref>) of two stimuli simultaneously presented to the left and right of a central fixation cross. Participants had to select the stimulus for which they thought it would be easier to decide what the dominant color would be, regardless of whether the patch was yellow or blue dominant. Importantly, in the difficulty judgment task, participants were never asked to report color decisions for either stimulus. In this task all 12 × 12 coherence combinations of the two stimuli were presented in a randomized order (see <xref ref-type="sec" rid="s4">Methods</xref>). We refer to this task as a difficulty judgment.</p>
<p>In the difficulty task, choice and RTs were affected by both the left (S1) and right (S2) stimulus strengths (<xref ref-type="fig" rid="fig1">Figure 1d</xref>). Participants chose S1 more often with increasing strength of S1 (<xref ref-type="fig" rid="fig1">Figure 1d</xref> top, abscissa) and decreasing strength of S2, and <italic>vice versa</italic>. The RTs exhibit a more complex pattern. For a given S1 strength (<xref ref-type="fig" rid="fig1">Figure 1d</xref> bottom, abscissa), RTs tend to be slowest when the strength of both stimuli are the same (open symbols), and the RTs accompanying these same matched difficulties are shorter for higher strength (<xref ref-type="fig" rid="fig1">Figure 1d</xref> bottom, inset). Therefore, the RTs are not simply a function of the difference between the two strengths. For example, RTs were significantly longer in the hard-hard (0:0, leftmost point in inse) combination (mean = 1.99 s, sd = 0.6) compared to easy-easy (0.64:0.64, rightmost point in inset) conditions (mean 1.30 s, sd = 0.36, difference in RT <italic>t</italic>(19) = 8.63, <italic>p</italic> &lt; 0.001, <italic>CI</italic>[0.52-0.85]). These tendencies lead to a criss-cross pattern in the RTs. For example, when S1 is difficult the shortest RT occurs when S2 is easy, wheres when S1 is easy, the longest RT occurs when S2 is easy. This leads to an inversion in the order of colors in the leftmost and rightmost stacks of points.</p>
<p>We developed four models (<xref ref-type="fig" rid="fig2">Fig. 2</xref>) of difficulty decisions and examined whether they could account for the choice and RT data. All models assume that for each stimulus (S1 and S2), momentary color evidence (MCE) for blue vs. yellow (positive for blue) is extracted at each point in time. The models differ in how they use this MCE to determine which stimulus is easier.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><p>Models of difficulty judgments. In each model, momentary color evidence (MCE) is obtained simultaneously from each of the two stimuli as the difference in proportion of blue vs. yellow dots on each frame. The models differ in i) how this momentary evidence is accumulated into a decision variable (second row) and ii) how the bounds are set for the decision (third row). For each model, an example of a simulation of a single-trial (fourth row) is illustrated in the 2D space of the decision variables <italic>DV</italic><sub><italic>S</italic>1</sub> and <italic>DV</italic><sub><italic>S</italic>2</sub> for the left (S1) and right (S2) stimuli. Each simulation shows a biased random walk that starts at the origin and terminates when it reaches one of the decision bounds. Decision bounds in green and blue correspond to S1 and S2 being judged the easier decision, respectively. For clarity, all bounds are illustrated as time-independent (although in the model they are allowed to collapse over time). The models predict different patterns of reaction times (RTs; bottom row) for different difficulty combinations of S1 (abscissa) and S2 (magenta = easy, yellow = hard). <bold>(a)</bold> The Race model, <bold>(b)</bold> the Difference model, <bold>(c)</bold> the Two-step model and <bold>(d)</bold> the Absolute momentary evidence model (gray area is not reachable as all accumulation is positive). See main text for model details.</p></caption>
<graphic xlink:href="528254v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<sec id="s2b1">
<title>Race model</title>
<p>In the <italic>Race model</italic>, the difficulty decision is determined by which of two color decisions terminates first, motivated by the regularity that more difficult stimuli typically require more samples of evidence.</p>
<p>In this model, MCE is accumulated into two independent decision variables, <italic>DV</italic><sub><italic>S</italic>1</sub> and <italic>DV</italic><sub><italic>S</italic>2</sub>, which represent the accumulated color evidence for the left and right stimulus, respectively. The single-trial example in <xref ref-type="fig" rid="fig2">Fig. 2a</xref> shows a schematic of the decision process, plotted as <italic>DV</italic><sub><italic>S</italic>2</sub> against <italic>DV</italic><sub><italic>S</italic>1</sub>. In this space the bounds form a square at ±<italic>B</italic> in each dimension. The decision variables both start at zero so that the trajectory starts at the origin and evolves as a function of time. The time dimension is not shown, so the displayed trajectory is the path of the decision variables up until the decision is made. The trajectory is confined to a space bounded by the green and blue termination bounds. The bounds are actually collapsing as a function of time but form a square at any point in time. Trajectories that reach the green or blue bound lead to S1 or S2 being judged as easier, respectively. In the example shown, S1 is judged as easier.</p>
<p>The bottom row of <xref ref-type="fig" rid="fig2">Fig. 2a</xref> shows the predicted pattern of RTs. When both color decisions are hard, difficulty choices are slow (long RT) since they depend on the winner of two slow processes. RTs decrease as either of the two color decisions becomes easier. When both color decisions are the easiest (0.64:0.64), RTs should be fastest since they reflect the minimum of two fast processes. This model, therefore, predicts that the shortest RTs occur when both stimuli are easiest, which is clearly contradicted by the data (e.g., the rightmost stack of points in <xref ref-type="fig" rid="fig1">Figure 1 d</xref>, bottom).</p>
</sec>
<sec id="s2b2">
<title>Difference model</title>
<p>In the <italic>Difference model</italic> (<xref ref-type="fig" rid="fig2">Fig. 2b</xref>), difficulty is determined by the difference between the absolute values of the decision variables, motivated by the intuition that the accumulation or weaker evidence is unlikely to traverse far from the origin compared to the accumulation of stronger evidence.</p>
<p>In this model the difficulty decision is made by computing |<italic>DV</italic><sub><italic>S</italic>1</sub>| - <italic>DV</italic><sub><italic>S</italic>2</sub>|. When this difference value reaches an upper/lower bound, then S1/S2 is chosen as the easier one. Thus, in contrast to the Race model, the decision boundary is applied to |<italic>DV</italic><sub><italic>S</italic>1</sub>| - |<italic>DV</italic><sub><italic>S</italic>2</sub>| instead of the individual <italic>DV<sub>S</sub></italic>. This gives rise to bounds that parallel the positive and negative diagonals on which |<italic>DV</italic><sub><italic>S</italic>1</sub>|-|<italic>DV</italic><sub><italic>S</italic>2</sub>| = 0. This leads to bounds that form channels emanating from the origin. Note that the four apices on the bounds are at (0, ±<italic><bold>B</bold></italic>) and (±<italic><bold>B</bold></italic>, 0), which correspond to where a decision would be made, that is |<italic>DV</italic><sub><italic>S</italic>1</sub>|-|<italic>DV</italic><sub><italic>S</italic>2</sub>| = ±<italic><bold>B</bold></italic>. Similarly, all other points on the bounds correspond to this difference being equal to ±<italic><bold>B</bold></italic>. Again, trajectories that reach the green or blue bound lead to S1 or S2 being judged as easier, respectively. In this example S2 is judged as easier.</p>
<p>The Difference model predicts a criss-cross pattern of RTs that is qualitatively similar to the data. The fastest RT occurs when S1 is easy and S2 is hard, as shown by the right end of the gold curve and the left end of the purple curve. When S2 is easy, the decisions take longer when S1 is also easy. Thus the curves must cross. The model also predicts that the easy-easy comparison takes less time than the hard-hard comparison (right end of purple compared to left end of gold). We will supply an intuition for this prediction under Experiment 2, which is designed to test it.</p>
</sec>
<sec id="s2b3">
<title>Two-step model</title>
<p>The <italic>Two-step model</italic> combines elements of the first two models and involves a two-step process. The motivation here is that if the dominant color of each stimulus were known, the difficulty decision would be simpler to compute and more accurate. Therefore, this model operates in two steps, the first of which estimates the dominant color of each stimulus and the second judges difficulty based on these estimates.</p>
<p>The Two-step model (<xref ref-type="fig" rid="fig2">Fig. 2c</xref>) first estimates the signs of the two strengths with a mini color decision (made at time <italic>t<sub>mini</sub></italic>). Similar to the Race model, the mini decision terminates as soon as one of the DVs has reached a bound. In the second step, further evidence is accumulated and a difficulty decision is made when
<disp-formula>
<alternatives><graphic xlink:href="528254v1_ueqn1.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula></p>
<p>For example, if S1 is estimated to have a positive coherence and S2 a negative coherence the decision should be made when <italic>DV</italic><sub><italic>S</italic>1</sub> + <italic>DV</italic><sub><italic>S</italic>2</sub> = ±<italic>B</italic>, whereas if both coherences are estimated to be positive the decision should be made when <italic>DV</italic><sub><italic>S</italic>1</sub> - <italic>DV</italic><sub><italic>S</italic>2</sub> = ±<italic><bold>B</bold></italic>.</p>
<p>This model predicts a similar RT pattern to the Difference model, but it requires one additional parameter: a decision bound for the initial color choice <italic><bold>B<sub>mini</sub></bold></italic>. The higher the bound, the longer the initial color decision will take, but the more accurate the estimate of the sign of each coherence will be. When both stimuli are hard, the initial color choice will be slow, thus causing overall longer RTs for hard-hard compared to easy-easy conditions. Additionally, similar to the Difference model, the duration of the second step depends on the difference in difficulty. When both stimuli are equally hard (or easy), the difference in DVs will take longer to reach a bound compared to conditions where the difference in difficulty is large. Thus, similar to the Difference model, this model predicts a crossing in the pattern of RTs where decisions about easy-easy stimuli take longer than decisions about easy-hard stimuli.</p>
</sec>
<sec id="s2b4">
<title>Absolute momentary evidence model</title>
<p>In the <italic>Absolute momentary evidence model</italic>, each decision variable represents the accumulated <italic>absolute</italic> momentary color evidence, as opposed to the signed evidence used in the first three models. The motivation here is the simplicity of accumulating momentary evidence bearing directly on difficulty. The obvious shortcoming is that this intuition is only valid if the samples have the same sign as the color coherence; in other words it ignores the contribution of noise.</p>
<p>In the model (<xref ref-type="fig" rid="fig2">Fig. 2d</xref>), on each frame absolute color strength is derived from each stimulus (independent of the color dominance of each frame) and the difference between these absolute color strength is accumulated over frames. A difficulty decision is made when the difference between the DVs reaches a bound.</p>
<p>Compared to the Difference model, the Absolute momentary evidence model generally predicts faster RTs for hard-hard conditions because any momentary evidence (regardless of sign) contributes to the accumulated differences between the two stimuli. The model also predicts slower RTs for easy-easy vs. easy-hard conditions due to the fact that differences in momentary evidence will generally be smaller when both stimuli have similar difficulty levels.</p>
</sec>
</sec>
<sec id="s2c">
<title>Model fitting</title>
<p>In each model, there are two separate streams of sensory evidence—one for each stimulus. For simplicity, we illustrate the models in <xref ref-type="fig" rid="fig2">Fig. 2</xref> as if the two streams of evidence were accumulated in parallel. However, in a previous study, we showed that decisions about two perceptual features (or two stimuli) are based on serial, time-multiplexed integration of decision evidence, causing longer reaction times for double-decisions compared to decisions about a single stimulus <xref ref-type="bibr" rid="c21"><italic><bold>Kang et al.</bold></italic> (<italic><bold>2021</bold></italic>)</xref>. We include this feature in our model, but its only consequence is to expand the decision times, without affecting distinguishing features of the models (see <xref ref-type="sec" rid="s4">Methods</xref> for additional explanation).</p>
<p>We fit all four models to each participant’s difficulty choices and RTs (see <xref ref-type="sec" rid="s4">Methods</xref> and Model Recovery). For each model, five parameters were optimized: a drift rate <italic>κ</italic> that relates coherence to the mean rate of accumulation of color evidence, three parameters controlling how each decision bound collapses over time, and a non-decision time <italic><bold>T</bold><sub>nd</sub></italic> reflecting sensory and motor processing time that add to the decision time to yield the measured reaction time. For the Two-step model, one additional parameter <italic><bold>B<sub>mini</sub></bold></italic> was required for the bound height of the initial color choice. We fit the model by maximum likelihood to each participant’s data individually.</p>
<p><xref ref-type="fig" rid="fig3">Figure 3</xref> shows model fits, averaged across participants (for parameters, see <xref ref-type="table" rid="tblS2">Tables S2</xref> to <xref ref-type="table" rid="tblS4">S4</xref> and <xref ref-type="table" rid="tbl1">Table 1</xref>). To compare the models we computed the Bayesian Information Criterion (BIC) for each model. This showed that the Difference model provided the best fit overall (group-level ΔBIC = 148.7 compared to the Two-step model, which was the second best). Compared to all other models, the Difference model was the preferred model for 12 out of 20 participants (<xref ref-type="fig" rid="fig3">Fig. 3</xref>, bottom row).</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><p>Reaction time difficulty judgment results (Experiment 1). Difficulty choices (top row) are shown as the proportion of trials in which participants chose S1 (left stimulus) as the easier stimulus. Reaction times are shown in the middle row. Data points are averages across participants (mean ± 1 SEM; <italic>N</italic> = 20). Lines represent model fits. Bottom row: ΔBIC values for each model, relative to BIC value of the winning model for each participant (hatched bars represent values &gt; 100).</p></caption>
<graphic xlink:href="528254v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><p>Fit parameter values for Difference model (Exp. 1).</p></caption>
<graphic xlink:href="528254v1_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>The Race model fails to capture the crossing of RTs for easy-easy vs. easy-hard stimuli since it predicts that decisions are fastest when both stimuli are easy. This model also fails systematically to explain the choice behavior (<xref ref-type="fig" rid="fig3">Fig. 3a</xref>, top). Overall, the Race model provides the poorest fit to participants’ data (group-level ΔBIC = 930.2 from Difference model).</p>
<p>The Absolute momentary evidence model provides a better fit to participants’ choices and correctly predicts the crossing of RTs. However, it underestimates RTs when both stimuli are hard. This is because in this model, any momentary evidence (regardless of sign) contributes to the difficulty decision. Consequently, this model also did not provide a good fit to the data overall (group-level ΔBIC = 509.0 from best model).</p>
<p>Finally, the fits obtained with the Difference model and Two-step model were very similar, and both provided a good fit to participants’ data. However, the Two-step model requires an extra parameter for the initial color bound. Consequently, compared to the Two-step model, the Difference model was the preferred model for 14 out of 20 participants. Because of the similarity of these models, we verified that model recovery could distinguish between these models. We generated 200 synthetic datasets using each model and then fit them with both models. The fitting procedure correctly classified (ΔBIC| &gt; 10) the correct model with 100 and 77% accuracy for the data generated by the difference and the two-step models, respectively (see <xref ref-type="sec" rid="s4">Methods</xref>).</p>
<p>In summary, we found support for a model in which difficulty is based on a moment-by-moment comparison of the absolute accumulated evidence from two stimuli.</p>
</sec>
<sec id="s2d">
<title>Optimal model</title>
<p>We model the decision process as a partially observable Markovian process (POMDP), and transform it into a fully observable Markov process (MDP) over the decision maker’s belief states. The belief states are uniquely defined by the tuple 〈<italic>t</italic><sub><italic>S</italic>1</sub>,<italic>t</italic><sub><italic>S</italic>2</sub>,<italic>DV</italic><sub><italic>S</italic>1</sub>,<italic>DV</italic><sub><italic>S</italic>2</sub>〉 where <italic>t<sub>x</sub></italic> is the time elapsed sampling stimulus <italic>x</italic> and <italic>DV<sub>x</sub></italic> is the accumulated evidence for stimulus <italic>x</italic>. Three actions are available in each belief state: choose the option <italic>S</italic>1, option <italic>S</italic>2, or continue gathering evidence (with evidence time shared equally between <italic>S</italic>1 and <italic>S</italic>2). The assignment of policies to belief states is deterministic: only one action is chosen in each state. Transitions between states, however, are stochastic, and depend on the coherences of the stimuli and noise, which is assumed Gaussian.</p>
<p>The behavior derived from the optimal decision policy (see <xref ref-type="sec" rid="s4">Methods</xref>) is qualitatively similar to that of the participants (<xref ref-type="fig" rid="fig4">Fig. 4a</xref>). Optimal performance shows a clear modulation by the strength of each stimulus. The proportion of correct responses and the decision speed are higher when strength is higher. The optimal models also captures the crossing of RTs for easy-easy vs. easy-hard stimuli that we observed in the data.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><p>Optimal policy. (a) Choices and response times obtained from simulations of the optimal model that maximizes the rate of correct choices (N=200,000 simulated trials). (b) The optimal decision policy is a deterministic mapping from a belief state to an action. The figure identifies the values of the decision variables for stimuli S1 and S2, for which it is optimal to continue sampling sensory information (shown in white) or commit to a choice (shown in grey). Each panel represents different time within a trial (where the time spent sampling each stimulus is t/2).</p></caption>
<graphic xlink:href="528254v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To determine which of the four models presented above is most similar to the optimal model, we performed simulations of the optimal model and fit the four models to the simulated data. The model that best accounted for the simulated data was the Difference model, followed by the Absolute momentary evidence model (Δ<italic>BIC</italic> = 2,847 relative to the Difference model), and the Two-step and Race models (Δ<italic>BIC</italic> = 6,949 and 15,465 respectively).</p>
<p>An analysis of the decision space of the optimal model allows us to identify similarities with the four models. In <xref ref-type="fig" rid="fig4">Fig. 4B</xref> we show the decision space of the optimal model for four different times (<italic>t</italic><sub><italic>S</italic>1</sub> + <italic>t</italic><sub><italic>S</italic>2</sub>). At early times, the decision space resembles that of the Difference model, in that the decision variable can diffuse along four paths defined by the possible signs of the color coherences. However, later in a trial, the regions where it is optimal to continue sampling evidence become disjoint. That is, the center of the graph is no longer a region where it is optimal to keep sampling information. This is because, if after prolonged deliberation the decision variable is still in the central region of the decision space, then it is reasonable to infer that the sensory evidence is weak, in which case it may be optimal to hasten the decision and move to the next trial rather than continue deliberating on a decision that has a high probability of being wrong. The logic is the same as why it is optimal to collapse decision boundaries over time in binary decisions <xref ref-type="bibr" rid="c14"><italic><bold>Frazier and Yu</bold></italic> (<italic><bold>2007</bold></italic>)</xref>; <xref ref-type="bibr" rid="c10"><italic><bold>Drugowitsch et al.</bold></italic> (<italic><bold>2012</bold></italic>)</xref>. Interestingly, such a disjoint decision space approximates an internal commitment to a decision about the sign of the color coherence, as in the Two-step model. We did not fit the parameters of the optimal model to the data as the experiment was not designed to incentivize maximization of the reward rate and fitting would have been computationally laborious. Although the difference model is in qualitative agreement with the optimal model.</p>
</sec>
<sec id="s2e">
<title>Difficulty judgments with unknown vs. known color dominance (Experiment 2)</title>
<p>The Difference model predicts that behavior should change if the color dominance of each patch is known. <xref ref-type="fig" rid="fig5">Figure 5a</xref> contrast the Difference model for an easy-easy vs. a hard-hard trial. When the drift component is small (hard-hard) the density of DVs across trials (orange circle) remains near the origin. When the drift component is large (easy-easy) the density moves into one of the channels (purple circle). Therefore, more density will cross the bound in the high drift case (grey hatched area for purple vs. orange circle), leading to RTs being shorter for the easy-easy condition compared to hard-hard condition (as in <xref ref-type="fig" rid="fig3">Fig. 3</xref>). However, if the color dominance of both stimuli is known then this changes the bounds as shown in <xref ref-type="fig" rid="fig5">Fig. 5b</xref>. In this example, both patches are known to be blue (positive) dominant. In this case the DVs can be compared in a signed manner where positive evidence corresponds to information in support of the known color, leading to a bound <italic>DV</italic><sub><italic>S</italic>1</sub> - <italic>DV</italic><sub><italic>S</italic>2</sub> = ±<italic>B</italic>, that is a simple channel (as in the Two-step model). In this case both hard-hard and easy-easy trials will on average cross the bound at the same rate and faster in general than in the unknown color condition. When the dominant colors are known, (<italic>i</italic>) reaction times should be faster overall, and (<italic>ii</italic>) reaction times should only depend on the difference in strengths between the stimuli, that is on ΔC = |C<sub><italic>S</italic>1</sub> - C<sub><italic>S</italic>2</sub>| (i.e., reaction times for 0:0 and 0.64:0.64 strengths should be the same).</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Reaction time task for unknown vs. known color dominance.</title>
<p><bold>(a &amp; b)</bold> Schematic illustration of the unknown-vs. known-color tasks. For each condition, the dispersion of DVs is represented in the 2D space of <italic>DV</italic><sub><italic>S</italic>1</sub> (abscissa) and <italic>DV</italic><sub><italic>S</italic>2</sub> (ordinate), assuming a constant noise in the drift diffusion process independent of strength. To provide intuition colored circles show the dispersion expected without absorption at the bounds and represent contours of equal density of the decision variable. Green and blue lines represent decision boundaries (B) for S1 and S2 being easier. <bold>(a)</bold> In the unknown-color condition, the Difference model computes the difference between the two absolute DVs. <bold>(b)</bold> In the known-color condition (example shown is for both stimuli blue dominant), the model compares the signed DVs, resulting in a larger region where the DV dispersion crosses the bounds (shaded areas). Thus, when both stimuli are blue-dominant, yellow (negative) evidence for S1 contributes to the decision that S2 is the easier stimulus.</p></caption>
<graphic xlink:href="528254v1_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We test both of these predictions in an additional experiment on three participants, with the same basic paradigm as Experiment 1. However, in some blocks of trials, participants were informed that both stimuli would be blue dominant or both yellow dominant (‘known color’ condition). In the other blocks they did not receive any instructions about the stimulus color so that, as in Experiment 1, each stimulus could either be blue or yellow dominant (‘unknown color’ condition). For the unknown color condition, only trials in which both patches had the same color dominance were included in the analyses. This ensured better comparability with performance in the known-color blocks (where both stimuli by definition always had the same color).</p>
<p>We first replicate the findings from Experiment 1, as shown in the left column of <xref ref-type="fig" rid="fig6">Fig. 6a</xref>. To evaluate the predictions, we also plot the data as a function of the difference in strength (<xref ref-type="fig" rid="fig6">Fig. 6a</xref>, right column). This way of plotting the RT highlights the fact that the RTs depend on more than the difference in strengths (i.e., also the strengths of S2, colors). The curves are fits of the Difference model.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><p>Reaction time task for unknown vs. known color dominance (Experiment 2a). <bold>(a)</bold> Unknown color condition. Proportion of S1 choices (top row) and reaction times (bottom row) plotted as a function of strength of S1 (left column) and difference of strengths of the two stimuli (right column). Lines show the fit of the Difference model. <bold>(b)</bold> as <bold>a</bold> for the known color condition. Lines show the predictions of behavior when the color dominance is known (correct sign applied as in <xref ref-type="fig" rid="fig7">Fig. 7b</xref>) based on the parameters obtained in the fit to <bold>a</bold>. <bold>(c)</bold> Comparison of overall choice performance and RTs in the known vs. unknown-color condition as a function of the absolute difference in strength levels (data mean ± 1 SEM across 3 participants).</p>
<p><bold><xref ref-type="fig" rid="figS6a">Figure 6—figure supplement 1</xref>.</bold> As main figure but with lines showing the fit of the Confidence model to the unknown color condition and predictions for the known color condition.</p></caption>
<graphic xlink:href="528254v1_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p><xref ref-type="fig" rid="fig6">Figure 6b</xref> shows the results for the same participants when the color dominance was known. The choice behavior (top row) is only subtly different from the unknown condition (<xref ref-type="fig" rid="fig6">Figure 6a</xref>) for reasons explained below. However there is a striking, qualitative difference in the pattern of RTs. Consistent with prediction, the RTs appear to depend only on the difference in strengths (<xref ref-type="fig" rid="fig6">Fig. 6b</xref>, bottom right), and they are faster when the color dominance is known (<xref ref-type="fig" rid="fig6">Fig. 6c</xref>). Note that all solid curves accompanying the <italic>known color</italic> data in panels <xref ref-type="fig" rid="fig6">Figure 6b</xref> &amp; <xref ref-type="fig" rid="fig6">c</xref> are not fits but predictions of the best fitting model to the <italic>unknown color</italic> condition.</p>
<p>To quantify the extent to which the difference in strengths (ΔC) explains RTs in the known vs. unknown conditions, we compared the variance explained by the six unique ΔC levels for the two conditions. The increase in variance explained under the known color dominance is highly significant for all participants (<italic>F</italic><sub>176,1290</sub> = 1.31, 1.41, 1.39 all p&lt; 10<sup>-6</sup>). Further, in the known color condition only one of the three participants showed a significant explanatory effect of C<sub><italic>S</italic>2</sub> on RT beyond its contribution to ΔC (p=0.002, 0.15 and 0.68 for the three participants; ANOVA of RT as additive in ΔC and C<sub><italic>S</italic>2</sub>, 6 levels each).</p>
<p>Examining choice as a function of the difference in strengths (<xref ref-type="fig" rid="fig6">Fig. 6c</xref>) shows that accuracy of difficulty choices was similar in the two conditions (mean <italic>P</italic>(Correct) = 0.87, sd = 0.014 for known and 0.86, sd = 0.018 for unknown condition; Fisher exact test, p&gt;0.12 for each participant). However, RTs were significantly faster in known vs. unknown condition (mean = 1.08 s, sd = 0.19 vs. 1.15 s, sd = 0.31). A two-way ANOVA of RT by condition (2 levels: known vs. unknown)× ΔC (6 levels) gave a main effect of condition <italic>p</italic> &lt; 10<sup>-8</sup> for all participants. Taken together, this suggests that similar bounds are used in the unknown and known color conditions as accuracy is similar. However, in the unknown color condition it takes longer, on average, to reach the bound (as in <xref ref-type="fig" rid="fig5">Fig. 5a</xref> vs. <xref ref-type="fig" rid="fig5">b</xref>) leading to longer RTs.</p>
<sec id="s2e1">
<title>Difference in confidence model</title>
<p>Up to now we have considered models that base difficulty on the color evidence, without requiring a decision about color dominance. We next consider the possibility that the difficulty comparison is actually a confidence judgment in disguise—that is the confidence one would assign to the two color dominance decisions were they made at each moment in time. Confidence is a mapping from DV and time into the log-odd of being correct if one were to choose the color (<italic><bold><xref ref-type="bibr" rid="c22">Kiani and Shadlen, 2009</xref></bold></italic>; <italic><bold><xref ref-type="bibr" rid="c23">Kiani et al., 2014</xref></bold></italic>). Our known color condition makes this seem unlikely as participants have no uncertainty about the color of each patch and, therefore, should have full confidence in both color estimates (so that the difference in confidence should be zero). It is not inconceivable, however, that participants evaluate a <italic>counterfactual</italic> form of confidence even in the known color condition—something to the effect of,”How confident would I be in the color choice if I did not know the color?”</p>
<p>We fit difficulty judgments to the unknown color condition by calculating the confidence for each decision, that is the probability (log-odds) of being correct if one were to choose the color dominance based on the sign of the DV. In the confidence model, the difficulty decision is made when the difference in absolute confidence for each stimulus reaches a bound. The fits of the confidence model are very poor (ΔBIC = 38, 56, 47 for participants 1 to 3, in favor of the Difference model; fit parameters: <xref ref-type="table" rid="tblS7">Table S7</xref>), and the model fails to explain the known color condition (<italic><bold><xref ref-type="fig" rid="figS6a">Figure 6—figure Supplement 1</xref></bold></italic>). The reason for this failure may be understood as follows. In the Difference model the decision only depends on the difference in the two DVs and not on the level of either DV. In contrast, the difference in confidence depends on the difference in DVs as well as the actual level of each DV. Indeed, confidence increases supra-linearly with DV such that a 0.64:0.64 coherence trial will tend to have a bigger difference in confidence than a 0:0 trial, which would lead to much shorter RTs for the former. This leads to the confidence model failing to explain the range of RTs apparent in the data (<italic><bold><xref ref-type="fig" rid="figS6a">Figure 6—figure Supplement 1</xref></bold></italic>).</p>
</sec>
<sec id="s2e2">
<title>Controlled duration task</title>
<p>In addition to the RT version of the task, the participants performed a version of the task in which viewing duration was controlled by the experimenter. Stimulus duration was sampled from a truncated exponential distribution leading to an equal probability of 6 discrete durations: {0.1, 0.15, 0.25, 0.45, 0.85, 1.65} s. Participants had to wait for the stimuli to disappear before indicating their response. Again there were blocks with unknown color dominance and blocks with known color dominance. The Difference model predicts that accuracy should be better in the known color dominance condition.</p>
<p><xref ref-type="fig" rid="fig7">Fig. 7</xref> shows the decision accuracy as a function of stimulus duration for the difficulty tasks, for both known (solid red) and unknown (hollow red) color. As expected, accuracy improved with longer stimulus durations. More importantly, choice accuracy was generally higher in blocks with known color (accuracy across durations: mean <italic>P</italic>(Correct) = 0.82, sd = 0.01) compared to blocks with unknown color (mean <italic>P</italic>(Correct) = 0.76, sd = 0.01; Fisher exact test, <italic>p</italic> 0.001 for each participants).</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7.</label>
<caption><title>Controlled duration task for unknown vs. known color dominance.</title>
<p>Performance in the controlled-duration task for difficulty judgments in the known-(solid-red) and unknown-color condition (open-red). Participants’ accuracy (mean ± 1 SEM) is shown for each stimulus duration. Here, we exclude trials which had no objective correct answer (i.e. trials in the difficulty task where S1 and S2 had the same strength). Lines illustrate model fits for the 6 stimulus times used in the experiment. Results are shown for individual participants.</p></caption>
<graphic xlink:href="528254v1_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We fit a single DDM model simultaneously to each participant’s choices for both difficulty tasks (solid and dashed lines in <xref ref-type="fig" rid="fig7">Fig. 7</xref>). For the unknown-color task we used the Difference model as in Experiment 1 (i.e. using the equation shown in <xref ref-type="fig" rid="fig5">Fig. 5a</xref>). For the known-color task, we set the signs of the DVs according to the true color dominance (as in <xref ref-type="fig" rid="fig5">Fig. 5b</xref>).</p>
<p>The model has four parameters (fit parameters <xref ref-type="table" rid="tblS6">Table S6</xref>): a drift rate coefficient (<italic>κ</italic>) and three parameters controlling how each decision bound collapses over time (as in the RT experiments). Previous work has shown that although evidence integration is serial, there is a buffer that can store a limited amount sensory information from both streams of evidence <xref ref-type="bibr" rid="c31"><italic><bold>Pashler</bold></italic> (<italic><bold>1994</bold></italic>)</xref>. This means information can be acquired in parallel until the buffer is full and then the accumulation happens in a multiplexed manner <xref ref-type="bibr" rid="c21"><italic><bold>Kang et al.</bold></italic> (<italic><bold>2021</bold></italic>)</xref>. We included a 80 ms buffer in the model, that represents the duration of the two stimulus streams that can be held in short-term memory. The buffer simply accommodates the observation that decision makers use all the information from both stimuli when they are presented for very short durations. Indeed, we found that the model with buffer was superior to a model without a buffer for all three participants (log<sub>10</sub> BF = 2.1, 2.1, 1.3 in favor of the model that includes the buffer).</p>
<p>An alternative explanation for the accuracy improvements is that the difficulty judgment is always based on the absolute DVs (as in <xref ref-type="fig" rid="fig5">Fig. 5a</xref>) but that the drift rate might be higher when participants know the correct color. For example, integration might be more efficient when focusing on evidence that is consistent with the instructed color. We therefore compared our model with an alternative model in which we allowed two different <italic>κ</italic> parameters—one for the known-color and one for the unknown-color condition. Model comparison reveals that the more parsimonious model with a single <italic>κ</italic>, across both conditions was preferred overall and strongly for two of the participants: log<sub>10</sub> BF = 8.7 (group level) and 4.77, 4.74, −0.85 (participants) in favor of the single <italic>κ</italic> model.</p>
<p>In summary, Experiment 2 provides evidence that knowing the correct color improves the accuracy and speed of difficulty judgments despite the fact that color identity is not relevant for the final difficulty choice. This effect is explained by the Difference model: when the correct color is known, difficulty judgments are based on a comparison of appropriately signed DVs, which provide more information than the unsigned absolute strength of evidence, as explained above.</p>
</sec>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Tasks that require consideration of multiple samples of evidence serve to elucidate the cognitive and neurophysiological mechanisms of decision making <xref ref-type="bibr" rid="c17"><italic><bold>Gold et al.</bold></italic> (<italic><bold>2007</bold></italic>)</xref>; <xref ref-type="bibr" rid="c6"><italic><bold>Brody and Hanks</bold></italic> (<italic><bold>2016</bold></italic>)</xref>. They promote the framework of sequential sampling with optional stopping, which unifies accounts of choice accuracy, response time, and confidence <italic><bold>Kiani et al.</bold></italic> (<italic><bold>2014</bold></italic>); <italic><bold>Van Den Berg et al.</bold></italic> (<italic><bold>2016</bold></italic>). In this paper we build on this sequential sampling framework to understand how people construct a subjective estimate of the difficulty of a decision. In many circumstances, one might judge the relative difficulty of two tasks by performing them and comparing accuracy, confidence and decision time—in a word, experience. We were intrigued by the possibility that relative difficulty of two decisions could be determined directly by accumulating a transformed version of the evidence used to make the perceptual decisions. We show that this is possible and, moreover, the process is distinct from the perceptual decisions. In some cases, the difficulty decision is made faster than at least one of the perceptual decisions (e.g., the difficult perceptual decision when the other stimulus is very easy). In other cases, the two perceptual decisions are almost certainly completed before the difficulty decision (e.g., when color decisions are both very easy).</p>
<p>Studies of subjective beliefs, such as difficulty and confidence, often rely on numerical scales or discrete categorizations (e.g., <italic><bold><xref ref-type="bibr" rid="c43">Yildirim et al., 2019</xref></bold></italic>; <italic><bold><xref ref-type="bibr" rid="c2">Ais et al., 2016</xref></bold></italic>; <italic><bold><xref ref-type="bibr" rid="c40">Van Den Berg et al., 2016</xref></bold></italic>). This is in some ways more intuitive and more germane, perhaps, to real world judgments, which do not always warrant a comparison (but see <italic><bold><xref ref-type="bibr" rid="c18">Gweon et al., 2017</xref></bold></italic>). We pursued the comparison as it allowed us to relate the difficulty decision to quantities that are known to govern the simple decision. Moreover, comparative judgments of difficulty allow us to ignore participant-specific attributes of the estimation (e.g., a task may be more difficult for one participant than for another one), and the idiosyncrasies involved in mapping a subjective quantity to a numeric scale <xref ref-type="bibr" rid="c25"><italic><bold>Mamassian</bold></italic> (<italic><bold>2020</bold></italic>)</xref>. Measuring the time it took our participants to form their judgments of difficulty allowed us to test between different mechanisms. An appealing possibility is that participants decided which of the lower-level decisions was easier by estimating the confidence they would have in the accuracy of these decisions, calculated independently for each decision, before choosing the one for which their confidence was higher. If this were the case, we should have seen that the low-level decision that was completed first was chosen as the easiest, as in the Race model, given that there is, on average, a monotonic relationship between confidence and response time <italic><bold>Kiani et al.</bold></italic> (<italic><bold>2014</bold></italic>); <xref ref-type="bibr" rid="c20"><italic><bold>Johnson</bold></italic> (<italic><bold>1939</bold></italic>)</xref>. This would predict that easy-easy trials should be the fastest, which was not the case. Accordingly, the Race model was not favored in a model comparison.</p>
<p>The model that best explained the difficulty choices and reaction times (Difference model) was one in which participants accumulate information about the predominant color—which would be used to resolve each low-level decision—and the decision about difficulty is based on the comparison of the accumulated evidence for the two color decisions. The decision about difficulty terminates when the difference between the absolute values of the evidence accumulated by the low-level decisions crosses a threshold. The model makes concrete the idea of difficulty estimation as a metacognitive process, as the evidence for the difficulty judgment is given by the output of lower-level decisions, thus instantiating a processing hierarchy.</p>
<p>The reaction time for difficulty judgments did not just depend on the difference in difficulty between the two color decisions. Specifically, responses were faster, when the sum of the color strengths was larger (i.e., a ‘magnitude’ effect) even if the difference in difficulty was the same. This effect has a parallel in value-based decision making. For instance, when people choose between two highly desirable items, the decision is faster than when the items are both less desirable, even if the decisions are difficult because the pairs comprise items of approximately equal value <xref ref-type="bibr" rid="c38"><italic><bold>Smith and Krajbich</bold></italic> (<italic><bold>2019</bold></italic>)</xref>. This effect can be explained by arguing that attention fluctuates between both items under comparison and that attention has a multiplicative effect on the subjective value of the unattended item <xref ref-type="bibr" rid="c38"><italic><bold>Smith and Krajbich</bold></italic> (<italic><bold>2019</bold></italic>)</xref>; <xref ref-type="bibr" rid="c34"><italic><bold>Sepulveda et al.</bold></italic> (<italic><bold>2020</bold></italic>)</xref>. Because of this multiplicative effect, the greater the value of the items under comparison, the greater the discount of the unattended item, leading to faster decisions (i.e., the magnitude effect).</p>
<p>This explanation does not apply in our case, since we could largely abolish the magnitude effect by informing the participants about the dominant color in each stimulus patch. In our task, the magnitude effect occurs, because DVs on hard-hard trials (<xref ref-type="fig" rid="fig5">Fig. 5a</xref>, orange circle) cross the bounds later than on easy-easy trials (purple circle). This arises because the DVs for easy-easy trials move into one of the channels, whereas weak-weak DVs linger near the origin making them less likely to cross a bound. When the color dominance is known (<xref ref-type="fig" rid="fig5">Fig. 5b</xref>), the bounds change so that the DV can reach a bound when lingering near the origin. Therefore, the reaction times now only depend on difference in difficulty and not the magnitude.</p>
<p>The difficulty decision relies on a difference in the absolute values of the DVs that would be formed to make the individual decisions. This quantity might be computed using a simple <italic>max</italic> operation. Neural implementation of simple drift diffusion, associated with a single binary decision, is organized as a race between two drift-diffusion processes: (<italic>i</italic>)the accumulation of the difference in momentary evidence for blue minus yellow (or more generally, colors that are not blue) and (<italic>ii</italic>) yellow minus blue (or not yellow). These racing accumulations are anticorrelated, albeit imperfectly. The absolute value of the DV can be approximated by the greater of the competing accumulations. The same computation is also applied to the other stimulus and the difference between the absolute DVs for the two stimuli is then computed. Such a process could be extended to difficulty decisions over more than two stimuli.</p>
<p>It has been proposed that confidence judgments about the accuracy of a decision require having learned a mapping between (<italic>i</italic>) the state of a decision variable (<italic>DV</italic>) and elapsed time (<italic>t</italic>) and (<italic>ii</italic>) the probability that the decision is correct <italic><bold>Kiani and Shadlen</bold></italic> (<italic><bold>2009</bold></italic>); <italic><bold>Kiani et al.</bold></italic> (<italic><bold>2014</bold></italic>); <italic><bold>Van Den Berg et al.</bold></italic> (<italic><bold>2016</bold></italic>). This mapping is used to define a policy; for instance, respond with high confidence if the estimated probability of being correct is greater than a criterion. An explicit calculation of confidence in the color decisions is not necessary in our task, because the difficulty decision is based on quantity derived directly from the two color decision variables. Indeed a model that com-pares confidence to make the difficulty judgement provides a poor fit to the data (<italic><bold><xref ref-type="fig" rid="figS6a">Figure 6—figure Supplement 1</xref>).</bold></italic> That said, there may be situations where the difficulty determinations involve calculation of confidence as an intermediate step. For example, in a difficulty-comparison of a color dominance in one patch and motion direction in another patch, the decision variables may not be directly comparable and may therefore require a conversion to confidence (cf. <italic><bold><xref ref-type="bibr" rid="c15">de Gardelle et al., 2016</xref></bold></italic>).</p>
</sec>
<sec id="s4">
<title>Methods and Materials</title>
<sec id="s4a">
<title>Participants</title>
<p>For Experiment 1 (Difficulty judgments in a reaction time task), 51 participants were recruited on Amazon Mechanical Turk. Only participants who completed the entire study and met performancebased inclusion criteria (see below) were included in the final sample of 20 participants (12 male and 8 female; 19 right-handed; age 20—51, mean = 33.6, sd = 9.1). Participants completed two one hour sessions each. They received $1 for each session, plus a performance-based bonus of up to $5. Participants who successfully completed both sessions of the task within 48 hours received an additional bonus of $1. These experiments were an early foray into using Mechanical Turk and we simply matched payment with the typical payment for similar online experiments. We have since become aware, and agree with, advocates who feel the pay is too low and have since moved to using the Prolific platform and ensure we pay $8/hour minimum.</p>
<p>For Experiment 2 (Difficulty judgments with unknown vs. known color dominance), 4 participants were recruited via a Sona Systems participant pool. After initial training, 3 participants (1 male and 2 female; all right-handed; age 20--24, mean = 21.7, sd = 2.1) were selected for the main experiment based on their performance (see below). Participants completed a total of 18 one hour sessions and received $17/h and an additional performance-based bonus.</p>
<p>All participants had normal or corrected-to-normal vision and were naïve about the hypotheses of the experiment. Participants provided written informed consent prior to the study. The study was approved by the local ethics committee (Institutional Review Board of Columbia University Medical Center).</p>
</sec>
<sec id="s4b">
<title>Apparatus and stimuli</title>
<p>Both experiments were conducted remotely during the SARS-CoV-2 pandemic (summer 2021). Participants completed the task online using a Google Chrome browser. The task was programmed in JavaScript and jsPsych <xref ref-type="bibr" rid="c8"><italic><bold>De Leeuw</bold></italic> (<italic><bold>2015</bold></italic>)</xref>. During the task, two dynamic random dot patches with yellow and blue dots were presented in rectangular apertures (3 × 5°, horizontal × vertical) to the leftand right of a red fixation cross, separated by a central gray bar(2×5°; <xref ref-type="fig" rid="fig1">Figure 1a</xref>). Visual stimuli were presented with a screen refresh rate of 60 Hz and stimulus density of 16 dots deg<sup>-2</sup> s<sup>-1</sup> (i.e. 4 dots displayed in each aperture on each frame). On each video frame, each dot was displayed in a location chosen from a uniform distribution over the aperture. The color of each dot was determined independent of its location, according to one of 6 color strength levels (see below).</p>
<p>Prior to the experiment, participants completed a virtual chin-rest procedure in order to estimate viewing distance and calibrate the screen pixels per degree <xref ref-type="bibr" rid="c24"><italic><bold>Li et al.</bold></italic> (<italic><bold>2020</bold></italic>)</xref>. This procedure involves first adjusting objects of known size displayed on the screen to match their physical size and then measuring the horizontal distance from fixation to the blind spot on the screen (taken as 13.5°).</p>
</sec>
<sec id="s4c">
<title>Overview of experimental tasks</title>
<p>On each trial, two patches of random dots were presented after an onset delay of 400–800 ms. Participants were asked to decide for which one of two patches of dots it is easier to decide what the dominant color is (yellow/blue). They were instructed to press the F or J key with their left/right index finger to indicate whether the left or right stimulus was the easier one, respectively. Participants did not have to report the individual color decision (yellow or blue) for either stimulus. Instead, they were required to indicate which patch (left or right) had the stronger color dominance, regardless of whether the majority of dots in that patch was yellow or blue.</p>
<p>The difficulty of the color choice was conferred by the probability that a dot would be colored blue or yellow on each frame. We refer to the signed quantity, <italic>C</italic><sup>±</sup> = 2(<italic>p</italic><sub>blue</sub> - 0.5), as the color coherence where positive coherences refer to blue dominant stimuli. The dominant color of each stimulus (yellow/blue) and its difficulty (color strength <italic>C</italic> = |<italic>C</italic><sup>±</sup>|) was fixed during a trial but randomized independently across trials. We used 6 different coherence levels ±{0,0.128,0.256,0.384,0.512,0.64}, resulting in 12 signed coherence levels for the 2 colors. All 12 × 12 color-coherence combinations for the 2 patches were presented in a pseudo-random, counter-balanced manner during the task.</p>
<p>Visual feedback was provided at the end of each trial. For correct responses, participants won 1 point. After errors and miss trials (too early/late), participants lost 1 point. For trials in which both stimuli were equally difficult (i.e., same coherence level), half of the trials were randomly designated ‘correct’. Miss trials were repeated later during the same block. Participants were instructed to try and gain as many points as possible and at the end of the experiment they received an extra bonus of one cent for every point they accumulated. Their point score was shown in the corner of the screen throughout the task and additional feedback about percent accuracy was provided at the end of every block.</p>
<p>Prior to completing the task with difficulty judgments, all participants were first trained on a task in which they had to make color judgments (blue/yellow) about a single patch of dots presented to the left or right of the central fixation cross. Participants used the M and K keys with their right index/middle finger to indicate their response. Throughout the task, the response mapping (M = yellow, K = blue) was shown on the screen. The ± sign of the 0 coherence level determined which response would be rewarded.</p>
<p>Participants were instructed to keep their eyes fixated on the central fixation cross throughout the task.</p>
</sec>
<sec id="s4d">
<title>Experiment 1: Difficulty judgments in a reaction time task</title>
<p>Participants performed two separate sessions with a total of 432 trials of the color judgment task and 1,152 trials of the difficulty task. In session 1, participants were first trained on the color judgment task (see above). They performed 6 blocks of 72 trials each, in which all 12 signed coherence levels were presented in random order. They then completed 3 blocks of the difficulty judgment task (96 trials/block), in which all 12 × 12 coherence combinations for the two patches were presented in random order. In a second session there were 9 blocks (96 trials/block) of the difficulty task.</p>
<p>In both sessions, participants performed a reaction time task in which they were instructed to respond as soon as they had made their decision. The stimuli disappeared as soon as participants made a response. Participants were instructed to try to be both as fast and as accurate as possible in order to maximize their score. Warning messages were presented if participants initiated a response before stimulus onset or within 200 ms of stimulus onset (“too early”) or when RTs exceeded 5 sec (“too slow!”).</p>
<p>After session 1, we fit a logistic of color choices against coherence and difficulty choices against the difference in strength of S1 and S2. Participants whose sensitivity (slope parameter of logistic) of color choices was less than 4 (n = 4), or whose sensitivity of difficulty choices was less than 3 (n = 21, a lower threshold used here as we found difficulty choices were harder than color choices) were not invited to participate in session 2 and were excluded from all analyses. Six additional participants were excluded because they did not complete session 2 despite meeting the performance criteria. In the final sample, mean sensitivity of color choices was 9.67 (sd = 2.66) and mean sensitivity of difficulty choices was 5.24 (sd = 1.03).</p>
</sec>
<sec id="s4e">
<title>Experiment 2: Difficulty judgments with unknown vs. known color dominance</title>
<p>Participants completed a total of 18 sessions on separate days. The first 4 sessions were regarded as training (see below) and were not included in the analysis. During sessions 5-17, participants performed different versions of the difficulty judgment task that alternated every 3-4 blocks of 96 trials each (order counterbalanced across participants): i) Variable duration task with unknown color (total of 3,888 trials per participant), ii) controlled duration task with known color (1,944 trials, half of which were blocks with blue stimuli while the other half of blocks had yellow stimuli), iii) reaction time task with unknown color (2,592 trials), iv) reaction time task with known color (1,296 trials, half of which were blocks with blue stimuli while the other half of blocks had yellow stimuli). In the final session, participants completed 600 trials of a controlled duration task in which they had to judge the dominant color of a single stimulus. In all versions of the controlled duration task, stimuli were presented with one of 6 stimulus durations {0.1, 0.15, 0.25, 0.45, 0.85, 1.65}s, which were randomized within blocks. This gives a discrete sample from a truncate exponential distribution. Participants were instructed to wait for the stimuli to disappear before indicating their response. Warning messages were presented if participants initiated a response before stimulus offset (“too early”) or later than 5 s after stimulus offset (“too slow!”).</p>
<p>In the difficulty task with unknown color, all 12 × 12 signed coherence combinations for the two patches were presented in random order. Participants were instructed that each color patch could be either yellow or blue and that the two patches would not necessarily be of the same color. In the blocks with known color, only coherence combinations with the same sign (6 × 6 combinations) were presented. Participants received instructions that all patches in the following blocks would be dominantly blue (or yellow). Throughout the task, participants were shown a brief instruction in the corner of the screen reminding them of the condition of the current block.</p>
<p>In all versions of the task, coherence combinations where both stimuli had the same difficulty (i.e., same strength) were presented with one third the frequency compared to other coherence combinations in order to reduce overall trial numbers. The rationale behind this was that choice accuracy was determined randomly in this condition, and thus, it is not informative with regard to participants’ actual choice performance. Consequently, for analyses of choice accuracy in the controlled Duration task, all trials with equal coherence combinations were excluded. All other coherence combinations were presented with equal frequency and in a randomized order.</p>
<p>Although all possible 12 × 12 coherence combinations were presented in the unknown color condition, only trials in which both patches had the same color were included in the analyses.This ensured better comparability with performance in the known-color blocks (where both stimuli by definition always had the same color). The task was designed with this in mind due to the fact that previous pilot studies from our lab revealed that performance tends to be worse when the 2 patches are of different color compared to when they are of the same color. Thus, participants performed twice the number of total trials with the unknown color condition, but only trials with equal color combinations were included in the main analyses, resulting in the same trial numbers for the known vs. unknown condition (1,944 trials each for controlled duration and 1,296 trials each for reaction time).</p>
<p><italic>Training sessions</italic> Prior to the experimental sessions, participants completed 4 training sessions. During session 1, participants were trained on a controlled duration task with single color judgments in which stimulus durations were drawn randomly from an exponential distribution with <italic><bold>μ</bold></italic> = 800 ms, truncated at 400–1800 ms. In session 2, participants performed a reaction time version of the color judgments task. Finally, in sessions 3 and 4, participants performed the difficulty judgments task with half the blocks of each session being a reaction time version of the task while the remaining blocks were a controlled duration version in which stimulus durations were drawn randomly from an exponential distribution (Session 3: <italic><bold>μ</bold></italic> = 900 ms, truncated at 400-2000 ms; Session 4: <italic><bold>μ</bold></italic> = 800 ms, truncated at 200-1800 ms). After training, all 4 participants met the performance criteria (slope of logistic function &gt; 4 for color choices and &gt; 3 for difficulty choices). However, one participant was excluded from the remaining sessions of the experiment due to failing to complete the training sessions in a timely manner.</p>
</sec>
<sec id="s4f">
<title>Drift diffusion model of color judgments</title>
<p>We fit a standard drift diffusion model to participants’ color choices and RTs. The model assumes that momentary color evidence is accumulated into a decision variable (DV). The process terminates when the DV reaches an upper or lower bound (±<italic>B</italic>), which corresponds to making a blue vs. yellow choice, respectively. The DV is determined by a Wiener process with drift, which starts at 0 and then evolves according to the sum of a deterministic and a stochastic component (with discrete updates every Δ<italic>t</italic>):
<disp-formula id="eqn1">
<alternatives><graphic xlink:href="528254v1_eqn1.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula></p>
<p>The deterministic term depends on the drift <italic>μ</italic> = <italic>κ</italic>(<italic>C</italic><sup>±</sup> + <italic>C</italic><sub>0</sub>) where <italic>C</italic><sup>±</sup> is the signed color coherence (positive for blue; negative for yellow), <italic>κ</italic> converts coherence to drift rate and <italic>C</italic><sub>0</sub> allows for a color bias. Here, the bias term is modeled as an offset in the coherence, rather than a shift in the starting point of the accumulation process. This approximates the optimal way of implementing a bias when coherence levels vary across trials <xref ref-type="bibr" rid="c19"><italic><bold>Hanks et al.</bold></italic> (<italic><bold>2011</bold></italic>)</xref>; <xref ref-type="bibr" rid="c44"><italic><bold>Zylberberg et al.</bold></italic> (<italic><bold>2018</bold></italic>)</xref>.</p>
<p>The second term of <xref ref-type="disp-formula" rid="eqn1">Eq. 1</xref> describes the stochastic component, which captures the variability introduced by the noise in the stimulus and in the neural response. This variability is modeled as independent samples from a Normal distribution with mean 0 and standard deviation <inline-formula><alternatives><inline-graphic xlink:href="528254v1_inline1.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, which results in the variance of the DV being equal to 1 after accumulating evidence for 1 s. This was done by convention, since for any other scaling of the variance, it would be possible to define an equivalent model in which the variance is 1 and the other parameters are a scaled version of the original ones <xref ref-type="bibr" rid="c30"><italic><bold>Palmer et al.</bold></italic> (<italic><bold>2005</bold></italic>)</xref>.</p>
<p>The accumulation process terminates when the DV crosses one of two bounds (±<italic>B</italic>), resulting in a blue or yellow choice. The decision time <italic>T<sub>d</sub></italic> is the time it takes for the DV to reach a bound. To account for the observation that RTs tend to be slower in erroneous, compared to correct choices, for a given coherence level (data not shown here), we implemented bounds that collapse overtime <xref ref-type="bibr" rid="c33"><italic><bold>Rapoport and Burkheimer</bold></italic> (<italic><bold>1971</bold></italic>)</xref>; <xref ref-type="bibr" rid="c10"><italic><bold>Drugowitsch et al.</bold></italic> (<italic><bold>2012</bold></italic>)</xref>; <xref ref-type="bibr" rid="c35"><italic><bold>Shadlen and Kiani</bold></italic> (<italic><bold>2013</bold></italic>)</xref>. Collapsing bounds result in an increased probability that the <italic>DV</italic> will reach the wrong bound the longer the accumulation process takes. We parameterized the upper collapsing bound as a logistic function:
<disp-formula id="eqn2">
<alternatives><graphic xlink:href="528254v1_eqn2.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
with three parameters <italic>a, u, d</italic>. Therefore the bound collapse (slope related to <italic>a</italic>) and reaches a value of <italic>u</italic>/2 at <italic>t</italic> = <italic>d</italic> and approaches 0 as <italic>t</italic> → ∞. The lower bound is simply the negative of the upper bound (<italic>u</italic> → -<italic>u</italic>).</p>
<p>Given a set of parameters (Φ = [<italic>κ</italic>, <italic>C</italic><sub>0</sub>, <italic>u</italic>, <italic>a</italic>, <italic>d</italic>]), we can estimate the joint probability density function for choices and decision times <italic>T<sub>d</sub></italic> as a function of the signed color coherence <italic>coh</italic>. We used a Δ<italic>t</italic> of 0.5 ms and obtained the probability density function by numerically solving the Fokker-Planck equation associated with a Wiener process with drift <italic><bold>Kiani and Shadlen</bold></italic> (<italic><bold>2009</bold></italic>), using the finite difference method of <xref ref-type="bibr" rid="c7">Chang &amp; Cooper (1970)</xref>. Finally, the RT is determined by the sum of the decision time <italic>T<sub>d</sub></italic> and a non-decision time, which is assumed to be Gaussian with mean <italic>T<sub>nd</sub></italic> and a standard deviation that was fixed to <italic>σ<sub>Tnd</sub></italic> = 0.05 s.</p>
<p>We fit the model parameters to the mean choice-RT data of individual participants by maximizing the likelihood of observing the data given the model parameters (Φ = [<italic>κ</italic>, <italic>C</italic><sub>0</sub>, <italic>u</italic>, <italic>a</italic>, <italic>d</italic>, <italic>T<sub>nd</sub></italic>]) and the signed color coherence <italic>coh</italic>. We used Bayesian adaptive direct search (BADS; <italic><bold><xref ref-type="bibr" rid="c1">Acerbi and Ma, 2017</xref></bold></italic>) to optimize the model parameters. All model fits were obtained by performing several iterations of the optimization procedure with 10 different sets of starting parameters.</p>
</sec>
<sec id="s4g">
<title>Drift diffusion models of difficulty judgments</title>
<p>We developed four alternative models of difficulty judgments. All models assume that momentary color evidence is integrated into a DV, as in the drift diffusion model for color judgments. However, for difficulty judgments, there are two DVs: <italic>DV</italic><sub><italic>S</italic>1</sub> and <italic>DV</italic><sub><italic>S</italic>2</sub>, representing the accumulated momentary evidence from the left and right stimulus, respectively. In all models, we assumed that accumulation proceeds in a serial, time-multiplexed manner where evidence integration switches back and forth between the two stimuli <xref ref-type="bibr" rid="c21"><italic><bold>Kang et al.</bold></italic> (<italic><bold>2021</bold></italic>)</xref>. We assumed perfect time sharing between <italic>DV</italic><sub><italic>S</italic>1</sub> and <italic>DV</italic><sub><italic>S</italic>2</sub>, resulting in decision times that are twice as long compared to parallel integration.</p>
<p>The models differ in a) how momentary color evidence is accumulated into a decision variable and b) the decision criterion that is used to make the difficulty choice (<xref ref-type="fig" rid="fig2">Fig. 2</xref>).
<list list-type="roman-lower">
<list-item><p>Race model</p>
<p>In the Race model, difficulty choice depends on a race between <italic>DV</italic><sub><italic>S</italic>1</sub> and <italic>DV</italic><sub><italic>S</italic>2</sub>. The DV for each stimulus is calculated in the same way as if participants made two independent color choices (<xref ref-type="disp-formula" rid="eqn1">Eq. 1</xref>) and the first decision to cross the bound is regarded as the easier decision. For difficulty choices, we did not include a color bias (<italic>C</italic><sub>0</sub>). Thus, the drift part of <italic>DV</italic><sub><italic>S</italic>1</sub> is simply <inline-formula><alternatives><inline-graphic xlink:href="528254v1_inline2.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> (and similarly for S2).</p>
<p>The difficulty choice in the Race model is determined by which DV crosses its bound first and the stimulus associated with this DV is chosen as the easier one. The decision time is determined by the time that the first DV crosses a bound. In the model the decision bounds collapse in the same way for both stimuli.</p></list-item>
<list-item><p>Difference model</p>
<p>In the Difference model, <italic>DV</italic><sub><italic>S</italic>1</sub> and <italic>DV</italic><sub><italic>S</italic>2</sub> are calculated in the same way as in the Race model. However, the decision bound for the difficulty choice is not applied to the individual color DVs, but instead to the difference in absolute DVs, i.e. |<italic>DV</italic><sub><italic>S</italic>1</sub>| - |<italic>DV</italic><sub><italic>S</italic>2</sub>|. A difficulty choice is made when this difference value reaches an upper (lower) bound, indicating that S1 (S2) is the easier stimulus. The bounds collapse symmetrically, according to <xref ref-type="disp-formula" rid="eqn2">Eq. 2</xref>.</p></list-item>
<list-item><p>Two-step model</p>
<p>The Two-step model is similar to the Difference model, however, the bounds for difficulty choice depend on the sign of each DV, according to an initial mini decision. The mini decision depends on a low-threshold bound <italic>B<sub>mini</sub></italic>. In order to minimize the number of additional parameters in this model, we modeled <italic>B<sub>mini</sub></italic> as time-independent for 2 s, followed by a sharp collapse. The DVs were calculated in the same way as in the Race and Difference models. Thus, choices and decision time (<italic>t<sub>mini</sub></italic>) for the mini decision only depend on the signed color coherence, <italic>C</italic><sub>0</sub> and the parameters <italic>κ</italic> and <italic>B</italic><sub>mini</sub>.</p>
<p>The model uses the mini decision to determine the color dominance of each stimulus and then only performs difficulty judgments assuming this color dominance. Therefore, once a mini decision has been made for either of the two DVs, a difficulty judgment is made when sign(<italic>DV</italic><sub><italic>S</italic>1</sub>(<italic>t<sub>mini</sub></italic>)) · <italic>DV</italic><sub><italic>S</italic>1</sub> - sign(<italic>DV</italic><sub><italic>S</italic>2</sub>(<italic>t<sub>mini</sub></italic>)) · <italic>DV</italic><sub><italic>S</italic>2</sub> reaches one of the bounds, that is ±<italic>B</italic>(<italic>t</italic>). We also tested a version of the Two-step model in which both DVs need to reach <italic>B<sub>mini</sub></italic> before the difficulty choice can be made. However, this model was inferior compared to the model presented here, in which only one mini decision is required, and the sign of the other DV is fixed according to its value at time <italic>t</italic><sub>1</sub> (group-level log<sub>10</sub> BF = 49.11 in favor of single mini-decision model).</p>
<p>As in the Difference model, the bounds for the difficulty choice collapse over time, starting from the beginning of the accumulation process (i.e., before a mini decision has been made). We constrained the model such that a difficulty choice could only be made at time <italic>t<sub>mini</sub></italic> at earliest, that is, once a mini decision has been made.</p></list-item>
<list-item><p>Absolute momentary evidence model</p>
<p>In the Absolute momentary evidence model, DVs represent the accumulated absolute momentary color evidence at each time step.
<disp-formula id="eqn3">
<alternatives><graphic xlink:href="528254v1_eqn3.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula></p>
<p>The model is, therefore, color agnostic in that it accumulates evidence in favor of strong color independent of whether the dominant color is blue or yellow on each frame. Thus, both DVs are always positive. Similar to the previous two models, a difficulty choice is made when the difference in DVs, <italic>DV</italic><sub><italic>S</italic>1</sub> - <italic>DV</italic><sub><italic>S</italic>2</sub> exceeds an upper/lower bound, which again collapses over time.</p></list-item>
</list></p>
<sec id="s4g1">
<title>Model fitting</title>
<p>To fit each model we simulated 1000 trials for each unique combination of signed coherence for S1 × S2 (using a Δ<italic>t</italic> of 5 ms). An Epanechnikov kernel smoothed probability distribution was then fit to the simulated RT data for each choice (S1 or S2) and combination of signed coherences. This was used to calculate the log likelihood of the data given the model parameters <italic>κ</italic>, <italic>u</italic>, <italic>a</italic>, <italic>d</italic>, <italic>T<sub>nd</sub></italic>, and in case of the Two-step model, <italic>B<sub>mini</sub></italic>. We used Bayesian adaptive direct search (BADS;<italic><bold><xref ref-type="bibr" rid="c1">Acerbi and Ma, 2017</xref></bold></italic>) to optimize the model parameters. Model fits were obtained by performing several iterations of the optimization procedure with 10 different sets of starting parameters. The Bayesian information criterion (BIC) was computed for each model and participant in order to compare the models while controlling for their number of free parameters. Group-level model comparison was performed by summing BICs across individual participants.</p>
</sec>
<sec id="s4g2">
<title>Model recovery</title>
<p>We used the parameters from the fits of the race, difference, two-step and absolute momentary evidence models to the data for each participant in Experiment 1 to generate 10 synthetic data sets for each participant. We then fit each synthetic data set with each of the four models as we did with the real data. For model recovery, we examined the proportion of times the BIC was lowest for the fit to the model that was used to generate the data. Classification accuracy was 93.5, 97.0,53.5 and 95.5% for data generated by the race, difference, two-step and absolute momentary evidence models, respectively. For data generated by the two-step model the BIC was lowest for the difference model in 36% of fits.</p>
</sec>
</sec>
<sec id="s4h">
<title>Model for Experiment 2: Difficulty judgments with unknown vs. known color dominance</title>
<p>In order to model choice accuracy in the unknown and known color condition, we used a Difference model in which difficulty choice was based on either the difference in absolute DVs (unknown color) or appropriately signed DVs (known color). To fit choices in difficulty judgments, we excluded trials in unknown condition in which both stimuli had the same strength (i.e. ΔC = 0), and trials in which the two stimuli had different dominant colors (so as to make comparable to the known color condition).</p>
<p>For the reaction time task in Exp. 2, we fit the Difference model as in Exp. 1 to the data from the unknown color condition. We then used the optimized parameters to predict choices and RTs in the known color condition using the same model, but with appropriately signed DVs instead of absolute DVs.</p>
<p>To fit the choices in the controlled duration task we simulated 2000 trials for each unique combination of signed coherence for S1 × S2 (using a Δ<italic>t</italic> of 5 ms) with a collapsing bound as in the RT task. Choice was based on crossing a bound or on the the sign of the difference in DVs at the end of evidence accumulation if no bound had been crossed. We fit both the known and unknown color conditions simultaneously using the appropriate decision rules for each (difference model with absolute DVs for the unknown and appropriately signed DVs instead of absolute DVs for the known color condition).</p>
<p>We included a buffer <italic>T</italic><sub>buf</sub> in the model that controls the duration of the stimulus streams that can be stored while the accumulation process alternates between the two stimuli and this was set to 80 ms based on our previous work <xref ref-type="bibr" rid="c21"><italic><bold>Kang et al.</bold></italic> (<italic><bold>2021</bold></italic>)</xref>. If the stimulus duration is shorter than the buffer, the amount of time that each stimulus is sampled, <italic>T</italic><sub>dur</sub>, equals the stimulus duration (i.e. all the information can be stored in the buffer and can be integrated into the DV). If the stimulus duration is longer than the buffer, <italic>T</italic><sub>dur</sub> equals the buffer plus the remaining stimulus duration, time-shared between the two stimuli:
<disp-formula id="eqn4">
<alternatives><graphic xlink:href="528254v1_eqn4.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula></p>
</sec>
<sec id="s4i">
<title>Difference in confidence model</title>
<p>For the reaction time data of Experiment 2 we fit a difference in confidence model. Rather than comparing the two DVs (as in the Difference model), we compare measures of confidence. Confidence is a mapping from DV and time into the probability of being correct if one were to choose color based on the sign of the DV. We followed the method in <italic><bold>Kiani and Shadlen</bold></italic> (<italic><bold>2009</bold></italic>) to calculate confidence. We placed bounds on the difference in confidence (measured as the log-odds of being correct). All other elements of the model were the same as for the Difference model (e.g. collapsing bounds). We fit the unknown color condition and use the fits to predict the known color condition. In the unknown color condition, we compared the difference in the absolute log-odds. In the known color condition we calculated the difference in the appropriately signed log-odds (i.e., the log-odds for choosing the known color). We chose to represent confidence as log-odds because using raw probabilities led to very poor fits. This is because for high:high coherences the difference in confidence (when both are close to 1) can be very small when represented in raw probabilities.</p>
</sec>
<sec id="s4j">
<title>Optimal reaction time model</title>
<p>To derive the decision strategy that maximizes the reward rate, we formalize the difficulty-judgment task as a partially observable Markov decision problem (POMDP). Following well-established proce-dures, we find the solution to the POMDP by transforming it into a fully observable Markov decision process (MDP) over belief states. The MDP comprises <xref ref-type="bibr" rid="c16"><italic><bold>Geffner and Bonet</bold></italic> (<italic><bold>2013</bold></italic>)</xref>:
<list list-type="bullet">
<list-item><p>a space <italic>S</italic>,</p></list-item>
<list-item><p>an initial state <italic>s</italic><sub>0</sub> ∈ <italic>S</italic>,</p></list-item>
<list-item><p>goal states <italic>S<sub>G</sub></italic> ∈ <italic>S</italic>,</p></list-item>
<list-item><p>a set of actions <italic>A</italic>(<italic>s</italic>) applicable in each state <italic>s</italic> ∈ <italic>S</italic>,</p></list-item>
<list-item><p>transition probabilities <italic>P<sub>a</sub></italic>(<italic>s</italic>’|<italic>s</italic>) that specify the probability of transitioning to state <italic>s’</italic> after selecting action <italic>a</italic> in state <italic>s</italic>, and</p></list-item>
<list-item><p>rewards and costs, <italic>r</italic>(<italic>a</italic>, <italic>s</italic>), for selecting action <italic>a</italic> in state <italic>s</italic>.</p></list-item>
</list></p>
<p>In our task, the state space is defined by the tuple 〈<italic>t</italic><sub><italic>S</italic>1</sub>,<italic>t</italic><sub><italic>S</italic>2</sub>,<italic>DV</italic><sub><italic>S</italic>1</sub>,<italic>DV</italic><sub><italic>S</italic>2</sub>〉 where <italic>t<sub>x</sub></italic> is the time spent sampling stimulus <italic>x</italic> and <italic>DV<sub>x</sub></italic> is the accumulated evidence for stimulus <italic>x</italic>. We discretize time and accumulated evidence in bins of Δ<italic>t</italic> and Δ<italic>DV</italic>. The initial state is the one for which no evidence has been accrued, <italic>s</italic><sub>0</sub> = 〈0, 0, 0, 0〉.</p>
<p>The actions available to the decision maker are: gather more evidence, choose the option <italic><bold>S</bold></italic>j (as the least-difficult random dot color patch), or choose the option <italic>S</italic>2. The last two actions terminate the trial and lead to a ‘dummy’ cost-free and absorbing goal state.</p>
<p>As with the models that we fit to the data, the two stimuli are sampled serially in rapid alternation so that we alternate between sampling <italic>S</italic>1 and <italic>S</italic>2 in sequential time steps (Δ<italic>t</italic>).</p>
<p>When stimulus <italic>Sx</italic> is sampled while in state <italic>s</italic>, the agent obtains an evidence sample which is used to update the state to <inline-formula><alternatives><inline-graphic xlink:href="528254v1_inline3.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. Because one stimulus is sampled at a time, only two of the four variables that define a state can change per new observation. For example, if the stimulus <italic>S</italic>1 is sampled, then <italic>t</italic><sub><italic>S</italic>2</sub> and <italic>DV</italic><sub><italic>S</italic>2</sub> do not change. In turn, since time evolves in steps of Δ<italic>t</italic>, then <inline-formula><alternatives><inline-graphic xlink:href="528254v1_inline4.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>.</p>
<p>To complete the definition of the transition probabilities, it remains only to specify how the probability of <italic>DV<sub>x</sub></italic> changes after sampling stimulus <italic>x</italic>, <inline-formula><alternatives><inline-graphic xlink:href="528254v1_inline5.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. As in the models we fit to the data, we assume that the sensory observations follow a normal distribution with mean equal to <inline-formula><alternatives><inline-graphic xlink:href="528254v1_inline6.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> and variance equal to Δ<italic>t</italic>, where <italic>κ</italic> is a drift rate coefficient and <inline-formula><alternatives><inline-graphic xlink:href="528254v1_inline7.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> is the signed color strength of the sampled patch. If <inline-formula><alternatives><inline-graphic xlink:href="528254v1_inline8.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> were known, the values of <italic>DV<sub>x</sub></italic> would follow a normal distribution:
<disp-formula id="eqn5">
<alternatives><graphic xlink:href="528254v1_eqn5.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <italic>DV<sub>x</sub></italic> is the state of the decision variable in state <italic>s</italic>, and <inline-formula><alternatives><inline-graphic xlink:href="528254v1_inline9.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> is the normal p.d.f. with mean <italic>μ</italic> and variance <italic>σ</italic><sup>2</sup>.</p>
<p>Since we do not know the color coherence <inline-formula><alternatives><inline-graphic xlink:href="528254v1_inline10.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, we must marginalize over its possible values:
<disp-formula id="eqn6">
<alternatives><graphic xlink:href="528254v1_eqn6.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula></p>
<p>For clarity of notation we omitted the associated action, <italic>sample<sub>x</sub></italic>. We assume that the decision maker knows the possible values that <inline-formula><alternatives><inline-graphic xlink:href="528254v1_inline11.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> can take. The probability distribution over the color coherence values given that one is in state <italic>s</italic>, <inline-formula><alternatives><inline-graphic xlink:href="528254v1_inline12.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, can be calculated as <xref ref-type="bibr" rid="c27"><italic><bold>Moreno-Bote</bold></italic> (<italic><bold>2010</bold></italic>)</xref>:
<disp-formula id="eqn7">
<alternatives><graphic xlink:href="528254v1_eqn7.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where the constant of proportionality is such that the sum of <inline-formula><alternatives><inline-graphic xlink:href="528254v1_inline13.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> over the possible values of <inline-formula><alternatives><inline-graphic xlink:href="528254v1_inline14.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> is equal to 1. The prior <inline-formula><alternatives><inline-graphic xlink:href="528254v1_inline15.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> is uniformly distributed over the discrete set of unsigned color coherences, as in the experiment.</p>
<p>We find the optimal policy by solving the Bellman equations (as in <xref ref-type="bibr" rid="c10"><italic><bold>Drugowitsch et al.</bold></italic> (<italic><bold>2012</bold></italic>)</xref>). Each state <italic>s</italic> has associated with it a value, <italic>V</italic>(<italic>s</italic>), given by the maximum value over the actions applicable in state <italic>s</italic> (in this case we have just sampled <italic>s</italic>2), so that
<disp-formula id="eqn8">
<alternatives><graphic xlink:href="528254v1_eqn8.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <italic>b</italic>(<italic>s</italic>, <italic>Sx</italic>) is the probability that choosing <italic>Sx</italic> is correct in state <italic>s</italic>, <italic>R<sub>c</sub></italic>, is the reward obtained for a correct choice, <italic>R<sub>n</sub></italic> is the reward obtained after an incorrect choice, <italic>t<sub>p</sub></italic> is the time penalty after an error, <italic>t<sub>nd</sub></italic> is the average non-decision time, <italic>t<sub>w</sub></italic> is the inter trial interval (from the time a choice is registered to onset of the random dot stimuli for the next trial) and <italic>ρ</italic> is the expected reward per unit of time.</p>
<p>The probability that choice <italic>Sx</italic> is correct in state <italic>s</italic>, <italic>b</italic>(<italic>s</italic>, choose <italic>Sx</italic>), is the probability that the color strength at stimulus <italic>Sx</italic> is higher than that of the other stimulus, so that:
<disp-formula id="eqn9">
<alternatives><graphic xlink:href="528254v1_eqn9.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where the summations are over all possible signed color coherence values, and
<disp-formula id="eqn10">
<alternatives><graphic xlink:href="528254v1_eqn10.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
constrains the summation in <xref ref-type="disp-formula" rid="eqn9">equation 9</xref> to the coherence pairs for which <italic>s</italic>1 is the objectively easier, plus half of the ties. Note that <italic>b</italic>(<italic>s</italic>, choose <italic>S</italic>2) = 1 - <italic>b</italic>(<italic>s</italic>, choose <italic>S</italic>1).</p>
<p>In <xref ref-type="disp-formula" rid="eqn8">equation 8</xref>, if <italic>ρ</italic> (the reward per unit of time) were known, the Bellman equations could be solved in a single backwards pass, assuming that for sufficiently long times the best action is to select one of two terminal actions, and then propagating the value function <italic>V</italic>(<italic>s</italic>) backwards in time. However, <italic>ρ</italic> is not known since it depends on the decision policy itself. Following a usual procedure (<xref ref-type="bibr" rid="c5"><italic><bold>Bertsekas et al., 2011</bold></italic></xref>), we find the value of <italic>ρ</italic> by root finding. We solve the Bellman equations by backwards induction for two extreme values of <italic>ρ</italic>, such that the actual value lies between them. Then we divide the range into two halves, keeping the half for which the value of the initial state <italic>V</italic>(<italic>s</italic><sub>0</sub>) has different signs for the extreme values of the range. We repeat this procedure multiple times, gradually bracketing the value of <italic>ρ</italic> in diminishing intervals, until the difference between the value we assume and the one resulting from solving Bellman’s equations is negligible.</p>
<p>Once the value of each state converges to its optimal value, <italic>V</italic>*(<italic>s</italic>), the best action in each state is the one for which the value of the state-action pair, <italic>Q</italic>(<italic>s</italic>, <italic>a</italic>) is equal to <italic>V</italic>*(<italic>s</italic>) (<xref ref-type="disp-formula" rid="eqn8">Eq. 8</xref>). For the analysis shown in <xref ref-type="fig" rid="fig4">Fig. 4</xref>, we simulated 200,000 trials following the optimal policy. The parameters used to make these simulations were: <italic>κ</italic> = 13, <italic>R<sub>c</sub></italic> = 1, <italic>R<sub>n</sub></italic> = 0, <italic>t<sub>p</sub></italic> = 1<italic>s</italic>, <italic>t<sub>nd</sub></italic> = 0.4<italic>s</italic>, <italic>t<sub>w</sub></italic> = 0.5<italic>s</italic>, Δ<italic>t</italic> = 0.05<italic>s</italic> and Δ<italic>DV</italic> = 0.1.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>This workwas supported by the National Institutes of Health (R01NS117699 to D.M.W; R01NS113113 to M.N.S.), and the Air Force Office of Scientific Research under award (FA9550-22-1-0337 to D.M.W and M.N.S) the Howard Hughes Medical Institute (M.N.S.), and Kavli Institute for Brain Science (A.L).</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="book"><string-name><surname>Acerbi</surname> <given-names>L</given-names></string-name>, <string-name><surname>Ma</surname> <given-names>WJ.</given-names></string-name> <chapter-title>Practical Bayesian Optimization for Model Fitting with Bayesian Adaptive Direct Search</chapter-title>. In: <person-group person-group-type="editor"><string-name><surname>Guyon</surname> <given-names>I</given-names></string-name>, <string-name><surname>Luxburg</surname> <given-names>UV</given-names></string-name>, <string-name><surname>Bengio</surname> <given-names>S</given-names></string-name>, <string-name><surname>Wallach</surname> <given-names>H</given-names></string-name>, <string-name><surname>Fergus</surname> <given-names>R</given-names></string-name>, <string-name><surname>Vishwanathan</surname> <given-names>S</given-names></string-name>, <string-name><surname>Garnett</surname> <given-names>R</given-names></string-name></person-group>, editors. <source>Advances in Neural Information Processing Systems</source>, vol. <volume>30</volume> <publisher-name>Curran Associates, Inc</publisher-name>.; <year>2017</year>. p. <fpage>1836</fpage>–<lpage>1846</lpage>. <ext-link ext-link-type="uri" xlink:href="https://proceedings.neurips.cc/paper/2017/file/df0aab058ce179e4f7ab135ed4e641a9-Paper.pdf">https://proceedings.neurips.cc/paper/2017/file/df0aab058ce179e4f7ab135ed4e641a9-Paper.pdf</ext-link>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Ais</surname> <given-names>J</given-names></string-name>, <string-name><surname>Zylberberg</surname> <given-names>A</given-names></string-name>, <string-name><surname>Barttfeld</surname> <given-names>P</given-names></string-name>, <string-name><surname>Sigman</surname> <given-names>M.</given-names></string-name> <article-title>Individual consistency in the accuracy and distribution of confidence judgments</article-title>. <source>Cognition</source>. <year>2016</year>; <volume>146</volume>:<fpage>377</fpage>–<lpage>386</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Bakkour</surname> <given-names>A</given-names></string-name>, <string-name><surname>Palombo</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Zylberberg</surname> <given-names>A</given-names></string-name>, <string-name><surname>Kang</surname> <given-names>YH</given-names></string-name>, <string-name><surname>Reid</surname> <given-names>A</given-names></string-name>, <string-name><surname>Verfaellie</surname> <given-names>M</given-names></string-name>, <string-name><surname>Shadlen</surname> <given-names>MN</given-names></string-name>, <string-name><surname>Shohamy</surname> <given-names>D.</given-names></string-name> <article-title>The hippocampus supports deliberation during value-based decisions</article-title>. <source>eLife</source>. <year>2019</year>; <volume>8</volume>:<fpage>e46080</fpage>. doi: <pub-id pub-id-type="doi">10.7554/eLife.46080</pub-id>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="other"><string-name><surname>Bennett-Pierre</surname> <given-names>G</given-names></string-name>, <string-name><surname>Asaba</surname> <given-names>M</given-names></string-name>, <string-name><surname>Gweon</surname> <given-names>H.</given-names></string-name> <article-title>Preschoolers consider expected task difficulty to decide what to do and whom to help</article-title>. In: <source>CogSci</source>; <year>2018</year>. p. <fpage>1359</fpage>–<lpage>1374</lpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="book"><string-name><surname>Bertsekas</surname> <given-names>DP</given-names></string-name>, <etal>et al.</etal> <chapter-title>Dynamic programming and optimal control</chapter-title> <edition>3rd</edition> edition, volume <volume>ii</volume>. <publisher-loc>Belmont, MA</publisher-loc>: <publisher-name>Athena Scientific</publisher-name>. <year>2011</year>;.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Brody</surname> <given-names>CD</given-names></string-name>, <string-name><surname>Hanks</surname> <given-names>TD.</given-names></string-name> <article-title>Neural underpinnings of the evidence accumulator</article-title>. <source>Current opinion in neurobiology</source>. <year>2016</year>; <volume>37</volume>:<fpage>149</fpage>–<lpage>157</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Chang</surname> <given-names>JS</given-names></string-name>, <string-name><surname>Cooper</surname> <given-names>G.</given-names></string-name> <article-title>A practical difference scheme for Fokker-Planck equations</article-title>. <source>Journal of Computational Physics</source>. <year>1970</year>; <volume>6</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>16</lpage>. doi: <pub-id pub-id-type="doi">10.1016/0021-9991(70)90001-X</pub-id>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>De Leeuw</surname> <given-names>JR.</given-names></string-name> <article-title>jsPsych: A JavaScript library for creating behavioral experiments in a Web browser</article-title>. <source>Behavior research methods</source>. <year>2015</year>; <volume>47</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>12</lpage>. doi: <pub-id pub-id-type="doi">10.3758/s13428-014-0458-y</pub-id>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Desender</surname> <given-names>K</given-names></string-name>, <string-name><surname>Van Opstal</surname> <given-names>F</given-names></string-name>, <string-name><surname>Van den Bussche</surname> <given-names>E.</given-names></string-name> <article-title>Subjective experience of difficulty depends on multiple cues</article-title>. <source>Scientific reports</source>. <year>2017</year>; <volume>7</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>14</lpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Drugowitsch</surname> <given-names>J</given-names></string-name>, <string-name><surname>Moreno-Bote</surname> <given-names>R</given-names></string-name>, <string-name><surname>Churchland</surname> <given-names>AK</given-names></string-name>, <string-name><surname>Shadlen</surname> <given-names>MN</given-names></string-name>, <string-name><surname>Pouget</surname> <given-names>A.</given-names></string-name> <article-title>The cost of accumulating evidence in perceptual decision making</article-title>. <source>Journal of Neuroscience</source>. <year>2012</year>; <volume>32</volume>(<issue>11</issue>):<fpage>3612</fpage>–<lpage>3628</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Dunn</surname> <given-names>T</given-names></string-name>, <string-name><surname>Inzlicht</surname> <given-names>M</given-names></string-name>, <string-name><surname>Risko</surname> <given-names>E.</given-names></string-name> <article-title>Anticipating cognitive effort: roles of perceived error-likelihood and time demands</article-title>. <source>Psychol Res</source>. <year>2019</year>; <volume>83</volume>(<issue>5</issue>):<fpage>1033</fpage>–<lpage>1056</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Fakcharoenphol</surname> <given-names>W</given-names></string-name>, <string-name><surname>Morphew</surname> <given-names>JW</given-names></string-name>, <string-name><surname>Mestre</surname> <given-names>JP.</given-names></string-name> <article-title>Judgments of physics problem difficulty among experts and novices</article-title>. <source>Physical review special topics-physics education research</source>. <year>2015</year>; <volume>11</volume>(<issue>2</issue>):<fpage>020128</fpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>Fleming</surname> <given-names>SM</given-names></string-name>, <string-name><surname>Massoni</surname> <given-names>S</given-names></string-name>, <string-name><surname>Gajdos</surname> <given-names>T</given-names></string-name>, <article-title>VergnaudJC. Metacognition about the past and future: quantifying common and distinct influences on prospective and retrospective judgments of self-performance</article-title>. <source>Neuroscience of Consciousness</source>. <year>2016</year>; <volume>2016</volume>(<issue>1</issue>):<fpage>niw018</fpage>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Frazier</surname> <given-names>P</given-names></string-name>, <string-name><surname>Yu</surname> <given-names>AJ.</given-names></string-name> <article-title>Sequential hypothesis testing under stochastic deadlines</article-title>. <source>Advances in neural information processing systems</source>. <year>2007</year>; <volume>20</volume>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>de Gardelle</surname> <given-names>V</given-names></string-name>, <string-name><surname>Le Corre</surname> <given-names>F</given-names></string-name>, <string-name><surname>Mamassian</surname> <given-names>P.</given-names></string-name> <article-title>Confidence as a common currency between vision and audition</article-title>. <source>Plos one</source>. <year>2016</year>; <volume>11</volume>(<issue>1</issue>):<fpage>e0147901</fpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Geffner</surname> <given-names>H</given-names></string-name>, <string-name><surname>Bonet</surname> <given-names>B.</given-names></string-name> <article-title>A concise introduction to models and methods for automated planning</article-title>. <source>Synthesis Lectures on Artificial Intelligence and Machine Learning</source>. <year>2013</year>; <volume>8</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>141</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Gold</surname> <given-names>JI</given-names></string-name>, <string-name><surname>Shadlen</surname> <given-names>MN</given-names></string-name>, <etal>et al.</etal> <article-title>The neural basis of decision making</article-title>. <source>Annual review of neuroscience</source>. <year>2007</year>; <volume>30</volume>(<issue>1</issue>):<fpage>535</fpage>–<lpage>574</lpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="other"><string-name><surname>Gweon</surname> <given-names>H</given-names></string-name>, <string-name><surname>Asaba</surname> <given-names>M</given-names></string-name>, <string-name><surname>Bennett-Pierre</surname> <given-names>G.</given-names></string-name> <article-title>Reverse-engineering the process: Adults’ and preschoolers’ ability to infer the difficulty of novel tasks</article-title>. In: <source>Reverse-engineering the process: Adults’ and preschoolers’ ability to infer the difficulty of novel tasks</source>., vol. <volume>CogSci</volume>; <year>2017</year>..</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Hanks</surname> <given-names>TD</given-names></string-name>, <string-name><surname>Mazurek</surname> <given-names>ME</given-names></string-name>, <string-name><surname>Kiani</surname> <given-names>R</given-names></string-name>, <string-name><surname>Hopp</surname> <given-names>E</given-names></string-name>, <string-name><surname>Shadlen</surname> <given-names>MN.</given-names></string-name> <article-title>Elapsed decision time affects the weighting of prior probability in a perceptual decision task</article-title>. <source>J Neurosci</source>. <year>2011</year>; <volume>31</volume>(<issue>17</issue>):<fpage>6339</fpage>–<lpage>6352</lpage>. doi: <pub-id pub-id-type="doi">10.1523/JNEUROSCI.5613-10.2011</pub-id>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="book"><string-name><surname>Johnson</surname> <given-names>DM.</given-names></string-name> <chapter-title>Confidence and speed in the two-category judgment</chapter-title>. <publisher-name>Columbia Univ</publisher-name>.; <year>1939</year>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Kang</surname> <given-names>YH</given-names></string-name>, <string-name><surname>Löffler</surname> <given-names>A</given-names></string-name>, <string-name><surname>Jeurissen</surname> <given-names>D</given-names></string-name>, <string-name><surname>Zylberberg</surname> <given-names>A</given-names></string-name>, <string-name><surname>Wolpert</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Shadlen</surname> <given-names>MN.</given-names></string-name> <article-title>Multiple decisions about one object involve parallel sensory acquisition but time-multiplexed evidence incorporation</article-title>. <source>Elife</source>. <year>2021</year>; <volume>10</volume>:<fpage>e63721</fpage>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Kiani</surname> <given-names>R</given-names></string-name>, <string-name><surname>Shadlen</surname> <given-names>MN.</given-names></string-name> <article-title>Representation of confidence associated with a decision by neurons in the parietal cortex</article-title>. <source>Science</source>. <year>2009</year>; <volume>324</volume>(<issue>5928</issue>):<fpage>759</fpage>–<lpage>764</lpage>. doi: <pub-id pub-id-type="doi">10.1126/science.1169405</pub-id>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Kiani</surname> <given-names>R</given-names></string-name>, <string-name><surname>Corthell</surname> <given-names>L</given-names></string-name>, <string-name><surname>Shadlen</surname> <given-names>MN.</given-names></string-name> <article-title>Choice certainty is informed by both evidence and decision time</article-title>. <source>Neuron</source>. <year>2014</year>; <volume>84</volume>(<issue>6</issue>):<fpage>1329</fpage>–<lpage>1342</lpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Li</surname> <given-names>Q</given-names></string-name>,<string-name><surname>Joo</surname> <given-names>SJ</given-names></string-name>, <string-name><surname>Yeatman</surname> <given-names>JD</given-names></string-name>, <string-name><surname>Reinecke</surname> <given-names>K.</given-names></string-name> <article-title>Controlling for participants’viewing distance in large-scale, psychophysical online experiments using a virtual chinrest</article-title>. <source>Sci Rep</source>. <year>2020</year>; <volume>10</volume>:<fpage>904</fpage>. doi: <pub-id pub-id-type="doi">10.1038/s41598-019-57204-1</pub-id>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Mamassian</surname> <given-names>P.</given-names></string-name> <article-title>Confidence forced-choice and other metaperceptual tasks</article-title>. <source>Perception</source>. <year>2020</year>; <volume>49</volume>(<issue>6</issue>):<fpage>616</fpage>–<lpage>635</lpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>Mante</surname> <given-names>V</given-names></string-name>, <string-name><surname>Sussillo</surname> <given-names>D</given-names></string-name>, <string-name><surname>Shenoy</surname> <given-names>KV</given-names></string-name>, <string-name><surname>Newsome</surname> <given-names>WT.</given-names></string-name> <article-title>Context-dependent computation by recurrent dynamics in prefrontal cortex</article-title>. <source>Nature</source>. <year>2013</year>; <volume>503</volume>:<fpage>78</fpage>–<lpage>84</lpage>. doi: <pub-id pub-id-type="doi">10.1038/nature12742</pub-id>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>Moreno-Bote</surname> <given-names>R.</given-names></string-name> <article-title>Decision confidence and uncertainty in diffusion models with partially correlated neuronal integrators</article-title>. <source>Neural computation</source>. <year>2010</year>; <volume>22</volume>(<issue>7</issue>):<fpage>1786</fpage>–<lpage>1811</lpage>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><string-name><surname>Morgan</surname> <given-names>G</given-names></string-name>, <string-name><surname>Kornell</surname> <given-names>N</given-names></string-name>, <string-name><surname>Kornblum</surname> <given-names>T</given-names></string-name>, <string-name><surname>Terrace</surname> <given-names>HS.</given-names></string-name> <article-title>Retrospective and prospective metacognitive judgments in rhesus macaques (Macaca mulatta)</article-title>. <source>Animal cognition</source>. <year>2014</year>; <volume>17</volume>(<issue>2</issue>):<fpage>249</fpage>–<lpage>257</lpage>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><string-name><surname>Moskowitz</surname> <given-names>JB</given-names></string-name>, <string-name><surname>Gale</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Gallivan</surname> <given-names>JP</given-names></string-name>, <string-name><surname>Wolpert</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Flanagan</surname> <given-names>JR.</given-names></string-name> <article-title>Human decision making anticipates future performance in motor learning</article-title>. <source>PLoS Computational Biology</source>. <year>2020</year>; <volume>16</volume>(<issue>2</issue>):<fpage>e1007632</fpage>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>Palmer</surname> <given-names>J</given-names></string-name>, <string-name><surname>Huk</surname> <given-names>AC</given-names></string-name>, <string-name><surname>Shadlen</surname> <given-names>MN.</given-names></string-name> <article-title>The effect of stimulus strength on the speed and accuracy of a perceptual decision</article-title>. <source>J Vis</source>. <year>2005</year>; <volume>5</volume>(<issue>5</issue>):<fpage>376</fpage>–<lpage>404</lpage>. doi: <pub-id pub-id-type="doi">10.1167/5.5.1</pub-id>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>Pashler</surname> <given-names>H.</given-names></string-name> <article-title>Dual-task interference in simple tasks: data and theory</article-title>. <source>Psychological bulletin</source>. <year>1994</year>; <volume>116</volume>(<issue>2</issue>):<fpage>220</fpage>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><string-name><surname>Peirce</surname> <given-names>CS</given-names></string-name>,<string-name><surname>Jastrow</surname> <given-names>J.</given-names></string-name> <article-title>On small differences in sensation</article-title>. <source>Memoirs of the National Academy of Sciences</source>. <year>1884</year>; <volume>3</volume>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><string-name><surname>Rapoport</surname> <given-names>A</given-names></string-name>, <string-name><surname>Burkheimer</surname> <given-names>GJ.</given-names></string-name> <article-title>Models for deferred decision making</article-title>. <source>Journal of Mathematical Psychology</source>. <year>1971</year>; <volume>8</volume>(<issue>4</issue>):<fpage>508</fpage>–<lpage>538</lpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Sepulveda</surname> <given-names>P</given-names></string-name>, <string-name><surname>Usher</surname> <given-names>M</given-names></string-name>, <string-name><surname>Davies</surname> <given-names>N</given-names></string-name>, <string-name><surname>Benson</surname> <given-names>AA</given-names></string-name>, <string-name><surname>Ortoleva</surname> <given-names>P</given-names></string-name>, <string-name><surname>De Martino</surname> <given-names>B.</given-names></string-name> <article-title>Visual attention modulates the integration of goal-relevant evidence and not value</article-title>. <source>Elife</source>. <year>2020</year>; <volume>9</volume>:<fpage>e60705</fpage>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>Shadlen</surname> <given-names>MN</given-names></string-name>, <string-name><surname>Kiani</surname> <given-names>R.</given-names></string-name> <article-title>Decision making as a window on cognition</article-title>. <source>Neuron</source>. <year>2013</year>; <volume>80</volume>(<issue>3</issue>):<fpage>791</fpage>–<lpage>806</lpage>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><string-name><surname>Shenhav</surname> <given-names>A</given-names></string-name>, <string-name><surname>Botvinick</surname> <given-names>MM</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>JD.</given-names></string-name> <article-title>The expected value of control: an integrative theory of anterior cingulate cortex function</article-title>. <source>Neuron</source>. <year>2013</year>; <volume>79</volume>(<issue>2</issue>):<fpage>217</fpage>–<lpage>240</lpage>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><string-name><surname>Siedlecka</surname> <given-names>M</given-names></string-name>, <string-name><surname>Paulewicz</surname> <given-names>B</given-names></string-name>, <string-name><surname>Wierzchoń</surname> <given-names>M.</given-names></string-name> <article-title>But I was so sure! Metacognitive judgments are less accurate given prospectively than retrospectively</article-title>. <source>Frontiers in psychology</source>. <year>2016</year>; <volume>7</volume>:<fpage>218</fpage>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><string-name><surname>Smith</surname> <given-names>SM</given-names></string-name>, <string-name><surname>Krajbich</surname> <given-names>I.</given-names></string-name> <article-title>Gaze amplifies value in decision making</article-title>. <source>Psychological science</source>. <year>2019</year>; <volume>30</volume>(<issue>1</issue>):<fpage>116</fpage>–<lpage>128</lpage>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><string-name><surname>Stein</surname> <given-names>BS</given-names></string-name>, <string-name><surname>Bransford</surname> <given-names>JD</given-names></string-name>, <string-name><surname>Franks</surname> <given-names>JJ</given-names></string-name>, <string-name><surname>Vye</surname> <given-names>NJ</given-names></string-name>, <string-name><surname>Perfetto</surname> <given-names>GA.</given-names></string-name> <article-title>Differences in judgments of learning difficulty</article-title>. <source>Journal of Experimental Psychology: General</source>. <year>1982</year>; <volume>111</volume>(<issue>4</issue>).</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><string-name><surname>Van Den Berg</surname> <given-names>R</given-names></string-name>, <string-name><surname>Anandalingam</surname> <given-names>K</given-names></string-name>, <string-name><surname>Zylberberg</surname> <given-names>A</given-names></string-name>, <string-name><surname>Kiani</surname> <given-names>R</given-names></string-name>, <string-name><surname>Shadlen</surname> <given-names>MN</given-names></string-name>, <string-name><surname>Wolpert</surname> <given-names>DM.</given-names></string-name> <article-title>A common mechanism underlies changes of mind about decisions and confidence</article-title>. <source>Elife</source>. <year>2016</year>; <volume>5</volume>:<fpage>e12192</fpage>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><string-name><surname>Vangsness</surname> <given-names>L</given-names></string-name>, <string-name><surname>Young</surname> <given-names>M.</given-names></string-name> <article-title>Central and Peripheral Cues to Difficulty in a Dynamic Task</article-title>. <source>Human Factors: The Journal of the Human Factors and Ergonomics Society</source>. <year>2019</year>; <volume>61</volume>(<issue>5</issue>):<fpage>749</fpage>–<lpage>762</lpage>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><string-name><surname>Wisniewski</surname> <given-names>D</given-names></string-name>, <string-name><surname>Reverberi</surname> <given-names>C</given-names></string-name>, <string-name><surname>Tusche</surname> <given-names>A</given-names></string-name>, <string-name><surname>Haynes</surname> <given-names>JD.</given-names></string-name> <article-title>The neural representation of voluntary task-set selection in dynamic environments</article-title>. <source>Cerebral Cortex</source>. <year>2015</year>; <volume>25</volume>(<issue>12</issue>):<fpage>4715</fpage>–<lpage>4726</lpage>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="other"><string-name><surname>Yildirim</surname> <given-names>I</given-names></string-name>, <string-name><surname>Saeed</surname> <given-names>B</given-names></string-name>, <string-name><surname>Bennett-Pierre</surname> <given-names>G</given-names></string-name>, <string-name><surname>Gerstenberg</surname> <given-names>T</given-names></string-name>, <string-name><surname>Tenenbaum</surname> <given-names>J</given-names></string-name>, <string-name><surname>Gweon</surname> <given-names>H.</given-names></string-name> <article-title>Explaining intuitive difficulty judgments by modeling physical effort and risk</article-title>. <source>arXiv preprint arXiv:190504445</source>. <year>2019</year>;.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><string-name><surname>Zylberberg</surname> <given-names>A</given-names></string-name>, <string-name><surname>Wolpert</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Shadlen</surname> <given-names>MN.</given-names></string-name> <article-title>Counterfactual reasoning underlies the learning of priors in decision making</article-title>. <source>Neuron</source>. <year>2018</year>; <volume>99</volume>(<issue>5</issue>):<fpage>1083</fpage>–<lpage>1097</lpage>.<page-range>e6</page-range>. doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2018.07.035</pub-id>.</mixed-citation></ref>
</ref-list>
<sec id="d1e4076">
<title>Supporting Information</title>
<table-wrap id="tblS1" orientation="portrait" position="float">
<label>Table S1.</label>
<caption><p>Fit parameter values for drift diffusion model of color judgments (Exp. 1a).</p></caption>
<graphic xlink:href="528254v1_tblS1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tblS2" orientation="portrait" position="float">
<label>Table S2.</label>
<caption><p>Fit parameter values for Race model (Exp. 1).</p></caption>
<graphic xlink:href="528254v1_tblS2.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tblS3" orientation="portrait" position="float">
<label>Table S3.</label>
<caption><p>Fit parameter values for Two-step model (Exp. 1).</p></caption>
<graphic xlink:href="528254v1_tblS3.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tblS4" orientation="portrait" position="float">
<label>Table S4.</label>
<caption><p>Fit parameter values for Absolute momentary evidence model (Exp. 1).</p></caption>
<graphic xlink:href="528254v1_tblS4.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tblS5" orientation="portrait" position="float">
<label>Table S5.</label>
<caption><p>Fit parameter values for Difference model in reaction time task (Exp. 2).</p></caption>
<graphic xlink:href="528254v1_tblS5.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tblS6" orientation="portrait" position="float">
<label>Table S6.</label>
<caption><p>Fit parameter values for Difference model in controlled duration task (Exp. 2). The high <italic>u</italic> parameter for subject 2 implies that the decision process was not bounded.</p></caption>
<graphic xlink:href="528254v1_tblS6.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tblS7" orientation="portrait" position="float">
<label>Table S7.</label>
<caption><p>Fit parameter values for Confidence model in reaction time task (Exp. 2).</p></caption>
<graphic xlink:href="528254v1_tblS7.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<fig id="figS6a" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6—figure supplement 1.</label>
<caption><p>As main figure but with lines showing the fit of the Confidence model to the unknown color condition and predictions for the known color condition.</p></caption>
<graphic xlink:href="528254v1_figS6a.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.86892.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Wyart</surname>
<given-names>Valentin</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Inserm</institution>
</institution-wrap>
<city>Paris</city>
<country>France</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This behavioral modeling study investigates how humans make decisions on the difficulty of perceptual categorization tasks. The study finds that such judgments are best described by an evidence-accumulation model that includes a dynamic comparison of difficulty-related evidence, which terminates when the difference in evidence between two tasks reaches a predetermined bound - a <bold>valuable</bold> finding for research in perceptual decision-making. The paper provides <bold>solid</bold> behavioral evidence for the proposed model, but reviewers noted some potential improvements in the model selection procedure and the relation of the optimal model of the task to the human data, and to the best-fitting model.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.86892.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Meta-cognition, and difficulty judgments specifically, is an important part of daily decision-making. When facing two competing tasks, individuals often need to make quick judgments on which task they should approach (whether their goal is to complete an easy or a difficult task).</p>
<p>In the study, subjects face two perceptual tasks on the same screen. Each task is a cloud of dots with a dominating color (yellow or blue), with a varying degree of domination - so each cloud (as a representation of a task where the subject has to judge which color is dominant) can be seen an easy or a difficult task. Observing both, the subject has to decide which one is easier.</p>
<p>It is well-known that choices and response times in each separate task can be described by a drift-diffusion model, where the decision maker accumulates evidence toward one of the decisions (&quot;blue&quot; or &quot;yellow&quot;) over time, making a choice when the accumulated evidence reaches a predetermined bound. However, we do not know what happens when an individual has to make two such judgments at the same time, without actually making a choice, but simply deciding which task would have stronger evidence toward one of the options (so would be easier to solve).</p>
<p>It is clear that the degree of color dominance (&quot;color strength&quot; in the study's terms) of both clouds should affect the decision on which task is easier, as well as the total decision time. Experiment 1 clearly shows that color strength has a simple cumulative effect on choice: cloud 1 is more likely to be chosen if it is easier and cloud 2 is harder. Response times, however, show a more complex interactive pattern: when cloud 2 is hard, easier cloud 1 produces faster decisions. When cloud 2 is easy, easier cloud 1 produces slower decisions.</p>
<p>The study explores several models that explain this effect. The best-fitting model (the Difference model is the paper's terminology) assumes that the decision-maker accumulates evidence in both clouds simultaneously and makes a difficulty judgment as soon as the difference between the values of these decision variables reaches a certain threshold. Another potential model that provides a slightly worse fit to the data is a two-step model. First, the decision maker evaluates the dominant color of each cloud, then judges the difficulty based on this information.</p>
<p>Importantly, the study explores an optimal model based on the Markov decision processes approach. This model shows a very similar qualitative pattern in RT predictions but is too complex to fit to the real data. It is hard to judge from the results of the study how the models identified above are specifically related to the optimal model - possibly, the fact that simple approaches such as the Difference model fit the data best could suggest the existence of some cognitive constraints that play a role in difficulty judgments.</p>
<p>The Difference model produces a well-defined qualitative prediction: if the dominant color of both clouds is known to the decision maker, the overall RT effect (hard-hard trials are slower than easy-easy trials) should disappear. Essentially, that turns the model into the second stage of the two-stage model, where the decision maker learns the dominant colors first. The data from Experiment 2 impressively confirms that prediction and provides a good demonstration of how the model can explain the data out-of-sample with a predicted change in context.</p>
<p>Overall, the study provides a very coherent and clean set of predictions and analyses that advance our understanding of meta-cognition. The field would benefit from further exploration of differences between the models presented and new competing predictions (for instance, exploring how the sequential presentation of stimuli or attentional behavior can impact such judgments). Finally, the study provides a solid foundation for future neuroimaging investigations.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.86892.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Starting from the observation that difficulty estimation lies at the core of human cognition, the authors acknowledge that despite extensive work focusing on the computational mechanisms of decision-making, little is known about how subjective judgments of task difficulty are made. Instantiating the question with a perceptual decision-making task, the authors found that how humans pick the easiest of two stimuli, and how quickly these difficulty judgments are made, are best described by a simple evidence accumulation model. In this model, perceptual evidence of concurrent stimuli is accumulated and difficulty is determined by the difference between the absolute values of decision variables corresponding to each stimulus, combined with a threshold crossing mechanism. Altogether, these results strengthen the success of evidence accumulation models, and more broadly sequential sampling models, in describing human decision-making, now extending it to judgments of difficulty.</p>
<p>The manuscript addresses a timely question and is very well written, with its goals, methods and findings clearly explained and directly relating to each other. The authors are specialists in evidence accumulation tasks and models. Their modelling of human behaviour within this framework is state-of-the-art. In particular, their model comparison is guided by qualitative signatures which are diagnostic to tease apart the different models (e.g., the RT criss-cross pattern). Human behaviour is then inspected for these signatures, instead of relying exclusively on quantitative comparison of goodness-of-fit metrics. This work will likely have a wide impact in the field of decision-making, and this across species. It will echo in particular with many other studies relying on the similar theoretical account of behaviour (evidence accumulation).</p>
<p>A few points nevertheless came to my attention while reading the manuscript, which the authors might find useful to answer or address in a new version of their manuscript.</p>
<p>1. The authors acknowledge that difficulty estimation occurs notably before exploration (e.g., attempting a new recipe) or learning (e.g., learning a new musical piece) situations. Motivated by the fact that naturalistic tasks make difficult the identification of the inference process underlying difficulty judgments, the authors instead chose a simple perceptual decision-making task to address their question. While I generally agree with the authors's general diagnostic, I am nevertheless concerned so as to whether the task really captures the cognitive process of interest as described in the introduction. As coined by the authors themselves, the main function of prospective difficulty judgment is to select a task which will then ultimately be performed, or reject one which won't. However, in the task presented here, participants are asked to produce difficulty judgments without those judgements actually impacting the future in the task. A feature thus key to difficulty judgments thus seems lacking from the task. Furthermore, the trial-by-trial feedback provided to participants also likely differ from difficulty judgments made in real world. This comment is probably difficult to address but it might generally be useful to discuss the limitations of the task, in particular in probing the desired cognitive process as described in introduction. Currently, no limitations are discussed.</p>
<p>2. The authors take their findings as the general indication that humans rely on accumulation evidence mechanisms to probe the difficulty of perceptual decisions. I would probably have been slightly more cautious in excluding alternative explanations. First, only accumulation models are compared. It is thus simply not possible to reach a different conclusion. Second, even though it is particularly compelling to see untested predictions from the winning model in experiment #1 to be directly tested, and validated in a second experiment, that second experiment presents data from only 3 participants (1 of which has slightly different behaviour than the 2 others), thereby limiting the generality of the findings. Third, the winning model in experiment #1 (difference model) is the preferred model on 12 participants, out of the 20 tested ones. Fourth, the raw BIC values are compared against each other in absolute terms without relying on significance testing of the differences in model frequency within the sample of participants (e.g., using exceedance probabilities; see Stephan et al., 2009 and Rigoux et al., 2014). Based on these different observations, I would thus have interpreted the results of the study with a bit more caution and avoided concluding too widely about the generality of the findings.</p>
<p>3. Deriving and describing the optimal model of the task was particularly appreciated. It was however a bit disappointing not to see how well the optimal model explains participants behaviour and whether it does so better than the other considered models. Also, it would have been helpful to see how close each of the 4 models compared in Figures 2 &amp; 3 get to the optimal solution. Note however that neither of these comments are needed to support the authors' claims.</p>
<p>4. The authors compared the difficulty vs. color judgment conditions to conclude that the accumulation process subtending difficulty judgements is partly distinct from the accumulation process leading to perceptual decisions themselves. To do so, they directly compared reaction times obtained in these two conditions (e.g. &quot;in other cases, the two perceptual decisions are almost certainly completed before the difficulty decision&quot;). However, I find it difficult to directly compare the 'color' and 'difficulty' conditions as the latter entails a single stimulus while the former comprises two stimuli. Any reaction-time difference between conditions could thus I believe only follow from asymmetric perceptual/cognitive load between conditions (at least in the sense RT_color &lt; RT_difficulty). One alternative could have been to present two stimuli in the 'color' condition as well, and asking participants to judge both (or probe which to judge later in the trial). Implementing this now would however require to run a whole new experiment which is likely too demanding. Perhaps the authors could instead also acknowledge that this a critical difference between their conditions, which makes direct comparison difficult.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.86892.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>The manuscript presents novel findings regarding the metacognitive judgment of difficulty of perceptual decisions. In the main task, subjects accumulated evidence over time about two patches of random dot motion, and were asked to report for which patch it would be easier to make a decision about its dominant color, while not explicitly making such decision(s). Using 4 models of difficulty decisions, the authors demonstrate that the reaction time of these decisions are not solely governed by the difference in difficulties between patches (i.e., difference in stimulus strength), but (also) by the difference in absolute accumulated evidence for color judgment of the two stimuli. In an additional experiment, the authors eliminated part of the uncertainty by informing participants about the dominant color of the two stimuli. In this case, reaction times were faster compared to the original task, and only depended on the difference between stimulus strength.</p>
<p>Overall, the paper is very well written, figures and illustrations clearly and adequately accompanied the text, and the method and modeling are rigor.</p>
<p>The weakness of the paper is that it does not provide sufficient evidence to rule out the possibility that judging the difficulty of a decision may actually be comparing between levels of confidence about the dominant color of each stimulus. One may claim that an observer makes an implicit color decision about each stimulus, and then compares the confidence levels about the correctness of the decisions. This concern is reflected in the paper in several ways:</p>
<p>1. It is not clear what were the actual instructors to the participants, as two different phrasings appear in the methods: one instructs participants to indicate which stimulus is the easier one and the other instructs them to indicate the patch with the stronger color dominance. If both instructions are the same, it can be assumed that knowing the dominant color of each patch is in fact solving the task, and no judgment of difficulty needs to be made (perhaps a confidence estimation). Since this is not a classical perceptual task where subjects need to address a certain feature of the stimuli, but rather to judge their difficulties, it is important to make it clear.</p>
<p>2. Two step model: two issues are a bit puzzling in this model. First, if an observer reaches a decision about the dominant color of each patch, does it mean one has made a color decision about the patches? If so, why should more evidence be accumulated? This may also support the possibility that this is a &quot;post decision&quot; confidence judgment rather than a &quot;pre decision&quot; difficulty judgment. Second, the authors assume the time it takes to reach a decision about the dominant color for both patches are equal, i.e., the boundaries for the &quot;mini decision&quot; are symmetrical. However, it would make sense to assume that patches with lower strength would require a longer time to reach the boundaries.</p>
<p>3. Experiment 2: the modification of the Difference model to fit the known condition (Figure 5b), can also be conceptualized as the two-step model, excluding the &quot;mini&quot; color decision time. These two models (Difference model with known color; two-step model) only differ from each other in a way that in the former the color is known in advance, and in the second, the subject has to infer it. One may wonder if the difference in patterns between the two (Figure 3C vs. Figure 6B) is only due to the inaccuracies of inferring the dominant color in the two-step model.</p>
<p>An additional concern is about the controlled duration task: Why were these specific durations chosen (0.1-1.65 sec; only a single duration was larger than 1sec), given the much longer reaction times in the main task (Experiment 1), which were all larger on average than 1sec? This seems a bit like an odd choice. Additionally, difficulty decision accuracies in this version of the task differ between known and unknown conditions (Figure 7), while in the reaction time version of the same task there were no detectable differences in performance between known and unknown conditions (Figure 6C), just in the reaction times. This discrepancy is not sufficiently explained in the manuscript. Could this be explained by the short trial durations?</p>
</body>
</sub-article>
</article>