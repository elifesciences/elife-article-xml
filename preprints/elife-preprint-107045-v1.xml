<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">107045</article-id>
<article-id pub-id-type="doi">10.7554/eLife.107045</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.107045.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories><title-group>
<article-title>Compensation of Hyperexcitability with Simulation-Based Inference</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2789-6068</contrib-id>
<name>
<surname>Müller-Komorowska</surname>
<given-names>Daniel</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>daniel.muller@oist.jp</email>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Fukai</surname>
<given-names>Tomoki</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02qg15b79</institution-id><institution>Neural Coding and Brain Computing Unit, Okinawa Institute of Science and Technology</institution></institution-wrap>, <city>Onna</city>, <country country="JP">Japan</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Slutsky</surname>
<given-names>Inna</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Tel Aviv University</institution>
</institution-wrap>
<city>Tel Aviv</city>
<country country="IL">Israel</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Poirazi</surname>
<given-names>Panayiota</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>FORTH Institute of Molecular Biology and Biotechnology</institution>
</institution-wrap>
<city>Heraklion</city>
<country country="GR">Greece</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-07-28">
<day>28</day>
<month>07</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP107045</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-04-08">
<day>08</day>
<month>04</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-01-10">
<day>10</day>
<month>01</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.01.07.631838"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Müller-Komorowska &amp; Fukai</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Müller-Komorowska &amp; Fukai</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-107045-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>The activity of healthy neuronal networks is tightly regulated, and a shift towards hyperexcitability can cause various problems, such as epilepsies, memory deficits, and motor disorders. Numerous cellular, synaptic, and intrinsic mechanisms of hyperexcitability and compensatory mechanisms to restore healthy activity have been proposed. However, quantifying multiple compensatory mechanisms and their dependence on specific pathophysiological mechanisms has proven challenging, even in computational models. We use simulation-based inference to quantify the interactions of compensatory mechanisms in a spiking neuronal network model. Various parameters of the model can compensate for changes in other parameters to maintain baseline activity, and we rank them by their compensatory potential. Furthermore, specific causes of hyperexcitability - interneuron loss, excitatory recurrent synapses, and principal cell depolarization - have distinct compensatory mechanisms that can restore normal excitability. Our results show that spiking neuronal network simulators could provide the quantitative foundation for targeting pathophysiological network mechanisms with precise interventions.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>nonuniqueness</kwd>
<kwd>degeneracy</kwd>
<kwd>pathophysiology</kwd>
<kwd>neural posterior estimation</kwd>
<kwd>precision medicine</kwd>
</kwd-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>

</front>
<body>
<sec id="s1">
<label>1</label>
<title>Introduction</title>
<p>Neuronal networks operate within narrow ranges of average activity. A shift outside that range is a key aspect of many brain disorders. Epilepsies are an extreme case where hyperactivity of a neuronal network spreads across the brain, causing seizures (<xref ref-type="bibr" rid="c7">Devinsky et al., 2018</xref>). Alzheimer’s disease shows local hyperexcitability at the early stage, increased bursting, and elevated intracellular calcium levels (<xref ref-type="bibr" rid="c1">Anastacio et al., 2022</xref>; <xref ref-type="bibr" rid="c23">Mittag et al., 2023</xref>). Although this kind of hyperexcitability rarely causes seizures, there are similarities between local patterns of hyperactivity in epilepsy and Alzheimer’s disease (<xref ref-type="bibr" rid="c16">Kamondi et al., 2024</xref>). In schizophrenia, the imbalance of excitation and inhibition shifts cortical networks toward hyperactivity (<xref ref-type="bibr" rid="c19">Liu et al., 2021</xref>). While hyperexcitability has wide-ranging effects on brain health, its causes are also diverse and complex.</p>
<p>From a theoretical perspective, anything that increases the average probability of a principal cell to fire is a step toward hyperexcitability. This includes changes in the kinetics, number and location of ion channels, synaptic changes, or cell loss. In epilepsies, changes at all levels of the network have been found At the cellular level, death of inhibitory interneurons is a key feature of epileptic animal models (<xref ref-type="bibr" rid="c13">Huusko et al., 2015</xref>), which has prompted the development of interneuron transplantation as a novel treatment strategy (<xref ref-type="bibr" rid="c11">Hunt &amp; Baraban, 2015</xref>). At the synaptic level, granule cells of the healthy dentate gyrus lack recurrent excitatory connections but have pathological excitatory recurrent connections in epileptic tissue, a phenomenon called mossy fiber sprouting (<xref ref-type="bibr" rid="c26">Scharfman et al., 2003</xref>). Ion channels have been most consistently associated with genetic but also acquired epilepsies (<xref ref-type="bibr" rid="c2">Beck &amp; Yaari, 2008</xref>; <xref ref-type="bibr" rid="c18">Lerche et al., 2013</xref>), coining the term “channelopathy,” a disease relating to ion channels (<xref ref-type="bibr" rid="c35">Wolfart &amp; Laker, 2015</xref>). Ion channels are also well-known from fundamental neuroscience to exhibit nonuniqueness (also known as degeneracy), meaning that widely different ion channel combinations can perform the same function (<xref ref-type="bibr" rid="c21">Marom &amp; Marder, 2023</xref>). Nonuniqueness has intriguing implications for epilepsy (<xref ref-type="bibr" rid="c29">Stöber et al., 2023</xref>). For the causes of epilepsies, nonuniqueness implies that there are multiple different ways to acquire clinically identical symptoms. For the cures of epilepsies, it means that there are various ways to recover healthy function. Thus far, these implications have been primarily theoretical, and it has been impossible to unify nonuniqueness at the ion channel level with synaptic and cell-type nonuniqueness. In a spiking neuronal network model, we quantify nonuniqueness at the intrinsic, synaptic, and cellular levels to identify mechanisms that can compensate for specific pathophysiology.</p>
<p>To find compensatory mechanisms, we use simulation-based inference (SBI), a broad category of tools used to solve the inverse problem of a simulator (<xref ref-type="bibr" rid="c5">Cranmer et al., 2020</xref>). While a simulator generates output given a set of parameters, SBI estimates the probability of sets of parameters to produce a given output. It can, therefore, be used to find multiple parameter sets to create the same output dynamic (<xref ref-type="bibr" rid="c10">Gonçalves et al., 2020</xref>), effectively quantifying nonuniqueness. For the longest time, approximate Bayesian computation (ABC) was the method of choice for simulation-based inference. However, ABC is sampling inefficient, which restricts it to small simulators. Several new approaches to SBI have been developed (<xref ref-type="bibr" rid="c5">Cranmer et al., 2020</xref>), one of which is neural posterior estimation (NPE, <xref ref-type="bibr" rid="c25">Papamakarios &amp; Murray (2018)</xref>), which works on mechanistic models of neurons and identifies compensatory mechanisms in the classic stomatogastric ganglion model system (<xref ref-type="bibr" rid="c10">Gonçalves et al., 2020</xref>). Recently, NPE has been used to find nonunique parameters that generate diverse output dynamics (<xref ref-type="bibr" rid="c9">Gao et al., 2024</xref>). Here, we use NPE to quantify nonuniqueness and identify compensatory mechanisms that avoid hyperexcitability in a spiking microcircuit simulator with two interneuron populations.</p>
<p>We specifically investigate three well-known pathophysiological issues: interneuron (IN) loss, excitatory recurrent sprouting, and principal cell (PC) depolarization. We find that various parameters related to these three conditions have compensatory potential. Which parameters are most effective depends on the specific pathophysiology. IN loss is best compensated by increasing IN → PC connectivity. Sprouting is compensated by a set of PC intrinsic properties and PC → PC synaptic weight. Intrinsic depolarization is compensated best by increasing the PC spiking threshold. Our results show that identifying the specific pathophysiology could be used to rank compensatory mechanisms and thereby find precise interventions.</p>
</sec>
<sec id="s2">
<label>2</label>
<title>Materials and Methods</title>
<sec id="s2a">
<label>2.1</label>
<title>The Spiking Neuronal Network Simulator</title>
<p>To quantify the compensatory mechanisms of hyperexcitability with simulation-based inference, we implemented a phenomenological spiking neuronal network simulator. We used adaptive exponential leaky integrate-and-fire neurons (AdEx) (<xref ref-type="bibr" rid="c4">Brette &amp; Gerstner, 2005</xref>) to model one excitatory and two inhibitory populations connected with conductance-based Tsodyks-Markram synapses to model shortterm plasticity (<xref ref-type="bibr" rid="c32">Tsodyks et al., 1998</xref>). The voltage changed according to <xref ref-type="disp-formula" rid="eqn1">Equation 1</xref>. The adaptation current <italic>w</italic> changed according to <xref ref-type="disp-formula" rid="eqn2">Equation 2</xref>. At spike time, variables were reset, as in <xref ref-type="disp-formula" rid="eqn3_1">Equation 3.1</xref> and <xref ref-type="disp-formula" rid="eqn3_2">Equation 3.2</xref>. See <xref rid="tbl1" ref-type="table">Table 1</xref> for descriptions and values of all intrinsic parameters.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><title>The intrinsic parameters of the AdEx model populations.</title>
<p>Square brackets indicate the lower and upper bound of the uniform prior distribution. If a cell contains a single number, that parameter is held constant. Δ<sub><italic>T</italic></sub>, slope factor; <italic>τ</italic><sub><italic>w</italic></sub>, adaptation time constant; <italic>a</italic>, subthreshold adaptation; <italic>b</italic>, spike-triggered adaptation; <italic>V</italic><sub><italic>r</italic></sub>, spike triggered reset voltage; <italic>C</italic>, capacitance; <italic>g</italic><sub><italic>L</italic></sub>, leak conductance; <italic>E</italic><sub><italic>L</italic></sub>, resting membrane potential; <italic>V</italic><sub><italic>T</italic></sub>, spike threshold. Note that <italic>V</italic><sub><italic>T</italic></sub> determines the point of exponential rise but is not the hard threshold for triggering the spike reset. A spike is triggered when the voltage is larger than 0 mV, see <xref ref-type="disp-formula" rid="eqn3_1">Equation 3.1</xref>; <italic>n</italic>, number of neurons in the population.</p></caption>
<graphic xlink:href="631838v1_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p><disp-formula id="eqn1">
<graphic xlink:href="631838v1_eqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn2">
<graphic xlink:href="631838v1_eqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn3_1">
<graphic xlink:href="631838v1_eqn3_1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn3_2">
<graphic xlink:href="631838v1_eqn3_2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula></p>
<p>A neuron received its input through <italic>I</italic><sub>total</sub> (<xref ref-type="disp-formula" rid="eqn4">Equation 4</xref>). <italic>g</italic><sub>PC</sub>, <italic>g</italic><sub>NIN</sub> &amp; <italic>g</italic><sub>AIN</sub> are the conductances from the presynaptic principal cells (PC), non-adapting interneurons (NIN) and adapting interneurons (AIN), respectively. <italic>g</italic><sub>INP</sub> is the excitatory conductance from a homogeneous Poisson spike train. <italic>g</italic><sub>GAP</sub> is a constant conductance that exists only between some NINs to simulate symmetric gap junction connections. The conductances and the synaptic resources changed as in <xref ref-type="disp-formula" rid="eqn5_1">Equation 5.1</xref>, <xref ref-type="disp-formula" rid="eqn5_2">Equation 5.2</xref>, <xref ref-type="disp-formula" rid="eqn5_3">Equation 5.3</xref>, <xref ref-type="disp-formula" rid="eqn5_4">Equation 5.4</xref> and <xref ref-type="disp-formula" rid="eqn5_5">Equation 5.5</xref> (<xref ref-type="bibr" rid="c32">Tsodyks et al., 1998</xref>). Cells were randomly connected with a probability <italic>p</italic>, excluding self-connectivity if a population was connected to itself. A presynaptic spike changed the synaptic resources according to <xref ref-type="disp-formula" rid="eqn6_1">Equation 6.1</xref>, <xref ref-type="disp-formula" rid="eqn6_2">Equation 6.2</xref> and <xref ref-type="disp-formula" rid="eqn6_3">Equation 6.3</xref>. If <italic>τ</italic><sub>facil</sub> was set to 0, <xref ref-type="disp-formula" rid="eqn5_3">Equation 5.3</xref> was deleted from the model, and u was kept constant at <italic>U</italic><sub>SE</sub>. <xref rid="tbl2" ref-type="table">Table 2</xref> shows the synaptic parameters for all connections.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2:</label>
<caption><title>The parameters of the Tsodyks-Markram synaptic connections.</title>
<p><italic>A</italic><sub>SE</sub>, maximum synaptic conductance; <italic>τ</italic><sub>in</sub>, time constant of synaptic decay; <italic>τ</italic><sub>rec</sub>, synaptic resource recovery time constant; <italic>U</italic><sub>SE</sub>, fraction of synaptic resources activated; <italic>τ</italic><sub>facil</sub>, decay of facilitation time constant; <italic>p</italic> pairwise connection probability in %. NIN GJ NIN, is a gap junction connection, modeled as a fixed conductance between connected NINs.</p></caption>
<graphic xlink:href="631838v1_tbl2.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p><disp-formula id="eqn4">
<graphic xlink:href="631838v1_eqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn5_1">
<graphic xlink:href="631838v1_eqn5_1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn5_2">
<graphic xlink:href="631838v1_eqn5_2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn5_3">
<graphic xlink:href="631838v1_eqn5_3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn5_4">
<graphic xlink:href="631838v1_eqn5_4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn5_5">
<graphic xlink:href="631838v1_eqn5_5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn6_1">
<graphic xlink:href="631838v1_eqn6_1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn6_2">
<graphic xlink:href="631838v1_eqn6_2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn6_3">
<graphic xlink:href="631838v1_eqn6_3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula></p>
<p>The model consists of three different populations: principal cells (PCs), adapting interneurons (AINs), and non-adapting interneurons (NINs). Their parameters are largely taken from <xref ref-type="bibr" rid="c24">Naud et al. (2008)</xref>. The AdEx model has nine parameters, and we additionally varied the number of neurons in the interneuron populations (see <xref rid="tbl1" ref-type="table">Table 1</xref> for all parameters). We kept Δ<italic>T, τ</italic><sub><italic>w</italic></sub>, <italic>a, b</italic>, and <italic>V</italic><sub><italic>r</italic></sub> constant to keep the parameter space tractable for simulation-based inference (SBI) and to keep qualitative changes of firing patterns to a minimum. That left <italic>C, g</italic><sub><italic>L</italic></sub>, <italic>E</italic><sub><italic>L</italic></sub> and <italic>V</italic><sub><italic>T</italic></sub> subject to SBI. This totals twelve free neuronal parameters plus the cell numbers of the two interneuron populations.</p>
<p>The neuronal populations and their homogeneous Poisson input were connected through 10 types of synapses and 1 gap junction. The homogeneous Poisson input innervated the PCs and the NINs. All parameters of both inputs were fixed. For the other chemical synapses we fixed the parameters <italic>τ</italic><sub>in</sub>, <italic>τ</italic><sub>rec</sub>, <italic>U</italic><sub>SE</sub> and <italic>τ</italic><sub>facil</sub>. The connection probability (in %) and the strength were varied during SBI. The chemical connections in the network were PC → PC, PC → aIN, PC → NIN, NIN → PC, NIN → NIN, AIN → PC, AIN → NIN, and AIN → AIN. Gap junctions connected NIN with other NIN. Therefore, eighteen connectivity parameters were varied during SBI.</p>
</sec>
<sec id="s2b">
<label>2.2</label>
<title>Summary Statistics</title>
<p>We performed inference given seven summary statistics, all of which were calculated on the PCs. The mean rate was calculated from all PCs, including silent ones. To calculate the mean interspike interval (ISI) entropy, we calculated the histogram of the ISIs in bins of 1 ms (Using scipy.stats.entropy from the SciPy library). Theta, gamma and fast power were calculated from the power spectral density (PSD; scipy.signal.periodogram). Theta power was calculated by summing the PSD between 8 Hz and 12 Hz, Gamma power between 30 Hz and 100 Hz and fast power between 100 and 150. The correlation was calculated between the convolved spike trains of 50 randomly chosen PCs and then averaged. For the average pairwise Pearson correlation, spike trains were convolved with as Gaussian kernel of 10 ms width. Pairs where one of the neurons had zero spikes were excluded from the average. The ISI coefficient of variance (CV) for each cell was calculated by dividing the mean of the ISI by the standard deviation of the ISI. Then, CVs of all cells were averaged, excluding cells with undefined CVs (less than two spikes or zero standard deviation). All target outcomes for SBI are shown in <xref rid="tbl3" ref-type="table">Table 3</xref>.</p>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3:</label>
<caption><title>The quantified outcomes of the simulator.</title>
<p>ISI, interspike interval; CV, coefficient of variation. We implemented the model with Brian2 (<xref ref-type="bibr" rid="c28">Stimberg et al., 2019</xref>). All simulations ran for 1 s with a temporal resolution of 0.1 ms.</p></caption>
<graphic xlink:href="631838v1_tbl3.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s2c">
<label>2.3</label>
<title>Simulation-Based Inference and Quality Checks</title>
<p>For SBI we used neural posterior estimation (NPE; <xref ref-type="bibr" rid="c10">Gonçalves et al. (2020)</xref>; <xref ref-type="bibr" rid="c25">Papamakarios &amp; Murray (2018)</xref>) with the SNPE_C inference implementation from the sbi Python package 0.22.0 (<xref rid="c31" ref-type="bibr">Tejero-Cantero et al., 2020</xref>). Initially 2620000 parameter samples were drawn from the prior, then simulated, and the parameter-outcome pairs were used to train a neuronal density estimator with default parameters (num_atoms=10, training_batch_size=50, learning_rate=0.0005, validation_fraction=0.1, stop_after_epochs=20, max_num_epochs=2147483647, clip_max_norm=5.0). For sequential inference, we used truncated sequential NPE (<xref ref-type="bibr" rid="c6">Deistler et al., 2022</xref>). The posterior estimate was truncated at the 0.0001 quantile in four sequential rounds, with 20000 simulations in each round. 1000000 samples were used to estimate the support. Undefined summary statistics (ISI Entropy, correlation or ISI CV) were set to 0. To calculate marginal pairwise correlations, 200000 samples were drawn from the baseline posterior distribution, and we used spearmanr from scipy.stats. To calculate the conditional correlation coefficients we used the sbi package function conditional_corrcoeff, conditioning other parameters on the maximum-a-posteriori (MAP) estimate. The MAP estimate was calculated with the posterior.map method.</p>
</sec>
<sec id="s2d">
<label>2.4</label>
<title>Specific Conditional Baseline Distributions</title>
<p>We introduced specific conditions on the posterior distribution to investigate the mechanisms that can compensate for interneuron loss, excitatory synaptic sprouting, and intrinsic hyperexcitability. For conditional sampling, we used the sbi.inference.MCMCPosterior implementation in the sbi Python package. To investigate interneuron loss, we compared the distributions:
<disp-formula id="eqn7_1">
<graphic xlink:href="631838v1_eqn7_1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn7_2">
<graphic xlink:href="631838v1_eqn7_2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula></p>
<p><xref ref-type="disp-formula" rid="eqn7_2">Equation 7.2</xref> produces healthy dynamics, despite interneuron loss and <xref ref-type="disp-formula" rid="eqn7_1">Equation 7.1</xref> is the healthy control, which produces healthy dynamics with a normal number of interneurons. 55 and 54 are the MAP estimates for the interneuron counts of the marginal baseline posterior.</p>
<p>To investigate excitatory synaptic sprouting, we compared the distributions:
<disp-formula id="eqn8_1">
<graphic xlink:href="631838v1_eqn8_1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn8_2">
<graphic xlink:href="631838v1_eqn8_2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula></p>
<p><xref ref-type="disp-formula" rid="eqn8_2">Equation 8.2</xref> produces healthy dynamics despite excitatory sprouting. The connection probability 3% is double the baseline MAP estimate of 1.5%. For comparison we chose an order of magnitude smaller percentage points for <xref ref-type="disp-formula" rid="eqn8_1">Equation 8.1</xref>. The connection strength 4.35 nS is the MAP estimate of the marginal BL posterior.</p>
<p>To investigate intrinsic changes in principal cell excitability, we compare the distributions:
<disp-formula id="eqn9_1">
<graphic xlink:href="631838v1_eqn9_1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn9_2">
<graphic xlink:href="631838v1_eqn9_2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula></p>
<p>These represent a minor increase of input resistance and resting membrane potential in principal cells. MAP estimate for baseline output of the two parameters was <inline-formula><inline-graphic xlink:href="631838v1_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="631838v1_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.</p>
<p>To compare conditional distributions of parameters, 100000 samples were drawn and we used scipy’s two sample implementation of the Kolmogorov-Smirnov test (ks_2samp).</p>
</sec>
<sec id="s2e">
<label>2.5</label>
<title>Conditional Baseline versus Hyperexcitable Distributions</title>
<p>In <xref rid="fig4" ref-type="fig">Figure 4</xref>, the compared distributions for IN Loss are: <italic>p</italic>(<italic>θ</italic>|<italic>x</italic><sub>BL</sub>, AIN<sub><italic>n</italic></sub> = 15, NIN<sub><italic>n</italic></sub> = 15) versus <italic>p</italic>(<italic>θ</italic>|<italic>x</italic><sub>HE</sub>, AIN<sub><italic>n</italic></sub> = 15, NIN<sub><italic>n</italic></sub> = 15). For Sprouting: <italic>p</italic>(<italic>θ</italic>|<italic>x</italic><sub>BL</sub>, PC → <italic>PC</italic><sub><italic>P</italic></sub> = 3%, <inline-formula><inline-graphic xlink:href="631838v1_inline3.gif" mimetype="image" mime-subtype="gif"/></inline-formula>) versus <italic>p</italic>(<italic>θ</italic>|<italic>x</italic><sub>HE</sub>, PC → PC<sub><italic>P</italic></sub> = 3%, <inline-formula><inline-graphic xlink:href="631838v1_inline4.gif" mimetype="image" mime-subtype="gif"/></inline-formula>). For Depolarized: <italic>p</italic>(<italic>θ</italic>|<italic>x</italic><sub>BL</sub>, <inline-formula><inline-graphic xlink:href="631838v1_inline5.gif" mimetype="image" mime-subtype="gif"/></inline-formula>) versus <italic>p</italic>(<italic>θ</italic>|<italic>x</italic><sub>HE</sub>, <inline-formula><inline-graphic xlink:href="631838v1_inline6.gif" mimetype="image" mime-subtype="gif"/></inline-formula>).</p>
</sec>
<sec id="s2f">
<label>2.6</label>
<title>Compensatory Effects on Simulator Output</title>
<p>In <xref rid="fig5" ref-type="fig">Figure 5</xref>, 100 samples were drawn from each pathophysiological conditional distribution: <italic>p</italic>(<italic>θ</italic>|<italic>x</italic><sub>HE</sub>, <inline-formula><inline-graphic xlink:href="631838v1_inline7.gif" mimetype="image" mime-subtype="gif"/></inline-formula>), <italic>p</italic>(<italic>θ</italic>|<italic>x</italic><sub>HE</sub>, PC → PC<sub><italic>P</italic></sub> = 3%, <inline-formula><inline-graphic xlink:href="631838v1_inline8.gif" mimetype="image" mime-subtype="gif"/></inline-formula>) and <italic>p</italic>(<italic>θ</italic>|<italic>x</italic><sub>HE</sub>, AIN<sub><italic>n</italic></sub> = 15, NIN<sub><italic>n</italic></sub> = 15). For each parameter and each sample, we varied the parameter linearly to get fifty values from lowest to highest prior value.</p>
</sec>
<sec id="s2g">
<label>2.7</label>
<title>Software</title>
<p>Prior samples were drawn and simulated on the Okinawa Institute of Science High Performance computing resources running CentOS 8. with the 4. version of the Linux kernel. The brian2 version was 2.5.0.3 (<xref ref-type="bibr" rid="c28">Stimberg et al., 2019</xref>). The Python version was 3.9.18.</p>
<p>The neural density estimator training, sequential NPE and conditional sampling were run on a Windows 10 computer with brian2 2.7.1. The Python version was 3.10.14.</p>
<p>Plotting was done with matplotlib 3.9.1 (<xref ref-type="bibr" rid="c12">Hunter, 2007</xref>) or seaborn 0.13.2 (<xref ref-type="bibr" rid="c34">Waskom, 2021</xref>). pandas 2.2.3 was used for data wrangling (<xref ref-type="bibr" rid="c22">McKinney, 2010</xref>). statsmodels 0.14.4 was used for ANOVA test (<xref ref-type="bibr" rid="c27">Seabold &amp; Perktold, 2010</xref>). scipy 1.13.1 was used for Kolmogorov-Smirnov tests and Spearman correlation coefficient (<xref ref-type="bibr" rid="c33">Virtanen et al., 2020</xref>).</p>
</sec>
</sec>
<sec id="s3">
<label>3</label>
<title>Results</title>
<p>To study the mechanisms of hyperexcitability, we implemented a phenomenological spiking neuronal microcircuit simulator (<xref rid="fig1" ref-type="fig">Figure 1 A</xref>, Methods <xref ref-type="sec" rid="s2a">Section 2.1</xref>). We drew 2620000 samples from the 32 dimensional prior parameter space (<xref rid="tbl1" ref-type="table">Table 1</xref> &amp; <xref rid="tbl2" ref-type="table">Table 2</xref>) and simulated them. Out of those simulations, 1462613 had zero PC spikes. <xref rid="fig1" ref-type="fig">Figure 1 B</xref> shows the outcome variables from the simulations with at least one action potential, showing that the simulator can generate a wide variety of outcomes, including the baseline and the hyperexcitable values targeted with SBI shown as crosses (<xref rid="tbl3" ref-type="table">Table 3</xref>). We used all 2620000 samples to train a neuronal density estimator, with the mean ISI entropy, correlation and ISI CV set to zero if there were zero PC spikes. We then used simulation-based calibration (<xref ref-type="bibr" rid="c30">Talts et al., 2018</xref>) to test the reliability of the posterior estimate <italic>q</italic>(<italic>θ</italic>|<italic>x</italic>), for all x, which are within the support of the likelihood. Simulation-based calibration showed that the posterior estimate was unreliable for several parameters (not shown). Therefore, we did not rely on the amortized posterior estimate but went on to perform truncated sequential NPE (<xref ref-type="bibr" rid="c6">Deistler et al., 2022</xref>) to get more precise estimates for the specific outcomes in <xref rid="tbl3" ref-type="table">Table 3</xref>. <xref rid="fig1" ref-type="fig">Figure 1 C</xref> shows simulation results from the maximum-a-posteriori (MAP) estimated parameters from the sequential posterior estimate, given baseline and hyperexcitable outcomes. To ensure that the posteriors were accurate, we also performed prior-predictive checks. <xref rid="fig1" ref-type="fig">Figure 1 D</xref> shows the simulation results from 1000 parameter sets sampled from the posterior. The simulation results are distinct for the two conditions and the target value for each outcome variable are well within the support for the baseline condition. For the hyperexcitable condition, however, the gamma and fast power outcomes are not within the interquartile range. This indicates that the model might be unable to decrease gamma and fast power while increasing excitability. However, because the mean rate and synchrony are increased, the posterior is still a good estimate of a hyperexcitable condition. Before exploring the hyperexcitable posterior, we investigated compensatory mechanisms that maintain the baseline condition by investigating the pairwise correlations in the posterior sample.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Sequential NPE finds distributions of parameters that produce different levels of excitability.</title>
<p><bold>A)</bold> An illustration of the spiking neuronal network simulator. See methods <xref ref-type="sec" rid="s2a">Section 2.1</xref> for details. <bold>B)</bold> Simulator outcome from 1122586 simulations. Simulations with zero PC spikes or undefined CV are not shown. The parameters were drawn from the prior distribution (see <xref ref-type="table" rid="tbl1">Table 1</xref> &amp; <xref ref-type="table" rid="tbl2">Table 2</xref>). The cross shows the two target outcomes the NPE was conditioned on. <bold>C)</bold> Shows the result of simulating the MAP parameters from <italic>p</italic>(<italic>θ</italic> |<italic>x</italic><sub>Baseline</sub>) and <italic>p</italic>(<italic>θ</italic> |<italic>x</italic><sub>Hyperexcitable</sub>). The top shows the voltage trace of a single PC, and the bottom shows spike raster plots for 50 of 500 PCs. <bold>D)</bold> Outcomes from simulating 1000 parameter sets that were drawn from each of the two distributions. The black x marks the value that was targeted with NPE. See <xref ref-type="table" rid="tbl3">Table 3</xref>. In the baseline condition, the targeted outcome is well within support of the outcome distribution for all parameters. In the hyperexcitable condition, gamma and fast power targets are not within the interquartile range.</p></caption>
<graphic xlink:href="631838v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To identify compensatory mechanisms, we calculated the pairwise correlation coefficients between parameter samples from the baseline posterior estimate. These correlations identify compensatory mechanisms, because they indicate that baseline activity can be maintained despite changes in one parameter if the other parameter changes accordingly. Since our model has 32 free parameters, 496 unique pairwise correlations exist. For each pair, we calculated the Spearman correlation coefficient from 200000 marginal posterior samples. Out of all pairs, only 19 have correlation coefficients larger than 0.1 or smaller than −0.1 <xref rid="fig2" ref-type="fig">Figure 2 A</xref>. The largest negative correlation (−0.94) is between the PC connection probability (PC → PC<sub><italic>p</italic></sub>) and the connection strength <inline-formula><inline-graphic xlink:href="631838v1_inline9.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. Both parameters are narrowly tuned and must be extremely small to maintain healthy dynamics (<xref rid="fig2" ref-type="fig">Figure 2 A</xref>). The MAP estimate (an estimate of the posterior distribution’s peak) for connection probability is 0.015, and for connection strength, it is 4.35 nS. Probability and strength of connections from both interneuron types to PCs are also negatively correlated, albeit with smaller correlation coefficients (<xref rid="fig2" ref-type="fig">Figure 2 B</xref>) and they are not as narrowly constrained (<xref rid="fig2" ref-type="fig">Figure 2 A</xref>).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Various parameter pairs can compensate each other to maintain baseline excitability.</title>
<p>200000 samples were drawn from the baseline posterior estimator and pairwise Spearman correlations were calculated for each of the 496 unique pairwise comparisons. <bold>A)</bold> shows 2D histograms of the 19 pairs with correlation coefficients larger &gt;0.1 or &lt;−0.1. The maximum pixel values read from top left to bottom right are: 813, 588,525,1718,411,863, 3328, 2923, 704, 757, 673, 2371, 327, 294, 3337, 278, 262, 301 and 291. The minimum pixel value is always 0, except for the second to last pair (<inline-formula><inline-graphic mime-subtype="gif" mimetype="image" xlink:href="631838v1_inline19.gif"/></inline-formula> vs <inline-formula><inline-graphic mime-subtype="gif" mimetype="image" xlink:href="631838v1_inline20.gif"/></inline-formula> where the minimum is 3. <bold>B)</bold> Shows the correlation coefficient of all parameter pairs as a diverging heatmap. The marginal correlation coefficients for the pairs shown in A from top left to bottom right, are: −0.31, −0.21, −0.13, 0.15, 0.13, −0.32, 0.19, −0.25, −0.13, −0.14, 0.54, 0.14, −0.22, −0.12, −0.94, −0.19, −0.16, 0.11, −0.32. <bold>C)</bold> Shows the correlation coefficients of samples drawn for each parameter pair while conditioning all other parameters on the map estimate. Correlation coefficients for the order in A from top left to bottom right, are: −0.43, 0.06, −0.41, 0.49, −0.01, −0.59, 0.42, 0.35, −0.47, −0.39, 0.59, 0.54, −0.47, −0.35, −0.49, −0.45, −0.47, −0.23, −0.51.</p></caption>
<graphic xlink:href="631838v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The largest positive correlation is between two intrinsic properties of <inline-formula><inline-graphic xlink:href="631838v1_inline10.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="631838v1_inline11.gif" mimetype="image" mime-subtype="gif"/></inline-formula> (0.54). Those are the equilibrium potential of the leak current and the threshold <italic>V</italic><sub><italic>T</italic></sub>, which causes the exponential non-linearity of the AdEX model. If PCs rest at a higher potential, similar activity levels can be achieved by raising the threshold and vice-versa. The capacitance is negatively correlated with the other three intrinsic properties (<xref rid="fig2" ref-type="fig">Figure 2 B</xref>). Increasing the capacitance reduces the overall excitability of the cell but also changes the filtering properties and, thereby, the frequency response. This might explain why PC<sub><italic>C</italic></sub> and <inline-formula><inline-graphic xlink:href="631838v1_inline12.gif" mimetype="image" mime-subtype="gif"/></inline-formula> are negatively correlated. If PC<sub><italic>C</italic></sub> would only decrease the mean rate, the intuitive compensatory mechanism would be to increase excitability by raising <inline-formula><inline-graphic xlink:href="631838v1_inline13.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, which would imply a positive correlation. The negative correlation is, therefore, likely compensating for one of the summary statistics that is not about the principal cell rate.</p>
<p>Out of the 19 meaningfully (correlation coefficient &gt;0.1 or &lt;−0.1) correlated parameter pairs, 12 involve intrinsic PC properties. None of the intrinsic interneuron parameters feature in meaningful correlations but both interneuron numbers are correlated with their respective population’s connection probability to principal cell <xref rid="fig2" ref-type="fig">Figure 2 A</xref>.</p>
<p>However, these are the marginal correlations and they are known to be weakly correlated. Marginal distributions are not constrained by any other parameters. In other words, a parameter’s marginal posterior distribution gives the probability for the parameter value to achieve the targeted outcome, while all other parameters are unknown. Because the unknown parameters are the broadest possible estimate of the parameter space, the marginal distributions are broad. However, the posterior is a better, more narrow estimate of the likely parameters, and we can use it to constrain the distribution of parameters. These constrained distributions are called conditional distributions because the other parameters are conditioned on particular values. When calculating conditional distributions of two parameters and correlating their samples, the correlation is called “conditional correlation”.</p>
<p>We therefore used the MAP estimate of the posterior distribution to calculate the conditional correlations (<xref rid="fig2" ref-type="fig">Figure 2 C</xref>). Most pairs that were meaningfully correlated with marginal sampling were also meaningfully correlated with conditional sampling. However, many pairs are only correlated for conditional sampling (<xref ref-type="supplementary-material" rid="supp1">Figure Supp 2.1</xref>). Stronger correlations have also been shown previously for conditioning on posterior samples, rather than the MAP (<xref ref-type="bibr" rid="c10">Gonçalves et al., 2020</xref>). <xref ref-type="supplementary-material" rid="supp1">Figure Supp 2.2 &amp; 2.3</xref> show the full marginal and conditional posterior distribution, respectively.</p>
<p>These correlations identify parameters that can compensate for changes in other parameters to maintain the baseline output. However, there is a more specific way of investigating compensatory mechanisms. By comparing two conditioned distributions, <italic>p</italic>(<italic>θ</italic>|<italic>x</italic><sub>BL</sub>, <italic>θ</italic><sub><italic>i</italic></sub> = <italic>k</italic>) and <italic>p</italic>(<italic>θ</italic>|<italic>x</italic><sub>BL</sub>, <italic>θ</italic><sub><italic>i</italic></sub> = <italic>j</italic>), we can find the compensatory mechanisms that maintain <italic>x</italic><sub>BL</sub> despite the condition. For example, if <italic>θ</italic><sub><italic>i</italic></sub> = <italic>k</italic> is a normal amount of interneurons and <italic>θ</italic><sub><italic>i</italic></sub> = <italic>j</italic> is the amount of interneurons expected in sclerotic tissue, we can find the parameters changes that can maintain healthy output despite the interneuron loss. We used this technique to investigate IN loss, recurrent excitation, and PC depolarization.</p>
<p>To find specific compensatory mechanisms, we sampled from the baseline posterior estimator with additional conditions on parameters representing known pathophysiological parameters (<xref rid="fig3" ref-type="fig">Figure 3</xref>). For interneuron loss, we conditioned the cell numbers in both interneuron populations (Normal: <xref ref-type="disp-formula" rid="eqn7_1">Equation 7.1</xref> versus IN Loss: <xref ref-type="disp-formula" rid="eqn7_2">Equation 7.2</xref>). For recurrent excitation (called sprouting), we conditioned the connection probability PC → PC<sub><italic>p</italic></sub> (Normal: <xref ref-type="disp-formula" rid="eqn8_1">Equation 8.1</xref> versus Sprouting: <xref ref-type="disp-formula" rid="eqn8_2">Equation 8.2</xref>). And for PC depolarization we conditioned PC<sub>EL</sub> and <inline-formula><inline-graphic xlink:href="631838v1_inline14.gif" mimetype="image" mime-subtype="gif"/></inline-formula> (Normal: <xref ref-type="disp-formula" rid="eqn9_1">Equation 9.1</xref> versus Depolarized: <xref ref-type="disp-formula" rid="eqn9_2">Equation 9.2</xref>). While conditioning on these parameters, we sampled all other parameters and compared the normal with the pathophysiological samples. The difference between the distributions of a parameter reveals compensatory mechanisms because it shows how the parameter can change to maintain baseline activity despite the pathophysiology. We use the Kolmogorov-Smirnov (KS) test statistic to quantify the difference between distributions, where 0 indicates identical distributions and 1 indicates non-overlapping distributions. <xref rid="fig3" ref-type="fig">Figure 3 A, B</xref> and <xref rid="fig3" ref-type="fig">C</xref> show the five parameters with the largest KS test statistic sorted from largest to smallest in each pathophysiological condition.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3:</label>
<caption><title>Specific pathophysiological conditions have distinct compensatory parameters that maintain baseline outcomes.</title>
<p>We compared samples from the baseline posterior estimator conditioned on normal and pathophysiological parameter values. To compare distributions, we calculated the Kolmogorov-Smirnov (KS) test statistic. <bold>A), B)</bold> and <bold>C)</bold> show the five parameters with the largest test statistic in each condition. <bold>A)</bold> compares 55 AIns and 54 NINs in each subpopulation (Normal, <xref ref-type="disp-formula" rid="eqn7_1">Equation 7.1</xref>) to 15 neurons in each population (IN Loss, <xref ref-type="disp-formula" rid="eqn7_2">Equation 7.2</xref>). <bold>B)</bold> compares PC − PC<sub><italic>p</italic></sub> of 0.15% (Normal, <xref ref-type="disp-formula" rid="eqn8_1">Equation 8.1</xref>) to 3% (Sprouting, <xref ref-type="disp-formula" rid="eqn8_2">Equation 8.2</xref>). <bold>C)</bold> compares <inline-formula><inline-graphic mime-subtype="gif" mimetype="image" xlink:href="631838v1_inline21.gif"/></inline-formula> (Normal, <xref ref-type="disp-formula" rid="eqn9_1">Equation 9.1</xref>), with <inline-formula><inline-graphic mime-subtype="gif" mimetype="image" xlink:href="631838v1_inline22.gif"/></inline-formula> (Depolarized, <xref ref-type="disp-formula" rid="eqn9_2">Equation 9.2</xref>). <bold>D)</bold> KS test statistic for all parameters and conditions. KS test results for all parameters and conditions are in <xref ref-type="supplementary-material" rid="supp1">Table Supp 3.1</xref>. <bold>E) &amp; F)</bold> show the absolute correlation coefficients from <xref ref-type="fig" rid="fig2">Figure 2</xref>. IN loss is the average absolute correlation of NIN<sub><italic>n</italic></sub> and AIN<sub><italic>n</italic></sub> with the other parameters. Sprouting is the absolute correlation of PC → PC<sub><italic>p</italic></sub> with the other parameters. Intrinsic is the average absolute correlation of <inline-formula><inline-graphic mime-subtype="gif" mimetype="image" xlink:href="631838v1_inline23.gif"/></inline-formula> and <inline-formula><inline-graphic mime-subtype="gif" mimetype="image" xlink:href="631838v1_inline24.gif"/></inline-formula> with the other parameters.</p></caption>
<graphic xlink:href="631838v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>For example, when the number of INs is constrained, increasing the AIN → PC<sub><italic>p</italic></sub> connection probability maintains baseline excitability (<xref rid="fig3" ref-type="fig">Figure 3 A</xref>, leftmost). <xref rid="fig3" ref-type="fig">Figure 3 D</xref> shows the KS test statistic for each parameter in each condition. As expected from the pairwise correlations in <xref rid="fig2" ref-type="fig">Figure 2</xref>, the PC → PC connection strength has the largest KS statistic in the sprouting conditional. For IN Loss and Depolarization (<xref rid="fig3" ref-type="fig">Figure 3 A &amp; C</xref>) on the other hand, the compensatory potential of the PC → PC connection is low. This shows that some compensatory parameters depend on other conditions. This is also true for IN loss and intrinsics. During IN loss, the connection probabilities from INs → PCs stand out as being particularly effective. In contrast, the threshold potential is uniquely positioned to maintain baseline excitability despite intrinsic depolarization.</p>
<p>For comparison, we also show the absolute correlation coefficients from <xref rid="fig2" ref-type="fig">Figure 2</xref> for the specific pathophysiological parameters (<xref rid="fig3" ref-type="fig">Figure 3 E &amp; F</xref>). PC → PC strength, AIN → PC strength, and <inline-formula><inline-graphic xlink:href="631838v1_inline15.gif" mimetype="image" mime-subtype="gif"/></inline-formula> show similar trends for all three conditions. However, the overall profile changes markedly. This highlights an important difference between quantifying compensatory potential from pairwise correlations as opposed to changes between different conditionals. The pairwise correlations are calculated across the entire range of possible values, whereas conditionals are specific points. Therefore, conditionals quantify the compensatory potential in response to a specific perturbation from point A to point B, which gives them an advantage if the perturbation is known. Pairwise correlations quantify whether there is a correlation across the entire prior range (or in case of conditional correlation coefficients: the range within support of the posterior estimate). Overall, pairwise correlations and conditionals represent distinct methods of quantifying compensation and many parameters are expectedly different, but some parameters such as <inline-formula><inline-graphic xlink:href="631838v1_inline16.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and synaptic strengths show similar trends.</p>
<p>So far we focused on the posterior estimator for baseline excitability. Next, we investigated the compensatory mechanisms that can move the network from hyperexcitable to baseline (<xref rid="fig4" ref-type="fig">Figure 4</xref>). The principle of <xref rid="fig4" ref-type="fig">Figure 4</xref> is similar to <xref rid="fig3" ref-type="fig">Figure 3</xref>, with one critical difference: Instead of comparing normal and pathophysiological parameter conditions at baseline (<xref rid="fig3" ref-type="fig">Figure 3</xref>), we compare baseline and hyperexcitable posterior estimation at the pathophysiological condition (<xref rid="fig4" ref-type="fig">Figure 4</xref>). A, B &amp; C show the parameters with the largest KS statistic. The KS statistics for the parameters are overall different from <xref rid="fig3" ref-type="fig">Figure 3</xref>. For example, three intrinsic PC properties are among the five parameters with the largest difference for IN loss. Furthermore, the IN → PC connections are no longer among the five largest. Excitatory sprouting and intrinsic depolarization are also different. However, the excitatory connection strength is still the parameter with the strongest compensatory potential in the sprouting condition. During intrinsic depolarization, PC threshold is still in the largest five, but the PC → PC connection probability is now first. This shows that the compensatory potential of some parameters depends on specifics of the compensated conditions, while others are critical across conditions. Finally, we also analyzed the correlation of parameters with specific outcome parameters.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4:</label>
<caption><title>Specific pathophysiological conditions have distinct compensatory parameters that can change the network from hyperexcitable to baseline.</title>
<p>We compared samples from the baseline posterior estimator to those from the hyperexcitable posterior estimator conditioned on pathophysiological parameter values. To compare distributions, we calculated the Kolmogorov-Smirnov (KS) test statistic. <bold>A), B)</bold> and <bold>C)</bold> show the five parameters with the largest test statistic. Each compares baseline and the hyperexcitable estimator for a specific pathophysiological condition. In <bold>A)</bold> the condition is that the IN numbers are set to 15. In <bold>B)</bold> the condition is that PC → PC<sub><italic>p</italic></sub> is set to 3%. In <bold>C)</bold> the condition is that <inline-formula><inline-graphic mime-subtype="gif" mimetype="image" xlink:href="631838v1_inline25.gif"/></inline-formula>) shows the KS test statistic calculated between the baseline and hyperexcitable posterior for each pathophysiological condition. KS test results for all parameters and conditions are in <xref ref-type="supplementary-material" rid="supp1">Table Supp 4.1</xref>.</p></caption>
<graphic xlink:href="631838v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We have used posterior density estimators to quantify compensatory mechanisms. However, the ultimate goal of a compensatory mechanism, in the clinical sense, is to bring the system from the pathophysiological state back to the healthy state. In the simulator, we can directly test the effect of parameter changes on the output and, furthermore, whether the effect depends on the specific pathophysiological cause. To this end, we used the hyperexcitable posterior density estimator and drew samples given each pathophysiological condition: IN Loss, Sprouting and Depolarization. To test the effect of a parameter on output, a single parameter was then systematically varied and simulated. If the pathophysiological condition influences the effect of a parameter on the output, we expect a change in the difference between conditions at some parameter point. The interaction of an ANOVA shows whether the interaction between the parameter change and any of the three pathophysiological conditions is significant. A statistically significant interaction indicates that the effect of a parameter on the outcome depends on the condition (or vice versa) and is thus specific to the pathophysiology. The results clearly show that the condition is important for the compensatory potential of many parameters (<xref rid="fig5" ref-type="fig">Figure 5</xref>). As expected, IN loss affects the influence of AIN → PC connectivity, and sprouting strongly affects <inline-formula><inline-graphic xlink:href="631838v1_inline17.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. The effect of <inline-formula><inline-graphic xlink:href="631838v1_inline18.gif" mimetype="image" mime-subtype="gif"/></inline-formula> on a variety of outcomes is also strongly condition-dependent. Overall, this shows that the compensatory effect of many parameters depends on the specific pathophysiological condition.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5:</label>
<caption><title>The pathophysiological condition changes the effect of parameters on simulated outcomes.</title>
<p>The hyperexcitable posterior estimator was sampled with additional pathophysiological conditions. Then, each parameter was varied to cover 50 points in the parameters prior range and the parameters were simulated. Each of the 50 points on the x-axis contains 100 samples and the error bars show the 95% confidence interval. The asterisks indicate where the p-value of the interaction between parameter and condition is <inline-formula><inline-graphic mime-subtype="gif" mimetype="image" xlink:href="631838v1_inline26.gif"/></inline-formula>. <xref ref-type="supplementary-material" rid="supp1">Figure Supp 5.1</xref> shows the effect of more parameters and <xref ref-type="supplementary-material" rid="supp1">Table Supp 5.1</xref> contains the p-values of the interactions.</p></caption>
<graphic xlink:href="631838v1_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s4">
<label>4</label>
<title>Discussion</title>
<p>The ideal compensatory mechanisms depend on the underlying pathological causes. Using simulation-based inference we quantify the ability of parameters to compensate for different causes of hyperexcitability. For example, we find that the threshold potential for exponential voltage rise (<italic>V</italic><sub><italic>T</italic></sub>) is the best parameter to compensate for intrinsic depolarization. However, when compensating for interneuron loss or recurrent excitatory sprouting, <italic>V</italic><sub><italic>T</italic></sub> compensation is less effective. The exponential voltage rise in neurons is mediated by voltage-activated sodium channels, which are a crucial target of antiepileptic drugs (<xref ref-type="bibr" rid="c17">Kaplan et al., 2016</xref>). Our findings, therefore, predict that in patients where seizures are not primarily caused by principal cell hyperexcitability, commonly used sodium channel blockers could be less effective. This could explain why sodium channel blockers do not control seizures in some patients.</p>
<p>Two other interesting parameters are the interneuron to principal cell connection probabilities (AIN → PC<sub><italic>p</italic></sub> and NIN → PC<sub><italic>p</italic></sub>). Increasing the connection probability of either can compensate for intrinsic depolarization but also for the loss of interneurons. On one hand, fewer interneurons mean less overall inhibition and it makes sense that this can be compensated for by increasing connectivity. On the other hand, fewer interneurons means that the effect of the connectivity parameter should decrease, because the same increase in connection probability creates fewer overall synapses. We predict that even in sclerotic tissue with severe interneuron loss, increasing the number of inhibitory synapses has great compensatory potential. In vivo, thousands of interneurons remain even after interneuron loss in the pilocarpine or traumatic brain injury rat model of epilepsy (<xref ref-type="bibr" rid="c13">Huusko et al., 2015</xref>). The remaining interneurons could restore healthy activity by maintaining more synapses on principal cells. There are currently no epilepsy treatments that target inhibitory synapses directly, and increasing the number of inhibitory synapses without affecting excitatory synapses could prove difficult. A promising direction could be to use astrocyte-secreted factors such as neurocan, which specifically control inhibitory synaptogenesis (<xref ref-type="bibr" rid="c14">Irala et al., 2024</xref>).</p>
<p>While synaptogenesis has not yet been targeted for epilepsy treatments, interneuron transplantation to replace lost interneurons has been explored and proven effective in rodents (<xref ref-type="bibr" rid="c11">Hunt &amp; Baraban, 2015</xref>). We find that the interneuron cell numbers, compared to synaptic and intrinsic parameters, do not compensate well for excitatory sprouting or intrinsic depolarization. Before using interneuron transplants, it could, therefore, be advisable to determine whether interneuron loss affects the epileptogenic region. This is especially important since some epileptogenic regions are non-sclerotic, having cell numbers similar to healthy controls (<xref ref-type="bibr" rid="c3">Blümcke et al., 2013</xref>). In these regions, seizures could be caused by other factors, and interneuron transplantation could be less effective.</p>
<p>Our results indicate that the pathophysiological mechanisms could be relevant to choosing optimal treatments, but measuring the number of interneurons, the number of recurrent excitatory synapses, or intrinsic excitability is currently impossible in living patients. It is, therefore, essential to develop methods to estimate these difficult-to-measure mechanistic features from measurable properties. Simulation-based inference can be used to estimate these mechanistic biomarkers. For example, <xref ref-type="bibr" rid="c8">Doorn et al. (2024)</xref> measured the activity of patient-derived neuronal cultures with multi-electrode arrays and used the posterior estimates of recurrent spiking neuronal network parameters conditioned on the activity as estimates of pathological mechanisms. This method shows some promise, but a gap remains between the activity in epileptic networks and the activity in cell cultures. Cell cultures are dominated by the details of the culturing technique and the patient’s genetics. This makes cell culture particularly useful for epilepsies with strong genetic components. In contrast, the activity of an epileptogenic network in vivo is more complex and depends on the patient’s genetics but also various protective or harmful environmental and developmental factors. Therefore, intracranial field recordings, as they are performed in pharmacoresistant epilepsies, could be necessary. Such recordings with phenomenological neuronal mass models, which simulate the average activity of coupled brain regions rather than the spiking of single neurons, have been used to estimate the epileptogenicity index (<xref ref-type="bibr" rid="c20">Makhalova et al., 2022</xref>). While this index does not describe a specific pathophysiological mechanism, it could be clinically meaningful. A clinical trial is ongoing to determine its efficacy in guiding surgical decisions on the resection of epileptogenic brain tissue (<xref ref-type="bibr" rid="c15">Jirsa et al., 2023</xref>). If neural mass models can provide meaningful estimates of epileptogenicity, spiking neuronal network models could provide estimates of pathophysiological mechanisms such as interneuron number, which we have found might be helpful to guide personalized treatment.</p>
<p>Comparing conditional distributions has, to our knowledge, not been used to identify compensatory mechanisms. It is thus worth comparing it to the more common way of identifying compensation from the posterior correlations between parameters (<xref ref-type="bibr" rid="c10">Gonçalves et al., 2020</xref>). If we sample from the posterior <italic>p</italic>(<italic>θ</italic>|<italic>x</italic>), correlations between <italic>θ</italic><sub><italic>i</italic></sub> and <italic>θ</italic><sub><italic>j</italic></sub> indicate that if either of the parameters were changed, we could keep the probability of generating <italic>x</italic>-type output constant by changing the other parameter. This identifies broadly applicable compensatory mechanisms that work across the entire parameter range.</p>
<p>On the other hand, comparing <italic>p</italic>(<italic>θ</italic><sub><italic>i</italic></sub>|<italic>x, θ</italic><sub><italic>j</italic></sub> = 5) to <italic>p</italic>(<italic>θ</italic><sub><italic>i</italic></sub>|<italic>x, θ</italic><sub><italic>j</italic></sub> = 10) shows, how <italic>θ</italic><sub><italic>i</italic></sub> could change to maintain <italic>x</italic>-type dynamics, despite <italic>θ</italic><sub><italic>j</italic></sub> being perturbed from 5 to 10. The conditional also tests only the compensation of one parameter to another (the unconditioned compensates for the conditioned), whereas the correlations find compensation in both directions. Overall, correlations discover broadly applicable mechanisms, while conditionals identify specific mechanisms. Therefore, the conditional distributions are likely more useful for precision treatments than the unspecific correlations.</p>
<p>In summary, we show that the pathophysiological mechanisms underlying hyperexcitability change the efficacy of compensatory mechanisms to restore normal excitability in a spiking neuronal network model. These findings suggest that these mechanisms and a biologically detailed simulator could be used to predict the outcome of treatment options, such as voltage-gated sodium channel blockers or interneuron transplants. Simulation-based prediction of treatment outcomes would be a major advance for treating brain disorders and precision medicine.</p>
</sec>
</body>
<back>
<sec id="s5" sec-type="data-availability">
<title>Code and Data Availability</title>
<p>The Python code to run the simulator, train the NPE, infer posteriors, analyze the data and plot the figures is available on GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/danielmk/hyperexcitability_sbi">https://github.com/danielmk/hyperexcitability_sbi</ext-link>). The simulated data and the trained NPEs will be publicly available in a data repository.</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>We are grateful for the help and support provided by the Scientific Computing and Data Analysis section of Core Facilities at OIST. We thank Milena Menezes Carvalho, Joanna Komorowska-Müller and Gastón Sivori for helpful comments on the manuscript. This work was supported by JSPS KAKENHI grant no. JP23H05476 to T.F.</p>
</ack>
<sec id="suppd1e1538" sec-type="supplementary-material">
<title>Additional files</title>
<supplementary-material id="supp1">
<label>Supplemental figures</label>
<media xlink:href="supplements/631838_file02.pdf"/>
</supplementary-material>
</sec>
<ref-list>
<title>Bibliography</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Anastacio</surname>, <given-names>H. T. D.</given-names></string-name>, <string-name><surname>Matosin</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Ooi</surname>, <given-names>L.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Neuronal hyperexcitability in Alzheimer’s disease: what are the drivers behind this aberrant phenotype?</article-title>. <source>Translational Psychiatry</source>, <volume>12</volume>(<issue>1</issue>). <pub-id pub-id-type="doi">10.1038/s41398-022-02024-7</pub-id></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Beck</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Yaari</surname>, <given-names>Y.</given-names></string-name></person-group> (<year>2008</year>). <article-title>Plasticity of intrinsic neuronal properties in CNS disorders</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>9</volume>(<issue>5</issue>), <fpage>357</fpage>–<lpage>369</lpage>. <pub-id pub-id-type="doi">10.1038/nrn2371</pub-id></mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Blümcke</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Thom</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Aronica</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Armstrong</surname>, <given-names>D. D.</given-names></string-name>, <string-name><surname>Bartolomei</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Bernasconi</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Bernasconi</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Bien</surname>, <given-names>C. G.</given-names></string-name>, <string-name><surname>Cendes</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Coras</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Cross</surname>, <given-names>J. H.</given-names></string-name>, <string-name><surname>Jacques</surname>, <given-names>T. S.</given-names></string-name>, <string-name><surname>Kahane</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Mathern</surname>, <given-names>G. W.</given-names></string-name>, <string-name><surname>Miyata</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Moshé</surname>, <given-names>S. L.</given-names></string-name>, <string-name><surname>Oz</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Özkara</surname>, <given-names>Ç.</given-names></string-name>, <string-name><surname>Perucca</surname>, <given-names>E.</given-names></string-name>, <etal>…</etal> <string-name><surname>Spreafico</surname>, <given-names>R.</given-names></string-name></person-group> (<year>2013</year>). <article-title>International consensus classification of hippocampal sclerosis in temporal lobe epilepsy: A Task Force report from the ILAE Commission on Diagnostic Methods</article-title>. <source>Epilepsia</source>, <volume>54</volume>(<issue>7</issue>), <fpage>1315</fpage>–<lpage>1329</lpage>. <pub-id pub-id-type="doi">10.1111/epi.12220</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brette</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Gerstner</surname>, <given-names>W.</given-names></string-name></person-group> (<year>2005</year>). <article-title>Adaptive Exponential Integrate-and-Fire Model as an Effective Description of Neuronal Activity</article-title>. <source>Journal of Neurophysiology</source>, <volume>94</volume>(<issue>5</issue>), <fpage>3637</fpage>–<lpage>3642</lpage>. <pub-id pub-id-type="doi">10.1152/jn.00686.2005</pub-id></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cranmer</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Brehmer</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Louppe</surname>, <given-names>G.</given-names></string-name></person-group> (<year>2020</year>). <article-title>The frontier of simulation-based inference</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>117</volume>(<issue>48</issue>), <fpage>30055</fpage>–<lpage>30062</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1912789117</pub-id></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Deistler</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Goncalves</surname>, <given-names>P. J.</given-names></string-name>, &amp; <string-name><surname>Macke</surname>, <given-names>J. H.</given-names></string-name></person-group> (<year>2022</year>). <source>Truncated proposals for scalable and hassle-free simulation-based inference</source>. <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2210.04815">https://arxiv.org/abs/2210.04815</ext-link></mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Devinsky</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Vezzani</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>O’Brien</surname>, <given-names>T. J.</given-names></string-name>, <string-name><surname>Jette</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Scheffer</surname>, <given-names>I. E.</given-names></string-name>, <string-name><surname>Curtis</surname>, <given-names>M. D.</given-names></string-name>, &amp; <string-name><surname>Perucca</surname>, <given-names>P.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Epilepsy</article-title>. <source>Nature Reviews Disease Primers</source>, <volume>4</volume>. <pub-id pub-id-type="doi">10.1038/nrdp.2018.24</pub-id></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Doorn</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Putten</surname>, <given-names>M. J. A. M. V.</given-names></string-name>, &amp; <string-name><surname>Frega</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2024</year>). <article-title>Automated inference of disease mechanisms in patient-hiPSC-derived neuronal networks</article-title>. <source>Biorxiv</source>. <pub-id pub-id-type="doi">10.1101/2024.05.23.595522</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Gao</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Deistler</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Schulz</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Goņcalves</surname>, <given-names>P. J.</given-names></string-name>, &amp; <string-name><surname>Macke</surname>, <given-names>J. H.</given-names></string-name></person-group> (<year>2024</year>). <article-title>Deep inverse modeling reveals dynamic-dependent invariances in neural circuit mechanisms</article-title>. <source>Biorxiv</source>. <pub-id pub-id-type="doi">10.1101/2024.08.21.608969</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gonçalves</surname>, <given-names>P. J.</given-names></string-name>, <string-name><surname>Lueckmann</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Deistler</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Nonnenmacher</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Öcal</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Bassetto</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Chintaluri</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Podlaski</surname>, <given-names>W. F.</given-names></string-name>, <string-name><surname>Haddad</surname>, <given-names>S. A.</given-names></string-name>, <string-name><surname>Vogels</surname>, <given-names>T. P.</given-names></string-name>, <string-name><surname>Greenberg</surname>, <given-names>D. S.</given-names></string-name>, &amp; <string-name><surname>Macke</surname>, <given-names>J. H.</given-names></string-name></person-group> (<year>2020</year>). <article-title>Training deep neural density estimators to identify mechanistic models of neural dynamics</article-title>. <source>eLife</source>, <volume>9</volume>, <fpage>1</fpage>–<lpage>46</lpage>. <pub-id pub-id-type="doi">10.7554/ELIFE.56261</pub-id></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hunt</surname>, <given-names>R. F.</given-names></string-name>, &amp; <string-name><surname>Baraban</surname>, <given-names>S. C.</given-names></string-name></person-group> (<year>2015</year>). <article-title>Interneuron transplantation as a treatment for epilepsy</article-title>. <source>Cold Spring Harbor Perspectives in Medicine</source>, <volume>5</volume>(<issue>12</issue>). <pub-id pub-id-type="doi">10.1101/cshperspect.a022376</pub-id></mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hunter</surname>, <given-names>J. D.</given-names></string-name></person-group> (<year>2007</year>). <article-title>Matplotlib: A 2D graphics environment</article-title>. <source>Computing in Science &amp; Engineering</source>, <volume>9</volume>(<issue>3</issue>), <fpage>90</fpage>–<lpage>95</lpage>. <pub-id pub-id-type="doi">10.1109/MCSE.2007.55</pub-id></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huusko</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Römer</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Ndode-Ekane</surname>, <given-names>X. E.</given-names></string-name>, <string-name><surname>Lukasiuk</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Pitkänen</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2015</year>). <article-title>Loss of hippocampal interneurons and epileptogenesis: a comparison of two animal models of acquired epilepsy</article-title>. <source>Brain Structure and Function</source>, <volume>220</volume>(<issue>1</issue>), <fpage>153</fpage>–<lpage>191</lpage>. <pub-id pub-id-type="doi">10.1007/s00429-013-0644-1</pub-id></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Irala</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Sakers</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Nagendren</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Severino</surname>, <given-names>F. P. U.</given-names></string-name>, <string-name><surname>Bindu</surname>, <given-names>D. S.</given-names></string-name>, <string-name><surname>Savage</surname>, <given-names>J. T.</given-names></string-name>, &amp; <string-name><surname>Eroglu</surname>, <given-names>C.</given-names></string-name></person-group> (<year>2024</year>). <article-title>Astrocyte-secreted neurocan controls inhibitory synapse formation and function</article-title>. <source>Neuron</source>, <volume>112</volume>(<issue>10</issue>), <fpage>1657</fpage>–<lpage>1675</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2024.03.007</pub-id></mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jirsa</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Triebkorn</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Hashemi</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Jha</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Gonzalez-Martinez</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Guye</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Makhalova</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Bartolomei</surname>, <given-names>F.</given-names></string-name></person-group> (<year>2023</year>). <article-title>Personalised virtual brain models in epilepsy</article-title>. <source>The Lancet Neurology</source>, <volume>22</volume>(<issue>5</issue>), <fpage>443</fpage>–<lpage>454</lpage>. <pub-id pub-id-type="doi">10.1016/S1474-4422(23)00008-X</pub-id></mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kamondi</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Grigg-Damberger</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Löscher</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Tanila</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Horvath</surname>, <given-names>A. A.</given-names></string-name></person-group> (<year>2024</year>). <article-title>Epilepsy and epileptiform activity in late-onset Alzheimer disease: clinical and pathophysiological advances, gaps and conundrums</article-title>. <source>Nature Reviews Neurology</source>, <volume>20</volume>(<issue>3</issue>), <fpage>162</fpage>–<lpage>182</lpage>. <pub-id pub-id-type="doi">10.1038/s41582-024-00932-4</pub-id></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kaplan</surname>, <given-names>D. I.</given-names></string-name>, <string-name><surname>Isom</surname>, <given-names>L. L.</given-names></string-name>, &amp; <string-name><surname>Petrou</surname>, <given-names>S.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Role of sodium channels in epilepsy</article-title>. <source>Cold Spring Harbor Perspectives in Medicine</source>, <volume>6</volume>(<issue>6</issue>). <pub-id pub-id-type="doi">10.1101/cshperspect.a022814</pub-id></mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lerche</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Shah</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Beck</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Noebels</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Johnston</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Vincent</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2013</year>). <article-title>Ion channels in genetic and acquired forms of epilepsy</article-title>. <source>Journal of Physiology</source>, <volume>591</volume>(<issue>4</issue>), <fpage>753</fpage>–<lpage>764</lpage>. <pub-id pub-id-type="doi">10.1113/jphysiol.2012.240606</pub-id></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Ouyang</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Zheng</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Mi</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Zhao</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Ning</surname>, <given-names>Y.</given-names></string-name>, &amp; <string-name><surname>Guo</surname>, <given-names>W.</given-names></string-name></person-group> (<year>2021</year>). <article-title>A Selective Review of the Excitatory-Inhibitory Imbalance in Schizophrenia: Underlying Biology, Genetics, Microcircuits, and Symptoms</article-title>. <source>Frontiers in Cell and Developmental Biology</source>, <volume>9</volume>. <pub-id pub-id-type="doi">10.3389/fcell.2021.664535</pub-id></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Makhalova</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Villalon</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Giusiano</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Woodman</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Bénar</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Guye</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Jirsa</surname>, <given-names>V.</given-names></string-name>, &amp; <string-name><surname>Bartolomei</surname>, <given-names>F.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Virtual epileptic patient brain modeling: Relationships with seizure onset and surgical outcome</article-title>. <source>Epilepsia</source>, <volume>63</volume>(<issue>8</issue>), <fpage>1942</fpage>–<lpage>1955</lpage>. <pub-id pub-id-type="doi">10.1111/epi.17310</pub-id></mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Marom</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Marder</surname>, <given-names>E.</given-names></string-name></person-group> (<year>2023</year>). <article-title>A biophysical perspective on the resilience of neuronal excitability across timescales</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>24</volume>(<issue>10</issue>), <fpage>640</fpage>–<lpage>652</lpage>. <pub-id pub-id-type="doi">10.1038/s41583-023-00730-9</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>McKinney</surname>, <given-names>W.</given-names></string-name></person-group> (<year>2010</year>). <article-title>Data Structures for Statistical Computing in Python</article-title>. In <person-group person-group-type="editor"><string-name><given-names>S.</given-names> <surname>van der Walt</surname></string-name> &amp; <string-name><given-names>J.</given-names> <surname>Millman</surname></string-name></person-group> (Eds.), <conf-name>Proceedings of the 9th Python in Science Conference : Proceedings of the 9th Python in Science Conference</conf-name>. <pub-id pub-id-type="doi">10.25080/Majora-92bf1922-00a</pub-id></mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mittag</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Mediavilla</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Remy</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Cuntz</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Jedlicka</surname>, <given-names>P.</given-names></string-name></person-group> (<year>2023</year>). <article-title>Modelling the contributions to hyperexcitability in a mouse model of Alzheimer’s disease</article-title>. <source>The Journal of Physiology</source>, <volume>601</volume>(<issue>15</issue>), <fpage>3403</fpage>–<lpage>3437</lpage>. <pub-id pub-id-type="doi">10.1113/JP283401</pub-id></mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Naud</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Marcille</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Clopath</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Gerstner</surname>, <given-names>W.</given-names></string-name></person-group> (<year>2008</year>). <article-title>Firing patterns in the adaptive exponential integrate-and-fire model</article-title>. <source>Biological Cybernetics</source>, <volume>99</volume>(<issue>4–5</issue>), <fpage>335</fpage>–<lpage>347</lpage>. <pub-id pub-id-type="doi">10.1007/s00422-008-0264-7</pub-id></mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Papamakarios</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Murray</surname>, <given-names>I.</given-names></string-name></person-group> (<year>2018</year>). <source>Fast \epsilon-free Inference of Simulation Models with Bayesian Conditional Density Estimation</source>. <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1605.06376">https://arxiv.org/abs/1605.06376</ext-link></mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Scharfman</surname>, <given-names>H. E.</given-names></string-name>, <string-name><surname>Sollas</surname>, <given-names>A. L.</given-names></string-name>, <string-name><surname>Berger</surname>, <given-names>R. E.</given-names></string-name>, &amp; <string-name><surname>Goodman</surname>, <given-names>J. H.</given-names></string-name></person-group> (<year>2003</year>). <article-title>Electrophysiological evidence of monosynaptic excitatory transmission between granule cells after seizure-induced mossy fiber sprouting</article-title>. <source>Journal of Neurophysiology</source>, <volume>90</volume>(<issue>4</issue>), <fpage>2536</fpage>–<lpage>2547</lpage>. <pub-id pub-id-type="doi">10.1152/jn.00251.2003</pub-id></mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Seabold</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Perktold</surname>, <given-names>J.</given-names></string-name></person-group> (<year>2010</year>,). <article-title>statsmodels: Econometric and statistical modeling with python</article-title>. <conf-name>9th Python in Science Conference</conf-name>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stimberg</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Brette</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Goodman</surname>, <given-names>D. F. M.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Brian 2, an intuitive and efficient neural simulator</article-title>. <source>eLife</source> <volume>41</volume>. <pub-id pub-id-type="doi">10.7554/eLife.47314</pub-id></mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stöber</surname>, <given-names>T. M.</given-names></string-name>, <string-name><surname>Batulin</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Triesch</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Narayanan</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Jedlicka</surname>, <given-names>P.</given-names></string-name></person-group> (<year>2023</year>). <article-title>Degeneracy in epilepsy: multiple routes to hyperexcitable brain circuits and their repair</article-title>. <source>Communications Biology</source>, <volume>6</volume>(<issue>1</issue>). <pub-id pub-id-type="doi">10.1038/s42003-023-04823-0</pub-id></mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Talts</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Betancourt</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Simpson</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Vehtari</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Gelman</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2018</year>). <source>Validating Bayesian Inference Algorithms with Simulation-Based Calibration</source>. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1804.06788">http://arxiv.org/abs/1804.06788</ext-link></mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tejero-Cantero</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Boelts</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Deistler</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Lueckmann</surname>, <given-names>J.-M.</given-names></string-name>, <string-name><surname>Durkan</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Gonçalves</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Greenberg</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Macke</surname>, <given-names>J.</given-names></string-name></person-group> (<year>2020</year>). <article-title>sbi: A toolkit for simulation-based inference</article-title>. <source>Journal of Open Source Software</source>, <volume>5</volume>(<issue>52</issue>), <fpage>2505</fpage>. <pub-id pub-id-type="doi">10.21105/joss.02505</pub-id></mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tsodyks</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Pawelzik</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Markram</surname>, <given-names>H.</given-names></string-name></person-group> (<year>1998</year>). <article-title>Neural Networks with Dynamic Synapses</article-title>. <source>Neural Computation</source>, <volume>10</volume>(<issue>4</issue>), <fpage>821</fpage>–<lpage>835</lpage>. <pub-id pub-id-type="doi">10.1162/089976698300017502</pub-id></mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Virtanen</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Gommers</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Oliphant</surname>, <given-names>T. E.</given-names></string-name>, <string-name><surname>Haberland</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Reddy</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Cournapeau</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Burovski</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Peterson</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Weckesser</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Bright</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>van der Walt</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>Brett</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Millman</surname>, <given-names>K. J.</given-names></string-name>, <string-name><surname>Mayorov</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Nelson</surname>, <given-names>A. R. J.</given-names></string-name>, <string-name><surname>Jones</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Kern</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Larson</surname>, <given-names>E.</given-names></string-name>, <etal>…</etal> <collab>SciPy 1.0 Contributors</collab></person-group>. (<year>2020</year>). <article-title>SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python</article-title>. <source>Nature Methods</source>, <volume>17</volume>, <fpage>261</fpage>–<lpage>272</lpage>. <pub-id pub-id-type="doi">10.1038/s41592-019-0686-2</pub-id></mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Waskom</surname>, <given-names>M. L.</given-names></string-name></person-group> (<year>2021</year>). <article-title>seaborn: statistical data visualization</article-title>. <source>Journal of Open Source Software</source>, <volume>6</volume>(<issue>60</issue>), <fpage>3021</fpage>. <pub-id pub-id-type="doi">10.21105/joss.03021</pub-id></mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wolfart</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Laker</surname>, <given-names>D.</given-names></string-name></person-group> (<year>2015</year>). <article-title>Homeostasis or channelopathy? Acquired cell type-specific ion channel changes in temporal lobe epilepsy and their antiepileptic potential</article-title>. <source>Frontiers in Physiology</source>, <volume>6</volume>(<month>MAY</month>). <pub-id pub-id-type="doi">10.3389/fphys.2015.00168</pub-id></mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107045.1.sa1</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Slutsky</surname>
<given-names>Inna</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Tel Aviv University</institution>
</institution-wrap>
<city>Tel Aviv</city>
<country>Israel</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study introduces a <bold>valuable</bold> simulation-based inference (SBI) framework to identify degenerate compensatory mechanisms that stabilize network activity despite neuronal hyperexcitability, a feature common to many brain disorders. By estimating posterior distributions of network parameters, the authors highlight factors such as threshold potential and interneuron-to-principal cell connectivity as key compensators for increased intrinsic excitability and interneuron loss. While the approach is promising and could become a key tool for probing network degeneracy, the study is currently <bold>incomplete</bold>. To fully realize its potential, the framework requires improved scalability and more rigorous cross-validation.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107045.1.sa0</article-id>
<title-group>
<article-title>Joint Public Review:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This manuscript couples a 32-parameter model with simulation-based inference (SBI) to identify parameter changes that can compensate for three canonical hyperexcitability perturbations (interneuron loss, recurrent-excitatory sprouting, and intrinsic depolarisation). The study demonstrates a careful implementation of SBI and offers a practical ranking of &quot;compensatory levers&quot; that could, in principle, guide therapeutic strategies for epilepsy and related network disorders.</p>
<p>Strengths:</p>
<p>(1) By analysing three mechanistically distinct hyper-excitable regimes within the same modelling and inference framework, the work reveals how different perturbations require different compensatory interventions.</p>
<p>(2) The authors adopt posterior estimation to systematically rank the efficiency of different mechanisms in balancing hyperexcitability.</p>
<p>(3) Code and data are available.</p>
<p>Weaknesses:</p>
<p>(1) A highly dense presentation of the simulated models and undefined symbols makes it hard for readers outside the modelling community to follow the biological message. An illustration of the models, accompanied by some explanations and references to the main equations and parameters discussed in this paper, would make the first section much more straightforward.</p>
<p>(2) This methodology appears to be a brute-force approach, requiring millions of simulations to tune 32 parameters in a network of 500-700 cells. It isn't scalable. Moreover, the authors did not use cross-validation, which, with a relatively low increase in computational cost, would provide a quantitative measure as to how well it generalizes; this combination raises doubts about both scalability and reliability.</p>
<p>(3) Several parameters remain so broadly distributed after fitting that the model cannot say with confidence which specific changes matter. Therefore, presenting them as &quot;compensatory levers&quot; is somewhat questionable.</p>
<p>(4) Every conclusion is drawn from simulated data; without testing the predictions on recordings, we have no evidence that the proposed interventions would work in real neural tissue. Because today we cannot diagnose which of the three modelled pathological regimes is actually present in vivo, the paper's recommendations cannot yet be used to guide therapy.</p>
</body>
</sub-article>
</article>