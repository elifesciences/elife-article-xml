<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">108442</article-id>
<article-id pub-id-type="doi">10.7554/eLife.108442</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.108442.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories><title-group>
<article-title>When word order matters: human brains represent sentence meaning differently from large language models</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7159-1413</contrib-id>
<name>
<surname>Fodor</surname>
<given-names>James</given-names>
</name>
<xref ref-type="aff" rid="a1">*</xref>
<email>fods12@gmail.com</email>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1237-9535</contrib-id>
<name>
<surname>Murawski</surname>
<given-names>Carsten</given-names>
</name>
<xref ref-type="aff" rid="a1">*</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9816-9423</contrib-id>
<name>
<surname>Suzuki</surname>
<given-names>Shinsuke</given-names>
</name>
<xref ref-type="aff" rid="a2">†</xref>
</contrib>
<aff id="a1"><label>*</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01ej9dk98</institution-id><institution>The Centre for Brain, Mind and Markets, Faculty of Business and Economics, The University of Melbourne</institution></institution-wrap>, <city>Melbourne</city>, <country country="AU">Australia</country></aff>
<aff id="a2"><label>†</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04jqj7p05</institution-id><institution>Faculty of Social Data Science, Hitotsubashi University</institution></institution-wrap>, <city>Tokyo</city>, <country country="JP">Japan</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Ding</surname>
<given-names>Nai</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Zhejiang University</institution>
</institution-wrap>
<city>Hangzhou</city>
<country country="CN">China</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Bi</surname>
<given-names>Yanchao</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Peking University</institution>
</institution-wrap>
<city>Beijing</city>
<country country="CN">China</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-10-09">
<day>09</day>
<month>10</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP108442</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-07-19">
<day>19</day>
<month>07</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-07-23">
<day>23</day>
<month>07</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.07.19.665701"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Fodor et al</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Fodor et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-108442-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Large language models based on the transformer architecture are now capable of producing human-like language. But do they encode and process linguistic meaning in a human-like way? Here, we address this question by analysing 7T fMRI data from 30 participants reading 108 sentences each. These sentences are carefully designed to disentangle sentence structure from word meaning, thereby testing whether transformers are able to represent aspects of sentence meaning above the word level. We found that while transformer models match brain representations better than models that completely ignore word order, all transformer models performed poorly overall. Further, transformers were significantly inferior to models explicitly designed to encode the structural relations between words. Our results provide insight into the nature of sentence representation in the brain, highlighting the critical role of sentence structure. They also cast doubt on the claim that transformers represent sentence meaning similarly to the human brain.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>

</front>
<body>
<p>Understanding how human language is processed and represented in the brain is a major scientific challenge. The past decade has seen a proliferation of work integrating theoretical approaches from linguistics and computer science with empirical data from neuroimaging studies in an effort to better understand how meaning is represented in the brain<sup><xref ref-type="bibr" rid="c1">1</xref>–<xref ref-type="bibr" rid="c7">7</xref></sup>. Most research has focused on evaluating vector-based models, in which the meaning of a word or phrase is represented as a vector of numbers. This approach forms the basis for large language models, which are neural networks based on the transformer architecture and trained to predict hidden tokens on very large corpora of natural text. Leading models such as GPT-4, Gemini, Llama, and Claude are highly versatile, capable of performing of generating grammatical and relevant responses to a wide range of queries and instructions<sup><xref ref-type="bibr" rid="c8">8</xref>–<xref ref-type="bibr" rid="c10">10</xref></sup>. The extensive linguistic capabilities of these models, along with their ability to acquire language competence from naturalistic data, has generated significant interest in their potential value as cognitive models of language processing in humans<sup><xref ref-type="bibr" rid="c11">11</xref>–<xref ref-type="bibr" rid="c13">13</xref></sup>. Studies have consistently found statistically significant correlations between brain activity and various semantic models, with several finding that transformers better explain brain activity compared to static word embedding models<sup><xref ref-type="bibr" rid="c14">14</xref>–<xref ref-type="bibr" rid="c17">17</xref></sup>.</p>
<p>Most research comparing language models to brain ac-tivity has used stimuli that have not been selected to evaluate any specific linguistic hypothesis. While there are many benefits to utilising naturalistic stimuli in the study of language<sup><xref ref-type="bibr" rid="c18">18</xref>–<xref ref-type="bibr" rid="c21">21</xref></sup>, such stimuli have the disadvantage that they may not adequately sample the linguis-tic phenomena of most interest<sup><xref ref-type="bibr" rid="c19">19</xref></sup>, and do not control for variables crucial for contrasting the representations of different models<sup><xref ref-type="bibr" rid="c22">22</xref></sup>. A particular challenge is distinguishing whether language models are predictive of brain activity solely due to word-level (lexical) semantic information, or whether they also incorporate representations of sentence structure in a manner comparable to the brain. Direct comparison of static word embeddings with contextualised transformer embeddings is insufficient to resolve this issue, because contextualised embeddings also capture polysemy and other semantic phenomena not directly related to sentence structure. Another limitation of existing studies is that establishing that features extracted from large language models are predictive of brain activity does not necessarily provide much insight about what information these features encode or how such information is utilised by the brain<sup><xref ref-type="bibr" rid="c23">23</xref>–<xref ref-type="bibr" rid="c25">25</xref></sup>. A final limitation of existing studies is that encoding techniques are best suited to use with vector representations of language, making it difficult to conduct comparisons with graph-based or other approaches specialised for explicitly representing sentence structure.</p>
<p>Here, we present results from an fMRI study in which 30 participants read isolated sentences and answered simple questions about their meaning. We also collected a separate dataset of behavioural ratings of all pairwise comparisons of the same set of sentences. First, we developed a hand-crafted set of sentences designed specifically to control for the confound of lexical similarity, allowing for clearer inferences about how sentence-level information is represented by the brain. Second, we conduct model comparison using representational similarity analysis (RSA), which involves comparing pairwise similarity scores for voxel activations and semantic models. This technique extracts information about the patterns of similarity of model representations, thereby providing additional insight into the nature of brain semantic representations beyond voxelwise predictability. Furthermore, RSA facilitates comparison between dissimilar types of representations, thereby allowing us to compare a wider range of computational models, including both vector-based and graph-based models. While this technique has been used extensively at the level of individual words, we are not aware of any previous research using RSA for model comparison at the sentence level<sup><xref ref-type="bibr" rid="c26">26</xref>–<xref ref-type="bibr" rid="c30">30</xref></sup>.</p>
<sec id="s1">
<label>1</label>
<title>Results</title>
<sec id="s1a">
<label>1.1</label>
<title>Stimuli and models</title>
<p>Our hand-crafted sentences were carefully designed to reveal the role of sentence structure in semantic representation. Illustrative example sentences are shown in <xref rid="fig1" ref-type="fig">Figure 1a</xref>, along with the design matrix indicating the different types of sentence comparisons we considered. This matrix exhibits a block diagonal structure, which is a result of including six subsets of sentences, each sharing a core vocabulary of words which are then rearranged to create systematic variations of sentence structure while preserving high lexical similarity. Within these six diagonal blocks, we distinguish between ‘on-diagonal’ and ‘off-diagonal’ sentence pairs. On-diagonal sentence pairs (depicted in shades of blue) have sentence elements simply added or removed. By contrast, the off-diagonal sentence pairs (depicted in light green) have sentence elements interchanged to vary sentence meaning while keeping most of the constituent words the same. This approach builds on our previous work using behavioural data<sup><xref ref-type="bibr" rid="c31">31</xref></sup>, where we showed that such methods allow for effective dissociation of lexical similarity from overall similarity in sentence meaning. The primary objective of the present study is to analyse the brain representations of the block diagonal sentences extracted during an fMRI reading task, and compare these to representations derived from a variety of computational models of sentence meaning to determine which models best match brain representations.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Summary of study methods for constructing stimuli, computing model representations, and collecting fMRI and behavioural data.</title>
<p><bold>a)</bold> We construct 108 handcrafted sentences, designed to enable systematic variation in sentence meaning while controlling for lexical similarity. Here we show the corresponding 108 × 108 design matrix colour-coded with the type of each sentence pair. Sentence pairs in the six blocks along the diagonal are the primary pairs of interest in this study. <bold>b)</bold> All sentences were encoded using each of the four computational models of sentence meaning which we examine in this study. <bold>c)</bold> We then computed representational similarity matrices of the 108 stimuli for each of the four models. More similar sentence pairs are shown in blue, and less similar in red. <bold>d)</bold> Study pipeline for the fMRI experiment, in which participants were presented one sentence at a time for 2-7 seconds depending on sentence length. Multiple choice comprehension questions were interspersed randomly to assess attention. After scanning, data was processed and brain activity patterns were used to compute a neural representational similarity matrix for each participant. Correlations were then computed between the model and brain RSA matrices. <bold>e)</bold> Study pipeline for behavioural experiment, in which online participants were each shown 112 sentence pairs and asked to rate their semantic similarity. Ratings were averaged over participants to compute a similarity matrix. The correlation was then computed between the model and behavioural RSA matrices.</p></caption>
<graphic xlink:href="665701v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We next computed the representations for each sentence using a range of computational models. We analysed four distinct approaches to semantic representation. The first was a simple ‘Mean’ model, consisting of the element-wise averages of static word embeddings of each word in the sentence. Since this model ignores the position of words within a sentence as well as their grammatical role, it serves as a baseline incorporating only lexical information. The second class consists of embeddings extracted from various transformer neural networks. Results for the ‘Transformers’ model are computed by averaging results over six different transformer models, with the details given in Methods. Both Mean and Transformer models are vector-based approaches, as they represent the meaning of a sentence with a vector of numbers<sup><xref ref-type="bibr" rid="c32">32</xref></sup>. By contrast, ‘Graph’ models are based on a nested graph formalism constructed in accordance with a semantic parsing paradigm. Here we selected Abstract Meaning Representation (AMR) as a widely-used exemplar of this approach to semantic representation<sup><xref ref-type="bibr" rid="c33">33</xref></sup>. Finally, we analysed a ‘Hybrid’ model, which includes components from both vector-based and graph-based formalisms. Building on our previous work<sup><xref ref-type="bibr" rid="c31">31</xref></sup>, our Hybrid model uses a semantic parser to tag each word based on its semantic role, and then constructs a separate vector embedding for each semantic role. All four models are summarised in <xref rid="fig1" ref-type="fig">Figure 1b</xref>.</p>
<p>Having constructed the model representations for our sentences, we next computed the similarities between all sentence pairs, using these data to construct RSA matrices for all four computational models. As shown in <xref rid="fig1" ref-type="fig">Figure 1c</xref>, the block diagonal structure corresponding to the six sentence subsets is clearly visible. Sentence pairs within these blocks have higher similarity owing to sharing many words in common, as per our design. More importantly, the RSA matrices also illustrate clear differences between how the four models represent sentences. In particular, the ‘swapped’ off-diagonal sentence pairs are accorded high similarities by the Mean model, much lower similarities by the Graph and Hybrid models, and intermediate similarities by the Transformer models (OpenAI embeddings shown for illustration). These differences are consistent with our previous findings that transformers are less sensitive to changes in sentence structure than hybrid or graph models. Here we aim to test which pattern of representational similarities best matches data collected using neuroimaging during a sentence reading task. The full set of RSA matrices for all models is shown in Supplementary Information Figure S1.</p>
</sec>
<sec id="s1b">
<label>1.2</label>
<title>fMRI results</title>
<p>To evaluate how well each model describes sentence processing in the brain, we collected fMRI data from 30 participants while reading each of the 108 sentences. Our experimental pipeline is depicted in <xref rid="fig1" ref-type="fig">Figure 1d</xref>, with additional details given in section 3. We presented each sentence four times, with randomly interposed questions incorporated as an attention check. Voxel data were analysed using GLMSingle, an algorithm which fits a hemodyamic response function to each voxel and then estimates the response of that voxel to each stimulus. We selected a subset of voxels for further analysis based on their stability score, which is computed as the average correlation of voxel activity across repetitions of the same stimulus<sup><xref ref-type="bibr" rid="c2">2</xref>,<xref ref-type="bibr" rid="c34">34</xref>,<xref ref-type="bibr" rid="c35">35</xref></sup>. We analysed stable voxels within two regions of interest: the language network<sup><xref ref-type="bibr" rid="c36">36</xref></sup>, and the entire cortex less the primary visual cortex. Model fit was assessed using representational similarity analysis, with higher correlations indicating that the corresponding model represents the set of stimuli more similarity to the brain.</p>
<p>We performed representational similarity analysis in two different ways. In the simple-average approach, we computed the RSA correlation for each participant separately and then took the average. In contrast, the group-average approach involves first averaging the RSA matrix across participants, and then computing the RSA correlation for this group-averaged matrix<sup><xref ref-type="bibr" rid="c26">26</xref>,<xref ref-type="bibr" rid="c27">27</xref>,<xref ref-type="bibr" rid="c37">37</xref></sup>. In each case, we computed the Spearman partial correlation across all 5,778 sentence pairs and also across the 918 block diagonal sentence pairs, controlling for differences in sentence length. The full set of results for all 17 models tested are shown in Supplementary Information Figure S2. Here we discuss results of the four models of main interest.</p>
<p>We first consider correlations computed using all sentence pairs, as shown in <xref rid="fig2" ref-type="fig">Figure 2a</xref>. In language network voxels, all models show positive correlations, with relatively small differences between models. For the simple-average method, the differences in correlation were not significant when comparing the Mean and Transformers models (Δ<italic>ρ</italic> = 0.001, <italic>t</italic> = 0.686, <italic>p</italic> = 0.4981), or the Hybrid and Transformer models (Δ<italic>ρ</italic> = 0.009, <italic>t</italic> = 2.720, <italic>p</italic> = 0.0109). However, the Graph model had a significantly higher correlation compared to the Hybrid model (Δ<italic>ρ</italic> = 0.043, <italic>t</italic> = 7.393, <italic>p &lt;</italic> 0.0001). Similar results were found using the group-average method (shown in <xref rid="fig2" ref-type="fig">Figure 2b</xref>), but with higher absolute values. The fact that all models show positive correlations when evaluating all sentence pairs is unsurprising, since most sentences can be differentiated from one another using purely lexical differences, which all models are sensitive to.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Model correlations with brain activity for all sentence pairs and the block-diagonal subset of sentence pairs.</title>
<p>Partial correlations between RSA matrices of five computational models (Random, Mean, Transformers, Hybrid, and Graph) and the brain RSA matrix, controlling for differences in sentence length. ‘Human’ refers to behavioural ratings. Blue bars indicate inclusion of all stable cortical voxels (excluding visual regions V1-V4), and green bars indicate inclusion of only stable voxels in the language network. Notation for statistical significance: * for p<italic>&lt;</italic>0.05, ** for p<italic>&lt;</italic>0.01, and *** for p<italic>&lt;</italic>0.001, with Bonferroni correction for three independent comparisons. <bold>a)</bold> Partial correlations for each individual participant shown as blue dots, with the simple average over individual correlations shown as a bar. <bold>b)</bold> Partial correlations computed using the group-averaged RSA matrix. Error bars show 95% confidence intervals calculated by bootstrap resampling over participants. <bold>c)</bold> Scatterplots showing the relationship between model similarities (horizontal axis) and group-average neural similarities (vertical axis) for all four computational models. Each dot corresponds to a single pairwise similarity, scaled to between 0 and 1 for visualisation. While all sentence pairs are shown for comparison, regression lines (red) are computed over the block diagonal pairs only.</p></caption>
<graphic xlink:href="665701v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We now consider correlations computed using only the block diagonal sentence pairs, which are designed to be more difficult for computational models to distinguish owing to high lexical similarity. Here our results are noticeably different. For the simple-average of voxels within the language network, we found a correlation of −0.204 for the Mean model. This comparatively large negative correlation indicates that brain representations of sentences differ significantly from representations constructed considering only lexical similarity, providing evidence that brain representations of sentences are highly sensitive to sentence structure. The Transformers model achieves a correlation of −0.045, which is significantly higher than the Mean model (Δ<italic>ρ</italic> = 0.159, <italic>t</italic> = 14.287, <italic>p &lt;</italic> 0.0001), though the negative sign indicates that transformers still poorly match brain similarities. The Hybrid model achieves the highest correlation of 0.070, much larger than the Transformers model (Δ<italic>ρ</italic> = 0.115, <italic>t</italic> = 8.150, <italic>p &lt;</italic> 0.0001). The Graph model shows similar results to the Hybrid model, with a correlation of 0.047 (Δ<italic>ρ</italic> = − 0.023, <italic>t</italic> = −1.783, <italic>p</italic> = 0.0851). Results were very similar using the group-average method, though generally correlations had higher absolute values. The results for Mean, Transformer, and Hybrid models were all consistent with our preregistered predictions based on previous work with a separate behavioural dataset<sup><xref ref-type="bibr" rid="c31">31</xref></sup>, though we did not make a prediction for the Graph model. In all cases, results are very similar whether computed over the entire cortex (excluding V1–V4) or focusing just on the language network.</p>
<p>To better understand the origin of such large differences in correlations, we plotted neural similarities against the similarities derived from all four computational models (see <xref rid="fig2" ref-type="fig">Figure 2c</xref>). For both the Mean and Transformer models, the blue ‘modified’ and ‘substituted’ sentence pairs are accorded comparable similarities to the light green ‘swapped’ sentence pairs. By contrast, the Hybrid and Graph models generally accord ‘swapped’ sentence pairs as having distinctly lower similarity than ‘substituted’ and ‘modified’ sentence pairs. This is easiest to see on the Hybrid subplot of <xref rid="fig2" ref-type="fig">Figure 2c</xref>, where the ‘swapped’ sentence pairs are noticeably to the left of the ‘modified’ and ‘substituted’ sentence pairs. Such a difference indicates that the Hybrid and Graph models have a greater ability to discriminate sentence pairs that are lexically similar but structurally different (due to interchanged semantic roles). This leads to sentence similarities which are in better accord with brain similarity data, and thereby drives the positive RSA correlations. These results indicate that when keeping lexical similarity roughly constant, as is the case for the block diagonal sentence pairs, brain similarity patterns are best explained by models that explicitly represent sentence structural elements, namely the Hybrid and Graph models. The Mean model, which completely ignores such structure, explains brain representations the worst, with Transformer models doing better than the Mean but still poorly overall.</p>
<p>We also conducted an analysis of RSA correlations for each layer of the Llama 3 transformer model. We chose this for analysis as a larger, more recent architecture with a large number of layers. As shown in <xref rid="fig5" ref-type="fig">Figure 5,layers</xref> 0 and 1 had large negative correlations more similar to the Mean-CN model, while layers 2 and 3 had slightly positive correlations closer to that of the Hybrid model. Layers 4 and on had more moderate negative correlations, with a slight downward trend over later layers. This pattern was largely similar for both the set all all pairwise comparisons and the set of block diagonal comparison pairs, though in the latter case correlations remained essentially constant from around layer 4 onwards. The corresponding RSA matrices (see <xref rid="fig5" ref-type="fig">Figure 5c</xref>) show clear differences in representation across layers, though the significance of these patterns is difficult to interpret. We found only modest differences across layers of the AMRbart and ERNIE transformers (see Supplementary Information Figures S6 and S7).</p>
<p>We next compared representations across different brain regions. In addition to the language network and visual cortex (V1–V4), we also considered several regions previously demonstrated to show activity in response to language stimuli, namely the dorsomedial prefrontal cortex, the dorsolateral prefrontal cortex, the posterior cingulate cortex, and the precuneus. The primary somatosensory cortex (S1) is also included as a comparison of a brain region expected to show little response to linguistic stimuli. As shown in <xref rid="fig3" ref-type="fig">Figure 3a</xref>, the RSA matrices for most of these regions show a very robust grid-like pattern not explained by the type of sentence pair in the design matrix. This effect is not explained by differences in sentence length, as the RSA matrices already control for this variable (shown on the right of <xref rid="fig3" ref-type="fig">Figure 3a</xref>). Upon further investigation, we identified the grid-like pattern as resulting from consistently high brain similarity of sentence pairs in which both sentences are relatively long, as measured by the number of characters. This is evident by visual comparison with the ‘minimum length’ RSA matrix on the right of <xref rid="fig3" ref-type="fig">Figure 3b</xref>, which shows the shortest length of the two sentences in each pair. In Supplementary Information Figure S4, we show that our main results are qualitatively similar when additionally controlling for the ‘long sentences effect’. After regressing out this effect using the minimum sentence length for each sentence pair (<xref rid="fig3" ref-type="fig">Figure 3b</xref>), we recovered a block diagonal structure comparable to the original design matrix shown in <xref rid="fig1" ref-type="fig">Figure 1a</xref>, most clearly visible in the language network.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Comparison of sentence representations and model correlations across brain regions.</title>
<p><bold>a)</bold> RSA matrices for various cortical regions, computed controlling for differences in sentence length. <bold>b)</bold> RSA matrices for various cortical regions, computed controlling for differences in sentence length and minimum sentence length. <bold>c)</bold> Searchlight RSA for the Hybrid model using 8mm radius showing cortical regions of interest, with those part of the language network underlined. RSA correlations are thresholded at z=2. <bold>d)</bold> Partial correlations controlling for differences in sentence length by cortical region, with each individual participant shown as blue dots, and the simple average over individual correlations shown as a bar. <bold>e)</bold> Partial correlations controlling for differences in sentence length computed using the group-averaged RSA matrix, shown by cortical region. Error bars show 95% confidence intervals calculated by bootstrap resampling over participants.</p></caption>
<graphic xlink:href="665701v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To more clearly visualise the location of the brain regions responsible for encoding sentence information in common with the computational models, we conducted an RSA-searchlight analysis. This involves computing the RSA correlation between each model and the voxel activations within an 8mm sphere surrounding each voxel within a cortical mask. The results (see <xref rid="fig2" ref-type="fig">Figure 2c</xref>) show significant correlations throughout the language network, including regions of the temporal lobe, the angular gyrus, and the frontal. Significant correlations are also evident in the posterior cingulate cortex, precuneus, and the visual cortex, with sporadic pockets throughout the dorso-lateral and dorsomedial frontal cortical regions. In <xref rid="fig3" ref-type="fig">Figure 3c-d</xref> we show the correlations for each model in each region. We observe low correlations for the somatosensory cortex, generally high correlations for the language network, and intermediate correlations for all other regions. For block diagonal sentence pairs, the Hybrid model has similar correlations across all regions, while the Graph model has the highest correlation in the visual cortex, but still positive correlations in the language network. We find similar results when additionally controlling for minimum sentence length, as shown in Supplementary Information Figure S5.</p>
<p>We also performed an analysis comparing the representation of each subregion of the language network, the locations of which are depicted in <xref rid="fig4" ref-type="fig">Figure 4a</xref>. We found a similar overall pattern of results within all subregions, with consistently positive correlations for the entire set of pairwise comparisons. The magnitude of the correlations varied across subregions, with the highest values observed for the anterior and posterior temporal lobe, and lower values for all frontal regions (see <xref rid="fig4" ref-type="fig">Figure 4b</xref>). For the set of block diagonal sentence pairs, all subregions showed the same pattern as our main results, with a negative correlation for the mean model, modest negative correlations for transformer models, and positive correlations for the hybrid model. These findings support previous results indicating that all subregions of the language network are sensitive to lexical, syntactic, and compositional aspects of language, without any obvious specialisation across subregions<sup><xref ref-type="bibr" rid="c38">38</xref>,<xref ref-type="bibr" rid="c39">39</xref></sup>. We find little difference when additionally controlling for minimum sentence length, as shown in Supplementary Information Figure S8.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Comparison of model correlations across subregions of the language network.</title>
<p><bold>a)</bold> Regions within the language network. <bold>b)</bold> Partial correlations controlling for differences in sentence shown by language network region, with each individual participant shown as blue dots, and the simple average over individual correlations shown as a bar. <bold>c)</bold> Partial correlations controlling for differences in sentence length computed using the group-averaged RSA matrix, shown by language network region. Error bars show 95% confidence intervals calculated by bootstrap resampling over participants.</p></caption>
<graphic xlink:href="665701v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s1c">
<label>1.3</label>
<title>Behavioural results</title>
<p>To supplement our neuromaging data, we also collected a set of behavioural data consisting of semantic similarity judgements. As illustrated in <xref rid="fig1" ref-type="fig">Figure 1e</xref>, we recruited 502 participants using an online platform, each of whom was presented with a set of 102 sentence pairs selected randomly from all 5,770 unique sentence pairs. Participants were asked to rate each sentence pair for semantic similarity on a scale of 1-7. Ratings were averaged over participants and scaled to between 0 and 1 for comparison with model similarities. The normalised human sentence similarity ratings ranged from 0 to 0.962, with mean=0.484 and SD=0.171 for block diagonal sentence pairs, and mean=0.072 and SD=0.071 for all other sentence pairs. The average standard deviation of similarity scores for each sentence pair computed across participants was equal to 0.244 for block diagonal sentence pairs and 0.106 for all other pairs. This is comparable to the 0.19 adjusted average standard deviation of the SICK sentence similarity dataset<sup><xref ref-type="bibr" rid="c40">40</xref></sup>, and 0.216 for the STS3k dataset<sup><xref ref-type="bibr" rid="c31">31</xref></sup>. The split-half reliability with the Spearman-Brown correction was 0.938 for the entire dataset, 0.954 for the block diagonal sentence pairs, and 0.715 for all other pairs, indicating high levels of agreement between participants.</p>
<p>We evaluated the fit between behavioural data and each computational model in the same manner as for the fMRI data. For the full set of sentence pairs (<xref rid="fig6" ref-type="fig">Figure 6a</xref> left), the Mean and Transformer models performed best with correlations of 0.510 and 0.568 respectively (Δ<italic>ρ</italic> = 0.049, <italic>t</italic> = 11.327, <italic>p &lt;</italic> 0.0001). The Hybrid model had a lower correlation relative to the Transformers (Δ<italic>ρ</italic> = − 0.093, <italic>t</italic> = −16.432, <italic>p &lt;</italic> 0.0001)., and the Graph model the lowest of all (Δ<italic>ρ</italic> = −0.044<italic>t</italic> = −6.306, <italic>p &lt;</italic> 0.0001). This pattern was reversed in the case of the block diagonal sentence pairs (<xref rid="fig6" ref-type="fig">Figure 6a</xref> right), with the Mean model having by far the lowest correlation of 0.437. Transformers had a much higher correlation of 0.639 (Δ<italic>ρ</italic> = 0.188, <italic>t</italic> = 22.449, <italic>p &lt;</italic> 0.0001), as did the Hybrid model with a correlation of 0.698 (Δ<italic>ρ</italic> = 0.045, <italic>t</italic> = 3.765, <italic>p</italic> = 0.0001). The Syntax model had an intermediate correlation of 0.533, lower by than the Hybrid model (Δ<italic>ρ</italic> = −0.145, <italic>t</italic> = −12.371, <italic>p &lt;</italic> 0.0001). This pattern of results is comparable to that we observed for our fMRI data, though with much higher correlations across all models owing to the much reduced noise in behavioural ratings compared to fMRI voxel data. Correlations for all computational models are shown in Supplementary Information Figure S3.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Average correlations between RSA matrices of each layer of Llama 3 and brain RSA matrix of each participant.</title> <p>Mean (Mn) and Hybrid (Hy) models are also shown for comparison. <bold>a)</bold> Partial correlations for each individual participant shown as blue dots, with the simple average over individual correlations shown as a bar. <bold>b)</bold> Partial correlations computed using the group-averaged RSA matrix. Error bars show 95% confidence intervals calculated by bootstrap resampling over participants. <bold>c)</bold> RSA matrices for the Mean model (Mn) along with selected layers of the Llama 3 model, computed controlling for differences in sentence length.</p></caption>
<graphic xlink:href="665701v1_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Behavioural ratings of sentence similarity show similar results to fMRI results, but with higher absolute correlations.</title>
<p><bold>a)</bold> (Left) Average correlations between RSA matrices of four computational models and human-rated similarities using all sentence pairs. (Right) Average correlations between RSA matrices of four computational models and human-rated similarities using only diagonal sentence pairs. <bold>b)</bold> Scatterplots showing the relationship between model similarities (horizontal axis) and human rated similarities (vertical axis) for all four computational models. Each dot corresponds to a single pairwise similarity, scaled to between 0 and 1 for visualisation. The 45-degree line (black) shows a hypothetical line of perfect fit between model and human similarities.</p></caption>
<graphic xlink:href="665701v1_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>As before, we show scatterplots of the human ratings plotted against model similarities (<xref rid="fig6" ref-type="fig">Figure 6b</xref>). While all four models broadly follow the ordering of human ratings along the 45-degree line, both the Mean and OpenAI transformer models place the ‘swapped’ sentence pairs below the line, meaning that these sentence pairs are accorded higher similarity ratings by the models than by humans. By contrast, the Hybrid and Syntax models place ‘swapped’ sentence pairs above the 45-degree line, meaning that they accord these sentence pairs lower similarities than humans do. These results indicate that for this set of stimuli, the Mean and OpenAI transformer models are less sensitive to variations in sentence structure than human raters, while the Hybrid and Syntax models are slightly more sensitive to such structure than the human raters.</p>
</sec>
</sec>
<sec id="s2">
<label>2</label>
<title>Discussion</title>
<p>In this paper we present, to our knowledge, the first fMRI evaluation of models of sentence representation that utilises stimuli specifically designed to distinguish the effects of lexical semantics from sentence structure. We also present the first quantitative comparison of static word embeddings, transformer neural networks, semantic parsing graphs, and hybrid models of sentence representation using a unified framework. In our neuroimaging experiment we found that over the block diagonal sentence pairs (the subset of sentence pairs designed to test for sensitivity to sentence structure), considering voxels in the language network, the Mean model had a strong negative correlation, the Transformers model a smaller negative correlation, and the Hybrid model a modest positive correlation. We found similar (though less pronounced) differences in our behavioural experiment. These findings provide two major contributions to our knowledge of sentence representation in the brain. First, we show that controlling for lexical similarity illuminates the brain’s sensitivity to sentence structure in a way that is not evident when the lexical confound is present. Second, the success of our Hybrid model provides novel insight into how sentence structure is represented in the brain, indicating the importance of semantic role and highlighting limitations of representations derived from transformer models.</p>
<p>Previous studies analysing sentence processing in the brain have used a variety of controlled stimuli to isolate the mechanisms of semantic composition. One method involves randomly shuffle the order of words within a sentence, thereby preserving lexical semantics while varying overall sentence meaning<sup><xref ref-type="bibr" rid="c41">41</xref>,<xref ref-type="bibr" rid="c42">42</xref></sup>. A second method involves constructing ‘jabberwocky’ sentences, which involve non-sensical words placed in grammatically well-formed sentences<sup><xref ref-type="bibr" rid="c38">38</xref>,<xref ref-type="bibr" rid="c43">43</xref>,<xref ref-type="bibr" rid="c44">44</xref></sup>. These stimuli are designed to control for syntactic structure or sentence form while manipulating sentence meaning. In both cases, the objective is typically to use jabberwocky or shuffled sentences as a control condition in which composition is prevented, thereby providing a baseline for sentences in which composition occurs<sup><xref ref-type="bibr" rid="c45">45</xref></sup>. Our study differs from these approaches in that we aim to preserve, rather than prevent composition. Instead, we control for lexical similarity while constructing semantically meaningful sentences with differing meanings.</p>
<p>Our results indicate that transformer representations do not adequately incorporate sentence structure in a brain-like manner. In particular, we show that when evaluated against both the brain and behavioural data, transformers are insufficiently sensitive to ‘swapping’ of semantic roles (see <xref rid="fig6" ref-type="fig">Figure 6</xref> and <xref rid="fig2" ref-type="fig">Figure 2</xref>), ranking such sentence pairs as more similar than do human participants (in the behavioural data) or brain representations (in the fMRI data). This effect was very robust, with negative correlations observed for block diagonal sentence pairs for all eight transformers we studied (see Supplementary Information Figure S2). By contrast, the Hybrid model is by design highly sensitive to such alterations of semantic roles, which better matches the pattern of brain similarities than other models. Indeed, for the behavioural data we find that the hybrid model is actually more sensitive to these ‘swapped’ sentences compared to human participants, who rate their similarity in between that of the Hybrid and Transformer models.</p>
<p>Several previous studies have found that voxelwise encoding models trained using features extracted from transformers are able to better predict brain activity than static word embedding models which ignore sentence structure<sup><xref ref-type="bibr" rid="c15">15</xref>–<xref ref-type="bibr" rid="c17">17</xref>,<xref ref-type="bibr" rid="c46">46</xref></sup>. However, interpreting these findings is difficult because there is no established method for determining which model features drive these correlations<sup><xref ref-type="bibr" rid="c47">47</xref></sup>. Indeed, some studies have found that even features from untrained transformers can achieve high voxelwise correlations<sup><xref ref-type="bibr" rid="c15">15</xref>,<xref ref-type="bibr" rid="c48">48</xref></sup>, casting doubt on whether the transformer features which drive brain correlations are linguistically relevant. Similarly, other studies using shuffled sentences to remove information about sentence structure have found this results in only modest reductions in voxelwise correlations<sup><xref ref-type="bibr" rid="c49">49</xref>,<xref ref-type="bibr" rid="c50">50</xref></sup>. An analyses which better controlled for various confounds found that most variance explainable by transformers was accounted for by static word embeddings and word rate<sup><xref ref-type="bibr" rid="c51">51</xref></sup>. Our results complement these findings, showing that in cases where sentence structure is critical, transformers are insufficiently sensitive to structural aspects of sentence meaning. In cases where transformers have been found to have an advantage, this may be due to their greater ability to contex-tualise polysemous word meanings based on the presence of other words, rather than their ability to represent sentence structure.</p>
<p>We analysed the fMRI data in two different ways: computing correlations for each individual participant and taking a simple average, and also computing a group-averaged RSA matrix and then computing the correlation. We found that both methods yielded a very similar pattern of results, but with the group-averaged correlations having about twice the magnitude of the simple-average correlations (see <xref rid="fig2" ref-type="fig">Figure 2</xref>). For instance, the correlation over block diagonal sentence pairs for the Mean model is −0.204 when averaged over individual subjects, and −0.378 when computed using the group-averaged RSA. Likewise, the hybrid model correlation is 0.070 when averaged over individual subjects, and 0.122 when computed using the group-averaged RSA. These results are likely explained by the highly noisy results at the individual level, which is partly averaged-out when computing the group-averaged RSA matrix.</p>
<p>We also found a robust ‘minimum sentence length’ effect, in which sentence pairs consisting of two long sentences resulted in highly similar brain activity (see <xref rid="fig3" ref-type="fig">Figure 3a-b</xref>). This is not explained by similar length sentences eliciting similar brain activity, as the effect does not arise for pairs consisting of two short or two medium-length sentences. Furthermore, all RSA partial correlations already control for the similarity of sentence length. Though we are not aware of this result having been reported using RSA, previous studies using other methodologies have found that activation of the language network increases with sentence length<sup><xref ref-type="bibr" rid="c38">38</xref>,<xref ref-type="bibr" rid="c52">52</xref>–<xref ref-type="bibr" rid="c54">54</xref></sup>. The cause of this effect is unclear. It may partly be explained by visual similarity of longer sentences, however we observe no similar effect that might be expected for the visual similarity of short or medium sentences. Furthermore, the minimum length effect is also evident in many brain regions outside the visual cortex, including the language network and frontal regions <xref rid="fig3" ref-type="fig">Figure 3</xref>. We speculate that the effect may be driven by multiple causes, including increased cognitive processing or memory load for processing longer sentences, greater depth of processing elicited by semantically richer stimuli<sup><xref ref-type="bibr" rid="c55">55</xref></sup>, or additional processing required for compositional combination of a larger number of sentence components. It is also possible that the structural similarity of longer sentences in our study, which all contain a similar set of semantic roles, results in similar brain representations even when the sentences do not have similar overall meanings. If so, this would indicate that extracting semantic features is important for brain processing of sentences even aside from lexical similarity. Further research will be required to disentangle the relative impacts of these distinct processes.</p>
<p>Our study has several limitations. First, our stimulus set consists of a relatively small selection of sentences, which follow broadly similar structure. Our aim in this study was to disentangle the effects of lexical similarity from structural similarity in realistic sentences, and as such we did not attempt to compile a representative sample of sentences from natural dialogue. In future work we hope to investigate the extent to which our results generalise to more complex and varied types of sentences. Second, the comparison between behavioural and fMRI data is somewhat difficult owing to the difference in task structure. In the behavioural experiment, participants viewed many pairs of related sentences, and explicitly asked to pay attention to differences in the words of each sentence. In contrast, in the fMRI task participants read one sentence at a time without an explicit comparison. Third, we analyse brain representations of sentence meaning over a single contiguous 3s interval. This is a substantial simplification of sentence processing, which takes place dynamically over time as words are successively integrated to form progressively more complex and structured representations<sup><xref ref-type="bibr" rid="c22">22</xref>,<xref ref-type="bibr" rid="c38">38</xref>,<xref ref-type="bibr" rid="c56">56</xref>–<xref ref-type="bibr" rid="c58">58</xref></sup>. While our approach is an important contribution, and builds upon previous studies comparing syntactic parse trees with brain data<sup><xref ref-type="bibr" rid="c52">52</xref>,<xref ref-type="bibr" rid="c59">59</xref>,<xref ref-type="bibr" rid="c60">60</xref></sup>, additional work is needed to link model representations with the dynamic cascade of brain activity during sentence processing.</p>
<p>While our results show that transformers do not represent sentences in a manner comparable to the brain, it is likely that individual features within transformer embeddings do represent aspects of sentence structure. Indeed, large language models show clear capabilities of correctly interpreting sentence structure<sup><xref ref-type="bibr" rid="c61">61</xref></sup>, and probing studies have found that transformers represent information about syntax and word order<sup><xref ref-type="bibr" rid="c62">62</xref>,<xref ref-type="bibr" rid="c63">63</xref></sup>. Nonetheless, the fact that transformers can encode and utilise structural information to perform linguistic tasks does not mean that they effectively utilise this information to construct a brain-like representation of sentence meaning. Our results indicate that despite the linguistic competencies of transformers, they do not combine syntactic and semantic information into an integrated sentence representation in a manner analogous to the human brain. Further research is needed to investigate exactly which features of sentence meaning are represented by large large models, and how they differ from those encoded in the human brain.</p>
<p>Our results provide important new insights about how sentence structure is represented in the brain. The simple Mean model, which ignores sentence structure, was a very poor match to brain activity when evaluated against the block diagonal subset of sentences (the sentence pairs designed to be difficult for models which do not represent sentence structure). While transformers were a much better match to brain activity than the Mean model, correlations were still negative, indicating that transformer representations were still a poor match to brain representation. In line with our preregistered prediction, we found that the Hybrid model best matched brain representations, thereby providing evidence that the brain incorporates structured information from semantic roles when representing sentence meaning. Evidently, such structure is not always adequately represented even in state-of-the-art transformer models. Our results highlight the importance investigating which semantic features are most important for representation of sentence meaning in the brain.</p>
</sec>
<sec id="s7">
<label>3</label>
<title>Methods</title>
<sec id="s7a">
<label>3.1</label>
<title>Stimuli and computational models</title>
<sec id="s7a1">
<label>3.1.1</label>
<title>Word embedding models</title>
<p>In this study we compared four different approaches for representing sentence meaning. The baseline for all comparisons was the Mean model in which sentence embeddings are constructed by elementwise averaging of word embeddings. We also evaluated two alternative models for combining word embeddings into sentence embeddings. Multiplicative (Mult) embeddings were constructed by adding one to each element of the word embeddings (to avoid negative numbers), then performing elementwise multiplication of all word embeddings. Convolutional (Conv) embeddings were constructed by adding one to each element of the word embeddings, then iteratively performing circular discrete convolution of each word embedding with the convolution of all previous word embeddings. For all three models based on word embeddings, sentence embeddings were constructed after removing a list of stop words containing words with little semantic content such as pronouns, modal verbs, conjunctions, and common prepositions. Cosine similarity was used to compute the similarity of each pair of sentence embeddings.</p>
</sec>
<sec id="s7a2">
<label>3.1.2</label>
<title>Transformer models</title>
<p>We computed the representations for a range of transformer architectures, along with the older InferSent LSTM model for comparison, as summarised in <xref rid="tbl1" ref-type="table">Table 1</xref>. As per our preregistration, for the statistical analysis we averaged the RSA correlation with brain representations over five different transformer architectures: ERNIE 2.0, AMRbart, SentBERT, DefSent, and OpenAI. For all transformers, sentence embeddings were normalised by subtracting the mean and dividing by the standard deviation of each feature. This is motivated by research indicating that without normalisation, transformers tend to learn very anisotropic embeddings with a few dimensions dominating over all the others<sup><xref ref-type="bibr" rid="c64">64</xref>,<xref ref-type="bibr" rid="c65">65</xref></sup>. Sentence similarities were computed using cosine similarity.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><title>Summary of models of sentence meaning analysed in this study.</title></caption>
<graphic xlink:href="665701v1_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s7a3">
<label>3.1.3</label>
<title>Graph models</title>
<p>We adopted AMR as a representative graph-based approach for representing sentence meaning. We used the SapienzaNLP (Spring) AMR parser<sup><xref ref-type="bibr" rid="c73">73</xref></sup> to parse all sentences, as it is among the best-performing AMR parses with freely available and easily implementable code. Evaluating syntax-based models using STS datasets requires a method for computing the similarity between the graphs for each sentence. While various techniques have been developed for converting graphs into vector embeddings, these have typically focused on knowledge databanks rather than natural language<sup><xref ref-type="bibr" rid="c74">74</xref>,<xref ref-type="bibr" rid="c75">75</xref></sup>. Furthermore, we are interested in testing graph-based models of representing sentences more directly, rather than the embeddings produced from these graphs. As such, we analyse the similarity of AMR-embeddings using two existing methods for comparing graph similarity directly: SMATCH<sup><xref ref-type="bibr" rid="c76">76</xref></sup> and WWLK<sup><xref ref-type="bibr" rid="c77">77</xref></sup>. In the main manuscript we report the results for the more widely-used SMATCH metric, as it achieved much higher correlations than the WWLK metric.</p>
</sec>
<sec id="s7a4">
<label>3.1.4</label>
<title>Hybrid models</title>
<p>To compute representations for the VerbNet-CN hybrid model, we used the GPT-4 model of the OpenAI Chat Completions API to parse each of the 108 sentences by assigning parts of the sentence to one of eight semantic roles: Verb, Agent, Patient, Theme, Time, Manner, Location, Trajectory. After parsing by semantic role, embeddings for each semantic role as before, by averaging the static ConceptNet embeddings of each constituent word after the removal of stop words. Words that are not associated with any semantic role were discarded. As before, the result is a set of role embeddings which constitutes the representation of the meaning of the sentence in terms of vector representations of each major semantic role.</p>
<p>To compute the similarity between two sentences, we first aligned the two sentences based on the semantic roles. Matching semantic roles were then accorded a similarity of 0.5 plus the computed cosine similarity between the rolewise embeddings. In cases where the semantic role was present in one sentence but not the other, a rolewise similarity of zero was used. Overall sentence similarity was computed as the weighted average of these eight rolewise similarities. We used fixed weights of 3 for the Verb, and 2 for Agent, Patient, and Theme, and 0.5 for Time, Manner, Location, and Trajectory, adopted from our previous study<sup><xref ref-type="bibr" rid="c31">31</xref></sup>.</p>
<p>To compute representations for the AMR-CN hybrid model<sup><xref ref-type="bibr" rid="c31">31</xref></sup>, we first parsed sentences using the SapienzaNLP (Spring) AMR parser<sup><xref ref-type="bibr" rid="c73">73</xref></sup>. Each token in the sentence was then assigned an ‘AMR role’ in accordance with its location in the parse tree by concatenating all nested parse labels. Role similarities were computed as the cosine similarity between the averaged ConceptNet word embeddings for all tokens with the same AMR role in each sentence of a sentence pair. Finally, the overall sentence similarity was computed as average role similarity over all roles found.</p>
</sec>
<sec id="s7a5">
<label>3.1.5</label>
<title>Sentence stimuli</title>
<p>A set of 108 sentences was hand-crafted specifically for this study. The aim was to include sentence pairs ranging from very similar to very dissimilar, while also providing for many pairwise sentence comparisons in which lexical similarity was high while overall meaning was different, owing to interchanging of semantic roles in the sentence. This allows for better model discrimination by ensuring that only models sensitive to sentence structure are able to accurately differentiate the meaning of such interchanged sentences.</p>
<p>The process by which sentences were constructed is summarised in <xref rid="tbl2" ref-type="table">Table 2</xref>. All sentences consisted of a single clause written in the active voice describing a specific event. Pronouns, proper nouns, and subordinate clauses were excluded for simplicity and to limit sources of syntactic variation. Sentences were produced by constructing systematic variations of an initial ‘base’ sentence by altering elements such as the subject, verb, and object, or adding modifiers like adjectives, location, or time. Several different categories of modified sentences were constructed. A small number of ‘same’ sentences were constructed by adding a single adjective with only minimal effect on sentence meaning, for example ‘the equipment’ becomes ‘the new equipment’. ‘Modified’ sentences were constructed by adding two or three modifier elements such as location, manner, or time when the event occurred. ‘Substituted’ sentences were designed to investigate the effect of altering key sentence elements, such as changing the subject, object, or verb of the sentence.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2.</label>
<caption><title>Explanation of the process of constructing sentences used in the study. Added or altered elements in the second sentence in each pair are italicised.</title></caption>
<graphic xlink:href="665701v1_tbl2.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>Critical to the study design was construction of ‘swapped’ sentences, in which one or more pairs of words interchanged roles in the sentence. For example, if in the initial sentence the subject is ‘the cameraman’, the direct object ‘the equipment’, and the indirect object ‘the director’, then in the interchanged sentence the subject is now ‘the director’, the direct object is ‘the cameraman’, and the indirect object is ‘the equipment’. As with the ‘base’ sentence, the swapped sentences were also systematically varied through substitutions and addition of modifiers. The aim of this procedure was to develop a set of sentence pairs with gradations of similarity while approximately controlling for lexical similarity. Differences in meaning in these sets of sentences are therefore mostly attributable to sentence structure and semantic roles, not simply use of different words. The complete set of stimuli are provided in Supplementary Information.</p>
<p>Using the methods described above, six distinct subsets each consisting of 18 related sentences were developed. This resulted in 5,778 pairwise comparisons across all sentences, of which 4,860 were ‘different’ sentence pairs and 918 were block diagonal sentence pairs of primary interest in this study. The RSA design matrix for all 108 sentences is shown in <xref rid="fig1" ref-type="fig">Figure 1a</xref>.</p>
<p>In our study preregistration (see <ext-link ext-link-type="uri" xlink:href="https://osf.io/jme7x">https://osf.io/jme7x</ext-link>), we predicted that over the block diagonal set of sentence pairs, the Hybrid model would have a higher correlation with brain representations than the average over five specified Transformers, which in turn would have a higher correlation than the Mean model. We did not make predictions for any other models.</p>
</sec>
</sec>
<sec id="s7b">
<label>3.2</label>
<title>fMRI data collection</title>
<sec id="s7b1">
<label>3.2.1</label>
<title>Participants</title>
<p>Thirty-nine participants (23 women, 14 men, 2 other) between the ages of 18 and 40 (mean=22.2) were recruited from our university campus (The University of Melbourne) for the study. All self-identified as native speakers of English, and all but one (a last-minute replacement) identified as right-handed. Participants received$70 as compensation for their time, which corresponds to about$23 per hour for a three-hour session. Nine participants were excluded from the main analysis: seven for scoring below 70% on the attention task (see details below), and two for head motion exceeding 4mm maximum framewise deviation averaged over eight runs, leaving data from 30 participants for subsequent analysis. Note that owing to somewhat poorer performance of participants compared to those in our pilot, we lowered the cutoff slightly from the 75% stated in the preregistration, which led to the inclusion of a single additional participant who scored 73%. In Supplementary Information Figure S11 we show that accuracy on attention check questions had a strong association with model correlations.</p>
<p>The study protocol was approved by the University of Melbourne Human Research Ethics Committee (Reference Number: 2023-28035-47583-3).</p>
</sec>
<sec id="s7b2">
<label>3.2.2</label>
<title>Experimental task</title>
<p>While undergoing scanning, participants were presented with a set of 108 sentences, each shown one at a time. They were instructed simply to read each sentence and think about its meaning. Sentence timing was varied with the length of the sentence, to allow sufficient time for reading longer sentences while avoiding leaving time for participants to engage in mind wandering after reading the shorter sentences. The time for each sentence was computed using a quadratic formula in the number of characters, with parameters chosen based on feedback from pilot participants. Presentation time ranged from 2-7 seconds, with an average of 4.29 seconds per sentence. The inter-stimulus interval was selected from a uniform random distribution between 2-7s, with an average of 4.5s. The order of sentences was randomised separately for each participant, with 54 sentences presented during each 508s run. The entire set of 108 sentences was presented every two runs, such that upon completion of all eight runs participants had seen each sentence four times. For five participants, only six runs were included, either because the participant did not complete the full scan or due to excessive head motion on the remaining two runs.</p>
</sec>
<sec id="s7b3">
<label>3.2.3</label>
<title>Attention task</title>
<p>To check attention and task engagement, participants were presented with four questions randomly distributed throughout each of the eight runs (40 questions total). All questions were four-option multiple choice questions relating to the meaning of the immediately preceding sentence. Each question, along with its potential answers, was displayed on screen for 5 seconds. Participants selected the answer using one of the two-button boxes held in each hand.</p>
</sec>
<sec id="s7b4">
<label>3.2.4</label>
<title>Image acquisition</title>
<p>The fMRI data was acquired using a 7 Tesla Siemens MAGNETOM scanner at the Melbourne Brain Centre (Parkville, Victoria) with a 32-channel radio frequency coil. The BOLD signal was measured using a multiband echo-planar imaging sequence (TR = 800 ms, TE= 22.2 ms, FA = 45°). We acquired 636 volumes on each of the eight runs, each with 84 interleaved slices (thickness = 1.6 mm, gap = 0 mm, FOV = 208mm, matrix = 130×130, multi-band factor = 6, voxel size=1.6×1.6×1.6mm<sup>3</sup>). Cardiac and respiratory traces were also recorded.</p>
</sec>
<sec id="s7b5">
<label>3.2.5</label>
<title>Preprocessing</title>
<p>Preprocessing was performed using fMRIprep with default parameters<sup><xref ref-type="bibr" rid="c78">78</xref></sup>. First, the T1-weighted (T1w) structural image was skull-stripped and normalized to the MNI152NLin2009-cAsym standard space. Second, each of the 8 BOLD runs was slice-time corrected and the volumes were motion-corrected by registering them to the single-band reference (SBRef) for each run. Distortion correction was applied by mapping field coefficients onto the reference image. All BOLD runs were then co-registered to the T1w reference, and resampled into the standard 1.6mm MNI152NLin2009cAsym space. Full details of this process are given in Supplementary Information.</p>
</sec>
<sec id="s7b6">
<label>3.2.6</label>
<title>GLM Model</title>
<p>To model the brain activity pattern resulting from each sentence, a general linear model (GLM) was fitted using a boxcar function for each separate sentence convolved with the canonical haemodynamic response (HRF). This approach yields beta coefficients for each voxel and each distinct sentence stimulus. GLMs were fitted using GLM-single<sup><xref ref-type="bibr" rid="c79">79</xref></sup>, a sophisticated software package able to automatically detect and remove sources of noise, and also fit an appropriate HRF for each voxel.</p>
<p>A constant stimulus duration of 3s was used for all stimuli for two reasons. First, GLMsingle does not support variable stimuli lengths. Second, participants will not form a full mental representation of a sentence until they finish reading it, so it is appropriate to only include the final portion of the stimulus for longer sentences.</p>
<p>In our preregistration we stated we would extract the representation over the final 3s for each stimulus. However, during the course of the study it became clear from participant feedback that the time provided for reading longer sentences was more than necessary, particularly for repeated trials. As such, in the main manuscript we instead report results for the middle 3s of each stimulus. For example, for a 7s sentence representations are evaluated during the window 2-5s. We show in Supplementary Information Figure S9 that our results are similar when using the final 3s but with lower absolute magnitudes, presumably because participants begin to disengage with the task at the end of longer sentence presentations.</p>
<p>Three regressors of no interest were included in the GLM. The first was the number of characters displayed to the participant at any given time, as a control for the optical size of the visual stimulus. The final two regressors specified the timing of button presses for question responses, with one regressor each for left-hand and right-hand presses.</p>
<p>Regressions were run for each subject using the default parameters. Beta coefficients for each presentation of all 108 sentences were then extracted from the final ‘TYPED_FITHRF_GLMDENOISE’ output of GLMSin-gle, and averaged over all four presentations of each sentence.</p>
</sec>
</sec>
<sec id="s7c">
<label>3.3</label>
<title>Behavioural data collection</title>
<sec id="s7c1">
<label>3.3.1</label>
<title>Participants</title>
<p>A total of 502 participants (267 male, 223 female, and 17 other; age range, 18-45; mean age ± SD, 29.80 ± 6.0) were recruited using the Prolific platform (<ext-link ext-link-type="uri" xlink:href="https://www.prolific.com/">https://www.prolific.com/</ext-link>). Participants were paid £4.50 for completing the task, which took an average of 22.5 minutes, amounting to an hourly rate of £11.96. All participants were self-declared native English speakers in Australia or the United States.</p>
<p>The study protocol was approved by the University of Melbourne Human Research Ethics Committee (Reference Number: 2023-23559-36378-6).</p>
</sec>
<sec id="s7c2">
<label>3.3.2</label>
<title>Survey task</title>
<p>Each participant provided similarity judgements on a 7-point Likert scale (1-7) of 102 sentence pairs randomly selected from the pool of all 5,778 sentence pairs. As our primary interest was in the block diagonal sentences, we over-sampled from these sentence pairs relative to the other sentence pairs. As such, each participant rated 42 block diagonal sentence pairs and 60 other sentence pairs.</p>
<p>Given the inherent vagueness of the similarity judgement task, previous studies have noted that lengthy instructions on how to make similarity judgements are often unclear, or may bias participant responses<sup><xref ref-type="bibr" rid="c80">80</xref>,<xref ref-type="bibr" rid="c81">81</xref></sup>. Because our goal was to elicit intuitive judgements without imposing any particular framework which might influence results, we did not provide participants with any special training or instructions about how to assign ratings. Participants were simply instructed to “consider both the similarity in meaning of the individual words contained in the sentences, as well as the similarity of the overall idea or meaning expressed by the sentences”. The full instructions given to participants can be found in the Supplementary Information.</p>
<p>In addition to the sentence pairs derived from the 108 experimental sentences, participants were also presented with additional 10 sentence pairs that served as an attention check. These stimuli consisted of either pairs of identical sentences (high similarity) or one simple sentence paired with a grammatically correct but nonsensical sentence (low similarity).</p>
</sec>
<sec id="s7c3">
<label>3.3.3</label>
<title>Preprocessing</title>
<p>We excluded all participants who failed more than two of the ten attention check items, resulting in 486 of 502 participants being retained. This amounted to 49,572 judgements, providing an average of 22 ratings for each block diagonal sentence pair and 6 for each of the other sentence pairs. Similarity judgements were averaged over participants and normalised between 0 and 1.</p>
</sec>
</sec>
<sec id="s7d">
<label>3.4</label>
<title>Representational Similarity Analysis</title>
<sec id="s7d1">
<label>3.4.1</label>
<title>Voxel Selection</title>
<p>Voxel selection was performed in two different ways. To provide an overall brain representation, we extracted all voxels within the cortical mask from the MNI152NLin2009cAsym template. To eliminate potential confound from visual regions, we also constructed a cortical mask excluding voxels in visual cortical regions V1-V4 from the cortical mask. In our preregistration we stated that we would remove any voxels having an absolute correlation with sentence length greater than 0.5. However during our analysis we found this to be infeasible given the large number of voxels sensitive to sentence length. We subsequently became aware that several previous studies have found similar length effects in the language network<sup><xref ref-type="bibr" rid="c52">52</xref>–<xref ref-type="bibr" rid="c54">54</xref></sup>. As such, we instead directly remove the visual cortex regions V1-V4 from analysis. As an additional check, we also performed all analyses controlling for the minimum sentence length, with the results shown in Supplementary Information Figure S4. In addition, we also analysed voxels within a language region of interest (ROI) mask. The mask contains 26,000 voxels found to be primarily sensitive to linguistic stimuli in a series of previous experiments involving contrasting sentence stimuli with pseudowords<sup><xref ref-type="bibr" rid="c15">15</xref></sup>.</p>
<p>To identify voxels sensitive to sentence stimuli, the stability score was computed for each voxel as the average correlation between its time series of activity on different presentations of the stimuli<sup><xref ref-type="bibr" rid="c2">2</xref></sup>. All voxels within the mask with stability scores above a threshold of 0.07 were selected for computing RSA matrices. We show in Supplementary Information Figure S10 that alternative stability thresholds yield similar results, though with higher magnitudes when higher thresholds are used.</p>
<p>Masks for cortical regions of interest were constructed using the Glasser atlas<sup><xref ref-type="bibr" rid="c82">82</xref></sup>. Parcel indices included in each region were as follows. Dorsolateral prefrontal cortex: 67,68,71,73,83,84,85,86,87; dorsomedial prefrontal cortex: 26,43,63,69; precuneus: 15,27,29,30,31,45,121,142; posterior cingulate: 14,32,33,34,35,38,161,162; primary visual cortex: 1,4,5,6; primary somatosensory cortex: 9,51,52,53.</p>
</sec>
<sec id="s7d2">
<label>3.4.2</label>
<title>Computing RSA matrices</title>
<p>For fMRI data, RSA matrices were computed by first normalising GLMSingle beta coefficients by subtracting the mean and dividing by the standard deviation for each voxel. Cosine similarities were then computed between the voxel representations of each sentence (using only the subset of included voxels) for each distinct pair of sentences, yielding an RSA matrix for each participant.</p>
<p>RSA matrices for computational models were computed differently depending on the model in question. For all vector-based models (including Mean and Transformers) sentence embeddings were extracted for each sentence, and then normalised by subtracting the mean and dividing by the standard deviation for each dimension. Pairwise sentence similarities were then computed using cosine similarity between the corresponding embeddings. For models not entirely based on vector representations (Smatch-AMR, and VerbNet-ConceptNet), we compute pairwise similarities as specified in subsection 3.1.</p>
</sec>
<sec id="s7d3">
<label>3.4.3</label>
<title>Data-model RSA correlations</title>
<p>RSA matrices for brain representations were compared with those of the computational models by calculating for each participant the partial Spearman correlation controlling for the difference in sentence lengths, then averaging over participants. We use the pingouin 0.5.4 python package, which utilises the inverse covariance matrix for computing partial Spearman correlations. This has been proven more reliable than the alternative regression residuals technique when a subset of variables are discrete (see discussion at <ext-link ext-link-type="uri" xlink:href="https://github.com/raphaelvallat/pingouin/issues/147">https://github.com/raphaelvallat/pingouin/issues/147</ext-link>). This is especially relevant for the Graph model using the SMATCH metric, which outputs discrete similarity scores.</p>
<p>In addition to the simple average across participants, we implemented an alternative method adapted from several previous studies<sup><xref ref-type="bibr" rid="c26">26</xref>,<xref ref-type="bibr" rid="c27">27</xref>,<xref ref-type="bibr" rid="c37">37</xref></sup>, in which a group-averaged RSA matrix was first constructed by averaging pairwise sentence similarities over participants, and then the correlation computed between each model RSA and this group-averaged RSA matrix.</p>
<p>For the simple average method, confidence intervals and statistical testing was performed using simple two-sided t-tests computed over participants. For the group average method, confidence intervals were estimated by bootstrapping over participants, performed 100 times. In the preregistration we planned to perform bootstrapping over stimuli as well as over participants, however in retrospect we judged this to be inappropriate since our sentences were not a random sampling from some corpus, but were specially constructed to provide specified semantic and syntactic variation. For both methods, the Bonferroni correction was used to adjust for three independent model comparisons (Mean to Transformer, Transformer to Hybrid, and Hybrid to Syntax), yielding a significance level of <italic>α</italic>=0.05/3 = 0.0167.</p>
<p>We also computed the correlation between humanrated similarities and the brain RSA similarities, though we did not perform a statistical test as we had no prior hypothesis about this correlation.</p>
</sec>
</sec>
<sec id="s7e">
<label>3.5</label>
<title>Searchlight RSA</title>
<p>To visualise the location of the cortical regions responsible for encoding sentence information, we implemented RSA-searchlight<sup><xref ref-type="bibr" rid="c83">83</xref></sup>. Using the mne-rsa package (see <ext-link ext-link-type="uri" xlink:href="https://users.aalto.fi/~vanvlm1/mne-rsa/index.html">https://users.aalto.fi/~vanvlm1/mne-rsa/index.html</ext-link>), we performed an 8mm searchlight analysis over all voxels within the cortical mask. Images were smoothed with 5mm FWHM and thresholded at z=2 using threshold-free cluster enhancement (tfce) correction for display.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>We would like to thank the staff at the Melbourne Brain Centre Imaging Unit for their assistance with collecting the fMRI scans.</p>
</ack>
<sec id="additional-info" sec-type="additional-information">
<title>Additional information</title>
<sec id="s6" sec-type="data-availability">
<title>Data and materials availability</title>
<p>Data will be uploaded to OpenNeuro upon publication, with code available from github.</p>
</sec>
<sec id="s3">
<title>Funding</title>
<p>This research was supported by a University of Melbourne Graduate Research Scholarship from the Faculty of Business and Economics (Fodor).</p>
</sec>
<sec id="s4">
<title>Author contributions</title>
<p>Conceptualisation: J.F.; Methodology: J.F., C.M., S.S.; Investigation: S.S.; Formal analysis: J.F.; Visualisation: J.F.; Writing – original draft: J.F.; Writing – review editing: J.F., C.M., S.S.</p>
</sec>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mitchell</surname>, <given-names>T.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Predicting human brain activity associated with the meanings of nouns</article-title>. <source>Science</source> <volume>320</volume>, <fpage>1191</fpage>–<lpage>1195</lpage>. ISSN: <issn>0036-8075</issn> (<year>2008</year>).</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Just</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Cherkassky</surname>, <given-names>V. L.</given-names></string-name>, <string-name><surname>Aryal</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Mitchell</surname>, <given-names>T. M.</given-names></string-name></person-group> <article-title>A neurosemantic theory of concrete noun representation based on the underlying brain codes</article-title>. <source>PloS one</source> <volume>5</volume>, <fpage>e8622</fpage>. ISSN: <issn>1932-6203</issn> (<year>2010</year>).</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wehbe</surname>, <given-names>L.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Simultaneously uncovering the patterns of brain regions involved in different story reading subprocesses</article-title>. <source>PloS one</source> <volume>9</volume>, <fpage>e112575</fpage>. ISSN: <issn>1932-6203</issn> (<year>2014</year>).</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huth</surname>, <given-names>A. G.</given-names></string-name>, <string-name><surname>De Heer</surname>, <given-names>W. A.</given-names></string-name>, <string-name><surname>Griffiths</surname>, <given-names>T. L.</given-names></string-name>, <string-name><surname>Theunissen</surname>, <given-names>F. E.</given-names></string-name> &amp; <string-name><surname>Gallant</surname>, <given-names>J. L.</given-names></string-name></person-group> <article-title>Natural speech reveals the semantic maps that tile human cerebral cortex</article-title>. <source>Nature</source> <volume>532</volume>, <fpage>453</fpage>–<lpage>458</lpage>. ISSN: <issn>1476-4687</issn> (<year>2016</year>).</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pereira</surname>, <given-names>F.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Toward a universal decoder of linguistic meaning from brain activation</article-title>. <source>Nature communications</source> <volume>9</volume>, <fpage>1</fpage>–<lpage>13</lpage>. ISSN: <issn>2041-1723</issn> (<year>2018</year>).</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Günther</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Rinaldi</surname>, <given-names>L.</given-names></string-name> &amp; <string-name><surname>Marelli</surname>, <given-names>M.</given-names></string-name></person-group> <article-title>Vector-space models of semantic representation from a cognitive perspective: A discussion of common misconceptions</article-title>. <source>Perspectives on Psychological Science</source> <volume>14</volume>, <fpage>1006</fpage>–<lpage>1033</lpage>. ISSN: <issn>1745-6916</issn> (<year>2019</year>).</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Karamolegkou</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Abdou</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Søgaard</surname>, <given-names>A.</given-names></string-name></person-group> <article-title>Mapping Brains with Language Models: A Survey</article-title>. <source>arXiv</source> <pub-id pub-id-type="doi">10.48550/arXiv.2306.05126</pub-id> (<year>2023</year>).</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ouyang</surname>, <given-names>L.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Training language models to follow instructions with human feedback</article-title>. <source>Advances in Neural Information Processing Systems</source> <volume>35</volume>, <fpage>27730</fpage>– <lpage>27744</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Touvron</surname>, <given-names>H.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Llama: Open and efficient foundation language models</article-title>. <source>arXiv</source> <pub-id pub-id-type="doi">10.48550/arXiv.2302.13971</pub-id> (<year>2023</year>).</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><collab>Gemini Team Google</collab> <etal>et al.</etal></person-group> <article-title>Gemini: a family of highly capable multimodal models</article-title>. <source>arXiv</source> <pub-id pub-id-type="doi">10.48550/arXiv.2312.11805</pub-id> (<year>2023</year>).</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bhatia</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Richie</surname>, <given-names>R.</given-names></string-name> &amp; <string-name><surname>Zou</surname>, <given-names>W.</given-names></string-name></person-group> <article-title>Distributed semantic representations for modeling human judgment</article-title>. <source>Current Opinion in Behavioral Sciences</source> <volume>29</volume>, <fpage>31</fpage>–<lpage>36</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Erk</surname>, <given-names>K.</given-names></string-name></person-group> <article-title>The probabilistic turn in semantics and pragmatics</article-title>. <source>Annual Review of Linguistics</source> <volume>8</volume>, <fpage>101</fpage>– <lpage>121</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tuckute</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Kanwisher</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Fedorenko</surname>, <given-names>E.</given-names></string-name></person-group> <article-title>Language in brains, minds, and machines</article-title>. <source>Annual Review of Neuroscience</source> <volume>47</volume>, <fpage>277</fpage>–<lpage>301</lpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Anderson</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Deep artificial neural networks reveal a distributed cortical network encoding propositional sentence-level meaning</article-title>. <source>Journal of Neuroscience</source> <volume>41</volume>, <fpage>4100</fpage>–<lpage>4119</lpage>. ISSN: <issn>0270-6474</issn> (<year>2021</year>).</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Schrimpf</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>The neural architecture of language: Integrative modeling converges on predictive processing</article-title>. <conf-name>Proceedings of the National Academy of Sciences 118</conf-name>. (<year>2021</year>).</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Antonello</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Turek</surname>, <given-names>J. S.</given-names></string-name>, <string-name><surname>Vo</surname>, <given-names>V.</given-names></string-name> &amp; <string-name><surname>Huth</surname>, <given-names>A.</given-names></string-name></person-group> <article-title>Low-dimensional structure in the space of language representations is reflected in brain responses</article-title>. <source>Advances in neural information processing systems</source> <volume>34</volume>, <fpage>8332</fpage>–<lpage>8344</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Pasquiou</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Lakretz</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Hale</surname>, <given-names>J. T.</given-names></string-name>, <string-name><surname>Thirion</surname>, <given-names>B.</given-names></string-name> &amp; <string-name><surname>Pallier</surname>, <given-names>C.</given-names></string-name></person-group> <article-title>Neural Language Models are not Born Equal to Fit Brain Data, but Training Helps</article-title> <conf-name>International Conference on Machine Learning - PMLR 2022</conf-name>, <year>2022</year>, <fpage>17499</fpage>–<lpage>17516</lpage>.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Aliko</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Huang</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Gheorghiu</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Meliss</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Skipper</surname>, <given-names>J. I.</given-names></string-name></person-group> <article-title>A naturalistic neuroimaging database for understanding the brain using ecological stimuli</article-title>. <source>Scientific Data</source> <volume>7</volume>, <fpage>1</fpage>–<lpage>21</lpage>. ISSN: <issn>2052-4463</issn> (<year>2020</year>).</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hamilton</surname>, <given-names>L. S.</given-names></string-name> &amp; <string-name><surname>Huth</surname>, <given-names>A. G.</given-names></string-name></person-group> <article-title>The revolution will not be controlled: natural stimuli in speech neuro-science</article-title>. <source>Language, cognition and neuroscience</source> <volume>35</volume>, <fpage>573</fpage>–<lpage>582</lpage>. ISSN: <issn>2327-3798</issn> (<year>2020</year>).</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nastase</surname>, <given-names>S. A.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>The “Narratives” fMRI dataset for evaluating models of naturalistic language comprehension</article-title>. <source>Scientific data</source> <volume>8</volume>, <fpage>250</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Kim</surname>, <given-names>J.-H.</given-names></string-name>, <string-name><surname>Brang</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>Liu</surname>, <given-names>Z.</given-names></string-name></person-group> <article-title>Naturalistic stimuli: A paradigm for multiscale functional characterization of the human brain</article-title>. <source>Current opinion in biomedical engineering</source> <volume>19</volume>, <fpage>100298</fpage>. ISSN: <issn>2468-4511</issn> (<year>2021</year>).</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Lai</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Pylkkänen</surname>, <given-names>L.</given-names></string-name></person-group> <article-title>Semantic composition in experimental and naturalistic paradigms</article-title>. <source>Imaging Neuroscience</source> <volume>2</volume>, <fpage>1</fpage>–<lpage>17</lpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Douglas</surname>, <given-names>P. K.</given-names></string-name></person-group> <article-title>Interpreting encoding and decoding models</article-title>. <source>Current opinion in neurobiology</source> <volume>55</volume>, <fpage>167</fpage>–<lpage>179</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bruffaerts</surname>, <given-names>R.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Redefining the resolution of semantic knowledge in the brain: advances made by the introduction of models of semantics in neuroimaging</article-title>. <source>Neuroscience &amp; Biobehavioral Reviews</source> <volume>103</volume>, <fpage>3</fpage>–<lpage>13</lpage>. ISSN: <issn>0149-7634</issn> (<year>2019</year>).</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hagoort</surname>, <given-names>P.</given-names></string-name></person-group> <article-title>The meaning-making mechanism(s) behind the eyes and between the ears</article-title>. <source>Philosophical Transactions of the Royal Society B</source> <volume>375</volume>, <fpage>20190301</fpage>. ISSN: <issn>0962-8436</issn> (<year>2020</year>).</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname>, <given-names>X.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Organizational principles of abstract words in the human brain</article-title>. <source>Cerebral Cortex</source> <volume>28</volume>, <fpage>4305</fpage>–<lpage>4318</lpage>. ISSN: <issn>1047-3211</issn> (<year>2018</year>).</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fernandino</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Tong</surname>, <given-names>J.-Q.</given-names></string-name>, <string-name><surname>Conant</surname>, <given-names>L. L.</given-names></string-name>, <string-name><surname>Humphries</surname>, <given-names>C. J.</given-names></string-name> &amp; <string-name><surname>Binder</surname>, <given-names>J. R.</given-names></string-name></person-group> <article-title>Decoding the information structure underlying the neural representation of concepts</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>119</volume>, <fpage>e2108091119</fpage>. ISSN: <issn>0027-8424</issn> (<year>2022</year>).</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tong</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>A distributed network for multimodal experiential representation of concepts</article-title>. <source>Journal of Neuroscience</source> <volume>42</volume>, <fpage>7121</fpage>–<lpage>7130</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Acunzo</surname>, <given-names>D. J.</given-names></string-name>, <string-name><surname>Low</surname>, <given-names>D. M.</given-names></string-name> &amp; <string-name><surname>Fairhall</surname>, <given-names>S. L.</given-names></string-name></person-group> <article-title>Deep neural networks reveal topic-level representations of sentences in medial prefrontal cortex, lateral anterior temporal lobe, precuneus, and angular gyrus</article-title>. <source>NeuroImage</source> <volume>251</volume>, <fpage>119005</fpage>. ISSN: <issn>1053-8119</issn> (<year>2022</year>).</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fairhall</surname>, <given-names>S. L.</given-names></string-name></person-group> <article-title>Sentence-level embeddings reveal dissociable word-and sentence-level cortical representation across coarse-and fine-grained levels of meaning</article-title>. <source>Brain and Language</source> <volume>250</volume>, <fpage>105389</fpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fodor</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>De Deyne</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Suzuki</surname>, <given-names>S.</given-names></string-name></person-group> <article-title>Compositionality and Sentence Meaning: Comparing Semantic Parsing and Transformers on a Challenging Sentence Similarity Dataset</article-title>. <source>Computational Linguistics</source>, <volume>51</volume>: <fpage>139</fpage>–<lpage>190</lpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lake</surname>, <given-names>B. M.</given-names></string-name> &amp; <string-name><surname>Murphy</surname>, <given-names>G. L.</given-names></string-name></person-group> <article-title>Word meaning in minds and machines</article-title>. <source>Psychological Review</source> <volume>130</volume>, <fpage>401</fpage>–<lpage>31</lpage>. ISSN: <issn>1939-1471</issn> (<year>2021</year>).</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Žabokrtský</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Zeman</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>Ševčíková</surname>, <given-names>M.</given-names></string-name></person-group> <article-title>Sentence meaning representations across languages: what can we learn from existing frameworks?</article-title> <source>Computational Linguistics</source> <volume>46</volume>, <fpage>605</fpage>–<lpage>665</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Anderson</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kiela</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Clark</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Poesio</surname>, <given-names>M.</given-names></string-name></person-group> <article-title>Visually grounded and textual semantic models differentially decode brain activity associated with concrete and abstract nouns</article-title>. <source>Transactions of the Association for Computational Linguistics</source> <volume>5</volume>, <fpage>17</fpage>–<lpage>30</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Just</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Cherkassky</surname>, <given-names>V. L.</given-names></string-name></person-group> <article-title>Neural representations of the concepts in simple sentences: Concept activation prediction and context effects</article-title>. <source>Neuroimage</source> <volume>157</volume>, <fpage>511</fpage>–<lpage>520</lpage>. ISSN: <issn>1053-8119</issn> (<year>2017</year>).</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fedorenko</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Ivanova</surname>, <given-names>A. A.</given-names></string-name> &amp; <string-name><surname>Regev</surname>, <given-names>T. I.</given-names></string-name></person-group> <article-title>The language network as a natural kind within the broader landscape of the human brain</article-title>. <source>Nature Reviews Neuroscience</source> <volume>25</volume>, <fpage>289</fpage>–<lpage>324</lpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Handjaras</surname>, <given-names>G.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>How concepts are encoded in the human brain: a modality independent, categorybased cortical organization of semantic knowledge</article-title>. <source>Neuroimage</source> <volume>135</volume>, <fpage>232</fpage>–<lpage>242</lpage>. ISSN: <issn>1053-8119</issn> (<year>2016</year>).</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shain</surname>, <given-names>C.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Distributed sensitivity to syntax and semantics throughout the language network</article-title>. <source>Journal of Cognitive Neuroscience</source> <volume>36</volume>, <fpage>1427</fpage>–<lpage>1471</lpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fedorenko</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Blank</surname>, <given-names>I. A.</given-names></string-name>, <string-name><surname>Siegelman</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Mineroff</surname>, <given-names>Z.</given-names></string-name></person-group> <article-title>Lack of selectivity for syntax relative to word meanings throughout the language network</article-title>. <source>Cognition</source> <volume>203</volume>, <fpage>104348</fpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Marelli</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>A SICK cure for the evaluation of compositional distributional semantic models</article-title> <conf-name>Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14)</conf-name> (<year>2014</year>), <fpage>216</fpage>–<lpage>223</lpage>.</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goucha</surname>, <given-names>T.</given-names></string-name> &amp; <string-name><surname>Friederici</surname>, <given-names>A. D.</given-names></string-name></person-group> <article-title>The language skeleton after dissecting meaning: A functional segregation within Broca’s area</article-title>. <source>NeuroImage</source> <volume>114</volume>, <fpage>294</fpage>–<lpage>302</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mollica</surname>, <given-names>F.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Composition is the core driver of the language-selective network</article-title>. <source>Neurobiology of Language</source> <volume>1</volume>, <fpage>104</fpage>–<lpage>134</lpage>. ISSN: <issn>2641-4368</issn> (<year>2020</year>).</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fedorenko</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Nieto-Castanon</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Kanwisher</surname>, <given-names>N.</given-names></string-name></person-group> <article-title>Lexical and syntactic representations in the brain: an fMRI investigation with multi-voxel pattern analyses</article-title>. <source>Neuropsychologia</source> <volume>50</volume>, <fpage>499</fpage>–<lpage>513</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Matchin</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Hammerly</surname>, <given-names>C.</given-names></string-name> &amp; <string-name><surname>Lau</surname>, <given-names>E.</given-names></string-name></person-group> <article-title>The role of the IFG and pSTS in syntactic prediction: Evidence from a parametric study of hierarchical structure in fMRI</article-title>. <source>cortex</source> <volume>88</volume>, <fpage>106</fpage>–<lpage>123</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Călinescu</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Ramchand</surname>, <given-names>G.</given-names></string-name> &amp; <string-name><surname>Baggio</surname>, <given-names>G.</given-names></string-name></person-group> <article-title>How (not) to look for meaning composition in the brain: A reassessment of current experimental paradigms</article-title>. <source>Frontiers in Language Sciences</source> <volume>2</volume>, <fpage>1096110</fpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Oota</surname>, <given-names>S. R.</given-names></string-name>, <string-name><surname>Gupta</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Toneva</surname>, <given-names>M.</given-names></string-name></person-group> <article-title>Joint processing of linguistic properties in brains and language models</article-title> <conf-name>Advances in Neural Information Processing Systems</conf-name> <volume>36</volume> (<year>2024</year>).</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Feghhi</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Hadidi</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Song</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Blank</surname>, <given-names>I. A.</given-names></string-name> &amp; <string-name><surname>Kao</surname>, <given-names>J. C.</given-names></string-name></person-group> <article-title>What Are Large Language Models Mapping to in the Brain? a Case Against Over-Reliance on Brain Scores</article-title>. <source>arXiv</source> <pub-id pub-id-type="doi">10.48550/arXiv.2406.01538</pub-id> (<year>2024</year>).</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hosseini</surname>, <given-names>E. A.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Artificial Neural Network Language Models Predict Human Brain Responses to Language Even After a Developmentally Realistic Amount of Training</article-title>. <source>Neurobiology of Language</source> <volume>5</volume>, <fpage>43</fpage>–<lpage>63</lpage>. ISSN: <issn>2641-4368</issn>. <pub-id pub-id-type="doi">10.1162/nol_a_00137</pub-id> (<month>Apr</month>. <year>2024</year>).</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Caucheteux</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Gramfort</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>King</surname>, <given-names>J.-R.</given-names></string-name></person-group> <article-title>Disentangling syntax and semantics in the brain with deep networks</article-title> <conf-name>International Conference on Machine Learning</conf-name> (<year>2021</year>), <fpage>1336</fpage>–<lpage>1348</lpage>.</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kauf</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Tuckute</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Levy</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Andreas</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Fedorenko</surname>, <given-names>E.</given-names></string-name></person-group> <article-title>Lexical-semantic content, not syntactic structure, is the main contributor to ANN-brain similarity of fMRI responses in the language network</article-title>. <source>Neurobiology of Language</source> <volume>5</volume>, <fpage>7</fpage>–<lpage>42</lpage>. ISSN: <issn>2641-4368</issn> (<year>2024</year>).</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Hadidi</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Feghhi</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Song</surname>, <given-names>B. H.</given-names></string-name>, <string-name><surname>Blank</surname>, <given-names>I. A.</given-names></string-name> &amp; <string-name><surname>Kao</surname>, <given-names>J. C.</given-names></string-name></person-group> <article-title>Illusions of Alignment Between Large Language Models and Brains Emerge From Fragile Methods and Overlooked Confounds</article-title>. <source>bioRxiv</source> <pub-id pub-id-type="doi">10.1101/2025.03.09.642245</pub-id> (<year>2025</year>).</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nelson</surname>, <given-names>M. J.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Neurophysiological dynamics of phrase-structure building during sentence processing</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>114</volume>, <fpage>E3669</fpage>–<lpage>E3678</lpage>. ISSN: <issn>0027-8424</issn> (<year>2017</year>).</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schuster</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Hawelka</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Himmelstoss</surname>, <given-names>N. A.</given-names></string-name>, <string-name><surname>Richlan</surname>, <given-names>F.</given-names></string-name> &amp; <string-name><surname>Hutzler</surname>, <given-names>F.</given-names></string-name></person-group> <article-title>The neural correlates of word position and lexical predictability during sentence reading: Evidence from fixation-related fMRI</article-title>. <source>Language, Cognition and Neuroscience</source> <volume>35</volume>, <fpage>613</fpage>–<lpage>624</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Woolnough</surname>, <given-names>O.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Spatiotemporally distributed frontotemporal networks for sentence reading</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>120</volume>, <fpage>e2300252120</fpage>. ISSN: <issn>0027-8424</issn> (<year>2023</year>).</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Deniz</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Tseng</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Wehbe</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>la Tour</surname>, <given-names>T.</given-names></string-name> D. &amp; <string-name><surname>Gallant</surname>, <given-names>J. L.</given-names></string-name></person-group> <article-title>Semantic representations during language comprehension are affected by context</article-title>. <source>Journal of Neuroscience</source> <volume>43</volume>, <fpage>3144</fpage>–<lpage>3158</lpage>. ISSN: <issn>0270-6474</issn> (<year>2023</year>).</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Baron</surname>, <given-names>S. G.</given-names></string-name>, <string-name><surname>Thompson-Schill</surname>, <given-names>S. L.</given-names></string-name>, <string-name><surname>Weber</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Osherson</surname>, <given-names>D.</given-names></string-name></person-group> <article-title>An early stage of conceptual combination: Superimposition of constituent concepts in left anterolateral temporal lobe</article-title>. <source>Cognitive neuroscience</source> <volume>1</volume>, <fpage>44</fpage>–<lpage>51</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Frankland</surname>, <given-names>S. M.</given-names></string-name> &amp; <string-name><surname>Greene</surname>, <given-names>J. D.</given-names></string-name></person-group> <article-title>Concepts and compositionality: in search of the brain’s language of thought</article-title>. <source>Annual review of psychology</source> <volume>71</volume>, <fpage>273</fpage>– <lpage>303</lpage>. ISSN: <issn>0066-4308</issn> (<year>2020</year>).</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Desbordes</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>King</surname>, <given-names>J.-R.</given-names></string-name> &amp; <string-name><surname>Dehaene</surname>, <given-names>S.</given-names></string-name></person-group> <article-title>Tracking the neural codes for words and phrases during semantic composition, working-memory storage, and retrieval</article-title>. <source>Cell Reports</source> <volume>43</volume> (<year>2024</year>).</mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stanojević</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Brennan</surname>, <given-names>J. R.</given-names></string-name>, <string-name><surname>Dunagan</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Steedman</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Hale</surname>, <given-names>J. T.</given-names></string-name></person-group> <article-title>Modeling structure-building in the brain with CCG parsing and large language models</article-title>. <source>Cognitive science</source> <volume>47</volume>, <fpage>e13312</fpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Fresen</surname>, <given-names>A. J.</given-names></string-name>, <string-name><surname>Choenni</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Heilbron</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Zuidema</surname>, <given-names>W.</given-names></string-name> &amp; <string-name><surname>de Heer Kloots</surname>, <given-names>M.</given-names></string-name></person-group> <article-title>Language Models That Accurately Represent Syntactic Structure Exhibit Higher Representational Similarity To Brain Activity</article-title> <conf-name>Proceedings of the Annual Meeting of the Cognitive Science Society</conf-name> <volume>46</volume> (<year>2024</year>).</mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chang</surname>, <given-names>T. A.</given-names></string-name> &amp; <string-name><surname>Bergen</surname>, <given-names>B. K.</given-names></string-name></person-group> <article-title>Language model behavior: A comprehensive survey</article-title>. <source>Computational Linguistics</source> <volume>50</volume>, <fpage>293</fpage>–<lpage>350</lpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Clark</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Khandelwal</surname>, <given-names>U.</given-names></string-name>, <string-name><surname>Levy</surname>, <given-names>O.</given-names></string-name> &amp; <string-name><surname>Manning</surname>, <given-names>C. D.</given-names></string-name></person-group> <article-title>What Does BERT Look at? an Analysis of BERT’s Attention</article-title> <conf-name>Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</conf-name> (<year>2019</year>), <fpage>276</fpage>–<lpage>286</lpage>.</mixed-citation></ref>
<ref id="c63"><label>63.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Manning</surname>, <given-names>C. D.</given-names></string-name>, <string-name><surname>Clark</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Hewitt</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Khandelwal</surname>, <given-names>U.</given-names></string-name> &amp; <string-name><surname>Levy</surname>, <given-names>O.</given-names></string-name></person-group> <article-title>Emergent linguistic structure in artificial neural networks trained by self-supervision</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>117</volume>, <fpage>30046</fpage>–<lpage>30054</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c64"><label>64.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Timkey</surname>, <given-names>W.</given-names></string-name> &amp; <string-name><surname>van Schijndel</surname>, <given-names>M.</given-names></string-name></person-group> <article-title>All Bark and No Bite: Rogue Dimensions in Transformer Language Models Obscure Representational Quality</article-title> <conf-name>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</conf-name> (<year>2021</year>), <fpage>4527</fpage>– <lpage>4546</lpage>.</mixed-citation></ref>
<ref id="c65"><label>65.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Cai</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Huang</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Bian</surname>, <given-names>Y.</given-names></string-name> &amp; <string-name><surname>Church</surname>, <given-names>K.</given-names></string-name></person-group> <article-title>Isotropy in the contextual embedding space: Clusters and manifolds</article-title> <conf-name>International Conference on Learning Representations</conf-name> (<year>2021</year>).</mixed-citation></ref>
<ref id="c66"><label>66.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Conneau</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kiela</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Schwenk</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Barrault</surname>, <given-names>L.</given-names></string-name> &amp; <string-name><surname>Bordes</surname>, <given-names>A.</given-names></string-name></person-group> <article-title>Supervised Learning of Universal Sentence Representations from Natural Language Inference Data</article-title>. <conf-name>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (Association for Computational Linguistics, Copenhagen, Denmark)</conf-name>. <year>2017</year>), <fpage>670</fpage>–<lpage>680</lpage>. <ext-link ext-link-type="uri" xlink:href="https://aclanthology.org/D17-1070">https://aclanthology.org/D17-1070</ext-link>.</mixed-citation></ref>
<ref id="c67"><label>67.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Cer</surname>, <given-names>D.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Universal sentence encoder for English</article-title> <conf-name>Proceedings of the 2018 conference on empirical methods in natural language processing: system demonstrations</conf-name> (<year>2018</year>), <fpage>169</fpage>–<lpage>174</lpage>.</mixed-citation></ref>
<ref id="c68"><label>68.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Sun</surname>, <given-names>Y.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Ernie 2.0: A continual pre-training framework for language understanding</article-title>. <conf-name>Proceedings of the AAAI conference on artificial intelligence</conf-name> <volume>34</volume>, <fpage>8968</fpage>–<lpage>8975</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c69"><label>69.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Reimers</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Gurevych</surname>, <given-names>I.</given-names></string-name></person-group> <article-title>Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks</article-title> <conf-name>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</conf-name> (<year>2019</year>), <fpage>3982</fpage>– <lpage>3992</lpage>.</mixed-citation></ref>
<ref id="c70"><label>70.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Tsukagoshi</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Sasano</surname>, <given-names>R.</given-names></string-name> &amp; <string-name><surname>Takeda</surname>, <given-names>K.</given-names></string-name></person-group> <article-title>DefSent: Sentence Embeddings using Definition Sentences</article-title> <conf-name>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)</conf-name> (<year>2021</year>), <fpage>411</fpage>–<lpage>418</lpage>.</mixed-citation></ref>
<ref id="c71"><label>71.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Bai</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>Y.</given-names></string-name> &amp; <string-name><surname>Zhang</surname>, <given-names>Y.</given-names></string-name></person-group> <article-title>Graph Pre-training for AMR Parsing and Generation</article-title> <conf-name>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</conf-name> (<year>2022</year>), <fpage>6001</fpage>–<lpage>6015</lpage>.</mixed-citation></ref>
<ref id="c72"><label>72.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Opitz</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Frank</surname>, <given-names>A.</given-names></string-name></person-group> <article-title>SBERT studies Meaning Representations: Decomposing Sentence Embeddings into Explainable Semantic Features</article-title> <conf-name>Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</conf-name> (<year>2022</year>), <fpage>625</fpage>–<lpage>638</lpage>.</mixed-citation></ref>
<ref id="c73"><label>73.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Bevilacqua</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Blloshmi</surname>, <given-names>R.</given-names></string-name> &amp; <string-name><surname>Navigli</surname>, <given-names>R.</given-names></string-name></person-group> <article-title>One SPRING to Rule Them Both: Symmetric AMR Semantic Parsing and Generation without a Complex Pipeline</article-title> <conf-name>Proceedings of AAAI</conf-name> (<year>2021</year>), <fpage>12564</fpage>– <lpage>12573</lpage>.</mixed-citation></ref>
<ref id="c74"><label>74.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goyal</surname>, <given-names>P.</given-names></string-name> &amp; <string-name><surname>Ferrara</surname>, <given-names>E.</given-names></string-name></person-group> <article-title>Graph embedding techniques, applications, and performance: A survey</article-title>. <source>Knowledge-Based Systems</source> <volume>151</volume>, <fpage>78</fpage>–<lpage>94</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c75"><label>75.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rossi</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Barbosa</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Firmani</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Matinata</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Merialdo</surname>, <given-names>P.</given-names></string-name></person-group> <article-title>Knowledge graph embedding for link prediction: A comparative analysis</article-title>. <source>ACM Transactions on Knowledge Discovery from Data (TKDD)</source> <volume>15</volume>, <fpage>1</fpage>–<lpage>49</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c76"><label>76.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Cai</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Knight</surname>, <given-names>K.</given-names></string-name></person-group> <article-title>Smatch: an evaluation metric for semantic feature structures</article-title> <conf-name>Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</conf-name> (<year>2013</year>), <fpage>748</fpage>–<lpage>752</lpage>.</mixed-citation></ref>
<ref id="c77"><label>77.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Opitz</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Daza</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Frank</surname>, <given-names>A.</given-names></string-name></person-group> <article-title>Weisfeiler-leman in the bamboo: Novel AMR graph metrics and a benchmark for AMR graph similarity</article-title>. <source>Transactions of the Association for Computational Linguistics</source> <volume>9</volume>, <fpage>1425</fpage>–<lpage>1441</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c78"><label>78.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Esteban</surname>, <given-names>O.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>fMRIPrep: a robust preprocessing pipeline for functional MRI</article-title>. <source>Nature Methods</source> <volume>16</volume>, <fpage>111</fpage>–<lpage>116</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c79"><label>79.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Prince</surname>, <given-names>J. S.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Improving the accuracy of singletrial fMRI response estimates using GLMsingle</article-title>. <source>eLife</source> <volume>11</volume>, <elocation-id>e77599</elocation-id>. ISSN: <issn>2050-084X</issn> (<year>2022</year>). <pub-id pub-id-type="doi">10.7554/eLife.77599</pub-id></mixed-citation></ref>
<ref id="c80"><label>80.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Abe</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Yokoi</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Kajiwara</surname>, <given-names>T.</given-names></string-name> &amp; <string-name><surname>Inui</surname>, <given-names>K.</given-names></string-name></person-group> <article-title>Why is sentence similarity benchmark not predictive of application-oriented task performance?</article-title> In <conf-name>Proceedings of the 3rd Workshop on Evaluation and Comparison of NLP Systems</conf-name> (<year>2022</year>), <fpage>70</fpage>–<lpage>87</lpage>.</mixed-citation></ref>
<ref id="c81"><label>81.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Abdalla</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Vishnubhotla</surname>, <given-names>K.</given-names></string-name> &amp; <string-name><surname>Mohammad</surname>, <given-names>S.</given-names></string-name></person-group> <article-title>What Makes Sentences Semantically Related? A Textual Relatedness Dataset and Empirical Study</article-title> <conf-name>Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics</conf-name> (<year>2023</year>), <fpage>782</fpage>–<lpage>796</lpage>.</mixed-citation></ref>
<ref id="c82"><label>82.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Glasser</surname>, <given-names>M. F.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>A multi-modal parcellation of human cerebral cortex</article-title>. <source>Nature</source> <volume>536</volume>, <fpage>171</fpage>–<lpage>178</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c83"><label>83.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nili</surname>, <given-names>H.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>A toolbox for representational similarity analysis</article-title>. <source>PLoS computational biology</source> <volume>10</volume>, <fpage>e1003553</fpage> (<year>2014</year>).</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108442.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Ding</surname>
<given-names>Nai</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Zhejiang University</institution>
</institution-wrap>
<city>Hangzhou</city>
<country>China</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This work provides a <bold>valuable</bold> comparison of sentence structure representations in the human brain and state-of-the-art Large Language Models (LLMs). Based on <bold>solid</bold> analysis of 7T fMRI data, it systematically identifies sentences in which LLMs underperform relative to models that explicitly code for syntactic structure. The study will be of significant interest to both cognitive neuroscientists and artificial intelligence researchers.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108442.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This paper investigates whether transformer-based models can represent sentence-level semantics in a human-like way. The authors designed a set of 108 sentences specifically to dissociate lexical semantics from sentence-level information and collected 7T fMRI data from 30 participants reading these sentences. They conducted representational similarity analysis (RSA) comparing brain data and model representations, as well as the human behavioral ratings. It is found that transformer-based models match brain representation better than a static word embedding baseline, which ignores word order, but fall short of models that encode the structural relations between words. The main contributions of this paper are:</p>
<p>(1) The construction of a sentence set that disentangles sentence structure from word meaning.</p>
<p>(2) A comprehensive comparison of neural sentence representations (via fMRI), human behavior, and multiple computational models at the sentence level.</p>
<p>Strengths:</p>
<p>(1) The paper evaluates a wide variety of models, including layer-wise analysis for transformers and region-wise analysis in the human brain.</p>
<p>(2) The stimulus design allows precise dissociation between lexical and sentence-level semantics. The RSA-based approach is empirically sound and intuitive.</p>
<p>(3) The constructed sentences, along with the fMRI and behavioral data, represent a valuable resource for studying sentence representation.</p>
<p>Weaknesses:</p>
<p>(1) The rationale behind averaging sentence embeddings across multiple transformer models (with different architectures and training objectives) is unclear. These transformer-based models have different training paradigms and model architectures, which may result in misaligned semantic spaces. The averaging operation may dilute the distinct sentence representations learned by each model, potentially weakening the overall semantic encoding for sentences. Please clarify this choice or cite supporting methodology.</p>
<p>(2) All structure-sensitive models discussed incorporate semantics to some extent. Including a purely syntactic baseline, such as a model based on context-free grammar, would help confirm the importance of syntactic structures.</p>
<p>(3) In Figure 2, human behavioral judgments show weak correlations with neural data, and even fall below those of computational models, suggesting the behavioral judgments may not reflect the sentence structures in a brain-like way. This discrepancy between behavioral and neural data should be clarified, as it affects the interpretation of the results.</p>
<p>(4) To better contextualize model and neural performance, sentence similarity should be anchored to a notion of semantic &quot;ground truth&quot;, such as the matrix shown in Figure 1a. Comparing this reference with human judgments, brain responses, and model similarities would help establish an upper bound.</p>
<p>(5) The structure of this paper is confusing. For instance, Figure 5 is cited early but appears much later. Reordering sections and figures would enhance readability.</p>
<p>(6) While the analysis is broad and comprehensive, it lacks depth in some respects. For instance, it remains unclear what specific insights are gained from comparing across brain regions (e.g., whole brain, language network, and other subregions). Similarly, the results of simple-average and group-average RSA appear quite similar and may not advance the interpretation.</p>
<p>(7) While explaining the grid-like pattern due to sentence length is important, this part feels somewhat disconnected from the central question of this paper (word order). It might be better placed in supplementary material.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108442.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The paper used fMRI data while reading a set of sentences. The sentences are designed to disentangle syntax from meaning. RSA was performed using voxel activations and a variety of language models. The results show that transformers are inferior to models with explicit syntactic representation in terms of matching brain representations.</p>
<p>Strengths:</p>
<p>(1) The study controls for some variables that allow for an investigation of sentence structure in the brain. This controlled setting has an advantage over naturalistic stimuli in targeting more specific linguistic phenomena.</p>
<p>(2) The study combines fMRI data with behavioral similarity ratings and a variety of language models (static, transformers, graph-based models).</p>
<p>Weaknesses:</p>
<p>(1) The stimuli are not fully controlled for lexical content across conditions. Residual lexical differences between sentences could still influence both brain and model similarity patterns. To more cleanly isolate syntactic effects, it would be useful to systematically vary only a single structural element while keeping all other lexical content constant (e.g., the boy kicked the ball / the ball kicked the boy). It would be better to engage more with the minimal pair paradigm, which is widely used in large language model probing research.</p>
<p>(2) The comparisons are done across fundamentally different model types, including static embeddings, graph-based parsers, and transformers. The inherent differences in dimensionality and training objectives might make the conclusion drawn from RSA inconclusive. Transformer embeddings typically occupy much higher-dimensional, anisotropic representational spaces, and their similarity structure may reflect richer, more heterogeneous information than models explicitly encoding semantic roles. A lower RSA correlation in this study does not necessarily imply that transformers fail to encode syntactic information; rather, they may represent additional aspects of meaning or context that diverge from the narrow structural contrasts probed here.</p>
<p>(3) The interpretation of the RSA correlation largely depends on the understanding of models. The authors suggest that because hybrid models correlate better than transformers, this implies that transformers are inferior at representing syntax. However, this is not a direct test of syntactic ability. Transformers may encode syntactic information, but it may not be expressed in a way that aligns with the RSA paradigm or the chosen stimuli. RSA does not reveal what the model encodes, and the models might achieve a good correlation for non-syntactic reasons (e.g., length of sentence, orthographic similarity, lexical features).</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108442.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Large Language Models have revolutionized Artificial Intelligence and can now match or surpass human language abilities on many tasks. This has fueled interest in cognitive neuroscience in exposing representational similarities between Language Models and brain recordings of language comprehension. The current study breaks from this mold by: (1) Systematically identifying sentence structures for which brain and Large Language Model representations diverge. (2) Demonstrating that brain representations for these sentences can be better accounted for by a model structured by the semantic roles of words in the sentence. As such, the study may now fuel interest in characterizing how Large Language Models and brain representations differ, which may prompt new, more brain-like language models.</p>
<p>Strengths:</p>
<p>(1) This study presents a bold and solid challenge to a literature trend that has touted similarities between Transformer models and human cognition based on representational correlations with brain activity. This challenge is substantiated by identifying sentences for which brain and model representations of sentences diverge and explaining those divergences using models structured by semantic roles/syntax.</p>
<p>(2) This study conducts a rigorous pre-registered analysis of a comprehensive selection of the state-of-the-art Large Language Models, on a controlled sentence comprehension fMRI dataset. The analysis is conducted within a Representation Similarity framework to support similarity comparisons between graph structures and brain activity without needing to vectorize graphs. Transformer models are predicted and shown to diverge from brain representations on subsets of sentences with similar word-level content but different sentence structures.</p>
<p>(3) The study introduces a 7T fMRI sentence comprehension dataset and accompanying human sentence similarity ratings, which may be a fruitful resource for developing more human-like language models. Unlike other model-based sentence datasets, the relation between grammatical structure and word-level content is controlled, and subsets of sentences for which models and brains diverge are identified.</p>
<p>Weaknesses:</p>
<p>(1) The interpretation of findings is nuanced. Although Transformers underperform as brain models on the critical subsets of controlled sentences, a Transformer outperforms all other models when evaluated on the union of all sentences when both word-level content and structure vary. Transformers also yield equivalent or better models of human behavioral data. Thus, although Transformers have demonstrable flaws as human models, which are pinpointed here, in the general case, (some) Transformers are more human-like than the other models considered.</p>
<p>(2) There may be confounds between the critical sentence structure manipulations and visual representations of sentence stimuli. This is inconvenient because activation in brain regions that process semantics tends to partially correlate with visual cortex representations, and computational models tend to reflect the number of words/tokens/elements in sentences. Although the study commendably controls for confounds associated with sentence length, there could still be residual effects that remain. For instance, the Graph model correlates most strongly with the visual cortex despite these sentence length controls.</p>
<p>(3) Sentence similarity computations are emphasized as the basis for unifying comparative analyses of graph structures and vector data. A strength of this approach is that correlation is not always the ideal similarity metric. However, a weakness is that similarity computations are not unified across models. This has practical consequences here because different similarity metrics applied to the same model produce positive or negative correlations with brain data.</p>
</body>
</sub-article>
<sub-article id="sa4" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108442.1.sa4</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Fodor</surname>
<given-names>James</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7159-1413</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Murawski</surname>
<given-names>Carsten</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1237-9535</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Suzuki</surname>
<given-names>Shinsuke</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9816-9423</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>We thank the reviewers for their insightful comments on our manuscript. Here we briefly highlight our responses to several issues raised by reviewers, and also provide a summary of planned changes to be made with the next draft.</p>
<p><bold>Reviewer 1:</bold></p>
<p>(1) The reviewer questions the rationale for averaging sentence embeddings across different models. However, our method involves computing correlations separately for each model, then averaging the correlations. We also report model correlations for each model separately in Fig S2. We will clarify this in our revised manuscript.</p>
<p>(2) We agree with the reviewer that including a context-free grammar model as a comparison would be informative. We will incorporate this in the revised manuscript.</p>
<p>(3) The reviewer raises questions about the low correlation between behavioural and brain similarities. While the behavioural judgements are made by different participants and involve a different task than the neuroimaging results, nonetheless we agree the difference is surprising and warrants more detailed consideration. We will provide additional discussion of the relationship between behavioural judgements and brain data in the revised manuscript.</p>
<p>(4) The reviewer suggests contrasting our models with a ‘semantic ground truth’, as in our design matrix shown in Fig 1. While our design matrix served as the basis for constructing a set of stimuli with systematic modifications, we respectfully suggest that it should not be regarded as a ‘semantic ground truth’. In particular, sentence pairs within each category will not have the same degrees of semantic similarity since the words and context differ across sentences in a graded manner. Furthermore, while we anticipated ‘different’ sentence pairs would be less similar than ‘swapped’ sentence pairs, and that within each of the six block diagonals the ‘modified’ or ‘substituted’ sentence pairs would be the most similar, we did not have any prediction about the magnitude of these differences. Our goal was to construct a set of sentence pairs which spanned a range of semantic similarities, and allowed for dissociation between lexical similarity and overall similarity in meaning. The design matrix is not intended to represent a ‘ground truth’ that human judgements or brain representations would be expected to conform with.</p>
<p>(5) In the revised draft we will modify the location of Fig. 5 so that it flows better with the text.</p>
<p>(6) We agree that the discussion of the differences between brain regions could be expanded. We will include this in the revised version of our manuscript. The reviewer questions our inclusion of the simple-average and group-average RSA analysis as they show similar results. We included both analyses in line with our preregistration, and also because we believe the fact that two distinct approaches to analyzing the data yield similar results strengthens our conclusions.</p>
<p>(7) We believe that the grid-like pattern in the RSA results is an important unexpected finding that warrants discussion in the main manuscript.</p>
<p><bold>Reviewer 2:</bold></p>
<p>(1) The reviewer argues that our stimuli do not fully control for lexical content across conditions, and that a more appropriate paradigm may be to utilise minimal pairs in which only a single variable of interest (such as sentence structure) is modified. We agree that most of our sentence pairs do not constitute minimal pairs, however this was not our objective. Our study design aimed to synthesise traditional minimal pair approaches with more recent research paradigms using naturalistic stimuli. As such, we selected stimuli which are more complex and contain more variable features than traditional minimal pair studies, but which also are tailored to highlight differences which are of particular theoretical interest. Because we are interested in comparing the effects of multiple sentence elements and semantic roles, a systematic pairwise comparison of minimal pairs is not necessarily optimal. Instead, we designed our stimuli to leverage the advantage of fMRI in that we can measure the brain representations corresponding to each sentence, and hence can conduct a full series of pairwise comparisons of sentence representations. Most of these comparisons will not be between minimal pairs, but we selected sentences so as to provide a range of semantic similarities (low to high), while also providing for semantic contrasts of theoretical interest (such as the ‘swapped’ and ‘substituted’ sentence pairs). We do not claim this approach to be universally superior to a minimal pair approach, but we do believe our novel approach provides additional insights and a new perspective on semantic representation relative to minimal pair studies. We will add additional detail in the revised manuscript providing additional explanation for how stimuli were chosen, and contrasting this with minimal pair approaches.</p>
<p>(2) The reviewer notes that low RSA correlations do not imply that transformers fail to encode syntactic information. We acknowledge this in our discussion (page 10), where we also highlight that our focus is not on whether transformers encode such information, but rather what transformer representations can tell us about how sentence structure is represented in the brain. Our results indicate that transformer embeddings do not have the same geometric properties as brain representations of sentence meaning, at least for certain types of sentences where lexical information is insufficient to determine overall meaning. The reviewer also notes that transformer embeddings are highly anisotropic, however we adjust for this by normalising each feature as discussed on page 14. Finally, the reviewer notes that the transformers we examine differ in architecture and training objectives. This is not critical for our study because we are not seeking to determine which architecture or training objectives are best. Our goal is simply to compare a range of approaches and see which, if any, have similar sentence representations to those formed by the brain. In fact, our results indicate that architecture and training regime make relatively little difference for our stimuli.</p>
<p>(3) The reviewer argues that RSA correlations do not measure the extent to which a model encodes syntactic information. This is very similar to the previous point. We do not claim that our results show that transformers do not encode syntactic information. Rather, our claim is that sentence embeddings derived from transformers have different geometric properties to brain representations, and that brain representations are better described by models explicitly representing key semantic roles. From this we conclude that, at least for the sentences we present, the brain is highly sensitive to semantic roles in a way that transformer representations are not (at least to the same extent). We also respectfully disagree with the reviewer’s suggestions that sentence length and orthographic or lexical similarities may drive model correlations with brain activity. As we discuss on page 19, we explicitly control for differences in sentence length when computing correlations. Our process for constructing our sentence set also controls for lexical similarity by generating pairs of sentences with all or mostly the same words but different orderings. We did not explicitly address orthographic similarity, but this will be strongly correlated with lexical similarity.</p>
<p><bold>Reviewer 3:</bold></p>
<p>(1) The reviewer emphasises the need for nuance in our conclusions, given that some of the transformers achieve higher correlations when assessed over the full set of sentences. We agree with this comment, and will modify the discussion section in the revised manuscript to address this point. Having said that, we would like to note one of the disadvantages of transformers as a model of mind or brain representations is that they are largely a ‘black box’ whose workings are poorly understood. One advantage of hybrid models like our simple semantic role model is that they can be much easier to interpret, thereby enabling them to be used to determine which features are most important for brain representations of sentence meaning, and what mechanisms are used to combine individual words into a full sentence. Given their relative simplicity and interpretability, we believe hybrid models have considerable value as scientific tools, even in cases where they achieve comparable correlations to transformers. We will highlight this issue more clearly in our revised manuscript.</p>
<p>(2) The reviewer notes that despite our existing controls, residual confounds of sentence length may remain. We agree that this is a potential issue, and will add discussion to the revised manuscript. We also will present further supplementary analyses which we believe indicate that sentence length effects do not drive our main results. At the same time, we believe the fact that our results are robust to simultaneously controlling for sentence length and the ‘minimum length effect’ (Fig. S5) indicates they are not primarily driven by sentence length effects.</p>
<p>(3) The reviewer notes that the method for computing similarities differs between the vector-based (mean and transformer) models, and the hybrid and syntax-based models, thereby potentially adding an additional confound to our results. We agree that this is a potential limitation, and our correlations should always be understood as applying to a model paired with a similarity metric. However, we believe that this is mostly unavoidable when comparing different formalisms. An alterative approach of first embedding a graph into a vector and then training an encoding model on the graph embeddings has a similar limitation of being dependent not just on the graph representation, but also on the way it was embedded into a vector and the way the encoding model was trained. Arguably this process is more opaque than similarity methods, since it is unclear to what extent the graph embeddings preserve the logic and properties of a graph-based representation. Further, it not clear whether there is any single method which can overcome the difficulty of comparing distinct formalisms for representing semantics. The reviewer also highlights how the correlations measured for the syntax model differ greatly depending on whether the Smatch or WWLK similarity metrics are used. We believe this highlights the need for careful examination of commonly used graph similarity metrics, as has been noted in previous research. We will include additional discussion of this issue in our revised manuscript.</p>
</body>
</sub-article>
</article>