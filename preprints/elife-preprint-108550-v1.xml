<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">108550</article-id>
<article-id pub-id-type="doi">10.7554/eLife.108550</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.108550.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Distinct cortical encoding of acoustic and electrical cochlear stimulation</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Hight</surname>
<given-names>Ariel Edward</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Insanally</surname>
<given-names>Michele N</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="aff" rid="a9">9</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Scarpa</surname>
<given-names>Julia K</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Cheng</surname>
<given-names>Yew-Song</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Trumpis</surname>
<given-names>Michael</given-names>
</name>
<xref ref-type="aff" rid="a5">5</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Viventi</surname>
<given-names>Jonathan</given-names>
</name>
<xref ref-type="aff" rid="a5">5</xref>
<xref ref-type="aff" rid="a6">6</xref>
<xref ref-type="aff" rid="a7">7</xref>
<xref ref-type="aff" rid="a8">8</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Svirsky</surname>
<given-names>Mario A</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
    <email>mario.svirsky@med.nyu.edu</email>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1230-6811</contrib-id>
<name>
<surname>Froemke</surname>
<given-names>Robert C</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<email>robert.froemke@med.nyu.edu</email>
</contrib>
    <aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0190ak572</institution-id><institution>Translational Neuroscience Institute, New York University Grossman School of Medicine</institution></institution-wrap>, <city>New York</city>, <country country="US">United States</country></aff>
    <aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0190ak572</institution-id><institution>Department of Otolaryngology-Head and Neck Surgery, New York University Grossman School of Medicine</institution></institution-wrap>, <city>New York</city>, <country country="US">United States</country></aff>
    <aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0190ak572</institution-id><institution>Department of Neuroscience, New York University Grossman School of Medicine</institution></institution-wrap>, <city>New York</city>, <country country="US">United States</country></aff>
    <aff id="a4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01an3r305</institution-id><institution>Department of Otolaryngology, University of Pittsburgh School of Medicine</institution></institution-wrap>, <city>Pittsburgh</city>, <country country="US">United States</country></aff>
<aff id="a5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00py81415</institution-id><institution>Department of Biomedical Engineering, Duke University</institution></institution-wrap>, <city>Durham</city>, <country country="US">United States</country></aff>
<aff id="a6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00py81415</institution-id><institution>Department of Neurobiology, Duke University School of Medicine</institution></institution-wrap>, <city>Durham</city>, <country country="US">United States</country></aff>
<aff id="a7"><label>7</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00py81415</institution-id><institution>Department of Neurosurgery, Duke University School of Medicine</institution></institution-wrap>, <city>Durham</city>, <country country="US">United States</country></aff>
<aff id="a8"><label>8</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00py81415</institution-id><institution>Department of Neurology, Duke University School of Medicine</institution></institution-wrap>, <city>Durham</city>, <country country="US">United States</country></aff>
    <aff id="a9"><label>9</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01an3r305</institution-id><institution>Department of Neurobiology, University of Pittsburgh School of Medicine</institution></institution-wrap>, <city>Pittsburgh</city>, <country country="US">United States</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Bathellier</surname>
<given-names>Brice</given-names>
</name>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-9211-1960</contrib-id><role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/00675rp98</institution-id><institution>Centre National pour la Recherche Scientifique et Technique (CNRST)</institution>
</institution-wrap>
<city>Paris</city>
<country>France</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Colgin</surname>
<given-names>Laura L</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Texas at Austin</institution>
</institution-wrap>
<city>Austin</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-10-13">
<day>13</day>
<month>10</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP108550</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-08-01">
<day>01</day>
<month>08</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-08-01">
<day>01</day>
<month>08</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.08.01.668170"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Hight et al</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Hight et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-108550-v1.pdf"/>
<abstract>
<title>Abstract</title><p>Cochlear implants are neuroprosthetic devices that restore hearing and speech comprehension to profoundly deaf humans, and represent an exemplar application of biomedical engineering and research to clinical conditions. However, the utility of these devices in many subjects is limited, largely due to lack of information about how neural circuits respond to implant stimulation. Recently we showed that deafened rats can use cochlear implants to recognize sounds, and that this training refined the responses of single neurons in the primary auditory cortex. Here we asked how local populations of cortical neurons represent acute implant stimuli, using electrode arrays we developed for cortical surface recordings for micro-electrocorticography (µECoG), a form of intracranial electroencephalography (iEEG). We found that there was a limited tonotopic organization across recording sites, relative to a clearer tonotopic spatial representation in normal-hearing rats. Single-trial iEEG responses to acoustic inputs were more reliable than responses to cochlear implant stimulation, although stimulus identity could be successfully decoded in both cases. However, the spatio-temporal response profiles to acoustic vs cochlear implant stimulation were substantially different. Decoders trained on acoustic responses showed essentially zero information transfer when tested on electrical stimulation responses in the same animals after deafening and cochlear implant stimulation. Thus while acute cochlear implant stimulation might activate the auditory cortex in a cochleotopic manner, the dynamics of network activity are quite distinct, suggesting that pitch percepts from acoustic and electrical stimulation are fundamentally different.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>

</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Cochlear implants are neuroprosthetic devices that restore hearing and provides users with an ability to attain open-set speech perception without other aids such as lip-reading (<xref ref-type="bibr" rid="c16">Djourno and Eyries, 1957</xref>; <xref ref-type="bibr" rid="c52">Simmons et al., 1965</xref>; <xref ref-type="bibr" rid="c45">Michelson, 1971</xref>; <xref ref-type="bibr" rid="c28">House and Urban, 1973</xref>; <xref ref-type="bibr" rid="c17">Eddington et al., 1978</xref>; <xref ref-type="bibr" rid="c25">Hochmair and Hochmair-Desoyer, 1981</xref>; <xref ref-type="bibr" rid="c61">Wilson et al., 1991</xref>; <xref ref-type="bibr" rid="c12">Clark, 2006</xref>; <xref ref-type="bibr" rid="c54">Svirsky, 2017</xref>). Cochlear implants function by inserting a single and flexible shank of electrodes along the cochlear spiral (generally 12-22 channels in human subjects), to stimulate primary afferent neurons of the auditory system and bypass pathologies of deafness. Individual electrodes deliver trains of electrical pulses, providing spectral cues as a function of location along the topographical axis of the cochlear spiral, mimicking the encoding of sound in a functional and healthy cochlea. Over 1 million users have been implanted world-wide, making it the most widely adopted type of brain-computer interface, surpassing vagus nerve stimulators, deep-brain stimulation electrodes, and artificial retinas (<xref ref-type="bibr" rid="c24">Hays et al., 2013</xref>; <xref ref-type="bibr" rid="c15">Dawson et al., 2016</xref>; <xref ref-type="bibr" rid="c2">Ayton et al., 2020</xref>; <xref ref-type="bibr" rid="c64">Zeng, 2022</xref>; <xref ref-type="bibr" rid="c33">Johnson et al., 2024</xref>). Cochlear implants are thus the gold-standard for neuroprosthetic device use in terms of performance, safety, and ability to fine-tune or personalize the programming of each device to individual users.</p>
<p>Despite their wide adoption in human subjects over the last several decades, there is limited understanding of how these devices restore functionality and the sense of hearing to users. One long-standing question has been how the central auditory system responds to and interprets signals resulting from electrical stimulation of auditory nerve fibers. It is unknown to what degree emulating the patterns evoked by acoustic stimulation in normal hearing users is important for auditory perception. Many structures of the central auditory system are organized tonotopically, following the frequency alignment of the cochlear basilar membrane (<xref ref-type="bibr" rid="c59">Walzl and Woolsey, 1946</xref>; <xref ref-type="bibr" rid="c43">Merzenich et al., 1973</xref>; <xref ref-type="bibr" rid="c50">Polley et al., 2007</xref>). This topographic mapping might facilitate the encoding of auditory stimuli. While previous studies have demonstrated cochleotopic organization in auditory cortex of cochlear implant animals (<xref ref-type="bibr" rid="c6">Bierer and Middlebrooks, 2002</xref>; <xref ref-type="bibr" rid="c34">Johnson et al., 2016</xref>), a fundamental question remains unanswered: does electrical stimulation of specific cochlear locations elicit the same cortical representations and perceptual qualities as acoustic stimulation of corresponding frequencies? The spatiotemporal dynamics of these representations and how they relate to acoustic processing in normal hearing individuals remain unclear. Previous psychophysical studies in human implant users have provided indirect evidence for perceptual differences (<xref ref-type="bibr" rid="c42">McDermott, 2004</xref>) and similarities (<xref ref-type="bibr" rid="c57">Vermeire et al., 2013</xref>), but direct neural evidence comparing representations in the same subjects has been lacking. This question has profound implications for how we design and program cochlear implants, or more generally other brain- computer interface devices.</p>
<p>Studies in non-human animals are required to understand the neural basis of cochlear implant use and the relation to spatiotemporal representations in the auditory system. Responses to cochlear implant stimulation have been studied in a number of species generally in non-behaving animals under anesthesia (<xref ref-type="bibr" rid="c37">Klinke et al., 1999</xref>; <xref ref-type="bibr" rid="c6">Bierer and Middlebrooks, 2002</xref>; <xref ref-type="bibr" rid="c46">Middlebrooks and Bierer, 2002</xref>; <xref ref-type="bibr" rid="c18">Fallon et al., 2014</xref>; <xref ref-type="bibr" rid="c34">Johnson et al., 2016</xref>), but occasionally in awake or behaving animals (<xref ref-type="bibr" rid="c58">Vollmer and Beitel, 2011</xref>; <xref ref-type="bibr" rid="c35">Keating et al., 2013</xref>; <xref ref-type="bibr" rid="c34">Johnson et al., 2016</xref>). Over the last decade we have examined cochlear implant responses in deafened rats (<xref ref-type="bibr" rid="c36">King et al., 2016</xref>; <xref ref-type="bibr" rid="c23">Glennon et al., 2019</xref>), where we showed that animals can be trained to report the activation of specific implant channels. Behavioral training with the cochlear implant led to substantial plasticity within the deafened rat auditory cortex, modifying synaptic receptive fields and adjusting excitatory-inhibitory balance at the level of single neurons. Prior to training, the responses of single cells to implant stimulation were erratic and inhibition was mismatched relative to excitation. After training, inhibition became aligned with excitation across the array of implant electrode channels (<xref ref-type="bibr" rid="c22">Glennon et al., 2023</xref>). However, intracellular recording in vivo is infeasible in human subjects. Thus other approaches more amenable to clinical use are required, to measure neural coding of cochlear implant signals and enable translation of results from non-human studies to improve implant performance by human subjects.</p>
<p>Here we aimed to determine the spatiotemporal representations of implant channels beyond the responses of single neurons, but instead across a broader extent of rat auditory cortex. We take advantage of improvements in micro-electrocorticography (µECoG), a sub-type of intracranial electroencephalography (iEEG) that generally uses grid electrodes placed epi- or sub-durally over the cortical surface to measure local electrical activity (<xref ref-type="bibr" rid="c29">Insanally et al., 2016</xref>; <xref ref-type="bibr" rid="c63">Woods et al. 2018</xref>). iEEG recordings have high temporal precision, greatly improved signal-noise ratios, and better spatial resolution than conventional scalp EEG recordings (<xref ref-type="bibr" rid="c1">Abdi-Sargezeh et al., 2023</xref>; <xref ref-type="bibr" rid="c31">Janiukstyte et al., 2023</xref>). Signals reflect local electrical fields generated by aggregate neural activity in the regions adjacent to recording sites (<xref ref-type="bibr" rid="c32">Jasper and Penfield, 1949</xref>; <xref ref-type="bibr" rid="c11">Chang, 2015</xref>; <xref ref-type="bibr" rid="c20">Fukushima et al., 2015</xref>). iEEG has been used for studies of human brain organization particularly of speech and language centers, but these recordings are necessarily done in epileptic subjects to help locate seizure foci before surgical resection (<xref ref-type="bibr" rid="c49">Nourski et al., 2013</xref>; <xref ref-type="bibr" rid="c44">Mesgarani et al., 2014</xref>; <xref ref-type="bibr" rid="c55">Tang et al., 2017</xref>; <xref ref-type="bibr" rid="c5">Beynon et al., 2021</xref>; <xref ref-type="bibr" rid="c48">Norman-Haignere et al., 2022</xref>). Non-human animal studies remain essential for determining how sensory inputs are represented and processed in subjects without overt neurological conditions. To this end have designed and manufactured a novel and flexible 60-channel cortical surface iEEG array for adult rats, and validated that we can measure auditory responses and cortical map topography in normal hearing animals with these arrays (<xref ref-type="bibr" rid="c29">Insanally et al., 2016</xref>; <xref ref-type="bibr" rid="c56">Trumpis et al., 2017</xref>; <xref ref-type="bibr" rid="c63">Woods et al. 2018</xref>). Using these custom-fabricated iEEG grid electrodes, we now ask how auditory cortex responds to implant stimulation in untrained or trained deafened adult rats, and how different evoked signals and/or mesoscale tonotopic organization is in cochlear implant users vs normal-hearing animals.</p>
</sec>
<sec id="s2">
<title>Materials and Methods</title>
<sec id="s2a">
<title>Surgical procedure for iEEG recordings</title>
<p>All animal procedures were performed in accordance with National Institutes of Health standards and were conducted under a protocol approved by the NYU Grossman School of Medicine Institutional Animal Care and Use Committee. We used a custom array consisting of 61 passive electrodes spaced 406 μm apart in an 8 x 8 grid, with three corner electrodes omitted and the fourth corner electrode intentionally unexposed to test encapsulation, reducing the number of active recorded sites to 60 (<xref ref-type="bibr" rid="c29">Insanally et al., 2016</xref>). iEEG grids were fabricated using a standard flex-PCB processing technique by Microconnex Flex Circuits (Snoqualmie, WA). All procedures and experiments were carried out in a sound- attenuation chamber.</p>
<p>A specific surgical protocol was developed for implantation of cortical surface iEEG in rats. Sprague-Dawley rats 4–6 months old were anesthetized with ketamine (40 mg kg−1, intramuscular injection) and dexmedetomidine (0.125 mg kg−1, intramuscular injection), or pentobarbital (50 mg kg−1, intraperitoneal injection). The head was secured in a custom head-holder that left the ears unobstructed. A longitudinal incision was made along the midline to expose the skull. Five bone screws were inserted into the skull around the point of entry of the electrode array to help anchor the dental cement (C &amp; B Metabond Quick! Luting Cement). After reflecting the right temporalis muscle, a 5 mm × 5 mm craniotomy was made on the right temporal skull to expose the brain, and a sterilized iEEG array was epidurally placed over the left hemisphere core auditory cortex, located using vasculature landmarks. A thin silver wire was soldered between the headstage and the skull screws to be used as ground and reference.</p>
</sec>
<sec id="s2b">
<title>Surgical procedure unilateral cochlear implantation of the right ear</title>
<p>Cochlear implantation procedures are similar to our past studies (<xref ref-type="bibr" rid="c36">King et al., 2016</xref>; <xref ref-type="bibr" rid="c22">Glennon et al., 2023</xref>). 8-channel animal cochlear implant arrays (HL08) were provided by Cochlear Americas. The array contained platinum-iridium band electrodes coated in silastic and connected to a nine-pin Nanonics connector (TE Connectivity, Berwyn, PA) with a single, additional extracochlear ball ground. The ipsilateral pinna was pulled forward and secured with a hemostat, the head rotated laterally, and the post-auricular junction between the ear canal and the sternocleidomastoid muscle (SCM) is identified as the initial incision site. An incision was made and the superficial fascia of the neck was dissected to identify the facial nerve i.e., cranial nerve (CN) VII. Minor bleeding was controlled using hemostatic epinephrine-soaked cotton pellets (Epidri pellets; Pascal International, Bellevue, WA), applied with light pressure. The SCM and posterior belly of the digastric muscle (PBD) were dissected from the tympanic bulla (TB) ventral and rostral to the trunk of CN VII. The TB was cleared of muscle and periosteum; the periosteum of the bulla was kept in normal saline and used later to seal the cochleostomy site. The drilling of the TB was begun ventrorostral to the trunk of CN VII with a 0.5 mm diamond burr and continued dorsally with care taken to avoid injuring CN VII, until the SA overlying the RW was fully visualized. Any remaining tissue or debris was removed with microforceps before the cochleostomy was performed.</p>
<p>Prior to performing the cochleostomy and inserting the array, the array lead and connector were secured. The post-auricular incision was expanded dorsally toward the skull. An area 4-5 mm in diameter was cleared and cleaned to expose the occipital skull, and the connector was attached perpendicular to the skull using C&amp;B-Metabond (Parkell, Edgewood, NY) and bone screws. The lead to the electrode array was then sutured to the trapezius muscle, allowing enough lead to remain free to facilitate motion required for array insertion. The lead to the separate ground electrode was similarly secured into small muscle pockets in the trapezius. The cochleostomy site was identified ∼0.5 mm directly below the lip of the RW in the basal turn of the cochlea, identified by both the stapedial artery and the cochlear promontory in the tympanic space. The site was gently drilled with a 0.1 mm diamond burr, and the array was inserted into the scala tympani without resistance using AOS forceps (Cochlear, Sydney, Australia) until all of the platinum-iridium contacts were within the scala tympani. The array occludes most, if not all, of the drill site, but to minimize postsurgical perilymphatic leak strips of periosteum taken from the bulla were placed around the implant to seal the site, followed by application of high-grade cyanoacrylate (Surgi-lock 2oc; Meridian Animal Health, Omaha, NE). The remaining lead was cemented into the bulla with C&amp;B-Metabond (Parkell). Before closure, a small square of gelfoam with dexamethasone was left on the root of the facial nerve to prevent inflammation and heal any minor damage that may have occurred.</p>
</sec>
<sec id="s2c">
<title>Bilateral sensorineural hearing loss</title>
<p>The deafening procedure was identical to the cochlear implantation procedure, with the exception of the array being removed before closure. Following both array and gelfoam removal, the cochleostomy site was closed with a trapezius muscle or periosteum graft, followed by 2-octyl cyanoacrylate (i.e., the array is removed from the cochlea). Both ears were deafened in this manner, but a functional array remained in the right ear for acute electrical stimulation.</p>
</sec>
<sec id="s2d">
<title>Behavioral training for tone and implant channel detection</title>
<p>Four animals with iEEG recording electrodes were behaviorally trained to detect target tones. Rats were food restricted and trained on a self-initiated, auditory go/no-go task (<xref ref-type="bibr" rid="c19">Froemke et al., 2013</xref>; <xref ref-type="bibr" rid="c41">Martins and Froemke, 2015</xref>; <xref ref-type="bibr" rid="c36">King et al., 2016</xref>). Animals nosepoked in a designated port to initiate trials and are trained to nosepoke in a different port if the target tone was presented (4 or 22.6 kHz, any intensity) or withhold from nosepoking if a nontarget (foil) tone was presented (0.5-32 kHz excluding 4 kHz if 4 kHz was the target, or 8-45.3 kHz excluding 22.6 kHz if 22.6 kHz was the target, at 0.5-1 octave intervals and at any intensity). A sugar pellet reward was given for correct nosepokes within 2.5 s of target-tone presentation, whereas a 7 s timeout was given if the animal incorrectly nosepoked for foil tones. The four rats that achieved &gt;70% target-tone hit rate and d’ ≥1.7 were included for further testing and implantation. A second subset of animals was behaviorally trained to detect cochlear implant channels; procedures were the same for tones except that a programmable clinical cochlear implant processor was used.</p>
</sec>
<sec id="s2e">
<title>Stimulus presentation for cortical sensory mapping in normal hearing rats</title>
<p>Tone presentation was similar to our previous study of iEEG responses in normal-hearing rats (<xref ref-type="bibr" rid="c29">Insanally et al., 2016</xref>). Pure tones from 0.5-32 kHz (0.5-1.0 octave spacing) were generated using an auditory processor (TDT System III RZ6) and presented at a pseudorandom sequence at a rate of 1.25 Hz to the contralateral (right) ear using a calibrated free-field speaker (MF1 Multi-Field Magnetic Speaker, Tucker-Davis Technologies). Each tone was repeated 30 times at 70 dB SPL. The calibrated speaker exhibited &lt;1% harmonic distortion and a flat output in the frequency range used.</p>
</sec>
<sec id="s2f">
<title>Stimulus presentation for cortical sensory mapping in cochlear implanted rats</title>
<p>Electrical stimulation was delivered by an off-the-shelf Nucleus Freedom system speech processor (Cochlear) in which its transmitter coil drove a CI24RE implant emulator, where its output was connected to the implanted electrodes. The implant emulator is a standard clinical cochlear implant that is mounted in a plastic box with a DB-25 connector (Cochlear). We created a pigtail wire with a DB-25 connector and an Omnetics/Nanonics connector (Omnetics/TE Connectivity) to couple the emulator to the skull-anchored connector. The skull-anchored connector is also an Omnetics/Nanonics connector that is directly attached to the implanted array. For about half of tested animals (N=3), electrodes were activated through the microphone of the speech processor via tones presented to each individual electrode’s frequency allocation. The remaining cochlear implanted animals (N=4) were stimulated directly; the CI24RE implant emulator was driven by a Freedom system speech processor connected through the Freedom Programming Pod to a personal computer running the Custom Sound EP software (Cochlear). The Custom Sound EABR function was used (5 charge-balanced biphasic pulses, 25 µs/phase, 900 Hz stimulation frequency) to program and deliver stimuli to the implant.</p>
</sec>
<sec id="s2g">
<title>Cochlear implant programming</title>
<p>Impedance and threshold measurements were obtained intraoperatively using Custom Sound EP (Cochlear) and were used for the initial programming of the sound processor. The ECAP thresholds were obtained and used to set the maximum stimulation level and the minimum stimulation level was set to 30 ‘clinical units’ below the maximum level, equivalent to 4.7 dB in the CI24RE implant emulator (<xref ref-type="bibr" rid="c3">Azadpour and McKay, 2012</xref>). All additional settings typically deployed in a clinical setting, such as ADRO, were turned off (Custom Sound, clinical programming software for Nucleus Freedom).</p>
</sec>
<sec id="s2h">
<title>Processing of cortical iEEG recordings</title>
<p>All signal processing and analyses were performed using custom MATLAB scripts (MathWorks, MA). To determine whether trials were functional or contained artifacts, raw measurements were first filtered (2-150 Hz, 6<sup>th</sup> order bandpass IIR filter) and then root mean squared power (rms) was computed for each channel. All trials with rms 20- 300 µV were considered functional; power less than 20 µV corresponded with pre-amplifier saturation, while power greater than 300 µV consistently indicated intermittent corruption from non-neural sources. To then process functional recordings, we first used a notch filter to remove 60 Hz noise and 90, 120, 180 Hz harmonics. Recorded signals were then downsampled from 20 to 2 kHz using the decimate function (MATLAB), performing also the function of low-pass (anti-alias) filter and thereby rejecting any artifacts resulting from electrical stimulation delivered by cochlear implant electrodes.</p>
<p>Event-related potentials (ERPs) were extracted from raw downsampled recordings by further bandpass filtering (2-100 Hz) using a digital zero-order 6<sup>th</sup> order Butterworth filter. Magnitudes of evoked ERP transients were measured by first rectifying measurements using the MATLAB abs() function and then subtracting the maximum of the baseline amplitude in the 50 ms pre-stimulus period (averaged over ±1 timestep) from the maximum of evoked amplitude in the 50 ms post-stimulus period (also averaged across three trials).</p>
<p>High gamma responses were extracted from raw downsampled recordings by further bandpass filtering (70-140 Hz) using a digital zero-order 6<sup>rd</sup> order Butterworth filter. Next, signals were rectified and smoothed with a 20 ms sliding window. Resulting signals that exceeded 5 times the 90<sup>th</sup> percentile were interpolated. Evoked high gamma magnitudes were extracted as for ERPs.</p>
</sec>
<sec id="s2i">
<title>Estimation of best frequency</title>
<p>All analyses of tone-evoked responses were restricted to the range of 1.4-32 kHz tones. Best frequency was estimated by computing the center of mass of tone-evoked responses at 70 dB SPL. The response mass function was defined by the mean vector after projecting all responses on a circular domain where vector angles are represented by tone frequencies, to prevent biasing the center of mass towards the interior of the 1.4-32 kHz stimulus range.</p>
</sec>
<sec id="s2j">
<title>Principal component analysis (PCA)</title>
<p>Evoked responses were analyzed by including both temporal (i.e., <italic>R</italic> post-stimulus responses) and spatial (i.e., <italic>S</italic> responsive sites) variables. These measurements were concatenated across individual trials, <italic>T</italic>, to create a 2-dimensional <italic>T</italic> (rows) x <italic>R</italic>-<italic>S</italic> (columns) matrices. PCA was then performed and <italic>R</italic>-<italic>S</italic> vectors were compressed using singular value decomposition to obtain a reduced-rank approximation of the original matrix. PCA was also performed on variations of our data including only spatial <italic>P</italic> values (i.e., including only evoked magnitudes) or only temporal <italic>R</italic> values (i.e., averaging responses across all recording sites). The top 15 ranked projections were preserved for further analysis, reducing the datasets into a <italic>T</italic> (rows) x 15 (column) matrix.</p>
</sec>
<sec id="s2k">
<title>Tensor component analysis (TCA)</title>
<p>We applied a canonical polyadic (CP) decomposition to a 3-dimensional model, enabling us to treating spatial and temporal aspects of iEEG recordings across multiple trials as linear independent (orthogonal) dimensions (<xref ref-type="bibr" rid="c38">Kolda and Bader, 2009</xref>; <xref ref-type="bibr" rid="c60">Williams et al., 2018</xref>). Naive feature vectors were constructed by arranging all data into a three-dimensional matrix composed of length-<italic>R</italic> post-stimulus responses, <italic>S</italic> responsive sites, and <italic>T</italic> stimulus trials resulting in a <italic>R</italic> x <italic>S</italic> x <italic>T</italic> matrix. CP decomposition was performed (<xref ref-type="bibr" rid="c4">Bader et al., 2023</xref>) for 15 latent factors, the number 15 chosen to exceed the number of tone or implant stimuli and to parallel the data reduction performed by PCA. Then the resulting estimate of the <italic>T</italic> factors for each of the 15 components reduced our datasets into <italic>T</italic> (rows) x 15 (column) matrices.</p>
</sec>
<sec id="s2l">
<title>Linear discriminant analysis (LDA)</title>
<p>We trained a decoder for predicting stimulus identity from single trial recordings by developing a supervised linear classifier. Each decoder was retrained and retested 1,000 times to average decoder performance across randomizations for combinations of trials used for training and test sets. Specifically, each bootstrap replicate was randomly partitioned to include 13 trials per stimulus for each training set and the remaining trials being used to test the decoder. LDA was applied to estimate the stimulus-likelihood map of the PCA- or TCA- compressed feature space. Naive feature vectors from the training set were normalized and compressed according to the learned transformations, and the maximum likelihood stimulus (i.e., the identity of the tone frequency or active cochlear implant electrode) was estimated for each response. Absolute accuracy of the decoder was computed as the average accuracy over all stimuli was estimated by the total proportion of correct predictions. In addition to absolute accuracy, we also computed the mean of the error distances between the predicted and actual stimulus, i.e., octaves or number of electrodes.</p>
</sec>
</sec>
<sec id="s3">
<title>Results</title>
<sec id="s3a">
<title>iEEG recordings in normal hearing and cochlear implanted rats</title>
<p>We had two main goals: 1) to determine which features of auditory cortex iEEG signals were most informative about stimulus identities; and 2) to use iEEG recordings to assess cortical coding of acoustic vs electrical stimuli in normal-hearing (NH) vs bilaterally deafened + unilaterally cochlear implanted (CI) rats. Animals were first anesthetized and then a craniotomy was performed to expose the primary auditory cortex. We implanted a custom 60-channel iEEG recording array (<xref ref-type="bibr" rid="c29">Insanally et al., 2016</xref>; <xref ref-type="bibr" rid="c56">Trumpis et al., 2017</xref>) over primary auditory cortex. Seven rats were normal- hearing and presented with acoustic pure-tone stimuli (<xref rid="fig1" ref-type="fig">Fig 1A</xref>, ‘NH’). Seven rats were bilaterally deafened via cochleostomy before receiving a unilateral cochlear implant (<xref rid="fig1" ref-type="fig">Fig. 1B</xref>, ‘CI’).</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Auditory cortex iEEG responses to pure tone stimuli in normal-hearing and deafened cochlear implant rats.</title><p><bold>A</bold>, Schematic of 60-channel cortical surface electrode arrays, covering 3.25 x 3.25 mm on the surface of auditory cortex to record tone-evoked responses in normal hearing (NH) trained rats.</p><p><bold>B</bold>, Some animals were bilaterally deafened and fitted with a unilateral cochlear implant (CI).</p><p><bold>C</bold>, Behavioral training of subset of animals on auditory go/no-go frequency recognition task. Animals were first trained when normal-hearing (NH, N=4, d’: 2.9±0.1) and then re-trained to respond to cochlear implant stimulation (CI, N=3, d’: 0.9±0.2).</p><p><bold>D</bold>, Examples of trial-averaged single-site iEEG responses (top, ERPs; middle, ERP spectrograms; bottom, HG). Clear transients were evoked by tones in normal-hearing animals (NH, left column) and in cochlear implant rats (CI, right column).</p><p><bold>E</bold>, iEEG response magnitude was similar between normal-hearing (NH, ERP amplitude: 1.9±0.1 µV; HG amplitude: 0.6±0.1 a.u.) and cochlear-implant rats (CI, ERP amplitude: 2.0±0.2 µV, p=0.43 compared to normal-hearing ERPs, Student’s paired two-tailed t-test; HG amplitude: 0.6±0.1 a.u., p=0.33 compared to normal-hearing HG).</p></caption>
<graphic xlink:href="668170v1_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>A subset of these animals from each of the two groups (N=4 normal-hearing rats, N=3 cochlear implant rats) were trained on an auditory detection and recognition go/no-go task we have used previously, both for normal hearing (<xref ref-type="bibr" rid="c19">Froemke et al., 2013</xref>; <xref ref-type="bibr" rid="c9">Carcea et al., 2017</xref>; <xref ref-type="bibr" rid="c30">Insanally et al., 2024</xref>) and with cochlear implants (<xref ref-type="bibr" rid="c36">King et al., 2016</xref>; <xref ref-type="bibr" rid="c22">Glennon et al., 2023</xref>). Normal-hearing rats each achieved high levels of performance, whereas the cochlear implant rats had more variable performance (<xref rid="fig1" ref-type="fig">Fig. 1C</xref>; normal-hearing behavioral performance d’: 2.9±0.1, cochlear implant performance: 0.9±0.2).</p>
<p>We acquired and then compared acute iEEG recordings of acoustic tone-evoked and electrical cochlear-implant-evoked responses in normal-hearing and cochlear implant rats. Raw responses were down-sampled and lowpass filtered to eliminate electrical artifacts from cochlear implant stimuli, and bandpass filtered again either to reveal slowly varying event-related potentials (ERPs, bandpass range: 2-100 Hz) or to reveal higher frequency high gamma oscillations (HG, bandpass range: 70-140 Hz) (<xref rid="fig1" ref-type="fig">Fig. 1D</xref>). Trial-averaged evoked responses were time-locked to the stimulus onset. Evoked response magnitudes were not measurably different between NH and CI rats (<xref rid="fig1" ref-type="fig">Fig. 1E</xref>). We found that the behavioral training (denoted purple in all figures) had no measured effect on our analyses of sensory encoding compared to responses measured in untrained rats (Student’s unpaired two-tailed t-test, p&gt;0.3 comparing normal hearing and cochlear implant signals in untrained vs trained rats).</p>
</sec>
<sec id="s3b">
<title>A1 encoding of tones and cochlear implant electrodes are spatially organized</title>
<p>iEEG recordings of tone-evoked responses are spatially restricted to areas across the recording array that appeared to shift as a function of tone frequency in normal-hearing animals (<xref rid="fig2" ref-type="fig">Fig. 2</xref>). Determining the best frequency at each recording site (i.e., the stimulus evoking the maximum response overall at that location) confirmed the general tonotopic organization of auditory cortex (<xref rid="fig2" ref-type="fig">Fig. 2A-E</xref>, ERPs; <xref rid="fig2" ref-type="fig">Fig. 2F-J</xref>, HG). Tone-evoked responses were similar in expected directions and gradients (<xref ref-type="bibr" rid="c50">Polley et al., 2007</xref>) indicating that iEEG measurements have the spatial resolution for testing whether evoked responses are cochleotopically organized.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Tone-evoked and cochlear implant-evoked iEEG measurements are spatially organized.</title>
<p><bold>A, F,</bold> Trial-averaged tone-evoked event-related potentials (ERPs, panel <bold>A</bold>) and high gamma (HG, panel <bold>F</bold>) were spatially restricted to regions along the iEEG recording array; these active regions shifted as a function of stimulus.</p><p><bold>B, G</bold>, Spatial correlations of evoked response areas decreased monotonically as a function of increasing stimulus separation. Evoked iEEG responses as assessed by ERPs and HG were nonrandom for normal-hearing and implanted rats (p&lt;10<sup>-8</sup> compared to all shuffled responses), but were locally tonotopic in normal-hearing rats (p&lt;10<sup>-4</sup>) but not implanted rats (ERPs: p=0.5, HG: p=0.7).</p><p><bold>C, H</bold>, Determining the preferred stimulus of spatially-evoked activity revealed smooth gradients shifting from high-to-low to high tone frequencies or cochlear implant channels (ERPs, panel <bold>C</bold>; HG, panel <bold>H</bold>).</p><p><bold>D, I</bold>, Local tonotopic gradients for each recording site plotted on a unit circle (blue) as a function of magnitude (strength of gradient) and angle (direction of gradient). The vectors across each recording site were averaged to produce an overall tonotopic vector (black) whose magnitude represents a metric of overall topography (ERPs, panel <bold>D</bold>; HG, panel <bold>I</bold>). The mean vector was plotted against the mean vector computed from n=1,000 shuffled maps (ERPs, panel <bold>D</bold>: normal-hearing z-score: 6.6, p&lt;10<sup>-10</sup>; implanted z-score: 7.9, p&lt;10<sup>-14</sup>; HG, panel <bold>I</bold>: normal-hearing z-score: 2.1, p=0.02; implanted z-score: 1.5, p=0.07).</p><p><bold>E, J</bold>, Z-scored magnitudes of mean tonotopic vectors across animals (ERPs, panel <bold>E</bold>: normal-hearing mean z-score: 4.7±1.0, implanted mean z-score: 2.6±1.0, p=0.22, Student’s paired two-tailed t-test; HG, panel <bold>J</bold>: normal-hearing mean z-score: 3.0±0.9, implanted mean z-score: 2.1±0.9, p=0.96).</p></caption>
<graphic xlink:href="668170v1_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We then asked whether individual cochlear implanted electrodes provide spatially restricted stimulation along the cochlear length and whether central auditory pathways would effectively preserve this cochleotopic encoding. We found that iEEG recordings of responses evoked by individual electrodes were spatially restricted to areas across the recording array (<xref rid="fig2" ref-type="fig">Fig. 2A,F</xref>) that appear to shift as a function of cochlear electrode location. To determine the degree of local and longer-range topography, we computed the spatial correlations as a function of stimulus separation, and compared the actual correlation coefficients to the distribution of responses when spatial locations were randomly shuffled. This analysis revealed a coarse topographic organization that was non-random (<xref rid="fig2" ref-type="fig">Fig. 2B,G</xref>; p&lt;10<sup>-8</sup> compared to all shuffled responses for ERPs and HG both for normal-hearing and implanted rats), but less sharply tonotopic relative to the tonotopic organization in normal-hearing animals assessed with pure tones (<xref rid="fig2" ref-type="fig">Fig. 2B</xref>, p&lt;10<sup>-4</sup> for ERPs and HG for normal-hearing rats; <xref rid="fig2" ref-type="fig">Fig. 2G</xref>, ERPs: p=0.5, HG: p=0.7 for implanted rats). Direct within- animal comparisons of normal-hearing vs implant maps (N=4) indicated that cochleotopic gradients were positioned in similar orientations and directions (<xref rid="fig2" ref-type="fig">Fig. 2C,H</xref>).</p>
<p>To quantify the degree and direction of potential spatial tonotopic or cochleotopic organization in the iEEG recordings, we computed the local gradients for each recording site (one example animal shown in <xref rid="fig2" ref-type="fig">Fig. 2D</xref>, ERPs; <xref rid="fig2" ref-type="fig">Fig. 2I</xref>, HG). Each gradient is a vector consisting of a magnitude and direction, and thus we then averaged these gradients from each recording site to get the overall cochleotopic vector, the magnitude of which is an index of spatial organization for a given animal. We shuffled the recording site location labels to generate putatively randomly organized maps (n=1000 random shuffles per animal), and compared the actual mean vector strength to the shuffled distributions. For this example animal, the ERP maps were significantly different from chance in terms of spatial organization (<xref rid="fig2" ref-type="fig">Fig. 2D</xref>, NH p=0.00003, CI p=0.0033), while this was more modest for the HG maps in this animal (<xref rid="fig2" ref-type="fig">Fig. 2I</xref>, NH p=0.02, CI p=0.07). This analysis revealed a similar kind of organization between ERP and HG maps of normal-hearing vs cochlear implant rats (<xref rid="fig2" ref-type="fig">Fig. 2E</xref>, NH mean z-score: 4.7±1.0, CI mean z-score: 2.6±1.0; <xref rid="fig2" ref-type="fig">Fig. 2J</xref>, NH mean z-score: 3.0±0.9, CI mean z-score: 2.1±0.9). Combined with results from <xref rid="fig2" ref-type="fig">Figure 2B,G</xref>, these analyses indicate that overall there was similar spatial organization to cortical iEEG responses in normal-hearing and cochlear implant animals, although the resolution of this topography was sharper for normal- hearing animals.</p>
</sec>
<sec id="s3c">
<title>Increased variability of trial-by-trial responses evoked by cochlear implant stimulation</title>
<p>The results described above for <xref rid="fig1" ref-type="fig">Figures 1</xref> and <xref rid="fig2" ref-type="fig">2</xref> used trial-averaged responses to examine the spatio-temporal organization of iEEG responses. We noticed that the iEEG recordings provided satisfactory signal-to-noise ratios to measure evoked ERPs (<xref rid="fig3" ref-type="fig">Fig. 3A,B</xref>) and HG transients (<xref rid="fig3" ref-type="fig">Fig. 3C,D</xref>) on a single trial basis. Therefore, we next asked if there were differences in single-trial encoding for cochlear implant vs normal-hearing rats. We first averaged evoked responses across all recording sites to reduce measurement noise. We then computed variability of responses in the 50 ms period immediately following stimulus onset, and found that in this temporal domain, the within-animal trial-by-trial variability in evoked responses was similar for cochlear implant rats compared to normal-hearing rats irrespective of recording site (‘Temporal’; <xref rid="fig3" ref-type="fig">Fig. 3B</xref>, ERPs, Student’s paired t-test, p=0.12; <xref rid="fig3" ref-type="fig">Fig. 3D, HG</xref>, p=0.17).</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Trial-by-trial cochleotopic encoding is more variable in cochlear implant vs normal-hearing rats.</title>
<p><bold>A, C,</bold> Trial-by-trial iEEG measurements of both tone-evoked (NH) and cochlear implant-evoked (CI) neural activity revealed peaks across time (left) and space (right) (ERP, <bold>A</bold>; HG, <bold>C</bold>)</p><p><bold>B, D,</bold> Variability of iEEG measurements across trials (root mean square, rms) was consistently higher for cochlear implant-evoked compared to tone-evoked activity, for ERPs in panel <bold>B</bold> (top, ERP temporal NH mean rms: 1.6±0.3 over all animals, CI mean rms: 1.9±0.5, Student’s two-tailed paired t-test for animals monitored before and after deafening, p=0.12; bottom, ERP spatial NH mean rms: 0.32±0.01, CI mean rms: 0.33±0.02, p=0.05) and HG in panel <bold>D</bold> (top, HG temporal NH mean rms: 2.4±0.3 over all animals, CI mean rms: 3.3±0.9, p=0.18; bottom, HG spatial NH mean rms: 1.2±0.2, CI mean rms: 1.3±0.3, p=0.32).</p></caption>
<graphic xlink:href="668170v1_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Then, we returned to the evoked responses for each recording site and measured the trial-by-trial evoked response peak. Next, we computed the variability of spatial distributions of evoked responses and found larger within-animal trial-by-trial variability in evoked responses for CI compared to NH rats (‘Spatial’; <xref rid="fig3" ref-type="fig">Fig. 3B</xref>, ERPs, Student’s paired two-tailed t-test, p=0.05; <xref rid="fig3" ref-type="fig">Fig. 3D, HG</xref>, p=0.32). We conclude that similar to the trial-averaged responses in <xref rid="fig2" ref-type="fig">Figure 2</xref>, analysis of ERPs more so than HG signals could identify the increased spatial variability of evoked responses across the auditory cortex in cochlear implant animals relative to normal-hearing animals.</p>
</sec>
<sec id="s3d">
<title>Single trials encode stimulus identity in normal-hearing and cochlear implant rats</title>
<p>Given that the trial-by-trial variability in evoked responses were higher for implant-evoked responses compared to responses in normal-hearing rats, we wondered if this would compromise the decoding of cochlear implant signals in some way. We next trained a classifier to determine if we could successfully decode stimulus identity from individual trials, and what differences there might be between decoding accuracy for normal-hearing vs cochlear implant rats. We reduced evoked responses into the top 15 principal components via PCA (<xref rid="fig4" ref-type="fig">Fig. 4A,B</xref>), and then trained an LDA decoder on 13 randomized trials of stimulus presentation to enable comparisons across animals that had different numbers of stimulus presentations (<xref ref-type="bibr" rid="c29">Insanally et al., 2016</xref>). Computed prediction probabilities were estimated by testing the decoder on the remaining trials. Selections of the 13 training and remaining test trials were randomized (N=1,000 trials), and final prediction probabilities were averaged across these repeats.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Trial-by-trial iEEG measurements encode stimulus identity.</title>
<p><bold>A,</bold> Trial-by-trial ERPs evoked by 1.4 kHz (left), 8 kHz (middle), and 32 kHz tones (right) are plotted for three recording sites (blue) reveal discernable evoked transients and spatially restricted patterns of evoked magnitudes (stimulus onsets depicted by dotted line).</p><p><bold>B,</bold> Trial-by-trial iEEG measurements concatenated such that columns represent recording sites (spatial) and post-stimulus sampling (temporal), rows by stimulus trials. Data then reorganized by PCA and reduced to the 15 components according to magnitude of explained variance.</p><p><bold>C,</bold> Classification matrices are plotted means across bootstrapped repeated (N=1,000) versions of LDA classifiers trained using 13 randomly selected trials for each stimulus, and classification predictions of single and remaining trials reveal significant prediction of stimulus identity (dashed line: chance-level error distance; solid lines: actual mean error distances).</p><p><bold>D,</bold> Stimulus prediction probabilities plotted across animals (black: mean, grey: s.e.m.) and as function of either octaves (normal-hearing) or channels (cochlear implant) from actual stimulus, reflecting a gradient in which adjacent stimuli share more encoded features than other stimuli.</p><p><bold>E,</bold> Decoder performance (mean error distance) across individual animals was somewhat worse for cochlear implant ERPs compared to tone-evoked ERPs (ERP mean error rate relative to chance for normal-hearing: 0.74±0.05, cochlear implant: 0.78±0.06; for animals assessed both first when normal-hearing and then after cochlear implantation p=0.02, Student’s two-tailed paired t-test), but not for HG (HG mean error rate relative to chance for normal-hearing: 0.90±0.03, cochlear implant: 0.91±0.04; for animals assessed both first when normal-hearing and then after cochlear implantation p=0.11).</p></caption>
<graphic xlink:href="668170v1_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>This approach successfully decoded tones and implant electrodes (<xref rid="fig4" ref-type="fig">Fig. 4C</xref>). Across animals, there were above-chance prediction of the correct stimulus from single trials, with higher errors when closer to the actual stimulus (<xref rid="fig4" ref-type="fig">Fig. 4D</xref>). Computing error distance mean across trials allowed us to compare decoding performance of normal-hearing vs implanted rats, as this combines absolute prediction probability and distribution of errors while normalizing to chance-level error distances, determined by the number of trained and tested stimuli. Decoders trained on responses from normal-hearing rats had better performance compared to responses from those animals after implantation (<xref rid="fig4" ref-type="fig">Fig. 4E</xref>; ERP mean error distance for normal-hearing rats: 0.74±0.05, cochlear implant rats: 0.78±0.06, p=0.02, Student’s paired two-tailed t-test; HG mean error distance for normal-hearing: 0.90±0.03, cochlear implant: 0.91±0.04, p=0.11).</p>
</sec>
<sec id="s3e">
<title>Single trial encoding is independently provided by both spatial and temporal cues</title>
<p>Which aspects of iEEG signals (spatial topography and/or temporal dynamics) contribute to stimulus decoding performance? We re-trained PCA-LDA decoders, but instead of using both spatial and temporal aspects of the full set of iEEG measurements (<xref rid="fig5" ref-type="fig">Fig. 5A</xref>), decoders were trained on the spatial-only (<xref rid="fig5" ref-type="fig">Fig. 5B</xref>) or temporal domain-only aspects (<xref rid="fig5" ref-type="fig">Fig. 5C</xref>) of evoked iEEG measurements. Decoders trained on the spatial or temporal domains only were essentially as good as predicting the stimulus as decoders trained on both aspects (<xref rid="fig5" ref-type="fig">Fig. 5D,E</xref>; mean error distance for spatial-only ERPs, normal-hearing: 0.77±0.04, implant: 0.77±0.08; for spatial-only HG, normal- hearing: 0.89±0.04, implant: 0.87±0.05; for temporal-only ERPs, normal-hearing: 0.82±0.05, implant: 0.81±0.07; for temporal-only HG, normal-hearing: 0.87±0.04, implant: 0.93±0.05; for spatial+temporal ERPs, normal-hearing: 0.74±0.04, implant: 0.86±0.06; for spatial+temporal HG, normal-hearing: 0.90±0.03, implant: 0.97±0.04). We conclude that both spatial and temporal aspects of iEEG measurements contribute to single-trial encoding of stimulus identity.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Trial-by-trial decoding from either spatial or temporal aspects of iEEG signals.</title>
<p><bold>A,</bold> Raw trial-by-trial ERPs for a single animal are plotted for 3 channels.</p><p><bold>B-C,</bold> Trial-by-trial iEEG measurements are reduced into either spatial only (<bold>B</bold>) or temporal only (<bold>C</bold>) by extracting either the magnitude of evoked activity or averaging across all recording sites.</p><p><bold>D,</bold> Re-training PCA-LDA decoders on spatial-only (middle) or temporal-only (right) does not abolish the encoding of stimulus identity.</p><p><bold>E,</bold> Decoder errors (mean error distance re. chance) across animals are plotted for decoders trained on spatial+temporal, spatial-only, and temporal-only iEEG measurements. Mean error distance for spatial+temporal ERPs, normal-hearing: 0.74±0.04, implant: 0.86±0.06; for spatial+temporal HG, normal-hearing: 0.90±0.03, implant: 0.97±0.04. Mean error distance for spatial-only ERPs, normal-hearing: 0.77±0.04, implant: 0.77±0.08; for HG, normal-hearing: 0.89±0.04, implant: 0.87±0.05. Mean error distance for temporal-only ERPs, normal-hearing: 0.82±0.05, implant: 0.81±0.07; for HG, normal-hearing: 0.87±0.04, implant: 0.93±0.05.</p></caption>
<graphic xlink:href="668170v1_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>In some cases, we found that the performance of either spatial-only or temporal-only could be somewhat better than decoders trained on both spatial and temporal aspects of iEEG measurements. This is likely due to the noise inherent in iEEG signals, such that constraining PCA reductions to one aspect of the data (either spatial or temporal) helps to eliminate variance in individual recordings.</p>
</sec>
<sec id="s3f">
<title>Reducing evoked responses using TCA preserves encoding of stimulus identity</title>
<p>One challenge with using PCA is that the ordinations of dimensionality reduction are unconstrained, because they are arbitrary linear combination of the original variables. A newer approach for dimensionality reduction called tensor component analysis (TCA) explicitly enables identification of which spatial, temporal, and single-trial factors best account for signal variability, and thus drive single-trial stimulus decoding (<xref ref-type="bibr" rid="c60">Williams et al., 2018</xref>). Here, we used TCA instead of PCA for LDA-based decoding, constraining data reduction dimensions on the full data set to the spatial, temporal, and to the trials of iEEG measurements (<xref rid="fig6" ref-type="fig">Fig. 6A</xref>). The resulting TCA- optimizations across 15 components reveal discernable patterns of spatial and temporal factors (<xref rid="fig6" ref-type="fig">Fig. 6B</xref>). We trained and tested a LDA decoder using only the trial factors, and found that single trial predictions accurately identified the stimulus (<xref rid="fig6" ref-type="fig">Fig. 6C-D</xref>). Decoders trained on responses from normal-hearing rats had better prediction performance compared to the responses from these same animals after cochlear implantation (<xref rid="fig6" ref-type="fig">Fig. 6E</xref>; ERP mean error distance for normal-hearing rats: 0.78±0.11, for cochlear implant rats: 0.80±0.15, p=0.01, Student’s paired two-tailed t-test; HG mean error distance for normal-hearing: 0.90±0.03, for cochlear implant: 0.88±0.05, p=0.1).</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><title>TCA-based decoding of single-trial iEEG measurements.</title>
<p><bold>A,</bold> Schematic of TCA with 3-dimensional tensors with orthogonal dimensions of spatial, temporal and trial factors.</p><p><bold>B,</bold> TCA-reduced iEEG measurements of stimulus-evoked ERPs in normal-hearing rats are plotted across 15 components of spatial (top row), temporal (middle row) and trial factors (bottom row).</p><p><bold>C,</bold> Classification matrices of mean decoder predictions across bootstrapped repeated (N=1,000) versions LDA classifiers trained using 13 randomly selected trials for each stimulus indicated that iEEG measurements encode stimulus identity from single stimulus presentations (dashed line: chance-level error distance; solid lines: actual mean error distances).</p><p><bold>D,</bold> Stimulus prediction probabilities are plotted across animals (black: mean, grey: std. error) and as a function of either octaves or channels in away from actual stimulus, normal-hearing and implanted rats. Correct prediction probabilities are high across all conditions and prediction errors coalescing of predictions toward actual stimuli (orange: mean and std. error of decoder performance on shuffled trials; grey: mean error distance, dashed line: chance level error distance).</p><p><bold>E,</bold> Decoder errors (mean error distance) across individual animals were slightly smaller for evoked iEEG measurements in normal-hearing compared to implanted rats (ERP mean error rate re. chance normal-hearing: 0.77±0.04, implanted: 0.80±0.06; HG mean error rate re. chance normal-hearing: 0.90±0.03, implanted: 0.88±0.05). Animals with both normal-hearing and implanted iEEG measurements only showed significant differences for ERP (top, Student’s paired t-test: p=0.01) but not HG (bottom, p=0.09).</p></caption>
<graphic xlink:href="668170v1_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s3g">
<title>Latent factors from unsupervised TCA revealed spatially-organized maps</title>
<p>These analyses revealed that single-trial iEEG responses can be successfully decoded, and the TCA-based approach suggests that individual factors driving decoding might relate to specific spatiotemporal features inherent in the data. Specifically, we asked whether the TCA-reduced data contained organized spatial features, e.g., patterns of tonotopy. We next optimized TCA models of the original data (<xref rid="fig7" ref-type="fig">Fig. 7A</xref>) and then weighed the spatial factors by the strength of trial factors associated with each stimulus, resulting in spatial maps for each stimulus frequency for both normal-hearing and electrode for implants rats (<xref rid="fig7" ref-type="fig">Fig. 7B</xref>). The resulting reorganized spatial factors were further reduced to a preferred stimulus. Resulting TCA-maps exhibited tonotopic features (<xref rid="fig7" ref-type="fig">Fig. 7C</xref>), similar to tonotopic maps extracted from ERP or HG components of the iEEG responses. TCA-recreated spatial maps also exhibited coarse topographic organization that was non-random compared to shuffled distributions (<xref rid="fig7" ref-type="fig">Fig. 7D</xref>, p&lt;10<sup>-8</sup> compared to all shuffled responses for ERPs and HG both for normal-hearing and implanted rats). TCA models from normal-hearing HG iEEG measurements exhibited clear tonotopic organization whereas tonotopy in models from other measurements was less clear (<xref rid="fig7" ref-type="fig">Fig. 7D</xref>, normal-hearing rats ERPs: p=0.18, normal-hearing rats HG: p&lt;10<sup>-4</sup>, cochlear implant rats ERPs: p=0.43, cochlear implant rats HG: p=0.40). As with analyses of <xref rid="fig2" ref-type="fig">Figure 2E,J</xref>, the magnitude of tonotopy computed from mean vector strengths was similar for ERP and HG measurements in normal-hearing vs cochlear implant rats (<xref rid="fig7" ref-type="fig">Fig 7E</xref>).</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7.</label>
<caption><title>TCA data reductions reveal latent spatial factors are topographically organized.</title><p><bold>A</bold>, TCA-based analysis of evoked neural activity, divided into 15 unique components where each component is separated into orthogonal dimensions of spatial factors (top row), temporal factors (middle row) and trial factors (bottom row).</p><p><bold>B</bold>, Spatial maps for tone-evoked or electrode-evoked responses recreated from TCA reduced data.</p><p><bold>C</bold>, Reducing re-organized spatial factors revealed a TCA map (left) with topographical gradients in same location and direction as the tonotopic map reduced from raw measurements (right).</p><p><bold>D</bold>, Spatial correlations of evoked response areas decreased monotonically as a function of increasing stimulus separation. TCA-reduced models of evoked iEEG responses as assessed by ERPs and HG were nonrandom for normal-hearing and implanted rats (p&lt;10<sup>-8</sup> compared to all shuffled responses). TCA-reduced models were locally tonotopic only for HG in normal-hearing rats (normal-hearing ERPs: p=0.18, normal-hearing HG: p&lt;10<sup>-4</sup>, cochlear implant ERPs: p=0.43, cochlear implant HG: p=0.40).</p><p><bold>E</bold>, Z-scored magnitudes of mean tonotopic vectors across animals were similar (ERPs, normal-hearing mean z-score: 6.2±3.6, cochlear implant mean z-score: 3.9±2.1, p=0.28, Student’s paired two-tailed t-test; HG, normal-hearing mean z-score: 2.9±1.1, implanted mean z-score: 2.5±0.7, p=0.88).</p></caption>
<graphic xlink:href="668170v1_fig7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s3h">
<title>iEEG measurements from implanted rats could not be decoded from models trained on normal-hearing data</title>
<p>We asked what features might be shared vs distinct in the nature of cortical encoding of tones (in normal-hearing rats) and electrode channels (in cochlear implant rats). We hypothesized that this overlap would be incomplete, with substantial variability across individuals. This was based on a considerable number of previous studies finding that adaptation periods are needed before maximizing cochlear implant outcomes in both animals (<xref ref-type="bibr" rid="c22">Glennon et al., 2023</xref>) and humans (<xref ref-type="bibr" rid="c27">Holden et al., 2013</xref>; <xref ref-type="bibr" rid="c14">Cusumano et al., 2017</xref>; <xref ref-type="bibr" rid="c21">Glennon et al., 2020</xref>; <xref ref-type="bibr" rid="c10">Caswell-Midwinter et al., 2022</xref>), as well as our results described above showing that iEEG measurements were less sharply topographic and more variable in implanted rats compared to normal-hearing animals. Thus, here we asked whether a decoder trained on tone-evoked iEEG measurements from normal-hearing rats could interpret implant-evoked iEEG measurements on single trials.</p>
<p>Our measurements of iEEG activity in the same animals before and after deafening and implant fitting provide an opportunity to examine this directly, and determine how individually distinct the neural coding of sound is for the auditory cortex in both normal-hearing and cochlear implant conditions. TCA-generated models provide a reasonable approach to quantify the degree of information transfer from the normal-hearing to the implanted condition, because the dimensions of data reductions are predetermined (i.e., spatial and temporal), rather than unconstrained as with PCA models. We generated TCA models of tone-evoked iEEG measurements from normal-hearing rats (<xref rid="fig8" ref-type="fig">Fig. 8A</xref>). Next, we extracted only the spatial and temporal components of these normal-hearing TCA models to constrain models for implanted rats, leaving only the trial factors to be optimized (<xref rid="fig8" ref-type="fig">Fig. 8B</xref>).</p>
<fig id="fig8" position="float" orientation="portrait" fig-type="figure">
<label>Figure 8.</label>
<caption><title>Lack of information transfer between acoustic and electrical stimulation representations in the same animals.</title>
<p><bold>A,</bold> Evoked iEEG measurements from a normal-hearing rat reduced using TCA.</p><p><bold>B,</bold> Evoked iEEG measurements in cochlear implant rat modeled using TCA, constraining the model with the spatial and temporal factors from the TCA model optimized on normal-hearing data, leaving only the trials as the optimizable variables.</p><p><bold>C,</bold> Linear discriminant analysis classifiers are trained on the trial factors extracted from the TCA-reduced models of evoked data in normal-hearing conditions and then used to predict stimulus identity from the trial factors from the TCA-reduced models of implant-evoked measurements.</p><p><bold>D,</bold> Classification matrices are plotted means of decoder predictions across bootstrapped repeated (N=1,000) versions of linear-discriminant analysis (LDA) classifiers reveal little information transfer (IT for animal 1; for ERPs: 1.1%, for HG: 0.3%).</p><p><bold>E,</bold> Classification matrices of normal-hearing trained and implant tested decoders reveal little-to- no information transfer in three other animals with iEEG measurements of both tone-evoked and implant-evoked responses (IT for animal 2, ERPs: 5.9%, HG: 0.2%; for animal 3, ERPs: 1.0%, HG: 0.1%; for animal 4, ERPs: 0.9%, HG: 0.1%).</p></caption>
<graphic xlink:href="668170v1_fig8.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Next, we compared these models across each animal by training an LDA decoder on the trial factors from tone-evoked TCA models and then testing the decoder on trial factors of the implant- evoked TCA models (<xref rid="fig8" ref-type="fig">Fig. 8C</xref>). From these resulting confusion matrices of prediction probabilities, we computed the mutual information between predictions of tone identity and actual implant channels to quantify how much tone predictions can be used to determine the actual identity of single channels, without imposing any hypotheses about how predicted tones map onto implant electrodes (e.g., tonotopy). We computed the pointwise mutual information for each combination of predicted tones and actual implant channels, which was then normalized by the joint probability. These resulting bits were combined across the entire confusion matrix to compute mutual information, and finally we converted this to a percentage of information transfer by dividing the experimentally measured mutual information by the total possible number of bits the matrix could provide.</p>
<p>We found the resulting information transfer to be low across all four animals where we measured both tone- and implant-evoked iEEG measurements (<xref rid="fig8" ref-type="fig">Fig. 8D,E</xref>; mean information transfer, ERPs: 2.2±1.1%; HG: 0.2±0.1%). The near-zero information transfer indicates that decoders trained on tone-evoked iEEG measurements do not make meaningful interpretations of implant-evoked iEEG measurements. We conclude that although iEEG responses can be meaningfully decoded from single-trial cortical responses (to either acoustic tones in normal-hearing animals or cochlear implant stimulation in deafened animals), the decoding algorithms and computations required are specific to the type of stimulus and do not immediately generalize between acoustic and electrical stimulation. This has implications for understanding the perceptual experiences of cochlea implant users e.g., pitch perception at acute implant stimulation. If the cortical representations were simply degraded or noisy versions of acoustic responses, we would expect partial information transfer. Instead, the mutual information analysis reveals that the acoustic response pattern does not inform the electrical stimulation response pattern. In turn, this suggests that the perceptual qualities (e.g., pitch) evoked by acoustic and electrical stimulation may be qualitatively different rather than simply degraded versions of each other.</p>
</sec>
</sec>
<sec id="s4">
<title>Discussion</title>
<p>Cochlear implants are the gold standard for success of brain-computer interfaces and neuroprosthetic devices to safely activate the human nervous system and effectively restore functional sensation (<xref ref-type="bibr" rid="c26">Hochmair et al., 2006</xref>; <xref ref-type="bibr" rid="c62">Wilson and Dorman, 2008</xref>; <xref ref-type="bibr" rid="c13">Clark, 2015</xref>; <xref ref-type="bibr" rid="c54">Svirsky, 2017</xref>; <xref ref-type="bibr" rid="c21">Glennon et al., 2020</xref>). While high levels of hearing and speech processing can be achieved by some users, outcomes remain highly variable in terms of learning rates and peak performance, especially in real-world conditions and even after controlling for age and durations of deafness (<xref ref-type="bibr" rid="c8">Blamey et al., 2013</xref>). Invariably, all users require an adaptation period; speech perception outcomes are initially poorer than later timepoints (<xref ref-type="bibr" rid="c27">Holden et al., 2013</xref>; <xref ref-type="bibr" rid="c14">Cusumano et al., 2017</xref>; <xref ref-type="bibr" rid="c10">Caswell-Midwinter et al., 2022</xref>; <xref ref-type="bibr" rid="c53">Stronks et al. 2025</xref>), indicating that both that acute encoding of cochlear implant stimulation by the central auditory system is not optimal and that neuroplastic processes are needed for maximizing outcomes. Current and future advances in engineering and implant programming algorithms might help improve outcomes further, but there is a general belief in the field that what is now required is an understanding of how the central nervous system responds to peripheral electrical stimulation (<xref ref-type="bibr" rid="c39">Kral et al., 2002</xref>; <xref ref-type="bibr" rid="c40">Kral and Eggermont, 2007</xref>; <xref ref-type="bibr" rid="c62">Wilson and Dorman, 2008</xref>; <xref ref-type="bibr" rid="c47">Moore and Shannon, 2009</xref>).</p>
<p>Our findings provide the first direct neural evidence that acoustic and electrical cochlear stimulation create fundamentally distinct cortical representations, with near-zero information transfer between modalities. This addresses a longstanding question in cochlear implant research: whether electrical stimulation of the cochlea can evoke the same percepts as acoustic stimulation, such as pitch and timing. The lack of transferable representations suggests that cochlear implant users may experience qualitatively different percepts that cannot be predicted from normal acoustic hearing. If so, this would challenge a foundational assumption of current cochlear implant design—that electrical stimulation should mimic the tonotopic patterns of acoustic hearing. Our data suggest that this biomimetic approach may be fundamentally limited because the cortical representations are non-overlapping.</p>
<p>Previous studies in non-human animals have established that stimulus identity can be encoded in A1 (<xref ref-type="bibr" rid="c6">Bierer and Middlebrooks, 2002</xref>; <xref ref-type="bibr" rid="c46">Middlebrooks and Bierer, 2002</xref>; <xref ref-type="bibr" rid="c7">Bierer and Middlebrooks, 2004</xref>). However, many of these studies have used invasive recording methods to examine single- neuron responses to implant activation. Invasive recordings are not feasible for human cochlear implant recipients, and thus decoding methods based on purely-invasive measures may be difficult to translate into human subjects for optimizing implant programming and/or training for use of the device. While our iEEG recordings are also invasive and under anesthesia, the principles of iEEG analysis for cochlear implant responses developed here might be more applicable to non-invasive EEG recordings or similar approaches more easily performed in humans. Grid electrodes allowed us to take simultaneous advantage both of temporal and spatial features in the data, some of which were more obvious in ERPs, others were more latent in HG signals or PCA/TCA factors.</p>
<p>Our results show that these features could provide accurate stimulus decoding even on single trials, indicating that: 1) use of these methods in translational or clinical settings could aid personalization and optimization of brain-computer interfaces, and 2) single-trial implant responses can be adequately processed by auditory cortex and presumably downstream regions related to perception and behavior. It has been unclear to what degree the patterns of tone-evoked and implant-evoked responses in normal-hearing vs deaf subjects are similar. We found that the encoding of cochlear implant electrodes was less reliable and identifiable than tone-evoked responses in normal-hearing animals. One caveat is that direct comparisons of evoked iEEG measurements between normal- hearing and implanted rats are challenging due to fundamental differences in the stimuli (e.g., the cochleotopic separation between stimuli such as the spacing between half-octaves vs spacing between successive CI electrodes), as well as the higher degree of inter-trial variability for implant responses (which is presumably not influenced by stimulus separation).</p>
<p>We also observed interesting differences in the information provided by ERPs vs HG signals. In terms of field potentials, the HG band is thought to most directly related to neuronal spike activity (<xref ref-type="bibr" rid="c51">Ray and Maunsell, 2011</xref>), which may account for why HG-evoked activity was more time-locked to stimuli and more spatially tuned compared to ERPs. Some single-channel HG measurements also had higher signal-to-noise levels than ERPs. A priori, it would seem that a decoder with access to both higher signal-to-noise measurements in the temporal and spatial domains should perform better at predicting stimulus identity. Instead, we found that decoding was more accurate with ERPs than HG. One possible explanation for poorer decoding performance with HG is that HG signals are more spatially tuned, leading to a smaller number of discernable channels with clear HG activity; accordingly, we found that across iEEG grid sites, there were more significant recording sites with ERPs than HG. HG responses also have higher trial-by-trial variability and are more temporally-constrained than ERPs, and thus the ERP might be more informative in terms of decoding performance.</p>
<p>Finally, we found that single-trial temporal factors could suffice to provide accurate decoding of implant channels. This suggests that preservation of clear cochleotopy in deaf subjects may not be a pre-requisite for successful implant use. Rather, it is likely that reductions in trial-by-trial and inter-neuronal variability might be more important as a mechanism for improving outcomes. This means that the neural responses to neuroprosthetic stimulation and use of brain-computer interfaces need not fully recapitulate responses to other modalities (e.g., acoustic stimulation) in space and time. Previously we showed that deafened rats could learn to use a cochlear implant to perform an auditory task, and that changes in cortical excitatory and inhibitory synapses related to implant use outcomes. In the current study, we did not track responses to implant use over time in relation to changes in perception and behavioral performance. Our results suggest that refinement particularly of inhibitory cortical responses might help increase inter-neuronal variance at the population level to increase spatial organization, while decreasing intra-trial variability at the single neuron level to enhance temporal organization and improve auditory perception.</p>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>We thank Badr Albanna, Elad Sagi, and Sam Zheng for comments, discussions, and technical assistance. This work was funded by the National Institute on Deafness and Other Communication Disorders (K99DC021727 to A.E.H., F30DC015170 to J.K.S., and R01DC012557 to R.C.F. and M.A.S.), the National Center for Advancing Translational Sciences (TL1TR001447 to A.E.H.), and the Charles H. Revson Foundation (to A.E.H.); the statements made and views expressed, however, are solely the responsibility of its authors. The current affiliation for Julia K. Scarpa is Weill Cornell Medicine, New York, NY 10065; for Yew-Song Cheng is Massachusetts Eye and Ear Infirmary, Harvard Medical School, Boston MA, 02114; for Michael Trumpis is Paradromics Inc., Austin TX 78759.</p>
</ack>
    <sec id="nt1">
        <title>Note</title>
        <p>This reviewed preprint has been updated to correct a typo in an email address.</p>
    </sec>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Abdi-Sargezeh</surname> <given-names>B</given-names></string-name>, <string-name><surname>Oswal</surname> <given-names>A</given-names></string-name>, <string-name><surname>Sanei</surname> <given-names>S</given-names></string-name></person-group> (<year>2023</year>) <article-title>Mapping scalp to intracranial EEG using generative adversarial networks for automatically detecting interictal epileptiform discharges</article-title>: <conf-name>2023 IEEE Statistical Signal Processing Workshop (SSP)</conf-name>, <fpage>710</fpage>–<lpage>714</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ayton</surname> <given-names>LN</given-names></string-name>, <string-name><surname>Barnes</surname> <given-names>N</given-names></string-name>, <string-name><surname>Dagnelie</surname> <given-names>G</given-names></string-name>, <string-name><surname>Fujikado</surname> <given-names>T</given-names></string-name>, <string-name><surname>Goetz</surname> <given-names>G</given-names></string-name>, <string-name><surname>Hornig</surname> <given-names>R</given-names></string-name>, <string-name><surname>Jones</surname> <given-names>BW</given-names></string-name>, <string-name><surname>Muqit</surname> <given-names>MMK</given-names></string-name>, <string-name><surname>Rathbun</surname> <given-names>DL</given-names></string-name>, <string-name><surname>Stingl</surname> <given-names>K</given-names></string-name>, <string-name><surname>Weiland</surname> <given-names>JD</given-names></string-name>, <string-name><surname>Petoe</surname> <given-names>MA</given-names></string-name></person-group> (<year>2020</year>) <article-title>An update on retinal prostheses</article-title>. <source>Clin Neurophysiol</source> <volume>131</volume>:<fpage>1383</fpage>–<lpage>1398</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Azadpour</surname> <given-names>M</given-names></string-name>, <string-name><surname>McKay</surname> <given-names>CM</given-names></string-name></person-group> (<year>2012</year>) <article-title>A psychophysical method for measuring spatial resolution in cochlear implants</article-title>. <source>J Assoc Res Otolaryngol</source> <volume>13</volume>:<fpage>145</fpage>–<lpage>157</lpage>.</mixed-citation></ref>
    <ref id="c4"><mixed-citation publication-type="software"><person-group person-group-type="author"><string-name><surname>Bader</surname> <given-names>BW</given-names></string-name>, <string-name><surname>Kolda</surname> <given-names>TG</given-names></string-name>, <etal>et al</etal></person-group> (<year>2023</year>) <article-title>Tensor Toolbox for MATLAB</article-title>. <version>v3.6</version>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Beynon</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>Luijten</surname> <given-names>BM</given-names></string-name>, <string-name><surname>Mylanus</surname> <given-names>EAM</given-names></string-name></person-group> (<year>2021</year>) <article-title>Intracorporeal cortical telemetry as a step to automatic closed-loop EEG-based CI fitting: A proof of concept</article-title>. <source>Audiol Res</source> <volume>11</volume>:<fpage>691</fpage>–<lpage>705</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bierer</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Middlebrooks</surname> <given-names>JC</given-names></string-name></person-group> (<year>2002</year>) <article-title>Auditory cortical images of cochlear-implant stimuli: dependence on electrode configuration</article-title>. <source>J Neurophysiol</source> <volume>87</volume>:<fpage>478</fpage>–<lpage>492</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bierer</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Middlebrooks</surname> <given-names>JC</given-names></string-name></person-group> (<year>2004</year>) <article-title>Cortical responses to cochlear implant stimulation: channel interactions</article-title>. <source>J Assoc Res Otolaryngol</source> <volume>5</volume>:<fpage>32</fpage>–<lpage>48</lpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Blamey</surname> <given-names>P</given-names></string-name> <etal>et al.</etal></person-group> (<year>2013</year>) <article-title>Factors affecting auditory performance of postlinguistically deaf adults using cochlear implants: an update with 2251 patients</article-title>. <source>Audiol Neurootol</source> <volume>18</volume>:<fpage>36</fpage>–<lpage>47</lpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carcea</surname> <given-names>I</given-names></string-name>, <string-name><surname>Insanally</surname> <given-names>MN</given-names></string-name>, <string-name><surname>Froemke</surname> <given-names>RC</given-names></string-name></person-group> (<year>2017</year>) <article-title>Dynamics of auditory cortical activity during behavioural engagement and auditory perception</article-title>. <source>Nat Commun</source> <volume>8</volume>:<fpage>14412</fpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Caswell-Midwinter</surname> <given-names>B</given-names></string-name>, <string-name><surname>Doney</surname> <given-names>EM</given-names></string-name>, <string-name><surname>Arjmandi</surname> <given-names>MK</given-names></string-name>, <string-name><surname>Jahn</surname> <given-names>KN</given-names></string-name>, <string-name><surname>Herrmann</surname> <given-names>BS</given-names></string-name>, <string-name><surname>Arenberg</surname> <given-names>JG</given-names></string-name></person-group> (<year>2022</year>) <article-title>The relationship between impedance, programming and word recognition in a large clinical dataset of cochlear implant recipients</article-title>. <source>Trends Hear</source> <volume>26</volume>:<fpage>23312165211060983</fpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chang</surname> <given-names>EF</given-names></string-name></person-group> (<year>2015</year>) <article-title>Towards large-scale, human-based, mesoscopic neurotechnologies</article-title>. <source>Neuron</source> <volume>86</volume>:<fpage>68</fpage>–<lpage>78</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Clark</surname> <given-names>GM</given-names></string-name></person-group> (<year>2006</year>) <article-title>The multiple-channel cochlear implant: the interface between sound and the central nervous system for hearing, speech, and language in deaf people-a personal perspective</article-title>. <source>Philos Trans R Soc Lond B Biol Sci</source> <volume>361</volume>:<fpage>791</fpage>–<lpage>810</lpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Clark</surname> <given-names>GM</given-names></string-name></person-group> (<year>2015</year>) <article-title>The multi-channel cochlear implant: Multi-disciplinary development of electrical stimulation of the cochlea and the resulting clinical benefit</article-title>. <source>Hear Res</source> <volume>322</volume>: <fpage>4</fpage>–<lpage>13</lpage>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cusumano</surname> <given-names>C</given-names></string-name>, <string-name><surname>Friedmann</surname> <given-names>DR</given-names></string-name>, <string-name><surname>Fang</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>B</given-names></string-name>, <string-name><surname>Roland</surname> <given-names>JT</given-names>, <suffix>Jr.</suffix></string-name>, <string-name><surname>Waltzman</surname> <given-names>SB</given-names></string-name></person-group> (<year>2017</year>) <article-title>Performance plateau in prelingually and postlingually deafened adult cochlear implant recipients</article-title>. <source>Otol Neurotol</source> <volume>38</volume>:<fpage>334</fpage>–<lpage>338</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dawson</surname> <given-names>J</given-names></string-name>, <string-name><surname>Pierce</surname> <given-names>D</given-names></string-name>, <string-name><surname>Dixit</surname> <given-names>A</given-names></string-name>, <string-name><surname>Kimberley</surname> <given-names>TJ</given-names></string-name>, <string-name><surname>Robertson</surname> <given-names>M</given-names></string-name>, <string-name><surname>Tarver</surname> <given-names>B</given-names></string-name>, <string-name><surname>Hilmi</surname> <given-names>O</given-names></string-name>, <string-name><surname>McLean</surname> <given-names>J</given-names></string-name>, <string-name><surname>Forbes</surname> <given-names>K</given-names></string-name>, <string-name><surname>Kilgard</surname> <given-names>MP</given-names></string-name>, <string-name><surname>Rennaker</surname> <given-names>RL</given-names></string-name>, <string-name><surname>Cramer</surname> <given-names>SC</given-names></string-name>, <string-name><surname>Walters</surname> <given-names>M</given-names></string-name>, <string-name><surname>Engineer</surname> <given-names>N</given-names></string-name></person-group> (<year>2016</year>) <article-title>Safety, feasibility, and efficacy of vagus nerve stimulation paired with upper-limb rehabilitation after ischemic stroke</article-title>. <source>Stroke</source> <volume>47</volume>:<fpage>143</fpage>–<lpage>150</lpage>.</mixed-citation></ref>
    <ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Djourno</surname> <given-names>A</given-names></string-name>, <string-name><surname>Eyries</surname> <given-names>C</given-names></string-name></person-group> (<year>1957</year>) <article-title>[Auditory prosthesis by means of a distant electrical stimulation of the sensory nerve with the use of an indwelt coiling]</article-title>. <source>Presse Med (1893)</source> <volume>65</volume>:<fpage>1417</fpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eddington</surname> <given-names>DK</given-names></string-name>, <string-name><surname>Dobelle</surname> <given-names>WH</given-names></string-name>, <string-name><surname>Brackmann</surname> <given-names>DE</given-names></string-name>, <string-name><surname>Mladejovsky</surname> <given-names>MG</given-names></string-name>, <string-name><surname>Parkin</surname> <given-names>JL</given-names></string-name></person-group> (<year>1978</year>) <article-title>Auditory prostheses research with multiple channel intracochlear stimulation in man</article-title>. <source>Ann Otol Rhinol Laryngol</source> <volume>87</volume>:<fpage>1</fpage>–<lpage>39</lpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fallon</surname> <given-names>JB</given-names></string-name>, <string-name><surname>Shepherd</surname> <given-names>RK</given-names></string-name>, <string-name><surname>Irvine</surname> <given-names>DRF</given-names></string-name></person-group> (<year>2014</year>) <article-title>Effects of chronic cochlear electrical stimulation after an extended period of profound deafness on primary auditory cortex organization in cats</article-title>. <source>Eur J Neurosci</source> <volume>39</volume>:<fpage>811</fpage>–<lpage>820</lpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Froemke</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Carcea</surname> <given-names>I</given-names></string-name>, <string-name><surname>Barker</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>Yuan</surname> <given-names>K</given-names></string-name>, <string-name><surname>Seybold</surname> <given-names>BA</given-names></string-name>, <string-name><surname>Martins</surname> <given-names>ARO</given-names></string-name>, <string-name><surname>Zaika</surname> <given-names>N</given-names></string-name>, <string-name><surname>Bernstein</surname> <given-names>H</given-names></string-name>, <string-name><surname>Wachs</surname> <given-names>M</given-names></string-name>, <string-name><surname>Levis</surname> <given-names>PA</given-names></string-name>, <string-name><surname>Polley</surname> <given-names>DB</given-names></string-name>, <string-name><surname>Merzenich</surname> <given-names>MM</given-names></string-name>, <string-name><surname>Schreiner</surname> <given-names>CE</given-names></string-name></person-group> (<year>2013</year>) <article-title>Long-term modification of cortical synapses improves sensory perception</article-title>. <source>Nat Neurosci</source> <volume>16</volume>:<fpage>79</fpage>–<lpage>88</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fukushima</surname> <given-names>M</given-names></string-name>, <string-name><surname>Chao</surname> <given-names>ZC</given-names></string-name>, <string-name><surname>Fujii</surname> <given-names>N</given-names></string-name></person-group> (<year>2015</year>) <article-title>Studying brain functions with mesoscopic measurements: Advances in electrocorticography for non-human primates</article-title>. <source>Curr Opin Neurobiol</source> <volume>32</volume>:<fpage>124</fpage>–<lpage>131</lpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Glennon</surname> <given-names>E</given-names></string-name>, <string-name><surname>Svirsky</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Froemke</surname> <given-names>RC</given-names></string-name></person-group> (<year>2020</year>) <article-title>Auditory cortical plasticity in cochlear implant users</article-title>. <source>Curr Opin Neurobiol</source> <volume>60</volume>:<fpage>108</fpage>–<lpage>114</lpage>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Glennon</surname> <given-names>E</given-names></string-name>, <string-name><surname>Valtcheva</surname> <given-names>S</given-names></string-name>, <string-name><surname>Zhu</surname> <given-names>A</given-names></string-name>, <string-name><surname>Wadghiri</surname> <given-names>YZ</given-names></string-name>, <string-name><surname>Svirsky</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Froemke</surname> <given-names>RC</given-names></string-name></person-group> (<year>2023</year>) <article-title>Locus coeruleus activity improves cochlear implant performance</article-title>. <source>Nature</source> <volume>613</volume>:<fpage>317</fpage>–<lpage>323</lpage>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Glennon</surname> <given-names>E</given-names></string-name>, <string-name><surname>Carcea</surname> <given-names>I</given-names></string-name>, <string-name><surname>Martins</surname> <given-names>ARO</given-names></string-name>, <string-name><surname>Multani</surname> <given-names>J</given-names></string-name>, <string-name><surname>Shehu</surname> <given-names>I</given-names></string-name>, <string-name><surname>Svirsky</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Froemke</surname> <given-names>RC</given-names></string-name></person-group> (<year>2019</year>) <article-title>Locus coeruleus activation accelerates perceptual learning</article-title>. <source>Brain Res</source> <volume>1709</volume>:<fpage>39</fpage>–<lpage>49</lpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hays</surname> <given-names>SA</given-names></string-name>, <string-name><surname>Rennaker</surname> <given-names>RL</given-names></string-name>, <string-name><surname>Kilgard</surname> <given-names>MP</given-names></string-name></person-group> (<year>2013</year>) <article-title>Targeting plasticity with vagus nerve stimulation to treat neurological disease</article-title>. <source>Prog Brain Res</source> <volume>207</volume>:<fpage>275</fpage>–<lpage>299</lpage>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hochmair</surname> <given-names>ES</given-names></string-name>, <string-name><surname>Hochmair-Desoyer</surname> <given-names>IJ</given-names></string-name></person-group> (<year>1981</year>) <article-title>An implanted auditory eight channel stimulator for the deaf</article-title>. <source>Med Biol Eng Comput</source> <volume>19</volume>:<fpage>141</fpage>–<lpage>148</lpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hochmair</surname> <given-names>I</given-names></string-name>, <etal>et al.</etal></person-group> (<year>2006</year>) <article-title>MED-EL cochlear implants: State of the art and a glimpse into the future</article-title>. <source>Trends Amplif</source> <volume>10</volume>:<fpage>201</fpage>–<lpage>219</lpage>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Holden</surname> <given-names>LK</given-names></string-name>, <string-name><surname>Finley</surname> <given-names>CC</given-names></string-name>, <string-name><surname>Firszt</surname> <given-names>JB</given-names></string-name>, <string-name><surname>Holden</surname> <given-names>TA</given-names></string-name>, <string-name><surname>Brenner</surname> <given-names>C</given-names></string-name>, <string-name><surname>Potts</surname> <given-names>LG</given-names></string-name>, <string-name><surname>Gotter</surname> <given-names>BD</given-names></string-name>, <string-name><surname>Vanderhoof</surname> <given-names>SS</given-names></string-name>, <string-name><surname>Mispagel</surname> <given-names>K</given-names></string-name>, <string-name><surname>Heydebrand</surname> <given-names>G</given-names></string-name>, <string-name><surname>Skinner</surname> <given-names>MW</given-names></string-name></person-group> (<year>2013</year>) <article-title>Factors affecting open-set word recognition in adults with cochlear implants</article-title>. <source>Ear Hear</source> <volume>34</volume>:<fpage>342</fpage>–<lpage>360</lpage>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>House</surname> <given-names>WF</given-names></string-name>, <string-name><surname>Urban</surname> <given-names>J</given-names></string-name></person-group> (<year>1973</year>) <article-title>Long term results of electrode implantation and electronic stimulation of the cochlea in man</article-title>. <source>Ann Otol Rhinol Laryngol</source> <volume>82</volume>:<fpage>504</fpage>–<lpage>517</lpage>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Insanally</surname> <given-names>M</given-names></string-name>, <string-name><surname>Trumpis</surname> <given-names>M</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>C</given-names></string-name>, <string-name><surname>Chiang</surname> <given-names>C-H</given-names></string-name>, <string-name><surname>Woods</surname> <given-names>V</given-names></string-name>, <string-name><surname>Palopoli-Trojani</surname> <given-names>K</given-names></string-name>, <string-name><surname>Bossi</surname> <given-names>S</given-names></string-name>, <string-name><surname>Froemke</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Viventi</surname> <given-names>J</given-names></string-name></person-group> (<year>2016</year>) <article-title>A low-cost, multiplexedμECoG system for high-density recordings in freely moving rodents</article-title>. <source>J Neural Eng</source> <volume>13</volume>:<fpage>026030</fpage>–<lpage>26030</lpage>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Insanally</surname> <given-names>MN</given-names></string-name>, <string-name><surname>Albanna</surname> <given-names>BF</given-names></string-name>, <string-name><surname>Toth</surname> <given-names>J</given-names></string-name>, <string-name><surname>DePasquale</surname> <given-names>B</given-names></string-name>, <string-name><surname>Fadaei</surname> <given-names>SS</given-names></string-name>, <string-name><surname>Gupta</surname> <given-names>T</given-names></string-name>, <string-name><surname>Lombardi</surname> <given-names>O</given-names></string-name>, <string-name><surname>Kuchibhotla</surname> <given-names>K</given-names></string-name>, <string-name><surname>Rajan</surname> <given-names>K</given-names></string-name>, <string-name><surname>Froemke</surname> <given-names>RC</given-names></string-name></person-group> (<year>2024</year>) <article-title>Contributions of cortical neuron firing patterns, synaptic connectivity, and plasticity to task performance</article-title>. <source>Nat Commun</source> <volume>15</volume>:<fpage>6023</fpage>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Janiukstyte</surname> <given-names>V</given-names></string-name>, <string-name><surname>Owen</surname> <given-names>TW</given-names></string-name>, <string-name><surname>Chaudhary</surname> <given-names>UJ</given-names></string-name>, <string-name><surname>Diehl</surname> <given-names>B</given-names></string-name>, <string-name><surname>Lemieux</surname> <given-names>L</given-names></string-name>, <string-name><surname>Duncan</surname> <given-names>JS</given-names></string-name>, <string-name><surname>de Tisi</surname> <given-names>J</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Taylor</surname> <given-names>PN</given-names></string-name></person-group> (<year>2023</year>) <article-title>Normative brain mapping using scalp EEG and potential clinical application</article-title>. <source>Sci Rep</source> <volume>13</volume>:<fpage>13442</fpage>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jasper</surname> <given-names>H</given-names></string-name>, <string-name><surname>Penfield</surname> <given-names>W</given-names></string-name></person-group> (<year>1949</year>) <article-title>Electrocorticograms in man: Effect of voluntary movement upon the electrical activity of the precentral gyrus</article-title>. <source>Archiv für Psychiatrie und Nervenkrankheiten</source> <volume>183</volume>:<fpage>163</fpage>–<lpage>174</lpage>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Johnson</surname> <given-names>KA</given-names></string-name> <etal>et al.</etal></person-group> (<year>2024</year>) <article-title>Proceedings of the 11th Annual Deep Brain Stimulation Think Tank: pushing the forefront of neuromodulation with functional network mapping, biomarkers for adaptive DBS, bioethical dilemmas, AI-guided neuromodulation, and translational advancements</article-title>. <source>Front Hum Neurosci</source> <volume>18</volume>:<fpage>1320806</fpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Johnson</surname> <given-names>LA</given-names></string-name>, <string-name><surname>Della Santina</surname> <given-names>CC</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>X</given-names></string-name></person-group> (<year>2016</year>) <article-title>Selective neuronal activation by cochlear implant stimulation in auditory cortex of awake primate</article-title>. <source>J Neurosci</source> <volume>36</volume>:<fpage>12468</fpage>–<lpage>12484</lpage>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Keating</surname> <given-names>P</given-names></string-name>, <string-name><surname>Nodal</surname> <given-names>FR</given-names></string-name>, <string-name><surname>Gananandan</surname> <given-names>K</given-names></string-name>, <string-name><surname>Schulz</surname> <given-names>AL</given-names></string-name>, <string-name><surname>King</surname> <given-names>AJ</given-names></string-name></person-group> (<year>2013</year>) <article-title>Behavioral sensitivity to broadband binaural localization cues in the ferret</article-title>. <source>J Assoc Res Otolaryngol</source> <volume>14</volume>:<fpage>561</fpage>–<lpage>572</lpage>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>King</surname> <given-names>J</given-names></string-name>, <string-name><surname>Shehu</surname> <given-names>I</given-names></string-name>, <string-name><surname>Roland</surname> <given-names>JT</given-names>, <suffix>Jr.</suffix></string-name>, <string-name><surname>Svirsky</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Froemke</surname> <given-names>RC</given-names></string-name></person-group> (<year>2016</year>) <article-title>A physiological and behavioral system for hearing restoration with cochlear implants</article-title>. <source>J Neurophysiol</source> <volume>116</volume>:<fpage>844</fpage>–<lpage>858</lpage>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Klinke</surname> <given-names>R</given-names></string-name>, <string-name><surname>Kral</surname> <given-names>A</given-names></string-name>, <string-name><surname>Heid</surname> <given-names>S</given-names></string-name>, <string-name><surname>Tillein</surname> <given-names>J</given-names></string-name>, <string-name><surname>Hartmann</surname> <given-names>R</given-names></string-name></person-group> (<year>1999</year>) <article-title>Recruitment of the auditory cortex in congenitally deaf cats by long-term cochlear electrostimulation</article-title>. <source>Science</source> <volume>285</volume>:<fpage>1729</fpage>–<lpage>1733</lpage>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kolda</surname> <given-names>TG</given-names></string-name>, <string-name><surname>Bader</surname> <given-names>BW</given-names></string-name></person-group> (<year>2009</year>) <article-title>Tensor Decompositions and Applications</article-title>. <source>SIAM Review</source> <volume>51</volume>:<fpage>455</fpage>–<lpage>500</lpage>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kral</surname> <given-names>A</given-names></string-name>, <etal>et al.</etal></person-group> (<year>2002</year>) <article-title>Hearing after congenital deafness: Central auditory plasticity and sensory deprivation</article-title>. <source>Cereb Cortex</source> <volume>12</volume>:<fpage>797</fpage>–<lpage>807</lpage>.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kral</surname> <given-names>A</given-names></string-name>, <string-name><surname>Eggermont</surname> <given-names>JJ</given-names></string-name></person-group> (<year>2007</year>) <article-title>What’s to lose and what’s to learn: Development under auditory deprivation, cochlear implants and limits of cortical plasticity</article-title>. <source>Brain Res Rev</source> <volume>56</volume>:<fpage>259</fpage>–<lpage>269</lpage>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Martins</surname> <given-names>ARO</given-names></string-name>, <string-name><surname>Froemke</surname> <given-names>RC</given-names></string-name></person-group> (<year>2015</year>) <article-title>Coordinated forms of noradrenergic plasticity in the locus coeruleus and primary auditory cortex</article-title>. <source>Nat Neurosci</source> <volume>18</volume>:<fpage>1483</fpage>–<lpage>1492</lpage>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McDermott</surname> <given-names>HJ</given-names></string-name></person-group> (<year>2004</year>) <article-title>Music perception with cochlear implants: a review</article-title>. <source>Trends Amplif</source> <volume>8</volume>:<fpage>49</fpage>–<lpage>82</lpage>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Merzenich</surname> <given-names>MM</given-names></string-name>, <string-name><surname>Knight</surname> <given-names>PL</given-names></string-name>, <string-name><surname>Roth</surname> <given-names>GL</given-names></string-name></person-group> (<year>1973</year>) <article-title>Cochleotopic organization of primary auditory cortex in the cat</article-title>. <source>Brain Res</source> <volume>63</volume>:<fpage>343</fpage>–<lpage>346</lpage>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mesgarani</surname> <given-names>N</given-names></string-name>, <string-name><surname>Cheung</surname> <given-names>C</given-names></string-name>, <string-name><surname>Johnson</surname> <given-names>K</given-names></string-name>, <string-name><surname>Chang</surname> <given-names>EF</given-names></string-name></person-group> (<year>2014</year>) <article-title>Phonetic feature encoding in human superior temporal gyrus</article-title>. <source>Science</source> <volume>343</volume>:<fpage>1006</fpage>–<lpage>1010</lpage>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Michelson</surname> <given-names>RP</given-names></string-name></person-group> (<year>1971</year>) <article-title>The results of electrical stimulation of the cochlea in human sensory deafness</article-title>. <source>Ann Otol Rhinol Laryngol</source> <volume>80</volume>:<fpage>914</fpage>–<lpage>919</lpage>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Middlebrooks</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Bierer</surname> <given-names>JA</given-names></string-name></person-group> (<year>2002</year>) <article-title>Auditory cortical images of cochlear-implant stimuli: coding of stimulus channel and current level</article-title>. <source>J Neurophysiol</source> <volume>87</volume>:<fpage>493</fpage>–<lpage>507</lpage>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Moore</surname> <given-names>DR</given-names></string-name>, <string-name><given-names>RV</given-names> <surname>Shannon</surname></string-name></person-group> (<year>2009</year>) <article-title>Beyond cochlear implants: awakening the deafened brain</article-title>. <source>Nat Neurosci</source> <volume>12</volume>:<fpage>686</fpage>–<lpage>691</lpage>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Norman-Haignere</surname> <given-names>SV</given-names></string-name>, <string-name><surname>Long</surname> <given-names>LK</given-names></string-name>, <string-name><surname>Mesgarani</surname> <given-names>N</given-names></string-name>, <string-name><surname>Devinsky</surname> <given-names>O</given-names></string-name>, <string-name><surname>Flinker</surname> <given-names>A</given-names></string-name>, <string-name><surname>Doyle</surname> <given-names>W</given-names></string-name>, <string-name><surname>Irobunda</surname> <given-names>I</given-names></string-name>, <string-name><surname>Merricks</surname> <given-names>EM</given-names></string-name>, <string-name><surname>Schevon</surname> <given-names>CA</given-names></string-name>, <string-name><surname>Feldstein</surname> <given-names>NA</given-names></string-name>, <string-name><surname>McKhann</surname> <given-names>GM</given-names></string-name></person-group> (<year>2022</year>) <article-title>Multiscale temporal integration organizes hierarchical computation in human auditory cortex</article-title>. <source>Nat Hum Behav</source> <volume>6</volume>:<fpage>455</fpage>–<lpage>469</lpage>-469.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nourski</surname> <given-names>KV</given-names></string-name>, <string-name><surname>Etler</surname> <given-names>CP</given-names></string-name>, <string-name><surname>Brugge</surname> <given-names>JF</given-names></string-name>, <string-name><surname>Oya</surname> <given-names>H</given-names></string-name>, <string-name><surname>Kawasaki</surname> <given-names>H</given-names></string-name>, <string-name><surname>Reale</surname> <given-names>RA</given-names></string-name>, <string-name><surname>Abbas</surname> <given-names>PJ</given-names></string-name>, <string-name><surname>Brown</surname> <given-names>CJ</given-names></string-name>, <string-name><surname>Howard</surname> <given-names>MA</given-names></string-name></person-group> (<year>2013</year>) <article-title>Direct recordings from the auditory cortex in a cochlear implant user</article-title>. <source>J Assoc Res Otolaryngol</source> <volume>14</volume>:<fpage>435</fpage>–<lpage>450</lpage>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Polley</surname> <given-names>DB</given-names></string-name>, <string-name><surname>Read</surname> <given-names>HL</given-names></string-name>, <string-name><surname>Storace</surname> <given-names>DA</given-names></string-name>, <string-name><surname>Merzenich</surname> <given-names>MM</given-names></string-name></person-group> (<year>2007</year>) <article-title>Multiparametric auditory receptive field organization across five cortical fields in the albino rat</article-title>. <source>J Neurophysiol</source> <volume>97</volume>:<fpage>3621</fpage>–<lpage>3638</lpage>.</mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ray</surname> <given-names>S</given-names></string-name>, <string-name><surname>Maunsell</surname> <given-names>JH</given-names></string-name></person-group> (<year>2011</year>) <article-title>Different origins of gamma rhythm and high-gamma activity in macaque visual cortex</article-title>. <source>PLoS Biol</source> <volume>9</volume>:<fpage>e1000610</fpage>.</mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Simmons</surname> <given-names>FB</given-names></string-name>, <string-name><surname>Epley</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Lummis</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Guttman</surname> <given-names>N</given-names></string-name>, <string-name><surname>Frishkopf</surname> <given-names>LS</given-names></string-name>, <string-name><surname>Harmon</surname> <given-names>LD</given-names></string-name>, <string-name><surname>Zwicker</surname> <given-names>E</given-names></string-name></person-group> (<year>1965</year>) <article-title>Auditory Nerve: Electrical Stimulation in Man</article-title>. <source>Science</source> <volume>148</volume>:<fpage>104</fpage>–<lpage>106</lpage>.</mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stronks</surname>, <given-names>HC</given-names></string-name>, <string-name><surname>Arendsen</surname> <given-names>TS</given-names></string-name>, <string-name><surname>Veenstra</surname> <given-names>M</given-names></string-name>, <string-name><surname>Boermans</surname> <given-names>P-PBM</given-names></string-name>, <string-name><surname>Briaire</surname> <given-names>JJ</given-names></string-name>, <string-name><surname>Frijns</surname> <given-names>JHM</given-names></string-name></person-group> (<year>2025</year>) <article-title>Effects of preoperative factors on the learning curves of postlingual cochlear implant recipients</article-title>. <source>Ear Hear</source> (in press).</mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Svirsky</surname> <given-names>M</given-names></string-name></person-group> (<year>2017</year>) <article-title>Cochlear implants and electronic hearing</article-title>. <source>Physics Today</source> <volume>70</volume>:<fpage>52</fpage>–<lpage>58</lpage>.</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tang</surname> <given-names>C</given-names></string-name>, <string-name><surname>Hamilton</surname> <given-names>LS</given-names></string-name>, <string-name><surname>Chang</surname> <given-names>EF</given-names></string-name></person-group> (<year>2017</year>) <article-title>Intonational speech prosody encoding in the human auditory cortex</article-title>. <source>Science</source> <volume>357</volume>:<fpage>797</fpage>–<lpage>801</lpage>.</mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Trumpis</surname> <given-names>M</given-names></string-name>, <string-name><surname>Insanally</surname> <given-names>M</given-names></string-name>, <string-name><surname>Zou</surname> <given-names>J</given-names></string-name>, <string-name><surname>Elsharif</surname> <given-names>A</given-names></string-name>, <string-name><surname>Ghomashchi</surname> <given-names>A</given-names></string-name>, <string-name><surname>Sertac Artan</surname> <given-names>N</given-names></string-name>, <string-name><surname>Froemke</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Viventi</surname> <given-names>J</given-names></string-name></person-group> (<year>2017</year>) <article-title>A low-cost, scalable, current-sensing digital headstage for high channel count muECoG</article-title>. <source>J Neural Eng</source> <volume>14</volume>:<fpage>026009</fpage>.</mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vermeire</surname> <given-names>K</given-names></string-name>, <string-name><surname>Landsberger</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Schleich</surname> <given-names>P</given-names></string-name>, <string-name><surname>Van de Heyning</surname> <given-names>PH</given-names></string-name></person-group> (<year>2013</year>) <article-title>Multidimensional scaling between acoustic and electric stimuli in cochlear implant users with contralateral hearing</article-title>. <source>Hear Res</source> <volume>306</volume>:<fpage>29</fpage>–<lpage>36</lpage>.</mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vollmer</surname> <given-names>M</given-names></string-name>, <string-name><surname>Beitel</surname> <given-names>RE</given-names></string-name></person-group> (<year>2011</year>) <article-title>Behavioral training restores temporal processing in auditory cortex of long-deaf cats</article-title>. <source>J Neurophysiol</source> <volume>106</volume>:<fpage>2423</fpage>–<lpage>2436</lpage>.</mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Walzl</surname> <given-names>EM</given-names></string-name>, <string-name><surname>Woolsey</surname> <given-names>CN</given-names></string-name></person-group> (<year>1946</year>) <article-title>Effects of cochlear lesions on click responses in the auditory cortex of the cat</article-title>. <source>Bull Johns Hopkins Hosp</source> <volume>79</volume>:<fpage>309</fpage>–<lpage>319</lpage>.</mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Williams</surname> <given-names>AH</given-names></string-name>, <string-name><surname>Kim</surname> <given-names>TH</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>F</given-names></string-name>, <string-name><surname>Vyas</surname> <given-names>S</given-names></string-name>, <string-name><surname>Ryu</surname> <given-names>SI</given-names></string-name>, <string-name><surname>Shenoy</surname> <given-names>KV</given-names></string-name>, <string-name><surname>Schnitzer</surname> <given-names>M</given-names></string-name>, <string-name><surname>Kolda</surname> <given-names>TG</given-names></string-name>, <string-name><surname>Ganguli</surname> <given-names>S</given-names></string-name></person-group> (<year>2018</year>) <article-title>Unsupervised Discovery of Demixed, Low-Dimensional Neural Dynamics across Multiple Timescales through Tensor Component Analysis</article-title>. <source>Neuron</source> <volume>98</volume>:<fpage>1099</fpage>–<lpage>1115</lpage>.</mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wilson</surname> <given-names>BS</given-names></string-name>, <string-name><surname>Finley</surname> <given-names>CC</given-names></string-name>, <string-name><surname>Lawson</surname> <given-names>DT</given-names></string-name>, <string-name><surname>Wolford</surname> <given-names>RD</given-names></string-name>, <string-name><surname>Eddington</surname> <given-names>DK</given-names></string-name>, <string-name><surname>Rabinowitz</surname> <given-names>WM</given-names></string-name></person-group> (<year>1991</year>) <article-title>Better speech recognition with cochlear implants</article-title>. <source>Nature</source> <volume>352</volume>:<fpage>236</fpage>–<lpage>238</lpage>.</mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wilson</surname> <given-names>BS</given-names></string-name>, <string-name><given-names>MF</given-names> <surname>Dorman</surname></string-name></person-group> (<year>2008</year>) <article-title>Cochlear implants: A remarkable past and a brilliant future</article-title>. <source>Hear Res</source> <volume>242</volume>:<fpage>3</fpage>–<lpage>21</lpage>.</mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Woods</surname> <given-names>V</given-names></string-name>, <string-name><surname>Trumpis</surname> <given-names>M</given-names></string-name>, <string-name><surname>Bent</surname> <given-names>B</given-names></string-name>, <string-name><surname>Palopoli-Trojani</surname> <given-names>K</given-names></string-name>, <string-name><surname>Chiang</surname> <given-names>C-H</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>C</given-names></string-name>, <string-name><surname>Yu</surname> <given-names>C</given-names></string-name>, <string-name><surname>Insanally</surname> <given-names>MN</given-names></string-name>, <string-name><surname>Froemke</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Viventi</surname> <given-names>J</given-names></string-name></person-group> (<year>2018</year>) <article-title>Long-term recording reliability of liquid crystal polymer µECoG arrays</article-title>. <source>J Neural Eng</source> <volume>15</volume>:<fpage>066024</fpage>.</mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zeng</surname> <given-names>FG</given-names></string-name></person-group> (<year>2022</year>) <article-title>Celebrating the one millionth cochlear implant</article-title>. <source>JASA Express Lett</source> <volume>2</volume>:<fpage>077201</fpage>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108550.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Bathellier</surname>
<given-names>Brice</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-9211-1960</contrib-id>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/00675rp98</institution-id><institution>Centre National pour la Recherche Scientifique et Technique (CNRST)</institution>
</institution-wrap>
<city>Paris</city>
<country>France</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>valuable</bold> study compares auditory cortex responses to sounds and cochlear implant stimulation measured with surface electrode grids in rats. Beyond the reduced frequency resolution of cochlear implants observed previously, this study suggests key discrepancies between neuronal representations of cochlear stimulations and natural sounds. However, the evidence for this potentially interesting result is <bold>incomplete</bold> because there is a lack of evidence for the effectiveness of the comparison method. This study is of interest to researchers in the auditory neuroscience field and clinicians implementing treatments with cochlear implants.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108550.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This manuscript addresses an important question: whether cortical population codes for cochlear-implant (CI) stimulation resemble those for natural acoustic input or constitute a qualitatively different representation. The authors record intracranial EEG (µECoG) responses to pure tones in normal-hearing rats and to single-channel CI pulses in bilaterally deafened, acutely implanted rats, analysing the data with ERP/high-gamma measures, tensor component analysis (TCA), and information-theoretic decoding. Across several readouts, the acoustic condition supports better single-trial stimulus classification than the CI condition. However, stronger decoding does not, on its own, establish that the acoustic responses instantiate a &quot;richer&quot; cortical code, and the evidence for orderly spatial organisation is not compelling for CI, and is also less evident than expected for normal-hearing, given prior knowledge. The overall narrative is interesting, but at present, the conclusions outpace the data because of statistical, methodological, and presentation issues.</p>
<p>Strengths:</p>
<p>The study poses a timely, clinically relevant question with clear implications for CI strategy. The analytical toolkit is appropriate: µECoG captures mesoscale patterns; TCA offers a transparent separation of spatial and temporal structure; and mutual-information decoding provides an interpretable measure of single-trial discriminability. Within-subject recordings in a subset of animals, in principle, help isolate modality effects from inter-animal variability. Where analyses are most direct, the acoustic condition yields higher single-trial decoding accuracy, which is a meaningful and clearly presented result.</p>
<p>Weaknesses:</p>
<p>Several limitations constrain how far the conclusions can be taken. Parts of the statistical treatment do not match the data structure: some comparisons mix paired and unpaired animals but are analysed as fully paired, raising concerns about misestimated uncertainty. Methodological reporting is incomplete in places; essential parameters for both acoustic and electrical stimulation, as well as objective verification of implantation and deafening, are not described with sufficient detail to support confident interpretation or replication. Figure-level clarity also undermines the message. In Figure 2, non-significant slopes for CI, repeated identification of a single &quot;best channel,&quot; mismatched axes, and unclear distinctions between example and averaged panels make the assertion of spatial organisation unconvincing; importantly, the normal-hearing panels also do not display tonotopy as clearly as expected, which weakens the key contrast the paper seeks to establish. Finally, the decoding claims would be strengthened by simple internal controls, such as within-modality train/test splits and decoding on raw ERP/high-gamma features to demonstrate that poor cross-modal transfer reflects genuine differences in the underlying responses rather than limitations of the modelling pipeline.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108550.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This article reports measurements of iEEG signals on the rat auditory cortex during cochlear implant or sound stimulation in separate groups of rats. The observations indicate some spatial organization of cochlear implant stimuli, but that is very different from cochlear implants.</p>
<p>Strengths:</p>
<p>The study includes interesting analyses of the sound and cochlear implant representation structure based on decoders.</p>
<p>Weaknesses:</p>
<p>The observation that responses to cochlear implant stimulation (stimulation) are spatially organized is not new (e.g., Adenis et al. 2024).</p>
<p>The claim that spatial and temporal dimensions contribute information about the sound is also not new; there is a large literature on this topic. Moreover, the results shown here are extremely weak. They show similar levels of information in the spatial and temporal dimensions, and no synergy between the two dimensions. This is however, likely the consequence of high measurement noise leading to poor accuracy in the information estimates, as the authors state.</p>
<p>The main claim of the study - the mismatch between cochlear implant and sound representation - is not supported. The responses to each modality are measured in different animals. The authors do not show that they actually can compare representations across animals (e.g., for the same sounds). Without this positive control, there is no reason to think that it is possible to decode from one animal with a decoder trained on another, and the negative result shown by the authors is therefore not surprising.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.108550.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Through micro-electroencephalography, Hight and colleagues studied how the auditory cortex in its ensemble responds to cochlear implant stimulation compared to the classic pure tones. Taking advantage of a double-implanted rat model (Micro-ECoG and Cochlear Implant), they tracked and analyzed changes happening in the temporal and spatial aspects of the cortical evoked responses in both normal hearing and cochlear-implanted animals. After establishing that single-trial responses were sufficient to encode the stimuli's properties, the authors then explored several decoder architectures to study the cortex's ability to encode each stimulus modality in a similar or different manner. They conclude that a) intracranial EEG evoked responses can be accurately recorded and did not differed between normal hearing and cochlear-implanted rats; b) Although coarsely spatially organized, CI-evoked responses had higher trial-by-trial variability than pure tones; c) Stimulus identity is independently represented by temporal and spatial aspect of cortical representations and can be accurately decoded by various means from single trials; d) and that Pure tones trained decoder can't decode CI-stimulus identity accurately.</p>
<p>Strength:</p>
<p>The model combining micro-eCoG and cochlear implantation and the methodology to extract both the Event Related Potentials (ERPs) and High-Gammas (HGs) is very well designed and appropriately analyzed. Likewise, the PCA-LDA and TCA-LDA are powerful tools that take full advantage of the information provided by the cortical ensembles.</p>
<p>The overall structure of the paper, with a paced and exhaustive progress through each step and evolution of the decoder, is very appreciable and easy to follow. The exploration of single-trial encoding and stimulus identity through temporal and spatial domains is providing new avenues to characterize the cortical responses to CI stimulations and their central representation. The fact that single trials suffice to decode the stimulus identity regardless of their modality is of great interest and noteworthy. Although the authors confirm that iEEG remains difficult to transpose in the clinic, the insights provided by the study confirm the potential benefit of using central decoders to help in clinic settings.</p>
<p>Weaknesses:</p>
<p>The conclusion of the paper, especially the concept of distinct cortical encoding for each modality, is unfortunately partially supported by the results, as the authors did not adequately consider fundamental limitations of CI-related stimulation.</p>
<p>First, the reviewer assumed that the authors stimulated in a Monopolar mode, which, albeit being clinically relevant, notoriously generates a high current spread in rodent models. Second, comparing the averaged BF maps for iEEG (Figure 2A, C), BFs ranged from 4 to 16kHz with a predominance of 4kHz BFs. The lack of BFs at higher frequencies hints at a potential location mismatch between the frequency range sampled at the level of the cortex (low to medium frequencies) and the frequency range covered by the CI inserted mostly in the first turn-and-a-half of the cochlea (high to medium frequencies). Looking at Figure 2F (and to some extent 2A), most of the CI electrodes elicited responses around the 4kHz regions, and averaged maps show a predominance of CI-3-4 across the cortex (Figure 2C, H) from areas with 4kHz BF to areas with 16kHz BF. It is doubtful that CI-3-4 are located near the 4kHz region based on Müller's work (1991) on the frequency representation in the rat cochlea.</p>
<p>Taken together with the Pearsons correlations being flat, the decoder examples showing a strong ability to identify CI-4 and 3 and the Fig-8D, E presenting a strong prediction of 4kHz and 8kHz for all the CI electrodes when using a pure tone trained decoder, it is possible that current spread ended stimulating indistinctly higher turns of the cochlea or even the modiolus in a non-specific manner, greatly reducing (or smearing) the place-coding/frequency resolution of each electrode, which in turn could explain the coarse topographic (or coarsely tonotopic according to the manuscript) organization of the cortical responses. Thus, the conclusion that there are distinct encodings for each modality is biased, as it might not account for monopolar smearing. To that end, and since it is the study's main message and title, it would have benefited from having a subgroup of animals using bipolar stimulations (or any focused strategy since they provide reduced current spread) to compare the spatial organization of iEEG responses and the performances of the different decoders to dismiss current spread and strengthen their conclusion.</p>
<p>Nevertheless, the reviewer wants to reiterate that the study proposed by Hight et al. is well constructed, relevant to the field, and that the overall proposal of improving patient performances and helping their adaptation in the first months of CI use by studying central responses should be pursued as it might help establish new guidelines or create new clinical tools.</p>
</body>
</sub-article>
</article>