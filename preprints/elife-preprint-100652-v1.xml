<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">100652</article-id>
<article-id pub-id-type="doi">10.7554/eLife.100652</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.100652.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Robust variability of grid cell properties within individual grid modules enhances encoding of local space</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4147-2026</contrib-id>
<name>
<surname>Redman</surname>
<given-names>William T</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n1">†</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0003-6698-476X</contrib-id>
<name>
<surname>Acosta-Mendoza</surname>
<given-names>Santiago</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">†</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2761-477X</contrib-id>
<name>
<surname>Wei</surname>
<given-names>Xue-Xin</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="aff" rid="a5">5</xref>
<xref ref-type="aff" rid="a6">6</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5366-8501</contrib-id>
<name>
<surname>Goard</surname>
<given-names>Michael J</given-names>
</name>
<xref ref-type="aff" rid="a7">7</xref>
<xref ref-type="aff" rid="a8">8</xref>
<xref ref-type="aff" rid="a9">9</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Interdepartmental Graduate Program in Dynamical Neuroscience, University of California</institution>, Santa Barbara</aff>
<aff id="a2"><label>2</label><institution>Intelligent Systems Center, Johns Hopkins University Applied Physics Lab</institution></aff>
<aff id="a3"><label>3</label><institution>Department of Neuroscience, The University of Texas at Austin</institution></aff>
<aff id="a4"><label>4</label><institution>Department of Psychology, The University of Texas at Austin</institution></aff>
<aff id="a5"><label>5</label><institution>Center for Perceptual Systems, The University of Texas at Austin</institution></aff>
<aff id="a6"><label>6</label><institution>Center for Theoretical and Computational Neuroscience, The University of Texas at Austin</institution></aff>
<aff id="a7"><label>7</label><institution>Department of Psychological and Brain Sciences, University of California</institution>, Santa Barbara</aff>
<aff id="a8"><label>8</label><institution>Department of Molecular, Cellular, and Developmental Biology, University of California</institution>, Santa Barbara</aff>
<aff id="a9"><label>9</label><institution>Neuroscience Research Institute, University of California Santa Barbara</institution></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Peyrache</surname>
<given-names>Adrien</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>McGill University</institution>
</institution-wrap>
<city>Montreal</city>
<country>Canada</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Poirazi</surname>
<given-names>Panayiota</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>FORTH Institute of Molecular Biology and Biotechnology</institution>
</institution-wrap>
<city>Heraklion</city>
<country>Greece</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>Corresponding author; email: <email>wredman@ucsb.edu</email></corresp>
<fn id="n1" fn-type="equal"><label>†</label><p>Equal contribution</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-09-13">
<day>13</day>
<month>09</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP100652</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-07-01">
<day>01</day>
<month>07</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-06-13">
<day>13</day>
<month>06</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.02.27.582373"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Redman et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Redman et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-100652-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Although grid cells are one of the most well studied functional classes of neurons in the mammalian brain, the assumption that there is a single grid orientation and spacing per grid module has not been carefully tested. We investigate and analyze a recent large-scale recording of medial entorhinal cortex to characterize the presence and degree of heterogeneity of grid properties within individual modules. We find evidence for small, but robust, variability and hypothesize that this property of the grid code could enhance the ability of encoding local spatial information. Performing analysis on synthetic populations of grid cells, where we have complete control over the amount heterogeneity in grid properties, we demonstrate that variability, of a similar magnitude to the analyzed data, leads to significantly decreased decoding error, even when restricted to activity from a single module. Our results highlight how the heterogeneity of the neural response properties may benefit coding and opens new directions for theoretical and experimental analysis of grid cells.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Added decoding of spatial position from a single grid cell module; revised figures and text to address comments from v1 preprint and from CoSyNe meeting.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<p>The discovery of grid cells in medial entorhinal cortex (MEC) [<xref ref-type="bibr" rid="c1">1</xref>] has led to considerable experimental and computational work aimed at identifying their origin [<xref ref-type="bibr" rid="c2">2</xref>–<xref ref-type="bibr" rid="c12">12</xref>] and their function [<xref ref-type="bibr" rid="c13">13</xref>–<xref ref-type="bibr" rid="c21">21</xref>]. The organization of grid cells into discrete modules [<xref ref-type="bibr" rid="c22">22</xref>, <xref ref-type="bibr" rid="c23">23</xref>], with particular grid properties (grid spacing and orientation) conserved within module, but not between modules, has fundamentally shaped this research. For instance, the increasing size and spacing of grid modules along the dorsal-ventral axis of MEC, by discontinuous jumps of a near constant ratio, has been argued to be optimal for encoding local spatial information [<xref ref-type="bibr" rid="c24">24</xref>, <xref ref-type="bibr" rid="c25">25</xref>], when grid cell activity across all modules is integrated together [<xref ref-type="bibr" rid="c24">24</xref>–<xref ref-type="bibr" rid="c28">28</xref>]. This is despite the fact that the hippocampus, a downstream target of the MEC, receives inputs from only a portion of the dorsal-ventral axis [<xref ref-type="bibr" rid="c29">29</xref>]. The modularity of the grid system has also been proposed to simplify the wiring necessary for generating continuous attractor dynamics [<xref ref-type="bibr" rid="c2">2</xref>, <xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c16">16</xref>], a computational mechanism theorized to underlie grid cells function that enjoys considerable experimental support [<xref ref-type="bibr" rid="c23">23</xref>, <xref ref-type="bibr" rid="c30">30</xref>–<xref ref-type="bibr" rid="c34">34</xref>].</p>
<p>Much of this prior theoretical work has made the additional assumption that grid cell properties are identical, up to a phase shift, within a single module. However, the distributions of measured orientation and spacing show non-zero variability [<xref ref-type="bibr" rid="c22">22</xref>, <xref ref-type="bibr" rid="c30">30</xref>, <xref ref-type="bibr" rid="c34">34</xref>]. This could be due to finite recording time, neurophysiological noise, or the sensitivity of numerical methods used to fit grid properties. Alternatively, this variability could reflect underlying inhomogeneity, at a fine scale, within modules. Despite the fundamental way in which grid cell function has been informed by their modular organization, to the best of our knowledge, no characterization of the degree and robustness of variability in grid properties within individual modules has been performed.</p>
<p>If robust variability of grid properties does exist, then it is possible that this heterogeneity could be exploited to encode additional information about local space, reducing the requirement of integration across multiple grid modules (<xref rid="fig1" ref-type="fig">Fig. 1</xref>). In particular, when all grid cells have the same grid orientation and spacing, the joint population activity has a translational invariance that persists, even as larger populations of grid cells are considered (<xref rid="fig1" ref-type="fig">Fig. 1</xref>, “Fixed grid properties within module”). In contrast, if grid cells within a module have variability in their grid orientation and spacing, then – over a <italic>finite</italic> area – the translational invariance of the population activity is broken, and distinct patterns emerge in distinct locations of space (<xref rid="fig1" ref-type="fig">Fig. 1</xref>, “Variable grid properties within module”). As an example, the blue and green grid cells in <xref rid="fig1" ref-type="fig">Fig. 1</xref> show the most overlap in the upper left half of the arena (denoted by cyan pixels), while the red and blue grid cells show the most overlap in the lower right portion of the arena (denoted by purple pixels). This is despite the fact that the variability in spacing and orientation is only on the order of a few centimeters and degrees, respectively.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Variability in grid cell properties within a module leads to enhanced encoding of local space.</title>
<p>When the activity of three idealized grid cells, all with the same grid spacing and orientation, are considered, the periodicity of the responses limits the amount of information conveyed about local space (Left column – “Fixed grid properties within module”). That is, there are multiple locations in physical space with identical population level activity. However, when three grid cells with variable grid spacing and orientation (in the realm of what is measured within individual grid modules – see Results), their joint activity contains considerably more information (Right column – “Variable grid properties within module”). This benefit of spatial inhomogeneity is expected to increase with larger populations of grid cells. Dashed squares in the joint activity map are enlarged below.</p></caption>
<graphic xlink:href="582373v2_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>In this paper, we perform detailed analysis of recent state-of-the-art MEC electrophysiological recordings, which were made publicly available [<xref ref-type="bibr" rid="c34">34</xref>]. We characterize the variability of grid orientation and spacing within individual modules, and find evidence for small, but robust, variability. This variability is present whether a single value of grid orientation and spacing is assigned to each grid cell, or whether grid distortion [<xref ref-type="bibr" rid="c35">35</xref>, <xref ref-type="bibr" rid="c36">36</xref>] is taken into account by considering three grid orientations and spacings independently. To assess the functional implications of this heterogeneity, we perform simulation experiments with synthetic, noisy grid cell populations, where we have complete control over the distribution of grid orientation and spacing. We find that the variability in grid cell orientation and spacing, at a similar degree as present in the data we analyze, leads to lower decoding error of local space when using the activity of a <italic>single</italic> module.</p>
<p>Taken together, our results challenge a long-held assumption and support a growing understanding of the spatial information encoded by grid cell populations [<xref ref-type="bibr" rid="c37">37</xref>–<xref ref-type="bibr" rid="c40">40</xref>]. Additionally, they encourage consideration of the broader benefits that multiple modules may provide, beyond the encoding of local space [<xref ref-type="bibr" rid="c41">41</xref>–<xref ref-type="bibr" rid="c43">43</xref>].</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Robust differences in grid cell properties within individual modules</title>
<p>To determine the extent to which variability of grid properties in individual modules exists, and to what extent this variability is a robust property of the grid code, we analyzed previously published MEC recordings [<xref ref-type="bibr" rid="c34">34</xref>], which include tens to hundreds of grid cells simultaneously recorded. This allows us to characterize the distribution of grid properties within a single grid module, to an extent not possible with other data sets.</p>
<p>For each grid cell, we compute the grid spacing (<italic>λ</italic>) and orientation (<italic>θ</italic>) by measuring properties associated with the six hexagonally distributed peaks of the spatial autocorrelogram (SAC), as traditionally performed [<xref ref-type="bibr" rid="c44">44</xref>] (<xref rid="fig2" ref-type="fig">Fig. 2A</xref>; see Materials and Methods). For clarity, we begin by focusing on a single module, recorded from an open field environment (recording identifier: Rat R, Day 1, Module 2 – R12). This module was picked for its long recording time (approximately 130 minutes of recorded activity, as compared to the other open field recordings that have 30 minutes or less of recorded activity) and for its large number of simultaneously recorded putative grid cells (<italic>N</italic> = 168). In this module, we find that grid cells with high grid scores (&gt; 0.85; <italic>N</italic> = 74) have a range of grid orientation and spacing (example cells shown in <xref rid="fig2" ref-type="fig">Fig. 2B</xref>; distributions across module shown in <xref rid="fig2" ref-type="fig">Fig. 2E, F</xref>), with <italic>λ</italic> ranging from 65 cm to 90 cm and <italic>θ</italic> ranging from 2<sup>°</sup> to 9<sup>°</sup>. Overlaying the SAC of pairs of grid cells with similar grid spacing and different grid orientation (<xref rid="fig2" ref-type="fig">Fig. 2C</xref>) or vice versa (<xref rid="fig2" ref-type="fig">Fig. 2D</xref>) enables visualization of the extent of this variability.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Grid properties are variable within a single grid module (recording ID R12).</title>
<p>(A) Overview of the standard procedure used to calculate the grid spacing and orientation of a given grid cell. First, spike maps are computed by identifying the location of the animal at the time of each spike. Gray line denotes the trajectory of the rat, red dots denote locations of spikes. A rate map is constructed by binning space and normalizing by the amount of time the rat spent in each spatial bin. A spatial autocorrelogram (SAC) is computed and, after the center peak is masked out (white pixels in the center of the spatial autocorrelogram – leading to change in color scale), the grid properties are fit by measuring the length and angle of the three peaks closest to 0<sup>°</sup>. (B) Example grid cells from the same module (recording ID R12), with estimated grid score, orientation (<italic>θ</italic>), and spacing (<italic>λ</italic>). (C)–(D) SAC overlaid for two pairs of grid cells [from (B)]; one pair with different <italic>θ</italic> and similar <italic>λ</italic> (C) and the other with similar <italic>θ</italic> and different <italic>λ</italic> (D). (E)–(F) Distribution of <italic>θ</italic> (E) and <italic>λ</italic> (F) across all grid cells with grid score &gt; 0.85 (N = 74).</p></caption>
<graphic xlink:href="582373v2_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Because individual grid fields can be cut-off by the boundaries of the environment, it is possible that computing the grid spacing from the SAC (which considers all grid fields) could lead to an under-estimate of <italic>λ</italic>, for some grid cells. To verify that the width of the distribution of grid spacing, within the same module, that we see is not due to the specifics of the SAC, we re-computed the grid spacing for all grid cells directly from their rate maps, considering only the three grid fields closest to the center of the environment (<xref rid="figS2" ref-type="fig">Fig. S2A</xref>; see Materials and Methods). We find that, while the grid spacing estimated from the SAC tends to be larger than the grid spacing estimated from the rate maps, a broad range of <italic>λ</italic> is again present (<xref rid="figS2" ref-type="fig">Fig. S2B, C</xref>).</p>
<p>To assess whether the heterogeneity of grid properties present in a single grid module is a robust feature or attributable to noise (either in the recording or the grid property fitting procedure), we measure the variability in grid orientation and spacing <bold>within</bold> a single grid cell and <bold>between</bold> pairs of grid cells. If the heterogeneity is explainable by noise, then we expect that the within-cell variability will be of the same size as the between-cell variability. In contrast, if the heterogeneity is a robust feature of the grid code, then we expect the within-cell variability will be significantly smaller than the between-cell variability.</p>
<p>To measure the within- and between-cell variability, we split the recording into evenly spaced 30 second bins, randomly assigning each temporal bin to one of two equal length halves and recomputing the grid properties for each half of the recording (<xref rid="fig3" ref-type="fig">Fig. 3A</xref>; see Materials and Methods). We set inclusion criteria to filter out cells that did not have consistent hexagonally structured SACs across splits of the recording (see Materials and Methods). While these requirements are strict (see <xref rid="figS1" ref-type="fig">Fig. S1</xref>, for percent of cells rejected), they set a conservative estimate on the amount of grid property variability, ensuring that we did not artificially inflate the variability due to weak grid cells. We do not find that the length of the temporal bin used to split the data has a large impact on the percent of cells accepted by this criteria (<xref rid="figS3" ref-type="fig">Fig. S3</xref>; see Materials and Methods).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3:</label>
<caption><title>Variability of grid properties is a robust feature of individual grid module (recording ID R12).</title>
<p>Schematic overview of approach used to compute the between- and within-cell variability of grid orientation and spacing. (B)–(C) Distribution of within- and between-cell variability of <italic>θ</italic> and <italic>λ</italic>, respectively. Note that the distribution is across all 100 random shuffles of the data into two halves. (D) Average within-cell variability of grid orientation <inline-formula><inline-graphic xlink:href="582373v2_inline35.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, compared to average between-cell variability of grid spacing <inline-formula><inline-graphic xlink:href="582373v2_inline36.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. (E) Same as (D), but for <italic>λ</italic>. 1 cell was excluded from (E) for visualization <inline-formula><inline-graphic xlink:href="582373v2_inline37.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, but was included in non-parametric statistical analysis. For (D)–(E), <italic>N</italic> = 82.</p></caption>
<graphic xlink:href="582373v2_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We find that the distribution of within-cell variability of grid orientation and spacing is more concentrated around 0 than the between-cell variability, across all 100 random shuffles of the data into two halves. Comparing the average within- and between-cell variability of grid spacing and orientation reveals that nearly all of the grid cells that passed the criteria for inclusion (<italic>N</italic> = 82) exhibit more between-cell than within-cell variability (<xref rid="fig3" ref-type="fig">Fig. 3D, E</xref>): 95.1% grid cells for orientation (<inline-formula><inline-graphic xlink:href="582373v2_inline1.gif" mime-subtype="gif" mimetype="image"/></inline-formula> denotes mean across cells) and 100% of grid cells for spacing <inline-formula><inline-graphic xlink:href="582373v2_inline2.gif" mime-subtype="gif" mimetype="image"/></inline-formula>.A Wilcoxon-Signed-Rank Test indicates that between-cell variability is significantly higher than within-cell variability for both orientation and spacing (Δ<italic>θ</italic>: <italic>p</italic> &lt; 0.001, Δ<italic>λ</italic> : <italic>p</italic> &lt; 0.001).</p>
<p>In keeping with convention, the reported grid cell properties are the average of those computed for each of the three independent axes in the SAC (Axis 1: aligned to ≈ 0<sup>°</sup>; Axis 2: aligned to ≈ 60<sup>°</sup>; Axis 3: aligned to ≈ −60<sup>°</sup> [<xref ref-type="bibr" rid="c45">45</xref>]). To ensure that this averaging is not contributing to the greater between-cell variability, we repeated the analysis above, restricting ourselves to each axis separately. The results again demonstrate that grid properties are significantly more robust within-cell than between-cell (<xref rid="fig4" ref-type="fig">Fig. 4A, B</xref>). For each axis, the average between-cell variability for every cell was significantly higher than the average within-cell variability (<xref rid="fig4" ref-type="fig">Fig. 4C, D</xref>), as reported by the Wilcoxon-Signed-Rank Test for orientation (<italic>p</italic> &lt; 0.001, for all three axes) and for spacing (<italic>p</italic> &lt; 0.001, for all three axes)</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4:</label>
<caption><title>Variability of grid properties, restricted to the same axis, is a robust feature of individual grid module (recording ID R12).</title>
<p>Same analysis as in <xref rid="fig3" ref-type="fig">Fig. 3 (B) – (E)</xref>, but for variability measured on each axis independently. For visualization, we exclude a small number of cells that were outside the axes limits, including 2, 5, and 10 cells for Axes 1–3, respectively (C); and 3, 4, and 3 cells for Axes 1–3, respectively (D); these cells were included in non-parametric statistical analyses.</p></caption>
<graphic xlink:href="582373v2_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Having demonstrated that grid cell properties are robustly heterogeneous in a single module, we proceed to analyze the remaining recordings in the data set (<italic>N</italic> = 420 cells across 8 modules; one module has no cells that pass our criteria) [<xref ref-type="bibr" rid="c34">34</xref>]. Although there are differences across recordings, we find larger between-than within-cell variability for grid orientation and spacing is present across all recordings (<xref rid="fig5" ref-type="fig">Fig. 5A, B</xref>; <xref ref-type="bibr" rid="c80">80</xref>.0% of grid cells have greater between-than within-variability for orientation, <inline-formula><inline-graphic xlink:href="582373v2_inline3.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="582373v2_inline4.gif" mime-subtype="gif" mimetype="image"/></inline-formula> of grid cells have greater between-than within-variability for spacing, <inline-formula><inline-graphic xlink:href="582373v2_inline5.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="582373v2_inline6.gif" mime-subtype="gif" mimetype="image"/></inline-formula>). A Wilcoxon-Signed-Rank Test finds that these differences are significant (Δ<italic>θ</italic>: <italic>p</italic> &lt; 0.001; Δ<italic>λ</italic> : <italic>p</italic> &lt; 0.001). We do not find evidence suggesting that the within-cell variability is influenced by grid score (<xref rid="fig5" ref-type="fig">Fig. 5C, D</xref>; linear regression for <italic>θ</italic>: <italic>R</italic><sup>2</sup> = 0.03, <italic>p</italic> = 0.55 Wald Test; linear regression for <italic>λ</italic>: <italic>R</italic><sup>2</sup> = 0.07, <italic>p</italic> = 0.14 Wald Test).</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5:</label>
<caption><title>Within module grid property variability is a robust feature across modules.</title>
<p>(A) Average within-cell variability of grid orientation <inline-formula><inline-graphic xlink:href="582373v2_inline38.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, compared to average between-cell variability of grid orientation <inline-formula><inline-graphic xlink:href="582373v2_inline39.gif" mime-subtype="gif" mimetype="image"/></inline-formula> for each cell (<italic>N</italic> = 420) across 8 modules (cells colored by their corresponding recording ID). The histogram above the plot shows the distribution of <inline-formula><inline-graphic xlink:href="582373v2_inline40.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and the histogram to the right shows the distribution of <inline-formula><inline-graphic xlink:href="582373v2_inline41.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. Same as (A), but for grid spacing. For visualization, 5 cells are excluded <inline-formula><inline-graphic xlink:href="582373v2_inline42.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, but are included in non-parametric statistical analyses. Dashed gray lines show the population mean. (C)–(D) Average within cell variability of <italic>θ</italic> and <italic>λ</italic> (respectively), as a function of grid score. For visualization, 3 and 22 cells are excluded from (C)–(D), respectively, but are included in statistical analyses. Black solid line is linear regression, with <italic>R</italic><sup>2</sup> and <italic>p</italic>-value reported above.</p></caption>
<graphic xlink:href="582373v2_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Taken together, our analysis of large-scale MEC recordings demonstrates that grid cells in the same grid module do not have a single grid spacing and orientation, but instead have a restricted range of values around the module mean. This property is a robust feature that cannot be explained by noise from the recording or fitting procedures.</p>
</sec>
<sec id="s2b">
<title>Variability in grid properties within single modules improves the encoding of local space</title>
<p>The variability of grid cell properties within individual grid modules, while statistically significant, is small in magnitude. Can a computational benefit in the encoding of local space be gained from this level of inhomogeneity? How sensitive might such a computational benefit be to the exact amount of variability present?</p>
<p>To address these questions, we generate populations of synthetic grid cells (see Materials and Methods), where we have complete control over the number of grid cells and their firing properties. For simplicity, we assume that all grid cells in our population have grid orientation and spacing sampled from Gaussian distributions, with means <inline-formula><inline-graphic xlink:href="582373v2_inline7.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="582373v2_inline8.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and standard deviations <italic>σ</italic><sub><italic>λ</italic></sub> and <italic>σ</italic><sub><italic>θ</italic></sub>, respectively. Assigning each grid cell in our population a grid orientation and spacing, we are able to generate “ideal” rate maps [<xref ref-type="bibr" rid="c14">14</xref>]. Sampling from a Poisson process on these ideal rate maps, we generate noisy grid cell rate maps (<xref rid="fig6" ref-type="fig">Fig. 6A</xref>). Leveraging a simple linear decoder (see Materials and Methods), we can examine how decoding error of local space is affected by the number of grid cells in the population and the amount of variability (<italic>σ</italic><sub><italic>λ</italic></sub> and <italic>σ</italic><sub><italic>θ</italic></sub>).</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6:</label>
<caption><title>Variability in grid properties enables improved decoding of local space from the activity of grid cells within a single module.</title>
<p>(A) Example noisy grid cell rate maps generated from a Poisson process. The size of the square arena is set to 1.5 m × 1.5 m to be consistent with what was used in the experimental set-up analyzed [<xref ref-type="bibr" rid="c34">34</xref>]. (B)–(C) Distribution of sampled grid spacing and orientation from synthetic population, when using <inline-formula><inline-graphic xlink:href="582373v2_inline43.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, <italic>σ</italic><sub><italic>λ</italic></sub> = 5 cm, and <italic>σ</italic><sub><italic>θ</italic></sub> = 1<sup>°</sup>; compare to the distribution measured from real data (<xref rid="fig2" ref-type="fig">Fig. 2E, F</xref>). (D) Decoding error, as a function of grid cell population size, with populations having either no variability in grid properties (black line) or variability similar to what was present in the data analyzed (blue line). The solid line is the mean across 25 independent grid cell populations and the shaded area is ± standard deviation of the 25 independent populations. The dashed black line shows chance level decoding error. (E) Decoding error for synthetic populations and real data for up to <italic>N</italic> = 64 cells (red line). (F) Decoding error, over a grid of <italic>σ</italic><sub><italic>θ</italic></sub> and <italic>σ</italic><sub><italic>λ</italic></sub> values, for populations of <italic>N</italic> = 1024 grid cells. White star denotes values used in (D).</p></caption>
<graphic xlink:href="582373v2_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We begin by investigating the decoding capabilities of a synthetic module with properties similar to that of the experimentally recorded module that was analyzed in detail (recording identifier R12; <xref rid="fig2" ref-type="fig">Figs. 2</xref>, <xref rid="fig3" ref-type="fig">3</xref>). We therefore set <inline-formula><inline-graphic xlink:href="582373v2_inline9.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="582373v2_inline10.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. To determine an appropriate value for <italic>σ</italic><sub><italic>λ</italic></sub> and <italic>σ</italic><sub><italic>θ</italic></sub>, we subtract the mean between-cell variability by the mean within-cell variability (<inline-formula><inline-graphic xlink:href="582373v2_inline11.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="582373v2_inline12.gif" mime-subtype="gif" mimetype="image"/></inline-formula>) We interpret these values as the amount of variability in grid spacing and orientation that is not due to noise. Therefore, we set <italic>σ</italic><sub><italic>θ</italic></sub> = 1<sup>°</sup> and <italic>σ</italic><sub><italic>λ</italic></sub> = 5 cm. This amount of variability leads to similar sampled distributions of <italic>λ</italic> and <italic>θ</italic> as was found in the real data (compare <xref rid="fig2" ref-type="fig">Fig. 2E, F</xref> with <xref rid="fig6" ref-type="fig">Fig. 6B, C</xref>).</p>
<p>Applying the linear decoder to populations of synthetic grid cells, we find that decoding error decreases as the number of grid cells is increased (<xref rid="fig6" ref-type="fig">Fig. 6D</xref>, blue line). When <italic>N</italic> = 1024, the decoding error is ≈ 20 cm, substantially better than random decoding (<xref rid="fig6" ref-type="fig">Fig. 6D</xref>, dashed black line). As expected, this result is not seen in a synthetic population of grid cells with no variability in grid properties (<italic>σ</italic><sub><italic>θ</italic></sub> = 0<sup>°</sup> and <italic>σ</italic><sub><italic>λ</italic></sub> = 0 cm) (<xref rid="fig6" ref-type="fig">Fig. 6D</xref>, black line). In particular, while the restricted number of grid firing fields enables a decoding error smaller than chance, the population with fixed grid properties exhibits little change in decoding error with increasing numbers of grid cells. This demonstrates that the improved encoding is specific to populations with inhomogeneity in their grid spacing and orientation.</p>
<p>To validate that the synthetic population was a reasonable surrogate to the experimentally recorded data, we perform the same decoding analysis on grid cells from recording ID R12 (see Materials and Methods). As the real data is limited in the number of cells, we are only able to compare up to populations of <italic>N</italic> = 64 (<xref rid="fig6" ref-type="fig">Fig. 6E</xref>). However, in this restricted range, we find agreement between the synthetic population with grid property variability and the recorded data (<xref rid="fig6" ref-type="fig">Fig. 6E</xref>, compare red and blue lines). This strengthens our hypothesis that the observed amounts of inhomogeneity in grid spacing and orientation can lead to improved decoding of local space.</p>
<p>To determine the extent to which the decrease in decoding error depends the exact variability of grid spacing and orientation, we perform a grid search over 36 pairs of (<italic>σ</italic><sub><italic>λ</italic></sub>, <italic>σ</italic><sub><italic>θ</italic></sub>) values in [0<sup>°</sup>, 1<sup>°</sup>, …, 5<sup>°</sup>] × [0 cm, 1 cm, …, 5 cm]. As expected, when the variability of both grid properties is large, we find nearly 0 decoding error of local space (<xref rid="fig6" ref-type="fig">Fig. 6E</xref>, bottom right). However, there is additionally a range of <italic>σ</italic><sub><italic>λ</italic></sub> and <italic>σ</italic><sub><italic>θ</italic></sub> values that lead to improved decoding, including values smaller than used (<xref rid="fig6" ref-type="fig">Fig. 6E</xref>, above and to the left of the white star). We perform the same grid search on synthetic populations of grid cells with different spacings <inline-formula><inline-graphic xlink:href="582373v2_inline13.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="582373v2_inline14.gif" mime-subtype="gif" mimetype="image"/></inline-formula> (<xref rid="figS4" ref-type="fig">Fig. S4A, B</xref>), finding it again possible for the decoding error to drop well below that of the fixed population, if a sufficient amount of variability exists. For the synthetic module with smaller spacing <inline-formula><inline-graphic xlink:href="582373v2_inline15.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, the existence of more grid fields in the 1.5 m × 1.5 m arena leads to greater complexity of interference patterns (<xref rid="fig1" ref-type="fig">Fig. 1</xref>), enabling the same amount of variability in grid spacing and orientation to lead to a sharper decrease in decoding error. Additionally, for the synthetic module with smaller spacing, a given value of <italic>σ</italic><sub><italic>λ</italic></sub> is a larger percentage of <inline-formula><inline-graphic xlink:href="582373v2_inline16.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, as compared to the synthetic module with larger spacing.</p>
<p>Finally, we consider how decoding within a single module compares to decoding across two modules. When the two modules are consecutive (e.g., modules 2 and 3), their grid spacing, <italic>λ</italic><sub>2</sub> and <italic>λ</italic><sub>3</sub>, has been experimentally found to be related via <inline-formula><inline-graphic xlink:href="582373v2_inline17.gif" mime-subtype="gif" mimetype="image"/></inline-formula> [<xref ref-type="bibr" rid="c22">22</xref>]. In such a case, decoding activity from populations with fixed grid properties leads to nearly 0 error (<xref rid="figS5" ref-type="fig">Fig. S5A</xref>, black line). The addition of variability in grid properties does not significantly change the behavior of the decoding (<xref rid="figS5" ref-type="fig">Fig. S5A</xref>, blue line). This suggests that small amounts of inhomogeneity may not disrupt the previously achieved theoretical bounds on decoding from multiple grid modules [<xref ref-type="bibr" rid="c24">24</xref>, <xref ref-type="bibr" rid="c25">25</xref>, <xref ref-type="bibr" rid="c28">28</xref>, <xref ref-type="bibr" rid="c46">46</xref>]. However, if the two modules being decoded from are non-consecutive (e.g., modules 1 and 3) then the grid spacing can be related by an integer multiple, <italic>λ</italic><sub>3</sub> = 2<italic>λ</italic><sub>1</sub>. In such a setting, the grid fields of the larger module are a subset of the grid fields of the smaller module, up to a rotation (due to the difference in orientation between the two modules), and we again find that variability in grid properties can improve decoding accuracy (<xref rid="figS5" ref-type="fig">Fig. S5B</xref>, compare black and blue lines). Taken together, these results suggest that <italic>individual</italic> grid modules can exhibit significant encoding of local space via heterogeneity in their grid properties, even when the extent of the variability in <italic>θ</italic> and <italic>λ</italic> is similar to that found in the analysis of the experimental recordings. This benefit can also improve encoding in cases when multiple, non-consecutive modules are considered.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>The multiple firing fields of grid cells, organized along a triangular lattice, has been historically interpreted as a limiting feature for encoding of local space. Particularly influential in shaping this view has been the discovery of the distribution of grid cells into distinct modules, with grid cell spacing (<italic>λ</italic>) and orientation (<italic>θ</italic>) preserved within, but not across, modules [<xref ref-type="bibr" rid="c22">22</xref>, <xref ref-type="bibr" rid="c23">23</xref>], making integration across multiple modules necessary for spatial information to be decoded [<xref ref-type="bibr" rid="c24">24</xref>–<xref ref-type="bibr" rid="c28">28</xref>]. While evidence for discontinuity in the grid cell properties across modules is strong, the corollary assumption, that within-module values of <italic>λ</italic> and <italic>θ</italic> are identical (within the bounds of noise), has not been systematically studied.</p>
<p>Analyzing recently collected MEC recordings, we found the range of <italic>λ</italic> and <italic>θ</italic> values was large, with examples of grid cell pairs in the same module having over 7<sup>°</sup> difference in grid orientation and 20 cm difference in grid spacing (<xref rid="fig2" ref-type="fig">Fig. 2</xref>). Statistical analysis shows that the variability is more robust than expected from noise, for the majority of grid cells (<xref rid="fig5" ref-type="fig">Fig. 5</xref>). This was despite the fact that we used a very conservative criteria for assessing whether a grid cell was robust enough to include in the analysis.</p>
<p>Our comparison of within- and between-cell grid property variability was key to our argument, as it was for previous work using it to study the robustness of differences in peak grid field firing rates [<xref ref-type="bibr" rid="c39">39</xref>]. The absence of its use in the characterization of distribution of <italic>λ</italic> and <italic>θ</italic> [<xref ref-type="bibr" rid="c30">30</xref>] may be why the heterogeneity was not identified until now. We find that our analysis is robust to choices of parameters (<xref rid="figS1" ref-type="fig">Figs. S1</xref>, <xref rid="figS3" ref-type="fig">S3</xref>) and whether we treat each grid field independently or take the average across grid fields (<xref rid="fig3" ref-type="fig">Figs. 3</xref>, <xref rid="fig4" ref-type="fig">4</xref>). This challenges the commonly held belief that the variability observed in the grid orientation and spacing is attributable solely to measurement noise.</p>
<p>We hypothesize that this variability may be used to increase the fidelity at which <italic>individual</italic> grid modules can encode local space. This idea is consistent with a large body of literature showing that heterogeneity in the responses of populations of neurons increases the robustness of encoding [<xref ref-type="bibr" rid="c47">47</xref>–<xref ref-type="bibr" rid="c50">50</xref>]. We indeed find, in noisy synthetic models of grid cells, that a level of variability in grid properties similar to what is quantified in the real data can be sufficient to accurately decode information of local space (<xref rid="fig6" ref-type="fig">Fig. 6</xref>). This benefit is increased with larger numbers of grid cells in the population (<xref rid="fig6" ref-type="fig">Fig. 6D</xref>), and is observed over a range of underlying variability values (<xref rid="fig6" ref-type="fig">Fig. 6F</xref>). We find that the improvement was most pronounced in modules with small grid spacing (<xref rid="figS4" ref-type="fig">Fig. S4A</xref>), although larger modules can see a decrease in decoding error for amounts of variability consistent with was was found in the analyzed data (<xref rid="figS4" ref-type="fig">Fig. S4B</xref>).</p>
<p>We note that our results are additionally aligned with recent findings of heterogeneity in maximum firing rates across individual grid fields [<xref ref-type="bibr" rid="c37">37</xref>–<xref ref-type="bibr" rid="c39">39</xref>] and grid sheering [<xref ref-type="bibr" rid="c35">35</xref>, <xref ref-type="bibr" rid="c36">36</xref>, <xref ref-type="bibr" rid="c40">40</xref>]. Our work further demonstrates that, even in the absence of these perturbations, individual grid modules may encode considerably more local spatial information than previously believed.</p>
<p>Finally, models of the formation of orientation maps in visual cortex have demonstrated that slight angular offsets of retinal mosaics, along which retinal receptive fields are organized, can generate complex patterns [<xref ref-type="bibr" rid="c51">51</xref>], similar to those found in visual cortex orientation maps [<xref ref-type="bibr" rid="c52">52</xref>]. Our results indicate that grid cells in MEC may be capable of leveraging a similar computational principle, suggesting that mosaic patterns might be a broadly utilized feature in neural coding [<xref ref-type="bibr" rid="c53">53</xref>].</p>
<sec id="s3a">
<title>Limitations</title>
<p>While the data set we analyzed [<xref ref-type="bibr" rid="c34">34</xref>] represents an advance in the ability to simultaneously record from tens to hundreds of putative grid cells, across grid modules, the MEC remains a challenging brain region to access for large-scale neurophysiological experiments. Indeed, with our conservative inclusion criteria, we were ultimately limited by having only 420 grid cells included in our analysis. Future work can perform more detailed and complete characterizations of grid property heterogeneity, as new neurotechnologies that enable larger yield of grid cells are developed [<xref ref-type="bibr" rid="c54">54</xref>, <xref ref-type="bibr" rid="c55">55</xref>].</p>
<p>Our decoding analysis, while demonstrating the possibility that variability in grid properties can be leveraged by single grid modules to enhance the encoding of local spatial information, made several simplifying assumptions: Poisson sampling for spike rates; linear decoding; normal distribution of grid properties. While comparison to real data showed that these assumptions are reasonable (<xref rid="fig6" ref-type="fig">Fig. 6E</xref>), future work can assess the extent to which these restrictions can be lifted, while still enabling individual grid modules to have low decoding error.</p>
</sec>
<sec id="s3b">
<title>Open questions</title>
<p>The heterogeneity in grid properties we characterize motivates the investigation of several new lines of research. Because these are directions that we believe to be fruitful for the field as a whole, we outline them below, with our hypotheses for possible answers.</p>
<sec id="s3b1">
<title>Q1: What causes grid property variability?</title>
<p>A natural first direction to address is identifying the source of the heterogeneity in grid cell properties we observe. One hypothesis is that this could be driven by “defects” in the specific connectivity pattern that is needed for a continuous attractor. However, whether stable path integration could occur, in the face of such defects, is unclear. As an alternative, the coupling between hippocampus and MEC, which has been shown to lead to variability in grid field firing rates (as experimentally observed) [<xref ref-type="bibr" rid="c39">39</xref>, <xref ref-type="bibr" rid="c56">56</xref>], may lead to differences in grid orientation and spacing. In particular, a previous computational model that learned grid cells from place cell input, using non-negative principal component analysis, has shown that place field width affects grid cell orientation and spacing [<xref ref-type="bibr" rid="c6">6</xref>]. Heterogeneity in the spatial coding properties of place cells that has been found along the transverse axis of CA3 [<xref ref-type="bibr" rid="c57">57</xref>–<xref ref-type="bibr" rid="c59">59</xref>], suggesting there may be a systematic differences in the place field widths of hippocampal inputs to MEC grid cells. Further, it was shown that this place-to-grid cell computational model has a linear relationship between place field width and grid spacing, and a non-monotonic relationship between place field width and grid orientation [<xref ref-type="bibr" rid="c6">6</xref>]. These may explain why we find stronger average variability in grid spacing than grid orientation (<xref rid="fig5" ref-type="fig">Fig. 5A, B</xref>).</p>
</sec>
<sec id="s3b2">
<title>Q2: How does grid property variability affect continuous attractor network structure?</title>
<p>Continuous attractor network models of grid cells [<xref ref-type="bibr" rid="c2">2</xref>, <xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c16">16</xref>] enjoy considerable experimental support [<xref ref-type="bibr" rid="c23">23</xref>, <xref ref-type="bibr" rid="c30">30</xref>–<xref ref-type="bibr" rid="c34">34</xref>], making them one of the “canonical” models in neuroscience. However, these models make use of the assumption that all the grid cells in a given module have the same grid orientation and spacing to simplify the network connectivity. In particular, by assuming equal grid orientation and spacing, it becomes possible to arrange grid cells in a two-dimensional space spanned by their phases (i.e., a “neural sheet” [<xref ref-type="bibr" rid="c16">16</xref>]). Neurons close in this space are wired with excitatory connections and neurons far in this space are wired with inhibitory connections. As the data set we analyzed was found to provide strong support for the basic predictions of continuous attractor networks (i.e., toroidal topology of the activity manifold) [<xref ref-type="bibr" rid="c34">34</xref>], we do not view our results as directly challenging these models. However, considering how these models can accommodate the observed variability is an important future direction. It is possible that these modifications are learnable, via some plasticity mechanism. These solutions may lead to geometric effects on the underlying manifold, which could be explored by using computational tools [<xref ref-type="bibr" rid="c60">60</xref>], as well as affect the dynamical properties of the neural population activity, which could be quantified by data-driven dynamical systems methods [<xref ref-type="bibr" rid="c61">61</xref>–<xref ref-type="bibr" rid="c63">63</xref>]. We hypothesize that the degree in variability of grid spacing and orientation may strike a balance between being small enough to keep the continuous attractor network structure stable, but large enough to enable encoding of local information of space.</p>
</sec>
<sec id="s3b3">
<title>Q3: How does grid property variability shape hippocampal representations?</title>
<p>The projections from MEC to hippocampus suggest that the variability in grid properties may influence hippocampal representations (even if grid cells do not comprise the majority of its inputs). We consider two possible ways in which this may happen. First, given that grid cells have been reported to maintain their grid spacing and orientation across exposures to new environments, while undergoing a change in their grid phase [<xref ref-type="bibr" rid="c30">30</xref>, <xref ref-type="bibr" rid="c64">64</xref>], the integration across multiple modules has been necessary to explain place field remapping. However, grid phase plays an important role in generating the specific complex interference patterns that emerge when considering the joint activity of grid cells with variable grid properties (<xref rid="fig1" ref-type="fig">Fig. 1</xref>). Thus the reported changes in phase may be sufficient to generate large (and seemingly random) changes in local spatial information conveyed by grid cells to hippocampal cells. This could drive additional changes in the local spatial information projected to hippocampus, as well as explain the significant differences in correlation structure between CA1 neurons across different environments [<xref ref-type="bibr" rid="c65">65</xref>].</p>
<p>And second, recent work on hippocampal place field drift [<xref ref-type="bibr" rid="c66">66</xref>–<xref ref-type="bibr" rid="c70">70</xref>] has demonstrated that there is a significant change in the place field location across time, especially in CA1. One possible source of this phenomenon is the reported instability of dendritic spines on the apical dendrites of CA1 place cells [<xref ref-type="bibr" rid="c59">59</xref>, <xref ref-type="bibr" rid="c71">71</xref>– 73], ostensibly leading to changes in the MEC inputs to these neurons. However, if grid cells across multiple modules are necessary for local spatial information, turnover in synaptic input is unlikely to cause large changes in the spatial preferences of CA1 neurons, as integration over several scales should provide stable encoding properties. In contrast, different subpopulations of grid cells with variable grid properties can lead to differences in the local spatial information encoded by their joint activity, even if they come from a single module, possibly influencing the spatial preferences of CA1 place cells.</p>
</sec>
<sec id="s3b4">
<title>Q4: Why are there multiple modules?</title>
<p>Given that our results demonstrate the ability of single grid modules to encode information about local space – a feat previously believed to be possible only if activity from multiple grid modules was integrated together – why is does MEC have multiple modules? While the variability removes the necessity for encoding local space with multiple modules, higher fidelity representations is achievable by integrating across multiple modules (<xref rid="figS5" ref-type="fig">Fig. S5</xref>). In addition, the use of grid cells beyond spatial navigation [<xref ref-type="bibr" rid="c74">74</xref>–<xref ref-type="bibr" rid="c79">79</xref>], where hierarchical representations are important [<xref ref-type="bibr" rid="c42">42</xref>, <xref ref-type="bibr" rid="c43">43</xref>], may be a sufficient implicit bias for the formation of multiple modules [<xref ref-type="bibr" rid="c80">80</xref>]. In particular, encoding information at multiple distinct scales is critical for multi-scale reasoning, a cognitive function grid cells may support.</p>
</sec>
</sec>
</sec>
<sec id="s4">
<title>Materials and Methods</title>
<sec id="s4a">
<title>Electrophysiology recordings</title>
<p>The neural activity analyzed in this paper comes from a publicly available data set, which has previously been described in detail [<xref ref-type="bibr" rid="c34">34</xref>]. We provide brief summary of the methodology and the experimental paradigms used during the recordings.</p>
<p>Three male rats (Long Evans – Rats Q, R, and S) were implanted with Neuropixels silicon probes [<xref ref-type="bibr" rid="c81">81</xref>, <xref ref-type="bibr" rid="c82">82</xref>]. These probes were targeted at the MEC-parasubiculum region and the surgery was performed as described previously [<xref ref-type="bibr" rid="c32">32</xref>, <xref ref-type="bibr" rid="c82">82</xref>]. After three hours of recovery, recordings were performed.</p>
<p>In the recordings analyzed, the rats foraged for randomly dispersed corn puffs in a 1.5 × 1.5 m<sup>2</sup> square open field arena, with walls of height 50 cm. The rats were familiar with the environment and task, having trained 10–20 times prior to the implantation. The rats were food restricted to motivate their foraging, being kept at a minimum of 90% of their original body weight (300–500 grams).</p>
<p>All procedures in the original study were approved by the Norwegian Food and Safety Authority and done in accordance with the Norwegian Animal Welfare Act and the European Convention for the Protection of Vertebrate Animals used for Experimental and Other Scientific Purposes.</p>
</sec>
<sec id="s4b">
<title>Electrophysiology post-processing</title>
<p>The neural activity analyzed in this paper was post-processed, before made publicly available. We describe, in brief, the post-processing performed [<xref ref-type="bibr" rid="c34">34</xref>], as well as the post-processing we performed on the downloaded data.</p>
<p>Spike sorting, via KiloSort 2.5 [<xref ref-type="bibr" rid="c82">82</xref>], was applied to the data recorded from the Neuropixel probes. Individual units were deemed putative cells if their average spike rate was in the range of 0.5–10Hz, and 99% of their interspike intervals were greater than 2 ms.</p>
<p>For each putative cell, rate maps were constructed by averaging the activity at binned spatial positions in the open field arena. This raw rate map was smoothed, using a Gaussian kernel. The autocorrelation of these rate maps were computed, and a grid score calculated, as described previously [<xref ref-type="bibr" rid="c44">44</xref>]. To determine which putative cells were grid cells, and to which module they belonged, autocorrelograms of raw rate maps were constructed, with some of the bins corresponding to the closest and furthest distances removed. These “cropped” rate maps were then clustered by using UMAP [<xref ref-type="bibr" rid="c83">83</xref>] to project the data onto a two-dimensional subspace. All the cells in the non-largest cluster were found to have similar grid spacing and orientation, as well as high grid scores. They were therefore deemed putative grid cells. All cells in these clusters had their spike trains placed in the public repository from which we downloaded the data.</p>
<p>From the downloaded spike trains, we constructed rate maps and autocorrelograms in a similar manner, using code made publicly available [<xref ref-type="bibr" rid="c8">8</xref>] (<xref rid="fig2" ref-type="fig">Fig. 2</xref>).</p>
</sec>
<sec id="s4c">
<title>Computing grid score, orientation and spacing from the spatial autocorrelogram</title>
<p>Grid spacing and grid orientation were computed according to standard methods described in detail previously [<xref ref-type="bibr" rid="c22">22</xref>, <xref ref-type="bibr" rid="c84">84</xref>]. Briefly, the goal of the procedure is to identify the location of the six nearest fields in the spatial autocorrelogram (SAC) (<xref rid="fig2" ref-type="fig">Fig. 2A</xref>). This was achieved by performing the following steps. First, the SAC was smoothed using a 2D Gaussian filter with <italic>σ</italic> = 1. Second, the center of the SAC was excluded by applying a mask. Because the size of the SAC’s central peak changes for every module, the radius of such mask was re-computed for each module. Third, we thresholded the SAC by applying an extended-maxima transform <monospace>ndimage.maximum_filter.</monospace> Fourth, we identified the center of every field by using the function <monospace>scipy.stats.find_peaks.</monospace></p>
<p>Once the peaks of every field had been found, we computed the location of every peak in polar coordinates. We then selected the 6 peaks that were closest to the center of the SAC, based on the computed radial components. Because every SAC is symmetric, we considered for further analysis the 3 peaks closest to the X axis in angular distance (Axis 1, 2, and 3 [<xref ref-type="bibr" rid="c45">45</xref>]). Grid spacing was computed as the arithmetic mean of the radial component of the 3 peaks (except when each peak was analyzed separately – <xref rid="fig4" ref-type="fig">Fig. 4</xref>). Given that the SAC dimensions are twice of that of the real arena, we multiplied the SAC radial mean by a factor of 2. Grid orientation was computed as the angular mean of orientations (relative to the x-axis) of the three peaks (except when each peak was analyzed separately – <xref rid="fig4" ref-type="fig">Fig. 4</xref>).</p>
<p>In order to ensure that subsequent analysis was performed only on cells whose SAC’s could be well described by hexagonal structure, we imposed the following constraints: 1) the relative angle between two peaks could not be &lt; 30<sup>°</sup>; 2) the relative angle between two peaks could not be &gt; 90<sup>°</sup>; 3) the values for grid spacing between the peaks could not be substantially different (the ratio of spacings between any two peaks must be &gt; 0.5 and &lt; 2). Cells that did not meet these criteria were determined to have “Poor grid fit” and were rejected from all subsequent analysis. The percentage of all cells that were removed by this inclusion criteria is shown in <xref rid="figS1" ref-type="fig">Fig. S1</xref>. We note that cells from one of the nine modules in the publicly available data set that we analyzed had 98.4% of cells rejected by this criteria (recording identifier – R23). We therefore did not include it in any subsequent analysis.</p>
<p>To compute the grid score of recorded MEC cells, we made use of previously published code [<xref ref-type="bibr" rid="c8">8</xref>], that is based on metrics that have become standards in quantifying grid cell properties[<xref ref-type="bibr" rid="c44">44</xref>].</p>
<p>For analysis of the distribution of grid properties (<xref rid="fig2" ref-type="fig">Fig. 2E, F</xref>), we included only grid cells with grid scores greater than 0.85. This was done to demonstrate that variability was present even in cells that exhibit robust grid cell properties. In the subsequent analyses, an alternative criteria is used, which considers the reliability of the grid responses (see below).</p>
</sec>
<sec id="s4d">
<title>Computing spacing from the rate maps</title>
<p>In order to characterize the spacing with a method that is less susceptible to the effects of having grid fields at the boundaries of the environment (as the SAC method could be), we compute the spacing using the rate maps of individual grid cells (<xref rid="figS2" ref-type="fig">Fig S2A</xref>). Once the rate map was computed, we smoothed it with a Gaussian filter, setting <italic>σ</italic> = 1.5. Then, using the function <monospace>scikit-image.feature.peak_local_max</monospace> we extract the position of the center of each firing field. Because our goal with this analysis is to show that the fields in the border do not impact our analysis with the SAC, we restrict ourselves to the 3 peaks that are closest to the center of the arena (<xref rid="figS2" ref-type="fig">Fig S2A</xref>). We compute the distances between those three peaks to each other and report the spacing as the average of the distances measured.</p>
</sec>
<sec id="s4e">
<title>Within and between cells splits</title>
<p>To characterize the within- and between-cell variability of grid spacing and orientation, we employed the following approach. First, we split the data into bins of fixed length (30 seconds). From this, we randomly assigned each interval to one of two blocks (denoted as blocks <italic>A</italic> and <italic>B</italic>), with exactly half the total number of intervals in each block. For each grid cell, we computed the grid spacing [<inline-formula><inline-graphic xlink:href="582373v2_inline18.gif" mime-subtype="gif" mimetype="image"/></inline-formula>and<inline-formula><inline-graphic xlink:href="582373v2_inline19.gif" mime-subtype="gif" mimetype="image"/></inline-formula>] and orientation [<inline-formula><inline-graphic xlink:href="582373v2_inline20.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and<inline-formula><inline-graphic xlink:href="582373v2_inline21.gif" mime-subtype="gif" mimetype="image"/></inline-formula>], from the data in each block. The within-cell differences of grid spacing and orientation was determined as <inline-formula><inline-graphic xlink:href="582373v2_inline22.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="582373v2_inline23.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. Each grid cell’s properties were also compared those of another grid cell, with the match being made using random sampling without replacement. These comparisons were determined as <inline-formula><inline-graphic xlink:href="582373v2_inline24.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="582373v2_inline25.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. This process was repeated 100 times (referring to each iteration as a “shuffle”), per recording. Examples of splits of the data, for different shuffles, is schematically illustrated in <xref rid="fig3" ref-type="fig">Fig. 3A</xref>). The resulting distributions of Δ<italic>θ</italic><sub>within</sub>, Δ<italic>λ</italic><sub>within</sub>, Δ<italic>θ</italic><sub>between</sub>, and Δ<italic>λ</italic><sub>between</sub>, across grid cells and splits of the data were then compared. If the within-cell variability in grid spacing and orientation was smaller than between-cell variability, we concluded that the variability of grid cell properties was a robust feature of the data and not due to noise.</p>
<p>When performing this shuffle analysis, we found that some cells, despite having a good grid fit when all the data was considered, did not have SACs that were well described by hexagonal structure when the data was split in half. We viewed this a manifestation of unreliable grid coding and a possible confound in our quantification of variability. As such, we introduced a new inclusion criteria (replacing that of requiring a grid score of &gt; 0.85), only considering cells that had poor grid fits on &lt; 5% of all shuffles. The percentage of all cells that were removed by this inclusion criteria is shown in <xref rid="figS1" ref-type="fig">Fig. S1</xref>. In general, we found that cells with high grid score were reliable, although there were exceptions. Additionally, we found that size of the bin used for splitting the data did not significantly affect the percent of cells with good grid fits (passed the prior inclusion criteria) that were considered reliable (<xref rid="figS3" ref-type="fig">Fig. S3</xref>).</p>
</sec>
<sec id="s4f">
<title>Synthetic grid cells</title>
<p>To study how variability in grid cell properties might endow the grid code with computational advantages, we generated synthetic grid cell rate maps, so that we could have complete control over the distribution of their properties. These synthetic grid cell rate maps were constructed as follows.</p>
<p>First, the lengths of each dimension the “arena” within which the simulated grid cells exist (<italic>L</italic><sub><italic>x</italic></sub> and <italic>L</italic><sub><italic>y</italic></sub>) were set. Then, for <italic>N</italic> ∈ ℕ grid cells, the grid spacing and orientation were sampled via <italic>λ</italic><sup>(<italic>i</italic>)</sup> ∼ 𝒩 (<italic>µ</italic><sub><italic>λ</italic></sub>, <italic>σ</italic><sub><italic>λ</italic></sub>) and <italic>θ</italic><sup>(<italic>i</italic>)</sup> ∼ 𝒩 (<italic>µ</italic><sub><italic>θ</italic></sub>, <italic>σ</italic><sub><italic>θ</italic></sub>) where 𝒩 (<italic>µ, σ</italic>) is a normal distribution with mean <italic>µ</italic> and variance <italic>σ</italic><sup>2</sup>. Grid phase was sampled as <italic>ϕ</italic><sup>(<italic>i</italic>)</sup> 𝒰 ([0, <italic>L</italic><sub><italic>x</italic></sub>] × [0, <italic>L</italic><sub><italic>y</italic></sub>]), where <italic>ϕ</italic> is a two dimensional vector, with first component uniformly sampled from [0, <italic>L</italic><sub><italic>x</italic></sub>] and second component uniformly sampled from [0, <italic>L</italic><sub><italic>y</italic></sub>]. To construct a population with no variability in grid properties (to use as a control), we set <italic>σ</italic><sub><italic>λ</italic></sub> = 0 m. and <italic>σ</italic><sub><italic>θ</italic></sub> = 0<sup>°</sup>.</p>
<p>For each grid cell, we generated idealized grid responses by summing three two-dimensional sinusoids [<xref ref-type="bibr" rid="c14">14</xref>], such that the activity at <bold>x</bold> = (<italic>x, y</italic>) ∈ [−<italic>L</italic><sub><italic>x</italic></sub><italic>/</italic>2, <italic>L</italic><sub><italic>x</italic></sub><italic>/</italic>2] ×[−<italic>L</italic><sub><italic>y</italic></sub><italic>/</italic>2, <italic>L</italic><sub><italic>y</italic></sub><italic>/</italic>2] is given by
<disp-formula id="eqn1">
<graphic xlink:href="582373v2_eqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <inline-formula><inline-graphic xlink:href="582373v2_inline26.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is the maximal firing rate, <italic>R</italic>(<italic>θ</italic><sub><italic>i</italic></sub>) is the two-dimensional rotation matrix, with rotation <italic>θ</italic><sub><italic>i</italic></sub>, and <bold>k</bold><sub><italic>j</italic></sub> are the wave vectors with 0<sup>°</sup>, 60<sup>°</sup> and 120<sup>°</sup> angular differences [i.e.,<inline-formula><inline-graphic xlink:href="582373v2_inline27.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. To match the recorded neural data, where individual grid cells have distinct maximal firing rates,<inline-formula><inline-graphic xlink:href="582373v2_inline28.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. We enforced <inline-formula><inline-graphic xlink:href="582373v2_inline29.gif" mime-subtype="gif" mimetype="image"/></inline-formula> to be within [<xref ref-type="bibr" rid="c2">2</xref>, <xref ref-type="bibr" rid="c30">30</xref>], by setting any sampled values outside of this range to the boundary values (i.e., 2 or 30).</p>
<p>To determine the extent to which local spatial information can be decoded from the activity of populations of grid cells with different degrees of variability in their grid properties, we performed the following analysis.</p>
<p>We generated noisy synthetic spike rates of <italic>N</italic> grid cells by assuming a Poisson process and sampling using the idealized rate maps (<xref ref-type="disp-formula" rid="eqn1">Eq. 1</xref>). More concretely, the activity of grid cell <italic>i</italic> at position (<italic>x, y</italic>) was assumed to be a random variable with a Poisson distribution, whose mean was <italic>X</italic><sup>(<italic>i</italic>)</sup>(<italic>x, y</italic>). Thus, the probability of observing <inline-formula><inline-graphic xlink:href="582373v2_inline30.gif" mime-subtype="gif" mimetype="image"/></inline-formula> spikes, at position (<italic>x, y</italic>), is given by
<disp-formula id="eqn2">
<graphic xlink:href="582373v2_eqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
</sec>
<sec id="s4g">
<title>Linear decoding synthetic data</title>
<p>For a given resolution of the arena, we generated <inline-formula><inline-graphic xlink:href="582373v2_inline31.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, where <italic>j</italic> = 1, …, 10. That is, we constructed 10 noisy rate maps. We performed cross-validated decoding by averaging across 9 of the 10 rate maps, to get an average rate map <inline-formula><inline-graphic xlink:href="582373v2_inline32.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. For sake of simplicity, consider <inline-formula><inline-graphic xlink:href="582373v2_inline33.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. To decode local position from the held out noisy rate map [e.g.<inline-formula><inline-graphic xlink:href="582373v2_inline34.gif" mime-subtype="gif" mimetype="image"/></inline-formula>], we multiplied the activity at each position by all the positions in the average rate map, taking the sum and assigning the decoded position as that with the largest value. The Euclidean distance between the decoded position and the true position is considered the error. This was performed 10 times (holding out each rate map once) and the average error across all positions in the environment was then averaged across all 10 of the validation splits.</p>
</sec>
<sec id="s4h">
<title>Linear decoding experimental data</title>
<p>To decode the electrophysiological data [<xref ref-type="bibr" rid="c34">34</xref>], we sampled subpopulations of grid cells from the <italic>N</italic> = 82 units (recording ID R12) that passed the criteria described previously. For each subpopulation, we split the recorded activity into 10 evenly spaced temporal bins, and constructed average ratemaps for each bin. This is consistent with what was done in decoding the synthetic data. All ratemaps, for each cell, were normalized by the maximal activity. We then randomly chose 5 of the 10 time bins to serve as the “train” data, the remaining 5 served as the “test” data. The rate maps were averaged and then the linear decoder was applied. We sampled 10 different choices of splitting the data and 25 choices of subpopulation.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>We thank the members of the Goard Lab, Francisco Acosta, Spencer Smith, Caleb Kemere, and the DYNS graduate students for useful discussions surrounding this work. We thank Andreas Herz for suggesting the analysis present in <xref rid="figS2" ref-type="fig">Fig. S2</xref>. This work was supported by grants to M.J.G. from NIH (R01 NS121919), NSF (1934288), and the Whitehall Foundation, and grants to X.X.W. from NSF (2318065).</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Torkel</given-names> <surname>Hafting</surname></string-name>, <string-name><given-names>Marianne</given-names> <surname>Fyhn</surname></string-name>, <string-name><given-names>Sturla</given-names> <surname>Molden</surname></string-name>, <string-name><given-names>May-Britt</given-names> <surname>Moser</surname></string-name>, and <string-name><given-names>Edvard I</given-names> <surname>Moser</surname></string-name></person-group>. <article-title>Microstructure of a spatial map in the entorhinal cortex</article-title>. <source>Nature</source>, <volume>436</volume>(<issue>7052</issue>):<fpage>801</fpage>–<lpage>806</lpage>, <year>2005</year>.</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><given-names>Alexis</given-names> <surname>Guanella</surname></string-name> and <string-name><given-names>Paul FMJ</given-names> <surname>Verschure</surname></string-name></person-group>. <article-title>A model of grid cells based on a path integration mechanism</article-title>. <source>Artificial Neural Networks–ICANN 2006: 16th International Conference, Athens, Greece, September 10-14, 2006</source>. Proceedings, Part I 16, pages <fpage>740</fpage>–<lpage>749</lpage>. <publisher-name>Springer</publisher-name>, <year>2006</year>.</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Mark C</given-names> <surname>Fuhs</surname></string-name> and <string-name><given-names>David S</given-names> <surname>Touretzky</surname></string-name></person-group>. <article-title>A spin glass model of path integration in rat medial entorhinal cortex</article-title>. <source>Journal of Neuroscience</source>, <volume>26</volume>(<issue>16</issue>):<fpage>4266</fpage>–<lpage>4276</lpage>, <year>2006</year>.</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Hugh T</given-names> <surname>Blair</surname></string-name>, <string-name><given-names>Adam C</given-names> <surname>Welday</surname></string-name>, and <string-name><given-names>Kechen</given-names> <surname>Zhang</surname></string-name></person-group>. <article-title>Scale-invariant memory representations emerge from moire interference between grid fields that produce theta oscillations: a computational model</article-title>. <source>Journal of Neuroscience</source>, <volume>27</volume>(<issue>12</issue>):<fpage>3211</fpage>–<lpage>3229</lpage>, <year>2007</year>.</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Jonathan J</given-names> <surname>Couey</surname></string-name>, <string-name><given-names>Aree</given-names> <surname>Witoelar</surname></string-name>, <string-name><given-names>Sheng-Jia</given-names> <surname>Zhang</surname></string-name>, <string-name><given-names>Kang</given-names> <surname>Zheng</surname></string-name>, <string-name><given-names>Jing</given-names> <surname>Ye</surname></string-name>, <string-name><given-names>Benjamin</given-names> <surname>Dunn</surname></string-name>, <string-name><given-names>Rafal</given-names> <surname>Czajkowski</surname></string-name>, <string-name><given-names>May-Britt</given-names> <surname>Moser</surname></string-name>, <string-name><given-names>Edvard I</given-names> <surname>Moser</surname></string-name>, <string-name><given-names>Yasser</given-names> <surname>Roudi</surname></string-name>, <etal>et al.</etal></person-group> <article-title>Recurrent inhibitory circuitry as a mechanism for grid formation</article-title>. <source>Nature neuroscience</source>, <volume>16</volume>(<issue>3</issue>):<fpage>318</fpage>–<lpage>324</lpage>, <year>2013</year>.</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Yedidyah</given-names> <surname>Dordek</surname></string-name>, <string-name><given-names>Daniel</given-names> <surname>Soudry</surname></string-name>, <string-name><given-names>Ron</given-names> <surname>Meir</surname></string-name>, and <string-name><given-names>Dori</given-names> <surname>Derdikman</surname></string-name></person-group>. <article-title>Extracting grid cell characteristics from place cell inputs using non-negative principal component analysis</article-title>. <source>Elife</source>, <volume>5</volume>:<fpage>e10094</fpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><given-names>Christopher J.</given-names> <surname>Cueva</surname></string-name> and <string-name><given-names>Xue-Xin</given-names> <surname>Wei</surname></string-name></person-group>. <article-title>Emergence of grid-like representations by training recurrent neural networks to perform spatial localization</article-title>. <source>International Conference on Learning Representations</source>, <year>2018</year>.</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Andrea</given-names> <surname>Banino</surname></string-name>, <string-name><given-names>Caswell</given-names> <surname>Barry</surname></string-name>, <string-name><given-names>Benigno</given-names> <surname>Uria</surname></string-name>, <string-name><given-names>Charles</given-names> <surname>Blundell</surname></string-name>, <string-name><given-names>Timothy</given-names> <surname>Lillicrap</surname></string-name>, <string-name><given-names>Piotr</given-names> <surname>Mirowski</surname></string-name>, <string-name><given-names>Alexander</given-names> <surname>Pritzel</surname></string-name>, <string-name><given-names>Martin J</given-names> <surname>Chadwick</surname></string-name>, <string-name><given-names>Thomas</given-names> <surname>Degris</surname></string-name>, <string-name><given-names>Joseph</given-names> <surname>Modayil</surname></string-name>, <etal>et al.</etal></person-group> <article-title>Vector-based navigation using grid-like representations in artificial agents</article-title>. <source>Nature</source>, <volume>557</volume>(<issue>7705</issue>):<fpage>429</fpage>–<lpage>433</lpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Simon Nikolaus</given-names> <surname>Weber</surname></string-name> and <string-name><given-names>Henning</given-names> <surname>Sprekeler</surname></string-name></person-group>. <article-title>Learning place cells, grid cells and invariances with excitatory and inhibitory plasticity</article-title>. <source>Elife</source>, <volume>7</volume>:<fpage>e34560</fpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ben Sorscher</surname>, <given-names>Gabriel Mel</given-names></string-name>, <string-name><given-names>Surya</given-names> <surname>Ganguli</surname></string-name>, and <string-name><given-names>Samuel</given-names> <surname>Ocko</surname></string-name></person-group>. <article-title>A unified theory for the origin of grid cells through the lens of pattern formation</article-title>. <source>Advances in neural information processing systems</source>, <volume>32</volume>, <year>2019</year>.</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>Mikail</given-names> <surname>Khona</surname></string-name>, <string-name><given-names>Sarthak</given-names> <surname>Chandra</surname></string-name>, and <string-name><given-names>Ila R</given-names> <surname>Fiete</surname></string-name></person-group>. <article-title>From smooth cortical gradients to discrete modules: spontaneous and topologically robust emergence of modularity in grid cells</article-title>. <source>bioRxiv</source>, pages <fpage>2021</fpage>–<lpage>10</lpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ben Sorscher</surname>, <given-names>Gabriel C Mel</given-names></string-name>, <string-name><given-names>Samuel A</given-names> <surname>Ocko</surname></string-name>, <string-name><given-names>Lisa M</given-names> <surname>Giocomo</surname></string-name>, and <string-name><given-names>Surya</given-names> <surname>Ganguli</surname></string-name></person-group>. <article-title>A unified theory for the computational and mechanistic origins of grid cells</article-title>. <source>Neuron</source>, <year>2022</year>.</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Bruce L</given-names> <surname>McNaughton</surname></string-name>, <string-name><given-names>Francesco P</given-names> <surname>Battaglia</surname></string-name>, <string-name><given-names>Ole</given-names> <surname>Jensen</surname></string-name>, <string-name><given-names>Edvard I</given-names> <surname>Moser</surname></string-name>, and <string-name><given-names>May-Britt</given-names> <surname>Moser</surname></string-name></person-group>. <article-title>Path integration and the neural basis of the’cognitive map’</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>7</volume>(<issue>8</issue>):<fpage>663</fpage>–<lpage>678</lpage>, <year>2006</year>.</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Trygve</given-names> <surname>Solstad</surname></string-name>, <string-name><given-names>Edvard I</given-names> <surname>Moser</surname></string-name>, and <string-name><given-names>Gaute T</given-names> <surname>Einevoll</surname></string-name></person-group>. <article-title>From grid cells to place cells: a mathematical model</article-title>. <source>Hippocampus</source>, <volume>16</volume>(<issue>12</issue>):<fpage>1026</fpage>–<lpage>1031</lpage>, <year>2006</year>.</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Edmund T</given-names> <surname>Rolls</surname></string-name>, <string-name><given-names>Simon M</given-names> <surname>Stringer</surname></string-name>, and <string-name><given-names>Thomas</given-names> <surname>Elliot</surname></string-name></person-group>. <article-title>Entorhinal cortex grid cells can map to hippocampal place cells by competitive learning</article-title>. <source>Network: Computation in Neural Systems</source>, <volume>17</volume>(<issue>4</issue>):<fpage>447</fpage>–<lpage>465</lpage>, <year>2006</year>.</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Yoram</given-names> <surname>Burak</surname></string-name> and <string-name><given-names>Ila R</given-names> <surname>Fiete</surname></string-name></person-group>. <article-title>Accurate path integration in continuous attractor network models of grid cells</article-title>. <source>PLoS computational biology</source>, <volume>5</volume>(<issue>2</issue>):<fpage>e1000291</fpage>, <year>2009</year>.</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Licurgo</given-names> <surname>de Almeida</surname></string-name>, <string-name><given-names>Marco</given-names> <surname>Idiart</surname></string-name>, and <string-name><given-names>John E</given-names> <surname>Lisman</surname></string-name></person-group>. <article-title>The input–output transformation of the hippocampal granule cells: from grid cells to place fields</article-title>. <source>Journal of Neuroscience</source>, <volume>29</volume>(<issue>23</issue>):<fpage>7504</fpage>–<lpage>7512</lpage>, <year>2009</year>.</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>John L</given-names> <surname>Kubie</surname></string-name> and <string-name><given-names>Steven E</given-names> <surname>Fox</surname></string-name></person-group>. <article-title>Do the spatial frequencies of grid cells mold the firing fields of place cells?</article-title> <source>Proceedings of the National Academy of Sciences</source>, <volume>112</volume>(<issue>13</issue>):<fpage>3860</fpage>–<lpage>3861</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Daniel</given-names> <surname>Bush</surname></string-name>, <string-name><given-names>Caswell</given-names> <surname>Barry</surname></string-name>, <string-name><given-names>Daniel</given-names> <surname>Manson</surname></string-name>, and <string-name><given-names>Neil</given-names> <surname>Burgess</surname></string-name></person-group>. <article-title>Using grid cells for navigation</article-title>. <source>Neuron</source>, <volume>87</volume>(<issue>3</issue>):<fpage>507</fpage>–<lpage>520</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Jake</given-names> <surname>Ormond</surname></string-name> and <string-name><given-names>Bruce L</given-names> <surname>McNaughton</surname></string-name></person-group>. <article-title>Place field expansion after focal mec inactivations is consistent with loss of fourier components and path integrator gain reduction</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>112</volume>(<issue>13</issue>):<fpage>4116</fpage>–<lpage>4121</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Caitlin S</given-names> <surname>Mallory</surname></string-name>, <string-name><given-names>Kiah</given-names> <surname>Hardcastle</surname></string-name>, <string-name><given-names>Jason S</given-names> <surname>Bant</surname></string-name>, and <string-name><given-names>Lisa M</given-names> <surname>Giocomo</surname></string-name></person-group>. <article-title>Grid scale drives the scale and long-term stability of place maps</article-title>. <source>Nature neuroscience</source>, <volume>21</volume>(<issue>2</issue>):<fpage>270</fpage>–<lpage>282</lpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Hanne</given-names> <surname>Stensola</surname></string-name>, <string-name><given-names>Tor</given-names> <surname>Stensola</surname></string-name>, <string-name><given-names>Trygve</given-names> <surname>Solstad</surname></string-name>, <string-name><given-names>Kristian</given-names> <surname>Frøland</surname></string-name>, <string-name><given-names>May-Britt</given-names> <surname>Moser</surname></string-name>, and <string-name><given-names>Edvard I</given-names> <surname>Moser</surname></string-name></person-group>. <article-title>The entorhinal grid map is discretized</article-title>. <source>Nature</source>, <volume>492</volume>(<issue>7427</issue>):<fpage>72</fpage>–<lpage>78</lpage>, <year>2012</year>.</mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Yi</given-names> <surname>Gu</surname></string-name>, <string-name><given-names>Sam</given-names> <surname>Lewallen</surname></string-name>, <string-name><given-names>Amina A</given-names> <surname>Kinkhabwala</surname></string-name>, <string-name><given-names>Cristina</given-names> <surname>Domnisoru</surname></string-name>, <string-name><given-names>Kijung</given-names> <surname>Yoon</surname></string-name>, <string-name><given-names>Jeffrey L</given-names> <surname>Gauthier</surname></string-name>, <string-name><given-names>Ila R</given-names> <surname>Fiete</surname></string-name>, and <string-name><given-names>David W</given-names> <surname>Tank</surname></string-name></person-group>. <article-title>A map-like micro-organization of grid cells in the medial entorhinal cortex</article-title>. <source>Cell</source>, <volume>175</volume>(<issue>3</issue>):<fpage>736</fpage>–<lpage>750</lpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Xue-Xin</given-names> <surname>Wei</surname></string-name>, <string-name><given-names>Jason</given-names> <surname>Prentice</surname></string-name>, and <string-name><given-names>Vijay</given-names> <surname>Balasubramanian</surname></string-name></person-group>. <article-title>A principle of economy predicts the functional architecture of grid cells</article-title>. <source>Elife</source>, <volume>4</volume>:<fpage>e08362</fpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c25"><label>[25]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Martin</given-names> <surname>Stemmler</surname></string-name>, <string-name><given-names>Alexander</given-names> <surname>Mathis</surname></string-name>, and <string-name><given-names>Andreas VM</given-names> <surname>Herz</surname></string-name></person-group>. <article-title>Connecting multiple spatial scales to decode the population activity of grid cells</article-title>. <source>Science Advances</source>, <volume>1</volume>(<issue>11</issue>):<fpage>e1500816</fpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c26"><label>[26]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Ila R</given-names> <surname>Fiete</surname></string-name>, <string-name><given-names>Yoram</given-names> <surname>Burak</surname></string-name>, and <string-name><given-names>Ted</given-names> <surname>Brookings</surname></string-name></person-group>. <article-title>What grid cells convey about rat location</article-title>. <source>Journal of Neuroscience</source>, <volume>28</volume>(<issue>27</issue>):<fpage>6858</fpage>–<lpage>6871</lpage>, <year>2008</year>.</mixed-citation></ref>
<ref id="c27"><label>[27]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Sameet</given-names> <surname>Sreenivasan</surname></string-name> and <string-name><given-names>Ila</given-names> <surname>Fiete</surname></string-name></person-group>. <article-title>Grid cells generate an analog error-correcting code for singularly precise neural computation</article-title>. <source>Nature neuroscience</source>, <volume>14</volume>(<issue>10</issue>):<fpage>1330</fpage>–<lpage>1337</lpage>, <year>2011</year>.</mixed-citation></ref>
<ref id="c28"><label>[28]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Alexander</given-names> <surname>Mathis</surname></string-name>, <string-name><given-names>Andreas VM</given-names> <surname>Herz</surname></string-name>, and <string-name><given-names>Martin</given-names> <surname>Stemmler</surname></string-name></person-group>. <article-title>Optimal population codes for space: grid cells outperform place cells</article-title>. <source>Neural computation</source>, <volume>24</volume>(<issue>9</issue>):<fpage>2280</fpage>–<lpage>2317</lpage>, <year>2012</year>.</mixed-citation></ref>
<ref id="c29"><label>[29]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>NM</given-names> <surname>Van Strien</surname></string-name>, <string-name><given-names>NLM</given-names> <surname>Cappaert</surname></string-name>, and <string-name><given-names>MP</given-names> <surname>Witter</surname></string-name></person-group>. <article-title>The anatomy of memory: an interactive overview of the parahippocampal–hippocampal network</article-title>. <source>Nature reviews neuroscience</source>, <volume>10</volume>(<issue>4</issue>):<fpage>272</fpage>–<lpage>282</lpage>, <year>2009</year>.</mixed-citation></ref>
<ref id="c30"><label>[30]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>KiJung</given-names> <surname>Yoon</surname></string-name>, <string-name><given-names>Michael A</given-names> <surname>Buice</surname></string-name>, <string-name><given-names>Caswell</given-names> <surname>Barry</surname></string-name>, <string-name><given-names>Robin</given-names> <surname>Hayman</surname></string-name>, <string-name><given-names>Neil</given-names> <surname>Burgess</surname></string-name>, and <string-name><given-names>Ila R</given-names> <surname>Fiete</surname></string-name></person-group>. <article-title>Specific evidence of low-dimensional continuous attractor dynamics in grid cells</article-title>. <source>Nature neuroscience</source>, <volume>16</volume>(<issue>8</issue>):<fpage>1077</fpage>–<lpage>1084</lpage>, <year>2013</year>.</mixed-citation></ref>
<ref id="c31"><label>[31]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Benjamin</given-names> <surname>Dunn</surname></string-name>, <string-name><given-names>Maria</given-names> <surname>Mørreaunet</surname></string-name>, and <string-name><given-names>Yasser</given-names> <surname>Roudi</surname></string-name></person-group>. <article-title>Correlations and functional connections in a population of grid cells</article-title>. <source>PLoS computational biology</source>, <volume>11</volume>(<issue>2</issue>):<fpage>e1004052</fpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c32"><label>[32]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Richard J</given-names> <surname>Gardner</surname></string-name>, <string-name><given-names>Li</given-names> <surname>Lu</surname></string-name>, <string-name><given-names>Tanja</given-names> <surname>Wernle</surname></string-name>, <string-name><given-names>May-Britt</given-names> <surname>Moser</surname></string-name>, and <string-name><given-names>Edvard I</given-names> <surname>Moser</surname></string-name></person-group>. <article-title>Correlation structure of grid cells is preserved during sleep</article-title>. <source>Nature neuroscience</source>, <volume>22</volume>(<issue>4</issue>):<fpage>598</fpage>–<lpage>608</lpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c33"><label>[33]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Sean G</given-names> <surname>Trettel</surname></string-name>, <string-name><given-names>John B</given-names> <surname>Trimper</surname></string-name>, <string-name><given-names>Ernie</given-names> <surname>Hwaun</surname></string-name>, <string-name><given-names>Ila R</given-names> <surname>Fiete</surname></string-name>, and <string-name><given-names>Laura Lee</given-names> <surname>Colgin</surname></string-name></person-group>. <article-title>Grid cell co-activity patterns during sleep reflect spatial overlap of grid fields during active behaviors</article-title>. <source>Nature neuroscience</source>, <volume>22</volume>(<issue>4</issue>):<fpage>609</fpage>–<lpage>617</lpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c34"><label>[34]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Richard J</given-names> <surname>Gardner</surname></string-name>, <string-name><given-names>Erik</given-names> <surname>Hermansen</surname></string-name>, <string-name><given-names>Marius</given-names> <surname>Pachitariu</surname></string-name>, <string-name><given-names>Yoram</given-names> <surname>Burak</surname></string-name>, <string-name><given-names>Nils A</given-names> <surname>Baas</surname></string-name>, <string-name><given-names>Benjamin A</given-names> <surname>Dunn</surname></string-name>, <string-name><given-names>May-Britt</given-names> <surname>Moser</surname></string-name>, and <string-name><given-names>Edvard I</given-names> <surname>Moser</surname></string-name></person-group>. <article-title>Toroidal topology of population activity in grid cells</article-title>. <source>Nature</source>, <volume>602</volume>(<issue>7895</issue>):<fpage>123</fpage>–<lpage>128</lpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c35"><label>[35]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Dori</given-names> <surname>Derdikman</surname></string-name>, <string-name><given-names>Jonathan R</given-names> <surname>Whitlock</surname></string-name>, <string-name><given-names>Albert</given-names> <surname>Tsao</surname></string-name>, <string-name><given-names>Marianne</given-names> <surname>Fyhn</surname></string-name>, <string-name><given-names>Torkel</given-names> <surname>Hafting</surname></string-name>, <string-name><given-names>May-Britt</given-names> <surname>Moser</surname></string-name>, and <string-name><given-names>Edvard I</given-names> <surname>Moser</surname></string-name></person-group>. <article-title>Fragmentation of grid cell maps in a multicompartment environment</article-title>. <source>Nature neuroscience</source>, <volume>12</volume>(<issue>10</issue>):<fpage>1325</fpage>–<lpage>1332</lpage>, <year>2009</year>.</mixed-citation></ref>
<ref id="c36"><label>[36]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Julija</given-names> <surname>Krupic</surname></string-name>, <string-name><given-names>Marius</given-names> <surname>Bauza</surname></string-name>, <string-name><given-names>Stephen</given-names> <surname>Burton</surname></string-name>, <string-name><given-names>Caswell</given-names> <surname>Barry</surname></string-name>, and <string-name><given-names>John</given-names> <surname>O’Keefe</surname></string-name></person-group>. <article-title>Grid cell symmetry is shaped by environmental geometry</article-title>. <source>Nature</source>, <volume>518</volume>(<issue>7538</issue>):<fpage>232</fpage>–<lpage>235</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c37"><label>[37]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Geoffrey W</given-names> <surname>Diehl</surname></string-name>, <string-name><given-names>Olivia J</given-names> <surname>Hon</surname></string-name>, <string-name><given-names>Stefan</given-names> <surname>Leutgeb</surname></string-name>, and <string-name><given-names>Jill K</given-names> <surname>Leutgeb</surname></string-name></person-group>. <article-title>Grid and nongrid cells in medial entorhinal cortex represent spatial location and environmental features with complementary coding schemes</article-title>. <source>Neuron</source>, <volume>94</volume>(<issue>1</issue>):<fpage>83</fpage>–<lpage>92</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c38"><label>[38]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Revekka</given-names> <surname>Ismakov</surname></string-name>, <string-name><given-names>Omri</given-names> <surname>Barak</surname></string-name>, <string-name><given-names>Kate</given-names> <surname>Jeffery</surname></string-name>, and <string-name><given-names>Dori</given-names> <surname>Derdikman</surname></string-name></person-group>. <article-title>Grid cells encode local positional information</article-title>. <source>Current Biology</source>, <volume>27</volume>(<issue>15</issue>):<fpage>2337</fpage>–<lpage>2343</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c39"><label>[39]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>Benjamin</given-names> <surname>Dunn</surname></string-name>, <string-name><given-names>Daniel</given-names> <surname>Wennberg</surname></string-name>, <string-name><given-names>Ziwei</given-names> <surname>Huang</surname></string-name>, and <string-name><given-names>Yasser</given-names> <surname>Roudi</surname></string-name></person-group>. <article-title>Grid cells show field-to-field variability and this explains the aperiodic response of inhibitory interneurons</article-title>. <source>arXiv</source> <pub-id pub-id-type="arxiv">1701.04893</pub-id>, <year>2017</year>.</mixed-citation></ref>
<ref id="c40"><label>[40]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Gily</given-names> <surname>Ginosar</surname></string-name>, <string-name><given-names>Johnatan</given-names> <surname>Aljadeff</surname></string-name>, <string-name><given-names>Liora</given-names> <surname>Las</surname></string-name>, <string-name><given-names>Dori</given-names> <surname>Derdikman</surname></string-name>, and <string-name><given-names>Nachum</given-names> <surname>Ulanovsky</surname></string-name></person-group>. <article-title>Are grid cells used for navigation? on local metrics, subjective spaces, and black holes</article-title>. <source>Neuron</source>, <year>2023</year>.</mixed-citation></ref>
<ref id="c41"><label>[41]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Jeff</given-names> <surname>Hawkins</surname></string-name>, <string-name><given-names>Marcus</given-names> <surname>Lewis</surname></string-name>, <string-name><given-names>Mirko</given-names> <surname>Klukas</surname></string-name>, <string-name><given-names>Scott</given-names> <surname>Purdy</surname></string-name>, and <string-name><given-names>Subutai</given-names> <surname>Ahmad</surname></string-name></person-group>. <article-title>A framework for intelligence and cortical function based on grid cells in the neocortex</article-title>. <source>Frontiers in neural circuits</source>, <volume>12</volume>:<fpage>121</fpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c42"><label>[42]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Mirko</given-names> <surname>Klukas</surname></string-name>, <string-name><given-names>Marcus</given-names> <surname>Lewis</surname></string-name>, and <string-name><given-names>Ila</given-names> <surname>Fiete</surname></string-name></person-group>. <article-title>Efficient and flexible representation of higher-dimensional cognitive variables with grid cells</article-title>. <source>PLoS computational biology</source>, <volume>16</volume>(<issue>4</issue>):<fpage>e1007796</fpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c43"><label>[43]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Jon W</given-names> <surname>Rueckemann</surname></string-name>, <string-name><given-names>Marielena</given-names> <surname>Sosa</surname></string-name>, <string-name><given-names>Lisa M</given-names> <surname>Giocomo</surname></string-name>, and <string-name><given-names>Elizabeth A</given-names> <surname>Buffalo</surname></string-name></person-group>. <article-title>The grid code for ordered experience</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>22</volume>(<issue>10</issue>):<fpage>637</fpage>–<lpage>649</lpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c44"><label>[44]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Francesca</given-names> <surname>Sargolini</surname></string-name>, <string-name><given-names>Marianne</given-names> <surname>Fyhn</surname></string-name>, <string-name><given-names>Torkel</given-names> <surname>Hafting</surname></string-name>, <string-name><given-names>Bruce L</given-names> <surname>McNaughton</surname></string-name>, <string-name><given-names>Menno P</given-names> <surname>Witter</surname></string-name>, <string-name><given-names>May-Britt</given-names> <surname>Moser</surname></string-name>, and <string-name><given-names>Edvard I</given-names> <surname>Moser</surname></string-name></person-group>. <article-title>Conjunctive representation of position, direction, and velocity in entorhinal cortex</article-title>. <source>Science</source>, <volume>312</volume>(<issue>5774</issue>):<fpage>758</fpage>–<lpage>762</lpage>, <year>2006</year>.</mixed-citation></ref>
<ref id="c45"><label>[45]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Tor</given-names> <surname>Stensola</surname></string-name>, <string-name><given-names>Hanne</given-names> <surname>Stensola</surname></string-name>, <string-name><given-names>May-Britt</given-names> <surname>Moser</surname></string-name>, and <string-name><given-names>Edvard I</given-names> <surname>Moser</surname></string-name></person-group>. <article-title>Shearing-induced asymmetry in entorhinal grid cells</article-title>. <source>Nature</source>, <volume>518</volume>(<issue>7538</issue>):<fpage>207</fpage>–<lpage>212</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c46"><label>[46]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Alexander</given-names> <surname>Mathis</surname></string-name>, <string-name><given-names>Andreas VM</given-names> <surname>Herz</surname></string-name>, and <string-name><given-names>Martin B</given-names> <surname>Stemmler</surname></string-name></person-group>. <article-title>Resolution of nested neuronal representations can be exponential in the number of neurons</article-title>. <source>Physical review letters</source>, <volume>109</volume>(<issue>1</issue>):<fpage>018103</fpage>, <year>2012</year>.</mixed-citation></ref>
<ref id="c47"><label>[47]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Maoz</given-names> <surname>Shamir</surname></string-name> and <string-name><given-names>Haim</given-names> <surname>Sompolinsky</surname></string-name></person-group>. <article-title>Implications of neuronal diversity on population coding</article-title>. <source>Neural computation</source>, <volume>18</volume>(<issue>8</issue>):<fpage>1951</fpage>–<lpage>1986</lpage>, <year>2006</year>.</mixed-citation></ref>
<ref id="c48"><label>[48]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Mircea I</given-names> <surname>Chelaru</surname></string-name> and <string-name><given-names>Valentin</given-names> <surname>Dragoi</surname></string-name></person-group>. <article-title>Efficient coding in heterogeneous neuronal populations</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>105</volume>(<issue>42</issue>):<fpage>16344</fpage>–<lpage>16349</lpage>, <year>2008</year>.</mixed-citation></ref>
<ref id="c49"><label>[49]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Julijana</given-names> <surname>Gjorgjieva</surname></string-name>, <string-name><given-names>Guillaume</given-names> <surname>Drion</surname></string-name>, and <string-name><given-names>Eve</given-names> <surname>Marder</surname></string-name></person-group>. <article-title>Computational implications of biophysical diversity and multiple timescales in neurons and synapses for circuit performance</article-title>. <source>Current opinion in neurobiology</source>, <volume>37</volume>:<fpage>44</fpage>–<lpage>52</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c50"><label>[50]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Nicolas</given-names> <surname>Perez-Nieves</surname></string-name>, <string-name><given-names>Vincent CH</given-names> <surname>Leung</surname></string-name>, <string-name><given-names>Pier Luigi</given-names> <surname>Dragotti</surname></string-name>, and <string-name><given-names>Dan FM</given-names> <surname>Goodman</surname></string-name></person-group>. <article-title>Neural heterogeneity promotes robust learning</article-title>. <source>Nature communications</source>, <volume>12</volume>(<issue>1</issue>):<fpage>5791</fpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c51"><label>[51]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Se-Bum</given-names> <surname>Paik</surname></string-name> and <string-name><given-names>Dario L</given-names> <surname>Ringach</surname></string-name></person-group>. <article-title>Retinal origin of orientation maps in visual cortex</article-title>. <source>Nature neuroscience</source>, <volume>14</volume>(<issue>7</issue>):<fpage>919</fpage>–<lpage>925</lpage>, <year>2011</year>.</mixed-citation></ref>
<ref id="c52"><label>[52]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Gary G</given-names> <surname>Blasdel</surname></string-name> and <string-name><given-names>Guy</given-names> <surname>Salama</surname></string-name></person-group>. <article-title>Voltage-sensitive dyes reveal a modular organization in monkey striate cortex</article-title>. <source>Nature</source>, <volume>321</volume>(<issue>6070</issue>):<fpage>579</fpage>–<lpage>585</lpage>, <year>1986</year>.</mixed-citation></ref>
<ref id="c53"><label>[53]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Spencer L</given-names> <surname>Smith</surname></string-name> and <string-name><given-names>Ikuko T</given-names> <surname>Smith</surname></string-name></person-group>. <article-title>Life imitates op art</article-title>. <source>Nature Neuroscience</source>, <volume>14</volume>(<issue>7</issue>):<fpage>803</fpage>–<lpage>804</lpage>, <year>2011</year>.</mixed-citation></ref>
<ref id="c54"><label>[54]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Ryan J</given-names> <surname>Low</surname></string-name>, <string-name><given-names>Yi</given-names> <surname>Gu</surname></string-name>, and <string-name><given-names>David W</given-names> <surname>Tank</surname></string-name></person-group>. <article-title>Cellular resolution optical access to brain regions in fissures: imaging medial prefrontal cortex and grid cells in entorhinal cortex</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>111</volume>(<issue>52</issue>):<fpage>18739</fpage>–<lpage>18744</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c55"><label>[55]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Weijian</given-names> <surname>Zong</surname></string-name>, <string-name><given-names>Horst A</given-names> <surname>Obenhaus</surname></string-name>, <string-name><given-names>Emilie R</given-names> <surname>Skytøen</surname></string-name>, <string-name><given-names>Hanna</given-names> <surname>Eneqvist</surname></string-name>, <string-name><given-names>Nienke L</given-names> <surname>de Jong</surname></string-name>, <string-name><given-names>Ruben</given-names> <surname>Vale</surname></string-name>, <string-name><given-names>Marina R</given-names> <surname>Jorge</surname></string-name>, <string-name><given-names>May-Britt</given-names> <surname>Moser</surname></string-name>, and <string-name><given-names>Edvard I</given-names> <surname>Moser</surname></string-name></person-group>. <article-title>Large-scale two-photon calcium imaging in freely moving mice</article-title>. <source>Cell</source>, <volume>185</volume>(<issue>7</issue>):<fpage>1240</fpage>–<lpage>1256</lpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c56"><label>[56]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Haggai</given-names> <surname>Agmon</surname></string-name> and <string-name><given-names>Yoram</given-names> <surname>Burak</surname></string-name></person-group>. <article-title>A theory of joint attractor dynamics in the hippocampus and the entorhinal cortex accounts for artificial remapping and grid cell field-to-field variability</article-title>. <source>Elife</source>, <volume>9</volume>:<fpage>e56894</fpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c57"><label>[57]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Heekyung</given-names> <surname>Lee</surname></string-name>, <string-name><given-names>Cheng</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>Sachin S</given-names> <surname>Deshmukh</surname></string-name>, and <string-name><given-names>James J</given-names> <surname>Knierim</surname></string-name></person-group>. <article-title>Neural population evidence of functional heterogeneity along the ca3 transverse axis: pattern completion versus pattern separation</article-title>. <source>Neuron</source>, <volume>87</volume>(<issue>5</issue>):<fpage>1093</fpage>–<lpage>1105</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c58"><label>[58]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Li</given-names> <surname>Lu</surname></string-name>, <string-name><given-names>Kei M</given-names> <surname>Igarashi</surname></string-name>, <string-name><given-names>Menno P</given-names> <surname>Witter</surname></string-name>, <string-name><given-names>Edvard I</given-names> <surname>Moser</surname></string-name>, and <string-name><given-names>May-Britt</given-names> <surname>Moser</surname></string-name></person-group>. <article-title>Topography of place maps along the ca3-to-ca2 axis of the hippocampus</article-title>. <source>Neuron</source>, <volume>87</volume>(<issue>5</issue>):<fpage>1078</fpage>–<lpage>1092</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c59"><label>[59]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>William T</given-names> <surname>Redman</surname></string-name>, <string-name><given-names>Nora S</given-names> <surname>Wolcott</surname></string-name>, <string-name><given-names>Luca</given-names> <surname>Montelisciani</surname></string-name>, <string-name><given-names>Gabriel</given-names> <surname>Luna</surname></string-name>, <string-name><given-names>Tyler D</given-names> <surname>Marks</surname></string-name>, <string-name><given-names>Kevin K</given-names> <surname>Sit</surname></string-name>, <string-name><given-names>Che-Hang</given-names> <surname>Yu</surname></string-name>, <string-name><given-names>Spencer</given-names> <surname>Smith</surname></string-name>, and <string-name><given-names>Michael J</given-names> <surname>Goard</surname></string-name></person-group>. <article-title>Long-term transverse imaging of the hippocampus with glass microperiscopes</article-title>. <source>Elife</source>, <volume>11</volume>:<fpage>e75391</fpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c60"><label>[60]</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><given-names>Francisco</given-names> <surname>Acosta</surname></string-name>, <string-name><given-names>Sophia</given-names> <surname>Sanborn</surname></string-name>, <string-name><given-names>Khanh Dao</given-names> <surname>Duc</surname></string-name>, <string-name><given-names>Manu</given-names> <surname>Madhav</surname></string-name>, and <string-name><given-names>Nina</given-names> <surname>Miolane</surname></string-name></person-group>. <article-title>Quantifying extrinsic curvature in neural manifolds</article-title>. <source>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</source>, pages <fpage>610</fpage>–<lpage>619</lpage>, <year>2023</year>.</mixed-citation></ref>
<ref id="c61"><label>[61]</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><given-names>William T</given-names> <surname>Redman</surname></string-name>, <string-name><given-names>Maria</given-names> <surname>Fonoberova</surname></string-name>, <string-name><given-names>Ryan</given-names> <surname>Mohr</surname></string-name>, <string-name><given-names>Ioannis G</given-names> <surname>Kevrekidis</surname></string-name>, and <string-name><given-names>Igor</given-names> <surname>Mezic</surname></string-name></person-group>. <chapter-title>Algorithmic (semi-) conjugacy via koopman operator theory</chapter-title>. <source>2022 IEEE 61st Conference on Decision and Control (CDC)</source>, pages <fpage>6006</fpage>–<lpage>6011</lpage>. <publisher-name>IEEE</publisher-name>, <year>2022</year>.</mixed-citation></ref>
<ref id="c62"><label>[62]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>William T</given-names> <surname>Redman</surname></string-name>, <string-name><given-names>Juan M</given-names> <surname>Bello-Rivas</surname></string-name>, <string-name><given-names>Maria</given-names> <surname>Fonoberova</surname></string-name>, <string-name><given-names>Ryan</given-names> <surname>Mohr</surname></string-name>, <string-name><given-names>Ioannis G</given-names> <surname>Kevrekidis</surname></string-name>, and <string-name><given-names>Igor</given-names> <surname>Mezic</surname></string-name></person-group>. <article-title>On equivalent optimization of machine learning methods</article-title>. <source>arXiv</source> <pub-id pub-id-type="arxiv">2302.09160</pub-id>, <year>2023</year>.</mixed-citation></ref>
<ref id="c63"><label>[63]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Mitchell</given-names> <surname>Ostrow</surname></string-name>, <string-name><given-names>Adam</given-names> <surname>Eisen</surname></string-name>, <string-name><given-names>Leo</given-names> <surname>Kozachkov</surname></string-name>, and <string-name><given-names>Ila</given-names> <surname>Fiete</surname></string-name></person-group>. <article-title>Beyond geometry: Comparing the temporal structure of computation in neural circuits with dynamical similarity analysis</article-title>. <source>Advances in Neural Information Processing Systems</source>, <volume>36</volume>, <year>2024</year>.</mixed-citation></ref>
<ref id="c64"><label>[64]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Marianne</given-names> <surname>Fyhn</surname></string-name>, <string-name><given-names>Torkel</given-names> <surname>Hafting</surname></string-name>, <string-name><given-names>Alessandro</given-names> <surname>Treves</surname></string-name>, <string-name><given-names>May-Britt</given-names> <surname>Moser</surname></string-name>, and <string-name><given-names>Edvard I</given-names> <surname>Moser</surname></string-name></person-group>. <article-title>Hippocampal remapping and grid realignment in entorhinal cortex</article-title>. <source>Nature</source>, <volume>446</volume>(<issue>7132</issue>):<fpage>190</fpage>–<lpage>194</lpage>, <year>2007</year>.</mixed-citation></ref>
<ref id="c65"><label>[65]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Eliott Robert Joseph</given-names> <surname>Levy</surname></string-name>, <string-name><given-names>Simón</given-names> <surname>Carrillo-Segura</surname></string-name>, <string-name><given-names>Eun Hye</given-names> <surname>Park</surname></string-name>, <string-name><given-names>William Thomas</given-names> <surname>Redman</surname></string-name>, <string-name><given-names>José Rafael</given-names> <surname>Hurtado</surname></string-name>, <string-name><given-names>SueYeon</given-names> <surname>Chung</surname></string-name>, and <string-name><given-names>André Antonio</given-names> <surname>Fenton</surname></string-name></person-group>. <article-title>A manifold neural population code for space in hippocampal coactivity dynamics independent of place fields</article-title>. <source>Cell Reports</source>, <volume>42</volume>(<issue>10</issue>), <year>2023</year>.</mixed-citation></ref>
<ref id="c66"><label>[66]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Emily A</given-names> <surname>Mankin</surname></string-name>, <string-name><given-names>Fraser T</given-names> <surname>Sparks</surname></string-name>, <string-name><given-names>Begum</given-names> <surname>Slayyeh</surname></string-name>, <string-name><given-names>Robert J</given-names> <surname>Sutherland</surname></string-name>, <string-name><given-names>Stefan</given-names> <surname>Leutgeb</surname></string-name>, and <string-name><given-names>Jill K</given-names> <surname>Leutgeb</surname></string-name></person-group>. <article-title>Neuronal code for extended time in the hippocampus</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>109</volume>(<issue>47</issue>):<fpage>19462</fpage>–<lpage>19467</lpage>, <year>2012</year>.</mixed-citation></ref>
<ref id="c67"><label>[67]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Yaniv</given-names> <surname>Ziv</surname></string-name>, <string-name><given-names>Laurie D</given-names> <surname>Burns</surname></string-name>, <string-name><given-names>Eric D</given-names> <surname>Cocker</surname></string-name>, <string-name><given-names>Elizabeth O</given-names> <surname>Hamel</surname></string-name>, <string-name><given-names>Kunal K</given-names> <surname>Ghosh</surname></string-name>, <string-name><given-names>Lacey J</given-names> <surname>Kitch</surname></string-name>, <string-name><given-names>Abbas</given-names> <surname>El Gamal</surname></string-name>, and <string-name><given-names>Mark J</given-names> <surname>Schnitzer</surname></string-name></person-group>. <article-title>Long-term dynamics of ca1 hippocampal place codes</article-title>. <source>Nature neuroscience</source>, <volume>16</volume>(<issue>3</issue>):<fpage>264</fpage>–<lpage>266</lpage>, <year>2013</year>.</mixed-citation></ref>
<ref id="c68"><label>[68]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Thomas</given-names> <surname>Hainmueller</surname></string-name> and <string-name><given-names>Marlene</given-names> <surname>Bartos</surname></string-name></person-group>. <article-title>Parallel emergence of stable and dynamic memory engrams in the hippocampus</article-title>. <source>Nature</source>, <volume>558</volume>(<issue>7709</issue>):<fpage>292</fpage>–<lpage>296</lpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="c69"><label>[69]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Walter G</given-names> <surname>Gonzalez</surname></string-name>, <string-name><given-names>Hanwen</given-names> <surname>Zhang</surname></string-name>, <string-name><given-names>Anna</given-names> <surname>Harutyunyan</surname></string-name>, and <string-name><given-names>Carlos</given-names> <surname>Lois</surname></string-name></person-group>. <article-title>Persistence of neuronal representations through time and damage in the hippocampus</article-title>. <source>Science</source>, <volume>365</volume>(<issue>6455</issue>):<fpage>821</fpage>–<lpage>825</lpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c70"><label>[70]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Can</given-names> <surname>Dong</surname></string-name>, <string-name><given-names>Antoine D</given-names> <surname>Madar</surname></string-name>, and <string-name><given-names>Mark EJ</given-names> <surname>Sheffield</surname></string-name></person-group>. <article-title>Distinct place cell dynamics in ca1 and ca3 encode experience in new environments</article-title>. <source>Nature communications</source>, <volume>12</volume>(<issue>1</issue>):<fpage>2977</fpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c71"><label>[71]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Adi</given-names> <surname>Mizrahi</surname></string-name>, <string-name><given-names>Justin C</given-names> <surname>Crowley</surname></string-name>, <string-name><given-names>Eran</given-names> <surname>Shtoyerman</surname></string-name>, and <string-name><given-names>Lawrence C</given-names> <surname>Katz</surname></string-name></person-group>. <article-title>High-resolution in vivo imaging of hippocampal dendrites and spines</article-title>. <source>Journal of Neuroscience</source>, <volume>24</volume>(<issue>13</issue>):<fpage>3147</fpage>–<lpage>3151</lpage>, <year>2004</year>.</mixed-citation></ref>
<ref id="c72"><label>[72]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Alessio</given-names> <surname>Attardo</surname></string-name>, <string-name><given-names>James E</given-names> <surname>Fitzgerald</surname></string-name>, and <string-name><given-names>Mark J</given-names> <surname>Schnitzer</surname></string-name></person-group>. <article-title>Impermanence of dendritic spines in live adult ca1 hippocampus</article-title>. <source>Nature</source>, <volume>523</volume>(<issue>7562</issue>):<fpage>592</fpage>–<lpage>596</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c73"><label>[73]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Thomas</given-names> <surname>Pfeiffer</surname></string-name>, <string-name><given-names>Stefanie</given-names> <surname>Poll</surname></string-name>, <string-name><given-names>Stephane</given-names> <surname>Bancelin</surname></string-name>, <string-name><given-names>Julie</given-names> <surname>Angibaud</surname></string-name>, <string-name><given-names>VVG Krishna</given-names> <surname>Inavalli</surname></string-name>, <string-name><given-names>Kevin</given-names> <surname>Keppler</surname></string-name>, <string-name><given-names>Manuel</given-names> <surname>Mittag</surname></string-name>, <string-name><given-names>Martin</given-names> <surname>Fuhrmann</surname></string-name>, and <string-name><given-names>U Valentin</given-names> <surname>Nägerl</surname></string-name></person-group>. <article-title>Chronic 2p-sted imaging reveals high turnover of dendritic spines in the hippocampus in vivo</article-title>. <source>Elife</source>, <volume>7</volume>:<fpage>e34700</fpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="c74"><label>[74]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Nathaniel J</given-names> <surname>Killian</surname></string-name>, <string-name><given-names>Michael J</given-names> <surname>Jutras</surname></string-name>, and <string-name><given-names>Elizabeth A</given-names> <surname>Buffalo</surname></string-name></person-group>. <article-title>A map of visual space in the primate entorhinal cortex</article-title>. <source>Nature</source>, <volume>491</volume>(<issue>7426</issue>):<fpage>761</fpage>–<lpage>764</lpage>, <year>2012</year>.</mixed-citation></ref>
<ref id="c75"><label>[75]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Alexandra O</given-names> <surname>Constantinescu</surname></string-name>, <string-name><given-names>Jill X</given-names> <surname>O’Reilly</surname></string-name>, and <string-name><given-names>Timothy EJ</given-names> <surname>Behrens</surname></string-name></person-group>. <article-title>Organizing conceptual knowledge in humans with a gridlike code</article-title>. <source>Science</source>, <volume>352</volume>(<issue>6292</issue>):<fpage>1464</fpage>–<lpage>1468</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c76"><label>[76]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Dmitriy</given-names> <surname>Aronov</surname></string-name>, <string-name><given-names>Rhino</given-names> <surname>Nevers</surname></string-name>, and <string-name><given-names>David W</given-names> <surname>Tank</surname></string-name></person-group>. <article-title>Mapping of a non-spatial dimension by the hippocampal– entorhinal circuit</article-title>. <source>Nature</source>, <volume>543</volume>(<issue>7647</issue>):<fpage>719</fpage>–<lpage>722</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c77"><label>[77]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Joshua B</given-names> <surname>Julian</surname></string-name>, <string-name><given-names>Alexandra T</given-names> <surname>Keinath</surname></string-name>, <string-name><given-names>Giulia</given-names> <surname>Frazzetta</surname></string-name>, and <string-name><given-names>Russell A</given-names> <surname>Epstein</surname></string-name></person-group>. <article-title>Human entorhinal cortex represents visual space using a boundary-anchored grid</article-title>. <source>Nature neuroscience</source>, <volume>21</volume>(<issue>2</issue>):<fpage>191</fpage>–<lpage>194</lpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="c78"><label>[78]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Matthias</given-names> <surname>Nau</surname></string-name>, <string-name><given-names>Tobias</given-names> <surname>Navarro</surname></string-name> Schröder, <string-name><given-names>Jacob LS</given-names> <surname>Bellmund</surname></string-name>, and <string-name><given-names>Christian F</given-names> <surname>Doeller</surname></string-name></person-group>. <article-title>Hexadirectional coding of visual space in human entorhinal cortex</article-title>. <source>Nature neuroscience</source>, <volume>21</volume>(<issue>2</issue>):<fpage>188</fpage>–<lpage>190</lpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="c79"><label>[79]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Niklas</given-names> <surname>Wilming</surname></string-name>, <string-name><given-names>Peter</given-names> <surname>König</surname></string-name>, <string-name><given-names>Seth</given-names> <surname>König</surname></string-name>, and <string-name><given-names>Elizabeth A</given-names> <surname>Buffalo</surname></string-name></person-group>. <article-title>Entorhinal cortex receptive fields are modulated by spatial attention, even without movement</article-title>. <source>Elife</source>, <volume>7</volume>:<fpage>e31745</fpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="c80"><label>[80]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Rylan</given-names> <surname>Schaeffer</surname></string-name>, <string-name><given-names>Mikail</given-names> <surname>Khona</surname></string-name>, <string-name><given-names>Tzuhsuan</given-names> <surname>Ma</surname></string-name>, <string-name><given-names>Cristobal</given-names> <surname>Eyzaguirre</surname></string-name>, <string-name><given-names>Sanmi</given-names> <surname>Koyejo</surname></string-name>, and <string-name><given-names>Ila</given-names> <surname>Fiete</surname></string-name></person-group>. <article-title>Self-supervised learning of representations for space generates multi-modular grid cells</article-title>. <source>Advances in Neural Information Processing Systems</source>, <volume>36</volume>, <year>2024</year>.</mixed-citation></ref>
<ref id="c81"><label>[81]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>James J</given-names> <surname>Jun</surname></string-name>, <string-name><given-names>Nicholas A</given-names> <surname>Steinmetz</surname></string-name>, <string-name><given-names>Joshua H</given-names> <surname>Siegle</surname></string-name>, <string-name><given-names>Daniel J</given-names> <surname>Denman</surname></string-name>, <string-name><given-names>Marius</given-names> <surname>Bauza</surname></string-name>, <string-name><given-names>Brian</given-names> <surname>Barbarits</surname></string-name>, <string-name><given-names>Albert K</given-names> <surname>Lee</surname></string-name>, <string-name><given-names>Costas A</given-names> <surname>Anastassiou</surname></string-name>, <string-name><given-names>Alexandru</given-names> <surname>Andrei</surname></string-name>, <string-name><given-names>Çagatay</given-names> <surname>Aydin</surname></string-name>, <etal>et al.</etal></person-group> <article-title>Fully integrated silicon probes for high-density recording of neural activity</article-title>. <source>Nature</source>, <volume>551</volume>(<issue>7679</issue>):<fpage>232</fpage>–<lpage>236</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c82"><label>[82]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Nicholas A</given-names> <surname>Steinmetz</surname></string-name>, <string-name><given-names>Cagatay</given-names> <surname>Aydin</surname></string-name>, <string-name><given-names>Anna</given-names> <surname>Lebedeva</surname></string-name>, <string-name><given-names>Michael</given-names> <surname>Okun</surname></string-name>, <string-name><given-names>Marius</given-names> <surname>Pachitariu</surname></string-name>, <string-name><given-names>Marius</given-names> <surname>Bauza</surname></string-name>, <string-name><given-names>Maxime</given-names> <surname>Beau</surname></string-name>, <string-name><given-names>Jai</given-names> <surname>Bhagat</surname></string-name>, <string-name><given-names>Claudia</given-names> <surname>Böhm</surname></string-name>, <string-name><given-names>Martijn</given-names> <surname>Broux</surname></string-name>, <etal>et al.</etal></person-group> <article-title>Neuropixels 2.0: A miniaturized high-density probe for stable, long-term brain recordings</article-title>. <source>Science</source>, <volume>372</volume>(<issue>6539</issue>):<fpage>eabf4588</fpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c83"><label>[83]</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>Leland</given-names> <surname>McInnes</surname></string-name>, <string-name><given-names>John</given-names> <surname>Healy</surname></string-name>, and <string-name><given-names>James</given-names> <surname>Melville</surname></string-name></person-group>. <article-title>Umap: Uniform manifold approximation and projection for dimension reduction</article-title>. <source>arXiv</source> <pub-id pub-id-type="arxiv">1802.03426</pub-id>, <year>2018</year>.</mixed-citation></ref>
<ref id="c84"><label>[84]</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>William N</given-names> <surname>Butler</surname></string-name>, <string-name><given-names>Kiah</given-names> <surname>Hardcastle</surname></string-name>, and <string-name><given-names>Lisa M</given-names> <surname>Giocomo</surname></string-name></person-group>. <article-title>Remembered reward locations restructure entorhinal spatial maps</article-title>. <source>Science</source>, <volume>363</volume>(<issue>6434</issue>):<fpage>1447</fpage>–<lpage>1452</lpage>, <year>2019</year>.</mixed-citation></ref>
</ref-list>
<sec id="s5">
<title>Supplemental material</title>
<fig id="figS1" position="float" fig-type="figure">
<label>Figure S1:</label>
<caption><title>Accepted and rejected cells, across all grid modules.</title>
<p>(Left) The percent of all cells, across all modules, that were rejected by our inclusion criteria. Cells that were rejected as not having SACs, computed with all data, that were well described by hexagonal structure (“Rejected: Poor grid fits”) are shown in red. Cells that were rejected as not reliably having SACs, computed from splits of the data, that were well described by hexagonal structure (“Rejected: Unreliable”) are shown in yellow. Cells that met these criteria (“Accepted”) are shown in blue. (Middle) Grid score of all cells, with coloring denoting whether they were accepted or rejected. Dashed gray line denotes population mean. (Right) The number of splits of the data (out of 100) that cells had SAC’s with poor grid fits, as a function of each cell’s grid score.</p></caption>
<graphic xlink:href="582373v2_figS1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS2" position="float" fig-type="figure">
<label>Figure S2:</label>
<caption><title>Variability in grid spacing, within a single module, exists when computing <italic>λ</italic> directly from the rate maps.</title>
<p>(A) (Left) Example grid cell rate maps from the same module (recording ID R12) with overlaid triangles, corresponding to the spacing between each of the three most central peaks. Grid spacing is computed as the average of the three lengths. (Right) To aid comparison, the triangles are enlarged (with their relative size fixed) and overlaid. Note that these cells are the same ones plotted in <xref rid="fig2" ref-type="fig">Fig. 2B</xref>. (B) Distribution of grid spacing computed using the SAC and the rate maps. (C) The grid spacing of all grid cells, from recording R12, computed using the SAC and the rate map. Red dashed line is the linear regression fit with <italic>R</italic><sup>2</sup> and <italic>p</italic>-value reported above.</p></caption>
<graphic xlink:href="582373v2_figS2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS3" position="float" fig-type="figure">
<label>Figure S3:</label>
<caption><title>Bin length does not affect the percent of cells, with good grid fits, that are accepted for analysis.</title>
<p>The percent of cells with good grid fits (i.e., those cells that do not get rejected for having “poor grid fits”) that are accepted by not being deemed unreliable, as a function of the size of the bins used in the shuffle analysis. All modules are plotted (each line is colored based on its recording ID).</p></caption>
<graphic xlink:href="582373v2_figS3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS4" position="float" fig-type="figure">
<label>Figure S4:</label>
<caption><title>Variability in grid properties improves decoding of local space for grid modules with different grid spacings.</title>
<p>(A)–(B) Same as <xref rid="fig6" ref-type="fig">Fig. 6F</xref>, for <inline-formula><inline-graphic xlink:href="582373v2_inline44.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="582373v2_inline45.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, respectively. <inline-formula><inline-graphic xlink:href="582373v2_inline46.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is set to 0<sup>°</sup>.</p></caption>
<graphic xlink:href="582373v2_figS4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS5" position="float" fig-type="figure">
<label>Figure S5:</label>
<caption><title>Variability in grid properties improves decoding of local space for multiple modules, when the modules have integer multiple spacing.</title>
<p>(A)–(B) Same as <xref rid="fig6" ref-type="fig">Fig. 6D</xref>, when decoding from multiple modules. (A) <inline-formula><inline-graphic xlink:href="582373v2_inline47.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="582373v2_inline48.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. (B) <inline-formula><inline-graphic xlink:href="582373v2_inline49.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="582373v2_inline50.gif" mime-subtype="gif" mimetype="image"/></inline-formula>.</p></caption>
<graphic xlink:href="582373v2_figS5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100652.1.sa4</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Peyrache</surname>
<given-names>Adrien</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>McGill University</institution>
</institution-wrap>
<city>Montreal</city>
<country>Canada</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>valuable</bold> study characterizes the variability in spacing and direction of entorhinal grid cells and shows how this variability can be used to disambiguate locations within an environment. These claims are supported by <bold>solid</bold> evidence, yet some aspects of the methodology should be clarified. This study will be of interest to neuroscientists working on spatial navigation and, more generally, on neural coding.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100652.1.sa3</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The present paper by Redman et al. investigated the variability of grid cell properties in the MEC by analyzing publicly available large-scale neural recording data. Although previous studies have proposed that grid spacing and orientation are homogeneous within the same grid module, the authors found a small but robust variability in grid spacing and orientation across grid cells in the same module. The authors also showed, through model simulations, that such variability is useful for decoding spatial position.</p>
<p>Strengths:</p>
<p>The results of this study provide novel and intriguing insights into how grid cells compose the cognitive map in the axis of the entorhinal cortex and hippocampus. This study analyzes large data sets in an appropriate manner and the results are solid.</p>
<p>Weaknesses:</p>
<p>A weakness of this paper is that the scope of the study may be somewhat narrow, as this study focused only on the variability of spacing and orientation across grid cells. I would suggest some additional analysis or discussion that might increase the value of the paper.</p>
<p>(1) Is the variability in grid spacing and orientation that the authors found intrinsically organized or is it shaped by experience? Previous research has shown that grid representations can be modified through experience (e.g., Boccara et al., Science 2019). To understand the dynamics of the network, it would be important to investigate whether robust variability exists from the beginning of the task period (recording period) or whether variability emerges in an experience-dependent manner within a session.</p>
<p>(2) It is important to consider the optimal variability size. The larger the variability, the better it is for decoding. On the other hand, as the authors state in the Discussion, it is assumed that variability does not exist in the continuous attractor model. Although this study describes that it does not address how such variability fits the attractor theory, it would be better if more detailed ideas and suggestions were provided as to what direction the study could take to clarify the optimal size of variability.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100652.1.sa2</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This paper presents an interesting and useful analysis of grid cell heterogeneity, showing that the experimentally observed heterogeneity of spacing and orientation within a grid cell module can allow more accurate decoding of location from a single module.</p>
<p>Strengths:</p>
<p>I found the statistical analysis of the grid cell variability to be very systematic and convincing. I also found the evidence for enhanced decoding of location based on between-cell variability within a module to be convincing and important, supporting their conclusions.</p>
<p>Weaknesses:</p>
<p>(1) Even though theoreticians might have gotten the mistaken impression that grid cells are highly regular, this might be due to an overemphasis on regularity in a subset of papers. Most experimentalists working with grid cells know that many if not most grid cells show high variability of firing fields within a single neuron, though this analysis focuses on between neurons. In response to this comment, the reviewers should tone down and modify their statements about what are the current assumptions of the field (and if possible provide a short supplemental section with direct quotes from various papers that have made these assumptions).</p>
<p>(2) The authors state that &quot;no characterization of the degree and robustness of variability in grid properties within individual modules has been performed.&quot; It is always dangerous to speak in absolute terms about what has been done in scientific studies. It is true that few studies have had the number of grid cells necessary to make comparisons within and between modules, but many studies have clearly shown the distribution of spacing in neuronal data (e.g. Hafting et al., 2005; Barry et al., 2007; Stensola et al., 2012; Hardcastle et al., 2015) so the variability has been visible in the data presentations. Also, most researchers in the field are well aware that highly consistent grid cells are much rarer than messy grid cells that have unevenly spaced firing fields. This doesn't hurt the importance of the paper, but they need to tone down their statements about the lack of previous awareness of variability (specific locations are noted in the specific comments).</p>
<p>(3) The methods section needs to have a separate subheading entitled: How grid cells were assigned to modules&quot; that clearly describes how the grid cells were assigned to a module (i.e. was this done by Gardner et al., or done as part of this paper's post-processing?</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100652.1.sa1</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Redman and colleagues analyze grid cell data obtained from public databases. They show that there is significant variability in spacing and orientation within a module. They show that the difference in spacing and orientation for a pair of cells is larger than the one obtained for two independent maps of the same cell. They speculate that this variability could be useful to disambiguate the rat position if only information from a single module is used by a decoder.</p>
<p>Strengths:</p>
<p>The strengths of this work lie in its conciseness, clarity, and the potential significance of its findings for the grid cell community, which has largely overlooked this issue for the past two decades. Their hypothesis is well stated and the analyses are solid.</p>
<p>Weaknesses:</p>
<p>On the side of weaknesses, we identified two aspects of concern. First, alternative explanations for the main result exist that should be explored and ruled out. Second, the authors' speculation about the benefits of variability in angle and spacing for spatial coding is not particularly convincing, although this issue does not diminish the importance or impact of the results.</p>
<p>Major comments:</p>
<p>(1) One possible explanation of the dispersion in lambda (not in theta) could be variability in the typical width of the field. For a fixed spacing, wider fields might push the six fields around the center of the autocorrelogram toward the outside, depending on the details of how exactly the position of these fields is calculated. We recommend authors show that lambda does not correlate with field width, or at least that the variability explained by field width is smaller than the overall lambda variability.</p>
<p>(2) An alternative explanation could be related to what happens at the borders. The authors tackle this issue in Figure S2 but introduce a different way of measuring lambda based on three fields, which in our view is not optimal. We recommend showing that the dispersions in lambda and theta remain invariant as one removes the border-most part of the maps but estimating lambda through the autocorrelogram of the remaining part of the map. Of course, there is a limit to how much can be removed before measures of lambda and theta become very noisy.</p>
<p>(3) A third possibility is slightly more tricky. Some works (for example Kropff et al, 2015) have shown that fields anticipate the rat position, so every time the rat traverses them they appear slightly displaced opposite to the direction of movement. The amount of displacement depends on the velocity. Maps that we construct out of a whole session should be deformed in a perfectly symmetric way if rats traverse fields in all directions and speeds. However, if the cell is conjunctive, we would expect a deformation mainly along the cell's preferred head direction. Since conjunctive cells have all possible preferred directions, and many grid cells are not conjunctive at all, this phenomenon could create variability in theta and lambda that is not a legitimate one but rather associated with the way we pool data to construct maps. To rule away this possibility, we recommend the authors study the variability in theta and lambda of conjunctive vs non-conjunctive grid cells. If the authors suspect that this phenomenon could explain part of their results, they should also take into account the findings of Gerlei and colleagues (2020) from the Nolan lab, that add complexity to this issue.</p>
<p>(4) The results in Figure 6 are correct, but we are not convinced by the argument. The fact that grid cells fire in the same way in different parts of the environment and in different environments is what gives them their appeal as a platform for path integration since displacement can be calculated independently of the location of the animal. Losing this universal platform is, in our view, too much of a price to pay when the only gain is the possibility of decoding position from a single module (or non-adjacent modules) which, as the authors discuss, is probably never the case. Besides, similar disambiguation of positions within the environment would come for free by adding to the decoding algorithm spatial cells (non-hexagonal but spatially stable), which are ubiquitous across the entorhinal cortex. Thus, it seems to us that - at least along this line of argumentation - with variability the network is losing a lot but not gaining much.</p>
<p>(5) In Figure 4 one axis has markedly lower variability. Is this always the same axis? Can the authors comment more on this finding?</p>
<p>(6) The paper would gain in depth if maps coming out of different computational models could be analyzed in the same way.</p>
<p>(7) Similarly, it would be very interesting to expand the study with some other data to understand if between-cell delta_theta and delta_lambda are invariant across environments. In a related matter, is there a correlation between delta_theta (delta_lambda) for the first vs for the second half of the session? We expect there should be a significant correlation, it would be nice to show it.</p>
</body>
</sub-article>
<sub-article id="sa4" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100652.1.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Redman</surname>
<given-names>William T</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4147-2026</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Acosta-Mendoza</surname>
<given-names>Santiago</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0003-6698-476X</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Wei</surname>
<given-names>Xue-Xin</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2761-477X</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Goard</surname>
<given-names>Michael J</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5366-8501</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>We thank the reviewers for their time and thoughtful comments. We are encouraged that all reviewers found our work novel and clear. We will submit a full revision to address all the points the reviewers made. Below, we briefly highlight a few clarifications and planned analyses to address major concerns; all other concerns raised by the reviewers will also be addressed in the revision.</p>
<p>Reviewers #1 and #3 asked whether the variability in grid properties emerged with experience/time in the environment. We agree that this is an interesting question, and we will re-analyze the data to explore whether between-cell variability increases with time <italic>within</italic> a session. However, we note that since the rats were already familiarized to the environment for 10-20 sessions prior to the recordings, there may be limited additional changes in between-cell variability <italic>between</italic> recording sessions. In one case, two sessions from the same rat were recorded on consecutive days (R11/R12 and R21/R22) - these sessions did not show any difference in variability.</p>
<p>Reviewer #2 noted that the variability in grid properties is known to experimentalists. We will tone down our discussion on the current assumptions in the field to accurately reflect this awareness in the community. However, we would like to emphasize that the lack of work carefully examining the robustness of this variability has prevented a firm understanding of whether this is an inherent property of grid cells or due to noise. The impact of this can be seen in theoretical neuroscience work where a considerable number of articles (including recent publications) start with the assumption that all grid cells within a module have identical properties, with the exception of phase shift and noise. In addition, since grid cells are assumed to be identical in the computational neuroscience community, there has been little work on quantifying how much variability a given model produces. This makes it challenging to understand how consistent different models are with our observations. We believe that making these limitations of previous work clear is important to properly conveying our work’s contribution.</p>
<p>Reviewer #3 asked whether the variability in grid properties could be driven by cells that were conjunctively tuned with head direction. We agree that this is an interesting hypothesis and will explore this by performing new analysis. We note that, as reported by Gardner et al. (2022), only 19 of the 168 cells in recording session R12 are conjunctive. Even if these cells are included in the same proportion as pure grid cells by our inclusion criteria (which appears unlikely, given that conjunctive cells may be less reliable across splits of the data), then approximately 9 out of the 82 cells we analyzed would be conjunctive. Therefore, we expect it to be unlikely that they are the main source of the variability we find. However, we will test this in our revised manuscript.</p>
<p>Reviewer #3 asked whether the “price” paid in having grid property variability was too high for the modest gain in ability to encode local space. We agree that losing the continuous attractor network (CAN) structure, and the ability to path integrate, would be a very large loss. However, we do not believe that the variability we observe necessarily destroys either CAN or path integration. We argue this for two reasons. First, the data we analyzed [from Gardner et al. (2022)] is exactly the data set that was found to have toroidal topology and therefore viewed to be in line with a major prediction of CANs. Thus, the amount of variability in grid properties does not rule out the underlying presence of a continuous attractor. Second, path integration may still be possible with grid cells that have variable properties. To illustrate this, and to address another comment from Reviewer #3, we have begun to analyze the distribution of grid properties in a recurrent neural network (RNN) model trained to perform path integration (Sorscher et al., 2019). This RNN model, in addition to others (Banino et al., 2018; Cueva and Wei, 2018), has been found to develop grid cells and there is evidence that it develops CANs as the underlying circuit mechanism (Sorscher et al., 2023). We find that the grid cells that emerge from this model exhibit variability in their grid spacings and orientations. This illustrates that path integration (the very task the RNN was trained to perform) is possible using grid cells with variable properties.</p>
</body>
</sub-article>
</article>