<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">105951</article-id>
<article-id pub-id-type="doi">10.7554/eLife.105951</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.105951.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.3</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Audiovisual cues must be predictable and win-paired to drive risky choice</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1905-2199</contrib-id>
<name>
<surname>Hathaway</surname>
<given-names>Brett A</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
<email>brett.hathaway@nih.gov</email>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0000-7363-1522</contrib-id>
<name>
<surname>Kim</surname>
<given-names>Dexter R</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n2">*</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Malhas</surname>
<given-names>Salwa BA</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n2">*</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8563-611X</contrib-id>
<name>
<surname>Hrelja</surname>
<given-names>Kelly M</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Kerker</surname>
<given-names>Lauren</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Hynes</surname>
<given-names>Tristan J</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">#</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Harris</surname>
<given-names>Celyn</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Langdon</surname>
<given-names>Angela J</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Winstanley</surname>
<given-names>Catharine A</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<email>cwinstanley@psych.ubc.ca</email>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03rmrcq20</institution-id><institution>Graduate Program in Neuroscience, Djavad Mowafaghian Centre for Brain Health, University of British Columbia</institution></institution-wrap>, <city>Vancouver</city>, <country country="CA">Canada</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03rmrcq20</institution-id><institution>Department of Psychology, Djavad Mowafaghian Centre for Brain Health, University of British Columbia</institution></institution-wrap>, <city>Vancouver</city>, <country country="CA">Canada</country></aff>
<aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04xeg9z08</institution-id><institution>National Institute of Mental Health Intramural Research Program, NIH</institution></institution-wrap>, <city>Bethesda</city>, <country country="US">United States</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Bradfield</surname>
<given-names>Laura A</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Technology Sydney</institution>
</institution-wrap>
<city>Sydney</city>
<country>Australia</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Wassum</surname>
<given-names>Kate M</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of California, Los Angeles</institution>
</institution-wrap>
<city>Los Angeles</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes><fn id="n1" fn-type="present-address"><label><italic><sup>#</sup></italic></label><p>Present address: Department of Experimental Psychology, University of Cambridge, UK</p></fn><fn id="n2" fn-type="equal"><label>*</label><p>These authors contributed equally to this work</p></fn>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-04-08">
<day>08</day>
<month>04</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP105951</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-01-28">
<day>28</day>
<month>01</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-01-11">
<day>11</day>
<month>01</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.09.20.507379"/>
</event>
</pub-history>
<permissions>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">
<ali:license_ref>https://creativecommons.org/publicdomain/zero/1.0/</ali:license_ref>
<license-p>This is an open-access article, free of all copyright, and may be freely reproduced, distributed, transmitted, modified, built upon, or otherwise used by anyone for any lawful purpose. The work is made available under the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">Creative Commons CC0 public domain dedication</ext-link>.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-105951-v1.pdf"/>
<abstract>
<title>Abstract</title><p>Risky or maladaptive decision making is thought to be central to the etiology of both drug and gambling addiction. Salient audiovisual cues paired with rewarding outcomes, such as the jackpot sound on a win, can enhance disadvantageous, risky choice in both rats and humans, yet it is unclear which aspects of the cue-reward contingencies drive this effect. Here, we implemented six variants of the rat Gambling Task (rGT), in which animals can maximise their total sugar pellet profits by avoiding options paired with higher per-trial gains but disproportionately longer and more frequent time-out penalties. When audiovisual cues were delivered concurrently with wins, and scaled in salience with reward size, significantly more rats preferred the risky options as compared to the uncued rGT. Similar results were observed when the relationship between reward size and cue complexity was inverted, and when cues were delivered concurrently with all outcomes. Conversely, risky choice did not increase when cues occurred randomly on 50% of trials, and decision making actually improved when cues were coincident with losses alone. As such, cues do not increase risky choice by simply elevating arousal, or amplifying the difference between wins and losses. It is instead important that the cues are reliably associated with wins; presenting the cues on losing outcomes as well as wins does not diminish their ability to drive risky choice. Computational analyses indicate reductions in the impact of losses on decision making in all rGT variants in which win-paired cues increased risky choice. These results may help us understand how sensory stimulation can increase the addictive nature of gambling and gaming products.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>added additional reference to published work</p></fn>
</fn-group>
</notes>
</front>
<body>
    <p>The lights and sounds of a casino are physiologically arousing and increase enjoyment, particularly in those with pathological gambling (<xref ref-type="bibr" rid="c11">Dixon et al., 2014</xref>; <xref ref-type="bibr" rid="c26">Loba et al., 2001</xref>; <xref ref-type="bibr" rid="c34">Spetch et al., 2020</xref>). Indeed, gambling-related cues can cause intense cravings in such individuals, and there is increasing concern over their contribution to addiction (<xref ref-type="bibr" rid="c25">Limbrick-Oldfield et al., 2017</xref>; <xref ref-type="bibr" rid="c2">Alter, 2017</xref>). Such cues feature prominently in electronic gaming machines (EGMs), which are specifically designed to encourage excessive gambling (<xref ref-type="bibr" rid="c15">Griffiths, 1993</xref>). In particular, the salient lights and sounds associated with EGMs are thought to facilitate problematic gambling in susceptible individuals and lead to an increased state of immersion as well as overestimation of the number of wins (<xref ref-type="bibr" rid="c11">Dixon et al., 2014</xref>; <xref ref-type="bibr" rid="c2">Alter, 2017</xref>; <xref ref-type="bibr" rid="c29">Murch et al., 2017</xref>). Deficits in cost/benefit decision making are particularly pronounced in individuals who prefer EGMs over other forms of gambling (<xref ref-type="bibr" rid="c14">Goudriaan et al., 2005</xref>). Together, this evidence suggests that cue-induced impairments in cost/benefit decision making may be a critical risk factor for the development and maintenance of behavioural addictions such as gambling disorder. However, the impact of salient audiovisual cues on decision making has not been well characterized.</p>
<p>One approach to investigate the influence of outcome-paired cues in cost/benefit decision making utilizes the rat Gambling Task (rGT), a rodent analog of the human Iowa Gambling Task (IGT, <xref ref-type="bibr" rid="c37">Zeeb et al., 2009</xref>; <xref ref-type="bibr" rid="c5">Bechara et al., 1994</xref>). In both tasks, optimal performance is attained by avoiding the two high-risk, high-reward options and instead favouring the low-risk options associated with lower per-trial gains. On the rGT, these low-risk, low-reward options result in less frequent and shorter time-out penalties and therefore more sucrose pellets may be earned overall. The addition of reward-concurrent audiovisual cues leads to a higher proportion of rats establishing a disadvantageous risky decision-making profile (<xref ref-type="bibr" rid="c4">Barrus &amp; Winstanley, 2016</xref>). A similar effect of reward-paired cues on risky decision making has been observed in humans (<xref ref-type="bibr" rid="c7">Cherkasova et al., 2018</xref>). Such cues also appear to lead to inflexibility in decision-making patterns, as indicated by insensitivity to reinforcer devaluation in the cued but not the uncued rGT (<xref ref-type="bibr" rid="c17">Hathaway et al., 2021</xref>; <xref ref-type="bibr" rid="c39">Zeeb &amp; Winstanley, 2013</xref>).</p>
<p>Investigating the learning dynamics of the uncued versus cued rGT using a series of reinforcement learning models revealed that potentiated learning from the cued rewards does not drive risk preference on the cued rGT, as might be expected (<xref ref-type="bibr" rid="c24">Langdon et al., 2019</xref>). Instead, rats on the cued task were relatively insensitive to the time-out penalties, particularly for the risky options featuring lengthy and more frequent penalties.</p>
<p>Several theories could explain these results. One possibility is that higher levels of arousal resulting from exposure to the cues persists through the time-out penalties on subsequent trials and thereby alters the processing of the punishment signal. Alternatively, reward-paired cues may change the representation of task structure, such that punishments are not correctly integrated into the stored action-outcome contingencies as the rats learn to choose between the options. Salient cues may cause rats to represent winning outcomes as different “states” to losing outcomes, where learning about one state does not generalize to another (<xref ref-type="bibr" rid="c30">Niv, 2019</xref>). In that case, time-out penalties would not appropriately devalue the risky options and rats would tend to choose the options offering the highest per-trial reward.</p>
<p>Here, to test these theories and further investigate impairments in risky decision making induced by reward-paired cues, we designed several variants of the rGT to specifically manipulate the complexity and contingency of the outcome-paired cues in the task. In the standard-cued task, the audiovisual cues scale in magnitude and complexity with reward size. To determine whether this scaling is a necessary feature to drive risky choice, we implemented an inverse relationship between cue complexity/magnitude and reward size. We next tested whether cuing all outcomes, ostensibly making trial outcomes more similar and perhaps permitting correct integration into each option’s learned value, would similarly impact risky choice as solely cuing the wins. To test whether increased sensory stimulation is sufficient to increase risky choice, cues were played randomly on 50% of trials, regardless of outcome. Lastly, we paired cues with losses instead of wins to investigate whether win-paired cues are necessary to drive risky choice. A reinforcer devaluation procedure was also utilized at the end of training to determine which cue-outcome associations would lead to inflexibility in choice. Using reinforcement learning models of choice behavior, we isolated the effect of these cue manipulations on the profile of trial-by-trial learning from wins and losses in the initial sessions of each task, and found that audiovisual cues selectively elevate risky choice when those cues are consistently paired with wins, while selectively cuing losses can rescue decision-making from risky preferences that might otherwise develop in this task. Parts of this work were included in a doctoral thesis (<xref ref-type="bibr" rid="c16a">Hathaway, 2023</xref>).</p>
<sec id="s1">
<title>Results</title>
<sec id="s1a">
<title>Win-paired cues drive preference for risky options</title>
<p>Differences in decision making induced by distinct cue-outcome associations were assessed by training cohorts of rats (<italic>n</italic> per task = 28-32) on six variants of the rGT (<xref rid="fig1" ref-type="fig">Figure 1A and B</xref>). Choice profiles were calculated as the percent choice of the four options on the rGT (optimal: P1, P2; risky: P3, P4) averaged from 4 sessions at the end of training, once a statistically stable baseline was reached (sessions 35-39, +/- 2; see Methods). On average, across the rGT task variants, rats showed a preference for the optimal (i.e., reward-maximizing) option P2. However, there was marked variation between the cohorts in preference for the high-risk options P3 and P4. When comparing P1-P4 choice in an omnibus ANOVA, a significant choice x task interaction was observed (<italic>F</italic>(14,415) = 2.16, <italic>p</italic> = .009; <xref rid="fig2" ref-type="fig">Figure 2A</xref>). Group comparisons showed differences in P1-P4 choice between task versions that consistently paired cues with wins (standard-cued, reverse-cued, outcome-cued) and those that did not (uncued, random-cued, loss-cued) (<xref rid="tbl1" ref-type="table">Table 1</xref>).</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1:</label>
<caption><title>the rat Gambling Task.</title><p>(A) Schematic of the cued rGT. A nose poke response in the food tray extinguished the traylight and initiated a new trial. After an inter-trial interval (ITI) of 5 s, four stimulus lights were turned on in holes 1, 2, 4, and 5, each of which was associated with a different number of sugar pellets. The order of the options from left to right was counter-balanced within each cohort to avoid development of a simple side bias (version A (shown): P1, P4, P3, P2; version B: P4, P1, P3, P2). The animal was required to respond at a hole within 10 s. This response was then rewarded or punished depending on the reinforcement schedule for that option. If the animal lost, the stimulus light in the chosen hole flashed at a frequency of 0.5 Hz for the duration of the time-out penalty, and all other lights were extinguished. The maximum number of pellets available per 30 min session shows that P1 and P2 are more optimal than P3 and P4. The percent choice of the different options is one of the primary dependent variables. A score variable is also calculated, as for the IGT, to determine the overall level of risky choice as follows: [(P1 + P2) – (P3 + P4)]. Figure is modified from Winstanley &amp; Floresco (2016). (B) Distinct variants of the rGT. On the uncued variant, no audiovisual cues were present. The standard task featured audiovisual cues that scaled in complexity and magnitude with reward size. The reverse-cued variant inverted this relationship, such that the simplest cue was paired with the largest reward, and vice versa. Audiovisual cues were paired with both wins and losses for the outcome-cued variant. For the random-cued variant, cues were played on 50% of trials, regardless of outcome. Lastly, for the loss-cued variant, cues were only paired with losing outcomes, at the onset of the time-out penalty.</p></caption>
<graphic xlink:href="507379v3_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Differences in baseline performance between task variants.</title><p>Comparative baseline performance on variants of the rGT. (A) Percent choice of each option in the six rGT task variants. (B) Average risk score shows risk preference is significantly modulated by the presence and contingency of outcome-paired cues, with preference for the high-risk options (P3 and P4) strongly enhanced in task variants in which the audiovisual cues scale with outcome magnitude and occur on winning trials. (C) Premature responding across the rGT variants, and (D) for risky versus optimal decision-makers. (E) Latency for reward collection on winning trials across the variants of the rGT. Data are expressed as mean + SEM.</p></caption>
<graphic xlink:href="507379v3_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><title>P1-P4 choice comparisons</title>
<p>Comparisons of P1-P4 between task variants using Tukey’s honest significant differences (HSD) test. Bolded values indicate a significant difference.</p></caption>
<graphic xlink:href="507379v3_tbl1.tif" mime-subtype="tiff" mimetype="image"/>
<graphic xlink:href="507379v3_tbl1a.tif" mime-subtype="tiff" mimetype="image"/>
<graphic xlink:href="507379v3_tbl1b.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<p>As is typical for analysis of data from this task and the IGT, an overall risk score was calculated by subtracting the percent choice of the low-risk/low-reward options from the percent choice of the risky high-reward options ([P1 + P2] – [P3 + P4]). Animals with a risk score above zero were designated as “optimal”, whereas rats with negative risk scores were classified as “risk-preferring”. Average risk score at the end of training differed significantly between tasks (<italic>F</italic>(5, 170) = 6.62, <italic>p</italic> &lt; .0001, <xref rid="fig2" ref-type="fig">Figure 2B</xref> and <xref rid="tbl2" ref-type="table">Table 2</xref>). In general, average risk score on tasks featuring win-paired cues was lower than on the uncued task, corresponding to a greater proportion of individual rats with a low or negative risk score, while the random-cued task did not differ significantly from the uncued task. Interestingly, rats trained on the loss-cued task exhibited the greatest preference for the optimal options (highest risk score) among all tasks. Task differences in choice preference may have been driven by increased prevalence of risk-preferring rats on the standard-cued and outcome-cued variants of the rGT, as a significant choice x task x risk status interaction was also observed (F(11,415) = 2.76, <italic>p</italic> = .002), and only risk-preferring rats exhibited task differences (risk-preferring: F(12,96) = 1.83, <italic>p</italic> = .05; optimal: F(10,248) = 1.12, <italic>p</italic> = .35). However, only one <italic>post-hoc</italic> comparison reached marginal significance among risky rats, likely due to the relatively low number of risk-preferring rats for some task variants.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2:</label>
<caption><title>Risk score comparisons</title><p>Comparisons of risk score between task variants using Tukey’s HSD test. Bolded values indicate a significant difference.</p></caption>
<graphic xlink:href="507379v3_tbl2.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
</sec>
<sec id="s1b">
<title>Premature responding</title>
<p>We next tested whether rats trained on each task variant differed in their level of motor impulsivity. This was measured by the proportion of premature responses made during the 5-second intertrial interval relative to the total number of trials. A significant difference was observed between tasks that was not dependent on risk status (F(5,164) = 5.48, <italic>p</italic> = .0001; <xref rid="fig2" ref-type="fig">Figure 2C</xref>). Post-hoc multiple comparisons showed that rats trained on the loss-cued task had the lowest rate of premature responding compared to all other tasks (<xref rid="tbl3" ref-type="table">Table 3</xref>). Rats trained on the reverse-cued and random-cued task variants also exhibited a lower level of premature responding compared to the uncued, standard-cued, and outcome-cued rats. Across all task groups, risk-preferring rats had a significantly higher proportion of premature responses that optimal rats (<italic>F</italic>(1,164) = 23.41, <italic>p</italic> &lt; .0001; <xref rid="fig2" ref-type="fig">Figure 2D</xref>).</p>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3:</label>
<caption><title>Premature responding comparisons</title><p>Comparisons of premature responding between task variants using Tukey’s HSD test. Bolded values indicate a significant difference.</p></caption>
<graphic xlink:href="507379v3_tbl3.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
</sec>
<sec id="s1c">
<title>Other variables</title>
<p>Rats differed in their latency to collect reward across the task variants (<italic>F</italic>(5,151) = 2.47, <italic>p</italic> = .04; <xref rid="fig2" ref-type="fig">Figure 2D</xref>). Results from the <italic>post-hoc</italic> multiple comparisons are displayed in <xref rid="tbl4" ref-type="table">Table 4</xref>, showing that rats trained on the random-cued task were significantly slower to collect reward than all other rats.</p>
<table-wrap id="tbl4" orientation="portrait" position="float">
<label>Table 4:</label>
<caption><title>Collect latency comparisons</title><p>Comparisons of collect latency between task variants using Tukey’s HSD test. Bolded values indicate a significant difference.</p></caption>
<graphic xlink:href="507379v3_tbl4.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<p>No differences between task variants were observed in latency to choose an option, trials completed, or omissions. Across all tasks, risk-preferring rats completed significantly fewer trials that optimal rats (<italic>F</italic>(1,151) = 99.28, <italic>p</italic> &lt; .0001), as expected given that they experienced a higher number of lengthy time-out penalties.</p>
</sec>
<sec id="s1d">
<title>Win-paired cues induce insensitivity to reinforcer devaluation</title>
<sec id="s1d1">
<title>Choice</title>
<p>To determine which task variants resulted in inflexible choice patterns, rats were subjected to a reinforcer devaluation test in which they received <italic>ad libitum</italic> access to sucrose pellets for 1 hour prior to task performance. Data from the devaluation test were then compared to a separate baseline session during which no experimental manipulation occurred. A significant devaluation x choice x task effect was observed that was dependent on risk status (devaluation x choice x task x risk status: <italic>F</italic>(15, 314) = .44, <italic>p</italic> = .002). This effect was marginally significant in risk-preferring rats (F(15,66) = 1.79, <italic>p</italic> = .06). Effects broken down by task for risk-preferring animals can be found in <xref rid="tbl5" ref-type="table">Table 5</xref>; risk-preferring rats on the uncued, random-cued, and loss-cued tasks were grouped together due to low <italic>n</italic> (1-3 per task). Among the risky rats, only those trained on tasks without win-paired cues exhibited changes in choice patterns following reinforcer devaluation. In <xref rid="fig3" ref-type="fig">Figure 3A</xref>, choice of the P1-P4 options in risk-preferring rats are depicted as a difference in % choice between baseline and devaluation sessions (baseline subtracted from devaluation) for each task variant. This was done to highlight shifts in choice separate from overall group differences in the selection of the different options.</p>
<table-wrap id="tbl5" orientation="portrait" position="float">
<label>Table 5:</label>
<caption><title>Devaluation in risk-preferring rats: P1-P4 choice</title><p>choice x devaluation interactions for each task in risk-preferring rats. Bolded values indicate a significant difference.</p></caption>
<graphic xlink:href="507379v3_tbl5.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3:</label>
<caption><title>Effects of sucrose pellet devaluation on choice preference.</title><p>(A) P1-P4 choice preference after reinforcer devaluation compared to baseline preference for risk-preferring rats. Devaluation did not shift choice patterns selectively in task variants featuring consistent win-paired cues (standard, outcome-cued, reverse-cued). (B) P1-P4 choice preference after reinforcer devaluation compared to baseline preference in optimal rats. Reinforcer devaluation induced a slight shift in choice preference, with no differences found between tasks. Data are expressed as the mean change in % choice from baseline + SEM to highlight effects independent of differences in preference for each option between cohorts.</p></caption>
<graphic xlink:href="507379v3_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>While the effects of devaluation did not differ by task in optimal rats (<italic>F</italic>(13,226) = 0.95, <italic>p</italic> = .50), a marginally significant choice x devaluation effect was observed in these rats (<italic>F</italic>(3,255) = 2.62, <italic>p</italic> = .06; see <xref rid="fig3" ref-type="fig">Figure 3B</xref>), indicating that some degree of shifting occurred in optimal rats that was not influenced by the presence or absence of cues.</p>
<p>The observed shifts in P1-P4 choice resulted in a significant task-dependent shift in risk score in risk-preferring rats (devaluation x task: <italic>F</italic>(5,22) = 3.90, <italic>p</italic> = .01) but not optimal rats (<italic>F</italic>(5,85) = 1.53, <italic>p</italic> = .19). Results are summarized by task in <xref rid="tbl6" ref-type="table">Table 6</xref>. Similar to the choice results, only rats trained on tasks without win-paired cues exhibited shifts in risk preference following reinforcer devaluation.</p>
<table-wrap id="tbl6" orientation="portrait" position="float">
<label>Table 6:</label>
<caption><title>Devaluation in risk-preferring rats: Risk score</title><p>risk score x devaluation interactions for each task in risk-preferring rats. Bolded values indicate a significant difference.</p></caption>
<graphic xlink:href="507379v3_tbl6.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<sec id="s1d1a">
<title>Other variables</title>
<p>Latency to collect reward did not shift in response to devaluation (<italic>F</italic>(1,107) = .55, <italic>p</italic> = .46). Latency to choose an option significantly increased across all tasks (<italic>F</italic>(1,107) = 71.38, <italic>p</italic> &lt; .0001), as did omissions (<italic>F</italic>(1,107) = 9.75, <italic>p</italic> = .002). Trials decreased in all rats, particularly optimal decision-makers (devaluation x risk status: <italic>F</italic>(1,107) = 6.72, <italic>p</italic> = .01; optimal: <italic>F</italic>(1,85) = 80.66, <italic>p</italic> &lt; .0001; risky: <italic>F</italic>(1,22) = 9.41, <italic>p</italic> = .006). Premature responding significantly decreased across all groups (<italic>F</italic>(1,107) = 63.32, <italic>p</italic> &lt; .0001).</p>
</sec>
</sec>
</sec>
<sec id="s1e">
<title>Nonlinear transform best describes impact of time-out penalties on choice for most rGT variants</title>
<p>These results indicate that salient audiovisual cues reliably paired with wins increase the number of individual rats that display a preference for risky options, and that this pattern of responding is insensitive to devaluation selectively in this subset of rats. Next, we asked how choice preferences on each rGT task variant related to learning dynamics during the initial sessions of each task, and how this differed between risk-preferring and optimal rats. We investigated differences in the acquisition of each task variant by fitting several reinforcement learning models to completed trials in the first 5 sessions, as described in <xref ref-type="bibr" rid="c24">Langdon et al. (2019)</xref>.</p>
<p>Each of these models assumes that choice on every trial probabilistically follows latent <italic>Q</italic>-values for each option, which are updated iteratively according to the experienced outcomes. Winning outcomes (<italic>R<sub>tr</sub></italic>) increase <italic>Q</italic>-values in a stepwise manner governed by the positive learning rate (<italic>η</italic><sup>+</sup>), according to a delta-rule update:
<disp-formula>
<graphic xlink:href="507379v3_ueqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Three different models were designed to determine how losing outcomes impacted <italic>Q</italic>-values. Each model tests a different hypothesis as to how time-out penalties (<italic>T<sub>tr</sub></italic>) are transformed into an equivalent “cost” in sucrose pellets.</p>
<table-wrap id="utbl1" orientation="portrait" position="float">
<graphic xlink:href="507379v3_utbl1.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<p>The scaled cost model assumes a linear relationship between the experienced time-out penalty durations, controlled by parameter <italic>m</italic>. The scaled + offset cost model features an additional offset parameter <italic>b</italic>, allowing for a global increase or decrease in the impact of time-out penalties. Lastly, the nonlinear cost model uses a power law to enable a nonlinear relationship between time-out duration and its relative impact on Q-values; the <italic>r</italic> parameter determines the curvature of this nonlinear transform. For all three models, a negative learning rate (<italic>η</italic><sup>−</sup>) was estimated to determine the stepwise decrease to <italic>Q</italic>-values following a time-out penalty. Choice probability was determined according to a softmax rule, where the <italic>β</italic> parameter controls how closely rats’ choices follow their latent <italic>Q</italic>-values (lower <italic>β</italic> value indicates more random choice across the four options; see Methods). Individual subject- and group-level parameters for each model were estimated by hierarchically sampling their posterior distributions for each of the RL models using Hamiltonian MCMC as implemented in Stan (<xref ref-type="bibr" rid="c6">Carpenter et al., 2017</xref>).</p>
<p>For each task variant, the best-fitting model was assessed using the Watanabe–Akaike information criterion (WAIC; <xref ref-type="bibr" rid="c36">Watanabe 2010</xref>). This term assesses model fit whilst also penalizing for model complexity, with lower WAIC indicating a better explanation of the data. Among the models tested, the nonlinear cost RL model best captured the pattern of choice during the learning phase for four of the six task variants (uncued, reverse, outcome, and loss), with the scaled + offset cost model performing better for the standard- and random-cued task variants (<xref rid="fig4" ref-type="fig">Figure 4</xref>). Together, this suggests that for the majority of rats, the subjective cost associated with a loss for each option was not related to time-out penalty duration in a linear manner, at least during the initial sessions of learning.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4:</label>
<caption><p>Difference in WAIC between each model and the nonlinear model for each of the rGT task variants. Lower WAIC indicates a better explanation of the data. Error bars are SEM.</p></caption>
<graphic xlink:href="507379v3_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>To confirm that the best-fitting models captured the dominant features of the behavioural data, we simulated the probability of each option on each trial for 20 sessions, using the subject-level model parameter estimates (<xref rid="fig5" ref-type="fig">Figure 5A</xref>). We then calculated the risk score for sessions 18-20 of the simulated data. While fewer significant differences were observed in the simulated data compared to the actual data (statistical tests available in <xref rid="tbls1" ref-type="table">supplemental tables 1</xref> and <xref rid="tbls2" ref-type="table">2</xref>), the overall pattern of results was largely preserved, with simulated choices on task variants featuring win-paired cues exhibiting lower risk scores than those from the uncued, random-cued, and loss-cued rGT. Consistent with the WAIC results indicating that the nonlinear model is the winning model for the majority of the rats, mean differences were larger and more statistical differences were found for the nonlinear model compared to the scaled + offset model.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5:</label>
<caption><p>Average risk score (sessions 18-20) for the nonlinear and scaled + offset models simulated with the subject-level parameter estimates for each task variant.</p></caption>
<graphic xlink:href="507379v3_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<sec id="s1e1">
<title>Outcome-paired cues differentially impact the learning rate for wins versus losses</title>
<p>Next, we asked how the model parameters that control learning differed between the rGT task cohorts in these early sessions of training. Since both the nonlinear cost and the scaled + offset cost models performed the best for some of the task variants, we compared the group-level mean posterior estimates for each parameter from both models. Differences between parameter estimates were considered credible when the 95% highest-density interval (HDI) for the sample difference between two mean estimates did not include zero.</p>
<p>Differences between task variants were found in the beta and learning rate estimates for both the nonlinear cost (<xref rid="fig6" ref-type="fig">Figure 6</xref>) and scaled + offset cost (<xref rid="fig7" ref-type="fig">Figure 7</xref>) models. Notably, pairing cues with wins reduces learning from punishments in these early sessions. All tasks featuring reward-paired cues (standard-, outcome-, reverse-cued tasks) exhibited a lower negative learning rate than the loss-cued task variant. The negative learning rate estimates for the uncued and random-cued variants fell between the estimates for the loss-cued task and the variants featuring win-paired cues. Thus, the rank order of the negative learning rate estimates exactly mirrored the pattern observed in the rats’ risk scores at the end of training. This suggests that win-paired cues reduce the impact of negative outcomes to drive risky choice. Given that across both models, the loss-cued task exhibited the highest negative learning rate, cuing losses may increase their impact on subsequent choice and thereby reduce risky choice.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Fig. 6:</label>
<caption><p>Group-level posterior estimates of nonlinear cost model parameters. Asterisks within the inset tables mark parameters for which the 95% HDI of the sample difference did not contain zero, indicating a credible difference. For each distribution, the line demarcates the means, the box demarcates the interquartile interval, and the whiskers demarcate the 95% HDI.</p></caption>
<graphic xlink:href="507379v3_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Fig. 7:</label>
<caption><p>Group-level posterior estimates of scaled + offset model parameters. Asterisks within the inset tables mark parameters for which the 95% HDI of the sample difference did not contain zero, indicating a credible difference. For each distribution, the line demarcates the means, the box demarcates the interquartile interval, and the whiskers demarcate the 95% HDI.</p></caption>
<graphic xlink:href="507379v3_fig7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Learning from wins was also affected by outcome-associated cues. Across both models, the positive learning rate estimate for the reverse-cued task was lower than the other variants featuring predictable win-paired cues; it was also lower than the loss-cued variant in the nonlinear model. These results suggest that the inverted relationship between cue complexity and reward size for the reverse-cued task may have diminished learning from wins.</p>
<p>Generally speaking, the tasks featuring win-paired cues exhibited a lower beta estimate, although a credible difference was only found when compared to the random-cued variant. This may indicate that when win-paired cues are present, choice patterns did not follow latent Q-values as closely.</p>
</sec>
<sec id="s1e2">
<title>Parameters predicting risk preference on the rGT</title>
<p>We next tested whether any of the subject-level parameter estimates in the nonlinear or scaled + offset model could reliably predict risk preference scores at the end of training. For the nonlinear model, we found that the beta parameter, negative learning rate, and global offset parameter were significant predictors of rats’ risk preferences during stable responding in the later sessions (beta: β = 0.20, 95% CI [0.03, 0.36], <italic>p</italic> = .02; negative learning rate: β = 0.21, 95% CI [0.05, 0.37], <italic>p</italic> = .01; offset: β = -0.17, 95% CI [-0.32, -0.02], <italic>p</italic> = .03). For the scaled + offset model, the beta parameter and negative learning rate were significant predictors of rats’ final risk preference (beta: β = 0.20, 95% CI [0.04, 0.36], <italic>p</italic> = .01; negative learning rate: β = 0.24, 95% CI [0.08, 0.39], <italic>p</italic> = .01). These predictive relationships indicate that risky choice was associated with a lower negative learning rate and a higher global offset of time-out penalty costs, providing further evidence that diminished impact of time-out penalties early in learning can lead to the development of a risky choice profile. Additionally, risk preference was associated with a lower beta estimate, indicating that risky rats’ choices did not follow the latent Q-values as closely compared to the optimal rats.</p>
</sec>
</sec>
</sec>
<sec id="s2">
<title>Discussion</title>
<p>Here, we showed that audiovisual cues drive risky choice on the rat gambling task (rGT) only if they are reliably, but not exclusively, win-paired. This was demonstrated by higher levels of risky choice in rats trained on the standard-cued, reverse-cued, and outcome-cued variants of the rGT. Computational analysis of the acquisition phase using reinforcement learning models revealed that differences in decision making were largely captured by parameters that control learning from punishments. These parameters predicted risk score at the end of training, indicating that risk-preferring rats discounted losses to a greater degree than optimal rats. There was also evidence that tasks featuring win-paired cues, and risky choice in general, was associated with lower beta estimates; this may be due to inconsistency in choice patterns early in training, perhaps resulting from reduced sensitivity to outcomes.</p>
<p>These results largely confirm and build upon the previous report investigating learning dynamics of the cued versus uncued rGT (<xref ref-type="bibr" rid="c24">Langdon et al., 2019</xref>). In order to maximize comparison of multiple cue-outcome schedules, we were unable to also include animals of both sexes, which we acknowledge is a significant limitation that must be addressed in future work. We previously observed that the addition of reward-paired cues to the task resulted in insensitivity to punishments, particularly on the risky options, and that time-out penalty weights could predict risk score at the end of training. The current studies extend these results to suggest that this relationship can be bidirectionally modulated, as loss-paired cues reduce risky choice and increase learning from losing outcomes. Furthermore, pairing cues with wins seems to dominate the decision-making process. Cuing the losses when the wins are also cued has no risk-reducing effect, and in fact may even further potentiate risky choice.</p>
<p>Results from the reinforcer devaluation test provide additional support for differences in decision-making processes when win-paired cues are present, in that risk-preferring rats trained on these tasks were not sensitive to changes in reinforcer value. This indicates that such cues can render choice patterns inflexible. However, no differences were found between tasks for optimal rats, and they were overall less sensitive to changes in reinforcer value. Optimal rats may therefore be indifferent to fluctuations in reward value such as occasional reward omission on the low-risk options, or in this case, reinforcer devaluation. Additionally, if we assume that frequency of winning becomes more desirable than reward size, optimal rats can only move to P1 to maximize win frequency, whereas risk-preferring rats have more options to which they may shift. Nevertheless, the fact that risk-preferring rats trained on these tasks did not shift suggests that win-paired cues, particularly when they track reward size, inhibit flexible responding in the face of devaluation of those rewards.</p>
    <p>While differences in reinforcer devaluation tests in risky versus optimal rats have not been previously observed on the rGT, the cohort sizes of the present study far exceed previous reports, which may have been underpowered to detect such differences. The results from risk-preferring rats corroborate previous studies demonstrating that rats trained on the uncued task are sensitive to this manipulation, whereas rats trained on the cued task are not (<xref ref-type="bibr" rid="c39">Zeeb &amp; Winstanley, 2013</xref>; <xref ref-type="bibr" rid="c17">Hathaway et al., 2021</xref>). This could be due to either enhanced habit formation or hypoactive, or otherwise maladaptive, goal-directed control. Altering serotonergic signaling in the lateral orbitofrontal cortex (OFC) can restore sensitivity to reinforcer devaluation in rats trained on the cued rGT, indicating that prefrontal cortices, and presumably impaired goal-directed control, play a role in inflexibility induced by reward-paired cues (<xref ref-type="bibr" rid="c17">Hathaway et al., 2021</xref>). Indeed, given the role of the lateral OFC in updating stored action-outcome contingencies, cue-guided learning, and in the acquisition of the uncued rGT (<xref ref-type="bibr" rid="c19">Izquierdo, 2017</xref>; <xref ref-type="bibr" rid="c3">Amodeo et al., 2017</xref>, <xref ref-type="bibr" rid="c38">Zeeb &amp; Winstanley, 2011</xref>), this region could be mediating both the differential processing of rewards and punishments across different variants of the rGT and cue-induced inflexibility. Alternatively, the task bracketing hypothesis from <xref ref-type="bibr" rid="c35">Vandaele et al. (2017)</xref> posits that the inclusion of salient cues in decision-making tasks (lever insertion, in their case) encourages the formation of rigid stimulus-response patterns, rather than generally reducing cognitive flexibility. Future studies could test other facets of cognitive flexibility both during and outside of the rGT (e.g., extinction training on the rGT, or probabilistic reversal learning after rGT training) to further explore these lines of thought.</p>
    <p>In addition to inducing inflexibility, win-paired cues on the outcome-cued and standard-cued tasks impacted choice patterns in a relatively comparable manner. These results run counter to the “state” hypothesis described in the introduction, in which we suggested that increasing the similarity of winning and losing trials may permit better integration of the time-out penalties into the learned values of each option. We instead observed that outcome-cued rats were equally as risky as those trained on the standard-cued paradigm. Cuing losses in this paradigm did not increase learning about those trial types; instead, it may have disguised them as wins. Losses disguised as wins (LDWs) are a feature of modern multi-line slot machines in which win-related cues are played when a small payout that is less than the bid is won, leading the player to believe they’ve won money when in fact they have experienced a net loss. These LDWs can therefore be miscategorized as wins (<xref ref-type="bibr" rid="c10">Dixon et al., 2010</xref>; <xref ref-type="bibr" rid="c21">Jensen et al., 2013</xref>). <xref ref-type="bibr" rid="c28">Marshall and Kirkpatrick (2017)</xref> applied a reinforcement learning model to behavioural data from their task investigating the LDW effect in rodents and showed that playing win-related sensory feedback during losses elevated stay biases on the high-risk option by increasing its value. A similar mechanism may be at play in the outcome-cued task. Conversely, cuing only losses may oppose the LDW effect, as others have shown that playing loss-associated cues during LDWs can permit subjects to correctly categorize them as losses (<xref ref-type="bibr" rid="c9">Dixon et al., 2015</xref>). It is interesting to note that rats on the outcome-cued task, together with the standard-cued task, had the lowest beta parameter estimate. This may suggest the model did not capture the development of their choice patterns to the same degree as the other tasks. It could be that adding a stay-bias parameter similar to the model by <xref ref-type="bibr" rid="c28">Marshall and Kirkpatrick (2017)</xref> would better encapsulate the learning dynamics for rats on this task. In general, greater risky choice was predicted by lower beta parameter values across multiple models and task variants. Whether this indicates that risky choice results in part from weaker adherence to internal representations of option values during decision making, or instead suggests we are failing to account for an important computational process in our models remains to be thoroughly investigated.</p>
<p>An alternate hypothesis for the impact of win-paired cues on decision making comes from research investigating the role of dopamine in the perception of time. The timing of dopamine signals can influence whether subjective time speeds up or slows down (<xref ref-type="bibr" rid="c33">Soares et al., 2016</xref>; <xref ref-type="bibr" rid="c20">Jakob et al., 2021</xref>). Hence, it could be that cued rewards alter the subjective experience of the time-out penalty duration via a dopaminergic mechanism. Indeed, the standard-cued task is more sensitive to dopamine manipulations than the uncued task (<xref ref-type="bibr" rid="c4">Barrus &amp; Winstanley, 2016</xref>). Dopamine signals provoked by win-paired cues may reduce the experienced duration of the time-out penalties such that their impact on the latent value of each option is diminished. Measurements of dopamine signals on-task using fiber photometry could be incorporated into a model to test this hypothesis (see <xref ref-type="bibr" rid="c20">Jakob et al., 2021</xref>).</p>
<p>While pairing cues with wins is sufficient to drive risky choice, cue complexity and magnitude appear to also play a role, as rats on the reverse-cued task were significantly less risky than the outcome-cued rats, and marginally different from the standard-cued rats. Additionally, parameter estimates for rats trained on the reverse-cued task did not completely align with the other tasks featuring win-paired cues (e.g., lower learning rate for rewarded trials). These rats also exhibited a lower rate of premature responding compared to all other tasks except for the loss-cued task. This may indicate that matching cue size and complexity to reward size can potentiate motor impulsivity. Indeed, when the salience of reward-predictive cues matches the size of the reward, activity in the nucleus accumbens is amplified in humans (<xref ref-type="bibr" rid="c22">Knutson et al., 2001</xref>), which may be diminished when cue size inversely scales with reward. As activity within the nucleus accumbens is critically involved in motor impulsivity on similar behavioural tasks (<xref ref-type="bibr" rid="c12">Economidou et al., 2012</xref>; <xref ref-type="bibr" rid="c31">Pattij et al., 2007</xref>), reduction of this signal could explain the low rate of premature responding in these rats.</p>
<p>Consistently pairing cues with wins proved to be a necessary component to induce risky choice, as playing cues randomly on 50% of trials regardless of outcome did not significantly shift risk preference compared to the uncued variant. We originally thought that the increased sensory stimulation from the random cues could increase arousal and therefore risk preference. However, rats instead learned to disregard these cues and were perhaps less engaged in the task, as indicated by the longer latencies to collect reward and reduced levels of premature responding. That being said, this finding does not disprove the hypothesis that increased arousal leads to riskier choice patterns; it may be that the cue-reward relationship increases arousal in a way that random cues cannot. Recent results implicating norepinephrine in cue-induced risky choice would suggest that arousal may contribute to the impact of cues on decision making (<xref ref-type="bibr" rid="c8">Chernoff et al., 2021</xref>). It would be interesting to pretrain rats on the association between the cues and reward prior to rGT training on the random-cued task; in that case, increased risk preference may be observed. This may represent an intriguing model of the effect of ambient lights and sounds of a casino on gambling behaviour.</p>
<p>Pairing cues with losses would also ostensibly increase arousal, however their behavioural impact was quite distinct from that of win-paired cues. Indeed, rats trained on the loss-cued task were the least risk-preferring out of all the groups, including the uncued task. This would suggest that, while the uncued task is usually regarded as a control for the cued task(s), it may also be a deviation from how optimal rats can be. Indeed, <xref ref-type="bibr" rid="c24">Langdon et al. (2019)</xref> found that all rats across both the uncued and standard-cued task were globally less sensitive to the time-out penalties, and that differences in risk preference arose from the degree of this reduced sensitivity. Conversely, rats on the loss-cued task appear to be more sensitive to losses. Thus, they could be more proactively risk-avoiding, and rats on the uncued task may be more willing to sample from the risky options despite having an overall optimal decision-making profile.</p>
<p>In sum, the results from these studies indicate that outcome-associated cues play a significant role in decision-making processes, and their effect is highly dependent on the outcome type with which they are associated. Differences in choice patterns are largely a result of changes to the relative impact of losses on decision making, as revealed by the effect of different cue paradigms on group-level parameter estimates capturing learning from losses in the tested reinforcement learning models. These analyses demonstrate the power of combining modeling approaches with careful behavioural manipulations to inform our understanding of action selection in complex decision-making scenarios. Furthermore, the findings provide critical insight into the influence of the rich sensory environment in casinos and other forms of gambling, particularly the addictive allure of electronic gaming machines.</p>
</sec>
<sec id="s3">
<title>Methods</title>
<sec id="s3a">
<title>Subjects</title>
<p>Subjects were four cohorts of 32-64 male Long Evans rats (Charles River Laboratories, St Constant, QC, Canada) weighing 275–300 g upon arrival to the facility. One to two weeks following arrival, rats were food-restricted to 14 g of rat chow per day and were maintained at least 85% body weight of an age- and sex-matched control. Water was available <italic>ad libitum</italic>. All subjects were pair-housed or trio-housed in a climate-controlled colony room under a 12 h reverse light-dark cycle (21 °C; lights off at 8am). Huts and paper towel were provided as environmental enrichment. Behavioural testing took place 5 days per week. Housing and testing conditions were in accordance with the Canadian Council of Animal Care, and experimental protocols were approved by the UBC Animal Care Committee.</p>
</sec>
<sec id="s3b">
<title>Behavioural apparatus</title>
<p>Testing took place in 32 standard five-hole operant chambers, each of which was enclosed in a ventilated, sound-attenuating chamber (Med Associates Inc, Vermont). Chambers were fitted with an array composed of five equidistantly spaced response holes. A stimulus light was located at the back of each hole, and nose-poke responses into these apertures were detected by vertical infrared beams. On the opposite wall, sucrose pellets (45 mg; Bioserv, New Jersey) were delivered to the magazine via an external pellet dispenser. The food magazine was also fitted with a tray light and infrared sensors to detect sucrose pellet collection. A house light could illuminate the chamber. The operant chambers were operated by software written in Med-PC by CAW, running on an IBM-compatible computer.</p>
</sec>
<sec id="s3c">
<title>Behavioural testing</title>
<p>Rats were first habituated to the operant chambers in two daily 30-minute sessions, during which sucrose pellets were present in the nose-poke apertures and food magazine. Rats were then trained on a variant of the five-choice serial reaction time task and the forced-choice variant of the rGT, as described in previous reports (<xref ref-type="bibr" rid="c37">Zeeb, Robbins, &amp; Winstanley, 2009</xref>; <xref ref-type="bibr" rid="c4">Barrus &amp; Winstanley, 2016</xref>).</p>
<p>A task schematic of the rGT is provided in <xref rid="fig1" ref-type="fig">Figure 1</xref>. During the 30-minute session, trials were initiated by making a nose-poke response within the illuminated food magazine. This response extinguished the light, which was followed by a five-second inter-trial interval (ITI) in which rats were required to inhibit their responses to proceed with the trial. Any response in the five-hole array during the ITI was recorded as a premature response and punished by a five-second time-out period, during which the house light was illuminated and no response could be made. Following the ITI, apertures 1, 2, 4, and 5 in the five-hole array were illuminated for 10 seconds. A lack of response after 10 seconds was recorded as an omission, at which point the food magazine was re-illuminated and rats could initiate a new trial. A nose-poke response within one of the illuminated apertures was either rewarded or punished according to that aperture’s reinforcement schedule. Probability of reward varied among options (0.9-0.4, P1-P4), as did reward size (1-4 sucrose pellets). Punishments were signalled by a light flashing at 0.5 Hz within the chosen aperture, signalling a time-out penalty which lasted for 5-40 seconds depending on the aperture selected. The task was designed such that the optimal strategy to earn the highest number of sucrose pellets during the 30-minute session would be to exclusively select the P2 option, due to the relatively high probability of reward (0.8) and short, infrequent time-out penalties (10 s, 0.2 probability). While options P3 and P4 provide higher per-trial gains of 3 or 4 sucrose pellets, the longer and more frequent time-out penalties associated with these options greatly reduces the occurrence of rewarded trials. Consistently selecting these options results in fewer sucrose pellets earned across the session and are therefore considered disadvantageous. The position of each option was counterbalanced across rats to mitigate potential side bias. Half the animals in each project were trained on version A (left to right arrangement: P1, P4, P2, P3) and the other half on version B (left to right arrangement: P4, P1, P3, P2).</p>
<sec id="s3c1">
<title>Task variants</title>
<p>Six variants of the task were used in this experiment (<italic>n</italic> = 28-32 rats per task variant). On the uncued task, winning trials were signalled by the illumination of the food magazine alone. On the standard-cued task, reward delivery occurred concurrently with 2-second compound tone/light cues. Cue complexity and variability scaled with reward size, such that the P1 cue consisted of a single tone and illuminated aperture, and the P4 cue consisted of multiple tones and flashing aperture lights presented in four different patterns across rewarded trials. The reverse-cued task featured an inversion of the cue-reward size relationship, such that the longest and most complex cue occurred on P1 winning trials, and P4 winning trials were accompanied by a single tone and illuminated aperture. On the outcome-cued task, all trial outcomes were accompanied by an audiovisual cue (i.e., during reward delivery and at the onset of the time-out penalty). The random-cued task consisted of cues that occurred on 50% of trials, regardless of outcome. Lastly, on the loss-cued task, cues occurred only on losing trials, at the onset of the time-out penalty. Cue complexity and magnitude scaled with reward size/time-out penalty length for the outcome-, random-, and loss-cued variants of the task (i.e., same pattern as the standard-cued task).</p>
</sec>
</sec>
<sec id="s3d">
<title>Reinforcer devaluation</title>
<p>128 rats (<italic>n</italic> = 12-28 per task version) underwent a reinforcer devaluation procedure. This procedure took place across two days. On the first day, half of the rats were given <italic>ad libitum</italic> access to the sucrose pellets used as a reward on the rGT for 1 hour prior to task initiation. The remaining rats completed the rGT without prior access to sucrose pellets. Following a baseline session day for which no sucrose pellets were administered prior to the task to any rats, the groups were then reversed and the other half were given 1-hour access to sucrose pellets.</p>
</sec>
<sec id="s3e">
<title>Behavioural measures and data analysis</title>
<p>All statistical analyses were completed using SPSS Statistics 27.0 software (SPSS/IBM, Chicago, IL, USA). As per previous reports, the following rGT variables were analyzed: percentage choice of each option ([number of times option chosen/total number of choices] × 100), risk score (calculated as percent choice of [(P1 + P2) − (P3 + P4)]), percentage of premature responses ([number of premature responses/total number of trials initiated] × 100), sum of omitted responses, sum of trials completed, and average latencies to choose an option and collect reward. Variables that were expressed as a percentage were subjected to an arcsine transformation to limit the effect of an artificially imposed ceiling (i.e., 100%). Animals with a mean positive baseline risk score were designated as “optimal”, whereas rats with negative risk scores were classified as “risk-preferring”.</p>
<p>For baseline analyses, mean values for each variable were calculated by averaging across four consecutive sessions that were deemed statistically stable (i.e., session and/or session x choice interaction were not significant in a repeated-measures ANOVA; following approximately 35-40 training sessions). Task (six levels: uncued, standard-cued, reverse-cued, outcome-cued, random-cued, loss-cued) and risk status (two levels: optimal, risk-preferring) were included as between-subjects factors for all baseline analyses. Choice data were analyzed with a two-way repeated measures ANOVA with choice (four levels: P1, P2, P3, and P4) as within-subject factors. For the analysis of the reinforcer devaluation data, devaluation (two levels: baseline, devaluation) and choice (four levels: P1-P4) were the within-subject factors and task version and risk status were the between-subjects factors.</p>
<p>For all analyses, if sphericity was violated as determined by Mauchley’s test, a Huynh–Feldt correction was applied, and corrected <italic>p</italic> values’ degrees of freedom were rounded to the nearest integer. Results were deemed to be significant if <italic>p</italic> values were less than or equal to an α of .05. Any main effects or interactions of significance were further analyzed via <italic>post hoc</italic> one-way ANOVA or Tukey’s tests. Any <italic>p</italic>-values &gt; .05 but &lt; .09 were reported as a statistical trend.</p>
</sec>
<sec id="s3f">
<title>Hierarchical modeling of learning from wins and losses</title>
<p>A full description of the modeling approach can be found in <xref ref-type="bibr" rid="c24">Langdon et al. (2019)</xref>. Valid choice trials from the first 5 sessions were concatenated into one long session and trial-by-trial preferences were modeled using variations on the Q-learning algorithm from reinforcement learning (RL; Sutton &amp; Barto, 1998). Each model was fit separately to each task variant group, thus allowing for the possibility that different RL models might perform better at predicting choice for each of the groups. Data from 11 rats were excluded due to missing sessions or technical issues. This left a total of 24 rats in the uncued task group, 32 rats in the standard-cued task group, 25 rats in the outcome-cued task group, and 28 rats in the reverse-, random-, and loss-cued task groups.</p>
<p>Each of these models assumes that choice on every trial probabilistically follows latent <italic>Q</italic>-values for each option, and these are updated iteratively according to the experienced outcomes. For our models, the probability of choosing option <italic>P<sub>x</sub></italic> on each trial follows the learned <italic>Q</italic>-values for <italic>x</italic> = [1,2,3,4] according to the softmax decision rule:
<disp-formula>
<graphic xlink:href="507379v3_ueqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>p(P<sub>x</sub>)</italic> is the probability of choosing option <italic>P<sub>x</sub></italic>, <italic>Q<sub>x</sub></italic> is the learned latent value of option <italic>x</italic>, and <italic>β</italic> is the inverse temperature parameter that controls how strongly choice follows the latent <italic>Q</italic>-values rather than a random (uniform) distribution over the four options. In each learning model, we assume learning of latent <italic>Q</italic>-values from positive outcomes follows a simple delta-rule update:
<disp-formula>
<graphic xlink:href="507379v3_ueqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>η+</italic> is a learning rate parameter that governs the step-size of the update, <italic>R<sub>tr</sub></italic> &gt; 0 is the number of pellets delivered on a given winning trial, and <italic>Q<sub>x</sub></italic> is the latent value for the chosen option <italic>x</italic> on a given trial.</p>
<p><italic>Q-</italic>values for learning from punishments were updated differently depending on the model. In each case, we sought to model the negative impact of time-out penalties on choice by transforming the duration of the penalty into an equivalent “cost” in sucrose pellets. Each model tests a different hypothesis on the transform of the punishments, with a separate negative learning rate <italic>η</italic>–. These are summarized in <xref rid="tbl1" ref-type="table">Table 1</xref>.</p>
<table-wrap id="utbl2" orientation="portrait" position="float">
<graphic xlink:href="507379v3_utbl2.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<p>In the scaled punishment model, we assume that the equivalent punishment for a time-out penalty on each losing trial scales linearly with the duration of the punishment. <italic>T<sub>tr</sub></italic>&gt;0 is the time-out penalty duration in seconds on a given losing trial and <italic>m</italic> is a scaling parameter that maps time-out duration into an equivalent cost in pellets (i.e., has units pellets/s). The scaled + offset model is the same as the scaled punishment model but features an additional offset parameter <italic>b</italic>, which removes the constraint that the linear transform between time-out penalty duration and equivalent cost is zero for zero duration.</p>
<p>An independent cost model, as originally described in <xref ref-type="bibr" rid="c24">Langdon et al. (2019)</xref>, was initially used to model a nonlinear relationship between penalty duration and equivalent cost. In this model, equivalent costs for each option are controlled independently by <italic>ω<sub>x</sub></italic> for each option <italic>P<sub>x</sub></italic>. The qualitative effects were still present in these model fits. However, due to the higher degree of model complexity and smaller datasets featured here (24-32 rats) versus datasets in <xref ref-type="bibr" rid="c24">Langdon et al. (2019</xref>; &gt;100 rats), independent parameters were not well isolated. Thus, we developed a more constrained nonlinear model, which uses a power function to allow a nonlinear mapping between experienced duration and the equivalent cost in pellets on each trial. The curvature of this relationship is determined by a single parameter <italic>r</italic>. This function has been previously used to describe expected utility during risky choice (<xref ref-type="bibr" rid="c18">Holt &amp; Laury, 2002</xref>; <xref ref-type="bibr" rid="c27">Lopez-Guzman et al., 2018</xref>).</p>
<p>For every model, <italic>Q</italic>-values were initialized at zero for the first session, and we assumed <italic>Q</italic>-values at the start of a subsequent session (on the next day for example) were the same as at the end of the previous session (i.e., we modeled no intersession effects on learning). Each model was fit to the entire set of choices for each group of rats using Hamiltonian Monte Carlo sampling with Stan to perform full Bayesian inference and return the posterior distribution of the model parameters conditional on the data and specification of the model (<xref ref-type="bibr" rid="c6">Carpenter et al., 2017</xref>). In each case, we partially pooled choice data across individual rats in a hierarchical model to simultaneously determine the distribution of individual- and group-level model parameters. We implemented a noncentered parameterization for group-level β, η+, and η− in each model, as this has been shown to improve performance and reduce autocorrelation between these group-level parameters in hierarchical RL models (<xref ref-type="bibr" rid="c1">Ahn et al, 2017</xref>).</p>
<p>Each model was fit using four chains with 1000 steps each (after an initial 1000 burn-in), yielding a total of 4000 posterior samples. To assess the convergence of the chains, we computed the <italic>R̂</italic> statistic (<xref ref-type="bibr" rid="c13">Gelman et al. 2013</xref>), which measures the degree of variation between chains relative to the variation within chains. If the <italic>R̂</italic> statistic exceeded 1.01, the number of warmup iterations were increased to a maximum of 5000. Using this approach, across all three models, no group-level or subject-level parameter had <italic>R̂</italic> &gt; 1.01, and the mode was 1.00, indicating that for each model all chains had converged successfully.</p>
<p>To measure the difference between group-level parameters, we used highest density intervals (HDI; <xref ref-type="bibr" rid="c23">Kruschke, 2014</xref>). The HDI is the interval which contains the required mass such that all points within the interval have a higher probability density than points outside the interval. Differences were considered credible when the 95% HDI for the sample difference between two mean estimates did not include zero. To compare the overall performance of each model, we computed the Watanabe–Akaike information criterion (WAIC; <xref ref-type="bibr" rid="c36">Watanabe, 2010</xref>), which, like AIC or BIC, provides a metric to compare different models fit to the same dataset. The WAIC is computed from the pointwise log-likelihood of the full posterior distribution (thereby assessing model fit) with a second term penalizing for model complexity.</p>
</sec>
</sec>
</body>
<back>
<sec id="s4">
<title>Supplemental tables and figures</title>
<table-wrap id="tbls1" orientation="portrait" position="float">
<label>Table S1:</label>
<caption><title>Nonlinear model simulated risk score comparisons</title><p>Comparisons of risk scores simulated from nonlinear model subject-level parameter estimates using Tukey’s HSD test. Bolded values indicate a significant difference, italicized values indicate a trending difference.</p></caption>
<graphic xlink:href="507379v3_tbls1.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<table-wrap id="tbls2" orientation="portrait" position="float">
<label>Table S2:</label>
<caption><title>Scaled + offset model simulated risk score comparisons</title><p>Comparisons of risk scores simulated from scaled + offset model subject-level parameter estimates using Tukey’s HSD test. Bolded values indicate a significant difference.</p></caption>
<graphic xlink:href="507379v3_tbls2.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<fig id="figs1" position="float" orientation="portrait" fig-type="figure">
<label>Fig. S1:</label>
<caption><p>Group-level posterior estimates of basic model parameters. Asterisks within the inset tables mark parameters for which the 95% HDI of the sample difference did not contain zero, indicating a credible difference. For each distribution, the box demarcates the interquartile interval and the whiskers demarcate the 95% HDI.</p></caption>
<graphic xlink:href="507379v3_figs1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<ack>
<title>Acknowledgements</title>
<p>This work was supported by a Discovery Grant awarded to CAW from the Natural Sciences and Engineering Council of Canada (NSERC; RGPIN-2017-05006) and a project grant (PJT-162312) awarded to CAW from the Canadian Institutes for Health Research (CIHR). BAH was supported by a CIHR Doctoral Award, and DRK was supported by an Undergraduate Summer Research Award from NSERC. AJL and BAH were supported by the Intramural Research Program at the National Institute of Mental Health (ZIA-MH002983). The experimental work took place at a UBC campus situated on the traditional, ancestral, and unceded land of the xʷməθkʷəy̓əm (Musqueam), sə̓lílwətaʔɬ/Selilwitulh (Tsleil-Waututh) and Sḵwx̱wú7mesh (Squamish) Peoples. We acknowledge and are grateful for their stewardship of this land for thousands of years.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ahn</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Haines</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Zhang</surname>, <given-names>L</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Revealing neurocomputational mechanisms of reinforcement learning and decision-making with the hBayesDM package</article-title>. <source>Computational Psychiatry</source>, <volume>1</volume>, <fpage>24</fpage>–<lpage>57</lpage>. doi:<pub-id pub-id-type="doi">10.1162/CPSY_a_00002</pub-id></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Alter</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2017</year>). <source>Irresistible: The rise of addictive technology and the business of keeping us hooked</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Penguin Press</publisher-name>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Amodeo</surname>, <given-names>L. R.</given-names></string-name>, <string-name><surname>McMurray</surname>, <given-names>M. S.</given-names></string-name>, &amp; <string-name><surname>Roitman</surname>, <given-names>J. D</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Orbitofrontal cortex reflects changes in response–outcome contingencies during probabilistic reversal learning</article-title>. <source>Neuroscience</source>, <volume>345</volume>, <fpage>27</fpage>–<lpage>37</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroscience.2016.03.034</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barrus</surname>, <given-names>M. M.</given-names></string-name>, &amp; <string-name><surname>Winstanley</surname>, <given-names>C. A</given-names></string-name></person-group>. (<year>2016</year>). <article-title>Dopamine D3 receptors modulate the ability of win-paired cues to increase risky choice in a rat gambling task</article-title>. <source>The Journal of Neuroscience</source>, <volume>36</volume>, <fpage>785</fpage>–<lpage>794</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2225-15.2016</pub-id></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bechara</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Damasio</surname>, <given-names>A. R.</given-names></string-name>, <string-name><surname>Damasio</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Anderson</surname>, <given-names>S. W</given-names></string-name></person-group>. (<year>1994</year>). <article-title>Insensitivity to future consequences following damage to human prefrontal cortex</article-title>. <source>Cognition</source>, <volume>50</volume>, <fpage>7</fpage>–<lpage>15</lpage>. doi:<pub-id pub-id-type="doi">10.1016/0010-0277(94)90018-3</pub-id></mixed-citation></ref>
    <ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carpenter</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Gelman</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Hoffman</surname>, <given-names>M. D.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Goodrich</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Betancourt</surname>, <given-names>M.</given-names></string-name>, <etal>…</etal> <string-name><surname>Riddell</surname><given-names>A.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Stan: A probabilistic programming language</article-title>. <source>Journal of Statistical Software</source>, <volume>76</volume>, <fpage>1</fpage>–<lpage>32</lpage>. doi:<pub-id pub-id-type="doi">10.18637/jss.v076.i01</pub-id></mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cherkasova</surname>, <given-names>M. V.</given-names></string-name>, <string-name><surname>Clark</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Barton</surname>, <given-names>J. J. S.</given-names></string-name>, <string-name><surname>Schulzer</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Shafiee</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Kingstone</surname>, <given-names>A.</given-names></string-name>, <etal>…</etal> <string-name><surname>Winstanley</surname>, <given-names>C. A.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Win-concurrent sensory cues can promote riskier choice</article-title>. <source>The Journal of Neuroscience</source>, <volume>38</volume>, <fpage>10362</fpage>–<lpage>10370</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.1171-18.2018</pub-id></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chernoff</surname>, <given-names>C. S.</given-names></string-name>, <string-name><surname>Hynes</surname>, <given-names>T. J.</given-names></string-name>, &amp; <string-name><surname>Winstanley</surname>, <given-names>C. A</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Noradrenergic contributions to cue-driven risk-taking and impulsivity</article-title>. <source>Psychopharmacology</source>, <volume>238</volume>, <fpage>1765</fpage>–<lpage>1779</lpage>. doi:<pub-id pub-id-type="doi">10.1007/s00213-021-05806-x</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dixon</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Collins</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Harrigan</surname>, <given-names>K. A.</given-names></string-name>, <string-name><surname>Graydon</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Fugelsang</surname>, <given-names>J. A</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Using sound to unmask losses disguised as wins in multiline slot machines</article-title>. <source>Journal of Gambling Studies</source>, <volume>31</volume>, <fpage>183</fpage>–<lpage>196</lpage>. doi:<pub-id pub-id-type="doi">10.1007/s10899-013-9411-8</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dixon</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Harrigan</surname>, <given-names>K. A.</given-names></string-name>, <string-name><surname>Sandhu</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Collins</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Fugelsang</surname>, <given-names>J. A</given-names></string-name></person-group>. (<year>2010</year>). <article-title>Losses disguised as wins in modern multi-line video slot machines</article-title>. <source>Addiction</source>, <volume>105</volume>, <fpage>1819</fpage>–<lpage>1824</lpage>. doi:<pub-id pub-id-type="doi">10.1111/j.1360-0443.2010.03050.x</pub-id></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dixon</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Harrigan</surname>, <given-names>K. A.</given-names></string-name>, <string-name><surname>Santesso</surname>, <given-names>D. L.</given-names></string-name>, <string-name><surname>Graydon</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Fugelsang</surname>, <given-names>J. A.</given-names></string-name>, &amp; <string-name><surname>Collins</surname>, <given-names>K</given-names></string-name></person-group>. (<year>2014</year>). <article-title>The impact of sound in modern multiline video slot machine play</article-title>. <source>Journal of Gambling Studies</source>, <volume>30</volume>, <fpage>913</fpage>–<lpage>929</lpage>. doi:<pub-id pub-id-type="doi">10.1007/s10899-013-9391-8</pub-id></mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Economidou</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Theobald</surname>, <given-names>D. E. H.</given-names></string-name>, <string-name><surname>Robbins</surname>, <given-names>R. W.</given-names></string-name>, <string-name><surname>Everitt</surname>, <given-names>B. J.</given-names></string-name>, &amp; <string-name><surname>Dalley</surname>, <given-names>J. W</given-names></string-name></person-group>. (<year>2012</year>). <article-title>Norepinephrine and dopamine modulate impulsivity on the five-choice serial reaction time task through opponent actions in the shell and core sub-regions of the nucleus accumbens</article-title>. <source>Neuropsychopharmacology</source>, <volume>37</volume>, <fpage>2057</fpage>–<lpage>2066</lpage>. doi:<pub-id pub-id-type="doi">10.1038/npp.2012.53</pub-id></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Gelman</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Carlin</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Stern</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Dunson</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Vehtari</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Rubin</surname>, <given-names>D</given-names></string-name></person-group>. (<year>2013</year>). <source>Bayesian data analysis</source> . <publisher-loc>Boca Raton</publisher-loc>: <publisher-name>Chapman and Hall/CRC</publisher-name>.</mixed-citation></ref>
    <ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goudriaan</surname>, <given-names>A. E.</given-names></string-name>, <string-name><surname>Oosterlaan</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>de Beurs</surname>, <given-names>E.</given-names></string-name> <string-name><surname>van den Brink</surname><given-names>W.</given-names></string-name></person-group> (<year>2005</year>). <article-title>Decision making in pathological gambling: A comparison between pathological gamblers, alcohol dependents, persons with tourette syndrome and normal controls</article-title>. <source>Brain Research. Cognitive Brain Research</source>, <volume>23</volume>, <fpage>137</fpage>–<lpage>151</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cogbrainres.2005.01.017</pub-id></mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Griffiths</surname>, <given-names>M. D</given-names></string-name></person-group>. (<year>1993</year>). <article-title>Fruit machine gambling: The importance of structural characteristics</article-title>. <source>Journal of Gambling Studies</source>, <volume>9</volume>, <fpage>101</fpage>–<lpage>120</lpage>. doi:<pub-id pub-id-type="doi">10.1007/BF01014863</pub-id></mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Haar</surname>, <given-names>C. V</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Challenges and opportunities in animal models of gambling-like behavior</article-title>. <source>Current Opinion in Behavioral Sciences</source>, <volume>31</volume>, <fpage>42</fpage>–<lpage>47</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cobeha.2019.10.013</pub-id></mixed-citation></ref>
<ref id="c16a"><mixed-citation publication-type="thesis"><person-group person-group-type="author"><string-name><surname>Hathaway</surname>, <given-names>B. A.</given-names></string-name></person-group> (<year>2023</year>). <article-title>Cognitive and neural underpinnings of the interaction between reward-paired cues, risky choice, and cognitive flexibility</article-title> [Doctoral dissertation, <publisher-name>University of British Columbia</publisher-name>]. UBC cIRcle repository.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hathaway</surname>, <given-names>B. A.</given-names></string-name>, <string-name><surname>Schumacher</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Hrelja</surname>, <given-names>K. M.</given-names></string-name>, &amp; <string-name><surname>Winstanley</surname>, <given-names>C. A</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Serotonin 2C antagonism in the lateral orbitofrontal cortex ameliorates cue-enhanced risk preference and restores sensitivity to reinforcer devaluation in male rats</article-title>. <source>eNeuro</source>, <volume>8</volume>, <fpage>ENEURO.0341</fpage>–<lpage>21.2021</lpage>. doi:<pub-id pub-id-type="doi">10.1523/ENEURO.0341-21.2021</pub-id></mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Holt</surname>, <given-names>C. A.</given-names></string-name>, &amp; <string-name><surname>Laury</surname>, <given-names>S. K</given-names></string-name></person-group>. (<year>2002</year>). <article-title>Risk aversion and incentive effects</article-title>. <source>The American Economic Review</source>, <volume>92</volume>(<issue>5</issue>), <fpage>1644</fpage>–<lpage>1655</lpage>. doi:<pub-id pub-id-type="doi">10.1257/000282802762024700</pub-id></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Izquierdo</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Functional heterogeneity within rat orbitofrontal cortex in reward learning and decision making</article-title>. <source>The Journal of Neuroscience</source>, <volume>37</volume>, <fpage>10529</fpage>–<lpage>10540</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.1678-17.2017</pub-id></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Jakob</surname>, <given-names>A. M. V.</given-names></string-name>, <string-name><surname>Mikhael</surname>, <given-names>J. G.</given-names></string-name>, <string-name><surname>Hamilos</surname>, <given-names>A. E.</given-names></string-name>, <string-name><surname>Assad</surname>, <given-names>J. A.</given-names></string-name>, &amp; <string-name><surname>Gershman</surname>, <given-names>S. J</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Dopamine mediates the bidirectional update of interval timing</article-title>. <source>bioRxiv</source>. doi:<pub-id pub-id-type="doi">10.1101/2021.11.02.466803</pub-id></mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jensen</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Dixon</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Harrigan</surname>, <given-names>K. A.</given-names></string-name>, <string-name><surname>Sheepy</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Fugelsang</surname>, <given-names>J. A.</given-names></string-name>, &amp; <string-name><surname>Jarick</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Misinterpreting ’winning’ in multiline slot machine games</article-title>. <source>International Gambling Studies</source>, <volume>13</volume>, <fpage>112</fpage>–<lpage>126</lpage>. doi:<pub-id pub-id-type="doi">10.1080/14459795.2012.717635</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Knutson</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Adams</surname>, <given-names>C. M.</given-names></string-name>, <string-name><surname>Fong</surname>, <given-names>G. W.</given-names></string-name>, &amp; <string-name><surname>Hommer</surname>, <given-names>D</given-names></string-name></person-group>. (<year>2001</year>). <article-title>Anticipation of increasing monetary reward selectively recruits nucleus accumbens</article-title>. <source>The Journal of Neuroscience</source>, <volume>21</volume>, <fpage>159</fpage>–<lpage>RC159</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.21-16-j0002.2001</pub-id></mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Kruschke</surname>, <given-names>J</given-names></string-name></person-group>. (<year>2014</year>). <source>Doing bayesian data analysis</source>. <publisher-loc>Saint Louis</publisher-loc>: <publisher-name>Elsevier Science &amp; Technology</publisher-name>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Langdon</surname>, <given-names>A. J.</given-names></string-name>, <string-name><surname>Hathaway</surname>, <given-names>B. A.</given-names></string-name>, <string-name><surname>Zorowitz</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Harris</surname>, <given-names>C. B. W.</given-names></string-name>, &amp; <string-name><surname>Winstanley</surname>, <given-names>C. A</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Relative insensitivity to time-out punishments induced by win-paired cues in a rat gambling task</article-title>. <source>Psychopharmacology</source>, <volume>236</volume>, <fpage>2543</fpage>–<lpage>2556</lpage>. doi:<pub-id pub-id-type="doi">10.1007/s00213-019-05308-x</pub-id></mixed-citation></ref>
    <ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Limbrick-Oldfield</surname>, <given-names>E. H.</given-names></string-name>, <string-name><surname>Mick</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Cocks</surname>, <given-names>R. E.</given-names></string-name>, <string-name><surname>McGonigle</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Sharman</surname>, <given-names>S. P.</given-names></string-name>, <string-name><surname>Goldstone</surname>, <given-names>A. P.</given-names></string-name>, <etal>…</etal> <string-name><surname>Clark</surname><given-names>L.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Neural substrates of cue reactivity and craving in gambling disorder</article-title>. <source>Translational Psychiatry</source>, <volume>7</volume>, <fpage>e992</fpage>. doi:<pub-id pub-id-type="doi">10.1038/tp.2016.256</pub-id></mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Loba</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Stewart</surname>, <given-names>S. H.</given-names></string-name>, <string-name><surname>Klein</surname>, <given-names>R. M.</given-names></string-name>, &amp; <string-name><surname>Blackburn</surname>, <given-names>J. R</given-names></string-name></person-group>. (<year>2001</year>). <article-title>Manipulations of the features of standard video lottery terminal (VLT) games: Effects in pathological and non-pathological gamblers</article-title>. <source>Journal of Gambling Studies</source>, <volume>17</volume>, <fpage>297</fpage>–<lpage>320</lpage>. doi:<pub-id pub-id-type="doi">10.1023/A:1013639729908</pub-id></mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lopez-Guzman</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Konova</surname>, <given-names>A. B.</given-names></string-name>, <string-name><surname>Louie</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Glimcher</surname>, <given-names>P.W</given-names></string-name></person-group>. (<year>2018</year>) <article-title>Risk preferences impose a hidden distortion on measures of choice impulsivity</article-title>. <source>PLoS ONE</source>, <volume>13</volume>, <fpage>e0191357</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0191357</pub-id></mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Marshall</surname>, <given-names>A. T.</given-names></string-name>, &amp; <string-name><surname>Kirkpatrick</surname>, <given-names>K</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Reinforcement learning models of risky choice and the promotion of risk-taking by losses disguised as wins in rats</article-title>. <source>Journal of Experimental Psychology. Animal Behavior Processes</source>, <volume>43</volume>, <fpage>262</fpage>–<lpage>279</lpage>. doi:<pub-id pub-id-type="doi">10.1037/xan0000141</pub-id></mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Murch</surname>, <given-names>W. S.</given-names></string-name>, <string-name><surname>Chu</surname>, <given-names>S. W. M.</given-names></string-name>, &amp; <string-name><surname>Clark</surname>, <given-names>L</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Measuring the slot machine zone with attentional dual tasks and respiratory sinus arrhythmia</article-title>. <source>Psychology of Addictive Behaviors</source>, <volume>31</volume>, <fpage>375</fpage>–<lpage>384</lpage>. doi:<pub-id pub-id-type="doi">10.1037/adb0000251</pub-id></mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Niv</surname>, <given-names>Y</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Learning task-state representations</article-title>. <source>Nature Neuroscience</source>, <volume>22</volume>, <fpage>1544</fpage>–<lpage>1553</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41593-019-0470-8</pub-id></mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pattij</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Janssen</surname>, <given-names>M. C. W.</given-names></string-name>, <string-name><surname>Vanderschuren</surname>, <given-names>Louk J. M. J</given-names></string-name>, <string-name><surname>Schoffelmeer</surname>, <given-names>A. N. M.</given-names></string-name>, &amp; <string-name><surname>Van Gaalen</surname>, <given-names>M. M.</given-names></string-name></person-group> (<year>2007</year>). <article-title>Involvement of dopamine D1 and D2 receptors in the nucleus accumbens core and shell in inhibitory response control</article-title>. <source>Psychopharmacology</source>, <volume>191</volume>, <fpage>587</fpage>–<lpage>598</lpage>. doi:<pub-id pub-id-type="doi">10.1007/s00213-006-0533-x</pub-id></mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pitchers</surname>, <given-names>K. K.</given-names></string-name>, <string-name><surname>Sarter</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Robinson</surname>, <given-names>T. E</given-names></string-name></person-group>. (<year>2018</year>). <article-title>The hot ’n’ cold of cue-induced drug relapse</article-title>. <source>Learning &amp; Memory (Cold Spring Harbor, N.Y.)</source>, <volume>25</volume>, <fpage>474</fpage>–<lpage>480</lpage>. doi:<pub-id pub-id-type="doi">10.1101/lm.046995.117</pub-id></mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Soares</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Atallah</surname>, <given-names>B. V.</given-names></string-name>, &amp; <string-name><surname>Paton</surname>, <given-names>J. J</given-names></string-name></person-group>. (<year>2016</year>). <article-title>Midbrain dopamine neurons control judgment of time</article-title>. <source>Science</source>, <volume>354</volume>, <fpage>1273</fpage>–<lpage>1277</lpage>. doi:<pub-id pub-id-type="doi">10.1126/science.aah5234</pub-id></mixed-citation></ref>
    <ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Spetch</surname>, <given-names>M. L.</given-names></string-name>, <string-name><surname>Madan</surname>, <given-names>C. R.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>Y. S.</given-names></string-name>, &amp; <string-name><surname>Ludvig</surname>, <given-names>E. A</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Effects of winning cues and relative payout on choice between simulated slot machines</article-title>, <source>Addiction</source>), <volume>115</volume>, <fpage>1719</fpage>–<lpage>1727</lpage>. doi:<pub-id pub-id-type="doi">10.1111/add.15010</pub-id></mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vandaele</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Pribut</surname>, <given-names>H. J.</given-names></string-name>, &amp; <string-name><surname>Janak</surname>, <given-names>P. H</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Lever insertion as a salient stimulus promoting insensitivity to outcome devaluation</article-title>. <source>Frontiers in Integrative Neuroscience</source>, <volume>11</volume>, <fpage>23</fpage>. doi:<pub-id pub-id-type="doi">10.3389/fnint.2017.00023</pub-id></mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Watanabe</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2010</year>). <article-title>Asymptotic equivalence of bayes cross validation and widely applicable information criterion in singular learning theory</article-title>. <source>Journal of Machine Learning Research</source>, <volume>11</volume>, <fpage>3571</fpage>–<lpage>3594</lpage>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zeeb</surname>, <given-names>F. D.</given-names></string-name>, <string-name><surname>Robbins</surname>, <given-names>T. W.</given-names></string-name>, &amp; <string-name><surname>Winstanley</surname>, <given-names>C. A</given-names></string-name></person-group>. (<year>2009</year>). <article-title>Serotonergic and dopaminergic modulation of gambling behavior as assessed using a novel rat gambling task</article-title>. <source>Neuropsychopharmacology (New York, N.Y.)</source>, <volume>34</volume>, <fpage>2329</fpage>–<lpage>2343</lpage>. doi:<pub-id pub-id-type="doi">10.1038/npp.2009.62</pub-id></mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zeeb</surname>, <given-names>F. D.</given-names></string-name>, &amp; <string-name><surname>Winstanley</surname>, <given-names>C. A</given-names></string-name></person-group>. (<year>2011</year>). <article-title>Lesions of the basolateral amygdala and orbitofrontal cortex differentially affect acquisition and performance of a rodent gambling task</article-title>. <source>The Journal of Neuroscience</source>, <volume>31</volume>, <fpage>2197</fpage>–<lpage>2204</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.5597-10.2011</pub-id></mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zeeb</surname>, <given-names>F. D.</given-names></string-name>, &amp; <string-name><surname>Winstanley</surname>, <given-names>C. A</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Functional disconnection of the orbitofrontal cortex and basolateral amygdala impairs acquisition of a rat gambling task and disrupts animals’ ability to alter decision-making behavior after reinforcer devaluation</article-title>. <source>The Journal of Neuroscience</source>, <volume>33</volume>, <fpage>6434</fpage>–<lpage>6443</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.3971-12.2013</pub-id></mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.105951.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Bradfield</surname>
<given-names>Laura A</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Technology Sydney</institution>
</institution-wrap>
<city>Sydney</city>
<country>Australia</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>important</bold> study provides a nuanced analysis of the impact of cues on cost/benefit decision-making deficits in male rats that could have translational relevance to many addictive disorders. The main findings are that cues paired with rewarded outcomes increase the proportion of risky outcomes, whereas risky choice is reduced when cues are paired with reward loss. The experimental data is <bold>convincing</bold>, but the computational analysis based on the optimisation of different Q-learning models is <bold>incomplete</bold>. The findings will be of interest to behavioural neuroscientists and clinicians with an interest in risk, decision making, and gambling disorders.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.105951.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Maladaptive decision-making is a trait commonly seen in gambling disorders. Salient cues can impact decision-making and drive gambling, though how cues affect decision-making isn't well understood. This manuscript describes the impact of cueing distinct outcomes of a validated rodent cost/benefit-making task based on the human Iowa Gambling Task. Comparing six task variants, the authors describe the effect of adding salient cues to wins (that scale with the size of win or the inverse), to every outcome regardless of loss or win, randomly to losses or wins, or to losses. Behavioral results reveal that cueing wins increased risky choices. By contrast, presenting the cues randomly or cueing the losses reduced risky choices. Risk-preferring animals of the uncued, randomly cued, and loss-cued tasks showed sensitivity to devaluation, whereas win-paired cued rats did not, suggesting cues blunt behavioral updating. Behavioral analyses were paired with computational modeling of initial acquisition which revealed that risky decision-making was related to reduced punishment learning. These data provide unique insight into how cues may bias behavior and drive gambling-related phenotypes.</p>
<p>Strengths:</p>
<p>The detailed analyses provide interesting insight into how cues impact complex decision-making. While there has been a great deal of work into the impact of cues on choice, few studies integrate multiple probabilistic outcomes. Complementing these data with computational parameters helps the reader to understand what may be driving these differences in behavior. The manuscript is well-written, clearly explaining the relevance of the results and potential future directions.</p>
<p>Weaknesses:</p>
<p>Two main questions arise from these results. The first - when do behavioral differences emerge between the task variants? Based on the results and discussion, the cues increase the salience of either the wins or the losses, biasing behavior in favor of either risky or optimal choice. If this is the case, one might expect the cues to expedite learning, particularly in the standard and loss condition. Providing an analysis of the acquisition of the tasks may provide insight into how the cues are &quot;teaching&quot; decision-making and might explain how biases are formed and cemented.</p>
<p>The second question is - does the learning period used for the modeling impact the interpretation of the behavioral results? The authors indicate that computational modeling was done on the first five sessions and used these data to predict preferences at baseline. Based on these results, punishment learning predicts choice preference. However, these animals are not naïve to the contingencies because of the forced choice training prior to the task, which may impact behavior in these early sessions. Though punishment learning may initially predict risk preference, other parameters later in training may also predict behavior at baseline. The authors also present simulated data from the models for sessions 18-20, but according to the statistical analysis section, sessions 35-40 were used for analysis (and presumably presented in Figure 1). If the simulation is carried out in sessions 35-40, do the models fit the data? Finally, though the n's are small, it would be interesting to see how the devaluation impacts computational metrics. These additional analyses may help to explain the nuanced effects of the cues in the task variants.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.105951.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The manuscript by Hathaway et al. describes a set of elegant behavioral experiments designed to understand which aspects of cue-reward contingencies drive risky choice behavior. The authors developed several clever variants of the well-established rodent gambling task (also developed by this group) to understand how audiovisual cues alter learning, choice behavior, and risk. Computational and sophisticated statistical approaches were used to provide evidence that: (1) audiovisual cues drive risky choice if they are paired with rewards and decrease risk if only paired with loss, (2) pairing cues with rewards reduces learning from punishment, and (3) differences in risk-taking seem to be present early on in training.</p>
<p>Strengths:</p>
<p>The paper is well-written, the experiments are well-designed, and the results are highly interesting, particularly for understanding how cues can motivate and invigorate normal and abnormal behavior.</p>
<p>Weaknesses:</p>
<p>Additional support and evidence are needed for the claims made by the authors. Some of the statements are inconsistent with the data and/or analyses or are only weakly supportive of the claims.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.105951.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>In this work, Hathaway and colleagues aim to understand how audiovisual cues at the time of outcome promote the selection of risky choices. A real-life illustration of this effect is used in electronic gambling machines which signal a win with flashing lights and jingles, encouraging the player to keep betting. More specifically, the authors ask whether the cue has to be paired exclusively to wins, or whether it can be paired to both outcomes, or exclusively loss outcomes, or occur randomly. To tackle this question, they employ a version of the Iowa Gambling Task adapted to rats, and test the effect of different rules of cue-outcome associations on the probability of selecting the riskier options; they then test the effect of prior reward devaluation on the task; finally, the optimised computational models on the early phases of the experiment to investigate potential mechanisms underlying the behavioural differences.</p>
<p>Strengths:</p>
<p>The experimental approach is very well thought-out, in particular, the choice of the different task variants covers a wide range of different potential hypotheses. Using this approach, they find that, although rats prefer the optimal choices, there is a shift towards selecting riskier options in the variants of the task where the cue is paired to win outcomes. They analyse this population average shift by showing that there is a concurrent increase in the number of risk-taking individuals in these tasks. They also make the novel discovery that pairing cues with loss outcomes only reduces the tendency for risky decisions.</p>
<p>The computational strategy is appropriate and in keeping with the accepted state of the art: defining a set of candidate models, optimising them, comparing them, simulating the best ones to ensure they replicate the main experimental results, then analysing parameter estimates in the different tasks to speculate about potential mechanisms.</p>
<p>Weaknesses:</p>
<p>There is a very problematic statistical stratagem that involves categorising individuals as either risky or optimal based on their choice probabilities. As a measurement or outcome, this is fine, as previously highlighted in the results, but this label is then used as a factor in different ANOVAs to analyse the very same choice probabilities, which then constitutes a circular argument (individuals categorised as risky because they make more risky choices, make more risky choices...).</p>
<p>A second experiment was done to study the effect of devaluation on risky choices in the different tasks. The results, which are not very clear to understand from Figure 3, would suggest that reward devaluation affects choices in tasks where the win-cue pairing is not present. The authors interpret this result by saying that pairing wins with cues makes the individuals insensitive to reward devaluation. Counter this, if an individual is prone to making risky choices in a given task, this points to an already distorted sense of value as the most rewarding strategy is to make optimal non-risky choices.</p>
<p>While the overall computational approach is excellent, I believe that the choice of computational models is poor. Loss trials come at a double cost, something the authors might want to elaborate more upon, firstly the lost opportunity of not having selected a winning option which is reflected in Q-learning by the fact that r=0, and secondly a waiting period which will affect the overall reward rate. The authors choose to combine these costs by attempting to convert the time penalty into &quot;reward currency&quot; using three different functions that make up the three different tested models. This is a bit of a wasted opportunity as the question when comparing models is not something like &quot;are individuals in the paired win-cue tasks more sensitive to risk? or less sensitive to time? etc&quot; but &quot;what is the best way of converting time into Q-value currency to fit the data?&quot; Instead, the authors could have contrasted other models that explicitly track time as a separate variable (see for example &quot;Impulsivity and risk-seeking as Bayesian inference under dopaminergic control&quot; (Mikhael &amp; Gershman 2021)) or give actions an extra risk bonus (as in &quot;Nicotinic receptors in the VTA promote uncertainty seeking&quot; (Naude et al 2016)). Another weakness of the computational section is the fact, that despite simulations having been made, figure 5 only shows the simulated risk scores and not the different choice probabilities which would be a much more interesting metric by which to judge model validity. In the last section, the authors ask whether the parameter estimates (obtained from optimisation on the early sessions) could be used to predict risk preference. While this is an interesting question to address, the authors give very little explanation as to how they establish any predictive relationship. A figure and more detailed explanation would have been warranted to support their claims.</p>
</body>
</sub-article>
<sub-article id="sa4" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.105951.1.sa4</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Hathaway</surname>
<given-names>Brett A</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1905-2199</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Kim</surname>
<given-names>Dexter R</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0000-7363-1522</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Malhas</surname>
<given-names>Salwa BA</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Hrelja</surname>
<given-names>Kelly M</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8563-611X</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Kerker</surname>
<given-names>Lauren</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Hynes</surname>
<given-names>Tristan J</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Harris</surname>
<given-names>Celyn</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Langdon</surname>
<given-names>Angela J</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Winstanley</surname>
<given-names>Catharine A</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>We thank the reviewers for their thoughtful comments and suggestions. We plan to make a number of revisions to the manuscript to address their feedback.</p>
<p>Firstly, we plan to incorporate feedback related to our modeling approach. We will provide justification for the chosen models and why this dataset is not appropriate for an in-depth exploration of other models. In particular, we will highlight that the models included in this manuscript were taken from Langdon et al. (2019) with a minor extension. Model development and validation in the Langdon et al. (2019) paper required a dataset with &gt;100 rats per task. As the current n per variant is 28-32, and behavioral performance on this task is highly variable, it would be difficult to sufficiently test the validity of models that majorly depart from the previously tested RL models. Nevertheless, we will acknowledge this as a limitation in the discussion section. Additionally, we will test some alternatives suggested by reviewers that fall within the scope of the current RL modeling framework (e.g., comparison to a standard delta-rule update for unrewarded choices). We will address other concerns brought up by reviewers by a.) providing a rationale for why we constrained our analyses to the first five sessions, b.) simulating data for sessions that match those that were analyzed in the real data (i.e., sessions 35-40 instead of 18-20), and c.) including a figure of the simulated choice probabilities rather than just risk score.</p>
<p>Secondly, we will include additional analyses and clarify the current statistical approach to address comments on how the data were analyzed. We will include an analysis of task acquisition to investigate when choice preferences emerge across the different variants. We will justify the statistical approach used for detecting behavioral differences between task variants, including a better explanation of the inclusion of the risky/optimal label as a between-subjects factor in the ANOVAs. We will also expand the section on parameters predicting risk preference on the rGT to fully explain the statistical method used and provide a figure of the results.</p>
<p>Lastly, we will provide a more detailed rationale for the reinforcer devaluation test, and describe the hypothesis it tests. We will also expand on how the results from the devaluation test support our conclusions, and address alternative explanations suggested by the reviewers.</p>
</body>
</sub-article>
</article>