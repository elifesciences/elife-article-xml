<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">106033</article-id>
<article-id pub-id-type="doi">10.7554/eLife.106033</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.106033.2</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.3</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories><title-group>
<article-title>Precision cutaneous stimulation in freely moving mice</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-6569-618X</contrib-id>
<name>
<surname>Parkes</surname>
<given-names>Isobel</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-5808-5172</contrib-id>
<name>
<surname>Schorscher-Petcu</surname>
<given-names>Ara</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0006-3962-5501</contrib-id>
<name>
<surname>Gan</surname>
<given-names>Qinyi</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-5693-7703</contrib-id>
<name>
<surname>Browne</surname>
<given-names>Liam E</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>liam.browne@ucl.ac.uk</email>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>Wolfson Institute for Biomedical Research, University College London</institution></institution-wrap>, <city>London</city>, <country country="GB">United Kingdom</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Griffith</surname>
<given-names>Theanne N</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/05rrcem69</institution-id><institution>University of California, Davis</institution>
</institution-wrap>
<city>Davis</city>
<country country="US">United States</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Taffe</surname>
<given-names>Michael A</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/0168r3w48</institution-id><institution>University of California, San Diego</institution>
</institution-wrap>
<city>San Diego</city>
<country country="US">United States</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-04-14">
<day>14</day>
<month>04</month>
<year>2025</year>
</pub-date>
<pub-date date-type="update" iso-8601-date="2026-02-06">
<day>06</day>
<month>02</month>
<year>2026</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP106033</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-01-22">
<day>22</day>
<month>01</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-01-15">
<day>15</day>
<month>01</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.08.06.606618"/>
</event>
<event>
<event-desc>Reviewed preprint v1</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2025-04-14">
<day>14</day>
<month>04</month>
<year>2025</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.106033.1"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.106033.1.sa3">eLife Assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.106033.1.sa2">Reviewer #1 (Public review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.106033.1.sa1">Reviewer #2 (Public review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.106033.1.sa0">Reviewer #3 (Public review):</self-uri>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Parkes et al</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Parkes et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-106033-v2.pdf"/>
<abstract>
<p>Somatosensation connects animals to their immediate environment, shaping critical behaviors essential for adaptation, learning, and survival. Probing the relationships between somatosensory inputs and behavior in mice presents substantial challenges, primarily due to the practical difficulties of delivering stimuli to the skin during movement. To address this problem, we have developed a system for precise cutaneous stimulation of mice as they walk and run through environments. The system employs real-time body part tracking and targeted optical stimuli, offering precision while preserving the naturalistic context of the behaviors studied to overcome the traditional trade-offs between precision and animal behavior. We demonstrate the system across nociceptive testing conducted in standard small chambers to behavior in large complex environments, such as mazes. We observed that cutaneous inputs evoke rapid responses, which modify behavior when stimuli are applied during motion. This system provides a means to explore the diverse and integrative nature of somatosensation, from reflexes to decision-making, in naturalistic settings.</p>
</abstract>
<funding-group>
<award-group id="par-1">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/029chgv08</institution-id>
<institution>Wellcome Trust (WT)</institution>
</institution-wrap>
</funding-source>
<award-id award-id-type="doi">10.35802/109372</award-id>
<principal-award-recipient>
<name>
<surname>Browne</surname>
<given-names>Liam E</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="par-2">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/03x94j517</institution-id>
<institution>UKRI | Medical Research Council (MRC)</institution>
</institution-wrap>
</funding-source>
<award-id>MR/N013867/1</award-id>
<principal-award-recipient>
<name>
<surname>Parkes</surname>
<given-names>Isobel</given-names>
</name>
</principal-award-recipient>
</award-group>
</funding-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Revisions in response to peer review. Clarified optical measures and end-to-end closed loop latency (~87 ms), corrected targeting error, and improved figures and terminology. Added movement state-dependent analysis, corrected max speed, and expanded basic quantification. The full reviewer responses will be in the eLife submission.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Survival and adaptation are supported by the somatosensory system, which provides signals from the body surface to drive and refine behavior. It links the skin and central nervous system, recruiting reflexes and shaping behavior through learning and fine-tuning responses. For instance, a noxious stimulus at the skin should generate appropriate responses that minimize harm and increase the odds of survival. However, probing the somatosensory system in freely moving animals presents significant challenges due to the trade-offs between precision and preserving natural behavior.</p>
<p>Current methods for cutaneous stimulation usually necessitate direct physical contact, which restricts the range of behaviors and environments that can be studied. These methods often involve restraining animals or confining them to small chambers where stimuli are applied to their body. While valuable for understanding immediate responses, such approaches fail to capture the complexity of naturalistic behaviors. There is a growing need to study freely moving mice in dynamic, naturalistic environments (<xref ref-type="bibr" rid="c1">1</xref>–<xref ref-type="bibr" rid="c5">5</xref>), moving away from restraining and restricting behavior. However, delivering precise cutaneous stimuli to mice navigating complex settings, such as mazes, remains a significant challenge.</p>
<p>Experiments can proceed in more complex environments without researchers in proximity when cutaneous stimuli such as electric shocks are delivered via a grid floor. This approach has contributed significantly to our understanding over decades, being used in learning studies to probe cells and circuits underpinning aversion, avoidance, fear, expectancy, and memory formation and retrieval. However, the underlying somatosensory processes cannot be resolved due to a lack of spatial precision and control — they indiscriminately stimulate multiple body parts in contact with the floor.</p>
<p>There have been attempts to bridge these gaps by applying localized cutaneous stimuli (e.g. von Frey filaments) to moving rodents. This has been shown to be useful in recent studies of circuits involved in pain processing (<xref ref-type="bibr" rid="c6">6</xref>, <xref ref-type="bibr" rid="c7">7</xref>). However, these approaches require experimenters to be in close proximity to the animals, to continuously observe their movements as they explore, and to manually touch a hind paw at regular intervals (<xref ref-type="bibr" rid="c8">8</xref>, <xref ref-type="bibr" rid="c9">9</xref>). This can cause observer bias and limits both precision and the complexity of the environments.</p>
<p>To address these challenges, we developed a closed-loop system to automatically deliver spatiotemporally precise cutaneous stimuli in a remote and dynamic manner, targeting mice as they freely explored environments. The system leverages advances in remote transdermal optogenetic stimulation (<xref ref-type="bibr" rid="c10">10</xref>) and real-time markerless body part (keypoint) tracking (<xref ref-type="bibr" rid="c11">11</xref>). The approach moves away from restricted and restrained behavior to enable behaviorally relevant stimulation in more naturalistic environments (<xref ref-type="bibr" rid="c3">3</xref>). This addresses the traditional trade-offs between precision and naturalistic environmental settings, providing a framework in which to integrate reflex recruitment, motivation, learning, and decision making.</p>
</sec>
<sec id="s2">
<title>Results</title>
<p>To develop closed-loop cutaneous stimulation in mice exploring large environments, we built a system that could rapidly track and target mice, and stimulate them remotely (<xref rid="fig1" ref-type="fig">Figure 1</xref>). We used real-time pose estimation to monitor body parts and target lasers for spatiotemporally precise thermal stimulation, and optogenetic stimulation of genetically-defined nociceptor fibers at the skin surface (<xref ref-type="bibr" rid="c10">10</xref>, <xref ref-type="bibr" rid="c11">11</xref>). The approach was demonstrated in large environments, allowing automated cutaneous stimulation in an arena and during goal-directed behavior as mice run through a maze.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Closed-loop cutaneous stimulation of mice freely moving in naturalistic environments.</title>
<p><bold>A</bold> Mice can be remotely targeted with cutaneous stimuli while freely exploring complex environments, such as a maze. <bold>B</bold> Schematic illustrating the closed-loop control workflow. A freely moving mouse is recorded using a camera feed, enabling real-time pose estimation to track multiple body part keypoints. The extracted frame keypoint (<italic>x, y</italic> ) of a selected body part is converted to pre-mapped <italic>x, y</italic> mirror galvanometer control signals to steer the laser beam paths and pulse the lasers. The movement of the galvanometer mirrors and triggering of the laser are determined by pre-programmed behavioral or environmental conditions, allowing stimulation to depend on behaviorally-relevant states: for example, if the mouse was performing specific actions (running, sleeping, grooming, rearing) or making choices (turning right in a maze, exploring a specific area of the environment). Flexible, state-dependent laser targeting was accomplished using an infrared laser for thermal stimulation and a blue laser for optogenetic stimulation of genetically targeted primary afferent neurons, enabling high spatiotemporal control of stimulation to small areas of skin. Panel B was created using <ext-link ext-link-type="uri" xlink:href="https://BioRender.com/fqettr4">BioRender.com</ext-link>.</p></caption>
<graphic xlink:href="606618v3_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<sec id="s2a">
<title>A system for closed-loop cutaneous stimulation</title>
<p>We designed a system that automatically tracks targets for cutaneous stimuli across a large environment, leveraging our laser-mirror galvanometer design (<xref ref-type="bibr" rid="c10">10</xref>). The environment was built on a large glass platform, allowing us to record exploring mice from below with a camera (<xref rid="fig2" ref-type="fig">Figure 2A,B</xref>). The camera enabled real-time tracking with DeepLabCut-Live! (<xref ref-type="bibr" rid="c11">11</xref>), estimating the keypoints of multiple body parts for every frame of the camera feed. The target body part keypoint <italic>x</italic> and <italic>y</italic> coordinates were converted to pre-mapped control signals for <italic>x</italic> and <italic>y</italic> galvanometer mirrors to steer lasers as required. This provides a closed-loop system for dynamic control of stimuli according to behaviorally-relevant criteria.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>A system for closed-loop cutaneous stimulation.</title>
<p><bold>A</bold> Rendering of the system shows camera and stimulation optics 1 m below the glass platform, accommodating a large circular arena (0.5 m diameter) for freely moving mice. <bold>B</bold> Side and aerial views. The blue laser beam (<italic>blue</italic>) was aligned to the galvanometer mirrors (<italic>GM</italic>) using mirrors (<italic>M1, M2</italic>), and lenses (<italic>L1, L2, L3</italic>) via ND filters. The infrared laser beam (<italic>red</italic> ) is directed through a beam shutter with mirrors (<italic>M3, M4</italic>) and lens (<italic>L4</italic>). Converged beams in <italic>purple</italic>. <bold>C</bold> Average image of the laser across a linear voltage grid (<italic>left</italic> ) and a pixel grid after mapping (<italic>left-middle</italic>). Pixel-voltage mapping corrects distortion (<italic>right-middle</italic> to <italic>right</italic> ). <bold>D</bold> A mouse on the platform. <bold>E</bold> Tracking in the arena. <bold>F</bold> Galvanometer mirrors tracking the left hind paw keypoint. <bold>G</bold> 2D histograms of paw keypoints highlight the dwell of the locomotor stance phase compared to tail base motion. <bold>H</bold> Histogram of tail base speed indicating categories from four wild type mice (16,000 frames). <bold>I</bold> Keypoint traces illustrating the out-of-phase swing-stance during locomotion. Left hind paw trace is shown in <italic>pink</italic>, while the right hind paw trace is shown in <italic>blue</italic>. The tail base speed is shown in <italic>orange</italic>. <bold>J</bold> Traces showing alternating left and right paw movement. <bold>K</bold> Accuracy of the laser targeting the hind paws across speed categories. <bold>L</bold> Error between the ground truth keypoint and laser spot in these same four mice, expressed as mean average Euclidean error (MAE). See also related <xref ref-type="fig" rid="figS2_1">figure supplements 1</xref> and <xref ref-type="fig" rid="figS2_2">2</xref>.</p></caption>
<graphic xlink:href="606618v3_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The system was optically precise. The glass platform was close to 1 m above the galvanometers, resulting in a maximum focal length variability of 3.49%, minimizing differences in the size of the laser spot in the stimulation plane. The absolute optical power and power density were uniform across the glass platform (coefficient of variation 0.035 and 0.029, respectively; <xref rid="figS2_1" ref-type="fig">Figure 2—figure supplement 1A</xref>). Laser power could be modulated using the analog control. The laser spot size was set to 2.00 ± 0.08 mm<sup>2</sup> (mean ± SD; coefficient of variation = 0.039) at the stimulation plane with a series of lenses along the blue light beam path (<xref ref-type="bibr" rid="c10">10</xref>). The laser spot could be moved along specific trajectories creating patterns (<xref rid="fig2" ref-type="fig">Figure 2C</xref>, <xref rid="figS2_1" ref-type="fig">Figure 2—figure supplement 1B</xref>). We used 10,000 <italic>x</italic> and <italic>y</italic> voltage pairs to jump the laser across the stimulation plane and map the voltages to corresponding pixels (<xref rid="fig2" ref-type="fig">Figure 2C</xref>). Surface fits resulted in a pixel-voltage mapping dictionary that minimized non-linear distortions. This resulted in a mean average Euclidean error (MAE) of 1.2 pixels (0.54 mm) between predicted and actual laser spot locations in the 500 mm arena. The system and glass platform were stable, showing a displacement equivalent to about half the width of a hind paw (MAE = 1.94 ± 2.61 mm) each week during intensive use of the system (<xref rid="figS2_1" ref-type="fig">Figure 2—figure supplement 1C</xref>), which can be corrected in less than 30 minutes by remapping.</p>
<p>The system could accurately target moving mice. Real-time estimation of keypoints (<xref rid="fig2" ref-type="fig">Figure 2D,E</xref>) was used for closedloop control of the galvanometer mirror angles, resulting in pairwise correlations of <italic>r</italic> = 0.999 between galvanometer coordinates and hind paw keypoints (<xref rid="fig2" ref-type="fig">Figure 2F</xref>). Thus, the laser could be targeted in real time to body parts when certain programmatic criteria were met (see <xref rid="figS2_2" ref-type="fig">Figure 2—figure supplement 2</xref> for the information flow). For instance, the laser beam could be triggered if the distance of an individual keypoint moves with variance ≤<italic>v</italic> for time ≥<italic>t</italic> and keypoint estimation likelihood was ≥<italic>l</italic>; where <italic>v, t</italic>, and <italic>l</italic> are user-defined variables. To determine the targeting accuracy, we used wild type mice that did not express ChR2 so that blue light pulses did not cause behavioral responses. The latency between acquiring a frame 1100 x 1100 pixels, estimating keypoints, and targeting a laser was 84 ± 12 ms (mean ± SD using 16,000 trials across 4 wild type mice; <xref rid="figS2_1" ref-type="fig">Figure 2—figure supplement 1D</xref>). This delay is sufficient to target paws: during locomotion, the hind paws were static for 350 ± 44 ms in the stance phase and moving for 100 ± 1 ms in the swing phase (<xref rid="figS2_1" ref-type="fig">Figure 2—figure supplement 1E</xref>). The positioning of paws during the stance phase of locomotion creates ‘footprints’ in keypoint space, indicating moments when the paws are momentarily static even as the mouse moves (<xref rid="fig2" ref-type="fig">Figure 2G</xref>).</p>
<p>Mice move around at variable speeds while exploring, which can be categorized (<xref rid="fig2" ref-type="fig">Figure 2H</xref>). During these movements, locomotor gait is defined by the coordinated sequence and timing of stance and swing phases across all four limbs. Each paw alternates between the stance and swing phase; thus, as the mouse moves forward, the individual paws are stationary during their respective stance phases. When the mouse was stationary (58 <italic>±</italic> 7% of the time), the hind paws were static in 99.8 <italic>±</italic> 0.1% frames, and this remains high even as the mouse increases its bodily speed: 95.7 <italic>±</italic> 0.1% frames for ‘low’ speed (28 ± 4% of the time), 79.3 ± 0.1% frames at ‘medium’ speed (8 ± 2% of the time), and 60 ± 0.3% at ‘high’ speed (6 ± 1% of the time). Therefore, even during locomotion, the hind paws are static long enough for stimulation with short-latency body part tracking (<xref rid="fig2" ref-type="fig">Figure 2I,J</xref>). The laser was successfully targeted to the hind paws with a high ‘hit accuracy’ when the mouse was moving at low speeds (95.5 ± 2.6%; <xref rid="fig2" ref-type="fig">Figure 2K</xref>). Hit accuracy refers to the percentage of trials in which the laser successfully targeted (‘hit’) the intended hind paw. As expected the hit accuracy was reduced during high-speed running. We found zero keypoint confusion across all speeds, with 657 out of 657 trials successfully targeting the correct hind paw. The optical system targeted the hind paws of wild type mice exploring an open arena 650 ± 30 times within 5 minutes at 30 frames per second (fps, <italic>n</italic> = 4 mice), providing multiple stimuli in short periods of time. We also targeted the fore paws but confusion between them resulted in 5.7 ± 2.2% targets being directed to the incorrect paw. This resulted in a low hit accuracy compared to the hind paws (<xref rid="figS2_1" ref-type="fig">Figure 2—figure supplement 1F</xref>). The laser spots were delivered with high accuracy to the targeted body parts, showing a small error of ≈1.3 mm MAE (<xref rid="fig2" ref-type="fig">Figure 2L</xref>). As laser targeting relies on real-time tracking to direct the laser to the specified body part, this metric includes any errors introduced by tracking and targeting. Thus, this design resulted in a fully automated system that facilitates spatiotemporally precise optical targeting of freely moving mice in a large environment.</p>
</sec>
<sec id="s2b">
<title>Cutaneous stimulation in large environments drives behavioral responses</title>
<p>We next used the closed-loop system to automatically deliver optogenetic cutaneous stimuli and examine the resultant behavior. A large circular arena was chosen to encourage free exploration and movement (<xref rid="fig3" ref-type="fig">Figure 3A,B</xref>) and behavior was examined by pose estimation, reconstructing the movement trajectories of body parts in the arena (<xref rid="fig3" ref-type="fig">Figure 3C</xref>). Brief transdermal optogenetic stimulation of nociceptors was used to achieve minimal cutaneous stimulation: mice expressed the blue-light sensitive opsin, ChR2, in nociceptors innervating the skin (Trpv1::ChR2; 10, 12, 13). Mice explored the arena and when stationary were stimulated on the hind paw with brief 10 ms pulses of light, delivered at intervals of at least 10 minutes (<xref rid="fig3" ref-type="fig">Figure 3B</xref>). We found the system accurately targeted the laser to the hind paw (<xref rid="fig3" ref-type="fig">Figure 3D</xref>).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Cutaneous stimulation in large environments drives behavioral responses.</title>
<p><bold>A</bold> Schematic of the open arena. <bold>B</bold> Protocol for minimal cutaneous stimulation using transdermal optogenetic activation of cutaneous nociceptors (Trpv1::ChR2, <italic>n</italic> = 10 mice). <bold>C</bold> A single frame showing a mouse exploring the open arena (<italic>left</italic> ). Keypoints for the left hind paw for 750 frames prior to and 1750 frames after the frame (1 min 23.33 s duration, <italic>middle</italic>). The body and head orientation at four time points are shown as <italic>orange</italic> rhombi connecting snout, left and right fore paw, and tail base (<italic>middle</italic>). Keypoint skeletons (<italic>right</italic> ). <bold>D</bold> Representative images of a 10 ms laser pulse spot targeting the plantar surface of the hind paw in littermate (<italic>top</italic>) and Trpv1::ChR2 (<italic>bottom</italic>) mice. <bold>E</bold> Representative keypoint traces during stimulation of the left hind paw for two mice (columns): five trials with one trial shown in bold across body parts (rows) for each mouse. <bold>F</bold> Example keypoint skeletons from Trpv1::ChR2 mice showing orienting behavior to hind paw stimulation (indicated by the <italic>blue</italic> arrow). Panel A was created using <ext-link ext-link-type="uri" xlink:href="https://BioRender.com/dkry6u2">BioRender.com</ext-link>.</p></caption>
<graphic xlink:href="606618v3_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The precise cutaneous input gave rise to motor output as coordinated behavior in freely moving mice. The brief stimuli caused paw withdrawals along with coordinated whole-body behaviors, such as rapid head orientation and body repositioning (<xref rid="fig3" ref-type="fig">Figure 3E,F</xref>). These behaviors were quantified as time-locked keypoint traces for each body part (<xref rid="fig3" ref-type="fig">Figure 3E,F</xref>). Littermate control mice that do not express ChR2 did not exhibit responses to optogenetic cutaneous stimuli, including paw withdrawals or whole-body behaviors (<italic>n</italic> = 10 mice). Therefore, the system enables fully automated and precise optical delivery of cutaneous stimuli to freely moving mice while simultaneously recording and quantifying behavior.</p>
</sec>
<sec id="s2c">
<title>Multi-animal stimulation for automatic nociceptive testing</title>
<p>The system could deliver cutaneous stimuli across a large space, evoking behavioral responses. Next, we demonstrate the flexibility of the system design and establish automatic nociceptive testing across multiple mice simultaneously. A method for random access targeting was developed (<xref rid="fig4" ref-type="fig">Figure 4A</xref>) to target nine mice (3 x 3 configuration) in individual chambers; we detected idle mice by analyzing motion energy in each chamber, then rapidly selected and cropped to one chamber for real-time pose estimation and stimulation (<xref rid="fig4" ref-type="fig">Figure 4B</xref>). This reduced the computational burden by decreasing image resolution, compared to running real-time pose estimation across the whole environment (<xref ref-type="bibr" rid="c11">11</xref>). The process operated as a loop, ensuring that automated stimuli were spaced by at least one minute apart for each mouse.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Multi-animal stimulation for automatic nociceptive testing.</title>
<p><bold>A</bold> Concept of the random access multi-animal stimulation. Motion energy was used to detect idle mice in multiple chambers, randomly selecting and cropping to one chamber for real-time pose estimation and stimulation. A laser spot was targeted to the hind paw of the mouse placed in the chamber. The process looped through each of the chambers, automatically targeting and stimulating the mice. <bold>B</bold> An example camera frame highlighting the chambers with different colors (<italic>left</italic> ). Motion energy and body part keypoints shown for an individual chamber (<italic>right</italic> ). <bold>C</bold> Representative paw responses and body repositioning following thermal stimulation (10 s pulse) and optogenetic stimulation (3 ms pulse). <bold>D</bold> Representative paw responses during thermal stimulation of wild type mice. Two traces plotted with keypoints are shown. The <italic>grey dashed</italic> line indicates laser stimulation onset. The <italic>orange dashed</italic> line indicates the motion energy response threshold used to determine paw movement. <bold>E</bold> Raster plot of motion energy during thermal stimulation trials for 18 wild-type mice (315 trials), sorted by response latency. <bold>F</bold> Representative hind paw responses during optogenetic stimulation of Trpv1::ChR2 mice. The <italic>grey dashed</italic> line indicates stimulation onset. <bold>G</bold> Cumulative distribution of paw response latencies to thermal and optogenetic stimulation. Thermal: 18 wild-type mice, 315 trials. Optogenetic: 9 Trpv1::ChR2 mice, 181 trials (range of 15 to 24 trials for individual mice). Panel A was created using <ext-link ext-link-type="uri" xlink:href="https://BioRender.com/camqr45">BioRender.com</ext-link>.</p></caption>
<graphic xlink:href="606618v3_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To test the system, we used: 1) thermal stimulation with a 10 s pulse of infrared light (785 nm) on the hind paw of wild type mice; and 2) optogenetic stimulation of cutaneous nociceptors with a 3 ms pulse of blue light (473 nm) on the hind paw of Trpv1::ChR2 mice. We varied the intensity of the optogenetic stimuli using 10 Hz pulse trains (0.5 - 8 mW/mm<sup>2</sup>) compared to a single pulse at higher intensity (40 mW/mm<sup>2</sup>).</p>
<p>Thermal and optogenetic stimulation induced similar nocifensive behaviors, including paw responses and whole-body movements (<xref rid="fig4" ref-type="fig">Figure 4C</xref>). This can be seen from traces of hind paw movement following thermal or optogenetic stimuli (<xref rid="fig4" ref-type="fig">Figure 4D-F</xref>). Consistent with previous studies, we observed the whole-body behaviors like head orienting concurrent with local withdrawal (<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c14">14</xref>). In the case of thermal stimulation, we analyzed the local motion energy of the stimulated hind paw movements to quantify the response. Following stimulation onset, mice showed a mean response latency of 4.74 <italic>±</italic> 2.48 s (mean <italic>±</italic> SD, 188 response trials; <xref rid="fig4" ref-type="fig">Figure 4E</xref>). Cumulative distributions further demonstrated nocifensive behaviors in response to infrared stimulation (<xref rid="fig4" ref-type="fig">Figure 4G</xref>) and illustrates the temporal resolution afforded by transdermal optogenetics compared to infrared stimulation. Optogenetic stimulation-induced response latencies followed the rank-order of stimulus intensity, demonstrating the dynamic range possible with this system (0.5 mW/mm<sup>2</sup>: 2.98 <italic>±</italic> 3.19 s, 1.0 mW/mm<sup>2</sup>: 2.84 <italic>±</italic> 3.19 s, 2.0 mW/mm<sup>2</sup>: 1.69 <italic>±</italic> 2.14 s, 4.0 mW/mm<sup>2</sup>: 1.72 <italic>±</italic> 2.25 s, 8.0 mW/mm<sup>2</sup>: 1.51 <italic>±</italic> 2.19 s, 40.0 mW/mm<sup>2</sup>: 0.81 <italic>±</italic> 1.65 s, mean <italic>±</italic> SD; <xref rid="fig4" ref-type="fig">Figure 4G</xref>). In contrast, littermate control mice did not exhibit responses (<xref ref-type="bibr" rid="c10">10</xref>, <xref ref-type="bibr" rid="c12">12</xref>).</p>
<p>This demonstrates the system is both versatile and precise, enabling the study of local paw withdrawals and whole-body movements including head orientation and body repositioning. The platform is large enough to accommodate 25 mice (5 x 5 configuration) in a single session, allowing for high-throughput automated experiments.</p>
</sec>
<sec id="s2d">
<title>Closed-loop cutaneous stimulation in mice running through a maze</title>
<p>We demonstrate that freely moving mice can be stimulated as they were running through a maze environment. The ability to deliver cutaneous stimuli to mice moving through behaviorally-relevant tasks has previously been a significant challenge and experimenters typically apply stimuli to moving mice manually (<xref ref-type="bibr" rid="c6">6</xref>–<xref ref-type="bibr" rid="c9">9</xref>).</p>
<p>To motivate movement in a task, we built a novel maze that encourages alternation between two rewards at separate locations. The maze had one-way doors, ensuring that after making a decision to turn left or right, mice could obtain a reward but are required to circle back to the maze’s start point to re-initiate the action-reward cycle (<xref rid="fig5" ref-type="fig">Figure 5A,B</xref>). The reward ports were activated by a brief nose poke and delivered a drop of sucrose water, followed by a timeout period. In addition to the timeout, the reward ports were only reset once the mouse exited the reward chamber through a one-way door, as determined by real-time keypoint tracking. The combination of a long timeout and required exit from the reward chamber rendered it more time-efficient to cycle between the two reward chambers and encouraged running along the corridors.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Closed-loop cutaneous stimulation in mice running through a maze.</title>
<p><bold>A</bold> Schematic of the maze design. A single trial was defined as the collection of a single reward, indicated by the <italic>orange</italic> and <italic>green</italic> arrows. The left and right corridors leading to the reward chambers were paired with stimulation of nociceptors using transdermal optogenetics. <bold>B</bold> Maze renderings from aerial, front, and side views. Mice entered via an entry chamber leading to a corridor and junction, choosing left or right through one-way doors. A sucrose-water reward awaited in the reward chamber, with exit through another one-way door. <bold>C</bold> Total number of rewards collected (left and right-hand side reward ports combined) for each training session. <bold>D</bold> Movement trajectories over an entire session (<italic>left)</italic> and a single trial (<italic>right</italic> ). Trajectories are shown from one mouse for the first stimulation session. <bold>E</bold> Frame sequences (0.2 s apart) from four trials in four mice show runs along maze corridors toward the reward chamber. Blue arrows indicate targeted stimulation. <bold>F</bold> Relative timings of corridor entry and subsequent reward collection (<italic>n</italic> = 4 mice). <bold>G</bold> Transition matrix showing mice predominately alternate between rewards at the left and right reward ports. <bold>H</bold> Example movement trajectories (tail base) in the left and right corridors from one mouse (<italic>left)</italic>. Bar plots showing path coherence and speed in the high stimulation corridor relative to the low stimulation corridor (<italic>right</italic> ). <bold>I</bold> Plot of speed and coherence in a 2-second window prior to the first stimulation in each trial colored by movement state cluster (Gaussian mixture modeling; 116 trials). <bold>J</bold> Speed and coherence relationships before and after stimulation, where the values of the prior state are colored and the responses are shown in black. The black lines pair values for each trial. Stimulation causes a consistent shift in the fast-direct state towards the slow-assess state, while stimulation of the slow-assess state shifts towards a direct movement. <bold>K</bold> Bar plots showing the change (post–pre) in speed and coherence. Stimulation resulted in changes in fast-direct trials (speed: Welch’s <italic>t</italic> = -6.90, <italic>p</italic> = 0.006; coherence: Welch’s <italic>t</italic> = -9.39, <italic>p</italic> = 0.003) and also slow-assess trials (coherence: Welch’s <italic>t</italic> = -26.9, <italic>p</italic> &lt; 0.0001). <bold>L</bold> Plot of post-pre stimulation speed values across all trials colored by state clusters. Panel A was created using <ext-link ext-link-type="uri" xlink:href="https://BioRender.com/0q9m1bi">BioRender.com</ext-link>.</p></caption>
<graphic xlink:href="606618v3_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Mice were trained over three sessions in the maze. In the first training session, they rapidly navigated the one-way doors with little delay after a few attempts. This quickly led to the use of reward ports in the chambers on either side of the maze. The first reward was collected after 440 ± 117 s (4 mice). By the third training session, this time decreased to 82 ± 38 s, suggesting rapid learning. During the reward port timeout, mice typically explored the corridor connected to the reward chamber or exited it to explore the entry corridor. By the third day of training, the number of completed trials had increased for all mice. On average, mice completed 64 ± 24 rewarded trials in the third training session (&lt;2 hour in duration), although individual performance varied considerably. For example, one mouse completed only 10 rewarded trials in the third session and another mouse completed 97 trials (<xref rid="fig5" ref-type="fig">Figure 5C</xref>).</p>
<p>Mice could be stimulated while they were running. Example movement trajectories from one mouse are shown in <xref rid="fig5" ref-type="fig">Figure 5D</xref>. Using Trpv1::ChR2 mice, we demonstrated the system’s utility in studying localized cutaneous hypersensitivity. We employed a widely used model of inflammatory pain with a unilateral injection of complete Freund’s adjuvant (CFA) in the hind paw. A brief (3 ms) nociceptive stimulus was successfully targeted to the contralateral (right, non-injected) paw with negligible confusion between paws (705/706 stimuli targeted the correct hind paw). This allows future studies in which phasic and tonic pain can be separated. Despite ongoing hypersensitivity and phasic stimuli, mice remained actively engaged in the task, collecting rewards sequentially from each side, as per their training (<xref rid="fig5" ref-type="fig">Figure 5F,G</xref>). Their rapid movement along the stimulation corridors (average maximum speed of 142 ± 26 mm/s, 4 mice) required precise targeting (<xref rid="fig5" ref-type="fig">Figure 5E</xref>).</p>
<p>Stimulation during movement revealed a frequency-dependent disruption of path coherence and speed. High frequency stimulation resulted in reduced locomotor speeds (<italic>p</italic> = 0.037 with paired t-test, <italic>n</italic> = 4 mice) and more variable trajectories compared to during low frequency stimulation (<xref rid="fig5" ref-type="fig">Figure 5H</xref>). Once through the stimulation corridors, the mice successfully collected a reward in almost all trials.</p>
<p>We then examined how behavior depends on the behavioral state prior to stimulation. Before stimulation, two behavioral states were identified (<xref rid="fig5" ref-type="fig">Figure 5I</xref>): one represents faster locomotion in a direct heading (fast-direct state), while the other represents slower movements with headings that were less coherent (slow-assess state). The two clusters had significantly different speeds and coherence (<italic>p</italic> &lt; 0.0001 for both; Welch’s t-test), where the 79 fast-direct trials (68.1%) showed speed of 90.8 ± 28.3 mm/s (mean ± SD) and coherence of 0.9 ± 0.1 (mean ± SD; arbitrary units) and the 37 slow-assess trials (31.9%) had lower speed of 32.5 ± 13.9 mm/s and less direct headings with a coherence of 0.1 ± 0.1. Stimulation of the two states produced robust opposing changes in behavior (<xref rid="fig5" ref-type="fig">Figure 5J,K</xref>). Slow-assess states become significantly more coherent as the stimulus drives a redirection of heading. Fast-direct states were significantly slowed and less direct, potentially representing a pause for information gain. In this case fast-direct states shift towards slow-assess and slow-assess shift towards fast-assess, where intermediate states may together represent a form of vigilant behavior. This demonstrates movement state-dependence changes behavior. Indeed, the speed after stimulation was proportional to the initial speed in the fast-direct trials; a positive linear correlation (Pearson’s <italic>r</italic> = 0.23, <italic>p</italic> = 0.046) indicates that the disruption of behavior partly scales with the initial movement state (<xref rid="fig5" ref-type="fig">Figure 5L</xref>).</p>
<p>We thus demonstrate automatic control of precise cutaneous stimuli as mice move through naturalistic environments.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>The somatosensory system provides a critical link between the brain, the body and its immediate external environment. The complex ways in which this system supports movement, learning, and action in rodents have historically posed substantial methodological challenges. Traditional methodologies have varied widely, encompassing both innovative and practical approaches — from stimulation of whiskers or skin in head-fixed animals (<xref ref-type="bibr" rid="c13">13</xref>, <xref ref-type="bibr" rid="c15">15</xref>–<xref ref-type="bibr" rid="c22">22</xref>) to the more straightforward manual touching of paws in mice (<xref ref-type="bibr" rid="c6">6</xref>, <xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c9">9</xref>, <xref ref-type="bibr" rid="c23">23</xref>). These approaches, however, have inherent limitations in replicating the dynamic and complex interactions experienced in naturalistic environmental settings. In response to these limitations, we have developed a system that enables cutaneous stimulation in more complex environments. This closed-loop system automatically tracks, targets, and stimulates mice remotely to study the somatosensory system in naturalistic environmental settings.</p>
<p>Generating cutaneous inputs in freely moving mice requires stimuli that are spatially and temporally precise. We achieved millisecond-timescale stimulation of small skin areas using transdermal optogenetics (‘remote touch’; 10). Opsins were genetically targeted to specific afferent fibers innervating skin and activated with light targeted precisely via a laser in free-space. This beam path was aligned to a second laser system and employed for thermal stimulation on a timescale of seconds. Delivery of these stimuli was controlled by a feedback system consisting of three main components: (<xref ref-type="bibr" rid="c1">1</xref>) real-time tracking infers the keypoints of various body parts, continuously transmitting this data to the controller; (<xref ref-type="bibr" rid="c2">2</xref>) user-defined rules determine the stimulation conditions (spatial, temporal, and physiological state-dependence), providing control signals for the actuators; and (<xref ref-type="bibr" rid="c3">3</xref>) mirror galvanometers target the beam path to specified keypoints and signals trigger light delivery, following which real-time tracking is then resumed. The processing latency can be further reduced by minimizing the frame resolution, narrowing to a region of interest (ROI), increasing the processing power, using alternative networks, or combinations thereof. We demonstrate an approach to reduce the pixel count by cropping to an ROI using our random access targeting method (<xref rid="fig4" ref-type="fig">Figure 4</xref>). One possible version of this would be centering a region on the mouse centroid as it moves, this would dramatically reduce the computational load to allow shorter processing latencies. With a reduced processing latency, high-speed video can be processed, which enables the approach to generalize to other body parts that move more rapidly. Additionally, predictive tracking can compensate for the remaining delay by estimating a keypoint location from its recent trajectory (e.g. constant-velocity extrapolation or a Kalman filter). This can reduce effective targeting error for continuously moving features such as the snout. However, we demonstrate here that this system can precisely target the hind paw for stimulation, even as the mice are in motion.</p>
<p>We demonstrate the versatility of the system from automated multi-animal nociceptive testing to sparse stimulation of freely moving mice in a circular arena. We show that stimuli could be targeted with high accuracy and resulted in immediate behavioral responses that could be mapped. The system was used to deliver cutaneous stimuli to mice running through a maze. Mice were trained on an alternation task with stimuli applied en route to the reward, thus separating choice, punishment, and reward in a naturalistic environment. Mice with a model of inflammatory pain still readily engaged in this task during noxious cutaneous input (punishment). The recruitment of reflexes during locomotion caused immediate evaluative behavior that temporarily disrupted goal-directed behavior. Achieving such localized stimulation has been challenging with traditional methods: electric grid floors generate whole body stimuli that are considered incompatible with models of chronic pain that generate unilateral hind paw hypersensitivity; and manual stimulation lacks capacity, reliability, and is potentially confounded by experimenter and observer biases. Our system addresses these issues, allowing for the dissociation of touch, phasic pain, and tonic pain to better understand their relationships with behavior.</p>
<p>Stimulation of the body and paws enables the study of pain, touch, thermoception, and movement (<xref ref-type="bibr" rid="c24">24</xref>–<xref ref-type="bibr" rid="c35">35</xref>). Paw stimulation is also ubiquitous in aversive learning and memory, using a crude shock stimulation with a grid floor (<xref ref-type="bibr" rid="c36">36</xref>, <xref ref-type="bibr" rid="c37">37</xref>), and can now be carried out with spatiotemporal precision. The stimulation can be static or dynamic and localized to small areas on the body in an automated manner. Automation improves the precision of stimulus delivery compared to traditional manual methods; it reduces labor and enhances the reliability of the data. All experiments were conducted remotely from an adjacent room to minimize potential observer effects and biases on the mice. Automated nociceptive assays have principally focused on the initial rapid movements elicited by stimulation of mice in small chambers (<xref ref-type="bibr" rid="c38">38</xref>–<xref ref-type="bibr" rid="c40">40</xref>). Here, we provide an approach to examine how these rapid movements are embedded within complex behavior in naturalistic environments, opening new ways to investigate nociception, and somatosensation more broadly.</p>
<p>We have previously mapped fast behavioral responses in stationary mice; demonstrating that fast responses to noxious stimuli are not localized and fixed, but are widespread and contextual (<xref ref-type="bibr" rid="c12">12</xref>) and that these are coordinated where whole-body movements depend on the initial posture (<xref ref-type="bibr" rid="c10">10</xref>). Here, we show state dependence of behavioral responses in mice that are moving, where noxious stimulation causes fast-direct moving mice to slow and mice already assessing their location to shift to a direct heading. This could be considered a state-dependent modulation or switching to a form of vigilance, and suggests that even the most rapid protective responses are modulated online by the current movement state, ensuring behavior remains appropriate to context.</p>
<p>While we demonstrate the utility of the optical system using nociceptive stimuli, this system can deliver various cutaneous inputs by targeting specific afferents for selective opsin expression, whether they are thermoreceptive, chemoreceptive, or mechanosensitive (<xref ref-type="bibr" rid="c10">10</xref>, <xref ref-type="bibr" rid="c38">38</xref>–<xref ref-type="bibr" rid="c41">41</xref>). Such “pure” stimuli do not occur in nature but offer crucial spatial, temporal, and genetic precision (<xref ref-type="bibr" rid="c36">36</xref>, <xref ref-type="bibr" rid="c42">42</xref>, <xref ref-type="bibr" rid="c43">43</xref>). Our system enables delivery of multiple wavelengths of light separately or together, to support combinations of opsins from the vast optogenetic toolbox. Opsins can be used to activate or silence neurons, with a range of kinetic properties, diverse light wavelength profiles allowing multi-color manipulations, or control different downstream signaling effectors (<xref ref-type="bibr" rid="c44">44</xref>). Thermal stimuli are also used routinely in research (<xref ref-type="bibr" rid="c15">15</xref>, <xref ref-type="bibr" rid="c38">38</xref>, <xref ref-type="bibr" rid="c45">45</xref>) but slow thermal dissipation can require mice to be stationary for consistent stimulation. Automation provides opportunities for development of analgesics, particularly for integrating reflexes with spontaneous, free operant behaviors. Indeed, cutaneous stimulation in naturalistic environments can be readily combined with approaches to quantify behavior (<xref ref-type="bibr" rid="c46">46</xref>–<xref ref-type="bibr" rid="c53">53</xref>).</p>
<p>The system has many applications for the study of sensorimotor transformations, perception, memory, learning, and action. It is flexible enough to trigger stimulation based on various states, including periods of inactivity or locomotion, at specific spatial locations, and with precise timing. Future work made possible by this system is expected to include examining how cutaneous input can interrupt and modulate specific swing phases (<xref ref-type="bibr" rid="c33">33</xref>), self-grooming, posture states (<xref ref-type="bibr" rid="c12">12</xref>), and other spontaneous behavioral syllables (<xref ref-type="bibr" rid="c48">48</xref>). It can facilitate investigations of naturalistic learning, whether through mazes, social interactions, or engagement with the environment or objects (<xref ref-type="bibr" rid="c54">54</xref>, <xref ref-type="bibr" rid="c55">55</xref>), and of sleep fragmentation (<xref ref-type="bibr" rid="c56">56</xref>), anxiety (<xref ref-type="bibr" rid="c57">57</xref>, <xref ref-type="bibr" rid="c58">58</xref>), fear (<xref ref-type="bibr" rid="c36">36</xref>), and stress (<xref ref-type="bibr" rid="c37">37</xref>). Finally, it has potential to provide free operant methods for analgesic development for chronic pain. The system may be combined with existing tools to record neural activity in freely moving mice, such as fiber photometry, miniscopes, or large-scale electrophysiology, and manipulations of this neural activity, such as optogenetics and chemogenetics. This can allow mechanistic dissection of cell and circuit biology in the context of naturalistic behaviors.</p>
<p>Establishing how behavior is shaped by somatosensation requires that mice can be stimulated while freely behaving. We describe a system that addresses this need, delivering cutaneous stimuli in a manner that is precise, remote, statedependent, dynamic, and fully automated to target freely behaving mice that are actively exploring complex environments.</p>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Animals</title>
<p>Mice were housed at 21 ± 2°C, 55% relative humidity, following a 12-hour light: 12-hour dark cycle with <italic>ad libitum</italic> access to food and water. Optogenetic experiments were performed using mice with ChR2 selectively expressed in nociceptors (Trpv1::ChR2). Heterozygous Trpv1-Cre mice, which have Cre recombinase inserted downstream of the <italic>Trpv1</italic> gene (<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:RRID:IMSR_JAX:017769">RRID:IMSR_JAX:017769</ext-link>, B6.129-Trpv1<sup><italic>tm</italic>1(<italic>cre</italic>)<italic>Bbm</italic></sup>/J; 59), were crossed with mice homozygous for Cre-dependent ChR2(H134R)-tdTomato (<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:RRID:IMSR_JAX:012567">RRID:IMSR_JAX:012567</ext-link>, Ai27(RCL-hChR2(H134R))/tdT-DChR2-tdTomato; 60). This produced progeny heterogeneous for both transgenes (Trpv1::ChR2) and control littermates that do not encode Cre recombinase but do encode Cre-dependent ChR2-tdTomato. Blue light directed to the glabrous plantar surface of the hind paw in Trpv1::ChR2 mice results in the direct time-locked activation of broad-class nociceptors with single action potential resolution (<xref ref-type="bibr" rid="c12">12</xref>). Experiments with the infrared (IR) laser were performed using wild type mice (<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID:RRID:IMSR_JAX:000664">RRID:IMSR_JAX:000664</ext-link>, C57BL/6J). Equal numbers of male and female adult mice were used (aged between 6 and 40 weeks), with 2 - 5 cohorts of mice per experiment. All animal work was carried out according to the UK Animal Scientific Procedures Act (1986), approved by the UCL Animal Welfare and Ethical Review Body (AWERB) and performed under licenses released by the UK Home Office.</p>
</sec>
<sec id="s4b">
<title>Design and development</title>
<p>Several substantial improvements were made to the optical design (<xref ref-type="bibr" rid="c10">10</xref>) to enable automated, multi-color, closed-loop optical stimulation across a large environment. Part lists are provided in Tables S1, S2 and S3 (Supplementary file 1).</p>
<p>The optical system was mounted on a large aluminum breadboard (0.75 m x 0.75 m) to provide more space for optical components and stability to the large glass platform. The diode laser beam (blue light, 473 nm, Cobolt, 06-01 MLD) was focused to the center of the galvanometers using two broadband dielectric mirrors (M1 and M2) via an axial adjustable lens (L1, 30 mm focal length), a collimating lens (L2, 150 mm focal length), and a long focal length lens (L3, 500 mm focal length). We added a second laser beam path to enable multi-color stimulation, using separate mirrors and lenses and an appropriate dichroic mirror. The infrared (IR) laser (785 nm, SLOC, RLM785TA-1500) beam passed through an optical beam shutter (Thorlabs, SH05RM) to pulse the light with a controller (Thorlabs, KSC101). Two additional mirrors (M3 and M4) aligned the IR beam through a long focal length lens (750 mm) to the DM, where the beam path was aligned to converge with the blue light laser beam path into a pair of galvanometer mirrors (GM).</p>
<p>For the large environment, a 0.55 m x 0.55 m glass stimulation platform was held in place above the optical components via a vertical optical construction rail (95 mm x 95 mm x 1500 mm) attached to the aluminum breadboard, as shown in <xref rid="fig2" ref-type="fig">Figure 2A</xref>. Aluminum construction rails (25 mm x 25 mm x 500 mm) were secured at each corner of the glass platform frame and the opposite side of the platform to the optical rail to ensure stability. The blue light laser spot size (1/e<sup>2</sup> width) was calibrated to 2.3 mm<sup>2</sup> using the non-rotating L1 adjustable lens housing and an optical beam profiler (BP209-VIS/M, Thorlabs). For the experiment using the IR laser, two near-IR hot mirrors (Thorlabs, FM201) were placed on top of the USB 3.0 camera (acA1920-40um camera, Basler) lens to minimize how much IR light was imaged by the camera.</p>
<p>For real-time markerless pose estimation to support automated, closed-loop stimulation, an additional camera was positioned below the glass stimulation platform. behavior was captured at 30 frames per second (fps) via a USB 3.0 to the primary computer (C1), which controls video recording, pose estimation, calculations, and directs the galvanometer mirrors to target lasers.</p>
</sec>
<sec id="s4c">
<title>Optical system calibration</title>
<p>The optical parameters of the system were characterized using the blue laser due to the high quality beam. The uniformity of blue light diode laser spot size across the glass stimulation platform was measured with an optical beam profiler (Thorlabs, BP209-VIS/M) placed at 16 locations across the platform. The beam profiler aperture was positioned at these locations using a custom laser-cut acrylic plate. Laser power was attenuated by 25% with an ND filter (Thorlabs, NE506B, optical density 0.6) to be within the operating range of the beam profiler. Absolute power (mW) at the 16 locations was assessed with a S121C photodiode measured by an optical power meter (Thorlabs, PM100D). The laser beam area and the optical power (mW) were calculated at each location (<xref rid="fig1" ref-type="fig">Figure 1A</xref>).</p>
<p>There was negligible distortion in the acquisition camera across the glass platform. This was determined by imaging a chessboard camera calibration pattern of 20 mm x 20 mm squares in a 14 x 10 grid at 5 different locations across the glass. OpenCV was used to measure square sizes and we calculated the min-max range of all squares was &lt;1 pixel, at 0.89 pixels, which is considered negligible. The Euclidean norm was computed for a matrix of the corners of all squares, providing a scale factor of 0.45 mm/pixel.</p>
<p>To generate a pixel-voltage coordinate dictionary that can be used to convert <italic>x,y</italic> pixel coordinates to <italic>x,y</italic> galvanometer voltage coordinates, the following steps were carried out. First, the galvanometers were raster stepped to direct the blue laser spot to a grid of 10,000 points (100 x 100), capturing these with the pose-estimation camera. For every point of the raster, the <italic>x,y</italic> voltages were mapped to the peak intensity pixel. A <italic>x,y</italic> voltage were then computed for every pixel by interpolation, fitting with a two-dimensional polynomial equation. This automated procedure took &lt;30 minutes and resulted in a pre-computed pixel-voltage dictionary. Entering an <italic>x,y</italic> coordinate for a body part, inferred from the camera feed, returns the interpolated <italic>x,y</italic> voltages to target the laser to the same location. We repeated the mapping once every week over the course of 10 weeks to ensure the stability of the mapping. This was done during extensive experimentation to account for potential movements during cleaning and changes in arenas.</p>
</sec>
<sec id="s4d">
<title>Pose estimation</title>
<sec id="s4d1">
<title>Training a DeepLabCut network model</title>
<p>DeepLabCut installation (v2.2.0.2; 46, 61) was coupled to Tensorflow-GPU (v2.5.0, with CUDA v11.2 and cuDNN v8.1). Training of the DeepLabCut neural network model was used with default network and training settings in an Anaconda environment with Python v3.8.13 installed. Videos were selected based on their representation of the whole breadth of behavioral responses, and k-means clustering was used to select the training images. 437 frames were labeled from 22 selected videos, and the network was trained for 200,000 iterations. Following further optimization of lighting, 210 frames from 11 additional videos were manually labeled and machine labels from 171 outlier frames from 9 videos were manually refined. These were fed back to the training dataset and the network retrained for a further 200,000 iterations. Training resulted in an MAE of 3.29 pixels, which is comparable to human ground truth variability quantified elsewhere (see 46). This model was used for all pose estimation. The video resolution (1920 x 1200) required a processing time higher than the frame interval (33.33 ms), resulting in real-time pose estimation on a sub-sample of all frames recorded. Therefore, <italic>post-hoc</italic> pose estimation was carried out to analyze all frames.</p>
</sec>
<sec id="s4d2">
<title>Real-time tracking</title>
<p>DLC-Live! SDK (v1.0; 11) was installed on a computer with fast processing capabilities (AMD Ryzen 5 3600 Six Core CPU (3.6 GHz - 4.2 GHz), NVIDIA GEFORCE RTX 2080 Ti GPU, quad-core RAM (64 GB), Windows 10, custom manufactured by PC Specialist Ltd.) in an Anaconda virtual environment (Python v3.7.10) with DeepLabCut (v2.1.10.4) installed. DLC-Live! SDK installation was coupled to Tensorflow-GPU (v1.13, with CUDA v10 and cuDNN v7.4). Integration of the Basler camera and the DLC-Live! GUI (DLG) utilized a Python wrapper, pypylon (v1.7.2, Basler), to facilitate communication with the pylon Camera Software Suite through a Linux subsystem in Windows 10 (WSL Ubuntu, v20.04). The trained DeepLabCut network model was loaded into the DLG, which captures the data from the camera and performs real-time pose estimation on the incoming camera feed. Custom code was written in Python for each experimental design; this comprised the conditions that defined the behavioral protocol and controlled stimulation as required (see Figure 22).</p>
</sec>
</sec>
<sec id="s4e">
<title>Optical system characterization</title>
<p>We characterized the latencies for real-time tracking, targeting, and stimulation. Control signals for the camera, mirror galvanometers, and laser were measured simultaneously at 100 kHz using a Digidata 1440a (Molecular Devices). During the exposure of each 5 ms frame, the tracking camera sent a voltage signal from its GPIO. The <italic>x</italic> - and <italic>y</italic> -axis scanner position outputs from the two mirror galvanometer drivers were used to monitor the movement of the mirrors. A 1 ms laser signal was sent to a microcontroller (Arduino UNO) to generate parallel digital outputs, which triggered the laser and monitored its timings. All four control signals were recorded during four 5-minute sessions with wild-type mice (C57BL/6J) exploring a circular arena. The tracking camera was set to record at a resolution of 1100 pixels x 1100 pixels, with a 5 ms exposure at 30 fps. The processor code identified frames with a likelihood &gt;0.8 for the ‘left_hindpaw_mid’ keypoint. The <italic>x,y</italic> pixel location was then converted to mirror galvanometer <italic>x,y</italic> voltage signals using a pixel-voltage coordinate dictionary. A multifunction DAQ device (USB-6002, National Instruments) was used to send these <italic>x,y</italic> voltages and subsequently a 1 ms command to the laser-triggering microcontroller. The laser was triggered only if more than 500 ms had passed since the previous stimulation. The camera signal confirmed an exposure time of 5 ms and a frame rate of 30 fps. The latency between camera acquisition and stimulation was calculated by collecting timestamps immediately after stimulation (acquisition timestamp) and comparing these to the frame timestamp on which pose estimation was carried out (processing timestamp). We estimated a processing latency of 84 ± 12 ms (mean ± SD) by subtracting the frame acquisition timestamp from the frame processing timestamp contained in DeepLabCut output files for 16,000 processed frames recorded across four mice (4,000 frames each). The latency between galvanometers moving and laser stimulation was determined by comparing the timings of galvanometer jumps and laser signals. This delay was 3.3 ± 0.5 ms (mean ± SD, for 245 trials). To synchronize the four voltage signals with frame and stimulation timestamps, we determined the timing of the first galvanometer jump when pose estimation was initialized. In the current configuration the end-to-end closed-loop delay is ≈ 87 ms from the combination of the processing latency and other delays.</p>
<p>The accuracy of real-time tracking for the ‘left_hindpaw_mid’ keypoint was assessed by manually identifying its coor-dinates (ground truth) and comparing these to the coordinates predicted by the DeepLabCut network model in real time on frames extracted from 5 videos of different mice exploring an open arena. Frames with a likelihood &gt;0.8 were selected, as in experimental protocols. Euclidean distances were calculated pairwise between ground truth coordinates and model-generated coordinates, and averaged to give the mean average Euclidean error (MAE). The MAE between the predicted and actual coordinates was 1.36 mm (calculated on 1,281 frames).</p>
<p>The accuracy of body part targeting was determined using a high-speed Basler acA2000-165umNIR camera recording frames at 648 x 650 pixels, 270 fps during the 5-minute sessions described above. We used a &gt;0.8 likelihood for the ‘left_forepaw’ keypoint in additional sessions. High-speed recordings captured each 1 ms laser pulse, and frames containing these pulses were identified using the reflection of the laser. We manually assessed 1279 frames and classified them as a ‘hit’ or ‘miss’, and whether a ‘hit’ was on the targeted paw to quantify confusion during keypoint tracking.</p>
<p>The accuracy of hitting the body part depended on how fast the mice were moving. To demonstrate this, we segmented the keypoint series using four speed categories: stationary, low, medium, and high. Speed was calculated using the Euclidean distance the ‘tail_base’ keypoint moved in each frame, divided this by the time elapsed, and smoothing the speed with a 10-frame rolling mean filter. The speed histogram informed the windows of categories (&lt;20, 20-120, 120-220, &gt;220 pixels per second, for stationary, low, medium, and high, respectively). The accuracy of hitting the ‘left_hindpaw_mid’ keypoint was calculated on frames across each speed category: 156 frames for stationary, 159 frames for low, 155 frames for medium, and 187 frames for high. Similarly, the accuracy of hitting the ‘left_forepaw’ keypoint was calculated on 155 frames for stationary, 156 frames for low, 155 frames for medium and 156 frames for high.</p>
<p>The error between the ground truth keypoint and the laser spot for the ‘left_hindpaw_mid’ keypoint was determined by manually identifying the body part coordinates (ground truth) on frames immediately prior to stimulation and then the coordinates for the laser spot on subsequent stimulation frames. These estimates were first made for all pre-stimulation frames and then for the set of stimulation frames. The mean average Euclidean error (MAE) was approximately 1.3 mm across all locomotion speeds categories (463 frames).</p>
</sec>
<sec id="s4f">
<title>Multi-chamber real-time pose estimation</title>
<p>To target and stimulate individual mice when multiple mice were present in chambers on the stimulation platform, we performed chamber-based cropping and subsequent real-time pose estimation. Nine mice were placed into nine chambers (100 mm x 100 mm wide, 120 mm tall), we monitored the motion in each chamber to find mice that were ‘idle’, the camera feed was cropped, body parts estimated, and the laser targeted to the hind paw coordinates.</p>
<p>The frame-to-frame absolute difference in pixel values (motion energy) was calculated in each region of interest for the individual chambers. Background noise was removed below &lt;10 motion energy and the mouse was defined as ‘idle’ if the summed motion energy was less than a specified threshold (30,000 motion energy) for 2 seconds. Idle mice that had not been stimulated in the previous 10 seconds were pseudo-randomly selected and their chamber cropped. The pose estimation <italic>(x, y)</italic> coordinates generated by the DeepLabCut network model were used to target the laser to the hind paw. We modified the following scripts in the <italic>dlclive</italic> and <italic>dlclivegui</italic> packages in DLC-Live! SDK to develop the multi-chamber real-time tracking approach: <italic>dlclive, utils</italic> (<italic>dlclive</italic> package) and <italic>pose_process</italic> (<italic>dlclivegui</italic> package).</p>
</sec>
<sec id="s4g">
<title>Assembly of a naturalistic task</title>
<p>The maze was constructed of 3 mm matte black acrylic (200 mm in height) and measured 500 mm x 180 mm (inner dimensions). The maze was constructed as a single junction, with 40 mm width corridors forming two chambers (70 mm x 100 mm) at either end of the junction corridors. The entrance to the maze was connected to a transparent acrylic chamber (100 mm x 100 mm, 130 mm tall). There were one-way doors (100 mm tall, 30 mm wide) designed as a push-through flap cut from 0.5 mm styrene and secured to the door frame with butterfly pins. The one-way doors were positioned at the junction and to leave the reward chambers; this created a one-way system, so once the mouse exited either chamber it was required to go back around the maze and through the junction decision point to re-enter the reward chamber. Each chamber contained a rectangular opening (20.5 mm x 11.5 mm) through which a water delivery port (Sanworks mouse behavior port) was fixed to the walls to allow the mouse to collect rewards. A water reward (∼ 5 <italic>μ</italic>l of 10% sucrose water) was delivered when the mouse’s nose broke the IR beam in the water delivery port. The reward delivery system was controlled with an Arduino. In addition to a reward timeout period of 45 - 60 s, the mouse was required to leave the chamber before the water reward port was reset and another reward could be collected.</p>
</sec>
<sec id="s4h">
<title>Behavioral protocols</title>
<sec id="s4h1">
<title>Experimental room, arena and cleaning set-up</title>
<p>The experimental room was maintained at 21°C with relative humidity between 45 - 65%. All behavior experiments on the system were performed in custom-built arenas laser cut from matte black acrylic and placed on the glass stimulation platform. Two infrared LED panels illuminated opposite sides of the arena to optimize lighting and achieve high contrast images. White noise at 68 dB was generated with custom Python code, through a L60 Ultrasound Speaker (Petterson Elektronic AB) via a second DAQ device (USB-6211, NI) and amplifier. The white noise played continuously through the duration of the habituation sessions and the experiment. The glass stimulation platform was cleaned twice with 70% ethanol, while the acrylic arena was cleaned twice with an odorless surface disinfectant between each animal to minimize olfactory cues. The lasers were targeted to the hind or fore paw glabrous skin in all experiments, contingent on meeting specific conditions defined in the protocol.</p>
</sec>
<sec id="s4h2">
<title>Habituation</title>
<p>Animals were placed in custom matte black acrylic chambers (100 mm x 100 mm, 80 mm in height) placed on a von Frey wire mesh grid and underwent two habituation sessions to the experimental room for 1 - 2 hours. Mice also underwent 1 or 2 handling sessions prior to experiments.</p>
</sec>
<sec id="s4h3">
<title>Minimal cutaneous stimulation in an open arena</title>
<p>Mice were placed in an acrylic arena painted matte black (500 mm outer diameter, 150 mm in height, 5 mm thick). Dividers (160 mm tall, 116 mm wide, matte black, 3 mm thick) were slotted onto the arena wall to separate the arena into 6 segments to enrich the environment. Mice were allowed to freely explore for 60 minutes. Individual 10 ms duration blue light laser pulses were remotely targeted to the left hind paw with a ≥ 10-minute interstimulus interval. Each stimulation was delivered contingent on the conditions that the hind paw was still and had not been stimulated &lt;10-minutes prior. The hind paw was considered still when both the standard deviation of its keypoint <italic>(x,y)</italic> was &lt;1 pixel and the likelihood of this keypoint was &gt;0.8 throughout a 2 s period. Stimulation was repeated over two sessions on consecutive days. Data was collected from 26 mice in total from 5 different cohorts. 16 Trpv1::ChR2 mice were split into two groups: 10 mice received blue light stimulation, and 6 mice received no stimulation as control. 10 littermate controls that received blue light stimulation were also used.</p>
</sec>
<sec id="s4h4">
<title>Somatosensory stimulation in multiple chambers</title>
<p>Nine mice were placed in 100 mm x 100 mm individual chambers in a 3 x 3 configuration, covered by a lid. Mice were habituated to the chambers atop the glass stimulation platform for two hours in two sessions prior to the first experimental day.</p>
<p>For the experiment with thermal stimulation, 18 C57BL/6J mice from 2 cohorts were used. Mice were placed in the chambers for 2 hours, and a 10 s laser pulse was targeted to one of the hind paws, with up to 10 stimulations on each paw &gt;1 minute apart. IR laser spot size was 2.2 mm<sup>2</sup> and the optical power was set to 1.4 W in the first cohort of mice and to 1.65 W in the second cohort of mice to elicit paw responses between 10 - 12 s.</p>
<p>For the experiment with transdermal optogenetic stimulation, 9 Trpv1::ChR2 and 9 littermate controls from two cohorts were used. Mice were similarly placed in the chambers for 2 hours, with optogenetic stimulations delivered to each hind paw &gt;1 minute apart. The stimulation protocol comprised 6 conditions: a single pulse stimulation at 40 mW/mm<sup>2</sup>, and a train of pulses (3 ms pulses at 10 Hz for 10 s) at 8, 4, 2, 1 and 0.5 mW/mm<sup>2</sup>. Spot size was 2.0 mm<sup>2</sup>. The order of stimulation intensity was pseudorandomized with Euler tours (<xref ref-type="bibr" rid="c62">62</xref>).</p>
</sec>
<sec id="s4h5">
<title>Somatosensory stimulation in a maze</title>
<p>Mice were first habituated to the maze without any doors during a 1 hour session. On three separate days following this, they underwent 3 training sessions with the one-way doors in place. Mice were water-deprived 16 to 18 hours prior to each experimental session to motivate the use of water rewards. A trial was defined as the mouse successfully collecting one reward; the collection of multiple rewards required the mouse to leave the reward chamber. Mice that had not made &gt;10 trials by the third training session were excluded from the subsequent stimulation sessions due to poor engagement. 7 out of 12 Trpv1::ChR2 mice from 4 cohorts passed this criteria. As proof-of-principle for precise contralateral stimulation in the context of a unilateral pain state, mice received 7 <italic>μ</italic>l of complete Freund’s adjuvant (CFA) via intraplantar injection in the left hind paw. CFA-injected mice showed significant mechanical allodynia compared to saline controls (<italic>p</italic> = 0.039 with Mann-Whitney test, <italic>n</italic> = 4 mice). After baseline measurements of mechanical sensitivity, mice were injected with CFA and mechanical allodynia was evaluated in both hind paws 2 days following injection. Mechanical allodynia resulting from injection of CFA into the left hind paw was measured by von Frey testing (Up-Down method). Mice were placed in individual chambers (100 mm x 100 mm) on a mesh wire floor and habituated to the test setup prior to testing. The von Frey test was conducted blind to experimental groups. Mice underwent two stimulation sessions in the maze, in which optogenetic stimuli were delivered to the right (uninjected) hind paw in the stimulation zones. There were two stimulation protocols: the left corridor was paired with 3 ms laser pulses at 5 Hz and the right corridor was paired with 3 ms laser pulses at 1 Hz. Laser power density was 40 mW/mm<sup>2</sup>. Training and experimental sessions lasted 1 - 2 hours.</p>
</sec>
</sec>
<sec id="s4i">
<title>Data analysis</title>
<sec id="s4i1">
<title>Data compression, analysis and visualization</title>
<p>Videos were acquired in AVI format and fed through offline DeepLabCut pose estimation to generate <italic>(x,y)</italic> coordinates and likelihoods for each body part. For the analysis of the recordings with multiple chambers, AVI video files were converted to MP4 format using H.264 compression. The MP4 video files were cropped into individual mouse chambers (230 x 230 pixels) before running pose estimation. Analyses were based on the position of the hind paw or tail base coordinates. All analysis code was written in Python 3 (v3.9.7), using the NumPy, Pandas and OpenCV packages. Data was visualized using Matplotlib and Seaborn packages. Schematics were created using BioRender in <xref rid="fig1" ref-type="fig">Figures 1B</xref> (<ext-link ext-link-type="uri" xlink:href="https://BioRender.com/fqettr4">https://BioRender.com/fqettr4</ext-link>), 3A (<ext-link ext-link-type="uri" xlink:href="https://BioRender.com/dkry6u2">https://BioRender.com/dkry6u2</ext-link>), 4A (<ext-link ext-link-type="uri" xlink:href="https://BioRender.com/camqr45">https://BioRender.com/camqr45</ext-link>), 5A (<ext-link ext-link-type="uri" xlink:href="https://BioRender.com/0q9m1bi">https://BioRender.com/0q9m1bi</ext-link>) and <xref rid="figS2_2" ref-type="fig">Figure 2–figure supplement 2</xref> (<ext-link ext-link-type="uri" xlink:href="https://BioRender.com/diopdjf">https://BioRender.com/diopdjf</ext-link>), and renderings in <xref rid="fig2" ref-type="fig">Figures 2</xref> and <xref rid="fig5" ref-type="fig">5</xref> were created using Solidworks.</p>
</sec>
<sec id="s4i2">
<title>Calculation of paw response latency with motion energy</title>
<p>Local motion energy was calculated inside a circular ROI (radius = 15 px) centered on the stimulation-side paw keypoint by taking absolute differences between consecutive frames, masking the ROI, suppressing values &lt;3 intensity units, and summing the remaining pixels. The ROI center was anchored to the DLC keypoint at the frame immediately before the nominal stimulation onset. The nominal stimulus time was refined per trial by locating the largest motion-energy peak within ±0.2 s of nominal onset; traces were then time-locked to this real onset and re-windowed from − 9.8 to +9.8 s, with the single-frame flash artifact at <italic>t</italic> = 0 set to zero. Motion-energy traces used for detection were denoised with a 3-sample median followed by a 7-sample Gaussian (<italic>σ</italic> = 2) before thresholding. Trials with threshold crossings in the 0– 1.5s window were not considered sufficiently idle. A trial was considered a response if the stimulation-paw motion energy first exceeded a fixed threshold (≥ 1000 summed units) within the analysis window of 1.5-9.8 s. Response latency was defined, for responding trials, as the time of the first threshold crossing within this window minus the refined onset time.</p>
</sec>
<sec id="s4i3">
<title>Calculation of paw response latency with pose estimation</title>
<p>We calculated the Euclidean distances for the paw keypoint during the trial window (− 2 to +10 s; optogenetic stimulus at <italic>t</italic> = 0) relative to its mean baseline coordinate (− 2 to 0 s). Analysis was conducted on the keypoint on the hind paw toes to reduce stimulation artifacts from light delivered to the center of the hind paw using coordinates with &gt;0.8 likelihood values. If the keypoint moved more than 3 pixels within the stimulation trial window the trial was classified as a response. For the responses, the latency was determined by taking the time where the movement first exceeds 3 pixels, relative to the stimulation onset time.</p>
</sec>
<sec id="s4i4">
<title>Calculation of speed</title>
<p>The estimated tail base coordinates were used to visualize trajectories in the open arena and maze. These estimated coordinates were used if the likelihood &gt;0.8 (open arena) and &gt;0.85 (maze). Tracking errors were removed when the Euclidean distance jumped &gt;30 pixels in a single frame and linear interpolation was performed using the 3 frames either side of the removed values. Speed was calculated by taking the difference in Euclidean distance (Δd) between frames as a function of the respective difference in frame times (Δt) and converted to mm/s using the scale factor calculated above. To reduce frame-to-frame jitter and suppress tracking noise while preserving changes in movement, the speed trace was smoothed using a rolling median filter with a window of 10 samples. For the maze, we calculated the speed (vigor) by capturing each ‘corridor run’ from the point the tail base entered the corridor to when it exited the corridor. Speed for the corridor run was calculated within this time window as above.</p>
</sec>
<sec id="s4i5">
<title>Calculation of movement state-dependence</title>
<p>Movement state clusters (fast-direct and slow-assess) were identified from tail-base speed and heading coherence in the 2-second window prior to stimulation. Speed was determined as Euclidean displacement divided by the frame interval, smoothed with a 10-frame rolling median, and the mean over the 2-second window was taken. Heading coherence was calculated from the frame-to-frame heading angle of the tail-base keypoint: headings were circularly smoothed by averaging unit vectors over a 10-frame window, and coherence was defined as the mean resultant length (<italic>R</italic>, 0–1) over the 2-second window. Plotting speed and coherence for the first stimulus hit in each trial revealed two discrete populations, consistent across all four mice. Gaussian mixture modeling assigned trials to two clusters whose speed and coherence differed significantly. Taking speed and coherence in the 2-second post-stimulation window allowed paired analysis within trials to evaluate how the behavioral change depends on its prior state.</p>
</sec>
</sec>
<sec id="s4j">
<title>Statistical analysis</title>
<p>Statistical analysis was performed in Python, with the SciPy, Statsmodels and Pingouin packages. Normality was determined using the Shapiro-Wilk normality test. The specific tests used for each comparison are detailed in the text. Statistical significance was considered as <italic>p</italic> &lt;0.05. Data are reported as mean <italic>±</italic> standard error of the mean (SEM) unless stated otherwise. The mouse was the experimental unit.</p>
</sec>
</sec>
</body>
<back>
<sec id="s9">
<title>Additional files</title>
<p>Supplementary file 1</p>
<p>Part lists required for the assembly of the optical system.</p>
<fig id="figS2_1" position="float" fig-type="figure">
<label>Figure 2—figure supplement 1.</label>
<caption><title>Spatial and temporal characterization of the closed-loop optical system.</title>
<p><bold>A</bold> Uniformity of laser spot area and optical power. Heatmaps of mean measurements taken from triplicate samples at 16 separate locations across the glass platform, and fit with a two-dimensional polynomial (area R<sup>2</sup> = 0.91; power R<sup>2</sup> = 0.75). <bold>B</bold> Galvanometer mirrors directed in a spiral formation across the glass platform. <bold>C</bold> The shift in the spatial calibration map was negligible as shown every week for 10 weeks during intensive use. Automatic remapping takes 30 minutes to complete. <bold>D</bold> The relative timings of the camera exposures (<italic>blue</italic>), mirror galvanometers (<italic>green</italic>) and laser (<italic>red</italic> ). The acquisition frame time is shown in <italic>gray</italic> with corresponding galvanometer mirror jumps and laser pulse occur around 80 ms later. <bold>E</bold> Histograms of the dwell time for hind paws spent in the swing and stance phases during locomotion. <bold>F</bold> Accuracy of the laser targeting the fore paws across the speed categories, which was limited by left-right confusion in the tracking of small bodyparts. This figure was created using <ext-link ext-link-type="uri" xlink:href="https://BioRender.com/diopdjf">BioRender.com</ext-link>.</p></caption>
<graphic xlink:href="606618v3_figS2_1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS2_2" position="float" fig-type="figure">
<label>Figure 2—figure supplement 2.</label>
<caption><title>Hardware and software information flow design.</title>
<p>Primary computer (C1) runs real-time pose estimation on the camera feed to predict multiple body part keypoints. These are converted to voltage signals at DAQ device (DAQ1), to control the galvanometer mirrors (GM) to target the laser spot coordinates. C1 also sends a trigger to DAQ1 to trigger the blue light laser or the infrared laser shutter via an Arduino UNO (Arduino 2). To generate blue light pulse trains following a trigger an Arduino was used (Arduino 1). The second computer (C2) interfaces with another DAQ device (DAQ2) to generate audio during experimental sessions. DAQ1 can also interface with DAQ2 to trigger audio depending on processor class conditions and for analog modulation of the blue light laser. The reward delivery system in <xref rid="fig4" ref-type="fig">Figure 4</xref> is controlled via two Arduinos (Arduino 3 and 4) interfacing with DAQ1.</p></caption>
<graphic xlink:href="606618v3_figS2_2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<table-wrap id="tblS1" orientation="portrait" position="float">
<label>Table S1.</label>
<caption><title>Optical components required for the assembly of the system.</title></caption>
<graphic xlink:href="606618v3_tblS1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tblS2" orientation="portrait" position="float">
<label>Table S2.</label>
<caption><title>Parts required for mounting optics in the system.</title></caption>
<graphic xlink:href="606618v3_tblS2.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tblS3" orientation="portrait" position="float">
<label>Table S3.</label>
<caption><title>Parts required for acquisition and control.</title></caption>
<graphic xlink:href="606618v3_tblS3.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<ack>
<title>Acknowledgements</title>
<p>We are grateful to Patrick Haggard and Andrew MacAskill for their comments on the initial manuscript. This work was supported a Sir Henry Dale Fellowship jointly funded by the Wellcome Trust and the Royal Society (109372/Z/15/Z) and funding from the Medical Research Council (MR/N013867/1).</p>
</ack>
<sec id="additional-info" sec-type="additional-information">
<title>Additional information</title>
<sec id="das" sec-type="data-availability">
<title>Data availability</title>
<p>The manuscript is a Tools and Resources study that provides a new method. Code to use this method is openly accessible at <ext-link ext-link-type="uri" xlink:href="https://github.com/browne-lab/closed-loop-somatosensory-stimulation">https://github.com/browne-lab/closed-loop-somatosensory-stimulation</ext-link></p>
</sec>
<sec id="s7">
<title>Materials availability</title>
<p>System configurations will be made available upon reasonable request to L.E.B.</p>
</sec>
<sec id="s5">
<title>Author contributions</title>
<p>L.E.B. supervised and conceptualized the project. L.E.B and I.P. designed the experiments, built the closed-loop system, and wrote code. Q.G. set up the reward systems. A.S-P supported the initial experiments. I.P. conducted the experiments. I.P and L.E.B. analyzed the data and wrote the manuscript. All authors reviewed the manuscript.</p>
</sec>

</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Ashley L.</given-names> <surname>Juavinett</surname></string-name>, <string-name><given-names>George</given-names> <surname>Bekheet</surname></string-name>, and <string-name><given-names>Anne K.</given-names> <surname>Churchland</surname></string-name></person-group>. <article-title>Chronically implanted neuropixels probes enable high-yield recordings in freely moving mice</article-title>. <source>eLife</source>, <volume>8</volume>:<elocation-id>e47188</elocation-id>, <year>2019</year>. <pub-id pub-id-type="doi">10.7554/eLife.47188</pub-id></mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Sandeep Robert</given-names> <surname>Datta</surname></string-name>, <string-name><given-names>David J</given-names> <surname>Anderson</surname></string-name>, <string-name><given-names>Kristin</given-names> <surname>Branson</surname></string-name>, <string-name><given-names>Pietro</given-names> <surname>Perona</surname></string-name>, and <string-name><given-names>Andrew</given-names> <surname>Leifer</surname></string-name></person-group>. <article-title>Computational Neuroethology: A Call to Action</article-title>. <source>Neuron</source>, <volume>104</volume>(<issue>1</issue>):<fpage>11</fpage>–<lpage>24</lpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Emily Jane</given-names> <surname>Dennis</surname></string-name>, <string-name><given-names>Ahmed</given-names> <surname>El Hady</surname></string-name>, <string-name><given-names>Angie</given-names> <surname>Michaiel</surname></string-name>, <string-name><given-names>Ann</given-names> <surname>Clemens</surname></string-name>, <string-name><given-names>Dougal R. Gowan</given-names> <surname>Tervo</surname></string-name>, <string-name><given-names>Jakob</given-names> <surname>Voigts</surname></string-name>, and <string-name><given-names>Sandeep Robert</given-names> <surname>Datta</surname></string-name></person-group>. <article-title>Systems neuroscience of natural behaviors in rodents</article-title>. <source>Journal of Neuroscience</source>, <volume>41</volume>(<issue>5</issue>):<fpage>911</fpage>– <lpage>919</lpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Matthew</given-names> <surname>Rosenberg</surname></string-name>, <string-name><given-names>Tony</given-names> <surname>Zhang</surname></string-name>, <string-name><given-names>Pietro</given-names> <surname>Perona</surname></string-name>, and <string-name><given-names>Markus</given-names> <surname>Meister</surname></string-name></person-group>. <article-title>Mice in a labyrinth show rapid learning, sudden insight, and efficient exploration</article-title>. <source>eLife</source>, <volume>10</volume>:<elocation-id>e66175</elocation-id>, <year>2021</year>. <pub-id pub-id-type="doi">10.7554/eLife.66175</pub-id></mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Weijian</given-names> <surname>Zong</surname></string-name>, <string-name><given-names>Horst A.</given-names> <surname>Obenhaus</surname></string-name>, <string-name><given-names>Emilie R.</given-names> <surname>Skytøen</surname></string-name>, <string-name><given-names>Hanna</given-names> <surname>Eneqvist</surname></string-name>, <string-name><given-names>Nienke L.</given-names> <surname>de Jong</surname></string-name>, <string-name><given-names>Ruben</given-names> <surname>Vale</surname></string-name>, <string-name><given-names>Marina R.</given-names> <surname>Jorge</surname></string-name>, <string-name><given-names>May Britt</given-names> <surname>Moser</surname></string-name>, and <string-name><given-names>Edvard I.</given-names> <surname>Moser</surname></string-name></person-group>. <article-title>Large-scale two-photon calcium imaging in freely moving mice</article-title>. <source>Cell</source>, <volume>185</volume>(<issue>7</issue>):<fpage>1240</fpage>–<lpage>1256</lpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Longzhen</given-names> <surname>Cheng</surname></string-name>, <string-name><given-names>Bo</given-names> <surname>Duan</surname></string-name>, <string-name><given-names>Tianwen</given-names> <surname>Huang</surname></string-name>, <string-name><given-names>Yan</given-names> <surname>Zhang</surname></string-name>, <string-name><given-names>Yangyang</given-names> <surname>Chen</surname></string-name>, <string-name><given-names>Olivier</given-names> <surname>Britz</surname></string-name>, <string-name><given-names>Lidia</given-names> <surname>Garcia-Campmany</surname></string-name>, <string-name><given-names>Xiangyu</given-names> <surname>Ren</surname></string-name>, <string-name><given-names>Linh</given-names> <surname>Vong</surname></string-name>, <string-name><given-names>Bradford B.</given-names> <surname>Lowell</surname></string-name>, <string-name><given-names>Martyn</given-names> <surname>Goulding</surname></string-name>, <string-name><given-names>Yun</given-names> <surname>Wang</surname></string-name>, and <string-name><given-names>Qiufu</given-names> <surname>Ma</surname></string-name></person-group>. <article-title>Identification of spinal circuits involved in touch-evoked dynamic mechanical pain</article-title>. <source>Nature Neuroscience</source>, <volume>20</volume>(<issue>6</issue>):<fpage>804</fpage>–<lpage>814</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Vijayan</given-names> <surname>Gangadharan</surname></string-name>, <string-name><given-names>Hongwei</given-names> <surname>Zheng</surname></string-name>, <string-name><given-names>Francisco J.</given-names> <surname>Taberner</surname></string-name>, <string-name><given-names>Jonathan</given-names> <surname>Landry</surname></string-name>, <string-name><given-names>Timo A.</given-names> <surname>Nees</surname></string-name>, <string-name><given-names>Jelena</given-names> <surname>Pistolic</surname></string-name>, <string-name><given-names>Nitin</given-names> <surname>Agarwal</surname></string-name>, <string-name><surname>Deepitha</surname> <given-names>Männich</given-names></string-name>, <string-name><given-names>Vladimir</given-names> <surname>Benes</surname></string-name>, <string-name><given-names>Moritz</given-names> <surname>Helmstaedter</surname></string-name>, <string-name><given-names>Björn</given-names> <surname>Ommer</surname></string-name>, <string-name><given-names>Stefan G.</given-names> <surname>Lechner</surname></string-name>, <string-name><given-names>Thomas</given-names> <surname>Kuner</surname></string-name>, and <string-name><given-names>Rohini</given-names> <surname>Kuner</surname></string-name></person-group>. <article-title>Neuropathic pain caused by miswiring and abnormal end organ targeting</article-title>. <source>Nature</source>, <volume>606</volume>(<issue>7912</issue>):<fpage>136</fpage>– <lpage>145</lpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Christopher J.</given-names> <surname>Labuda</surname></string-name> and <string-name><given-names>Perry N.</given-names> <surname>Fuchs</surname></string-name></person-group>. <article-title>A behavioral test paradigm to measure the aversive quality of inflammatory and neuropathic pain in rats</article-title>. <source>Experimental Neurology</source>, <volume>163</volume>(<issue>2</issue>):<fpage>490</fpage>–<lpage>494</lpage>, <year>2000</year>.</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Megan L.</given-names> <surname>Uhelski</surname></string-name>, <string-name><given-names>Samara A.</given-names> <surname>Morris-Bobzean</surname></string-name>, <string-name><given-names>Torry S.</given-names> <surname>Dennis</surname></string-name>, <string-name><given-names>Linda I.</given-names> <surname>Perrotti</surname></string-name>, and <string-name><given-names>Perry N.</given-names> <surname>Fuchs</surname></string-name></person-group>. <article-title>Evaluating underlying neuronal activity associated with escape/avoidance behavior in response to noxious stimulation in adult rats</article-title>. <source>Brain Research</source>, <volume>1433</volume>:<fpage>56</fpage>–<lpage>61</lpage>, <year>2012</year>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Ara</given-names> <surname>Schorscher-Petcu</surname></string-name>, Flóra Takács, and <string-name><given-names>Liam E</given-names> <surname>Browne</surname></string-name></person-group>. <article-title>Scanned optogenetic control of mammalian somatosensory input to map input-specific behavioral outputs</article-title>. <source>eLife</source>, <volume>10</volume>:<elocation-id>e62026</elocation-id>, <year>2021</year>. <pub-id pub-id-type="doi">10.7554/eLife.62026</pub-id></mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Gary A</given-names> <surname>Kane</surname></string-name>, <string-name><given-names>Gonçalo</given-names> <surname>Lopes</surname></string-name>, <string-name><given-names>Jonny L</given-names> <surname>Saunders</surname></string-name>, <string-name><given-names>Alexander</given-names> <surname>Mathis</surname></string-name>, and <string-name><given-names>Mackenzie W</given-names> <surname>Mathis</surname></string-name></person-group>. <article-title>Real-time, low-latency closed-loop feedback using markerless posture tracking</article-title>. <source>eLife</source>, <volume>9</volume>:<elocation-id>e61909</elocation-id>, <year>2020</year>. <pub-id pub-id-type="doi">10.7554/eLife.61909</pub-id></mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Liam E.</given-names> <surname>Browne</surname></string-name>, <string-name><given-names>Alban</given-names> <surname>Latremoliere</surname></string-name>, <string-name><given-names>Brendan P.</given-names> <surname>Lehnert</surname></string-name>, <string-name><given-names>Alyssa</given-names> <surname>Grantham</surname></string-name>, <string-name><given-names>Catherine</given-names> <surname>Ward</surname></string-name>, <string-name><given-names>Chloe</given-names> <surname>Alexandre</surname></string-name>, <string-name><given-names>Michael</given-names> <surname>Costigan</surname></string-name>, <string-name><given-names>Frédéric</given-names> <surname>Michoud</surname></string-name>, <string-name><given-names>David P.</given-names> <surname>Roberson</surname></string-name>, <string-name><given-names>David D.</given-names> <surname>Ginty</surname></string-name>, and <string-name><given-names>Clifford J.</given-names> <surname>Woolf</surname></string-name></person-group>. <article-title>Time-Resolved Fast Mammalian Behavior Reveals the Complexity of Protective Pain Responses</article-title>. <source>Cell Reports</source>, <volume>20</volume>(<issue>1</issue>):<fpage>89</fpage>–<lpage>98</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Christopher J.</given-names> <surname>Black</surname></string-name>, <string-name><given-names>Anusha B.</given-names> <surname>Allawala</surname></string-name>, <string-name><given-names>Kiernan</given-names> <surname>Bloye</surname></string-name>, <string-name><given-names>Kevin N.</given-names> <surname>Vanent</surname></string-name>, <string-name><given-names>Muhammad M.</given-names> <surname>Edhi</surname></string-name>, <string-name><given-names>Carl Y.</given-names> <surname>Saab</surname></string-name>, and <string-name><given-names>David A.</given-names> <surname>Borton</surname></string-name></person-group>. <article-title>Automated and rapid self-report of nociception in transgenic mice</article-title>. <source>Scientific Reports</source>, <volume>10</volume>(<issue>1</issue>):<fpage>13215</fpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Dvir</given-names> <surname>Blivis</surname></string-name>, <string-name><given-names>Gal</given-names> <surname>Haspel</surname></string-name>, <string-name><given-names>Philip Z.</given-names> <surname>Mannes</surname></string-name>, Michael <string-name><given-names>J.</given-names> <surname>O’Donovan</surname></string-name>, and <string-name><given-names>Michael J.</given-names> <surname>Iadarola</surname></string-name></person-group>. <article-title>Identification of a novel spinal nociceptive-motor gate control for aδ pain stimuli in rats</article-title>. <source>eLife</source>, <volume>6</volume>:<elocation-id>e23584</elocation-id>, <year>2017</year>. <pub-id pub-id-type="doi">10.7554/eLife.23584</pub-id></mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Julia</given-names> <surname>Pai</surname></string-name>, <string-name><given-names>Takaya</given-names> <surname>Ogasawara</surname></string-name>, <string-name><given-names>Ethan S.</given-names> <surname>Bromberg-Martin</surname></string-name>, <string-name><given-names>Kei</given-names> <surname>Ogasawara</surname></string-name>, <string-name><given-names>Robert W.</given-names> <surname>Gereau</surname></string-name>, and <string-name><given-names>Ilya E.</given-names> <surname>Monosov</surname></string-name></person-group>. <article-title>Laser stimulation of the skin for quantitative study of decision-making and motivation</article-title>. <source>Cell Reports Methods</source>, <volume>2</volume>(<issue>9</issue>):<fpage>100296</fpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Christina</given-names> <surname>Buetfering</surname></string-name>, <string-name><given-names>Zihui</given-names> <surname>Zhang</surname></string-name>, <string-name><given-names>Margarita</given-names> <surname>Pitsiani</surname></string-name>, <string-name><given-names>John</given-names> <surname>Smallridge</surname></string-name>, <string-name><given-names>Ellen</given-names> <surname>Boven</surname></string-name>, <string-name><given-names>Sacha</given-names> <surname>McElligott</surname></string-name>, and <string-name><given-names>Michael</given-names> <surname>Häusser</surname></string-name></person-group>. <article-title>Behaviorally relevant decision coding in primary somatosensory cortex neurons</article-title>. <source>Nature Neuroscience</source>, <volume>25</volume>(<issue>9</issue>):<fpage>1225</fpage>–<lpage>1236</lpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Zengcai V.</given-names> <surname>Guo</surname></string-name>, <string-name><given-names>Nuo</given-names> <surname>Li</surname></string-name>, <string-name><given-names>Daniel</given-names> <surname>Huber</surname></string-name>, <string-name><given-names>Eran</given-names> <surname>Ophir</surname></string-name>, <string-name><given-names>Diego</given-names> <surname>Gutnisky</surname></string-name>, <string-name><given-names>Jonathan T.</given-names> <surname>Ting</surname></string-name>, <string-name><given-names>Guoping</given-names> <surname>Feng</surname></string-name>, and <string-name><given-names>Karel</given-names> <surname>Svoboda</surname></string-name></person-group>. <article-title>Flow of cortical activity underlying a tactile decision in mice</article-title>. <source>Neuron</source>, <volume>81</volume>(<issue>1</issue>):<fpage>179</fpage>–<lpage>194</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Y. Kate</given-names> <surname>Hong</surname></string-name>, <string-name><given-names>Clay O.</given-names> <surname>Lacefield</surname></string-name>, <string-name><given-names>Chris C.</given-names> <surname>Rodgers</surname></string-name>, and <string-name><given-names>Randy M.</given-names> <surname>Bruno</surname></string-name></person-group>. <article-title>Sensation, movement and learning in the absence of barrel cortex</article-title>. <source>Nature</source>, <volume>561</volume>(<issue>7724</issue>):<fpage>542</fpage>–<lpage>546</lpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Dario</given-names> <surname>Campagner</surname></string-name>, <string-name><given-names>Mathew H.</given-names> <surname>Evans</surname></string-name>, <string-name><given-names>Katarina</given-names> <surname>Chlebikova</surname></string-name>, <string-name><given-names>Andrea</given-names> <surname>Colins-Rodriguez</surname></string-name>, <string-name><given-names>Michaela S.E.</given-names> <surname>Loft</surname></string-name>, <string-name><given-names>Sarah</given-names> <surname>Fox</surname></string-name>, <string-name><given-names>David</given-names> <surname>Pettifer</surname></string-name>, <string-name><given-names>Mark D.</given-names> <surname>Humphries</surname></string-name>, <string-name><given-names>Karel</given-names> <surname>Svoboda</surname></string-name>, and <string-name><given-names>Rasmus S.</given-names> <surname>Petersen</surname></string-name></person-group>. <article-title>Prediction of choice from competing mechanosensory and choice-memory cues during active tactile decision making</article-title>. <source>Journal of Neuroscience</source>, <volume>39</volume>(<issue>20</issue>):<fpage>3921</fpage>–<lpage>3933</lpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Vahid</given-names> <surname>Esmaeili</surname></string-name>, <string-name><given-names>Keita</given-names> <surname>Tamura</surname></string-name>, <string-name><given-names>Georgios</given-names> <surname>Foustoukos</surname></string-name>, <string-name><given-names>Anastasiia</given-names> <surname>Oryshchuk</surname></string-name>, <string-name><given-names>Sylvain</given-names> <surname>Crochet</surname></string-name>, and <string-name><given-names>Carl CH</given-names> <surname>Petersen</surname></string-name></person-group>. <article-title>Cortical circuits for transforming whisker sensation into goal-directed licking</article-title>. <source>Current Opinion in Neurobiology</source>, <volume>65</volume>:<fpage>38</fpage>– <lpage>48</lpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Fred</given-names> <surname>Schwaller</surname></string-name>, <string-name><given-names>Valérie</given-names> <surname>Bégay</surname></string-name>, <string-name><given-names>Gema</given-names> <surname>García-García</surname></string-name>, <string-name><given-names>Francisco J.</given-names> <surname>Taberner</surname></string-name>, <string-name><given-names>Rabih</given-names> <surname>Moshourab</surname></string-name>, <string-name><given-names>Brennan</given-names> <surname>McDonald</surname></string-name>, <string-name><given-names>Trevor</given-names> <surname>Docter</surname></string-name>, <string-name><given-names>Johannes</given-names> <surname>Kühnemund</surname></string-name>, <string-name><given-names>Julia</given-names> <surname>Ojeda-Alonso</surname></string-name>, <string-name><given-names>Ricardo</given-names> <surname>Paricio-Montesinos</surname></string-name>, <string-name><given-names>Stefan G.</given-names> <surname>Lechner</surname></string-name>, <string-name><given-names>James F.A.</given-names> <surname>Poulet</surname></string-name>, <string-name><given-names>Jose M.</given-names> <surname>Millan</surname></string-name>, and <string-name><given-names>Gary R.</given-names> <surname>Lewin</surname></string-name></person-group>. <article-title>USH2A is a Meissner’s corpuscle protein necessary for normal vibration sensing in mice and humans</article-title>. <source>Nature Neuroscience</source>, <volume>24</volume>(<issue>1</issue>):<fpage>74</fpage>–<lpage>81</lpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Alan J.</given-names> <surname>Emanuel</surname></string-name>, <string-name><given-names>Brendan P.</given-names> <surname>Lehnert</surname></string-name>, <string-name><given-names>Stefano</given-names> <surname>Panzeri</surname></string-name>, <string-name><given-names>Christopher D.</given-names> <surname>Harvey</surname></string-name>, and <string-name><given-names>David D.</given-names> <surname>Ginty</surname></string-name></person-group>. <article-title>Cortical responses to touch reflect subcortical integration of LTMR signals</article-title>. <source>Nature</source>, <volume>600</volume>(<issue>7890</issue>):<fpage>680</fpage>–<lpage>685</lpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Zheng</given-names> <surname>Gan</surname></string-name>, <string-name><given-names>Han</given-names> <surname>Li</surname></string-name>, <string-name><given-names>Paul Vincent</given-names> <surname>Naser</surname></string-name>, <string-name><given-names>Manfred Josef</given-names> <surname>Oswald</surname></string-name>, and <string-name><given-names>Rohini</given-names> <surname>Kuner</surname></string-name></person-group>. <article-title>Suppression of neuropathic pain and comorbidities by recurrent cycles of repetitive transcranial direct current motor cortex stimulation in mice</article-title>. <source>Scientific Reports</source>, <volume>11</volume>(<issue>1</issue>):<fpage>9735</fpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Michael J.</given-names> <surname>Caterina</surname></string-name>, <string-name><given-names>Mark A.</given-names> <surname>Schumacher</surname></string-name>, <string-name><given-names>Makoto</given-names> <surname>Tominaga</surname></string-name>, <string-name><given-names>Tobias A.</given-names> <surname>Rosen</surname></string-name>, <string-name><given-names>Jon D.</given-names> <surname>Levine</surname></string-name>, and <string-name><given-names>David</given-names> <surname>Julius</surname></string-name></person-group>. <article-title>The capsaicin receptor: A heat-activated ion channel in the pain pathway</article-title>. <source>Nature</source>, <volume>389</volume>(<issue>6653</issue>):<fpage>816</fpage>–<lpage>824</lpage>, <year>1997</year>.</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Isabelle</given-names> <surname>Decosterd</surname></string-name> and <string-name><given-names>Clifford J</given-names> <surname>Woolf</surname></string-name></person-group>. <article-title>Spared nerve injury: an animal model of persistent peripheral neuropathic pain</article-title>. <source>Pain</source>, <volume>87</volume>(<issue>2</issue>):<fpage>149</fpage>–<lpage>158</lpage>, <year>2000</year>.</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Isaac M.</given-names> <surname>Chiu</surname></string-name>, <string-name><given-names>Balthasar A.</given-names> <surname>Heesters</surname></string-name>, <string-name><given-names>Nader</given-names> <surname>Ghasemlou</surname></string-name>, <string-name><given-names>Christian A.</given-names> <surname>Von Hehn</surname></string-name>, <string-name><given-names>Fan</given-names> <surname>Zhao</surname></string-name>, <string-name><given-names>Johnathan</given-names> <surname>Tran</surname></string-name>, <string-name><given-names>Brian</given-names> <surname>Wainger</surname></string-name>, <string-name><given-names>Amanda</given-names> <surname>Strominger</surname></string-name>, <string-name><given-names>Sriya</given-names> <surname>Muralidharan</surname></string-name>, <string-name><given-names>Alexander R.</given-names> <surname>Horswill</surname></string-name>, <string-name><given-names>Juliane Bubeck</given-names> <surname>Wardenburg</surname></string-name>, <string-name><given-names>Sun Wook</given-names> <surname>Hwang</surname></string-name>, <string-name><given-names>Michael C.</given-names> <surname>Carroll</surname></string-name>, and <string-name><given-names>Clifford J.</given-names> <surname>Woolf</surname></string-name></person-group>. <article-title>Bacteria activate sensory neurons that modulate pain and inflammation</article-title>. <source>Nature</source>, <volume>501</volume>(<issue>7465</issue>):<fpage>52</fpage>–<lpage>57</lpage>, <year>2013</year>.</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Sanjeev S.</given-names> <surname>Ranade</surname></string-name>, <string-name><given-names>Seung Hyun</given-names> <surname>Woo</surname></string-name>, <string-name><given-names>Adrienne E.</given-names> <surname>Dubin</surname></string-name>, <string-name><given-names>Rabih A.</given-names> <surname>Moshourab</surname></string-name>, <string-name><given-names>Christiane</given-names> <surname>Wetzel</surname></string-name>, <string-name><given-names>Matt</given-names> <surname>Petrus</surname></string-name>, <string-name><given-names>Jayanti</given-names> <surname>Mathur</surname></string-name>, <string-name><given-names>Valérie</given-names> <surname>Bégay</surname></string-name>, <string-name><given-names>Bertrand</given-names> <surname>Coste</surname></string-name>, <string-name><given-names>James</given-names> <surname>Mainquist</surname></string-name>, <string-name><given-names>A. J.</given-names> <surname>Wilson</surname></string-name>, <string-name><given-names>Allain G.</given-names> <surname>Francisco</surname></string-name>, <string-name><given-names>Kritika</given-names> <surname>Reddy</surname></string-name>, <string-name><given-names>Zhaozhu</given-names> <surname>Qiu</surname></string-name>, <string-name><given-names>John N.</given-names> <surname>Wood</surname></string-name>, <string-name><given-names>Gary R.</given-names> <surname>Lewin</surname></string-name>, and <string-name><given-names>Ardem</given-names> <surname>Patapoutian</surname></string-name></person-group>. <article-title>Piezo2 is the major transducer of mechanical forces for touch sensation in mice</article-title>. <source>Nature</source>, <volume>516</volume>(<issue>729</issue>):<fpage>121</fpage>–<lpage>125</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Jamie K.</given-names> <surname>Moy</surname></string-name>, <string-name><given-names>Jasper L.</given-names> <surname>Kuhn</surname></string-name>, <string-name><given-names>Thomas A.</given-names> <surname>Szabo-Pardi</surname></string-name>, <string-name><given-names>Grishma</given-names> <surname>Pradhan</surname></string-name>, and <string-name><given-names>Theodore J.</given-names> <surname>Price</surname></string-name></person-group>. <article-title>eIF4E phosphorylation regulates ongoing pain, independently of inflammation, and hyperalgesic priming in the mouse CFA model</article-title>. <source>Neurobiology of Pain</source>, <volume>4</volume>:<fpage>45</fpage>–<lpage>50</lpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Gregory</given-names> <surname>Corder</surname></string-name>, <string-name><given-names>Biafra</given-names> <surname>Ahanonu</surname></string-name>, <string-name><given-names>Benjamin F.</given-names> <surname>Grewe</surname></string-name>, <string-name><given-names>Dong</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>Mark J.</given-names> <surname>Schnitzer</surname></string-name>, and <string-name><given-names>Grégory</given-names> <surname>Scherrer</surname></string-name></person-group>. <article-title>An amygdalar neural ensemble that encodes the unpleasantness of pain</article-title>. <source>Science</source>, <volume>363</volume>(<issue>6424</issue>):<fpage>276</fpage>–<lpage>281</lpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Kieran A.</given-names> <surname>Boyle</surname></string-name>, <string-name><given-names>Mark A.</given-names> <surname>Gradwell</surname></string-name>, <string-name><given-names>Toshiharu</given-names> <surname>Yasaka</surname></string-name>, <string-name><given-names>Allen C.</given-names> <surname>Dickie</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Polgár</surname></string-name>, <string-name><given-names>Robert P.</given-names> <surname>Ganley</surname></string-name>, <string-name><given-names>Desmond P.H.</given-names> <surname>Orr</surname></string-name>, <string-name><given-names>Masahiko</given-names> <surname>Watanabe</surname></string-name>, <string-name><given-names>Victoria E.</given-names> <surname>Abraira</surname></string-name>, <string-name><given-names>Emily D.</given-names> <surname>Kuehn</surname></string-name>, <string-name><given-names>Amanda L.</given-names> <surname>Zimmerman</surname></string-name>, <string-name><given-names>David D.</given-names> <surname>Ginty</surname></string-name>, <string-name><given-names>Robert J.</given-names> <surname>Callister</surname></string-name>, <string-name><given-names>Brett A.</given-names> <surname>Graham</surname></string-name>, and <string-name><given-names>David I.</given-names> <surname>Hughes</surname></string-name></person-group>. <article-title>Defining a Spinal Microcircuit that Gates Myelinated Afferent Input: Implications for Tactile Allodynia</article-title>. <source>Cell Reports</source>, <volume>28</volume>(<issue>2</issue>):<fpage>526</fpage>–<lpage>540</lpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Dina L.</given-names> <surname>Juarez-Salinas</surname></string-name>, <string-name><given-names>Joao M.</given-names> <surname>Braz</surname></string-name>, <string-name><given-names>Alexander</given-names> <surname>Etlin</surname></string-name>, <string-name><given-names>Steven</given-names> <surname>Gee</surname></string-name>, <string-name><given-names>Vikaas</given-names> <surname>Sohal</surname></string-name>, and <string-name><given-names>Allan I.</given-names> <surname>Basbaum</surname></string-name></person-group>. <article-title>GABAergic cell transplants in the anterior cingulate cortex reduce neuropathic pain aversiveness</article-title>. <source>Brain</source>, <volume>142</volume>(<issue>9</issue>):<fpage>2655</fpage>–<lpage>2669</lpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Seungwon</given-names> <surname>Choi</surname></string-name>, <string-name><given-names>Junichi</given-names> <surname>Hachisuka</surname></string-name>, <string-name><given-names>Matthew A.</given-names> <surname>Brett</surname></string-name>, <string-name><given-names>Alexandra R.</given-names> <surname>Magee</surname></string-name>, <string-name><given-names>Yu</given-names> <surname>Omori</surname></string-name>, <string-name><given-names>Noor ul Aine</given-names> <surname>Iqbal</surname></string-name>, <string-name><given-names>Dawei</given-names> <surname>Zhang</surname></string-name>, <string-name><given-names>Michelle M.</given-names> <surname>DeLisle</surname></string-name>, <string-name><given-names>Rachel L.</given-names> <surname>Wolfson</surname></string-name>, <string-name><given-names>Ling</given-names> <surname>Bai</surname></string-name>, <string-name><given-names>Celine</given-names> <surname>Santiago</surname></string-name>, <string-name><given-names>Shiaoching</given-names> <surname>Gong</surname></string-name>, <string-name><given-names>Martyn</given-names> <surname>Goulding</surname></string-name>, <string-name><given-names>Nathaniel</given-names> <surname>Heintz</surname></string-name>, <string-name><given-names>H. Richard</given-names> <surname>Koerber</surname></string-name>, <string-name><given-names>Sarah E.</given-names> <surname>Ross</surname></string-name>, and <string-name><given-names>David D.</given-names> <surname>Ginty</surname></string-name></person-group>. <article-title>Parallel ascending spinal pathways for affective touch and pain</article-title>. <source>Nature</source>, <volume>587</volume>(<issue>7833</issue>):<fpage>258</fpage>–<lpage>263</lpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Graziana</given-names> <surname>Gatto</surname></string-name>, <string-name><given-names>Steeve</given-names> <surname>Bourane</surname></string-name>, <string-name><given-names>Xiangyu</given-names> <surname>Ren</surname></string-name>, <string-name><given-names>Stefania</given-names> <surname>Di Costanzo</surname></string-name>, <string-name><given-names>Peter K.</given-names> <surname>Fenton</surname></string-name>, <string-name><given-names>Priyabrata</given-names> <surname>Halder</surname></string-name>, <string-name><given-names>Rebecca P.</given-names> <surname>Seal</surname></string-name>, and <string-name><given-names>Martyn D.</given-names> <surname>Goulding</surname></string-name></person-group>. <article-title>A Functional Topographic Map for Spinal Sensorimotor Reflexes</article-title>. <source>Neuron</source>, <volume>109</volume>(<issue>1</issue>):<fpage>91</fpage>– <lpage>104</lpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Robert A.R.</given-names> <surname>Drake</surname></string-name>, <string-name><given-names>Kenneth A.</given-names> <surname>Steel</surname></string-name>, <string-name><given-names>Richard</given-names> <surname>Apps</surname></string-name>, <string-name><given-names>Bridget M.</given-names> <surname>Lumb</surname></string-name>, and <string-name><given-names>Anthony E.</given-names> <surname>Pickering</surname></string-name></person-group>. <article-title>Loss of cortical control over the descending pain modulatory system determines the development of the neuropathic pain state in rats</article-title>. <source>eLife</source>, <volume>10</volume>:<elocation-id>e65156</elocation-id>, <year>2021</year>. <pub-id pub-id-type="doi">10.7554/eLife.65156</pub-id></mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Steven J.</given-names> <surname>Middleton</surname></string-name>, <string-name><given-names>Irene</given-names> <surname>Perini</surname></string-name>, <string-name><given-names>Andreas C.</given-names> <surname>Themistocleous</surname></string-name>, <string-name><given-names>Greg A.</given-names> <surname>Weir</surname></string-name>, <string-name><given-names>Kirsty</given-names> <surname>McCann</surname></string-name>, <string-name><given-names>Allison M.</given-names> <surname>Barry</surname></string-name>, <string-name><given-names>Andrew</given-names> <surname>Marshall</surname></string-name>, <string-name><given-names>Michael</given-names> <surname>Lee</surname></string-name>, <string-name><given-names>Leah M.</given-names> <surname>Mayo</surname></string-name>, <string-name><given-names>Manon</given-names> <surname>Bohic</surname></string-name>, <string-name><given-names>Georgios</given-names> <surname>Baskozos</surname></string-name>, <string-name><given-names>India</given-names> <surname>Morrison</surname></string-name>, Line <string-name><given-names>S.</given-names> <surname>Löken</surname></string-name>, <string-name><given-names>Sarah</given-names> <surname>McIntyre</surname></string-name>, <string-name><given-names>Saad S.</given-names> <surname>Nagi</surname></string-name>, <string-name><given-names>Roland</given-names> <surname>Staud</surname></string-name>, <string-name><given-names>Isac</given-names> <surname>Sehlstedt</surname></string-name>, <string-name><given-names>Richard D.</given-names> <surname>Johnson</surname></string-name>, <string-name><given-names>Johan</given-names> <surname>Wessberg</surname></string-name>, <string-name><given-names>John N.</given-names> <surname>Wood</surname></string-name>, <string-name><given-names>Christopher G.</given-names> <surname>Woods</surname></string-name>, <string-name><given-names>Aziz</given-names> <surname>Moqrich</surname></string-name>, <string-name><given-names>Håkan</given-names> <surname>Olausson</surname></string-name>, and <string-name><given-names>David L.</given-names> <surname>Bennett</surname></string-name></person-group>. <article-title>Nav1.7 is required for normal C-low threshold mechanoreceptor function in humans and mice</article-title>. <source>Brain</source>, <volume>145</volume>(<issue>10</issue>):<fpage>3637</fpage>–<lpage>3653</lpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Alexandra S.</given-names> <surname>Klein</surname></string-name>, <string-name><given-names>Nate</given-names> <surname>Dolensek</surname></string-name>, <string-name><given-names>Caroline</given-names> <surname>Weiand</surname></string-name>, and <string-name><given-names>Nadine</given-names> <surname>Gogolla</surname></string-name></person-group>. <article-title>Fear balance is maintained by bodily feedback to the insular cortex in mice</article-title>. <source>Science</source>, <volume>374</volume>(<issue>6570</issue>):<fpage>1010</fpage>–<lpage>1015</lpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Valeria</given-names> <surname>Bonapersona</surname></string-name>, <string-name><given-names>Heike</given-names> <surname>Schuler</surname></string-name>, <string-name><given-names>Ruth</given-names> <surname>Damsteegt</surname></string-name>, <string-name><given-names>Youri</given-names> <surname>Adolfs</surname></string-name>, <string-name><given-names>R. Jeroen</given-names> <surname>Pasterkamp</surname></string-name>, <string-name><given-names>Martijn P.</given-names> <surname>van den Heuvel</surname></string-name>, <string-name><given-names>Marian</given-names> <surname>Joëls</surname></string-name>, and <string-name><given-names>R. Angela</given-names> <surname>Sarabdjitsingh</surname></string-name></person-group>. <article-title>The mouse brain after foot shock in four dimensions: Temporal dynamics at a single-cell resolution</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>119</volume>(<issue>8</issue>):<fpage>e2114002119</fpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Christopher</given-names> <surname>Dedek</surname></string-name>, <string-name><given-names>Mehdi A.</given-names> <surname>Azadgoleh</surname></string-name>, and <string-name><given-names>Steven A.</given-names> <surname>Prescott</surname></string-name></person-group>. <article-title>Reproducible and fully automated testing of nocifensive behavior in mice</article-title>. <source>Cell Reports Methods</source>, <volume>3</volume>:<fpage>100650</fpage>, <year>2023</year>.</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>Jacqueline A</given-names> <surname>Iredale</surname></string-name>, <string-name><given-names>Amy J</given-names> <surname>Pearl</surname></string-name>, <string-name><given-names>Robert J</given-names> <surname>Callister</surname></string-name>, <string-name><given-names>Christopher V</given-names> <surname>Dayas</surname></string-name>, <string-name><given-names>Elizabeth E</given-names> <surname>Manning</surname></string-name>, and <string-name><given-names>Brett A</given-names> <surname>Graham</surname></string-name></person-group>. <article-title>‘Optical Von-Frey’ method to determine nociceptive thresholds: a novel paradigm for preclinical pain assessment and analgesic screening</article-title>. <source>bioRxiv</source>, page 2023.11.02.565390, 1 <year>2023</year>.</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Justin</given-names> <surname>Burdge</surname></string-name>, <string-name><given-names>Anissa</given-names> <surname>Jhumka</surname></string-name>, <string-name><given-names>Simon</given-names> <surname>Ogundare</surname></string-name>, <string-name><given-names>Nicholas</given-names> <surname>Baer</surname></string-name>, <string-name><given-names>Sasha</given-names> <surname>Fulton</surname></string-name>, <string-name><given-names>Brittany</given-names> <surname>Bistis</surname></string-name>, <string-name><given-names>William</given-names> <surname>Foster</surname></string-name>, <string-name><given-names>Andre</given-names> <surname>Toussaint</surname></string-name>, <string-name><given-names>Miao</given-names> <surname>Li</surname></string-name>, <string-name><given-names>Yosuke M</given-names> <surname>Morizawa</surname></string-name>, <string-name><given-names>Leah</given-names> <surname>Yadessa</surname></string-name>, <string-name><given-names>Ashar</given-names> <surname>Khan</surname></string-name>, <string-name><given-names>Abednego</given-names> <surname>Delinois</surname></string-name>, <string-name><given-names>Wadzanayi</given-names> <surname>Mayiseni</surname></string-name>, <string-name><given-names>Noah</given-names> <surname>Loran</surname></string-name>, <string-name><given-names>Guang</given-names> <surname>Yang</surname></string-name>, and <string-name><given-names>Ishmail</given-names> <surname>Abdus-Saboor</surname></string-name></person-group>. <article-title>Remote automated delivery of mechanical stimuli coupled to brain recordings in behaving mice</article-title>. <source>eLife</source>, <volume>13</volume>:<elocation-id>RP99614</elocation-id>, 1 <year>2023</year>. <pub-id pub-id-type="doi">10.7554/eLife.99614</pub-id></mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Aaron D.</given-names> <surname>Mickle</surname></string-name> and <string-name><given-names>Robert W.</given-names> <surname>Gereau</surname></string-name></person-group>. <article-title>A bright future? Optogenetics in the periphery for pain research and therapy</article-title>, <source>Pain</source> <volume>159</volume>:<fpage>S65</fpage>–<lpage>S73</lpage><year>2018</year>.</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Victoria J.</given-names> <surname>Madden</surname></string-name>, <string-name><given-names>Mark J.</given-names> <surname>Catley</surname></string-name>, <string-name><given-names>Luzia</given-names> <surname>Grabherr</surname></string-name>, <string-name><given-names>Francesca</given-names> <surname>Mazzola</surname></string-name>, <string-name><given-names>Mohammad</given-names> <surname>Shohag</surname></string-name>, and <string-name><given-names>G. Lorimer</given-names> <surname>Moseley</surname></string-name></person-group>. <article-title>The effect of repeated laser stimuli to ink-marked skin on skin temperature-recommendations for a safe experimental protocol in humans</article-title>. <source>PeerJ</source>, <volume>4</volume>(<issue>1</issue>):<elocation-id>e1577</elocation-id>, <year>2016</year>.</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Menghon</given-names> <surname>Cheah</surname></string-name>, <string-name><given-names>James</given-names> <surname>Fawcett</surname></string-name>, and <string-name><given-names>Melissa</given-names> <surname>Andrews</surname></string-name></person-group>. <article-title>Assessment of Thermal Pain Sensation in Rats and Mice Using the Hargreaves Test</article-title>. <source>Bio Protoc</source>, <volume>7</volume>(<issue>16</issue>):<fpage>e2506</fpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Valentina</given-names> <surname>Emiliani</surname></string-name>, <string-name><given-names>Emilia</given-names> <surname>Entcheva</surname></string-name>, <string-name><given-names>Rainer</given-names> <surname>Hedrich</surname></string-name>, <string-name><given-names>Peter</given-names> <surname>Hegemann</surname></string-name>, <string-name><given-names>Kai R.</given-names> <surname>Konrad</surname></string-name>, <string-name><given-names>Christian</given-names> <surname>Lüscher</surname></string-name>, <string-name><given-names>Mathias</given-names> <surname>Mahn</surname></string-name>, <string-name><given-names>Zhuo Hua</given-names> <surname>Pan</surname></string-name>, <string-name><given-names>Ruth R.</given-names> <surname>Sims</surname></string-name>, <string-name><given-names>Johannes</given-names> <surname>Vierock</surname></string-name>, and <string-name><given-names>Ofer</given-names> <surname>Yizhar</surname></string-name></person-group>. <article-title>Optogenetics for light control of biological systems</article-title>. <source>Nature Reviews Methods Primers</source>, <volume>2</volume>(<issue>1</issue>):<fpage>55</fpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Kendall</given-names> <surname>Mitchell</surname></string-name>, <string-name><given-names>Brian D.</given-names> <surname>Bates</surname></string-name>, <string-name><given-names>Jason M.</given-names> <surname>Keller</surname></string-name>, <string-name><given-names>Matthew</given-names> <surname>Lopez</surname></string-name>, <string-name><given-names>Lindsey</given-names> <surname>Scholl</surname></string-name>, <string-name><given-names>Julia</given-names> <surname>Navarro</surname></string-name>, <string-name><given-names>Nicholas</given-names> <surname>Madian</surname></string-name>, <string-name><given-names>Gal</given-names> <surname>Haspel</surname></string-name>, <string-name><given-names>Michael I.</given-names> <surname>Nemenov</surname></string-name>, and <string-name><given-names>Michael J.</given-names> <surname>Iadarola</surname></string-name></person-group>. <article-title>Ablation of rat TRPV1-expressing Adelta/C-fibers with resiniferatoxin: Analysis of withdrawal behaviors, recovery of function and molecular correlates</article-title>. <source>Molecular Pain</source>, <volume>6</volume>:<fpage>94</fpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Alexander</given-names> <surname>Mathis</surname></string-name>, <string-name><given-names>Pranav</given-names> <surname>Mamidanna</surname></string-name>, <string-name><given-names>Kevin M</given-names> <surname>Cury</surname></string-name>, <string-name><given-names>Taiga</given-names> <surname>Abe</surname></string-name>, <string-name><given-names>Venkatesh N</given-names> <surname>Murthy</surname></string-name>, <string-name><given-names>Mackenzie Weygandt</given-names> <surname>Mathis</surname></string-name>, and <string-name><given-names>Matthias</given-names> <surname>Bethge</surname></string-name></person-group>. <article-title>DeepLabCut: markerless pose estimation of user-defined body parts with deep learning</article-title>. <source>Nature Neuroscience</source>, <volume>21</volume>(<issue>9</issue>):<fpage>1281</fpage>–<lpage>1289</lpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Jessica M</given-names> <surname>Jones</surname></string-name>, <string-name><given-names>William</given-names> <surname>Foster</surname></string-name>, <string-name><given-names>Colin R</given-names> <surname>Twomey</surname></string-name>, <string-name><given-names>Justin</given-names> <surname>Burdge</surname></string-name>, <string-name><given-names>Osama M</given-names> <surname>Ahmed</surname></string-name>, <string-name><given-names>Talmo D</given-names> <surname>Pereira</surname></string-name>, <string-name><given-names>Jessica A</given-names> <surname>Wojick</surname></string-name>, <string-name><given-names>Gregory</given-names> <surname>Corder</surname></string-name>, <string-name><given-names>Joshua B</given-names> <surname>Plotkin</surname></string-name>, and <string-name><given-names>Ishmail</given-names> <surname>Abdus-Saboor</surname></string-name></person-group>. <article-title>A machine-vision approach for automated pain measurement at millisecond timescales</article-title>. <source>eLife</source>, <volume>9</volume>:<elocation-id>e57258</elocation-id>, <year>2020</year>. <pub-id pub-id-type="doi">10.7554/eLife.57258</pub-id></mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>AB</given-names> <surname>Wiltschko</surname></string-name>, <string-name><given-names>T</given-names> <surname>Tsukahara</surname></string-name>, <string-name><given-names>A</given-names> <surname>Zeine</surname></string-name>, <string-name><given-names>R</given-names> <surname>Anyoha</surname></string-name>, <string-name><given-names>WF</given-names> <surname>Gillis</surname></string-name>, <string-name><given-names>JE</given-names> <surname>Markowitz</surname></string-name>, <string-name><given-names>RE</given-names> <surname>Peterson</surname></string-name>, <string-name><given-names>J</given-names> <surname>Katon</surname></string-name>, <string-name><given-names>MJ</given-names> <surname>Johnson</surname></string-name>, and <string-name><given-names>SR</given-names> <surname>Datta</surname></string-name></person-group>. <article-title>Revealing the structure of pharmacobehavioral space through motion sequencing</article-title>. <source>Nature Neuroscience</source>, <volume>23</volume>(<issue>11</issue>):<fpage>1433</fpage>–<lpage>1443</lpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Alexander I.</given-names> <surname>Hsu</surname></string-name> and <string-name><given-names>Eric A.</given-names> <surname>Yttri</surname></string-name></person-group>. <article-title>B-SOiD, an open-source unsupervised algorithm for identification and fast prediction of behaviors</article-title>. <source>Nature Communications</source>, <volume>12</volume>(<issue>1</issue>):<fpage>5188</fpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Zihe</given-names> <surname>Zhang</surname></string-name>, <string-name><given-names>David P.</given-names> <surname>Roberson</surname></string-name>, <string-name><given-names>Masakazu</given-names> <surname>Kotoda</surname></string-name>, <string-name><given-names>Bruno</given-names> <surname>Boivin</surname></string-name>, <string-name><given-names>James P.</given-names> <surname>Bohnslav</surname></string-name>, <string-name><given-names>Rafael</given-names> <surname>González-Cano</surname></string-name>, <string-name><given-names>David A.</given-names> <surname>Yarmolinsky</surname></string-name>, <string-name><given-names>Bruna Lenfers</given-names> <surname>Turnes</surname></string-name>, <string-name><given-names>Nivanthika K.</given-names> <surname>Wimalasena</surname></string-name>, <string-name><given-names>Shay Q.</given-names> <surname>Neufeld</surname></string-name>, <string-name><given-names>Lee B.</given-names> <surname>Barrett</surname></string-name>, <string-name><given-names>Nara L.M.</given-names> <surname>Quintão</surname></string-name>, <string-name><given-names>Victor</given-names> <surname>Fattori</surname></string-name>, <string-name><given-names>Daniel G.</given-names> <surname>Taub</surname></string-name>, <string-name><given-names>Alexander B.</given-names> <surname>Wiltschko</surname></string-name>, <string-name><given-names>Nick A.</given-names> <surname>Andrews</surname></string-name>, <string-name><given-names>Christopher D.</given-names> <surname>Harvey</surname></string-name>, <string-name><given-names>Sandeep Robert</given-names> <surname>Datta</surname></string-name>, and <string-name><given-names>Clifford J.</given-names> <surname>Woolf</surname></string-name></person-group>. <article-title>Automated preclinical detection of mechanical pain hypersensitivity and analgesia</article-title>. <source>Pain</source>, <volume>163</volume>(<issue>12</issue>):<fpage>2326</fpage>–<lpage>2336</lpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Caleb</given-names> <surname>Weinreb</surname></string-name>, <string-name><given-names>Mohammed</given-names> <surname>Abdal</surname></string-name>, <string-name><given-names>Monium</given-names> <surname>Osman</surname></string-name>, <string-name><given-names>Libby</given-names> <surname>Zhang</surname></string-name>, <string-name><given-names>Sherry</given-names> <surname>Lin</surname></string-name>, <string-name><given-names>Jonah</given-names> <surname>Pearl</surname></string-name>, <string-name><given-names>Sidharth</given-names> <surname>Annapragada</surname></string-name>, <string-name><given-names>Eli</given-names> <surname>Conlin</surname></string-name>, <string-name><given-names>Winthrop F</given-names> <surname>Gillis</surname></string-name>, <string-name><given-names>Maya</given-names> <surname>Jay</surname></string-name>, <string-name><given-names>Shaokai</given-names> <surname>Ye</surname></string-name>, <string-name><given-names>Alexander</given-names> <surname>Mathis</surname></string-name>, <string-name><given-names>Mackenzie Weygandt</given-names> <surname>Mathis</surname></string-name>, <string-name><given-names>Talmo</given-names> <surname>Pereira</surname></string-name>, <string-name><given-names>Scott W</given-names> <surname>Linderman</surname></string-name>, and <string-name><given-names>Sandeep Robert</given-names> <surname>Datta</surname></string-name></person-group>. <article-title>Keypoint-MoSeq: parsing behavior by linking point tracking to pose dynamics</article-title>. <source>Nature Methods</source>, <volume>21</volume>:<fpage>1329</fpage>–<lpage>1339</lpage>, <year>2024</year>.</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Manon</given-names> <surname>Bohic</surname></string-name>, <string-name><given-names>Luke A.</given-names> <surname>Pattison</surname></string-name>, <string-name><given-names>Z. Anissa</given-names> <surname>Jhumka</surname></string-name>, <string-name><given-names>Heather</given-names> <surname>Rossi</surname></string-name>, <string-name><given-names>Joshua K.</given-names> <surname>Thackray</surname></string-name>, <string-name><given-names>Matthew</given-names> <surname>Ricci</surname></string-name>, <string-name><given-names>Nahom</given-names> <surname>Mossazghi</surname></string-name>, <string-name><given-names>William</given-names> <surname>Foster</surname></string-name>, <string-name><given-names>Simon</given-names> <surname>Ogundare</surname></string-name>, <string-name><given-names>Colin R.</given-names> <surname>Twomey</surname></string-name>, <string-name><given-names>Helen</given-names> <surname>Hilton</surname></string-name>, <string-name><given-names>Justin</given-names> <surname>Arnold</surname></string-name>, <string-name><given-names>Max A.</given-names> <surname>Tischfield</surname></string-name>, <string-name><given-names>Eric A.</given-names> <surname>Yttri</surname></string-name>, <string-name><given-names>Ewan St. John</given-names> <surname>Smith</surname></string-name>, <string-name><given-names>Ishmail</given-names> <surname>Abdus-Saboor</surname></string-name>, and <string-name><given-names>Victoria E.</given-names> <surname>Abraira</surname></string-name></person-group>. <article-title>Mapping the neuroethological signatures of pain, analgesia, and recovery in mice</article-title>. <source>Neuron</source>, <volume>111</volume>(<issue>18</issue>):<fpage>2811</fpage>–<lpage>2830</lpage>, <year>2023</year>.</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Talmo D</given-names> <surname>Pereira</surname></string-name>, <string-name><given-names>Nathaniel</given-names> <surname>Tabris</surname></string-name>, <string-name><given-names>Junyu</given-names> <surname>Li</surname></string-name>, <string-name><given-names>Shruthi</given-names> <surname>Ravindranath</surname></string-name>, <string-name><given-names>Eleni S</given-names> <surname>Papadoyannis</surname></string-name>, Z <string-name><given-names>Yan</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>David M</given-names> <surname>Turner</surname></string-name>, <string-name><given-names>Grace</given-names> <surname>McKenzie-Smith</surname></string-name>, <string-name><given-names>Sarah D</given-names> <surname>Kocher</surname></string-name>, <string-name><given-names>Annegret L</given-names> <surname>Falkner</surname></string-name>, <string-name><given-names>Joshua W</given-names> <surname>Shaevitz</surname></string-name>, and <string-name><given-names>Mala</given-names> <surname>Murthy</surname></string-name></person-group>. <article-title>SLEAP: Multi-animal pose tracking</article-title>. <source>Nature Methods</source>, <volume>19</volume>:<fpage>486</fpage>–<lpage>495</lpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>June Seek</given-names> <surname>Choi</surname></string-name> and <string-name><given-names>Jeansok J.</given-names> <surname>Kim</surname></string-name></person-group>. <article-title>Amygdala regulates risk of predation in rats foraging in a dynamic fear environment</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>107</volume>(<issue>50</issue>):<fpage>21773</fpage>–<lpage>21777</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Alexander T.</given-names> <surname>Lai</surname></string-name>, <string-name><given-names>German</given-names> <surname>Espinosa</surname></string-name>, <string-name><given-names>Gabrielle E.</given-names> <surname>Wink</surname></string-name>, <string-name><given-names>Christopher F.</given-names> <surname>Angeloni</surname></string-name>, <string-name><given-names>Daniel A.</given-names> <surname>Dombeck</surname></string-name>, and <string-name><given-names>Malcolm A.</given-names> <surname>MacIver</surname></string-name></person-group>. <article-title>A robot-rodent interaction arena with adjustable spatial complexity for ethologically relevant behavioral studies</article-title>. <source>Cell Reports</source>, <volume>43</volume>(<issue>2</issue>):<fpage>113671</fpage>, <year>2024</year>.</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Chloe</given-names> <surname>Alexandre</surname></string-name>, <string-name><given-names>Giulia</given-names> <surname>Miracca</surname></string-name>, <string-name><given-names>Victor Duarte</given-names> <surname>Holanda</surname></string-name>, <string-name><given-names>Ashley</given-names> <surname>Sharma</surname></string-name>, <string-name><given-names>Kamila</given-names> <surname>Kourbanova</surname></string-name>, <string-name><given-names>Ashley</given-names> <surname>Ferreira</surname></string-name>, <string-name><given-names>Maíra A.</given-names> <surname>Bicca</surname></string-name>, <string-name><given-names>Xiangsunze</given-names> <surname>Zeng</surname></string-name>, <string-name><given-names>Victoria A.</given-names> <surname>Nassar</surname></string-name>, <string-name><given-names>Seungkyu</given-names> <surname>Lee</surname></string-name>, <string-name><given-names>Satvinder</given-names> <surname>Kaur</surname></string-name>, <string-name><given-names>Sridevi V.</given-names> <surname>Sarma</surname></string-name>, <string-name><given-names>Pierre</given-names> <surname>Sacré</surname></string-name>, <string-name><given-names>Thomas E.</given-names> <surname>Scammell</surname></string-name>, <string-name><given-names>Clifford J.</given-names> <surname>Woolf</surname></string-name>, and <string-name><given-names>Alban</given-names> <surname>Latremoliere</surname></string-name></person-group>. <article-title>Nociceptor spontaneous activity is responsible for fragmenting non–rapid eye movement sleep in mouse models of neuropathic pain</article-title>. <source>Science Translational Medicine</source>, <volume>16</volume>(<issue>743</issue>):<fpage>eadg3036</fpage>, 4 <year>2024</year>.</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Lauren L.</given-names> <surname>Orefice</surname></string-name>, <string-name><given-names>Jacqueline R.</given-names> <surname>Mosko</surname></string-name>, <string-name><given-names>Danielle T.</given-names> <surname>Morency</surname></string-name>, <string-name><given-names>Michael F.</given-names> <surname>Wells</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Tasnim</surname></string-name>, <string-name><given-names>Shawn M.</given-names> <surname>Mozeika</surname></string-name>, <string-name><given-names>Mengchen</given-names> <surname>Ye</surname></string-name>, <string-name><given-names>Anda M.</given-names> <surname>Chirila</surname></string-name>, <string-name><given-names>Alan J.</given-names> <surname>Emanuel</surname></string-name>, <string-name><given-names>Genelle</given-names> <surname>Rankin</surname></string-name>, <string-name><given-names>Ryann M.</given-names> <surname>Fame</surname></string-name>, <string-name><given-names>Maria K.</given-names> <surname>Lehtinen</surname></string-name>, <string-name><given-names>Guoping</given-names> <surname>Feng</surname></string-name>, and <string-name><given-names>David D.</given-names> <surname>Ginty</surname></string-name></person-group>. <article-title>Targeting Peripheral Somatosensory Neurons to Improve Tactile-Related Phenotypes in ASD Models</article-title>. <source>Cell</source>, <volume>178</volume>(<issue>4</issue>):<fpage>867</fpage>–<lpage>886</lpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Mimi</given-names> <surname>La-Vu</surname></string-name>, <string-name><given-names>Brooke C.</given-names> <surname>Tobias</surname></string-name>, <string-name><given-names>Peter J.</given-names> <surname>Schuette</surname></string-name>, and <string-name><given-names>Avishek</given-names> <surname>Adhikari</surname></string-name></person-group>. <article-title>To Approach or Avoid: An Introductory Overview of the Study of Anxiety Using Rodent Assays</article-title>, <source>Front Behav Neurosci</source> <volume>14</volume>:<elocation-id>145</elocation-id> <year>2020</year>.</mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Daniel J</given-names> <surname>Cavanaugh</surname></string-name>, <string-name><given-names>Alexander T</given-names> <surname>Chesler</surname></string-name>, <string-name><given-names>Alexander C</given-names> <surname>Jackson</surname></string-name>, <string-name><given-names>Yaron M</given-names> <surname>Sigal</surname></string-name>, <string-name><given-names>Hiroki</given-names> <surname>Yamanaka</surname></string-name>, <string-name><given-names>Rebecca</given-names> <surname>Grant</surname></string-name>, <string-name><given-names>Dajan</given-names> <surname>O’Donnell</surname></string-name>, <string-name><given-names>Roger A</given-names> <surname>Nicoll</surname></string-name>, <string-name><given-names>Nirao M</given-names> <surname>Shah</surname></string-name>, <string-name><given-names>David</given-names> <surname>Julius</surname></string-name>, and <string-name><given-names>Allan I</given-names> <surname>Basbaum</surname></string-name></person-group>. <article-title>Trpv1 reporter mice reveal highly restricted brain distribution and functional expression in arteriolar smooth muscle cells</article-title>. <source>Journal of Neuroscience</source>, <volume>31</volume>(<issue>13</issue>):<fpage>5067</fpage>–<lpage>5077</lpage>, <year>2011</year>.</mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Linda</given-names> <surname>Madisen</surname></string-name>, <string-name><given-names>Tianyi</given-names> <surname>Mao</surname></string-name>, <string-name><given-names>Henner</given-names> <surname>Koch</surname></string-name>, <string-name><given-names>Jia-min</given-names> <surname>Zhuo</surname></string-name>, <string-name><given-names>Antal</given-names> <surname>Berenyi</surname></string-name>, <string-name><given-names>Shigeyoshi</given-names> <surname>Fujisawa</surname></string-name>, <string-name><given-names>Yun-Wei A</given-names> <surname>Hsu</surname></string-name>, <string-name><given-names>Alfredo J</given-names> <surname>Garcia</surname></string-name> 3rd, <string-name><given-names>Xuan</given-names> <surname>Gu</surname></string-name>, <string-name><given-names>Sebastien</given-names> <surname>Zanella</surname></string-name>, <string-name><given-names>Jolene</given-names> <surname>Kidney</surname></string-name>, <string-name><given-names>Hong</given-names> <surname>Gu</surname></string-name>, <string-name><given-names>Yimei</given-names> <surname>Mao</surname></string-name>, <string-name><given-names>Bryan M</given-names> <surname>Hooks</surname></string-name>, <string-name><given-names>Edward S</given-names> <surname>Boyden</surname></string-name>, <string-name><given-names>György</given-names> <surname>Buzsáki</surname></string-name>, <string-name><given-names>Jan M</given-names> <surname>Ramirez</surname></string-name>, <string-name><given-names>Allan R</given-names> <surname>Jones</surname></string-name>, <string-name><given-names>Karl</given-names> <surname>Svoboda</surname></string-name>, <string-name><given-names>Xue</given-names> <surname>Han</surname></string-name>, <string-name><given-names>Eric E</given-names> <surname>Turner</surname></string-name>, and <string-name><given-names>Hongkui</given-names> <surname>Zeng</surname></string-name></person-group>. <article-title>A toolbox of Cre-dependent optogenetic transgenic mice for light-induced activation and silencing</article-title>. <source>Nature Neuroscience</source>, <volume>15</volume>(<issue>5</issue>):<fpage>793</fpage>–<lpage>802</lpage>, <year>2012</year>.</mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Tanmay</given-names> <surname>Nath</surname></string-name>, <string-name><given-names>Alexander</given-names> <surname>Mathis</surname></string-name>, <string-name><given-names>An Chi</given-names> <surname>Chen</surname></string-name>, <string-name><given-names>Amir</given-names> <surname>Patel</surname></string-name>, <string-name><given-names>Matthias</given-names> <surname>Bethge</surname></string-name>, and <string-name><given-names>Mackenzie Weygandt</given-names> <surname>Mathis</surname></string-name></person-group>. <article-title>Using DeepLabCut for 3D markerless pose estimation across species and behaviors</article-title>. <source>Nature Protocols</source>, <volume>14</volume>(<issue>7</issue>):<fpage>2152</fpage>–<lpage>2176</lpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>J. J. W.</given-names> <surname>Bakermans</surname></string-name> and <string-name><given-names>T. E</given-names> <surname>Behrens</surname></string-name></person-group>. <article-title>Controlling precedence in sequential stimulus presentation with Euler tours</article-title>. <source>PsyArXiv</source>, <year>2021</year>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106033.2.sa4</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Griffith</surname>
<given-names>Theanne N</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/05rrcem69</institution-id><institution>University of California, Davis</institution>
</institution-wrap>
<city>Davis</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>important</bold> study combines real-time key point tracking with transdermal activation of sensory neurons as a general technique to explore how somatosensory stimulation impacts behavior in freely moving mice. After addressing concerns about classification of the behavioral responses to nociceptor stimulation, the authors now <bold>convincingly</bold> demonstrate a state-dependence in the behavioral response following nociceptor activation, highlighting how their real-time optogenetic stimulation capabilities can yield new insights into complex sensory processing. This work is a technological advancement that will be of interest to a broad readership, in particular labs studying somatosensation, enabling rigorous investigation of behaviors that were previously difficult or impossible to study.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106033.2.sa3</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This study presents a system for delivering precisely controlled cutaneous stimuli to freely moving mice by coupling markerless real-time tracking to transdermal optogenetic stimulation, using the tracking signal to direct a laser via galvanometer mirrors. The principal claims are that the system achieves sub-mm targeting accuracy with a latency of &lt;100 ms. Due to the nature of mouse gait, this enables accurate targeting of forepaws even when mice are moving.</p>
<p>Strengths:</p>
<p>The study is of high quality and the evidence for the claims is convincing. There is increasing focus in neurobiology in studying neural function in freely moving animals, engaged in natural behaviour. However, a substantial challenge is how to deliver controlled stimuli to sense organs under such conditions. The system presented here constitutes notable progress towards such experiments in the somatosensory system and is, in my view, a highly significant development that will be of interest to a broad readership.</p>
<p>My comments on the original submission have been fully addressed.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106033.2.sa2</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Parkes et al. combined real-time keypoint tracking with transdermal activation of sensory neurons to examine the effects of recruitment of sensory neurons in freely moving mice. This builds on the authors' previous investigations involving transdermal stimulation of sensory neurons in stationary mice. They illustrate multiple scenarios in which their engineering improvements enable more sophisticated behavioral assessments, including 1) stimulation of animals in multiple states in large arenas, 2) multi-animal nociceptive behavior screening through thermal and optogenetic activation, and 3) stimulation of animals running through maze corridors. Overall, the experiments and the methodology, in particular, is written clearly. The revised manuscript nicely demonstrates a state-dependence in the behavioral response to activation of TrpV1 sensory neurons, which is a nice demonstration of how their real-time optogenetic stimulation capabilities can yield new insights into complex sensory processing.</p>
<p>Comments on revisions:</p>
<p>I agree that your revisions have substantially improved the clarity and quality of the work.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106033.2.sa1</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>To explore the diverse nature of somatosensation, Parkes et al. established and characterized a system for precise cutaneous stimulation of mice as they walk and run in naturalistic settings. This paper provides a framework for real-time body part tracking and targeted optical stimuli with high precision, ensuring reliable and consistent cutaneous stimulation. It can be adapted in somatosensation labs as a general technique to explore somatosensory stimulation and its impact on behavior, enabling rigorous investigation of behaviors that were previously difficult or impossible to study.</p>
<p>Strengths:</p>
<p>The authors characterized the closed-loop system to ensure that it is optically precise and can precisely target moving mice. The integration of accurate and consistent optogenetic stimulation of the cutaneous afferents allows systematic investigation of somatosensory subtypes during a variety of naturalistic behaviors. Although this study focused on nociceptors innervating the skin (Trpv1::ChR2 animals), this setup can be extended to other cutaneous sensory neuron subtypes, such as low-threshold mechanoreceptors and pruriceptors. This system can also be adapted for studying more complex behaviors, such as the maze assay and goal-directed movements.</p>
<p>Weaknesses:</p>
<p>Although the paper has strengths, its weakness is that some behavioral outputs could be analyzed in more detail to reveal different types of responses to painful cutaneous stimuli. For example, paw withdrawals were detected after optogenetically stimulating the paw (Figures 3E and 3F). Animals exhibit different types of responses to painful stimuli on the hindpaw in standard pain assays, such as paw lifting, biting, and flicking, each indicating a different level of pain. The output of this system is body part keypoints, which are the standard input to many existing tools. Analyzing these detailed keypoints would greatly strengthen this system by providing deeper biological insights into the role of somatosensation in naturalistic behaviors. Additionally, if the laser spot size could be reduced to a diameter of 2 mm², it would allow the activation of a smaller number of cutaneous afferents, or even a single one, across different skin types in the paw, such as glabrous or hairy skin.</p>
<p>Comments on revisions:</p>
<p>The authors successfully addressed all of my questions and concerns.</p>
</body>
</sub-article>
<sub-article id="sa4" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106033.2.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Parkes</surname>
<given-names>Isobel</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-6569-618X</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Schorscher-Petcu</surname>
<given-names>Ara</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-5808-5172</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Gan</surname>
<given-names>Qinyi</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">https://orcid.org/0009-0006-3962-5501</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Browne</surname>
<given-names>Liam E</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-5693-7703</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>The following is the authors’ response to the original reviews.</p>
<disp-quote content-type="editor-comment">
<p><bold>Public Reviews:</bold></p>
<p><bold>Reviewer #1 (Public review)</bold>:</p>
<p>Summary:</p>
<p>This study presents a system for delivering precisely controlled cutaneous stimuli to freely moving mice by coupling markerless real-time tracking to transdermal optogenetic stimulation, using the tracking signal to direct a laser via galvanometer mirrors. The principal claims are that the system achieves sub-mm targeting accuracy with a latency of &lt;100 ms. The nature of mouse gait enables accurate targeting of forepaws even when mice are moving.</p>
<p>Strengths:</p>
<p>The study is of high quality and the evidence for the claims is convincing. There is increasing focus in neurobiology in studying neural function in freely moving animals, engaged in natural behaviour. However, a substantial challenge is how to deliver controlled stimuli to sense organs under such conditions. The system presented here constitutes notable progress towards such experiments in the somatosensory system and is, in my view, a highly significant development that will be of interest to a broad readership.</p>
<p>Weaknesses:</p>
<p>(1) &quot;laser spot size was set to 2.00 } 0.08 mm2 diameter (coefficient of variation = 3.85)&quot; is unclear. Is the 0.08 SD or SEM? (not stated). Also, is this systematic variation across the arena (or something else)? Readers will want to know how much the spot size varies across the arena - ie SD. CV=4 implies that SD~7 mm. ie non-trivial variation in spot size, implying substantial differences in power delivery (and hence stimulus intensity) when the mouse is in different locations. If I misunderstood, perhaps this helps the authors to clarify. Similarly, it would be informative to have mean &amp; SD (or mean &amp; CV) for power and power density. In future refinements of the system, would it be possible/useful to vary laser power according to arena location?</p>
</disp-quote>
<p>We thank the reviewer for their comments and for identifying areas needing more clarity. The previous version was ambiguous: 0.08 refers to the standard deviation (SD). We have removed the ambiguity by stating mean ± SD and reporting a unitless coefficient of variation (CV).</p>
<p>The revised text reads “laser spot size was set to 2.00 ± 0.08 mm<sup>2</sup> (mean ± SD; coefficient of variation = 0.039).” This makes clear that the variability in spot size is minimal: it is 0.08 mm<sup>2</sup> SD (≈0.03 mm SD in diameter). This should help clarify that spot size variability across the arena is minute and unlikely to contribute meaningfully to differences in stimulus intensity across locations. The power was modulated depending on the experiment, so we provide the unitless CV here in “The absolute optical power and power density were uniform across the glass platform (coefficient of variation 0.035 and 0.029, respectively; Figure 2—figure supplement)”. We are grateful to the reviewer for spotting these omissions.</p>
<p>The reviewer also asks whether, in the future, it is “possible/useful to vary laser power according to arena location”. This is already possible in our system for infrared cutaneous stimulation using analog modulation (Figure 4). We have added the following sentence to make this clearer: “Laser power could be modulated using the analog control.”</p>
<disp-quote content-type="editor-comment">
<p>(2) &quot;The video resolution (1920 x 1200) required a processing time higher than the frame interval (33.33 ms), resulting in real-time pose estimation on a sub-sample of all frames recorded&quot;. Given this, how was it possible to achieve 84 ms latency? An important issue for closed-loop research will relate to such delays. Therefore please explain in more depth and (in Discussion) comment on how the latency of the current system might be improved/generalised. For example, although the current system works well for paws it would seem to be less suited to body parts such as the snout that do not naturally have a stationary period during the gait cycle.</p>
</disp-quote>
<p>We captured and stored video with a frame-to-frame interval of 33.33 ms (30 fps). DeepLabCut-live! was run in a latency-optimization mode, meaning that new frames are not processed while the network is busy - only the most recent frame is processed when free. The processing latency is measured per processed frame, and intermediate frames are thus skipped while the network is busy. Although a wide field of view and high resolution is required to capture the large environment, increasing the per-frame compute time, the processing latency remained small enough to track and stimulate moving mice. This processing latency of 84 ± 12 ms (mean ± SD) was calculated using the timestamps stored in the output files from DeepLabCut-live!: subtracting the frame acquisition timestamp from the frame processing timestamp across 16,000 processed frames recorded across four mice (4,000 each). In addition, there is a small delay to move the galvanometers and trigger the laser, calculated as 3.3 ± 0.5 ms (mean ± SD; 245 trials). This is described in the manuscript, but can be combined with the processing latency to indicate a total closed-loop delay of ≈87 ms so we have expanded on the ‘Optical system characterization’ subsection in the Methods, adding “We estimated a processing latency of 84 ± 12 ms (mean ± SD) by subtracting…” and that “In the current configuration the end-to-end closed-loop delay is ≈87 ms from the combination of the processing latency and other delays”. To the Discussion, we now comment on how this latency can be reduced and how this can allow for generalization to more rapidly moving body parts.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public review)</bold>:</p>
<p>Parkes et al. combined real-time keypoint tracking with transdermal activation of sensory neurons to examine the effects of recruitment of sensory neurons in freely moving mice. This builds on the authors' previous investigations involving transdermal stimulation of sensory neurons in stationary mice. They illustrate multiple scenarios in which their engineering improvements enable more sophisticated behavioral assessments, including (1) stimulation of animals in multiple states in large arenas, (2) multi-animal nociceptive behavior screening through thermal and optogenetic activation, and (3) stimulation of animals running through maze corridors. Overall, the experiments and the methodology, in particular, are written clearly. However, there are multiple concerns and opportunities to fully describe their newfound capabilities that, if addressed, would make it more likely for the community to adopt this methodology:</p>
<p>The characterization of laser spot size and power density is reported as a coefficient of variation, in which a value of ~3 is interpreted as uniform. My interpretation would differ - data spread so that the standard deviation is three times larger than the mean indicates there is substantial variability in the data. The 2D polynomial fit is shown in Figure 2 - Figure Supplement 1A and, if the fit is good, this does support the uniformity claim (range of spot size is 1.97 to 2.08 mm2 and range of power densities is 66.60 to 73.80 mW). The inclusion of the raw data for these measurements and an estimate of the goodness of fit to the polynomials would better help the reader evaluate whether these parameters are uniform across space and how stable the power density is across repeated stimulations of the same location. Even more helpful would be an estimate of whether the variation in the power density is expected to meaningfully affect the responses of ChR2-expressing sensory neurons.</p>
</disp-quote>
<p>We thank the reviewer for their comments. As also noted in response to Reviewer 1, the coefficient of variation (CV) is now reported in unitless form (rather than a percentage) to ensure clarity. For avoidance of doubt, the CV is 0.039 (3.9%), so the variation in laser spot size is minimal – there is negligible spot size variability across the system. The ranges are indeed consistent with uniformity. We have included the goodness-of-fit estimates in the appropriate figure legend “fit with a two-dimensional polynomial (area R<sup>2</sup> = 0.91; power R<sup>2</sup> = 0.75)”. This indicates that the polynomials fit well overall.</p>
<p>The system already allows for control of spot size. To examine whether the variation in the power density affects the responses of ChR2-expressing sensory neurons, we examined this in our previous work that focused more on input-output relationships, demonstrating a steep relationship between spot size (range of 0.02 mm<sup>2</sup> to 2.30 mm<sup>2</sup>) and the probability of paw response, demonstrating a meaningful change in response probability (Schorscher-Petcu et al. eLife, 2021). In future studies, we aim to use this approach to “titrate” cutaneous inputs as mice move through their environments.</p>
<disp-quote content-type="editor-comment">
<p>While the error between the keypoint and laser spot error was reported as ~0.7 to 0.8 mm MAE in Figure 2L, in the methods, the authors report that there is an additional error between predicted keypoints and ground-truth labeling of 1.36 mm MAE during real-time tracking. This suggests that the overall error is not submillimeter, as claimed by the authors, but rather on the order of 1.5 - 2.5 mm, which is considerable given the width of a hind paw is ~5-6 mm and fore paws are even smaller. In my opinion, the claim for submillimeter precision should be softened and the authors should consider that the area of the paw stimulated may differ from trial to trial if, for example, the error is substantial enough that the spot overlaps with the edge of the paw.</p>
</disp-quote>
<p>We thank the reviewer for identifying a discrepancy in these reported errors. We clarify this below and in the manuscript</p>
<p>The real-time tracking error is the mean absolute Euclidean distance (MAE) between ground truth and DLC on the left hind paw where likelihood was relatively high. More specifically, ground truth was obtained by manual annotation of the left hind paw center. The corresponding DLC keypoint was evaluated in frames with likelihood &gt;0.8 (the stimulation threshold). Across 1,281 frames from five videos of freely exploring mice (30 fps), the MAE was 1.36 mm.</p>
<p>The targeting error is the MAE between ground truth and the laser spot location, so should reflect the real-time tracking error plus errors from targeting the laser. More specifically, this metric was determined by comparing the manually determined ground truth keypoint of the left hind paw and the actual center of the laser spot. Importantly, this metric was calculated using four five-minute high-speed videos recorded at 270 fps of mice freely exploring the open arena (463 frames) and frames were selected with a likelihood threshold &gt;0.8. This allowed us to resolve the brief laser pulses but inadvertently introduced a difference in spatial scaling. After rescaling, the values give a targeting error MAE now in line with the real-time tracking error  (see corrected Figure 2L). This is approximately 1.3 mm across all locomotion speeds categories. These errors are small and are limited by the spatial resolution of the cameras. We thank the reviewer for noting this discrepancy and prompting us to get to its root cause.</p>
<p>We have amended the subtitle on Figure 2L as “Ground truth keypoint to laser spot error” and have avoided the use of submillimeter throughout. We have added the following sentence to clarify this point: “As laser targeting relies on real-time tracking to direct the laser to the specified body part, this metric includes any errors introduced by tracking and targeting”.</p>
<disp-quote content-type="editor-comment">
<p>As the major advance of this paper is the ability to stimulate animals during ongoing movement, it seems that the Figure 3 experiment misses an opportunity to evaluate state-dependent whole-body reactions to nociceptor activation. How does the behavioral response relate to the animal's activity just prior to stimulation?</p>
</disp-quote>
<p>The reviewers suggest analysis of state-dependent responses. In the Figure 3 experiment, mice were stimulated up to five times when stationary. Analysis of whole body reactions in stationary mice has been described in (Schorscher-Petcu et al. eLife, 2021) and doing this here would be redundant, so instead we now analyse the responses of moving mice in Figure 5. This new analysis shows robust state-dependent responses during movement as suggested by the reviewer. We find two behavioral clusters: one that is for faster, direct (coherent) movement and the other that is for slower assessment (incoherent) movement. Stimulation during the former results in robust and consistent slowing and shift towards assessment, whereas stimulation during the former results in a reduction in assessment. We describe and interpret these new data in the Results and Discussion sections and add information in the Methods and Figure legend, as given below. We believe that demonstrating movement statedependence is a valuable addition to the paper and thank the reviewer for suggesting this.</p>
<disp-quote content-type="editor-comment">
<p>Given the characterization of full-body responses to activation of TrpV1 sensory neurons in Figure 4 and in the authors' previous work, stimulation of TrpV1 sensory neurons has surprisingly subtle effects as the mice run through the alternating T maze. The authors indicate that the mice are moving quickly and thus that precise targeting is required, but no evidence is shared about the precision of targeting in this context beyond images of four trials. From the characterization in Figure 2, at max speed (reported at 241 +/- 53 mm/s, which is faster than the high speeds in Figure 2), successful targeting occurs less than 50% of the time. Is the initial characterization consistent with the accuracy in this context? To what extent does inaccuracy in targeting contribute to the subtlety of affecting trajectory coherence and speed? Is there a relationship between animal speed and disruption of the trajectory?</p>
</disp-quote>
<p>We thank the reviewer for pointing out the discrepancy in the reported maximum speed. We have corrected the error in the main text: the average maximum speed is 142 ± 26 mm/s (four mice).</p>
<p>The self-paced T-maze alternation task in Figure 5 demonstrates that mice running in a maze can be stimulated using this method. We did not optimize the particular experimental design to assess the hit accuracy, as this was determined in Figure 2. Instead, we optimized for the pulse frequencies, meaning the galvanometers tracked with processed frames but the laser was triggered whether or not the paw was actually targeted. However, even in this case with the system pulsing in the free-run mode, the laser hit rate was 54 ± 6% (mean ± sem, n = 7 mice). We have weakened references to submillimeter as it was only inferred from other experiments and was not directly measured here. We find in this experiment that stimulation in freely moving mice can cause them to briefly halt and evaluate. In the future, we will use experimental designs to more optimally examine learning.</p>
<p>The reviewer also asks if there is a relationship between speed and disruption of the trajectory. We find that this is the case as described above with our additional analysis.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #3 (Public review)</bold>:</p>
<p>Summary:</p>
<p>To explore the diverse nature of somatosensation, Parkes et al. established and characterized a system for precise cutaneous stimulation of mice as they walk and run in naturalistic settings. This paper provides a framework for real-time body part tracking and targeted optical stimuli with high precision, ensuring reliable and consistent cutaneous stimulation. It can be adapted in somatosensation labs as a general technique to explore somatosensory stimulation and its impact on behavior, enabling rigorous investigation of behaviors that were previously difficult or impossible to study.</p>
<p>Strengths:</p>
<p>The authors characterized the closed-loop system to ensure that it is optically precise and can precisely target moving mice. The integration of accurate and consistent optogenetic stimulation of the cutaneous afferents allows systematic investigation of somatosensory subtypes during a variety of naturalistic behaviors. Although this study focused on nociceptors innervating the skin (Trpv1::ChR2 animals), this setup can be extended to other cutaneous sensory neuron subtypes, such as low-threshold mechanoreceptors and pruriceptors. This system can also be adapted for studying more complex behaviors, such as the maze assay and goal-directed movements.</p>
<p>Weaknesses:</p>
<p>Although the paper has strengths, its weakness is that some behavioral outputs could be analyzed in more detail to reveal different types of responses to painful cutaneous stimuli. For example, paw withdrawals were detected after optogenetically stimulating the paw (Figures 3E and 3F). Animals exhibit different types of responses to painful stimuli on the hind paw in standard pain assays, such as paw lifting, biting, and flicking, each indicating a different level of pain. Improving the behavioral readouts from body part tracking would greatly strengthen this system by providing deeper insights into the role of somatosensation in naturalistic behaviors. Additionally, if the laser spot size could be reduced to a diameter of 2 mm², it would allow the activation of a smaller number of cutaneous afferents, or even a single one, across different skin types in the paw, such as glabrous or hairy skin.</p>
</disp-quote>
<p>We thank the reviewer for highlighting how our system can be combined with improved readouts of coping behavior to provide deeper insights. Optogenetic and infrared cutaneous stimulation are well established generators of coping behaviors (lifting, flicking, licking, biting, guarding). Detection of these behaviors is an active and evolving field with progress being made regularly (e.g. Jones et al., eLife 2020 [PAWS];  Wotton et al., Mol Pain 2020; Zhang et al., Pain 2022; Oswell et al., bioRxiv 2024 [LUPE]; Barkai et al., Cell Reports Methods 2025 [BAREfoot], along with more general tools like Hsu et al., Nature Communications 2021 [B-SOiD]; Luxem et al., Communications Biology 2022 [VAME]; Weinreb et al,. Nature Methods 2024 [Keypoints-MoSeq]). One output of our system is bodypart keypoints, which are the typical input to many of these tools. We will leave the readers and users of the system to decide which tools are appropriate for their experimental designs - the focus of this current manuscript is describing the novel stimulation approach in moving animals.</p>
<disp-quote content-type="editor-comment">
<p><bold>Recommendations for the authors:</bold></p>
<p><bold>Reviewer #1 (Recommendations for the authors)</bold>:</p>
<p>(1) It is hard to see how the rig is arranged from the render of Figure 2AB due to the components being black on black. A particularly useful part of Fig2AB is the aerial view in panel B that shows the light paths. I suggest adding the labelling of Figure 2A also to that. The side/rear views could perhaps be deleted, allowing the aerial view to be larger.</p>
</disp-quote>
<p>We appreciate this suggestion and have revised Figure 2B to improve the visibility of the optomechanical components. We have enlarged the side and aerial views, removed the rear view, and added further labels to the aerial view.</p>
<disp-quote content-type="editor-comment">
<p>(2) MAE - to interpret the 0.54 result, it would be useful to state the arena size in this paragraph.</p>
</disp-quote>
<p>Thank you. We have added the arena size in this paragraph and also added scales in the relevant figure (Figure 2).</p>
<disp-quote content-type="editor-comment">
<p>(3) &quot;pairwise correlations of R = 0.999 along both x- and y-axes&quot;. Is this correlation between hindpaw keypoint and galvo coordinates?</p>
</disp-quote>
<p>Yes, we have added the following to clarify: “...between galvanometer coordinates and hind paw keypoints”</p>
<disp-quote content-type="editor-comment">
<p>(4) Latency was 84 ms. Is this mainly/entirely the delay between DLC receiving the camera image and outputting key point coordinates?</p>
</disp-quote>
<p>Yes, we hope that the additional detail in the Methods and Discussion described above will now clarify the current closed-loop latencies.</p>
<disp-quote content-type="editor-comment">
<p>(5) &quot;Mice move at variable speeds&quot;: in this sentence, spell out when &quot;speed&quot; refers to mouse and when it refers to hindpaw. Similarly, Fig 2i. The sentence is potentially confusing to general readers (paws stationary although the mouse is moving). Presumably, it's due to gait. I suggest explaining this here.</p>
</disp-quote>
<p>The speed values that relate to the mouse body and paws are now clearer in the main text and in the legend for Figure 2I.</p>
<disp-quote content-type="editor-comment">
<p>(6) Figure 2k and associated main text. It is not clear what &quot;success/hit rate&quot; means here.</p>
</disp-quote>
<p>We have added the following sentence in the main text: “Hit accuracy refers to the percentage of trials in which the laser successfully targeted (‘hit’) the intended hind paw.” and use hit accuracy throughout instead of success rate.</p>
<disp-quote content-type="editor-comment">
<p>(7) Figure 2L. All these points are greater than the &quot;average&quot; 0.54 reported in the text. How is this possible?</p>
</disp-quote>
<p>The MAE of 0.54 mm refers to the “predicted and actual laser spot locations” (that is, the difference between where the calibration map should place the laser spot and where it actually fell), while Figure 2L MAE values refers to the error between the ground truth keypoint to laser spot (that is, the error between the human-observed paw target and where the laser spot fell). The latter error will include the former error so is expected to be larger. We have clarified this point throughout the text, for example, stating “As laser targeting relies on real-time tracking to direct the laser to the specified body part, this metric inherently accounts for any errors introduced by the tracking and targeting.”. This is also discussed above in response to Reviewer 2.</p>
<disp-quote content-type="editor-comment">
<p>(8) &quot;large circular arena&quot;. State the size here</p>
</disp-quote>
<p>We have added this to the Figure 2 legend.</p>
<disp-quote content-type="editor-comment">
<p>(9) Figure 3c-left. Can the contrast between the mouse and floor be increased here?</p>
</disp-quote>
<p>We have improved the contrast in this image.</p>
<disp-quote content-type="editor-comment">
<p>(10) Figure 5c. It is unclear what C1, C2, etc refers to. Mice?</p>
</disp-quote>
<p>Yes, these refer to mice. We have removed reference to these now as they are not needed.</p>
<disp-quote content-type="editor-comment">
<p>(11) Discussion. A comment. There is scope for elaborating on the potential for new research by combining it with new methods for measurements of neural activity in freely moving animals in the somatosensory system.</p>
</disp-quote>
<p>Thank you. We agree and have added more detail on this in the discussion stating “The system may be combined with existing tools to record neural activity in freely-moving mice, such as fiber photometry, miniscopes, or large-scale electrophysiology, and manipulations of this neural activity, such as optogenetics and chemogenetics. This can allow mechanistic dissection of cell and circuit biology in the context of naturalistic behaviors.”</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #3 (Recommendations for the authors)</bold>:</p>
<p>(1) Include the number of animals for behavior assays for the panels (e.g., Figures 4G).</p>
</disp-quote>
<p>Where missing, we now state the number of animals in panels.</p>
<disp-quote content-type="editor-comment">
<p>(2) If representative responses are shown, such as in Figures 3E and 4F, include the average response with standard deviation so readers can appreciate the variation in the responses.</p>
</disp-quote>
<p>We appreciate the suggestion to show variability in the responses. We have made several changes to Figures 3 and 4. Specifically, to illustrate the variability across multiple trials more clearly, Figure 3E now shows representative keypoint traces for each body part from two mice during their 5 trials. For Figure 4, we have re-analyzed the thermal stimulation trials and shown a raster plot of keypoint-based local motion energy (Figure 4E) sorted by response latency for hundreds of trials. Figure 4G now presents the cumulative distribution for all trials and animals for thermal (18 wild-type mice, 315 trials) and optogenetic stimulation trials (9 Trpv1::ChR2 mice, 181 trials). We also now provide means ± SD for the key metrics for optogenetic and thermal stimulation trials in Figure 4 in the Results section. This keeps the manuscript focused on the methodological advances while showing the trial variability.</p>
<disp-quote content-type="editor-comment">
<p>(3) &quot;optical targeting of freely-moving mice in a large environments&quot; should be &quot;optical targeting of freely-moving mice in a large environment&quot;.</p>
</disp-quote>
<p>Corrected</p>
<disp-quote content-type="editor-comment">
<p>(4) Define fps when you first mention this in the manuscript.</p>
</disp-quote>
<p>Added</p>
<disp-quote content-type="editor-comment">
<p>(5) Data needs to be shown for the claim &quot;Mice concurrently turned their heads toward the stimulus location while repositioning their bodies away from it&quot;.</p>
</disp-quote>
<p>We state this observation to qualify that the stimulation of stationary mice resulted in behavioral responses “consistent with previous studies”. It would be redundant to repeat our full analysis and might distract from the novelty of the current manuscript. We have restricted this sentence to make it clearer: “Consistent with previous studies, we observed the whole-body behaviors like head orienting concurrent with local withdrawal (Browne et al., Cell Reports 2017; Blivis et al., eLife, 2017.)”</p>
</body>
</sub-article>
</article>