<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">100084</article-id>
<article-id pub-id-type="doi">10.7554/eLife.100084</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.100084.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Semantic plasticity across timescales in the human brain</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0003-9814-2436</contrib-id>
<name>
<surname>Solomon</surname>
<given-names>Sarah H</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6604-9155</contrib-id>
<name>
<surname>Kay</surname>
<given-names>Kendrick</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8086-0331</contrib-id>
<name>
<surname>Schapiro</surname>
<given-names>Anna C</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Psychology, University of Pennsylvania</institution></aff>
<aff id="a2"><label>2</label><institution>Radiology, University of Minnesota</institution></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Bottini</surname>
<given-names>Roberto</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Trento</institution>
</institution-wrap>
<city>Trento</city>
<country>Italy</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Bi</surname>
<given-names>Yanchao</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Beijing Normal University</institution>
</institution-wrap>
<city>Beijing</city>
<country>China</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>Corresponding author; email: <email>sarahsol@sas.upenn.edu</email></corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-08-14">
<day>14</day>
<month>08</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP100084</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-06-06">
<day>06</day>
<month>06</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-05-24">
<day>24</day>
<month>05</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.02.07.579310"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Solomon et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Solomon et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-100084-v1.pdf"/>
<abstract>
<title>Abstract</title><p>Our representations of the world need to be stable enough to support general knowledge but flexible enough to incorporate new information as our environment changes. How does the human brain manage this stability-plasticity trade-off? We analyzed a large dataset in which participants viewed objects embedded in thousands of natural scenes across many fMRI sessions. Semantic item representations were located by jointly leveraging a voxelwise encoding model to find reliable item representations and a word-embedding model to evaluate semantic content. Within the medial temporal lobe, semantic item representations in hippocampal subfield CA1, parahippocampal cortex, and perirhinal cortex gradually drifted across a period of multiple months. Whole-brain analyses revealed a gradient of plasticity in the temporal lobe, with drift more evident in anterior than posterior areas. On short timescales, rapid plasticity was observed only in parahippocampal cortex, such that item co-occurrence statistics warped item representations within a single session. Together, the results suggest that the brain solves the stability-plasticity trade-off through a gradient of plasticity across semantic regions.</p>
</abstract>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>The main changes in this version of the manuscript are an updated title and extra supplemental material. A statement on whole-brain drift results was added to the abstract, and a sentence clarifying the nature of semantic memory was added to the main manuscript.</p></fn>
</fn-group>
<fn-group content-type="external-links">
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://naturalscenesdataset.org">https://naturalscenesdataset.org</ext-link>
</p></fn>
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://cocodataset.org">https://cocodataset.org</ext-link>
</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<label>1.</label><title>Introduction</title>
<p>The human brain flexibly adjusts its representations of the world as the environment continually changes, yet these representations remain stable enough to be useful over time. This trade-off between stability and plasticity is a pervasive tension that manifests broadly within biological and artificial systems (<xref ref-type="bibr" rid="c29">Meyer et al., 2014</xref>; <xref ref-type="bibr" rid="c61">Wandell &amp; Smirnakis, 2009</xref>; <xref ref-type="bibr" rid="c10">Carpenter &amp; Grossberg, 1987</xref>). When it comes to our units of knowledge about the world (“concepts”), this knowledge must be mutable enough to be molded by new semantic content and associations but resilient enough to not be completely overwritten. Semantic memory encompasses the multifaceted organized knowledge (e.g., perceptual, emotional, relational) that enables us to recognize, comprehend, and make inferences about objects and events (<xref ref-type="bibr" rid="c45">Smith &amp; Estes, 1978</xref>; Rogers &amp; McClelland, 2008; <xref ref-type="bibr" rid="c6">Binder &amp; Desai, 2011</xref>). Semantic plasticity is evident across short and long timescales as our experiences accumulate over days and across a lifetime. For example, your concept of <italic>crickets</italic> likely includes that they are insects that can chirp and jump and are found among trees and patio furniture in summers. However, if you visit a street vendor in Thailand, your concept will update accordingly: crickets are also a crunchy, nutty-flavored fried snack found alongside beer and peanuts. Your <italic>cricket</italic> concept is malleable enough to absorb these new data without your forgetting everything you previously knew about crickets. Concepts can be substantially modified as new information is learned, as in this example, but can also undergo subtle shifts in response to a constantly changing environment (<xref ref-type="bibr" rid="c34">Rogers &amp; McClelland, 2004</xref>; <xref ref-type="bibr" rid="c33">Musz &amp; Thompson-Schill, 2015</xref>).</p>
<p>One type of semantic information that is updated in this scenario is the set of items with which crickets are associated. You previously knew that crickets co-occur with patio furniture and trees, and now you also know that they co-occur with beer and peanuts. Semantic structure—i.e., the web of associations between semantic items or features— is a fundamental component of semantic knowledge. Associations among semantic features have consequences for how categories are learned (<xref ref-type="bibr" rid="c46">Solomon &amp; Schapiro, 2023</xref>) and how their labels are used in language (<xref ref-type="bibr" rid="c47">Solomon et al., 2019</xref>). Encoding associations between concepts themselves builds our “thematic” semantic knowledge, which includes contiguity relations based on co-occurrence in events or scenarios (<xref ref-type="bibr" rid="c32">Mirman et al., 2017</xref>) and influences semantic behavior such as relatedness judgments and word recall (<xref ref-type="bibr" rid="c63">Wisniewski &amp; Bassok, 1999</xref>; <xref ref-type="bibr" rid="c9">Cann et al., 2011</xref>). If two items co-occur often, they likely play complementary roles within situations or events and are judged to be semantically related (e.g., <italic>flower</italic> and <italic>vase</italic>; <italic>cake</italic> and <italic>birthday candle</italic>). Therefore, updating this associative structure has semantic consequences: realizing that crickets can co-occur with beer and peanuts infuses the <italic>cricket</italic> concept with new semantic information. We do not yet know how the human brain dynamically updates representations of semantic structure within a constantly changing environment.</p>
<p>Semantic plasticity requires new structure to be learned, and this new information must then be integrated into existing semantic representations. Much is already known about how humans learn <italic>novel</italic> structure when it is isolated from our existing world knowledge. In a phenomenon known as statistical learning, humans can implicitly learn associative structure embedded among stimuli across a wide range of domains (e.g., <xref ref-type="bibr" rid="c38">Saffran et al., 1996</xref>; <xref ref-type="bibr" rid="c16">Frost et al., 2019</xref>). This learning occurs automatically, even when the structure is irrelevant to the task. The neural correlates of this learning have been thoroughly explored and suggest important contributions from the medial temporal lobe (MTL), including the hippocampus (<xref ref-type="bibr" rid="c11">Covington et al., 2018</xref>; <xref ref-type="bibr" rid="c41">Schapiro et al., 2012</xref>; <xref ref-type="bibr" rid="c40">2014</xref>; <xref ref-type="bibr" rid="c43">2016</xref>; <xref ref-type="bibr" rid="c57">Turk-Browne et al., 2009</xref>; <xref ref-type="bibr" rid="c58">2010</xref>; <xref ref-type="bibr" rid="c7">Bornstein &amp; Daw, 2012</xref>; <xref ref-type="bibr" rid="c19">Harrison et al., 2006</xref>; <xref ref-type="bibr" rid="c52">Strange et al., 2005</xref>). Neural representations corresponding to individual items shift as a result of structure learning, with associated items evoking more similar neural patterns post-learning (<xref ref-type="bibr" rid="c41">Schapiro et al., 2012</xref>, <xref ref-type="bibr" rid="c43">2016</xref>; <xref ref-type="bibr" rid="c60">Wammes et al., 2022</xref>). Our computational model of the hippocampus implicates subfield CA1 in particular in the extraction of novel structure (<xref ref-type="bibr" rid="c42">Schapiro et al., 2017</xref>; <xref ref-type="bibr" rid="c53">Sučević &amp; Schapiro, 2023</xref>).</p>
<p>Understanding how newly experienced semantic structure is incorporated into existing knowledge representations also requires an understanding of how that structure is represented in long-term memory in the first place. While the precise neural underpinnings are still unknown, temporo-parietal cortex is often implicated in language-based tasks of thematic knowledge (<xref ref-type="bibr" rid="c32">Mirman et al., 2017</xref>). In the context of (non-language) visual tasks, experiments have localized and examined the neural representation of object associations. In particular, the parahippocampal cortex has been implicated in visual object semantics (Bonner et al., 2016) and, more specifically, appears to represent the long-term co-occurrence statistics of objects in natural scenes (Stansbury et al., 2013; Bonner &amp; Epstein, 2021).</p>
<p>This leads to our key question: How is new information integrated with these existing representations of semantic structure? More generally, the question of how new information is integrated into long-term memory is an active area of inquiry within biological and artificial systems (<xref ref-type="bibr" rid="c26">McClelland et al., 1995</xref>, <xref ref-type="bibr" rid="c27">2020</xref>; <xref ref-type="bibr" rid="c20">Hebscher et al., 2019</xref>; <xref ref-type="bibr" rid="c59">van Kesteren et al., 2012</xref>). Systems consolidation theories posit that new declarative memories are first encoded in the hippocampus and then integrated slowly, over time and sleep, into neocortical sites (<xref ref-type="bibr" rid="c26">McClelland et al., 1995</xref>; <xref ref-type="bibr" rid="c50">Squire &amp; Zola-Morgan, 1991</xref>; <xref ref-type="bibr" rid="c12">Diekelmann &amp; Born, 2010</xref>). However, recent theories suggest that direct rapid cortical learning can occur in certain circumstances, particularly when the new information is consistent with prior knowledge (<xref ref-type="bibr" rid="c27">McClelland et al., 2020</xref>; <xref ref-type="bibr" rid="c20">Hebscher et al., 2019</xref>; <xref ref-type="bibr" rid="c59">van Kesteren et al., 2012</xref>). This suggests that while substantial updates to semantic knowledge may require a hippocampus-dependent gradual consolidation process, more subtle semantic shifts might be implemented rapidly and directly in cortical circuits.</p>
<p>A phenomenon of recent interest known as “representational drift” might provide additional insight into this problem. Not only do neural activation patterns change to accommodate new learning, but they gradually change over time even in the apparent absence of new knowledge or behavior (<xref ref-type="bibr" rid="c37">Rule et al., 2019</xref>; <xref ref-type="bibr" rid="c13">Driscoll et al., 2017</xref>, <xref ref-type="bibr" rid="c14">2022</xref>; <xref ref-type="bibr" rid="c30">Micou &amp; O’Leary, 2023</xref>). The mechanisms underlying representational drift and how it bears on theories of cortical function are still debated, but some have suggested that it might support the kind of continual learning described above (<xref ref-type="bibr" rid="c14">Driscoll et al., 2022</xref>). Regarding semantic knowledge, representational drift has been compared to the continual changes of successfully learned category representations within the layers of artificial networks (<xref ref-type="bibr" rid="c30">Micou &amp; O’Leary, 2023</xref>). The phenomenon of representational drift might provide leverage into understanding semantic plasticity and how it unfolds across different timescales. To our knowledge, representational drift of semantic information has not yet been investigated in humans.</p>
<p>Here our goal is to examine how semantic representations shift over time and in response to changing environments (<xref rid="fig1" ref-type="fig">Fig. 1</xref>). Despite clear flexibility within the human semantic system (Yee &amp; Thompson-Schill, 2016; <xref ref-type="bibr" rid="c48">Solomon &amp; Thompson-Schill, 2017</xref>, <xref ref-type="bibr" rid="c49">2020</xref>; <xref ref-type="bibr" rid="c47">Solomon et al., 2019</xref>; <xref ref-type="bibr" rid="c33">Musz &amp; Thompson-Schill, 2015</xref>), neural approaches to object semantics typically make an implicit assumption of representational stability. We challenge this assumption, capitalizing on a rich fMRI dataset—in which each participant viewed thousands of visual scenes over the course of many months—to explore whether and how semantic representations change over short and long timescales in the human brain. We focus on the MTL because of its known contributions to rapid learning and visual object semantics, and its theorized joint role in perceptual and memory processes (<xref ref-type="bibr" rid="c18">Graham et al., 2010</xref>; <xref ref-type="bibr" rid="c25">Martin &amp; Barense, 2023</xref>). We uncover reliable object representations across the MTL and find that object representations in hippocampal subfield CA1, parahippocampal cortex (PHC), and perirhinal cortex (PRC) contain semantic information. Within these semantic regions, we find that object representations drift across the span of ∼8-months, with PHC showing the highest rate of drift. Finally, we find evidence that changes in these PHC object representations are explained by changes in semantic structure within the recent (∼1 hour) visual environment. Whole-brain analyses further reveal a distribution of representational flexibility across ventral temporal cortex. Together, the results demonstrate that PHC contains object semantics that dynamically update, whereas more posterior areas represent object semantics in a more stable manner. The semantic system may thus solve the stability plasticity trade-off by allowing only a subset of its representations to rapidly adapt to a changing environment.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Natural scenes and item co-occurrences.</title>
<p>(A) Stimuli consisted of natural scene photographs from the COCO image database (<ext-link ext-link-type="uri" xlink:href="http://cocodataset.org">http://cocodataset.org</ext-link>). The first example image contains a cat and plants, the second contains a cat and a cake, and the third contains a cat and books. (B) We test whether items that share recent patterns of co-occurrence <italic>(plant, cake</italic>, and <italic>book</italic> all co-occur with cat) become more similarly represented in the brain. Axes are hypothetical dimensions of neural activity, and proximity of items within this space reflects the similarity of their neural representations.</p></caption>
<graphic xlink:href="579310v2_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2">
<label>2.</label><title>Results</title>
<p>We analyzed data from the NSD experiment (Allen et al., 2022), in which participants viewed thousands of natural scenes across ≥30 fMRI sessions over the span of ∼8 months. The stimuli were real-world photographs containing familiar objects, including tools, vehicles, and animals (e.g., cake, plant, book; <xref rid="fig1" ref-type="fig">Fig. 1A</xref>). Our key goal was to explore the plasticity of semantic representations in the brain. To do this, we first implemented a voxel-wise object encoding model in order to locate reliable item (object) representations across the brain (<xref rid="fig2" ref-type="fig">Fig. 2A</xref>). We then found the regions in which these item representations were semantic in nature, using a word-embedding model that captures semantic similarities using word co-occurrences in text (<xref rid="fig2" ref-type="fig">Fig. 2B</xref>). Once semantic item representations were located, we could then explore the plasticity of these representations on different timescales. We assessed long-term plasticity by examining the extent to which item representations drifted across the course of the experiment (∼8 months; <xref rid="fig2" ref-type="fig">Fig. 2C</xref>). To assess short-term plasticity, we asked whether item co-occurrence statistics in the first half of a session predicted item similarities in the second half of the session (<xref rid="fig2" ref-type="fig">Fig. 2D</xref>).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Methodological approach.</title>
<p>Multiple measures were extracted from searchlights across the brain. (A) The fidelity of item representations was assessed using a voxel-wise encoding model that predicted each voxel’s response to each of the 80 objects. (B) Semantic content was assessed by comparing neural across-item similarity with the similarities contained within a word embedding model. (C) Representational drift corresponded to decreases in within-item neural similarity over time. (D) We calculated sensitivity to recent statistical structure of the stimuli by determining whether the statistical structure in the first half of a session influenced neural across-item similarity in the second half of a session. We subtracted the correlation in the opposite direction as a tight control to ensure our measure reflected a time-dependent influence of recent structure on neural representation.</p></caption>
<graphic xlink:href="579310v2_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>The degree of successful item decoding, semantic content, representational drift, and sensitivity to recent statistics was measured in searchlights across the brain (<xref rid="fig2" ref-type="fig">Fig. 2</xref>).</p>
<p>Searchlight values were averaged within ROIs that included hippocampal subfield CA1; a combined ROI including hippocampal subfields CA2, CA3, and dentate gyrus (DG); the subiculum; parahippocampal cortex (PHC), perirhinal cortex (PRC), and control region V1. Note that we use the term PHC in the context of its definition within the MTL (<xref ref-type="bibr" rid="c21">Hindy &amp; Turk-Browne, 2016</xref>). Whole-brain results are also reported.</p>
<sec id="s2a">
<title>Object Encoding</title>
<p>We first determined which brain regions contained reliable item representations, since these item representations were the focus of our subsequent analyses. A voxel-wise object encoding model was used to determine which regions of the MTL encoded the identity of the 80 items (<xref rid="fig2" ref-type="fig">Figs. 2A</xref>; 3A). Successful object encoding (all <italic>p</italic>’s <italic>&lt;</italic> 0.008) was observed in all MTL ROIs as well as in V1 (<xref rid="fig3" ref-type="fig">Fig. 3B</xref>). These results revealed that each of these brain regions—including the hippocampal subfields— contained reliable object representations evoked by the natural scenes. A whole-brain analysis revealed widespread encoding success across much of the brain, especially in visually responsive cortex (<xref rid="fig3" ref-type="fig">Fig. 3C</xref>).</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3:</label>
<caption><title>Item encoding.</title>
<p>(A) A voxel-wise encoding model employing cross-validated ridge regression was used to predict each voxel’s response to the 80 items and to subsequently predict multivoxel activity patterns evoked by individual scenes. Predictions were compared to actual neural responses to determine the fidelity of item representations across the brain. Item encoding was successful within all ROIs (B) and large swaths of cortex (C).</p></caption>
<graphic xlink:href="579310v2_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2b">
<title>Semantic Content in the MTL</title>
<p>Having established the locations of reliable item representations, we then sought to determine whether these representations contained semantic information. The encoding model generated predicted patterns of neural activity for each item; these patterns were correlated with each other to generate a neural similarity matrix. Neural similarity was then compared with semantic similarity, which was captured using word2vec (<xref rid="fig2" ref-type="fig">Fig. 2B</xref>), a measure of similarity derived from word co-occurrences in text. Semantic similarity reliably correlated with neural similarity in hippocampal subfield CA1 (<italic>t</italic>(7)=3.2, <italic>p</italic>=0.015), PHC (<italic>t</italic>(7)=5.52, <italic>p</italic>=0.0009), and PRC (<italic>t</italic>(7)=2.65, <italic>p</italic>=0.033). Semantic similarity did not reliably predict neural item similarity in the other hippocampal subfields (CA23DG: <italic>t</italic>(7)=2.14, <italic>p</italic>=0.069; SUB: <italic>t</italic>(7)=2.3, <italic>p</italic>=0.055) or in EC (<italic>t</italic>(7)=1.53, <italic>p</italic>=0.17). A significant negative effect was observed in V1 (<italic>t</italic>(7)=-4.97, <italic>p</italic>=0.002). This negative effect can be explained by a constraint we implemented in which only pairs of items that never co-occurred were analyzed (see Supplemental Figure 1). This was done to eliminate the possibility that items appearing in the same images would inflate the similarity between neural and semantic spaces. The observed negative relationship between semantic similarity and neural similarity in V1 was likely driven by the fact that items with high semantic similarity often occur in visually dissimilar scenes—for example, snowboards and surfboards are semantically similar but occur in very different visual contexts. Thus, our results reveal that evoked object representations in CA1, PHC, and PRC are semantic in nature (<xref rid="fig4" ref-type="fig">Fig. 4A</xref>). A whole-brain analysis additionally revealed reliable semantic content within some of the more anterior areas with reliable item representations (<xref rid="fig4" ref-type="fig">Fig. 4B</xref>). Establishing semantic content within CA1, PHC, and PRC set the stage to then examine the plasticity of these semantic representations over time.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Semantic content.</title>
<p>(A) Neural across-item similarities positively correlated with semantic similarities extracted from a word embedding model in CA1, PHC, and PRC. (B) Item representations were semantic in nature within a subset of temporal, parietal, and cingulate regions that exhibited successful item encoding.</p></caption>
<graphic xlink:href="579310v2_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2c">
<title>Long-term Drift of Item Representations in the MTL</title>
<p>Having established semantic representations in CA1, PHC, and PRC, we aimed to determine whether these representations gradually drifted over time. If neural activity for a given item drifts over the span of months, then within-item pattern similarity would be more similar for sessions closer together in time (e.g., sessions 1 and 2) than for sessions more separated in time (e.g., sessions 1 and 30), with the degree of similarity scaling with the number of intervening sessions (<xref rid="fig2" ref-type="fig">Fig. 2C</xref>). That is, within-item similarity would decrease as the number of intervening sessions increased (<xref rid="fig5" ref-type="fig">Fig. 5A</xref>). On average, there were approximately 8 days in between sessions. Reliable drift was observed in all semantic ROIs (<xref rid="fig5" ref-type="fig">Fig. 5B</xref>), including CA1 (<italic>t</italic>(7)=2.81, <italic>p</italic>=0.026), PHC (<italic>t</italic>(7)=3.44, <italic>p</italic>=0.012), and PRC (<italic>t</italic>(7)=3.68, <italic>p</italic>=0.008). Drift was not observed in V1 (<italic>t</italic>(7)=1.46, <italic>p</italic>=0.18). Drift in PHC was reliably greater than in PRC (<italic>t</italic>(7)=2.86, <italic>p</italic>=0.024) and marginally greater than in CA1 (<italic>t</italic>(7)=2.30, p=0.055) and V1 (<italic>t</italic>(7)=2.28, <italic>p</italic>=0.056). No other comparisons were significant (<italic>p</italic>’s &gt; 0.1). This drift effect cannot be explained by an increase or decrease in semantic content within neural representations across the course of the experiment; correspondence between neural and semantic similarity spaces, established using word2vec, was stable over time, with no increase or decrease across the thirty sessions (CA1, PHC, PRC, and V1 <italic>p</italic>’s &gt; 0.4). A whole-brain analysis revealed reliable drift of item representations in anterior ventral temporal cortex, predominantly in the left hemisphere. It is notable that not all regions containing semantic representations revealed the same amount of drift (<xref rid="fig5" ref-type="fig">Fig. 5C</xref>), suggesting a gradient of stability to plasticity within the semantic system (see Supplemental Figure 2 for further analysis). Taken together, these analyses confirm the existence of drift in semantic object representations over long time-scales and suggest that these representations may drift at different rates in different brain regions. More generally, these results demonstrate the plasticity of neural object representations, leaving open the question of what factors contribute to these representational changes.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Representational drift across long timescales.</title>
<p>Within regions containing semantic item representations, we asked whether these representations drifted across the 30 sessions (∼8 months). (A) Within-item neural similarity was regressed against number of intervening sessions. Negative slopes indicate representational drift, where item representations gradually changed over time. Circles reflect average item similarity across participants at each time interval, and the solid line indicates the linear fit. Dashed lines indicate fits for individual participants. (B) Drift was significant in all semantic ROIs but not in V1. (C) Only a subset of semantic regions exhibited significant drift in item representations over time.</p></caption>
<graphic xlink:href="579310v2_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2d">
<title>Recent Structure Rapidly Influences Item Representations in PHC</title>
<p>We observed that regions within the MTL (CA1, PHC, and PRC) and temporal cortex contained semantic item representations that drifted over long periods of time. Here we ask whether and where semantic shifts might occur more rapidly (within a single fMRI session), and whether the recent semantic environment can drive such shifts. To do this, we compared item co-occurrence structure in the first half of a session with across-item neural similarity in the second half of that session to determine whether recent structure in the environment results in rapid representational change (<xref rid="fig2" ref-type="fig">Figs. 2D</xref>; 6A). That is, if two items tend to occur with the same items in the first half of the session, are they represented more similarly in the second half of the session? Importantly, we implemented a tight control, in which we also calculated the correlation between item statistics in the second half of the session with neural similarity in the first half of a session. We subtracted this backwards correlation from the forwards correlation to ensure that our results signify a time-dependent effect of recent co-occurrence structure on neural similarity. We found that recent structure rapidly influenced the neural similarity of items in PHC (<italic>t</italic>(7)=3.1, <italic>p</italic>=0.017). This result was marginal in CA1 (<italic>t</italic>(7)=2.28, <italic>p</italic>=0.056), and was not significant in either PRC (<italic>t</italic>(7)=1.11, <italic>p</italic>=0.3) or in V1 (<italic>t</italic>(7)=0.42, <italic>p</italic>=0.68). These results suggest that the semantic plasticity in PHC is in part explained by the rapid influence of recent structure on neural object representations (<xref rid="fig6" ref-type="fig">Fig. 6B</xref>).</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Influence of recent statistical structure on item representations.</title>
<p>(A) Structural similarity between pairs of items was calculated using a network modularity approach. Items that tended to occur with the same items across trials have a higher likelihood of being assigned to the same module and thus were structurally “similar”. (B) For a pair of items, structural similarity in the first half of a session predicted neural similarity in the second half of a session in PHC, but not in other semantic ROIs or in V1. (C) A whole-brain analysis revealed a significant cluster that overlaps with the PHC ROI (black outline), as well as clusters in right fusiform cortex and bilateral clusters in posterior middle temporal gyrus (not shown).</p></caption>
<graphic xlink:href="579310v2_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We correlated the rapid structure effect in each session with a measure capturing the degree of similarity (“structure match”) between recent and long-term item co-occurrence structure. We observed that PHC representations were more likely to change when the recent structure (i.e., structure in the first half of the session) differed from long-term structure (<italic>t</italic>(7)=3.0, <italic>p</italic>=0.012). In other words, PHC updated its item representations more when it was confronted with more novel structural information (<xref rid="fig7" ref-type="fig">Fig. 7</xref>).</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7.</label>
<caption><title>Relationship between recent and long-term structure.</title>
<p>The similarity between long-term item co-occurrence structure and the structure in the first half of each session predicted the degree of structure-induced change in PHC, indicating that PHC updated its representations in the face of new information.</p></caption>
<graphic xlink:href="579310v2_fig7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>In a whole-brain analysis, we explored whether semantic regions outside the MTL also contained item representations that were rapidly influenced by recent structure. Notably, this analysis revealed a significant cluster that overlapped with our PHC ROI (<xref rid="fig6" ref-type="fig">Fig. 6C</xref>). Additionally, we observed a significant cluster extending into the right fusiform cortex and bilateral clusters in posterior middle temporal gyrus. The locations of the ventral temporal clusters fell anterior to the parahippocampal place area (PPA) and fusiform face area (FFA), as assessed on the cortical surface (Supplemental Figure 3).</p>
</sec>
</sec>
<sec id="s3">
<label>3.</label><title>Discussion</title>
<p>How plastic are semantic representations in the human brain? To address this question, we analyzed data from an fMRI experiment in which participants viewed objects embedded in thousands of natural scenes across the span of approximately eight months. We found reliable representations of the objects in large swaths of visual and temporal cortices, including all regions of interest within the medial temporal lobe (MTL). A subset of these regions contained item representations that were semantic in nature, including hippocampal subfield CA1, parahippocampal cortex (PHC), and perirhinal cortex (PRC). These semantic item representations gradually drifted across the eight months, with the highest level of drift observed in PHC. On short timescales (within ∼1 hour), representational change in PHC was predicted by the object co-occurrence structure embedded within recently observed visual scenes, suggesting that item representations in PHC are rapidly influenced by the statistical structure of the semantic environment.</p>
<p>Our finding that item representations in PHC are influenced by recent object co-occurrence statistics suggests that this region is involved in rapid semantic learning, at least in the context of viewing natural scenes (<xref rid="fig1" ref-type="fig">Fig. 1</xref>). The location of this effect is anterior to the parahippocampal place area (PPA), which is functionally defined as a region recruited during scene perception (<xref ref-type="bibr" rid="c54">Sun et al., 2021</xref>). The location of our learning effect relative to typical perception effects is consistent with the idea of a functional gradient in the ventral stream, in which posterior portions are more involved in visual encoding and spatial associations, whereas anterior portions are more involved in visual memory, scene context, and non-spatial associations (<xref ref-type="bibr" rid="c2">Aminoff et al., 2007</xref>; <xref ref-type="bibr" rid="c4">Bainbridge et al., 2021</xref>; <xref ref-type="bibr" rid="c5">Baldassano et al., 2013</xref>; <xref ref-type="bibr" rid="c51">Steel et al., 2023</xref>). Additionally, our observation that PHC representations are influenced by recent object co-occurrence statistics is consistent with and builds on prior work claiming that this region represents the long-term object co-occurrence structure in natural scenes (Bonner &amp; Epstein, 2021; Stansbury et al., 2013). Here, we show that these structural representations are dynamic—they are constantly modified by recent experience.</p>
<p>The flexibility of item representations in PHC—evidenced by both rapid structural shifts and long-term representational drift—is an important step towards understanding how semantic plasticity unfolds within the human brain. However, PHC’s role in semantic updating more generally is unclear. It is possible that we observed representational change in PHC because its internal computations render it uniquely suited to associative contextual processing (<xref ref-type="bibr" rid="c2">Aminoff et al., 2007</xref>; <xref ref-type="bibr" rid="c3">2013</xref>), but it is also possible that PHC emerged because of its role in the visual processing of naturalistic scenes (<xref ref-type="bibr" rid="c15">Epstein &amp; Baker, 2019</xref>). It will therefore be interesting to test whether our plasticity findings hold in experiments using non-scene stimuli. PHC does seem sensitive to an object’s associations and contexts when items are shown in isolation in the absence of a scene (<xref ref-type="bibr" rid="c2">Aminoff et al., 2007</xref>; Bonner &amp; Epstein, 2021). Further, neuroimaging investigations of thematic semantic processing—involving verbal rather than visual stimuli—implicate regions of posterior temporal cortex in the processing of semantic relations (<xref ref-type="bibr" rid="c32">Mirman et al. 2017</xref>), raising the possibility of a general role of semantic plasticity in PHC. Another possibility is that subtle representational shifts, like the ones reported here, will be found in the diverse regions of the brain responsible for representing the stimulus content itself. In our data, the item co-occurrence statistics are implicitly represented in the similarity space of the neural item representations themselves. It is thus possible that, for any given experiment, semantic plasticity may be observed within the neural regions that represent the particular stimuli used. In other words, it is not yet known whether the plastic representations observed in PHC arise by means of domain-specific or general mechanisms.</p>
<p>We observed only marginal evidence for an influence of statistical structure on item representations in the hippocampus. The hippocampus is known to be sensitive to statistical structure (<xref ref-type="bibr" rid="c11">Covington et al., 2018</xref>; <xref ref-type="bibr" rid="c41">Schapiro et al., 2012</xref>; <xref ref-type="bibr" rid="c40">2014</xref>; <xref ref-type="bibr" rid="c43">2016</xref>; <xref ref-type="bibr" rid="c57">Turk-Browne et al., 2009</xref>; <xref ref-type="bibr" rid="c58">2010</xref>; <xref ref-type="bibr" rid="c7">Bornstein &amp; Daw, 2012</xref>; <xref ref-type="bibr" rid="c19">Harrison et al., 2006</xref>; <xref ref-type="bibr" rid="c52">Strange et al., 2005</xref>; <xref ref-type="bibr" rid="c44">Schlichting et al., 2015</xref>), and we have argued that the properties of hippocampal subfield CA1 in particular are well-suited to rapid learning of statistical associations between stimuli (<xref ref-type="bibr" rid="c42">Schapiro et al., 2017</xref>). The hippocampus can learn novel associations among unfamiliar stimuli such as novel objects and fractals (<xref ref-type="bibr" rid="c44">Schlichting et al., 2015</xref>; <xref ref-type="bibr" rid="c43">Schapiro et al., 2016</xref>) but can also learn novel structure among real-world objects and/or visual scenes (<xref ref-type="bibr" rid="c55">Tompary &amp; Davachi, 2017</xref>; <xref ref-type="bibr" rid="c7">Bornstein &amp; Daw, 2012</xref>). However, in these paradigms, while the stimuli may either be novel or drawn from prior knowledge, the <italic>associations</italic> between stimuli are novel. This is in contrast to the current study, in which the real-world items within the natural scenes were embedded within real-world co-occurrence structure. That is, the statistical structure of the items was consistent with prior structural knowledge (as these were photographs from the real world; <xref rid="fig1" ref-type="fig">Fig. 1A</xref>). Thus, while the hippocampus is necessary for novel structure learning, it might not be necessary for making tweaks to pre-existing structural representations of known items. However, the marginal effect of rapid statistical learning in CA1 leaves open the possibility that the hippocampus did contribute to the rapid learning effects in cortical regions. Future research leveraging hippocampal lesion or perturbation is needed to determine whether the hippocampus plays a causal role.</p>
<p>We did not find reliable evidence of rapid learning in the hippocampus, instead observing robust neocortical learning in PHC. This is inconsistent with a strict conception of systems consolidation in which new information must first be encoded in the hippocampus and then subsequently communicated to neocortex through a gradual consolidation process (<xref ref-type="bibr" rid="c50">Squire &amp; Zola-Morgan, 1991</xref>). It is, however, consistent with a growing body of empirical and theoretical work suggesting that rapid cortical learning can occur under certain circumstances. For example, rapid formation of cortical engrams and “tags” have been demonstrated during learning in rodents (<xref ref-type="bibr" rid="c23">Kitamura et al., 2017</xref>; Lesburguéres et al., 2011), visual exposure to movies of natural scenes results in an immediate memory trace in cat visual cortex (<xref ref-type="bibr" rid="c64">Yao et al., 2007</xref>), and there is MRI evidence in humans for rapid learning-related microstructural changes in parietal cortex and medial temporal lobe cortex (<xref ref-type="bibr" rid="c8">Brodt et al., 2018</xref>; <xref ref-type="bibr" rid="c39">Sagi et al., 2012</xref>). Fast mapping is another phenomenon in which incoming information putatively bypasses traditional hippocampal circuits to be integrated within neocortex (e.g., <xref ref-type="bibr" rid="c28">Merhav et al., 2015</xref>). By examining the conditions that support rapid cortical learning, it appears that one important factor is the extent to which new information is congruent with prior knowledge or existing “schemas” (<xref ref-type="bibr" rid="c56">Tse et al., 2007</xref>; <xref ref-type="bibr" rid="c20">Hebscher et al., 2019</xref>; <xref ref-type="bibr" rid="c59">van Kesteren et al., 2012</xref>; <xref ref-type="bibr" rid="c27">McClelland et al., 2020</xref>). When new information is consistent with what is already known, it can potentially bypass the hippocampally-mediated consolidation process and become rapidly encoded within neocortex. A recent artificial network model offers a computational demonstration of how new information that is congruent with prior knowledge can be rapidly integrated within cortex-like representations, while incongruent information requires a gradual consolidation process involving hippocampal replay of old and new memories (<xref ref-type="bibr" rid="c27">McClelland et al., 2020</xref>).</p>
<p>We observed increased rapid learning in PHC when the structure of the recent environment was more dissimilar from long-term structure, suggesting that PHC updates its representations when confronted with new information. Based on the theory that rapid cortical learning can occur only when the new information is consistent with prior knowledge, one might have predicted the opposite—that increased learning would occur when the recent and long-term structure are more similar. However, the semantic structural changes we explore here are quite subtle. Even the most “dissimilar” co-occurrence structures in our case are likely still highly consistent with prior knowledge; The stimuli were natural images of real-world scenes, with associative structure thus drawn from the known distribution of real-world statistics. Our results are therefore compatible with the view that rapid cortical learning can only occur when the new information is consistent with prior knowledge.</p>
<p>In addition to rapid cortical learning, we also observed representational drift of semantic content over a period of many months. To our knowledge, this is the first such demonstration of semantic representational drift in humans. The phenomenon of representational drift is typically explored in animal models. In one example, mice were trained on a virtual-navigation task such that their behavioral performance was stable across a month. Despite this stable behavior, the individual neurons in posterior parietal cortex that were sensitive to different features of the task changed across days, resulting in the drift of activity patterns over time (<xref ref-type="bibr" rid="c13">Driscoll et al., 2017</xref>). Representational drift can be driven by both time and experience (<xref ref-type="bibr" rid="c17">Geva et al., 2023</xref>), may contribute to the delicate balance between stability and flexibility in learning and memory systems (<xref ref-type="bibr" rid="c13">Driscoll et al., 2017</xref>, <xref ref-type="bibr" rid="c14">2022</xref>), and could play a role in continual learning (<xref ref-type="bibr" rid="c14">Driscoll et al., 2022</xref>; <xref ref-type="bibr" rid="c30">Micou &amp; O’Leary, 2023</xref>). Notably, there is recent evidence of representational drift in humans: <xref ref-type="bibr" rid="c35">Roth &amp; Merriam (2023)</xref> recently used the Natural Scenes Dataset to reveal drift of representations in early visual cortex. We did not observe drift in V1 in the current study, but we targeted object representations, which would be expected to manifest more anteriorly, whereas Roth &amp; Merriam directly targeted representations characteristic of V1 (orientation and spatial frequency).</p>
<p>Our joint observations that recent item statistics rapidly influenced item representations in PHC and that these representations drifted over longer periods of time leads us to speculate that representational change on these two timescales may be linked. That is, the accumulation of small representational changes based on environmental statistics may, over time, result in the gradual drift of these representations over longer timescales. The participants in the current study were regularly exposed to most of the target items (e.g., plant, book) in their day-to-day life in between fMRI sessions, providing frequent opportunities for their representations to update based on which items were seen together in different contexts. Thus, the long-term representational drift we observed in PHC would presumably mainly reflect observations of and experiences with these items and their surroundings in the real world. Future work may be able to more directly link these short- and long-term changes through exposure to stimuli unlikely to be encountered between sessions.</p>
<p>We found different levels of drift over time across semantic regions: even though drift was observed in PHC, CA1, and PRC, the degree of drift varied across regions, with greater drift in PHC than PRC. A whole-brain analysis suggested increased long-term plasticity in more anterior portions of semantic-sensitive regions (<xref rid="fig5" ref-type="fig">Fig. 5C</xref>). The finding that some regions revealed drift of semantic representations whereas others did not provides a hypothesis for the brain’s solution to the stability-plasticity trade-off in the semantic system. The brain harbors less volatile item representations in more posterior areas that are able to withstand a dynamic environment, in addition to more malleable item representations more anteriorly that can accommodate new information when needed. Additionally, only a subset of semantic regions is sensitive to the recent statistics of the environment, including PHC, further suggesting a division of labor within the brain such that some regions retain stable representations of the world whereas other regions shift their representations over short and long timescales.</p>
<p>In summary, our findings reveal how the brain manages the stability-plasticity trade-off in the context of visual object semantics. While some regions of visual and temporal cortex contain static representations of the world, other more anterior regions, especially PHC, contain plastic representations that absorb the recent statistics of the visual environment and also drift across long periods of time. This variation in representational flexibility may allow the brain to provide the stability that is necessary for a useful model of the world while also being able to adjust to a constantly changing environment.</p>
</sec>
<sec id="s4">
<label>4.</label><title>Methods</title>
<p>This study is based on the Natural Scenes Dataset (NSD) which has been described in Allen (2022) and is openly available (<ext-link ext-link-type="uri" xlink:href="http://naturalscenesdataset.org">http://naturalscenesdataset.org</ext-link>). Here, we summarize the main characteristics of the dataset and describe the data that are relevant to the current paper. See Allen et al. (2022) for full details on MRI acquisition.</p>
<sec id="s4a">
<title>Participants</title>
<p>Eight participants contributed data to the study (six females and two males; age range 19-32). All participants had normal or corrected-to-normal vision. Informed consent was obtained in accordance with the University of Minnesota Institutional Review Board.</p>
</sec>
<sec id="s4b">
<title>Design and Procedure</title>
<p>Each participant viewed 9,000–10,000 distinct natural images across 30-40 sessions while fMRI data were collected. Each of these images was presented up to three times across the entire experiment; participants performed a long-term continuous recognition task on each trial in which they indicated via a button press whether each image presented was new or old (i.e., whether that image had previously appeared at any earlier time in the experiment). Each NSD session contained 12 runs of the NSD task, with 62-63 image trials per run, resulting in 750 image trials per session. On each trial an image was presented for three seconds followed by a one second gap. In this study, data from sessions 1-30 were analyzed for each participant, corresponding to a time range of 210-287 days.</p>
</sec>
<sec id="s4c">
<title>Stimuli</title>
<p>Natural images were drawn from the Common Objects in Context (COCO; <ext-link ext-link-type="uri" xlink:href="https://cocodataset.org">https://cocodataset.org</ext-link>) database. COCO images are photographs that come with segmentations indicating the presence and location of a set of 80 objects (e.g., person, giraffe, bus, umbrella). For the purposes of this study, we represent each image as a sparse vector indicating the count of each of the 80 objects contained therein. Each of the 80 COCO objects appeared in at least 100 images to each participant, and 90% of the images contained multiple object categories. In this paper we use the terms “objects” and “items” interchangeably. The experiment was designed such that each participant was assigned a set of 10,000 images, 9,000 of which were unique to that subject and 1,000 of which were common across subjects; thus, different subjects experienced different object co-occurrence statistics over time.</p>
</sec>
<sec id="s4d">
<title>MRI Acquisition</title>
<p>The NSD neuroimaging data were collected at the Center for Magnetic Resonance Research at the University of Minnesota. Anatomical data were collected using a 3T Siemens Prisma scanner and a 32-channel RF head coil and included T1 (0.8-mm isotropic resolution, TR=2400 ms, TE=2.22ms, TI=1000 ms, flip angle 8°) and T2 (0.8-mm isotropic resolution, TR=3200 ms, TE=563 ms, TI=1000 ms) scans. Functional data were collected using a 7T Siemens Magnetom, a 32-channel-receive RF head coil, and gradient-echo EPI at 1.8-mm isotropic resolution and 1.6-s TR with whole-brain coverage. Participants were scanned approximately once per week.</p>
</sec>
<sec id="s4e">
<title>MRI Pre-processing and GLM Analysis</title>
<p>Data were processed using a variety of methods and multiple versions of data were generated. Here we summarize the methods that are relevant to the current study. Functional data were pre-processed to correct for slice time differences, head motion within and across scan sessions, EPI distortion, and gradient non-linearities. These data were upsampled to a 1.0-mm high-resolution preparation. GLM analysis of these pre-processed timeseries data provided beta estimates of BOLD response amplitudes for single trials (i.e., single image presentations). We used the version of the beta estimates (‘betas_fithrf’) in which an optimal HRF is identified for each individual voxel before fitting a single-trial design matrix to the data. These high-resolution 1.0-mm betas were mapped to 2.0-mm MNI space using cubic interpolation. Trial-wise activity was z-scored for each voxel in each session. To define regions of interest (ROIs) we used MTL atlas labels derived from a database of manual anatomical segmentations (<xref ref-type="bibr" rid="c21">Hindy &amp; Turk-Browne, 2016</xref>; <xref ref-type="bibr" rid="c1">Aly &amp; Turk-Browne, 2016</xref>).</p>
</sec>
<sec id="s4f">
<title>Object Encoding Model</title>
<p>An encoding model was used to localize brain regions containing reliable object representations, and to generate multivoxel object pattern estimates in these regions that were used for subsequent analyses. The goal of this model was to predict how each voxel responds to the different target objects. As an overview, we constructed a voxel-wise object encoding model using a ridge-regression approach in which beta estimates for the 80 objects were generated for each voxel and then evaluated based on how well this model predicted left out data. The natural images presented on each trial were represented as sparse 80-dimensional vectors indicating which objects were present in each image and in what quantities. We modeled the trial-wise beta estimates for each voxel using these stimulus vectors. An encoding model was created within each session, with the 6 odd runs used as training data and the 6 even runs used as test data.</p>
<sec id="s4f1">
<title>Model estimation</title>
<p>Data from the 6 training runs were concatenated resulting in an 80 (items) x 375 (trials) matrix. Trial-wise betas for each voxel were regressed against the 80 item vectors using ridge-regression (<xref rid="fig3" ref-type="fig">Fig. 3A</xref>), which reduces overfitting by including hyperparameter λ that encourages shrinkage of model parameters. In order to determine the optimal λ for each voxel, we implemented fracridge (Rokem &amp; Kay, 2020) in a 3-fold cross-validation procedure within the training data. In each fold, voxel betas were estimated on 66% of the training data using a range of λ values and validated on the remaining 33% of training data. On each validation trial, the model’s predicted response for each voxel was the 80-item beta estimates multiplied by the 80-item stimulus vector plus the model’s constant term. Model error was quantified as the absolute difference between the voxel’s true response on that trial and the model’s predicted response. Mean squared error (MSE) was calculated across validation trials for each λ value for each voxel, and the best λ for each voxel was extracted. For each voxel, the optimal λ values in the three iterations were averaged, and this value was used as the voxel’s λ value in the main stage of model estimation. Once the optimal λ values were extracted across voxels, the same model estimation procedure with ridge-regression was applied to the full 80 (items) x 375 (trials) training data matrix. The final output of the model estimation stage is a beta estimate for each item in each voxel, in addition to the voxel-wise constant terms.</p>
</sec>
<sec id="s4f2">
<title>Model testing</title>
<p>The voxel-wise beta estimates from the model estimation stage were used to predict trial-level voxel responses in the 6 left-out test runs. To generate the model’s predictions for each voxel’s response on each trial, the trial’s 80-item stimulus vector was multiplied by the voxel’s 80-item beta vector and the constant from the ridge regression was added. Each voxel’s data were mean-centered separately within the predicted and actual test patterns. Because we are interested in multivoxel object representations, we used the model’s voxel-wise predictions to generate multivoxel trial-level predictions within cubical searchlights (3 x 3 x 3 voxels) centered on each voxel across the brain. Within each searchlight, model accuracy was calculated as the Pearson correlation between predicted and actual multivoxel patterns. This correlation value was assigned to the voxel at the center of each searchlight. Thus, for each voxel in each session for each participant, we have a measure reflecting the degree to which objects are represented within its local neighborhood.</p>
</sec>
<sec id="s4f3">
<title>Generating neural representations of items</title>
<p>We used the encoding model to generate predicted item patterns at multiple timescales. First, in order to get the best possible model estimates, we took the optimal lambda determined in the model estimation procedure and fit the encoding model to all of the 750 trials in a given session. The beta estimates for each item were then used to generate predicted activity patterns for each of the 80 objects in each searchlight. These session-length item patterns were used in the semantic detection and semantic drift analyses described below. Second, we generated item patterns corresponding to the first and second half of each session. Each session was split into two blocks (block 1: runs 1-6; block 2: runs 7-12). Using the exact same model estimation methods described above, new encoding models were run within each block in order to generate predicted patterns (beta estimates) for each item separately within the first and second half of each session (e.g., a “giraffe” pattern in block 1, and a “giraffe” pattern in block 2). These block-length item patterns were used in the recent structure sensitivity analysis described below.</p>
</sec>
</sec>
<sec id="s4g">
<title>Semantic Detection</title>
<p>Word2vec (<xref ref-type="bibr" rid="c31">Mikolov et al., 2013</xref>) was used to capture semantic relations among our 80 items. Word2vec is an implementation for word embeddings which captures similarities between words based on their co-occurrence in text. The vector embeddings for the set of items were correlated with each other to generate an 80 x 80 semantic similarity matrix. Within searchlights across the brain, we used the object encoding model to generate predicted multivoxel patterns for each of the items (at the session level) and correlated these patterns to generate an 80 x 80 neural similarity matrix (<xref rid="fig2" ref-type="fig">Fig. 2B</xref>). To determine whether the encoded neural patterns contained semantic information, we correlated the semantic and neural similarity matrices with each other using Spearman rank correlation (<xref rid="fig2" ref-type="fig">Fig. 2B</xref>). Semantically similar items tend to occur in the same images, and there is some possibility that this might lead to inflated similarity estimates between neural and semantic spaces. Thus, to ensure a conservative analytical approach, for each participant we excluded cells from the neural and semantic matrices that corresponded with items that co-occurred at any point in the experiment, resulting in a subset of item-pairs for each subject (<italic>M</italic>=1390 pairs, <italic>SD</italic>=24). The resulting Spearman’s rho coefficient was assigned to the voxel at the center of the searchlight. This analysis was run on each of the 30 sessions for each of the 8 participants. In ROI analyses, voxel values within each ROI were averaged within each session for each participant. In whole-brain analyses, brain maps were averaged across sessions.</p>
</sec>
<sec id="s4h">
<title>Long-term Drift</title>
<p>In order to determine whether item representations drift over long timescales, we calculated the extent to which the representation of a particular item in a particular session (e.g., giraffe in session1) is more similar to neighboring sessions (e.g., giraffe in session 2) than in distant sessions (e.g., giraffe in session 30). Within each searchlight across the brain, the encoded patterns for each item were extracted within each session and were correlated with each other to generate a 30 x 30 matrix. Cells in this matrix that corresponded to the same time lag (i.e., number of intervening sessions) were averaged, resulting in a 1 x 29 vector containing the average within-item similarities at different degrees of lag. For example, the first value in this vector would correspond to the similarity of giraffe patterns that were separated by a single session (e.g., session 1 and session 2; session 29 and session 30), whereas the last value would correspond to the similarity of giraffe patterns that were separated by 29 sessions (i.e., session 1 and session 30). This similarity-by-lag vector was regressed against the amount of lag (1-29) to determine whether within-item similarity values increased or decreased over time within each searchlight. Beta values were averaged across items, and the resulting value was assigned to the voxel at the center of the searchlight. In ROI analyses, voxel values within each ROI were averaged for each participant.</p>
</sec>
<sec id="s4i">
<title>Influence of Recent Structure</title>
<p>The goal of this analysis was to determine whether recent structure in the visual semantic environment—that is, the patterns of co-occurrences among items—rapidly influences the nature of those item representations.</p>
<sec id="s4i1">
<title>Quantifying recent structure</title>
<p>Structure was characterized in terms of item co-occurrence across trials (<xref rid="fig1" ref-type="fig">Fig. 1</xref>). Co-occurrence of sets of items can be captured using the construct of network modularity or community structure, which has been used in many experimental studies of structure learning in humans (e.g., Schapiro et al., 2013; <xref ref-type="bibr" rid="c46">Solomon &amp; Schapiro, 2023</xref>). In our case, the input into the modularity function is the pairwise co-occurrence frequencies of the 80 items. The modular organization of these items was calculated using Brain Connectivity Toolbox (brain-connectivity-toolbox.net; <xref ref-type="bibr" rid="c36">Rubinov &amp; Sporns, 2010</xref>). The outputs of this function include an overall measure of modularity (i.e., how well the inputs can be described in terms of clusters with high within- and low between-connectivity), and assignments of each item to one of the modules detected. Thus, for each pair of items, we can observe whether the two items were assigned to the same or distinct modules (<xref rid="fig6" ref-type="fig">Fig. 6A</xref>). Since the modularity function is stochastic, it was run 100 times on each input; we counted, for each pair of items, the number of times (out of 100) that the items were assigned to the same module. This value was taken to reflect the measure of structural similarity between any two items. The gamma parameter in the modularity function biases the model to find smaller (γ &gt; 1) or larger (γ &lt; 1) modules. We set γ = 1.5 because it resulted in the most sensitivity in our structural similarity measure, as determined by a parameter search on each participant’s session 1 data. The upshot of this analysis is an 80 x 80 matrix capturing pairwise structural similarity between items, as computed by the modularity calculation (<xref rid="fig2" ref-type="fig">Fig. 2D</xref>).</p>
</sec>
<sec id="s4i2">
<title>Assessing influence of recent structure on neural representations</title>
<p>Each session was split into two blocks corresponding to the first half (runs 1-6) and second half (runs 7-12) of the session. Within each block, we calculated the co-occurrence frequencies between items across the 375 corresponding trials. These co-occurrence matrices were submitted as input to the modularity calculations described above. This enabled the quantification of structural similarity amongst items in block 1, in addition to the structural similarity amongst items in block 2. We then used our split-session encoding models to generate predicted item patterns separately for block 1 and block 2 and calculated between-item neural pattern similarity within each block. To determine whether recent structure influenced neural similarity among items, we correlated the structural similarity values from block 1 with neural similarity in block 2 (“forward correlation”). Higher correlation values indicate that items that tended to co-occur in block 1 were represented more similarity in block 2. However, this relationship on its own could indicate an influence of long-term object co-occurrence structure on neural similarity, rather than a rapid influence of recent structure. We thus also correlated structural similarity in block 2 with neural similarity in block 1 (“backwards correlation”); high correlation values indicate a relationship between long-term object co-occurrence and neural similarity, but cannot indicate a causal temporal dependence between the two. In order to control for an effect of long-term structure, we subtracted the backward correlation value from the forward correlation value. This subtraction is a powerful means of controlling for any alternative influences on neural similarity between items. Thus, positive values in this measure indicate a rapid influence of recent structure on neural representations. In ROI analyses, voxel values within each ROI were averaged within each session for each participant. In whole-brain analyses, brain maps were averaged across sessions.</p>
</sec>
</sec>
<sec id="s4j">
<title>Structure-based Updating</title>
<p>If a relationship exists between recent semantic structure and subsequent item similarity, we aimed to determine what might modulate this effect. One possibility is that the degree to which structure modulates neural item similarity is influenced by the degree of mismatch between the recently observed structure and the long-term structure of item co-occurrences stored in memory. To make this long-term item co-occurrence structure concrete, we calculated, for each subject, the number of times each pair of items co-occurred across the 30 experimental sessions. For each session, we then generated a structure mismatch value for each session by calculating the Pearson distance between the co-occurrence statistics in the first half of the session with the long-term structure. Intuitively, this quantifies how atypical the co-occurrences were in a given session compared to the long-term average. To test whether this mismatch value relates to the degree of representational change, the relationship between structure mismatch and the recent structure effect across sessions was calculated using a Spearman correlation for each participant.</p>
</sec>
<sec id="s4k">
<title>Whole-brain significance testing</title>
<p>Group-level reliability across the brain was calculated using threshold-free cluster enhancement (<xref ref-type="bibr" rid="c62">Winkler et al., 2014</xref>) on the session-averaged maps from each participant; significance was assessed at a corrected α = 0.05. The resulting maps were used to create masks within which subsequent reliability analyses were performed; to increase power for these subsequent analyses (by reducing multiple comparisons), masks were generated using a threshold of α = 0.01. The first step was to locate regions of the brain in which object encoding was successful. Within the resulting encoding mask, regions that reliably contained semantic content were located. Within the resulting semantic mask, the reliability of long-term drift effects and short-term structural effects were assessed.</p>
</sec>
</sec>
<sec id="d1e1073" sec-type="supplementary-material">
<title>Supporting information</title>
<supplementary-material id="d1e1155">
<label>Supplemental Material</label>
<media xlink:href="supplements/579310_file02.pdf"/>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>We are grateful to Michael Arcaro for helpful discussions. Collection of the NSD dataset was supported by NSF IIS-1822683 and NSF IIS-1822929.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Aly</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Turk-Browne</surname>, <given-names>N. B</given-names></string-name>. (<year>2016</year>). <article-title>Attention stabilizes representations in the human hippocampus</article-title>. <source>Cerebral Cortex</source>, <volume>26</volume>(<issue>2</issue>), <fpage>783</fpage>–<lpage>796</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Aminoff</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Gronau</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Bar</surname>, <given-names>M</given-names></string-name>. (<year>2007</year>). <article-title>The parahippocampal cortex mediates spatial and nonspatial associations</article-title>. <source>Cerebral cortex</source>, <volume>17</volume>(<issue>7</issue>), <fpage>1493</fpage>–<lpage>1503</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Aminoff</surname>, <given-names>E. M.</given-names></string-name>, <string-name><surname>Kveraga</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Bar</surname>, <given-names>M</given-names></string-name>. (<year>2013</year>). <article-title>The role of the parahippocampal cortex in cognition</article-title>. <source>Trends in cognitive sciences</source>, <volume>17</volume>(<issue>8</issue>), <fpage>379</fpage>–<lpage>390</lpage>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Bainbridge</surname>, <given-names>W. A.</given-names></string-name>, <string-name><surname>Hall</surname>, <given-names>E. H.</given-names></string-name>, &amp; <string-name><surname>Baker</surname>, <given-names>C. I</given-names></string-name>. (<year>2021</year>). <article-title>Distinct representational structure and localization for visual encoding and recall during visual imagery</article-title>. <source>Cerebral Cortex</source>, <volume>31</volume>(<issue>4</issue>), <fpage>1898</fpage>–<lpage>1913</lpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Baldassano</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Beck</surname>, <given-names>D. M.</given-names></string-name>, &amp; <string-name><surname>Fei-Fei</surname>, <given-names>L</given-names></string-name>. (<year>2013</year>). <article-title>Differential connectivity within the parahippocampal place area</article-title>. <source>Neuroimage</source>, <volume>75</volume>, <fpage>228</fpage>–<lpage>237</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Binder</surname>, <given-names>J. R.</given-names></string-name>, &amp; <string-name><surname>Desai</surname>, <given-names>R. H</given-names></string-name>. (<year>2011</year>). <article-title>The neurobiology of semantic memory</article-title>. <source>Trends in cognitive sciences</source>, <volume>15</volume>(<issue>11</issue>), <fpage>527</fpage>–<lpage>536</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Bornstein</surname>, <given-names>A. M.</given-names></string-name>, &amp; <string-name><surname>Daw</surname>, <given-names>N. D</given-names></string-name>. (<year>2012</year>). <article-title>Dissociating hippocampal and striatal contributions to sequential prediction learning</article-title>. <source>European Journal of Neuroscience</source>, <volume>35</volume>(<issue>7</issue>), <fpage>1011</fpage>–<lpage>1023</lpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Brodt</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Gais</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Beck</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Erb</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Scheffler</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Schönauer</surname>, <given-names>M</given-names></string-name>. (<year>2018</year>). <article-title>Fast track to the neocortex: A memory engram in the posterior parietal cortex</article-title>. <source>Science</source>, <volume>362</volume>(<issue>6418</issue>), <fpage>1045</fpage>–<lpage>1048</lpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Cann</surname>, <given-names>D. R.</given-names></string-name>, <string-name><surname>McRae</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Katz</surname>, <given-names>A. N</given-names></string-name>. (<year>2011</year>). <article-title>False recall in the Deese–Roediger– McDermott paradigm: The roles of gist and associative strength</article-title>. <source>Quarterly Journal of Experimental Psychology</source>, <volume>64</volume>(<issue>8</issue>), <fpage>1515</fpage>–<lpage>1542</lpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Carpenter</surname>, <given-names>G. A.</given-names></string-name>, &amp; <string-name><surname>Grossberg</surname>, <given-names>S</given-names></string-name>. (<year>1987</year>). <article-title>ART 2: Self-organization of stable category recognition codes for analog input patterns</article-title>. <source>Applied optics</source>, <volume>26</volume>(<issue>23</issue>), <fpage>4919</fpage>–<lpage>4930</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Covington</surname>, <given-names>N. V.</given-names></string-name>, <string-name><surname>Brown-Schmidt</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Duff</surname>, <given-names>M. C</given-names></string-name>. (<year>2018</year>). <article-title>The necessity of the hippocampus for statistical learning</article-title>. <source>Journal of cognitive neuroscience</source>, <volume>30</volume>(<issue>5</issue>), <fpage>680</fpage>–<lpage>697</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Diekelmann</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Born</surname>, <given-names>J</given-names></string-name>. (<year>2010</year>). <article-title>The memory function of sleep</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>11</volume>(<issue>2</issue>), <fpage>114</fpage>–<lpage>126</lpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>Driscoll</surname>, <given-names>L. N.</given-names></string-name>, <string-name><surname>Pettit</surname>, <given-names>N. L.</given-names></string-name>, <string-name><surname>Minderer</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Chettih</surname>, <given-names>S. N.</given-names></string-name>, &amp; <string-name><surname>Harvey</surname>, <given-names>C. D</given-names></string-name>. (<year>2017</year>). <article-title>Dynamic reorganization of neuronal activity patterns in parietal cortex</article-title>. <source>Cell</source>, <volume>170</volume>(<issue>5</issue>), <fpage>986</fpage>–<lpage>999</lpage>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Driscoll</surname>, <given-names>L. N.</given-names></string-name>, <string-name><surname>Duncker</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>Harvey</surname>, <given-names>C. D</given-names></string-name>. (<year>2022</year>). <article-title>Representational drift: Emerging theories for continual learning and experimental future directions</article-title>. <source>Current Opinion in Neurobiology</source>, <volume>76</volume>, <fpage>102609</fpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Epstein</surname>, <given-names>R. A.</given-names></string-name>, &amp; <string-name><surname>Baker</surname>, <given-names>C. I</given-names></string-name>. (<year>2019</year>). <article-title>Scene perception in the human brain</article-title>. <source>Annual review of vision science</source>, <volume>5</volume>, <fpage>373</fpage>–<lpage>397</lpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Frost</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Armstrong</surname>, <given-names>B. C.</given-names></string-name>, &amp; <string-name><surname>Christiansen</surname>, <given-names>M. H</given-names></string-name>. (<year>2019</year>). <article-title>Statistical learning research: A critical review and possible new directions</article-title>. <source>Psychological Bulletin</source>, <volume>145</volume>(<issue>12</issue>), <fpage>1128</fpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Geva</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Deitch</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Rubin</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Ziv</surname>, <given-names>Y</given-names></string-name>. (<year>2023</year>). <article-title>Time and experience differentially affect distinct aspects of hippocampal representational drift</article-title>. <source>Neuron</source>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Graham</surname>, <given-names>K. S.</given-names></string-name>, <string-name><surname>Barense</surname>, <given-names>M. D.</given-names></string-name>, &amp; <string-name><surname>Lee</surname>, <given-names>A. C</given-names></string-name>. (<year>2010</year>). <article-title>Going beyond LTM in the MTL: a synthesis of neuropsychological and neuroimaging findings on the role of the medial temporal lobe in memory and perception</article-title>. <source>Neuropsychologia</source>, <volume>48</volume>(<issue>4</issue>), <fpage>831</fpage>–<lpage>853</lpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Harrison</surname>, <given-names>L. M.</given-names></string-name>, <string-name><surname>Duggins</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Friston</surname>, <given-names>K. J</given-names></string-name>. (<year>2006</year>). <article-title>Encoding uncertainty in the hippocampus</article-title>. <source>Neural Networks</source>, <volume>19</volume>(<issue>5</issue>), <fpage>535</fpage>–<lpage>546</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Hebscher</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Wing</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Ryan</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Gilboa</surname>, <given-names>A</given-names></string-name>. (<year>2019</year>). <article-title>Rapid cortical plasticity supports long-term memory formation</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>23</volume>(<issue>12</issue>), <fpage>989</fpage>–<lpage>1002</lpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Hindy</surname>, <given-names>N. C.</given-names></string-name>, &amp; <string-name><surname>Turk-Browne</surname>, <given-names>N. B</given-names></string-name>. (<year>2016</year>). <article-title>Action-based learning of multistate objects in the medial temporal lobe</article-title>. <source>Cerebral Cortex</source>, <volume>26</volume>(<issue>5</issue>), <fpage>1853</fpage>–<lpage>1865</lpage>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Kemp</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Tenenbaum</surname>, <given-names>J. B</given-names></string-name>. (<year>2008</year>). <article-title>The discovery of structural form</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>105</volume>(<issue>31</issue>), <fpage>10687</fpage>–<lpage>10692</lpage>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Kitamura</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Ogawa</surname>, <given-names>S. K.</given-names></string-name>, <string-name><surname>Roy</surname>, <given-names>D. S.</given-names></string-name>, <string-name><surname>Okuyama</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Morrissey</surname>, <given-names>M. D.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>L. M.</given-names></string-name>, … &amp; <string-name><surname>Tonegawa</surname>,<given-names>S.</given-names></string-name>, (<year>2017</year>). <article-title>Engrams and circuits crucial for systems consolidation of a memory</article-title>. <source>Science</source>, <volume>356</volume>(<issue>6333</issue>), <fpage>73</fpage>–<lpage>78</lpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Lesburguères</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Gobbo</surname>, <given-names>O. L.</given-names></string-name>, <string-name><surname>Alaux-Cantin</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Hambucken</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Trifilieff</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Bontempi</surname>, <given-names>B</given-names></string-name>. (<year>2011</year>). <article-title>Early tagging of cortical networks is required for the formation of enduring associative memory</article-title>. <source>Science</source>, <volume>331</volume>(<issue>6019</issue>), <fpage>924</fpage>–<lpage>928</lpage>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Martin</surname>, <given-names>C. B.</given-names></string-name>, &amp; <string-name><surname>Barense</surname>, <given-names>M. D</given-names></string-name>. (<year>2023</year>). <article-title>Perception and memory in the ventral visual stream and medial temporal lobe</article-title>. <source>Annual review of vision science</source>, <volume>9</volume>, <fpage>409</fpage>–<lpage>434</lpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>McClelland</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>McNaughton</surname>, <given-names>B. L.</given-names></string-name>, &amp; <string-name><surname>O’Reilly</surname>, <given-names>R. C</given-names></string-name>. (<year>1995</year>). <article-title>Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory</article-title>. <source>Psychological review</source>, <volume>102</volume>(<issue>3</issue>), <fpage>419</fpage>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>McClelland</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>McNaughton</surname>, <given-names>B. L.</given-names></string-name>, &amp; <string-name><surname>Lampinen</surname>, <given-names>A. K</given-names></string-name>. (<year>2020</year>). <article-title>Integration of new information in memory: new insights from a complementary learning systems perspective</article-title>. <source>Philosophical Transactions of the Royal Society B</source>, <volume>375</volume>(<issue>1799</issue>), <fpage>20190637</fpage>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><string-name><surname>Merhav</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Karni</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Gilboa</surname>, <given-names>A</given-names></string-name>. (<year>2015</year>). <article-title>Not all declarative memories are created equal: fast mapping as a direct route to cortical declarative representations</article-title>. <source>Neuroimage</source>, <volume>117</volume>, <fpage>80</fpage>–<lpage>92</lpage>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><string-name><surname>Meyer</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Bonhoeffer</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Scheuss</surname>, <given-names>V</given-names></string-name>. (<year>2014</year>). <article-title>Balance and stability of synaptic structures during synaptic plasticity</article-title>. <source>Neuron</source>, <volume>82</volume>(<issue>2</issue>), <fpage>430</fpage>–<lpage>443</lpage>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>Micou</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>O’Leary</surname>, <given-names>T</given-names></string-name>. (<year>2023</year>). <article-title>Representational drift as a window into neural and behavioural plasticity</article-title>. <source>Current Opinion in Neurobiology</source>, <volume>81</volume>, <fpage>102746</fpage>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>Mikolov</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Corrado</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Dean</surname>, <given-names>J</given-names></string-name>. (<year>2013</year>). <article-title>Efficient estimation of word representations in vector space</article-title>. <source>arXiv preprint arXiv</source>:<volume>1301</volume>.<fpage>3781</fpage>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><string-name><surname>Mirman</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Landrigan</surname>, <given-names>J. F.</given-names></string-name>, &amp; <string-name><surname>Britt</surname>, <given-names>A. E</given-names></string-name>. (<year>2017</year>). <article-title>Taxonomic and thematic semantic systems</article-title>. <source>Psychological bulletin</source>, <volume>143</volume>(<issue>5</issue>), <fpage>499</fpage>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><string-name><surname>Musz</surname>, <given-names>E.</given-names></string-name>, &amp; <string-name><surname>Thompson-Schill</surname>, <given-names>S. L</given-names></string-name>. (<year>2015</year>). <article-title>Semantic variability predicts neural variability of object concepts</article-title>. <source>Neuropsychologia</source>, <volume>76</volume>, <fpage>41</fpage>–<lpage>51</lpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="book"><string-name><surname>Rogers</surname>, <given-names>T. T.</given-names></string-name>, &amp; <string-name><surname>McClelland</surname>, <given-names>J. L</given-names></string-name>. (<year>2004</year>). <source>Semantic cognition: A parallel distributed processing approach</source>. <publisher-name>MIT press</publisher-name>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>Roth</surname>, <given-names>Z. N.</given-names></string-name>, &amp; <string-name><surname>Merriam</surname>, <given-names>E. P</given-names></string-name>. (<year>2023</year>). <article-title>Representations in human primary visual cortex drift over time</article-title>. <source>Nature Communications</source>, <volume>14</volume>(<issue>1</issue>), <fpage>4422</fpage>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><string-name><surname>Rubinov</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Sporns</surname>, <given-names>O</given-names></string-name>. (<year>2010</year>). <article-title>Complex network measures of brain connectivity: uses and interpretations</article-title>. <source>Neuroimage</source>, <volume>52</volume>(<issue>3</issue>), <fpage>1059</fpage>–<lpage>1069</lpage>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><string-name><surname>Rule</surname>, <given-names>M. E.</given-names></string-name>, <string-name><surname>O’Leary</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Harvey</surname>, <given-names>C. D</given-names></string-name>. (<year>2019</year>). <article-title>Causes and consequences of representational drift</article-title>. <source>Current opinion in neurobiology</source>, <volume>58</volume>, <fpage>141</fpage>–<lpage>147</lpage>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><string-name><surname>Saffran</surname>, <given-names>J. R.</given-names></string-name>, <string-name><surname>Aslin</surname>, <given-names>R. N.</given-names></string-name>, &amp; <string-name><surname>Newport</surname>, <given-names>E. L</given-names></string-name>. (<year>1996</year>). <article-title>Statistical learning by 8-month-old infants</article-title>. <source>Science</source>, <volume>274</volume>(<issue>5294</issue>), <fpage>1926</fpage>–<lpage>1928</lpage>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><string-name><surname>Sagi</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Tavor</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Hofstetter</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Tzur-Moryosef</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Blumenfeld-Katzir</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Assaf</surname>, <given-names>Y</given-names></string-name>. (<year>2012</year>). <article-title>Learning in the fast lane: new insights into neuroplasticity</article-title>. <source>Neuron</source>, <volume>73</volume>(<issue>6</issue>), <fpage>1195</fpage>–<lpage>1203</lpage>.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><string-name><surname>Schapiro</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Gregory</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Landau</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>McCloskey</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Turk-Browne</surname>, <given-names>N. B</given-names></string-name>. (<year>2014</year>). <article-title>The necessity of the medial temporal lobe for statistical learning</article-title>. <source>Journal of cognitive neuroscience</source>, <volume>26</volume>(<issue>8</issue>), <fpage>1736</fpage>–<lpage>1747</lpage>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><string-name><surname>Schapiro</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Kustner</surname>, <given-names>L. V.</given-names></string-name>, &amp; <string-name><surname>Turk-Browne</surname>, <given-names>N. B</given-names></string-name>. (<year>2012</year>). <article-title>Shaping of object representations in the human medial temporal lobe based on temporal regularities</article-title>. <source>Current biology</source>, <volume>22</volume>(<issue>17</issue>), <fpage>1622</fpage>–<lpage>1627</lpage>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><string-name><surname>Schapiro</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Turk-Browne</surname>, <given-names>N. B.</given-names></string-name>, <string-name><surname>Botvinick</surname>, <given-names>M. M.</given-names></string-name>, &amp; <string-name><surname>Norman</surname>, <given-names>K. A</given-names></string-name>. (<year>2017</year>). <article-title>Complementary learning systems within the hippocampus: a neural network modelling approach to reconciling episodic memory with statistical learning</article-title>. <source>Philosophical Transactions of the Royal Society B: Biological Sciences</source>, <volume>372</volume>(<issue>1711</issue>), <fpage>20160049</fpage>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><string-name><surname>Schapiro</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Turk-Browne</surname>, <given-names>N. B.</given-names></string-name>, <string-name><surname>Norman</surname>, <given-names>K. A.</given-names></string-name>, &amp; <string-name><surname>Botvinick</surname>, <given-names>M. M.</given-names></string-name> (<year>2016</year>). <article-title>Statistical learning of temporal community structure in the hippocampus</article-title>. <source>Hippocampus</source>, <volume>26</volume>(<issue>1</issue>), <fpage>3</fpage>–<lpage>8</lpage>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><string-name><surname>Schlichting</surname>, <given-names>M. L.</given-names></string-name>, <string-name><surname>Mumford</surname>, <given-names>J. A.</given-names></string-name>, &amp; <string-name><surname>Preston</surname>, <given-names>A. R</given-names></string-name>. (<year>2015</year>). <article-title>Learning-related representational changes reveal dissociable integration and separation signatures in the hippocampus and prefrontal cortex</article-title>. <source>Nature communications</source>, <volume>6</volume>(<issue>1</issue>), <fpage>8151</fpage>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><string-name><surname>Smith</surname>, <given-names>E. E.</given-names></string-name>, &amp; <string-name><surname>Estes</surname>, <given-names>W. K</given-names></string-name>. (<year>1978</year>). <article-title>Theories of semantic memory</article-title>. <source>Handbook of learning and cognitive processes</source>, <volume>6</volume>, <fpage>1</fpage>–<lpage>56</lpage>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><string-name><surname>Solomon</surname>, <given-names>S. H.</given-names></string-name>, &amp; <string-name><surname>Schapiro</surname>, <given-names>A. C</given-names></string-name>. (<year>2023</year>). <article-title>Structure shapes the representation of a novel category. <italic>Journal of Experimental Psychology: Learning</italic></article-title>, <source>Memory, and Cognition</source>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><string-name><surname>Solomon</surname>, <given-names>S. H.</given-names></string-name>, <string-name><surname>Medaglia</surname>, <given-names>J. D.</given-names></string-name>, &amp; <string-name><surname>Thompson-Schill</surname>, <given-names>S. L</given-names></string-name>. (<year>2019</year>). <article-title>Implementing a concept network model</article-title>. <source>Behavior research methods</source>, <volume>51</volume>, <fpage>1717</fpage>–<lpage>1736</lpage>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><string-name><surname>Solomon</surname>, <given-names>S. H.</given-names></string-name>, &amp; <string-name><surname>Thompson-Schill</surname>, <given-names>S. L</given-names></string-name>. (<year>2017</year>). <article-title>Finding features, figuratively</article-title>. <source>Brain and language</source>, <volume>174</volume>, <fpage>61</fpage>–<lpage>71</lpage>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><string-name><surname>Solomon</surname>, <given-names>S. H.</given-names></string-name>, &amp; <string-name><surname>Thompson-Schill</surname>, <given-names>S. L</given-names></string-name>. (<year>2020</year>). <article-title>Feature uncertainty predicts Behavioral and neural responses to combined concepts</article-title>. <source>Journal of Neuroscience</source>, <volume>40</volume>(<issue>25</issue>), <fpage>4900</fpage>–<lpage>4912</lpage>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><string-name><surname>Squire</surname>, <given-names>L. R.</given-names></string-name>, &amp; <string-name><surname>Zola-Morgan</surname>, <given-names>S</given-names></string-name>. (<year>1991</year>). <article-title>The medial temporal lobe memory system</article-title>. <source>Science</source>, <volume>253</volume>(<issue>5026</issue>), <fpage>1380</fpage>–<lpage>1386</lpage>.</mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><string-name><surname>Steel</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Garcia</surname>, <given-names>B. D.</given-names></string-name>, <string-name><surname>Goyal</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Mynick</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Robertson</surname>, <given-names>C. E</given-names></string-name>. (<year>2023</year>). <article-title>Scene Perception and Visuospatial Memory Converge at the Anterior Edge of Visually Responsive Cortex</article-title>. <source>Journal of Neuroscience</source>, <volume>43</volume>(<issue>31</issue>), <fpage>5723</fpage>–<lpage>5737</lpage>.</mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><string-name><surname>Strange</surname>, <given-names>B. A.</given-names></string-name>, <string-name><surname>Duggins</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Penny</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Dolan</surname>, <given-names>R. J.</given-names></string-name>, &amp; <string-name><surname>Friston</surname>, <given-names>K. J</given-names></string-name>. (<year>2005</year>). <article-title>Information theory, novelty and hippocampal responses: unpredicted or unpredictable?</article-title>. <source>Neural Networks</source>, <volume>18</volume>(<issue>3</issue>), <fpage>225</fpage>–<lpage>230</lpage>.</mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><string-name><surname>Sučević</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Schapiro</surname>, <given-names>A. C</given-names></string-name>. (<year>2023</year>). <article-title>A neural network model of hippocampal contributions to category learning</article-title>. <source>Elife</source>, <volume>12</volume>, <fpage>e77185</fpage>.</mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><string-name><surname>Sun</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Frank</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Epstein</surname>, <given-names>R. A.</given-names></string-name>, &amp; <string-name><surname>Peter</surname>, <given-names>U. T</given-names></string-name>. (<year>2021</year>). <article-title>The parahippocampal place area and hippocampus encode the spatial significance of landmark objects</article-title>. <source>NeuroImage</source>, <volume>236</volume>, <fpage>118081</fpage>.</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><string-name><surname>Tompary</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Davachi</surname>, <given-names>L</given-names></string-name>. (<year>2017</year>). <article-title>Consolidation promotes the emergence of representational overlap in the hippocampus and medial prefrontal cortex</article-title>. <source>Neuron</source>, <volume>96</volume>(<issue>1</issue>), <fpage>228</fpage>–<lpage>241</lpage>.</mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><string-name><surname>Tse</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Langston</surname>, <given-names>R. F.</given-names></string-name>, <string-name><surname>Kakeyama</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Bethus</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Spooner</surname>, <given-names>P. A.</given-names></string-name>, <string-name><surname>Wood</surname>, <given-names>E. R.</given-names></string-name>, … &amp; <string-name><surname>Morris</surname>, <given-names>R. G.</given-names></string-name> (<year>2007</year>). <article-title>Schemas and memory consolidation</article-title>. <source>Science</source>, <volume>316</volume>(<issue>5821</issue>), <fpage>76</fpage>–<lpage>82</lpage>.</mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><string-name><surname>Turk-Browne</surname>, <given-names>N. B.</given-names></string-name>, <string-name><surname>Scholl</surname>, <given-names>B. J.</given-names></string-name>, <string-name><surname>Chun</surname>, <given-names>M. M.</given-names></string-name>, &amp; <string-name><surname>Johnson</surname>, <given-names>M. K</given-names></string-name>. (<year>2009</year>). <article-title>Neural evidence of statistical learning: Efficient detection of visual regularities without awareness</article-title>. <source>Journal of cognitive neuroscience</source>, <volume>21</volume>(<issue>10</issue>), <fpage>1934</fpage>–<lpage>1945</lpage>.</mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><string-name><surname>Turk-Browne</surname>, <given-names>N. B.</given-names></string-name>, <string-name><surname>Scholl</surname>, <given-names>B. J.</given-names></string-name>, <string-name><surname>Johnson</surname>, <given-names>M. K.</given-names></string-name>, &amp; <string-name><surname>Chun</surname>, <given-names>M. M</given-names></string-name>. (<year>2010</year>). <article-title>Implicit perceptual anticipation triggered by statistical learning</article-title>. <source>Journal of Neuroscience</source>, <volume>30</volume>(<issue>33</issue>), <fpage>11177</fpage>–<lpage>11187</lpage>.</mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><string-name><surname>Van Kesteren</surname>, <given-names>M. T.</given-names></string-name>, <string-name><surname>Ruiter</surname>, <given-names>D. J.</given-names></string-name>, <string-name><surname>Fernández</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Henson</surname>, <given-names>R. N.</given-names></string-name> (<year>2012</year>). <article-title>How schema and novelty augment memory formation</article-title>. <source>Trends in neurosciences</source>, <volume>35</volume>(<issue>4</issue>), <fpage>211</fpage>–<lpage>219</lpage>.</mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><string-name><surname>Wammes</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Norman</surname>, <given-names>K. A.</given-names></string-name>, &amp; <string-name><surname>Turk-Browne</surname>, <given-names>N</given-names></string-name>. (<year>2022</year>). <article-title>Increasing stimulus similarity drives nonmonotonic representational change in hippocampus</article-title>. <source>elife</source>, <volume>11</volume>, <fpage>e68344</fpage>.</mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><string-name><surname>Wandell</surname>, <given-names>B. A.</given-names></string-name>, &amp; <string-name><surname>Smirnakis</surname>, <given-names>S. M</given-names></string-name>. (<year>2009</year>). <article-title>Plasticity and stability of visual field maps in adult primary visual cortex</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>10</volume>(<issue>12</issue>), <fpage>873</fpage>–<lpage>884</lpage>.</mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><string-name><surname>Winkler</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Ridgway</surname>, <given-names>G. R.</given-names></string-name>, <string-name><surname>Webster</surname>, <given-names>M. A.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>S. M.</given-names></string-name>, &amp; <string-name><surname>Nichols</surname>, <given-names>T. E</given-names></string-name>. (<year>2014</year>). <article-title>Permutation inference for the general linear model</article-title>. <source>Neuroimage</source>, <volume>92</volume>, <fpage>381</fpage>–<lpage>397</lpage>.</mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><string-name><surname>Wisniewski</surname>, <given-names>E. J.</given-names></string-name>, &amp; <string-name><surname>Bassok</surname>, <given-names>M</given-names></string-name>. (<year>1999</year>). <article-title>What makes a man similar to a tie? Stimulus compatibility with comparison and integration</article-title>. <source>Cognitive psychology</source>, <volume>39</volume>(<issue>3-4</issue>), <fpage>208</fpage>–<lpage>238</lpage>.</mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><string-name><surname>Yao</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Shi</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Han</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Gao</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Dan</surname>, <given-names>Y</given-names></string-name>. (<year>2007</year>). <article-title>Rapid learning in cortical coding of visual scenes</article-title>. <source>Nature neuroscience</source>, <volume>10</volume>(<issue>6</issue>), <fpage>772</fpage>–<lpage>778</lpage>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100084.1.sa4</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Bottini</surname>
<given-names>Roberto</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Trento</institution>
</institution-wrap>
<city>Trento</city>
<country>Italy</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>valuable</bold> study investigates how the human brain flexibly adjusts its representations of the world as the environment continually changes. It utilizes a unique dataset in which participants view thousands of natural scenes across many fMRI sessions over multiple months. The evidence supporting the claims of the authors is <bold>incomplete</bold>, with statistical inference not always warranted. The study would interest a broad readership in cognitive neuroscience.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100084.1.sa3</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This study investigates how the human brain flexibly adjusts its representations of the world as the environment continually changes. The authors identified regions where the representation continuously drifted across multiple months. They also found that the representation in the parahippocampal cortex could be rapidly influenced by recent environmental inputs.</p>
<p>Strengths:</p>
<p>(1) This study touches upon a crucial but less-explored issue: the relationship between semantic knowledge updating and representation drift in the brain.</p>
<p>(2) This study addresses this issue with a unique dataset in which participants viewed objects embedded in thousands of natural scenes across many fMRI sessions over eight months.</p>
<p>(3) The method for investigating whether the recent inputs could change the neural representation is compelling (i.e., subtracting the backward correlation value from the forward correlation value).</p>
<p>Weaknesses:</p>
<p>(1) Statistical Inference.</p>
<p>(a) Statistical inference is across eight subjects. Low statistical power means high false positive rates.</p>
<p>(b) Multiple comparisons across brain regions were not corrected.</p>
<p>(2) Object Encoding</p>
<p>It is unclear whether the identified brain regions represent the objects (as declared in the manuscript) or the visual features shared by pictures of similar items. Such visual features could be those of the background (e.g., spatial layout or the color tone of the scene), not the objects.</p>
<p>(3) Semantic Content in the MTL</p>
<p>Items with higher levels of semantic association tend to cooccur in the same picture. The results could be driven by the number of pictures shared between each pair of items, not semantic similarity (as declared in the manuscript).</p>
<p>(4) Long-term Drift of Item Representations in the MTL</p>
<p>(a) The results show a long-term representational drift in the brain but provide no evidence suggesting that this long-term neural representational drift reflects the drift in semantic representation. Although the authors used the &quot;semantic&quot; mask defined in the previous step, it does not mean the representation drift in the semantic mask is semantic, and there is doubt whether the &quot;semantic&quot; mask defined in the previous step is really semantic (see the third point).</p>
<p>(b) The beta value of the drift can not be directly compared across regions. Different regions have different sizes and signal-to-noise ratios in the BOLD signal. Their within-item similarity can not be compared directly in the first place.</p>
<p>(5) Recent Structure Rapidly Influences Item Representations in PHC</p>
<p>(a) It is unclear why the authors implement additional modularity analysis instead of directly using the pairwise co-occurrence frequencies among the 80 items, which is more straightforward.</p>
<p>(b) It does not make sense to compare the recent structure to the long-term structure across all 30 sessions because the structure of the posterior sessions cannot influence the current structure updating.</p>
<p>(c) It is unclear how the authors calculate the structure-induced change in the PHC in Figure 7.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100084.1.sa2</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The authors set out to uncover which brain regions might support the continuous updating of semantic associations thereby showing a system of semantic plasticity. Using fMRI data from participants viewing thousands of natural scene images over 30 recording sessions, they hoped to establish how objects co-occuring with each other within images influences the semantic representations in the human brain that relate to those object concepts.</p>
<p>Strengths:</p>
<p>There is a lot to like about the paper. A major strength of the methods and results is the convincing demonstration of many of the results. This includes showing item representations in the ventral visual pathway and medial temporal lobes (MTL), as we would expect. They also show semantic effects - defined using the word co-occurrence vectors from word2vec, along the posterior and anterior ventral visual pathway and MTL - replicating various past studies. The authors use a creative approach to show that the item representations measured within each session are modulated by the co-occurrence structure in previous trials, becoming more closely related. And that item representations seem to subtly change over the course of the 30 sessions, in that they become less related to each other with increasing distance. However, the semantic effects within each session itself are claimed to remain unchanged.</p>
<p>Weaknesses:</p>
<p>This leads to what I see as a weakness in the study. The conclusions relate to semantic plasticity and the changes in semantic (associative) representations. The drift analyses do appear to show representational changes across the sessions, but this is based on the item representations. The inference is that this is due to an updating of knowledge about the associations each item has had with other items. Yet, in the same regions, the authors suggest that semantic associative effects, as tested using word2vec for each session, remain stable. Doesn't this seem to contradict the claims about semantic plasticity?</p>
<p>Some of this is difficult to unpick as the semantic stability analysis using word2vec in each session is only very briefly mentioned, and the data is not shown (I would include it). So, at present, I feel they show evidence of representational changes but do not show evidence of what the nature of the change is. If the neural representations consistently reflect the long-term semantic associations (which is what word2vec captures), then how does this combine with the drift effects of item representations?</p>
<p>Does it mean that the changes in item representations do not reflect semantic associative knowledge? And reflect some other non-specified type of information (perhaps as the participants are doing an image memory test).</p>
<p>Another potential weakness is the robustness of the drift analysis itself. For the drift analysis, item representations in each session are compared to all other sessions and then averaged according to the number of intervening sessions. This means the data for item representation with a session difference of 1 will be based on 29 data points, a session difference of 2 on 28 data points ... and a session difference of 29 based on 1 data point. So there is a huge imbalance in the amount of data that goes into the analysis for the different numbers of intervening sessions. This leads me to wonder if it could impact the validity of the results. An alternative might be to use 1 datapoint for each session (or a suitable value, I imagine 5 would still give enough data to analyse drifts) and calculate drift, and then repeat this with different partitions of the data to see how stable it is, and if drift is reliably occurring. Alternatively, the analyses they use might have been used and validated previously.</p>
<p>To be clear, I do think this is a very nice study and will have a positive impact on researchers interested in object processing, semantic knowledge, statistical learning, and schemas. But think there are some gaps between what the data shows evidence for, and the ultimate inferences made.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100084.1.sa1</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This study characterizes the relative stability of semantic representations in the human brain using functional magnetic resonance imaging (fMRI) data. The authors suggest that representations in the early stages of processing within the visual system are stable over hours, weeks, and months, while representations in later stages of processing - within the medial temporal lobe - change more rapidly, sometimes within the span of a single fMRI session.</p>
<p>To make this claim, the authors conduct a series of analyses using a well-established fMRI dataset. This begins with a decoding analysis to identify regions that contain reliable object-specific information. This approach identifies early stages within canonical visual cortices (e.g., primary visual cortex, V1), as well as downstream regions within the medial temporal lobe (MTL); this includes perirhinal cortex (PRC), parahippocampal cortex (PHC), and several subfields within the hippocampal cortex (e.g., CA1). Next, they identify regions that are correlated with &quot;semantic features&quot; associated with these objects, determined using word2vec embeddings of each of these object names. Several regions within the MTL (CA1, PRC, PHC) were significantly correlated with these word2vec embeddings. The authors then turn their analyses to representational change across two different timescales. Between scan sessions, regions at early stages of visual processing (e.g., V1) contain relatively stable representations, while regions within the MTL decreased their auto-correlation across sessions, suggesting that there is increased representational change/drift in the MTL. Finally, the authors demonstrate that there is representational change with PHC within a single scan session - changes that reflect the statistics of visual experiences.</p>
<p>Strengths:</p>
<p>The analyses conducted in this study are solid and creative and they yield compelling theoretical results. Beyond the paper's central claims, this study also highlights the utility of publicly available datasets (i.e., NSD) in exploring and evaluating novel theoretical ideas.</p>
<p>Especially compelling is the combined analysis used to estimate reliable item-level representations, first, and then the long-term drift of item representations (i.e., between sessions). The design choices for modeling the fMRI data (e.g., the cross-validated approach to predicting voxel-level responses) reflect state-of-the-art analysis methods, while the control regions used in these analyses (e.g., V1) provide compelling contrasts to the experimental effects. This makes it clear that the observed representational drift/instability is not present throughout the visual system. These results indicate that this effect is worthy of future experiments, while also providing auxiliary information related to effect size, etc.</p>
<p>Weaknesses:</p>
<p>The concerns outlined here do not challenge the central claim within this study, relating to the relative instability of representations within the MTL as compared to V1. Instead, these concerns focus on whether these representations should be described as &quot;semantic,&quot; the importance we should give to the distinction between PHC and other MTC structures, and the lack of systematic analysis in relation to the &quot;gradient&quot; from posterior to anterior regions. In each case, I have provided suggestions as to how these concerns might be addressed. Finally, I've made a note about whether these data should be interpreted in terms of neural &quot;plasticity&quot; given the lack of behavioral change in relation to these fMRI data.</p>
<p>(1) No reason to believe that representations within the MTL are necessarily 'semantic.'</p>
<p>The authors suggest &quot;evoked object representations in CA1, PHC, and PRC are semantic in nature.&quot; However, the correlation between fMRI responses and word2vec embeddings-the only evidence for &quot;semantic&quot; representations-is ambiguous. These structures might contain high-dimensional features that are associated with these objects for other reasons; concretely, there might be visual information that is not semantic but relates to the reliable visual properties of these objects (e.g., texture, shape, location in the image). Yet there are no analyses to disambiguate between these alternative accounts. As such, labeling these as &quot;semantic&quot; representations is suggestive but premature. Nonetheless, developing such a control analysis should be relatively straightforward. I outline one possible approach below.</p>
<p>While &quot;semantic&quot; information is a relatively nebulous term in the cognitive neurosciences, contemporary deep-learning methods might offer unambiguous ways to characterize such representations. If we assume that &quot;semantics&quot; relate to the meaning of an object/entity and not the &quot;low-level&quot; sensory attributes related to encoding this information, this leads to a straightforward implementation of object semantics: the reliable variance that can be isolated within the residuals of a sensory encoder. For example, do word2vec embeddings explain variance within the medial temporal lobe above and beyond the variance explained by a vision-only image encoder? Of course, care must be taken to use a visual encoder which is not itself a crystallization of object semantics (e.g., encoders optimized using a classification objective), but this is all very feasible given contemporary computer vision methods. Adding such a control analysis would offer a significant improvement over the current approach, clarifying the nature of the stimulus-driven representations within the medial temporal lobe by disentangling &quot;semantic&quot; properties of reliable visual features.</p>
<p>Additionally, it is not clear whether results from the current &quot;object encoding&quot; analysis and &quot;semantic detection&quot; analysis differ because of underlying differences in representational content in these regions or because of design choices in these analyses themselves. That is, while the object encoding analysis learns a linear projection from a one-hot 80-dimensional vector to hemodynamic responses in each brain region, the semantic detection analysis correlates these predicted hemodynamic responses with word2vec embeddings associated with each of these 80 objects. These different analysis methods result in different outcomes: not all regions identified by the object encoding analysis are also identified in the semantic detection analysis (e.g., hippocampal subfields). It is not clear to what degree these different outcomes are a function of &quot;semantic&quot; information, or are simply a consequence of differences in analytic approaches. It would be useful to know the results by repeating the logic from the object encoding analysis, but instead of 1-hot vectors for each object, use the word2vec embeddings.</p>
<p>(2) Unclear if the differences between PHC and other MTL structures are driven by SNR.</p>
<p>Parahippocampal cortex (PHC) is a region reliably identified by the analyses in this study: PHC is identified in the analysis of item encoding, semantic content, and representational drift across long (between-session) and short (within-session) timescales. Control regions here provide a convincing contrast to PHC in each of these analyses, and so the role of PHC appears clear in these analyses. However, it is unclear how to interpret the difference between PHC and other structures within the MTC - namely, the observation that PHC alone is influenced by representational drift across shorter timescales. It's possible that these effects are common throughout the MTL, but are only evident in PHC because of increased SNR. This concern seems plausible when observing PHC's &quot;encoding success&quot; and &quot;semantic content,&quot; both visually and statistically, relative to other MTL structures: the magnitude of PHC's effect appears greater, which could simply be an artifact of PHC's relatively high SNR. In fMRI data, for example, PRC typically has relatively low SNR due to field inhomogeneities related to dropout, due to PRC's relative proximity to the ear canal-which is exacerbated in 7T (vs 3T) scanners, which was the case for the data in this study.</p>
<p>Addressing this concern could be relatively straightforward. For example, including information about the SNR in each respective brain region would be very helpful. If the SNR across brain regions within the MTL is relatively uniform, then this already addresses the concern above. regardless, it would be useful to report the experimental effects in relation, for example, the split-half reliability of signal in each brain region. That is, instead of simply reporting that that results are significant across brain regions, the authors might estimate how reliable the variance is across brain regions, and use this reliable variance as a ceiling which can be used to normalize the amount of variance explained in each analysis. By providing an account of the differences in the reliability/SNR of different regions, we would have a much better estimate of the relative importance of differences in the results reported for different regions within the MTL.</p>
<p>(3) Need for more systematic analysis/visualization of &quot;posterior&quot; vs. &quot;anterior&quot; regions.</p>
<p>The authors report that &quot;Whole-brain analyses revealed a gradient of plasticity in the temporal lobe, with drift more evident in anterior than posterior areas.&quot; However, the only contrast provided in the main text is between MTL structures and V1-there is no &quot;gradient&quot; in any of these analyses. There are other regions visualized in Supplemental Figure 3, but there is not a systematic evaluation of the gradient along a &quot;posterior/anterior&quot; axis. It would be helpful to see the results in Figures 3A, 4A, 5A, and 6A to include other posterior visual regions (e.g., V4, LOC, PPA, FFA) beyond V1.</p>
<p>(4) Without behavioral data, not a direct relationship with &quot;stability-plasticity tradeoff&quot;</p>
<p>The results from this study are framed in relation to a &quot;stability-plasticity tradeoff.&quot; As argued in this manuscript, this tradeoff is central to animal behavior - our ability to rapidly deploy prior knowledge to respond to the world around us. Given that there are no behavioral measures used in the current study, however, no claims can be made about how these fMRI data might relate to learning, or behavior more generally. As such, framing these results in terms of a stability-plasticity tradeoff is tenuous. &quot;Representational drift,&quot; on the other hand, is a term that is relatively agnostic in its relationship with behavior, and aptly describes the results presented here. The authors refer to this term as well. Considering the lack of behavioral evidence, alongside the core findings from these neuroimaging data, &quot;representational stability&quot; or &quot;representational &quot;drift&quot; seems to be a more direct description of the available data than &quot;neural plasticity&quot; or a &quot;stability-plasticity tradeoff.&quot;</p>
</body>
</sub-article>
<sub-article id="sa4" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100084.1.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Solomon</surname>
<given-names>Sarah H</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0003-9814-2436</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Kay</surname>
<given-names>Kendrick</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6604-9155</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Schapiro</surname>
<given-names>Anna C</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8086-0331</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>We are very appreciative of the reviewers’ assessment that we used “solid and creative” methods to provide a “convincing demonstration” of “compelling theoretical results” on a “crucial but less-explored issue” in cognitive neuroscience. We are also grateful for their thoughtful suggestions for analyses and for pointing out areas where our analysis descriptions need more clarity. While we will respond to all comments in a future response and revision, here we provide information and clarification on a few central points.</p>
<p>Localization of semantic content:</p>
<p>Regarding our semantic analysis, one reviewer rightly pointed out that items with a high degree of semantic association, as captured by word2vec, tend to occur in the same images, and they expressed concern that this could drive our similarity results. We wish to clarify here (and will revise the manuscript accordingly) that we excluded all pairs of co-occurring items in our word2vec semantic analysis in order to avoid this issue. Thus, our results cannot be driven by the number of images within which items co-occurred. We also agree with the reviewer who stated that “semantic information” is a nebulous term in the cognitive neurosciences, and it appears to have led to some confusion as to the nature of our claims. We take a broad view of this term, with the perspective that visual features (e.g., color, shape) can contribute to semantic content rather than necessarily competing with it. In our work, we use word2vec to identify neural representations that reflect the kind of semantic content present in word embedding models—but the conclusions we draw do not depend on these representations being devoid of visual content. That is, we do not use word2vec to examine semantic <italic>versus</italic> visual representations, but rather to narrow down the set of representations to be considered in subsequent analyses. While there are a range of legitimate views on what should be considered a “semantic” representation, our broad view, which is inclusive of visual content, along with our strategy for localizing semantic content are both standardly used in the visual neuroscience literature. Prior work in this literature has compared the ability of word2vec and low-level visual models to predict neural responses to natural images and found that the brain regions in which activity is accurately predicted by the models are considerably distinct: whereas a low-level visual model best predicts activity in V1, V2, and V4, word2vec performs better in more anterior regions, including in visual areas such as lateral occipital cortex (Güçlü &amp; van Gerven, 2015, <italic>arXiv</italic>). This suggests that our effects are unlikely to be explained by overlap in the kinds of low-level visual features mentioned by the reviewers. However, the semantic content we localize and the representation of high-level visual features may indeed overlap, and this is compatible with our claims. We will do more in our revision to be explicit about our intended meaning in our use of the word “semantic” and how our approach relates to and builds on prior work in this literature.</p>
<p>Long-term representational drift:</p>
<p>We want to clarify our claims regarding the representational drift analysis. One reviewer stated that, while we show evidence of representational drift, we “provide no evidence suggesting that this long-term neural representational drift reflects a drift in semantic representation.” Another reviewer said: “The inference is that this [drift] is due to an updating of knowledge about the associations each item has had with other items,” and that our finding that semantic structure remains stable within these regions seems “to contradict the claims about semantic plasticity.” The claim we intended to make, which will be unpacked more clearly in our revision, is that the neural representations underlying semantic content drift over time, even if the semantic content itself is unchanging. In other words, we do not claim that our across-session drift analyses show changes in knowledge about object associations. Indeed, one of the reasons that representational drift has recently captured the attention of neuroscientists is that the neural representations underlying certain behaviors or cognitive content appear to drift over time even when the behaviors or cognitive content remain fixed. The relational structure of the neural representations can remain stable, even if the particular neurons recruited to represent each stimulus change over time (see, e.g., the T-maze in Rule, O’Leary, &amp; Harvey., 2019, <italic>Curr Opin Neurobiol</italic>). Here we are translating these ideas, which were developed using animal models and/or primarily focused on low-level vision, to the semantic system in humans. The neural representations we identify in our paper capture semantic information because they share a similarity structure with word2vec, and the level of similarity to word2vec remains stable over time. Thus, our findings provide a simple demonstration of long-term representational drift in the human semantic system akin to that reported in animals—drift in the neural semantic representations of items even as the relations between these item representations appear stable.</p>
<p>Signal-to-noise variability across the MTL:</p>
<p>A reviewer raised the possibility that differences between our ROIs could be driven by variability in signal-to-noise ratio (SNR) across regions, particularly within the medial temporal lobe (MTL). We looked at noise ceiling SNR brain maps for each participant, which reflect the reliability of neural responses across repetitions of the same image. Preliminary analyses indicate that SNR differences do not account for our object encoding, semantic content, representational drift, or short-term plasticity measures across the MTL.</p>
</body>
</sub-article>
</article>