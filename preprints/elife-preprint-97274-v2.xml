<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">97274</article-id>
<article-id pub-id-type="doi">10.7554/eLife.97274</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.97274.2</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.3</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Local, calcium- and reward-based synaptic learning rule that enhances dendritic nonlinearities can solve the nonlinear feature binding problem</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6124-949X</contrib-id>
<name>
<surname>Khodadadi</surname>
<given-names>Zahra</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>zahra.khodadadi@scilifelab.se</email>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9068-6744</contrib-id>
<name>
<surname>Trpevski</surname>
<given-names>Daniel</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9134-3601</contrib-id>
<name>
<surname>Lindroos</surname>
<given-names>Robert</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">†</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0550-0739</contrib-id>
<name>
<surname>Hellgren Kotaleski</surname>
<given-names>Jeanette</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n1">†</xref>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/026vcq606</institution-id><institution>Science for Life Laboratory, Department of Computer Science, KTH Royal Institute of Technology</institution></institution-wrap>, <city>Stockholm</city>, <country country="SE">Sweden</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/056d84691</institution-id><institution>Department of Neuroscience, Karolinska Institutet</institution></institution-wrap>, <city>Stockholm</city>, <country country="SE">Sweden</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Ding</surname>
<given-names>Jun</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Stanford University</institution>
</institution-wrap>
<city>Stanford</city>
<country>United States of America</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Poirazi</surname>
<given-names>Panayiota</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>FORTH Institute of Molecular Biology and Biotechnology</institution>
</institution-wrap>
<city>Heraklion</city>
<country>Greece</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="equal"><label>†</label><p>These authors contributed equally to this work</p></fn>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-06-17">
<day>17</day>
<month>06</month>
<year>2024</year>
</pub-date>
<pub-date date-type="update" iso-8601-date="2025-04-24">
<day>24</day>
<month>04</month>
<year>2025</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP97274</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-03-14">
<day>14</day>
<month>03</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-03-14">
<day>14</day>
<month>03</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.03.12.584462"/>
</event>
<event>
<event-desc>Reviewed preprint v1</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2024-06-17">
<day>17</day>
<month>06</month>
<year>2024</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.97274.1"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.97274.1.sa2">eLife assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.97274.1.sa1">Reviewer #1 (Public Review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.97274.1.sa0">Reviewer #2 (Public Review):</self-uri>
<self-uri content-type="author-comment" xlink:href="https://doi.org/10.7554/eLife.97274.1.sa3">Author response:</self-uri>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Khodadadi et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Khodadadi et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-97274-v2.pdf"/>
<abstract>
<title>Abstract</title>
<p>This study investigates the computational potential of single striatal projection neurons (SPN), emphasizing dendritic nonlinearities and their crucial role in solving complex integration problems. Utilizing a biophysically detailed multicompartmental model of an SPN, we introduce a calcium-based, local synaptic learning rule dependent on dendritic plateau potentials. According to what is known about excitatory corticostriatal synapses, the learning rule is governed by local calcium dynamics from NMDA and L-type calcium channels and dopaminergic reward signals. In order to devise a self-adjusting learning rule, which ensures stability for individual synaptic weights, metaplasticity is also used. We demonstrate that this rule allows single neurons to solve the nonlinear feature binding problem, a task traditionally attributed to neuronal networks. We also detail an inhibitory plasticity mechanism that contributes to dendritic compartmentalization, further enhancing computational efficiency in dendrites. This <italic>in silico</italic> study highlights the computational potential of single neurons, providing deeper insights into neuronal information processing and the mechanisms by which the brain executes complex computations.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>The modeling code used in this study is structured for reproducibility and is available at https://github.com/zahradd/dSPN-learning-rule. This corrects a previous mistake in the repository name.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Classically, single neurons in the nervous system have been thought to operate as simple linear integrators where the nonlinearity of dendrites can be neglected (<xref ref-type="bibr" rid="c53">McCulloch and Pitts, 1943</xref>). Based on this simplification, powerful artificial neural systems have been created, outperforming humans on multiple tasks (<xref ref-type="bibr" rid="c78">Silver <italic>et al</italic>., 2018</xref>). However, in recent decades it has been shown that active dendritic properties participate in shaping neuronal output, and also the dendrites can display nonlinear integration of input signals (<xref ref-type="bibr" rid="c3">Antic <italic>et al</italic>., 2010</xref>). Dendritic nonlinearities endow a neuron with the ability to perform sophisticated dendritic computations (<xref ref-type="bibr" rid="c82">Tran-Van-Minh <italic>et al</italic>., 2015</xref>; <xref ref-type="bibr" rid="c25">Gidon <italic>et al</italic>., 2020</xref>), expanding its computational power beyond what is available with the somatic voltage threshold and making it similar to a multilayer artificial neural network (<xref ref-type="bibr" rid="c62">Poirazi, Brannon and Mel, 2003</xref>).</p>
<p>A dendritic nonlinearity common among projection neurons in several brain areas is the NMDA-dependent plateau potential (<xref ref-type="bibr" rid="c59">Oikonomou <italic>et al</italic>., 2014</xref>). Plateau potentials are regenerative, all-or-none, supralinear voltage elevations triggered by spatio-temporally clustered glutamatergic input (<xref ref-type="bibr" rid="c71">Schiller <italic>et al</italic>., 2000</xref>; <xref ref-type="bibr" rid="c63">Polsky, Mel and Schiller, 2004</xref>; <xref ref-type="bibr" rid="c48">Losonczy and Magee, 2006</xref>; <xref ref-type="bibr" rid="c50">Major <italic>et al</italic>., 2008</xref>; <xref ref-type="bibr" rid="c42">Larkum <italic>et al</italic>., 2009</xref>; <xref ref-type="bibr" rid="c43">Lavzin <italic>et al</italic>., 2012</xref>; <xref ref-type="bibr" rid="c91">Xu <italic>et al</italic>., 2012</xref>). Such plateaus require that nearby spines are coactivated, but the spatial requirement is somewhat loose as even single dendritic branches have been proposed to act as computational units (<xref ref-type="bibr" rid="c48">Losonczy and Magee, 2006</xref>; <xref ref-type="bibr" rid="c7">Branco and Häusser, 2010</xref>). With that said, multiple so-called hotspots, preferentially responsive to different input values or features, are known to form with close dendritic proximity (<xref ref-type="bibr" rid="c34">Jia <italic>et al</italic>., 2010</xref>; <xref ref-type="bibr" rid="c13">Chen <italic>et al</italic>., 2011</xref>; <xref ref-type="bibr" rid="c85">Varga <italic>et al</italic>., 2011</xref>). Such functional synaptic clusters are present in multiple species, developmental stages and brain regions (<xref ref-type="bibr" rid="c40">Kleindienst <italic>et al</italic>., 2011</xref>; <xref ref-type="bibr" rid="c81">Takahashi <italic>et al</italic>., 2012</xref>; <xref ref-type="bibr" rid="c89">Winnubst <italic>et al</italic>., 2015</xref>; <xref ref-type="bibr" rid="c88">Wilson <italic>et al</italic>., 2016</xref>; <xref ref-type="bibr" rid="c33">Iacaruso, Gasler and Hofer, 2017</xref>; <xref ref-type="bibr" rid="c72">Scholl, Wilson and Fitzpatrick, 2017</xref>; <xref ref-type="bibr" rid="c57">Niculescu <italic>et al</italic>., 2018</xref>; <xref ref-type="bibr" rid="c39">Kerlin <italic>et al</italic>., 2019</xref>; <xref ref-type="bibr" rid="c36">Ju <italic>et al</italic>., 2020</xref>). Hence, multiple features are commonly clustered in a single dendritic branch, indicating that this could be the neural substrate where combinations of simple features into more complex items occur.</p>
<p>Combinations of features in dendritic branches further provide single neurons with the possibility to solve linearly non-separable tasks, such as the nonlinear feature binding problem (NFBP) (<xref ref-type="bibr" rid="c82">Tran-Van-Minh <italic>et al</italic>., 2015</xref>; <xref ref-type="bibr" rid="c25">Gidon <italic>et al</italic>., 2020</xref>). In its most basic form, the NFBP involves discriminating between two groups of feature combinations. This problem is nonlinear because the neuron must learn to respond only to specific feature combinations, even though all features contribute equally in terms of synaptic input. A commonly used example involves two different shapes combined with two different colors, resulting in four total combinations. Out of these, the neuron should respond to only two specific feature combinations (exemplified in <xref rid="fig1" ref-type="fig">Figure 1A</xref> and <xref rid="fig1" ref-type="fig">1B</xref>).</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Learning Mechanisms in direct pathway Striatal Projection Neurons (dSPNs) for the Nonlinear Feature Binding Problem (NFBP)</title><p>(<bold>A</bold>) : Inputs and assumed supralinearity that could solve the NFBP: The NFBP is represented with an example from visual feature binding. In the simplest form of the NFBP, a stimulus has two features, here shape and form, each with two possible values, strawberry and banana, and red and yellow, respectively. In the NFBP the neuron should learn to respond by spiking to two of the feature combinations, representing the relevant stimuli (red strawberry and yellow banana), while remaining silent for the other two feature combinations which represent the irrelevant stimuli (yellow strawberry and red banana). Assuming that each feature is represented with locally clustered synapses, a solution of the NFBP can be achieved when the co-active clusters on a single dendrite, corresponding to a relevant stimulus, evoke a plateau potential, thus superlinearly exciting the soma. Conversely, co-activation of synaptic clusters for the irrelevant combinations should not evoke plateau potentials.</p><p>(<bold>B</bold>) : Synaptic clustering in dendrites: Illustration of how synaptic plasticity in SPNs may contribute to solving the NFBP for a pre-existing arrangement of synaptic clusters on two dendrites. A plasticity rule which strengthens only synaptic clusters representing relevant feature combinations, so that they produce robust supralinear responses, while weakening synapses activated by irrelevant feature combinations, could solve the NFBP.</p><p>(<bold>C</bold>) : Dopamine (Da) feedback: dopaminergic inputs from the midbrain to the striatum (Str) guides the learning process, differentiating between positive feedback for relevant stimuli and negative feedback for irrelevant stimuli. Positive feedback represented by dopamine peaks is necessary for LTP, and negative feedback represented by a dopamine pause is necessary for LTD.</p><p>(<bold>D</bold>) : Signaling pathways underlying synaptic plasticity in dSPNs: Illustrations of signaling components at the corticostriatal synapse that modify synaptic strength (redrawn from <xref ref-type="bibr" rid="c75">Shen et al., 2008</xref>). NMDA calcium influx, followed by stimulation of D<sub>1</sub> dopamine receptors (D<sub>1</sub>Rs), triggers LTP (while inhibiting the LTD cascade). L-type calcium influx and activation of metabotropic glutamate receptors (mGluRs) when D<sub>1</sub>Rs are free of dopamine triggers LTD (while counteracting the LTP cascade).</p></caption>
<graphic xlink:href="584462v3_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>As a task, the NFBP is relevant to brain regions which perform integration of multimodal input signals, or signals representing different features of the same modality (<xref ref-type="bibr" rid="c67">Roskies, 1999</xref>). It is usually illustrated with examples from the visual system, as in <xref rid="fig1" ref-type="fig">Figure 1A</xref> (<xref ref-type="bibr" rid="c67">Roskies, 1999</xref>; <xref ref-type="bibr" rid="c51">von der Malsburg, 1999</xref>; <xref ref-type="bibr" rid="c82">Tran-Van-Minh <italic>et al</italic>., 2015</xref>). A region that integrates multimodal inputs, such as sensory information and motor-related signals, is the input nucleus of the basal ganglia, the striatum (<xref ref-type="bibr" rid="c65">Reig and Silberberg, 2014</xref>; <xref ref-type="bibr" rid="c35">Johansson and Silberberg, 2020</xref>), and this system will be used in the present modeling study. We will here, however, continue to illustrate the NFBP with the more intuitive features borrowed from the visual field, although for the dorsal striatum these features would rather map onto different sensory- and motor-related features. Plateau potentials and some clustering of input have been demonstrated in SPNs (<xref ref-type="bibr" rid="c61">Plotkin, Day and Surmeier, 2011</xref>; <xref ref-type="bibr" rid="c59">Oikonomou <italic>et al</italic>., 2014</xref>; <xref ref-type="bibr" rid="c19">Du <italic>et al</italic>., 2017</xref>; <xref ref-type="bibr" rid="c32">Hwang <italic>et al</italic>., 2022</xref>; <xref ref-type="bibr" rid="c15">Day <italic>et al</italic>., 2024</xref>; <xref ref-type="bibr" rid="c68">Sanabria <italic>et al</italic>., 2024</xref>).</p>
<p>In addition to integrating converging input from the cortex and the thalamus, the striatum is densely innervated by midbrain dopaminergic neurons which carry information about rewarding stimuli (<xref ref-type="bibr" rid="c73">Schultz, 2007</xref>; <xref ref-type="bibr" rid="c52">Matsuda <italic>et al</italic>., 2009</xref>; <xref ref-type="bibr" rid="c80">Surmeier <italic>et al</italic>., 2010</xref>). As such, the striatum is thought to be an important site of reward learning, associating actions with outcomes based on neuromodulatory cues. In this classical framework, peaks in dopamine signify rewarding outcomes and pauses in dopamine represent the omission of expected rewards (<xref ref-type="bibr" rid="c74">Schultz, Dayan and Montague, 1997</xref>). Dopamine signals further control the synaptic plasticity of corticostriatal synapses on the SPNs (<xref rid="fig1" ref-type="fig">Figure 1C</xref>). In direct pathway SPNs (dSPN) expressing the D<sub>1</sub> receptor, a dopamine peak together with significant calcium influx through NMDA receptors triggers synaptic strengthening (long-term potentiation - LTP). Conversely, when little or no dopamine is bound to the D<sub>1</sub> receptors, as during a dopamine pause, and there is significant calcium influx through L-type calcium channels, synaptic weakening occurs (long-term depression - LTD, see <xref rid="fig1" ref-type="fig">Figure 1D</xref>) (<xref ref-type="bibr" rid="c75">Shen <italic>et al</italic>., 2008</xref>; <xref ref-type="bibr" rid="c20">Fino <italic>et al</italic>., 2010</xref>; <xref ref-type="bibr" rid="c60">Plotkin <italic>et al</italic>., 2013</xref>).</p>
<p>The ability to undergo LTP or LTD is itself regulated (<xref ref-type="bibr" rid="c30">Huang <italic>et al</italic>., 1992</xref>), a concept termed metaplasticity (<xref ref-type="bibr" rid="c2">Abraham and Bear, 1996</xref>). Metaplasticity refers to changes in synaptic plasticity driven by prior synaptic activity (<xref ref-type="bibr" rid="c22">Frey <italic>et al</italic>., 1995</xref>) or by neuromodulators (<xref ref-type="bibr" rid="c55">Moody, Carlisle and O’Dell, 1999</xref>), effectively making plasticity itself adaptable. Metaplasticity can further regulate synaptic physiology to shape future plasticity without directly altering synaptic efficacy, acting as a homeostatic mechanism to keep synapses within an optimal dynamic range (<xref ref-type="bibr" rid="c1">Abraham, 2008</xref>).</p>
<p>If dopamine peaks are associated with the relevant feature combinations in the NFBP and dopamine pauses with the irrelevant ones, it can trigger LTP in synapses representing the relevant feature combinations and LTD in those representing irrelevant combinations. If, after learning, the relevant feature combinations have strong enough synapses so they can evoke plateau potentials while the irrelevant feature combinations have weak enough synapses so they don’t evoke plateaus, the outcome of this learning process should be a synaptic arrangement that could solve the NFBP (<xref rid="fig1" ref-type="fig">Figure 1B</xref>) (<xref ref-type="bibr" rid="c82">Tran-Van-Minh <italic>et al</italic>., 2015</xref>). In line with this, it has been demonstrated that the NFBP can be solved in abstract neuron models where the soma and dendrites are represented by single electrical compartments and where neuronal firing and plateau potentials are phenomenologically represented by instantaneous firing rate functions (<xref ref-type="bibr" rid="c44">Legenstein and Maass, 2011</xref>; <xref ref-type="bibr" rid="c70">Schiess, Urbanczik and Senn, 2016</xref>). Good performance on the NFBP has also been demonstrated with biologically detailed models (<xref ref-type="bibr" rid="c4">Bicknell and Häusser, 2021</xref>). This solution used a multicompartmental model of a single pyramidal neuron, including both excitatory and inhibitory synapses and supralinear NMDA depolarizations. Synapses representing different features were randomly dispersed throughout the dendrites and a phenomenological precalculated learning rule - dependent on somatic spike timing and high local dendritic voltage - was used to optimize the strength of the synapses. The solution did, however, depend on a form of supervised learning as somatic current injections were used to raise the spiking probability of the relevant feature combinations.</p>
<p>In this study, we aim to investigate whether and to what extent the theoretical solution to the NFBP, as proposed by e.g. <xref ref-type="bibr" rid="c82">Tran-Van-Minh et al., (2015)</xref> can be achieved using biophysically detailed models of SPNs and a biologically plausible local learning rule. Our approach relies on the following key mechanisms:
<list list-type="order">
<list-item><p><bold>A local learning rule:</bold> We develop a learning rule driven by local calcium dynamics in the synapse and by reward signals from the neuromodulator dopamine. This plasticity rule is based on the known synaptic machinery for triggering LTP or LTD in the corticostriatal synapse onto dSPNs (<xref ref-type="bibr" rid="c75">Shen <italic>et al</italic>., 2008</xref>). Importantly, the rule does not rely on supervised learning paradigms and neither is a separate training and testing phase needed.</p></list-item>
<list-item><p><bold>Robust dendritic nonlinearities:</bold> According to <xref ref-type="bibr" rid="c82">Tran-Van-Minh et al., (2015)</xref> sufficient supralinear integration is needed to ensure that e.g. two inputs (i.e. one feature combination in the NFBP, <xref rid="fig1" ref-type="fig">Figure 1A</xref>) on the same dendrite generate greater somatic depolarization than if those inputs were distributed across different dendrites. To accomplish this we generate sufficiently robust dendritic plateau potentials using the approach in <xref ref-type="bibr" rid="c83">Trpevski et al., (2023)</xref>.</p></list-item>
<list-item><p><bold>Metaplasticity:</bold> Although not discussed much in more theoretical work, our study demonstrates the necessity of metaplasticity for achieving stable and physiologically realistic synaptic weights. This mechanism ensures that synaptic strengths remain within biologically plausible ranges during training, regardless of initial synaptic weights.</p></list-item>
</list>
We first demonstrate the effectiveness of the proposed learning rule under the assumption of pre-existing clustered synapses for each individual feature, as suggested by <xref ref-type="bibr" rid="c82">Tran-Van-Minh et al., (2015)</xref>. These clustered synapses are trained, to a degree where they can reliably evoke robust plateau potentials for the relevant feature combinations required to solve the NFBP, while synapses representing irrelevant features are weakened (illustrated in <xref rid="fig1" ref-type="fig">Figure 1B</xref>).</p>
<p>We then extend the analysis by applying the learning rule to more randomly distributed synapses, which initially exhibit minimal local supralinear integration. However, when incorporating the assumption that branch-specific plasticity mechanisms are at play, supralinear integration emerges within distinct dendritic branches. This suggests that branch-specific plasticity could play a critical role in enabling single neurons to solve nonlinear problems. Furthermore, we explore an activity-dependent rule for GABAergic plasticity and demonstrate its potential importance in shaping dendritic nonlinearities. This mechanism may thus further enhance computational capabilities by refining and stabilizing the integration of inputs across dendritic branches.</p>
<p>Although brain systems like the striatum, which integrate multimodal inputs, somehow solve nonlinear problems at the network or systems level, it remains unclear whether individual neurons in the brain regularly solve the NFBP. Our investigation suggests, however, that single SPNs possess the computational capacity to address linearly non-separable tasks. This is achieved by leveraging the organism’s performance feedback, represented by dopamine peaks (success) and dopamine pauses (failure), in combination with their ability to generate robust dendritic plateau potentials. Since the mechanisms used in the rule are general to the brain, this capability may also extend to other projection neurons capable of producing dendritic plateaus, such as pyramidal neurons. However, the specific feedback mechanisms, represented here by dopamine, would need to be associated with alternative neuromodulatory signals depending on the type of neuron and synapse involved.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Characterization of the dendritic nonlinearities in the model</title>
<p>The nonlinear, sigmoidal voltage sensitivity of the NMDA receptors is a crucial element for forming dendritic plateau potentials. We use a model for generating plateau potentials first presented in <xref ref-type="bibr" rid="c24">Gao <italic>et al</italic>., (2021)</xref> and adjusted to SPNs (<xref ref-type="bibr" rid="c83">Trpevski <italic>et al</italic>., 2023</xref>). To produce robust, all-or-none plateau potentials, glutamate spillover from the synaptic cleft that activates extrasynaptic NMDA receptors is included in the model. Glutamate spillover occurs when the total synaptic weight of the nearby activated synapses reaches a threshold value (see Methods). The threshold value here is set to be equivalent to the total weight of 8 clustered synapses with weights of 0.25 each (weights of 0.25 corresponds to a maximal conductance of 0.625 nS). <xref rid="fig2" ref-type="fig">Figure 2A</xref> shows the somatic membrane potential following synaptic activation of a cluster of synapses of increasing size and the corresponding local spine membrane potential as well as the NMDA and L-type calcium accumulated in a single spine (averaged over all spines in the cluster). A plateau potential is generated when a critical level of total NMDA conductance in a dendritic segment is reached (accomplished here by the addition of more synapses in a cluster eventually leading to glutamate spillover). Reaching the spillover threshold produces a sudden and prolonged increase in NMDA conductance, caused by the activation of extrasynaptic NMDA receptors (where the clearance of glutamate is assumed to be slower). The result is a more robust plateau potential that better resembles experimentally generated plateau potentials, as investigated in more detail in <xref ref-type="bibr" rid="c83">Trpevski <italic>et al</italic>., (2023)</xref>.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Characterization of dendritic plateau potentials in the model.</title><p>(<bold>A</bold>) : Somatic voltage, spine voltage, NMDA calcium, and L-type calcium evoked by a cluster varying in size from 1 to 20 synapses. A plateau potential is evoked when glutamate spillover is activated, here triggered when 8 synapses with a weight of 0.25 each are coactivated (corresponding to the “baseline” weights in C).</p><p>(<bold>B</bold>) : Schematic of the neuron morphology with an arrow indicating the stimulated dendritic branch shown in panel A.</p><p>(<bold>C</bold>) : The mean maximal amplitude, with standard deviation shown in bars, of the measures in A averaged over 10 different dendrites, and 10 trials per dendrite. The curves represent clusters with different synaptic weights: baseline (0.25, 0.625 nS), strengthened (0.4, 1 nS) and weakened weights (0.2, 0.5 nS). Synaptic background noise is used in all simulations to elevate the membrane potential to ranges seen in vivo (<xref ref-type="bibr" rid="c65">Reig and Silberberg, 2014</xref>).</p></caption>
<graphic xlink:href="584462v3_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>The synaptic input to the neuron is provided through the activation of a cluster of synapses at the indicated location in <xref rid="fig2" ref-type="fig">Figure 2B</xref>, and gives the voltage and calcium responses as exemplified in <xref rid="fig2" ref-type="fig">Figure 2A</xref>. <xref rid="fig2" ref-type="fig">Figure 2C</xref> shows the maximal amplitudes of the somatic and spine voltage together with NMDA and L-type calcium signals in the dendritic spines, averaged over 10 trials and over 10 dendrites. The “baseline” results in <xref rid="fig2" ref-type="fig">Figure 2C</xref> are within the range of the initial synaptic weights of excitatory synapses in all remaining figures in the article, and thus illustrate a possible initial situation before learning. Stronger and weaker synapses require a smaller and a larger cluster to trigger a plateau potential, respectively (<xref rid="fig2" ref-type="fig">Figure 2C</xref>, spine voltage panel). In the simulation using “strengthened” synapses the synaptic weights in the cluster are 60% greater than in the “baseline” case, and hence need fewer synapses to trigger plateau potentials. Conversely, with weaker synapses, where weights are 25% smaller than the “baseline” case, more synapses are needed to evoke a plateau.</p>
<p>To summarize, the dSPN model exhibits the dendritic nonlinearities required for solving the NFBP. Further, clusters of strengthened synapses can reliably generate robust plateau potentials, which produces a long lasting somatic depolarization and thereby increases the likelihood for somatic spiking (in accordance with <xref ref-type="bibr" rid="c19">Du et al., 2017</xref> and also illustrated in <xref ref-type="bibr" rid="c83">Trpevski et al., 2023</xref>). Conversely, clusters of weakened synapses will most likely not generate plateau potentials, and thus the neuron will spike with much lower probability following activation of such a cluster.</p>
</sec>
<sec id="s2b">
<title>Characterization of the synaptic plasticity rule</title>
<p>To characterize the learning rule we started with a simple setup where three features, each illustrating either a color or a shape, were distributed onto two dendritic branches. The setup was such that one relevant and one irrelevant feature combination were represented in each dendrite and the relevant-irrelevant feature combination was unique to each dendrite (see illustration in <xref rid="fig3" ref-type="fig">Figure 3A</xref>). Each feature was represented with 5 synapses, and we start with the assumption that those synapses are already organized in pre-existing clusters. In addition to background synaptic noise inputs, 108 randomly distributed glutamatergic synapses were also added. These synapses were activated together with all four stimuli, i.e. they were feature-unspecific. SPNs have a very hyperpolarized resting potential, and the additional feature-unspecific synapses allowed the neurons to spike often enough in the beginning of the learning process so that a dopamine feedback signal would be elicited and trigger learning in the activated synapses.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3:</label>
<caption><title>Example of setup and learning-induced synaptic plasticity</title><p>(<bold>A</bold>) : Illustration of input configuration. The upper panel illustrates the arrangement of features across two dendrites. Each dendrite has synaptic clusters for three features, allowing the representation of each of the four stimuli if seen from the whole neuron’s perspective (but only one relevant stimulus per dendrite). The bottom panel illustrates the stimulation protocol used in the simulation, where stimulus presentation is followed by a dopaminergic feedback signal only if the neuron spikes. Two stimuli are spaced 800 ms apart, to allow for the calcium dynamics to reach baseline levels.</p><p>(<bold>B</bold>) : Example voltage in the soma and the middle of dendrite 1 (d<sub>1</sub>) and dendrite 2 (d<sub>2</sub>) before and after learning. Each dendrite here stops responding to the respective irrelevant stimuli during learning.</p><p>(<bold>C</bold>), (<bold>D</bold>): Evolution of synaptic conductances during learning (top row) and examples of peak Ca²⁺ levels (dots) alongside kernel dynamics in single synapses (three lower rows). Panels in (C) depict clustered synapses in dendrite 1 (d1), where ‘yellow’ and ‘banana’ generally undergo LTP, while ‘red’ undergoes LTD. Panels in (D) show distributed, feature-unspecific synapses. Among these, the purple and blue traces represent synapses that are weakened, while the green trace exemplifies a synapse near one of the clusters that, by chance, achieves a sufficiently high local NMDA calcium level for LTP to dominate. The initial synaptic conductances are drawn from a normal distribution with a mean of 0.625 and a standard deviation of 0.375 nS. MP-K and LTP-K refer to metaplasticity and LTP kernels, respectively, while the solid line represents the midpoint of the kernels, where LTP is strongest. ‘Max’ indicates the peak NMDA calcium during a single stimulus.</p></caption>
<graphic xlink:href="584462v3_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>The learning rule modified synaptic weights based on local calcium levels at each synapse, employing distinct plasticity kernels for LTP and LTD, each associated with different calcium sources—NMDA and L-type channels, respectively (<xref rid="fig1" ref-type="fig">Figure 1</xref>; see also Methods). The LTD kernel was governed by a calcium threshold, above which the change of synaptic weight was proportional to the amplitude of L-type calcium. That is, higher calcium levels trigger a larger reduction of weights than low concentrations. Conversely, the LTP kernel was represented by a bell-shaped function over a range of NMDA calcium concentrations, allowing LTP in the presence of dopamine when calcium levels fell within this range, while calcium outside this range did not elicit LTP (see Methods).</p>
<p>An additional feature of the learning rule was metaplasticity (<xref ref-type="bibr" rid="c1">Abraham, 2008</xref>), which dynamically adjusted the calcium dependence of the LTP kernel. That is, the LTP kernel’s calcium dependence was adjusted over time (see Methods). Metaplasticity enabled e.g. previously weak synapses that were repeatedly co-activated with rewards, to eventually participate in LTP, as their calcium threshold was gradually lowered when the LTP-kernel was shifted. The same mechanism also prevented excessive strengthening of already potent synapses as also the upper calcium threshold for LTP was lowered following repeated co-activation with rewards. This behavior of the LTP kernel ensured stability in synaptic weights and allowed for continuous refinement of synaptic efficacy based on activation pattern and presence/absence of dopamine.</p>
<p>Initially, the synaptic weight of each synapse was set to a value chosen uniformly at random from a range of 0.25 ± 0.15 (corresponding to conductances of 0.625 ± 0.375 nS). Initially, the synapses therefore experienced different NMDA and L-type calcium levels following activation, and hence their weights were also updated differently based on where the calcium level fell within their individual plasticity kernels.</p>
<p>The neuron model was during training activated with a sequence of 960 feature combinations, including equal amounts of relevant (i.e., ‘red strawberry’ and ‘yellow banana’) and irrelevant feature combinations (i.e., ‘yellow strawberry’ and ‘red banana’). Thus, dopamine peaks and dopamine pauses occurred equally often at the beginning of the learning phase. When the neuron spiked for the relevant feature combinations, dopamine rewards were delivered, triggering LTP in the active synapses with NMDA Ca levels within the LTP kernel. Conversely, spiking for the irrelevant feature combinations elicited a dopamine pause as feedback, triggering LTD as a function of L-type Ca. As learning progressed, the neuron learned to respond only to the relevant feature combinations (see example in <xref rid="fig3" ref-type="fig">Figure 3B</xref>). Initially, all four stimuli—‘yellow banana’ and ‘red banana’ in dendrite 1, and ‘red strawberry’ and ‘yellow strawberry’ in dendrite 2—elicited robust supralinear responses, as they together reached the threshold for glutamate spillover in the model. This is shown with gray lines in the voltage traces in <xref rid="fig3" ref-type="fig">Figure 3B</xref>. After learning, the neuron could differentiate between the two sets of stimuli. The relevant feature combinations associated with a reward continued to provoke a plateau potential and eliciting somatic spiking, while in contrast, the neuron’s response to irrelevant feature combinations was notably decreased (shown with black lines in the somatic voltage trace in <xref rid="fig3" ref-type="fig">Figure 3B</xref>).</p>
<p><xref rid="fig3" ref-type="fig">Figure 3C</xref> shows the evolution of synaptic conductances during the learning process for dendrite 1 (dendrite 2 is not shown, but has a similar behavior for relevant and irrelevant stimuli). The synapses representing the relevant feature combination in this dendrite (‘yellow’ and ‘banana’) are typically strengthened, eventually encoding this stimulus robustly. Conversely, the synapses for the feature ‘red’, activated during the irrelevant feature combination (‘red banana’) are all weakened, making the dendrite only weakly responsive to this stimulus following learning. Note that during the learning process LTD could also occur in some synapses representing ‘yellow’ and ‘banana’ because these features were also part of the irrelevant stimuli (‘yellow strawberry’ and ‘red banana’, respectively). As a result, a small number of these synapses, in particular those whose initial weights are low, have been weakened and are not recruited in the clusters to encode the ‘yellow banana’ stimulus. This means that our learning rule tends to stabilize the number of synapses that are needed to perform the task, but not necessarily all the synapses carrying the relevant features (as some by chance may be outside of the plastic region of the LTP kernel). Depending on the initial local Ca response in the synapse to relevant and irrelevant stimuli, individual synapses might either be preferentially recruited into the LTP or LTD process.</p>
<p>The evolution of synaptic weights for clustered and feature-unspecific synapses is illustrated in the top panels of <xref rid="fig3" ref-type="fig">Figure 3C</xref> and <xref rid="fig3" ref-type="fig">D</xref>. Correspondingly, the calcium dynamics for three color-coded synapses in each case (indicated with arrows in the top panels) are shown in the bottom panels, demonstrating how the dynamics evolve under the influence of LTP and metaplasticity kernels. This highlights the process by which synapses stabilize at specific conductances/weights during learning.</p>
<p>The red synapses (exemplified in <xref rid="fig3" ref-type="fig">Figure 3C</xref>, second row) represents an irrelevant feature combination (‘red banana’), and as learning progresses, LTD becomes more frequent due to repeated dopamine pauses. These pauses shift the metaplasticity kernel towards higher calcium levels, moving the red synapses outside the range for LTP. This shift ensures that the red synapses weaken over time, preventing them from encoding irrelevant stimuli and reducing the dendrite’s response to these inputs. This can be compared with <xref rid="fig3s1" ref-type="fig">Figure 3—figure supplement 1</xref> (red synapse) that lacks metaplasticity.</p>
<p>The yellow synapse (exemplified in <xref rid="fig3" ref-type="fig">Figure 3C</xref>, third row), part of the relevant feature combination (‘yellow banana’), initially undergoes LTP as repeated dopamine rewards strengthen it. However, not all yellow synapses are equally strengthened. Synapses with weak initial weights may fail to potentiate further due to the slow adaptation of the LTP kernel and their inability to reach the required calcium levels. Specifically, the first example, “yellow syn. 1”, exhibits an increase in synaptic conductance, whereas the second example, “yellow syn. 2”, does not undergo potentiation (see arrows in <xref rid="fig3" ref-type="fig">Figure 3C</xref> top).</p>
<p>The banana synapses (exemplified in <xref rid="fig3" ref-type="fig">Figure 3C</xref>, fourth row) follows a similar trajectory to the yellow synapses. As part of the relevant feature combination, they are strengthened during the learning process through repeated LTP. Some weak synapses also undergo LTD for the same reasons as for the few yellow synapses.</p>
<p>Feature-unspecific synapses, like the purple synapse in <xref rid="fig3" ref-type="fig">Figure 3D</xref>, typically weaken over time. These synapses are co-activated with irrelevant stimuli and experience frequent dopamine pauses, causing the metaplasticity kernel to shift upward and away from the calcium levels required for LTP. As a result, LTD dominates in these synapses, leading to their gradual weakening. Initially, LTP and LTD typically occur equally often, but as learning progresses, both the frequency of dopamine pauses and thus LTD decreases, allowing the weights to stabilize over time.</p>
<p>In contrast, the green synapse, though feature-unspecific, behaves differently due to its proximity to a cluster. It benefits from high local voltage and calcium, due to glutamate spillover that generates plateau potentials during relevant stimuli (e.g., ‘yellow banana’), keeping calcium levels within the high end of the LTP kernel. As the learning process progresses and dopamine pauses become less frequent, the LTP kernel shifts downward. This causes the calcium level associated with the other relevant stimuli (i.e. ‘red strawberry’) to also fall within the plastic region of the LTP kernel, and thereby further strengthening the synapse.</p>
<p>Finally, the blue synapse initially triggers calcium levels within the LTP kernel, leading to early strengthening. However, as the LTD amplitude is proportional to the L-type calcium level, LTD eventually dominates, weakening the blue synapse. This happens because feature-unspecific synapses experience dopamine pauses and peaks equally often in the beginning. Once calcium levels fall below the optimal range of the LTP kernel due to dopamine pauses, LTP ceases, and the synapse stabilizes at a lower weight (compare to <xref rid="fig3s1" ref-type="fig">Figure 3—figure supplement 1</xref>, blue trace, where LTP and LTD stays balanced throughout the simulation and the weight stays high). In summary, synaptic weights are dynamically regulated by the interplay of LTD and LTP, modulated by the metaplasticity kernel. This process ensures that synapses adjust appropriately based on their relevance to feature combinations, stabilizing in a manner that reflects their functional roles and initial conditions.</p>
</sec>
<sec id="s2c">
<title>Characterization of input combinations that can be learned</title>
<p>After demonstrating that the SPN can differentiate between relevant and irrelevant stimuli in the simplified example in <xref rid="fig3" ref-type="fig">Figure 3</xref>, we generalized this setup by varying the innervation of the four features across the two dendrites and recorded the SPN’s performance on the NFBP as learning progressed. We only used feature innervations where both relevant feature combinations were present, with at least one relevant feature on each dendrite. This ensures sufficient innervation to potentially solve the NFBP (for an illustration see <xref rid="fig4" ref-type="fig">Figure 4A</xref>). The SPN’s performance was assessed during training to determine whether it spiked for relevant feature combinations and remained silent for irrelevant ones. Performance of 100% indicates the SPN spikes exclusively for relevant stimuli, while 50% indicates one of two scenarios: (i) the SPN spikes for all four stimuli, or (ii) it remains silent for all four. A performance of 75% reflects intermediate spiking behavior, such as spiking for one relevant combination while remaining silent for the other three, or spiking for three combinations and being silent for one irrelevant combination. The NFBP is considered solved when performance exceeds 87.5%, which occurs when the SPN consistently spikes for one relevant combination and spikes at least half the time for the other relevant combination while ignoring irrelevant stimuli.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4:</label>
<caption><title>Impact of input configurations and synaptic cluster locations on NFBP learning performance</title><p>(<bold>A</bold>): Illustration of creating different input configurations where two, three or four features are placed in two dendritic locations.</p><p>(<bold>B</bold>) : Performance trajectories for all 31 unique input configurations over training epochs. Each line represents the learning performance of a single configuration, with blue traces indicating setups where no dendrite receives more than three features and deep red traces representing setups where at least one dendrite contains all four features. The inset shows the number of configurations in each group that reached the NFBP learning criterion: 18/18 for the blue group and 5/13 for the deep red group.</p><p>(<bold>C</bold>) : Performance on the last 160 stimuli for the two groups of configurations: (C<sub>1</sub>) setups where each dendrite has at most three features and (C<sub>2</sub>) setups where at least one dendrite contains all four features.</p><p>(<bold>D</bold>) and (<bold>E)</bold>: Performance in a three-feature configuration as a function of cluster location. (D) illustrates the distribution of synaptic clusters across dendritic locations, and (E) shows performance over the last 160 stimulus presentations as a function of somatic distance for these configurations. A total of 60 unique configurations were tested, with synapse clusters randomly assigned to different dendritic locations. The solid line represents a quadratic fit to the data.</p></caption>
<graphic xlink:href="584462v3_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>In cases where both dendrites receive two or three features, ensuring that each dendrite has at least one relevant combination, the mean performance exceeds 90%, indicating that both relevant combinations are learned (<xref rid="fig4" ref-type="fig">Figure 4B</xref>, blue traces). However, when at least one dendrite is innervated by all four features, learning becomes significantly more challenging. The dendrite with four features struggles to resolve the competition between feature combinations, making it difficult to encode a single relevant combination. This often results in only one relevant combination being learned, with the same combination often being redundantly encoded in both dendrites, or else the dendrite with four features is failing to encode any combination as all features are weakened (<xref rid="fig4" ref-type="fig">Figure 4B</xref>, deep red traces). In some cases, depending on the order of stimuli during training, both relevant combinations can still be learned, solving the NFBP. Specifically, 5 out of 13 setups in which one dendrite received all four features successfully solved the task (<xref rid="fig4" ref-type="fig">Figure 4B</xref>).</p>
<p><xref rid="fig4" ref-type="fig">Figure 4C</xref> provides a detailed view of performance during the last 160 training examples for each of the four stimuli. <xref rid="fig4" ref-type="fig">Figure 4C</xref><sub>1</sub> corresponds to the blue traces in <xref rid="fig4" ref-type="fig">Figure 4B</xref>, where the NFBP is solved, with most errors caused by spiking for irrelevant combinations. <xref rid="fig4" ref-type="fig">Figure 4C</xref><sub>2</sub> corresponds to the deep red traces in <xref rid="fig4" ref-type="fig">Figure 4B</xref>, where the NFBP is generally not solved, as relevant stimuli elicit spikes only about 75% of the time. These results suggest that when one dendrite is innervated by all four features, the competition between feature combinations creates a bottleneck for learning. This can lead to one combination dominating early in training and being encoded in both dendrites, while the other relevant combination is weakened or entirely suppressed. In cases where learning fails, the dendrite with four features often either fails to encode any combination due to excessive LTD or instead encodes the same combination already represented in the other dendrite. Addressing this challenge may require mechanisms to “break symmetry” during learning, as noted in previous studies using abstract neuron models. Symmetry-breaking strategies, such as amplifying or attenuating dendritic nonlinearities as they propagate to the soma, can reduce competition and enable successful differentiation of feature combinations (e.g., branch plasticity; Legenstein and Maas, 2011).</p>
</sec>
<sec id="s2d">
<title>Optimal learning is achieved at intermediate distances from soma through excitatory plasticity</title>
<p>We also investigated the impact of synaptic positioning on learning (<xref rid="fig4" ref-type="fig">Figure 4D</xref>) when using the same input setup as in <xref rid="fig3" ref-type="fig">Figure 3</xref>, but varying dendritic locations. Our results predict that the best performance on the NFBP is obtained with synaptic clusters positioned at intermediate somatic distances from the soma (<xref rid="fig4" ref-type="fig">Figure 4E</xref>). From <xref rid="fig4" ref-type="fig">Figure 4E</xref> one can infer that after learning the proximal synapses have actually decreased when trained on the NFBP as the performance is around 50%. The neuron stays silent for the irrelevant feature combinations (blue dots), which is the correct response, but also the neuron can’t respond to the relevant feature combinations (red dots). For successively more distal synapses the performance increases and then slightly decreases for the most distal clusters that sometimes fail to evoke somatic spiking for the correct feature combinations (red dots). This result can be conceptually explained in the following way. The electrotonic properties of dendrites dictate that synapses near the soma, in the most proximal regions, are less capable of supralinear input integration underlying plateau potentials (<xref ref-type="bibr" rid="c19">Du <italic>et al</italic>., 2017</xref>). This is due to the soma acting as a current sink, resulting in smaller localized voltage changes (and hence a lower input resistance in accordance with Ohm’s law). Consequently, these synapses cannot easily evoke dendritic nonlinearities necessary for solving the NFBP, and hence the performance with proximal clusters is low. Note that in our simulations we allow glutamatergic synapses on spines quite close to the soma, although SPN dendritic spines are relatively rare at more proximal distances than 40-50 <italic>μ</italic>m from the soma (<xref ref-type="bibr" rid="c87">Wilson <italic>et al</italic>., 1983</xref>).</p>
<p>In contrast, the most distal dendritic regions are electrically more isolated and have a higher local input resistance, enabling larger voltage changes locally and thus also higher local calcium concentrations when synapses are activated in our model. This allows even a small number of active synapses to generate local supralinear NMDA-dependent responses. Such ease of elevating the local calcium, seems advantageous, However, this ultimately results in decreased performance on the NFBP for the following reasons. In distal synaptic clusters, excessive spiking for irrelevant stimuli occurs during the early and middle stages of learning. This leads to frequent punishment signals (negative feedback), which, in turn, reduce the neuron’s ability to spike for relevant combinations later in training. Additionally, while distal synapses can generate plateau potentials and NMDA-dependent responses, these signals naturally attenuate as they propagate toward the soma, sometimes failing to elicit somatic spikes for the relevant stimuli. This combination of excessive negative feedback early on and attenuated distal signals reduces the effectiveness of the feedback loop, making it difficult for the neuron to selectively strengthen synapses associated with relevant stimuli and weaken those tied to irrelevant ones.</p>
<p>The ideal learning zone for NFBP in our simulations thus lies at an intermediate somatic distance, roughly 100-150 µm from the soma, where synapses can effectively contribute to learning the NFBP (<xref rid="fig4" ref-type="fig">Figure 4E</xref>). In this zone synaptic changes are more likely to impact the neuron’s firing probability as the dendritic plateau potential at this location causes a larger elevation of the somatic potential, and thus synapses at this distance benefit more from the dopamine feedback loop. Note that the prediction that proximal and very distal synapses are less likely to contribute to the solving of the NFBP doesn’t imply they are not important for more ‘linear’ learning contexts. For instance, if we had trained the neuron to only respond to one single stimulus, such as ‘red strawberry’, both proximal and very distal synapses representing that stimulus would of course be able to both strengthen or weaken as well as contribute to spiking of the neuron following learning.</p>
</sec>
<sec id="s2e">
<title>The possible role of inhibitory plasticity in learning</title>
<p>In our initial simulations we assumed that only the excitatory synapses could undergo plasticity during learning, and we identified two critical observations that highlight possible areas for improvement. The first is a vulnerability to noise, which resulted in a performance around 90 percent, as illustrated in <xref rid="fig4" ref-type="fig">Figure 4B</xref>. The second is a decrease in performance observed across very distal synapses, as detailed in <xref rid="fig4" ref-type="fig">Figure 4E</xref>. These findings prompted us to explore the potential role of inhibitory synapses.</p>
<p>We developed a phenomenological inhibitory plasticity rule to enhance the contrast of dendritic nonlinearities (detailed in the Methods section). This rule is designed to compartmentalize dendrites, ensuring they predominantly respond to excitatory inputs that cause the strongest activation. Such compartmentalization has been experimentally observed in radial oblique and basal dendrites of CA1 pyramidal neurons, where NMDA spikes and plateau potentials are the main forms of dendritic nonlinearity. Co-located inhibitory synapses in these dendrites regulate whether these nonlinear responses are elicited or not (<xref ref-type="bibr" rid="c49">Lovett-Barron <italic>et al</italic>., 2012</xref>).</p>
<p>Unlike excitatory plasticity, which relies on dopaminergic feedback signals, our inhibitory plasticity model follows a rule that passively follows the local Ca level from voltage-gated channels. It reinforces the voltage elevation of the most active excitatory synapses within a dendritic branch by decreasing the inhibition corresponding to the same features there (<xref ref-type="bibr" rid="c10">Chapman, Nuwer and Jacob, 2022</xref>), and conversely, it strengthens inhibitory synapses for features which generate less excitatory activity (see Methods for details).</p>
<p>To demonstrate how the inhibitory plasticity rule works, we use the same excitatory synapse setup as in <xref rid="fig4" ref-type="fig">Figure 4</xref> to which we add four inhibitory synapses near each cluster in the middle of the dendritic branch, representing each of the four features (<xref rid="fig5" ref-type="fig">Figure 5A</xref>). Thus, a single feature activates both the excitatory and inhibitory synapses. To achieve a level of depolarization and spike probability comparable to that in our excitatory-only setup, we increased the number of feature-unspecific input from 108 to 144. Alongside this, we began with low inhibitory synaptic weights. These two changes were needed in order to maintain higher baseline activity in the model as starting with strong inhibitory weights could excessively suppress excitatory activity, as e. g. inhibitory inputs close to clustered synapses can effectively counteract the NMDA-dependent nonlinearities (<xref ref-type="bibr" rid="c18">Doron <italic>et al</italic>., 2017</xref>; <xref ref-type="bibr" rid="c19">Du <italic>et al</italic>., 2017</xref>; <xref ref-type="bibr" rid="c17">Dorman, Jędrzejewska-Szmek and Blackwell, 2018</xref>). Here, as in the example in <xref rid="fig3" ref-type="fig">Figure 3</xref>, the conductances of the excitatory inputs representing ‘yellow’ and ‘banana’ increase in dendrite 1, strengthening the ‘yellow banana’ pairing, while the weights of synapses representing the feature ‘red’ decrease (<xref rid="fig5" ref-type="fig">Figure 5E</xref>). Conversely, the inhibitory synapses associated with the ‘yellow’ and ‘banana’ features in dendrite 1 are weakened, while those linked to the ‘red’ and ‘strawberry’ features in the same dendrite are strengthened (<xref rid="fig5" ref-type="fig">Figure 5D</xref>, right panel). This behaviour of the inhibitory plasticity rule effectively prevents the cell from spiking following activation of the irrelevant stimuli. In this particular example the ‘red banana’ combination is strongly inhibited and thereby effectively compartmentalizing dendrite 1 to be responsive to ‘yellow banana’ (since in this case no excitatory ‘strawberry’ input is present).</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5:</label>
<caption><title>Effects of inhibitory inputs on performance</title><p>(<bold>A</bold>) Dendritic input configuration with inhibitory synapses added. The setup of the excitatory and feature-unspecific synapses is the same as in <xref rid="fig3" ref-type="fig">Figure 3A</xref> (the feature-unspecific synapses are not shown). Inhibitory synaptic connections for each of the four features are added in both dendrites, with one synapse per feature.</p><p>(<bold>B</bold>) : Displays average performance for 31 unique input configurations of 2, 3, or 4 features on two dendrites as a comparison between the setup with (orange) and without inhibitory plasticity (blue). The bar plot inset shows the number of configurations that successfully solved the NFBP with and without inhibition.</p><p>(<bold>C</bold>) : Performance over the last 160 stimulus presentations as a function of somatic distance of the synaptic clusters for the input configuration in (A). A total of 60 unique configurations were tested, with synapse clusters randomly assigned to different dendritic locations. The solid line represents a quadratic fit to the data. The dashed line is the corresponding quadratic fit from <xref rid="fig4" ref-type="fig">Figure 4E</xref>.</p><p>(<bold>D</bold>) : Peak voltage-gated calcium (left panel, dots) and plasticity thresholds dynamics (lines) during learning (number of training examples). The upper threshold (C<sub>TH</sub>) moves towards peak calcium levels while the lower threshold (C<sub>TL</sub>) moves towards the next highest level. (Right) Inhibitory synaptic conductances for the synapses in dendrite 1. Strengthened inhibitory synapses prevent excitation by the corresponding features (here ‘red’ and ‘strawberry’), while weakened inhibitory synapses allow excitation by their corresponding features (here ‘yellow’ and ‘banana’).</p><p>(<bold>E</bold>) : Excitatory synaptic conductances (top) and calcium levels and kernel dynamics (below) over learning. The specific conductances in the top panel corresponding to the kernel dynamics and calcium levels in the bottom panels are indicated with arrows. Note that kernel and calcium dynamics for the example ‘yellow’ synapse refer to the only ‘yellow’ synapse in the top panel which initially weakens and is later strengthened. MP-K, LTP-K stands for metaplasticity- and LTP kernel, while the solid line shows the midpoint of the LTP kernels. Max refers to the peak NMDA calcium during a single stimulus.</p></caption>
<graphic xlink:href="584462v3_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We also show the dynamics of peak calcium levels associated with both excitatory and inhibitory synapses for each task (<xref rid="fig5" ref-type="fig">Figure 5D</xref>, left panel, and <xref rid="fig5" ref-type="fig">Figure 5E</xref>). For excitatory synapses, the patterns in peak NMDA calcium levels also behave as in the example in <xref rid="fig3" ref-type="fig">Figure 3C</xref> (compared to <xref rid="fig5" ref-type="fig">Figure 5E</xref>). For inhibitory synapses, the peak calcium levels arising from voltage-gated calcium channels further exemplify how inhibition suppresses calcium activity arising from irrelevant stimuli while allowing that evoked by relevant stimuli (<xref rid="fig5" ref-type="fig">Figure 5D</xref>, left panel). The maximum threshold level (C<sub>TH</sub>) of calcium for inhibitory synapses followed the highest excitatory synaptic activity, which in this case corresponded to the ‘yellow banana’ input.</p>
<p>We also compared the performance for different feature configurations with added inhibitory synapses to the results for the excitatory-only setup from <xref rid="fig4" ref-type="fig">Figure 4B</xref>. The results show not only that learning with inhibitory plasticity is faster, i.e. requires less training examples, but also achieves high performance, nearing 100%. In the configurations with all four features in one dendrite 7/13 learned the NFBP, compared to 5/13 without inhibition (shown in the bar plot inset in <xref rid="fig5" ref-type="fig">Figure 5B</xref>).</p>
<p>To understand why inhibition improved learning, we examined the dynamics of L-type calcium during early learning. The presence of inhibition resulted in slightly lower initial L-type calcium levels compared to the excitatory-only setup, leading to reduced LTD at the start. This reduction in LTD helped prevent excessive weakening of synapses, increasing the likelihood of selecting one combination over others (<xref rid="fig5s1" ref-type="fig">Figure 5—figure supplement 1B</xref>, showing excitatory synaptic weights without (left) and with inhibition (middle): In the setup without inhibition all four features weaken over time due to competition, while in contrast, the setup including inhibition demonstrates better-regulated learning and more stable feature selection).</p>
<p>Inhibitory plasticity additionally produced a marked improvement in performance when the location of the synaptic clusters was varied, especially prominent at very distal locations (<xref rid="fig5" ref-type="fig">Figure 5C</xref>). Without inhibition it was difficult for synapses on distal dendrites to differentiate between relevant and irrelevant stimuli. In the middle of the learning, setups without inhibition typically spiked too much compared to setups including inhibition (e. g. spike for ‘red banana’ in the left panels of <xref rid="fig5s1" ref-type="fig">Figure 5—figure supplement 1A</xref>). This in turn caused increased LTD and decreased weights in the feature-unspecific synapses, leading to too little spiking at the end of the learning (e. g. no spike for ‘yellow banana’ in the right panels of <xref rid="fig5s1" ref-type="fig">Figure 5—figure supplement 1A</xref>). With inhibition on the other hand, the contrast between relevant and irrelevant stimuli was larger. Larger contrast in turn gave less spiking for the wrong combination in the middle of learning and thereby less reduction of the weights of the feature-unspecific synapses. Therefore, large excitation in a single dendrite, combined with a larger drive of feature-unspecific synapses were enough to cause spiking in relevant stimuli at the end of learning, while spiking in irrelevant stimuli was suppressed (<xref rid="fig5s1" ref-type="fig">Figure 5—figure supplement 1A</xref>, red traces).</p>
<p>In summary, incorporating inhibitory plasticity suggests that inhibitory synapses may fine-tune dendritic responsiveness and enhance NFBP performance by preventing excitation from irrelevant stimuli, which in turn allows for more rapid, robust, and accurate learning.</p>
</sec>
<sec id="s2f">
<title>Dendritic Branch Plasticity and Synaptic Learning – Investigating the Role of Randomly Distributing Excitatory and Inhibitory Synapses on the Dendrites</title>
<p>We finally challenged our plasticity rule by relaxing the assumption that single features are represented by pre-clustered synapses on specific dendritic branches. The behaviour of the synaptic plasticity rule was therefore investigated using a setup where 200 excitatory synapses, representing the different features, were randomly distributed across 30 dendrites. In this setup, each feature was represented by 40 synapses and an additional 40 represented the feature-unspecific synapses. <xref rid="fig6" ref-type="fig">Figure 6A</xref> illustrates the setup and exemplifies the pre- and post-learning synaptic weights for both excitatory and inhibitory synapses. Our objective was to examine the learning dynamics in the absence of assumed synaptic clustering and to determine the capability of the single neuron to learn the NFBP. To address the reduced effectiveness of non-clustered synaptic inputs in eliciting sufficient depolarization and calcium influx—key for learning and synaptic plasticity—we slightly increased the initial weights compared to the clustered setup to 0.3 ± 0.1 (around 0.75 nS). A branch-specific mechanism for creating non-linearities was also introduced by assuming that glutamate spillover occurs in all co-activated synapses on the same dendritic branch. This hypothetical construct assumes that concurrent activation of a critical mass of co-activated synapses in a single dendritic branch would trigger both plateau potentials and a rise in calcium levels, endowing the dendrites with supralinear responses even without closely clustered synapses. Starting with an excitation-only setup, and running the model with these changes resulted in a moderate mean performance of about 65% (<xref rid="fig6" ref-type="fig">Figure 6B</xref>, ‘Without inhibitory’). However, on a linear task (e.g. learning only ‘yellow banana’ or ‘red strawberry’) with randomly placed synapses the performance was close to 100% (even when starting from an initial condition without spiking—a paradigm called subthreshold learning—see <xref rid="fig6s1" ref-type="fig">Figure 6—figure supplement 1B</xref> and <xref rid="fig6s1" ref-type="fig">1C</xref>).</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6:</label>
<caption><title>Performance analysis of learning using distributed synaptic inputs</title><p>(<bold>A</bold>) : Example illustration of synaptic distribution before (top) and after learning (bottom) of the 200 excitatory and 60 inhibitory inputs. S - strawberry, Y - yellow, B - banana, R - red, U - feature-unspecific inputs. Bordered markers (circles and diamonds) indicate synapses whose conductances are shown in (C).</p><p>(<bold>B</bold>) : Performance over training epochs with and without inhibitory plasticity. (Left) Mean performance of the setups with and without inhibitory synapses. (Right) Individual traces for the setup with inhibition. Each of these individual trials (31 in total) uses a unique random distribution of synapses.</p><p>(<bold>C</bold>) : Example of summed synaptic conductances (left) and voltage (right) in the soma, and four example dendrites (d1-d4) of the synaptic distribution in (A) in a trial where the NFBP is successfully solved. The sums of both excitatory (left) and inhibitory (right) inputs are shown.</p></caption>
<graphic xlink:href="584462v3_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We next extended our investigation by including 60 inhibitory synapses, 15 for each feature, dispersed randomly over the 30 dendrites. Performance improved with the introduction of these additional nonlinearities, especially in combination with the branch-specific spillover mechanisms. In the right panel of <xref rid="fig6" ref-type="fig">Figure 6B</xref>, we show that with inhibition the model reaches a performance of about 75% for all distributions of synapses, while a subset of distributions (5/31) achieve performance close to 100%. There are also a few distributions that partially solve the NFBP, reaching a performance between 75% and 100% (4/31).</p>
<p>To explore the model’s ability to handle increased feature complexity, we extended the task to include two configurations: a subset of 9 feature combinations, including one non-linear combination, and a more challenging subset of 25 feature combinations, including two non-linear combinations (see <xref rid="fig6s1" ref-type="fig">Figure 6—figure supplement 1A</xref>). In these extended simulations, the model achieved accuracies of 80% and 75% for the 9- and 25-feature tasks, respectively, as shown in see <xref rid="fig6s1" ref-type="fig">Figure 6—figure supplement 1A</xref>.</p>
<p>For a more granular analysis of the successful cases with randomly distributed synapses, we selected an example that successfully learned the NFBP. In <xref rid="fig6" ref-type="fig">Figure 6C</xref>, we present the somatic and dendritic voltage responses for four dendritic branches (d1–d4) where relevant stimuli were encoded. The voltage traces display somatic and dendritic responses to all four stimuli after learning. Additionally, the cumulative synaptic conductances for both excitatory and inhibitory inputs were calculated at the midpoint of each dendritic branch. Notably, dendrites 1 and 4 show enhanced excitatory inputs for the ‘yellow banana’ pattern and increased inhibitory inputs for the ‘red strawberry’ pattern, while dendrites 2 and 3 exhibit the reverse arrangement. The synapses in dendrites 1 to 4, whose weights are shown in panel C, are marked in <xref rid="fig6" ref-type="fig">Figure 6A</xref> with black borders around the markers.</p>
<p>These results show that for an adequate random innervation of distributed synapses, where the necessary features for a relevant stimulus innervate the same dendritic branch with enough synapses, that stimulus can be stored on that dendrite. In this way, the NFBP can also be learned if the two relevant stimuli are encoded on different dendrites and each of them can trigger a supralinear dendritic response. Since on average the two features representing a relevant stimulus do not innervate a single dendrite with enough synapses, the stimulus is not stored in a single dendrite, but is distributed across the dendritic tree. And since distributed synapses summate more linearly at the soma, only one of the relevant stimuli can be typically encoded by the neuron.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>In this article we studied whether single neurons can solve linearly non-separable computational tasks, represented by the NFBP, by using a biophysically detailed multicompartment dSPN model. Based on the synaptic machinery of corticostriatal synapses onto dSPNs, we propose a learning rule that uses local synaptic calcium concentration and dopamine feedback signals: rewards for relevant stimuli and omitted rewards for irrelevant stimuli. Assuming first that single features in the NFBP are represented by clustered synapses, we show that the learning rule can solve the NFBP by strengthening (or stabilizing) synaptic clusters for relevant stimuli and weakening clusters for the irrelevant stimuli. The feature combinations for the relevant stimuli, stored in strengthened synaptic clusters, trigger supralinear dendritic responses in the form of plateau potentials, which is an important ingredient for the solution of the NFBP, as plateaus significantly increase the likelihood of neuronal spiking in SPNs in a robust way (<xref ref-type="bibr" rid="c19">Du <italic>et al</italic>., 2017</xref>).</p>
<p>The location of the synaptic clusters along the dendrites influenced the performance on the NFBP. In our model the region for optimal performance was 100-150 <italic>μ</italic>m away from the soma, at about the same distance as where the somatic depolarization and induced spike probability, following activation of clustered synaptic input, was largest in the model by <xref ref-type="bibr" rid="c46">Lindroos and Hellgren Kotaleski (2021)</xref>. Clusters placed further away produce smaller somatic depolarizations, due to dendritic filtering (<xref ref-type="bibr" rid="c50">Major <italic>et al</italic>., 2008</xref>), and as a consequence do not control the likelihood of somatic spiking as decisively. As the supralinear dendritic response is necessary for discriminating the relevant from the irrelevant stimuli, the performance with distally placed clusters decreases somewhat.</p>
<p>We further verified that supralinear dendritic responses were necessary to solve the NFBP by using randomly distributed synapses instead of clustered synapses for each feature. In this scenario, only one relevant stimulus is sometimes learned in a dendritic branch by the randomly distributed synapses. In the random setup the glutamate spillover models were updated to include the synapses in the whole dendritic branch, building on the notion that the single branch acts as a single computational unit (<xref ref-type="bibr" rid="c48">Losonczy and Magee, 2006</xref>; <xref ref-type="bibr" rid="c7">Branco and Häusser, 2010</xref>). The realism of this assumption about spillover is of course open to debate. In actual dendritic branches, however, the diffusion of signaling molecules likely plays a crucial role in both synaptic plasticity at existing synapses and for locally induced structural plasticity (<xref ref-type="bibr" rid="c58">Nishiyama and Yasuda, 2015</xref>; <xref ref-type="bibr" rid="c11">Chater <italic>et al</italic>., 2024</xref>). These processes may both enhance branch-specific supralinearities in qualitatively similar ways as when using spillover, but the mechanisms are not explored in the current model.</p>
<p>By using a phenomenological inhibitory plasticity rule based on the BCM formalism (<xref ref-type="bibr" rid="c5">Bienenstock, Cooper and Munro, 1982</xref>), we also show that inhibitory synapses can significantly improve performance on the NFBP. This is in line with earlier theoretical studies where negative synaptic weights were required to solve the NFBP (<xref ref-type="bibr" rid="c70">Schiess, Urbanczik and Senn, 2016</xref>). In our setup with pre-existing synaptic clusters, inhibitory synapses made learning faster and increased performance by inhibiting supralinear NMDA responses for the irrelevant stimuli. This was specifically true in distal dendrites where the input impedance is higher (<xref ref-type="bibr" rid="c6">Branco, Clark and Häusser, 2010</xref>). The threshold for plateau potential initiation is also lower in distal dendrites compared to proximal (<xref ref-type="bibr" rid="c48">Losonczy and Magee, 2006</xref>) which likely will further extend the influence of inhibition in this region (<xref ref-type="bibr" rid="c18">Doron <italic>et al</italic>., 2017</xref>; <xref ref-type="bibr" rid="c19">Du <italic>et al</italic>., 2017</xref>). Similarly, in the scenario with distributed synapses, inhibition enables one of the relevant stimuli to be reliably encoded in the dendritic branch by strengthening the inhibitory synapses for features different from those of the encoded stimulus. Together, it therefore seems like inhibition not only has a role in learning (<xref ref-type="bibr" rid="c12">Chen <italic>et al</italic>., 2015</xref>; <xref ref-type="bibr" rid="c14">Cichon and Gan, 2015</xref>), but also improves the ability of the neuron to discriminate between stimuli with shared features.</p>
<p>In calcium-dependent plasticity models, a “no man’s land” has sometimes been proposed as a region where synaptic weights remain largely unchanged within a specific calcium range, reducing sensitivity to fluctuations and improving stability (<xref ref-type="bibr" rid="c47">Lisman, 2001</xref>; <xref ref-type="bibr" rid="c54">Moldwin, Azran and Segev, 2024</xref>). For our inhibitory rule, which builds on an BCM-like mechanism, introduction of such a mechanism in future work could make the system less sensitive to fluctuations in calcium concentration.</p>
<p>Although our learning rule infrequently solves the NFBP when used with only randomly distributed synapses, it can always learn to perform a linearly separable task, such as learning to respond to only one relevant stimulus (such as red strawberry). Moreover, the learning rule is general enough so that in addition to the feature-specific inputs related to the task, it can handle feature-unspecific inputs that might or might not be related to the NFBP. Finally, the learning rule is always “on”, continuously updating synapses with each stimulus presentation, which is a more realistic mechanism compared to using separate training and testing phases as in the field of machine learning. The synaptic weights automatically stabilize in the model when the performance improves, with metaplasticity playing a crucial role in this process. That is, rewards are then seen very regularly as the neuron has learned to spike for the relevant stimuli, while omitted rewards seldomly occur as the neuron stays silent when the irrelevant stimuli are provided.</p>
<p>When formulating the learning rule in this article, our goal was to base it on what is known regarding the synaptic machinery in corticostriatal synapses. This implied that the learning rule is based on the local calcium activity and on dopamine signals. Feedback from the dopamine system can also be viewed as an innate, evolutionarily encoded “supervisor”, which instructs neurons which feature combinations are beneficial and which ones should be avoided. However, in our case we do not use additional excitation to promote somatic spiking for only the relevant feature combinations, and in that sense the learning rule does not require a supervised learning paradigm. However, since the SPNs rest at very hyperpolarized membrane potential, our setup includes distributed excitatory inputs which are feature-unspecific in order to make sure that the neuron spikes for all stimuli, especially at the beginning of training. These additional inputs are on average weakened as learning progresses (as they are activated for all stimuli and thus often receive negative feedback). That general or noisy inputs are reduced during learning is in line with the observed reduction of execution-variability during motor-learning as a novice becomes an expert (<xref ref-type="bibr" rid="c38">Kawai <italic>et al</italic>., 2015</xref>). Specifically also, the underlying neuronal representation of corticostriatal synapses undergo a similar change during learning (<xref ref-type="bibr" rid="c69">Santos <italic>et al</italic>., 2015</xref>).</p>
<p>Since each synapse has its own calcium response, it is important for the learning rule to be able to follow individual synaptic activities. The LTP plasticity kernel in our model is for this reason itself plastic (metaplasticity), meaning that it changes its calcium dependence as a function of the history of reward and punishment. This setup helps the model separate clustered synaptic input from the feature-unspecific input at the beginning of training, as only clustered synapses will see enough calcium to fall within the LTP plastic range (LTP kernel).</p>
<p>We further use an asymmetric metaplasticity rule, where negative feedback causes a larger shift of the LTP kernel than a positive. This was necessary in order to prevent LTP in synapses that should ultimately undergo LTD. Hence, similarly to the classical loss-aversion tendency described in economic decision theory (<xref ref-type="bibr" rid="c37">Kahneman and Tversky, 1979</xref>), the model predicts that negative feedback will have a bigger impact in changing a well learned behavior on the single cell level than a positive feedback. Dopamine signaling has also been linked as a neural substrate to the decision making theory mentioned above (<xref ref-type="bibr" rid="c79">Stauffer <italic>et al</italic>., 2016</xref>).</p>
<p>It is not known whether single neurons solve the NFBP or other linearly non-separable tasks. However, many brain nuclei receive convergent inputs from numerous other brain nuclei, acting as integratory hubs (<xref ref-type="bibr" rid="c27">van den Heuvel and Sporns, 2013</xref>). Since feature binding evidently occurs in the brain, and functional clusters for single features such as visual stimulus orientation, receptive fields, color, or sound intensity exist on single neurons (<xref ref-type="bibr" rid="c13">Chen <italic>et al</italic>., 2011</xref>; <xref ref-type="bibr" rid="c88">Wilson <italic>et al</italic>., 2016</xref>; <xref ref-type="bibr" rid="c33">Iacaruso, Gasler and Hofer, 2017</xref>; <xref ref-type="bibr" rid="c72">Scholl, Wilson and Fitzpatrick, 2017</xref>; <xref ref-type="bibr" rid="c36">Ju <italic>et al</italic>., 2020</xref>), it is possible that the NFBP is a relevant task for neurons to solve. How brain regions with different synaptic machinery than the striatal dSPN might solve the NFBP remains a question, and reliance on other neuromodulatory signals may be part of the answer. For example, in the striatum, the indirect pathway SPNs (iSPN) have analogous synaptic machinery to the one in dSPNs, requiring calcium influx from the same sources for LTP and LTD, but are differently responsive to dopamine (<xref ref-type="bibr" rid="c75">Shen <italic>et al</italic>., 2008</xref>). In iSPNs a dopamine pause, together with a peak in adenosine, is required to trigger LTP, whereas a dopamine peak without peaks in adenosine rather promotes LTD (<xref ref-type="bibr" rid="c75">Shen <italic>et al</italic>., 2008</xref>; <xref ref-type="bibr" rid="c56">Nair <italic>et al</italic>., 2015</xref>). Therefore, we expect that an analogously formulated learning rule will also solve the NFBP in iSPNs, activating them for irrelevant feature combinations to e.g. suppress movement, and suppressing their activity for relevant feature combinations to facilitate movement. In addition, LTP in dSPNs is significantly facilitated by co-regulation of other neuromodulatory systems, such as when there is a coincident acetylcholine pause with the dopamine peak, which we have not explicitly included in the model (<xref ref-type="bibr" rid="c56">Nair <italic>et al</italic>., 2015</xref>; <xref ref-type="bibr" rid="c8">Bruce <italic>et al</italic>., 2019</xref>; <xref ref-type="bibr" rid="c66">Reynolds <italic>et al</italic>., 2022</xref>).</p>
</sec>
<sec id="s4">
<title>Methods</title>
<p>In this paper we introduce a local, calcium- and reward-based synaptic learning rule, constrained by experimental findings, to investigate learning in SPNs. The learning rule operates based on the changes in local calcium concentration resulting from synaptic activation patterns that evoke dendritic non-linearities, such as plateau potentials. Such events affecting the postsynaptic calcium concentration can enable learning of the nonlinear feature binding problem (NFBP). The learning rule is embedded in a biophysically detailed model of a dSPN built and simulated in the NEURON software, v8.2 (Carnevale et al., 2006). Here we will focus on the setup of the learning rule and only give a short summary of the neuron and synapse models, and emphasize changes compared to previously published versions. For a detailed description of the neuron model setup, see <xref ref-type="bibr" rid="c45">Lindroos et al., (2018)</xref> and <xref ref-type="bibr" rid="c46">Lindroos and Hellgren Kotaleski, (2021)</xref>. The modeling of plateau potentials is explained in <xref ref-type="bibr" rid="c83">Trpevski et al., (2023)</xref>. See also the section Code and Software Availability below.</p>
<sec id="s4a">
<title>Neuron model</title>
<p>In short, the dSPN model used here was taken from the library of biophysically detailed models in (<xref ref-type="bibr" rid="c46">Lindroos and Hellgren Kotaleski, 2021</xref>), including a reconstructed morphology and all of the most influential ion channels, including six calcium channels, each with its own voltage dependence and dendritic distribution. In accordance with <xref ref-type="bibr" rid="c83">Trpevski et al., (2023)</xref>, the model was further extended with synaptic spines on selected dendrites. Each spine was modeled as two additional compartments consisting of a neck and a head region, and contains voltage-gated calcium channels of types R (Ca<sub>v</sub>2.3), T (Ca<sub>v</sub>3.2 and Ca<sub>v</sub>3.3), and L (Ca<sub>v</sub>1.2 and Ca<sub>v</sub>1.3); the addition of explicit spines did not change the basic behavior of the model, such as the response to current injections, etc.</p>
</sec>
<sec id="s4b">
<title>Calcium sources used in learning</title>
<p>The intracellular calcium concentration is separated into distinct pools that are used during the learning process. For learning in glutamatergic synapses, one pool for NMDA-evoked calcium concentration ([Ca]<sub>NMDA</sub>) is used, and another for L-type calcium concentration ([Ca]<sub>L-type</sub>), to reflect the different synaptic plasticity responses of the dSPN’s biochemical machinery to these two calcium sources in the corticostriatal synapse (<xref ref-type="bibr" rid="c75">Shen <italic>et al</italic>., 2008</xref>; <xref ref-type="bibr" rid="c20">Fino <italic>et al</italic>., 2010</xref>; <xref ref-type="bibr" rid="c60">Plotkin <italic>et al</italic>., 2013</xref>). Both pools are based on the calcium influx from the corresponding source (NMDA and the L-type channels Ca<sub>v</sub>1.2 and Ca<sub>v</sub>1.3, respectively). Inspired by findings that calcium from various voltage-dependent calcium channels affects GABAergic plasticity in different systems (<xref ref-type="bibr" rid="c41">Kurotani <italic>et al</italic>., 2008</xref>; <xref ref-type="bibr" rid="c31">Hulme and Connelly, 2014</xref>; <xref ref-type="bibr" rid="c84">Udakis <italic>et al</italic>., 2020</xref>), we also incorporate a third calcium pool based on calcium influx from all voltage gated channels (T-, R-, L- and N-type, [Ca]<sub>V</sub>). All pools include extrusion mechanisms in the form of a calcium pump as well as a one-dimensional time-decay. The calcium pump follows the implementation in <xref ref-type="bibr" rid="c90">Wolf et al., (2005)</xref>. The parameters for the [Ca]<sub>NMDA</sub> model were manually tuned to match the [Ca] amplitudes and durations reported in <xref ref-type="bibr" rid="c17">Dorman et al., (2018)</xref>. The voltage gated calcium channel conductances in the spines were also manually tuned to match the relative calcium proportions in <xref ref-type="bibr" rid="c9">Carter and Sabatini, (2004)</xref> and <xref ref-type="bibr" rid="c28">Higley and Sabatini, (2010)</xref>, as well as the calcium amplitudes due to stimulation with backpropagating action potentials (<xref ref-type="bibr" rid="c77">Shindou, Ochi-Shindou and Wickens, 2011</xref>). Spatial calcium diffusion was not included in the present model.</p>
</sec>
<sec id="s4c">
<title>Glutamatergic synaptic input</title>
<p>Clustered synapses were modeled following <xref ref-type="bibr" rid="c83">Trpevski et al., (2023)</xref> using a version of the saturating synapse model in <xref ref-type="bibr" rid="c16">Destexhe <italic>et al.</italic>, (1994)</xref>. The synaptic model included AMPA and NMDA conductances activated on spines as well as extrasynaptic NMDA conductances located on the dendritic shafts adjacent to the spine. The strength of the individual synapses on spines were scaled using a weight parameter (w) taking on positive values. More explicitly, in our model, the parameter w represents the percentage of the maximum synaptic conductance g<sub>max</sub>. For instance, when w=0.5, the synaptic conductance (g) is 0.5*g<sub>max</sub>. Importantly, changes in w affect both NMDA and AMPA receptor conductances simultaneously, as both share the same scaling factor. Extrasynaptic conductances were activated following sufficiently large stimulation of nearby spines, resulting in glutamate spillover. Extrasynaptic NMDA synapses were included because they provide robust all-or-none dendritic plateaus (<xref ref-type="bibr" rid="c83">Trpevski <italic>et al</italic>., 2023</xref>). The maximal conductance of both synaptic and extrasynaptic NMDARs was set to 2.5 nS, which is lower than the 3.5 nS used in <xref ref-type="bibr" rid="c83">Trpevski et al., (2023)</xref>. This reduction in conductance was implemented to compensate for the increased number of inputs in the model. In this model, spillover was triggered when the sum of the weights of active synapses in a cluster exceeded a threshold value of 2. For instance, eight synapses with individual weights greater than 0.25 would activate spillover. This threshold was lower than the value of 4 used in <xref ref-type="bibr" rid="c83">Trpevski et al., (2023)</xref> in order to facilitate spillover and enhance non-linearity in the context of distributed synapses. However, this scaling only affects the size of the clustered inputs presumed to give rise to plateau potentials, which likely varies across different neuronal subtypes or even between distinct dendritic branches within the same subtype. In the NEURON simulation environment, an integrate-and-fire cell was used to generate a spike in extrasynaptic NMDARs when the spillover threshold is reached. As synaptic weight increases, fewer synapses are required to meet the threshold. This also links long-term potentiation (LTP) to enhanced glutamate spillover. In addition to task-related inputs, the neuron also receives background noise, modeled as excitatory and inhibitory synapses distributed across the dendrites. Since the number of electrical compartments in the model is significantly lower than the number of synapses in a real SPN, these converging synapses were represented by a single non-saturating synapse with input frequency scaled accordingly. This was implemented using a dual exponential synapse model based on the NEURON exp2syn mechanism following <xref ref-type="bibr" rid="c46">Lindroos and Hellgren Kotaleski (2021)</xref> with time constants and other parameters adapted from <xref ref-type="bibr" rid="c29">Hjorth et al., (2020)</xref>.</p>
</sec>
<sec id="s4d">
<title>Learning rule</title>
<sec id="s4d1">
<title>Excitatory synaptic plasticity</title>
<p>The learning rule is grounded in experimental evidence indicating that striatal LTP relies on NMDA receptor activation and the presence of dopamine, whereas LTD depends on the activation of L-type calcium channels (Cav1.3) and mGluR5 receptors in the absence of dopamine (<xref ref-type="bibr" rid="c75">Shen <italic>et al</italic>., 2008</xref>; <xref ref-type="bibr" rid="c20">Fino <italic>et al</italic>., 2010</xref>; <xref ref-type="bibr" rid="c60">Plotkin <italic>et al</italic>., 2013</xref>; <xref ref-type="bibr" rid="c92">Yagishita <italic>et al</italic>., 2014</xref>; <xref ref-type="bibr" rid="c21">Fisher <italic>et al</italic>., 2017</xref>; <xref ref-type="bibr" rid="c76">Shindou <italic>et al</italic>., 2019</xref>). Under basal dopamine levels, no significant synaptic plasticity is assumed to occur. This rule outlines a reward-based learning mechanism where a dopamine peak enhances synaptic weight via an LTP plasticity kernel, while a dopamine pause reduces synaptic weight through an LTD kernel. Thus, dopamine functions as a switch, determining whether LTP or LTD pathways are activated (as illustrated in <xref rid="fig1" ref-type="fig">Figure 1D</xref>). Notably, synaptic weights affect both AMPA and NMDA receptors, consistent with findings that the NMDA-to-AMPA ratio remains unchanged following LTP (<xref ref-type="bibr" rid="c86">Watt <italic>et al</italic>., 2004</xref>). Additionally, the previously described spillover mechanism is linked to synaptic weights, representing an attempt to associate plasticity with increased glutamate spillover resulting from the retraction of astrocytic processes from the spine (<xref ref-type="bibr" rid="c26">Henneberger <italic>et al</italic>., 2020</xref>). The excitatory synaptic plasticity rule encompasses key components such as LTP, LTD, and metaplasticity, each of which will be elaborated upon in the subsequent sections.</p>
</sec>
<sec id="s4d2">
<title>LTP</title>
<p>The LTP process is initiated by elevated dopamine levels, following calcium influx through NMDA receptors. Synaptic strength is adjusted using the LTP kernel, a bell-shaped function where the maximum increase occurs when peak NMDA calcium levels are at the kernel’s midpoint; deviations above or below this midpoint result in smaller increases (<xref rid="fig7" ref-type="fig">Figure 7A</xref>). The left side of the LTP kernel represents the lower calcium threshold necessary for LTP induction, while the right side indicates an upper calcium threshold beyond which LTP does not occur. This framework, in conjunction with metaplasticity, establishes an upper boundary for synaptic strength, ensuring that synaptic weights do not exceed a certain limit (<xref ref-type="bibr" rid="c93">Zenke and Gerstner, 2017</xref>; <xref ref-type="bibr" rid="c94">Zenke, Gerstner and Ganguli, 2017</xref>). Since each synapse experiences unique calcium levels (due to different synaptic conductance, local input resistance, etc), adjusting the calcium dependence of the LTP kernel allows for individualized tuning of synaptic weights (see <xref rid="fig7" ref-type="fig">Figure 7A</xref> and <xref rid="fig7" ref-type="fig">7C</xref> for illustrations).</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7:</label>
<caption><title>Synaptic Plasticity Rules: Calcium and Dopamine Interactions in Synaptic Weight Modification</title><p>(<bold>A</bold>) : Synaptic weight updates following a dopamine peak. (Left) LTP kernel is a bell-shaped curve describing the amount of weight increase, which happens over a region of [Ca]<sub>NMDA</sub>. (Right) A wider bell-shaped kernel, i.e. the metaplasticity kernel, determines how the LTP kernel is shifted along the calcium level ([Ca]<sub>NMDA</sub>) axis following a peak in dopamine.</p><p>(<bold>B</bold>) : Synaptic weight updates following a dopamine pause. (Left) The LTD plasticity kernel. The LTD threshold is constant and set at 70 nM (Right). Metaplasticity describing how the LTP kernel shifts along the calcium axis following a dopamine pause.</p><p>(<bold>C</bold>) : A schematic of how the LTP kernel is shifted following a dopamine peak, and examples of NMDA calcium levels before and after the shift. The NMDA calcium levels increase following activation of the strengthened synapse due to the previous dopamine peak (illustrated with the red circle jumping to the blue circle). The LTP kernel also moves downwards, and in this example the strengthened synapse (blue circle) would stabilize, and thus would not increase in strength even though additional rewards arrive.</p><p>(<bold>D</bold>) : A schematic showing how the LTP kernel is shifted following a dopamine pause, and examples of NMDA calcium levels before and after the shift. The calcium level shortly before the dopamine pause is shown with the red circle. The dopamine pause causes a decrease in synaptic weight and a smaller calcium response results in the next synapse activation (illustrated with the red circle jumping to the blue one). Also, the LTP kernel moves up towards higher NMDA calcium levels, and thus the weakened synapse (blue circle) is more likely to stay out of the plastic region of the LTP kernel (unless it in the future is activated with dopamine peaks more regularly than with dopamine pauses).</p><p>(<bold>E</bold>) : Illustration of the inhibitory plasticity rule. (Left) Changes in synaptic weight for active (beige) and inactive (blue) synapses based on voltage dependent calcium levels in the dendritic shaft at the location of the inhibitory synapse. The dashed lines show the minimum/lower (C<sub>TL</sub>) and maximum/higher (C<sub>TH</sub>) threshold. (Right) Functions for updating the lower and higher thresholds with voltage dependent calcium level. The asterisk denotes the Ca level where the curves for active and inactive synapses meet, which is a point of zero update.</p></caption>
<graphic xlink:href="584462v3_fig7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>The update of the synaptic weights follow a rule formulated using the derivative of the sigmoid function. The sigmoid function (<xref rid="eqn1" ref-type="disp-formula">Eq. 1</xref>) transforms the calcium concentration into a normalized range between 0 and 1:
<disp-formula id="eqn1">
<graphic xlink:href="584462v3_eqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where θ represents the midpoint of the transition, representing the calcium concentration at which the function increases most rapidly, and β determines the steepness of this transition.</p>
<p>The derivative of the sigmoid function, given by:
<disp-formula id="eqn2">
<graphic xlink:href="584462v3_eqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
produces a bell-shaped curve, which forms the LTP kernel. This kernel peaks at the midpoint θ, where synaptic modification is maximized, and decays symmetrically on each side. The parameter β here controls the width of the kernel, thereby regulating the sensitivity of synaptic weight changes to calcium fluctuations.</p>
<p>Based on this general description of the mathematical formulas underlying the LTP kernel, the LTP learning rule for the synaptic weights is formulated as:
<disp-formula id="eqn3">
<graphic xlink:href="584462v3_eqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where dw<sub>ltp</sub> represents the change in synaptic weight, η<sub>ltp</sub> is the learning rate, and [Ca]<sub>NMDA</sub> denotes the calcium concentration mediated by NMDA receptors. The parameters θ<sub>ltp</sub> and β<sub>ltp</sub> define the midpoint and slope of the sigmoid curve specific to LTP. The parameter values used in these equations are provided in <xref rid="tbl1" ref-type="table">Table 1</xref>.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><title>Excitatory Plasticity Parameters</title></caption>
<graphic xlink:href="584462v3_tbl1.tif" mime-subtype="tiff" mimetype="image"/>
<graphic xlink:href="584462v3_tbl1a.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
</sec>
<sec id="s4d3">
<title>LTD</title>
<p>The LTD process is triggered by a dopamine pause and is dependent on L-type calcium. The LTD plasticity kernel (<xref rid="eqn4" ref-type="disp-formula">Eq. 4</xref>), describes a threshold level of the calcium level necessary for LTD to occur (<xref ref-type="bibr" rid="c77">Shindou, Ochi-Shindou and Wickens, 2011</xref>), after which the decrease in synaptic weight is linearly proportional to the amplitude of the peak calcium level, and is scaled by the learning rate (η<sub>ltd</sub>, see left panel of <xref rid="fig7" ref-type="fig">Figure 7B</xref> for an illustration). The peak calcium threshold is implemented with a sigmoid function, whose slope parameter, β<sub>ltd</sub>, was set to a high-value to make the curve resemble a step function. The threshold is set at 70 nM and is fixed. The NMDA calcium dependence of the LTP kernel midpoint, θ<sub>ltp</sub>, is also increased during LTD, as described in the next section (<xref rid="fig7" ref-type="fig">Figure 7B</xref> right panel and <xref rid="fig7" ref-type="fig">Figure 7D</xref>).
<disp-formula id="eqn4">
<graphic xlink:href="584462v3_eqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
</sec>
<sec id="s4d4">
<title>Metaplasticity</title>
<p>Metaplasticity is a form of regulatory mechanism changing the state of the synapses in such a way as to influence subsequent learning (<xref ref-type="bibr" rid="c1">Abraham, 2008</xref>). In our model we implemented this as a reward-dependent change of the calcium concentration over which the LTP kernel was operating. Specifically, activation of the LTD pathway triggered a shift of the LTP kernel towards higher calcium concentrations while activation of the LTP pathway pushed it in the opposite direction. Metaplasticity was also implemented using a bell-shaped kernel with the same midpoint as the LTP kernel, but with a wider calcium dependence (<xref rid="fig7" ref-type="fig">Figures 7A-D</xref>). The position of the metaplasticity kernel is updated at the same time with the LTP kernel, so that both kernels remain centered at the same calcium level (<xref rid="fig7" ref-type="fig">Figure. 7C</xref> and <xref rid="fig7" ref-type="fig">7D</xref>). This setup with the two dynamically moving kernels together allowed for a wide range of calcium levels to induce plasticity. In addition, using a wider metaplasticity kernel that:
<list list-type="order">
<list-item><p>Following activation of the LTP pathway (i.e. after a dopamine peak, see <xref rid="fig7" ref-type="fig">Figure 7C</xref> for an illustration),
<list list-type="alpha-lower">
<list-item><p>In synapses with low calcium levels, the kernel will be shifted closer to the observed calcium level and thereby eventually enable LTP in synapses that are regularly activated during rewards, despite that they initially don’t generate big elevations in calcium.</p></list-item>
<list-item><p>In synapses with already high calcium levels (above the kernel midpoint), the kernel will be shifted away from the observed calcium level, and thereby protect the synapse from excessive LTP and instead stabilize the weight (as illustrated with the red circle moving to the blue one in <xref rid="fig7" ref-type="fig">Figure 7C</xref>).</p></list-item>
</list>
</p></list-item>
<list-item><p>Following activation of the LTD pathway (i.e. after a dopamine pause), the kernel will be shifted towards higher calcium levels and thereby reduce the likelihood of LTP in these synapses that are weakened following LTD (see <xref rid="fig7" ref-type="fig">Figure 7D</xref> for an illustration).</p></list-item>
</list>
The update of the LTP kernel was further asymmetric following activation of the LTD or LTP pathways in such a way that the LTD pathway caused a larger shift of the metaplasticity kernel than the LTP pathway. This further reduced the likelihood of inducing LTP in synapses often participating in LTD or in synapses randomly activated with regard to the dopamine feedback signal. It also allows initially weaker synapses to be recruited for LTP if they are more consistently co-active with a reward than with an omitted reward (an illustration of this can be seen in <xref rid="fig5" ref-type="fig">Figure 5E</xref>, where one of the yellow synapses is strengthened in the middle of the training session). The LTP kernel was updated according to <xref rid="eqn5" ref-type="disp-formula">Eq. 5</xref>, based on the learning rate (η<sub>s</sub>), the peak NMDA calcium level ([Ca]<sub>NMDA</sub>), and the slope of the sigmoid curve (β<sub>mp</sub>). The value of the slope β<sub>mp</sub> creates a wider bell-shaped function in <xref rid="eqn5" ref-type="disp-formula">Eq. 5</xref>. The rate η<sub>s</sub>, captures the described asymmetry in how the metaplasticity kernel is shifted in response to dopamine feedback where the specific rates following dopamine peaks and pauses are denoted n<sub>s,ltp</sub> and n<sub>s,ltp</sub>, respectively. Here n<sub>s,ltd</sub> is four times larger than n<sub>s,ltp</sub> (see <xref rid="tbl1" ref-type="table">Table 1</xref>).
<disp-formula id="eqn5">
<graphic xlink:href="584462v3_eqn5.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
For better clarity, we also provide the pseudo code for the learning rule below: Inputs:
<list list-type="simple">
<list-item><p>- [Ca]<sub>NMDA</sub>: Calcium level associated with the NMDA channel</p></list-item>
<list-item><p>- [Ca]<sub>Ltype</sub>: Calcium level associated with the L-type channel</p></list-item>
<list-item><p>- dopamine_level: Dopamine level (1 for peak, −1 for pause, 0 for basal)</p></list-item>
</list>
Output:
<list list-type="simple">
<list-item><p>- Δw: Change in synaptic weight</p></list-item>
<list-item><p>begin
<list list-type="simple">
<list-item><p>if dopamine_level == 1 then
<list list-type="simple">
<list-item><p># Calculate the change in synaptic weight for the LTP process</p></list-item>
<list-item><p>Δw = solve <xref rid="eqn3" ref-type="disp-formula">Eq. 3</xref> with [Ca]<sub>NMDA</sub>, η<sub>ltp</sub>, θ<sub>ltp</sub>, and β<sub>ltp</sub></p></list-item>
<list-item><p># Update the LTP kernel midpoint for metaplasticity update θ<sub>ltp</sub></p></list-item>
<list-item><p>using <xref rid="eqn5" ref-type="disp-formula">Eq. 5</xref> with [Ca]<sub>NMDA</sub>, η<sub>s,ltp</sub>, and β<sub>mp</sub></p></list-item>
</list>
</p></list-item>
<list-item><p>else if dopamine_level == −1 then
<list list-type="simple">
<list-item><p># Calculate the change in synaptic weight for the LTD process</p></list-item>
<list-item><p>Δw = solve <xref rid="eqn4" ref-type="disp-formula">Eq. 4</xref> with [Ca]<sub>Ltype</sub>, η<sub>ltd</sub>, θ<sub>ltd</sub>, and β<sub>ltd</sub></p></list-item>
<list-item><p># Update the LTP kernel midpoint for metaplasticity</p></list-item>
<list-item><p>update θ<sub>ltp</sub> using <xref rid="eqn5" ref-type="disp-formula">Eq. 5</xref> with [Ca]<sub>NMDA</sub>, η<sub>s,ltd</sub> and β<sub>mp</sub></p></list-item>
</list>
</p></list-item>
<list-item><p>else if dopamine_level == 0 then
<list list-type="simple">
<list-item><p># No significant synaptic plasticity under basal dopamine levels</p></list-item>
<list-item><p>Δw = 0</p></list-item>
</list>
</p></list-item>
<list-item><p>end if</p></list-item>
<list-item><p>return Δw</p></list-item>
</list>
</p></list-item>
<list-item><p>end</p></list-item>
</list>
</p>
</sec>
<sec id="s4d5">
<title>Inhibitory synaptic plasticity</title>
<p>In contrast to the well studied mechanistic underpinnings of glutamatergic plasticity in e.g. SPNs, much less is known about how inhibitory synapses might be updated during learning. The inhibitory plasticity rule developed here is therefore more phenomenological and exploratory in nature and was developed to enhance nonlinearities in the local dendrite. The rule is based on the Bienenstock-Cooper-Munro (BCM) formalism (<xref ref-type="bibr" rid="c5">Bienenstock, Cooper and Munro, 1982</xref>). In the BCM rule there is a threshold level of synaptic activity below which LTD is triggered and above which LTP is triggered (<xref rid="fig7" ref-type="fig">Figure 7E</xref>). Inspired by (<xref ref-type="bibr" rid="c23">Gandolfi <italic>et al</italic>., 2020</xref>; <xref ref-type="bibr" rid="c10">Chapman, Nuwer and Jacob, 2022</xref>; <xref ref-type="bibr" rid="c64">Ravasenga <italic>et al</italic>., 2022</xref>), we use calcium from all voltage-gated calcium channels ([Ca]<sub>V</sub>) as the indicator of excitatory synaptic activity near the dendritic shaft where an inhibitory synapse is located. The inhibitory rule is designed to passively observe and respond to the surrounding excitatory synaptic activity, governed by local voltage-gated calcium influx, but without reliance on dopamine or explicit feedback. It operates at a slower pace to ensure that it follows the average excitatory activity levels, and is meant to enhance the contrast in activity by amplifying local differences in excitatory synaptic efficacy.</p>
<p><xref rid="eqn6" ref-type="disp-formula">Equation 6</xref> describes how the inhibitory synaptic weights change based on the calcium concentration (calculated from calcium influx from all voltage-gated ion channels close to the synapse).
<disp-formula id="eqn6">
<graphic xlink:href="584462v3_eqn6.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
It consists of two sigmoidal terms, where the parameters <italic>a</italic> and <italic>b</italic> determine the contribution of each component, <italic>β</italic><sub>inh</sub> determines the steepness of the transitions and C<sub>TL</sub> and C<sub>TH</sub> determines the calcium concentration at which each sigmoid is half activated (see <xref rid="fig7" ref-type="fig">Figure 7E</xref>). Based on this, and modulated by a rate constant, <italic>η</italic><sub><italic>act</italic></sub>, <xref rid="eqn7" ref-type="disp-formula">Equation 7</xref> describes the specific rule used to update the weights of the inhibitory synapses.
<disp-formula id="eqn7">
<graphic xlink:href="584462v3_eqn7.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The weight change also depends on the magnitude of the weights themselves, in such a way that intermediate weights update faster than small or large weights. This helps stabilize the weights of the inhibitory synapses at the end of learning, and prevents the weight from taking on large or negative values. Large weights are then close to <inline-formula><inline-graphic xlink:href="584462v3_inline1.gif" mime-subtype="gif" mimetype="image"/></inline-formula> at the end of learning and small weights close to 0 (see <xref rid="fig5" ref-type="fig">Figure 5D</xref> for an example and <xref rid="tbl2" ref-type="table">table 2</xref> for parameter values).</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2:</label>
<caption><title>Inhibitory Plasticity Parameters</title></caption>
<graphic xlink:href="584462v3_tbl2.tif" mime-subtype="tiff" mimetype="image"/>
<graphic xlink:href="584462v3_tbl2a.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<p>The learning rule further differentiates between active and inactive synapses. For active synapses: i) if the calcium concentration exceeds C<sub>TH</sub>, the weight is depressed, ii) if calcium falls between C<sub>TL</sub> and C<sub>TH</sub>, the weight is potentiated and iii) when calcium is below C<sub>TL</sub>, little or no weight change occurs. For inactive synapses, the rule is reversed: i) when calcium exceeds C<sub>TH</sub>, the weight is potentiated, ii) if calcium falls between C<sub>TL</sub> and C<sub>TH</sub>, the weight is depressed and iii) no changes occur when calcium is below C<sub>TL</sub> (as in the case of active synapses). The schematic in <xref rid="fig7" ref-type="fig">Figure 7E</xref> (left panel) illustrates these weight updates, showing how the learning rule differentially affects active and inactive synapses. The black curves represent the relationship between calcium concentration and synaptic weight change, with the beige and blue shaded regions indicating potentiation and depression zones for each case.</p>
<p>The half activation thresholds, C<sub>TL</sub>, and C<sub>TH</sub>, are further dynamically updated to track the calcium levels of the synapse. These updates of the thresholds ensure that the plasticity rule remains sensitive to changes in calcium concentration and stabilize synaptic learning. <xref rid="eqn8" ref-type="disp-formula">Equations 8</xref> and <xref rid="eqn9" ref-type="disp-formula">9</xref> describe these adaptive dynamics. This is, in fact, metaplasticity of the inhibitory synapses.
<disp-formula id="eqn8">
<graphic xlink:href="584462v3_eqn8.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<disp-formula id="eqn9">
<graphic xlink:href="584462v3_eqn9.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<p>The upper threshold C<sub>TH</sub> shifts towards the highest observed calcium level in the synapse, while the lower threshold C<sub>TL</sub> moves to a level below the maximum. The rate of these adjustments is determined by the parameters <italic>η</italic><sub>TH</sub> and <italic>η</italic><sub>TL</sub>, which scale the influence of calcium activity on the threshold dynamics. The parameters a<sub>TH</sub>, b<sub>TH</sub> determine the rate of change of C<sub>TH</sub>, while a<sub>TL</sub>, b<sub>TL</sub> define the rate of change of C<sub>TL</sub> (see <xref rid="tbl2" ref-type="table">Table 2</xref> for parameter values). The parameter <italic>c</italic> in <xref rid="eqn9" ref-type="disp-formula">Equation 9</xref> is used to make the two curves for the high and low thresholds (C<sub>TL</sub>, C<sub>TH</sub>) to intersect at zero which minimizes the fluctuations around the transition point (green asterisk in <xref rid="fig7" ref-type="fig">Figure 7E</xref>, right panel).</p>
<p>Pseudocode for the algorithm describing inhibitory plasticity is given below.</p>
<p>Inputs:
<list list-type="simple">
<list-item><p>- [Ca]<sub>V</sub>: Ca concentration from voltage-gated calcium channels</p></list-item>
</list>
Output:
<list list-type="simple">
<list-item><p>- dw<sub>inh</sub>: Change in synaptic weight</p></list-item>
<list-item><p>begin
<list list-type="simple">
<list-item><p>if synapse_active then
<list list-type="simple">
<list-item><p># Active synapse: Compute weight change using negative learning rate</p></list-item>
<list-item><p>dw = solve Eq.7 with [Ca], <italic>η</italic><sub>act</sub>, C<sub>TH</sub>, C<sub>TL</sub>, <italic>η</italic><sub>TH</sub>, a<sub>inh</sub>, b<sub>inh</sub>, <inline-formula><inline-graphic xlink:href="584462v3_inline2.gif" mime-subtype="gif" mimetype="image"/></inline-formula></p></list-item>
<list-item><p># Update the upper threshold (C<sub>TH</sub>) based on <xref rid="eqn8" ref-type="disp-formula">Eq. 8</xref></p></list-item>
<list-item><p>update C<sub>TH</sub> using <xref rid="eqn8" ref-type="disp-formula">Eq. 8</xref> with C<sub>TH,</sub> C<sub>TL</sub>, <italic>η</italic><sub>TH</sub>, a<sub>TH</sub>,b<sub>TH</sub></p></list-item>
<list-item><p># Update the lower threshold (C<sub>TL</sub>) based on <xref rid="eqn9" ref-type="disp-formula">Eq. 9</xref></p></list-item>
<list-item><p>update C<sub>TL</sub> using <xref rid="eqn9" ref-type="disp-formula">Eq. 9</xref> with C<sub>TH,</sub> C<sub>TL</sub>, <italic>η</italic><sub>TL</sub>, a<sub>TL</sub>,b<sub>TL</sub>, c</p></list-item>
</list>
</p></list-item>
<list-item><p>else
<list list-type="simple">
<list-item><p># Inactive synapse: Compute weight change using positive learning rate</p></list-item>
<list-item><p>dw = solve Eq.7 with [Ca]<sub>V</sub>, <italic>η</italic><sub>act</sub>, C<sub>TH</sub>, C<sub>TL</sub>, <italic>η</italic><sub>TH</sub>, a<sub>inh</sub>, b<sub>inh</sub>, <inline-formula><inline-graphic xlink:href="584462v3_inline3.gif" mime-subtype="gif" mimetype="image"/></inline-formula></p></list-item>
<list-item><p># Update the upper threshold (C<sub>TH</sub>) based on <xref rid="eqn8" ref-type="disp-formula">Eq. 8</xref></p></list-item>
<list-item><p>update C<sub>TH</sub> using <xref rid="eqn8" ref-type="disp-formula">Eq. 8</xref> with C<sub>TH,</sub> C<sub>TL</sub>, <italic>η</italic><sub>TH</sub>, a<sub>TH</sub>,b<sub>TH</sub></p></list-item>
<list-item><p># Update the lower threshold (C<sub>TL</sub>) based on <xref rid="eqn9" ref-type="disp-formula">Eq. 9</xref></p></list-item>
<list-item><p>update C<sub>TL</sub> using <xref rid="eqn9" ref-type="disp-formula">Eq. 9</xref> with C<sub>TH,</sub> C<sub>TL</sub>, <italic>η</italic><sub>TL</sub>, a<sub>TL</sub>,b<sub>TL</sub>, c</p></list-item>
</list>
</p></list-item>
<list-item><p>end if</p></list-item>
<list-item><p>return dw<sub>inh</sub></p></list-item>
</list>
</p></list-item>
<list-item><p>end</p></list-item>
</list>
</p>
</sec>
</sec>
<sec id="s4e">
<title>Training Procedure</title>
<p>The features of a stimulus were represented by the shape and color of bananas and strawberries. We presented the neuron with a sequence of stimuli, typically around 960, each belonging to one of four possible feature combinations, as illustrated in <xref rid="fig1" ref-type="fig">Figure 1</xref>. The four stimuli: ‘red strawberry’, ‘yellow banana’, ‘red banana’ and ‘yellow strawberry’, were presented in random order three times each within a block of 12 stimuli, followed by another reshuffled block of 12, and so on. Each stimulus presentation lasted 20 ms, during which time all the stimuli-related synapses receive one randomly-timed spike per synapse. Whenever relevant, inhibitory synapses were activated concurrently with the excitatory synapses and the stimuli lasted for 100 ms. The stimuli presentation was followed by a reward cue lasting 50 ms that arrived 300 ms after the stimulus onset. The reward cue was represented with +1 for relevant stimuli if the neuron spiked (representing a peak in dopamine), with −1 for irrelevant stimuli if the neuron spiked (representing a dopamine pause) and 0 for baseline levels or when the neuron was silent. However, in an additional subthreshold learning task, the reward cue was delivered even in the absence of somatic spiking for active glutamate synapses, such that if they were active following the relevant stimuli (‘red strawberry’ and ‘yellow banana’) they got a dopamine peak, and a dopamine pause for irrelevant stimuli (<xref rid="fig6s1" ref-type="fig">Figure 6—figure supplement 1B</xref> and <xref rid="fig6s1" ref-type="fig">1C</xref>). The time between two stimuli was 800 ms, long enough to allow for the voltage, calcium (and all other state variables in the model) to return to their baseline values (<xref rid="fig3" ref-type="fig">Figure 3A</xref>). During the stimulus presentation, the stimuli-related synapses receive one randomly-timed spike per synapse. Further, the learning rule was on during the whole procedure, such that synapses were continuously updated throughout the simulation. Hence, there were no separate training and testing phases in which synapses were plastic and frozen, respectively.</p>
<p>Two distinct synaptic arrangements were used for representing the features: the clustered and the distributed setups.</p>
<sec id="s4e1">
<title>Clustered setup</title>
<p>This setup was based on the assumption of pre-existing clustered synapses for each feature. Features were allocated to two dendritic branches. Each branch had each feature represented with five synapses clustered closely on a single dendrite. Depending on the feature combination, two, three, or four features were represented in clusters on one or both dendritic branches (see <xref rid="fig3" ref-type="fig">Figs. 3A</xref>, <xref rid="fig4" ref-type="fig">4A</xref> and <xref rid="fig4" ref-type="fig">4D</xref> for examples). Additionally, 108 feature-unspecific synapses were distributed throughout the dendrites, activated concurrently with all stimuli to enhance the probability of spiking (as plateau potentials together with the general background synaptic noise used do not often lead to spikes in SPNs, cf <xref rid="fig2" ref-type="fig">Figure 2A</xref>). The features representing a stimulus (clustered synapses) were active within 20 ms, while feature-unspecific input was activated over a 50 ms window. In simulations with inhibition, four inhibitory synapses, each one representing a feature, were placed near each cluster (<xref rid="fig5" ref-type="fig">Figure 5A</xref>). Within this setup a single stimulus activated both excitatory and inhibitory synapses. To match the level of depolarization seen in our excitatory-only setup, the number of feature-unspecific synapses were increased to 144 in the simulations including inhibitory plasticity. The initial conductance of inhibitory synapses was set to 0.1 ± 0.01 nS.</p>
</sec>
<sec id="s4e2">
<title>Distributed setup</title>
<p>In contrast, this setup examined learning dynamics in neurons without pre-existing synaptic clustering for individual features. A total of 200 excitatory synapses were randomly distributed over 30 dendrites. Each feature was represented by 40 excitatory synapses, and an additional 40 feature-unspecific excitatory synapses were used (<xref rid="fig6" ref-type="fig">Figure 6A</xref>). We initiated this experiment with excitatory synaptic weights at 0.3 ± 0.1 (around 0.75 nS). This higher initial weight was chosen to compensate for the reduced efficacy of non-clustered synaptic inputs in producing sufficient depolarization and calcium influx. Extending our investigation, we added 60 inhibitory synapses, 15 for each feature, dispersed randomly over the 30 dendrites. We initiated this extended experiment with excitatory synaptic weights at 0.45 ± 0.1 (around 1.125 nS), aiming to maintain the same baseline voltage activity as in the excitatory-only case. <xref rid="fig6" ref-type="fig">Figure 6A</xref> illustrates this setup, exemplifying the pre- and post-learning synaptic weights for both excitatory and inhibitory synapses.</p>
</sec>
</sec>
</sec>
</body>
<back>
<sec id="s7">
<fig id="fig3s1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3—figure supplement 1.</label>
<caption><title>Learning-induced synaptic plasticity with metaplasticity turned off</title><p>(<bold>A</bold>): Example voltage traces recorded at the soma and in two dendrites before and after learning. Without metaplasticity, no significant learning occurs—every stimulus triggers spikes (50% performance). (<bold>B</bold>, <bold>C</bold>): Evolution of synaptic conductances throughout learning (top row) and characteristic examples of peak calcium levels (dots), along with the constant kernels in single synapses (shaded areas, bottom rows). The same synaptic arrangement and initial synaptic weights as in <xref rid="fig3" ref-type="fig">Figure 3A</xref> is used (for both clustered and feature-unspecific synapses). (B) illustrates changes in clustered synapses on dendrite 1 (d1). (C) shows distributed, feature-unspecific synapses. The final outcome depends on the initial synaptic weights. Synapses whose calcium levels are within or above the LTP region cannot be weakened, because any LTD during irrelevant stimuli is counteracted by LTP occurring for the relevant stimuli. The calcium levels remain “trapped” within the LTP kernel, and the synaptic weights “zig-zag” around a steady state level (seen in the example clustered ‘red’, ‘yellow’ and ‘banana’ synapse, as well as for the example green and blue feature-unspecific synapse). The synapses with small initial weights, whose calcium levels are situated below the LTP kernel are weakened (example purple synapse). The MP-K and LTP-K denote metaplasticity and LTP kernels, respectively, with the solid line representing the midpoint of the kernels where LTP is strongest. In summary, without metaplasticity learning of NFBP is difficult if initial synaptic weights are not optimally tuned with regard to the postsynaptic calcium concentration. Metaplasticity allows the synapses to fall in and out of the LTP kernel range. They can be strengthened as long as their calcium levels are within the LTP kernel, are stabilized when they are above the LTP kernel, and can be weakened when they are below the LTP kernel.</p></caption>
<graphic xlink:href="584462v3_fig3s1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig5s1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5—figure supplement 1.</label>
<caption><title>Learning with and without inhibitory inputs in distal dendrites.</title><p>(<bold>A</bold>) The figure illustrates the impact of inhibitory inputs on learning dynamics in two distal dendrites (d1 and d2). The top panels depict somatic voltage, while the middle and bottom panels show dendritic voltages. The left panels show voltage in the middle of the learning process (approximately 480 training epochs) with and without inhibitory inputs. The right panels show voltage at the end of the learning process (approximately 960 training epochs). The dashed black line corresponds to the scenario without inhibitory inputs, and the solid red line indicates the presence of inhibitory inputs. In the middle of learning, inhibition prevents spiking for the irrelevant stimuli, thus leading to less LTD. This preserves synaptic strengths in both the clustered and feature-unspecific synapses, allowing the neuron to spike for the relevant stimuli at the end of learning. The overall decrease in unspecific input was 39% without inhibitory inputs and 35% with inhibitory inputs.</p><p>(<bold>B</bold>) The effect of inhibitory plasticity on learning in a dendrite receiving all four features. The left panel shows excitatory synaptic weights in d1 without inhibition, where all features weaken over time due to competition. The middle panel illustrates excitatory synapses in the presence of inhibition, where learning is better regulated. The right panel shows inhibitory synaptic weights.</p></caption>
<graphic xlink:href="584462v3_fig5s1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig6s1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6 - figure supplement 1.</label>
<caption><title>Other learning paradigms</title><p><bold>(A)</bold> : Learning of 5×5 and 3×3 feature combination tasks with randomly distributed synapses over 30 dendrites. The neuron is trained to spike for black-marked combinations and remain silent for white-marked ones. For the 25-feature (5×5) combination, the model used 500 excitatory synapses (50 per feature) with initial conductances of 1.125 ± 0.25 nS, along with 100 inhibitory synapses (10 per feature) with initial conductances of 0.1 ± 0.01 nS. For the 9-feature (3×3) combination, the model used 312 excitatory synapses (52 per feature) and 96 inhibitory synapses (16 per feature), with the same initial weights as in the 5×5 case.</p><p><bold>(B)</bold> : Learning of a 2×2 linear feature combination task with randomly distributed synapses. Each feature is represented by 75 synapses distributed across 30 dendrites (300 total synapses), with an initial synaptic weight of 0.375 ± 0.25 nS. The top row shows the feature combinations used, followed by the performance across 30 different synaptic distributions. The bottom row illustrates somatic voltage traces before and after learning, where the neuron starts from a silent state (red trace) and learns to spike through metaplasticity and dopamine-driven weight updates. Additionally, in the subthreshold learning paradigm, dopamine was given without spiking for expected firings and suppressed when unexpected spiking occurred.</p><p><bold>(C)</bold> : Evolution of synaptic conductances (left column) and calcium dynamics with metaplasticity activity (right column) during learning for each feature (X1, X2, Y1, Y2). The left panels display the weight adjustments of all synapses corresponding to each feature, with one synapse per feature bolded to highlight its individual trajectory. The right panels show the corresponding calcium traces and kernel dynamics for the bolded synapse. MP-K and LTP-K refer to metaplasticity and LTP kernels, respectively, with the solid line representing the midpoint of the kernels where LTP is strongest. ‘Max’ indicates the peak NMDA calcium level during a single stimulus.</p></caption>
<graphic xlink:href="584462v3_fig6s1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s5" sec-type="data-availability">
<title>Code and Data Availability</title>
<p>The modeling code used in this study is structured for reproducibility and is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/zahradd/dSPN-learning-rule">https://github.com/zahradd/dSPN-learning-rule</ext-link>. This repository includes the simulations underlying the figures in the manuscript, along with a README file providing detailed instructions for environment setup and result reproduction. Additionally, model components adapted from <xref ref-type="bibr" rid="c46">Lindroos and Hellgren Kotaleski (2021)</xref> and <xref ref-type="bibr" rid="c83">Trpevski et al., (2023)</xref> are available on ModelDB (accession numbers: 266775 and 2017143).</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>We would like to thank the members of the Hellgren Kotaleski laboratory for their helpful discussions on various aspects of the manuscript. DT extends gratitude to Ana Kalajdjieva for illustrating the mouse brain. We acknowledge the use of Fenix Infrastructure resources, which are partially funded by the European Union’s Horizon 2020 research and innovation programme through the ICEI project under grant agreement No. 800858.</p>
<p>Simulations were also performed on resources provided by the National Academic Infrastructure for Supercomputing in Sweden (NAISS) at PDC KTH, partially funded by the Swedish Research Council through grant agreement No. 2022-06725.</p>
<p>This study was supported by the Swedish Research Council (VR-M-2020-01652), the Swedish e-Science Research Centre (SeRC), Science for Life Laboratory, EU/Horizon 2020 No. 945539 (HBP SGA3) and No. 101147319 (EBRAINS 2.0 Project), the European Union’s Research and Innovation Program Horizon Europe under grant agreement No. 101137289 (the Virtual Brain Twin Project), and KTH Digital Futures.</p>
</ack>
<sec id="d1e2513" sec-type="additional-information">
<title>Additional information</title>
<sec id="s6">
<title>Author contributions</title>
<p>ZK and DT implemented the model, ran the simulations and analyzed the data with support from RL.</p>
<p>JHK and RL supervised all aspects of the study.</p>
<p>All authors contributed to the writing of the manuscript.</p>
</sec>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Abraham</surname>, <given-names>W.C.</given-names></string-name></person-group> (<year>2008</year>) ‘<article-title>Metaplasticity: tuning synapses and networks for plasticity</article-title>’, <source>Nature reviews. Neuroscience</source>, <volume>9</volume>(<issue>5</issue>), p. <fpage>387</fpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Abraham</surname>, <given-names>W.C.</given-names></string-name> and <string-name><surname>Bear</surname>, <given-names>M.F.</given-names></string-name></person-group> (<year>1996</year>) ‘<article-title>Metaplasticity: the plasticity of synaptic plasticity</article-title>’, <source>Trends in neurosciences</source>, <volume>19</volume>(<issue>4</issue>), pp. <fpage>126</fpage>–<lpage>130</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Antic</surname>, <given-names>S.D.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2010</year>) ‘<article-title>The decade of the dendritic NMDA spike</article-title>’, <source>Journal of neuroscience research</source>, <volume>88</volume>(<issue>14</issue>), pp. <fpage>2991</fpage>–<lpage>3001</lpage>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bicknell</surname>, <given-names>B.A.</given-names></string-name> and <string-name><surname>Häusser</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2021</year>) ‘<article-title>A synaptic learning rule for exploiting nonlinear dendritic computation</article-title>’, <source>Neuron</source>, <volume>109</volume>(<issue>24</issue>), pp. <fpage>4001</fpage>–<lpage>4017.</lpage> </mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bienenstock</surname>, <given-names>E.L.</given-names></string-name>, <string-name><surname>Cooper</surname>, <given-names>L.N.</given-names></string-name> and <string-name><surname>Munro</surname>, <given-names>P.W.</given-names></string-name></person-group> (<year>1982</year>) ‘<article-title>Theory for the development of neuron selectivity: orientation specificity and binocular interaction in visual cortex</article-title>’, <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>, <volume>2</volume>(<issue>1</issue>), pp. <fpage>32</fpage>–<lpage>48</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Branco</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Clark</surname>, <given-names>B.A.</given-names></string-name> and <string-name><surname>Häusser</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2010</year>) ‘<article-title>Dendritic discrimination of temporal input sequences in cortical neurons</article-title>’, <source>Science</source>, <volume>329</volume>(<issue>5999</issue>), pp. <fpage>1671</fpage>–<lpage>1675</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Branco</surname>, <given-names>T.</given-names></string-name> and <string-name><surname>Häusser</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2010</year>) ‘<article-title>The single dendritic branch as a fundamental functional unit in the nervous system</article-title>’, <source>Current opinion in neurobiology</source>, <volume>20</volume>(<issue>4</issue>), pp. <fpage>494</fpage>–<lpage>502</lpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bruce</surname>, <given-names>N.J.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2019</year>) ‘<article-title>Regulation of adenylyl cyclase 5 in striatal neurons confers the ability to detect coincident neuromodulatory signals</article-title>’, <source>PLoS computational biology</source>, <volume>15</volume>(<issue>10</issue>), p. <fpage>e1007382</fpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carter</surname>, <given-names>A.G.</given-names></string-name> and <string-name><surname>Sabatini</surname>, <given-names>B.L.</given-names></string-name></person-group> (<year>2004</year>) ‘<article-title>State-dependent calcium signaling in dendritic spines of striatal medium spiny neurons</article-title>’, <source>Neuron</source>, <volume>44</volume>(<issue>3</issue>), pp. <fpage>483</fpage>–<lpage>493</lpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chapman</surname>, <given-names>C.A.</given-names></string-name>, <string-name><surname>Nuwer</surname>, <given-names>J.L.</given-names></string-name> and <string-name><surname>Jacob</surname>, <given-names>T.C.</given-names></string-name></person-group> (<year>2022</year>) ‘<article-title>The Yin and Yang of GABAergic and Glutamatergic Synaptic Plasticity: Opposites in Balance by Crosstalking Mechanisms</article-title>’, <source>Frontiers in synaptic neuroscience</source>, <volume>14</volume>, p. <fpage>911020</fpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chater</surname>, <given-names>T.E.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2024</year>) ‘<article-title>Competitive processes shape multi-synapse plasticity along dendritic segments</article-title>’, <source>Nature communications</source>, <volume>15</volume>(<issue>1</issue>), p. <fpage>7572</fpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname>, <given-names>S.X.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2015</year>) ‘<article-title>Subtype-specific plasticity of inhibitory circuits in motor cortex during motor learning</article-title>’, <source>Nature neuroscience</source>, <volume>18</volume>(<issue>8</issue>), pp. <fpage>1109</fpage>–<lpage>1115</lpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname>, <given-names>X.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2011</year>) ‘<article-title>Functional mapping of single spines in cortical neurons in vivo</article-title>’, <source>Nature</source>, <volume>475</volume>(<issue>7357</issue>), pp. <fpage>501</fpage>–<lpage>505</lpage>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cichon</surname>, <given-names>J.</given-names></string-name> and <string-name><surname>Gan</surname>, <given-names>W.-B.</given-names></string-name></person-group> (<year>2015</year>) ‘<article-title>Branch-specific dendritic Ca(2+) spikes cause persistent synaptic plasticity</article-title>’, <source>Nature</source>, <volume>520</volume>(<issue>7546</issue>), pp. <fpage>180</fpage>–<lpage>185</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Day</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2024</year>) ‘<article-title>GABAergic regulation of striatal spiny projection neurons depends upon their activity state</article-title>’, <source>PLoS biology</source>, <volume>22</volume>(<issue>1</issue>), p. <fpage>e3002483</fpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Destexhe</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Mainen</surname>, <given-names>Z.F.</given-names></string-name> and <string-name><surname>Sejnowski</surname>, <given-names>T.J.</given-names></string-name></person-group> (<year>1994</year>) ‘<article-title>An efficient method for computing synaptic conductances based on a kinetic model of receptor binding</article-title>’, <source>Neural computation</source>, <volume>6</volume>(<issue>1</issue>), pp. <fpage>14</fpage>–<lpage>18</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dorman</surname>, <given-names>D.B.</given-names></string-name>, <string-name><surname>Jędrzejewska-Szmek</surname>, <given-names>J.</given-names></string-name> and <string-name><surname>Blackwell</surname>, <given-names>K.T.</given-names></string-name></person-group> (<year>2018</year>) ‘<article-title>Inhibition enhances spatially-specific calcium encoding of synaptic input patterns in a biologically constrained model</article-title>’, <source>eLife</source>, <volume>7</volume>. <pub-id pub-id-type="doi">10.7554/eLife.38588</pub-id>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Doron</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2017</year>) ‘<article-title>Timed Synaptic Inhibition Shapes NMDA Spikes, Influencing Local Dendritic Processing and Global I/O Properties of Cortical Neurons</article-title>’, <source>Cell reports</source>, <volume>21</volume>(<issue>6</issue>), pp. <fpage>1550</fpage>–<lpage>1561</lpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Du</surname>, <given-names>K.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2017</year>) ‘<article-title>Cell-type-specific inhibition of the dendritic plateau potential in striatal spiny projection neurons</article-title>’, <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>114</volume>(<issue>36</issue>), pp. <fpage>E7612</fpage>–<lpage>E7621</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fino</surname>, <given-names>E.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2010</year>) ‘<article-title>Distinct coincidence detectors govern the corticostriatal spike timing-dependent plasticity</article-title>’, <source>The Journal of physiology</source>, <volume>588</volume>(<issue>Pt 16</issue>), pp. <fpage>3045</fpage>–<lpage>3062</lpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fisher</surname>, <given-names>S.D.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2017</year>) ‘<article-title>Reinforcement determines the timing dependence of corticostriatal synaptic plasticity in vivo</article-title>’, <source>Nature communications</source>, <volume>8</volume>(<issue>1</issue>), p. <fpage>334</fpage>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Frey</surname>, <given-names>U.</given-names></string-name> <etal>et al.</etal></person-group> (<year>1995</year>) ‘<article-title>Asymptotic hippocampal long-term potentiation in rats does not preclude additional potentiation at later phases</article-title>’, <source>Neuroscience</source>, <volume>67</volume>(<issue>4</issue>), pp. <fpage>799</fpage>–<lpage>807</lpage>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gandolfi</surname>, <given-names>D.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2020</year>) ‘<article-title>Inhibitory Plasticity: From Molecules to Computation and Beyond</article-title>’, <source>International journal of molecular sciences</source>, <volume>21</volume>(<issue>5</issue>). <pub-id pub-id-type="doi">10.3390/ijms21051805</pub-id>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gao</surname>, <given-names>P.P.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2021</year>) ‘<article-title>Local glutamate-mediated dendritic plateau potentials change the state of the cortical pyramidal neuron</article-title>’, <source>Journal of neurophysiology</source>, <volume>125</volume>(<issue>1</issue>), pp. <fpage>23</fpage>–<lpage>42</lpage>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gidon</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2020</year>) ‘<article-title>Dendritic action potentials and computation in human layer 2/3 cortical neurons</article-title>’, <source>Science</source>, <volume>367</volume>(<issue>6473</issue>), pp. <fpage>83</fpage>–<lpage>87</lpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Henneberger</surname>, <given-names>C.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2020</year>) ‘<article-title>LTP Induction Boosts Glutamate Spillover by Driving Withdrawal of Perisynaptic Astroglia</article-title>’, <source>Neuron</source>, <volume>108</volume>(<issue>5</issue>), pp. <fpage>919</fpage>–<lpage>936.</lpage> </mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van den Heuvel</surname>, <given-names>M.P.</given-names></string-name> and <string-name><surname>Sporns</surname>, <given-names>O.</given-names></string-name></person-group> (<year>2013</year>) ‘<article-title>Network hubs in the human brain</article-title>’, <source>Trends in cognitive sciences</source>, <volume>17</volume>(<issue>12</issue>), pp. <fpage>683</fpage>–<lpage>696</lpage>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Higley</surname>, <given-names>M.J.</given-names></string-name> and <string-name><surname>Sabatini</surname>, <given-names>B.L.</given-names></string-name></person-group> (<year>2010</year>) ‘<article-title>Competitive regulation of synaptic Ca2+ influx by D2 dopamine and A2A adenosine receptors</article-title>’, <source>Nature neuroscience</source>, <volume>13</volume>(<issue>8</issue>), pp. <fpage>958</fpage>–<lpage>966</lpage>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hjorth</surname>, <given-names>J.J.J.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2020</year>) ‘<article-title>The microcircuits of striatum in silico</article-title>’, <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>117</volume>(<issue>17</issue>), pp. <fpage>9554</fpage>–<lpage>9565</lpage>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname>, <given-names>Y.Y.</given-names></string-name> <etal>et al.</etal></person-group> (<year>1992</year>) ‘<article-title>The influence of prior synaptic activity on the induction of long-term potentiation</article-title>’, <source>Science (New York, N.Y.)</source>, <volume>255</volume>(<issue>5045</issue>), pp. <fpage>730</fpage>–<lpage>733</lpage>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hulme</surname>, <given-names>S.R.</given-names></string-name> and <string-name><surname>Connelly</surname>, <given-names>W.M.</given-names></string-name></person-group> (<year>2014</year>) ‘<article-title>L-type calcium channel-dependent inhibitory plasticity in the thalamus</article-title>’, <source>Journal of neurophysiology</source>, <volume>112</volume>(<issue>9</issue>), pp. <fpage>2037</fpage>–<lpage>2039</lpage>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hwang</surname>, <given-names>F.-J.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2022</year>) ‘<article-title>Motor learning selectively strengthens cortical and striatal synapses of motor engram neurons</article-title>’, <source>Neuron</source>, <volume>110</volume>(<issue>17</issue>), pp. <fpage>2790</fpage>–<lpage>2801.</lpage> </mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Iacaruso</surname>, <given-names>M.F.</given-names></string-name>, <string-name><surname>Gasler</surname>, <given-names>I.T.</given-names></string-name> and <string-name><surname>Hofer</surname>, <given-names>S.B.</given-names></string-name></person-group> (<year>2017</year>) ‘<article-title>Synaptic organization of visual space in primary visual cortex</article-title>’, <source>Nature</source>, <volume>547</volume>(<issue>7664</issue>), pp. <fpage>449</fpage>–<lpage>452</lpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jia</surname>, <given-names>H.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2010</year>) ‘<article-title>Dendritic organization of sensory input to cortical neurons in vivo</article-title>’, <source>Nature</source>, <volume>464</volume>(<issue>7293</issue>), pp. <fpage>1307</fpage>–<lpage>1312</lpage>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Johansson</surname>, <given-names>Y.</given-names></string-name> and <string-name><surname>Silberberg</surname>, <given-names>G.</given-names></string-name></person-group> (<year>2020</year>) ‘<article-title>The Functional Organization of Cortical and Thalamic Inputs onto Five Types of Striatal Neurons Is Determined by Source and Target Cell Identities</article-title>’, <source>Cell reports</source>, <volume>30</volume>(<issue>4</issue>), pp. <fpage>1178</fpage>–<lpage>1194.</lpage> </mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ju</surname>, <given-names>N.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2020</year>) ‘<article-title>Spatiotemporal functional organization of excitatory synaptic inputs onto macaque V1 neurons</article-title>’, <source>Nature communications</source>, <volume>11</volume>(<issue>1</issue>), p. <fpage>697</fpage>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kahneman</surname>, <given-names>D.</given-names></string-name> and <string-name><surname>Tversky</surname>, <given-names>A.</given-names></string-name></person-group> (<year>1979</year>) ‘<article-title>Prospect theory: An analysis of decision under risk</article-title>’, <source>Econometrica: journal of the Econometric Society</source>, <volume>47</volume>(<issue>2</issue>), p. <fpage>263</fpage>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kawai</surname>, <given-names>R.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2015</year>) ‘<article-title>Motor cortex is required for learning but not for executing a motor skill</article-title>’, <source>Neuron</source>, <volume>86</volume>(<issue>3</issue>), pp. <fpage>800</fpage>–<lpage>812</lpage>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kerlin</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2019</year>) ‘<article-title>Functional clustering of dendritic activity during decision-making</article-title>’, <source>eLife</source>, <volume>8</volume>. <pub-id pub-id-type="doi">10.7554/eLife.46966</pub-id>.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kleindienst</surname>, <given-names>T.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2011</year>) ‘<article-title>Activity-dependent clustering of functional synaptic inputs on developing hippocampal dendrites</article-title>’, <source>Neuron</source>, <volume>72</volume>(<issue>6</issue>), pp. <fpage>1012</fpage>–<lpage>1024</lpage>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kurotani</surname>, <given-names>T.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2008</year>) ‘<article-title>State-dependent bidirectional modification of somatic inhibition in neocortical pyramidal cells</article-title>’, <source>Neuron</source>, <volume>57</volume>(<issue>6</issue>), pp. <fpage>905</fpage>–<lpage>916</lpage>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Larkum</surname>, <given-names>M.E.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2009</year>) ‘<article-title>Synaptic integration in tuft dendrites of layer 5 pyramidal neurons: a new unifying principle</article-title>’, <source>Science</source>, <volume>325</volume>(<issue>5941</issue>), pp. <fpage>756</fpage>–<lpage>760</lpage>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lavzin</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2012</year>) ‘<article-title>Nonlinear dendritic processing determines angular tuning of barrel cortex neurons in vivo</article-title>’, <source>Nature</source>, <volume>490</volume>(<issue>7420</issue>), pp. <fpage>397</fpage>–<lpage>401</lpage>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Legenstein</surname>, <given-names>R.</given-names></string-name> and <string-name><surname>Maass</surname>, <given-names>W.</given-names></string-name></person-group> (<year>2011</year>) ‘<article-title>Branch-specific plasticity enables self-organization of nonlinear computation in single neurons</article-title>’, <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>, <volume>31</volume>(<issue>30</issue>), pp. <fpage>10787</fpage>–<lpage>10802</lpage>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lindroos</surname>, <given-names>R.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2018</year>) ‘<article-title>Basal Ganglia Neuromodulation Over Multiple Temporal and Structural Scales-Simulations of Direct Pathway MSNs Investigate the Fast Onset of Dopaminergic Effects and Predict the Role of Kv4.2</article-title>’, <source>Frontiers in neural circuits</source>, <volume>12</volume>, p. <fpage>3</fpage>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lindroos</surname>, <given-names>R.</given-names></string-name> and <string-name><surname>Hellgren Kotaleski</surname>, <given-names>J.</given-names></string-name></person-group> (<year>2021</year>) ‘<article-title>Predicting complex spikes in striatal projection neurons of the direct pathway following neuromodulation by acetylcholine and dopamine</article-title>’, <source>The European journal of neuroscience</source>, <volume>53</volume>(<issue>7</issue>), pp. <fpage>2117</fpage>–<lpage>2134</lpage>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lisman</surname>, <given-names>J.E.</given-names></string-name></person-group> (<year>2001</year>) ‘<article-title>Three Ca2+ levels affect plasticity differently: the LTP zone, the LTD zone and no man’s land</article-title>’, <source>The Journal of physiology</source>, <volume>532</volume>(<issue>Pt 2</issue>), p. <fpage>285</fpage>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Losonczy</surname>, <given-names>A.</given-names></string-name> and <string-name><surname>Magee</surname>, <given-names>J.C.</given-names></string-name></person-group> (<year>2006</year>) ‘<article-title>Integrative properties of radial oblique dendrites in hippocampal CA1 pyramidal neurons</article-title>’, <source>Neuron</source>, <volume>50</volume>(<issue>2</issue>), pp. <fpage>291</fpage>–<lpage>307</lpage>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lovett-Barron</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2012</year>) ‘<article-title>Regulation of neuronal input transformations by tunable dendritic inhibition</article-title>’, <source>Nature neuroscience</source>, <volume>15</volume>(<issue>3</issue>), pp. <fpage>423</fpage>–<lpage>30</lpage>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Major</surname>, <given-names>G.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2008</year>) ‘<article-title>Spatiotemporally graded NMDA spike/plateau potentials in basal dendrites of neocortical pyramidal neurons</article-title>’, <source>Journal of neurophysiology</source>, <volume>99</volume>(<issue>5</issue>), pp. <fpage>2584</fpage>–<lpage>2601</lpage>.</mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>von der Malsburg</surname>, <given-names>C.</given-names></string-name></person-group> (<year>1999</year>) ‘<article-title>The what and why of binding: the modeler’s perspective</article-title>’, <source>Neuron</source>, <volume>24</volume>(<issue>1</issue>), pp. <fpage>95</fpage>–<lpage>104</lpage>, 111–25.</mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Matsuda</surname>, <given-names>W.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2009</year>) ‘<article-title>Single nigrostriatal dopaminergic neurons form widely spread and highly dense axonal arborizations in the neostriatum</article-title>’, <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>, <volume>29</volume>(<issue>2</issue>), pp. <fpage>444</fpage>–<lpage>453</lpage>.</mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McCulloch</surname>, <given-names>W.S.</given-names></string-name> and <string-name><surname>Pitts</surname>, <given-names>W.</given-names></string-name></person-group> (<year>1943</year>) ‘<article-title>A logical calculus of the ideas immanent in nervous activity</article-title>’, <source>The Bulletin of mathematical biophysics</source>, <volume>5</volume>(<issue>4</issue>), pp. <fpage>115</fpage>–<lpage>133</lpage>.</mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Moldwin</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Azran</surname>, <given-names>L.S.</given-names></string-name> and <string-name><surname>Segev</surname>, <given-names>I.</given-names></string-name></person-group> (<year>2024</year>) ‘<article-title>A Generalized Framework for the Calcium Control Hypothesis Describes Weight-Dependent Synaptic Plasticity</article-title>’, <source>bioRxiv</source>. <pub-id pub-id-type="doi">10.1101/2023.07.13.548837</pub-id>.</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Moody</surname>, <given-names>T.D.</given-names></string-name>, <string-name><surname>Carlisle</surname>, <given-names>H.J.</given-names></string-name> and <string-name><surname>O’Dell</surname>, <given-names>T.J.</given-names></string-name></person-group> (<year>1999</year>) ‘<article-title>A nitric oxide-independent and beta-adrenergic receptor-sensitive form of metaplasticity limits theta-frequency stimulation-induced LTP in the hippocampal CA1 region</article-title>’, <source>Learning &amp; memory (Cold Spring Harbor, N.Y.)</source>, <volume>6</volume>(<issue>6</issue>), pp. <fpage>619</fpage>–<lpage>633</lpage>.</mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nair</surname>, <given-names>A.G.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2015</year>) ‘<article-title>Sensing Positive versus Negative Reward Signals through Adenylyl Cyclase-Coupled GPCRs in Direct and Indirect Pathway Striatal Medium Spiny Neurons</article-title>’, <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>, <volume>35</volume>(<issue>41</issue>), pp. <fpage>14017</fpage>–<lpage>14030</lpage>.</mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Niculescu</surname>, <given-names>D.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2018</year>) ‘<article-title>A BDNF-Mediated Push-Pull Plasticity Mechanism for Synaptic Clustering</article-title>’, <source>Cell reports</source>, <volume>24</volume>(<issue>8</issue>), pp. <fpage>2063</fpage>–<lpage>2074</lpage>.</mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nishiyama</surname>, <given-names>J.</given-names></string-name> and <string-name><surname>Yasuda</surname>, <given-names>R.</given-names></string-name></person-group> (<year>2015</year>) ‘<article-title>Biochemical Computation for Spine Structural Plasticity</article-title>’, <source>Neuron</source>, <volume>87</volume>(<issue>1</issue>), pp. <fpage>63</fpage>–<lpage>75</lpage>.</mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Oikonomou</surname>, <given-names>K.D.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2014</year>) ‘<article-title>Spiny neurons of amygdala, striatum, and cortex use dendritic plateau potentials to detect network UP states</article-title>’, <source>Frontiers in cellular neuroscience</source>, <volume>8</volume>, p. <fpage>292</fpage>.</mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Plotkin</surname>, <given-names>J.L.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2013</year>) ‘<article-title>Regulation of dendritic calcium release in striatal spiny projection neurons</article-title>’, <source>Journal of neurophysiology</source>, <volume>110</volume>(<issue>10</issue>), pp. <fpage>2325</fpage>–<lpage>2336</lpage>.</mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Plotkin</surname>, <given-names>J.L.</given-names></string-name>, <string-name><surname>Day</surname>, <given-names>M.</given-names></string-name> and <string-name><surname>Surmeier</surname>, <given-names>D.J.</given-names></string-name></person-group> (<year>2011</year>) ‘<article-title>Synaptically driven state transitions in distal dendrites of striatal spiny neurons</article-title>’, <source>Nature neuroscience</source>, <volume>14</volume>(<issue>7</issue>), pp. <fpage>881</fpage>–<lpage>888</lpage>.</mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Poirazi</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Brannon</surname>, <given-names>T.</given-names></string-name> and <string-name><surname>Mel</surname>, <given-names>B.W.</given-names></string-name></person-group> (<year>2003</year>) ‘<article-title>Pyramidal neuron as two-layer neural network</article-title>’, <source>Neuron</source>, <volume>37</volume>(<issue>6</issue>), pp. <fpage>989</fpage>–<lpage>999</lpage>.</mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Polsky</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Mel</surname>, <given-names>B.W.</given-names></string-name> and <string-name><surname>Schiller</surname>, <given-names>J.</given-names></string-name></person-group> (<year>2004</year>) ‘<article-title>Computational subunits in thin dendrites of pyramidal cells</article-title>’, <source>Nature neuroscience</source>, <volume>7</volume>(<issue>6</issue>), pp. <fpage>621</fpage>–<lpage>627</lpage>.</mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ravasenga</surname>, <given-names>T.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2022</year>) ‘<article-title>Spatial regulation of coordinated excitatory and inhibitory synaptic plasticity at dendritic synapses</article-title>’, <source>Cell reports</source>, <volume>38</volume>(<issue>6</issue>), p. <fpage>110347</fpage>.</mixed-citation></ref>
<ref id="c65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Reig</surname>, <given-names>R.</given-names></string-name> and <string-name><surname>Silberberg</surname>, <given-names>G.</given-names></string-name></person-group> (<year>2014</year>) ‘<article-title>Multisensory integration in the mouse striatum</article-title>’, <source>Neuron</source>, <volume>83</volume>(<issue>5</issue>), pp. <fpage>1200</fpage>–<lpage>1212</lpage>.</mixed-citation></ref>
<ref id="c66"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Reynolds</surname>, <given-names>J.N.J.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2022</year>) ‘<article-title>Coincidence of cholinergic pauses, dopaminergic activation and depolarisation of spiny projection neurons drives synaptic plasticity in the striatum</article-title>’, <source>Nature communications</source>, <volume>13</volume>(<issue>1</issue>), p. <fpage>1296</fpage>.</mixed-citation></ref>
<ref id="c67"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Roskies</surname>, <given-names>A.L.</given-names></string-name></person-group> (<year>1999</year>) ‘<article-title>The binding problem</article-title>’, <source>Neuron</source>, <volume>24</volume>(<issue>1</issue>), pp. <fpage>7</fpage>–<lpage>9</lpage>, 111–25.</mixed-citation></ref>
<ref id="c68"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sanabria</surname>, <given-names>B.D.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2024</year>) ‘<article-title>Cell-Type Specific Connectivity of Whisker-Related Sensory and Motor Cortical Input to Dorsal Striatum</article-title>’, <source>eNeuro</source>, <volume>11</volume>(<fpage>1</fpage>). <pub-id pub-id-type="doi">10.1523/ENEURO.0503-23.2023</pub-id>.</mixed-citation></ref>
<ref id="c69"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Santos</surname>, <given-names>F.J.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2015</year>) ‘<article-title>Corticostriatal dynamics encode the refinement of specific behavioral variability during skill learning</article-title>’, <source>eLife</source>, <volume>4</volume>, p. <elocation-id>e09423</elocation-id>.</mixed-citation></ref>
<ref id="c70"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schiess</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Urbanczik</surname>, <given-names>R.</given-names></string-name> and <string-name><surname>Senn</surname>, <given-names>W.</given-names></string-name></person-group> (<year>2016</year>) ‘<article-title>Somato-dendritic Synaptic Plasticity and Error-backpropagation in Active Dendrites</article-title>’, <source>PLoS computational biology</source>, <volume>12</volume>(<issue>2</issue>), p. <fpage>e1004638</fpage>.</mixed-citation></ref>
<ref id="c71"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schiller</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2000</year>) ‘<article-title>NMDA spikes in basal dendrites of cortical pyramidal neurons</article-title>’, <source>Nature</source>, <volume>404</volume>(<issue>6775</issue>), pp. <fpage>285</fpage>–<lpage>289</lpage>.</mixed-citation></ref>
<ref id="c72"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Scholl</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>D.E.</given-names></string-name> and <string-name><surname>Fitzpatrick</surname>, <given-names>D.</given-names></string-name></person-group> (<year>2017</year>) ‘<article-title>Local Order within Global Disorder: Synaptic Architecture of Visual Space</article-title>’, <source>Neuron</source>, <volume>96</volume>(<issue>5</issue>), pp. <fpage>1127</fpage>–<lpage>1138.</lpage> </mixed-citation></ref>
<ref id="c73"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schultz</surname>, <given-names>W.</given-names></string-name></person-group> (<year>2007</year>) ‘<article-title>Multiple dopamine functions at different time courses</article-title>’, <source>Annual review of neuroscience</source>, <volume>30</volume>, pp. <fpage>259</fpage>–<lpage>288</lpage>.</mixed-citation></ref>
<ref id="c74"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schultz</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name> and <string-name><surname>Montague</surname>, <given-names>P.R.</given-names></string-name></person-group> (<year>1997</year>) ‘<article-title>A neural substrate of prediction and reward</article-title>’, <source>Science</source>, <volume>275</volume>(<issue>5306</issue>), pp. <fpage>1593</fpage>–<lpage>1599</lpage>.</mixed-citation></ref>
<ref id="c75"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shen</surname>, <given-names>W.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2008</year>) ‘<article-title>Dichotomous dopaminergic control of striatal synaptic plasticity</article-title>’, <source>Science</source>, <volume>321</volume>(<issue>5890</issue>), pp. <fpage>848</fpage>–<lpage>851</lpage>.</mixed-citation></ref>
<ref id="c76"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shindou</surname>, <given-names>T.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2019</year>) ‘<article-title>A silent eligibility trace enables dopamine-dependent synaptic plasticity for reinforcement learning in the mouse striatum</article-title>’, <source>The European journal of neuroscience</source>, <volume>49</volume>(<issue>5</issue>), pp. <fpage>726</fpage>–<lpage>736</lpage>.</mixed-citation></ref>
<ref id="c77"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shindou</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Ochi-Shindou</surname>, <given-names>M.</given-names></string-name> and <string-name><surname>Wickens</surname>, <given-names>J.R.</given-names></string-name></person-group> (<year>2011</year>) ‘<article-title>A Ca(2+) threshold for induction of spike-timing-dependent depression in the mouse striatum</article-title>’, <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>, <volume>31</volume>(<issue>36</issue>), pp. <fpage>13015</fpage>–<lpage>13022</lpage>.</mixed-citation></ref>
<ref id="c78"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Silver</surname>, <given-names>D.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2018</year>) ‘<article-title>A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play</article-title>’, <source>Science</source>, <volume>362</volume>(<issue>6419</issue>), pp. <fpage>1140</fpage>–<lpage>1144</lpage>.</mixed-citation></ref>
<ref id="c79"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stauffer</surname>, <given-names>W.R.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2016</year>) ‘<article-title>Components and characteristics of the dopamine reward utility signal</article-title>’, <source>The Journal of comparative neurology</source>, <volume>524</volume>(<issue>8</issue>), pp. <fpage>1699</fpage>–<lpage>1711</lpage>.</mixed-citation></ref>
<ref id="c80"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Surmeier</surname>, <given-names>D.J.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2010</year>) ‘<article-title>The role of dopamine in modulating the structure and function of striatal circuits</article-title>’, <source>Progress in brain research</source>, <volume>183</volume>, pp. <fpage>149</fpage>–<lpage>167</lpage>.</mixed-citation></ref>
<ref id="c81"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Takahashi</surname>, <given-names>N.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2012</year>) ‘<article-title>Locally synchronized synaptic inputs</article-title>’, <source>Science</source>, <volume>335</volume>(<issue>6066</issue>), pp. <fpage>353</fpage>–<lpage>356</lpage>.</mixed-citation></ref>
<ref id="c82"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tran-Van-Minh</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2015</year>) ‘<article-title>Contribution of sublinear and supralinear dendritic integration to neuronal computations</article-title>’, <source>Frontiers in cellular neuroscience</source>, <volume>9</volume>, p. <fpage>67</fpage>.</mixed-citation></ref>
<ref id="c83"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Trpevski</surname>, <given-names>D.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2023</year>) ‘<article-title>Glutamate spillover drives robust all-or-none dendritic plateau potentials-an investigation using models of striatal projection neurons</article-title>’, <source>Frontiers in cellular neuroscience</source>, <volume>17</volume>, p. <fpage>1196182</fpage>.</mixed-citation></ref>
<ref id="c84"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Udakis</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2020</year>) ‘<article-title>Interneuron-specific plasticity at parvalbumin and somatostatin inhibitory synapses onto CA1 pyramidal neurons shapes hippocampal output</article-title>’, <source>Nature communications</source>, <volume>11</volume>(<issue>1</issue>), p. <fpage>4395</fpage>.</mixed-citation></ref>
<ref id="c85"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Varga</surname>, <given-names>Z.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2011</year>) ‘<article-title>Dendritic coding of multiple sensory inputs in single cortical neurons in vivo</article-title>’, <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>108</volume>(<issue>37</issue>), pp. <fpage>15420</fpage>–<lpage>15425</lpage>.</mixed-citation></ref>
<ref id="c86"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Watt</surname>, <given-names>A.J.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2004</year>) ‘<article-title>A proportional but slower NMDA potentiation follows AMPA potentiation in LTP</article-title>’, <source>Nature neuroscience</source>, <volume>7</volume>(<issue>5</issue>), pp. <fpage>518</fpage>–<lpage>524</lpage>.</mixed-citation></ref>
<ref id="c87"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wilson</surname>, <given-names>C.J.</given-names></string-name> <etal>et al.</etal></person-group> (<year>1983</year>) ‘<article-title>Three-dimensional structure of dendritic spines in the rat neostriatum</article-title>’, <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>, <volume>3</volume>(<issue>2</issue>), pp. <fpage>383</fpage>–<lpage>388</lpage>.</mixed-citation></ref>
<ref id="c88"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wilson</surname>, <given-names>D.E.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2016</year>) ‘<article-title>Orientation selectivity and the functional clustering of synaptic inputs in primary visual cortex</article-title>’, <source>Nature neuroscience</source>, <volume>19</volume>(<issue>8</issue>), pp. <fpage>1003</fpage>–<lpage>1009</lpage>.</mixed-citation></ref>
<ref id="c89"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Winnubst</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2015</year>) ‘<article-title>Spontaneous Activity Drives Local Synaptic Plasticity In Vivo</article-title>’, <source>Neuron</source>, <volume>87</volume>(<issue>2</issue>), pp. <fpage>399</fpage>–<lpage>410</lpage>.</mixed-citation></ref>
<ref id="c90"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wolf</surname>, <given-names>J.A.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2005</year>) ‘<article-title>NMDA/AMPA ratio impacts state transitions and entrainment to oscillations in a computational model of the nucleus accumbens medium spiny projection neuron</article-title>’, <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source>, <volume>25</volume>(<issue>40</issue>), pp. <fpage>9080</fpage>–<lpage>9095</lpage>.</mixed-citation></ref>
<ref id="c91"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname>, <given-names>N.-L.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2012</year>) ‘<article-title>Nonlinear dendritic integration of sensory and motor input during an active sensing task</article-title>’, <source>Nature</source>, <volume>492</volume>(<issue>7428</issue>), pp. <fpage>247</fpage>–<lpage>251</lpage>.</mixed-citation></ref>
<ref id="c92"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yagishita</surname>, <given-names>S.</given-names></string-name> <etal>et al.</etal></person-group> (<year>2014</year>) ‘<article-title>A critical time window for dopamine actions on the structural plasticity of dendritic spines</article-title>’, <source>Science</source>, <volume>345</volume>(<issue>6204</issue>), pp. <fpage>1616</fpage>–<lpage>1620</lpage>.</mixed-citation></ref>
<ref id="c93"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zenke</surname>, <given-names>F.</given-names></string-name> and <string-name><surname>Gerstner</surname>, <given-names>W.</given-names></string-name></person-group> (<year>2017</year>) ‘<article-title>Hebbian plasticity requires compensatory processes on multiple timescales</article-title>’, <source>Philosophical transactions of the Royal Society of London. Series B, Biological sciences</source>, <volume>372</volume>(<issue>1715</issue>). <pub-id pub-id-type="doi">10.1098/rstb.2016.0259</pub-id>.</mixed-citation></ref>
<ref id="c94"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zenke</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Gerstner</surname>, <given-names>W.</given-names></string-name> and <string-name><surname>Ganguli</surname>, <given-names>S.</given-names></string-name></person-group> (<year>2017</year>) ‘<article-title>The temporal paradox of Hebbian learning and homeostatic plasticity</article-title>’, <source>Current opinion in neurobiology</source>, <volume>43</volume>, pp. <fpage>166</fpage>–<lpage>176</lpage>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.97274.2.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Ding</surname>
<given-names>Jun</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Stanford University</institution>
</institution-wrap>
<city>Stanford</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
</front-stub>
<body>
<p>This computational modeling study builds on multiple previous lines of experimental and theoretical research to investigate how a single neuron can solve a nonlinear pattern classification task. The study presents <bold>solid</bold> evidence that the location of synapses on dendritic branches, as well as synaptic plasticity of excitatory and inhibitory synapses, influences the ability of a neuron to discriminate combinations of sensory stimuli. The ideas in this work are very interesting, presenting an <bold>important</bold> direction in the computational neuroscience field about how to harness the computational power of &quot;active dendrites&quot; for solving learning tasks.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.97274.2.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This computational modeling study builds on multiple previous lines of experimental and theoretical research to investigate how a single neuron can solve a nonlinear pattern classification task. The authors construct a detailed biophysical and morphological model of a single striatal medium spiny neuron, and endow excitatory and inhibitory synapses with dynamic synaptic plasticity mechanisms that are sensitive to (1) the presence or absence of a dopamine reward signal, and (2) spatiotemporal coincidence of synaptic activity in single dendritic branches. The latter coincidence is detected by voltage-dependent NMDA-type glutamate receptors, which can generate a type of dendritic spike referred to as a &quot;plateau potential.&quot; In the absence of inhibitory plasticity, the proposed mechanisms result in good performance on a nonlinear classification task when specific input features are segregated and clustered onto individual branches, but reduced performance when input features are randomly distributed across branches. Interestingly, adding inhibitory plasticity improves classification performance even when input features are randomly distributed.</p>
<p>Strengths:</p>
<p>The integrative aspect of this study is its major strength. It is challenging to relate low-level details such as electrical spine compartmentalization, extrasynaptic neurotransmitter concentrations, dendritic nonlinearities, spatial clustering of correlated inputs, and plasticity of excitatory and inhibitory synapses to high-level computations such as nonlinear feature classification. Due to high simulation costs, it is rare to see highly biophysical and morphological models used for learning studies that require repeated stimulus presentations over the course of a training procedure. The study aspires to prove the principle that experimentally-supported biological mechanisms can explain complex learning.</p>
<p>Weaknesses:</p>
<p>The high level of complexity of each component of the model makes it difficult to gain an intuition for which aspects of the model are essential for its performance, or responsible for its poor performance under certain conditions. Stripping down some of the biophysical detail and comparing it to a simpler model may help better understand each component in isolation.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.97274.2.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The study explores how single striatal projection neurons (SPNs) utilize dendritic nonlinearities to solve complex integration tasks. It introduces a calcium-based synaptic learning rule that incorporates local calcium dynamics and dopaminergic signals, along with metaplasticity to ensure stability for synaptic weights. Results show SPNs can solve the nonlinear feature binding problem and enhance computational efficiency through inhibitory plasticity in dendrites, emphasizing the significant computational potential of individual neurons. In summary, the study provides a more biologically plausible solution to single-neuron learning and gives further mechanical insights into complex computations at the single-neuron level.</p>
<p>Strengths:</p>
<p>The paper introduces a novel learning rule for training a single multicompartmental neuron model to perform nonlinear feature binding tasks (NFBP), highlighting two main strengths: the learning rule is local, calcium-based, and requires only sparse reward signals, making it highly biologically plausible, and it applies to detailed neuron models that effectively preserve dendritic nonlinearities, contrasting with many previous studies that use simplified models.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.97274.2.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Khodadadi</surname>
<given-names>Zahra</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6124-949X</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Trpevski</surname>
<given-names>Daniel</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9068-6744</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Lindroos</surname>
<given-names>Robert</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9134-3601</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Hellgren Kotaleski</surname>
<given-names>Jeanette</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0550-0739</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>The following is the authors’ response to the original reviews</p>
<disp-quote content-type="editor-comment">
<p><bold>Public Reviews:</bold></p>
<p><bold>Reviewer #1 (Public Review):</bold></p>
<p>Summary:</p>
<p>This computational modeling study builds on multiple previous lines of experimental and theoretical research to investigate how a single neuron can solve a nonlinear pattern classification task. The authors construct a detailed biophysical and morphological model of a single striatal medium spiny neuron, and endow excitatory and inhibitory synapses with dynamic synaptic plasticity mechanisms that are sensitive to (1) the presence or absence of a dopamine reward signal, and (2) spatiotemporal coincidence of synaptic activity in single dendritic branches. The latter coincidence is detected by voltage-dependent NMDA-type glutamate receptors, which can generate a type of dendritic spike referred to as a &quot;plateau potential.&quot; The proposed mechanisms result in moderate performance on a nonlinear classification task when specific input features are segregated and clustered onto individual branches, but reduced performance when input features are randomly distributed across branches. Given the high level of complexity of all components of the model, it is not clear which features of which components are most important for its performance. There is also room for improvement in the narrative structure of the manuscript and the organization of concepts and data.</p>
<p>Strengths:</p>
<p>The integrative aspect of this study is its major strength. It is challenging to relate low-level details such as electrical spine compartmentalization, extrasynaptic neurotransmitter concentrations, dendritic nonlinearities, spatial clustering of correlated inputs, and plasticity of excitatory and inhibitory synapses to high-level computations such as nonlinear feature classification. Due to high simulation costs, it is rare to see highly biophysical and morphological models used for learning studies that require repeated stimulus presentations over the course of a training procedure. The study aspires to prove the principle that experimentally-supported biological mechanisms can explain complex learning.</p>
<p>Weaknesses:</p>
<p>The high level of complexity of each component of the model makes it difficult to gain an intuition for which aspects of the model are essential for its performance, or responsible for its poor performance under certain conditions. Stripping down some of the biophysical detail and comparing it to a simpler model may help better understand each component in isolation. That said, the fundamental concepts behind nonlinear feature binding in neurons with compartmentalized dendrites have been explored in previous work, so it is not clear how this study represents a significant conceptual advance. Finally, the presentation of the model, the motivation and justification of each design choice, and the interpretation of each result could be restructured for clarity to be better received by a wider audience.</p>
</disp-quote>
<p>Thank you for the feedback! We agree that the complexity of our model can make it challenging to intuitively understand the underlying mechanisms. To address this, we have revised the manuscript to include additional simulations and clearer explanations of the mechanisms at play.</p>
<p>In the revised introduction, we now explicitly state our primary aim: to assess to what extent a biophysically detailed neuron model can support the theory proposed by Tran-Van-Minh et al. and explore whether such computations can be learned by a single neuron, specifically a projection neuron in the striatum. To achieve this, we focus on several key mechanisms:</p>
<p>(1) A local learning rule: We develop a learning rule driven by local calcium dynamics in the synapse and by reward signals from the neuromodulator dopamine. This plasticity rule is based on the known synaptic machinery for triggering LTP or LTD in the corticostriatal synapse onto dSPNs (Shen <italic>et al.</italic>, 2008). Importantly, the rule does not rely on supervised learning paradigms and neither is a separate training and testing phase needed.</p>
<p>(2) Robust dendritic nonlinearities: According to Tran-Van-Minh et al., (2015) sufficient supralinear integration is needed to ensure that e.g. two inputs (i.e. one feature combination in the NFBP, Figure 1A) on the same dendrite generate greater somatic depolarization than if those inputs were distributed across different dendrites. To accomplish this we generate sufficiently robust dendritic plateau potentials using the approach in Trpevski et al., (2023).</p>
<p>(3) Metaplasticity: Although not discussed much in more theoretical work, our study demonstrates the necessity of metaplasticity for achieving stable and physiologically realistic synaptic weights. This mechanism ensures that synaptic strengths remain within biologically plausible ranges during training, regardless of initial synaptic weights.</p>
<p>We have also clarified our design choices and the rationale behind them, as well as restructured the interpretation of our results for greater accessibility. We hope these revisions make our approach and findings more transparent and easier to engage with for a broader audience.</p>
<disp-quote content-type="editor-comment">
<p><bold>Recommendations for the authors:</bold></p>
<p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p>
<p>This study extends three previous lines of work:</p>
<p>(1) Prior computational/phenomenological work has shown that the presence of dendritic nonlinearities can enable single neurons to perform linearly non-separable tasks like XOR and feature binding (e.g. Tran-Van-Minh et al., Front. Cell. Neurosci., 2015).</p>
</disp-quote>
<p>Prior computational and phenomenological work, such as Tran-Van-Minh et al. (Front. Cell. Neurosci., 2015), directly inspired our study, as we now explicitly state in the introduction (page 4, lines 19-22). While Tran-Van-Minh theoretically demonstrated that these principles could solve the NFBP, it remains untested to what extent this can be achieved quantitatively in biophysically detailed neuron models using biologically plausible learning rules - which is what we test here.</p>
<disp-quote content-type="editor-comment">
<p>(2) This study and a previous biophysical modeling study (Trpevski et al., Front. Cell. Neurosci., 2023) rely heavily on the finding from Chalifoux &amp; Carter, J. Neurosci., 2011 that blocking glutamate transporters with TBOA increases dendritic calcium signals. The proposed model thus depends on a specific biophysical mechanism for dendritic plateau potential generation, where spatiotemporally clustered inputs must be co-activated on a single branch, and the voltage compartmentalization of the branch and the voltage-dependence of NMDARs is not enough, but additionally glutamate spillover from neighboring synapses must activate extrasynaptic NMDARs. If this specific biophysical implementation of dendritic plateau potentials is essential to the findings in this study, the authors have not made that connection clear. If it is a simple threshold nonlinearity in dendrites that is important for the model, and not the specific underlying biophysical mechanisms, then the study does not appear to provide a conceptual advance over previous studies demonstrating nonlinear feature binding with simpler implementations of dendritic nonlinearities.</p>
</disp-quote>
<p>We appreciate the feedback on the hypothesized role of glutamate spillover in our model. While the current manuscript and Trpevski et al. (2023) emphasize glutamate spillover as a plausible biophysical mechanism to provide sufficiently robust and supralinear plateau potentials, we acknowledge, however, that the mechanisms of supralinearity of dendritic integration, might not depend solely on this specific mechanism in other types of neurons. In Trpevski et al (2023) we, however, realized that if we allow too ‘graded’ dendritic plateaus, using the quite shallow Mg-block reported in experiments, it was difficult to solve the NFBP. The conceptual advance of our study lies in demonstrating that sufficiently nonlinear dendritic integration is needed and that this can be accounted for by assuming spillover in SPNs—but regardless of its biophysical source (e.g. NMDA spillover, steeper NMDA Mg block activation curves or other voltage dependent conductances that cause supralinear dendritic integration)—it enables biophysically detailed neurons to solve the nonlinear feature binding problem. To address this point and clarify the generality of our conclusions, we have revised the relevant sections in the manuscript to state this explicitly.</p>
<disp-quote content-type="editor-comment">
<p>(3) Prior work has utilized &quot;sliding-threshold,&quot; BCM-like plasticity rules to achieve neuronal selectivity and stability in synaptic weights. Other work has shown coordinated excitatory and inhibitory plasticity. The current manuscript combines &quot;metaplasticity&quot; at excitatory synapses with suppression of inhibitory strength onto strongly activated branches. This resembles the lateral inhibition scheme proposed by Olshausen (Christopher J. Rozell, Don H. Johnson, Richard G. Baraniuk, Bruno A. Olshausen; Sparse Coding via Thresholding and Local Competition in Neural Circuits. Neural Comput 2008; 20 (10): 2526-2563. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/neco.2008.03-07-486">https://doi.org/10.1162/neco.2008.03-07-486</ext-link>). However, the complexity of the biophysical model makes it difficult to evaluate the relative importance of the additional complexity of the learning scheme.</p>
</disp-quote>
<p>We initially tried solving the NFBP with only excitatory plasticity, which worked reasonably well, especially if we assume a small population of neurons collaborates under physiological conditions. However, we observed that plateau potentials from distally located inputs were less effective, and we now explain this limitation in the revised manuscript (page 14, lines 23-37).</p>
<p>To address this, we added inhibitory plasticity inspired by mechanisms discussed in Castillo et al. (2011) , Ravasenga et al., and Chapman et al. (2022) , as now explicitly stated in the text (page 32, lines 23-26). While our GABA plasticity rule is speculative, it demonstrates that distal GABAergic plasticity can enhance nonlinear computations. These results are particularly encouraging, as it shows that implementing these mechanisms at the single-neuron level produces behavior consistent with network-level models like BCM-like plasticity rules and those proposed by Rozell et al. We hope this will inspire further experimental work on inhibitory plasticity mechanisms.</p>
<disp-quote content-type="editor-comment">
<p>P2, paragraph 2: Grammar: &quot;multiple dendritic regions, preferentially responsive to different input values or features, are known to form with close dendritic proximity.&quot; The meaning is not clear. &quot;Dendritic regions&quot; do not &quot;form with close dendritic proximity.&quot;</p>
</disp-quote>
<p>Rewritten (current page 2, line 35)</p>
<disp-quote content-type="editor-comment">
<p>P5, paragraph 3: Grammar: I think you mean &quot;strengthened synapses&quot; not &quot;synapses strengthened&quot;.</p>
</disp-quote>
<p>Rewritten (current page 14, line 36)</p>
<disp-quote content-type="editor-comment">
<p>P8, paragraph 1: Grammar: &quot;equally often&quot; not &quot;equally much&quot;.</p>
</disp-quote>
<p>Updated (current page 10, line 2)</p>
<disp-quote content-type="editor-comment">
<p>P8, paragraph 2: &quot;This is because of the learning rule that successively slides the LTP NMDA Ca-dependent plasticity kernel over training.&quot; It is not clear what is meant by &quot;sliding,&quot; either here or in the Methods. Please clarify.</p>
</disp-quote>
<p>We have updated the text and removed the word “sliding” throughout the manuscript to clarify that the calcium dependence of the kernels are in fact updated</p>
<disp-quote content-type="editor-comment">
<p>P10, Figure 3C (left): After reading the accompanying text on P8, para 2, I am left not understanding what makes the difference between the two groups of synapses that both encode &quot;yellow,&quot; on the same dendritic branch (d1) (so both see the same plateau potentials and dopamine) but one potentiates and one depresses. Please clarify.</p>
</disp-quote>
<p>Some &quot;yellow&quot; and &quot;banana&quot; synapses are initialized with weak conductances, limiting their ability to learn due to the relatively slow dynamics of the LTP kernel. These weak synapses fail to reach the calcium thresholds necessary for potentiation during a dopamine peak, yet they remain susceptible to depression under LTD conditions. Initially, the dynamics of the LTP kernel does not allow significant potentiation, even in the presence of appropriate signals such as plateau potentials and dopamine (page 10, lines 22–26). We have added a more detailed explanation of how the learning rule operates in the section “Characterization of the Synaptic Plasticity Rule” on page 9 and have clarified the specific reason why the weaker yellow synapses undergo LTD (page 11, lines 1–7).</p>
<p>As shown in Supplementary Figure 6, during subthreshold learning, the initial conductance is also low, which similarly hinders the synapses' ability to potentiate. However, with sufficient dopamine, the LTP kernel adapts by shifting closer to the observed calcium levels, allowing these synapses to eventually strengthen. This dynamic highlights how the model enables initially weak synapses to &quot;catch up&quot; under consistent activation and favorable dopaminergic conditions.</p>
<disp-quote content-type="editor-comment">
<p>P9, paragraph 1: The phrase &quot;the metaplasticity kernel&quot; is introduced here without prior explanation or motivation for including this level of complexity in the model. Please set it up before you use it.</p>
</disp-quote>
<p>A sentence introducing metaplasticity has been added to the introduction (page 3, lines 36-42) as well as on page 9, where the kernel is introduced (page 9, lines 26-35)</p>
<disp-quote content-type="editor-comment">
<p>P10, Figure 3D: &quot;kernel midline&quot; is not explained.</p>
</disp-quote>
<p>We have replotted fig 3 to make it easier to understand what is shown. Also, an explanation of the Kernel midpoint is added to the legend (current page 12, line 19)</p>
<disp-quote content-type="editor-comment">
<p>P11, paragraph 1; P13, Fig. 4C: My interpretation of these data is that clustered connectivity with specific branches is essential for the performance of the model. Randomly distributing input features onto branches (allowing all 4 features to innervate single branches) results in poor performance. This is bad, right? The model can't learn unless a specific pre-wiring is assumed. There is not much interpretation provided at this stage of the manuscript, just a flat description of the result. Tell the reader what you think the implications of this are here.</p>
</disp-quote>
<p>Thanks for the suggestion - we have updated this section of the manuscript, adding an interpretation of the results that the model often fails to learn both relevant stimuli if all four features are clustered onto the same dendrite (page 13, lines 31-42).</p>
<p>In summary, when multiple feature combinations are encoded in the same dendrite with similar conductances, the ability to determine which combination to store depends on the dynamics of the other dendrite. Small variations in conductance, training order, or other stochastic factors can influence the outcome. This challenge, known as the symmetry-breaking problem, has been previously acknowledged in abstract neuron models (Legenstein and Maass, 2011). To address this, additional mechanisms such as branch plasticity—amplifying or attenuating the plateau potential as it propagates from the dendrite to the soma—can be employed (Legenstein and Maass, 2011).</p>
<disp-quote content-type="editor-comment">
<p>P12, paragraph 2; P13, Figure 4E: This result seems suboptimal, that only synapses at a very specific distance from the soma can be used to effectively learn to solve a NFBP. It is not clear to what extent details of the biophysical and morphological model are contributing to this narrow distance-dependence, or whether it matches physiological data.</p>
</disp-quote>
<p>We have added Figure 5—figure supplement 1A to clarify why distal synapses may not optimally contribute to learning. This figure illustrates how inhibitory plasticity improves performance by reducing excessive LTD at distal dendrites, thereby enhancing stimulus discrimination. Relevant explanations have been integrated into Page 18, Lines 25-39 in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p>P14, paragraph 2: Now the authors are assuming that inhibitory synapses are highly tuned to stimulus features. The tuning of inhibitory cells in the hippocampus and cortex is controversial but seems generally weaker than excitatory cells, commensurate with their reduced number relative to excitatory cells. The model has accumulated a lot of assumptions at this point, many without strong experimental support, which again might make more sense when proposing a new theory, but this stitching together of complex mechanisms does not provide a strong intuition for whether the scheme is either biologically plausible or performant for a general class of problem.</p>
</disp-quote>
<p>We acknowledge that it is not currently known whether inhibitory synapses in the striatum are tuned to stimulus features. However, given that the striatum is a purely inhibitory structure, it is plausible that lateral inhibition from other projection neurons could be tuned to features, even if feedforward inhibition from interneurons is not. Therefore, we believe this assumption is reasonable in the context of our model. As noted earlier, the GABA plasticity rule in our study is speculative. However, we hope that our work will encourage further experimental investigations, as we demonstrate that if GABAergic inputs are sufficiently specific, they can significantly enhance computations (This is discussed on page 17, lines 8-15.).</p>
<disp-quote content-type="editor-comment">
<p>P16, Figure 5E legend: The explanation of the meaning of T_max and T_min in the legend and text needs clarification.</p>
</disp-quote>
<p>The abbreviations  T<sub>min</sub> and  T<sub>max</sub> have been updated to CTL and CTH to better reflect their role in calcium threshold tracking. The Figure 5E legend and relevant text have been revised for clarity. Additionally, the Methods section has been reorganized for better readability.</p>
<disp-quote content-type="editor-comment">
<p>P16, Figure 5B, C: When the reader reaches this paper, the conundrums presented in Figure 4 are resolved. The &quot;winner-takes-all&quot; inhibitory plasticity both increases the performance when all features are presented to a single branch and increases the range of somatodendritic distances where synapses can effectively be used for stimulus discrimination. The problem, then, is in the narrative. A lot more setup needs to be provided for the question related to whether or not dendritic nonlinearity and synaptic inhibition can be used to perform the NFBP. The authors may consider consolidating the results of Fig. 4 and 5 so that the comparison is made directly, rather than presenting them serially without much foreshadowing.</p>
</disp-quote>
<p>In order to facilitate readability, we have updated the following sections of the manuscript to clarify how inhibitory plasticity resolves challenges from Figure 4:</p>
<p>Figure 5B and Figure 5–figure supplement 1B: Two new panels illustrate the role of inhibitory plasticity in addressing symmetry problems.</p>
<p>Figure 5–figure supplement 1A: Shows how inhibitory plasticity extends the effective range of somatodendritic distances.</p>
<disp-quote content-type="editor-comment">
<p>P18, Figure 6: This should be the most important figure, finally tying in all the previous complexity to show that NFBP can be partially solved with E and I plasticity even when features are distributed randomly across branches without clustering. However, now bringing in the comparison across spillover models is distracting and not necessary. Just show us the same plateau generation model used throughout the paper, with and without inhibition.</p>
</disp-quote>
<p>Figure updated. Accumulative spillover and no-spillover conditions have been removed.</p>
<disp-quote content-type="editor-comment">
<p>P18, paragraph 2: &quot;In Fig. 6C, we report that a subset of neurons (5 out of 31) successfully solved the NFBP.&quot; This study could be significantly strengthened if this phenomenon could (perhaps in parallel) be shown to occur in a simpler model with a simpler plateau generation mechanism. Furthermore, it could be significantly strengthened if the authors could show that, even if features are randomly distributed at initialization, a pruning mechanism could gradually transition the neuron into the state where fewer features are present on each branch, and the performance could approach the results presented in Figure 5 through dynamic connectivity.</p>
</disp-quote>
<p>To model structural plasticity is a good suggestion that should be investigated in later work, however, we feel that it goes beyond what we can do in the current manuscript.  We now acknowledge that structural plasticity might play a role. For example we show that if we can assume ‘branch-specific’ spillover, that leads to sufficiently development of local dendritic non-linearities, also one can learn with distributed inputs. In reality, structural plasticity is likely important here, as we now state (current page 22, line 35-42).</p>
<disp-quote content-type="editor-comment">
<p>P17, paragraph 2: &quot;As shown in Fig. 6B, adding the hypothetical nonlinearities to the model increases the performance towards solving part of the NFBP, i.e. learning to respond to one relevant feature combination only. The performance increases with the amount of nonlinearity.&quot; This is not shown in Figure 6B.</p>
</disp-quote>
<p>Sentence removed. We have added a Figure 6 - figure supplement 1 to better explain the limitations.</p>
<disp-quote content-type="editor-comment">
<p>P22, paragraph 1: The &quot;w&quot; parameter here is used to determine whether spatially localized synapses are co-active enough to generate a plateau potential. However, this is the same w learned through synaptic plasticity. Typically LTP and LTD are thought of as changing the number of postsynaptic AMPARs. Does this &quot;w&quot; also change the AMPAR weight in the model? Do the authors envision this as a presynaptic release probability quantity? If so, please state that and provide experimental justification. If not, please justify modifying the activation of postsynaptic NMDARs through plasticity.</p>
</disp-quote>
<p>This is an important remark. Our plasticity model differs from classical LTP models as it depends on the link between LTP and increased spillover as described by Henneberger et al., (2020).</p>
<p>We have updated the method section (page 27, lines 6-11), and we acknowledge, however, that in a real cell, learning might first strengthen the AMPA component, but after learning the ratio of NMDA/AMPA is unchanged ( Watt et al., 2004). This re-balancing between NMDA and AMPA might perhaps be a slower process.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public Review):</bold></p>
<p>Summary:</p>
<p>The study explores how single striatal projection neurons (SPNs) utilize dendritic nonlinearities to solve complex integration tasks. It introduces a calcium-based synaptic learning rule that incorporates local calcium dynamics and dopaminergic signals, along with metaplasticity to ensure stability for synaptic weights. Results show SPNs can solve the nonlinear feature binding problem and enhance computational efficiency through inhibitory plasticity in dendrites, emphasizing the significant computational potential of individual neurons. In summary, the study provides a more biologically plausible solution to single-neuron learning and gives further mechanical insights into complex computations at the single-neuron level.</p>
<p>Strengths:</p>
<p>The paper introduces a novel learning rule for training a single multicompartmental neuron model to perform nonlinear feature binding tasks (NFBP), highlighting two main strengths: the learning rule is local, calcium-based, and requires only sparse reward signals, making it highly biologically plausible, and it applies to detailed neuron models that effectively preserve dendritic nonlinearities, contrasting with many previous studies that use simplified models.</p>
<p>Weaknesses:</p>
<p>I am concerned that the manuscript was submitted too hastily, as evidenced by the quality and logic of the writing and the presentation of the figures. These issues may compromise the integrity of the work. I would recommend a substantial revision of the manuscript to improve the clarity of the writing, incorporate more experiments, and better define the goals of the study.</p>
</disp-quote>
<p>Thanks for the valuable feedback. We have now gone through the whole manuscript updating the text, and also improved figures and added some supplementary figures to better explain model mechanisms. In particular, we state more clearly our goal already in the introduction.</p>
<disp-quote content-type="editor-comment">
<p>Major Points:</p>
<p>(1) Quality of Scientific Writing: The current draft does not meet the expected standards. Key issues include:</p>
<p>i. Mathematical and Implementation Details: The manuscript lacks comprehensive mathematical descriptions and implementation details for the plasticity models (LTP/LTD/Meta) and the SPN model. Given the complexity of the biophysically detailed multicompartment model and the associated learning rules, the inclusion of only nine abstract equations (Eq. 1-9) in the Methods section is insufficient. I was surprised to find no supplementary material providing these crucial details. What parameters were used for the SPN model? What are the mathematical specifics for the extra-synaptic NMDA receptors utilized in this study? For instance, Eq. 3 references [Ca2+]-does this refer to calcium ions influenced by extra-synaptic NMDARs, or does it apply to other standard NMDARs? I also suggest the authors provide pseudocodes for the entire learning process to further clarify the learning rules.</p>
</disp-quote>
<p>The model is quite detailed but builds on previous work. For this reason, for model components used in earlier published work (and where models are already available via model repositories, such as ModelDB), we refer the reader to these resources in order to improve readability and to highlight what is novel in this paper - the learning rules itself. The learning rule is now explained in detail. For modelers that want to run the model, we have also provided a GitHub link to the simulation code. We hope this is a reasonable compromise to all readers, i.e, those that only want to understand what is new here (learning rule) and those that also want to test the model code. We explain this to the readers at the beginning of the Methods section.</p>
<disp-quote content-type="editor-comment">
<p>ii. Figure quality. The authors seem not to carefully typeset the images, resulting in overcrowding and varying font sizes in the figures. Some of the fonts are too small and hard to read. The text in many of the diagrams is confusing. For example, in Panel A of Figure 3, two flattened images are combined, leading to small, distorted font sizes. In Panels C and D of Figure 7, the inconsistent use of terminology such as &quot;kernels&quot; further complicates the clarity of the presentation. I recommend that the authors thoroughly review all figures and accompanying text to ensure they meet the expected standards of clarity and quality.</p>
</disp-quote>
<p>Thanks for directing our attention to these oversights. We have gone through the entire manuscript, updating the figures where needed, and we are making sure that the text and the figure descriptions are clear and adequate and use consistent terminology for all quantities.</p>
<disp-quote content-type="editor-comment">
<p>iii. Writing clarity. The manuscript often includes excessive and irrelevant details, particularly in the mathematical discussions. On page 24, within the &quot;Metaplasticity&quot; section, the authors introduce the biological background to support the proposed metaplasticity equation (Eq. 5). However, much of this biological detail is hypothesized rather than experimentally verified. For instance, the claim that &quot;a pause in dopamine triggers a shift towards higher calcium concentrations while a peak in dopamine pushes the LTP kernel in the opposite direction&quot; lacks cited experimental evidence. If evidence exists, it should be clearly referenced; otherwise, these assertions should be presented as theoretical hypotheses. Generally, Eq. 5 and related discussions should be described more concisely, with only a loose connection to dopamine effects until more experimental findings are available.</p>
</disp-quote>
<p>The “Metaplasticity” section (pages 30-32) has been updated to be more concise, and the abundant references to dopamine have been removed.</p>
<disp-quote content-type="editor-comment">
<p>(2) Goals of the Study: The authors need to clearly define the primary objective of their research. Is it to showcase the computational advantages of the local learning rule, or to elucidate biological functions?</p>
</disp-quote>
<p>We have explicitly stated our goal in the introduction (page 4, lines 19-22). Please also see the response to reviewer 1.</p>
<disp-quote content-type="editor-comment">
<p>i. Computational Advantage: If the intent is to demonstrate computational advantages, the current experimental results appear inadequate. The learning rule introduced in this work can only solve for four features, whereas previous research (e.g., Bicknell and Hausser, 2021) has shown capability with over 100 features. It is crucial for the authors to extend their demonstrations to prove that their learning rule can handle more than just three features. Furthermore, the requirement to fine-tune the midpoint of the synapse function indicates that the rule modifies the &quot;activation function&quot; of the synapses, as opposed to merely adjusting synaptic weights. In machine learning, modifying weights directly is typically more efficient than altering activation functions during learning tasks. This might account for why the current learning rule is restricted to a limited number of tasks. The authors should critically evaluate whether the proposed local learning rule, including meta-plasticity, actually offers any computational advantage. This evaluation is essential to understand the practical implications and effectiveness of the proposed learning rule.</p>
</disp-quote>
<p>Thank you for your feedback. To address the concern regarding feature complexity, we extended our simulations to include learning with 9 and 25 features, achieving accuracies of 80% and 75%, respectively (Figure 6—figure supplement 1A). While our results demonstrate effective performance, the absence of external stabilizers—such as error-modulated functions used in prior studies like Bicknell and Hausser (2021)—means that the model's performance can be more sensitive to occasional incorrect outcomes. For instance, while accuracy might reach 90%, a few errors can significantly affect overall performance due to the lack of mechanisms to stabilize learning.</p>
<p>In order to clarify the setup of the rule, we have added pseudocode in the revised manuscript (Pages 31-32) detailing how the learning rule and metaplasticity update synaptic weights based on calcium and dopamine signals. Additionally, we have included pseudocode for the inhibitory learning rule on Pages 34-35. In future work, we also aim to incorporate biologically plausible mechanisms, such as dopamine desensitization, to enhance stability.</p>
<disp-quote content-type="editor-comment">
<p>ii. Biological Significance: If the goal is to interpret biological functions, the authors should dig deeper into the model behaviors to uncover their biological significance. This exploration should aim to link the observed computational features of the model more directly with biological mechanisms and outcomes.</p>
</disp-quote>
<p>As now clearly stated in the introduction, the goal of the study is to see whether and to what quantitative extent the theoretical solution of the NFBP proposed in Tran-Van-Minh et al. (2015) can be achieved with biophysically detailed neuron models and with a biologically inspired learning rule. The problem has so far been solved with abstract and phenomenological neuron models (Schiess et al., 2014; Legenstein and Maass, 2011) and also with a detailed neuron model but with a precalculated voltage-dependent learning rule (Bicknell and Häusser, 2021).</p>
<p>We have also tried to better explain the model mechanisms by adding supplementary figures.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p>
<p>Minor:</p>
<p>(1) The [Ca]NMDA in Figure 2A and 2C can have large values even when very few synapses are activated. Why is that? Is this setting biologically realistic?</p>
</disp-quote>
<p>The elevated [Ca²⁺]NMDA with minimal synaptic activation arises from high spine input resistance, small spine volume, and NMDA receptor conductance, which scales calcium influx with synaptic strength. Physiological studies report spine calcium transients typically up to ~1 μM (Franks and Sejnowski 2002, DOI: 10.1002/bies.10193), while our model shows ~7 μM for 0.625 nS and around ~3 μM for 0.5 nS, exceeding this range. The calcium levels of the model might therefore be somewhat high compared to biologically measured levels - however, this does not impact the learning rule, as the functional dynamics of the rule remain robust across calcium variations.</p>
<disp-quote content-type="editor-comment">
<p>(2) In the distributed synapses session, the study introduces two new mechanisms &quot;Threshold spillover&quot; and &quot;Accumulative spillover&quot;. Both mechanisms are not basic concepts but quantitative descriptions of them are missing.</p>
</disp-quote>
<p>Thank you for your feedback. Based on the recommendations from Reviewer 1, we have simplified the paper by removing the &quot;Accumulative spillover&quot; and focusing solely on the &quot;Thresholded spillover&quot; mechanism. In the updated version of the paper, we refer to it only as glutamate spillover. However, we acknowledge (page 22, lines 40-42) that to create sufficient non-linearities, other mechanisms, like structural plasticity, might also be involved (although testing this in the model will have to be postponed to future work).</p>
<disp-quote content-type="editor-comment">
<p>(3) The learning rule achieves moderate performance when feature-relevant synapses are organized in pre-designed clusters, but for more general distributed synaptic inputs, the model fails to faithfully solve the simple task (with its performance of ~ 75%). Performance results indicate the learning rule proposed, despite its delicate design, is still inefficient when the spatial distribution of synapses grows complex, which is often the case on biological neurons. Moreover, this inefficiency is not carefully analyzed in this paper (e.g. why the performance drops significantly and the possible computation mechanism underlying it).</p>
</disp-quote>
<p>The drop in performance when using distributed inputs (to a mean performance of 80%) is similar to the mean performance in the same situation in Bicknell and Hausser (2021), see their Fig. 3C. The drop in performance is due to that: i) the relevant feature combinations are not often colocalized on the same dendrite so that they can be strengthened together, and ii) even if they are, there may not be enough synapses to trigger the supralinear response from the branch spillover mechanism, i.e. the inputs are not summated in a supralinear way (Fig. 6B, most input configurations only reach 75%).</p>
<p>Because of this, at most one relevant feature combination can be learned. In the several cases when the random distribution of synapses is favorable for both relevant feature combinations to be learned, the NFBP is solved (Figs. 6B, some performance lines reach 100 % and 6C, example of such a case). We have extended the relevant sections of the paper trying to highlight the above mentioned mechanisms.</p>
<p>Further, the theoretical results in Tran-Van-Minh et al. 2015 already show that to solve the NFBP with supralinear dendrites requires features to be pre-clustered in order to evoke the supralinear dendritic response, which would activate the soma. The same number of synapses distributed across the dendrites i) would not excite the soma as strongly, and ii) would summate in the soma as in a point neuron, i.e. no supralinear events can be activated, which are necessary to solve the NFBP. Hence, one doesn’t expect distributed synaptic inputs to solve the NFBP with any kind of learning rule.</p>
<disp-quote content-type="editor-comment">
<p>(4) Figure 5B demonstrates that on average adding inhibitory synapses can enhance the learning capabilities to solve the NFBP for different pattern configurations (2, 3, or 4 features), but since the performance for excitatory-only setup varies greatly between different configurations (Figure 4B, using 2 or 3 features can solve while 4 cannot), can the results be more precise about whether adding inhibitory synapses can help improve the learning with 4 features?</p>
</disp-quote>
<p>In response to the question, we added a panel to Figure 5B showing that without inhibitory synapses, 5 out of 13 configurations with four features successfully learn, while with inhibitory synapses, this improves to 7 out of 13. Figure 5—figure supplement 1B provides an explanation for this improvement: page 18 line 10-24</p>
<disp-quote content-type="editor-comment">
<p>(5) Also, in terms of the possible role of inhibitory plasticity in learning, as only on-site inhibition is studied here, can other types of inhibition be considered, like on-path or off-path? Do they have similar or different effects?</p>
</disp-quote>
<p>This is an interesting suggestion for future work. We observed relevant dynamics in Figure 6A, where inhibitory synapses increased their weights on-site when randomly distributed. Previous work by Gidon and Segev (2012) examined the effects of different inhibitory types on NMDA clusters, highlighting the role of on-site and off-path inhibition in shunting. In our context, on-site inhibition in the same branch, appears more relevant for maintaining compartmentalized dendritic processing.</p>
<disp-quote content-type="editor-comment">
<p>(6) Figure 6A is mentioned in the context of excitatory-only setup, but it depicts the setup when both excitatory and inhibitory synapses are included, which is discussed later in the paper. A correction should be made to ensure consistency.</p>
</disp-quote>
<p>We have updated the figure and the text in order to make it more clear that simulations are run both with and without inhibition in this context (page 21 line 4-13)</p>
<disp-quote content-type="editor-comment">
<p>(7) In the &quot;Ca and kernel dynamics&quot; plots (Fig 3,5), some of the kernel midlines (solid line) are overlapped by dots, e.g. the yellow line in Fig 3D, and some kernel midlines look like dots, which leads to confusion. Suggest to separate plots of Ca and kernel dynamics for clarity.</p>
</disp-quote>
<p>The design of the figures has been updated to improve the visibility of the calcium and kernel dynamics during training.</p>
<disp-quote content-type="editor-comment">
<p>(8) The formulations of the learning rule are not well-organized, and the naming of parameters is kind of confusing, e.g. T_min, T_max, which by default represent time, means &quot;Ca concentration threshold&quot; here.</p>
</disp-quote>
<p>The abbreviations of the thresholds  ( T<sub>min</sub>,  T<sub>max</sub> in the initial version) have been updated to CTL and CTH, respectively, to better reflect their role in tracking calcium levels. The mathematical formulations have further been reorganized for better readability. The revised Methods section now follows a more structured flow, first explaining the learning mechanisms, followed by the equations and their dependencies.</p>
</body>
</sub-article>
</article>