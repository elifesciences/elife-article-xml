<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">103701</article-id>
<article-id pub-id-type="doi">10.7554/eLife.103701</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.103701.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.3</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Beyond gradients: Factorized, geometric control of interference and generalization</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6128-1721</contrib-id>
<name>
<surname>Scott</surname>
<given-names>Daniel N</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
<email>dnscott87@gmail.com</email>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8451-0523</contrib-id>
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Department of Neuroscience, Brown University</institution></institution-wrap>, <city>Providence</city>, <country>United States</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Department of Cognitive and Psychological Sciences, Brown University</institution></institution-wrap>, <city>Providence</city>, <country>United States</country></aff>
<aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Carney Institute for Brain Science, Brown University</institution></institution-wrap>, <city>Providence</city>, <country>United States</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Zenke</surname>
<given-names>Friedemann</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Friedrich Miescher Institute for Biomedical Research</institution>
</institution-wrap>
<city>Basel</city>
<country>Switzerland</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Behrens</surname>
<given-names>Timothy E</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Oxford</institution>
</institution-wrap>
<city>Oxford</city>
<country>United Kingdom</country>
</aff>
</contrib>
</contrib-group>
<pub-date date-type="original-publication" iso-8601-date="2024-12-11">
<day>11</day>
<month>12</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP103701</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-10-10">
<day>10</day>
<month>10</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-09-23">
<day>23</day>
<month>09</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2021.11.19.466943"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Scott &amp; Frank</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Scott &amp; Frank</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-103701-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Interference and generalization, which refer to counter-productive and useful interactions between learning episodes, respectively, are poorly understood in biological neural networks. Whereas much previous work has addressed these topics in terms of specialized brain systems, here we investigated how learning rules should impact them. We found that plasticity between groups of neurons can be decomposed into biologically meaningful factors, with factor geometry controlling interference and generalization. We introduce a “coordinated eligibility theory” in which plasticity is determined according to products of these factors, and is subject to surprise-based metaplasticity. This model computes directional derivatives of loss functions, which need not align with task gradients, allowing it to protect networks against catastrophic interference and facilitate generalization. Because the model’s factor structure is closely related to other plasticity rules, and is independent of how feedback is transmitted, it introduces a widely-applicable framework for interpreting supervised, reinforcement-based, and unsupervised plasticity in nervous systems.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>The previous versions of the manuscript emphasized connections with noise correlations and different aspects of biology, whereas the current version's is much more streamlined. Substantively, little has changed, although the current version does include demonstrations of our fundamental ideas in terms of supervised learning (with RL moved to the supplement), along with metaplasticity mechanisms for controlling factor geometry.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>When animals learn new skills they often generalize prior learning, and rarely forget or degrade it (<xref ref-type="bibr" rid="c7">Dekker <italic>et al</italic>.2022</xref>; <xref ref-type="bibr" rid="c14">Franklin &amp; Frank 2018</xref>; <xref ref-type="bibr" rid="c17">Ghirlanda &amp; Enquist 2003</xref>; <xref ref-type="bibr" rid="c40">Tenenbaum &amp; Griffiths 2001</xref>; <xref ref-type="bibr" rid="c39">Shepard 1987</xref>). How biological neural networks support these capacities, including whether and how plasticity rules do, remains poorly understood. For example, previous work has typically addressed interference (memory degradation) and generalization (constructive re-use) using divisions of labor across large scale brain networks (<xref ref-type="bibr" rid="c34">Schapiro <italic>et al</italic>. 2017</xref>; <xref ref-type="bibr" rid="c31">O’Reilly &amp; Norman 2002</xref>; <xref ref-type="bibr" rid="c27">Mcclelland <italic>et al</italic>. 1995</xref>; <xref ref-type="bibr" rid="c13">Frank &amp; Badre 2012</xref>; Niv <italic>et al</italic>. 2015; <xref ref-type="bibr" rid="c32">Rougier <italic>et al</italic>. 2005</xref>; <xref ref-type="bibr" rid="c4">Collins &amp; Frank 2013</xref>; <xref ref-type="bibr" rid="c12">Flesch <italic>et al</italic>. 2021</xref>) leaving open the question of how local plasticity rules do or don’t impact such outcomes. Computational work on biological plasticity, by contrast, has often focused on understanding how biology relates to gradient descent (via error backpropagation) in artificial neural networks (<xref ref-type="bibr" rid="c45">Zenke &amp; Ganguli 2018</xref>; Bellec <italic>et al</italic>. 2020; <xref ref-type="bibr" rid="c25">Liu <italic>et al</italic>. 2021</xref>), or how it might perform unsupervised functions like feature detection (<xref ref-type="bibr" rid="c2">Bienenstock <italic>et al</italic>. 1982</xref>). Many empirical studies show, however, that in-vivo plasticity impacts interference and generalization, with cellular and dendritic excitability modulation appearing particularly important in this regard (<xref ref-type="bibr" rid="c3">Cichon &amp; Gan 2015</xref>; Yang <italic>et al</italic>. 2014; Sehgal, Filho, <italic>et al</italic>. 2021). We address these sorts of mechanisms theoretically here.</p>
<p>We approached the question of how plasticity impacts interference and generalization (examples in <xref rid="fig1" ref-type="fig">figure 1A-C</xref>) by examining neural network loss gradients. We observed that, mathematically, gradients can be decomposed into analogues of population response changes and receptive-field re-weightings, and that interference and generalization are functions of these changes (<xref rid="fig1" ref-type="fig">figure 1D-E</xref>). The population responses in this formulation are layer-wise (or “local”) neural response patterns, whereas the receptive fields specify the relative sensitivities of an individual neuron to different input patterns. To make these two concepts more concrete, consider two neurons that initially respond proportionally to a stimulus. If one then increases its firing rate relative to the other, we would refer to this as a change in population response to that stimulus. If, instead, each maintains its response relative to the other but shifts which features drive that response, we would refer to these as purely receptive field changes (for each neuron).</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><p>Conceptual overview of this work. (A) Animals have goals, which they must learn to achieve. In this case, consider revising a paper. (B) Some feedback signals (e.g., from reviewers or co-authors) will conflict with one another. An appropriate way to deal with these conflicts is to integrate over learning signals, averaging out noise and clarifying signal (upper arrow). A poor way to deal with conflict is to completely adhere to all feedback, even when it conflicts with other feedback (lower arrow), i.e., to perform sequential gradient descent, which can result in undoing previous learning, rather than reconciling new learning with old. (C) A related situation arises when contextual information suggests generalizing learning. For example, recognizing that two types of feedback reflect the same principle can support learning based on the principle (upper arrow) rather than solely the particulars of the feedback (lower arrow), generalizing learning. (D) Within a network, regularizing plasticity towards particular activity subspaces (which can be shared across contexts) and minimizing the overlap of these subspaces when they interfere, can accomplish these goals. (E) Examining gradient descent, we observe that “input” and “output” or “receptive field” and “population response” factors in a network layer’s plasticity partition this plasticity into subspaces. (F) We explore the idea that independently controlling these two biologically meaningful factors (using functions u and v in the panel) would be useful for avoiding interference and promoting generalization. (G) Example of two tasks that overlap in either RFs (bottom) or PRs(top). (H) We investigate four different scenarios, showing that managing population-response and receptive-field plasticity can avoid interference and promote generalization. (I) These properties result from the fact that coordinating plasticity factors can take arbitrary paths through weight space, whereas gradients always move directly towards individual tasks’ solutions.</p></caption>
<graphic xlink:href="466943v3_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Notably, distinct biological processes can control population response and receptive field plasticity and, thereby, network function (for example, <xref ref-type="bibr" rid="c3">Cichon &amp; Gan 2015</xref>; Sehgal, Filho, <italic>et al</italic>. 2021). We thus developed a “coordinated eligibility” theory (<xref rid="fig1" ref-type="fig">figure 1D,F</xref>), in which structured population-response (PR) and receptive-field (RF) eligibility formed the building blocks of network plasticity. (“Eligibility” refers to the capacity for plasticity, as distinguished from realized plasticity). This theory is closely related to other biological plasticity theories, including three-factor rules (<xref ref-type="bibr" rid="c42">Williams 1992</xref>; <xref ref-type="bibr" rid="c11">Fiete &amp; Seung 2006</xref>; <xref ref-type="bibr" rid="c19">Izhikevich 2007</xref>; <xref ref-type="bibr" rid="c10">Farries &amp; Fairhall 2007</xref>; <xref rid="c4" ref-type="bibr">Frémaux, Sprekeler, <italic>et al</italic>. 2013</xref>), the BCM model (<xref ref-type="bibr" rid="c2">Bienenstock <italic>et al</italic>. 1982</xref>), and two-threshold calcium theories (<xref ref-type="bibr" rid="c9">Evans &amp; Blackwell 2015</xref>), supporting its plausibility and making it applicable to understanding these. By exposing tunable parameters of plasticity, which facilitate holistic function, it provides an account of how local plasticity might avoid problems deriving from the memorylessness, and local (rather than global) optimality of gradient descent.</p>
<p>Our mathematical results establish the power and relevance of coordinated eligibility models to in-vivo plasticity, and our simulations provide a further foundation for understanding them. Because we identify two mechanisms for managing between-task learning interactions, and these interactions can be either constructive or destructive, there is a natural set (2×2) of asymptotic network conditions to investigate (<xref rid="fig1" ref-type="fig">figure 1H</xref>). Our first four simulations address these cases, using a form of surprise-based metaplasticity to structure population-response and receptive-field changes. In line with our mathematical results, they detail how networks can avoid interference and promote generalization, by projecting population-response or receptive-field changes onto distinct or shared subspaces between tasks. As we show, performing these projections overcomes various limitations of learning strictly via gradient descent, by learning along directional derivatives of task losses (<xref rid="fig1" ref-type="fig">figure 1I</xref>). In this context we find that forgetting and incorrect generalization are inversely related, and that this can be understood in terms of the weight geometry of task solutions. Whereas these initial simulations focused on control of either PR or RFs independently, our fifth simulation consider a case in which PR and RF eligibilities are yoked, finding that they allow powerful forms of dimensionality reduction to be embedded in plasticity rules themselves. Together, these results provide an account of interference and generalization in terms of two fundamental biological components, in a framework that can be applied to investigate unsupervised, reinforcement-based, or supervised plasticity in the brain.</p>
</sec>
<sec id="s2">
<title>Results</title>
<p>We present our results in a mathematical section and several simulation sections. In the mathematical section we define our basic neural network model and we ask how interference and generalization between tasks are related to weight changes. We find that we can decompose interference and generalization according to “receptive field” (RF) and “population response” (PR) factors of plasticity for each neural network layer. We then formulate our coordinated eligibility theory in terms of these factors. Next, to quantify the impact of coordinated eligibility on task performance, we consider networks which leverage unsupervised metaplasticity to coordinate input and response plasticity components, and we compare them to gradient descent. To do so, we simulate a series of supervised learning problems, aimed at probing the degrees of freedom introduced by the factorized, geometric form of the coordinated eligibility theory. Notably, determining when and where to apply different sorts of metaplasticity is not our goal. Nonetheless, our simulations show how coordinating input plasticity, response plasticity, or both, can effectively avoid interference and promote generalization. Our fifth simulation also initiates work on a fundamentally new direction, that of composing gradient projections according to representational structure across layers, which may facilitate functions such as compositional learning.</p>
<sec id="s2a">
<title>Weight gradients factorize into population-response and receptive-field changes</title>
<p>We consider neural networks performing sequences of tasks. The neural networks are standard multi-layer perceptrons, with layers defined by the equation:
<disp-formula id="ueqn1">
<graphic xlink:href="466943v3_ueqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Each layer output <italic>y</italic> is sum of inputs <italic>x</italic> weighted according to matrix <italic>w</italic>, subject to activation function <italic>ϕ</italic>. We define task performance in terms of loss functions denoted <italic>L</italic>. Here we use a supervised learning paradigm, making these losses explicit, but our results apply equally to reinforcement learning and unsupervised settings, where one can often consider learning in terms of implicit loss functions (indeed we demonstrate analogous effects in RL contexts in the appendices, together with a fuller explanation of the application to RL).</p>
<p>The gradient of network parameters with respect to a loss can be computed using the chain rule:
<disp-formula id="eqn1">
<graphic xlink:href="466943v3_eqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
This equation is summed over all indices. Performing some partial sums, as shown explicitly in the appendix, gives an outer-product in terms of a column vector <italic>g</italic> and the layer’s input <italic>x</italic>:
<disp-formula id="eqn2">
<graphic xlink:href="466943v3_eqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
In this equation the column vector <italic>g</italic> summarizes how <italic>y</italic> should change, given input <italic>x</italic>, for the loss to change maximally. The matrix <italic>D</italic><sub><italic>ϕ</italic></sub> is a diagonal matrix of the local slopes of <italic>ϕ</italic> at each component of <italic>z</italic>. The gradient of the loss with respect to <italic>y</italic> (the term <italic>dL/dy</italic>) captures how downstream processing makes use of the local post-synaptic firing rates, ultimately manifesting in a loss value. In the reinforcement learning and unsupervised cases, this <italic>g</italic> is typically accumulated through experience, whereas supervision and backpropagation implicitly determine it. This representation of the gradient is striking in relation to neuroscience, because the <italic>x</italic> vector denotes how a given neuron’s inputs should be re-weighted (i.e., plasticity of dendritic processes and receptive fields), whereas the <italic>g</italic> vector denotes how a layer of neurons’ collective output is changed (i.e., plasticity of population response patterns). In particular, this parallels the fact that individual neurons can independently exhibit both gain (or excitability) changes and re-weighting of their inputs (see, for example, <xref ref-type="bibr" rid="c3">Cichon &amp; Gan 2015</xref>; <xref rid="c44" ref-type="bibr">Yang <italic>et al</italic>. 2014</xref>; <xref rid="c38" ref-type="bibr">Sehgal, Filho, <italic>et al</italic>. 2021</xref>; <xref ref-type="bibr" rid="c36">Scott &amp; Frank 2022</xref>). As such, processing can change when population responses change, inputs are re-weighted with respect to one-another, or both. For example, a weight change Δ<italic>w</italic> = <italic>uv</italic><sup><italic>T</italic></sup>, can involve input reweighting (changes in the row space of <italic>w</italic> arising from <italic>v</italic>), population response changes (differences in the column space of <italic>w</italic> arising from <italic>u</italic>) or both. We hypothesized that this would allow interference and generalization between tasks to be managed at these two distinct loci, and we show that this is the case below.</p>
</sec>
<sec id="s2b">
<title>Gradient factors determine interference and generalization</title>
<p>For a weight change to impact performance, by definition, it must have a non-zero inner product with the gradient of a loss. Indeed, the loss gradient is defined to be the direction in weight space along which that loss increases maximally. Hence an orthogonal change in weights (i.e., in the loss’ null-space) will neither increase nor decrease the loss. If we consider two rank-1 weight changes that are outer products (such as gradients for two tasks), denoted <inline-formula><inline-graphic xlink:href="466943v3_inline1.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <inline-formula><inline-graphic xlink:href="466943v3_inline2.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, then these have an inner product:
<disp-formula id="eqn3">
<graphic xlink:href="466943v3_eqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
This equation shows that both the input and population response components of plasticity must overlap for interference or generalization to occur. Intuitively, gradient updates interfere with one another when they change network responses to the same input in opposite ways, for example when <italic>u</italic><sub>1</sub> = <italic>g</italic><sub>1</sub> = −<italic>g</italic><sub>2</sub> = <italic>u</italic><sub>2</sub> and <italic>v</italic><sub>1</sub> = <italic>x</italic><sub>1</sub> = <italic>x</italic><sub>2</sub> = <italic>v</italic><sub>2</sub>. Updates generalize across tasks when they change the network in similar ways, such as when <italic>u</italic><sub>1</sub> = <italic>g</italic><sub>1</sub> ∝ <italic>g</italic><sub>2</sub> = <italic>u</italic><sub>2</sub> and <italic>v</italic><sub>1</sub> = <italic>x</italic><sub>1</sub> = <italic>x</italic><sub>2</sub> = <italic>v</italic><sub>2</sub>. Both situations are illustrated in <xref rid="fig2" ref-type="fig">figure 2A</xref>, using the minimal example of trying to learn two conflicting (non-proportional) input-output mappings using one input and one output neuron (see the caption for further details). In multi-dimensional networks, interference occurs when weights are changed in opposite directions by receptive field plasticity, population response plasticity, or both. These situations are illustrated in <xref rid="fig2" ref-type="fig">figure 2B</xref> and <xref rid="fig2" ref-type="fig">2C</xref>, and described further in the caption. Note, however, that if a network only changes responses to two completely distinct stimuli, as when <italic>v</italic><sub>1</sub> · <italic>v</italic><sub>2</sub> = <italic>x</italic><sub>1</sub> · <italic>x</italic><sub>2</sub> = 0, then no interference occurs. The same is true when the stimuli themselves are identical, but their processing is completely segregated.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><p>Illustrations of interference from PR and RF plasticity. (A) A simple linear network, with one input neuron (x), one response neuron (y), and a loss function (L). If an input <italic>x</italic> has a target output <italic>y</italic><sup>∗</sup>(1) for one task, and <italic>y</italic><sup>∗</sup>(2) for a second, then alternating training will pull the weight connecting <italic>x</italic> and <italic>y</italic> in opposite directions. Notice that if the output activity started on one side of both <italic>y</italic><sup>∗</sup>(1) and <italic>y</italic><sup>∗</sup>(2), then there would first be a period of generalization, during which performance improved on both tasks while training either one. In the lower panel, showing weight/activity dynamics over time, these regions of the weight/activity space are denoted with + and -symbols indicating generalization and interference, and the task-solutions are denoted with dashed lines. The basic illustration is also representative of higher dimensional cases; in more complex networks the main question is how these phenomena are distributed over groups of neurons and weights, instead of individual ones, and multiple tasks, instead of task pairs. (B) A network with two inputs, illustrating RF-change induced interference. Here, training changes weights in two dimensions generating a pattern of regions of interference and generalization based on current weights and the angles between task solutions. Lower left panel:Gradient descent is subject to the same oscillatory behavior in the interference-producing region between task solutions. Lower right panel:By restricting weight update dimensions, one can avoid interference. (C) A network with two outputs, illustrating PR-change induced interference, analogous to B.</p></caption>
<graphic xlink:href="466943v3_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2c">
<title>Coordinating eligibility controls learning interactions</title>
<p>Observing the facts above about gradients, interference, and generalization, along with the many biological plasticity controllers, we formalize a coordinated eligibility theory of plasticity. Note that “eligibility” refers to the capacity for plasticity, whereas plasticity refers to synaptic weight (and hence network) change itself. In this theory, plasticity takes the form:
<disp-formula id="eqn4">
<graphic xlink:href="466943v3_eqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Here, <italic>u</italic> and <italic>v</italic> are generic vectors, <italic>α</italic> is a scalar, and <italic>i</italic> is an index with an arbitrary range.</p>
<p>Many specific forms of plasticity are instances of <xref ref-type="disp-formula" rid="eqn4">equation (4)</xref>. For example, when there are as many terms <italic>i</italic> as synapses, and <italic>u</italic><sub><italic>i</italic></sub> and <italic>v</italic><sub><italic>i</italic></sub> are arbitrary, we can capture every possible weight update. When <italic>i</italic> = 1, <italic>u</italic> = −<italic>g</italic> and <italic>v</italic> = <italic>x</italic> we recover gradient descent. Other choices interpolate between these two extremes of flexibility, and other canonical models can also be described using <xref ref-type="disp-formula" rid="eqn4">equation (4)</xref>. Setting <italic>i</italic> = 1, <inline-formula><inline-graphic xlink:href="466943v3_inline3.gif" mime-subtype="gif" mimetype="image"/></inline-formula> (with <italic>r</italic> denoting “reward”), <inline-formula><inline-graphic xlink:href="466943v3_inline4.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, and <italic>v</italic> = <italic>x</italic> gives a REINFORCE algorithm (<xref ref-type="bibr" rid="c42">Williams 1992</xref>), which can approximate gradient descent by estimating <italic>g</italic> over time. Specifically, in this latter case, population response variability drives sample-based integration of the gradient term (<italic>α</italic> and <inline-formula><inline-graphic xlink:href="466943v3_inline5.gif" mime-subtype="gif" mimetype="image"/></inline-formula> combine in expectation to form <italic>g</italic>). By generalizing this classic REINFORCE model to use non-isotropic sampling (Cov(Δ<italic>y</italic>) ≠ <italic>I</italic>), one arrives at a coordinated eligibility model that effectively projects <italic>g</italic>, which can have much lower sample complexity, along with some of the geometric properties we discuss here.</p>
<p>More broadly, a reasonable set of models to consider might take <italic>α, u</italic>, and <italic>v</italic>, to be functions of <italic>g</italic> (without necessarily requiring <italic>g</italic> to be known explicitly) and <italic>x</italic>, the weight update to have many fewer degrees of freedom than <italic>n</italic>× <italic>m</italic> for <italic>w</italic> ∈<italic>R</italic><sup><italic>n×m</italic></sup>, and the update itself to be distinct from the loss gradient of some task at hand. We investigate several such models below. Specifically, in our simulations we take <italic>α</italic> to be 1, and the factors <italic>u</italic> and <italic>v</italic> to be functions of the gradient components <italic>g</italic> and <italic>x</italic>. These gradient components are projected onto different subspaces according to task demands by matrices <italic>P</italic> and <italic>Q</italic>, and normalized (projected onto the unit sphere via transform <italic>S</italic>). Mathematically:
<disp-formula id="eqn5">
<graphic xlink:href="466943v3_eqn5.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
This is one of the simplest coordinated eligibility models, but is flexible enough to avoid interference and promote generalization. Specifically, neglecting some technicality related to normalization, the inner product between two weight updates (with subscripts 1 and 2) will then be:
<disp-formula id="eqn6">
<graphic xlink:href="466943v3_eqn6.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The column spaces (or, roughly, outputs) of the transformation matrices can therefore be used to increase or decrease either quantity in parentheses.</p>
<p>There are many ways these transformations could be manipulated biologically, but we observe that simple, surprise-based, unsupervised metaplasticity can manage interference and generalization. (Both unsupervised and surprised based metaplasticity are well established empirically. See, for example, <xref rid="c43" ref-type="bibr">Yagishita <italic>et al</italic>. 2014</xref>; <xref ref-type="bibr" rid="c20">Jaskir &amp; Frank 2021</xref>; <xref ref-type="bibr" rid="c36">Scott &amp; Frank 2022</xref>) In our simulations below, networks compute surprise over inputs and feedback signals, in order to determine when and how to change the transforms <italic>P</italic> and <italic>Q</italic>. This allows them to perform patternseparation (in the high-surprise case) or integration-based coarse-coding (in the low-surprise case) of plasticity components <italic>u</italic> and <italic>v</italic>, by progressively removing dimensions from the column spaces of <italic>P</italic> and <italic>Q</italic>.</p>
</sec>
<sec id="s2d">
<title>Pattern-separating receptive field plasticity reduces interference</title>
<p>To quantify the impacts of coordinating eligibility, we first simulated one of the simplest continual learning problems, online linear regression. Simulating a linear regression problem had the advantages of allowing us to use an easy-to-understand linear neural network, and therefore to compare the network’s solution at each time to the true (minimum norm) solution in terms of both the network’s function and its weights. We demonstrate below that our coordinated eligibility model converges to the true optimal solution for the whole curriculum, whereas gradient descent does not (despite learning locally optimal solutions for each task, sequentially). By comparing plasticity models, this analysis also reveals important properties of both learning algorithms.</p>
<p>Our linear regression problem was composed of 80 input-output associations (“tasks”) with 100-dimensional unit-normal input vectors and 20-dimensional unit-normal target vectors, drawn at uniform angles (<xref rid="fig3" ref-type="fig">figure 3A-3B</xref>). These pairs were learned completely and sequentially in one sweep through the data (<xref rid="fig3" ref-type="fig">figure 3C</xref>), using either gradient descent or the coordinated eligibility model. A sweep was defined as reduction of the RMSE for a task from an initial value of 1 to a criterion value of 0.05. Mathematically, this resulted in neural networks approximately solving the ordinary least squares regression equations:
<disp-formula id="ueqn2">
<graphic xlink:href="466943v3_ueqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><p>Receptive-field eligibility separation. (A) The network we used was single linear perceptron layer, with a single readout. (B) Tasks in this simulation were each defined by random, unit-normal, 100 dimensional input vectors and similarly distributed 20 dimensional target vectors. (C) Training was performed sequentially over 80 such tasks. When outputs were within 0.05 units of Euclidean distance of targets, training proceeded to the next task. (D) Networks computed surprise over inputs, which was used to determine task change-points and orthogonalize new input plasticity vectors against previous plasticity. (E) The surprise function used was a logistic curve over input cosine angle. (F) The optimal set of weights for the curriculum was computed, for comparison with network outputs, using the pseudo-inverse of the inputs. Intuitively, the solution is the intersection of individual task solutions, which themselves are rank-1 outer products between the (unit normal) inputs and targets, shown here as lines intersecting a unit sphere. (G) Error on each task, computed after training that task. (H) Backward transfer on each task, i.e. task errors at the end of curriculum training. (I) Initial task error on new tasks at each point in curriculum learning (forward transfer). The CEM shows negative transfer related to the fact that it remembers previous inputs, whereas this is reduced, but still present, for GD. (J) Layer weight norms in both models, over the course of learning. CEM weight norms grew over the course of learning to match the optimal network weight norm, given by the dashed red line, whereas GD does not. GD struggles to leave a region of weight space proximal to all individual task solutions, but not their intersection. (I) Distance from the optimal set of weights, indicating that not only is the weight norm of the CEM solution growing properly, the network is also converging to the optimum rather than diverging in an inappropriate direction. By contrast, GD gets further from the curriculum solution over time.</p></caption>
<graphic xlink:href="466943v3_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>The minimal norm solution (and hence the optimal network weight matrix) is given via a multiplication of T (a matrix of target vectors) by the pseudo-inverse of <italic>X</italic> (a matrix of input vectors):
<disp-formula id="ueqn3">
<graphic xlink:href="466943v3_ueqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
This equation is appropriate regardless of the number of tasks (columns of T and X) the network has seen, and therefore defines an optimal solution after every individual task is learned.</p>
<p>To solve this problem, we simulated a single-headed, single-layer linear network with a squared-error loss. (We also obtain similar results in reinforcement learning simulations using categorical action choice, cross-entropy loss, and nonlinear activation functions, however, which we discuss in the appendices.) In this setting the transformation from weights to a loss value has a large null space, meaning many weights are compatible with solving the task (which is why the weight matrix is a pseudo-inverse rather than an inverse). As a result, upon learning the first input-output pair, the weights “listening to” every other input dimension are free to vary, because the first input has no projection along these. Each of these additional dimensions is constrained only once it is associated with an input, and a learning algorithm can therefore proceed by “listening” only to unique dimensions in new inputs (learning with orthogonal input plasticity vectors <italic>u</italic>) to avoid interference. Given these observations, we set the network’s surprise-based metaplasticity to detect input change-points (using the surprise function in <xref rid="fig3" ref-type="fig">figure 3E</xref>), and to progressively remove dimensions of input plasticity when these change-points occurred (<xref rid="fig3" ref-type="fig">figure 3D</xref>). How and when networks would know to use this exact form of metaplasticity is an interesting open question, but we introduce it here to demonstrate our points about the geometry of our plasticity factors. We expected this geometry to produce a path toward the optimal solution in weight space that would stay within the solution manifolds identified for previously learned tasks (<xref rid="fig3" ref-type="fig">figure 3F</xref>).</p>
<p>We compared the properties of our coordinated eligibility model with gradient descent by examining training error, forward and backward transfer, and network weights, averaged over 200 simulations (<xref rid="fig3" ref-type="fig">figure 3G-K</xref>). Training error at the end of training for each task was consistently just below criterion, per expectations, with the margin decreasing over task number, consistent with networks taking steps which were less direct relative to gradients as fewer dimensions of the input space became available for learning (<xref rid="fig3" ref-type="fig">figure 3G</xref>). Backward transfer was assessed by testing each task after training the entire curriculum. Networks using gradient descent completely unlearned task 1 by this time, and showed graded forgetting as a function of time-since training for each task (<xref rid="fig3" ref-type="fig">figure 3F</xref>). By contrast, the coordinated eligibility model showed minimal interference (<xref rid="fig3" ref-type="fig">figure 3H</xref>). We also observed that both gradient descent and the CEM introduced significant negative forward transfer (<xref rid="fig3" ref-type="fig">figure 3I</xref>). That is, solving tasks made the initial, untrained error on new tasks larger. This is expected, because each task defines a solution space of weight matrices, and the intersection of a set of these task solution spaces gets further from the origin as their number increases. Because the tasks were normalized, with unit-normal inputs and targets, predicting the 0 vector for new inputs will result in an error of 1, and the further from the origin new untrained task outputs are, the larger the initial error is likely to be. This led us to suspect that gradient-descent was under-fitting the data, and remained in the vicinity of the origin by virtue of moving directly towards each new task’s individual solution subspace.</p>
<p>To test this hypothesis about the nature of the forward transfer problem, we computed the norm of the network’s weights after completing every task, and similarly checked the distance from (curriculum) optimality at each point. We observed that the weight norms under gradient descent were consistently low, relative to the norm of the full solution, whereas the CEM weight norms grew to match this norm (<xref rid="fig3" ref-type="fig">figure 3J</xref>). Intuitively, this resulted in the gradient-based solution becoming more distant from the optimal solution as more tasks were completed (<xref rid="fig3" ref-type="fig">figure 3K</xref>).</p>
</sec>
<sec id="s2e">
<title>Pattern-separating population response plasticity reduces interference</title>
<p>Because of the symmetry of relationship (3) between population-response and receptive-field changes, interference and generalization can also be manipulated by changing population responses. Indeed, there are some data suggesting this may occur in the brain, with memories being increasingly segregated according to their distance in time as a result of (for example, CREB-based) excitability drift (Sehgal, Zhou, <italic>et al</italic>. 2018; <xref ref-type="bibr" rid="c24">Lisman <italic>et al</italic>. 2018</xref>). Here, we model a complementary (and analogous) situation to the previous simulation, involving population-response based pattern separation, using task-dependent readouts. We describe a pure form of this scenario below, in which interference can only be managed via population response plasticity, because network inputs don’t change. As such, our simulation is a model of purely contextual behavior, with context inferred based on network history.</p>
<p>Specifically, we simulate a continual learning scenario in which the input is constant, but target outputs change across tasks. To do so, we used a single linear layer with a constant scalar input and 100 response neurons (<xref rid="fig4" ref-type="fig">figure 4A</xref>). The response neurons were subject to a sequence of unit-random, 100 dimensional readout weights, one defined for each subsequent task, of which there were 80. Without loss of generality, each readout had a target response of 1, defining a 100 dimensional target at the layer output (<xref rid="fig4" ref-type="fig">figure 4B</xref>). Networks received each input, were trained to produce the paired target (up to an SSE of 0.05), and then were trained on subsequent input-target pairs, until the whole curriculum had been seen (4C). Mathematically, jointly solving all tasks in the curriculum is equivalent to solving the following equation for <italic>w</italic>:
<disp-formula id="eqn7">
<graphic xlink:href="466943v3_eqn7.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><p>Population-response eligibility separation. (A) These simulations used linear network layers subject to linear readouts, one for each task. (B) Each task is defined by a new random 100-dimensional readout. (C) Tasks are solved sequentially, to within a small error bound, as with the previous simulation, before a new random readout is drawn and applied to initiate learning a new task. (D) Updates to firing-rate response subspaces are orthogonalized based on surprise computed over feedback (gradient) components. (E) Surprise is computed as previously, using a logistic function over relative angles. (F) Optimal weights are analogous to those of the previous simulation. (G) Training error both networks completely solve each task in the curriculum. (H) Gradient descent shows significant forgetting, whereas the CEM does not. (I) Remembering earlier learning produces negative forward transfer, as previously. (J) GD fails to push weights outside the region around the origin, causing them to (K) become increasingly far from optimal as new tasks are seen.</p></caption>
<graphic xlink:href="466943v3_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>As with the simulation above, this is a standard linear regression problem. Applying a continual learning algorithm will therefore approximate the solution:
<disp-formula id="ueqn4">
<graphic xlink:href="466943v3_ueqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
To remove interference in this setting, networks computed surprise over feedback change-points (<xref rid="fig4" ref-type="fig">figure 4D</xref>), using a logistic curve over output-plasticity cosine similarity (i.e., in a manner analogous to the previous simulation) (<xref rid="fig4" ref-type="fig">figure 4E</xref>). As with the previous simulation, this surprise signal was used to orthogonalize ongoing plasticity from previous plasticity, following these change-points.</p>
<p>After training networks to solve this sequence of tasks, we observe that backward transfer again completely abolishes earlier learning under gradient descent (<xref rid="fig4" ref-type="fig">figure 4H</xref>). Here, too, we have averaged over simulations (400), and again, the coordinated eligibility model does not suffer from negative backward transfer (<xref rid="fig4" ref-type="fig">figure 4H</xref>). Forward transfer results are also analogous to the previous simulation (<xref rid="fig4" ref-type="fig">figure 4I</xref>), and appear to be explained by the same difference in the algorithms’ abilities to effectively leave the origin of the networks’ weight spaces (<xref rid="fig4" ref-type="fig">figure 4J-K</xref>). As with our previous simulations, we note that we obtained similar results in reinforcement learning simulations (also discussed in the appendices).</p>
</sec>
<sec id="s2f">
<title>Coarse-coding receptive field plasticity generalizes learning</title>
<p>A network that perfectly pattern separates all learning will completely avoid interference, at the potential cost of also removing positive transfer between tasks (i.e., generalization). By contrast, a network that coarse-codes or generalizes receptive field plasticity will produce generalized learning, while potentially risking negative transfer. In any given setting, there are therefore sets of desirable basis functions for receptive-field plasticity, and sets of undesirable ones. In the previous section, we addressed the removal of undesirable generalization (i.e., interference) by restricting plasticity, and in this section, we explore the promotion of desirable generalization via coarse-coding. In the pattern-separation simulations above, our network had a built-in assumption that inputs with sufficiently different angles represented different tasks, defining boundaries across which learning should be separated. However, there are many complementary situations in which superficially dissimilar states should instead be considered equivalent in a more abstract sense. This is typically studied in the context of state abstraction and task-set clustering across contexts in reinforcement learning <xref ref-type="bibr" rid="c23">Lehnert <italic>et al</italic>. 2020</xref>; <xref ref-type="bibr" rid="c4">Collins &amp; Frank 2013</xref>, whereby such abstraction is needed for generalization.</p>
<p>To motivate this situation, consider the case of object affordances. Many classes of objects are loosely defined by their uses, such that (for example) the category of mugs is a set of things one drinks from. Such uses create natural categories for generalizing learning. If we interpret a target network output as an action, use, or label, then the inputs which should prompt a given output can often be inferred by learning the input transformations which the target output is invariant to. For example, if I see several distinct mugs, I can note that those physical transformations taking one mug to another should generally leave their shared property of being open-top vessels intact; this will allow me to drink out of the transformed objects. Knowing this set of transformations will increase my ability to say which other sorts of objects might be mugs, and therefore to generalize inferences or associations over this class. In this case, learning (plasticity) could be coarse-coded by yoking receptive-field changes <italic>v</italic> (which represent changes to how mug features are detected) for a second labeling task over category members from the first (i.e., according to similarity over vectors <italic>u</italic>, representing the mug-category response). For example, by observing that I can’t drink coffee out of a particular floppy mug, I may be justified in learning that “can be floppy” is generally false for open-top-drinking-vessels broadly, and therefore other mugs specifically. A similar plasticity-component logic would apply in other generalization scenarios, and structurally equivalent forms of generalization have been studied empirically in state abstraction and task-set clustering situations <xref ref-type="bibr" rid="c6">Collins &amp; Frank 2016</xref>).</p>
<p>In analogy with this example, we simulated a continual learning problem in which object classes had (by definition) the same target outputs, and were seen in blocks. During the first block, networks learned one distinct target output for each group of inputs. We refer to this first block as an association block. Target similarity, computed as cosine angle, was then used to induce a similarity measure on inputs, which itself defined coarse-coded input plasticity in a subsequent block of trials (a generalization block). In this second block of trials, we model a new group of tasks using a separate regression head, and demonstrate that the coordinated eligibility model is able to effectively transfer learning within classes defined by the first block.</p>
<p>Concretely, we simulated two linear regression problems, using a network with 100 dimensional inputs, 20 dimensional outputs, and two readouts (<xref rid="fig5" ref-type="fig">figure 5A</xref>). All of these were random unit vectors (<xref rid="fig5" ref-type="fig">figure 5B</xref>). Inputs during the association task (“object exemplars”) were randomly paired (and hence had no intrinsic similarity), and pairs had the same associated target (“object property or class”). During the association curriculum, networks were trained to produce the correct target for each object, sequentially (<xref rid="fig5" ref-type="fig">figure 5C</xref>). Surprise was computed over targets (technically, population response feedback) to establish class-presentation change-points. Future receptive field plasticity was then coarse-coded over the inputs that had been seen during the previous low-surprise period (<xref rid="fig5" ref-type="fig">figure 5D</xref>). Subsequently, during a generalization task, new targets were generated for each existing pair of inputs, on a new readout (i.e., old inputs/classes were conserved) (<xref rid="fig5" ref-type="fig">figure 5E</xref>). These new input-target associations were trained (sequentially, in a curriculum) on one of each pair of inputs and tested on the other (<xref rid="fig5" ref-type="fig">figure 5F</xref>). Performance was assessed at each stage of the task (<xref rid="fig5" ref-type="fig">figure 5G</xref>), verifying that both gradient descent and the coordinated eligibility model performed identically at initialization, after association training, and after training during the generalization phase. The algorithms differed in terms of their generalization however (by construction), with coarse-coded plasticity ensuring that held-out inputs were properly associated with trained targets during the generalization phase.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><p>Receptive field pattern completion. (A) The network we used was an MLP with one readout (head) for the association curriculum and one for the generalization curriculum. (B) Inputs were 100 dim. unit random vectors. Targets were 20 dim. unit random vectors. (C) During the association phase, the network learned to map pairs of inputs, presented sequentially, to targets (of which there was one for each pair). (D) Surprise was computed over target prediction errors and used to chunk learning temporally, producing a coarse-code for gradient components between elevated surprise events. (E) A generalization curriculum re-used inputs from the association curriculum, but paired them with new targets. (F) Training was performed on only one item out of each pair, testing was performed on the held out item subject to coarse-coded plasticity. (G) Initial error, error at the end of the association-learning phase, error at the end of training during the generalization phase (for trained items) and generalization (test) error at the end of the generalization phase. Coarse coding generalized learning.</p></caption>
<graphic xlink:href="466943v3_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2g">
<title>Coarse-coding population response plasticity generalizes learning</title>
<p>As with pattern separation, pattern completion (or coarse-coding) can also be applied over population responses. We illustrate this by simulating a network performing tasks analogous to the RF pattern completion case just discussed, with PR and RF roles reversed. Specifically, we first simulated a curriculum in which pairs of targets (on independent readouts) were associated (via training) with individual inputs (<xref rid="fig6" ref-type="fig">figures 6A-C</xref>). At every input transition, input-based surprise was used to coarse-code plasticity for the previously seen targets (which shared the previous input) (<xref rid="fig6" ref-type="fig">figure 6D</xref>). As previously, networks made use of this coarse-coding during training on a generalization curriculum (<xref rid="fig6" ref-type="fig">figure 6E-f</xref>). During these tasks, networks were given a sequence of new inputs, and were required to produce one out of of each of 40 pairs of targets. Plasticity during training was constrained to the coarse-coded dimensions discovered previously. Testing the network on the held-out targets verified that it properly produced each second target, given each held-out readout, and that performance at other phases of learning was otherwise identical (<xref rid="fig6" ref-type="fig">figure 6G</xref>).</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6.</label>
<caption><p>Population response pattern completion. (A) The network we used was an MLP with one readout (head) per target in the association curriculum, and these were re-used for the generalization curriculum. (B) Inputs were 20 dim. unit random vectors. Targets were 100 dim. unit random vectors. (C) During the association phase, the network learned to map inputs, presented sequentially, to pairs of targets (one pair per input). (D) Surprise was computed over inputs and used to chunk learning temporally and coarse-code gradient components between elevated surprise events. (E) A generalization curriculum re-used readouts from the association curriculum, but paired them with new inputs. (F) Training was performed on only one target out of each pair associated with a given input, while testing was performed on the held out readout, subject to coarse-coded plasticity. (G) Initial error, error at the end of the association-learning phase, error at the end of training during the generalization phase (for trained targets) and generalization (test) error at the end of the generalization phase. Coarse coding generalized learning.</p></caption>
<graphic xlink:href="466943v3_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2h">
<title>Eligibility components are compositional</title>
<p>Moving beyond simple subspace restrictions in our coordinated eligibility theory, we examined tasks with compositional inputs, requiring compositional responses. Many objects can be described as bundles of features of varying statistical interdependence, and when learning a task, subsets of these features might dictate separate elements of an appropriate response (<xref rid="fig7" ref-type="fig">figure 7B</xref>). Brain regions with convergent input from diverse pre-synaptic partners would be well served by plasticity mechanisms that could manage responsiveness to the compositional building blocks in such mixed inputs, and the resulting compositionality would also facilitate combinatorial generalization (as in e.g. <xref ref-type="bibr" rid="c30">O’reilly 2001</xref>). While there are circuit level architectural mechanisms that can gate attention to specific features in order to govern responding (<xref ref-type="bibr" rid="c13">Frank &amp; Badre 2012</xref>; Niv <italic>et al</italic>. 2015), just as there are for pattern separation vs completion <xref ref-type="bibr" rid="c31">O’Reilly &amp; Norman 2002</xref>, we again consider here how learning rules themselves can implement compositional inductive biases. As we show, associations between population-response plasticity and receptive field plasticity can produce compositional learning.</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7.</label>
<caption><p>Compositional plasticity. (A) Networks were MLPs with single readouts. (B) Tasks for a curriculum were produced by taking 10 feature loadings, converting them via scaling to 10 task demands (latent outputs), and then generating observed inputs and targets as sums of features and demands (respectively). (C) Once input and target vectors were computed, we produced a curriculum of overlapping (interfering) tasks by circularly shifting them. (D) During training, networks learned to produce each target given each input. (E) Plasticity in the network was restricted to a sum of de-mixed subspaces (the representation in the network of each latent task demand could only learn about the representation of each feature). Unlike our other simulations, we did not perform unsupervised plasticity on gradient elements to first learn this de-mixing, as this learning problem is itself complex, and our main concern is the use of the PR-vs-RF eligibility decomposition itself. (F) Training error over 10 passes through the data, averaged over all tasks and over 50 simulation repetitions. The CEM converges to sub-criterion error with far fewer passes through the data than the network learning via GD. (G) Average weights between feature representations and their demand representations, with 1 being optimal. (H) Average weights between demands and features which are irrelevant for them, with 0 being optimal. Note that there are many more such spurious relationships than true ones. (I) Impact of linking number <italic>l</italic> (and hence dimensionality reduction) on cumulative training error over the 10-repetition window in F. Linking number 1 (corresponding to plasticity width 1 in the figure) represents completely accurate prior associations, whereas linking number greater than or equal to 20 (plasticity width 41) represents all-to-all plasticity between representations (gradient descent). The y-axis is cumulative error of the CEM as a fraction of GD.</p></caption>
<graphic xlink:href="466943v3_fig7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig8" position="float" fig-type="figure">
<label>Figure 8.</label>
<caption><p>RF splitting in nonlinear neural networks that learn according to policy-gradient-like updates. (A) Training error for a simulation mirroring the RF splitting simulation (figure 3 from the main text). (B) The policy-gradient learner shows significant interference, whereas the coordinated eligibility model avoids this. (C). Sampled population response changes mirror those derived from analytic gradients in both models.</p></caption>
<graphic xlink:href="466943v3_fig8.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig9" position="float" fig-type="figure">
<label>Figure 9.</label>
<caption><p>PR splitting in nonlinear neural networks that learn according to policy-gradient-like updates. (A) Training error for a simulation mirroring the PR splitting simulation (figure 4 from the main text). (B) The gradient-based method shows significant interference, whereas the coordinated eligibility model reduces this interference. Here, the CET does not totally abolish interference, because updates are only locally optimal, rather than globally optimal, owing to the curvature of the loss landscape induced by network nonlinearities. (C) Angles between CEM PR changes and gradient ones. CEM PR changes are consistently at a fairly high angle to analytic gradients, indicating that the locally optimal updates are nearly orthogonal to the gradient updates.</p></caption>
<graphic xlink:href="466943v3_fig9.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Our basic insight is that (unlike the earlier simulations) population response plasticity need not be independent of receptive field plasticity. Indeed, there is little reason to think these two aspects of response change are, in general, independent. Instead, as we consider here, subspaces of candidate population response changes (i.e., span({<italic>u</italic><sub><italic>i</italic></sub>}), for some set <italic>u</italic><sub><italic>i</italic></sub>) may be associated with subspaces of receptive field changes (span({ <italic>v</italic><sub><italic>j</italic></sub> }), for some set <italic>v</italic><sub><italic>j</italic></sub>), leading to weight update matrices in span <inline-formula><inline-graphic xlink:href="466943v3_inline6.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, for <italic>u</italic><sub><italic>i</italic></sub> ∈ {<italic>u</italic><sub><italic>i</italic></sub>} and <italic>v</italic><sub><italic>j</italic></sub>∈{ <italic>v</italic><sub><italic>j</italic></sub>}. When subspace associations such as these exist, the building blocks of representation changes are inherently yoked to those of receptive field changes. Learning multiple such updates simultaneously produces compositional learning, along with dimensionality reduction; instead of learning on the complete bipartite graph of possible population-response and receptive field updates, some smaller eligibility graph (with fewer edges) is thereby assumed.</p>
<p>As a biological example, striatal neurons multiplexing sensory information from different areas may have different population-level representations related to different sensory modalities, and it may be useful to explore holistic changes in these representations in a way that keeps learning somewhat separated by (for example, internal to) different modalities. This would imply yoking a representation change associated with one modality to a set of receptive field changes “listening” to that same modality. As noted above, we are not suggesting that other mechanisms cannot accomplish similar goals. Instead, we show that synaptic plasticity could be either pre-configured or tuned online to perform such functions in some circuits.</p>
<p>To explore this idea, we simulated simple, single-layer linear networks (<xref rid="fig7" ref-type="fig">figure 7A</xref>) solving compositional task sets. Tasks were constructed by generating random mathematical bases for network inputs and hidden layer responses, and associating elements of each basis with elements of the other. This defined how features (latent inputs, the input basis components), translated into latent task demands (the output basis components) in a 1-to-1 fashion (<xref rid="fig7" ref-type="fig">figure 7B</xref>). Since basis components for each feature were unit vectors, the inputs for each feature were generated as compositions of rotations and reflections (elements of the orthogonal group <italic>O</italic>(<italic>n</italic>)). The desired input-to-hidden transformation was thus an orthogonal matrix <inline-formula><inline-graphic xlink:href="466943v3_inline7.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, with input feature vectors encoded in <italic>A</italic> and task demands in <italic>B</italic> (<xref rid="fig7" ref-type="fig">figure 7B</xref>). Stimuli were generated as compositions of the basic features, with 10 random loadings per task, and target outputs were generated as compositions of graded responses to these input features (using the same loadings) (<xref rid="fig7" ref-type="fig">figure 7B</xref>). The strength of an input feature therefore determined the extent to which its associated output was required. Because there are 40-choose-10 features per task (which precludes using averages over draws to avoid introducing non-uniform sampling effects in our results), we selected stimuli to include all 40 features with equal frequency (<xref rid="fig7" ref-type="fig">figure 7C</xref>). Specifically, we did so by circularly shifting feature loadings to define a curriculum. These tasks were then learned sequentially (<xref rid="fig7" ref-type="fig">figure 7D</xref>), with plasticity in our coordinated eligibility model restricted to feature-demand subspaces which included the correct associations (<xref rid="fig7" ref-type="fig">figure 7E</xref>). We ran a series of such simulations, varying a “linking number” parameter, <italic>l</italic>, which determined the degree of plasticity restriction. This parameter varied between all-to-all (gradient) connectivity and 1-to-1 (completely accurate prior associations), and allowed us to examine the impact of restriction on learning.</p>
<p>Our results are illustrated in <xref rid="fig7" ref-type="fig">figure 7F-I</xref>, showing performance of the coordinated eligibility model relative to GD, averaged over 60 random task and network initializations. The coordinated eligibility model converges to its asymptotic error in fewer passes over the data relative to gradient descent, with less interference (<xref rid="fig7" ref-type="fig">figure 7F</xref>). This can be observed in the weights of the network, as relevant weights (defined as those connecting input features with their associated output demands) rapidly increase and plateau for the coordinated eligibility model, whereas gradient descent increases them much more slowly (<xref rid="fig7" ref-type="fig">figure 7G</xref>). Similarly, irrelevant weights (or spurious associations) grow much more rapidly for gradient descent, then decay, whereas the coordinated eligibility model suffers less from this problem (<xref rid="fig7" ref-type="fig">figure 7H</xref>) (the scales differ because there are many more irrelevant weights). Linking number impacted average cumulative error as expected, with even limited dimensionality reduction providing significant decreases in cumulative training error (<xref rid="fig7" ref-type="fig">figure 7I</xref>). Thus, feature matching via coordinated receptive field and response eligibility can drastically improve learning in compositional tasks relative to gradient descent.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Our results contribute to a tradition of work that shows how models of biological plasticity may have functions beyond those imparted by gradients. In this work, we showed that restricting plasticity to structured receptive field and population-response changes provides a powerful way to manage interference, and generalization. In managing generalization, we also illustrated links with the topic of state abstraction. Furthermore, by linking these constraints, networks can also learn compositionally. This compositional learning has the potential benefit of significantly reducing learning-problem dimensionality, among others. In support of these ideas, we introduced a plasticity equation encapsulating these different models. We called this umbrella description the coordinated eligibility theory, and showed how unsupervised learning on gradient components could produce the functions discussed above.</p>
<p>The plausibility of our model rests on the observation that modulatory neural inputs controlling plasticity are extremely numerous and diverse (reviewed in <xref ref-type="bibr" rid="c36">Scott &amp; Frank 2022</xref>). In the cortex, for example, parvalbumin expressing interneurons such as basket and chandelier cells likely impact population response plasticity, via their impacts on local population-level firing rate variability. Similarly, somatostatin interneurons exert a degree of control over dendritic calcium concentrations, and (presumably) thereby receptive field plasticity (<xref ref-type="bibr" rid="c18">Higley 2014</xref>; <xref rid="c28" ref-type="bibr">Naka <italic>et al</italic>. 2019</xref>; <xref rid="c21" ref-type="bibr">Kecskés <italic>et al</italic>. 2020</xref>). Numerous other control mechanisms are also plausible, and as one would predict from our theory, experimental calcium manipulations in dendrites have already been shown to causally impact learning interference between tasks (<xref rid="c44" ref-type="bibr">Yang <italic>et al</italic>. 2014</xref>; <xref ref-type="bibr" rid="c3">Cichon &amp; Gan 2015</xref>; <xref rid="c38" ref-type="bibr">Sehgal, Filho, <italic>et al</italic>. 2021</xref>).</p>
<p>The extent to which any given locus of plasticity displays either fixed or metaplastic gradient projections, along with what these projections are, would be expected to vary, and is a subject of further investigation suggested by our theory. Metaplasticity in action selection is most well established in the dopamine system, for example, (<xref rid="c43" ref-type="bibr">Yagishita <italic>et al</italic>. 2014</xref>; <xref ref-type="bibr" rid="c5">Collins &amp; Frank 2014</xref>; <xref ref-type="bibr" rid="c20">Jaskir &amp; Frank 2021</xref>; <xref ref-type="bibr" rid="c36">Scott &amp; Frank 2022</xref>), where our theory suggests considering potential distinctions between D1 and D2 (dopamine receptor) pathways, which are associated with different aspects of cost and benefit calculations. In particular, these pathways specialize in decision-making under different circumstances (<xref ref-type="bibr" rid="c5">Collins &amp; Frank 2014</xref>; <xref ref-type="bibr" rid="c20">Jaskir &amp; Frank 2021</xref>), and they may further profit from considering how their PRs and RFs can be differentially sculpted (for example, to prevent unlearning in D1 MSNs while promoting new learning in D2 MSNs). As these examples suggest, our coordinated eligibility theory should useful in examining diverse circuits.</p>
<p>Our coordinated eligibility theory is also closely related to a number of other plasticity models, in both neuroscience and machine learning. As we discuss in the supplementary material, versions of the Bienenstock-Cooper-Munroe (<xref ref-type="bibr" rid="c2">Bienenstock <italic>et al</italic>. 1982</xref>), two-threshold calcium theories (<xref ref-type="bibr" rid="c9">Evans &amp; Blackwell 2015</xref>), and neuromodulated Hebbian (or “three-factor”) rules (<xref ref-type="bibr" rid="c15">Frémaux &amp; Gerstner 2016</xref>) are special cases of <xref ref-type="disp-formula" rid="eqn4">equation (4)</xref>. As a result, our findings describe these models. Similarly, other continual learning schemes can be understood in terms of our results. For example, elastic weight consolidation (<xref rid="c22" ref-type="bibr">Kirkpatrick <italic>et al</italic>. 2017</xref>) can be considered an axis-aligned, less-structured version of our model, in the sense that weight values (and hence projections of weights onto axes in network weight-spaces) are fixed in ad-hoc non-decomposed ways. As further examples, memorization methods like gradient episodic memory (<xref rid="c26" ref-type="bibr">Lopez-Paz &amp; Ranzato 2017</xref>) and replay-based methods (<xref rid="c41" ref-type="bibr">Wang <italic>et al</italic>. 2022</xref>) both essentially propose ways to remain within earlier tasks’ solution manifolds, which our networks do explicitly on the basis of gradient factors. By contrast with our work, however, these methods lack the the structural and functional insight provided by the decompositions and geometry we have discussed, and neither do they address generalization.</p>
<p>Nonetheless, our results here are limited in a variety of ways. Most notably, they can and should be extended to understand coordinated eligibility involving multiple non-linear network layers, and more complex combinations of learning subspaces. Here, we have focused on linear systems, because understanding phenomena in them is virtually always the foundation for understanding more complex cases. As such, our results here are applicable both infinitesimally within non-linear systems, as usual, and within linear network activity regimes induced by ReLU and GELU non-linearities, for example. They are therefore also applicable, in principle, to non-linear systems in general, but further work will be required to understand the details of such applications. In a similar manner, the subspace plasticity restrictions we discussed here can be considered as primitives in more complex settings. For example, it is likely that biological networks have a variety of more and less plastic subspaces within connected networks, such that plasticity is not a simple, binary function of connectivity. Our networks are the only ones we know of which describe this situation, and understanding biological plasticity will likely benefit from both such expanded understandings of coordinated eligibility models.</p>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Network model</title>
<p>All simulations were carried out using PyTorch, running custom network layers. Code for these simulations can be found at <ext-link ext-link-type="uri" xlink:href="http://www.github.com/DanielNScott/beyond-grads">www.github.com/DanielNScott/beyond-grads</ext-link>. Network layers implementing coordinated eligibility used forward and backward hooks to compute surprise as a function of inputs during network forward passes or as a function of supervision mismatch during backward passes. To do so, networks maintained histories of inputs and supervision, generally for one time-step of training, and compared new inputs or supervisory signals with those seen just prior. To compute gradient manipulations, layers also maintained state in the form of projection matrices. For pattern-separation simulations, these had previously seen dimensions removed, whereas for pattern-completion simulations, dimensions were merged by removing the independent (to-be-merged) dimensions and replacing them with one (joint) dimension. In our compositional plasticity simulation (simulation 5), the independent projections were not learned, being directly implemented instead.</p>
</sec>
<sec id="s4b">
<title>Surprise computations</title>
<p>During blocked learning, the appearance of a new task can be detected as a change-point in inputs or feedbacks, and likewise, these can be grouped over time according to contiguity. Empirical evidence suggests the locus coeruleus is heavily involved in signaling such (unvalenced) surprise (reviewed in <xref ref-type="bibr" rid="c33">Sara &amp; Bouret 2012</xref>), whereas midbrain dopamine projections signal both valenced (reward-prediction error) and unvalenced surprise, associated with reinforcement learning and stimulus-stimulus association learning, respectively (<xref ref-type="bibr" rid="c8">Diederen &amp; Fletcher 2021</xref>; <xref ref-type="bibr" rid="c35">Schultz <italic>et al</italic>. 1997</xref>). The neuromodulators these areas release, norepinephrine, and dopamine, have major impacts on plasticity (reviewed in <xref ref-type="bibr" rid="c36">Scott &amp; Frank 2022</xref>). Our networks compute such surprise signals, and use them to perform pattern-separation (in the high-surprise case) or integration-based coarse-coding (in the low-surprise case) on plasticity components <italic>u</italic> and <italic>v</italic>, by changing the transformations <italic>P</italic> and <italic>Q</italic> over time.</p>
<p>Specifically, each layer computes a running average <italic>µ</italic> of its inputs over time. When new inputs arrive, surprise <italic>s</italic> is computed as the logistic function applied to cosine-angle dissimilarity between new and old inputs. That is:
<disp-formula id="ueqn5">
<graphic xlink:href="466943v3_ueqn5.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
This surprise function is shown in <xref rid="fig3" ref-type="fig">figure 3E</xref>. The parameters <italic>θ</italic><sub>0</sub> and <italic>m</italic> define the shape (cutoff location and cutoff sharpness) of the sigmoid. The running mean computation is weighted by surprise, such that surprising events more fully replace the running average, and the transform <italic>T</italic><sub><italic>u</italic></sub> has the most-recent running mean removed according to surprise as well. That is, <inline-formula><inline-graphic xlink:href="466943v3_inline8.gif" mime-subtype="gif" mimetype="image"/></inline-formula> for a normalized mean <inline-formula><inline-graphic xlink:href="466943v3_inline9.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. An analogous computation is performed on the <italic>v</italic> vectors, as we describe in the relevant section below. As we show below, these operations allow our networks to flexibly manage interference and generalization across tasks.</p>
</sec>
<sec id="s4c">
<title>Simulations 1 and 2</title>
<p>For each repetition of simulation 1, we initialized our network’s input eligibility transform as the identity matrix, <italic>T</italic><sub><italic>u</italic></sub> = <italic>I</italic>. After training on input <italic>x</italic><sub><italic>t</italic></sub> during the <italic>t</italic>-th task, <italic>T</italic><sub><italic>u</italic></sub> was updated as <inline-formula><inline-graphic xlink:href="466943v3_inline10.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, where <italic>u</italic><sub><italic>t</italic></sub> represents the vector <inline-formula><inline-graphic xlink:href="466943v3_inline11.gif" mime-subtype="gif" mimetype="image"/></inline-formula> scaled to have unit norm, <italic>ρ</italic> is a mixture parameter, <italic>s</italic> is surprise (which was very close to 1 at task transitions, and 0 otherwise), and <inline-formula><inline-graphic xlink:href="466943v3_inline12.gif" mime-subtype="gif" mimetype="image"/></inline-formula> was the average input over the immediately preceding period of low-surprise (i.e., <inline-formula><inline-graphic xlink:href="466943v3_inline13.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, the input during the t-th task).</p>
<p>Plasticity in simulation 2 was treated analogously to plasticity in simulation 1, with the transform <italic>T</italic><sub><italic>v</italic></sub> being updated according to surprising output update supervision signals <italic>g</italic><sub><italic>t</italic></sub>, rather than <italic>T</italic><sub><italic>u</italic></sub> being updated according to surprising inputs.</p>
</sec>
<sec id="s4d">
<title>Simulation 5</title>
<p>For simulation 5, we generated orthogonal bases <italic>A</italic> and <italic>B</italic> for the inputs and targets by randomly sampling multivariate normal distributions and applying the Gram-Schmidt procedure to orthogonalize them. The columns of <italic>A</italic> served as vectors mapping latent features to observed inputs, and the columns of <italic>B</italic> as vectors mapping latent demands to observed targets. We generated compositional input stimuli by circularly shifting (“rolling”) a fixed vector with <italic>C</italic> non-zero random weights <italic>w</italic><sub><italic>i</italic></sub>, and using each of these as weights applied to the latent features. The same procedure was used to generate target outputs. For example, if stimuli are denoted <italic>s</italic><sub><italic>i</italic></sub>, then in the <italic>n</italic> = 3, <italic>C</italic> = 2 case, we would have a set of inputs:
<disp-formula id="ueqn6">
<graphic xlink:href="466943v3_ueqn6.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Juxtaposition here represents matrix multiplication, and parenthesis denote vectors (not indexing). Targets were generated using the same set of weights and the demand-target map <italic>B</italic> instead of the feature-input map <italic>A</italic>. Matching the inputs and targets shows that the learned optimal weight matrix will be <inline-formula><inline-graphic xlink:href="466943v3_inline14.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, because this matrix first inverts the feature-to-input map (<italic>A</italic>) then applies to feature-to-demand map (<italic>I</italic>), and finally the demand-to-target map (<italic>B</italic>). This weight matrix was learned directly in the gradient descent simulations, and indirectly, in the latent feature-demand space, using the CEM. Since the basis transormations are arbitrary, both cases are equivalent to learning the identity map.</p>
<p>Linking numbers were free parameters that we used to encode prior information about the target weight transformation. In a simulation with linking number <italic>l</italic>, for each index <italic>t</italic>, plasticity was restricted to retain only terms between features [<italic>t</italic> − <italic>l, t</italic> + <italic>l</italic>] and their associated demands. For example, given a linking number of 1, plasticity would include terms <inline-formula><inline-graphic xlink:href="466943v3_inline15.gif" mime-subtype="gif" mimetype="image"/></inline-formula> in the feature-demand space. A linking number of <italic>l</italic> = 0 therefore provided complete information about which features should be associated with which demands <inline-formula><inline-graphic xlink:href="466943v3_inline16.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, again, in the feature-demand space), such that only the strengths of these relationships required learning. A linking number such that 2<italic>l</italic> + 1 ≥ <italic>n</italic> was equivalent to gradient descent (<inline-formula><inline-graphic xlink:href="466943v3_inline17.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, since <italic>p</italic><sub><italic>i</italic></sub> and <italic>q</italic><sub><italic>j</italic></sub> span all feature-demand basis pairs). These restrictions can be accomplished at by taking 2<italic>l</italic> + 1 projections of <italic>g</italic> and 2<italic>l</italic> + 1 projections of <italic>x</italic>, then summing all of their pairwise products, or they can be implemented parsimoniously using a mask <italic>M</italic>. The t-th row of this mask is then a vector of length <italic>n</italic> with 2<italic>l</italic> + 1 ones centered on the t-th component, with zeros elsewhere. We took the latter approach, transforming gradients into the feature-demand space, masking them, then transforming them back. Denoting the full gradient <italic>G</italic>, this meant that at each backward pass of the CEM network, we set <italic>G</italic>↦ <italic>B</italic>(<italic>M</italic> ⊙ <italic>B</italic><sup><italic>T</italic></sup> <italic>GA</italic><sup><italic>T</italic></sup>)<italic>A</italic>.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>For helpful discussion, commentary, and feedback, we thank Matthew Nassar, Apoorva Bhandari, Rex Liu, Christopher I. Moore, Ian A. More, David Badre, Scott Susi, Cris Buc Calderon, and the Frank lab. Daniel Scott was supported by NIMH training grant T32MH115895 (PI’s:Frank, Badre, Moore). The project was supported by NIMH R01 MH084840-08A1. Computing hardware was supported by NIH Office of the Director grant S10OD025181.</p></ack>
<sec id="s5">
<title>Additional information</title>
<sec id="s5a">
<title>Author contributions</title>
<p>D.N.S. and M.J.F. developed the research topic. D.N.S. developed the mathematical analyses, functional and biological interpretations, wrote code, performed simulations, and drafted the manuscript. M.J.F. provided extensive feedback at all project stages and on all topics. D.N.S. and M.J.F redrafted and edited the manuscript, and prepared it for submission. D.N.S. and M.J.F revised it upon receiving feedback.</p>
</sec>
<sec id="s6">
<title>Declaration of interests</title>
<p>The authors declare no competing interests.</p>
</sec>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Bellec</surname>, <given-names>G.</given-names></string-name> <etal>et al.</etal> .  . <collab>Bandiera abtest: a Cc license type: cc by Cg type: Nature Research Journals Number: 1 Primary atype: Research Publisher</collab>:  <collab>Subject term: Electrical and electronic engineering;Learning algorithms;Network models;Neuroscience;Synaptic plasticity Subject term id: electrical-and-electronic-engineering;learning-algorithms;network-models;neuroscience;synaptic-plasticity, 3625</collab></person-group><chapter-title>A solution to the learning dilemma for recurrent networks of spiking neurons</chapter-title>. <source>Nature Communications</source> <volume>11</volume>. : <publisher-name>Nature Publishing Group</publisher-name> . issn: <issn>2041-1723</issn>. <ext-link ext-link-type="uri" xlink:href="https://www.nature.com/articles/s41467-020-17236-y">https://www.nature.com/articles/s41467-020-17236-y</ext-link> (2021) (<month>July</month> 17, <year>2020</year>).</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bienenstock</surname>, <given-names>E. L.</given-names></string-name>, <string-name><surname>Cooper</surname>, <given-names>L. N.</given-names></string-name> &amp; <string-name><surname>Munro</surname>, <given-names>P. W.</given-names></string-name></person-group> <article-title>Theory for the development of neuron selectivity: orientation specificity and binocular interaction in visual cortex</article-title>. <source>Journal of Neuroscience</source> <volume>2</volume>, <fpage>32</fpage>–<lpage>48</lpage>. issn: <issn>0270-6474</issn>, <issn>1529-2401</issn>. <ext-link ext-link-type="uri" xlink:href="https://www.jneurosci.org/content/2/1/32">https://www.jneurosci.org/content/2/1/32</ext-link> (<month>Jan</month>. 1, <year>1982</year>).</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cichon</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Gan</surname>, <given-names>W.-B.</given-names></string-name></person-group> <article-title>Branch-specific dendritic Ca2+ spikes cause persistent synaptic plasticity</article-title>. <source>Nature</source> <volume>520</volume>, <fpage>180</fpage>–<lpage>185</lpage>. issn: <issn>0028-0836</issn>, <issn>1476-4687</issn>. <ext-link ext-link-type="uri" xlink:href="http://www.nature.com/articles/nature14251">http://www.nature.com/articles/nature14251</ext-link> (2022) (<month>Apr</month>. <year>2015</year>).</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Collins</surname>, <given-names>A. G. E.</given-names></string-name> &amp; <string-name><surname>Frank</surname>, <given-names>M. J.</given-names></string-name></person-group> <article-title>Cognitive control over learning: Creating, clustering, and generalizing task-set structure</article-title>. <source>Psychological Review</source> <volume>120</volume>, <fpage>190</fpage>–<lpage>229</lpage>. issn: <issn>1939-1471</issn>, <issn>0033-295X</issn>. <pub-id pub-id-type="doi">10.1037/a0030852</pub-id> (<month>Jan</month>. <year>2013</year>).</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Collins</surname>, <given-names>A. G. E.</given-names></string-name> &amp; <string-name><surname>Frank</surname>, <given-names>M. J.</given-names></string-name></person-group> <article-title>Opponent Actor Learning (OpAL): Modeling Interactive Effects of Striatal Dopamine on Reinforcement Learning and Choice Incentive</article-title>. <source>Psychological Review</source> <volume>121</volume>, <fpage>337</fpage>–<lpage>366</lpage>. issn: <issn>1939-1471</issn>, <issn>0033-295X</issn>. (<year>2014</year>).</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Collins</surname>, <given-names>A. G. E.</given-names></string-name> &amp; <string-name><surname>Frank</surname>, <given-names>M. J.</given-names></string-name></person-group> <article-title>Neural Signature of Hierarchically Structured Expectations Predicts Clustering and Transfer of Rule Sets in Reinforcement Learning</article-title>. <source>Cognition</source> <volume>152</volume>, <fpage>160</fpage>–<lpage>169</lpage>. issn: <issn>0010-0277</issn>. (<month>Jul</month>. <year>2016</year>).</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dekker</surname>, <given-names>R. B.</given-names></string-name>, <string-name><surname>Otto</surname>, <given-names>F.</given-names></string-name> &amp; <string-name><surname>Summerfield</surname>, <given-names>C.</given-names></string-name></person-group> <article-title>Curriculum learning for human compositional generalization</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>119</volume>, <fpage>e2205582119</fpage>. issn: <issn>0027-8424</issn>, <issn>1091-6490</issn>. <pub-id pub-id-type="doi">10.1073/pnas.2205582119</pub-id> (<month>Oct</month>. 11, <year>2022</year>).</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Diederen</surname>, <given-names>K. M. J.</given-names></string-name> &amp; <string-name><surname>Fletcher</surname>, <given-names>P. C.</given-names></string-name></person-group> <article-title>Dopamine, Prediction Error and Beyond</article-title>. <source>The Neuroscientist</source> <volume>27</volume>, <fpage>30</fpage>–<lpage>46</lpage>. issn: <issn>1073-8584</issn>. (<month>Feb</month>. <year>2021</year>).</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Evans</surname>, <given-names>R. C.</given-names></string-name> &amp; <string-name><surname>Blackwell</surname>, <given-names>K. T.</given-names></string-name></person-group> <article-title>Calcium: Amplitude, Duration, or Location?</article-title> <source>The Biological Bulletin</source> <volume>228</volume>, <fpage>75</fpage>–<lpage>83</lpage>. issn: <issn>0006-3185</issn>, <issn>1939-8697</issn>. <pub-id pub-id-type="doi">10.1086/BBLv228n1p75</pub-id> (<month>Feb</month>. <year>2015</year>).</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Farries</surname>, <given-names>M. A.</given-names></string-name> &amp; <string-name><surname>Fairhall</surname>, <given-names>A. L.</given-names></string-name></person-group> <article-title>Reinforcement Learning With Modulated Spike Timing–Dependent Synaptic Plasticity</article-title>. <source>Journal of Neurophysiology</source> <volume>98</volume>, <fpage>3648</fpage>–<lpage>3665</lpage>. issn: <issn>0022-3077</issn>. <pub-id pub-id-type="doi">10.1152/jn.00364.2007</pub-id> (<month>Dec</month>. 1, <year>2007</year>).</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fiete</surname>, <given-names>I. R.</given-names></string-name> &amp; <string-name><surname>Seung</surname>, <given-names>H. S.</given-names></string-name></person-group> <article-title>Gradient Learning in Spiking Neural Networks by Dynamic Perturbation of Conductances</article-title>. <source>Physical Review Letters</source> <volume>97</volume>, <fpage>048104</fpage>. issn: <issn>0031-9007</issn>, <issn>1079-7114</issn>. <pub-id pub-id-type="doi">10.1103/PhysRevLett.97.048104</pub-id> (<month>July</month> 28, <year>2006</year>).</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Flesch</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Juechems</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Dumbalska</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Saxe</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Summerfield</surname>, <given-names>C.</given-names></string-name></person-group> <article-title>Rich and lazy learning of task repre-sentations in brains and neural networks</article-title>. <source>bioRxiv</source>. <elocation-id>2021.04.23.441128</elocation-id>. <pub-id pub-id-type="doi">10.1101/2021.04.23.441128v1</pub-id> (<month>Apr</month>. 23, <year>2021</year>).</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Frank</surname>, <given-names>M. J.</given-names></string-name> &amp; <string-name><surname>Badre</surname>, <given-names>D.</given-names></string-name></person-group> <article-title>Mechanisms of Hierarchical Reinforcement Learning in Corticostriatal Circuits 1: Computational Analysis</article-title>. <source>Cerebral Cortex</source> <volume>22</volume>, <fpage>509</fpage>–<lpage>526</lpage>. issn: <issn>1047-3211</issn>. <pub-id pub-id-type="doi">10.1093/cercor/bhr114</pub-id> (<month>Mar</month>. 1, <year>2012</year>).</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Franklin</surname>, <given-names>N. T.</given-names></string-name> &amp; <string-name><surname>Frank</surname>, <given-names>M. J.</given-names></string-name></person-group> <article-title>Compositional clustering in task structure learning</article-title>. <source>PLOS Computational Biology</source> <volume>14</volume> <fpage>e1006116</fpage>. issn: <issn>1553-7358</issn>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1006116</pub-id> (<month>Apr</month>. 19, <year>2018</year>).</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Frémaux</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Gerstner</surname>, <given-names>W.</given-names></string-name></person-group> <article-title>Neuromodulated Spike-Timing-Dependent Plasticity, and Theory of Three-Factor Learning Rules</article-title>. <source>Frontiers in Neural Circuits</source> <volume>9</volume>. issn: <issn>1662-5110</issn>. <pub-id pub-id-type="doi">10.3389/fncir.2015.00085/full</pub-id> (2020) (<year>2016</year>).</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Frémaux</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Sprekeler</surname>, <given-names>H.</given-names></string-name> &amp; <string-name><surname>Gerstner</surname>, <given-names>W.</given-names></string-name></person-group> <article-title>Reinforcement Learning Using a Continuous Time Actor-Critic Framework with Spiking Neurons</article-title>. <source>PLOS Computational Biology</source> <volume>9</volume>, <fpage>e1003024</fpage>. issn: <issn>1553-7358</issn>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1003024</pub-id> (<month>Apr</month>. 11, <year>2013</year>).</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ghirlanda</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Enquist</surname>, <given-names>M.</given-names></string-name></person-group> <article-title>A century of generalization</article-title>. <source>Animal Behaviour</source> <volume>66</volume>, <fpage>15</fpage>–<lpage>36</lpage>. issn: <issn>0003-3472</issn>. <ext-link ext-link-type="uri" xlink:href="https://linkinghub.elsevier.com/retrieve/pii/S0003347203921749">https://linkinghub.elsevier.com/retrieve/pii/S0003347203921749</ext-link> (<month>Jul</month>. <year>2003</year>).</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Higley</surname>, <given-names>M. J.</given-names></string-name></person-group> <article-title>Localized GABAergic inhibition of dendritic Ca2+ signalling</article-title>. <source>Nature Reviews Neuroscience</source> <volume>15</volume>, <fpage>567</fpage>–<lpage>572</lpage>. issn: <issn>1471-003X</issn>, <issn>1471-0048</issn>. <ext-link ext-link-type="uri" xlink:href="http://www.nature.com/articles/nrn3803">http://www.nature.com/articles/nrn3803</ext-link> (<month>Sept</month>. <year>2014</year>).</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Izhikevich</surname>, <given-names>E. M.</given-names></string-name></person-group> <article-title>Solving the Distal Reward Problem through Linkage of STDP and Dopamine Signaling</article-title>. <source>Cerebral Cortex</source> <volume>17</volume>, <fpage>2443</fpage>–<lpage>2452</lpage>. issn: <issn>1047-3211</issn>, <issn>1460-2199</issn>. <pub-id pub-id-type="doi">10.1093/cercor/bhl152</pub-id> (<month>Oct</month>. 1, <year>2007</year>).</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Jaskir</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Frank</surname>, <given-names>M. J.</given-names></string-name></person-group> <article-title>On the normative advantages of basal ganglia opponency in decision-making</article-title>. <source>bioRxiv</source> (<year>2021</year>).</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kecskés</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Somatostatin expressing GABAergic interneurons in the medial entorhinal cortex preferentially inhibit layerIII-V pyramidal cells</article-title>. <source>Communications Biology</source> <volume>3</volume>, <fpage>754</fpage>. issn: <issn>2399-3642</issn>. <ext-link ext-link-type="uri" xlink:href="http://www.nature.com/articles/s42003-020-01496-x">http://www.nature.com/articles/s42003-020-01496-x</ext-link> (<month>Dec</month>. <year>2020</year>).</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kirkpatrick</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Overcoming catastrophic forgetting in neural networks</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>114</volume>:<fpage>3521</fpage>–<lpage>3526</lpage>. issn: <issn>0027-8424</issn>, <issn>1091-6490</issn>. <ext-link ext-link-type="uri" xlink:href="https://www.pnas.org/content/114/13/3521">https://www.pnas.org/content/114/13/3521</ext-link> (<month>Mar</month>. 28, <year>2017</year>).</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lehnert</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Littman</surname>, <given-names>M. L.</given-names></string-name> &amp; <string-name><surname>Frank</surname>, <given-names>M. J.</given-names></string-name></person-group> <article-title>Reward-Predictive Representations Generalize across Tasks in Reinforcement Learning</article-title>. <source>PLOS Computational Biology</source> <volume>16</volume>, <fpage>e1008317</fpage>. issn: <issn>1553-7358</issn>. (2021) (<month>Oct</month>. <year>2020</year>).</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lisman</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Cooper</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Sehgal</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Silva</surname>, <given-names>A. J.</given-names></string-name></person-group> <article-title>Memory Formation Depends on Both Synapse-Specific Modifications of Synaptic Strength and Cell-Specific Increases in Excitability</article-title>. <source>Nature Neuroscience</source> <volume>21</volume>, <fpage>309</fpage>–<lpage>314</lpage>. issn: <issn>1097-6256</issn>, <issn>1546-1726</issn>. (2022) (<month>Mar</month>. <year>2018</year>).</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname>, <given-names>Y. H.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Mihalas</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Shea-Brown</surname>, <given-names>E.</given-names></string-name> &amp; <string-name><surname>Sümbül</surname>, <given-names>U.</given-names></string-name></person-group> <article-title>Cell-type–specific neuromodulation guides synaptic credit assignment in a spiking neural network</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>118</volume>, <fpage>e2111821118</fpage>. issn: <issn>0027-8424</issn>, <issn>1091-6490</issn>. <pub-id pub-id-type="doi">10.1073/pnas.2111821118</pub-id> (2021) (<month>Dec</month>. 21, <year>2021</year>).</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Lopez-Paz</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>Ranzato</surname>, <given-names>M. A.</given-names></string-name></person-group> <article-title>Gradient Episodic Memory for Continual Learning</article-title> In <conf-name>Advances in Neural Information Processing Systems</conf-name> <volume>30</volume> (<publisher-name>Curran Associates, Inc.</publisher-name>,). (<year>2022</year>).</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mcclelland</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Mcnaughton</surname>, <given-names>B. L.</given-names></string-name> &amp; <string-name><surname>O’Reilly</surname>, <given-names>R. C.</given-names></string-name></person-group> <article-title>Why There Are Complementary Learning Systems in the Hippocampus and Neocortex: Insights From the Successes and Failures of Connectionist Models of Learning and Memory</article-title>. <source>Psychological Review</source> <volume>102</volume>, <fpage>419</fpage>–<lpage>457</lpage> (<year>1995</year>).</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Naka</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Complementary networks of cortical somatostatin interneurons enforce layer specific control</article-title>. <source>eLife</source> <volume>8</volume>, <elocation-id>e43696</elocation-id>. issn: <issn>2050-084X</issn>. <ext-link ext-link-type="uri" xlink:href="https://elifesciences.org/articles/43696">https://elifesciences.org/articles/43696</ext-link> (<month>Mar</month>. 18, <year>2019</year>).</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Niv</surname>, <given-names>Y.</given-names></string-name> <etal>et al.</etal></person-group> <chapter-title>Reinforcement Learning in Multidimensional Environments Relies on Attention Mechanisms</chapter-title>. <source>Journal of Neuroscience</source> <volume>35</volume>. Publisher: <publisher-name>Society for Neuroscience Section: Articles</publisher-name>, <fpage>8145</fpage>–<lpage>8157</lpage>. issn: <issn>0270-6474</issn>, <issn>1529-2401</issn>. <ext-link ext-link-type="uri" xlink:href="https://www.jneurosci.org/content/35/21/8145">https://www.jneurosci.org/content/35/21/8145</ext-link> (<month>May</month> 27, <year>2015</year>).</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>O’reilly</surname>, <given-names>R. C.</given-names></string-name></person-group> <article-title>Generalization in Interactive Networks: The Benefits of Inhibitory Competition and Hebbian Learning</article-title>. <source>Neural Computation</source> <volume>13</volume>, <fpage>1199</fpage>–<lpage>1242</lpage> (<year>2001</year>).</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>O’Reilly</surname>, <given-names>R. C.</given-names></string-name> &amp; <string-name><surname>Norman</surname>, <given-names>K. A.</given-names></string-name></person-group> <article-title>Hippocampal and neocortical contributions to memory: Advances in the complementary learning systems framework</article-title>. <source>Trends in cognitive sciences</source> <volume>6</volume>, <fpage>505</fpage>–<lpage>510</lpage>. <ext-link ext-link-type="uri" xlink:href="http://www.sciencedirect.com/science/article/pii/S1364661302020053">http://www.sciencedirect.com/science/article/pii/S1364661302020053</ext-link> (<year>2002</year>).</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rougier</surname>, <given-names>N. P.</given-names></string-name>, <string-name><surname>Noelle</surname>, <given-names>D. C.</given-names></string-name>, <string-name><surname>Braver</surname>, <given-names>T. S.</given-names></string-name>, <string-name><surname>Cohen</surname>, <given-names>J. D.</given-names></string-name> &amp; <string-name><surname>O’Reilly</surname>, <given-names>R. C.</given-names></string-name></person-group> <article-title>Prefrontal cortex and flexible cognitive control: Rules without symbols</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>102</volume>. <fpage>7338</fpage>–<lpage>7343</lpage>. issn: <issn>0027-8424</issn>, <issn>1091-6490</issn>. <ext-link ext-link-type="uri" xlink:href="https://www.pnas.org/content/102/20/7338">https://www.pnas.org/content/102/20/7338</ext-link> (<month>May</month> 17, <year>2005</year>).</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sara</surname>, <given-names>S. J.</given-names></string-name> &amp; <string-name><surname>Bouret</surname>, <given-names>S.</given-names></string-name></person-group> <article-title>Orienting and Reorienting: The Locus Coeruleus Mediates Cognition through Arousal</article-title>. <source>Neuron</source> <volume>76</volume>, <fpage>130</fpage>–<lpage>141</lpage>. issn: <issn>0896-6273</issn>. (2022) (<month>Oct</month>. <year>2012</year>).</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schapiro</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Turk-Browne</surname>, <given-names>N. B.</given-names></string-name>, <string-name><surname>Botvinick</surname>, <given-names>M. M.</given-names></string-name> &amp; <string-name><surname>Norman</surname>, <given-names>K. A.</given-names></string-name></person-group> <article-title>Complementary learning systems within the hippocampus: a neural network modelling approach to reconciling episodic memory with statistical learning</article-title>. <source>Philosophical Transactions of the Royal Society B: Biological Sciences</source> <volume>372</volume>, <fpage>20160049</fpage>. issn: <issn>0962-8436</issn>, <issn>1471-2970</issn>. <pub-id pub-id-type="doi">10.1098/rstb.2016.0049</pub-id> (<month>Jan</month>. 5, <year>2017</year>).</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schultz</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name> &amp; <string-name><surname>Montague</surname>, <given-names>P. R.</given-names></string-name></person-group> <article-title>A Neural Substrate of Prediction and Reward</article-title>. <source>Science</source> <volume>275</volume>, <fpage>1593</fpage>– <lpage>1599</lpage>. issn: <issn>0036-8075</issn>, <issn>1095-9203</issn>. <pub-id pub-id-type="doi">10.1126/science.275.5306.1593</pub-id> (2020) (<month>Mar</month>. 14, <year>1997</year>).</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Scott</surname>, <given-names>D. N.</given-names></string-name> &amp; <string-name><surname>Frank</surname>, <given-names>M. J.</given-names></string-name></person-group> <chapter-title>Adaptive control of synaptic plasticity integrates micro-and macroscopic network function</chapter-title>. <source>Neuropsychopharmacology</source>. Publisher: <publisher-name>Nature Publishing Group</publisher-name>, <fpage>1</fpage>–<lpage>24</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sehgal</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Zhou</surname>, <given-names>M.</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Memory Allocation Mechanisms Underlie Memory Linking across Time</article-title>. <source>Neurobiology of Learning and Memory</source> <volume>153</volume>, <fpage>21</fpage>–<lpage>25</lpage>. issn: <issn>1074-7427</issn>. (2022) (<month>Sept</month>. <year>2018</year>).</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Sehgal</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Filho</surname>, <given-names>D. A.</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Co-allocation to overlapping dendritic branches in the retrosplenial cortex integrates memories across time preprint</article-title> <source>bioRxiv</source>, <month>Nov</month>. 1, 2021). <pub-id pub-id-type="doi">10.1101/2021.10.28.466343</pub-id> (<year>2022</year>).</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shepard</surname>, <given-names>R.</given-names></string-name></person-group> <article-title>Toward a universal law of generalization for psychological science</article-title>. <source>Science</source> <volume>237</volume>, <fpage>1317</fpage>–<lpage>1323</lpage>. issn: <issn>0036-8075</issn>, <issn>1095-9203</issn>. <pub-id pub-id-type="doi">10.1126/science.3629243</pub-id> (<month>Sept</month>. 11, <year>1987</year>).</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name> &amp; <string-name><surname>Griffiths</surname>, <given-names>T. L.</given-names></string-name></person-group> <article-title>Generalization, similarity, and Bayesian inference</article-title>. <source>Behavioral and Brain Sciences</source> <volume>24</volume>, <fpage>629</fpage>–<lpage>640</lpage>. issn: <issn>0140-525X</issn>, <issn>1469-1825</issn>. <ext-link ext-link-type="uri" xlink:href="https://www.cambridge.org/core/product/identifier/S0140525X01000061/type/journal_article">https://www.cambridge.org/core/product/identifier/S0140525X01000061/type/journal_article</ext-link> (<month>Aug</month>. <year>2001</year>).</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Wang</surname>, <given-names>L.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Memory Replay with Data Compression for Continual Learning</article-title> <month>Mar</month>. <source>arXiv</source>. <pub-id pub-id-type="arxiv">2202.06592</pub-id> [cs]. (<year>2024</year>).</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Williams</surname>, <given-names>R. J.</given-names></string-name></person-group> <article-title>Simple statistical gradient-following algorithms for connectionist reinforcement learning</article-title>. <source>Machine learning</source> <volume>8</volume>, <fpage>229</fpage>–<lpage>256</lpage> (<year>1992</year>).</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Yagishita</surname>, <given-names>S.</given-names></string-name> <etal>et al.</etal></person-group> <chapter-title>A critical time window for dopamine actions on the structural plasticity of dendritic spines</chapter-title>. <source>Science</source> <volume>345</volume>. Publisher: <publisher-name>American Association for the Advancement of Science</publisher-name>, <fpage>1616</fpage>–<lpage>1620</lpage>. <pub-id pub-id-type="doi">10.1126/science.1255514</pub-id> (<month>Sept</month>. 26, <year>2014</year>).</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname>, <given-names>G.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Sleep promotes branch-specific formation of dendritic spines after learning</article-title>. <source>Science</source> <volume>344</volume>, <fpage>1173</fpage>– <lpage>1178</lpage>. issn: <issn>0036-8075</issn>, <issn>1095-9203</issn>. <pub-id pub-id-type="doi">10.1126/science.1249098</pub-id> (2021) (<month>June</month> 6, <year>2014</year>).</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zenke</surname>, <given-names>F.</given-names></string-name> &amp; <string-name><surname>Ganguli</surname>, <given-names>S.</given-names></string-name></person-group> <article-title>SuperSpike: Supervised Learning in Multilayer Spiking Neural Networks</article-title>. <source>Neural Computation</source> <volume>30</volume>, <fpage>1514</fpage>–<lpage>1541</lpage>. issn: <issn>0899-7667</issn>. <pub-id pub-id-type="doi">10.1162/neco_a_01086</pub-id> (<month>June</month> 1, <year>2018</year>).</mixed-citation></ref>
</ref-list>
<sec id="s7">
<title>Supplementary material</title>
<sec id="s7a">
<title>Gradients, sampling, PRs, and RFs</title>
<p>In this section, we discuss some of the relationships between gradients, sample-based gradient estimates, and coordinated eligibility theories. To do so, we first show how to arrive at the PR-RF decomposition of the gradient, then we take the expectation (over noisy task repetitions) of a neuromodulated Hebbian rule to get a similar result.</p>
<p>Using Einstein notation, basis vectors <italic>e</italic><sub><italic>n</italic></sub>, dual basis vectors <italic>e</italic><sup><italic>m</italic></sup>, <italic>h</italic> as the element-wise derivative of <italic>ϕ</italic>, and <italic>D</italic><sub><italic>h</italic></sub> as matrix with <italic>h</italic> on the diagonal, the derivative of reward with respect to weights <italic>W</italic> is:
<disp-formula id="ueqn7">
<graphic xlink:href="466943v3_ueqn7.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
On the last line, we have defined <italic>b</italic> as (<italic>dr/dy</italic>)<sup><italic>T</italic></sup> and <italic>g</italic>, the gradient output filter or gradient population response change, as <italic>D</italic><sub><italic>h</italic></sub><italic>b</italic>. This has the same form as our coordinated eligibility models.</p>
<p>The same form can be arrived at as the expected value of a set of reward-modulated Hebbian updates (<xref ref-type="bibr" rid="c42">Williams 1992</xref>). When these Hebbian updates are, on average, gradient-following, they are called REINFORCE algorithms (<xref ref-type="bibr" rid="c42">Williams 1992</xref>). Conceptually, it is important to note that REINFORCE algorithms are <italic>defined</italic> as gradient following methods, however, whereas neuromodulated plasticity is frequently defined mathematically, without respect to function (<xref ref-type="bibr" rid="c15">Frémaux &amp; Gerstner 2016</xref>). As such, the two don’t always coincide. Moreover, even when a neuro-modulated Hebbian rule is a REINFORCE algorithm for <italic>some</italic> network, that does not make it the REINFORCE algorithm for the <italic>specific</italic> network it is being applied to. With these points in mind, we can examine the following neuromodulated Hebbian rule, using a local linear expansion of <italic>r</italic> around <inline-formula><inline-graphic xlink:href="466943v3_inline18.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, and denoting firing rate noise by <italic>λ</italic><sub><italic>y</italic></sub>:
<disp-formula id="ueqn8">
<graphic xlink:href="466943v3_ueqn8.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
These equations indicate that when the output firing rate covariance <italic>C</italic><sub><italic>y</italic></sub> is proportional to the matrix of firing rate slopes <italic>D</italic><sub><italic>h</italic></sub>, the neuromodulated Hebbian update is equal to the gradient in expectation. This specific conclusion is the same as that of Williams’ (1992) REINFORCE paper. More interesting, however, is the general reliance on <italic>C</italic><sub><italic>y</italic></sub>, which was not calculated in that work. This term is often assumed to be isotropic (see, e.g., <xref ref-type="bibr" rid="c11">Fiete &amp; Seung 2006</xref>), but in real neural networks, one would not expect it to be Kohn <italic>et al</italic>. 2016. In particular, when <italic>D</italic><sub><italic>h</italic></sub>≈ <italic>I</italic>, which is (notably) always true for neurons in a GELU or ReLU network with firing rates reasonably far from zero, we have that <italic>b</italic> ≈ <italic>g</italic>, and hence <italic>C</italic><sub><italic>y</italic></sub> warps the gradient according to the main dimensions of variability in the network noise. In the case where <italic>C</italic><sub><italic>y</italic></sub> is not full rank, meaning that some dimensions have no noise, it projects those dimensions out of <italic>g</italic>. (Cases where the eigenvalue scales are very different interpolate between the projecting and non-projecting cases.) Since non-isotropic noise is more biologically plausible than isotropic noise, this provides another motivation for constructing the filter transforms <italic>u</italic>(<italic>g</italic>) and <italic>v</italic>(<italic>x</italic>) as we have in the main manuscript.</p>
<p>Finally, note that sampling can also be implemented upstream of a neuron’s activation function. Consider the update equation analogous to REINFORCE here, known as the node perturbation update (<xref ref-type="bibr" rid="c11">Fiete &amp; Seung 2006</xref>):
<disp-formula id="ueqn9">
<graphic xlink:href="466943v3_ueqn9.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
As with the previous equations, shrinking (i.e., regularizing) the covariance matrix here towards a low-rank matrix will project the gradient output filter.</p>
</sec>
<sec id="s7b">
<title>Coordinated eligibility results for reinforcement learning</title>
<p>The coordinated eligibility theory can be applied to supervised, unsupervised, or reinforcement-based plasticity. We applied it to supervised plasticity in the main text, without loss of generality, because this was the most straightforward demonstration to emphasize the geometric relationships between plasticity factors and their impacts on interference and generalization. Notably however, these results also apply to reinforcement-learning and unsupervised scenarios, which are connected to supervised learning through sampled and implicit gradients, respectively. Coordinated eligibility theories, by our definition, posit factor-structured transforms of these gradients, and do not require that such gradients are explicitly computed or represented.</p>
<p>In reinforcement learning, there are unique additional challenges due to the exploration exploitation problem, which impacts sample complexity. Network-based reinforcement learning requires searching over spaces of candidate actions, parameterized by network weights, in order to find good ones and propagate loss information. This makes the relevant search problems high-dimensional, and as a result, methods such as REINFORCE must accumulate many directional derivatives of gradients (i.e., sample many potential changes in their actions) in order to effectively follow loss gradients. These methods typically add noise to each neuron’s activity, and adjust synaptic weights via neuromodulated Hebbian plasticity. A well known limitation of such methods is that they require an inordinate number of samples to converge, relying on noisy perturbations to happen upon useful trajectories. Nevertheless, because they approximate gradient descent, these networks also inherit the usual deficiencies considered in the main text for the case of supervised learning, including catastrophic interference and lack of compositional generalization. Our Coordinated Eligibility Model can mitigate some of these deficiencies while remaining biologically plausible.</p>
<p>By restricting the number of dimensions involved in network plasticity, methods such as ours improve the sample complexity of RL methods, at the potential cost of moving in weight directions that have some significant non-zero angle relative to the un-restricted network gradients. To be clear, this cost is also the price paid for the benefit of avoiding interference, or promoting generalization, however. Previous work has shown how this sample complexity reduction can nonetheless improve learning outcomes (Nassar <italic>et al</italic>. 2021), but did not assess the impacts of different factor geometries, as we have here.</p>
</sec>
<sec id="s7c">
<title>Reinforcement learning simulations</title>
<p>In this section, we briefly describe simulations paralleling those in the main text, applying the CET to contextual bandit tasks. Contextual bandit tasks are simple RL scenarios in which states are visited randomly, and each state requires learning a single (stochastically optimal) response through trial and error. This is typically framed as visiting different casinos, wherein one has a set of slot machines to choose between playing; the context is the casino, the action is the slot machine play, the outcomes are in general stochastic, and the reinforcement learning problem is choosing the best machine in each casino based on reward receipt (which agents must essentially average over time). This setup is the reinforcement learning analogue of supervised input-output learning, such as labeling images. Contexts are analogous to images and actions to labels. The supervised case and the reinforcement one differ only in that actions must be tried and compared in order to determine the correct response for each input, with the additional caveat that feedback may be stochastic.</p>
<p>Any sensible RL model can solve contextual bandit tasks, but in networks, changing contexts generally induces experience-dependent forgetting, if learning is done online and in a blocked fashion. Furthermore, performing gradient descent on policies does nothing to manage generalization of learning from one context to another. These issues are inherited directly from relationships between gradients, as discussed in the main text. Issues related to exploration/sampling exacerbate them, but are fundamentally distinct. As such, coordinated eligibility models can control both interference and generalization in RL models, just as in the main text, which we demonstrate here.</p>
<p>Our reinforcement learning simulations used simple nonlinear three-layer neural networks, with 100 input neurons and 200 hidden neurons. RF-separation simulations used a single head with 10 output neurons, and PR-separation simulations used 20-unit heads for each task. Network weights were initialized according to log-normal distributions, while network outputs were softmaxed to get action probabilities, then subject to an expected-value loss. Neurons used softplus differentiable, positive-firing-rates. The networks were therefore non-linear, owing to both the softmax criteria and the softplus activations. During training, they learned sequences of 20 contextual bandit tasks, in a blocked fashion, with each block (single task training episode) containing 100 training trials. Backward transfer (destructive interference) was assessed by examining performance during a second epoch of training (a second training pass through the entire task set). To separate the CET’s impacts on sample complexity and on factor geometry, we defined “sub-trials” as loops of gradient accumulation steps. Each trial was composed of 500 sub-trials, and during each sub-trial, networks output an action probability distribution, and were presented with a reward-prediction error.</p>
<p>Our RF-splitting simulations (<xref rid="fig1" ref-type="fig">figure 1S</xref>) made use of 20 input-output pairs. Each input was a 40-hot binary vector, composed of a random portion and a deterministic one. The deterministic component was used to guarantee every vector had at least one input that was unique, whereas the random component provided overlap. Specifically, the unique portion of each input was a 1-hot vector of length 20, which was prepended to a randomly permuted 40-hot vector of length 80. Each input had a unique associated target action (1-hot of length 20 serving as a softmax output target). Networks were trained to produce these actions as described above, using either a policy-gradient method (REINFORCE) or a projected policy gradient (our CET). Projections were defined offline to isolate the unique elements of different inputs and project policy gradient input filters onto these components. (Note that this can also be done online, as in the main text). Training curves over the whole simulation (<xref rid="fig1" ref-type="fig">figure 1S, A</xref>) illustrate that both methods completely learn each task. The policy gradient method produces significant forgetting (<xref rid="fig1" ref-type="fig">figure 1S, A</xref> and <xref rid="fig1" ref-type="fig">B</xref>), however, whereas the coordinated eligibilty model does not. Finally, the accuracy of the sampled population response filters can be seen to be equivalent across the two simulations (as it should be, <xref rid="fig1" ref-type="fig">figure 1S</xref>, panel <xref rid="fig1" ref-type="fig">C</xref>).</p>
<p>Our PR-splitting simulations (<xref rid="fig2" ref-type="fig">figure 2S</xref>) also consisted of 20 input-output pairs. Like the tasks in the text, these all used the same constant input, and each required a single target action. Each task used a different readout head, which was a random matrix with i.i.d. log-normal entries, randomly scaled by row (fixed across epochs) to have mean 1-norms of 1, with a standard deviation of 0.2. Hidden weights were distributed according to the same log-normal distribution parameters. PR projections were defined with each task’s firing-rate sample space in the joint null-space of all other task’s readout weights. These projections were pulled back to the population response space on z-values through the instantaneous firing rate nonlinearities, for sampling. As above, both policy gradient and coordinated eligibility networks learned the all tasks completely (<xref rid="fig2" ref-type="fig">figure 2S</xref>, panel <xref rid="fig2" ref-type="fig">A</xref>), while the policy gradient updates produced significant backward transfer (<xref rid="fig2" ref-type="fig">figure 2S, A</xref> and <xref rid="fig2" ref-type="fig">B</xref>). Unlike the RF simulation, population response changes had consistent angles of roughly 0.4<italic>π</italic> relative to true gradients (<xref rid="fig2" ref-type="fig">figure 2S, C</xref>), indicating that the optimal updates (for the whole curriculum) were very nearly orthogonal to the gradient updates.</p>
<p>Analogous effects to those seen in <xref rid="fig5" ref-type="fig">figures 5</xref>,<xref rid="fig6" ref-type="fig">6</xref>, and <xref rid="fig7" ref-type="fig">7</xref>, relating to generalization and composition of plasticity components can also be shown in reinforcement learning simulations.</p>
</sec>
<ref-list>
<title>References</title>
<ref id="sc1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fiete</surname>, <given-names>I. R.</given-names></string-name> &amp; <string-name><surname>Seung</surname>, <given-names>H. S.</given-names></string-name></person-group> <article-title>Gradient Learning in Spiking Neural Networks by Dynamic Perturbation of Conductances</article-title>. <source>Physical Review Letters</source> <volume>97</volume>, <fpage>048104</fpage>. issn: <issn>0031-9007</issn>, <issn>1079-7114</issn>. <pub-id pub-id-type="doi">10.1103/PhysRevLett.97.048104</pub-id> (<month>July</month> 28, <year>2006</year>).</mixed-citation></ref>
<ref id="sc2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Frémaux</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Gerstner</surname>, <given-names>W.</given-names></string-name></person-group> <article-title>Neuromodulated Spike-Timing-Dependent Plasticity, and Theory of Three-Factor Learning Rules</article-title>. <source>Frontiers in Neural Circuits</source> <volume>9</volume>. issn: <issn>1662-5110</issn>. <pub-id pub-id-type="doi">10.3389/fncir.2015.00085/full</pub-id> (2020) (<year>2016</year>).</mixed-citation></ref>
<ref id="sc3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kohn</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Coen-Cagli</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Kanitscheider</surname>, <given-names>I.</given-names></string-name> &amp; <string-name><surname>Pouget</surname>, <given-names>A.</given-names></string-name></person-group> <article-title>Correlations and Neuronal Population Information</article-title>. <source>Annual Review of Neuroscience</source> <volume>39</volume>, <fpage>237</fpage>–<lpage>256</lpage>. issn: <issn>0147-006X</issn>, <issn>1545-4126</issn>. <pub-id pub-id-type="doi">10.1146/annurev-neuro-070815-013851</pub-id> (<month>July</month> 8, <year>2016</year>).</mixed-citation></ref>
<ref id="sc4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Scott</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>Bhandari</surname>, <given-names>A.</given-names></string-name></person-group> <article-title>Noise Correlations for Faster and More Robust Learning</article-title>. <source>The Journal of Neuroscience</source> <volume>41</volume>, <fpage>6740</fpage>–<lpage>6752</lpage>. issn: <issn>0270-6474</issn>, <issn>1529-2401</issn>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.3045-20.2021</pub-id> (<month>Aug</month>. 4, <year>2021</year>).</mixed-citation></ref>
<ref id="sc5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Williams</surname>, <given-names>R. J.</given-names></string-name></person-group> <article-title>Simple statistical gradient-following algorithms for connectionist reinforcement learning</article-title>. <source>Machine learning</source> <volume>8</volume>, <fpage>229</fpage>–<lpage>256</lpage> (<year>1992</year>).</mixed-citation></ref>
</ref-list>
</sec>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.103701.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Zenke</surname>
<given-names>Friedemann</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Friedrich Miescher Institute for Biomedical Research</institution>
</institution-wrap>
<city>Basel</city>
<country>Switzerland</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>valuable</bold> study introduces a novel method for controlling generalization and interference in neural networks undergoing continual learning. The authors provide <bold>solid</bold> evidence that their parsimonious method performs better than online gradient descent in several continual learning situations while providing biologically plausible links to three-factor learning rules. However, empirical validation is limited to linear networks, which raises questions about the generality of the results in non-linear networks. While the work is interesting to theoretical and experimental neuroscientists, improving the article presentation by clearly defining terminology before using it and providing more details on the setup of the simulation experiments would be vital to make the article more accessible.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.103701.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This paper advances a new understanding of plasticity in artificial neural networks. It shows that weight changes can be decomposed into two components: the first governs the magnitude (or gain) of responses in a particular layer; the second governs the relationship of those responses to the input to that layer. Then, it shows that separate control of these two factors via a surprise-based metaplasticity can avoid catastrophic forgetting as well as induce successful generalization in different conditions, through a series of simulation experiments in linear networks. The authors argue that separate control of the two factors may be at work in the brain and may underlie the ability of humans and other animals to perform successful sequential learning. The paper is hampered by confusing terminology and the precise setup of some of the simulations is unclear. The paper also focuses exclusively on the linear case, which limits confidence in the generality of the results. The paper would also benefit from the inclusion of specific predictions for neural data that would confirm the idea that the separate control of these two factors underlies successful continual learning in the brain.</p>
<p>Strengths:</p>
<p>(1) The theoretical framework developed by the paper is interesting, and could have wide applicability for both training networks and for understanding plasticity.</p>
<p>(2) The simulations convincingly show benefits to the coordinated eligibility model of plasticity advanced by the authors.</p>
<p>Weaknesses:</p>
<p>(1) The simulation results are limited to simple tasks in linear networks, it would be interesting to see how the intuitions developed in the linear case extend to nonlinear networks.</p>
<p>(2) The terminology is somewhat confusing and this can make the paper difficult to follow in some places.</p>
<p>(3) The details of some of the simulations are lacking.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.103701.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Scott and Frank propose a new method for controlling generalization and interference in neural networks that undergo continual learning. Their method called coordinated eligibility models (CEM), relies on the factorization of synaptic updates into input-driven and output-driving factors. They subsequently employ the fact that it is sufficient to orthogonalize any one of these two factors across different data points to nullify the interference during learning. They exemplify this on a number of toy tasks while comparing their result to vanilla gradient.</p>
<p>Strengths:</p>
<p>The specific mechanism proposed here is novel (while, as authors acknowledge, there is a large number of other mechanisms for the selective recruitment of synapses for the prevention of catastrophic forgetting). Furthermore, it is simple, elegant, and to a large extent biologically plausible, potentially pointing to specific and testable aspects of learning dynamics.</p>
<p>Weaknesses:</p>
<p>(1) Scope and toy nature of experiments: the model was only applied to very simple problems tailored specifically to demonstrate the strengths of the CEM method. Furthermore, single hyperparameter setting is presented for every scenario which leaves it questionable how general the numerical results are. The selection of input, output dimensionality and data set size also seems to be underexplored. Will a larger curriculum, smaller or larger dimension, compromise any of the CEM ingredients? Restriction to linear models seems arbitrary (it should be a no-time test to add non-linearity within a pytorch framework that authors used), and applicability for any non-synthetic problem is not obvious.</p>
<p>It is also unclear to what extent of domain knowledge is needed for surprise signals to be successfully generated. Can the authors make a stronger case about novel curriculum entries being easily recognizable by cosine distance, either in the brain or in machine learning? Can they alternatively demonstrate their method on a less toy benchmark (e.g. permuted MNIST from Kirkpatrick et al 2017 that they cite)?</p>
<p>Another limitation is that unlike smoother models of plasticity budgets (e.g. Kirkpatrick et al 17, Zenke et al 17), here eligibility seems to be lost forever, once surprise is applied. What happens to the model if more data from a previously visited task becomes available? Will the system be able to continue learning within the right context and how does CEM perform compared to other catastrophic-forgetting-prevention strategies?</p>
<p>(2) The clarity and organization must be improved. Specifically, the balance between verbal descriptions, equations, figures, and their captions needs to be improved. For example - two full-size equations are dedicated to the application of linear regression (around lines 183 and 236) while by far less obvious math such as settings for fig 7, including 'feature loadings', 'demands', etc., is presented in a hardly readable mixture figure and main text. Similarly, the surprise mechanism which is a key ingredient for the model is presented in a very non-straightforward fashion, scattered between the main text, figure, and methods. The figure legends are poorly informative in many cases as well (see minor comments for examples).</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.103701.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This paper describes a modification of gradient descent learning, and shows in several simulations that this modification allows online learning of linear regression problems where naive gradient descent fails. The modification starts from the observation that the rank-1 weight update of online gradient learning can be written as the outer product Δw ∝ g xᵀ of a vector g and the input x. Modifying this update rule, by projecting g or x to some subspaces, i.e. Δw ∝ Pg (Qx)ᵀ, allows for preventing the typical catastrophic forgetting behavior of online gradient descent, as confirmed in the simulations. The projection matrices P and Q are updated with a &quot;surprise&quot;-modulation rule.</p>
<p>Strengths:</p>
<p>I find it interesting to explore the benefits of alternatives to naive online gradient learning for continual learning.</p>
<p>Weaknesses:</p>
<p>The novelty and advancement in our theoretical understanding of plasticity in neural systems are unclear. I appreciate gaining insights from simple mathematical arguments and simulations with toy models, but for this paper, I do not yet clearly see what I learned: on the mathematical/ML/simulation side it is unclear how it relates to the continual learning literature, on the neuroscience/surprise side I see only a number of papers cited but not any clear connection to data or novel insights.</p>
<p>More specifically:</p>
<p>(1) It is unclear what exactly the &quot;coordinated eligibility theory&quot; is. Is any update rule that satisfies Equation 4 included in the coordinated eligibility theory? If yes, what is the point: any update rule can be written in this way, including standard online gradient descent. If no, what is it? It is not Equation 5 it seems, because this is called &quot;one of the simplest coordinated eligibility models&quot;.</p>
<p>(2) There is a lot of work on continual learning which is not discussed, e.g. &quot;Orthogonal Gradient Descent for Continual Learning&quot; (Farajtabar et al. 2019), &quot;Continual learning in low-rank orthogonal subspaces&quot; (Chaudhry et al. 2020), or &quot;Keep Moving: identifying task-relevant subspaces to maximise plasticity for newly learned tasks&quot; (Anthes et al. 2024), to name just a few. What is the novelty of this work relative to these existing works? Is the novelty in the specific projection operator? If yes, what are the benefits of this projection operator in theory and simulations? How would, for example, the approach of Farajtabar et al. 2019 perform on the tasks in Figures 3-7?</p>
<p>(3) There is also work on using surprise signals for multitask learning in models of biological neural networks, e.g. &quot;Fast adaptation to rule switching using neuronal surprise&quot; (Barry et al. 2023).</p>
<p>(4) What is the motivation for the projection to the unit sphere in Equation 5?</p>
<p>(5) What is the motivation for the surprise definition? For example, why cos(x⋅μ) = cos(|x||μ|cos(θ)) = cos(cos(θ))? (Assuming x and μ have unit length and θ is the angle between x and μ).</p>
</body>
</sub-article>
</article>