<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">101780</article-id>
<article-id pub-id-type="doi">10.7554/eLife.101780</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.101780.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>A General Framework for Characterizing Optimal Communication in Brain Networks</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0615-1777</contrib-id>
<name>
<surname>Fakhar</surname>
<given-names>Kayson</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>kayson.fakhar@gmail.com</email>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Hadaeghi</surname>
<given-names>Fatemeh</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Seguin</surname>
<given-names>Caio</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Dixit</surname>
<given-names>Shrey</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9081-3088</contrib-id>
<name>
<surname>Messé</surname>
<given-names>Arnaud</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Zamora-López</surname>
<given-names>Gorka</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Misic</surname>
<given-names>Bratislav</given-names>
</name>
<xref ref-type="aff" rid="a5">5</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Hilgetag</surname>
<given-names>Claus C</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a6">6</xref>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00g30e956</institution-id><institution>Institute of Computational Neuroscience, University Medical Center Eppendorf-Hamburg, Hamburg University, Hamburg Center of Neuroscience</institution></institution-wrap>, <city>Hamburg</city> <country>Germany</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01kg8sb98</institution-id><institution>Department of Psychological and Brain Sciences, Indiana University</institution></institution-wrap>, <city>Bloomington</city>, <country>USA</country></aff>
<aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04n0g0b29</institution-id><institution>Center for Brain and Cognition, Pompeu Fabra University</institution></institution-wrap>, <city>Barcelona</city>, <country>Spain</country></aff>
<aff id="a4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04n0g0b29</institution-id><institution>Department of Information and Communication Technologies, Pompeu Fabra University</institution></institution-wrap>, <city>Barcelona</city>, <country>Spain</country></aff>
<aff id="a5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01pxwe438</institution-id><institution>McConnell Brain Imaging Centre, Montréal Neurological Institute, McGill University</institution></institution-wrap>, <city>Montréal</city>, <country>Canada</country></aff>
<aff id="a6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05qwgg493</institution-id><institution>Department of Health Sciences, Boston University</institution></institution-wrap>, <city>Boston</city>, <country>USA</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Schneider-Mizell</surname>
<given-names>Casey M</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Allen Institute for Brain Science</institution>
</institution-wrap>
<city>Seattle</city>
<country>United States of America</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Cardona</surname>
<given-names>Albert</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Cambridge</institution>
</institution-wrap>
<city>Cambridge</city>
<country>United Kingdom</country>
</aff>
</contrib>
</contrib-group>
<pub-date date-type="original-publication" iso-8601-date="2024-11-11">
<day>11</day>
<month>11</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP101780</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-08-09">
<day>09</day>
<month>08</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-06-12">
<day>12</day>
<month>06</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.06.12.598676"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Fakhar et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Fakhar et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-101780-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Communication in brain networks is the foundation of cognitive function and behavior. A multitude of evolutionary pressures, including the minimization of metabolic costs while maximizing communication efficiency, contribute to shaping the structure and dynamics of these networks. However, how communication efficiency is characterized depends on the assumed model of communication dynamics. Traditional models include shortest path signaling, random walker navigation, broadcasting, and diffusive processes. Yet, a general and model-agnostic framework for characterizing optimal neural communication remains to be established.</p><p>Our study addresses this challenge by assigning communication efficiency through game theory, based on a combination of structural data from human cortical networks with computational models of brain dynamics. We quantified the exact influence exerted by each brain node over every other node using an exhaustive multi-site virtual lesioning scheme, creating optimal influence maps for various models of brain dynamics. These descriptions show how communication patterns unfold in the given brain network if regions maximize their influence over one another. By comparing these influence maps with a large variety of brain communication models, we found that optimal communication most closely resembles a broadcasting model in which regions leverage multiple parallel channels for information dissemination. Moreover, we show that the most influential regions within the cortex are formed by its rich-club. These regions exploit their topological vantage point by broadcasting across numerous pathways, thereby significantly enhancing their effective reach even when the anatomical connections are weak.</p><p>Our work provides a rigorous and versatile framework for characterizing optimal communication across brain networks and reveals the most influential brain regions and the topological features underlying their optimal communication.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>In the realm of network science, the human brain represents a perfect example of a complex system. Viewing the brain as a network has uncovered key topological characteristics, including the presence of densely interconnected modules, central hubs, and hierarchical structures in information processing [<xref ref-type="bibr" rid="c1">1</xref>,<xref ref-type="bibr" rid="c2">2</xref>]. This perspective, particularly obtained by analysis of large-scale structural brain networks — the connectome — elucidated that a range of network characteristics arise from the interplay between two conflicting evolutionary imperatives: minimizing wiring costs on one hand and maximizing signaling efficiency on the other [<xref ref-type="bibr" rid="c3">3</xref>–<xref ref-type="bibr" rid="c5">5</xref>].</p>
<p>The brain is confined within a three-dimensional space, making the formation and maintenance of long-range connections metabolically expensive. Conversely, a network predominantly comprising short-range connections, although economical in wiring costs, necessitates multiple intermediate nodes for information relay to distant nodes, diminishing effective communication capacity [<xref ref-type="bibr" rid="c6">6</xref>,<xref ref-type="bibr" rid="c7">7</xref>]. It has been shown that this dichotomy leads to a compromise, where predominantly short-range connections among neighboring regions coexist with a selective set of long-range connections that function as communication shortcuts [<xref ref-type="bibr" rid="c8">8</xref>,<xref ref-type="bibr" rid="c9">9</xref>].</p>
<p>In this view, signaling efficiency between nodes is graded based on the number of steps from a source to a target, presupposing information transmission <italic>exclusively</italic> along one path, the shortest path [<xref ref-type="bibr" rid="c10">10</xref>]. However, it has been argued that such a conceptualization of signaling unrealistically requires brain regions to possess global knowledge of the network’s connectivity [<xref ref-type="bibr" rid="c11">11</xref>]. To address this issue, alternative <bold>communication models (CMs)</bold> have been developed, accommodating other conceptualizations, such as cascading dynamics and diffusive processes, where the information permeates through the network via parallel pathways. Consequently, alternative conceptualizations of how distant brain regions interact yield diverse interpretations of communication efficiency [<xref ref-type="bibr" rid="c12">12</xref>]. For instance, as mentioned above, the <bold>shortest path efficiency (SPE)</bold>, derived from the inverse of the shortest path length, reflects efficiency under the assumption that information flows along the shortest path only. In contrast, <bold>diffusion efficiency (DE)</bold>, defined by the inverse of the average path length of an unbiased random walker traversing from the source to the target, assumes information to propagate along parallel pathways with no specific preference for any of them. Quantifying how much a source can effectively influence its target depends on which perspective is chosen. Given SPE, the source has optimal influence over its unconnected target, if the number of intermediate nodes along the shortest path between them is minimal. Given DE, the source has optimal influence over its unconnected target, if it has the largest number of pathways connected with it, regardless of how long they are. Thus, optimality of signaling depends on assumptions about the regime in which the information propagates in the network.</p>
<p>Moreover, despite this plurality of signaling conceptualizations, these models of propagation simplify communication patterns to linear, discrete interactions, thereby abstracting the complexities inherent in biological systems, such as non-linear interactions, oscillatory behaviors, and conductance delays [<xref ref-type="bibr" rid="c12">12</xref>,<xref ref-type="bibr" rid="c13">13</xref>]. A plethora of biophysical models have been developed to address such details by modeling the behavior of regions as the average activity of biophysically grounded neuronal populations [<xref ref-type="bibr" rid="c14">14</xref>,<xref ref-type="bibr" rid="c15">15</xref>]. This mean-field formalization of brain activity comes with its own definitions of communication, such as communication through coherence, positing neuronal synchronization as a pivotal mechanism [<xref ref-type="bibr" rid="c16">16</xref>–<xref ref-type="bibr" rid="c18">18</xref>].</p>
<p>Therefore, while it is acknowledged that the brain’s structural evolution favors optimal inter-regional communication, a consensus on the precise model of communication within brain networks and subsequently its optimality, remains missing due to conflicting assumptions about signal propagation. Addressing this issue is of particular interest, for several reasons. For example, the identification of structural features that improve information flow in brain networks elucidates their role in disease and may allow targeting them for specific therapeutic interventions. Such insights may also guide the design of neuromorphic systems that achieve a similar level of resource management as the brain [<xref ref-type="bibr" rid="c19">19</xref>–<xref ref-type="bibr" rid="c21">21</xref>].</p>
<p>To provide a mathematically rigorous definition of optimal communication, we resort to game theory. This field analyzes interactions among agents to offer a normative account, that is, to prescribe <italic>how they should behave</italic> in a defined scenario, given their goals, the rules of the game, and the consequences of others’ decisions [<xref ref-type="bibr" rid="c22">22</xref>]. Notably, game theoretical solutions are well established in fields where players lack ‘agency’. In behavioral ecology, for example, game theoretical models are used to define normative descriptions for how animals should behave in scenarios involving optimizing a goal, such as foraging or reproducing [<xref ref-type="bibr" rid="c23">23</xref>,<xref ref-type="bibr" rid="c24">24</xref>]. Thus, this theoretical approach is well suited for investigating a pivotal question in neuroscience: How should brain regions interact, considering the limitations imposed by the structural connectome and the behavior of other regions, with the aim of optimizing their communication efficiency? This question is framed by two principal constraints and one overarching objective. The first constraint is imposed by the <italic>brain’s network structure</italic>, delineating interactions between nodes. The second constraint is the <italic>behavior of other nodes</italic>, dictating their response to incoming signals. The objective, in this context, is to maximize signaling efficiency – conceptualized as the extent of a node’s influence over others. Such a formulation gives rise to a concrete definition of optimality as an equilibrium point where no region can increase its influence on others any further. Notably, this game-theoretical approach offers a model-agnostic and data-driven toolkit to define communication within brain networks. By ‘model agnostic’ we mean that the game can be constructed using any model of information propagation and local dynamics incorporated into an arbitrary connectome structure. It then defines optimality in a sense that, given the defined game, how much each node can influence other nodes. Note that optimality in this framework depends on the defined game, meaning that optimal communication can differ given different network architectures and models of communication.</p>
<p>In the present work (summarized in <xref rid="fig1" ref-type="fig">Figure 1</xref>), we used the human connectome, large-scale models of dynamics, and a game-theoretical perspective of signaling to address three questions: First, how does the communication landscape look like in the state of <bold>optimal signal propagation (OSP)</bold>, where nodes maximize their influence on each other given the structural and dynamical constraints? Second, which model of information propagation aligns best with the data-driven formulation of signaling? And third, which brain regions are the most influential ones and why?</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Overview of the present work:</title>
<p>We used the human connectome and a linear model of local node dynamics as the main network model. Moreover, we explored Macaque and mouse connectomes, as well as nonlinear models including a neural mass model of local dynamics. These two variables, network structure and local dynamics, define our ‘game constraints’, since they dictate how information flows in the network and how nodes respond to incoming signals. For every game, such as a linear model of dynamics on the human connectome, the approach of MSA (see <xref rid="fig2" ref-type="fig">Figure 2</xref>), uncovered the ‘optimal influence’ landscape of the network, that is, a game-theoretical equilibrium point where nodes cannot unilaterally increase their influence on each other any further. We compared the optimal influence profile of nodes at this point with various communication models and analyzed the most influential nodes in such a signal propagation regime. SPE: Shortest path efficiency, NE: Navigation efficiency, SI: Search information.</p></caption>
<graphic xlink:href="598676v1_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>To answer the first question, we used <bold>multi-perturbation Shapley value analysis (MSA)</bold> and approximately 7,000 million combinations of virtual lesions to precisely quantify the amount of influence exerted by each brain region (node) over every other node. We call this communication landscape the <bold>‘Optimal Influence’ (OI)</bold>. To answer the second question, we systematically compared putative models of neural communication against the derived OI and found <bold>Communicability (CO)</bold> [<xref ref-type="bibr" rid="c25">25</xref>] to capture a substantial variation observed in OI. CO is a non-conservative cascade model that posits regions to broadcast their signals across multiple parallel pathways. However, our results indicate that CO tends to underestimate the actual influence exerted via longer pathways. Thus, we proposed complementary analytical models that better replicate the OI. Further investigations using a nonlinear model of dynamics and a <bold>neural mass model (NMM)</bold> allowed us to determine which of the two game constraints more strongly shape neural signaling, the global network architecture or local dynamics. We found that all models of local dynamics yielded effectively the same landscape, suggesting that network topology is a more important constraint than specific models of local dynamics. Finally, to address the third question, we revealed that areas located on the medial surface of the brain, including the precuneus, anterior cingulate cortex, and superior prefrontal cortex, exerted the strongest influence across the brain network. Notably, these regions are components of the cortical rich-club organization, which is hypothesized to act as the backbone of large-scale brain communication. Together, our results suggest that signaling in the human brain is best captured by broadcasting-like dynamics, and to optimize their influence, hub regions propagate information over multiple pathways.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Characterizing the State of Optimal Signal Propagation</title>
<p>To elucidate the concept of OSP, we start with an intuitive example. Consider a scenario where an orchestra attempts to distribute funds raised from a performance. A proposal would be to divide the funds equally among all members, a strategy that leads to the ‘egalitarian value’ by which every musician is paid the same amount [<xref ref-type="bibr" rid="c26">26</xref>]. However, considering discrepancies in the effort of individual players — ranging from ensemble players to soloists and a conductor — makes this strategy <italic>unfair</italic> for those who contributed more. Assuming that everyone is set to maximize their share, the egalitarian proposal is rejected, and counterproposals follow until the <italic>optimally fair solution</italic> is found that is proportional to the invested contribution of every player. One can see this iterative process as traversing a convex solution space with a fixed point, representing the optimal solution. Any other solution is either incorrect, e.g., the solution results in shares that add up to a different value rather than the raised fund, or suboptimal, meaning that a better solution exists which, given enough time, will be selected eventually. Note that, by definition, there cannot be two equally optimal solutions into which the payoff is divided, while it is possible for multiple players to receive the same share, as with the egalitarian strategy.</p>
<p>This complexity mirrors the challenge we address in our study: <italic>accurately decomposing the activity profile of each target node by identifying the precise contribution of each source node</italic>. This problem and the space of all possible solutions for a network of three nodes is depicted in (<xref rid="fig2" ref-type="fig">Figure.2. A</xref> and <xref rid="fig2" ref-type="fig">B</xref>). For every target node in a network of nodes, the space of all possible solutions encompasses dimensions, with the set of potential solutions having an arbitrarily complex structure. Consequently, finding the one optimal solution in this space requires a systematic and extensive exploration of different decomposition solutions. To address this issue, Shapley provided an axiomatic framework that finds the optimal solution (called the Shapley value, see Discussion about its distinction from SHAP values) using information from all possible ways the players can form coalitions [<xref ref-type="bibr" rid="c27">27</xref>]. This algorithm serves as an external authority that, instead of navigating the solution space using proposals and counterproposals, computes the contribution of each player by systematically removing them from the game and tracking the game outcome.</p>
<p>To do so, we used the approach of multi-perturbation Shapley value analysis (MSA) [<xref ref-type="bibr" rid="c28">28</xref>–<xref ref-type="bibr" rid="c30">30</xref>] that applies exhaustive multi-site virtual lesioning across all combinations of source nodes while tracking the resultant changes in the target node, as illustrated in (<xref rid="fig2" ref-type="fig">Figure 2. C.</xref>) The approach is analogous to repeatedly performing the same musical piece while each time a subset of players is excluded, thereby discerning each individual’s contribution to the performed track (see, <italic>e</italic>.<italic>g</italic>., [<xref ref-type="bibr" rid="c31">31</xref>]). For instance, the contribution of a cello player to the song is easily distinguished by taking the difference between two pieces, once with the cello player included and once without. By evaluating all possible combinations of players, higher-order interactions are then accounted for (<italic>e</italic>.<italic>g</italic>., contributions of the entire string ensemble), and thus the exact contribution of each player across all possible configurations is inferred (see section <italic>Game-theoretical Framework</italic> in Materials and Methods for more details). In essence, our framework reveals the unique itemized description of each player’s contribution to the overall outcome. This detailed analysis allows for a precise division of payoffs, ensuring that players have no incentive to deviate from their allocated share [<xref ref-type="bibr" rid="c32">32</xref>,<xref ref-type="bibr" rid="c33">33</xref>]. The resulting game-theoretical equilibrium state, here termed the optimal signal propagation state, represents the only fair allocation of nodal influence in which no better solution can be found. Note that the ‘equilibrium’ here refers to the unique point in the solution space of the division problem and not the neural space (See Discussion).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Visual summary of the MSA approach:</title>
<p><bold>A</bold>. A simple toy network with two sources and one target, in which the sources have different amounts of influence on the target. <bold>B</bold>. For this toy network, the space of all possible ways in which the activity of the target node can be decomposed into contributions from source nodes has two dimensions. There exists a subset of potential solutions where the activity of the target node is correctly decomposed, but the decomposition is not optimal. There exists one equilibrium point where the decomposition is correct and optimal. <bold>C</bold>. For every game, that is, the simulation of a whole-brain computational model, MSA performs extensive multi-site lesioning analysis to uncover the influence of every node on every other node. For every target node, MSA lesions combinations of source nodes, tracks how the activity of the target node changes given each perturbation and, for all source nodes, computes the difference between two scenarios: one with the source node included in the lesion-set, and the other where the source node is not lesioned. The difference between these two cases defines the contribution of the source to that specific coalition/combination of sources. Averaged over all contributions, the time-varying contribution of each source is then inferred. Iterating over all nodes results in the ‘optimal influence’ landscape that can be decomposed into two components: Direct influences, where nodes influence their connected neighbors, and indirect influences, where nodes influence distant unconnected nodes.</p></caption>
<graphic xlink:href="598676v1_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>In our work, the ‘game’ was conceptualized as a large-scale model of the brain dynamics approximating the empirical <bold>functional connectivity (FC)</bold> by associating a differential equation to each node of the given <bold>structural connectivity (SC)</bold>. Specifically, utilizing the consensus SC and averaged FC data from 70 healthy young individuals [<xref ref-type="bibr" rid="c34">34</xref>,<xref ref-type="bibr" rid="c35">35</xref>], we calibrated a linearized Wilson-Cowan model, as detailed in the ‘Large-scale Computational Models of the Brain Dynamics’ section under Materials and Methods. Then, MSA was used to perform systematic <italic>in-silico</italic> lesioning of combinations of source nodes while tracking the altered activity of a target node. This iterative process over all nodes elucidates the comprehensive influence landscape of every node on every other node within the network (illustrated in <xref rid="fig2" ref-type="fig">Figure 2</xref>). This landscape depicts the extent of influence one node exerts over another under the state of OSP.</p>
<p><xref rid="fig2" ref-type="fig">Figure 2</xref> reveals that brain regions exert influence not only on their directly connected neighbors, but also on distant and unconnected regions. This observation suggests that optimal communication within the brain requires the propagation of signals beyond immediate connections, traversing through intermediate regions to form multi-step processing pathways. This notion is supported by evidence of significant functional coupling between spatially distant, unconnected regions [<xref ref-type="bibr" rid="c13">13</xref>]. We then reorganized the OI matrix according to established large-scale functional brain modules, <italic>i</italic>.<italic>e</italic>., the resting-state networks, as depicted in <xref rid="fig3" ref-type="fig">Figure 3</xref>. We calculated two key metrics: firstly, the average intra- and inter-module influence, which quantifies the normalized aggregate influence that regions belonging to a module exert both internally and on other modules. Secondly, we assessed the heterogeneity of these influences to determine the diversity of communication patterns within and between modules. A low heterogeneity indicates a narrow distribution of normalized total influence among nodes, measured as the standard deviation, whereas high heterogeneity suggests a wide variation in interaction strengths. We then asked <italic>whether any modules exhibited deviations from the expected levels of influence and heterogeneity</italic>. We derived the expected level via the egalitarian strategy where influence is uniformly distributed across all modules, corresponding to an equal division of %100 of the flow among the nine modules. Our analysis revealed a generally balanced communication landscape, with the largest deviations being approximately %3. However, the default mode network stood out, demonstrating both substantial average intra- and inter-module influence and lower heterogeneity (<xref rid="fig3" ref-type="fig">Figure 3</xref>). This finding implies that nodes in the default mode network have a large and relatively similar amount of influence over each other and the rest of the brain. In contrast, the auditory network is characterized by a more varied and modest level of influence, predominantly within its own module, but extending to others as well. Together, the results presented in <xref rid="fig3" ref-type="fig">Figure 3</xref> suggest that while there is a relatively homogeneous level of influence within and between different cognitive modules, the default mode network distinguishes itself as a key orchestrator of brain-wide communication dynamics.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Large-scale network organization of the optimal influence landscape:</title>
<p>Optimal influences were reorganized according to nine large-scale functional network modules and characterized by two metrics: 1. Average influence, which captures the normalized total influence of a given module within itself and to other modules. 2. Heterogeneity of influences, accounting for the normalized variation of influences within a functional module and to other modules. The egalitarian value represents a naive strategy for assigning contributions in which all players are assumed to contribute equally, i.e., by equal division of the total influence among all nine functional modules. The bars represent how much each module deviates positively or negatively from the egalitarian assumption.</p></caption>
<graphic xlink:href="598676v1_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Collectively, our findings in this section indicate that manipulating a single region can impact the global dynamics of the entire brain (also as shown by [<xref ref-type="bibr" rid="c36">36</xref>–<xref ref-type="bibr" rid="c38">38</xref>]), extending beyond anatomically connected regions. As a result, a critical question arises: <italic>Which poly-synaptic signaling conceptualization most accurately encapsulates these observed indirect influences?</italic></p>
</sec>
<sec id="s2b">
<title>Optimal Signaling via Broadcasting Over Parallel Pathways</title>
<p>To determine which model of signal propagation most accurately captures the indirect influence exerted by brain regions on one another, we explored a spectrum of communication models, spanning from routing strategies to diffusive processes [<xref ref-type="bibr" rid="c12">12</xref>,<xref ref-type="bibr" rid="c39">39</xref>]. Routing strategies postulate that information travels predominantly along, or with respect to the shortest path. As introduced before, SPE is straightforward in its approach, focusing on the shortest path alone. <bold>Navigation Efficiency (NE)</bold>, on the other hand, is a geometrically greedy routing model, aiming to minimize the physical distance to a target node at each step. <bold>Search Information (SI)</bold> quantifies the amount of information required for a random walker to find and navigate along the shortest path. Therefore, the more the required information, the more difficult the communication between two nodes is assumed to be. Conversely, at the opposite end of the spectrum lie diffusion processes that envision information cascades throughout the network. This could involve longer, even recurrent routes to the same nodes. The efficiency of signaling under these processes is then quantified by CO and DE. CO adopts a broadcasting strategy, whereby information spreads from the source and reaches the target through multiple pathways, while being subjected to exponential decay with each step. This decay inherently reduces the impact of longer pathways. DE, in contrast, does not incorporate attenuation, focusing instead on counting the steps a random walker takes from source to target. For detailed descriptions of these models, refer to the ‘Communication Models’ section under Materials and Methods.</p>
<p>A simple pairwise Pearson’s correlation between OI and each CM matrices showed a large positive correlation between OI and CO (R<sup>2</sup>=0.88; all p-values in this work are strictly smaller than 0.0001 unless mentioned otherwise) and a large negative relationship with SI (R<sup>2</sup>=0.68) while other metrics such as SPE, NE, and DE exhibited nonlinear relationships with OI. This finding (<xref rid="fig4" ref-type="fig">Figure 4</xref>) suggests that, although all conceptualizations capture a degree of OI, the one assuming an attenuating diffusion dynamic for the signal propagation over multiple pathways most effectively mirrors OI. This result aligns with existing studies indicating CO’s efficacy in capturing the spread of electrical stimulation to unconnected nodes [<xref ref-type="bibr" rid="c40">40</xref>], predicting large-scale functional modules more accurately than SC [<xref ref-type="bibr" rid="c41">41</xref>], and determining the degree of compensation by other regions following perturbation [<xref ref-type="bibr" rid="c42">42</xref>].</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Comparison of optimal influences with other putative communication measures:</title>
<p>Pairwise Pearson’s correlation between each communication measure and optimal influences, to characterize the alignment with existing communication models. Communicability (r=0.94) and Search Information (r=-0.83) had the best alignment in this univariate setting.</p></caption>
<graphic xlink:href="598676v1_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>However, we noticed that CO slightly underestimates the true influence of longer pathways. To address this limitation, three alternative approaches were explored: adjusting communicability with a scaling factor <bold>(scaled communicability; scaled CO)</bold> [<xref ref-type="bibr" rid="c43">43</xref>], using a linear instead of exponential attenuation <bold>(Linear Attenuation Model; LAM)</bold>, and employing the covariance structure of a <bold>spatial autoregressive model (SAR)</bold> that considers linear attenuation and regional co-fluctuation. Each of these models incorporates a single adjustable parameter: a scaling factor for scaled CO, an attenuation factor for LAM, and a degree of spatial influence for SAR. After fitting these parameters to replicate OI, we found that, except for SAR, the other two models failed to rectify the issue (as shown in <xref rid="fig5" ref-type="fig">Figure 5. A</xref>). While scaled CO and LAM showed marginal improvements in variance explained (R<sup>2</sup>=0.89 and 0.9, respectively) compared to CO (R<sup>2</sup>=0.88), SAR achieved a near-perfect performance (R<sup>2</sup>=0.997). We then fitted SAR to CO instead of OI to evaluate to which extent CO captures the real degree of spatial influence. Varying the SAR parameter indicated that CO’s positioning on the spectrum is considerably skewed towards a steep attenuation (0.06), in contrast to OI’s more moderate rate of spatial decay (0.43). This finding supports our intuition that CO is overly strict with discounting longer pathways, since it assumes the signal to fade almost seven times faster than it actually does. It also indicates that a wide range of discount factors between 0.2 and 0.7 performs similarly well (<xref rid="fig5" ref-type="fig">Figure 5. B</xref>), relaxing the need to search for an exact value (same applies to the scaling factor of CO and attenuation factor of LAM; see <xref rid="figS1" ref-type="fig">Supplementary Figure 1</xref>).</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Strategies to alleviate the underestimated influence of long-range pathways:</title>
<p><bold>A</bold>. Difference between adjacency matrices of tunable models and OI that indicates where these models underestimate (red) and overestimate (blue) the influence of nodes on each other. <bold>B</bold>. SAR obtains a correlation coefficient of r= 0.99 by increasing the depth by which signals can travel, however, the plot on the bottom shows that a wide range of values from 0.2 to 0.7 can be chosen with small degradation of fit. SAR: Spatial Auto-Regressive model, CO: Communicability, OI: Optimal Influence.</p></caption>
<graphic xlink:href="598676v1_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We subsequently explored the depth of influence in terms of the number of hops, specifically addressing how far a signal travels before its causal impact substantially diminishes. To this end, we used a linear regression model, fitted it to results from progressively diffused signals in the network. Put simply, we iteratively predicted the OI starting from walks of zero length (no spread of influence) and incrementally considered longer walks, applying a monotonic discount to additional steps. The analysis, as depicted in (<xref rid="fig6" ref-type="fig">Figure 6. A</xref>), demonstrated peak performance at the sixth step, achieving an R<sup>2</sup> of 0.75. This means that the summation of only the first six steps captures %75 of the variance in OI (also see <xref rid="figS8" ref-type="fig">Supplementary Figure 8</xref> for the result from an exponential discount instead of linear). Further, a multivariate Lasso regularized linear regression model was trained on all walks simultaneously to identify a parsimonious combination that most effectively predicts OI (<xref rid="fig6" ref-type="fig">Figure 6. B</xref>). Aligning with the result from the univariate model, walks of length five, six, and the eighth steps (excluding seventh) were contributing the most, allowing the model to predict OI with a high degree of accuracy (R<sup>2</sup>=0.96). These results imply that signal influence notably decreases after approximately eight processing steps, despite the network’s diameter being around ten steps, meaning that the information flow between the most distant nodes is heavily degraded (<xref rid="fig6" ref-type="fig">Figure 6</xref>. B). While information from the initial eight steps is sufficient to explain %96 of the OI, the superior predictive performance of models such as SAR, LAM, and CO suggests that incorporating all possible paths yields additional, albeit small, information. Moreover, the real advantage of communication models lies in their relative simplicity compared to using a regularized multivariate model. Altogether, it is important to note that the longer processing pathways that are missed by CO, Scaled CO, and LAM still influence the target node, but based on comparing how much SAR gained in predictive performance, they account for about %5 of the whole communication dynamics. This finding provides a rough estimate of how much mismatch, and in which pathways, are expected when using CO, scaled CO, and LAM in human neuroimaging data. However, when these communication models were applied to mouse and macaque connectomes, a discrepancy in capturing OI in directed networks emerged (<xref rid="figS2" ref-type="fig">Supplementary Figure 2</xref>). SAR marginally outperformed LAM and scaled CO in the mouse connectome (r=0.21, 0.18, 0.17, respectively) but showed significantly better performance in the macaque (r=0.92, 0.24, 0.23, respectively). The enhanced performance from mouse to macaque hints at the potential influence of network size, considering the macaque network comprises 29 nodes compared to the mouse’s 112. Nonetheless, the specific effects of network size, density, reciprocity, weight distribution and normalization, as well as other global characteristics on modelling OI necessitate further systematic investigation using synthetic network models. This finding delineates the limitations of current CMs in accurately depicting optimal signal propagation in large, directed networks. However, the observed inverted U-shaped fitting curves of LAM and scaled CO (detailed in <xref rid="figS2" ref-type="fig">Supplementary Figure 2</xref>) suggest a slower spatial decay in signal propagation than assumed by models like CO. In essence, despite the struggle of these models to precisely capture the optimal signal flow in larger directed networks, there is a consensus that the influence of regions extends further than traditionally postulated by communication models.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Uni-and-multivariate models of OI:</title>
<p><bold>A</bold>. Predictive power of a linear regression model trained on walks up to 15 broadcasting steps. <bold>B</bold>. A regularized multivariate model trained on all steps shows a small set of steps to be sufficient to explain %96 of OI on average. Each dot represents one cross-validation trial (N=100). <bold>C</bold>. Sets of regularized multivariate models were trained on network features at each degree of spatial influence for SAR and LAM to capture the impact of this parameter on the performance of the statistical model. The dashed line on the left shows a scenario when the degree of spatial influence is zero, effectively rendering SAR an identity matrix. The second dashed line indicates where the model performed the best, explaining %99 OI. <bold>D</bold>. Bars represent the contribution of each feature to the model, averaged over degrees of influence. Error bars indicate the %95 confidence interval. OI: Optimal influence.</p></caption>
<graphic xlink:href="598676v1_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>In our final analysis of this section, we sought to determine if other communication models, despite their complex relationship with OI, could surpass CO in predicting it. Additionally, it is possible for more intuitive variables, such as the fiber length or Euclidean distance, to provide better predictive performance. To see if OI is better predicted using available variables, including CMs, another multivariate regularized linear regression model was employed (illustrated in <xref rid="fig6" ref-type="fig">Figure 6. C</xref>). Excluding SAR, the model successfully explained %93 of the variance in OI using just three variables: LAM, CO, and SPE, with LAM making the most significant contribution. We then trained a set of models with the same variables but different attenuation factors of LAM and SAR to observe the dynamics of feature importance across different factors. To our surprise, at its optimal parameter value, SAR emerged as the predominant predictor, effectively simplifying the statistical model to a univariate format and once again perfectly predicting OI (as seen in <xref rid="fig6" ref-type="fig">Figure 6. C</xref>). SAR maintained its dominance as the most critical variable over a range from 0.1 to 0.8, after which CO became more influential. This shift underscores the role of discounting of the signal, elucidating why DE was the least effective model in our study. The reason is that, at around <italic>α</italic> = 1where no discount is considered, SAR converges to DE, rendering it uninformative, whereas LAM retains its distinctiveness, surpassing both CO and SAR. Averaged over all values of <italic>α</italic> shows that SAR was the most important feature, followed by CO and LAM (<xref rid="fig6" ref-type="fig">Figure 6. D</xref>) which all follow broadcasting-like communication dynamics.</p>
<p>Collectively, our findings indicate that optimal influence in brain networks requires signal propagation across multiple pathways, akin to a broadcasting approach. The influence diminishes with each processing step, but not as quickly as it is assumed by CO. Moreover, a simple statistical model, <italic>i</italic>.<italic>e</italic>., SAR, accurately predicts the network’s influence structure at the optimal signal propagation regime. Importantly, previous studies indicated that SAR performs as well as many other biophysically detailed NMMs in predicting the FC [<xref ref-type="bibr" rid="c44">44</xref>,<xref ref-type="bibr" rid="c45">45</xref>]. Interestingly, comparing the performance of multivariate models against simple CMs suggests that little is gained from additional variables and more computationally expensive predictive models.</p>
<p>It is important to acknowledge that all CMs, including SAR, are predicated on a linear dynamic model, prioritizing simplicity over biophysical complexity. However, brain regions are argued to perform nonlinear operations, show oscillatory patterns of activity and show metastability by switching between multiple states to support cognition and behavior. Therefore, to affirm the notion of optimal communication in brain networks, it is essential to compare these findings with more realistic dynamics that capture such complex phenomena.</p>
</sec>
<sec id="s2c">
<title>Global Network Topology is More Influential Than Local Node Dynamics</title>
<p>Previous research has demonstrated that linear models of local dynamics are as effective, if not more so, as nonlinear models in capturing the macroscopic dynamics of the brain [<xref ref-type="bibr" rid="c44">44</xref>,<xref ref-type="bibr" rid="c46">46</xref>–<xref ref-type="bibr" rid="c48">48</xref>]. This observation led us to hypothesize that optimal signal propagation in large-scale brain networks, as measured by fMRI-BOLD signal, might also be adequately represented by linear communication models. In other words, we hypothesized that <italic>optimal signal propagation should follow the same line of reasoning and be relatively consistent across different dynamical models</italic>. The equilibrium state in decomposing contributions should remain consistent across different dynamical models, irrespective of their complexity. This expectation would hold true unless the local dynamics — how regions process incoming signals — impose substantial constraints on information flow within the network.</p>
<p>To evaluate this hypothesis, we incorporated two additional models into our analysis: one using a nonlinear <bold>tangent hyperbolic (Tanh)</bold> transfer function, contrasting it with the linear function used in the linear model, and the other one a well-established oscillatory NMM known as the Hopf/Stuart-Landau model, operating in its critical metastable regime [<xref ref-type="bibr" rid="c49">49</xref>]. Pearson’s correlation conducted to compare these models with the linear model confirmed our hypothesis. As depicted in (<xref rid="fig7" ref-type="fig">Figure 7. A</xref>), both the nonlinear and Hopf models showed high correlations with the linear model (R<sup>2</sup>=0.98 and 0.94, respectively). Further, we investigated the influence of local dynamics on OI by contrasting a model fitted to FC with one that was not, hence producing dynamics that poorly resemble the FC. The resulting scatter plot of OI for these models, as shown in (<xref rid="fig7" ref-type="fig">Figure 7. B</xref>), indicated another strong correlation (R<sup>2</sup>=0.93). Collectively, these findings suggest that the equilibrium state of optimal signal propagation does not substantially vary even when employing more complex dynamical models. The reason is that, as previously found [<xref ref-type="bibr" rid="c31">31</xref>], while nonlinear transformations significantly impact the <italic>time-varying</italic> structure of individual contributions, they do not alter the overall amplitude of them, which in this context, is viewed as the <italic>total</italic> amount of influence one node exerts over another. Scaling, on the other hand, that determines the magnitude of these contributions, is inherently governed by the structural connectome across all models. Consequently, <italic>the total influence</italic> of one node on another is predominantly dictated by network topology rather than the specific dynamical model employed. However, <italic>the time-resolved</italic> pattern of fluctuations is specified by the model, which here is simply neglected as a direct consequence of collapsing the temporal information (refer to <xref rid="figS3" ref-type="fig">Supplementary Figure 3</xref> for more details).</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7.</label>
<caption><title>Correlations among linear, nonlinear, and neural mass models of local dynamics:</title> <p><bold>A</bold>. OI matrices for a linear and a nonlinear model show a near-perfect correlation. Moreover, a Hopf model also has a strong correlation with the linear model, indicating that a linear model of local dynamics represents the communication in brain networks under OI as well as more complex node models <bold>B</bold>. Scatter plot between two settings of the same linear model, one fitted to resting-state fMRI and the other using a random value for the global coupling parameter. The finding provides evidence for the greater role of network’s structure compared to nodal dynamics in shaping brain-wide optimal influence.</p></caption>
<graphic xlink:href="598676v1_fig7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>In summary, our findings indicate that linear models of dynamics effectively capture the degree of influence regions exert on each other under the optimal signal propagation state. Findings from this section not only corroborate previous research suggesting that macroscopic dynamics of large-scale brain networks are well approximated by linear models, but also support the hypothesis posited in the preceding section. Together, these two aspects suggest that it is the structural connectivity that shapes the landscape of optimal signaling in brain networks, rather than the models of local dynamics, since OIs are remarkably similar irrespective of the biophysical complexity embedded in models of local dynamics. The equilibrium reached in this game-theoretical framework, as demonstrated, is accurately represented by simplified abstract models of signal propagation. Thus, not only do simple communication models such as SAR perform on a par with NMMs in predicting empirical FC, but also, they represent how information optimally flows in large-scale brain networks.</p>
</sec>
<sec id="s2d">
<title>Rich-Clubs Harness Parallel Pathways to Amplify Their Influence</title>
<p>It has been shown that a set of cortical hubs exerts a relatively large wiring cost to link with other distant regions, forming a rich-club organization [<xref ref-type="bibr" rid="c50">50</xref>–<xref ref-type="bibr" rid="c52">52</xref>]. Thus, these topologically central nodes are argued to be the backbone of information transfer across multiple distant specialized modules [<xref ref-type="bibr" rid="c53">53</xref>,<xref ref-type="bibr" rid="c54">54</xref>]. Previous works proposed that these connections play a crucial role in information processing by diversifying areal input-output connectivity [<xref ref-type="bibr" rid="c55">55</xref>], leading to a richer functional repertoire [<xref ref-type="bibr" rid="c43">43</xref>], or integrating information from the whole brain [<xref ref-type="bibr" rid="c56">56</xref>]. Moreover, it was shown that the connections among adjacent regions are stronger than those among distant areas [<xref ref-type="bibr" rid="c57">57</xref>,<xref ref-type="bibr" rid="c58">58</xref>]. Empirical findings and modeling work have suggested an exponential distant rule by which the strength of connections decays exponentially with spatial distance [<xref ref-type="bibr" rid="c59">59</xref>,<xref ref-type="bibr" rid="c60">60</xref>]. For instance, in our human connectome dataset, the correlation between structural weights and fiber lengths is -0.6 (See <xref rid="figS4" ref-type="fig">Supplementary Figure 4</xref>). Together, these findings pose a question, <italic>if and how do rich-club regions keep their line of communication optimal given these relatively weak connection strengths of long-distance projections?</italic></p>
<p>To answer this question, we first investigated the relationship between the strength of connections between pairs of connected regions and the respective influence they assert on each other. Intuitively, the stronger a connection is, the greater its influence, leading to stronger communication between two regions. This relation has also been supported experimentally by comparing the effect of optogenetics stimulation of a region over its connected neighbors [<xref ref-type="bibr" rid="c61">61</xref>]. Our result corroborated this finding and showed a strong correlation between the structural weight and the amount of influence nodes assert on their connected neighbors (r=0.95). However, several pair-wise interactions fall well above the regression line (<xref rid="fig8" ref-type="fig">Figure 8</xref>. A) suggesting that some regions assert strong influence on others despite their weak connection weights (likewise noticeable in both mouse and macaque connectomes; <xref rid="figS5" ref-type="fig">Supplementary Figure 5</xref>. A). This ‘bump’ is also captured by SAR, LAM, and CO (<xref rid="figS5" ref-type="fig">Supplementary Figure 5</xref>. B), providing further evidence that these simple models can reproduce optimal information flow among connected regions. As (<xref rid="fig8" ref-type="fig">Figure 8. B, C</xref>, and <xref rid="fig8" ref-type="fig">D</xref>) shows these connections mostly lie between regions located at the medial surface of the cortex, coinciding with rich-club regions [<xref ref-type="bibr" rid="c50">50</xref>,<xref ref-type="bibr" rid="c62">62</xref>]. We then computed the amount that each node influences other <italic>unconnected</italic> regions (<xref rid="fig8" ref-type="fig">Figure 8. F</xref>) and found the same regions to be the most influential, providing more evidence that this influence is not related to the weak link itself, but the node’s overall connectivity. To test this hypothesis, we first computed several graph centrality measures, built both on the shortest-path and random walk signaling conceptualization. A Spearman’s rank correlation between how influential a node is and how central it is suggests two conclusions (<xref rid="fig8" ref-type="fig">Figure 8. E</xref>): First, all centrality measures show a moderate to strong positive correlation with the amount of influence nodes assert over the rest of the network, directly and indirectly. Second, those with the largest <italic>indirect</italic> influence (indicated with red) always lie on the top-right of the data cloud, supporting the idea that they are topologically central. We further utilized null and synthetic networks to see if we can delineate the role of connection strength and connectivity pattern in signal propagation. Although less noticeable, the trend persisted when the network topology was shuffled while nodal strength was preserved. It also persisted when the weights were shuffled while the topology was held constant. The trend only disappeared when both topology <italic>and</italic> weights were allocated randomly in synthetic random networks (<xref rid="figS5" ref-type="fig">Supplementary Figure 5. C, D</xref>, and <xref rid="figS5" ref-type="fig">E</xref>).</p>
<fig id="fig8" position="float" fig-type="figure">
<label>Figure 8.</label>
<caption><title>Hubs, rich-club nodes, and their influence:</title>
<p><bold>A</bold>. Scatter plot of the influences of nodes on their connected neighbors (direct influence in <xref rid="fig2" ref-type="fig">Figure 2</xref>) versus the strength of the underlying connections. Despite the overall strong correlation between the total influence and the strength of structural connections, residuals (depicted by warm colors) reveal several weak connections with more influence than expected by their connection weights. <bold>B</bold>. The position of weak connections with strong influence in the adjacency matrix. <bold>C</bold>. The position of these connections in the structural brain network shows that they are mainly long-range connections among the hub regions of the cortex. <bold>D</bold>. shows those hub regions. <bold>E</bold>. The relationship between the influence of a region is and its centrality, by four centrality measures (see Material and Methods, Graph-theoretical Measures). <bold>F</bold>. The most indirectly influential nodes (indicated by red points in E.) that can propagate information to distant and unconnected regions. DMPFC: Dorsomedial prefrontal cortex, PCC: Posterior cingulate cortex, ACC: Anterior cingulate cortex, SFC: Superior frontal cortex, SMA: Supplementary motor area, VLPFC: Ventrolateral prefrontal cortex.</p></caption>
<graphic xlink:href="598676v1_fig8.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We then compared the edge betweenness centrality of every connection with its strength, under both shortest-path and random walk conceptualization. <bold>Shortest-path edge-betweenness centrality (SPEBC)</bold> of a link, measures how many shortest paths in the network go through this specific connection, while <bold>random walk edge-betweenness centrality (RWEBC)</bold> counts the number of times a random walker traversed this link to move from a node to another. While the trend is missing when compared to the connection weight, it is apparent when compared to the influence, suggesting that the effect cannot be captured by how central <italic>individual links</italic> are given these two signaling strategies (<xref rid="fig9" ref-type="fig">Figure 9. A</xref> and <xref rid="fig9" ref-type="fig">B</xref>). Together, these findings propose that neither connectivity nor weights <italic>alone</italic> are responsible for the emergence of efficient signal propagation between weakly connected nodes. But the signature of more influence compared to the underlying weight is only observed when central nodes are allocated with weak links.</p>
<fig id="fig9" position="float" fig-type="figure">
<label>Figure 9.</label>
<caption><title>Relationship between centrality of individual connections and their influence:</title><p><bold>A</bold>. Strength of individual connections versus their centrality in terms of shortest-path edge betweenness centrality. The lower panel shows the same relationship, but for the amount of influence a node has over its connected neighbor compared to the centrality of their connections. <bold>B</bold>. Depicts the same information for the random walk (diffusive) model of information flow. In both A and B, this relationship is compared against a null model in which the structural connectivity is shuffled while preserving the strength of each node, i.e., the weighted sum of its connections.</p></caption>
<graphic xlink:href="598676v1_fig9.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Lastly, to further investigate this phenomenon, we systematically changed the degree of spatial influence for a SAR model while calculating the spread of data along the second <bold>principal component (PC)</bold>. The first PC captures the main direction of variability between the influence and connection strength, which is the observed strong relationship. However, the second PC captures how much data points are spread orthogonal to the main axis, indicating the amount of which weak links are influential. In other words, this metric measures the variability around the regression line, a small variability indicates a robust prediction of influence from the connection weight, showing their tight coupling. In contrast, large variability approximates how much communication between two nodes was independent of the connection strength, potentially relying on other parallel pathways (<xref rid="fig10" ref-type="fig">Figure 10</xref>). We found that a steep decay factor leads to low variability, as nodes could only influence their connected neighbors before the signal subsides. A shallower decay rate, on the other hand, resulted in more variability since the signal could traverse longer parallel pathways, echoing in the network and reach the target from multiple fronts (<xref rid="fig10" ref-type="fig">Figure 10</xref>). This finding provides further evidence for central nodes utilizing not only the direct path but other longer paths to compensate for the weak direct connection strength.</p>
<fig id="fig10" position="float" fig-type="figure">
<label>Figure 10.</label>
<caption><title>How influence decouples from the underlying structural connections:</title>
<p>The spread of points along the second principal component, i.e., orthogonal to the regression line, across different values of spatial influence. A very small degree of spatial influence represents a case in which the signal can only reach the neighboring nodes, while higher values indicate influences that extend over longer pathways and reverberate in the network, effectively decoupled from the underlying structural weight.</p></caption>
<graphic xlink:href="598676v1_fig10.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Moreover, we found that these nodes also have both larger average controllability and modal controllability (see <xref rid="figS6" ref-type="fig">Supplementary Figure 6</xref>), providing insight about their potential role in steering the dynamics of the brain. Average controllability measures the ability of a node to push the global dynamics into easy-to-reach states, while the modal controllability measures the power of a node to push the network towards farther and hard-to-reach states. It has been shown that the nodal strength has a strong positive correlation with average controllability and a strong negative correlation with modal controllability [<xref ref-type="bibr" rid="c63">63</xref>]. Our results also support this finding, with the Spearman’s rank correlation of nodal influence and average controllability being 0.86 and -0.63 for modal controllability. However, the influential nodes are clustered in the top-right corner of the scatter plot for modal controllability (<xref rid="figS6" ref-type="fig">Supplementary Figure 6</xref>). This finding suggests that these nodes steer the network to both easy-to-reach and hard-to-reach dynamical states due to their extensive local and long-range connectivity.</p>
<p>Altogether, results from this section propose a mechanism with which hub regions optimally communicate with their distant counterparts, given the structurally weak connections between them. These regions harness their topologically central positions to broadcast their signals not only via one (their direct) connection but other parallel indirect ones to direct the global dynamics of the brain towards different states, even those that are energetically costly to reach. In other words, the weak connection between two ‘peripheral’ nodes results in weak communication, though, this inefficiency is compensated by central nodes that have access to many pathways to amplify their signal.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>In this work, we explored the characteristics of brain communication in a state of optimal signal propagation. We employed a game-theoretical framework to uncover how nodes influence each other optimally, given a set of constraints. We defined these constraints as the network’s structural topology and its functional activity, which emerged from three increasingly complex large-scale brain models. These models ranged from a linear model, where the output of each node is the weighted sum of its inputs, via a nonlinear model, in which the node modifies the incoming signals using a Tanh function, to a Hopf model that, relative to the other two models, represents more biophysical realism, such as conductance delay, metastability, and oscillatory dynamics of the brain signals, at the cost of greater computational complexity. Our results indicate that the strength by which nodes influence each other depends less on the local node model and more on the global network structure, permitting us to apply a wide range of graph theoretical metrics that fundamentally relate to the linear model. For instance, comparing putative communication models, we found that the optimal signal propagation in brain networks is better captured by frameworks that conceptualize communication to follow a broadcasting strategy. This means that, although signals travel along multiple parallel pathways, they subside after each processing step and degrade after six to eight steps. Finally, we show that topologically central brain regions, such as precuneus, prefrontal cortex, and anterior cingulate cortex, amplify their influence over remote regions by harnessing such parallel pathways. These results have several implications and caveats that are discussed below.</p>
<sec id="s3a">
<title>Interpreting Game-theoretical Solutions for Influence Decomposition</title>
<p>Here, we argue for developing normative formulations of brain signaling and network organization. This approach follows similar studies in synthetic brain networks, where a work also using game theory showed how nodes aiming at maximizing the network’s navigability while minimizing their wiring cost organize in structures remarkably similar to empirical brain networks [<xref ref-type="bibr" rid="c5">5</xref>]. Interestingly, related work [<xref ref-type="bibr" rid="c64">64</xref>] addressed the long-standing question of why six degrees of separation exist in social networks [<xref ref-type="bibr" rid="c65">65</xref>]. Using normative modeling provided by game theory, the authors found the reason to be a trade-off between a node’s aspiration to maximize its centrality, while minimizing its connection maintenance cost [<xref ref-type="bibr" rid="c64">64</xref>]. In the present work, we also found that the first eight steps of propagation are sufficient to reconstruct OI, with a peak on the sixth step.</p>
<p>Also relevant for our work, the Shapley value has been shown to converge to a Nash equilibrium in some games, for instance, bargaining in which players have to divide a sum among themselves while maximizing their payoffs, allowing us to draw a connection between this value and the notion of the equilibrium state [<xref ref-type="bibr" rid="c32">32</xref>]. interestingly, this finding has been experimentally replicated, where subjects played a simplified bidding game and frequently settled on division solutions very similar to their Shapley values [<xref ref-type="bibr" rid="c66">66</xref>]. Thus, it is important to note that the equilibrium discussed in the current paper is a game theoretical equilibrium in the solution space (<xref rid="fig2" ref-type="fig">Figure 2. B</xref>) and not necessarily associated with the neural dynamics. Related to this point is the notion of optimality. Here, by optimal influence, we refer to <italic>the optimal solution for decomposing influences, from the cooperative game theoretical perspective, that translates to the non-cooperative game-theoretical definition of optimality as the largest amount of influence that a node can potentially assert on a target given the game constraints</italic>. As depicted in (<xref rid="fig2" ref-type="fig">Figure 2. B.</xref>), optimality here refers to the equilibrium point in the solution space. We call it optimal because, as shown before [<xref ref-type="bibr" rid="c27">27</xref>], the Shapley value is a unique solution, and in fact the only solution that satisfies three of the four axioms related to fairness [<xref ref-type="bibr" rid="c26">26</xref>,<xref ref-type="bibr" rid="c67">67</xref>] which guarantees stability and dominance of the solution compared to others. Lastly, the Shapley value is being used in the context of interpretability of machine learning features by frameworks such as <bold>SHAP (SHapley Additive exPlanations;</bold> see [<xref ref-type="bibr" rid="c68">68</xref>,<xref ref-type="bibr" rid="c69">69</xref>]). However, what is done in the present work is fundamentally different from SHAP. Although both frameworks compute Shapley values, SHAP does it for input features of machine learning algorithms. In contrast, here we compute the Shapley value of each node of the network, with respect to all other nodes, at every time point. This warrants a different interpretation of the results compared to the SHAP framework.</p>
<p>There is a large body of research aiming at decomposing the amount of influence originating from a set of source nodes on a target node. Some attempts have used information theory, such as causal information [<xref ref-type="bibr" rid="c70">70</xref>], and information transfer [<xref ref-type="bibr" rid="c71">71</xref>], as well as using <bold>Partial Information Decomposition (PID)</bold> [<xref ref-type="bibr" rid="c72">72</xref>–<xref ref-type="bibr" rid="c74">74</xref>]. In PID, the information transferred can be further decomposed into synergistic, redundant and unique contributions. In the current work, we deliberately used the wording of influence instead of information, since a formal link between these two properties still needs to be established (but see [<xref ref-type="bibr" rid="c75">75</xref>] for an example of equating them). Our framework, however, does not measure the amount of information transferred as defined by information theory; it also does not explicitly decompose the influence into subparts. What it does is to characterize the amount of influence one node has over another at any time points, given a modeling paradigm (see <xref rid="figS3" ref-type="fig">Supplementary Figure 3</xref>). This influence embeds higher order interactions, such as synergistic and redundant interactions, but eventually summarizes them into one value per time point, describing the average contribution of a node to its targets given its contribution to all possible coalitions of sources. Therefore, we believe that our framework complements the rich body of previous research by providing another level of rigorous granularity, specifically, time-resolved exact influence. Further research is needed to establish where the two perspectives of game theory and information theory converge, and how combining them could provide insights about communication in brain networks.</p>
<p>On a related note, due to its reliance on multi-site lesioning, MSA has been used to address the complexity resulting from higher order interactions in the context of causal inference [<xref ref-type="bibr" rid="c76">76</xref>–<xref ref-type="bibr" rid="c79">79</xref>]. Following the well-established Woodwardian account of causality, that is, the manipulability account [<xref ref-type="bibr" rid="c80">80</xref>], MSA at its core is a causal inference framework. The manipulability account of causality [<xref ref-type="bibr" rid="c80">80</xref>] states that “C is a cause of E, if manipulating C results in tractable changes in E”. Here we define manipulation as lesioning, as is customary in neuroscience [<xref ref-type="bibr" rid="c81">81</xref>–<xref ref-type="bibr" rid="c84">84</xref>]. We then address the problem of “counterfactuals” by exploring all possible ways that causes can interact at any time-point to produce an effect, leading to one of the most detailed accounts of causality. Therefore, placing our method in the large family of <bold>effective connectivity (EC)</bold> methods appears as a natural next step. However, here we decided to opt out of this comparison in favor of communication models, since they conceptualize brain-wide causal interactions, which involve both direct and indirect interactions, uncovering causal pathways instead [<xref ref-type="bibr" rid="c85">85</xref>]. Expanding causal relationships to pathways of different lengths allows for multiple causes to interact and jointly produce an effect. Moreover, comparing our findings with those from EC approaches would involve considering a host of methods, not limited to but including spectral dynamic causal modeling [<xref ref-type="bibr" rid="c86">86</xref>], partial correlation analysis, Granger causality, dynamic differential covariance [<xref ref-type="bibr" rid="c87">87</xref>,<xref ref-type="bibr" rid="c88">88</xref>], transfer entropy [<xref ref-type="bibr" rid="c71">71</xref>], and so forth. We believe that this worthwhile comparison calls for a separate and extensive analysis that is beyond the scope of the current work.</p>
<p>Finally, our framework is model-agnostic, meaning that the game and its constraints should be defined first. This approach comes with great liberty to explore different dynamical models. However, we acknowledge that this freedom can be a double-edged sword. On the one hand, it allows researchers to investigate a multitude of questions, potentially providing meaningful insight into the mechanism of communication and its role in behavior. On the other hand, it can result in ill-conceived games that lead to misinterpretations. For instance, here the time-resolved influence of all nodes over each other is a three-dimensional array. Conventionally, it would be tempting to average over the time points and produce a time-averaged influence matrix. However, since our models were stationary, the average value of the vector would be highly noisy, providing little insight into “how much” nodes modulate each other’s activity. Instead, we computed the variance to capture this feature, but one might as well compute alternative metrics, such as standard deviation, entropy, energy, where each requires careful interpretation. Moreover, variance alone might be a poor indicator of influence if the network has inhibitory connections, as both biological and <bold>artificial neural networks (ANNs)</bold> tend to have. By contrast, the present work focuses on conventional neuroimaging datasets with non-negative connection weights.</p>
<p>In sum, it is crucial to define every step of the game carefully to avoid misinterpretations. It is also important to keep in mind the provided definitions for optimality, equilibrium and influence to avoid confusion in interpreting the results of the game-theoretical analysis.</p>
</sec>
<sec id="s3b">
<title>Broadcasting as an Optimal Signaling Strategy</title>
<p>Many previous studies in network neuroscience have relied on a graph theoretical definition of efficiency that is based on the shortest path distance [<xref ref-type="bibr" rid="c89">89</xref>]. Here, we show that the underlying signal propagation dynamics in large-scale brain networks is likely to follow a broadcasting regime. This finding implies that broadcasting goes beyond signaling along the shortest path but does not downplay its role. In other words, we show that the shortest path is critical, but not the only path along which a signal traverses. The broadcasting mechanism also circumvents a major problem of the shortest path signaling concept, that nodes would have to find the shortest path to every other node in the network without access to global information on the network organization. By broadcasting, nodes simply transmit their signal via their outgoing connections in every direction. And since the signal degrades over every step, nodes topologically closest to the source receive the signal most strongly. Put differently, navigation along the shortest path emerges naturally and without a need for centralized routing strategies, simply because the closest node receives more signal compared to the farther ones. This line of reasoning is compatible with the result depicted in (<xref rid="fig8" ref-type="fig">Figure 8. E</xref>) where closeness centrality predicted the influential nodes with such great accuracy compared to other centrality measures. Additionally, communication models, such as communicability, are thought to be energetically costlier than routing strategies, such as signaling exclusively along the shortest paths [<xref ref-type="bibr" rid="c12">12</xref>]. The reason for this argument is the fact that communicability accounts for paths of all length. However, as shown here, paths longer than seven steps are unlikely to be meaningfully contributing. In support of this finding, Griffa and colleagues [<xref ref-type="bibr" rid="c90">90</xref>] using information theory found that not only parallel communication is present in the human cortex, but also pathways longer than five steps are not as effective. These observations suggest that regions balance between robustness and energetic cost of signal transmission by using a handful of parallel pathways. Intriguingly, Griffa et al. reported that the capacity for parallel communication is larger in the human cortex compared to macaque and mouse, proposing an evolutionary advantage for broadcasting over multiple pathways [<xref ref-type="bibr" rid="c90">90</xref>]. They also found that these pathways are more frequently placed between different functional modules, rather than within them, which aligns with our finding that hub regions harness parallel pathways to compensate for weak structural connections among them.</p>
<p>Another implication of this finding is that metrics such as global efficiency, representing the average shortest-path distance between all nodes, are not ideal for capturing the signaling dynamics of the brain. As Zamora-Lopez and Gilson argue [<xref ref-type="bibr" rid="c91">91</xref>], all such graph theoretical metrics assume some sort of dynamics. It is important to first establish the correct dynamics and then apply the corresponding metrics. Prompted by our findings, we would suggest that, when possible, metrics based on the shortest path distance should be replaced with others based on communicability, LAM, or SAR. For instance, instead of using the average shortest path as a measure of global network efficiency, one may compute the average communicability as <italic>global broadcasting efficiency</italic>. Similarly, closeness centrality may be redefined as the <italic>broadcasting strength</italic> by taking the average node-wise communicability instead of the average node-wise shortest-path distance.</p>
<p>Next, it is not yet clear whether the broadcasted signal is modified along longer chains in the network, or just relayed to boost the transmitted information. If the signal is modified, then it is likely that these pathways serve a computational role. Previous work suggests that within-module communication involves more redundant information compared to communication across modules which is mainly synergistic [<xref ref-type="bibr" rid="c74">74</xref>,<xref ref-type="bibr" rid="c92">92</xref>]. Interpreting our work in this perspective, information travels along fewer parallel pathways within a functional module to be processed locally, resulting in higher redundancy. However, signals are likely modified along the parallel pathways and combined with incoming signals from other modules, leading to a greater synergy.</p>
<p>Interestingly, the broadcasting conceptualization is argued to be a better model of information propagation in social networks compared to a random-walker-based navigation [<xref ref-type="bibr" rid="c93">93</xref>]. In neuroscience, the broadcasting model of information propagation bears qualitative resemblance with concepts such as traveling waves of excitation [<xref ref-type="bibr" rid="c94">94</xref>], bridging a gap between communication models and communication via oscillation. Notably, we found a correlation of 0.23 between OI and FC (<xref rid="figS9" ref-type="fig">Supplementary Figure 9</xref>), that is close to what has been previously reported by comparing <bold>cortico-cortical evoked potentials (CCEPs)</bold> with FC [<xref ref-type="bibr" rid="c95">95</xref>]. Moreover, it has been proposed that at least a subset of CCEPs propagate as traveling waves [<xref ref-type="bibr" rid="c96">96</xref>]. Together, these works, and our findings suggest that, first, correlation-based measures such as FC capture the propagation of information in brain networks to a limited extent, and second an approach combining CMs with traveling waves could provide biophysical mechanisms for simple signal propagation models based on broadcasting regime such as communicability.</p>
<p>Finally, we found that the rich-club organization of the human cortex is a major contributor to shaping brain-wide communication dynamics. An inspiring work using normative modeling suggested that hierarchies and rich-club organization are spandrels of modules and hubs [<xref ref-type="bibr" rid="c97">97</xref>]. Spandrels are evolutionary features that evolve alongside adaptive phenotypes, while themselves serve no adaptive function. In other words, the rich-club organization is proposed to be the byproduct of modular organization while serving no adaptive function by itself [<xref ref-type="bibr" rid="c98">98</xref>]. Our work provides evidence that, although the rich club organization could have emerged as a byproduct of modular organization, it might not be a purely ornamental spandrel, as the rich club regions represent the most influential regions of the brain (<xref rid="fig8" ref-type="fig">Figure 8</xref>). Previous works relating rich club regions to signaling also indicated an integrative role of these regions, which have longer temporal receptive fields compared to others, allowing them to integrate more information over time [<xref ref-type="bibr" rid="c99">99</xref>,<xref ref-type="bibr" rid="c100">100</xref>]. Interestingly, our results depicted in <xref rid="fig8" ref-type="fig">Figures 8</xref> and <xref rid="fig10" ref-type="fig">10</xref> support this idea. We found that rich club regions integrate signals over longer and parallel structural pathways, enhancing their broadcasting capacity. Moreover, a recent empirical work identified disturbances in these regions and their broadcasting efficiency in patients suffering from disorders of consciousness [<xref ref-type="bibr" rid="c101">101</xref>]. Put together, these findings suggest a causal functional role for the rich-club organization of the human cerebral cortex.</p>
</sec>
<sec id="s3c">
<title>Role of Network Dynamics in Optimal Signaling</title>
<p>Although our work suggests a greater role for the network’s structure in shaping the state of optimal signal propagation in the network compared to the specifics of the local node dynamics, this finding does not mean that the local dynamics are irrelevant. We believe that the inequality between the network’s structure and dynamics in determining signal flow arises from factors such as the assumed homogeneity of nodes in our network models. Here, nodes are assumed to be identical objects with identical features and dynamics. This assumption certainly does not apply in the brain, and a growing body of network models that incorporate regional differences aim at addressing this issue [<xref ref-type="bibr" rid="c102">102</xref>,<xref ref-type="bibr" rid="c103">103</xref>]. As mentioned before, our framework is model agnostic, so it is also possible to interrogate networks with heterogeneous models of dynamics. For applying the present approach to heterogeneous networks, we hypothesize that, firstly, how nodes influence one another further decouples from the structure [<xref ref-type="bibr" rid="c76">76</xref>], and secondly, simple communication models fail to replicate the OI as well as they have done in this work. Thus, further work can shine light on the interplay between the network’s structure and its dynamics in shaping OI, since not only heterogeneous network models are biologically more plausible, but also, they can help to investigate how information optimally flows in networks where nodes respond differently to incoming signals.</p>
</sec>
<sec id="s3d">
<title>Limitations and Further Directions</title>
<p>A conceptual note is that OI, as a normative framework, describes the landscape of communication dynamics if nodes maximize their influence. As in other game-theoretical models, this assumption might not fully hold. The derived landscape is a prediction that would need to be experimentally tested using <italic>in-vivo</italic> multi-site lesioning experiments, which is currently not feasible. However, recent work indirectly supports our findings by showing that propagation of electrical stimulation in the human cortex is well captured by communicability [<xref ref-type="bibr" rid="c40">40</xref>], which we found to have one of the largest correlations with OI. There are also technical limitations of our framework, specifically its computational cost, since one needs potentially to simulate millions of <italic>in-silico</italic> lesion combinations for each target node. For instance, in this work we performed around half a billion lesion simulations for just one game, such as a linear model on the human connectome (see section Game-theoretical Framework in Material and Methods). Performing such an intensive analysis is not possible on a simple laptop. Therefore, due to its brute-force approach, our framework provides rigorous results at the expense of high computational effort, apart from the fact that it is yet to be used <italic>in-vivo</italic> (but see [<xref ref-type="bibr" rid="c104">104</xref>]).</p>
<p>Finally, we focused on the influence of nodes on each other without relating these influences to behavior or cognitive function. Moreover, we did not investigate how this influence landscape changes due to brain disorders, aging, and other factors. Future work may take on these challenges, for instance, by tracking the dynamics of OI during neurodegenerative disease progression.</p>
</sec>
</sec>
<sec id="s4">
<title>Material and methods</title>
<p>In this study, we used multiple Python libraries, including MSApy [<xref ref-type="bibr" rid="c30">30</xref>], Neurolib [<xref ref-type="bibr" rid="c105">105</xref>], Netneurotools, BCTpy [<xref ref-type="bibr" rid="c106">106</xref>], nctpy [<xref ref-type="bibr" rid="c107">107</xref>], and Networkx [<xref ref-type="bibr" rid="c108">108</xref>]. The Jupyter notebooks and Python functions to reproduce this work are available at the GitHub repository below: <ext-link ext-link-type="uri" xlink:href="https://github.com/kuffmode/OI-and-CMs">https://github.com/kuffmode/OI-and-CMs</ext-link></p>
<p>The simulation results are available at the link below:</p>
<p><ext-link ext-link-type="uri" xlink:href="https://zenodo.org/records/10849223">https://zenodo.org/records/10849223</ext-link></p>
<p>Additionally, a dedicated user-friendly Python library to compute OI and some communication models is developed and can be found at:</p>
<p><ext-link ext-link-type="uri" xlink:href="https://github.com/kuffmode/YANAT">https://github.com/kuffmode/YANAT</ext-link></p>
<p>All connectomes are available as a part of the Netneurotools library:</p>
<p><ext-link ext-link-type="uri" xlink:href="https://github.com/netneurolab/netneurotools">https://github.com/netneurolab/netneurotools</ext-link></p>
<sec id="s4a">
<title>Structural and Functional Connectomes</title>
<p>We analyzed three publicly available connectomes of human, macaque, and mouse to address differences in invasive versus non-invasive imaging modalities and reconstruction techniques.</p>
<sec id="s4a1">
<title>Human Connectome</title>
<p>Structural and functional connectivity datasets were acquired from a cohort of 70 healthy subjects at the Lausanne University Hospital in Switzerland, and the details are described elsewhere [<xref ref-type="bibr" rid="c34">34</xref>,<xref ref-type="bibr" rid="c35">35</xref>,<xref ref-type="bibr" rid="c109">109</xref>]. Briefly, the group comprised individuals with an average age of 28.8 years (standard deviation 9.1 years), including 27 females, and all were scanned using a 3 Tesla MRI machine. A deterministic streamline tractography was employed to create individual SC matrices from each participant’s <bold>diffusion spectrum imaging (DSI)</bold> data, which were recorded at five distinct levels of brain parcellation. However, here we have used only one with relatively high-resolution (219 cortical regions). The strength of each structural connection within these matrices was approximated by the density of fiber tracts.</p>
<p>To mitigate the size disparities between brain regions and counteract the inherent preference for longer fiber tracts in the tractography technique, a normalization procedure was applied. This involved adjusting the streamline counts by the average surface areas of the connected regions and the mean streamline lengths. The culmination of this process was the formation of a unified, binary group-average SC matrix, which was derived using a consensus strategy that ensured the individual edge length distributions were conserved [<xref ref-type="bibr" rid="c34">34</xref>,<xref ref-type="bibr" rid="c110">110</xref>].</p>
<p>Functional brain data were gathered from the same group of subjects through <bold>resting-state functional MRI (rs-fMRI)</bold> scans conducted with open eyes. The initial processing steps of this functional data included adjustments for several physiological variables, notably the influence of white matter, cerebrospinal fluid, and motion artifacts that comprise three axes of translation and rotation as determined by rigid body co-registration. Following these corrections, the <bold>blood oxygen level-dependent (BOLD)</bold> time series were subjected to a low pass filtering process, utilizing a temporal Gaussian filter set to a full width half maximum of 1.92 seconds. The analysis excluded the first four temporal points from each scan and further data refinement was achieved through high-motion frame censoring, a method detailed in Power and colleagues [<xref ref-type="bibr" rid="c111">111</xref>].</p>
<p>For the assessment of FC, the study calculated zero-lag Pearson correlation coefficients, which measured the functional relationships between pairs of brain regions in each individual’s rs-fMRI time series. Lastly, the group-average FC matrix was computed as the mean of these individual pairwise connectivity values, which includes negative values as well.</p>
</sec>
<sec id="s4a2">
<title>Macaque Connectome</title>
<p>The connectivity matrix for the macaque was derived from retrograde tract-tracing experiments and is provided by [<xref ref-type="bibr" rid="c59">59</xref>]. These experiments involved the use of fluorescent tracers in a group of 28 macaque monkeys. The projections that were reconstructed from these experiments were mapped according to a division of 91 cortical areas. This division was based on a combination of histological examinations and atlas-based references. In each tract-tracing experiment, Markov and colleagues quantified the number of neurons that were labeled in each of these 91 areas. The count of labeled neurons was then adjusted by subtracting the number of neurons that were native to the site of tracer injection. The outcome of this process was a 29×91 matrix, which represents the connection weights extending from each injection site to other regions of the brain. Here, we focused on the subset of this matrix that describes the weighted and directed connections between 29 cortical areas, leading to a 29×29 SC matrix.</p>
</sec>
<sec id="s4a3">
<title>Mouse Connectome</title>
<p>The connectivity matrix for the mouse was compiled using tract-tracing data openly accessible from the Allen Institute Mouse Brain Connectivity Atlas [<xref ref-type="bibr" rid="c112">112</xref>]. Briefly, the process involved injecting anterograde recombinant adeno-associated viral tracers into designated areas within the right hemisphere of mouse brains. Three weeks following the injection, during which the viral tracer projections developed, the brains were extracted for reconstruction. These reconstructions were then standardized and aligned with the Allen Reference Atlas’ common coordinate framework.</p>
<p>Nodes in the network were identified based on a specialized parcellation derived from the Allen Developing Mouse Brain Atlas. This parcellation initially included 65 areas in each hemisphere, but 9 areas were excluded as they did not participate in any tract-tracing experiments. Consequently, the network that was analyzed constituted 112 regions [<xref ref-type="bibr" rid="c113">113</xref>]. Edges represent axonal projections between different areas, and they were quantified as normalized connection densities. Specifically, this measure represents the number of connections per unit volume from a source area to a target area.</p>
</sec>
</sec>
<sec id="s4b">
<title>Large-scale Computational Models of the Brain Dynamics</title>
<p>In this work, we employed three models with increasing biological fidelity. The most abstract and simplistic model is the linear model, where the output of a node is a weighted sum of its inputs. The nonlinear model extends the linear model by applying a nonlinear transformation to the input (here, <italic>tanh</italic>(·)). And lastly, the neural mass model describes nodes as Stuart-Landau oscillators. Below are the details of each model.</p>
<sec id="s4b1">
<title>Linear and nonlinear Model</title>
<p>The linear model we used, also known as the multivariate Ornstein-Uhlenbeck process, follows the continuous dynamical system equations described in [<xref ref-type="bibr" rid="c114">114</xref>].
<disp-formula id="eqn1">
<graphic xlink:href="598676v1_eqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
 Independent Gaussian noise <bold><italic>ξ</italic></bold> with mean zero and unit variance were presented to each node. Here, <italic>τ</italic> denotes the relaxation time of the node, which was set to 0.02. It should be noted that, in practice, the adjacency matrix is normalized to ensure that its largest eigenvalue | λ<sub><italic>max</italic></sub>| = 1. Consequently, the practical decay rate aligns with the product of the relaxation time, <italic>τ</italic>, and the maximum eigenvalue, λ<sub><italic>max</italic></sub>. <italic>σ</italic> <sub><italic>in</italic></sub> denotes the strength of the noise and was set to 0.05 in all experiments. Given the empirical functional connectivity matrices, we optimized the coupling parameter, <italic>g</italic>, to maximize correlation between empirical and simulated FCs. With our modeling setting, <italic>g</italic> = 0.74 demonstrated the best fit with a correlation of 0.23. The nonlinear model modifies the linear one simply by adding a nonlinear transformation and a larger input noise of 2 instead of 0.05 to go beyond the linear part of the function, leading to the equation below:
<disp-formula id="eqn2">
<graphic xlink:href="598676v1_eqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
</sec>
<sec id="s4b2">
<title>Neural mass model</title>
<p>Further, we explored SC networks governed by Hopf/Stuart-Landau equations [<xref ref-type="bibr" rid="c49">49</xref>]. This model, recognized as the canonical approach for examining the shift from noisy to oscillatory dynamics, elucidates the behavior of a nonlinear oscillating system near the Hopf bifurcation. In essence, the dynamics of each network node are captured by the following complex equation:
<disp-formula id="eqn3">
<graphic xlink:href="598676v1_eqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>Where <italic>z</italic><sub><italic>i</italic></sub> = <italic>x</italic><sub><italic>i</italic></sub> + <italic>jy</italic><sub><italic>i</italic></sub> is a complex representation of the node state, with ξ<sub><italic>I</italic></sub> (<italic>t</italic>) representing Gaussian noise characterized by a standard deviation σ<sub><italic>in</italic></sub> = 0.05. This system undergoes a supercritical bifurcation at <italic>a</italic><sub><italic>i</italic></sub> = 0, where it shifts from a stable fixed point (i.e.,<italic>z</italic><sub><italic>i</italic></sub> = 0) to a limit cycle oscillation with frequency <italic>f</italic><sub><italic>i</italic></sub> = <italic>w</italic><sub><italic>i</italic></sub> /2π.</p>
<p>By decomposing the complex state into its Cartesian components and incorporating the influence of other nodes in the input of each node, we derived a set of coupled equations (<xref ref-type="disp-formula" rid="eqn4">Eq. 4</xref>) to govern the entire brain dynamics. This formulation enables the representation of the influence of nodes on each other’s temporal state through a diffusive interaction, where <italic>g</italic> serves as a global coupling factor.
<disp-formula id="eqn4">
<graphic xlink:href="598676v1_eqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>Similar to the other two models, the global dynamics of the network are influenced by model’s parameters. Here, we precisely tuned the global coupling, <italic>g</italic> and the bifurcation parameter, <italic>a</italic><sub><italic>i</italic></sub>, to match the empirical FC. Setting <italic>g</italic> at 5.6 and <italic>a</italic><sub><italic>i</italic></sub> = 0.15 for all nodes, yields a correlation of 0.35. Other parameters, as detailed in the Neurolib library, remain unaltered as follows. The model features a diffusive coupling type, a signal velocity of 20.0 m/s, a global coupling strength set at 5.8, a 5.0 ms Ornstein-Uhlenbeck timescale, Ornstein-Uhlenbeck noise intensity fixed at 0.05 mV/ms/sqrt(ms), a mean value of Ornstein-Uhlenbeck process maintained at 0.0 mV/ms, a Hopf bifurcation parameter set to 0.15, and an oscillator frequency of 32 Hz. We collected state variable,<italic>x</italic>, representing signals acquired from various brain regions for subsequent analyzes.</p>
</sec>
</sec>
<sec id="s4c">
<title>Game-theoretical Framework</title>
<p>MSA is built upon Shapley values, which quantify a player’s <italic>fair</italic> share of a collectively generated outcome (see <xref rid="fig2" ref-type="fig">Figure 2</xref>). Generally, Shapley values are calculated by adding a player to all possible coalitions and observing the value they bring to the coalition. Formally, the contribution of player <italic>i</italic> to a coalition <italic>S</italic> is given by:
<disp-formula id="ueqn1">
<graphic xlink:href="598676v1_ueqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
 Where <italic>v</italic>(<italic>S</italic>) represents the value of coalition <italic>S</italic>. The Shapley value γ<sub><italic>i</italic></sub> is the average of these contributions across all permutations <italic>R</italic> of the player set:
<disp-formula id="ueqn2">
<graphic xlink:href="598676v1_ueqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
 where ℛ is the set of all permutations, and <italic>S</italic><sub><italic>i</italic></sub> (<italic>R</italic>) is the coalition formed by ordering <italic>R</italic> up to player <italic>i</italic>. However, due to the computational complexity of calculating Shapley values for large sets, MSA relies on an unbiased estimator by sampling permutations. We employed a sample size <italic>m</italic> ≪ <italic>N</italic>!, generating <italic>m</italic> × <italic>N</italic> unique permutations for every target region, where <italic>N</italic> is the number of source regions.</p>
<p>In this work, we iterated this process over every node (target node) by systematically lesioning other nodes (source nodes) and tracking the time-resolved difference between when the sources were lesioned and when they were not. Lesioning was modeled by setting the incoming and outgoing connections of sources to zero. For every source node, we sampled 1,000 permutations. However, we confirmed that the algorithm converged by comparing it against a larger sample size of 10,000, which resulted in a correlation coefficient of 1.0 (<xref rid="figS7" ref-type="fig">supplementary Figure 7</xref>). We also ran the analysis for 10 repetitions and averaged the resulting influence matrices. The final matrix has a shape of (number of regions × number of regions × simulation time) that we reduced to a two-dimensional matrix (number of regions × number of regions) by taking the variance of each influence profile. Altogether, each of the experiments on the human connectome resulted in roughly 480 million <italic>in-silico</italic> lesions (219 targets x 219 sources × 1,000 combination of lesions per source for each target × 10 trials). Due to the computational implausibility of the neural mass model, we ran the analysis only once instead of 10 repetitions, thus 48 million lesions. Together with all control analyzes, the total number of in-silico lesions for the human connectome amounts to 7,200 million:</p>
<p>480m for the linear model, 480m for the nonlinear, 48m for the Hopf, 480m for the topology-shuffled null model, 480m for the weight-shuffled null model, 4,800 for the case where we used 10,000 lesion combinations per source for each target, and 480m for a test case where the coupling was set to zero. All experiments were conducted on a high-performance computing facility provided by the institute of computational neuroscience, university hospital of Hamburg.</p>
</sec>
<sec id="s4d">
<title>Communication Models and Measures</title>
<p>In this section, we introduce the communication models and measures employed to analyze the dynamics of information flow within the studied network. The corresponding formulas and procedures for computation are presented in <xref rid="tbl1" ref-type="table">Table 1</xref>.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><title>Communication Models and Measures</title></caption>
<graphic xlink:href="598676v1_tbl1.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<p>The structural connectivity matrix <italic>W</italic> ∈ ℝ<sup><italic>N</italic>×<italic>N</italic></sup> denotes the strength of pairwise connections between N brain regions. We define the connection length matrix <italic>L</italic> = 1/<italic>W</italic>, where <italic>L</italic><sub><italic>ij</italic></sub> is the travel cost between regions <italic>i</italic> and <italic>j</italic>. This conversion from connection weights to lengths is required for network communication models that optimize for minimal transmission cost of signals, e.g., shortest path efficiency.</p>
<sec id="s4d1">
<title>Shortest Path Efficiency</title>
<p>Shortest Path Efficiency measures the effectiveness of communication along the most direct route between two nodes in a network. Here, the Floyd-Warshall algorithm was employed to determine the sequence of regions Ω<sub><italic>ij</italic></sub> = {<italic>i</italic>,<italic>u</italic>,…,<italic>v</italic>,<italic>j</italic>} that minimizes the total transmission cost for signals traveling between regions <italic>i</italic> and <italic>j</italic>. This cost, denoted by <inline-formula><inline-graphic xlink:href="598676v1_inline1.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, is defined as the sum <italic>L</italic><sub><italic>iu</italic></sub> + … +<italic>L</italic><sub><italic>vj</italic></sub> . Subsequently, the Shortest Path Efficiency (SPE) between two regions is quantified as the reciprocal of the minimum transmission cost, expressed as<inline-formula><inline-graphic xlink:href="598676v1_inline2.gif" mime-subtype="gif" mimetype="image"/></inline-formula> as detailed in [<xref ref-type="bibr" rid="c10">10</xref>].</p>
</sec>
<sec id="s4d2">
<title>Navigation Efficiency</title>
<p>Navigation within the network employs a greedy protocol that assumes signal transmission to minimize the inter-regional Euclidean distance. The process involves iterative progression from a source region <italic>i</italic> to a target region <italic>j</italic>. At each step, the neighbor spatially closest to <italic>j</italic> is chosen as the next node in the path [<xref ref-type="bibr" rid="c115">115</xref>]. This sequence continues until the target is reached, marking successful navigation, or a previously visited node is encountered, indicating a failure in navigation. The cumulative length of a successful path is denoted by ,Λ<sub><italic>ij</italic></sub> = <italic>L</italic><sub><italic>iu</italic></sub> + … + <italic>L</italic><sub><italic>vi</italic></sub> ,where Ω<sub><italic>ij</italic></sub> = {<italic>i</italic>,<italic>u</italic>,…,<italic>v</italic>,<italic>j</italic>} represents the sequence of nodes traversed. If navigation fails Λ<sub><italic>ij</italic></sub>, is set to infinity. Navigation efficiency is thus defined as the reciprocal of the traversed path length.</p>
</sec>
<sec id="s4d3">
<title>Diffusion Efficiency</title>
<p>The Diffusion Efficiency (DE) model characterizes signaling through the lens of random walks. The computation of DE involves the utilization of the transition matrix, <italic>P</italic> within a Markov chain process unfolding on the connection weight matrix, <italic>W</italic>. Specifically, it considers the probability, <italic>p</italic><sub><italic>ij</italic></sub>, that a simple random walker at node <italic>i</italic> will advance to node <italic>j</italic> and the mean first passage time, <italic>t</italic><sub><italic>ij</italic></sub> which quantifies the expected number of intermediate regions visited in a random walk. To elaborate on the computation procedure, please refer to <xref rid="tbl1" ref-type="table">Table 1</xref>. Additionally, for a more in-depth theoretical understanding, consult references [<xref ref-type="bibr" rid="c116">116</xref>,<xref ref-type="bibr" rid="c117">117</xref>].</p>
</sec>
<sec id="s4d4">
<title>Search Information</title>
<p>Search information is a metric that evaluates the required amount of information to push a random walker towards the shortest path, thereby reflecting the accessibility of efficient communication routes under a diffusive model. Computing SI involves finding the above-mentioned shortest path,Ω<italic>ij</italic> between two regions, and the probability,Π<sub><italic>ij</italic></sub> , that a random walker will accidentally traverse from region <italic>i</italic> to region <italic>j</italic> following this path. This probability is computed using the transition matrix, <italic>P</italic> within a Markov chain process unfolding on the connection weight matrix. <xref rid="tbl1" ref-type="table">Table 1</xref> summarizes the computation procedure.</p>
</sec>
<sec id="s4d5">
<title>Communicability and Scaled Communicability</title>
<p>The measure of communicability between nodes, <italic>i</italic> and <italic>j</italic> , is expressed as the weighted sum of the overall pathways connecting them, where each walk’s contribution is weighted proportionally to the inverse of its length—signifying the number of connections traversed. In practice, before computing communicability, nonbinary connection weight matrices are commonly normalized. This normalization step is employed to diminish the impact of highly influential nodes with substantial strength. Refer to <xref rid="tbl1" ref-type="table">Table 1</xref> for the computation procedure and references [<xref ref-type="bibr" rid="c25">25</xref>,<xref ref-type="bibr" rid="c91">91</xref>] for additional theoretical details. We also reported the scaled communicability measure, which introduces the modulating parameter, to control the decay rate.</p>
</sec>
<sec id="s4d6">
<title>Linear Attenuation Model</title>
<p>The Linear attenuation model (LAM) follows the same line of reasoning as communicability, that information propagation can be represented as a weighted sum of all walks in the network. The difference lies in how walk-lengths are discounted. In contrast to communicability, where the sum of walks is estimated through the exponentiation of the adjacency matrix, Katz introduced an attenuation factor,α , to reduce the influence over every step monotonically. Katz proposed a closed-form expression, given by ( 𝕀 − <italic>αW</italic><sup>−1</sup>) [<xref ref-type="bibr" rid="c118">118</xref>]. It is important to note that the convergence condition in this context is <inline-formula><inline-graphic xlink:href="598676v1_inline3.gif" mime-subtype="gif" mimetype="image"/></inline-formula> , where λ<sub><italic>max</italic></sub> represents the spectral radius of the adjacency matrix, <italic>W</italic>. Prior to computing the Linear Attenuation Model (LAM), the adjacency matrix undergoes a normalization process, similar to the one applied in the computation of communicability.</p>
</sec>
<sec id="s4d7">
<title>Spatial Autoregressive Model</title>
<p>Moreover, we incorporated the spatial autoregressive (SAR) model into our analysis. This model, characterized as a generic representation of diffuse processes on networks, is intricately linked to the distribution of paths within the network [<xref ref-type="bibr" rid="c43">43</xref>,<xref ref-type="bibr" rid="c44">44</xref>,<xref ref-type="bibr" rid="c55">55</xref>,<xref ref-type="bibr" rid="c119">119</xref>]. In this model, the fluctuating signals at each node are interconnected through a system of structural equations, expressing each signal as a linear function of others. This interconnection is influenced by a global coupling strength factor denoted as α. Importantly, when the network experiences input noise, the SAR model predicts that each signal follows a multivariate normal distribution. This prediction is mathematically represented by the covariance matrix (𝕀 − <italic>αŴ</italic>)<sup>−1</sup> (𝕀 − <italic>αŴ</italic>)<sup>−<italic>T</italic></sup> The term Ŵ denotes the normalized adjacency matrix, where each element <italic>ŵ</italic><sub><italic>ij</italic></sub> is obtained by dividing the original connection strength, <italic>w</italic><sub><italic>ij</italic></sub> by the sum of all connection strengths in the corresponding row of the matrix <italic>W</italic>. 𝕀 is the identity matrix and <italic>T</italic> stands for the transposed inverse matrix.</p>
</sec>
</sec>
<sec id="s4e">
<title>Null and Simulated Network Models</title>
<p>We employed two simulated weighted networks and two null models as described below:</p>
<sec id="s4e1">
<title>Erdős-Rényi model</title>
<p>An Erdős-Rényi random graph, denoted as <italic>G</italic>(<italic>N</italic>,<italic>P</italic>), was generated with 100 nodes, where <italic>p</italic> = 0.35 represents the probability that any two distinct nodes are connected by an edge. The graph was constructed by iterating over all possible pairs of nodes and connecting them with an edge with the probability <italic>p</italic>. This resulted in a binary adjacency matrix <italic>W</italic> where <italic>W</italic><sub><italic>ij</italic></sub> is 1 if nodes <italic>i</italic> and <italic>j</italic> are connected and 0 otherwise. After generating the binary structure of the graph, weights were assigned to the edges by sampling from a log-normal distribution. The weight <italic>W</italic><sub><italic>ij</italic></sub> for each edge in the graph was drawn from In 𝒩 (<italic>μ</italic>,<italic>σ</italic><sup>2</sup>)where <italic>μ</italic> = 1 and <italic>σ</italic> = 0.5. The log-normal distribution was chosen for its property of providing a multiplicative effect, appropriate for modeling local dynamical systems coupled in a network.</p>
</sec>
</sec>
<sec id="s4f">
<title>Barabási-Albert model</title>
<p>The Barabási-Albert model was used to generate synthetic scale-free networks through a preferential attachment mechanism. As with the Erdős-Rényi model, we generated a network with 100 nodes. Each new node added to the network creates <italic>m</italic> = 20 edges to existing nodes, with a preference for nodes that already have a higher degree, thus simulating the “rich get richer” phenomenon and producing hubs in the network. In this Barabási-Albert model, the probability that a new node will be connected to a node <italic>i</italic> depends on the degree <italic>k</italic><sub><italic>i</italic></sub>, according to the rule:
<disp-formula id="ueqn3">
<graphic xlink:href="598676v1_ueqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
 Where Σ<sub><italic>j</italic></sub> <italic>k</italic><sub><italic>j</italic></sub> is the sum of degrees of all existing nodes at the time of attachment. Similar to the Erdős-Rényi model, the edges of the resulting binary network were weighted by sampling from a log-normal distribution with parameters <italic>μ</italic> = 1 and <italic>σ</italic> = 0.5. Moreover, to model weakly connected hubs, all hubs in the network were fully connected with weights assigned from a separate log-normal distribution characterized by both mean and standard deviation equal to 0.1. This simulates the scenario where hubs have additional connections among themselves with relatively smaller weights, representing the observed weaker links of the rich-club in the brain.</p>
<sec id="s4f1">
<title>Topology-conserving null model</title>
<p>To investigate the impact of connection strength on network dynamics while maintaining the underlying topology, a weight shuffling procedure was implemented. The adjacency matrix was kept unaltered to preserve the original connectivity pattern, while the weights were redistributed to randomize the strength of the connections. This process was defined as follows:</p>
<p>Given a weighted adjacency matrix,<italic>W</italic> , with fixed topology, the set of non-zero weights corresponding to the edges in <italic>W</italic> was permuted. The permutation was performed in such a manner that each edge received a new weight from the set, ensuring that the sum of the weights and the overall weight distribution remained unchanged. This shuffling procedure was iterated 10 times, yielding 10 distinct weighted networks with identical topologies but randomized weight configurations.</p>
</sec>
<sec id="s4f2">
<title>Weight-conserving null model</title>
<p>To study the impact of topology, we used a degree-, weight- and strength-preserving model introduced by [<xref ref-type="bibr" rid="c120">120</xref>] in which the connectivity was shuffled while the total degree and strength of the nodes were preserved. We chose the default parameters provided by the BCTpy toolbox, however, the correlation between the strength sequence of pre- and post-rewired network was r=0.97 that implies a robust rewiring. As per Rubinov and Sporns [<xref ref-type="bibr" rid="c120">120</xref>], the rewiring algorithm consists of two steps:</p>
<list list-type="order">
<list-item><p>The network is randomized while maintaining each node’s degree using a connection-switching algorithm, here Maslov-Sneppen [<xref ref-type="bibr" rid="c121">121</xref>]. In this process, connections are adjusted by switching pairs of edges in a way that preserves the sum of weights for the involved nodes.</p></list-item>
<list-item><p>Original network weights are then reassigned to the randomized network. This reassignment is done by first ranking all weights by magnitude and then associating them with the network’s connections to approximate the original distribution of weights. During this process, weights are iteratively matched and re-ranked until all connections in the new network closely resemble the original positive and negative strengths.</p></list-item>
</list>
</sec>
</sec>
<sec id="s4g">
<title>Multivariate Statistical Model</title>
<p>We conducted two sets of Lasso regularized multivariate regression models (<xref rid="fig6" ref-type="fig">Figure 6</xref>. B and C). In one, we systematically explored the dynamics of feature importance in predicting the optimal signal propagation and using the other set, we investigated the number of steps needed to predict the optimal signal propagation.</p>
<p>For the first set, we constructed a feature matrix <italic>X</italic> encompassing all communication measures, topological and geodesic distance measures, FC, structural weights, and fiber length between regions.</p>
<p>A range of 50 (see <xref rid="tbl1" ref-type="table">Table 1</xref>) values from 0 to 1, delineating the degree of spatial influence, was explored. For each <italic><italic>α</italic></italic>, the SAR and LAM models were computed and subsequently integrated into the feature matrix <italic>X</italic>. A total of 25 repetition runs were performed for each <italic><italic>α</italic></italic>, wherein the dataset was randomly partitioned into training and testing subsets of proportion 0.7-0.3 using a 10-folds cross validation approach. The training set was subjected to standard scaling before model fitting. The statistical model was assessed through the coefficient of determination <italic>R</italic><sup>2</sup> . The absolute values of the regression coefficients obtained from the model were normalized to sum to 100, reflecting the relative contribution of each feature to the model. These contributions were recorded for each <italic><italic>α</italic></italic> and averaged over all trials to ascertain the consistent predictors.</p>
<p>For the second set, a range of 15 steps were generated by first raising the structural connectivity matrix to the power of 0 to 15 and then discounting the longer paths according to the optimal discount factor of the LAM model (<italic><italic>α</italic></italic> = 0.64). For each step, 100 repetitions were performed following the same cross-validation, evaluation, and feature importance ranking introduced above.</p>
</sec>
<sec id="s4h">
<title>Graph-theoretical Measures</title>
<p>Several graph-theoretical measures were employed in this study that are summarized in <xref rid="tbl2" ref-type="table">Table 2</xref> and briefly explained here.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2:</label>
<caption><p>Graph-theoretical Measures</p></caption>
<graphic xlink:href="598676v1_tbl2.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<sec id="s4h1">
<title>Closeness Centrality</title>
<p>Closeness centrality is a measure reflecting the average shortest path length from a given node to all other nodes in the network. It quantifies how “close” a node is to all other nodes, which can indicate the node’s efficiency in spreading information through the network. As with the SPE, the shortest path distance was calculated using the Floyd-Warshall algorithm.</p>
</sec>
<sec id="s4h2">
<title>Eigenvector Centrality</title>
<p>Eigenvector centrality extends the concept of centrality by not only considering the number of connections a node has, but also the centrality of its neighbors [<xref ref-type="bibr" rid="c122">122</xref>,<xref ref-type="bibr" rid="c123">123</xref>]. It assigns relative scores to all nodes in the network, based on the principle that connections to high-scoring nodes contribute more to the score of the node than equal connections to low-scoring nodes. As detailed in <xref rid="tbl2" ref-type="table">Table 2</xref>, this quantity at the site of <italic>i</italic>-th node is calculated as the <italic>i</italic>-th component of the eigenvector of the adjacency matrix.</p>
</sec>
<sec id="s4h3">
<title>Shortest path Node and Edge Betweenness Centrality</title>
<p>Shortest path betweenness centrality measures the extent to which a node lies on the shortest paths between other nodes in the network. It captures the influence of a node over the flow of information in the network by identifying nodes that frequently act as bridges along the shortest paths between other nodes [<xref ref-type="bibr" rid="c124">124</xref>]. Subsequently, the shortest path <italic>edge</italic> betweenness centrality quantifies the number of times an edge acts as a bridge along the shortest path between two nodes. It reflects the importance of an edge in facilitating communication within the network. To elaborate on the computation of these metrics, please refer to <xref rid="tbl2" ref-type="table">Table 2</xref>.</p>
</sec>
<sec id="s4h4">
<title>Random-walk Node and Edge Betweenness Centrality</title>
<p>Random walk betweenness centrality, also known as current flow betweenness centrality, is also a measure that quantifies the node’s role in facilitating information flow in the network [<xref ref-type="bibr" rid="c125">125</xref>]. However, unlike shortest path betweenness centrality, which only considers the shortest paths, random walk centrality is based on the probability that a random walk starting at a source node will pass through a given node before reaching the destination node. For detailed information on the computation of Random-walk Node and Edge Betweenness Centrality based on the current flow notion, refer to <xref rid="tbl2" ref-type="table">Table 2</xref>.</p>
</sec>
<sec id="s4h5">
<title>Average and Modal Controllability</title>
<p>Average controllability measures the ability of a node to steer the system into many easy-to-reach states, given a discrete dynamical system. It is particularly useful in understanding the ease with which any state of the system can be reached from a given initial state. Similarly, modal controllability represents the ability of a node to steer the system into farther and hard-to-reach states. In computing the controllability measure, we used Schur decomposition to find the unitary matrix, <italic>U</italic>, and the upper triangular matrix,<italic>T</italic> , to express the adjacency matrix, W. the Computation procedure is summarized in <xref rid="tbl2" ref-type="table">Table 2</xref>.</p>
</sec>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>The funding is gratefully acknowledged: <bold>K.F:</bold> German Research Foundation (DFG)-SFB 936-178316478-A1; TRR169-A2; SPP 2041/GO 2888/2-2. <bold>F.H:</bold> DFG TRR169-A2. SD: SFB 936-178316478-A1. <bold>A.M:</bold> SFB 936-178316478-A1. <bold>B.M:</bold> the Natural Sciences and Engineering Research Council of Canada (NSERC Discovery Grant RGPIN #017-04265). The Brain Canada Future Leaders Fund and the Canadian Institutes of Health Research (CIHR). <bold>C.S:</bold> N/A; <bold>G.Z:</bold> N/A; <bold>C.H:</bold> SFB 936-178316478-A1; TRR169-A2; SFB 1461/A4; SPP 2041/HI 1286/7-1, the Human Brain Project, EU (SGA2, SGA3).</p>
</ack>
<sec id="s5">
<title>Authors’ contributions</title>
<p>Conceptualization: K.F., F.H., C.S., B.M., A.M., G.Z., C.H.</p>
<p>Data curation: K.F., C.S.</p>
<p>Formal analysis: K.F., F.H., A.M.</p>
<p>Funding acquisition: C.H.</p>
<p>Investigation: K.F., S.D., F.H., C.S.</p>
<p>Methodology: K.F., F.H., A.M., C.S.</p>
<p>Resources: C.H.</p>
<p>Supervision: A.M., B.M., G.Z., C.H.</p>
<p>Validation: F.H., C.H.</p>
<p>Visualization: K.F.</p>
<p>Writing—original draft: K.F., F.H.</p>
<p>Writing—review and editing: K.F., S.D., F.H., A.M., C.S., G.Z., B.M., C.H.</p>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sporns</surname> <given-names>O</given-names></string-name>, <string-name><surname>Chialvo</surname> <given-names>DR</given-names></string-name>, <string-name><surname>Kaiser</surname> <given-names>M</given-names></string-name>, <string-name><surname>Hilgetag</surname> <given-names>CC</given-names></string-name></person-group>. <article-title>Organization, development and function of complex brain networks</article-title>. <source>Trends Cogn Sci</source>. <year>2004</year>;<volume>8</volume>: <fpage>418</fpage>–<lpage>425</lpage>.</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bullmore</surname> <given-names>ET</given-names></string-name>, <string-name><surname>Sporns</surname> <given-names>O.</given-names></string-name></person-group> <article-title>Complex brain networks: graph theoretical analysis of structural and functional systems</article-title>. <source>Nat Rev Neurosci</source>. <year>2009</year>;<volume>10</volume>: <fpage>186</fpage>–<lpage>198</lpage>.</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Betzel</surname> <given-names>RF</given-names></string-name>, <string-name><surname>Avena-Koenigsberger</surname> <given-names>A</given-names></string-name>, <string-name><surname>Goñi</surname> <given-names>J</given-names></string-name>, <string-name><surname>He</surname> <given-names>Y</given-names></string-name>, <string-name><surname>de Reus</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Griffa</surname> <given-names>A</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Generative models of the human connectome</article-title>. <source>Neuroimage</source>. <year>2016</year>;<volume>124</volume>: <fpage>1054</fpage>–<lpage>1064</lpage>.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kaiser</surname> <given-names>M</given-names></string-name>, <string-name><surname>Hilgetag</surname> <given-names>CC</given-names></string-name></person-group>. <article-title>Nonoptimal component placement, but short processing paths, due to long-distance projections in neural systems</article-title>. <source>PLoS Comput Biol</source>. <year>2006</year>;<volume>2</volume>: <fpage>e95</fpage>.</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gulyás</surname> <given-names>A</given-names></string-name>, <string-name><surname>Bíró</surname> <given-names>JJ</given-names></string-name>, <string-name><surname>Kőrösi</surname> <given-names>A</given-names></string-name>, <string-name><surname>Rétvári</surname> <given-names>G</given-names></string-name>, <string-name><surname>Krioukov</surname> <given-names>D.</given-names></string-name></person-group> <article-title>Navigable networks as Nash equilibria of navigation games</article-title>. <source>Nat Commun</source>. <year>2015</year>;<volume>6</volume>: <fpage>7651</fpage>.</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname> <given-names>IE</given-names></string-name>, <string-name><surname>Clandinin</surname> <given-names>TR</given-names></string-name></person-group>. <article-title>The Influence of Wiring Economy on Nervous System Evolution</article-title>. <source>Curr Biol</source>. <year>2016</year>;<volume>26</volume>: <fpage>R1101</fpage>–<lpage>R1108</lpage>.</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bullmore</surname> <given-names>E</given-names></string-name>, <string-name><surname>Sporns</surname> <given-names>O.</given-names></string-name></person-group> <article-title>The economy of brain network organization</article-title>. <source>Nat Rev Neurosci</source>. <year>2012</year>;<volume>13</volume>: <fpage>336</fpage>–<lpage>349</lpage>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bassett</surname> <given-names>DS</given-names></string-name>, <string-name><surname>Bullmore</surname> <given-names>ET</given-names></string-name></person-group>. <article-title>Small-World Brain Networks Revisited</article-title>. <source>Neuroscientist</source>. <year>2017</year>;<volume>23</volume>: <fpage>499</fpage>–<lpage>516</lpage>.</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>S</given-names></string-name>, <string-name><surname>Hilgetag</surname> <given-names>CC</given-names></string-name>, <string-name><surname>Zhou</surname> <given-names>C.</given-names></string-name></person-group> <article-title>Trade-off between multiple constraints enables simultaneous formation of modules and hubs in neural systems</article-title>. <source>PLoS Comput Biol</source>. <year>2013</year>;<volume>9</volume>: <fpage>e1002937</fpage>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Latora</surname> <given-names>V</given-names></string-name>, <string-name><surname>Marchiori</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Efficient behavior of small-world networks</article-title>. <source>Phys Rev Lett</source>. <year>2001</year>;<volume>87</volume>: <fpage>198701</fpage>.</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Avena-Koenigsberger</surname> <given-names>A</given-names></string-name>, <string-name><surname>Misic</surname> <given-names>B</given-names></string-name>, <string-name><surname>Sporns</surname> <given-names>O.</given-names></string-name></person-group> <article-title>Communication dynamics in complex brain networks</article-title>. <source>Nat Rev Neurosci</source>. <year>2018</year>;<volume>19</volume>: <fpage>17</fpage>–<lpage>33</lpage>.</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Seguin</surname> <given-names>C</given-names></string-name>, <string-name><surname>Sporns</surname> <given-names>O</given-names></string-name>, <string-name><surname>Zalesky</surname> <given-names>A.</given-names></string-name></person-group> <article-title>Brain network communication: concepts, models and applications</article-title>. <source>Nat Rev Neurosci</source>. <year>2023</year>. doi:<pub-id pub-id-type="doi">10.1038/s41583-023-00718-5</pub-id></mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Suárez</surname> <given-names>LE</given-names></string-name>, <string-name><surname>Markello</surname> <given-names>RD</given-names></string-name>, <string-name><surname>Betzel</surname> <given-names>RF</given-names></string-name>, <string-name><surname>Misic</surname> <given-names>B.</given-names></string-name></person-group> <article-title>Linking Structure and Function in Macroscale Brain Networks</article-title>. <source>Trends Cogn Sci</source>. <year>2020</year>;<volume>24</volume>: <fpage>302</fpage>–<lpage>315</lpage>.</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bettinardi</surname> <given-names>RG</given-names></string-name>, <string-name><surname>Deco</surname> <given-names>G</given-names></string-name>, <string-name><surname>Karlaftis</surname> <given-names>VM</given-names></string-name>, <string-name><surname>Van Hartevelt</surname> <given-names>TJ</given-names></string-name>, <string-name><surname>Fernandes</surname> <given-names>HM</given-names></string-name>, <string-name><surname>Kourtzi</surname> <given-names>Z</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>How structure sculpts function: Unveiling the contribution of anatomical connectivity to the brain’s spontaneous correlation structure</article-title>. <source>Chaos</source>. <year>2017</year>;<volume>27</volume>: <fpage>047409</fpage>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Breakspear</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Dynamic models of large-scale brain activity</article-title>. <source>Nat Neurosci</source>. <year>2017</year>;<volume>20</volume>: <fpage>340</fpage>–<lpage>352</lpage>.</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vinck</surname> <given-names>M</given-names></string-name>, <string-name><surname>Uran</surname> <given-names>C</given-names></string-name>, <string-name><surname>Spyropoulos</surname> <given-names>G</given-names></string-name>, <string-name><surname>Onorato</surname> <given-names>I</given-names></string-name>, <string-name><surname>Broggini</surname> <given-names>AC</given-names></string-name>, <string-name><surname>Schneider</surname> <given-names>M</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Principles of large-scale neural interactions</article-title>. <source>Neuron</source>. <year>2023</year>;<volume>111</volume>: <fpage>987</fpage>–<lpage>1002</lpage>.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fries</surname> <given-names>P.</given-names></string-name></person-group> <article-title>Rhythms for Cognition: Communication through Coherence</article-title>. <source>Neuron</source>. <year>2015</year>;<volume>88</volume>: <fpage>220</fpage>–<lpage>235</lpage>.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Buehlmann</surname> <given-names>A</given-names></string-name>, <string-name><surname>Deco</surname> <given-names>G.</given-names></string-name></person-group> <article-title>Optimal information transfer in the cortex through synchronization</article-title>. <source>PLoS Comput Biol</source>. <year>2010</year>;<volume>6</volume>. doi:<pub-id pub-id-type="doi">10.1371/journal.pcbi.1000934</pub-id></mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Senn</surname> <given-names>W</given-names></string-name>, <string-name><surname>Dold</surname> <given-names>D</given-names></string-name>, <string-name><surname>Kungl</surname> <given-names>AF</given-names></string-name>, <string-name><surname>Ellenberger</surname> <given-names>B</given-names></string-name>, <string-name><surname>Jordan</surname> <given-names>J</given-names></string-name>, <string-name><surname>Bengio</surname> <given-names>Y</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>A neuronal least-action principle for real-time learning in cortical circuits</article-title>. <source>bioRxiv</source>. <year>2023</year>. doi:<pub-id pub-id-type="doi">10.1101/2023.03.25.534198</pub-id></mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Padamsey</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Rochefort</surname> <given-names>NL</given-names></string-name></person-group>. <article-title>Paying the brain’s energy bill</article-title>. <source>Curr Opin Neurobiol</source>. <year>2023</year>;<volume>78</volume>: <fpage>102668</fpage>.</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lennie</surname> <given-names>P.</given-names></string-name></person-group> <article-title>The cost of cortical computation</article-title>. <source>Curr Biol</source>. <year>2003</year>;<volume>13</volume>: <fpage>493</fpage>–<lpage>497</lpage>.</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Binmore</surname> <given-names>KG</given-names></string-name></person-group>. <source>Game Theory: A Very Short Introduction</source>. <publisher-name>OUP Oxford</publisher-name>; <year>2007</year>.</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Dugatkin</surname> <given-names>LA</given-names></string-name>, <string-name><surname>Reeve</surname> <given-names>HK</given-names></string-name></person-group>. <source>Game Theory and Animal Behavior</source>. <publisher-name>Oxford University Press</publisher-name>, <publisher-loc>USA</publisher-loc>; <year>2000</year>.</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Davies</surname> <given-names>NB</given-names></string-name>, <string-name><surname>Krebs</surname> <given-names>JR</given-names></string-name>, <string-name><surname>West</surname> <given-names>SA</given-names></string-name></person-group>. <article-title>An Introduction to Behavioural Ecology</article-title>. <source>John Wiley &amp; Sons</source>; <year>2012</year>.</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Estrada</surname> <given-names>E</given-names></string-name>, <string-name><surname>Hatano</surname> <given-names>N.</given-names></string-name></person-group> <article-title>Communicability in complex networks</article-title>. <source>Physical Review E</source>. <year>2008</year>. doi:<pub-id pub-id-type="doi">10.1103/physreve.77.036111</pub-id></mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Algaba</surname> <given-names>E</given-names></string-name>, <string-name><surname>Fragnelli</surname> <given-names>V</given-names></string-name>, <string-name><surname>Sánchez-Soriano</surname> <given-names>J.</given-names></string-name></person-group> <source>Handbook of the Shapley Value</source>. <publisher-name>CRC Press</publisher-name>; <year>2019</year>.</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Shapley</surname> <given-names>LS</given-names></string-name></person-group>. <chapter-title>A value for n-person games</chapter-title>. In: <person-group person-group-type="editor"><string-name><given-names>H. W.</given-names> <surname>Kuhn</surname></string-name> &amp; <string-name><given-names>A. W.</given-names> <surname>Tucker</surname></string-name></person-group>, editor. <source>Contributions to the theory of games</source>. <publisher-loc>Princeton, NJ</publisher-loc>: <publisher-name>Princeton University Press</publisher-name>; <year>1953</year>. pp. <fpage>307</fpage>–<lpage>317</lpage>.</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Keinan</surname> <given-names>A</given-names></string-name>, <string-name><surname>Hilgetag</surname> <given-names>CC</given-names></string-name>, <string-name><surname>Meilijson</surname> <given-names>I</given-names></string-name>, <string-name><surname>Ruppin</surname> <given-names>E.</given-names></string-name></person-group> <article-title>Causal localization of neural function: the Shapley value method</article-title>. <source>Neurocomputing</source>. <year>2004</year>;<volume>58-60</volume>: <fpage>215</fpage>–<lpage>222</lpage>.</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Keinan</surname> <given-names>A</given-names></string-name>, <string-name><surname>Sandbank</surname> <given-names>B</given-names></string-name>, <string-name><surname>Hilgetag</surname> <given-names>CC</given-names></string-name>, <string-name><surname>Meilijson</surname> <given-names>I</given-names></string-name>, <string-name><surname>Ruppin</surname> <given-names>E.</given-names></string-name></person-group> <article-title>Fair attribution of functional contribution in artificial and biological networks</article-title>. <source>Neural Comput</source>. <year>2004</year>;<volume>16</volume>: <fpage>1887</fpage>–<lpage>1915</lpage>.</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Fakhar</surname> <given-names>K</given-names></string-name>, <string-name><surname>Dixit</surname> <given-names>S.</given-names></string-name></person-group> <source>MSA: A compact Python package for Multiperturbation Shapley value Analysis</source>. <year>2021</year>. doi:<pub-id pub-id-type="doi">10.5281/zenodo.5636435</pub-id></mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fakhar</surname> <given-names>K</given-names></string-name>, <string-name><surname>Dixit</surname> <given-names>S</given-names></string-name>, <string-name><surname>Hadaeghi</surname> <given-names>F</given-names></string-name>, <string-name><surname>Kording</surname> <given-names>KP</given-names></string-name>, <string-name><surname>Hilgetag</surname> <given-names>CC</given-names></string-name></person-group>. <article-title>Downstream network transformations dissociate neural activity from causal functional contributions</article-title>. <source>Sci Rep</source>. <year>2024</year>;<volume>14</volume>: <fpage>2103</fpage>.</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gul</surname> <given-names>F.</given-names></string-name></person-group> <article-title>Bargaining Foundations of Shapley Value</article-title>. <source>Econometrica</source>. <year>1989</year>;<volume>57</volume>: <fpage>81</fpage>–<lpage>95</lpage>.</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pérez-Castrillo</surname> <given-names>D</given-names></string-name>, <string-name><surname>Wettstein</surname> <given-names>D.</given-names></string-name></person-group> <article-title>Bidding for the Surplus : A Non-cooperative Approach to the Shapley Value</article-title>. <source>J Econ Theory</source>. <year>2001</year>;<volume>100</volume>: <fpage>274</fpage>–<lpage>294</lpage>.</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Griffa</surname> <given-names>A</given-names></string-name>, <string-name><surname>Alemán-Gómez</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Hagmann</surname> <given-names>P.</given-names></string-name></person-group> <article-title>Structural and functional connectome from 70 young healthy adults [data set]</article-title>. <source>Zenodo</source>. <year>no date</year></mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Shafiei</surname> <given-names>G</given-names></string-name>, <string-name><surname>Markello</surname> <given-names>R</given-names></string-name>, <string-name><surname>Talpalaru</surname> <given-names>T</given-names></string-name>, <string-name><surname>Makowski</surname> <given-names>C</given-names></string-name>, <string-name><surname>Kirschner</surname> <given-names>M</given-names></string-name>, <string-name><surname>Devenyi</surname> <given-names>GA</given-names></string-name>, <etal>et al.</etal></person-group> <source>Consensus Structural and functional connectome from 70 young healthy adults</source>. <year>2019</year>. doi:<pub-id pub-id-type="doi">10.5281/zenodo.3067849</pub-id></mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Rabuffo</surname> <given-names>G</given-names></string-name>, <string-name><surname>Lokossou</surname> <given-names>H-A</given-names></string-name>, <string-name><surname>Li</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Ziaee-Mehr</surname> <given-names>A</given-names></string-name>, <string-name><surname>Hashemi</surname> <given-names>M</given-names></string-name>, <string-name><surname>Quilichini</surname> <given-names>PP</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>On Global Brain Reconfiguration after Local Manipulations</article-title>. <source>bioRxiv</source>. <year>2023</year>. p. 2023.09.08.556815. doi:<pub-id pub-id-type="doi">10.1101/2023.09.08.556815</pub-id></mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Young</surname> <given-names>MP</given-names></string-name>, <string-name><surname>Hilgetag</surname> <given-names>CC</given-names></string-name>, <string-name><surname>Scannell</surname> <given-names>JW</given-names></string-name></person-group>. <article-title>On imputing function to structure from the behavioural effects of brain lesions</article-title>. <source>Philos Trans R Soc Lond B Biol Sci</source>. <year>2000</year>;<volume>355</volume>: <fpage>147</fpage>–<lpage>161</lpage>.</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Grayson</surname> <given-names>DS</given-names></string-name>, <string-name><surname>Bliss-Moreau</surname> <given-names>E</given-names></string-name>, <string-name><surname>Machado</surname> <given-names>CJ</given-names></string-name>, <string-name><surname>Bennett</surname> <given-names>J</given-names></string-name>, <string-name><surname>Shen</surname> <given-names>K</given-names></string-name>, <string-name><surname>Grant</surname> <given-names>KA</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>The Rhesus Monkey Connectome Predicts Disrupted Functional Networks Resulting from Pharmacogenetic Inactivation of the Amygdala</article-title>. <source>Neuron</source>. <year>2016</year>;<volume>91</volume>: <fpage>453</fpage>–<lpage>466</lpage>.</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Seguin</surname> <given-names>C</given-names></string-name>, <string-name><surname>Tian</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Zalesky</surname> <given-names>A.</given-names></string-name></person-group> <article-title>Network communication models improve the behavioral and functional predictive utility of the human structural connectome</article-title>. <source>Netw Neurosci</source>. <year>2020</year>;<volume>4</volume>: <fpage>980</fpage>–<lpage>1006</lpage>.</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Seguin</surname> <given-names>C</given-names></string-name>, <string-name><surname>Jedynak</surname> <given-names>M</given-names></string-name>, <string-name><surname>David</surname> <given-names>O</given-names></string-name>, <string-name><surname>Sina</surname> <given-names>ML</given-names></string-name>, <string-name><surname>Sporns</surname> <given-names>O</given-names></string-name>, <string-name><surname>Zalesky</surname> <given-names>A.</given-names></string-name></person-group> <article-title>Communication dynamics in the human connectome shape the cortex-wide propagation of direct electrical stimulation</article-title>. <source>bioRxiv</source>. <year>2022</year>. p. 2022.07.05.498875. doi:<pub-id pub-id-type="doi">10.1101/2022.07.05.498875</pub-id></mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Seguin</surname> <given-names>C</given-names></string-name>, <string-name><surname>Sina</surname> <given-names>ML</given-names></string-name>, <string-name><surname>Sporns</surname> <given-names>O</given-names></string-name>, <string-name><surname>Zalesky</surname> <given-names>A</given-names></string-name>, <string-name><surname>Calamante</surname> <given-names>F.</given-names></string-name></person-group> <article-title>Network communication models narrow the gap between the modular organization of structural and functional brain networks</article-title>. <source>bioRxiv</source>. <year>2022</year>. p. 2022.02.18.480871. doi:<pub-id pub-id-type="doi">10.1101/2022.02.18.480871</pub-id></mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Betzel</surname> <given-names>RF</given-names></string-name>, <string-name><surname>Gu</surname> <given-names>S</given-names></string-name>, <string-name><surname>Medaglia</surname> <given-names>JD</given-names></string-name>, <string-name><surname>Pasqualetti</surname> <given-names>F</given-names></string-name>, <string-name><surname>Bassett</surname> <given-names>DS</given-names></string-name></person-group>. <article-title>Optimally controlling the human connectome: the role of network topology</article-title>. <source>Sci Rep</source>. <year>2016</year>;<volume>6</volume>: <fpage>30770</fpage>.</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zamora-López</surname> <given-names>G</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Deco</surname> <given-names>G</given-names></string-name>, <string-name><surname>Kringelbach</surname> <given-names>ML</given-names></string-name>, <string-name><surname>Zhou</surname> <given-names>C.</given-names></string-name></person-group> <article-title>Functional complexity emerging from anatomical constraints in the brain: the significance of network modularity and richclubs</article-title>. <source>Sci Rep</source>. <year>2016</year>;<volume>6</volume>: <fpage>38424</fpage>.</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Messé</surname> <given-names>A</given-names></string-name>, <string-name><surname>Rudrauf</surname> <given-names>D</given-names></string-name>, <string-name><surname>Benali</surname> <given-names>H</given-names></string-name>, <string-name><surname>Marrelec</surname> <given-names>G.</given-names></string-name></person-group> <article-title>Relating structure and function in the human brain: relative contributions of anatomy, stationary dynamics, and non-stationarities</article-title>. <source>PLoS Comput Biol</source>. <year>2014</year>;<volume>10</volume>: <fpage>e1003530</fpage>.</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Messé</surname> <given-names>A</given-names></string-name>, <string-name><surname>Rudrauf</surname> <given-names>D</given-names></string-name>, <string-name><surname>Giron</surname> <given-names>A</given-names></string-name>, <string-name><surname>Marrelec</surname> <given-names>G.</given-names></string-name></person-group> <article-title>Predicting functional connectivity from structural connectivity via computational models using MRI: an extensive comparison study</article-title>. <source>Neuroimage</source>. <year>2015</year>;<volume>111</volume>: <fpage>65</fpage>–<lpage>75</lpage>.</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Abdelnour</surname> <given-names>F</given-names></string-name>, <string-name><surname>Voss</surname> <given-names>HU</given-names></string-name>, <string-name><surname>Raj</surname> <given-names>A.</given-names></string-name></person-group> <article-title>Network diffusion accurately models the relationship between structural and functional brain connectivity networks</article-title>. <source>Neuroimage</source>. <year>2014</year>;<volume>90</volume>: <fpage>335</fpage>–<lpage>347</lpage>.</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Nozari</surname> <given-names>E</given-names></string-name>, <string-name><surname>Bertolero</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Stiso</surname> <given-names>J</given-names></string-name>, <string-name><surname>Caciagli</surname> <given-names>L</given-names></string-name>, <string-name><surname>Cornblath</surname> <given-names>EJ</given-names></string-name>, <string-name><surname>He</surname> <given-names>X</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Macroscopic resting-state brain dynamics are best described by linear models</article-title>. <source>Nat Biomed Eng</source>. <year>2023</year>. doi:<pub-id pub-id-type="doi">10.1038/s41551-023-01117-y</pub-id></mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Messé</surname> <given-names>A</given-names></string-name>, <string-name><surname>Hollensteiner</surname> <given-names>KJ</given-names></string-name>, <string-name><surname>Delettre</surname> <given-names>C</given-names></string-name>, <string-name><given-names>Dell-Brown</given-names> <surname>L-A</surname></string-name>, <string-name><surname>Pieper</surname> <given-names>F</given-names></string-name>, <string-name><surname>Nentwig</surname> <given-names>LJ</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Structural basis of envelope and phase intrinsic coupling modes in the cerebral cortex</article-title>. <source>Neuroimage</source>. <year>2023</year>;<volume>276</volume>: <fpage>120212</fpage>.</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Deco</surname> <given-names>G</given-names></string-name>, <string-name><surname>Kringelbach</surname> <given-names>ML</given-names></string-name>, <string-name><surname>Jirsa</surname> <given-names>VK</given-names></string-name>, <string-name><surname>Ritter</surname> <given-names>P.</given-names></string-name></person-group> <article-title>The dynamics of resting fluctuations in the brain: metastability and its dynamical cortical core</article-title>. <source>Sci Rep</source>. <year>2017</year>;<volume>7</volume>: <fpage>3095</fpage>.</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van den Heuvel</surname> <given-names>MP</given-names></string-name>, <string-name><surname>Sporns</surname> <given-names>O.</given-names></string-name></person-group> <article-title>Rich-Club Organization of the Human Connectome</article-title>. <source>Journal of Neuroscience</source>. <year>2011</year>;<volume>31</volume>: <fpage>15775</fpage>–<lpage>15786</lpage>.</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zamora-López</surname> <given-names>G</given-names></string-name>, <string-name><surname>Zhou</surname> <given-names>C</given-names></string-name>, <string-name><surname>Kurths</surname> <given-names>J.</given-names></string-name></person-group> <article-title>Cortical hubs form a module for multisensory integration on top of the hierarchy of cortical networks</article-title>. <source>Front Neuroinform</source>. <year>2010</year>;<volume>4</volume>: <fpage>1</fpage>.</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zamora-López</surname> <given-names>G</given-names></string-name>, <string-name><surname>Zhou</surname> <given-names>C</given-names></string-name>, <string-name><surname>Kurths</surname> <given-names>J.</given-names></string-name></person-group> <article-title>Exploring brain function from anatomical connectivity</article-title>. <source>Front Neurosci</source>. <year>2011</year>;<volume>5</volume>: <fpage>83</fpage>.</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Harriger</surname> <given-names>L</given-names></string-name>, <string-name><surname>van den Heuvel</surname> <given-names>MP</given-names></string-name>, <string-name><surname>Sporns</surname> <given-names>O.</given-names></string-name></person-group> <article-title>Rich club organization of macaque cerebral cortex and its role in network communication</article-title>. <source>PLoS One</source>. <year>2012</year>;<volume>7</volume>: <fpage>e46497</fpage>.</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van den Heuvel</surname> <given-names>MP</given-names></string-name>, <string-name><surname>Kahn</surname> <given-names>RS</given-names></string-name>, <string-name><surname>Goñi</surname> <given-names>J</given-names></string-name>, <string-name><surname>Sporns</surname> <given-names>O.</given-names></string-name></person-group> <article-title>High-cost, high-capacity backbone for global brain communication</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2012</year>;<volume>109</volume>: <fpage>11372</fpage>–<lpage>11377</lpage>.</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Betzel</surname> <given-names>RF</given-names></string-name>, <string-name><surname>Bassett</surname> <given-names>DS</given-names></string-name></person-group>. <article-title>Specificity and robustness of long-distance connections in weighted, interareal connectomes</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2018</year>;<volume>115</volume>: <fpage>E4880</fpage>–<lpage>E4889</lpage>.</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goulas</surname> <given-names>A</given-names></string-name>, <string-name><surname>Schaefer</surname> <given-names>A</given-names></string-name>, <string-name><surname>Margulies</surname> <given-names>DS</given-names></string-name></person-group>. <article-title>The strength of weak connections in the macaque cortico-cortical network</article-title>. <source>Brain Struct Funct</source>. <year>2015</year>;<volume>220</volume>: <fpage>2939</fpage>–<lpage>2951</lpage>.</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Beul</surname> <given-names>SF</given-names></string-name>, <string-name><surname>Goulas</surname> <given-names>A</given-names></string-name>, <string-name><surname>Hilgetag</surname> <given-names>CC</given-names></string-name></person-group>. <article-title>Comprehensive computational modelling of the development of mammalian cortical connectivity underlying an architectonic type principle</article-title>. <source>PLoS Comput Biol</source>. <year>2018</year>;<volume>14</volume>: <fpage>e1006550</fpage>.</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Lynn</surname> <given-names>CW</given-names></string-name>, <string-name><surname>Holmes</surname> <given-names>CM</given-names></string-name>, <string-name><surname>Palmer</surname> <given-names>SE</given-names></string-name></person-group>. <article-title>Heavy-tailed neuronal connectivity arises from Hebbian self-organization</article-title>. <source>Nat Phys</source>. <year>2024</year>. doi:<pub-id pub-id-type="doi">10.1038/s41567-023-02332-9</pub-id></mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Markov</surname> <given-names>NT</given-names></string-name>, <string-name><surname>Ercsey-Ravasz</surname> <given-names>M</given-names></string-name>, <string-name><surname>Lamy</surname> <given-names>C</given-names></string-name>, <string-name><surname>Ribeiro Gomes</surname> <given-names>AR</given-names></string-name>, <string-name><surname>Magrou</surname> <given-names>L</given-names></string-name>, <string-name><surname>Misery</surname> <given-names>P</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>The role of long-range connections on the specificity of the macaque interareal cortical network</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2013</year>;<volume>110</volume>: <fpage>5187</fpage>–<lpage>5192</lpage>.</mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ercsey-Ravasz</surname> <given-names>M</given-names></string-name>, <string-name><surname>Markov</surname> <given-names>NT</given-names></string-name>, <string-name><surname>Lamy</surname> <given-names>C</given-names></string-name>, <string-name><surname>Van Essen</surname> <given-names>DC</given-names></string-name>, <string-name><surname>Knoblauch</surname> <given-names>K</given-names></string-name>, <string-name><surname>Toroczkai</surname> <given-names>Z</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>A predictive network model of cerebral cortical connectivity based on a distance rule</article-title>. <source>Neuron</source>. <year>2013</year>;<volume>80</volume>: <fpage>184</fpage>–<lpage>197</lpage>.</mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Kim</surname> <given-names>S</given-names></string-name>, <string-name><surname>Moon</surname> <given-names>HS</given-names></string-name>, <string-name><surname>Vo</surname> <given-names>TT</given-names></string-name>, <string-name><surname>Kim</surname> <given-names>C-H</given-names></string-name>, <string-name><surname>Im</surname> <given-names>GH</given-names></string-name>, <string-name><surname>Lee</surname> <given-names>S</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Whole-brain mapping of effective connectivity by fMRI with cortex-wide patterned optogenetics</article-title>. <source>Neuron</source>. <year>2023</year>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2023.03.002</pub-id></mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van den Heuvel</surname> <given-names>MP</given-names></string-name>, <string-name><surname>Mandl</surname> <given-names>RCW</given-names></string-name>, <string-name><surname>Stam</surname> <given-names>CJ</given-names></string-name>, <string-name><surname>Kahn</surname> <given-names>RS</given-names></string-name>, <string-name><surname>Hulshoff Pol</surname> <given-names>HE</given-names></string-name></person-group>. <article-title>Aberrant Frontal and Temporal Complex Network Structure in Schizophrenia: A Graph Theoretical Analysis</article-title>. <source>J Neurosci</source>. <year>2010</year>;<volume>30</volume>: <fpage>15915</fpage>–<lpage>15926</lpage>.</mixed-citation></ref>
<ref id="c63"><label>63.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gu</surname> <given-names>S</given-names></string-name>, <string-name><surname>Pasqualetti</surname> <given-names>F</given-names></string-name>, <string-name><surname>Cieslak</surname> <given-names>M</given-names></string-name>, <string-name><surname>Telesford</surname> <given-names>QK</given-names></string-name>, <string-name><surname>Yu</surname> <given-names>AB</given-names></string-name>, <string-name><surname>Kahn</surname> <given-names>AE</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Controllability of structural brain networks</article-title>. <source>Nat Commun</source>. <year>2015</year>;<volume>6</volume>: <fpage>8414</fpage>.</mixed-citation></ref>
<ref id="c64"><label>64.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Samoylenko</surname> <given-names>I</given-names></string-name>, <string-name><surname>Aleja</surname> <given-names>D</given-names></string-name>, <string-name><surname>Primo</surname> <given-names>E</given-names></string-name>, <string-name><surname>Alfaro-Bittner</surname> <given-names>K</given-names></string-name>, <string-name><surname>Vasilyeva</surname> <given-names>E</given-names></string-name>, <string-name><surname>Kovalenko</surname> <given-names>K</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Why are there six degrees of separation in a social network?</article-title> <source>arXiv [physics.soc-ph]</source>. <year>2022</year>. Available: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2211.09463">http://arxiv.org/abs/2211.09463</ext-link></mixed-citation></ref>
<ref id="c65"><label>65.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Travers</surname> <given-names>J</given-names></string-name>, <string-name><surname>Milgram</surname> <given-names>S.</given-names></string-name></person-group> <article-title>An experimental study of the small world problem</article-title>. <source>Soc Networks</source>. <year>1977</year>. Available: <ext-link ext-link-type="uri" xlink:href="https://www.sciencedirect.com/science/article/pii/B9780124424500500183">https://www.sciencedirect.com/science/article/pii/B9780124424500500183</ext-link></mixed-citation></ref>
<ref id="c66"><label>66.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Chessa</surname> <given-names>M</given-names></string-name>, <string-name><surname>Hanaki</surname> <given-names>N</given-names></string-name>, <string-name><surname>Lardon</surname> <given-names>A</given-names></string-name>, <string-name><surname>Yamada</surname> <given-names>T.</given-names></string-name></person-group> <article-title>Cost of Complexity in Implementing the Shapley Value by Choosing a Proposer Through a Bidding Procedure</article-title>. <source>Institute of Social and Economic Research, Osaka University</source>; <year>2022</year>.</mixed-citation></ref>
<ref id="c67"><label>67.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Roth</surname> <given-names>AE</given-names></string-name></person-group>. <chapter-title>The Shapley value: essays in honor of Lloyd S</chapter-title>. <source>Shapley</source>. <publisher-name>Cambridge University Press</publisher-name>; <year>1988</year>.</mixed-citation></ref>
<ref id="c68"><label>68.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Lundberg</surname> <given-names>SM</given-names></string-name>, <string-name><surname>Lee</surname> <given-names>S-I.</given-names></string-name></person-group> <article-title>A unified approach to interpreting model predictions</article-title>. <source>Adv Neural Inf Process Syst</source>. <year>2017</year>; <fpage>4765</fpage>–<lpage>4774</lpage>.</mixed-citation></ref>
<ref id="c69"><label>69.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Chen</surname> <given-names>H</given-names></string-name>, <string-name><surname>Covert</surname> <given-names>IC</given-names></string-name>, <string-name><surname>Lundberg</surname> <given-names>SM</given-names></string-name>, <string-name><surname>Lee</surname> <given-names>S-I.</given-names></string-name></person-group> <article-title>Algorithms to estimate Shapley value feature attributions</article-title>. <source>arXiv [cs.LG]</source>. <year>2022</year>. Available: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2207.07605">http://arxiv.org/abs/2207.07605</ext-link></mixed-citation></ref>
<ref id="c70"><label>70.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Ay</surname> <given-names>N</given-names></string-name>, <string-name><surname>Polani</surname> <given-names>D.</given-names></string-name></person-group> <article-title>INFORMATION FLOWS IN CAUSAL NETWORKS</article-title>. <source>Advances in Complex Systems</source>. <year>2008</year>. pp. <fpage>17</fpage>–<lpage>41</lpage>. doi:<pub-id pub-id-type="doi">10.1142/s0219525908001465</pub-id></mixed-citation></ref>
<ref id="c71"><label>71.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Novelli</surname> <given-names>L</given-names></string-name>, <string-name><surname>Lizier</surname> <given-names>JT</given-names></string-name></person-group>. <article-title>Inferring network properties from time series using transfer entropy and mutual information: Validation of multivariate versus bivariate approaches</article-title>. <source>Network Neuroscience</source>. <year>2020</year>; <fpage>1</fpage>–<lpage>32</lpage>.</mixed-citation></ref>
<ref id="c72"><label>72.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Ehrlich</surname> <given-names>DA</given-names></string-name>, <string-name><surname>Schneider</surname> <given-names>AC</given-names></string-name>, <string-name><surname>Wibral</surname> <given-names>M</given-names></string-name>, <string-name><surname>Priesemann</surname> <given-names>V</given-names></string-name>, <string-name><surname>Makkeh</surname> <given-names>A.</given-names></string-name></person-group> <article-title>Partial Information Decomposition Reveals the Structure of Neural Representations</article-title>. <source>arXiv [cs.IT]</source>. <year>2022</year>. Available: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2209.10438">http://arxiv.org/abs/2209.10438</ext-link></mixed-citation></ref>
<ref id="c73"><label>73.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gutknecht</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>Wibral</surname> <given-names>M</given-names></string-name>, <string-name><surname>Makkeh</surname> <given-names>A.</given-names></string-name></person-group> <article-title>Bits and pieces: understanding information decomposition from part-whole relationships and formal logic</article-title>. <source>Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences</source>. <year>2021</year>;<volume>477</volume>: <fpage>20210110</fpage>.</mixed-citation></ref>
<ref id="c74"><label>74.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Luppi</surname> <given-names>AI</given-names></string-name>, <string-name><surname>Rosas</surname> <given-names>FE</given-names></string-name>, <string-name><surname>Mediano</surname> <given-names>PAM</given-names></string-name>, <string-name><surname>Menon</surname> <given-names>DK</given-names></string-name>, <string-name><surname>Stamatakis</surname> <given-names>EA</given-names></string-name></person-group>. <article-title>Information decomposition and the informational architecture of the brain</article-title>. <source>Trends Cogn Sci</source>. <year>2024</year>. doi:<pub-id pub-id-type="doi">10.1016/j.tics.2023.11.005</pub-id></mixed-citation></ref>
<ref id="c75"><label>75.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Ay</surname> <given-names>N</given-names></string-name>, <string-name><surname>Polani</surname> <given-names>D</given-names></string-name>, <string-name><surname>Virgo</surname> <given-names>N.</given-names></string-name></person-group> <article-title>Information Decomposition based on Cooperative Game Theory</article-title>. <source>arXiv [cs.IT]</source>. <year>2019</year>. Available: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1910.05979">http://arxiv.org/abs/1910.05979</ext-link></mixed-citation></ref>
<ref id="c76"><label>76.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Fakhar</surname> <given-names>K</given-names></string-name>, <string-name><surname>Hadaeghi</surname> <given-names>F</given-names></string-name>, <string-name><surname>Hilgetag</surname> <given-names>CC</given-names></string-name></person-group>. <article-title>Causal Influences Decouple From Their Underlying Network Structure In Echo State Networks</article-title>. <source>2022 International Joint Conference on Neural Networks (IJCNN)</source>. <year>2022</year>. pp. <fpage>1</fpage>–<lpage>8</lpage>.</mixed-citation></ref>
<ref id="c77"><label>77.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fakhar</surname> <given-names>K</given-names></string-name>, <string-name><surname>Hilgetag</surname> <given-names>CC</given-names></string-name></person-group>. <article-title>Systematic perturbation of an artificial neural network: A step towards quantifying causal contributions in the brain</article-title>. <source>PLoS Comput Biol</source>. <year>2022</year>;<volume>18</volume>: <fpage>e1010250</fpage>.</mixed-citation></ref>
<ref id="c78"><label>78.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Zavaglia</surname> <given-names>M</given-names></string-name>, <string-name><surname>Malherbe</surname> <given-names>C</given-names></string-name>, <string-name><surname>Schlaadt</surname> <given-names>S</given-names></string-name>, <string-name><surname>Nachev</surname> <given-names>P</given-names></string-name>, <string-name><surname>Hilgetag</surname> <given-names>CC</given-names></string-name></person-group>. <article-title>Ground-truth validation of uni- and multivariate lesion inference approaches</article-title>. <source>bioRxiv</source>. <year>2023</year>. p. 2023.03.28.534534. doi:<pub-id pub-id-type="doi">10.1101/2023.03.28.534534</pub-id></mixed-citation></ref>
<ref id="c79"><label>79.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Malherbe</surname> <given-names>C</given-names></string-name>, <string-name><surname>Cheng</surname> <given-names>B</given-names></string-name>, <string-name><surname>Königsberg</surname> <given-names>A</given-names></string-name>, <string-name><surname>Cho</surname> <given-names>T-H</given-names></string-name>, <string-name><surname>Ebinger</surname> <given-names>M</given-names></string-name>, <string-name><surname>Endres</surname> <given-names>M</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Game-theoretical mapping of fundamental brain functions based on lesion deficits in acute stroke</article-title>. <source>Brain Commun</source>. <year>2021</year>;<volume>3</volume>: <fpage>fcab204</fpage>.</mixed-citation></ref>
<ref id="c80"><label>80.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Woodward</surname> <given-names>J.</given-names></string-name></person-group> <source>Making Things Happen: A Theory of Causal Explanation</source>. <publisher-name>Oxford University Press</publisher-name>, <publisher-loc>USA</publisher-loc>; <year>2005</year>.</mixed-citation></ref>
<ref id="c81"><label>81.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Joutsa</surname> <given-names>J</given-names></string-name>, <string-name><surname>Lipsman</surname> <given-names>N</given-names></string-name>, <string-name><surname>Horn</surname> <given-names>A</given-names></string-name>, <string-name><surname>Cosgrove</surname> <given-names>GR</given-names></string-name>, <string-name><surname>Fox</surname> <given-names>MD</given-names></string-name></person-group>. <article-title>The return of the lesion for localization and therapy</article-title>. <source>Brain</source>. <year>2023</year>. doi:<pub-id pub-id-type="doi">10.1093/brain/awad123</pub-id></mixed-citation></ref>
<ref id="c82"><label>82.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Adolphs</surname> <given-names>R.</given-names></string-name></person-group> <article-title>Human Lesion Studies in the 21st Century</article-title>. <source>Neuron</source>. <year>2016</year>;<volume>90</volume>: <fpage>1151</fpage>–<lpage>1153</lpage>.</mixed-citation></ref>
<ref id="c83"><label>83.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Siddiqi</surname> <given-names>SH</given-names></string-name>, <string-name><surname>Kording</surname> <given-names>KP</given-names></string-name>, <string-name><surname>Parvizi</surname> <given-names>J</given-names></string-name>, <string-name><surname>Fox</surname> <given-names>MD</given-names></string-name></person-group>. <article-title>Causal mapping of human brain function</article-title>. <source>Nat Rev Neurosci</source>. <year>2022</year>;<volume>23</volume>: <fpage>361</fpage>–<lpage>375</lpage>.</mixed-citation></ref>
<ref id="c84"><label>84.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Vaidya</surname> <given-names>AR</given-names></string-name>, <string-name><surname>Pujara</surname> <given-names>MS</given-names></string-name>, <string-name><surname>Petrides</surname> <given-names>M</given-names></string-name>, <string-name><surname>Murray</surname> <given-names>EA</given-names></string-name>, <string-name><surname>Fellows</surname> <given-names>LK</given-names></string-name></person-group>. <article-title>Lesion Studies in Contemporary Neuroscience</article-title>. <source>Trends Cogn Sci</source>. <year>2019</year>; <fpage>1</fpage>–<lpage>19</lpage>.</mixed-citation></ref>
<ref id="c85"><label>85.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ross</surname> <given-names>LN</given-names></string-name></person-group>. <article-title>Causal Selection and the Pathway Concept</article-title>. <source>Philos Sci</source>. <year>2018</year>;<volume>85</volume>: <fpage>551</fpage>–<lpage>572</lpage>.</mixed-citation></ref>
<ref id="c86"><label>86.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Seguin</surname> <given-names>C</given-names></string-name>, <string-name><surname>Razi</surname> <given-names>A</given-names></string-name>, <string-name><surname>Zalesky</surname> <given-names>A.</given-names></string-name></person-group> <article-title>Inferring neural signalling directionality from undirected structural connectomes</article-title>. <source>Nat Commun</source>. <year>2019</year>;<volume>10</volume>: <fpage>4289</fpage>.</mixed-citation></ref>
<ref id="c87"><label>87.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Rosen</surname> <given-names>BQ</given-names></string-name>, <string-name><surname>Sejnowski</surname> <given-names>TJ</given-names></string-name></person-group>. <article-title>Dynamical differential covariance recovers directional network structure in multiscale neural systems</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2022</year>;<volume>119</volume>: <fpage>e2117234119</fpage>.</mixed-citation></ref>
<ref id="c88"><label>88.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Laasch</surname> <given-names>N</given-names></string-name>, <string-name><surname>Braun</surname> <given-names>W</given-names></string-name>, <string-name><surname>Knoff</surname> <given-names>L</given-names></string-name>, <string-name><surname>Bielecki</surname> <given-names>J</given-names></string-name>, <string-name><surname>Hilgetag</surname> <given-names>CC</given-names></string-name></person-group>. <article-title>A new approach for estimating effective connectivity from activity in neural networks</article-title>. <source>bioRxiv</source>. <year>2024</year>. p. 2024.02.05.578871. doi:<pub-id pub-id-type="doi">10.1101/2024.02.05.578871</pub-id></mixed-citation></ref>
<ref id="c89"><label>89.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Sporns</surname> <given-names>O.</given-names></string-name></person-group> <article-title>Graph theory methods: applications in brain networks</article-title>. <source>Dialogues Clin Neurosci</source>. <year>2022</year>. Available: <ext-link ext-link-type="uri" xlink:href="https://www.tandfonline.com/doi/full/10.31887/DCNS.2018.20.2/osporns">https://www.tandfonline.com/doi/full/10.31887/DCNS.2018.20.2/osporns</ext-link></mixed-citation></ref>
<ref id="c90"><label>90.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Griffa</surname> <given-names>A</given-names></string-name>, <string-name><surname>Mach</surname> <given-names>M</given-names></string-name>, <string-name><surname>Dedelley</surname> <given-names>J</given-names></string-name>, <string-name><surname>Gutierrez-Barragan</surname> <given-names>D</given-names></string-name>, <string-name><surname>Gozzi</surname> <given-names>A</given-names></string-name>, <string-name><surname>Allali</surname> <given-names>G</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Evidence for increased parallel information transmission in human brain networks compared to macaques and male mice</article-title>. <source>Nat Commun</source>. <year>2023</year>;<volume>14</volume>. doi:<pub-id pub-id-type="doi">10.1038/s41467-023-43971-z</pub-id></mixed-citation></ref>
<ref id="c91"><label>91.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Zamora-López</surname> <given-names>G</given-names></string-name>, <string-name><surname>Gilson</surname> <given-names>M.</given-names></string-name></person-group> <article-title>An integrative dynamical perspective for graph theory and the study of complex networks</article-title>. <source>arXiv [physics.soc-ph]</source>. <year>2023</year>. Available: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2307.02449">http://arxiv.org/abs/2307.02449</ext-link></mixed-citation></ref>
<ref id="c92"><label>92.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Luppi</surname> <given-names>AI</given-names></string-name>, <string-name><surname>Mediano</surname> <given-names>PAM</given-names></string-name>, <string-name><surname>Rosas</surname> <given-names>FE</given-names></string-name>, <string-name><surname>Holland</surname> <given-names>N</given-names></string-name>, <string-name><surname>Fryer</surname> <given-names>TD</given-names></string-name>, <string-name><surname>O’Brien</surname> <given-names>JT</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>A synergistic core for human brain evolution and cognition</article-title>. <source>Nat Neurosci</source>. <year>2022</year>;<volume>25</volume>: <fpage>771</fpage>–<lpage>782</lpage>.</mixed-citation></ref>
<ref id="c93"><label>93.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Ghosh</surname> <given-names>R</given-names></string-name>, <string-name><surname>Lerman</surname> <given-names>K</given-names></string-name>, <string-name><surname>Surachawala</surname> <given-names>T</given-names></string-name>, <string-name><surname>Voevodski</surname> <given-names>K</given-names></string-name>, <string-name><surname>Teng</surname> <given-names>S-H.</given-names></string-name></person-group> <article-title>Non-Conservative Diffusion and its Application to Social Network Analysis</article-title>. <source>arXiv [cs.SI]</source>. <year>2011</year>. Available: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1102.4639">http://arxiv.org/abs/1102.4639</ext-link></mixed-citation></ref>
<ref id="c94"><label>94.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Muller</surname> <given-names>L</given-names></string-name>, <string-name><surname>Chavane</surname> <given-names>F</given-names></string-name>, <string-name><surname>Reynolds</surname> <given-names>J</given-names></string-name>, <string-name><surname>Sejnowski</surname> <given-names>TJ</given-names></string-name></person-group>. <article-title>Cortical travelling waves: mechanisms and computational principles</article-title>. <source>Nat Rev Neurosci</source>. <year>2018</year>;<volume>19</volume>: <fpage>255</fpage>–<lpage>268</lpage>.</mixed-citation></ref>
<ref id="c95"><label>95.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Keller</surname> <given-names>CJ</given-names></string-name>, <string-name><surname>Bickel</surname> <given-names>S</given-names></string-name>, <string-name><surname>Entz</surname> <given-names>L</given-names></string-name>, <string-name><surname>Ulbert</surname> <given-names>I</given-names></string-name>, <string-name><surname>Milham</surname> <given-names>MP</given-names></string-name>, <string-name><surname>Kelly</surname> <given-names>C</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Intrinsic functional architecture predicts electrically evoked responses in the human brain</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2011</year>;<volume>108</volume>: <fpage>10308</fpage>–<lpage>10313</lpage>.</mixed-citation></ref>
<ref id="c96"><label>96.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Campbell</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Davis</surname> <given-names>TS</given-names></string-name>, <string-name><surname>Anderson</surname> <given-names>DN</given-names></string-name>, <string-name><surname>Arain</surname> <given-names>A</given-names></string-name>, <string-name><surname>Inman</surname> <given-names>CS</given-names></string-name>, <string-name><surname>Smith</surname> <given-names>EH</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Subsets of cortico-cortical evoked potentials propagate as traveling waves</article-title>. <source>bioRxiv</source>. <year>2023</year>. doi:<pub-id pub-id-type="doi">10.1101/2023.03.27.534002</pub-id></mixed-citation></ref>
<ref id="c97"><label>97.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rubinov</surname> <given-names>M.</given-names></string-name></person-group> <article-title>Constraints and spandrels of interareal connectomes</article-title>. <source>Nat Commun</source>. <year>2016</year>;<volume>7</volume>: <fpage>1</fpage>–<lpage>11</lpage>.</mixed-citation></ref>
<ref id="c98"><label>98.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gould</surname> <given-names>SJ</given-names></string-name>, <string-name><surname>Lewontin</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Maynard Smith</surname> <given-names>J</given-names></string-name>, <string-name><surname>Holliday</surname> <given-names>R.</given-names></string-name></person-group> <article-title>The spandrels of San Marco and the Panglossian paradigm: a critique of the adaptationist programme</article-title>. <source>Proceedings of the Royal Society of London Series B Biological Sciences</source>. <year>1997</year>;<volume>205</volume>: <fpage>581</fpage>–<lpage>598</lpage>.</mixed-citation></ref>
<ref id="c99"><label>99.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hasson</surname> <given-names>U</given-names></string-name>, <string-name><surname>Yang</surname> <given-names>E</given-names></string-name>, <string-name><surname>Vallines</surname> <given-names>I</given-names></string-name>, <string-name><surname>Heeger</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Rubin</surname> <given-names>N.</given-names></string-name></person-group> <article-title>A Hierarchy of Temporal Receptive Windows in Human Cortex</article-title>. <source>Journal of Neuroscience</source>. <year>2008</year>;<volume>28</volume>: <fpage>2539</fpage>–<lpage>2550</lpage>.</mixed-citation></ref>
<ref id="c100"><label>100.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chaudhuri</surname> <given-names>R</given-names></string-name>, <string-name><surname>Knoblauch</surname> <given-names>K</given-names></string-name>, <string-name><surname>Gariel</surname> <given-names>M-A</given-names></string-name>, <string-name><surname>Kennedy</surname> <given-names>H</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>X-J.</given-names></string-name></person-group> <article-title>A Large-Scale Circuit Mechanism for Hierarchical Dynamical Processing in the Primate Cortex</article-title>. <source>Neuron</source>. <year>2015</year>;<volume>88</volume>: <fpage>419</fpage>–<lpage>431</lpage>.</mixed-citation></ref>
<ref id="c101"><label>101.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Panda</surname> <given-names>R</given-names></string-name>, <string-name><surname>López-González</surname> <given-names>A</given-names></string-name>, <string-name><surname>Gilson</surname> <given-names>M</given-names></string-name>, <string-name><surname>Gosseries</surname> <given-names>O</given-names></string-name>, <string-name><surname>Thibaut</surname> <given-names>A</given-names></string-name>, <string-name><surname>Frasso</surname> <given-names>G</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Whole-brain analyses indicate the impairment of posterior integration and thalamo-frontotemporal broadcasting in disorders of consciousness</article-title>. <source>Hum Brain Mapp</source>. <year>2023</year>;<volume>44</volume>: <fpage>4352</fpage>–<lpage>4371</lpage>.</mixed-citation></ref>
<ref id="c102"><label>102.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Bazinet</surname> <given-names>V</given-names></string-name>, <string-name><surname>Hansen</surname> <given-names>JY</given-names></string-name>, <string-name><surname>Misic</surname> <given-names>B.</given-names></string-name></person-group> <article-title>Towards a biologically annotated brain connectome</article-title>. <source>Nat Rev Neurosci</source>. <year>2023</year>. doi:<pub-id pub-id-type="doi">10.1038/s41583-023-00752-3</pub-id></mixed-citation></ref>
<ref id="c103"><label>103.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Deco</surname> <given-names>G</given-names></string-name>, <string-name><surname>Kringelbach</surname> <given-names>ML</given-names></string-name>, <string-name><surname>Arnatkeviciute</surname> <given-names>A</given-names></string-name>, <string-name><surname>Oldham</surname> <given-names>S</given-names></string-name>, <string-name><surname>Sabaroedin</surname> <given-names>K</given-names></string-name>, <string-name><surname>Rogasch</surname> <given-names>NC</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Dynamical consequences of regional heterogeneity in the brain’s transcriptional landscape</article-title>. <source>Sci Adv</source>. <year>2021</year>;<volume>7</volume>. doi:<pub-id pub-id-type="doi">10.1126/sciadv.abf4752</pub-id></mixed-citation></ref>
<ref id="c104"><label>104.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zavaglia</surname> <given-names>M</given-names></string-name>, <string-name><surname>Hilgetag</surname> <given-names>CC</given-names></string-name></person-group>. <article-title>Causal functional contributions and interactions in the attention network of the brain: an objective multi-perturbation analysis</article-title>. <source>Brain Struct Funct</source>. <year>2016</year>;<volume>221</volume>: <fpage>2553</fpage>–<lpage>2568</lpage>.</mixed-citation></ref>
<ref id="c105"><label>105.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cakan</surname> <given-names>C</given-names></string-name>, <string-name><surname>Jajcay</surname> <given-names>N</given-names></string-name>, <string-name><surname>Obermayer</surname> <given-names>K.</given-names></string-name></person-group> <article-title>neurolib: A Simulation Framework for Whole-Brain Neural Mass Modeling</article-title>. <source>Cognit Comput</source>. <year>2023</year>;<volume>15</volume>: <fpage>1132</fpage>–<lpage>1152</lpage>.</mixed-citation></ref>
<ref id="c106"><label>106.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rubinov</surname> <given-names>M</given-names></string-name>, <string-name><surname>Sporns</surname> <given-names>O.</given-names></string-name></person-group> <article-title>Complex network measures of brain connectivity: uses and interpretations</article-title>. <source>Neuroimage</source>. <year>2010</year>;<volume>52</volume>: <fpage>1059</fpage>–<lpage>1069</lpage>.</mixed-citation></ref>
<ref id="c107"><label>107.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Parkes</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Kim</surname>, <given-names>J. Z.</given-names></string-name>, &amp; <string-name><surname>Stiso</surname>, <given-names>J.</given-names></string-name></person-group> <source>nctpy: Network Control Theory for Python</source>. doi:<pub-id pub-id-type="doi">10.5281/zenodo.7383161</pub-id> <year>no date</year></mixed-citation></ref>
<ref id="c108"><label>108.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Hagberg</surname> <given-names>A</given-names></string-name>, <string-name><surname>Swart</surname> <given-names>PJ</given-names></string-name>, <string-name><surname>Schult</surname> <given-names>DA</given-names></string-name>. . ;  . <collab>Report No.: LA-UR-08-05495; LA-UR-08-5495</collab></person-group><article-title>Exploring network structure, dynamics, and function using NetworkX</article-title>. <source>Los Alamos National Laboratory (LANL), Los Alamos, NM (United States)</source>; <year>2008</year> <month>Jan</month>. . Available: <ext-link ext-link-type="uri" xlink:href="https://www.osti.gov/biblio/960616">https://www.osti.gov/biblio/960616</ext-link></mixed-citation></ref>
<ref id="c109"><label>109.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shafiei</surname> <given-names>G</given-names></string-name>, <string-name><surname>Markello</surname> <given-names>RD</given-names></string-name>, <string-name><surname>Makowski</surname> <given-names>C</given-names></string-name>, <string-name><surname>Talpalaru</surname> <given-names>A</given-names></string-name>, <string-name><surname>Kirschner</surname> <given-names>M</given-names></string-name>, <string-name><surname>Devenyi</surname> <given-names>GA</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Spatial Patterning of Tissue Volume Loss in Schizophrenia Reflects Brain Network Architecture</article-title>. <source>Biol Psychiatry</source>. <year>2020</year>;<volume>87</volume>: <fpage>727</fpage>–<lpage>735</lpage>.</mixed-citation></ref>
<ref id="c110"><label>110.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Betzel</surname> <given-names>RF</given-names></string-name>, <string-name><surname>Griffa</surname> <given-names>A</given-names></string-name>, <string-name><surname>Hagmann</surname> <given-names>P</given-names></string-name>, <string-name><surname>Mišic</surname> <given-names>B.</given-names></string-name></person-group> <article-title>Distance-dependent consensus thresholds for generating group-representative structural brain networks</article-title>. <source>Netw Neurosci</source>. <year>2019</year>;<volume>3</volume>: <fpage>475</fpage>–<lpage>496</lpage>.</mixed-citation></ref>
<ref id="c111"><label>111.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Power</surname> <given-names>JD</given-names></string-name>, <string-name><surname>Barnes</surname> <given-names>KA</given-names></string-name>, <string-name><surname>Snyder</surname> <given-names>AZ</given-names></string-name>, <string-name><surname>Schlaggar</surname> <given-names>BL</given-names></string-name>, <string-name><surname>Petersen</surname> <given-names>SE</given-names></string-name></person-group>. <article-title>Spurious but systematic correlations in functional connectivity MRI networks arise from subject motion</article-title>. <source>Neuroimage</source>. <year>2012</year>;<volume>59</volume>: <fpage>2142</fpage>–<lpage>2154</lpage>.</mixed-citation></ref>
<ref id="c112"><label>112.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Oh</surname> <given-names>SW</given-names></string-name>, <string-name><surname>Harris</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Ng</surname> <given-names>L</given-names></string-name>, <string-name><surname>Winslow</surname> <given-names>B</given-names></string-name>, <string-name><surname>Cain</surname> <given-names>N</given-names></string-name>, <string-name><surname>Mihalas</surname> <given-names>S</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>A mesoscale connectome of the mouse brain</article-title>. <source>Nature</source>. <year>2014</year>;<volume>508</volume>: <fpage>207</fpage>–<lpage>214</lpage>.</mixed-citation></ref>
<ref id="c113"><label>113.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rubinov</surname> <given-names>M</given-names></string-name>, <string-name><surname>Ypma</surname> <given-names>RJF</given-names></string-name>, <string-name><surname>Watson</surname> <given-names>C</given-names></string-name>, <string-name><surname>Bullmore</surname> <given-names>ET</given-names></string-name></person-group>. <article-title>Wiring cost and topological participation of the mouse brain connectome</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2015</year>;<volume>112</volume>: <fpage>10032</fpage>–<lpage>10037</lpage>.</mixed-citation></ref>
<ref id="c114"><label>114.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fernández Galán</surname> <given-names>R.</given-names></string-name></person-group> <article-title>On how network architecture determines the dominant patterns of spontaneous neural activity</article-title>. <source>PLoS One</source>. <year>2008</year>;<volume>3</volume>: <fpage>e2148</fpage>.</mixed-citation></ref>
<ref id="c115"><label>115.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Seguin</surname> <given-names>C</given-names></string-name>, <string-name><surname>van den Heuvel</surname> <given-names>MP</given-names></string-name>, <string-name><surname>Zalesky</surname> <given-names>A.</given-names></string-name></person-group> <article-title>Navigation of brain networks</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2018</year>;<volume>115</volume>: <fpage>6297</fpage>–<lpage>6302</lpage>.</mixed-citation></ref>
<ref id="c116"><label>116.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname> <given-names>H.</given-names></string-name></person-group> <article-title>Network landscape from a Brownian particle’s perspective</article-title>. <source>Phys Rev E Stat Nonlin Soft Matter Phys</source>. <year>2003</year>;<volume>67</volume>: <fpage>041908</fpage>.</mixed-citation></ref>
<ref id="c117"><label>117.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goñi</surname> <given-names>J</given-names></string-name>, <string-name><surname>Avena-Koenigsberger</surname> <given-names>A</given-names></string-name>, <string-name><surname>Velez de Mendizabal</surname> <given-names>N</given-names></string-name>, <string-name><surname>van den Heuvel</surname> <given-names>MP</given-names></string-name>, <string-name><surname>Betzel</surname> <given-names>RF</given-names></string-name>, <string-name><surname>Sporns</surname> <given-names>O.</given-names></string-name></person-group> <article-title>Exploring the morphospace of communication efficiency in complex networks</article-title>. <source>PLoS One</source>. <year>2013</year>;<volume>8</volume>: <fpage>e58070</fpage>.</mixed-citation></ref>
<ref id="c118"><label>118.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Katz</surname> <given-names>L.</given-names></string-name></person-group> <article-title>A new status index derived from sociometric analysis</article-title>. <source>Psychometrika</source>. <year>1953</year>;<volume>18</volume>: <fpage>39</fpage>–<lpage>43</lpage>.</mixed-citation></ref>
<ref id="c119"><label>119.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tononi</surname> <given-names>G</given-names></string-name>, <string-name><surname>Sporns</surname> <given-names>O</given-names></string-name>, <string-name><surname>Edelman</surname> <given-names>GM</given-names></string-name></person-group>. <article-title>A measure for brain complexity: relating functional segregation and integration in the nervous system</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>1994</year>;<volume>91</volume>: <fpage>5033</fpage>–<lpage>5037</lpage>.</mixed-citation></ref>
<ref id="c120"><label>120.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rubinov</surname> <given-names>M</given-names></string-name>, <string-name><surname>Sporns</surname> <given-names>O.</given-names></string-name></person-group> <article-title>Weight-conserving characterization of complex functional brain networks</article-title>. <source>Neuroimage</source>. <year>2011</year>;<volume>56</volume>: <fpage>2068</fpage>–<lpage>2079</lpage>.</mixed-citation></ref>
<ref id="c121"><label>121.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Maslov</surname> <given-names>S</given-names></string-name>, <string-name><surname>Sneppen</surname> <given-names>K.</given-names></string-name></person-group> <article-title>Specificity and stability in topology of protein networks</article-title>. <source>Science</source>. <year>2002</year>;<volume>296</volume>: <fpage>910</fpage>–<lpage>913</lpage>.</mixed-citation></ref>
<ref id="c122"><label>122.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zuo</surname> <given-names>X-N</given-names></string-name>, <string-name><surname>Ehmke</surname> <given-names>R</given-names></string-name>, <string-name><surname>Mennes</surname> <given-names>M</given-names></string-name>, <string-name><surname>Imperati</surname> <given-names>D</given-names></string-name>, <string-name><surname>Castellanos</surname> <given-names>FX</given-names></string-name>, <string-name><surname>Sporns</surname> <given-names>O</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Network centrality in the human functional connectome</article-title>. <source>Cereb Cortex</source>. <year>2012</year>;<volume>22</volume>: <fpage>1862</fpage>–<lpage>1875</lpage>.</mixed-citation></ref>
<ref id="c123"><label>123.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Oldham</surname> <given-names>S</given-names></string-name>, <string-name><surname>Fulcher</surname> <given-names>B</given-names></string-name>, <string-name><surname>Parkes</surname> <given-names>L</given-names></string-name>, <string-name><surname>Arnatkevic Iute</surname> <given-names>A</given-names></string-name>, <string-name><surname>Suo</surname> <given-names>C</given-names></string-name>, <string-name><surname>Fornito</surname> <given-names>A.</given-names></string-name></person-group> <article-title>Consistency and differences between centrality measures across distinct classes of networks</article-title>. <source>PLoS One</source>. <year>2019</year>;<volume>14</volume>: <fpage>e0220061</fpage>.</mixed-citation></ref>
<ref id="c124"><label>124.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Freeman</surname> <given-names>LC</given-names></string-name></person-group>. <article-title>A Set of Measures of Centrality Based on Betweenness</article-title>. <source>Sociometry</source>. <year>1977</year>;<volume>40</volume>: <fpage>35</fpage>–<lpage>41</lpage>.</mixed-citation></ref>
<ref id="c125"><label>125.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Newman</surname> <given-names>MEJ</given-names></string-name></person-group>. <article-title>A measure of betweenness centrality based on random walks</article-title>. <source>Soc Networks</source>. <year>2005</year>;<volume>27</volume>: <fpage>39</fpage>–<lpage>54</lpage>.</mixed-citation></ref>
</ref-list>
<sec id="s6">
<title>Supplementary information</title>
<fig id="figS1" position="float" fig-type="figure">
<label>Supplementary Figure 1.</label>
<caption><p>Fitting curve of the scaled communicability (left) and the linear attenuation model (right) to the optimal influence matrix of the human connectome.</p></caption>
<graphic xlink:href="598676v1_figS1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS2" position="float" fig-type="figure">
<label>Supplementary Figure 2.</label>
<caption><p>Fitting curves of the spatial autoregressive model (top), scaled communicability (middle) and the linear attenuation model (bottom) to the optimal influence matrix of macaque (left) and mouse (right) connectomes.</p></caption>
<graphic xlink:href="598676v1_figS2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS3" position="float" fig-type="figure">
<label>Supplementary Figure 3.</label>
<caption><p>Temporal characteristics of optimal influence, given the Hopf model. The part above shows how the amplitude of influence between two regions relates to the structural weight and the topological distance between them. The heatmaps in the middle represent the brain-wide incoming and outgoing influence to and from the posterior cingulate cortex (PCC). Together with the column-averaged time course of these influences, the middle plot suggests that PCC receives a diverse range of incoming influences but broadcasts the same message to the rest of the network. This is also apparent from the zoomed-in view of the heatmap at the bottom.</p></caption>
<graphic xlink:href="598676v1_figS3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS4" position="float" fig-type="figure">
<label>Supplementary Figure 4.</label>
<caption><p>The relationship between the log-normalized structural weights and the fiber length, which had a correlation of -0.6, suggesting that the longer the fiber, the weaker its strength is.</p></caption>
<graphic xlink:href="598676v1_figS4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS5" position="float" fig-type="figure">
<label>Supplementary Figure 5.</label>
<caption><p>Further analysis of the influence of weak connections in null, synthetic, and supplementary networks. A. The relationship between structural weights and the influence of two connected regions in the mouse and macaque connectome supports the results from the human connectome. There exists many weak connections that exert more influence than expected from their connection weights (the ‘bump’) B. Communication models capture the bump to different extent. C. The bump is also apparent in the strength-preserved null model, although localized in weaker connections. D. Two synthetic networks in which both the weights and the topology is randomized did not replicate the bump. E. Topology-preserved weight-shuffled networks replicated the bump, however, as with C. they are localized to weak connections, suggesting a complementary role for both weight distribution and topological features.</p></caption>
<graphic xlink:href="598676v1_figS5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS6" position="float" fig-type="figure">
<label>Supplementary Figure 6.</label>
<caption><p>The relationship between influential nodes (in red) and their controllability measures.</p></caption>
<graphic xlink:href="598676v1_figS6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS7" position="float" fig-type="figure">
<label>Supplementary Figure 7.</label>
<caption><p>Comparing the optimal influence matrices from 1,000 and 10,000 lesion samples per source node.</p></caption>
<graphic xlink:href="598676v1_figS7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS8" position="float" fig-type="figure">
<label>Supplementary Figure 8.</label>
<caption><p>The amount of which univariate and multivariate models can predict optimal influence from summing individual walks, discounted exponentially (as with communicability).</p></caption>
<graphic xlink:href="598676v1_figS8.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS9" position="float" fig-type="figure">
<label>Supplementary Figure 9.</label>
<caption><p>Comparing optimal influence with functional connectivity.</p></caption>
<graphic xlink:href="598676v1_figS9.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.101780.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Schneider-Mizell</surname>
<given-names>Casey M</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Allen Institute for Brain Science</institution>
</institution-wrap>
<city>Seattle</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Compelling</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>The focus of this study is the development of a <bold>compelling</bold> method for analyzing network communication in the brain through an exhaustive computational analysis of virtual lesions. Using human neuroimaging data, the authors identified brain regions that exert the greatest influence over others. These <bold>important</bold> results revealed the characteristic connectivity profile of such brain regions and provided a network analysis method that will find applicability beyond the datasets used.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.101780.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>In this study, Fakhar et al. use a game-theoretical framework to model interregional communication in the brain. They perform virtual lesioning using MSA to obtain a representation of the influence each node exerts on every other node, and then compare the optimal influence profiles of nodes across different communication models. Their results indicate that cortical regions within the brain's &quot;rich club&quot; are most influential.</p>
<p>Strengths:</p>
<p>Overall, the manuscript is well-written. Illustrative examples help to give the reader intuition for the approach and its implementation in this context. The analyses appear to be rigorously performed and appropriate null models are included.</p>
<p>Weaknesses:</p>
<p>The use of game theory to model brain dynamics relies on the assumption that brain regions are similar to agents optimizing their influence, and implies competition between regions. The model can be neatly formalized, but is there biological evidence that the brain optimizes signaling in this way? This could be explored further. Specifically, it would be beneficial if the authors could clarify what the agents (brain regions) are optimizing for at the level of neurobiology - is there evidence for a relationship between regional influence and metabolic demands? Identifying a neurobiological correlate at the same scale at which the authors are modeling neural dynamics would be most compelling.</p>
<p>It is not entirely clear what Figure 6 is meant to contribute to the paper's main findings on communication. The transition to describing this Figure in line 317 is rather abrupt. The authors could more explicitly link these results to earlier analyses to make the rationale for this figure clearer. What motivated the authors' investigation into the persistence of the signal influence across steps?</p>
<p>The authors used resting-state fMRI data to generate functional connectivity matrices, which they used to inform their model of neural dynamics. If I understand correctly, their functional connectivity matrices represent correlations in neural activity across an entire fMRI scan computed for each individual and then averaged across individuals. This approach seems limited in its ability to capture neural dynamics across time. Modeling time series data or using a sliding window FC approach to capture changes across time might make more sense as a means of informing neural dynamics.</p>
<p>The authors evaluated their model using three different structural connectomes: one inferred from diffusion spectrum imaging in humans, one inferred from anterograde tract tracing in mice, and one inferred from retrograde tract-tracing in macaque. While the human connectome is presumably an undirected network, the mouse and macaque connectomes are directed. What bearing does experimentally inferred knowledge of directionality have on the derivation of optimal influence and its interpretation?</p>
<p>It would be useful if the authors could assess the performance of the model for other datasets. Does the model reflect changes during task engagement or in disease states in which relative nodal influence would be expected to change? The model assumes optimality, but this assumption might be violated in disease states.</p>
<p>The MSA approach is highly computationally intensive, which the authors touch on in the Discussion section. Would it be feasible to extend this approach to task or disease conditions, which might necessitate modeling multiple states or time points, or could adaptations be made that would make this possible?</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.101780.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The authors provide a compelling method for characterizing communication within brain networks. The study engages important, biologically pertinent, concerns related to the balance of dynamics and structure in assessing the focal points of brain communication. The methods are clear and seem broadly applicable, however further clarity on this front is required.</p>
<p>Strengths:</p>
<p>The study is well-developed, providing an overall clear exposition of relevant methods, as well as in-depth validation of the key network structural and dynamical assumptions. The questions and concerns raised in reading the text were always answered in time, with straightforward figures and supplemental materials.</p>
<p>Weaknesses:</p>
<p>The narrative structure of the work at times conflicts with the interpretability. Specifically, in the current draft, the model details are discussed and validated in succession, leading to confusion. Introducing a &quot;base model&quot; and &quot;core datasets&quot; needed for this type of analysis would greatly benefit the interpretability of the manuscript, as well as its impact.</p>
</body>
</sub-article>
</article>