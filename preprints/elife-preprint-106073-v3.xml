<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">106073</article-id>
<article-id pub-id-type="doi">10.7554/eLife.106073</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.106073.3</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.5</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Disinformation elicits learning biases</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Vidal-Perez</surname>
<given-names>Juan</given-names>
</name>
<xref ref-type="aff" rid="A1">1</xref>
<xref ref-type="aff" rid="A2">2</xref>
<email xlink:href="mailto:juanvidalpe@gmail.com">juanvidalpe@gmail.com</email>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Dolan</surname>
<given-names>Raymond J</given-names>
</name>
<xref ref-type="aff" rid="A1">1</xref>
<xref ref-type="aff" rid="A2">2</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Moran</surname>
<given-names>Rani</given-names>
</name>
<xref ref-type="aff" rid="A1">1</xref>
<xref ref-type="aff" rid="A3">3</xref>
<email xlink:href="mailto:rani.moran@gmail.com">rani.moran@gmail.com</email>
</contrib>
<aff id="A1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>Max Planck Centre for Computational Psychiatry and Ageing, University College London</institution></institution-wrap>, <city>London</city>, <country country="GB">United Kingdom</country></aff>
<aff id="A2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02704qw51</institution-id><institution>Wellcome Centre for Human Neuroimaging, University College London</institution></institution-wrap>, <city>London</city>, <country country="GB">United Kingdom</country></aff>
<aff id="A3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/026zzn846</institution-id><institution>Department of Psychology, School of Biological and Behavioural Sciences, Queen Mary University of London</institution></institution-wrap>, <city>London</city>, <country country="GB">United Kingdom</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Diaconescu</surname>
<given-names>Andreea Oliviana</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/03dbr7087</institution-id><institution>University of Toronto</institution>
</institution-wrap>
<city>Toronto</city>
<country>Canada</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-8451-0523</contrib-id><role>Senior Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="FN1" fn-type="coi-statement"><p>The authors declare that they have no competing interests.</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-05-12">
<day>12</day>
<month>05</month>
<year>2025</year>
</pub-date>
<pub-date date-type="update" iso-8601-date="2025-11-06">
<day>06</day>
<month>11</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP106073</elocation-id>
<history><date date-type="sent-for-review" iso-8601-date="2025-01-28">
<day>28</day>
<month>01</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-01-17">
<day>17</day>
<month>01</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.31219/osf.io/st4kg"/>
</event>
<event>
<event-desc>Reviewed preprint v1</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2025-05-12">
<day>12</day>
<month>05</month>
<year>2025</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.106073.1"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.106073.1.sa3">eLife Assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.106073.1.sa2">Reviewer #1 (Public review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.106073.1.sa1">Reviewer #2 (Public review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.106073.1.sa0">Reviewer #3 (Public review):</self-uri>
</event>
<event>
<event-desc>Reviewed preprint v2</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2025-09-04">
<day>04</day>
<month>09</month>
<year>2025</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.106073.2"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.106073.2.sa0">eLife Assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.106073.2.sa1">Reviewer #1 (Public review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.106073.2.sa2">Reviewer #2 (Public review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.106073.2.sa3">Reviewer #3 (Public review):</self-uri>
<self-uri content-type="author-comment" xlink:href="https://doi.org/10.7554/eLife.106073.2.sa4">Author response:</self-uri>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Vidal-Perez et al</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Vidal-Perez et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-106073-v3.pdf"/>
<self-uri xlink:href="st4kg.pdf" content-type="docx" xlink:role="full-text"/>
<abstract>
<p>In open societies disinformation is often considered a threat to the very fabric of democracy. However, we know little about how disinformation exerts its impact, especially its influences on individual learning processes. Guided by the notion that disinformation exerts its pernicious effects by capitalizing on learning biases, we ask which aspects of learning from potential disinformation align with ideal “Bayesian” principles, and which exhibit biases deviating from these standards. To this end, we harnessed a reinforcement learning framework, offering computationally tractable models capable of estimating latent aspects of a learning process as well as identifying biases in learning. In two experiments, participants completed a two-armed bandit task, where they repeatedly chose between two lotteries and received outcome-feedback from sources of varying credibility, who occasionally disseminated disinformation by lying about true choice outcome (e.g., reporting non reward when a reward was truly earned or vice versa). Computational modelling indicated that learning increased in tandem with source credibility, consistent with ideal Bayesian principles. However, we also observed striking biases reflecting divergence from idealized Bayesian learning patterns. Notably, in one experiment individuals learned from sources that should have been ignored, as these were known to be fully unreliable. Additionally, the presence of disinformation elicited exaggerated learning from trustworthy information (akin to jumping to conclusions) and exacerbated a normalized measure of “positivity bias” whereby individuals self-servingly boost their learning from positive, relative to negative, choice-feedback. Thus, in the face of disinformation we identify specific cognitive mechanisms underlying learning biases, with potential implications for societal strategies aimed at mitigating its harmful impacts.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="s1" sec-type="intro">
<title>Introduction</title>
<p>Disinformation is a pervasive and pernicious feature of the modern world (<xref ref-type="bibr" rid="c1">1</xref>). It is linked to negative social impacts that include public-health risks (<xref ref-type="bibr" rid="c2">2</xref>–<xref ref-type="bibr" rid="c4">4</xref>), political radicalization (<xref ref-type="bibr" rid="c5">5</xref>,<xref ref-type="bibr" rid="c6">6</xref>), violence (6—8) and adherence to conspiracy theories (<xref ref-type="bibr" rid="c8">8</xref>,<xref ref-type="bibr" rid="c9">9</xref>). Consequently, there is a growing interest in comprehending how false information propagates across social networks (<xref ref-type="bibr" rid="c10">10</xref>–<xref ref-type="bibr" rid="c12">12</xref>), including an interest in designing strategies to curb its impact (<xref ref-type="bibr" rid="c13">13</xref>–<xref ref-type="bibr" rid="c16">16</xref>) albeit with limited success to date (<xref ref-type="bibr" rid="c17">17</xref>). However, there is also a considerable knowledge lacuna regarding how individuals learn and update their beliefs when exposed to potential disinformation. Addressing this gap is crucial, as it has been suggested that disinformation propagates by exploiting cognitive biases (<xref ref-type="bibr" rid="c18">18</xref>–<xref ref-type="bibr" rid="c22">22</xref>). Thus, uncovering whether and how potential disinformation elicits distinct learning <italic>biases</italic> has the potential to better enable targeted interventions aimed at countering its harmful effects.</p>
<p>We start with an assessment of a prediction that individuals should modulate their learning as a function of the credibility of an information source, and learn more from credible, truthful, information-sources. This prediction is based on Bayesian principles of learning and on previous findings showing that individuals flexibly and adaptively adjust their learning rates in response to key statistical features of the environment. For example, learning is more rapid when observationuncertainty (“noise”) decreases and in volatile, changing, compared to stable environments, particularly following detection of change-points that render re-change knowledge obsolete (<xref ref-type="bibr" rid="c23">23</xref>–<xref ref-type="bibr" rid="c25">25</xref>). Moreover, human choice is strongly influenced by social information of high (as opposed to low) credibility, such as majority opinions more confident judgments (<xref ref-type="bibr" rid="c26">26</xref>) and large group consensus (<xref ref-type="bibr" rid="c27">27</xref>). Additionally, people are disposed to follow trustworthy advisors (<xref ref-type="bibr" rid="c28">28</xref>), including those who have recommended optimal actions in the past (<xref ref-type="bibr" rid="c29">29</xref>,<xref ref-type="bibr" rid="c30">30</xref>).</p>
<p>We hypothesised that in a disinformation context individuals would show significant deviations from idealized Bayesian learning, reflecting a diversity of biases. First, filtering non-credible information is likely to be cognitively demanding (<xref ref-type="bibr" rid="c31">31</xref>), and this predicts such information would impact belief updating, even if individuals are aware it is untrustworthy. An additional consideration is that humans tend to learn more from positive self-confirming information (<xref ref-type="bibr" rid="c32">32</xref>–<xref ref-type="bibr" rid="c34">34</xref>), which presents one in a positive light. We conjectured, influenced by ideas from motivated-cognition (<xref ref-type="bibr" rid="c35">35</xref>), that low-credibility information provides a pathway for amplification of such a bias, as uncertainty regarding informationveracity might dispose individuals to self-servingly interpret positive information as true and explain-away negative information as false. A final additional consideration is the question of how exposure to potential disinformation impacts on learning from trusted sources. One possibility is that disinformation serves as a background context against which credible information would appear more salient. Alternatively, it might lead individuals to strategically reduce their overall learning in disinformation-rich environments, resulting in diminished learning from credible sources.</p>
<p>To address these questions, we adopt a novel approach within the disinformation literature by exploiting a Reinforcement Learning (RL) <italic>experimental</italic> framework (<xref ref-type="bibr" rid="c36">36</xref>). While RL has guided disinformation research in recent years (<xref ref-type="bibr" rid="c37">37</xref>–<xref ref-type="bibr" rid="c41">41</xref>), our approach is novel in using one of its most popular tasks: the “bandit task”. This has the advantage that it provides computationally tractable models, that enable estimation of latent aspects of learning processes, such as belief updating. Moreover, our approach also enables an examination of the dynamics of belief updates over short timescales reflecting real-life engagements with disinformation, such as deciding whether to share a post on social media. Moreover, bandit tasks in RL have proven success in characterizing key decision-making biases (e.g., positivity bias (<xref ref-type="bibr" rid="c42">42</xref>–<xref ref-type="bibr" rid="c44">44</xref>)), albeit in scenarios where learners receive accurate information. . Finally, a previous literature has suggested a role for reinforcement in the dissemination of disinformation, where individuals may receive positive reinforcement (likes, shares) for spreading sensationalized or misleading information on social media platforms, inadvertently reinforcing such behaviours and contributing to a disinformation proliferation (<xref ref-type="bibr" rid="c15">15</xref>,<xref ref-type="bibr" rid="c40">40</xref>,<xref ref-type="bibr" rid="c45">45</xref>).</p>
<p>We developed a novel “disinformation” version of the classical two-armed bandit task to test the effects of potential disinformation on learning. In the <italic>traditional</italic> two-armed bandit task (<xref ref-type="bibr" rid="c36">36</xref>,<xref ref-type="bibr" rid="c42">42</xref>,<xref ref-type="bibr" rid="c46">46</xref>), participants choose repeatedly between two unfamiliar bandits (i.e., slot machines), that provided rewards with different probabilities, to learn which bandit is more rewarding. Critically, in our <italic>disinformation</italic>-variant, true choice outcomes (reward or non-reward) were <italic>latent</italic>, i.e., unobservable. Instead, participants were informed about choice-outcomes by computer-programmed “feedback agents”, who were disposed to occasionally disseminate disinformation by lying (reporting a reward when the true outcome was non-reward or vice versa). As these feedback-agents varied in truthfulness, this allowed us to test the effects of source-credibility on learning. We show across two studies that the extent of belief-updates increases as a function of source-credibility. However, there were striking deviations from ideal-Bayesian learning, where we identify several sources of bias related to processing potential disinformation. In one experiment, individuals learned from noncredible information that should in principle be ignored. Additionally, in both experiments, participants exhibited increased learning from trustworthy information when it was preceded by noncredible information and an amplified normalized positivity bias for non-credible sources, where individuals preferentially learn from positive compared to negative feedback (relative to the overall extent of learning).</p>
</sec>
<sec id="s2" sec-type="results">
<title>Results</title>
<sec id="s2-1">
<title>Disinformation two-armed bandit task</title>
<p>We conducted a discovery (n=104) and main study (n=204). In both studies the learning tasks had the same basic structure but with a few subtle differences between them (see Discovery study and SI Discovery study methods). To anticipate, the results of both studies support mostly similar conclusions, and, in the results section, we focus on the main study, with the final results section detailing similarities and differences in findings across the two studies.</p>
<p>In the main study, participants (n=204) completed the <italic>disinformation</italic> two-armed bandit task. In the <italic>traditional</italic> two-armed bandit task (<xref ref-type="bibr" rid="c36">36</xref>,<xref ref-type="bibr" rid="c42">42</xref>,<xref ref-type="bibr" rid="c46">46</xref>), participants choose between two slot-machines (i.e., bandits) differing in their reward probability. Participants are not instructed about bandit rewardprobabilities but instead they are provided with veridical choice feedback (e.g., reward or nonreward), allowing participants to learn which bandit is more rewarding. By contrast, in our disinformation version <italic>true</italic> choice-outcomes were latent (i.e., unobserved) and participants were informed about these outcomes via three computerized feedback-agents, who had privileged access to the true outcomes.</p>
<p>Before commencing the task, participants were instructed that feedback agents could disseminate disinformation, meaning that they were disposed to lie on a random minority of trials, reporting a reward when the true outcome was a non-reward, or vice versa (<xref ref-type="fig" rid="fig1">Fig. 1a</xref>). Participants were explicitly instructed about the credibility of each agent (i.e., based on the proportion of truth-telling trials), indicated by a “star system”: the 3-star agent was always truthful, the 2-star agents told the truth on 75% of the trials while the 1-star agent did so on 50% of the trials (<xref ref-type="fig" rid="fig1">Fig. 1b</xref>). Note that while the 1-star agent’s feedback was statistically equivalent to random feedback, participants were not explicitly instructed about this equivalence. Each experimental block encompassed 3 bandit pairs, each presented over 15 trials in a randomly interleaved manner. The agent on each trial was random subject to the constraint that each agent provided feedback for 5 trials for each bandit pair. Thus, in every trial, participants were presented with one of the bandit pairs and the feedback agent associated with that trial. Upon selecting a bandit, they then received feedback from the agent (<xref ref-type="fig" rid="fig1">Fig. 1c</xref>). Importantly, at the end of the experiment participants received a performance-based bonus based on <italic>true</italic> bandit outcomes, which could differ from agent-provided feedback. Within each bandit-pair one bandit provided a (true) reward on 75% of the trials and the other on 25% of trials. Choice accuracy, i.e., the probability of selecting the more rewarding bandit (within each pair), was significantly above chance (mean accuracy = 0.62, t(203) = 19.94, p &lt;.001) and improved as a function of increasing experience with each bandit-pair (average overall improvement over 15 trials = 0.22, t(203)=19.95, p&lt;0.001) (<xref ref-type="fig" rid="fig1">Fig. 1d</xref>).</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Task design and performance.</title>
<p><bold>a</bold>, Illustration of agent-feedback. Each selected bandit generated a <italic>true</italic> outcome, either a reward or a non-reward. Participants <italic>did not</italic> see this true outcome but instead were informed about it via a computerised feedback agent (reward: dollar sign; non-reward: sad emoji). Agents told the truth on most trials (left panel). However, on a random minority of trials they lied, reporting a reward when the true outcome was a non-reward or vice versa (right panel). <bold>b</bold>, Participants received feedback from 3 distinct feedback agents of variable credibility (i.e., truth-telling probability). Credibility was represented using a star based system: a 3-star agent always reported the truth (and never lied), a 2-star agent reported the truth on 75% of trials (lying on the remaining 25%), and a 1-star agent reported the truth half of the time (lying on the other half). Participants were explicitly instructed and quizzed about the credibility of each agent prior to the task. <bold>c</bold>, Trial-structure: On each trial participants were first presented with the feedback agent for that trial (here, the 2-star agent) and next offered a choice between a pair of bandits (represented by identicons) (for 2sec). Next, choice-feedback was provided by the agent. <bold>d</bold>, Learning curves. Average choice accuracy as a function of trial number (within a bandit-pair). Thin lines: individual participants; thick line: group mean with thickness representing the group standard error of the mean for each trial.</p></caption>
<graphic xlink:href="st4kgv5_fig1.tif" mime-subtype="tif" mimetype="image"/>
</fig>
</sec>
<sec id="s2-2">
<title>Credible feedback promotes greater learning</title>
<p>A hallmark of RL value-learning is that participants are more likely to repeat a choice following positive compared to negative reward-feedback (henceforth, “feedback effect on choice repetition”). We tested a hypothesis, based on Bayesian reasoning, that this tendency would increase as a function of agent-credibility (<xref ref-type="fig" rid="fig3">Fig. 3a</xref>). Thus, in a binomial mixed-effects model we regressed choice-repetition (i.e., whether participants repeated their choice from the most recent trial featuring the same bandit pair; 0-switch; 1-repeat) on feedback-valence (negative or positive) and agent-credibility (1,2, or 3-star), where these are taken from the last trial featuring the same bandit pair (Methods for modelspecification). Feedback valence exerted a positive effect on choice-repetition (b=0.72, F(1,2436)=1369.6, p&lt;0.001) and interacted with agent-credibility (F(2,2436)=307.11, p&lt;0.001), with a feedback effect being greater for more credible agents (3-star vs. 2-star: b= 0.91, F(1,2436)=351.17; 3-star vs. 1-star: b=1.15, t(2436)=24.02; and 2-star vs. 1-star: b=0.24, t(2436)=5.34, all p’s&lt;0.001). Additionally, we found a positive effect of feedback for the 3-star agent (b=1.41, F(1,2436)=1470.2, p&lt;0.001), and a smaller effect of feedback for the 2-star agent (b=0.49 ,F(1,2436)=230.0, p&lt;0.001). These results support our hypothesis that learning increases as a function of information credibility (note that the feedback effect for the 1-star agent is examined below; see “Non-credible feedback elicits learning”).</p>
<p>To confirm that increased learning based on information credibility is expected under an assumption that subjects adhere to Bayesian reasoning, we formulated two Bayesian models whereby the latent value of each bandit is represented as a distribution over the probability that a bandit is truly rewarding (<xref ref-type="fig" rid="fig2">Fig. 2a</xref>, top panel; <xref ref-type="fig" rid="figS5">Fig. S5c</xref> for an illustration of the model; for full model descriptions, see Methods). In the <italic>instructed-credibility Bayesian</italic> model, belief-updates are based on the <italic>instructed</italic> credibility of feedback-sources. This model is based on an idealized assumptions that during the feedback stage of each trial, the value of the chosen bandit is updated (based on feedback valence and credibility) according to Bayes rule reflecting perfect adherence to the instructed task structure (i.e., how true outcomes and feedback are generated). In contrast, a <italic>free-credibility Bayesian</italic> model, allows for the possibility that Bayes-rule updates during feedback are based on “distorted probabilities” (<xref ref-type="bibr" rid="c47">47</xref>), attributing <italic>non-instructed</italic> degrees of credibility to sources of false information (despite our explicit instructions on the credibility of different agents). In this variant, we fixed the credibility of the 3-star agent to 1 and estimated the credibility of 2 and 1-star agents as free parameters (which were highly recoverable; see Methods and <xref ref-type="section" rid="s6-3-3">SI 3.3</xref>). Both models additionally assumed uninformative, uniform, priors over reward probabilities of novel bandits and that learning is non-forgetful. Simulations based on both Bayesian models (see Methods) predicted increased learning as a function of feedback credibility (<xref ref-type="fig" rid="fig3">Fig. 3b</xref>; <bold>top panels</bold>; <xref ref-type="section" rid="s6-3-1-1-1">SI 3.1.1.1</xref> <xref ref-type="table" rid="tblS3">Tables S3</xref> and <xref ref-type="table" rid="tblS4">S4</xref> for statistical analysis).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Computational models and cross-fitting method.</title>
<p><bold>a</bold>, Summary of the two model families. In our Bayesian models (top panel), the observer maintains a belief-distribution over the probability a bandit is <italic>truly</italic> rewarding (denoted <italic>r</italic>). On each trial, this distribution is updated for the selected bandit according to Bayes rule, based on the valence (i.e., rewarding/non-rewarding; denoted <italic>f</italic>) and credibility of the trial’s reward feedback (denoted <italic>c</italic>). In credit-assignment models (bottom panel), the observer maintains a subjective point-value (denoted <italic>Q</italic>) reflecting a choice propensity for each bandit. On each trial the propensity of the chosen bandit is updated based on a free CA parameter, quantifying the extent of value increase/decrease following positive/negative feedback. CA parameters can be modulated by the valence and credibility of feedback. <bold>b,c</bold>, Model selection between the credibility-CA model (without perseveration) and the two variants of Bayesian models. Most participants were best fitted by a credibility-CA model, compared to the instructed-credibility Bayesian model (b) or free-credibility Bayesian (c) models. <bold>d</bold>, Cross-fitting method: Firstly, we fit a Bayesian model to empirical data, to estimate its (ML) parameters. This yields the Bayesian learning token that comes closest to accounting for a participant’s choices. Secondly, we simulate synthetic data based on the Bayesian model, using its ML parameters to obtain instances of how a Bayesian learner would behave in our task. Thirdly, we fit these synthetic data with a CA model, thus estimating “Bayesian CA parameters”, i.e., CA parameters capturing the performance of a Bayesian model. Finally, we fit the CA model directly to empirical data to obtain “empirical CA parameters”. A comparison of Bayesian and empirical CA parameters, allows us to identify, which aspects of behaviour are consistent with our Bayesian models, as well as characterize biases in behaviour that deviate from <bold>our</bold> Bayesian learning models.</p></caption>
<graphic xlink:href="st4kgv5_fig2.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3:</label>
<caption><title>Learning adaptations to credibility.</title>
<p><bold>a</bold>, Probability of repeating a choice as a function of feedbackvalence and agent-credibility on the previous trial for the same bandit pair. The effect of feedback-valence on repetition increases as the feedback credibility increases, indicating that more credible feedback has a greater effect on behaviour. <bold>b</bold>, Similar analysis as in panel a, but for synthetic data obtained by simulating the main models. Simulations were computed using the ML parameters of participants for each model. The null model (<bold>bottom left</bold>) attributes a single CA to all credibility-levels, hence feedback exerts a constant effect on repetition (independently of its credibility). The credibility-CA model (<bold>bottom-right</bold>) allowed credit assignment to change as a function of source credibility, predicting varying effects of feedback with different credibility levels. The instructed-credibility Bayesian model (<bold>top left</bold>) updated beliefs based on the true credibility of the feedback, and therefore predicted an increase effect of feedback on repetition as credibility increased. Finally, the free-credibility Bayesian model (<bold>top right</bold>) allowed for a possibility that participants use distorted credibilities for 1- star and 2-star agents when following a Bayesian strategy, also predicting an increase in the effect of feedback as credibility increased. <bold>c</bold>, ML credit assignment parameters for the credibility-CA model. Participants show a CA increase as a function of agent-credibility, as predicted by Bayesian-CA parameters for both the instructed-credibility and free-credibility Bayesian models. Moreover, participants showed a positive CA for the 1-star agent (which essentially provides random feedback), which is only predicted by cross-fitting parameters for the free-credibility Bayesian model. <bold>d</bold>, ML credibility parameters for a free-credibility Bayesian model attributing credibility 1 to the 3-star agent but estimating credibility for the two lying agents as free parameters. Small dots represent results for individual participants/simulations, big circles represent the group mean (a,b,d) or median (c) of participants’ behaviour. Results of the synthetic model simulations are represented by diamonds (instructed-credibility Bayesian model), squares (free-credibility Bayesian model), upward-pointing triangles (null-CA model) and downward-pointing triangles (credibility-CA model). Error bars show the standard error of the mean. (*) p&lt;.05, (**) p&lt;0.01, (***) p&lt;.001.</p></caption>
<graphic xlink:href="st4kgv5_fig3.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<p>Next, we formulated a family of <italic>non-Bayesian</italic> computational RL models. Importantly, these models can flexibly express non-Bayesian learning patterns and, as we show in following sections, can serve to identify learning biases deviating from an idealized Bayesian strategy. Here, an assumption is that during feedback, the choice propensity for the chosen bandit (which here is represented by a point estimate, “Q value“, rather than a distribution) either increases or decreases (for positive or negative feedback, respectively) according to a magnitude quantified by the free “Credit-Assignment (CA)” model parameters (<xref ref-type="bibr" rid="c48">48</xref>):
<disp-formula id="FD1">
<alternatives>
<mml:math id="M1" display="block"><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>←</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>Q</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:mi>A</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mi>F</mml:mi></mml:math>
<graphic xlink:href="st4kgv5_eqn1.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
</disp-formula>
</p>
<p>where <italic>F</italic> is the feedback received from the agents (coded as 1 for reward feedback and −1 for nonreward feedback), while <italic>f<sub>Q</sub></italic> (∈[0,1]) is the free parameter representing the forgetting rate of the Q-value (<xref ref-type="fig" rid="fig2">Fig. 2a</xref>, <bold>bottom panel</bold>; <xref ref-type="fig" rid="figS5">Fig. S5b</xref>; see “Methods: RL models”). The probability to choose a bandit (say A over B) in this family of models is a logistic function of the contrast choice-propensities between these two bandits. One interpretation of this model is as a logistic regression, where the CA parameters take the role of regression coefficients corresponding to the change in log odds of repeating the just-taken action in future trials based on the feedback (+/− CA for positive or negative feedback, respectively; the model also includes gradual perseveration which allows for constant logodd changes that are not affected by choice feedback). The forgetting rate captures the extent to which the effect of each trial on future choices diminishes with time. The Q-values are thus exponentially decaying sums of logistic choice propensities based on the types of feedback a bandit received.</p>
<p>Within this model-family, different model variants varied as to how task-variables influenced CA parameters with the “null” model attributing the same CA to all feedback-agents (regardless of their credibility, i.e., a single free CA-parameter), whereas the “credibility-CA” model availed of three separate CA parameters, one for each feedback agent, thereby allowing us to test how learning was modulated by feedback-credibility. Using a bootstrap generalized-likelihood ratio test for modelcomparison (Methods) we rejected the null model (group level: p&lt;0.001), in favour of the credibility-CA model. Furthermore, model-simulations based on participants best-fitting parameters (Methods) falsified the null model as it failed to predict credibility-modulated learning, showing instead, equal learning from all feedback sources (<xref ref-type="fig" rid="fig3">Fig, 3b</xref>; <bold>bottom-left panel</bold>). In contrast, the credibility-CA model successfully predicted increased learning as a function of credibility (<xref ref-type="fig" rid="fig3">Fig. 3b</xref>, <bold>bottom-right panel</bold>) (see <xref ref-type="section" rid="s6-3-1-1-1">SI 3.1.1.1</xref> Tables <xref ref-type="table" rid="tblS5">S5</xref> and <xref ref-type="table" rid="tblS6">S6</xref>).</p>
<p>After confirming CA parameters are highly recoverable (see Methods and <xref ref-type="section" rid="s6-3-4">SI 3.4</xref>), we examined how the Maximum Likelihood (ML) CA parameters from the credibility-CA model differed as a function of feedback credibility (<xref ref-type="fig" rid="fig3">Fig. 3c</xref>; see <xref ref-type="section" rid="s6-3-3-1">SI 3.3.1</xref> for detailed ML parameter results). Using a mixed effects model (Methods), we regressed the CA parameters on their associated agents, finding that CA differed across the agents (F(2,609)=212.65, p&lt;0.001), increasing as a function of agent-credibility (3-star vs. 2-star: b= 1.02, F(1,609)=253.73 ; 3-star vs. 1-star: b=1.24, t(609)=19.31; and 2-star vs. 1-star: b=0.22, t(609)=3.38, all p’s&lt;0.001).</p>
</sec>
<sec id="s2-3">
<title>Substantial deviations from our Bayesian learning models</title>
<p>We next implemented a model comparison between each of our Bayesian models and the credibility-CA model, using a parametric bootstrap cross-fitting method (Methods). We found that the credibility-CA model provided a superior fit for 71% of participants (sign test; p&lt;0.001) when compared to the instructed-credibility Bayesian model, <xref ref-type="fig" rid="fig2">Fig. 2b</xref>; and for 53.9% (p=0.29) when compared to the free-credibility Bayesian model, <xref ref-type="fig" rid="fig2">Fig 2c</xref>). We considered using AIC and BIC, which apply “off-the shelf” penalties for model-complexity. However, these methods do not adapt to features like finite sample size (relying instead on asymptotic assumption) or temporal dependence (as is common in reinforcement learning experiments). In contrast, the parametric bootstrap cross-fitting method replaces these fixed penalties with empirical, data-driven criteria for model-selection. Indeed, modelrecovery simulations confirmed that whereas AIC and BIC were heavily biased in favour of the Bayesian models, the bootstrap method provided excellent model-recovery (See <xref ref-type="fig" rid="figS20">Fig. S20</xref>).</p>
<p>To further characterise deviations between behaviour and our Bayesian learning models, we used a “cross-fitting” method. Treating CA parameters as data-features of interest (i.e., feedback dependent changes in choice propensity), our goal was to examine if and how empirical features differ from features extracted from simulations of our Bayesian learning models. Towards that goal, we simulated synthetic data based on <italic>Bayesian</italic> agents (using participants’ best fitting parameters), but fitted these data using the CA-models, obtaining what we term “Bayesian-CA parameters” (<xref ref-type="fig" rid="fig2">Fig. 2d</xref>; Methods). A comparison of these Bayesian-CA parameters, with empirical-CA parameters obtained by fitting CA models to empirical data, allowed us to uncover patterns consistent with, or deviating from, ideal-Bayesian value-based inference. Under the logistic-regression interpretation of the CA-model family the cross-fitting method comprises a comparison between empirical regression coefficients (i.e., empirical CA parameters) and regression coefficient based on simulations of Bayesian models (Bayesian CA parameters). Using this approach, we found that both the instructed-credibility and free-credibility Bayesian models predicted increased Bayesian-CA parameters as a function of agent credibility (<xref ref-type="fig" rid="fig3">Fig. 3c</xref>; see <xref ref-type="section" rid="s6-3-1-1-2">SI 3.1.1.2</xref> Tables <xref ref-type="table" rid="tblS8">S8</xref> and <xref ref-type="table" rid="tblS9">S9</xref>). However, an in-depth comparison between Bayesian and empirical CA parameters revealed discrepancies from ideal Bayesian learning, which we describe in the following sections.</p>
</sec>
<sec id="s2-4">
<title>Non-credible feedback elicits learning</title>
<p>While our task instructions framed the 1-star agent as highly deceptive, lying 50% of the time, its feedback is statistically equivalent to entirely non-informative i.e., <italic>random</italic> feedback. Thus, participants should ignore and filter-out such feedback from their belief updates. Indeed, for the 1- star agent, simulations based on the instructed-credibility Bayesian model provided no evidence for either a positive effect of feedback on choice-repetition (mixed effects model described above; b=− 0.01, t(2436)=−0.41, p=0.68; <xref ref-type="fig" rid="fig3">Fig 3b</xref> <bold>top-left</bold>) or a positive Bayesian-CA (b=−0.01, t(609)=−0.31, p=0.76; <xref ref-type="fig" rid="fig3">Fig. 3c</xref>). However, contrary to this, we hypothesized that participants would struggle to entirely disregard non-credible feedback. Indeed, we found a positive effect of feedback on choice-repetition for the 1-star agent (mixed effects model, delta(M)=0.049, b=0.25, t(2436)=8.05, p&lt;0.001), indicating participants are more likely to repeat a bandit selection after receiving positive feedback from this agent (<xref ref-type="fig" rid="fig3">Fig. 3a</xref>). Similarly, the CA parameter for the 1-star agent in the credibility-CA model was positive (b=0.23, t(609)=4.54, p&lt;0.001) (<xref ref-type="fig" rid="fig3">Fig. 3c</xref>). The upshot of this empirical finding is that participants updated their beliefs based on random feedback (<bold>see</bold> <xref ref-type="fig" rid="figS7">Fig. S7</xref> for analysis showing that this resulted in decreased accuracy rates).</p>
<p>A potential explanation for this finding is that participants <italic>do</italic> rely on a Bayesian strategy but “distort probabilities”, attributing non-instructed degrees of credibility to lying sources (despite our explicit instructions on the credibility of different agents). Consistent with this, the ML-estimated credibility of the 1-star agent (<xref ref-type="fig" rid="fig3">Fig. 3d</xref>) was significantly greater than 0.5 (Wilcoxon signed-rank test, median=0.08, z=5.50, p&lt;0.001), allowing the free-credibility Bayesian model to predict a positive feedback effect on choice-repetition (mixed-effects model: b=0.12, t(2436)=9.48, p&lt;0.001; <xref ref-type="fig" rid="fig3">Fig 3b</xref> <bold>topright</bold>) and a positive Bayesian-CA (b=0.08, t(609)=3.32, p&lt;0.001; <xref ref-type="fig" rid="fig3">Fig. 3c</xref>) for the 1-star agent. In our Discussion we elaborate on why it might be difficult to filter out this feedback even if one can explicitly infer its randomness.</p>
</sec>
<sec id="s2-5">
<title>Increased learning from fully credible feedback when it follows non-informative feedback</title>
<p>A comparison of empirical and Bayesian credit-assignment parameters revealed a further deviation from ideal Bayesian learning: participants showed an exaggerated credit-assignment for the 3-star agent compared with Bayesian models [Wilcoxon signed-rank test, instructed-credibility Bayesian model (median difference=0.74, z=11.14); free-credibility Bayesian model (median difference=0.62, z=10.71), all p’s&lt;0.001] (<xref ref-type="fig" rid="fig3">Fig. 3a</xref>). One explanation for enhanced learning for the 3-star agents is a contrast effect, whereby credible information looms larger against a backdrop of non-credible information. To test this hypothesis, we examined whether the impact of feedback from the 3-star agent is modulated by the credibility of the agent in the trial immediately preceding it. More specifically, we reasoned that the impact of a 3-star agent would be amplified by a “low credibility context” (i.e., when it is preceded by a low credibility trial). In a binomial mixed effects model, we regressed choice-repetition on feedback valence from the last trial featuring the same bandit pair (i.e., the learning trial) and the feedback agent on the trial immediately preceding that last trial (i.e., the contextual credibility; see Methods for model-specification). This analysis included only learning trials featuring the 3-star agent, and context trials featuring the same bandit pair as the learning trial (<xref ref-type="fig" rid="fig4">Fig. 4a</xref>). We found that feedback valence interacted with contextual credibility (F(2,2086)=11.47, p&lt;0.001) such that the feedback-effect (from the 3-star agent) decreased as a function of the preceding context-credibility (3-star context vs. 2-star context: b= −0.29, F(1,2086)=4.06, p=0.044; 2-star context vs. 1-star context: b=−0.41, t(2086)=−2.94, p=0.003; and 3-star context vs. 1-star context: b=−0.69, t(2086)=−4.74, p&lt;0.001) (<xref ref-type="fig" rid="fig4">Fig. 4b</xref>). This contrast effect was not predicted by simulations of our main models of interest (<xref ref-type="fig" rid="fig4">Fig. 4c</xref>). No effect was found when focussing on contextual trials featuring a bandit pair different than the one in the learning trial (see <xref ref-type="section" rid="s6-3-5">SI 3.5</xref>). Thus, these results support an interpretation that credible feedback exerts a greater impact on participants’ learning when it follows non-credible feedback in the same learning context.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4:</label>
<caption><title>Contextual effects and learning.</title>
<p><bold>a</bold>, Trials contributing to the analysis of effects of credibility-context on learning from the fully credible agent. We included only “current trials (n)” for which: 1) the last trial (trial nk) offering the same bandit pair (i.e., the learning trial) was associated with the 3-star agent, and 2) the immediately preceding context trial (n-k-1) featured the same bandit pair. We examined how choice-repetition (from n-k to n) was modulated by feedback valence on the learning trial, and by the feedback agent on the context trial. Note the greyed-out star-rating on the current trial indicates the identity of the current agent and was not included in the analysis. <bold>b</bold>, Difference in probability of repeating a choice after receiving positive vs negative feedback (i.e., feedback effect) from the 3-star agent, as a function of the credibility context. The 3-star agent feedback-effect is greater when preceded by a lower-credibility context, compared to a higher credibility context. Big circles represent the group mean, and error bars show the standard error of the mean. (*) p&lt;.05, (**) p&lt;0.01. <bold>c</bold>, We ran the same mixed effects model (regressing choice repetition of learning-trial feedback valence and on contextual credibility) on simulated data (See Methods: Model-agnostic analysis of contextual credibility effects on choice-repetition). The panels show contrasts in feedback-effect (from the 3-star agent in the learning trial) on choice-repetition between contextual credibility agent-pairs. None of our models predicted the contrast effects observed in participants. Histograms represent the distribution of regression coefficients based on 101 group-level synthetic datasets, simulated based on each model. The label right to each histograms represents the proportion of simulated datasets that predict an equal or stronger effect than the one observed in participants.</p></caption>
<graphic xlink:href="st4kgv5_fig4.tif" mime-subtype="tif" mimetype="image"/>
</fig>
</sec>
<sec id="s2-6">
<title>Positivity bias in learning and credibility</title>
<p>Previous research has shown that reinforcement learning is characterized by a positivity bias, wherein subjects systematically learn more from positive than from negative feedback (<xref ref-type="bibr" rid="c42">42</xref>,<xref ref-type="bibr" rid="c44">44</xref>). One account is that this bias might result from motivated cognition influences on learning, whereby participants favour positive feedback that reflects well on their choices. We conjectured that feedback of ambiguous veracity (i.e., from the 1-star and 2-star agents) would promote this bias by allowing participants to explain-away negative feedback as a case of an agent-lying, while choosing to believe positive feedback. Following previous research, we quantified positivity bias in 2 ways: 1) as the <italic>absolute</italic> difference between credit-assignment based on positive or negative feedback, and 2) as the same difference but <italic>relative</italic> to the overall extent of learning. We note that the second, relative, definition, is more akin to “percentage change” measurements providing a control for the overall lower levels of credit-assignment for less credible agent. To investigate this bias across different levels of feedback credibility we formulated a more detailed variant of the CA model. To quantify the extent of a chosen-bandit’s value increase or decrease - following positive or negative feedback respectively - the “credibility-valence-CA” variant included separate CA parameters for positive (CA+) and negative (CA−) feedback for each feedback agent. In effect, this model variant enabled us to test whether different levels of feedback credibility elicited a positivity bias (i.e., CA+ &gt; CA−). Using a bootstrap generalized-likelihood ratio test for model comparison (Methods), we rejected, in favour of the valence-credibility-CA model, the null-CA model, the credibility-CA model and a “constant feedbackvalence bias” CA model, which attributed a common valence bias (CA+ minus CA−) to all agents (all group level: all p’s&lt;0.001). This test supported our choice of flexible CA parametrization as a factorial function of agent and feedback-valence.</p>
<p>After confirming the parameters of this model were highly recoverable (see Methods and <xref ref-type="section" rid="s6-3-4">SI 3.4</xref>), we used a mixed effects model to regress the ML parameters (<xref ref-type="fig" rid="fig5">Fig. 5a</xref>; see <xref ref-type="section" rid="s6-3-3-1">SI 3.3.1</xref> for detailed ML parameter results) on their associated agent-credibility and valence (see Methods). This revealed participants attributed a greater CA to positive feedback than to negative feedback (b=0.64, F(1,1218)=37.39, p&lt;0.001). Strikingly, for lying agents, participants selectively assigned credit based on positive feedback (1-star: b=0.61, F(1,1218)=22.81, p&lt;0.001; 2-star: b=0.85, F(1,1218)=43.5, p&lt;0.001), with no evidence for significant credit-assignment based on negative feedback (1-star: b=−0.03, F(1,1218)=0.07, p=0.79; 2-star: b=0.14, F(1,1218)=1.28, p=0.25). Only for the 3-star agent, creditassignment was positive for both positive (b=1.83, F(1,1218)=203.1, p&lt;0.001) and negative (b=1.25, F(1,1218)=95.7, p=&lt;0.001) feedback. We found no significant interaction effect between feedback valence and credibility on CA (F(2,1218)=0.12, p=0.88; <xref ref-type="fig" rid="fig5">Fig. 5a-b</xref>). Thus, there was no evidence for our hypothesis when positivity-bias was measured in absolute terms.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5:</label>
<caption><title>Positivity bias as a function of agent-credibility.</title>
<p><bold>a</bold>, ML parameters from the credibility-valence-CA model. CA+ and CA− are free parameters representing credit assignments for positive and negative feedback respectively (for each credibility level). Our data revealed a positivity bias (CA+ &gt; CA−) for all credibility levels. <bold>b</bold>, Absolute valence bias index (defined as CA<sup>+</sup>−CA<sup>−</sup>) based on the ML parameters from the credibility-valence CA model. Positive values indicate a positivity bias, while negative values represent a negativity bias. <bold>c</bold>, Relative valence bias index (defined as (CA<sup>+</sup>−CA<sup>−</sup>)/(|CA<sup>+</sup>|+|CA<sup>−</sup>|)) based on the ML parameters from the credibility-valence CA model. Positive values indicate a positivity bias, while negative values represent a negativity bias. Small dots represent fitted parameters for individual participants and big circles represent the group median (a,b) or mean (c) (both of participants’ behavior), while squares are the median or mean of the fitted parameters of the free-credibility Bayesian model simulations. Error bars show the standard error of the mean. (***) p&lt;.001 for ML fits of participants behavior.</p></caption>
<graphic xlink:href="st4kgv5_fig5.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<p>However, we found evidence for agent-based modulation of positivity bias when this bias was measured in relative terms. Here we calculated, for each participant and agent, a relative Valence Bias Index (rVBI) as the difference between the Credit Assignment for positive feedback (CA<sup>+</sup>) and negative feedback (CA<sup>−</sup>), relative to the overall magnitude of CA (i.e., |CA<sup>+</sup>| + |CA<sup>−</sup>|) (<xref ref-type="fig" rid="fig5">Fig. 5c</xref>). Using a mixed effects model, we regressed rVBIs on their associated credibility (see Methods), revealing a relative positivity bias for all credibility levels [overall rVBI (b=0.32, F(1,609)=68.16), 50% credibility (b=0.39, t(609)=8.00), 75% credibility (b=0.41, F(1,609)=73.48) and 100% credibility (b=0.17, F(1,609)=12.62), all p’s&lt;0.001]. Critically, the rVBI varied depending on the credibility of feedback (F(2,609)=14.83, p&lt;0.001), such that the rVBI for the 3-star agent was lower than that for both the 1-star (b=−0.22, t(609)=−4.41, p&lt;0.001) and 2-start agent (b=−0.24, F(1,609)=24.74, p&lt;0.001). Feedback with 50% and 75% credibility yielded similar rVBI values (b=0.028, t(609)=0.56,p=0.57). Finally, a positivity bias could not stem from a Bayesian strategy as both Bayesian models predicted a negativity bias (<xref ref-type="fig" rid="fig5">Fig. 5b-c</xref>; <xref ref-type="fig" rid="figS8">Fig. S8</xref>; and <xref ref-type="section" rid="s6-3-1-1-3">SI 3.1.1.3</xref> <xref ref-type="table" rid="tblS11">Table S11</xref>–<xref ref-type="table" rid="tblS12">S12</xref>, 3.2.1.1, and 3.2.1.2). Taken together, this provides equivocal support for our initial hypothesis, depending on the measurement scale used to assess the effect (absolute or relative).</p>
<p>Previous research has suggested that positivity bias may spuriously arise from pure choiceperseveration (i.e., a tendency to repeat previous choices regardless of outcome) (<xref ref-type="bibr" rid="c49">49</xref>,<xref ref-type="bibr" rid="c50">50</xref>). While our models included a perseveration-component, we acknowledge this control is not perfect (<xref ref-type="bibr" rid="c51">51</xref>). Therefore, in additional control analyses, we generated (using ex-post simulations based on best fitting parameters) synthetic datasets using models including choice-perseveration, but devoid of feedback-valence bias, and fitted these with our credibility-valence model (see <xref ref-type="section" rid="s6-3-6-1">SI 3.6.1</xref>). These analyses confirmed that a pure perseveration account can masquerade as an apparent positivity bias, and even predict the qualitative pattern of results related to credibility (i.e., a higher relative positivity bias for low-credibility feedback). Critically, however, this account consistently predicted a reduced magnitude of credibility-effect on relative positivity bias as compared to the one we observed in participants, suggesting at least some of the relative amplification of positivity bias goes above and beyond contributions from perseveration.</p>
</sec>
<sec id="s2-7">
<title>True feedback elicits greater learning</title>
<p>Our findings are consistent with participant modulation of the extent of credit-assignment based <italic>solely</italic> on cued task-variables, such as feedback-credibility and valence. However, we also considered another possibility: that participants might infer, on a <italic>trial-by-trial</italic> basis, whether the feedback they received was true or false and adjust their credit assignment based on this inference. For example, for a given feedback-agent, participants might boost the credit assigned to a chosen bandit as a function of the degree to which they believe feedback was true. Notably, Bayesian inference can support a trial-level calculation of a posterior probability that feedback is true based on its credibility, valence and a prior belief (based on experiences in previous trials) regarding the probability that the chosen bandit is truly rewarding (<xref ref-type="fig" rid="fig6">Fig. 6a</xref>). The beliefs can partly discriminate between truthful and false feedback. These beliefs can partially discriminate between truthful and false feedback. As proof of this, we calculated a Bayesian posterior feedback-truthfulness belief for each participant and trial featuring the 1- or 2-star agents, (Methods; Recall for the 3-star agent, feedback is always true). On testing whether these posterior-truthfulness beliefs vary as a function of objective feedback truthfulness (true vs. lie), we found beliefs are stronger for truthful trials than for untruthful trials for both agents (1-star agent: mean difference=0.10, t(203)=39.47, p&lt;0.001; 2-star agent: mean difference=0.08 , t(203)=34.43, p&lt;0.001) (<xref ref-type="fig" rid="fig6">Fig. 6b</xref> and <xref ref-type="fig" rid="figS9">Fig. S9a</xref>). Note that this calculation was feasible because, as experimenters, we had privileged access to the objective truth of the choice-feedback as, when designing the experimental sessions, we generated latent true choice outcomes which could be compared to agent-reported feedback.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6:</label>
<caption><title>Credit assignment is enhanced for feedback that is more likely to be true.</title>
<p><bold>a</bold>, The posterior belief that the received feedback is truthful (y-axis) is plotted against the prior belief (held before receiving feedback) that the chosen bandit would be rewarding (x-axis). The plot illustrates how this posterior belief is influenced by the valence of the feedback (reward indicated by solid lines, no reward by dashed lines) and the credibility of the feedback agent (represented by different colors). <bold>b</bold>, Distribution of posterior belief probability that feedback is true, calculated separately for each agent (1 or 2 star) and objective feedback-truthfulness (true or lie). These probabilities were computed based on trial-sequences and feedback participants experienced, indicating belief probabilities that feedback is true are higher in truth compared to lie trials. For illustration, plotted distributions pool trials across participants. The black line within each box represents the median, upper and lower bounds represent the third and first quartile respectively. The width of each half-violin plot corresponds to the density of each posterior belief value among all trials for a given condition. <bold>c</bold>, Maximum likelihood (ML) estimate of the “truth-bonus” parameter derived from the “Truth-CA” model. The significantly positive truth bonus indicates that participants increased credit assignment as a function of the likelihood this feedback was true (after controlling for the credibility of this feedback) . Each small dot represents the fitted truth-bonus parameter for an individual participant, the large circle indicates the group mean, and the error bars represent the standard error of the mean. <bold>d</bold>, Distribution of truth-bonus parameters predicted by synthetic simulations of our alternative computational models. For each alternative model, we generated 101 synthetic group-level datasets based on the maximum likelihood parameters fitted to the participants’ actual behavior. Each of these datasets was then independently fitted with the “Truth-CA” model. Each histogram represents the distribution of the mean truth bonus across the 101 simulated group-level datasets for a specific alternative model. Notably, the truth bonus observed in our participants was significantly higher than the truth bonus predicted by any of these alternative models (proportion of datasets predicting a higher truth bonus: Instructed-credibility Bayesian &lt; 0.01, Free-credibility Bayesian = 0, Credibility-CA = 0, Credibility-Valence CA = 0). (**) p&lt;.01</p></caption>
<graphic xlink:href="st4kgv5_fig6.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<p>To formally address whether feedback truthfulness modulates credit assignment, we fitted a new variant of the CA model (the “Truth-CA” model) to the data. This variant works as our Credibility-CA model, but incorporated a truth-bonus parameter (<italic>TB</italic>) which increases the degree of credit assignment for feedback as a function of the <italic>experimenter-determined</italic> likelihood the feedback is true (which is read from the curves in <xref ref-type="fig" rid="fig6">Fig 6a</xref> when x is taken to be the true probability the bandit is rewarding). Specifically, after receiving feedback, the Q-value of the chosen option is updated according to the following rule:
<disp-formula id="FD2">
<alternatives>
<mml:math id="M2" display="block"><mml:mi>Q</mml:mi><mml:mo>←</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>Q</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mi>Q</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:mi>A</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>B</mml:mi><mml:mo>∗</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mn>0.5</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mi>F</mml:mi></mml:math>
<graphic xlink:href="st4kgv5_eqn2.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
</disp-formula>
</p>
<p>where <italic>TB</italic> is the free parameter representing the truth bonus, and <italic>P(truth)</italic> is the probability the received feedback being true (from the experimenter’s perspective). We acknowledge that this model falls short of providing a mechanistically plausible description of the credit assignment process, because, participants have no access to the experimenter’s truthfulness likelihoods (as the true bandit reward probabilities are unknown to them). Nonetheless, we use this ‘oracle model’ as a measurement tool to glean rough estimates for the extent to which credit assignment Is boosted as a function of its truthfulness likelihood.</p>
<p>Fitting this Truth-CA model to participants’ behaviour revealed a significant positive truth-bonus (mean=0.21, t(203)=3.12, p=0.002), suggesting that participants indeed assign greater weight to feedback that is likely to be true (<xref ref-type="fig" rid="fig6">Fig. 6c</xref>; see <xref ref-type="section" rid="s6-3-3-1">SI 3.3.1</xref> for detailed ML parameter results). Notably, simulations using our other models (Methods) consistently predicted smaller truth biases (compared to the empirical bias) (<xref ref-type="fig" rid="fig6">Fig. 6d</xref>). Moreover, truth bias was still detected even in a more flexible model that allowed for both a positivity bias and truth-bias (see <xref ref-type="section" rid="s6-3-7">SI 3.7</xref>). The upshot is that participants are biased to assign higher credit based on feedback that is more likely to be true in a manner that is inconsistent with out Bayesian models and above and beyond the previously identified positivity biases.</p>
</sec>
<sec id="s2-8">
<title>Discovery study</title>
<p>The discovery study (n=104) used a disinformation task structurally similar to that used in our main study, but with three notable differences: 1) it included 4 feedback agents, with credibilities of 50%, 70%, 85% and 100%, represented by 1, 2, 3, and 4 stars, respectively; 2) each experimental block consisted of a single bandit pair, presented over 16 trials (with 4 trials for each feedback agent); and 3) in certain blocks, unbeknownst to participants, the two bandits within a pair were equally rewarding (see <xref ref-type="section" rid="s6-1-1">SI section 1.1</xref>). Overall, this study’s results supported similar conclusions as our main study (see <xref ref-type="section" rid="s6-1-2">SI section 1.2</xref>) with a few differences. We found convergent support for increased learning from more credible sources (<xref ref-type="section" rid="s6-1-2-1">SI 1.2.1</xref>), superior fit for the CA model over Bayesian models (<xref ref-type="section" rid="s6-1-2-2">SI 1.2.2</xref>) and increased learning from feedback inferred to be true (<xref ref-type="section" rid="s6-1-2-6">SI 1.2.6</xref>). Additionally, we found an inflation of positivity bias for low-credibility both when measured relative to the overall level of credit assignment (as in our main study), or in absolute terms (unlike in our main study) (<xref ref-type="fig" rid="figS3">Fig. S3</xref>; <xref ref-type="section" rid="s6-1-2-5">SI 1.2.5</xref>). Moreover, choiceperseveration could not predict an amplification of positivity bias for low-credibility sources (see <xref ref-type="section" rid="s6-3-6-2">SI 3.6.2</xref>). However, we found no evidence for learning based on 50%-credibility feedback when examining either the feedback effect on choice repetition or CA in the credibility-CA model (<xref ref-type="section" rid="s6-1-2-3">SI 1.2.3</xref>).</p>
</sec>
</sec>
<sec id="s3" sec-type="discussion">
<title>Discussion</title>
<p>Accurate information enables individuals to adapt effectively to their environment (<xref ref-type="bibr" rid="c52">52</xref>,<xref ref-type="bibr" rid="c53">53</xref>). Indeed, it has been suggested that the importance and utility of information elevate its status to that of a secondary reinforcer, imbuing it with intrinsic value beyond its immediate usefulness (<xref ref-type="bibr" rid="c54">54</xref>,<xref ref-type="bibr" rid="c55">55</xref>). However, a significant societal challenge arises from the fact that, as social animals, much information we receive is mediated by others, entailing it can be inaccurate, biased or purposefully misleading. Here, using a novel variant of the two-armed bandit task, we asked how we update our beliefs in the presence of potential disinformation, wherein <italic>true choice</italic> outcomes are latent and feedback is provided by potentially disinformative agents.</p>
<p>We acknowledge that several factors may limit the external validity of our task, including the fact that participants were explicitly instructed about the credibility of information sources. In contrast, in many real-life scenarios, individuals need to learn the credibility of information sources based on their own experience of the world or may even have false beliefs regarding the source-credibility of agents. Moreover, in our task, the experimenter fully controlled the credibility of the information source in every trial, whereas in many real-life situations people can exercise a degree of control over the credibility of information they receive. For example, search engines allow an exercise of choice regarding the credibility of sources. Finally, in our task, feedback agents served as rudimentary representations of social agents, who lied randomly and arbitrarily, in a motivation-free manner. Conversely, in real life, others may strategically attempt to mislead us, and we can exploit knowledge of their motivation to lie, such as when we assume that a used cars seller is more likely to portray a clapped-out car as excellent, rather than state the unfiltered truth. Nevertheless, our results attest to the utility of our task in identifying biased aspects of learning in the face of disinformation, even in a simplified scenario.</p>
<p>Consistent with Bayesian-learning principles, we show that individuals increased their learning as a function of feedback credibility. This aligns with previous studies demonstrating an impressive human ability to flexibly increase learning rates when environmental changes render prior knowledge obsolete (<xref ref-type="bibr" rid="c23">23</xref>,<xref ref-type="bibr" rid="c56">56</xref>,<xref ref-type="bibr" rid="c57">57</xref>), and when there is reduced inherent uncertainty, such as “observation noise” (<xref ref-type="bibr" rid="c23">23</xref>,<xref ref-type="bibr" rid="c56">56</xref>–<xref ref-type="bibr" rid="c58">58</xref>). However, as hypothesized, when facing potential disinformation, we also find that individuals exhibit several important biases i.e., deviations from strictly idealized Bayesian strategies. Future studies should explore if and under what assumptions, about the task’s generative structure and/or learner’s priors and objectives, more complex Bayesian models (e.g., active inference (<xref ref-type="bibr" rid="c59">59</xref>)) might account for our empirical findings. In our main study, we show that participants revised their beliefs based on entirely non-credible feedback, whereas an ideal Bayesian strategy dictates such feedback should be ignored. This finding resonates with the “continued-influence effect” whereby misleading information continues to influence an individual’s beliefs even after it has been retracted (<xref ref-type="bibr" rid="c60">60</xref>,<xref ref-type="bibr" rid="c61">61</xref>). One possible explanation is that some participants failed to infer that feedback from the 1- star agent was statistically void of information content, essentially random (e.g., the group-level credibility of this agent was estimated by our free-credibility Bayesian model as higher than 50%). Participants were instructed that this feedback would be “a lie” 50% of the time but were not explicitly told that this meant it was random and should therefore be disregarded. Notably, however, there was no corresponding evidence random feedback affected behaviour in our discovery study. It is possible that an individual’s ability to filter out random information might have been limited due to a high cognitive load induced by our main study task, which required participants to track the values of three bandit pairs and juggle between three interleaved feedback agents (whereas in our discovery study each experimental block featured a single bandit pair). Future studies should explore more systematically how the ability to filter random feedback depends on cognitive load (<xref ref-type="bibr" rid="c62">62</xref>).</p>
<p>Previous reinforcement learning studies, report greater credit-assignment based on positive compared to negative feedback, albeit only in the context of veridical feedback (<xref ref-type="bibr" rid="c43">43</xref>,<xref ref-type="bibr" rid="c44">44</xref>,<xref ref-type="bibr" rid="c63">63</xref>). Here, we investigated whether a positivity bias is amplified for information of low credibility, but our findings are equivocal and vary as a function of scaling (absolute or relative) and study. We observe selective absolute amplification of a positivity bias for information of low and intermediate credibility in the discovery study alone. In contrast, we find a relative (to the overall extent of CA) amplification of confirmation bias in both studies. Importantly, the magnitude of these amplification effects cannot be reproduced in ex-post simulations of a model incorporating simple choice perseveration without an explicit positivity bias, suggesting that at least part of the amplification reflects a genuine increase in positivity bias.</p>
<p>Of note, previous literature has interpreted enhanced learning for positive outcomes in reinforcement learning as indicative of a confirmation bias (<xref ref-type="bibr" rid="c42">42</xref>,<xref ref-type="bibr" rid="c44">44</xref>). For example, positive feedback may confirm, to a greater extent than negative feedback one’s choice as superior (e.g., “I chose the better of the two options”). Leveraging the framework of motivated cognition (<xref ref-type="bibr" rid="c35">35</xref>), we posited that feedback of uncertain veracity (e.g., low credibility) amplifies this bias by incentivising individuals to self-servingly accept positive feedback as true (because it confers positive, desirable outcomes), and explain away undesirable, choice-disconfirming, negative feedback as false. This could imply an amplified confirmation bias on social media, where content from sources of uncertain credibility, such as unknown or unverified users, is more easily interpreted in a self-serving manner, disproportionately reinforcing existing beliefs (<xref ref-type="bibr" rid="c64">64</xref>). In turn, this could contribute to an exacerbation of the negative social outcomes previously linked to confirmation bias such as polarization (<xref ref-type="bibr" rid="c65">65</xref>,<xref ref-type="bibr" rid="c66">66</xref>), the formation of ‘echo chambers’ (<xref ref-type="bibr" rid="c19">19</xref>), and the persistence of misbelief regarding contemporary issues of importance such as vaccination (<xref ref-type="bibr" rid="c67">67</xref>,<xref ref-type="bibr" rid="c68">68</xref>) and climate change (<xref ref-type="bibr" rid="c69">69</xref>–<xref ref-type="bibr" rid="c72">72</xref>). We note however, that further studies are required to determine whether positivity bias in our task is indeed a form of confirmation bias. Future studies could also benefit from using designs that are better suited for dissociating learning asymmetries from gradual perseveration (<xref ref-type="bibr" rid="c51">51</xref>).</p>
<p>A striking finding in our study was that for a fully credible feedback agent, credit assignment was exaggerated (i.e., higher than predicted by our Bayesian models). Furthermore, the effect of fully credible feedback on choice was further boosted when it was preceded by a low-credibility context related to current learning. We interpret this in terms of a “contrast effect”, whereby veridical information looms larger against a backdrop of disinformation (<xref ref-type="bibr" rid="c21">21</xref>). One upshot is that exaggerated learning might entail a risk of jumping to premature conclusions based on limited credible evidence (e.g., a strong conclusion that a vaccine produces significant side-effect risks based on weak credible information, following non-credible information about the same vaccine). An intriguing possibility, that could be tested in future studies, is that participants strategically amplify the extent of learning from credible feedback to dilute the impact of learning from non-credible feedback. For example, a person scrolling through a social media feed, encountering copious amounts of disinformation, might amplify the weight they assign to credible feedback in order to dilute effects of ‘fake news’. Ironically, these results also suggest that public campaigns might be more effective when embedding their messages in low-credibility contexts, which may boost their impact.</p>
<p>Our findings show that individuals increase their credit assignment for feedback in proportion to the perceived probability that the feedback is true, even after controlling for source credibility and feedback valence. Strikingly, this learning bias was not predicted by any of our Bayesian or creditassignment (CA) models. Notably, our evidence for this bias is based on a “oracle model” that incorporates the probability of feedback truthfulness from the experimenter’s perspective, rather than the participant’s. This raises an important open question: how do individuals form beliefs about feedback truthfulness, and how do these beliefs influence credit assignment? Future research should address this by eliciting trial-by-trial beliefs about feedback truthfulness. Doing so would also allow for testing the intriguing possibility that an exaggerated positivity bias for non-credible sources reflects, to some extent, a truth-based discounting of negative feedback—i.e., participants may judge such feedback as less likely to be true. However, it is important to note that the positivity bias observed for fully credible sources (here and in other literature) cannot be attributed to a truth bias—unless participants were, against instructions, distrustful of that source.</p>
<p>An important question arises as to the psychological locus of the biases we uncovered. Because we were interested in how individuals process disinformation—deliberately false or misleading information intended to deceive or manipulate—we framed the feedback agents in our study as deceptive, who would occasionally “lie” about the true choice outcome. However, statistically (though not necessarily psychologically), these agents are equivalent to agents who mix truth-telling with random “guessing” or “noise” where inaccuracies may arise from factors such as occasionally lacking access to true outcomes, simple laziness, or mistakes, rather than an intent to deceive. This raises the question of whether the biases we observed are driven by the perception of potential disinformation as deceitful per se or simply as deviating from the truth. Future studies could address this question by directly comparing learning from statistically equivalent sources framed as either lying or noisy. Unlike previous studies wherein participants had to infer source credibility from experience (<xref ref-type="bibr" rid="c30">30</xref>,<xref ref-type="bibr" rid="c37">37</xref>,<xref ref-type="bibr" rid="c73">73</xref>), we took an explicit-instruction approach, allowing us to precisely assess source-credibility impact on learning, without confounding it with errors in learning about the sources themselves. More broadly, our work connects with prior research on observational learning, which examined how individuals learn from the actions or advice of social partners (<xref ref-type="bibr" rid="c73">73</xref>–<xref ref-type="bibr" rid="c76">76</xref>). This body of work has demonstrated that individuals integrate learning from their private experiences with learning based on others’ actions or advice—whether by inferring the value others attribute to different options or by mimicking their behavior (<xref ref-type="bibr" rid="c58">58</xref>,<xref ref-type="bibr" rid="c77">77</xref>). However, our task differs significantly from traditional observational learning. Firstly, our feedback agents interpret outcomes rather than demonstrating or recommending actions (<xref ref-type="bibr" rid="c30">30</xref>,<xref ref-type="bibr" rid="c37">37</xref>,<xref ref-type="bibr" rid="c73">73</xref>). Secondly, participants in our study lack private experiences unmediated by feedback sources. Finally, unlike most observational learning paradigms, we systematically address scenarios with deliberately misleading social partners. Future studies could bridge this by incorporating deceptive social partners into observational learning, offering a chance to develop unified models of how individuals integrate social information when credibility is paramount for decision-making.</p>
<p>We conclude by noting previous research has often attributed the negative impacts of disinformation, such as polarization and the formation of echo chambers, to intricate processes facilitated by external or self-selection of information (<xref ref-type="bibr" rid="c78">78</xref>–<xref ref-type="bibr" rid="c80">80</xref>). These processes include algorithms tailoring information to align with users’ attitudes (<xref ref-type="bibr" rid="c81">81</xref>) or individuals consciously opting to engage with like-minded peers (<xref ref-type="bibr" rid="c82">82</xref>). However, our study reveals a more profound effect of disinformation, namely that even in minimal conditions, when low credibility information is explicitly identified, disinformation significantly impacts individuals’ beliefs and decision-making processes. This occurs even when the decision at hand entails minimal emotional engagement or pertinence to deep, identity-related, issues. A critical next step is to deepen our understanding of these biases, particularly within complex social environments, not least to enable the development of effective prospective interventions capable of mitigating the potentially pernicious impacts of disinformation.</p>
</sec>
<sec id="s4" sec-type="materials|methods">
<title>Materials and Methods</title>
<sec id="s4-1">
<title>Participants</title>
<p>We recruited 246 participants (mean age 39.33± 12.65, 112 female) from the Prolific participant pool (<ext-link ext-link-type="uri" xlink:href="http://www.prolific.co">www.prolific.co</ext-link>) who went on to perform the task on the Gorilla platform (<xref ref-type="bibr" rid="c83">83</xref>). All participants were fluent English speakers with normal or corrected-to-normal vision and a Prolific approval rate of 95% or higher. UCL Research Ethics Committee approved the study (Project ID 6649/004), and all participants provided prior informed consent.</p>
</sec>
<sec id="s4-2">
<title>Experimental protocol</title>
<sec id="s4-2-1">
<title>Traditional two-armed bandit task</title>
<p>At the beginning of the experiment participants completed a traditional version of the two-armed bandit task. Participants performed 45 trials, each featuring one of three randomly interleaved bandit pairs (such that each pair was presented on 15 trials). On each trial, participants choose between the bandit-pair, with each bandit being represented by a distinct identicon. Once a bandit was selected it generated a true outcome (converted to bonus monetary compensation) corresponding to either a reward or nothing. Within each bandit-pair, one bandit provided rewards on 75% of trials (with 25% providing no-reward), while the other bandit rewarded on 25% of the trials (75% non-reward trials). Participants were uninformed about the reward probabilities of each bandit and had to learn these based on experience.</p>
<p>At onset of each trial, the two bandits were presented, one on each side of the screen, and participants were asked to indicate their choice within 3 seconds by pressing the left/right arrow-keys. If the 3 seconds elapsed with no choice, participants were shown a “too slow” message and proceeded to the next trial. Following choice, the unselected bandit disappeared, and the participants were presented with the outcome of the selected bandit for 1200ms, followed by a 250 ms ISI before the start of the next trial. Rewards were represented by a green dollar symbol and non-rewards by a red sad face (both in the center of the screen). At the end of the task, participants were informed about the number of rewards they had earned.</p>
</sec>
<sec id="s4-2-2">
<title>Disinformation task</title>
<p>This involved a modified, disinformation version, of the same two-armed bandit task. Participants performed 8 blocks, each consisting of 45 trials. Each block followed the structure of the traditional two-armed bandit task, but with a critical difference: true choice-outcomes were withheld from participants and instead they received reward-feedback from a feedback agent. Participants were instructed prior to the task that feedback agents mostly provide accurate feedback (i.e., the true outcome) but could lie on a random minority of trials by reporting a reward in case of a true nonreward, or vice versa. The task featured three feedback agents varying in their credibility (i.e., probability of truth-telling), as indicated by a “star-rating” system, about which participants were instructed prior to the task. The 3-star agent always told the truth, whereas the other 2 agents were partially credible, reporting the truth on 75% (2-star) or 50% (1-star) of the trials. Feedback agents were randomly interleaved across trials subject to the constraint that each agent appeared on 5-trials for each bandit pair.</p>
<p>At the onset of each trial, participants were presented with the feedback agent for the trial (screen center) and with the two bandits, one on each side of the screen. Participants made a 2-second time limited choice by pressing the left/right arrow-keys. Following choice, the unselected bandit disappeared, and were then presented with the agent feedback for 1200ms (represented by either a rewarding green dollar sign or a non-rewarding red sad face in the center of the screen). All stimuli then disappeared for 250 ms to be followed by the start of the next trial. At the end of each block, participants were informed about the number of true rewards they had earned. They then received a 30-second break before the next block started with new 3 bandit pairs.</p>
</sec>
<sec id="s4-2-3">
<title>General protocol</title>
<p>At the beginning of the experiment, participants were presented with instructions for the traditional two-armed bandit task. The instructions were interleaved with four multiple-choice questions. When participants answered a question incorrectly, they could re-read the instructions and re-attempt. If participants answered a question incorrectly twice, they were compensated for the time but could not continue to the next stage. Upon completing the instructions participants proceeded to the traditional two-armed bandit task.</p>
<p>After the two-armed bandit task, participants were presented with instructions regarding the disinformation task. Again, these were interleaved with six questions wherein participants had two attempts to answer each question correctly. If they answered a question incorrectly twice, they were rejected and received partial participatory compensation. Participants then proceeded to the disinformation task. After completing the disinformation task, participants completed three psychiatric questionnaires (presented in random order): 1) the Obsessional Compulsive Inventory - Revised (OCI-R) (<xref ref-type="bibr" rid="c84">84</xref>), assessing symptoms of obsessive-compulsive disorder (OCD); 2) The Revised Green et al. Paranoid Thoughts Scale (R-GPTS) (<xref ref-type="bibr" rid="c85">85</xref>), measuring paranoid ideations; and 3) the DOG scale, evaluating dogmatism (<xref ref-type="bibr" rid="c86">86</xref>).</p>
<p>The participants took on average 43 minutes to complete the experiment. They received a fixed compensation of 5.48 GBP and variable compensation between 0 and 2 GBP based on their performance on the disinformation task.</p>
</sec>
<sec id="s4-2-4">
<title>Attention checks</title>
<p>The two tasks included randomly interleaved catch trials wherein participants were cued to press a given key within a 3-second limit. None of the participants failed more than one of these attention checks.</p>
</sec>
</sec>
<sec id="s4-3">
<title>Data analysis</title>
<sec id="s4-3-1">
<title>Exclusion criteria</title>
<p>Participants were excluded if they: 1) Either repeated or alternated key presses in more than 70% of the trials, and/or 2) their reaction time was lower than 150 ms in more than 5% of the trials. Based on these criteria 42 participants were excluded, while 204 participants were kept for the analyses.</p>
</sec>
<sec id="s4-3-2">
<title>Accuracy</title>
<p>Accuracy rates were calculated as the probability of choosing within a given pair the bandit with a higher reward probability. For <xref ref-type="fig" rid="fig1">figure 1d</xref>, we calculated for each participant and for each trial (within a bandit-pair) averaged accuracy across all bandit-pairs. We then averaged accuracy at the trial level across participants. Overall improvement for each participant was calculated as the average accuracy difference between the last and first trials for each of the bandit-pairs.</p>
</sec>
<sec id="s4-3-3">
<title>Computational models</title>
<sec id="s4-3-3-1">
<title>RL Models</title>
<p>We formulated a family of RL models to account for participant choices. In these models, a tendency to choose each bandit is captured by a Q-value. After reward-feedback the Q-value of the chosen bandit was updated conditional on the agent and on whether the feedback was positive or negative according to the following rule:
<disp-formula id="FD3">
<alternatives>
<mml:math id="M3" display="block"><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>←</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>Q</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:mi>A</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mi>F</mml:mi></mml:math>
<graphic xlink:href="st4kgv5_eqn3.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
<label>(1)</label>
</disp-formula>
</p>
<p>where <italic>CA</italic> is a free credit assignment parameter representing the magnitude of the value increase/decrease following feedback receipt <italic>F</italic> from the agents (coded as 1 for reward feedback and −1 for non-reward feedback), while <italic>f<sub>Q</sub></italic> (∈ [0,1]) is the free parameter representing the forgetting rate of the Q-value. Additionally, the value of each of the other bandits (i.e., the unchosen bandit in the presented pair and all the bandits from the other not-shown pairs) were forgotten as per the following:
<disp-formula id="FD4">
<alternatives>
<mml:math id="M4" display="block"><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>←</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>Q</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="st4kgv5_eqn4.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
<label>(2)</label>
</disp-formula>
</p>
<p>Alternative model-variants differed based on whether the CA parameter(s) were influenced by agents and/or feedback valence (see <xref ref-type="table" rid="tbl1">Table 1</xref> below), allowing us to test how these variables impacted learning.</p>
<table-wrap id="tbl1" position="float" orientation="portrait">
<label>Table 1:</label>
<caption><title>summary of free parameters for each of the CA models.</title></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl1.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#F2F2F2">
<th align="center" valign="top">Model</th>
<th align="center" valign="top">Free CA parameter</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#F2F2F2"><bold>Null</bold></td>
<td align="center" valign="top"><italic>CA</italic></td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#F2F2F2"><bold>Credibility-CA</bold></td>
<td align="center" valign="top"><italic>CA</italic><sub>0.5</sub>, <italic>CA</italic><sub>0.75</sub>, <italic>CA</italic><sub>1</sub></td>
</tr>
<tr>
<td align="center" valign="middle" style="background-color:#F2F2F2"><bold>Credibility-Valence-CA</bold></td>
<td align="center" valign="top"><italic>CA</italic><sub>0.5</sub>+, <italic>CA</italic><sub>0.75</sub>+,<italic>CA</italic><sub>1</sub>+
<break/><italic>CA</italic><sub>0.5</sub>−,<italic>CA</italic><sub>0.75</sub>−, <italic>CA</italic><sub>1</sub>−</td>
</tr>
<tr>
<td align="center" valign="middle" style="background-color:#F2F2F2"><bold>constant feedback 
<break/> valence bias CA</bold></td>
<td align="center" valign="top"><italic>VB</italic>
<break/><italic>CA</italic><sub>0.5</sub>−, <italic>CA</italic><sub>0.75</sub>−, <italic>CA</italic><sub>1</sub>−</td>
</tr>
<tr>
<td align="center" valign="middle" style="background-color:#F2F2F2"><bold>Truth-CA</bold></td>
<td align="center" valign="top"><italic>TB</italic>
<break/><italic>CA</italic><sub>0.5</sub>,<italic>CA</italic><sub>0.75</sub>, <italic>CA</italic><sub>1</sub></td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<list list-type="order">
<list-item><p>The “Null” model included a unique CA parameter conveying an assumption that feedback is modulated by neither agent-credibility nor feedback valence.</p></list-item>
<list-item><p>The “Credibility-CA” models included a dedicated CA parameter for each agent allowing for the possibility learning was selectively modulated by agent credibility (but not by feedback valence).</p></list-item>
<list-item><p>The “Credibility-Valence-CA” model included distinct CA parameters for rewarding (CA+) and nonrewarding feedback (CA−) for each agent, allowing CA to be influenced by both feedback valence and credibility.</p></list-item>
<list-item><p>The “constant feedback-valence bias” CA model included separate CA− parameters for each agent, but a single valence bias parameter (VB) common to all agents, such that the CA+ parameter for each agent corresponded to the sum of its CA− parameter and the common VB parameter.</p></list-item>
</list>
<p>Additionally, we formulated a “Truth-CA” model, which worked as our Credibility-CA model, but incorporated a free truth-bonus parameter (<italic>TB</italic>). This parameter modulates the extent of credit assignment for each agent based on the posterior probability of feedback being true (given the credibility of the feedback agent, and the true reward probability of the chosen bandit). The chosen bandit was updated as follows:
<disp-formula id="FD5">
<alternatives>
<mml:math id="M5" display="block"><mml:mi>Q</mml:mi><mml:mo>←</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>Q</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mi>Q</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:mi>A</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>B</mml:mi><mml:mo>∗</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mn>0.5</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mi>F</mml:mi></mml:math>
<graphic xlink:href="st4kgv5_eqn5.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
<label>(3)</label>
</disp-formula>
</p>
<p>where Prob(truth) is the posterior probability of the feedback being true in the current trial (for exact calculation of Prob(truth) see “Methods: Bayesian estimation of posterior belief that feedback is true”).</p>
<p>All models also included gradual perseveration for each bandit. In each trial the perseveration values (Pers) were updated according to
<disp-formula id="FD6">
<alternatives>
<mml:math id="M6" display="block"><mml:mi>P</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>←</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>P</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mi>P</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>P</mml:mi><mml:mi>E</mml:mi><mml:mi>R</mml:mi><mml:mi>S</mml:mi></mml:math>
<graphic xlink:href="st4kgv5_eqn6.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
<label>(4)</label>
</disp-formula>
</p>
<p>Where PERS is a free parameter representing the Pers-value change for the chosen bandit, and <italic>f<sub>p</sub></italic>(∈ [0,1]) is the free parameter denoting the forgetting rate applied to the Pers value. Additionally, the Pers-values of all the non-chosen bandits (i.e., again, the unchosen bandit of the current pair, and all the bandits from the not-shown pairs) were forgotten as follows:
<disp-formula id="FD7">
<alternatives>
<mml:math id="M7" display="block"><mml:mi>P</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>←</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>P</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mi>P</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="st4kgv5_eqn7.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
<label>(5)</label>
</disp-formula>
</p>
<p>We modelled choices using a <italic>softmax</italic> decision rule, representing the probability of the participant to choose a given bandit over the alternative:
<disp-formula id="FD8">
<alternatives>
<mml:math id="M8" display="block"><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mtext> </mml:mtext><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mtext> </mml:mtext><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>P</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math>
<graphic xlink:href="st4kgv5_eqn8.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
<label>(6)</label>
</disp-formula>
</p>
</sec>
<sec id="s4-3-3-2">
<title>Bayesian Models</title>
<p>We also formulated a Bayesian model corresponding to an ideal belief updating strategy. In this model, beliefs about each bandit were represented by a density distribution over the probability that a bandit provides a true reward <italic>g(p),</italic> where <italic>p</italic> is the probability of a true reward (see full derivation in <xref ref-type="section" rid="s6-4-1">SI 4.1</xref>). During learning, following reward-feedback, the distribution <italic>for</italic> the chosen bandit was updated based on the agent’s feedback (<italic>F</italic>) and its associated credibility (<italic>C</italic>):
<disp-formula id="FD9">
<alternatives>
<mml:math id="M9" display="block"><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>←</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:mo>∗</mml:mo><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mtext>   </mml:mtext><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext>  </mml:mtext><mml:mi>F</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math>
<graphic xlink:href="st4kgv5_eqn9.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
<label>(7)</label>
</disp-formula>
<disp-formula id="FD10">
<alternatives>
<mml:math id="M10" display="block"><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>←</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:mo>∗</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mtext>   </mml:mtext><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mtext>  </mml:mtext><mml:mi>F</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:math>
<graphic xlink:href="st4kgv5_eqn10.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
<label>(8)</label>
</disp-formula>
<disp-formula id="FD11">
<alternatives>
<mml:math id="M11" display="block"><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>←</mml:mo><mml:mfrac><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mn>1</mml:mn></mml:msubsup><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mfrac></mml:math>
<graphic xlink:href="st4kgv5_eqn11.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
<label>(9)</label>
</disp-formula>
</p>
<p>At the beginning of each block priors for each bandit were initialized to uniform distributions (<italic>g(p)=U[0,1]</italic>). In the <italic>instructed-credibility Bayesian model</italic>, we fixed the credibilities to their true values (i.e., 0.5, 0.75 and 1).</p>
<p>We also formulated a <italic>free-credibility Bayesian model</italic>, where we only fixed the three-star agent credibility to 1 but estimated the credibility of the two lying agents as free parameters. This model allowed the possibility that participants use distorted instructed-credibilities when following a Bayesian strategy.</p>
<p>For both versions, we modelled choice using a SoftMax function with a free inverse temperature parameter (<italic>β</italic>):
<disp-formula id="FD12">
<alternatives>
<mml:math id="M12" display="block"><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>β</mml:mi><mml:mo>∗</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mtext> </mml:mtext><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math>
<graphic xlink:href="st4kgv5_eqn12.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
<label>(10)</label>
</disp-formula>
</p>
<p>Where here <italic>Q(bandit)</italic> is the expected probability, the bandit provides a true reward.</p>
<p>Additionally, we formulated extended Bayesian models to account for choice-perseveration (see <xref ref-type="section" rid="s6-3-6-1">SI 3.6.1</xref>). These models operate as our instructed-credibility and free-credibility Bayesian models, but also incorporate a perseveration values, updated in each trial as in our CA models (<xref ref-type="disp-formula" rid="FD6">Eqs. 4</xref> and <xref ref-type="disp-formula" rid="FD7">5</xref>). For these extended models, we modelled choices using the following <italic>softmax</italic> decision rule:
<disp-formula id="FD13">
<alternatives>
<mml:math id="M13" display="block"><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>β</mml:mi><mml:mo>*</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mtext> </mml:mtext><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mtext> </mml:mtext><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>P</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math>
<graphic xlink:href="st4kgv5_eqn13.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
<label>(11)</label>
</disp-formula>
</p>
</sec>
</sec>
<sec id="s4-3-4">
<title>Parameter optimization, model selection and synthetic model simulations</title>
<p>For each participant, we estimated the free parameter values that maximized the summed loglikelihood of the observed choices across all games. Trials where participants showed a response time below 150 ms were excluded from the log-likelihood calculations. To minimise the chances of finding local minima, we ran the fitting procedure 10 times for each participant, using random initializations for the parameters (CA~U[-10,10], PERS~U[-5,5], f<sub>Q</sub>~[0,1], f<sub>p</sub>~[0,1], TB~[-10,10], β~[0,30], C~U[0,1]).</p>
<p>We performed model comparison between Bayesian and CA models using the parametric bootstrap cross-fitting method (PBCM)(<xref ref-type="bibr" rid="c87">87</xref>,<xref ref-type="bibr" rid="c88">88</xref>). In brief, this method relies on generating, for each participant, synthetic datasets (we used 201) based on maximal likelihood parameters and each model variant (i.e., the Bayesian model and the CA model), and fitting each dataset with the two models. We then calculated the log likelihood difference between the two fits for each dataset, obtaining two log likelihood difference distributions, one for each generative model. We determined a loglikelihood difference threshold that leads to best model-classification (i.e., maximizing the proportion of true positives and true negatives). Finally, we fit the empirical data from each participant with the two model variants, calculating an empirical loglikelihood difference. A comparison of this empirical likelihood difference to the classification threshold determines which model provides a better fit for a participant’s data (see <xref ref-type="fig" rid="figS6">Fig. S6</xref> for more information). We used this procedure to compare our Bayesian models (instructed-credibility and free-credibility Bayesian) with a simplified version of the credibility-CA model that did not include perseveration (PERS, fP = 0).</p>
<p>We also performed model-comparisons for nested CA models using generalized-likelihood ratio tests where the null distribution for rejecting a nested model (in favour of a nesting model) was based on a bootstrapping method (BGLRT)(<xref ref-type="bibr" rid="c48">48</xref>,<xref ref-type="bibr" rid="c89">89</xref>).</p>
<p>To assess the mechanistic predictions of each model, we generated synthetic simulations based on the ML parameters of participants. Unless stated otherwise, we generated 5 simulations for each participant (1020 total simulations) with a new sequence of trials generated as in the actual data. We analysed these data in the same way as we analysed empirical data, after pooling together the 5 simulated data set per participant.</p>
</sec>
<sec id="s4-3-5">
<title>Parameter recovery</title>
<p>For each model of interest, we generated 201 synthetic simulations based on parameters sampled from uniform distributions (CA~U[-10,10], PERS~U[-5,5], f<sub>Q</sub>~U[0,1], f<sub>p</sub>~U[0,1], β~U[0,30], C~U[0,1]). We fitted each simulated dataset with its generative model and calculated the Spearman’s correlation between the generative and fitted parameters.</p>
</sec>
<sec id="s4-3-6">
<title>Mixed effects models</title>
<sec id="s4-3-6-1">
<title>Model-agnostic analysis of agent-credibility effects on choice-repetition</title>
<p>We used a mixed-effects binomial regression model to assess whether, and how, value-learning was modulated by agent-credibility, with participants serving as random effects. The regressed variable <italic>REPEAT</italic> indicated whether the current trial repeated the choice from the previous trial featuring the same bandit-pair (repeated choice=1, non-repeated choice=0) and was regressed on the following regressors: <italic>FEEDBACK</italic> coded whether feedback received in the previous trial with the same bandit pair was positive or negative (coded as 0.5, −0.5, respectively), <italic>BETTER</italic> coded whether the bandit chosen in that previous trial was the better -mostly rewarding- or the worse -mostly unrewarding-bandit within the pair, coded as 0.5 and −0.5 respectively, AGENT<sub>2-star</sub> indicated whether feedback received in the previous trial (featuring the same bandit pair) came from the 2-star agent (previous feedback from 2-star agent=1, otherwise=0) and, AGENT<sub>3-star</sub> indicated whether the feedback in the previous trial came from the 3-star agent. The model in Wilkinson’s notation was:
<disp-formula id="FD14">
<alternatives>
<mml:math id="M14" display="block"><mml:mi>R</mml:mi><mml:mi>E</mml:mi><mml:mi>P</mml:mi><mml:mi>E</mml:mi><mml:mi>A</mml:mi><mml:mi>T</mml:mi><mml:mo>∼</mml:mo><mml:mi>F</mml:mi><mml:mi>E</mml:mi><mml:mi>E</mml:mi><mml:mi>D</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mi>C</mml:mi><mml:mi>K</mml:mi><mml:mo>∗</mml:mo><mml:mi>B</mml:mi><mml:mi>E</mml:mi><mml:mi>T</mml:mi><mml:mi>T</mml:mi><mml:mi>E</mml:mi><mml:mi>R</mml:mi><mml:mo>∗</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="st4kgv5_eqn14.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
<label>(12)</label>
</disp-formula>
</p>
<p>In <xref ref-type="fig" rid="fig2">figure 2a and 2b</xref>, we plot the choice-repeat probability based on feedback-valence and agentcredibility from the preceding trial with the same bandit pair. We independently calculated the repeat probability for the better (mostly rewarding) and worse (mostly non-rewarding) bandits and averaged across them. This calculation was done at the participants level, and finally averaged across participants.</p>
</sec>
<sec id="s4-3-6-2">
<title>Model-agnostic analysis of contextual credibility effects on choice-repetition</title>
<p>We used a different mixed-effects binomial regression model to test whether value learning from the 3-star agent was modulated by contextual credibility. We focused this analysis on instances where the previous trial with the same bandit pair featured the 3-star agent. We regressed the variable <italic>REPEAT</italic>, which indicated whether the current trial repeated the choice from the previous trial featuring the same bandit-pair (repeated choice=1, non-repeated choice=0). We included the following regressors: <italic>FEEDBACK</italic> coding the valence of feedback in the previous trial with the same bandit pair (positive=0.5, negative=−0.5), CONTEXT<sub>2-star</sub> indicating whether the trial immediately preceding the previous trial with the same bandit pair (context trial) featured the 2-star agent (feedback from 2-star agent=1, otherwise=0), and CONTEXT<sub>3-star</sub> indicating whether the trial immediately preceding the previous trial with the same bandit pair featured the 3-star agent. We also included a regressor (<italic>BETTER</italic>) coding whether the bandit chosen in the learning trial was the better -mostly rewarding- or the worse -mostly unrewarding- bandit within the pair. We included in this analysis only current trials where the context trial featured the same bandit pair. The model in Wilkinson’s notation was:
<disp-formula id="FD15">
<alternatives>
<mml:math id="M15" display="block"><mml:mi>R</mml:mi><mml:mi>E</mml:mi><mml:mi>P</mml:mi><mml:mi>E</mml:mi><mml:mi>A</mml:mi><mml:mi>T</mml:mi><mml:mo>∼</mml:mo><mml:mi>F</mml:mi><mml:mi>E</mml:mi><mml:mi>E</mml:mi><mml:mi>D</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mi>C</mml:mi><mml:mi>K</mml:mi><mml:mo>∗</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:mi>O</mml:mi><mml:mi>N</mml:mi><mml:mi>T</mml:mi><mml:mi>E</mml:mi><mml:mi>X</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:mi>O</mml:mi><mml:mi>N</mml:mi><mml:mi>T</mml:mi><mml:mi>E</mml:mi><mml:mi>X</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:mi>E</mml:mi><mml:mi>T</mml:mi><mml:mi>T</mml:mi><mml:mi>E</mml:mi><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="st4kgv5_eqn15.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
<label>(13)</label>
</disp-formula>
</p>
<p>In <xref ref-type="fig" rid="fig4">figure 4c</xref>, we independently calculate the repeat probability difference for the better (mostly rewarding) and worse (mostly non-rewarding) bandits and averaged across them. This calculation was done at the participants level, and finally averaged across participants.</p>
</sec>
<sec id="s4-3-6-3">
<title>Effects of agent-credibility on CA parameters from credibility-CA model</title>
<p>We used a mixed-effects linear regression model to assess whether, and how, credit assignment was modulated by feedback-agent, with participants serving as random effects (data from <xref ref-type="fig" rid="fig2">Fig. 2c</xref>). We regressed the maximal likelihood CA parameters from the credibility-CA model. The regressors AGENT<sub>2—star</sub> and AGENT<sub>3—star</sub> indicated, respectively, whether the CA parameter was attributed to the 2- star or the 3-star agent. The model’s Wilkinson’s notation was:
<disp-formula id="FD16">
<alternatives>
<mml:math id="M16" display="block"><mml:mi>C</mml:mi><mml:mi>A</mml:mi><mml:mo>∼</mml:mo><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="st4kgv5_eqn16.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
<label>(14)</label>
</disp-formula>
</p>
</sec>
<sec id="s4-3-6-4">
<title>Effects of agent-credibility and feedback valence on CA parameters from credibility-valence-CA model</title>
<p>We used a second mixed-effects linear regression model to test for a valence bias in learning, and how such bias was modulated by feedback credibility, with participants serving again as random effects (data from <xref ref-type="fig" rid="fig3">Fig. 3a</xref>). The maximal likelihood CA parameters from the credibility-valence-CA model served as the regressed variable, which was regressed on: AGENT<sub>2—star</sub> and AGENT<sub>3—star</sub> (defined in the same way as the previous model), and <italic>VALENCE</italic> coding whether the CA parameter was attributed to positive (coded as 0.5) or negative (coded as −0.5) feedback. The Wilkinson’s notation of the model was:
<disp-formula id="FD17">
<alternatives>
<mml:math id="M17" display="block"><mml:mi>C</mml:mi><mml:mi>A</mml:mi><mml:mo>∼</mml:mo><mml:mi>V</mml:mi><mml:mi>A</mml:mi><mml:mi>L</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:mi>C</mml:mi><mml:mi>E</mml:mi><mml:mo>∗</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="st4kgv5_eqn17.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
<label>(15)</label>
</disp-formula>
</p>
<p>We used a separate mixed-effects linear regression model to test how relative valence bias was modulated by feedback credibility. We first computed the relative valence bias index (rVBI) for each credibility level, and we then regressed these values on AGENT<sub>2—star</sub> and AGENT<sub>3—star</sub> (defined in the same way as the previous models).</p>
<disp-formula id="FD18">
<alternatives>
<mml:math id="M18" display="block"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi>r</mml:mi><mml:mi>V</mml:mi><mml:mi>B</mml:mi><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>C</mml:mi><mml:msup><mml:mi>A</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo>−</mml:mo><mml:mi>C</mml:mi><mml:msup><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:msup></mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:msup><mml:mi>A</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:msup><mml:mi>A</mml:mi><mml:mo>−</mml:mo></mml:msup></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>r</mml:mi><mml:mi>V</mml:mi><mml:mi>B</mml:mi><mml:mi>I</mml:mi><mml:mo>∼</mml:mo><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math>
<graphic xlink:href="st4kgv5_eqn18.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
<label>(16)</label>
</disp-formula>
</sec>
</sec>
<sec id="s4-3-7">
<title>Bayesian estimation of posterior belief that feedback is true</title>
<p>We calculated the Bayesian posterior conditional probability of feedback truthfulness (<xref ref-type="fig" rid="fig4">Fig. 4a and 4b</xref>) follows. First, we calculated the probability of each true outcome, r (0-non-reward; 1-reward) conditional on the feedback, <italic>f</italic> (0: non-reward, 1: reward), the credibility of the agent reporting the feedback (C) and the history of experiences from past trials (H):
<disp-formula id="FD19">
<alternatives>
<mml:math id="M19" display="block"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∝</mml:mo><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>    </mml:mtext><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:mo>∗</mml:mo><mml:msub><mml:mn>1</mml:mn><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>C</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:msub><mml:mn>1</mml:mn><mml:mrow><mml:mi>f</mml:mi><mml:mo>≠</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover><mml:mo>∗</mml:mo><mml:msub><mml:mn>1</mml:mn><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:msub><mml:mn>1</mml:mn><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math>
<graphic xlink:href="st4kgv5_eqn19.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
<label>(17)</label>
</disp-formula>
</p>
<p>Where proportionality omits terms independent of <italic>r</italic>, <inline-formula id="ID1">
<alternatives>
<mml:math display="inline" id="I1">
<mml:mrow><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mn>1</mml:mn></mml:msubsup><mml:mrow><mml:mi>p</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>|</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math>
<inline-graphic xlink:href="st4kgv5_ieq1.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
</inline-formula> is the expected probability of the chosen bandit is rewarding (conditional on past-trial history), and <italic>g(p|H)</italic> is the density over the probability (the chosen bandit) is rewarded (conditional on the history of previous trials).</p>
<p>Next, we normalized the two terms (for <italic>r</italic>=0,1) to sum to 1 (to correct for the proportionality in (<xref ref-type="bibr" rid="c14">14</xref>)). Finally, the posterior belief in truthfulness was taken as <italic>Prob(r=f|f,C,H)</italic>.</p>
<p>In <xref ref-type="fig" rid="fig4">Fig. 4b</xref>, we calculated for each participant the mean posterior belief of truthfulness separately for trials where each agents told the truth or lied, and we compared these mean beliefs between the two kinds of trials using a paired t-tests (one test per agent).</p>
</sec>
</sec>
</sec>
</body>
<back>
<sec id="s6">
<title>Supplementary Information</title>
<sec id="s6-1">
<label>1.</label>
<title>Discovery Study</title>
<sec id="s6-1-1">
<label>1.1</label>
<title>Methods</title>
<p>The methods in our discovery study were similar to the ones in our main study. Here we specify only the methodological differences between the two studies.</p>
<sec id="s6-1-1-1">
<label>1.1.1</label>
<title>Participants, general protocol and exclusions</title>
<p>We recruited 111 participants (mean age 36.23± 11.26, 50 female) from the Prolific participant pool (<ext-link ext-link-type="uri" xlink:href="http://www.prolific.co">www.prolific.co</ext-link>) who performed the task in the Gorilla platform <sup><xref ref-type="bibr" rid="c83">83</xref></sup>. All participants were fluent English speakers with normal or corrected-to-normal vision and a Prolific approval rate of 95% or higher. The UCL Research Ethics Committee approved the study (Project ID 6649/004), and all participants provided informed consent before the experiment.</p>
<p>The participants took on average 60 minutes to complete the experiment. They received a fixed compensation of 6 GBP and variable compensation between 0 and 2 GBP based on their performance on the disinformation task.</p>
<p>Based on the same exclusion criteria from the main task, 7 participants were excluded, while 104 participants were kept for the analyses.</p>
</sec>
<sec id="s6-1-1-2">
<label>1.1.2</label>
<title>Task differences between discovery study and main study</title>
<p>In the discovery study participants also completed a traditional version of the two-armed bandit task. The task was like the one in the main study, but each block featured a single bandit pair. Participants completed 6 blocks in total (of 16 trials each), 3 before the disinformation task and 3 right after.</p>
<p>The disinformation task in the discovery study worked as the one in the main study, but with a three main differences. Firstly, it included 4 feedback agents, with credibilities of 50%, 70%, 85% and 100%, represented by 1, 2, 3, and 4 stars, respectively (<xref ref-type="fig" rid="figS1">Fig. S1a</xref>). Each experimental block consisted of a single bandit pair, presented over 16 trials (with 4 trials for each feedback agent). Participants completed a total of 15 blocks: in 5 of them the bandits had 25% and 75% probability; while in the remaining 10 blocks, the two bandits within a pair were equally rewarding, with a reward probability randomly sampled between 60 and 80%.</p>
<p>At the end of the experiment, a subset of participants (n=79) completed eight standard self-report questionnaires: 1) the Obsessional Compulsive Inventory - Revised (OCI-R)<sup><xref ref-type="bibr" rid="c84">84</xref></sup>, assessing symptoms of obsessive-compulsive disorder (OCD); 2) The Revised Green et al. Paranoid Thoughts Scale (R-GPTS) <sup><xref ref-type="bibr" rid="c85">85</xref></sup>, measuring paranoid ideations; 3) the DOG scale<sup><xref ref-type="bibr" rid="c86">86</xref></sup>, evaluating dogmatism; 4) the autism-spectrum quotient (AQ)<sup><xref ref-type="bibr" rid="c90">90</xref></sup>, assessing symptoms of autism spectrum disorder; 5)the Adult ADHD Self-Report Scale (ASRS)<sup><xref ref-type="bibr" rid="c91">91</xref></sup>, for attention-deficit/hyperactivity disorder; 6) the GAD-7 scale<sup><xref ref-type="bibr" rid="c92">92</xref></sup> for generalized anxiety disorder; 7) the self-rating depression scale (SDS)<sup><xref ref-type="bibr" rid="c93">93</xref></sup>; and 8) and the Barratt Impulsiveness scale (BIS) for impulsivity<sup><xref ref-type="bibr" rid="c94">94</xref></sup>.</p>
</sec>
<sec id="s6-1-1-3">
<label>1.1.3</label>
<title>Computational models</title>
<sec id="s6-1-1-3-1">
<title>RL Models</title>
<p>The RL models in the discovery task were analogous to the ones in the main task but included extra free CA parameters to accommodate the use of 4 (instead of 3) feedback agents.</p>
<table-wrap id="tblS1" position="float" orientation="portrait">
<label>Table 1:</label>
<caption><title>summary of free parameters for each of the CA models.</title></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl2.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#F2F2F2">
<th align="center" valign="top">Model</th>
<th align="center" valign="top">Free CA parameter</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#F2F2F2"><bold>Null</bold></td>
<td align="center" valign="top"><italic>CA</italic></td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#F2F2F2"><bold>Credibility-CA</bold></td>
<td align="center" valign="top"><italic>CA</italic><sub>0.5</sub>, <italic>CA</italic><sub>0.7</sub>, <italic>CA</italic><sub>0.85</sub>, <italic>CA</italic><sub>1</sub></td>
</tr>
<tr>
<td align="center" valign="middle" style="background-color:#F2F2F2"><bold>Credibility-Valence-CA</bold></td>
<td align="center" valign="top"><italic>CA</italic><sub>0.5</sub>+, <italic>CA</italic><sub>0.7</sub>+,<italic>CA</italic><sub>0.85</sub>+<italic>CA</italic><sub>1</sub>+
<break/><italic>CA</italic><sub>0.5</sub>−,<italic>CA</italic><sub>0.7</sub>−, <italic>CA</italic><sub>0.85</sub>−, <italic>CA</italic><sub>1</sub>−</td>
</tr>
<tr>
<td align="center" valign="middle" style="background-color:#F2F2F2"><bold>constant feedback 
<break/> valence bias CA</bold></td>
<td align="center" valign="top"><italic>VB</italic>
<break/><italic>CA</italic><sub>0.5</sub>−, <italic>CA</italic><sub>0.7</sub>−, <italic>CA</italic><sub>0.85</sub>−, <italic>CA</italic><sub>1</sub>−</td>
</tr>
<tr>
<td align="center" valign="middle" style="background-color:#F2F2F2"><bold>Truth-CA</bold></td>
<td align="center" valign="top"><italic>TB</italic>
<break/><italic>CA</italic><sub>0.5</sub>,<italic>CA</italic><sub>0.7</sub>, <italic>CA</italic><sub>0.85</sub>, <italic>CA</italic><sub>1</sub></td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
<sec id="s6-1-1-3-2">
<title>Bayesian Models</title>
<p>The Bayesian models in the discovery study worked like the one in the main study. In the <italic>free-credibility Bayesian model</italic>, we fixed the 4-star agent credibility to 1 but estimated the credibility of the three lying agents as free parameters.</p>
</sec>
</sec>
<sec id="s6-1-1-4">
<label>1.1.4</label>
<title>Mixed effects models</title>
<p>The mixed-effects models in our discovery study used the same regressors as in our main study, replacing (AGENT<sub>2-star</sub> + AGENT<sub>3-star</sub>) with (AGENT<sub>2-star</sub> + AGENT<sub>3-star</sub> + AGENT<sub>4-star</sub>) to account for the fact that the task featured four (instead of three agents). Moreover, when regressing the CA parameters from truth-CA model on agent-credibility and feedback truthfulness, we replaced the regressor <italic>CREDIBILITY</italic> with regressors indicating the presence/absence of the 2-star and 3-star agents (AGENT<sub>2- star</sub> + AGENT<sub>3-star</sub>).</p>
</sec>
</sec>
<sec id="s6-1-2" sec-type="results">
<label>1.2</label>
<title>Results</title>
<sec id="s6-1-2-1">
<label>1.2.1</label>
<title>Credible feedback promotes greater learning</title>
<p>To test whether participants modulated their learning based on feedback credibility, we regressed in a binomial mixed-effects model, choice-repetition, on feedback-valence (negative or positive) and the agent-credibility (1,2,3 or 4-star) from the last trial (<xref ref-type="fig" rid="figS2">Fig. S2a</xref>) (see <xref ref-type="section" rid="s6-1-1-3">SI 1.1.3</xref> for full model description). Consistent with findings in the main task, we found that feedback valence exerted a positive effect on choice-repetition (b=1.02, F(1,2462)=617.38, p&lt;0.001), and it interacted with agent-credibility (F(3,2462)=196.61, p&lt;0.001), such that, the feedback effect was larger for more credible agents (4- star vs. 3-star: b=1.21, F(1,2462)=137.71; 4-star vs. 2-star: b=0.47, F(1,2462)=322.88; 4-star vs. 1-star: b= 2.55, t(2462)=22.91; 3-star vs. 2-star: =2.03, F(1,2462)=40.54; 3-star vs. 1-star: b=1.24, t(2462)=11.25; and 2-star vs. 1-star: b=0.52, t(2462)=4.74, all p’s&lt;0.001). Additionally, we found a positive feedback-effect for the 4-star agent (b=2.46, F(1,2462)= 911.81, p&lt;0.001), a smaller feedbackeffect for the 3-star agent (b=1.15, F(1,2462)=206.19, p&lt;0.001), and an even smaller feedback-effect for the 2-star agent (b=2.03, F(1,2462)=40.54, p&lt;0.001). Such increased learning as a function of feedback credibility was predicted by simulations based on the instructed-credibility Bayesian, free-credibility Bayesian and credibility-CA models, but not by the null-CA model (<xref ref-type="fig" rid="figS2">Fig. S2b</xref>).</p>
<p>We next examined how the Maximum Likelihood (ML) CA parameters from the credibility-CA model differed as a function of feedback credibility (<xref ref-type="fig" rid="figS2">Fig. S2c</xref>; see <xref ref-type="section" rid="s6-3-3-2">SI 3.3.2</xref> for detailed ML parameter results). We regressed, using a mixed effects model (Methods and <xref ref-type="section" rid="s6-1-1-4">SI 1.1.4</xref>), the CA parameters on their associated agent, showing that CA differed across the agents (F(3,412)=98.77, p&lt;0.001), increasing as a function of agent-credibility (4-star vs. 3-star: b=0.49, F(1,412)=99.94; 4-star vs. 2-star: b=0.89, F(1,412)=330.15; 4-star vs. 1-star: b= 1.4, Ft(412)=28.5 ; 3-star vs. 2-star: b=0.4, F(1,412)=66.8; 3-star vs. 1-star: b=0.91, t(412)=18.5; and 2-star vs. 1-star: b=0.51, t(412)=10.33, all p’s&lt;0.001).</p>
<fig id="figS1" position="float" fig-type="figure">
<label>SI Figure 1:</label>
<caption><title>Task design, performance and model selection in discovery study.</title>
<p><bold>a</bold>, During the task participants received feedback from 4 feedback agents, varying in their credibility (i.e., truth-telling probability). The credibility of the agents was represented using a star-based system: the 4-star agent always reported the truth (and never lied), whereas the 3-star agent reported the truth on 85% of the trials (lying on the remaining 15%), the 2-star agent reported the truth on 70% of the trials (lying on the remaining 30%), and the 1-star agent reported the truth half of the time (lying on the other half). Participants were explicitly instructed and quizzed about the credibility of each agent prior to the task. <bold>b</bold>, Learning curve. Average choice accuracy as a function of trial number (within a bandit-pair). Thin lines: individual participants; thick line: group mean with thickness representing the group standard error of the mean for each trial. <bold>c,d</bold>, Model selection between the credibility-CA model and the two variants of Bayesian models. Most participants were best fitted by the credibility-CA model, compared to the instructed-credibility Bayesian (<bold>c</bold>) or free-credibility Bayesian (<bold>d</bold>) models.</p></caption>
<graphic xlink:href="st4kgv5_fig7.tif" mime-subtype="tif" mimetype="image"/>
</fig>
</sec>
<sec id="s6-1-2-2">
<label>1.2.2</label>
<title>Substantial deviations from Bayesian Learning</title>
<p>Model comparisons between each of the Bayesian models and the credibility-CA revealed that the credibility-CA model provided a superior fit for 80.8% of participants (sign test; z=6.17, p&lt;0.001) when compared to the instructed-credibility Bayesian model (<xref ref-type="fig" rid="figS1">Fig. S1c</xref>), and for 60.6% (z=2.06, p= 0.03) when compared with the free-credibility Bayesian model (<xref ref-type="fig" rid="figS1">Fig. S1d</xref>). In line with the main study, this suggests most of the participants deviated from normative learning.</p>
<p>The Bayesian-CA parameters revealed that both the instructed-credibility and free-credibility Bayesian models predicted increased Bayesian-CA parameters as a function of agent credibility (<xref ref-type="fig" rid="figS2">Fig. S2c</xref>; See <xref ref-type="section" rid="s6-3-1-2-2">SI 3.1.2.2</xref>). We next test whether the different deviations from normative Bayesian learning that we described in the main study are still present in the discovery study.</p>
</sec>
<sec id="s6-1-2-3">
<label>1.2.3</label>
<title>The effect of non-credible feedback and learning</title>
<p>In the main study, we found evidence supporting the idea that participants update their beliefs based on random feedback (a positive feedback effect for the 1-star agent on choice-repetition and a positive CA parameter). However, corresponding analyses for the discovery task revealed neither a feedbackeffect on choice-repetition (mixed effects model, b=−0.09, t(2462)=−1.21, p=0.22; <xref ref-type="fig" rid="figS2">Fig. S2a</xref>), nor positive credit-assignment (b=−0.13, t(412)=−1.07, p=0.28; <xref ref-type="fig" rid="figS2">Fig. S2c</xref>) for the 1-star agent. Moreover, based on the free-credibility Bayesian model, we found no evidence ML-estimated credibility for the 1-star agent differed from 0.5 (Wilcoxon signed-rank test, median=−0.02, z=−0.29, p=0.76; <xref ref-type="fig" rid="figS2">Fig. S2d</xref>). Importantly, we show below that feedback from this agent was not fully ignored as it still elicited a positivity bias. Incidentally, using the free-credibility Bayesian model we found the ML-estimated credibility increased as a function of instructed agent-credibility (Wilcoxon signed-rank test; 3-star vs 2-star, median=0.13, z=6.75; 3-star vs 1-star, median=0.28, z=7.45; 2-star vs 1-star, median=0.10 z=4.54; all p’s&lt;0.001), and was lower than the instructed credibility for the 2-star (median=−0.06 z=4.90, p&lt;0.001) and 3-star agents (median=−0.27, z=−4.49, p&lt;0.001). In line with the main study, this finding suggests that participants tend to underestimate the credibility of agents with intermediate levels of credibility.</p>
</sec>
<sec id="s6-1-2-4">
<label>1.2.4</label>
<title>Exaggerated learning for fully credible feedback</title>
<p>Consistent with the main study, both Bayesian models predicted an attenuated credit-assignment for the fully credible agent (Wilcoxon signed-rank test; instructed-credibility Bayesian model: median difference=0.67 z=6.70; free-credibility Bayesian model: median difference=0.26, z=4.28, all p’s&lt;0.001). We did not analyse the effects of the credibility context on learning, since this task affords no instances where the credibility context featured a separate bandit pair (because our discovery task featured a single bandit-pair per block).</p>
<fig id="figS2" position="float" fig-type="figure">
<label>SI Figure 2:</label>
<caption><title>Learning adaptations to credibility in discovery study.</title>
<p><bold>a</bold>, Probability of repeating a choice as a function of feedback-valence and agent-credibility on the previous trial with the same bandit pair. As in the main study, the effect of feedback-valence on repetition increases as feedback credibility increases, indicating that more credible feedback has a greater effect on behavior. <bold>b</bold>, Same analysis as in panel a, but for synthetic data obtained by simulating the main models. Simulations were computed using the ML parameters of participants for each model. <bold>c</bold>, ML credit assignment parameters for the credibility-CA model. Consistent with the main study, participants show a CA increase as a function of agent-credibility, as predicted by cross-fitting parameters from instructed-credibility Bayesian and free-credibility Bayesian model simulations. However, we find no evidence for a positive CA for the 1-star agent. <bold>d</bold>, ML credibility parameters for a free-credibility Bayesian model attributing credibility 1 to the 4-star agent but estimating credibility for the three lying agents as free parameters. Small dots represent results for individual participants/simulations, big circles represent the group mean (a,b,d) or median (c) of participants’ behavior. Results of the synthetic model simulations are represented by diamonds (instructed-credibility Bayesian model), squares (free-credibility Bayesian model), upward-pointing triangles (null-CA model) and downward-pointing triangles (credibility-CA model). Error bars show the standard error of the mean. (*) p&lt;.05, (**) p&lt;0.01,(***) p&lt;.001.</p></caption>
<graphic xlink:href="st4kgv5_fig8.tif" mime-subtype="tif" mimetype="image"/>
</fig>
</sec>
<sec id="s6-1-2-5">
<label>1.2.5</label>
<title>Individuals show a positivity bias in learning, particularly for sources of limited credibility</title>
<p>Next, we turned to test whether, in the discovery study, participants showed greater learning from positive (instead of negative) feedback. We regressed in a mixed-effects model the ML parameters from the credibility-valence-CA model (<xref ref-type="fig" rid="figS3">Fig. S3a</xref>; see <xref ref-type="section" rid="s6-3-3-2">SI 3.3.2</xref> for detailed ML parameter results) on their associated agent-credibility and valence (see SI Discovery study methods). As in the main study, this revealed an overall positivity bias in credit-assignment (b=0.94, F(1,824)=42.60, p&lt;0.001). Furthermore, participants assigned negative credit based on negative feedback from the 1-star agent (b=−0.51, F(1,824)=3.89, p=0.049), and positive credit based on positive feedback from the same agent (b=0.42, F(1,824)=5.74, p=0.017). Critically, this suggests that in agreement with conclusions from the main task, participants do not ignore random feedback. Instead, at the group level, both negative and positive feedback from the 1-star agent led to a value increase of the selected bandit. Participants selectively assigned positive credit to positive feedback from the 2-star agent (b=1.25, F(1,824)=16.34, p&lt;0.001), with no evidence for CA based on negative feedback (b=−0.34, F(1,824)=−2.53, p=0.11). For the 3-star and 4-star agents, credit-assignment was positive for both positive (3-star: b=2.28, F(1,824)=71.28; 4-star: b=2.91, F(1,824)=183.22; p&lt;0.001) and negative (3-star: b=0.86, F(1,824)=37.77; 4-star: b=2.60, F(1,824)=146.55; p&lt;0.001) feedback.</p>
<p>In line with the main task, free-credibility Bayesian-CA parameters revealed a <italic>negativity</italic> bias (b=-0.71, F(1,824)=49.8, p&lt;0.001; <xref ref-type="fig" rid="figS3">Fig. S3a</xref>), and lower absolute valence bias indices than the ones from participants for all credibility levels (<xref ref-type="fig" rid="figS3">Fig. S3b</xref>) [Wilcoxon signed-rank test, 50% credibility (median difference=1.43, z=3.99, p&lt;0.001), 70% credibility (median difference=1.70, z=5.44, p&lt;0.001), 85% credibility (median difference=1.59, z=4.78, p&lt;0.001) and 100% credibility (median difference=1.06, z=3.06, p=0.002)]. Results supporting the same conclusions were observed for instructed-credibility Bayesian-CA parameters (See <xref ref-type="section" rid="s6-3-1-2-3">SI 3.1.2.3</xref> and <xref ref-type="section" rid="s6-3-2-2-1">3.2.2.1</xref>). These results confirm that the detected positivity bias represent a departure from normative Bayesian learning.</p>
<p>In the main study, we found no group-level evidence positivity-bias was modulated by agentcredibility in absolute terms. However, in the discovery study, the mixed effects regressing the credibility-valence-CA model parameters (<xref ref-type="fig" rid="figS3">Fig. S3a-b</xref>) revealed a significant interaction effect between feedback valence and credibility on CA (F(3,824)=3.28 p=0.02), such that the valence effect for the 2- star agent was larger than the one for the 4-star gent (b=1.29, F(1, 824)=9.84, p=0.002), with no significant valence effect difference between other agent pairs (see SI Supplementary statistics 4.3 <xref ref-type="table" rid="tblS30">Table 30</xref>). Moreover, while the valence effect for the lying agents was significantly positive (1-star: b=0.94, t(824)=3.24, p&lt;0.001; 2-star: b=1.60, F(1, 824)=30.21, p=0.001; 3-star: b=0.94, F(1, 824)=10.63, p=0.001), we found no evidence for a positivity bias for the 4-star agent (b=0.31, F(1, 824)=1.12, p=0.29). In contrast, we found no evidence for an interaction between feedback valence and credibility based on free-credibility Bayesian-CA (<xref ref-type="fig" rid="figS3">Fig. S3b</xref>; F(3,824)=0.11 p=0.95) and instructed-credibility Bayesian-CA (F(3,824)=0.25 p=0.85) parameters. These results suggest that participants show a heightened positivity bias (measured in absolute terms) in response to low-credibility feedback.</p>
<p>The positivity bias measured relative to the overall extent of learning (i.e., the rVBI) was significantly positive for low-credibility feedback [50% credibility (b=0.35, t(412)=5.58), 70% credibility (b=0.45, F(1,412)=51.44), 85% credibility (b=0.28, F(1,412)=20.12), all p’s&lt;0.001] (<xref ref-type="fig" rid="figS3">Fig. S3c</xref>). However, we found no evidence for positive rVBI for the fully credible agent (b=0.03, F(1,412)=0.25, p=0.62). Moreover, in line with the main study, we found that the rVBI varied depending on the credibility of feedback (F(3,412)=12.33, p&lt;0.001), such that the rVBI for 4-star agent was lower than the one for any of the low-credibility agents [50% credibility (b=−0.32, t(412)=−4.44), 70% credibility (b=−0.42, F(1,412)=33.88), 85% credibility (b=−0.25, F(1,412)=12.1), all p’s&lt;0.001]. The rVBI for 70% credibility agent was higher than the one for the 85% credibility agent (b=−0.17, F(1,412)=5.49, p=0.019). Feedback with 50% credibility yielded similar rVBI values to feedback with and 70% (b=0.10, t(412)=1.39, p=0.17) or 85% credibility (b=−0.07, t(412)=−0.96, p=0.34). Notably, our rVBI results were not predicted by either the free-credibility Bayesian-CA (<xref ref-type="fig" rid="figS3">Fig. S3c</xref>) and instructed-credibility Bayesian-CA parameters (see <xref ref-type="section" rid="s6-3-2-2-2">SI 3.2.2.2</xref>), nor by a pure choice-perseveration account (see <xref ref-type="section" rid="s6-3-6-2">SI 3.6.2</xref>). These results support the same conclusion from the main study, suggesting that positivity bias, relative to the overall extent of CA, is higher for lying, compared to fully-credible, agents.</p>
<fig id="figS3" position="float" fig-type="figure">
<label>SI Figure 3:</label>
<caption><title>Positivity bias as a function of agent-credibility in the discovery study.</title>
<p><bold>a</bold>, Maximum likelihood parameters from the credibility-valence-CA model. CA+ and CA− are free parameters representing credit assignments for positive and negative feedback respectively (for each credibility level). The data revealed a positivity bias (CA+ &gt; CA−) for feedback of low-credibility, but not for fully credible feedback. <bold>b</bold>, Absolute valence bias index (defined as CA<sup>+</sup>-CA<sup>−</sup>) based on the ML parameters from the credibility-valence CA model. Positive values indicate a positivity bias, while negative values represent a negativity bias. <bold>c</bold>, Relative valence bias index (rVBI, defined as (CA<sup>+</sup>-CA<sup>−</sup>)/(|CA<sup>+</sup>|+|CA<sup>−</sup>|)) based on the ML parameters from the credibility-valence CA model. Positive values indicate a positivity bias, while negative values represent a negativity bias. Small dots represent fitted parameters for individual participants and big circles represent the group median (a,b) or mean (c) (both of participants’ behavior), while squares are the median or mean of the fitted parameters of the free-credibility Bayesian model simulations. Error bars show the standard error of the mean. (**) p&lt;.01, (***) p&lt;.001 for ML fits of participants behavior.</p></caption>
<graphic xlink:href="st4kgv5_fig9.tif" mime-subtype="tif" mimetype="image"/>
</fig>
</sec>
<sec id="s6-1-2-6">
<label>1.2.6</label>
<title>True feedback elicits greater learning</title>
<p>We next assessed whether participants infer whether the feedback they received on each trial was true or false and adjust their credit assignment based on this inference. We again used the “Truth-CA” model to obtain estimates for the truth bonus (<italic>TB</italic>), the increase in credit assignment as a function of the posterior probability of feedback being true. As in our main study, the fitted truth bias parameter was significantly positive, indicating that participants assign greater weight to feedback they believe is likely to be true (<xref ref-type="fig" rid="figS4">Fig, S4a</xref>; see <xref ref-type="section" rid="s6-3-3-1">SI 3.3.1</xref> for detailed ML parameter results). Strikingly, modelsimulations (Methods) predicted a lower truth bonus than the one observed in participants (<xref ref-type="fig" rid="figS4">Fig. S4b</xref>).</p>
<fig id="figS4" position="float" fig-type="figure">
<label>SI Figure 4:</label>
<caption><title>Credit assignment is enhanced for feedback inferred to be true in discovery study.</title>
<p><bold>a</bold>, Maximum likelihood (ML) estimate of the “truth-bonus” parameter derived from the “Truth-CA” model. The significantly positive truth bonus indicates that participants increased the degree to which they updated their value estimates (credit assignment) when they inferred a higher probability that the feedback they received was true. Each small dot represents the fitted truth-bonus parameter for an individual participant, the large circle indicates the group mean, and the error bars represent the standard error of the mean. <bold>b</bold>, Distribution of truthbonus parameters predicted by synthetic simulations of our alternative computational models. For each alternative model, we generated 101 group-level synthetic datasets based on the maximum likelihood parameters fitted to the participants’ actual behavior. Each of these synthetic datasets was then independently fitted with the “Truth-CA” model. Each histogram represents the distribution of the mean truth bonus across the 101 simulated datasets for a specific alternative model. Notably, the truth bonus observed in our participants was significantly higher than the truth bonus predicted by any of these alternative models (proportion of datasets predicting a higher truth bonus = 0 for all models). (***) p&lt;.001</p></caption>
<graphic xlink:href="st4kgv5_fig10.tif" mime-subtype="tif" mimetype="image"/>
</fig>
</sec>
</sec>
</sec>
<sec id="s6-2">
<label>2.</label>
<title>Additional Supplementary Figures</title>
<fig id="figS5" position="float" fig-type="figure">
<label>SI Figure 5:</label>
<caption><title>Illustration of computational models over 15 trials with an example bandit-pair.</title>
<p><bold>a</bold>, Example block with a bandit pair. The top bandit provided true rewards 75% of the time, while the bottom bandit did so 25% of the time. The agent providing feedback on each trial is represented above the plot, while the feedback is depicted in the horizontal line of the bandit selected for that trial. Dollar signs represent positive feedback, while sad emojis represent negative feedback. <bold>b</bold>, Values of the two bandits computed based on credibility-CA model. The values are represented as a point estimates (i.e., Q-values). On each trial, the Q-value of the selected bandit is updated based on the feedback valence and credibility. Values correspond to ends of trials following credit-assignment. <bold>c</bold>, Posterior beliefs about the true reward probabilities of the bandits, computed using the instructed-credibility Bayesian model. The x-axis in each subplot represents the probability of a true reward (p), while the y-axis represents the density distribution of such true reward probability (g(p)). On each trial, the density distribution g(p) of the selected bandit is updated based on the feedback valence and credibility. Both <bold>b</bold> and <bold>c</bold> were generated with the mean ML parameters from participants fitted with the CA-credibility and instructed-credibility Bayesian models respectively.</p></caption>
<graphic xlink:href="st4kgv5_fig11.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<fig id="figS6" position="float" fig-type="figure">
<label>SI Figure 6:</label>
<caption><title>Model comparison between Bayesian models and credibility-CA model for main study.</title>
<p><bold>a</bold>, Histograms of log-likelihood improvements for three example participants. For each participant, we generated 201 simulations based on their ML parameters for each model variant (i.e., the Bayesian model and the CA model). We fitted each dataset with the two models and calculated the log-likelihood difference between the two fits for each dataset (CA fit - Bayesian fit), resulting in two log-likelihood difference distributions: one for the dataset based on Bayesian simulations (grey) and another for the dataset based on CA simulations (blue). A greater value along the x-axis indicates that a dataset was better fitted with the CA model compared to the Bayesian model. We determined a log-likelihood difference threshold that leads to the best model classification (i.e., maximizing the average of true positives and true negatives), represented by a red line in the plots. Finally, we fitted the empirical data of each participant with the two model variants, calculating an empirical loglikelihood difference, represented as a black dashed line in the plots. The three example plots correspond to participants with different model classification accuracy (i.e., proportion of true positives and true negatives) and different model classifications, both stated above each subplot. <bold>b</bold>, Distribution of model classification accuracy for the model comparison between the instructed-credibility Bayesian and credibility-CA models. A greater average of TP and TN represents a better discrimination between the models. <bold>c</bold>, Distribution of model classification accuracy for the model comparison between the free-credibility Bayesian and credibility-CA models. Vertical orange lines represent the mean classification accuracy for each model comparison.</p></caption>
<graphic xlink:href="st4kgv5_fig12.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<fig id="figS7" position="float" fig-type="figure">
<label>SI Figure 7:</label>
<caption><title>Effects of CA for the 1-star and 3-star agents on accuracy.</title>
<p><bold>a</bold>, Scatter plot between the absolute CA parameter for the 1-star agent in the main task (x-axes) and the predicted drop in accuracy due to CA based on random feedback (y-axes). For each participant, we generated 5000 synthetic simulations based on their ML parameters from the credibility-CA model, and another 5000 simulations using the same ML parameters but ablating CA for the 1-star agent by fixing it to 0. The difference in mean accuracy between the two datasets represents the estimated drop in accuracy for each participant due to learning from random feedback. The negative Pearson’s correlation illustrates that accuracy drop increases as a function of (absolute) credit assignment based on random feedback. Circles represent the datapoints of individual participants, lines represent the prediction from linear regression on the data with shaded areas representing the 99% confidence interval. <bold>b</bold>, Mean learning curves for different 1-star CA parameter values. We generated synthetic simulations based on the credibility-CA model ML parameters from participants but fixing the 1-star CA to different values between −2 and 5. We generated 100 synthetic simulations per participant for each 1-star CA value and averaged across participants. As (absolute) CA attributed to random feedback diverges from 0 (with all other parameters held invariant), accuracy decreases. <bold>c</bold>, For comparison with b we show the mean learning curves for different 3- star CA values, calculated in the same way but fixing the 3-star CA to different values. Here, accuracy increases with the CA attributed to fully credible.</p></caption>
<graphic xlink:href="st4kgv5_fig13.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<fig id="figS8" position="float" fig-type="figure">
<label>SI Figure 8:</label>
<caption><title>Positivity bias as a function of agent-credibility compared with instructed-credibility Bayesian-CA parameters in the main study.</title>
<p><bold>a</bold>, ML parameters from the credibility-valence-CA model. CA+ and CA− are free parameters representing credit assignments for positive and negative feedback respectively (for each credibility level). Empirical-CA parameters revealed a positivity bias (CA+ &gt; CA−) for all credibility levels, while instructed-credibility Bayesian-CA parameters revealed a negativity bias. <bold>b</bold>, Absolute valence bias index (defined as CA<sup>+</sup>-CA<sup>−</sup>) based on the ML parameters from the credibility-valence CA model. Positive values indicate a positivity bias, while negative values represent a negativity bias. <bold>c</bold>, Relative valence bias index (rVBI, defined as (CA<sup>+</sup>-CA<sup>−</sup>)/(|CA<sup>+</sup>|+|CA<sup>−</sup>|)) based on the ML parameters from the credibility-valence CA model. Positive values indicate a positivity bias, while negative values represent a negativity bias. Small dots represent fitted parameters for individual participants and big circles represent the group median (a,b) or mean (c) (both of participants’ behaviour), while diamonds are the median or mean of the fitted parameters of the instructed-credibility Bayesian model simulations. Error bars show the standard error of the mean. (***) p&lt;.001 for ML fits of participants behaviour.</p></caption>
<graphic xlink:href="st4kgv5_fig14.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<fig id="figS9" position="float" fig-type="figure">
<label>SI Figure 9:</label>
<caption><title>Posterior-truthfulness belief as a function of objective feedback truthfulness based on distorted credibilities from free-credibility Bayesian model fits.</title>
<p><bold>a</bold>, Main study distributions of posterior truthfulness belief probability that feedback is true calculated separately for each agent (1 or 2 star) and objective feedback-truthfulness (true or lie). These probabilities are based on the ML credibilities from the free-credibility Bayesian model fits for each participant. The probabilities are computed based on trial-sequences and feedback participants experienced, revealing that belief probabilities that feedback is true are higher in truth compared to lie trials, even if participants attribute distorted feedback-credibilities. For illustration, plotted distributions pool trials across participants. The black line within each box represents the median, upper and lower bounds represent the third and first quartile respectively. The width of each half-violin plot corresponds to the frequency of each posterior belief value among all trials for a given condition. <bold>b</bold>, Same as in a, but for discovery study.</p></caption>
<graphic xlink:href="st4kgv5_fig15.tif" mime-subtype="tif" mimetype="image"/>
</fig>
</sec>
<sec id="s6-3">
<label>3.</label>
<title>Supplementary Statistics</title>
<sec id="s6-3-1">
<label>3.1.</label>
<title>Mixed-effects model results</title>
<sec id="s6-3-1-1">
<label>3.1.1</label>
<title>Main study</title>
<sec id="s6-3-1-1-1">
<label>3.1.1.1</label>
<title>Choice repetition and feedback credibility</title>
<p>In this section we provide full result tables for mixed effects models used in the sections “Credible feedback promotes greater learning” and “Non-credible feedback elicits learning”; and figures <xref ref-type="fig" rid="fig3">3a and 3b</xref>. The Wilkinson’s notation of the model is:
<disp-formula id="FD20">
<alternatives>
<mml:math id="M20" display="block"><mml:mi>R</mml:mi><mml:mi>E</mml:mi><mml:mi>P</mml:mi><mml:mi>E</mml:mi><mml:mi>A</mml:mi><mml:mi>T</mml:mi><mml:mo>∼</mml:mo><mml:mi>F</mml:mi><mml:mi>E</mml:mi><mml:mi>E</mml:mi><mml:mi>D</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mi>C</mml:mi><mml:mi>K</mml:mi><mml:mo>∗</mml:mo><mml:mi>B</mml:mi><mml:mi>E</mml:mi><mml:mi>T</mml:mi><mml:mi>T</mml:mi><mml:mi>E</mml:mi><mml:mi>R</mml:mi><mml:mo>∗</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="st4kgv5_eqn20.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
</disp-formula>
</p>
<table-wrap id="tblS2" position="float" orientation="portrait">
<label>Table 2:</label>
<caption><title>Mixed-effects binomial regression model regressing choice-repetition on feedback-valence, agent-credibility and better/worse choice from previous trial featuring the same bandit pair.</title><p>Based on participants’ data. Feedback effect increased as a function of agent-credibility (3-star vs. 2-star: b=0.91, F(1,2436)=351.17; 3-star vs. 1-star: b=1.15, t(2436)=24.02; and 2-star vs. 1-star: b=0.24, t(2436)=5.34, all p’s&lt;0.001). Feedback valence exerted a positive effect for the 1-star agent (b=0.25, t(2436)=8.05, p&lt;0.001).</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl3.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top" colspan="8">PARTICIPANTS DATA</th>
</tr>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top">Name</th>
<th align="center" valign="top">Estimate</th>
<th align="center" valign="top">SE</th>
<th align="center" valign="top">tStat</th>
<th align="center" valign="top">DF</th>
<th align="center" valign="top">pValue</th>
<th align="center" valign="top">Lower</th>
<th align="center" valign="top">Upper</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>(Intercept)</bold></td>
<td align="center" valign="top">0.99</td>
<td align="center" valign="top">0.04</td>
<td align="center" valign="top">25.27</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">0.92</td>
<td align="center" valign="top">1.07</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>FEEDBACK</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.25</td>
<td align="center" valign="top">0.03</td>
<td align="center" valign="top">8.05</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">0.19</td>
<td align="center" valign="top">0.31</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>BETTER</bold></td>
<td align="center" valign="top">0.58</td>
<td align="center" valign="top">0.03</td>
<td align="center" valign="top">18.41</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">0.51</td>
<td align="center" valign="top">0.64</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(2-STAR)</bold></td>
<td align="center" valign="top">0.01</td>
<td align="center" valign="top">0.02</td>
<td align="center" valign="top">0.48</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">0.62</td>
<td align="center" valign="top">−0.03</td>
<td align="center" valign="top">0.05</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(3-STAR)</bold></td>
<td align="center" valign="top">−0.13</td>
<td align="center" valign="top">0.02</td>
<td align="center" valign="top">−5.43</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">−0.18</td>
<td align="center" valign="top">−0.08</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>FEEDBACK:BETTER</bold></td>
<td align="center" valign="top">−0.02</td>
<td align="center" valign="top">0.06</td>
<td align="center" valign="top">−0.25</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">0.8</td>
<td align="center" valign="top">−0.14</td>
<td align="center" valign="top">0.11</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>FEEDBACK:AGENT(2-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.24</td>
<td align="center" valign="top">0.04</td>
<td align="center" valign="top">5.34</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">0.15</td>
<td align="center" valign="top">0.33</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>BETTER:AGENT(2-STAR)</bold></td>
<td align="center" valign="top">−0.07</td>
<td align="center" valign="top">0.04</td>
<td align="center" valign="top">−1.63</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">0.1</td>
<td align="center" valign="top">−0.16</td>
<td align="center" valign="top">0.01</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>FEEDBACK:AGENT(3-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">1.16</td>
<td align="center" valign="top">0.05</td>
<td align="center" valign="top">24.02</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">1.06</td>
<td align="center" valign="top">1.25</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>BETTER:AGENT(3-STAR)</bold></td>
<td align="center" valign="top">−0.13</td>
<td align="center" valign="top">0.05</td>
<td align="center" valign="top">−2.73</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">−0.23</td>
<td align="center" valign="top">−0.04</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>FEEDBACK:BETTER:AGENT(2-STAR)</bold></td>
<td align="center" valign="top">0.07</td>
<td align="center" valign="top">0.09</td>
<td align="center" valign="top">0.82</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">0.42</td>
<td align="center" valign="top">−0.1</td>
<td align="center" valign="top">0.25</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>FEEDBACK:BETTER:AGENT(3-STAR)</bold></td>
<td align="center" valign="top">0.07</td>
<td align="center" valign="top">0.1</td>
<td align="center" valign="top">0.71</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">0.48</td>
<td align="center" valign="top">−0.12</td>
<td align="center" valign="top">0.26</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8"><bold>Any interaction between FEEDBACK and AGENT:</bold> F(2,2436)=307.11, p&lt;0.001</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8" style="background-color:#d9e2f3"><bold>FEEDBACK:AGENT(3-STAR) vs FEEDBACK:AGENT(2-STAR)</bold>: b= 0.91, F(1,2436)=351.17, p&lt;0.001</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<table-wrap id="tblS3" position="float" orientation="portrait">
<label>Table 3:</label>
<caption><title>Mixed-effects binomial regression model regressing choice-repetition on feedback-valence, agent-credibility and better/worse choice from previous trial featuring the same bandit pair.</title>
<p>Based on instructed-credibility Bayesian model simulations. Feedback effect increased as a function of agent-credibility (3-star vs. 2-star: b=0.47, F(1,2436)=581.93; 3-star vs. 1-star: b=0.86, t(2436)=44.52; and 2-star vs. 1-star: b=0.39, t(2436)=21.22, all p’s&lt;0.001). Feedback valence did not exert a positive effect for the 1-star agent (b=−0.01, t(2436)=−0.41, p=0.68).</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl4.tif" mime-subtype="tif" mimetype="image"/>
<graphic xlink:href="st4kgv5_tbl5.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top" colspan="8">INSTRUCTED-CREDIBILITY BAYESIAN MODEL</th>
</tr>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top">Name</th>
<th align="center" valign="top">Estimate</th>
<th align="center" valign="top">SE</th>
<th align="center" valign="top">tStat</th>
<th align="center" valign="top">DF</th>
<th align="center" valign="top">pValue</th>
<th align="center" valign="top">Lower</th>
<th align="center" valign="top">Upper</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>(Intercept)</bold></td>
<td align="center" valign="top">0.33</td>
<td align="center" valign="top">0.02</td>
<td align="center" valign="top">15.06</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">0.28</td>
<td align="center" valign="top">0.37</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>FEEDBACK</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">−0.01</td>
<td align="center" valign="top">0.01</td>
<td align="center" valign="top">−0.41</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.68</td>
<td align="center" valign="top">−0.03</td>
<td align="center" valign="top">0.02</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>BETTER</bold></td>
<td align="center" valign="top">0.84</td>
<td align="center" valign="top">0.01</td>
<td align="center" valign="top">65.92</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">0.81</td>
<td align="center" valign="top">0.86</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(2-STAR)</bold></td>
<td align="center" valign="top">−0.03</td>
<td align="center" valign="top">0.01</td>
<td align="center" valign="top">−3.45</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">−0.05</td>
<td align="center" valign="top">−0.01</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(3-STAR)</bold></td>
<td align="center" valign="top">−0.07</td>
<td align="center" valign="top">0.01</td>
<td align="center" valign="top">−6.9</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">−0.09</td>
<td align="center" valign="top">−0.05</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>FEEDBACK:BETTER</bold></td>
<td align="center" valign="top">0.03</td>
<td align="center" valign="top">0.03</td>
<td align="center" valign="top">1.27</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">0.2</td>
<td align="center" valign="top">−0.02</td>
<td align="center" valign="top">0.08</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>FEEDBACK:AGENT(2-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.39</td>
<td align="center" valign="top">0.02</td>
<td align="center" valign="top">21.22</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">0.35</td>
<td align="center" valign="top">0.42</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>BETTER:AGENT(2-STAR)</bold></td>
<td align="center" valign="top">−0.02</td>
<td align="center" valign="top">0.02</td>
<td align="center" valign="top">−0.98</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">0.33</td>
<td align="center" valign="top">−0.05</td>
<td align="center" valign="top">0.02</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>FEEDBACK:AGENT(3-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.86</td>
<td align="center" valign="top">0.02</td>
<td align="center" valign="top">44.52</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">0.82</td>
<td align="center" valign="top">0.9</td>
</tr>
<tr>
<td align="center" valign="top"><bold>BETTER:AGENT(3-STAR)</bold></td>
<td align="center" valign="top">−0.13</td>
<td align="center" valign="top">0.02</td>
<td align="center" valign="top">−6.75</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">−0.17</td>
<td align="center" valign="top">−0.09</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>FEEDBACK:BETTER:AGENT(2-STAR)</bold></td>
<td align="center" valign="top">−0.07</td>
<td align="center" valign="top">0.04</td>
<td align="center" valign="top">−1.94</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">0.052</td>
<td align="center" valign="top">−0.14</td>
<td align="center" valign="top">0.0007</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>FEEDBACK:BETTER:AGENT(3-STAR)</bold></td>
<td align="center" valign="top">0.004</td>
<td align="center" valign="top">0.04</td>
<td align="center" valign="top">0.1</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">0.92</td>
<td align="center" valign="top">−0.07</td>
<td align="center" valign="top">0.08</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8"><bold>Any interaction between FEEDBACK and AGENT:</bold> F(2,2436)=991.54, p&lt;0.001</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8" style="background-color:#d9e2f3"><bold>FEEDBACK:AGENT(3-STAR) vs FEEDBACK:AGENT(2-STAR)</bold>: b=0.47, F(1,2436)=581.93, p&lt;0.001</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<table-wrap id="tblS4" position="float" orientation="portrait">
<label>Table 4:</label>
<caption><title>Mixed-effects binomial regression model regressing choice-repetition on feedback-valence, agent-credibility and better/worse choice from previous trial featuring the same bandit pair.</title>
<p>Based on Free-credibility Bayesian model simulations. Feedback effect increased as a function of agentcredibility (3-star vs. 2-star: b=0.70, F(1,2436)=1268.1; 3-star vs. 1-star: b=0.85, t(2436)=43.63; and 2- star vs. 1-star: b=0.15, t(2436)=7.99, all p’s&lt;0.001). Feedback valence exerted a positive effect for the 1-star agent (b=0.12, t(2436)=9.48, p=0.68).</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl6.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top" colspan="8">FREE-CREDIBILITY BAYESIAN MODEL</th>
</tr>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top">Name</th>
<th align="center" valign="top">Estimate</th>
<th align="center" valign="top">SE</th>
<th align="center" valign="top">tStat</th>
<th align="center" valign="top">DF</th>
<th align="center" valign="top">pValue</th>
<th align="center" valign="top">Lower</th>
<th align="center" valign="top">Upper</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>(Intercept)</bold></td>
<td align="center" valign="top">0.37</td>
<td align="center" valign="top">0.02</td>
<td align="center" valign="top">16.87</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">0.33</td>
<td align="center" valign="top">0.41</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>FEEDBACK</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.12</td>
<td align="center" valign="top">0.01</td>
<td align="center" valign="top">9.48</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">0.1</td>
<td align="center" valign="top">0.15</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>BETTER</bold></td>
<td align="center" valign="top">0.83</td>
<td align="center" valign="top">0.01</td>
<td align="center" valign="top">64.91</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">0.8</td>
<td align="center" valign="top">0.85</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(2-STAR)</bold></td>
<td align="center" valign="top">0</td>
<td align="center" valign="top">0.01</td>
<td align="center" valign="top">−0.07</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">0.95</td>
<td align="center" valign="top">−0.02</td>
<td align="center" valign="top">0.02</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(3-STAR)</bold></td>
<td align="center" valign="top">−0.03</td>
<td align="center" valign="top">0.01</td>
<td align="center" valign="top">−3.08</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">0.002</td>
<td align="center" valign="top">−0.05</td>
<td align="center" valign="top">−0.01</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>FEEDBACK:BETTER</bold></td>
<td align="center" valign="top">−0.02</td>
<td align="center" valign="top">0.03</td>
<td align="center" valign="top">−0.85</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">0.39</td>
<td align="center" valign="top">−0.07</td>
<td align="center" valign="top">0.03</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>FEEDBACK:AGENT(2-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.15</td>
<td align="center" valign="top">0.02</td>
<td align="center" valign="top">7.99</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">0.11</td>
<td align="center" valign="top">0.18</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>BETTER:AGENT(2-STAR)</bold></td>
<td align="center" valign="top">−0.02</td>
<td align="center" valign="top">0.02</td>
<td align="center" valign="top">−0.82</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">0.41</td>
<td align="center" valign="top">−0.05</td>
<td align="center" valign="top">0.02</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>FEEDBACK:AGENT(3-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.85</td>
<td align="center" valign="top">0.02</td>
<td align="center" valign="top">43.63</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">0.81</td>
<td align="center" valign="top">0.89</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>BETTER:AGENT(3-STAR)</bold></td>
<td align="center" valign="top">−0.15</td>
<td align="center" valign="top">0.02</td>
<td align="center" valign="top">−7.87</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">−0.19</td>
<td align="center" valign="top">−0.12</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>FEEDBACK:BETTER:AGENT(2-STAR)</bold></td>
<td align="center" valign="top">0</td>
<td align="center" valign="top">0.04</td>
<td align="center" valign="top">−0.08</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">0.93</td>
<td align="center" valign="top">−0.07</td>
<td align="center" valign="top">0.07</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>FEEDBACK:BETTER:AGENT(3-STAR)</bold></td>
<td align="center" valign="top">−0.04</td>
<td align="center" valign="top">0.04</td>
<td align="center" valign="top">−1.07</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">0.28</td>
<td align="center" valign="top">−0.12</td>
<td align="center" valign="top">0.03</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8"><bold>Any interaction between FEEDBACK and AGENT</bold>: F(2,2436)=1041.3, p&lt;0.001</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8" style="background-color:#d9e2f3"><bold>FEEDBACK:AGENT(3-STAR) vs FEEDBACK:AGENT(2-STAR)</bold>: b=0.70, F(1,2436)=1268.1, p&lt;0.001</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<table-wrap id="tblS5" position="float" orientation="portrait">
<label>Table 5:</label>
<caption><title>Mixed-effects binomial regression model regressing choice-repetition on feedback-valence, agent-credibility and better/worse choice from previous trial featuring the same bandit pair.</title>
<p>Based on null-CA model simulations. The feedback effect did not interact with agent-credibility (F(2,2436)=0.11, p=0.89).</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl7.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top" colspan="8">NULL-CA MODEL</th>
</tr>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top">Name</th>
<th align="center" valign="top">Estimate</th>
<th align="center" valign="top">SE</th>
<th align="center" valign="top">tStat</th>
<th align="center" valign="top">DF</th>
<th align="center" valign="top">pValue</th>
<th align="center" valign="top">Lower</th>
<th align="center" valign="top">Upper</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>(Intercept)</bold></td>
<td align="center" valign="top">0.86</td>
<td align="center" valign="top">0.03</td>
<td align="center" valign="top">25.46</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">0.79</td>
<td align="center" valign="top">0.92</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>FEEDBACK</bold></td>
<td align="center" valign="top">0.69</td>
<td align="center" valign="top">0.01</td>
<td align="center" valign="top">51.25</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">0.66</td>
<td align="center" valign="top">0.72</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>BETTER</bold></td>
<td align="center" valign="top">0.37</td>
<td align="center" valign="top">0.01</td>
<td align="center" valign="top">27.54</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">0.35</td>
<td align="center" valign="top">0.4</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(2-STAR)</bold></td>
<td align="center" valign="top">−0.01</td>
<td align="center" valign="top">0.01</td>
<td align="center" valign="top">−0.87</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">0.38</td>
<td align="center" valign="top">−0.03</td>
<td align="center" valign="top">0.01</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(3-STAR)</bold></td>
<td align="center" valign="top">0.01</td>
<td align="center" valign="top">0.01</td>
<td align="center" valign="top">1.2</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">0.23</td>
<td align="center" valign="top">−0.01</td>
<td align="center" valign="top">0.03</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>FEEDBACK:BETTER</bold></td>
<td align="center" valign="top">−0.01</td>
<td align="center" valign="top">0.03</td>
<td align="center" valign="top">−0.49</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">0.62</td>
<td align="center" valign="top">−0.07</td>
<td align="center" valign="top">0.04</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>FEEDBACK:AGENT(2-STAR)</bold></td>
<td align="center" valign="top">0.004</td>
<td align="center" valign="top">0.02</td>
<td align="center" valign="top">−0.2</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">0.84</td>
<td align="center" valign="top">−0.04</td>
<td align="center" valign="top">0.03</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>BETTER:AGENT(2-STAR)</bold></td>
<td align="center" valign="top">−0.07</td>
<td align="center" valign="top">0.02</td>
<td align="center" valign="top">−3.86</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">−0.11</td>
<td align="center" valign="top">−0.04</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>FEEDBACK:AGENT(3-STAR)</bold></td>
<td align="center" valign="top">0.006</td>
<td align="center" valign="top">0.02</td>
<td align="center" valign="top">0.29</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">0.77</td>
<td align="center" valign="top">−0.03</td>
<td align="center" valign="top">0.05</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>BETTER:AGENT(3-STAR)</bold></td>
<td align="center" valign="top">−0.08</td>
<td align="center" valign="top">0.02</td>
<td align="center" valign="top">−3.81</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">−0.12</td>
<td align="center" valign="top">−0.04</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>FEEDBACK:BETTER:AGENT(2-STAR)</bold></td>
<td align="center" valign="top">−0.02</td>
<td align="center" valign="top">0.04</td>
<td align="center" valign="top">−0.53</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">0.6</td>
<td align="center" valign="top">−0.1</td>
<td align="center" valign="top">0.06</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>FEEDBACK:BETTER:AGENT(3-STAR)</bold></td>
<td align="center" valign="top">−0.03</td>
<td align="center" valign="top">0.04</td>
<td align="center" valign="top">−0.66</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">0.51</td>
<td align="center" valign="top">−0.11</td>
<td align="center" valign="top">0.05</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8" style="background-color:#d9e2f3"><bold>Any interaction between FEEDBACK and AGENT</bold>: F(2,2436)=0.11, p=0.89</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8"><bold>FEEDBACK:AGENT(3-STAR) vs FEEDBACK:AGENT(2-STAR)</bold>: b=0.002, F(1,2436)=0.22, p=0.64</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<table-wrap id="tblS6" position="float" orientation="portrait">
<label>Table 6:</label>
<caption><title>Mixed-effects binomial regression model regressing choice-repetition on feedback-valence, agent-credibility and better/worse choice from previous trial featuring the same bandit pair.Based on credibility-CA model simulations.</title>
<p>Feedback effect increased as a function of agent-credibility (3- star vs. 2-star: b=0.96, F(1,2436)=2009.5.1; 3-star vs. 1-star: b=1.15, t(2436)=54.5; and 2-star vs. 1- star: b=0.19, t(2436)=9.79, all p’s&lt;0.001). Feedback valence exerted a positive effect for the 1-star agent (b=0.25, t(2436)=18.31, p&lt;0.001).</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl8.tif" mime-subtype="tif" mimetype="image"/>
<graphic xlink:href="st4kgv5_tbl9.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top" colspan="8">CREDIBILITY-CA MODEL</th>
</tr>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top">Name</th>
<th align="center" valign="top">Estimate</th>
<th align="center" valign="top">SE</th>
<th align="center" valign="top">tStat</th>
<th align="center" valign="top">DF</th>
<th align="center" valign="top">pValue</th>
<th align="center" valign="top">Lower</th>
<th align="center" valign="top">Upper</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>(Intercept)</bold></td>
<td align="center" valign="top">0.9</td>
<td align="center" valign="top">0.03</td>
<td align="center" valign="top">26.07</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">0.84</td>
<td align="center" valign="top">0.97</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>FEEDBACK</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.25</td>
<td align="center" valign="top">0.01</td>
<td align="center" valign="top">18.31</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">0.22</td>
<td align="center" valign="top">0.28</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>BETTER</bold></td>
<td align="center" valign="top">0.49</td>
<td align="center" valign="top">0.01</td>
<td align="center" valign="top">35.89</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">0.46</td>
<td align="center" valign="top">0.51</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(2-STAR)</bold></td>
<td align="center" valign="top">−0.01</td>
<td align="center" valign="top">0.01</td>
<td align="center" valign="top">−0.52</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">0.6</td>
<td align="center" valign="top">−0.02</td>
<td align="center" valign="top">0.01</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(3-STAR)</bold></td>
<td align="center" valign="top">−0.1</td>
<td align="center" valign="top">0.01</td>
<td align="center" valign="top">−9.62</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">p&lt;0.001</td>
<td align="center" valign="top">−0.12</td>
<td align="center" valign="top">−0.08</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>FEEDBACK:BETTER</bold></td>
<td align="center" valign="top">0.03</td>
<td align="center" valign="top">0.03</td>
<td align="center" valign="top">1.08</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">0.28</td>
<td align="center" valign="top">−0.02</td>
<td align="center" valign="top">0.08</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>FEEDBACK:AGENT(2-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.19</td>
<td align="center" valign="top">0.02</td>
<td align="center" valign="top">9.79</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">0.15</td>
<td align="center" valign="top">0.23</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>BETTER:AGENT(2-STAR)</bold></td>
<td align="center" valign="top">−0.03</td>
<td align="center" valign="top">0.02</td>
<td align="center" valign="top">−1.79</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">0.07</td>
<td align="center" valign="top">−0.07</td>
<td align="center" valign="top">0</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>FEEDBACK:AGENT(3-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">1.15</td>
<td align="center" valign="top">0.02</td>
<td align="center" valign="top">54.5</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">1.11</td>
<td align="center" valign="top">1.19</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>BETTER:AGENT(3-STAR)</bold></td>
<td align="center" valign="top">−0.1</td>
<td align="center" valign="top">0.02</td>
<td align="center" valign="top">−4.85</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">−0.14</td>
<td align="center" valign="top">−0.06</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>FEEDBACK:BETTER:AGENT(2-STAR)</bold></td>
<td align="center" valign="top">−0.01</td>
<td align="center" valign="top">0.04</td>
<td align="center" valign="top">−0.2</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">0.84</td>
<td align="center" valign="top">−0.08</td>
<td align="center" valign="top">0.07</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>FEEDBACK:BETTER:AGENT(3-STAR)</bold></td>
<td align="center" valign="top">−0.07</td>
<td align="center" valign="top">0.04</td>
<td align="center" valign="top">−1.65</td>
<td align="center" valign="top">2436</td>
<td align="center" valign="top">0.1</td>
<td align="center" valign="top">−0.15</td>
<td align="center" valign="top">0.01</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8"><bold>Any interaction between FEEDBACK and AGENT</bold>: F(2,2436)=1618.8, p&lt;0.001</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8" style="background-color:#d9e2f3"><bold>FEEDBACK:AGENT(3-STAR) vs FEEDBACK:AGENT(2-STAR)</bold>: b=0.96, F(1,2436)=2009.5, p&lt;0.001</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
<sec id="s6-3-1-1-2">
<label>3.1.1.2</label>
<title>CA and feedback credibility</title>
<p>In this section we provide full result tables for mixed effects models used in the sections “Credible feedback promotes greater learning”, “Most participants deviate from Bayesian Learning” and “Noncredible feedback elicits learning”; and <xref ref-type="fig" rid="fig3">figure 3c</xref>. The Wilkinson’s notation of the model is:
<disp-formula id="FD21">
<alternatives>
<mml:math id="M21" display="block"><mml:mi>C</mml:mi><mml:mi>A</mml:mi><mml:mo>∼</mml:mo><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="st4kgv5_eqn21.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
</disp-formula>
</p>
<table-wrap id="tblS7" position="float" orientation="portrait">
<label>Table 7:</label>
<caption><title>Mixed-effects linear regression model regressing CA on agent-credibility, based on credibility-CA fits of participants’ data.</title>
<p>CA increased as a function of agent-credibility (3-star vs. 2- star: b= 1.02, F(1,609)=253.73; 3-star vs. 1-star: b=1.24, t(609)=19.31; and 2-star vs. 1-star: b=0.22, t(609)=3.38, all p’s&lt;0.001). We found a positive CA for the 1-star agent (b=0.23, t(609)=4.54, p&lt;0.001).</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl10.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top" colspan="8">PARTICIPANTS DATA</th>
</tr>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top">Name</th>
<th align="center" valign="top">Estimate</th>
<th align="center" valign="top">SE</th>
<th align="center" valign="top">tStat</th>
<th align="center" valign="top">DF</th>
<th align="center" valign="top">pValue</th>
<th align="center" valign="top">Lower</th>
<th align="center" valign="top">Upper</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>(Intercept)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.23</td>
<td align="center" valign="top">0.05</td>
<td align="center" valign="top">4.54</td>
<td align="center" valign="top">609</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">0.13</td>
<td align="center" valign="top">0.33</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>AGENT(2-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.22</td>
<td align="center" valign="top">0.06</td>
<td align="center" valign="top">3.38</td>
<td align="center" valign="top">609</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">0.09</td>
<td align="center" valign="top">0.34</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>AGENT(3-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">1.24</td>
<td align="center" valign="top">0.06</td>
<td align="center" valign="top">19.31</td>
<td align="center" valign="top">609</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">1.12</td>
<td align="center" valign="top">1.37</td>
</tr>
<tr>
<td align="center" valign="top" colspan="8" style="background-color:#d9e2f3"><bold>Any effect of AGENT:</bold> F(2,609)=212.65, p&lt;0.001
<break/><bold>AGENT(3-STAR) vs AGENT(2-STAR):</bold> b= 1.02, F(1,609)=253.73, p&lt;0.001</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<table-wrap id="tblS8" position="float" orientation="portrait">
<label>Table 8:</label>
<caption><title>Mixed-effects linear regression model regressing CA on agent-credibility, based on credibility-CA fits of instructed-credibility Bayesian model simulations.</title>
<p>CA increased as a function of agent-credibility (3-star vs. 2-star: b= 0.33, F(1,609)=233.17; 3-star vs. 1-star: b=0.61, t(609)=28.55; and 2-star vs. 1-star: b=0.28, t(609)=13.28, all p’s&lt;0.001). There was no evidence that CA for the 1- star agent differed from 0 (b=−0.01, t(609)=−0.31, p=0.76).</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl11.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top" colspan="8">INSTRUCTED-CREDIBILITY BAYESIAN SIMULATIONS</th>
</tr>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top">Name</th>
<th align="center" valign="top">Estimate</th>
<th align="center" valign="top">SE</th>
<th align="center" valign="top">tStat</th>
<th align="center" valign="top">DF</th>
<th align="center" valign="top">pValue</th>
<th align="center" valign="top">Lower</th>
<th align="center" valign="top">Upper</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>(Intercept)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">−0.01</td>
<td align="center" valign="top">0.02</td>
<td align="center" valign="top">−0.64</td>
<td align="center" valign="top">609</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.54</td>
<td align="center" valign="top">−0.06</td>
<td align="center" valign="top">0.03</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>AGENT(2-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.30</td>
<td align="center" valign="top">0.02</td>
<td align="center" valign="top">11.22</td>
<td align="center" valign="top">609</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">0.24</td>
<td align="center" valign="top">0.35</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>AGENT(3-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.60</td>
<td align="center" valign="top">0.02</td>
<td align="center" valign="top">22.93</td>
<td align="center" valign="top">609</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">0.55</td>
<td align="center" valign="top">0.66</td>
</tr>
<tr>
<td align="center" valign="top" colspan="8" style="background-color:#d9e2f3"><bold>Any effect of AGENT:</bold> F(2,609)=262.96, p&lt;0.001
<break/><bold>AGENT(3-STAR) vs AGENT(2-STAR):</bold> b=0.30, F(1,609)=136.94, p&lt;0.001</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<table-wrap id="tblS9" position="float" orientation="portrait">
<label>Table 9:</label>
<caption><title>Mixed-effects linear regression model regressing CA on agent-credibility, based on credibility-CA fits of free-credibility Bayesian model simulations.</title>
<p>CA increased as a function of agentcredibility (3-star vs. 2-star: b= 0.5, F(1,609)=272.63; 3-star vs. 1-star: b=0.61, t(609)=20.05; and 2-star vs. 1-star: b=0.11, t(609)=3.54, all p’s&lt;0.001). We detected a positive CA for the 1-star agent (b=0.08, t(609)=3.32, p&lt;0.001).</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl12.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top" colspan="8">FREE-CREDIBILITY BAYESIAN SIMULATIONS</th>
</tr>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top">Name</th>
<th align="center" valign="top">Estimate</th>
<th align="center" valign="top">SE</th>
<th align="center" valign="top">tStat</th>
<th align="center" valign="top">DF</th>
<th align="center" valign="top">pValue</th>
<th align="center" valign="top">Lower</th>
<th align="center" valign="top">Upper</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>(Intercept)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.08</td>
<td align="center" valign="top">0.02</td>
<td align="center" valign="top">3.01</td>
<td align="center" valign="top">609</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.002</td>
<td align="center" valign="top">0.03</td>
<td align="center" valign="top">0.13</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>AGENT(2-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.11</td>
<td align="center" valign="top">0.03</td>
<td align="center" valign="top">3.26</td>
<td align="center" valign="top">609</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.001</td>
<td align="center" valign="top">0.05</td>
<td align="center" valign="top">0.18</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>AGENT(3-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.61</td>
<td align="center" valign="top">0.03</td>
<td align="center" valign="top">20.05</td>
<td align="center" valign="top">609</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">0.54</td>
<td align="center" valign="top">0.67</td>
</tr>
<tr>
<td align="center" valign="top" colspan="8" style="background-color:#d9e2f3"><bold>Any effect of AGENT:</bold> F(2,609)=172.43, p&lt;0.001
<break/><bold>AGENT(3-STAR) vs AGENT(2-STAR):</bold> b=0.5, F(1,609)=201.64, p&lt;0.001</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
<sec id="s6-3-1-1-3">
<label>3.1.1.3</label>
<title>CA, feedback valence and feedback credibility</title>
<p>In this section we provide full result tables for mixed effects models used in the sections “Individuals show a positivity bias in learning” and “Positivity bias increases for sources of limited credibility”; and <xref ref-type="fig" rid="fig5">figure 5a</xref> and <xref ref-type="fig" rid="fig5">5b</xref>. The Wilkinson’s notation of the model is:
<disp-formula id="FD22">
<alternatives>
<mml:math id="M22" display="block"><mml:mi>C</mml:mi><mml:mi>A</mml:mi><mml:mo>∼</mml:mo><mml:mi>V</mml:mi><mml:mi>A</mml:mi><mml:mi>L</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:mi>C</mml:mi><mml:mi>E</mml:mi><mml:mo>∗</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="st4kgv5_eqn22.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
</disp-formula>
</p>
<table-wrap id="tblS10" position="float" orientation="portrait">
<label>Table 10:</label>
<caption><title>Mixed-effects linear regression model regressing CA on feedback-valence and agent-credibility, based on credibility-valence-CA fits of participants’ data.</title>
<p>We found an overall positive valence effect(b=0.64, F(1,1218)=37.39, p&lt;0.001), with no interactions with agent credibility (F(2,1218)=0.12, p=0.88).</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl13.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top" colspan="8">PARTICIPANTS DATA</th>
</tr>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top">Name</th>
<th align="center" valign="top">Estimate</th>
<th align="center" valign="top">SE</th>
<th align="center" valign="top">tStat</th>
<th align="center" valign="top">DF</th>
<th align="center" valign="top">pValue</th>
<th align="center" valign="top">Lower</th>
<th align="center" valign="top">Upper</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>(Intercept)</bold></td>
<td align="center" valign="top">0.29</td>
<td align="center" valign="top">0.09</td>
<td align="center" valign="top">3.19</td>
<td align="center" valign="top">1218</td>
<td align="center" valign="top">0.001</td>
<td align="center" valign="top">0.11</td>
<td align="center" valign="top">0.47</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>VALENCE</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.65</td>
<td align="center" valign="top">0.18</td>
<td align="center" valign="top">3.56</td>
<td align="center" valign="top">1218</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">0.29</td>
<td align="center" valign="top">1</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(2-STAR)</bold></td>
<td align="center" valign="top">0.21</td>
<td align="center" valign="top">0.13</td>
<td align="center" valign="top">1.61</td>
<td align="center" valign="top">1218</td>
<td align="center" valign="top">0.11</td>
<td align="center" valign="top">-0.05</td>
<td align="center" valign="top">0.46</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(3-STAR)</bold></td>
<td align="center" valign="top">1.25</td>
<td align="center" valign="top">0.13</td>
<td align="center" valign="top">9.76</td>
<td align="center" valign="top">1218</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">1</td>
<td align="center" valign="top">1.5</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>VALENCE:AGENT(2-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.05</td>
<td align="center" valign="top">0.26</td>
<td align="center" valign="top">0.21</td>
<td align="center" valign="top">1218</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.83</td>
<td align="center" valign="top">-0.45</td>
<td align="center" valign="top">0.56</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>VALENCE:AGENT(3-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">-0.07</td>
<td align="center" valign="top">0.26</td>
<td align="center" valign="top">-0.29</td>
<td align="center" valign="top">1218</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.77</td>
<td align="center" valign="top">-0.58</td>
<td align="center" valign="top">0.43</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8" style="background-color:#d9e2f3"><bold>Average valence effect</bold>: b=0.64, F(1,1218)=37.39, p&lt;0.001
<break/><bold>Any interaction</bold>: F(2,1218)=0.12, p=0.88</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8"><bold>Effect of negative feedback 1-star</bold>: b=-0.03, F(1,1218)=0.07, p=0.79
<break/><bold>Effect of positive feedback 1-star</bold>: b=0.61, F(1,1218)=22.81, p&lt;0.001
<break/><bold>Effect of negative feedback 2-star</bold>: b=0.14, F(1,1218)=1.28, p=0.25
<break/><bold>Effect of positive feedback 2-star</bold>: b=0.85, F(1,1218)=43.5, p&lt;0.001
<break/><bold>Effect of negative feedback 3-star</bold>: b=1.25, F(1,1218)=95.7, p=&lt;0.001
<break/><bold>Effect of positive feedback 3-star</bold>: b=1.83, F(1,1218)=203.1, p&lt;0.001</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<table-wrap id="tblS11" position="float" orientation="portrait">
<label>Table 11:</label>
<caption><title>Mixed-effects linear regression model regressing CA on feedback-valence and agentcredibility, based on credibility-valence-CA fits of instructed-credibility Bayesian model simulations.</title>
<p>We found an overall negative valence effect (b=-0.54, F(1,1218)=101.87, p&lt;0.001), with no interactions with agent credibility (F(2,1218)=0.02, p=0.98).</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl14.tif" mime-subtype="tif" mimetype="image"/>
<graphic xlink:href="st4kgv5_tbl15.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top" colspan="8">INSTRUCTED-CREDIBILITY BAYESIAN SIMULATIONS</th>
</tr>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top">Name</th>
<th align="center" valign="top">Estimate</th>
<th align="center" valign="top">SE</th>
<th align="center" valign="top">tStat</th>
<th align="center" valign="top">DF</th>
<th align="center" valign="top">pValue</th>
<th align="center" valign="top">Lower</th>
<th align="center" valign="top">Upper</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>(Intercept)</bold></td>
<td align="center" valign="top">0</td>
<td align="center" valign="top">0.05</td>
<td align="center" valign="top">-0.06</td>
<td align="center" valign="top">1218</td>
<td align="center" valign="top">0.95</td>
<td align="center" valign="top">-0.09</td>
<td align="center" valign="top">0.09</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>VALENCE</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">-0.5</td>
<td align="center" valign="top">0.09</td>
<td align="center" valign="top">-5.38</td>
<td align="center" valign="top">1218</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">-0.68</td>
<td align="center" valign="top">-0.32</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(2-STAR)</bold></td>
<td align="center" valign="top">0.29</td>
<td align="center" valign="top">0.07</td>
<td align="center" valign="top">4.41</td>
<td align="center" valign="top">1218</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">0.16</td>
<td align="center" valign="top">0.41</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(3-STAR)</bold></td>
<td align="center" valign="top">0.62</td>
<td align="center" valign="top">0.07</td>
<td align="center" valign="top">9.54</td>
<td align="center" valign="top">1218</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">0.49</td>
<td align="center" valign="top">0.75</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>VALENCE:AGENT(2-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">-0.04</td>
<td align="center" valign="top">0.13</td>
<td align="center" valign="top">-0.34</td>
<td align="center" valign="top">1218</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.73</td>
<td align="center" valign="top">-0.3</td>
<td align="center" valign="top">0.21</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>VALENCE:AGENT(3-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">-0.08</td>
<td align="center" valign="top">0.13</td>
<td align="center" valign="top">-0.6</td>
<td align="center" valign="top">1218</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.54</td>
<td align="center" valign="top">-0.33</td>
<td align="center" valign="top">0.18</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8" style="background-color:#d9e2f3"><bold>Average valence effect</bold>: b=-0.54, F(1,1218)=101.87, p&lt;0.001
<break/><bold>Any interaction</bold>: F(2,1218)=0.02, p=0.98</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8"><bold>Effect of negative feedback 1-star</bold>: b=0.25, F(1,1218)=14.17, p&lt;0.001
<break/><bold>Effect of positive feedback 1-star</bold>: b=-0.25, F(1,1218)=14.78, p&lt;0.001
<break/><bold>Effect of negative feedback 2-star</bold>: b=0.55, F(1,1218)=72.47, p&lt;0.001
<break/><bold>Effect of positive feedback 2-star</bold>: b=0.014, F(1,1218)=0.04, p=0.83
<break/><bold>Effect of negative feedback 3-star</bold>: b=0.91, F(1,1218)=193.45, p&lt;0.001
<break/><bold>Effect of positive feedback 3-star</bold>: b=0.33, F(1,1218)=25.91, p&lt;0.001</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<table-wrap id="tblS12" position="float" orientation="portrait">
<label>Table 12:</label>
<caption><title>Mixed-effects linear regression model regressing CA on feedback-valence and agentcredibility, based on credibility-valence-CA fits of free-credibility Bayesian model simulations.</title>
<p>We found an overall negative valence effect (b=-0.54, F(1,1218)=98.91, p&lt;0.001), with no interactions with agent credibility (F(2,1218)=0.06, p=0.94).</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl16.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr>
<th align="center" valign="top" colspan="8" style="background-color:#e7e6e6">FREE-CREDIBILITY BAYESIAN SIMULATIONS</th>
</tr>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top">Name</th>
<th align="center" valign="top">Estimate</th>
<th align="center" valign="top">SE</th>
<th align="center" valign="top">tStat</th>
<th align="center" valign="top">DF</th>
<th align="center" valign="top">pValue</th>
<th align="center" valign="top">Lower</th>
<th align="center" valign="top">Upper</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>(Intercept)</bold></td>
<td align="center" valign="top">0.08</td>
<td align="center" valign="top">0.05</td>
<td align="center" valign="top">1.72</td>
<td align="center" valign="top">1218</td>
<td align="center" valign="top">0.09</td>
<td align="center" valign="top">-0.01</td>
<td align="center" valign="top">0.17</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>VALENCE</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">-0.51</td>
<td align="center" valign="top">0.09</td>
<td align="center" valign="top">-5.39</td>
<td align="center" valign="top">1218</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">-0.7</td>
<td align="center" valign="top">-0.33</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(2-STAR)</bold></td>
<td align="center" valign="top">0.1</td>
<td align="center" valign="top">0.07</td>
<td align="center" valign="top">1.56</td>
<td align="center" valign="top">1218</td>
<td align="center" valign="top">0.12</td>
<td align="center" valign="top">-0.03</td>
<td align="center" valign="top">0.24</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(3-STAR)</bold></td>
<td align="center" valign="top">0.62</td>
<td align="center" valign="top">0.07</td>
<td align="center" valign="top">9.31</td>
<td align="center" valign="top">1218</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">0.49</td>
<td align="center" valign="top">0.76</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>VALENCE:AGENT(2-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">-0.02</td>
<td align="center" valign="top">0.13</td>
<td align="center" valign="top">-0.18</td>
<td align="center" valign="top">1218</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.85</td>
<td align="center" valign="top">-0.29</td>
<td align="center" valign="top">0.24</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>VALENCE:AGENT(3-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">-0.07</td>
<td align="center" valign="top">0.13</td>
<td align="center" valign="top">-0.56</td>
<td align="center" valign="top">1218</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.58</td>
<td align="center" valign="top">-0.34</td>
<td align="center" valign="top">0.19</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8" style="background-color:#d9e2f3"><bold>Average valence effect</bold>: b=-0.54, F(1,1218)=98.91, p&lt;0.001
<break/><bold>Any interaction</bold>: F(2,1218)=0.06, p=0.94</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8"><bold>Effect of negative feedback 1-star</bold>: b=0.34, F(1,1218)=25.29, p&lt;0.001
<break/><bold>Effect of positive feedback 1-star</bold>: b=-0.17, F(1,1218)=6.74, p=0.010
<break/><bold>Effect of negative feedback 2-star</bold>: b=0.45, F(1,1218)=45.91, p&lt;0.001
<break/><bold>Effect of positive feedback 2-star</bold>: b=-0.08, F(1,1218)=1.48, p=0.22
<break/><bold>Effect of negative feedback 3-star</bold>: b=1.00, F(1,1218)=221.82, p&lt;0.001
<break/><bold>Effect of positive feedback 3-star</bold>: b=0.41, F(1,1218)=37.84, p&lt;0.001</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
</sec>
<sec id="s6-3-1-2">
<label>3.1.2</label>
<title>Discovery study</title>
<sec id="s6-3-1-2-1">
<label>3.1.2.1</label>
<title>Choice repetition and feedback credibility</title>
<p>In this section we provide full result tables for mixed effects models used in the SI Discovery study sections “Credible feedback promotes greater learning” and “Learning for non-credible feedback”; and <xref ref-type="fig" rid="figS2">SI figure 2a</xref>. The Wilkinson’s notation of the model is:
<disp-formula id="FD23">
<alternatives>
<mml:math id="M23" display="block"><mml:mi>R</mml:mi><mml:mi>E</mml:mi><mml:mi>P</mml:mi><mml:mi>E</mml:mi><mml:mi>A</mml:mi><mml:mi>T</mml:mi><mml:mo>∼</mml:mo><mml:mi>F</mml:mi><mml:mi>E</mml:mi><mml:mi>E</mml:mi><mml:mi>D</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mi>C</mml:mi><mml:mi>K</mml:mi><mml:mo>∗</mml:mo><mml:mi>B</mml:mi><mml:mi>E</mml:mi><mml:mi>T</mml:mi><mml:mi>T</mml:mi><mml:mi>E</mml:mi><mml:mi>R</mml:mi><mml:mo>∗</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>4</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="st4kgv5_eqn23.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
</disp-formula>
</p>
<table-wrap id="tblS13" position="float" orientation="portrait">
<label>Table 13:</label>
<caption><title>Mixed-effects binomial regression model regressing choice-repetition on feedbackvalence, agent-credibility and better/worse choice from previous trial featuring the same bandit pair.</title>
<p>Based on participants’ data. Feedback effect increased as a function of agent-credibility, and we found no significant feedback valence effect for the 1-star agent.</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl17.tif" mime-subtype="tif" mimetype="image"/>
<graphic xlink:href="st4kgv5_tbl18.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top" colspan="8">PARTICIPANTS’ DATA</th>
</tr>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top">Name</th>
<th align="center" valign="top">Estimate</th>
<th align="center" valign="top">SE</th>
<th align="center" valign="top">tStat</th>
<th align="center" valign="top">DF</th>
<th align="center" valign="top">pValue</th>
<th align="center" valign="top">Lower</th>
<th align="center" valign="top">Upper</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>(Intercept)</bold></td>
<td align="center" valign="top">1.87</td>
<td align="center" valign="top">0.09</td>
<td align="center" valign="top">19.89</td>
<td align="center" valign="top">2462</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">1.68</td>
<td align="center" valign="top">2.05</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>FEEDBACK</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">-0.09</td>
<td align="center" valign="top">0.08</td>
<td align="center" valign="top">-1.21</td>
<td align="center" valign="top">2462</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.22</td>
<td align="center" valign="top">-0.24</td>
<td align="center" valign="top">0.06</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>BETTER</bold></td>
<td align="center" valign="top">0.82</td>
<td align="center" valign="top">0.13</td>
<td align="center" valign="top">6.11</td>
<td align="center" valign="top">2462</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">0.56</td>
<td align="center" valign="top">1.09</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(2-STAR)</bold></td>
<td align="center" valign="top">0.19</td>
<td align="center" valign="top">0.05</td>
<td align="center" valign="top">3.44</td>
<td align="center" valign="top">2462</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">0.08</td>
<td align="center" valign="top">0.3</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(3-STAR)</bold></td>
<td align="center" valign="top">0.05</td>
<td align="center" valign="top">0.05</td>
<td align="center" valign="top">0.88</td>
<td align="center" valign="top">2462</td>
<td align="center" valign="top">0.37</td>
<td align="center" valign="top">-0.06</td>
<td align="center" valign="top">0.16</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(4-STAR)</bold></td>
<td align="center" valign="top">-0.39</td>
<td align="center" valign="top">0.06</td>
<td align="center" valign="top">-7.07</td>
<td align="center" valign="top">2462</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">-0.5</td>
<td align="center" valign="top">-0.28</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>FEEDBACK:BETTER</bold></td>
<td align="center" valign="top">-0.67</td>
<td align="center" valign="top">0.27</td>
<td align="center" valign="top">-2.51</td>
<td align="center" valign="top">2462</td>
<td align="center" valign="top">0.012</td>
<td align="center" valign="top">-1.2</td>
<td align="center" valign="top">-0.15</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>FEEDBACK:AGENT(2-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.52</td>
<td align="center" valign="top">0.11</td>
<td align="center" valign="top">4.74</td>
<td align="center" valign="top">2462</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">0.31</td>
<td align="center" valign="top">0.74</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>BETTER:AGENT(2-STAR)</bold></td>
<td align="center" valign="top">-0.01</td>
<td align="center" valign="top">0.2</td>
<td align="center" valign="top">-0.04</td>
<td align="center" valign="top">2462</td>
<td align="center" valign="top">0.97</td>
<td align="center" valign="top">-0.39</td>
<td align="center" valign="top">0.38</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>FEEDBACK:AGENT(3-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">1.24</td>
<td align="center" valign="top">0.11</td>
<td align="center" valign="top">11.25</td>
<td align="center" valign="top">2462</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">1.03</td>
<td align="center" valign="top">1.46</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>BETTER:AGENT(3-STAR)</bold></td>
<td align="center" valign="top">-0.27</td>
<td align="center" valign="top">0.2</td>
<td align="center" valign="top">-1.41</td>
<td align="center" valign="top">2462</td>
<td align="center" valign="top">0.16</td>
<td align="center" valign="top">-0.66</td>
<td align="center" valign="top">0.11</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>FEEDBACK:AGENT(4-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">2.55</td>
<td align="center" valign="top">0.11</td>
<td align="center" valign="top">22.91</td>
<td align="center" valign="top">2462</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">2.33</td>
<td align="center" valign="top">2.77</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>BETTER:AGENT(4-STAR)</bold></td>
<td align="center" valign="top">-0.5</td>
<td align="center" valign="top">0.2</td>
<td align="center" valign="top">-2.56</td>
<td align="center" valign="top">2462</td>
<td align="center" valign="top">0.01</td>
<td align="center" valign="top">-0.88</td>
<td align="center" valign="top">-0.12</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>FEEDBACK:BETTER:AGENT(2-STAR)</bold></td>
<td align="center" valign="top">0.71</td>
<td align="center" valign="top">0.39</td>
<td align="center" valign="top">1.8</td>
<td align="center" valign="top">2462</td>
<td align="center" valign="top">0.071</td>
<td align="center" valign="top">-0.06</td>
<td align="center" valign="top">1.48</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>FEEDBACK:BETTER:AGENT(3-STAR)</bold></td>
<td align="center" valign="top">0.44</td>
<td align="center" valign="top">0.39</td>
<td align="center" valign="top">1.11</td>
<td align="center" valign="top">2462</td>
<td align="center" valign="top">0.27</td>
<td align="center" valign="top">-0.33</td>
<td align="center" valign="top">1.2</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>FEEDBACK:BETTER:AGENT(4-STAR)</bold></td>
<td align="center" valign="top">0.24</td>
<td align="center" valign="top">0.39</td>
<td align="center" valign="top">0.62</td>
<td align="center" valign="top">2462</td>
<td align="center" valign="top">0.53</td>
<td align="center" valign="top">-0.52</td>
<td align="center" valign="top">1.01</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8"><bold>Overall feedback effect</bold>: b=1.02, F(1,2462)=617.38, p&lt;0.001
<break/><bold>Feedback effect for AGENT(4-STAR</bold>): b=2.46, F(1,2462)= 911.81, p&lt;0.001
<break/><bold>Feedback effect for AGENT(3-STAR)</bold>: b=1.15, F(1,2462)=206.19, p&lt;0.001
<break/><bold>Feedback effect for AGENT(2-STAR)</bold>: b=0.43, F(1,2462)=28.84, p&lt;0.001
<break/><bold>Any interaction</bold>: F(3,2462)=196.61, p&lt;0.001</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8" style="background-color:#d9e2f3"><bold>FEEDBACK:AGENT(4-STAR) vs FEEDBACK:AGENT(2-STAR)</bold>: b=0.47, F(1,2462)=322.88, p&lt;0.001
<break/><bold>FEEDBACK:AGENT(4-STAR) vs FEEDBACK:AGENT(3-STAR):</bold> b=1.21, F(1,2462)=137.71, p&lt;0.001
<break/><bold>FEEDBACK:AGENT(3-STAR) vs FEEDBACK:AGENT(2-STAR):</bold> b=2.03, F(1,2462)=40.54, p&lt;0.001</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
<sec id="s6-3-1-2-2">
<label>3.1.2.2</label>
<title>CA and feedback credibility</title>
<p>In this section we provide full result tables for mixed effects models used in the SI Discovery study sections “Credible feedback promotes greater learning”, “Most participants deviate from Bayesian Learning” and “Non-credible feedback elicits learning”; and <xref ref-type="fig" rid="figS2">SI figure 2c</xref>. The Wilkinson’s notation of the model is:
<disp-formula id="FD24">
<alternatives>
<mml:math id="M24" display="block"><mml:mi>C</mml:mi><mml:mi>A</mml:mi><mml:mo>∼</mml:mo><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>4</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="st4kgv5_eqn24.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
</disp-formula>
</p>
<table-wrap id="tblS14" position="float" orientation="portrait">
<label>Table 14:</label>
<caption><title>Mixed-effects linear regression model regressing CA on agent-credibility, based on credibility-CA fits of participants’ data.</title>
<p>CA increased as a function of agent-credibility. We found no evidence for significant CA for the 1-star agent.</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl19.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top" colspan="8">PARTICIPANTS’ DATA</th>
</tr>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top">Name</th>
<th align="center" valign="top">Estimate</th>
<th align="center" valign="top">SE</th>
<th align="center" valign="top">tStat</th>
<th align="center" valign="top">DF</th>
<th align="center" valign="top">pValue</th>
<th align="center" valign="top">Lower</th>
<th align="center" valign="top">Upper</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>(Intercept)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">-0.13</td>
<td align="center" valign="top">0.13</td>
<td align="center" valign="top">-1.07</td>
<td align="center" valign="top">412</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.28</td>
<td align="center" valign="top">-0.38</td>
<td align="center" valign="top">0.11</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>AGENT(2-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.5</td>
<td align="center" valign="top">0.17</td>
<td align="center" valign="top">3.03</td>
<td align="center" valign="top">412</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.003</td>
<td align="center" valign="top">0.18</td>
<td align="center" valign="top">0.83</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>AGENT(3-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">1.27</td>
<td align="center" valign="top">0.17</td>
<td align="center" valign="top">7.68</td>
<td align="center" valign="top">412</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">0.94</td>
<td align="center" valign="top">1.59</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>AGENT(4-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">2.67</td>
<td align="center" valign="top">0.17</td>
<td align="center" valign="top">16.13</td>
<td align="center" valign="top">412</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.002</td>
<td align="center" valign="top">2.34</td>
<td align="center" valign="top">2.99</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8" style="background-color:#d9e2f3"><bold>AGENT(3-STAR) vs AGENT(2-STAR):</bold> b=0.77, F(1,412)=21.58, p&lt;0.001
<break/><bold>AGENT(4-STAR) vs AGENT(3-STAR)</bold>: b=1.4, F(1,412)=71.40, p&lt;0.001
<break/><bold>AGENT(4-STAR) vs AGENT(2-STAR)</bold>: b=2.17, F(1,412)=171.49, p&lt;0.001</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<table-wrap id="tblS15" position="float" orientation="portrait">
<label>Table 15:</label>
<caption><title>Mixed-effects linear regression model regressing CA on agent-credibility, based on credibility-CA fits of instructed-credibility Bayesian model simulations.</title>
<p>CA increased as a function of agent-credibility. Instructed-credibility Bayesian simulations do net predict significant CA for the 1- star agent.</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl20.tif" mime-subtype="tif" mimetype="image"/>
<graphic xlink:href="st4kgv5_tbl21.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top" colspan="8">INSTRUCTED-CREDIBILITY BAYESIAN SIMULATIONS</th>
</tr>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top">Name</th>
<th align="center" valign="top">Estimate</th>
<th align="center" valign="top">SE</th>
<th align="center" valign="top">tStat</th>
<th align="center" valign="top">DF</th>
<th align="center" valign="top">pValue</th>
<th align="center" valign="top">Lower</th>
<th align="center" valign="top">Upper</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>(Intercept)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">-0.02</td>
<td align="center" valign="top">0.05</td>
<td align="center" valign="top">-0.33</td>
<td align="center" valign="top">412</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.74</td>
<td align="center" valign="top">-0.11</td>
<td align="center" valign="top">0.08</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>AGENT(2-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.51</td>
<td align="center" valign="top">0.05</td>
<td align="center" valign="top">10.33</td>
<td align="center" valign="top">412</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">0.41</td>
<td align="center" valign="top">0.61</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>AGENT(3-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.91</td>
<td align="center" valign="top">0.05</td>
<td align="center" valign="top">18.5</td>
<td align="center" valign="top">412</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">0.81</td>
<td align="center" valign="top">1.01</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>AGENT(4-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">1.4</td>
<td align="center" valign="top">0.05</td>
<td align="center" valign="top">28.5</td>
<td align="center" valign="top">412</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">1.31</td>
<td align="center" valign="top">1.5</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8"><bold>Any difference across agents</bold>: F(3,412)=98.77, p&lt;0.001</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8" style="background-color:#d9e2f3"><bold>AGENT(3-STAR) vs AGENT(2-STAR)</bold>: b=0.4, F(1,412)=66.8, p&lt;0.001
<break/><bold>AGENT(4-STAR) vs AGENT(3-STAR)</bold>: b=0.49, F(1,412)=99.94, p&lt;0.001
<break/><bold>AGENT(4-STAR) vs AGENT(2-STAR)</bold>: b=0.89, F(1,412)=330.15, p&lt;0.001</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<table-wrap id="tblS16" position="float" orientation="portrait">
<label>Table 16:</label>
<caption><title>Mixed-effects linear regression model regressing CA on agent-credibility, based on credibility-CA fits of free-credibility Bayesian model simulations.</title>
<p>CA increased as a function of agentcredibility. Free-credibility Bayesian simulations do net predict significant CA for the 1-star agent.</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl22.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top" colspan="8">FREE-CREDIBILITY BAYESIAN SIMULATIONS</th>
</tr>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top">Name</th>
<th align="center" valign="top">Estimate</th>
<th align="center" valign="top">SE</th>
<th align="center" valign="top">tStat</th>
<th align="center" valign="top">DF</th>
<th align="center" valign="top">pValue</th>
<th align="center" valign="top">Lower</th>
<th align="center" valign="top">Upper</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>(Intercept)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">-0.1</td>
<td align="center" valign="top">0.09</td>
<td align="center" valign="top">-1.12</td>
<td align="center" valign="top">412</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.26</td>
<td align="center" valign="top">-0.27</td>
<td align="center" valign="top">0.07</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>AGENT(2-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.41</td>
<td align="center" valign="top">0.11</td>
<td align="center" valign="top">3.68</td>
<td align="center" valign="top">412</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">0.19</td>
<td align="center" valign="top">0.63</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>AGENT(3-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.95</td>
<td align="center" valign="top">0.11</td>
<td align="center" valign="top">8.48</td>
<td align="center" valign="top">412</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">0.73</td>
<td align="center" valign="top">1.17</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>AGENT(4-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">2.09</td>
<td align="center" valign="top">0.11</td>
<td align="center" valign="top">18.64</td>
<td align="center" valign="top">412</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.002</td>
<td align="center" valign="top">1.87</td>
<td align="center" valign="top">2.31</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8" style="background-color:#d9e2f3"><bold>AGENT(3-STAR) vs AGENT(2-STAR):</bold> b=0.54, F(1,412)=22.97, p&lt;0.001
<break/><bold>AGENT(4-STAR) vs AGENT(3-STAR):</bold> b=1.14, F(1,412)=103.24, p&lt;0.001
<break/><bold>AGENT(4-STAR) vs AGENT(2-STAR):</bold> b=1.68, F(1,412)=223.60, p&lt;0.001</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
<sec id="s6-3-1-2-3">
<label>3.1.2.3</label>
<title>CA, feedback valence and feedback credibility</title>
<p>In this section we provide full result tables for mixed effects models used in the SI Discovery study sections “Individuals show a positivity bias in learning” and “Positivity bias increases for sources of limited credibility”; and <xref ref-type="fig" rid="figS3">SI figure 3a</xref> and <xref ref-type="fig" rid="figS3">3b</xref>. The Wilkinson’s notation of the model is:
<disp-formula id="FD25">
<alternatives>
<mml:math id="M25" display="block"><mml:mi>C</mml:mi><mml:mi>A</mml:mi><mml:mo>∼</mml:mo><mml:mi>V</mml:mi><mml:mi>A</mml:mi><mml:mi>L</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:mi>C</mml:mi><mml:mi>E</mml:mi><mml:mo>∗</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mi>G</mml:mi><mml:mi>E</mml:mi><mml:mi>N</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>4</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="st4kgv5_eqn25.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
</disp-formula>
</p>
<table-wrap id="tblS17" position="float" orientation="portrait">
<label>Table 17:</label>
<caption><title>Mixed-effects linear regression model regressing CA on feedback-valence and agentcredibility, based on credibility-valence-CA fits of participants’ data.</title>
<p>We found an overall positive valence effect, which interacted with agent credibility, such that the valence effect was two 2-star agent than for the 4-star agent. Moreover, we found a positive valence effect for the 1-star, 2-star and 3-star agents, but not for the 4-star agent. Finally, the negative feedback from 1-star agent had a significant negative effect on CA, while positive feedback from the same agent had a significant positive effect.</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl23.tif" mime-subtype="tif" mimetype="image"/>
<graphic xlink:href="st4kgv5_tbl24.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top" colspan="8">PARTICIPANTS’ DATA</th>
</tr>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top">Name</th>
<th align="center" valign="top">Estimate</th>
<th align="center" valign="top">SE</th>
<th align="center" valign="top">tStat</th>
<th align="center" valign="top">DF</th>
<th align="center" valign="top">pValue</th>
<th align="center" valign="top">Lower</th>
<th align="center" valign="top">Upper</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>(Intercept)</bold></td>
<td align="center" valign="top">-0.05</td>
<td align="center" valign="top">0.16</td>
<td align="center" valign="top">-0.29</td>
<td align="center" valign="top">824</td>
<td align="center" valign="top">0.77</td>
<td align="center" valign="top">-0.36</td>
<td align="center" valign="top">0.27</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>VALENCE</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.94</td>
<td align="center" valign="top">0.29</td>
<td align="center" valign="top">3.24</td>
<td align="center" valign="top">824</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.001</td>
<td align="center" valign="top">0.37</td>
<td align="center" valign="top">1.51</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(2-STAR)</bold></td>
<td align="center" valign="top">0.5</td>
<td align="center" valign="top">0.21</td>
<td align="center" valign="top">2.44</td>
<td align="center" valign="top">824</td>
<td align="center" valign="top">0.015</td>
<td align="center" valign="top">0.1</td>
<td align="center" valign="top">0.9</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(3-STAR)</bold></td>
<td align="center" valign="top">1.39</td>
<td align="center" valign="top">0.21</td>
<td align="center" valign="top">6.76</td>
<td align="center" valign="top">824</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">0.99</td>
<td align="center" valign="top">1.79</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(4-STAR)</bold></td>
<td align="center" valign="top">2.8</td>
<td align="center" valign="top">0.21</td>
<td align="center" valign="top">13.66</td>
<td align="center" valign="top">824</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">2.4</td>
<td align="center" valign="top">3.21</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>VALENCE:AGENT(2-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.66</td>
<td align="center" valign="top">0.41</td>
<td align="center" valign="top">1.6</td>
<td align="center" valign="top">824</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.11</td>
<td align="center" valign="top">-0.15</td>
<td align="center" valign="top">1.46</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>VALENCE:AGENT(3-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.01</td>
<td align="center" valign="top">0.41</td>
<td align="center" valign="top">0.02</td>
<td align="center" valign="top">824</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.99</td>
<td align="center" valign="top">-0.8</td>
<td align="center" valign="top">0.81</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>VALENCE:AGENT(4-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">-0.63</td>
<td align="center" valign="top">0.41</td>
<td align="center" valign="top">-1.54</td>
<td align="center" valign="top">824</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.12</td>
<td align="center" valign="top">-1.44</td>
<td align="center" valign="top">0.17</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8" style="background-color:#d9e2f3"><bold>Average valence effect</bold>: b=0.94, F(1,824)=42.60, p&lt;0.001</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8"><bold>Effect of negative feedback 1-star</bold>: b=-0.51, F(1,824)=3.89, p=0.049</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8" style="background-color:#d9e2f3"><bold>Effect of positive feedback 1-star</bold>: b=0.42, F(1,824)=5.74, p=0.017
<break/><bold>Effect of negative feedback 2-star</bold>: b=-0.34, F(1,824)=2.53, p=0.11</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8"><bold>Effect of positive feedback 2-star</bold>: b=1.25, F(1,824)=16.34, p&lt;0.001
<break/><bold>Effect of negative feedback 3-star</bold>: b=0.86, F(1,824)=37.77, p&lt;0.001
<break/><bold>Effect of positive feedback 3-star</bold>: b=2.28, F(1,824)=71.28, p&lt;0.001
<break/><bold>Effect of negative feedback 4-star</bold>: b=2.60, F(1,824)=146.55, p&lt;0.001
<break/><bold>Effect of positive feedback 4-star</bold>: b=2.91, F(1,824)=183.22, p&lt;0.001</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8" style="background-color:#d9e2f3"><bold>Any interaction</bold>: F(3,824)=3.28 p=0.02
<break/><bold>Valence effect AGENT(2-STAR)</bold>: b=1.60, F(1, 824)=30.21, p&lt;0.001
<break/><bold>Valence effect AGENT(3-STAR)</bold>: b=0.94, F(1, 824)=10.63, p=0.001
<break/><bold>Valence effect AGENT(4-STAR)</bold>: b=0.31, F(1, 824)=1.12, p=0.29</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8"><bold>Valence effect AGENT(2-STAR) vs AGENT(3-STAR)</bold>: b=0.65, F(1, 824)=2.50, p=0.11</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8" style="background-color:#d9e2f3"><bold>Valence effect AGENT(2-STAR) vs AGENT(4-STAR)</bold>: b=1.29, F(1, 824)=9.84, p=0.002</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8"><bold>Valence effect AGENT(3-STAR) vs AGENT(4-STAR)</bold>: b=0.64, F(1, 824)=2.42, p=0.12</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<table-wrap id="tblS18" position="float" orientation="portrait">
<label>Table 18:</label>
<caption><title>Mixed-effects linear regression model regressing CA on feedback-valence and agentcredibility, based on credibility-valence-CA fits of instructed-credibility Bayesian model simulations.</title>
<p>We found an overall negative valence effect, with no interactions with agent credibility.</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl25.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top" colspan="8">INSTRUCTED-CREDIBILITY BAYESIAN SIMULATIONS</th>
</tr>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top">Name</th>
<th align="center" valign="top">Estimate</th>
<th align="center" valign="top">SE</th>
<th align="center" valign="top">tStat</th>
<th align="center" valign="top">DF</th>
<th align="center" valign="top">pValue</th>
<th align="center" valign="top">Lower</th>
<th align="center" valign="top">Upper</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>(Intercept)</bold></td>
<td align="center" valign="top">-0.01</td>
<td align="center" valign="top">0.08</td>
<td align="center" valign="top">-0.13</td>
<td align="center" valign="top">824</td>
<td align="center" valign="top">0.89</td>
<td align="center" valign="top">-0.18</td>
<td align="center" valign="top">0.15</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>VALENCE</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">-0.41</td>
<td align="center" valign="top">0.16</td>
<td align="center" valign="top">-2.53</td>
<td align="center" valign="top">824</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.012</td>
<td align="center" valign="top">-0.72</td>
<td align="center" valign="top">-0.09</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(2-STAR)</bold></td>
<td align="center" valign="top">0.54</td>
<td align="center" valign="top">0.11</td>
<td align="center" valign="top">4.79</td>
<td align="center" valign="top">824</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">0.32</td>
<td align="center" valign="top">0.77</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(3-STAR)</bold></td>
<td align="center" valign="top">0.98</td>
<td align="center" valign="top">0.11</td>
<td align="center" valign="top">8.59</td>
<td align="center" valign="top">824</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">0.75</td>
<td align="center" valign="top">1.2</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(4-STAR)</bold></td>
<td align="center" valign="top">1.53</td>
<td align="center" valign="top">0.11</td>
<td align="center" valign="top">13.41</td>
<td align="center" valign="top">824</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">1.3</td>
<td align="center" valign="top">1.75</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>VALENCE:AGENT(2-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">-0.02</td>
<td align="center" valign="top">0.23</td>
<td align="center" valign="top">-0.11</td>
<td align="center" valign="top">824</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.91</td>
<td align="center" valign="top">-0.47</td>
<td align="center" valign="top">0.42</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>VALENCE:AGENT(3-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">-0.11</td>
<td align="center" valign="top">0.23</td>
<td align="center" valign="top">-0.5</td>
<td align="center" valign="top">824</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.61</td>
<td align="center" valign="top">-0.56</td>
<td align="center" valign="top">0.33</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>VALENCE:AGENT(4-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">-0.18</td>
<td align="center" valign="top">0.23</td>
<td align="center" valign="top">-0.77</td>
<td align="center" valign="top">824</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.44</td>
<td align="center" valign="top">-0.62</td>
<td align="center" valign="top">0.27</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8" style="background-color:#d9e2f3"><bold>Average valence effect</bold>: b=-0.49, F(1,824)=36.47, p&lt;0.001
<break/><bold>Any interaction</bold>: F(3,824)=0.25 p=0.85</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<table-wrap id="tblS19" position="float" orientation="portrait">
<label>Table 19:</label>
<caption><title>Mixed-effects linear regression model regressing CA on feedback-valence and agentcredibility, based on credibility-valence-CA fits of free-credibility Bayesian model simulations.</title>
<p>We found an overall negative valence effect, with no interactions with agent credibility.</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl26.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top" colspan="8">FREE-CREDIBILITY BAYESIAN SIMULATIONS</th>
</tr>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top">Name</th>
<th align="center" valign="top">Estimate</th>
<th align="center" valign="top">SE</th>
<th align="center" valign="top">tStat</th>
<th align="center" valign="top">DF</th>
<th align="center" valign="top">pValue</th>
<th align="center" valign="top">Lower</th>
<th align="center" valign="top">Upper</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>(Intercept)</bold></td>
<td align="center" valign="top">-0.1</td>
<td align="center" valign="top">0.1</td>
<td align="center" valign="top">-0.99</td>
<td align="center" valign="top">824</td>
<td align="center" valign="top">0.32</td>
<td align="center" valign="top">-0.31</td>
<td align="center" valign="top">0.1</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>VALENCE</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">-0.68</td>
<td align="center" valign="top">0.2</td>
<td align="center" valign="top">-3.37</td>
<td align="center" valign="top">824</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
<td align="center" valign="top">-1.07</td>
<td align="center" valign="top">-0.28</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(2-STAR)</bold></td>
<td align="center" valign="top">0.44</td>
<td align="center" valign="top">0.14</td>
<td align="center" valign="top">3.1</td>
<td align="center" valign="top">824</td>
<td align="center" valign="top">0.002</td>
<td align="center" valign="top">0.16</td>
<td align="center" valign="top">0.72</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(3-STAR)</bold></td>
<td align="center" valign="top">1.03</td>
<td align="center" valign="top">0.14</td>
<td align="center" valign="top">7.27</td>
<td align="center" valign="top">824</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">0.75</td>
<td align="center" valign="top">1.31</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(4-STAR)</bold></td>
<td align="center" valign="top">2.28</td>
<td align="center" valign="top">0.14</td>
<td align="center" valign="top">16.13</td>
<td align="center" valign="top">824</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">2.01</td>
<td align="center" valign="top">2.56</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>VALENCE:AGENT(2-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.05</td>
<td align="center" valign="top">0.28</td>
<td align="center" valign="top">0.17</td>
<td align="center" valign="top">824</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.86</td>
<td align="center" valign="top">-0.51</td>
<td align="center" valign="top">0.6</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>VALENCE:AGENT(3-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">-0.07</td>
<td align="center" valign="top">0.28</td>
<td align="center" valign="top">-0.25</td>
<td align="center" valign="top">824</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.8</td>
<td align="center" valign="top">-0.63</td>
<td align="center" valign="top">0.48</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>VALENCE:AGENT(4-STAR)</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">-0.1</td>
<td align="center" valign="top">0.28</td>
<td align="center" valign="top">-0.36</td>
<td align="center" valign="top">824</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.72</td>
<td align="center" valign="top">-0.66</td>
<td align="center" valign="top">0.45</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8" style="background-color:#d9e2f3"><bold>Average valence effect</bold>: b=-0.71, F(1,824)=49.8, p&lt;0.001
<break/><bold>Any interaction</bold>: F(3,824)=0.11 p=0.95</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
</sec>
</sec>
<sec id="s6-3-2">
<label>3.2.</label>
<title>Additional analyses of model parameters main study</title>
<sec id="s6-3-2-1">
<label>3.2.1</label>
<title>Main study</title>
<sec id="s6-3-2-1-1">
<label>3.2.1.1</label>
<title>Comparison of empirical-aVBI and instructed-credibility Bayesian-aVBI</title>
<p>In this section we provide full result tables for the sections “Individuals show a positivity bias in learning” and “Positivity bias increases for sources of limited credibility”; and <xref ref-type="fig" rid="fig5">figure 5a</xref> and <xref ref-type="fig" rid="fig5">5b</xref>. For each individual and credibility level we calculated the absolute Valence Bias Index (aVBI), defined as the difference between the Credit Assignment for positive (CA+) and negative feedback (CA-).</p>
<table-wrap id="tblS20" position="float" orientation="portrait">
<label>Table 20:</label>
<caption><title>Statistics summarizing Wilcoxon test results comparing aVBI from participants with the one from instructed-credibility Bayesian simulations.</title>
<p>Participants showed a greater aVBI than predicted by the instructed-credibility Bayesian model, for all levels of credibility.</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl27.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top">Name</th>
<th align="center" valign="top">Median difference</th>
<th align="center" valign="top">z</th>
<th align="center" valign="top">pValue</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>50% credibility</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">1.34</td>
<td align="center" valign="top">5.20</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>75% credibility</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">1.34</td>
<td align="center" valign="top">5.94</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>100% credibility</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">1.10</td>
<td align="center" valign="top">5.87</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<table-wrap id="tblS21" position="float" orientation="portrait">
<label>Table 21:</label>
<caption><title>Statistics summarizing Wilcoxon test results comparing aVBI from participants with the one from free-credibility Bayesian simulations.</title>
<p>Participants showed a greater aVBI than predicted by the free-credibility Bayesian model, for all levels of credibility.</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl28.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top">Name</th>
<th align="center" valign="top">Median difference</th>
<th align="center" valign="top">z</th>
<th align="center" valign="top">pValue</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>50% credibility</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">1.02</td>
<td align="center" valign="top">5.95</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>75% credibility</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">1.21</td>
<td align="center" valign="top">6.13</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>100% credibility</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">1.21</td>
<td align="center" valign="top">5.36</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
<sec id="s6-3-2-1-2">
<label>3.2.1.2</label>
<title>rVBI for Bayesian models</title>
<p>In this section we provide full result tables for the section “Positivity bias increases for sources of limited credibility”; and <xref ref-type="fig" rid="fig5">figure 5c</xref>.</p>
<table-wrap id="tblS22" position="float" orientation="portrait">
<label>Table 22:</label>
<caption><title>Mixed-effects linear regression model regressing rVBIs on agent-credibility, based on credibility-valence-CA fits of instructed-credibility Bayesian model simulations.</title>
<p>The instructed-credibility Bayesian model predicted a negative rVBI for all credibility levels, with an increase in rVBI for higher credibility-levels.</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl29.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top" colspan="8">INSTRUCTED-CREDIBILITY BAYESIAN SIMULATIONS</th>
</tr>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top">Name</th>
<th align="center" valign="top">Estimate</th>
<th align="center" valign="top">SE</th>
<th align="center" valign="top">tStat</th>
<th align="center" valign="top">DF</th>
<th align="center" valign="top">pValue</th>
<th align="center" valign="top">Lower</th>
<th align="center" valign="top">Upper</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>(Intercept)</bold></td>
<td align="center" valign="top">-0.20</td>
<td align="center" valign="top">0.06</td>
<td align="center" valign="top">-3.38</td>
<td align="center" valign="top">609</td>
<td align="center" valign="top">&lt;0.001</td>
<td align="center" valign="top">-0.32</td>
<td align="center" valign="top">-0.08</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(2-STAR)</bold></td>
<td align="center" valign="top">0.07</td>
<td align="center" valign="top">0.03</td>
<td align="center" valign="top">2.24</td>
<td align="center" valign="top">609</td>
<td align="center" valign="top">0.026</td>
<td align="center" valign="top">0.01</td>
<td align="center" valign="top">0.14</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(3-STAR)</bold></td>
<td align="center" valign="top">0.10</td>
<td align="center" valign="top">0.03</td>
<td align="center" valign="top">2.91</td>
<td align="center" valign="top">609</td>
<td align="center" valign="top">0.04</td>
<td align="center" valign="top">0.03</td>
<td align="center" valign="top">0.16</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8" style="background-color:#d9e2f3"><bold>Average rVBI effect</bold>: b=-0.14, F(1,609)=6.49, p=0.011
<break/><bold>Any interaction</bold>: F(2,609)=4.64 p=0.01</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<table-wrap id="tblS23" position="float" orientation="portrait">
<label>Table 23:</label>
<caption><title>Mixed-effects linear regression model regressing rVBIs on agent-credibility, based on credibility-valence-CA fits of free-credibility Bayesian model simulations.</title>
<p>We found a negative relative valence effect, with no interactions with agent credibility.</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl30.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top" colspan="8">FREE-CREDIBILITY BAYESIAN SIMULATIONS</th>
</tr>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top">Name</th>
<th align="center" valign="top">Estimate</th>
<th align="center" valign="top">SE</th>
<th align="center" valign="top">tStat</th>
<th align="center" valign="top">DF</th>
<th align="center" valign="top">pValue</th>
<th align="center" valign="top">Lower</th>
<th align="center" valign="top">Upper</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>(Intercept)</bold></td>
<td align="center" valign="top">-0.15</td>
<td align="center" valign="top">0.06</td>
<td align="center" valign="top">-2.64</td>
<td align="center" valign="top">609</td>
<td align="center" valign="top">0.008</td>
<td align="center" valign="top">-0.27</td>
<td align="center" valign="top">0.04</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(2-STAR)</bold></td>
<td align="center" valign="top">-0.03</td>
<td align="center" valign="top">0.03</td>
<td align="center" valign="top">-0.95</td>
<td align="center" valign="top">609</td>
<td align="center" valign="top">0.34</td>
<td align="center" valign="top">-0.09</td>
<td align="center" valign="top">0.03</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(3-STAR)</bold></td>
<td align="center" valign="top">-0.02</td>
<td align="center" valign="top">0.03</td>
<td align="center" valign="top">-0.67</td>
<td align="center" valign="top">609</td>
<td align="center" valign="top">0.50</td>
<td align="center" valign="top">-0.08</td>
<td align="center" valign="top">0.04</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8" style="background-color:#d9e2f3"><bold>Average rVBI effect</bold>: b=-0.17, F(1,609)=9.55, p=0.002
<break/><bold>Any interaction</bold>: F(2,609)=0.48 p=0.63</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
</sec>
<sec id="s6-3-2-2">
<label>3.2.2</label>
<title>Discovery study</title>
<sec id="s6-3-2-2-1">
<label>3.2.2.1</label>
<title>Comparison of empirical-aVBI and Bayesian-aVBI</title>
<p>In this section we provide full result tables for the SI Discovery study sections “Individuals show a positivity bias in learning” and “Positivity bias increases for sources of limited credibility”; and <xref ref-type="fig" rid="figS3">SI figure 3a</xref> and <xref ref-type="fig" rid="figS3">3b</xref>.</p>
<table-wrap id="tblS24" position="float" orientation="portrait">
<label>Table 24:</label>
<caption><title>Statistics summarizing Wilcoxon test results comparing aVBI from participants with the one from instructed-credibility Bayesian simulations.</title>
<p>Participants showed a greater aVBI than predicted by the instructed-credibility Bayesian model, for all levels of credibility.</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl31.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top" colspan="8">INSTRUCTED-CREDIBILITY BAYESIAN SIMULATIONS</th>
</tr>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top">Name</th>
<th align="center" valign="top">Median difference</th>
<th align="center" valign="top">Z</th>
<th align="center" valign="top">pValue</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>50% credibility</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">1.04</td>
<td align="center" valign="top">3.63</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>70% credibility</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">1.58</td>
<td align="center" valign="top">5.27</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>85% credibility</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">1.49</td>
<td align="center" valign="top">4.70</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>100% credibility</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.93</td>
<td align="center" valign="top">2.82</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.005</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<table-wrap id="tblS25" position="float" orientation="portrait">
<label>Table 25:</label>
<caption><title>Statistics summarizing Wilcoxon test results comparing aVBI from participants with the one from free-credibility Bayesian simulations.</title>
<p>Participants showed a greater aVBI than predicted by the free-credibility Bayesian model, for all levels of credibility.</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl32.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top" colspan="8">FREE-CREDIBILITY BAYESIAN SIMULATIONS</th>
</tr>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top">Name</th>
<th align="center" valign="top">Median difference</th>
<th align="center" valign="top">Z</th>
<th align="center" valign="top">pValue</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>50% credibility</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">1.43</td>
<td align="center" valign="top">3.99</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>70% credibility</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">1.70</td>
<td align="center" valign="top">5.44</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>85% credibility</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">1.59</td>
<td align="center" valign="top">4.78</td>
<td align="center" valign="top" style="background-color:#d9e2f3">&lt;0.001</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#d9e2f3"><bold>100% credibility</bold></td>
<td align="center" valign="top" style="background-color:#d9e2f3">1.06</td>
<td align="center" valign="top">3.06</td>
<td align="center" valign="top" style="background-color:#d9e2f3">0.002</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
<sec id="s6-3-2-2-2">
<label>3.2.2.2</label>
<title>rVBI for Bayesian models</title>
<p>In this section we provide full result tables for the SI Discovery study section “Positivity bias increases for sources of limited credibility”; and <xref ref-type="fig" rid="figS3">SI figure 3c</xref>.</p>
<table-wrap id="tblS26" position="float" orientation="portrait">
<label>Table 26:</label>
<caption><title>Mixed-effects linear regression model regressing rVBIs on agent-credibility, based on credibility-valence-CA fits of instructed-credibility Bayesian model simulations.</title>
<p>We found no relative valence effect, with no interactions with agent credibility.</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl33.tif" mime-subtype="tif" mimetype="image"/>
<graphic xlink:href="st4kgv5_tbl34.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top" colspan="8">INSTRUCTED-CREDIBILITY BAYESIAN SIMULATIONS</th>
</tr>
<tr>
<th align="center" valign="top" style="background-color:#e7e6e6">Name</th>
<th align="center" valign="top">Estimate</th>
<th align="center" valign="top">SE</th>
<th align="center" valign="top">tStat</th>
<th align="center" valign="top">DF</th>
<th align="center" valign="top">pValue</th>
<th align="center" valign="top">Lower</th>
<th align="center" valign="top">Upper</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>(Intercept)</bold></td>
<td align="center" valign="top">-0.06</td>
<td align="center" valign="top">0.08</td>
<td align="center" valign="top">-0.78</td>
<td align="center" valign="top">412</td>
<td align="center" valign="top">0.44</td>
<td align="center" valign="top">-0.21</td>
<td align="center" valign="top">0.092</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(2-STAR)</bold></td>
<td align="center" valign="top">-0.05</td>
<td align="center" valign="top">0.04</td>
<td align="center" valign="top">-1.26</td>
<td align="center" valign="top">412</td>
<td align="center" valign="top">0.21</td>
<td align="center" valign="top">-0.13</td>
<td align="center" valign="top">0.03</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(3-STAR)</bold></td>
<td align="center" valign="top">-0.02</td>
<td align="center" valign="top">0.04</td>
<td align="center" valign="top">-0.44</td>
<td align="center" valign="top">412</td>
<td align="center" valign="top">0.66</td>
<td align="center" valign="top">-0.10</td>
<td align="center" valign="top">0.06</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(4-STAR)</bold></td>
<td align="center" valign="top">-0.03</td>
<td align="center" valign="top">0.04</td>
<td align="center" valign="top">-0.78</td>
<td align="center" valign="top">412</td>
<td align="center" valign="top">0.44</td>
<td align="center" valign="top">-0.11</td>
<td align="center" valign="top">0.05</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8" style="background-color:#d9e2f3"><bold>Average rVBI effect</bold>: b=-0.085, F(1,412)=1.32, p=0.25
<break/><bold>Any interaction</bold>: F(3,412)=0.57 p=0.64</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<table-wrap id="tblS27" position="float" orientation="portrait">
<label>Table 27:</label>
<caption><title>Mixed-effects linear regression model regressing rVBIs on agent-credibility, based on credibility-valence-CA fits of free-credibility Bayesian model simulations.</title>
<p>We found no relative valence effect, with no interactions with agent credibility.</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl35.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top" colspan="8">FREE-CREDIBILITY BAYESIAN SIMULATIONS</th>
</tr>
<tr style="background-color:#e7e6e6">
<th align="center" valign="top">Name</th>
<th align="center" valign="top">Estimate</th>
<th align="center" valign="top">SE</th>
<th align="center" valign="top">tStat</th>
<th align="center" valign="top">DF</th>
<th align="center" valign="top">pValue</th>
<th align="center" valign="top">Lower</th>
<th align="center" valign="top">Upper</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>(Intercept)</bold></td>
<td align="center" valign="top">-0.02</td>
<td align="center" valign="top">0.08</td>
<td align="center" valign="top">-0.21</td>
<td align="center" valign="top">412</td>
<td align="center" valign="top">0.83</td>
<td align="center" valign="top">-0.17</td>
<td align="center" valign="top">0.14</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(2-STAR)</bold></td>
<td align="center" valign="top">-0.02</td>
<td align="center" valign="top">0.04</td>
<td align="center" valign="top">-0.59</td>
<td align="center" valign="top">412</td>
<td align="center" valign="top">0.55</td>
<td align="center" valign="top">-0.10</td>
<td align="center" valign="top">0.05</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(3-STAR)</bold></td>
<td align="center" valign="top">0.007</td>
<td align="center" valign="top">0.04</td>
<td align="center" valign="top">0.19</td>
<td align="center" valign="top">412</td>
<td align="center" valign="top">0.85</td>
<td align="center" valign="top">-0.07</td>
<td align="center" valign="top">0.08</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold>AGENT(4-STAR)</bold></td>
<td align="center" valign="top">-0.02</td>
<td align="center" valign="top">0.04</td>
<td align="center" valign="top">-0.43</td>
<td align="center" valign="top">412</td>
<td align="center" valign="top">0.66</td>
<td align="center" valign="top">-0.10</td>
<td align="center" valign="top">0.06</td>
</tr>
<tr>
<td align="left" valign="top" colspan="8" style="background-color:#d9e2f3"><bold>Average rVBI effect</bold>: b=-0.024, F(1,412)=0.11, p=0.74
<break/><bold>Any interaction</bold>: F(3,412)=0.26, p=0.85</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
</sec>
</sec>
<sec id="s6-3-3">
<label>3.3</label>
<title>Distribution of fitted parameters</title>
<sec id="s6-3-3-1">
<label>3.3.1</label>
<title>Main study</title>
<table-wrap id="tblS28" position="float" orientation="portrait">
<label>Table 28:</label>
<caption><title>fitted parameters from participants for our main CA models.</title><p>Values represent the group mean (sd).</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl36.tif" mime-subtype="tif" mimetype="image"/>
<graphic xlink:href="st4kgv5_tbl37.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr>
<th align="center" valign="top"/>
<th align="center" valign="top" style="background-color:#e7e6e6">Credibility-CA</th>
<th align="center" valign="top" style="background-color:#e7e6e6">Credibility Valence CA</th>
<th align="center" valign="top" style="background-color:#e7e6e6">Truth CA</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><inline-formula id="ID2">
<alternatives>
<mml:math display="inline" id="I2"><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi><mml:msubsup><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mrow><mml:mn mathvariant="bold">0.5</mml:mn></mml:mrow><mml:mo mathvariant="bold">−</mml:mo></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="st4kgv5_ieq2.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
</inline-formula></td>
<td align="center" valign="middle" rowspan="2">0.23 (0.41)</td>
<td align="center" valign="top">-0.01 (1.55)</td>
<td align="center" valign="middle" rowspan="2">0.23 (0.42)</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><inline-formula id="ID3">
<alternatives>
<mml:math display="inline" id="I3"><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi><mml:msubsup><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mrow><mml:mn mathvariant="bold">0.5</mml:mn></mml:mrow><mml:mo mathvariant="bold">+</mml:mo></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="st4kgv5_ieq3.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
</inline-formula></td>
<td align="center" valign="top">0.59 (1.87)</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><inline-formula id="ID4">
<alternatives>
<mml:math display="inline" id="I4"><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi><mml:msubsup><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mrow><mml:mn mathvariant="bold">0.75</mml:mn></mml:mrow><mml:mo mathvariant="bold">−</mml:mo></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="st4kgv5_ieq4.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
</inline-formula></td>
<td align="center" valign="middle" rowspan="2">0.45 (0.50)</td>
<td align="center" valign="top">0.17 (1.48)</td>
<td align="center" valign="middle" rowspan="2">0.39 (0.51)</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><inline-formula id="ID5">
<alternatives>
<mml:math display="inline" id="I5"><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi><mml:msubsup><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mrow><mml:mn mathvariant="bold">0.75</mml:mn></mml:mrow><mml:mo mathvariant="bold">+</mml:mo></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="st4kgv5_ieq5.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
</inline-formula></td>
<td align="center" valign="top">0.81 (1.85)</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><inline-formula id="ID6">
<alternatives>
<mml:math display="inline" id="I6"><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi><mml:msubsup><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mrow><mml:mn mathvariant="bold">1</mml:mn></mml:mrow><mml:mo mathvariant="bold">−</mml:mo></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="st4kgv5_ieq6.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
</inline-formula></td>
<td align="center" valign="middle" rowspan="2">1.47 (1.07)</td>
<td align="center" valign="top">1.28 (1.70)</td>
<td align="center" valign="middle" rowspan="2">1.35 (1.10)</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><inline-formula id="ID7">
<alternatives>
<mml:math display="inline" id="I7"><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi><mml:msubsup><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mrow><mml:mn mathvariant="bold">1</mml:mn></mml:mrow><mml:mo mathvariant="bold">+</mml:mo></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="st4kgv5_ieq7.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
</inline-formula></td>
<td align="center" valign="top">1.80 (2.42)</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><italic><bold>TB</bold></italic></td>
<td align="center" valign="top" colspan="2" style="background-color:#000000"/>
<td align="center" valign="top">0.21 (0.94)</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold><italic>f<sub>Q</sub></italic></bold></td>
<td align="center" valign="top">0.25 (0.26)</td>
<td align="center" valign="top">0.27 (0.28)</td>
<td align="center" valign="top">0.25 (0.26)</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold><italic>PERS</italic></bold></td>
<td align="center" valign="top">0.63 (0.36)</td>
<td align="center" valign="top">0.48 (1.44)</td>
<td align="center" valign="top">0.63 (0.38)</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold><italic>f<sub>P</sub></italic></bold></td>
<td align="center" valign="top">0.16 (0.19)</td>
<td align="center" valign="top">0.28 (0.34)</td>
<td align="center" valign="top">0.16 (0.19)</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<fig id="figS10" position="float" fig-type="figure">
<label>SI Figure 10:</label>
<caption><title>Distribution of ML parameters from participants fitted with the Credibility-CA model.</title></caption>
<graphic xlink:href="st4kgv5_fig16.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<fig id="figS11" position="float" fig-type="figure">
<label>SI Figure 11:</label>
<caption><title>Distribution of ML parameters from participants fitted with the Credibility-Valence CA model.</title></caption>
<graphic xlink:href="st4kgv5_fig17.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<fig id="figS12" position="float" fig-type="figure">
<label>SI Figure 12:</label>
<caption><title>Distribution ML parameters from participants fitted with the Truth CA model.</title></caption>
<graphic xlink:href="st4kgv5_fig18.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<table-wrap id="tblS29" position="float" orientation="portrait">
<label>Table 29:</label>
<caption><title>fitted parameters from participants for our main Bayesian models.</title><p>Values represent the group mean (sd).</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl38.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr>
<th align="center" valign="top"/>
<th align="center" valign="top" style="background-color:#e7e6e6">Instructed-credibility</th>
<th align="center" valign="top" style="background-color:#e7e6e6">Free-credibility</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold><italic>β</italic></bold></td>
<td align="center" valign="top">4.26(3.02)</td>
<td align="center" valign="top">4.96 (3.34)</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold><italic>C</italic><sub>0.5</sub></bold></td>
<td align="center" valign="top" style="background-color:#000000"/>
<td align="center" valign="top">0.60 (0.23)</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold><italic>C</italic><sub>0.75</sub></bold></td>
<td align="center" valign="top" style="background-color:#000000"/>
<td align="center" valign="top">0.65 (0.23)</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<fig id="figS13" position="float" fig-type="figure">
<label>SI Figure 13:</label>
<caption><title>Distribution ML parameters from participants fitted with (a) the Instructed-credibility Bayesian model, and (b) the free-credibility Bayesian model.</title></caption>
<graphic xlink:href="st4kgv5_fig19.tif" mime-subtype="tif" mimetype="image"/>
</fig>
</sec>
<sec id="s6-3-3-2">
<label>3.3.2</label>
<title>Discovery study</title>
<table-wrap id="tblS30" position="float" orientation="portrait">
<label>Table 30:</label>
<caption><title>fitted parameters from participants for our main CA models.</title><p>Values represent the group mean (sd).</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl39.tif" mime-subtype="tif" mimetype="image"/>
<graphic xlink:href="st4kgv5_tbl40.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr>
<th align="center" valign="top" style="background-color:#e7e6e6"/>
<th align="center" valign="top" style="background-color:#e7e6e6">Credibility-CA</th>
<th align="center" valign="top" style="background-color:#e7e6e6">Credibility-Valence CA</th>
<th align="center" valign="top" style="background-color:#e7e6e6">Truth CA</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><inline-formula id="ID8">
<alternatives>
<mml:math display="inline" id="I8"><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi><mml:msubsup><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mrow><mml:mn mathvariant="bold">0.5</mml:mn></mml:mrow><mml:mo mathvariant="bold">−</mml:mo></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="st4kgv5_ieq8.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
</inline-formula></td>
<td align="center" valign="middle" rowspan="2">-0.13 (0.81)</td>
<td align="center" valign="top">-0.50 (1.88)</td>
<td align="center" valign="middle" rowspan="2">-0.24 (1.47)</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><inline-formula id="ID9">
<alternatives>
<mml:math display="inline" id="I9"><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi><mml:msubsup><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mrow><mml:mn mathvariant="bold">0.5</mml:mn></mml:mrow><mml:mo mathvariant="bold">+</mml:mo></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="st4kgv5_ieq9.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
</inline-formula></td>
<td align="center" valign="top">0.39 (2.14)</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><inline-formula id="ID10">
<alternatives>
<mml:math display="inline" id="I10"><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi><mml:msubsup><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mrow><mml:mn mathvariant="bold">0.7</mml:mn></mml:mrow><mml:mo mathvariant="bold">−</mml:mo></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="st4kgv5_ieq10.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
</inline-formula></td>
<td align="center" valign="middle" rowspan="2">0.37 (0.70)</td>
<td align="center" valign="top">-0.31 (1.87)</td>
<td align="center" valign="middle" rowspan="2">-0.06 (1.69)</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><inline-formula id="ID11">
<alternatives>
<mml:math display="inline" id="I11"><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi><mml:msubsup><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mrow><mml:mn mathvariant="bold">0.7</mml:mn></mml:mrow><mml:mo mathvariant="bold">+</mml:mo></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="st4kgv5_ieq11.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
</inline-formula></td>
<td align="center" valign="top">1.23 (2.29)</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><inline-formula id="ID12">
<alternatives>
<mml:math display="inline" id="I12"><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi><mml:msubsup><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mrow><mml:mn mathvariant="bold">0.85</mml:mn></mml:mrow><mml:mo mathvariant="bold">−</mml:mo></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="st4kgv5_ieq12.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
</inline-formula></td>
<td align="center" valign="middle" rowspan="2">1.14 (0.99)</td>
<td align="center" valign="top">0.90 (1.67)</td>
<td align="center" valign="middle" rowspan="2">0.02 (1.72)</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><inline-formula id="ID13">
<alternatives>
<mml:math display="inline" id="I13"><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi><mml:msubsup><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mrow><mml:mn mathvariant="bold">0.85</mml:mn></mml:mrow><mml:mo mathvariant="bold">+</mml:mo></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="st4kgv5_ieq13.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
</inline-formula></td>
<td align="center" valign="top">1.78 (2.21)</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><inline-formula id="ID14">
<alternatives>
<mml:math display="inline" id="I14"><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi><mml:msubsup><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mrow><mml:mn mathvariant="bold">1</mml:mn></mml:mrow><mml:mo mathvariant="bold">−</mml:mo></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="st4kgv5_ieq14.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
</inline-formula></td>
<td align="center" valign="middle" rowspan="2">2.56 (2.10)</td>
<td align="center" valign="top">2.62 (2.51)</td>
<td align="center" valign="middle" rowspan="2">0.98 (2.72)</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><inline-formula id="ID15">
<alternatives>
<mml:math display="inline" id="I15"><mml:mrow><mml:mi mathvariant="bold-italic">C</mml:mi><mml:msubsup><mml:mi mathvariant="bold-italic">A</mml:mi><mml:mrow><mml:mn mathvariant="bold">1</mml:mn></mml:mrow><mml:mo mathvariant="bold">+</mml:mo></mml:msubsup></mml:mrow></mml:math>
<inline-graphic xlink:href="st4kgv5_ieq15.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
</inline-formula></td>
<td align="center" valign="top">2.90 (2.77)</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold><italic>TB</italic></bold></td>
<td align="center" valign="top" colspan="2" style="background-color:#000000"/>
<td align="center" valign="top">3.18 (3.26)</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold><italic>f<sub>Q</sub></italic></bold></td>
<td align="center" valign="top">0.26 (0.21)</td>
<td align="center" valign="top">0.23 (0.23)</td>
<td align="center" valign="top">0.47 (0.33)</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold><italic>PERS</italic></bold></td>
<td align="center" valign="top">1.24 (0.95)</td>
<td align="center" valign="top">0.87 (1.66)</td>
<td align="center" valign="top">2.43 (1.55)</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold><italic>f<sub>P</sub></italic></bold></td>
<td align="center" valign="top">0.51 (0.33)</td>
<td align="center" valign="top">0.63 (0.41)</td>
<td align="center" valign="top">0.43 (0.28)</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<fig id="figS14" position="float" fig-type="figure">
<label>SI Figure 14:</label>
<caption><title>Distribution of ML parameters from participants fitted with the Credibility-CA model.</title></caption>
<graphic xlink:href="st4kgv5_fig20.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<fig id="figS15" position="float" fig-type="figure">
<label>SI Figure 15:</label>
<caption><title>Distribution of ML parameters from participants fitted with the Credibility-Valence CA model.</title></caption>
<graphic xlink:href="st4kgv5_fig21.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<fig id="figS16" position="float" fig-type="figure">
<label>SI Figure 16:</label>
<caption><title>Distribution ML parameters from participants fitted with the Truth CA model.</title></caption>
<graphic xlink:href="st4kgv5_fig22.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<table-wrap id="tblS31" position="float" orientation="portrait">
<label>Table 31:</label>
<caption><title>fitted parameters from participants for our main Bayesian models.</title><p>Values represent the group mean (sd).</p></caption>
<alternatives>
<graphic xlink:href="st4kgv5_tbl41.tif" mime-subtype="tif" mimetype="image"/>
<table frame="box" rules="all">
<thead>
<tr>
<th align="center" valign="top"/>
<th align="center" valign="top" style="background-color:#e7e6e6">Instructed-credibility</th>
<th align="center" valign="top" style="background-color:#e7e6e6">Free-credibility</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold><italic>β</italic></bold></td>
<td align="center" valign="top">9.70 (5.25)</td>
<td align="center" valign="top">13.11 (7.14)</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold><italic>C</italic><sub>0.5</sub></bold></td>
<td align="center" valign="top" style="background-color:#000000"/>
<td align="center" valign="top">0.50 (0.20)</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold><italic>C</italic><sub>0.7</sub></bold></td>
<td align="center" valign="top" style="background-color:#000000"/>
<td align="center" valign="top">0.59 (0.20)</td>
</tr>
<tr>
<td align="center" valign="top" style="background-color:#e7e6e6"><bold><italic>C</italic><sub>0.85</sub></bold></td>
<td align="center" valign="top" style="background-color:#000000"/>
<td align="center" valign="top">0.76 (0.18)</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<fig id="figS17" position="float" fig-type="figure">
<label>SI Figure 17:</label>
<caption><title>Distribution ML parameters from participants fitted with (a) the Instructed-credibility Bayesian model, and (b) the free-credibility Bayesian model.</title></caption>
<graphic xlink:href="st4kgv5_fig23.tif" mime-subtype="tif" mimetype="image"/>
</fig>
</sec>
</sec>
<sec id="s6-3-4">
<label>3.4</label>
<title>Parameter and model recovery</title>
<fig id="figS18" position="float" fig-type="figure">
<label>SI Figure 18:</label>
<caption><title>Parameter recovery for parameters of interest from free-credibility Bayesian model.</title>
<p><bold>a</bold>, Recovery for the credibility parameter of the 1-star agent. <bold>b</bold>, Recovery for the credibility parameter of the 2-star agent. Recoverability is represented by scatter plots between the generative credibility parameters used to create the synthetic datasets (x-axis) and the corresponding credibility parameters fitted from those datasets (y-axis). Circles represent the datapoints of individual simulations, the denoted metric “r” corresponds to the Spearman correlation between the generative and fitted parameters.</p></caption>
<graphic xlink:href="st4kgv5_fig24.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<fig id="figS19" position="float" fig-type="figure">
<label>SI Figure 19:</label>
<caption><title>Parameter recovery for parameters of interest from credibility-CA model.</title>
<p>Recovery for the CA parameter of the 1-star agent (<bold>a</bold>), 2-star agent (<bold>b</bold>), and 3-star agent (<bold>c</bold>). Recoverability is represented by scatter plots between the generative CA parameters used to create the synthetic datasets (x-axis) and the corresponding CA parameters fitted from those datasets (y-axis). Circles represent the datapoints of individual simulations, the denoted metric “r” corresponds to the Spearman correlation between the generative and fitted parameters.</p></caption>
<graphic xlink:href="st4kgv5_fig25.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<fig id="figS20" position="float" fig-type="figure">
<label>SI Figure 20:</label>
<caption><title>Parameter recovery for parameters and metrics of interest from credibility-valence-CA model.</title>
<p>Recovery for the CA<sup>−</sup> and CA<sup>+</sup> parameters (<bold>top two rows</bold>) and their associated absolute valence bias (aVBI) and relative valence bias (rVBI) (<bold>bottom two rows</bold>) for the 1-star agent (<bold>a, d, g, j</bold>), 2-star agent (<bold>b, e, h, k</bold>), and 3-star agent (<bold>c, f, i, l</bold>). Recoverability is represented by scatter plots between the generative parameters/metrics used to create the synthetic datasets (x-axis) and the corresponding parameters/metrics fitted from those datasets (y-axis). Circles represent the datapoints of individual simulations, the denoted metric “r” corresponds to the Spearman correlation between the generative and fitted parameters.</p></caption>
<graphic xlink:href="st4kgv5_fig26.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<fig id="figS21" position="float" fig-type="figure">
<label>SI Figure 21:</label>
<caption><title>Model recovery assessment using Parametric Bootstrap Cross-fitting Method (PBCM), AIC, and BIC.</title>
<p>We ran a model recovery analysis to assess how well different model selection methods identify the generative models. We report confusions matrices for comparisons between each Bayesian model variant (Instructed-credibility: top; Free-credibility: bottom matrices) and the Credibility-CA model (without perseveration) for 3 model-comparison methods (PBCM-left; AIC- middle, BIC-right matrices). Each matrix cell displays the percentage of simulated datasets generated by the “row model” where the “column model” provided a better fit (e.g., the top right cell describes the proportion of datasets generated by a Bayesian variant, which were better fit by the Credibility-CA model). These proportions were calculated according to the following method (applied separately for each compared model-pair). For each model under comparison (Bayesian or Credibility-CA), we created 100 synthetic datasets per participant using their empirical maximum likelihood (ML) parameter estimates. Each of these synthetic datasets was then fitted with both models. Next, we calculated, for each participant (and each model-comparison method), individual-level 2x2 confusion matrices displaying the proportion of that individual’s “row model” generated datasets (out of 100) that was best fit by each of the two models. Finally, the matrices shown in the figure represent the across-participant average of these individual-level confusion matrices. The results clearly demonstrate that the PBCM provides an unbiased recovery of both the Bayesian and the Credibility-CA models, while achieving the highest rate of correct classifications (the average of main diagonal matrix cells). In contrast, both the AIC and BIC methods exhibit a significant bias towards selecting the Bayesian models, with a substantial (majority for BIC) selection of a Bayesian model as the winning model for data generated by the CA model.</p></caption>
<graphic xlink:href="st4kgv5_fig27.tif" mime-subtype="tif" mimetype="image"/>
</fig>
</sec>
<sec id="s6-3-5">
<label>3.5</label>
<title>Contrast effects for contexts featuring a different bandit</title>
<p>Given that we observed a contrast effect when both the learning and the immediately preceding “context trial” involved the same pair of bandits, we next investigated whether this effect persisted when the context trial featured a different bandit pair – a situation where the context would be irrelevant to the current learning. Again, we used in a binomial mixed effects model, regressing choicerepetition on feedback valence in the learning trial and the feedback agent in the context trial. This analysis included only learning trials featuring the 3-star agent, and context trials featuring a different bandit pair than the learning trial (<xref ref-type="fig" rid="figS22">Fig. S22a</xref>). We found no significant evidence of an interaction between feedback valence and contextual credibility (F(2,2364)=0.21, p=0.81) (<xref ref-type="fig" rid="figS22">Fig. S22b</xref>). This null result was consistent with the range of outcomes predicted by our main computational models (<xref ref-type="fig" rid="figS22">Fig. S22c</xref>).</p>
<fig id="figS22" position="float" fig-type="figure">
<label>Figure 22:</label>
<caption><title>Contextual effects and learning when the context trial features a different bandit pair than the learning trial.</title>
<p><bold>a</bold>, Trials contributing to the analysis of effects of credibility-context on learning from the fully credible agent. We included the same trials as in our main analysis, with one key the difference: we only included context trials featuring a different bandit pair than the learning and current trial. We examined how choicerepetition (from n-k to n) was modulated by feedback valence on the learning trial, and on the feedback agent on the context trial. Note the greyed-out star-rating on the current trial indicates the identity of the current agent and was not included in the analysis. <bold>b</bold>, Difference in probability of repeating a choice after receiving positive vs negative feedback (i.e., feedback effect) from the 3-star agent, as a function of the credibility context. We found no significant effect of the credibility context on learning from the 3-star agent. <bold>c</bold>, Difference in feedback valence effect on choice-repetition between contextual credibility pairs based on synthetic simulations of our alternative models. Histograms represent the distribution of regression coefficients based on 101 group-level synthetic datasets simulated based on each model. Participants’ results were within the range of effects predicted by our main models (more than 5% of group-level simulations predicted and equal or stronger effect). Big circles represent the group mean, and error bars show the standard error of the mean. (*) p&lt;.05, (**) p&lt;0.01.</p></caption>
<graphic xlink:href="st4kgv5_fig28.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<p>we aimed to formally compare the influence of two types of contextual trials: those featuring the same bandit pair as the learning trial versus those featuring a different pair. To achieve this, we extended our mixed-effects model by incorporating a new predictor variable, “<italic>CONTEXT_TYPE</italic>” which coded whether the contextual trial involved the same bandit pair (coded as −0.5) or a different bandit pair (+0.5) compared to the learning trial. The Wilkinson notation for this expanded mixed-effects model is:
<disp-formula id="FD26">
<alternatives>
<mml:math id="M26" display="block"><mml:mi>R</mml:mi><mml:mi>E</mml:mi><mml:mi>P</mml:mi><mml:mi>E</mml:mi><mml:mi>A</mml:mi><mml:mi>T</mml:mi><mml:mo>∼</mml:mo><mml:mi>C</mml:mi><mml:mi>O</mml:mi><mml:mi>N</mml:mi><mml:mi>T</mml:mi><mml:mi>E</mml:mi><mml:mi>X</mml:mi><mml:mi>T</mml:mi><mml:mo>_</mml:mo><mml:mi>T</mml:mi><mml:mi>Y</mml:mi><mml:mi>P</mml:mi><mml:mi>E</mml:mi><mml:mo>∗</mml:mo><mml:mi>F</mml:mi><mml:mi>E</mml:mi><mml:mi>E</mml:mi><mml:mi>D</mml:mi><mml:mi>B</mml:mi><mml:mi>A</mml:mi><mml:mi>C</mml:mi><mml:mi>K</mml:mi><mml:mo>∗</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:mi>O</mml:mi><mml:mi>N</mml:mi><mml:mi>T</mml:mi><mml:mi>E</mml:mi><mml:mi>X</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:mi>O</mml:mi><mml:mi>N</mml:mi><mml:mi>T</mml:mi><mml:mi>E</mml:mi><mml:mi>X</mml:mi><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mn>3</mml:mn><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:mi>E</mml:mi><mml:mi>T</mml:mi><mml:mi>T</mml:mi><mml:mi>E</mml:mi><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math>
<graphic xlink:href="st4kgv5_eqn26.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
</disp-formula>
</p>
<p>This expanded model revealed a significant three-way interaction between feedback valence, contextual credibility, and context type (F(2,4451) = 7.71, p&lt;0.001). Interpreting this interaction, we found a 2-way interaction between context-source and feedback valence when the context was the same (F(2,4451) = 12.03, p&lt;0.001), but not when context was different (F(2,4451) = 0.23, p = 0.79). Further interpreting the double feedback-valence * context-source interaction (for the same context) we obtained the same conclusions as reported in the main text.</p>
</sec>
<sec id="s6-3-6">
<label>3.6</label>
<title>Positivity bias results cannot be explained by a pure perseveration</title>
<sec id="s6-3-6-1">
<label>3.6.1</label>
<title>Main study</title>
<p>Previous research has suggested it may be challenging to dissociate between a feedback-valence positivity bias and perseveration (i.e., a tendency to repeat previous choices regardless of outcome). While our Credit Assignment (CA) models already include a perseveration mechanism to account for this, this control may not be perfect. We thus conducted several tests to examine if our positivity-bias related results could be accounted for by perseveration.</p>
<p>First we examined whether our Bayesian-models, augmented by a perseveration mechanism (as in our CA model) can generate predictions similar to our empirical results. We repeated our cross-fitting procedure to these extended Bayesian models. To briefly recap, this involved fitting participant behavior with them, generating synthetic datasets based on the resulting maximum likelihood (ML) parameters, and then fitting these simulated datasets with our Credibility-Valence CA model (which is designed to detect positivity bias). This test revealed that adding perseveration to our Bayesian models did not predict a positivity bias in learning. In absolute terms there was a small negativity bias (instructed-credibility Bayesian: b=-0.19, F(1,1218)=17.78, p&lt;0.001, <xref ref-type="fig" rid="figS23">Fig. S23a-b</xref>; free-credibility Bayesian: b=-0.17, F(1,1218)=13.74, p&lt;0.001, <xref ref-type="fig" rid="figS23">Fig. S23d-e</xref>). In relative terms we detected no valence related bias (instructed-credibility Bayesian: b=-0.034, F(1,609)=0.45, p=0.50, <xref ref-type="fig" rid="figS22">Fig. S22c</xref>; free-credibility Bayesian: b=-0.04, F(1,609)=0.51, p=0.47, <xref ref-type="fig" rid="figS23">Fig. S23f</xref>). More critically, these simulations also did not predict a change in the level of positivity bias as a function of feedback credibility, neither at an absolute level (instructed-credibility Bayesian: F(2,1218)=0.024, p=0.98, <xref ref-type="fig" rid="figS23">Fig. S23b</xref>; free-credibility Bayesian: F(2,1218)=0.008, p=0.99, <xref ref-type="fig" rid="figS23">Fig. S23e</xref>), nor at a relative level (instructed-credibility Bayesian: F(2,609)=1.57, p=0.21, <xref ref-type="fig" rid="figS23">Fig. S23c</xref>; free-credibility Bayesian: F(2,609)=0.13, p=0.88, <xref ref-type="fig" rid="figS23">Fig. S23f</xref>). The upshot is that our positivity-bias findings cannot be accounted for by our Bayesian models even when these are augmented with perseveration.</p>
<fig id="figS23" position="float" fig-type="figure">
<label>Figure 23:</label>
<caption><title>Predicted positivity bias as a function of agent-credibility based on Bayesian account including perseveration.</title>
<p><bold>a</bold>, ML parameters from fitting simulations of the instructed-credibility Bayesian model (with perseveration) with the credibility-valence-CA model. Simulations predict a negativity bias (CA+ &lt; CA-) for all credibility levels. <bold>b</bold>, Absolute valence bias index (defined as CA<sup>+</sup>-CA<sup>−</sup>) based on the ML parameters from the credibility-valence CA model. Positive values indicate a positivity bias, while negative values represent a negativity bias. <bold>c</bold>, Relative valence bias index (defined as (CA<sup>+</sup>-CA<sup>−</sup>)/(|CA<sup>+</sup>|+|CA<sup>−</sup>|)) based on the ML parameters from the credibility-valence CA model. Positive values indicate a positivity bias, while negative values represent a negativity bias. <bold>d-f</bold>, Same as a-c, but for simulations based in the extended version of the free-credibility Bayesian model (including perseveration). Small dots represent fitted parameters for individual participants and big diamonds/squares represent the group median (a,b,d,e) or mean (c,f) for the instructed/free-credibility Bayesian model simulations. Error bars show the standard error of the mean.</p></caption>
<graphic xlink:href="st4kgv5_fig29.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<p>However, it is still possible that empirical CA parameters from our credibility-valence model (reported in main text <xref ref-type="fig" rid="fig5">Fig. 5</xref>) were distorted, absorbing variance from a perseveration. To address this, we took a “devil’s advocate” approach testing the assumption that CA parameters are not <italic>truly</italic> affected by feedback valance and that there is only perseveration in our data. Towards that goal, we simulated data using our Credibility-CA model (which includes perseveration but does not contain a valence bias in its learning mechanism) and then fitted these synthetic datasets using our Credibility-Valence CA model to see if the observed positivity bias could be explained by perseveration alone. Specifically, we generated 101 “group-level” synthetic datasets (each including one simulation for each participant, based on their empirical ML parameters), and fitted each dataset with our Credibility-Valence CA model. We then analysed the resulting ML parameters in each dataset using the same mixed-effects models as described in the main text, examining the distribution of effects of interest across these simulated datasets. Comparing these simulation results to the data from participants revealed a nuanced picture. While the positivity bias observed in participants is within the range predicted by a pure perseveration account when measured in absolute terms (<xref ref-type="fig" rid="figS24">Fig. S24a</xref>), it is much higher than predicted by pure perseveration when measured relative to the overall level of learning (<xref ref-type="fig" rid="figS24">Fig. S24c</xref>). Interestingly, a pure perseveration account predicted an amplification of the relative positivity bias under low (compared to full) credibility (with the two rightmost histograms in <xref ref-type="fig" rid="figS24">Fig. S24d</xref> falling in the positive range). However, the magnitude of this effect was significantly smaller than the empirical effect (as the bulk of these same histograms lies below the green points). Moreover, this account predicted a negative amplification (i.e., attenuation) of an absolute positivity bias, which was again significantly smaller than the empirical effect (see corresponding histograms in S24b). This pattern raises an intriguing possibility that perseveration may, at least partially, mask a true amplification of absolute positivity bias.</p>
<fig id="figS24" position="float" fig-type="figure">
<label>Figure 24:</label>
<caption><title>Predicted positivity bias results for participants and for simulations of the Credibility-CA (including perseveration, but no valence-bias component).</title>
<p><bold>a</bold>, Valence bias results measured in absolute terms (by regressing the ML CA parameters, on their associated valence and credibility). <bold>b</bold>, Difference in positivity bias (measured in absolute terms) across credibility levels. On the x-axis, the hyphen (-) represents subtraction, such that a label of ‘0.5–1’ indicates the difference in the measurement for the 0.5 and 1.0 credibility conditions. Such differences are again based in the same mixed effects model as plot a. The inflation of aVBI for lower-credibility agents is larger than the one predicted by a pure perseveration account. <bold>c</bold>, Valence bias results measured in relative terms (by regressing the rVBIs on their associated credibility). Participants present a higher rVBI than what would be predicted by a perseveration account (except for the completely credible agent). <bold>d</bold>, Difference in rVBI across credibility levels. Such differences are again based in the same mixed effects model as plot c. The inflation of rVBI for lower-credibility agents is larger than the one predicted by a pure perseveration account. Histograms depict the distribution of coefficients from 101 simulated group-level datasets generated by the Credibility-CA model and fitted with the Credibility-Valence CA model. Gray circles represent the mean coefficient from these simulations, while black/green circles show the actual regression coefficients from participant behaviour (green for significant effects in participants, black for non-significant). Significance markers (* p&lt;.05, ** p&lt;.01) indicate that fewer than 5% or 1% of simulated datasets, respectively, predicted an effect as strong as or stronger than that observed in participants, and in the same direction as the participant effect.</p></caption>
<graphic xlink:href="st4kgv5_fig30.tif" mime-subtype="tif" mimetype="image"/>
</fig>
</sec>
<sec id="s6-3-6-2">
<label>3.6.2</label>
<title>Discovery study</title>
<p>We then replicated these analyses in our discovery study to confirm our findings. We again checked whether extended versions of the Bayesian models (including perseveration) predicted the positivity bias results observed. Our cross-fitting procedure showed that the instructed-credibility Bayesian model with perseveration did predict a positivity bias for all credibility levels in this discovery study, both when measured in absolute terms [50% credibility (b=1.74,t(824)=6.15), 70% credibility (b=2.00,F(1,824)=49.98), 85% credibility (b=1.81,F(1,824)=40.78), 100% credibility (b=2.42,F(1,824)=72.50), all p’s&lt;0.001], and in relative terms [50% credibility (b=0.25,t(412)=3.44), 70% credibility (b=0.31,F(1,412)=17.72), 85% credibility (b=0.34,F(1,412)=21.06), 100% credibility (b=0.42,F(1,412)=31.24), all p’s&lt;0.001]. However, importantly, these simulations did not reveal a significant change in the level of positivity bias as a function of feedback credibility, neither at an absolute level (F(3,412)=1.43,p=0.24), nor at a relative level (F(3,412)=2.06,p=0.13) (<xref ref-type="fig" rid="figS25">Fig. S25a-c</xref>). Numerically, the trend was towards an increasing (rather than decreasing) positivity bias as a function of credibility. In contrast, simulations of the free-credibility Bayesian model (with perseveration) predicted a slight negativity bias when measured in absolute terms (b=-0.35,F(1,824)=5.14,p=0.024), and no valence bias when measured relative to the overall degree of learning (b=0.05,F(1,412)=0.55,p=0.46). Crucially, this model also did not predict a change in the level of positivity bias as a function of feedback credibility, neither at an absolute level (F(3,824)=0.27,p=0.77), nor at a relative level (F(3,412)=0.76,p=0.47) (<xref ref-type="fig" rid="figS25">Fig. S25d-f</xref>).</p>
<fig id="figS25" position="float" fig-type="figure">
<label>Figure 25:</label>
<caption><title>Predicted positivity bias in discovery study as a function of agent-credibility based on Bayesian account including perseveration.</title>
<p><bold>a</bold>, ML parameters from fitting simulations of the instructed-credibility Bayesian model (with perseveration) with the credibility-valence-CA model. Simulations predict a positivity bias (CA+ &gt; CA-) for all credibility levels. <bold>b</bold>, Absolute valence bias index (defined as CA<sup>+</sup>-CA<sup>−</sup>) based on the ML parameters from the credibility-valence CA model. Positive values indicate a positivity bias, while negative values represent a negativity bias. <bold>c</bold>, Relative valence bias index (defined as (CA<sup>+</sup>-CA<sup>−</sup>)/(|CA<sup>+</sup>|+|CA<sup>−</sup>|)) based on the ML parameters from the credibility-valence CA model. Positive values indicate a positivity bias, while negative values represent a negativity bias. <bold>c-f</bold>, Same as a-c, but for simulations based in the extended version of the free-credibility Bayesian model (including perseveration). Small dots represent fitted parameters for individual participants and big diamonds/squares represent the group median (a,b,d,e) or mean (c,f) for the instructed/free-credibility Bayesian model simulations. Error bars show the standard error of the mean.</p></caption>
<graphic xlink:href="st4kgv5_fig31.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<p>As in our main study, we next assessed whether our Credibility-CA model (which includes perseveration but no valence bias) predicted the positivity bias results observed in participants in the discovery study. This analysis revealed that the average positivity bias in participants is higher than predicted by a pure perseveration account, both when measured in absolute terms (<xref ref-type="fig" rid="figS26">Fig. S26a</xref>) and in relative terms (<xref ref-type="fig" rid="figS26">Fig. S26c</xref>). Specifically, only the aVBI for the 70% credibility agent was above what a perseveration account would predict, while the rVBI for all agents except the completely credible one exceeded that threshold. Furthermore, the inflation in positivity bias for lower credibility feedback (compared to the 100% credibility agent) is significantly higher in participants than would be predicted by a pure perseveration account, in both absolute (<xref ref-type="fig" rid="figS26">Fig. S26b</xref>) and relative (<xref ref-type="fig" rid="figS26">Fig. S26d</xref>) terms.</p>
<fig id="figS26" position="float" fig-type="figure">
<label>Figure 26:</label>
<caption><title>Predicted positivity bias results for participants and for simulations of the Credibility-CA (including perseveration, but no valence-bias component) in discovery study.</title>
<p><bold>a</bold>, Valence bias results measured in absolute terms (by regressing the ML CA parameters, on their associated valence and credibility). <bold>b</bold>, Difference in positivity bias (measured in absolute terms) across credibility levels. On the x-axis, the hyphen (-) represents subtraction, such that a label of ‘0.5–1’ indicates the difference in the measurement for the 0.5 and 1.0 credibility conditions. Such differences are again based in the same mixed effects model as plot a. The inflation of aVBI for lower-credibility agents is larger than the one predicted by a pure perseveration account. <bold>c</bold>, Valence bias results measured in relative terms (by regressing the rVBIs on their associated credibility). Participants present a higher rVBI than what would be predicted by a perseveration account (except for the completely credible agent). <bold>d</bold>, Difference in rVBI across credibility levels. Such differences are again based in the same mixed effects model as plot c. The inflation of rVBI for lower-credibility agents is larger than the one predicted by a pure perseveration account. Histograms depict the distribution of coefficients from 101 simulated group-level datasets generated by the Credibility-CA model and fitted with the Credibility-Valence CA model. Gray circles represent the mean coefficient from these simulations, while black/green circles show the actual regression coefficients from participant behavior (green for significant effects in participants, black for nonsignificant). Significance markers (* p&lt;.05, ** p&lt;.01) indicate that fewer than 5% or 1% of simulated datasets, respectively, predicted an effect as strong as or stronger than that observed in participants, and in the same direction as the participant effect.</p></caption>
<graphic xlink:href="st4kgv5_fig32.tif" mime-subtype="tif" mimetype="image"/>
</fig>
<p>Together, these results show that the general positivity bias observed in participants could be predicted by an instructed-credibility Bayesian model with perseveration, or by a CA model with perseveration. Moreover, we find that these two models can predict a positivity bias for the 50% credibility agent, raising a concern that our positivity bias findings for this source may be an artefact of not-fully controlled for perseveration. However, the credibility modulation of this positivity bias, where the bias is amplified for lower credibility feedback, is consistently not predicted by perseveration alone, regardless of whether perseveration is incorporated into a Bayesian or a CA model. This finding suggests that participants are genuinely modulating their learning based on feedback credibility, and that this modulation is not merely an artifact of choice perseveration.</p>
</sec>
</sec>
<sec id="s6-3-7">
<label>3.7</label>
<title>Truth inference is still detected when controlling for valence bias</title>
<p>Given that participants frequently select bandits that are, on average, mostly rewarding, it is reasonable to assume that positive feedback is more likely to be objectively true than negative feedback. This raises a question if the “truth inference” effect we observed in participants might simply be an alternative description of a positivity bias in learning. To directly test this idea, we extended our Truth-CA model to explicitly account for a valence bias in credit assignment. This extended model features separate CA parameters for positive and negative feedback for each agent. When we fitted this new model to participant behavior, it still revealed a significant truth bonus in both the main study (Wilkoxon’s signrank test: median = 0.09, z(202)=2.12, p=0.034; <xref ref-type="fig" rid="figS27">Fig. S27a</xref>) and the discovery study (median = 3.52, z(102)=7.86, p&lt;0.001; <xref ref-type="fig" rid="figS27">Fig. S27c</xref>). Moreover, in the main study, this truth bonus remained significantly higher than what was predicted by all the alternative models, with the exception of the instructed-credibility bayesian model (<xref ref-type="fig" rid="figS27">Fig. S27b</xref>). In the discovery study, the truth bonus was significantly higher than what was predicted by all the alternative models (<xref ref-type="fig" rid="figS27">Fig. S27d</xref>).</p>
<fig id="figS27" position="float" fig-type="figure">
<label>SI Figure 27:</label>
<caption><title>Credit assignment is enhanced for feedback inferred to be true, even when controlling for positivity bias.</title>
<p><bold>a</bold>, Maximum likelihood (ML) estimate of the “truth-bonus” parameter derived from the “Truth-CA” model with valence bias in main study. <bold>b</bold>, Distribution of truth-bonus parameters predicted by synthetic simulations of our alternative computational models in main study. For each alternative model, we generated 101 group-level synthetic datasets based on the maximum likelihood parameters fitted to the participants’ actual behaviour. Each of these synthetic datasets was then independently fitted with the “Truth-CA” model with valence bias. Each histogram represents the distribution of the mean truth bonus across the 100 simulated datasets for a specific alternative model. Notably, the truth bonus observed in our participants was significantly higher than the truth bonus predicted by all alternative models, with the exception of the instructed-credibility Bayesian model. <bold>c-d</bold>, Same as a-b, but for discovery study. (*)&lt;0.05, (***) p&lt;.001</p></caption>
<graphic xlink:href="st4kgv5_fig33.tif" mime-subtype="tif" mimetype="image"/>
</fig>
</sec>
</sec>
<sec id="s6-4">
<label>4.</label>
<title>Supplementary Bayesian Derivations</title>
<sec id="s6-4-1">
<label>4.1.</label>
<title>Derivation of posterior update for Bayesian model</title>
<p>In the Bayesian models, the beliefs about each bandit were represented by density distribution <italic>g(p)</italic> over the probability <italic>p</italic> a bandit will provide a true reward. In a given trial <italic>n</italic>, after reward-feedback was provided, the distribution <italic>for</italic> the chosen bandit was updated based on Bayes rule considering the agent’s feedback in the current trial (<italic>f<sub>n</sub></italic>), its associated credibility (<italic>C<sub>n</sub></italic>), and the history of the bandit prior to trial n (<italic>H<sub>1,2,…n−1</sub></italic>). This update was calculated as (note proportionality omits terms that are independent of p and <italic>r<sub>n</sub></italic> denotes the true, latent, choice outcome on trial n):
<disp-formula id="FD27">
<alternatives>
<mml:math id="M27" display="block"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>…</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>…</mml:mn><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∝</mml:mo><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>…</mml:mn><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>…</mml:mn><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>     </mml:mtext><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>…</mml:mn><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mn>1</mml:mn></mml:munderover><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>…</mml:mn><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>     </mml:mtext><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>…</mml:mn><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mn>1</mml:mn></mml:munderover><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>…</mml:mn><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>…</mml:mn><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>     </mml:mtext><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>…</mml:mn><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mn>1</mml:mn></mml:munderover><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>…</mml:mn><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>∗</mml:mo><mml:msub><mml:mn>1</mml:mn><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>     </mml:mtext><mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:msub><mml:mn>1</mml:mn><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>∗</mml:mo><mml:msub><mml:mn>1</mml:mn><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:msub><mml:mn>1</mml:mn><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>     </mml:mtext><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>…</mml:mn><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mn>1</mml:mn><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mn>1</mml:mn><mml:mrow><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math>
<graphic xlink:href="st4kgv5_eqn27.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
</disp-formula>
</p>
<p>This was followed with normalisation to compensate for the proportionality in the derivation above
<disp-formula id="FD28">
<alternatives>
<mml:math id="M28" display="block"><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>…</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>←</mml:mo><mml:mfrac><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>…</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mn>1</mml:mn></mml:msubsup><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>…</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mfrac></mml:math>
<graphic xlink:href="st4kgv5_eqn28.tif" mime-subtype="tif" mimetype="image"/>
</alternatives>
</disp-formula>
</p>
<p>For the forgone trial n bandit we have <italic>g(p|H</italic><sub>1,2,…<italic>n</italic></sub>) = <italic>g(p|H</italic><sub>1,2,…<italic>n</italic>−1</sub>).</p>
</sec>
</sec>
</sec>
<sec id="das" sec-type="data-availability">
<title>Data availability</title>
<p>All code and data used to generate the results and figures in this paper will be made available upon publication.</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>We thank Bastien Blain, Lucie Charles and Stephano Palminteri for helpful discussions. We thank Nira Liberman, Keiji Ota, Nitzan Shahar, Konstantinos Tsetsos and Tali Sharot for providing feedback on earlier versions of the manuscript. We additionally thank the members of the Max Planck UCL Centre for Computational Psychiatry and Ageing Research for insightful discussions. The Max Planck UCL Centre is a joint initiative supported by UCL and the Max Planck Society.</p>
<p>J.V.P. is a pre-doctoral fellow of the International Max Planck Research School on Computational Methods in Psychiatry and Ageing Research (IMPRS COMP2PSYCH). We acknowledge funding from the Max Planck research school to J.V.P. (577749-D-CON 186534), and funding from the Max Planck Society to R.J.D. (549771-D.CON 177814). The project that gave rise to these results received the support of a fellowship from “la Caixa” Foundation (ID 100010434), with the fellowship code LCF/BQ/EU21/11890109.</p>
<p>J.V.P. contributed to the study design, data collection, data coding, data analyses, and writing of the manuscript. R.M. contributed to the study design, data analyses, and writing of the manuscript. R.J.D. contributed to the writing of the manuscript.</p>
</ack>
<ref-list>
<title>References and Notes:</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><collab>World Economic Forum</collab></person-group>. <article-title>Global Risks Report 2024</article-title>. <ext-link ext-link-type="uri" xlink:href="https://www.weforum.org/publications/global-risks-report-2024/">https://www.weforum.org/publications/global-risks-report-2024/</ext-link></mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carrieri</surname> <given-names>V</given-names></string-name>, <string-name><surname>Madio</surname> <given-names>L</given-names></string-name>, <string-name><surname>Principe</surname> <given-names>F</given-names></string-name></person-group>. <article-title>Vaccine hesitancy and (fake) news: Quasi-experimental evidence from Italy</article-title>. <source>Health Econ</source>. <year>2019</year>;<volume>28</volume>(<issue>11</issue>):<fpage>1377</fpage>–<lpage>82</lpage>.</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rocha</surname> <given-names>YM</given-names></string-name>, <string-name><surname>de Moura</surname> <given-names>GA</given-names></string-name>, <string-name><surname>Desidèrio</surname> <given-names>GA</given-names></string-name>, <string-name><surname>de Oliveira</surname> <given-names>CH</given-names></string-name>, <string-name><surname>Lourengo</surname> <given-names>FD</given-names></string-name>, <string-name><surname>de Figueiredo Nicolete</surname> <given-names>LD</given-names></string-name></person-group>. <article-title>The impact of fake news on social media and its influence on health during the COVID-19 pandemic: a systematic review</article-title>. <source>J Public Health</source>. <year>2023</year> <month>Jul</month> <day>1</day>;<volume>31</volume>(<issue>7</issue>):<fpage>1007</fpage>–<lpage>16</lpage>.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Belluz</surname> <given-names>J. Vox</given-names></string-name></person-group>. <year>2017</year>. <article-title>Why Japan’s HPV vaccine rates dropped from 70% to near zero</article-title>. <ext-link ext-link-type="uri" xlink:href="https://www.vox.com/science-and-health/2017/12/1/16723912/japan-hpv-vaccine">https://www.vox.com/science-and-health/2017/12/1/16723912/japan-hpv-vaccine</ext-link></mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Horta Ribeiro</surname> <given-names>M</given-names></string-name>, <string-name><surname>Calais</surname> <given-names>PH</given-names></string-name>, <string-name><surname>Almeida</surname> <given-names>VAF</given-names></string-name>, <string-name><surname>Meira</surname> <given-names>W</given-names> <suffix>Jr.</suffix></string-name></person-group> <article-title>“Everything I Disagree Withis #FakeNews”: Correlating Political Polarization and Spread of Misinformation</article-title>. <source>arXiv</source>. <year>2017</year>. <ext-link ext-link-type="uri" xlink:href="https://ui.adsabs.harvard.edu/abs/2017arXiv170605924H">https://ui.adsabs.harvard.edu/abs/2017arXiv170605924H</ext-link></mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Piazza</surname> <given-names>JA</given-names></string-name></person-group>. <article-title>Fake news: the effects of social media disinformation on domestic terrorism</article-title>. <source>Dyn Asymmetric Confl</source>. <year>2022</year> <month>Jan</month> <day>2</day>;<volume>15</volume>(<issue>1</issue>):<fpage>55</fpage>–<lpage>77</lpage>.</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Roy</surname> <given-names>S</given-names></string-name>, <string-name><surname>Singh</surname> <given-names>AK</given-names></string-name>, <string-name><surname>Kamruzzaman</surname></string-name></person-group>. <article-title>Sociological perspectives of social media, rumors, and attacks on minorities: Evidence from Bangladesh</article-title>. <source>Front Sociol</source>. <year>2023</year> <month>Feb</month> <day>24</day>;<volume>8</volume>:<fpage>1067726</fpage>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Wendling</surname> <given-names>M</given-names></string-name></person-group> <article-title>The saga of “Pizzagate”: The fake story that shows how conspiracy theories spread</article-title>. <source>BBC News</source>. <year>2016</year> <month>Dec</month> <day>2</day>, <ext-link ext-link-type="uri" xlink:href="https://www.bbc.com/news/blogs-trending-38156985">https://www.bbc.com/news/blogs-trending-38156985</ext-link></mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Enders</surname> <given-names>AM</given-names></string-name>, <string-name><surname>Uscinski</surname> <given-names>JE</given-names></string-name>, <string-name><surname>Seelig</surname> <given-names>MI</given-names></string-name>, <string-name><surname>Klofstad</surname> <given-names>CA</given-names></string-name>, <string-name><surname>Wuchty</surname> <given-names>S</given-names></string-name>, <string-name><surname>Funchion</surname> <given-names>JR</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>The Relationship Between Social Media Use and Beliefs in Conspiracy Theories and Misinformation</article-title>. <source>Polit Behav</source>. <year>2023</year> <month>Jun</month> <day>1</day>;<volume>45</volume>(<issue>2</issue>):<fpage>781</fpage>–<lpage>804</lpage>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guess</surname> <given-names>A</given-names></string-name>, <string-name><surname>Nagler</surname> <given-names>J</given-names></string-name>, <string-name><surname>Tucker</surname> <given-names>J</given-names></string-name></person-group>. <article-title>Less than you think: Prevalence and predictors of fake news dissemination on Facebook</article-title>. <source>Sci Adv</source>. <year>2019</year> <month>Jan</month> <day>9</day>;<volume>5</volume>(<issue>1</issue>):<elocation-id>eaau4586</elocation-id>.</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Del Vicario</surname> <given-names>M</given-names></string-name>, <string-name><surname>Bessi</surname> <given-names>A</given-names></string-name>, <string-name><surname>Zollo</surname> <given-names>F</given-names></string-name>, <string-name><surname>Petroni</surname> <given-names>F</given-names></string-name>, <string-name><surname>Scala</surname> <given-names>A</given-names></string-name>, <string-name><surname>Caldarelli</surname> <given-names>G</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>The spreading of misinformation online</article-title>. <source>Proc Natl Acad Sci</source>. <year>2016</year> <month>Jan</month> <day>19</day>;<volume>113</volume>(<issue>3</issue>):<fpage>554</fpage>–<lpage>9</lpage>.</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shao</surname> <given-names>C</given-names></string-name>, <string-name><surname>Ciampaglia</surname> <given-names>GL</given-names></string-name>, <string-name><surname>Varol</surname> <given-names>O</given-names></string-name>, <string-name><surname>Yang</surname> <given-names>KC</given-names></string-name>, <string-name><surname>Flammini</surname> <given-names>A</given-names></string-name>, <string-name><surname>Menczer</surname> <given-names>F</given-names></string-name></person-group>. <article-title>The spread of low-credibility content by social bots</article-title>. <source>Nat Commun</source>. <year>2018</year> <month>Nov</month> <day>20</day>;<volume>9</volume>(<issue>1</issue>):<fpage>4787</fpage>.</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sharevski</surname> <given-names>F</given-names></string-name>, <string-name><surname>Alsaadi</surname> <given-names>R</given-names></string-name>, <string-name><surname>Jachim</surname> <given-names>P</given-names></string-name>, <string-name><surname>Pieroni</surname> <given-names>E</given-names></string-name></person-group>. <article-title>Misinformation warnings: Twitter’s soft moderation effects on COVID-19 vaccine belief echoes</article-title>. <source>Comput Secur</source>. <year>2022</year> <month>Mar</month>;<volume>114</volume>:<fpage>102577</fpage>.</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Walter</surname> <given-names>N</given-names></string-name>, <string-name><surname>Murphy</surname> <given-names>ST</given-names></string-name></person-group>. <article-title>How to unring the bell: A meta-analytic approach to correction of misinformation</article-title>. <source>Commun Monogr</source>. <year>2018</year> <month>Jul</month> <day>3</day>;<volume>85</volume>(<issue>3</issue>):<fpage>423</fpage>–<lpage>41</lpage>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Globig</surname> <given-names>LK</given-names></string-name>, <string-name><surname>Holtz</surname> <given-names>N</given-names></string-name>, <string-name><surname>Sharot</surname> <given-names>T</given-names></string-name></person-group>. <article-title>Changing the Incentive Structure of Social Media Platforms to Halt the Spread of Misinformation</article-title>. <ext-link ext-link-type="uri" xlink:href="https://psyarxiv.com/26j8w/">https://psyarxiv.com/26j8w/</ext-link></mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Roozenbeek</surname> <given-names>J</given-names></string-name>, <string-name><surname>van der Linden</surname> <given-names>S</given-names></string-name></person-group>. <article-title>Fake news game confers psychological resistance against online misinformation</article-title>. <source>Palgrave Commun</source>. <year>2019</year> <month>Jun</month> <day>25</day>;<volume>5</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>10</lpage>.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>O’Mahony</surname> <given-names>C</given-names></string-name>, <string-name><surname>Brassil</surname> <given-names>M</given-names></string-name>, <string-name><surname>Murphy</surname> <given-names>G</given-names></string-name>, <string-name><surname>Linehan</surname> <given-names>C</given-names></string-name></person-group>. <article-title>The efficacy of interventions in reducing belief in conspiracy theories: A systematic review</article-title>. <source>PLOS One</source>. <year>2023</year> <month>Apr</month> <day>5</day>;<volume>18</volume>(<issue>4</issue>):<elocation-id>e0280902</elocation-id>.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vosoughi</surname> <given-names>S</given-names></string-name>, <string-name><surname>Roy</surname> <given-names>D</given-names></string-name>, <string-name><surname>Aral</surname> <given-names>S</given-names></string-name></person-group>. <article-title>The spread of true and false news online</article-title>. <source>Science</source>. <year>2018</year> <month>Mar</month> <day>9</day>;<volume>359</volume>(<issue>6380</issue>):<fpage>1146</fpage>–<lpage>51</lpage>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Modgil</surname> <given-names>S</given-names></string-name>, <string-name><surname>Singh</surname> <given-names>RK</given-names></string-name>, <string-name><surname>Gupta</surname> <given-names>S</given-names></string-name>, <string-name><surname>Dennehy</surname> <given-names>D</given-names></string-name></person-group>. <article-title>A Confirmation Bias View on Social Media Induced Polarisation During Covid-19</article-title>. <source>Inf Syst Front</source>. <year>2021</year> <month>Nov</month> <day>20</day>; <pub-id pub-id-type="doi">10.1007/s10796-021-10222-9</pub-id></mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Menczer</surname> <given-names>F</given-names></string-name>, <string-name><surname>Ciampaglia</surname> <given-names>GL</given-names></string-name></person-group>. <article-title>The Conversation</article-title>. <year>2018</year>. <source>Misinformation and biases infect social media, both intentionally and accidentally</source>. <ext-link ext-link-type="uri" xlink:href="http://theconversation.com/misinformation-and-biases-infect-social-media-both-intentionally-and-accidentally-97148">http://theconversation.com/misinformation-and-biases-infect-social-media-both-intentionally-and-accidentally-97148</ext-link></mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pennycook</surname> <given-names>G</given-names></string-name>, <string-name><surname>Bear</surname> <given-names>A</given-names></string-name>, <string-name><surname>Collins</surname> <given-names>ET</given-names></string-name>, <string-name><surname>Rand</surname> <given-names>DG</given-names></string-name></person-group>. <article-title>The Implied Truth Effect: Attaching Warnings to a Subset of Fake News Headlines Increases Perceived Accuracy of Headlines Without Warnings</article-title>. <source>Manag Sci</source>. <year>2020</year> <month>Nov</month>;<volume>66</volume>(<issue>11</issue>):<fpage>4944</fpage>–<lpage>57</lpage>.</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Swire</surname> <given-names>B</given-names></string-name>, <string-name><surname>Berinsky</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>Lewandowsky</surname> <given-names>S</given-names></string-name>, <string-name><surname>Ecker</surname> <given-names>UKH</given-names></string-name></person-group>. <article-title>Processing political misinformation: comprehending the Trump phenomenon</article-title>. <source>R Soc Open Sci</source>. <year>2017</year> <month>Mar</month>;<volume>4</volume>(<issue>3</issue>):<fpage>160802</fpage>.</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Behrens</surname> <given-names>TEJ</given-names></string-name>, <string-name><surname>Woolrich</surname> <given-names>MW</given-names></string-name>, <string-name><surname>Walton</surname> <given-names>ME</given-names></string-name>, <string-name><surname>Rushworth</surname> <given-names>MFS</given-names></string-name></person-group>. <article-title>Learning the value of information in an uncertain world</article-title>. <source>Nat Neurosci</source>. <year>2007</year> <month>Sep</month>;<volume>10</volume>(<issue>9</issue>):<fpage>1214</fpage>–<lpage>21</lpage>.</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nassar</surname> <given-names>MR</given-names></string-name>, <string-name><surname>Wilson</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Heasly</surname> <given-names>B</given-names></string-name>, <string-name><surname>Gold</surname> <given-names>JI</given-names></string-name></person-group>. <article-title>An approximately Bayesian delta-rule model explains the dynamics of belief updating in a changing environment</article-title>. <source>J Neurosci Off J Soc Neurosci</source>. <year>2010</year> <month>Sep</month> <day>15</day>;<volume>30</volume>(<issue>37</issue>):<fpage>12366</fpage>–<lpage>78</lpage>.</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Diederen</surname> <given-names>KMJ</given-names></string-name>, <string-name><surname>Schultz</surname> <given-names>W</given-names></string-name></person-group>. <article-title>Scaling prediction errors to reward variability benefits error-driven learning in humans</article-title>. <source>J Neurophysiol</source>. <year>2015</year> <month>Jul</month> <day>15</day>;<volume>114</volume>(<issue>3</issue>):<fpage>1628</fpage>.</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Campbell-Meiklejohn</surname> <given-names>D</given-names></string-name>, <string-name><surname>Simonsen</surname> <given-names>A</given-names></string-name>, <string-name><surname>Frith</surname> <given-names>CD</given-names></string-name>, <string-name><surname>Daw</surname> <given-names>ND</given-names></string-name></person-group>. <article-title>Independent Neural Computation of Value from Other People’s Confidence</article-title>. <source>J Neurosci</source>. <year>2017</year> <month>Jan</month> <day>18</day>;<volume>37</volume>(<issue>3</issue>):<fpage>673</fpage>–<lpage>84</lpage>.</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>De Martino</surname> <given-names>B</given-names></string-name>, <string-name><surname>Bobadilla-Suarez</surname> <given-names>S</given-names></string-name>, <string-name><surname>Nouguchi</surname> <given-names>T</given-names></string-name>, <string-name><surname>Sharot</surname> <given-names>T</given-names></string-name>, <string-name><surname>Love</surname> <given-names>BC</given-names></string-name></person-group>. <article-title>Social Information Is Integrated into Value and Confidence Judgments According to Its Reliability</article-title>. <source>J Neurosci</source>. <year>2017</year> <month>Jun</month> <day>21</day>;<volume>37</volume>(<issue>25</issue>):<fpage>6066</fpage>–<lpage>74</lpage>.</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Toelch</surname> <given-names>U</given-names></string-name>, <string-name><surname>Bach</surname> <given-names>DR</given-names></string-name>, <string-name><surname>Dolan</surname> <given-names>RJ</given-names></string-name></person-group>. <article-title>The neural underpinnings of an optimal exploitation of social information under uncertainty</article-title>. <source>Soc Cogn Affect Neurosci</source>. <year>2014</year> <month>Nov</month>;<volume>9</volume>(<issue>11</issue>):<fpage>1746</fpage>–<lpage>53</lpage>.</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Biele</surname> <given-names>G</given-names></string-name>, <string-name><surname>Rieskamp</surname> <given-names>J</given-names></string-name>, <string-name><surname>Gonzalez</surname> <given-names>R</given-names></string-name></person-group>. <article-title>Computational models for the combination of advice and individual learning</article-title>. <source>Cogn Sci</source>. <year>2009</year> <month>Mar</month>;<volume>33</volume>(<issue>2</issue>):<fpage>206</fpage>–<lpage>42</lpage>.</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vélez</surname> <given-names>N</given-names></string-name>, <string-name><surname>Gweon</surname> <given-names>H</given-names></string-name></person-group>. <article-title>Integrating Incomplete Information With Imperfect Advice</article-title>. <source>Top Cogn Sci</source>. <year>2019</year> <month>Apr</month>;<volume>11</volume>(<issue>2</issue>):<fpage>299</fpage>–<lpage>315</lpage>.</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Jiwa</surname> <given-names>M</given-names></string-name>, <string-name><surname>Yu</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Boonyaratvej</surname> <given-names>J</given-names></string-name>, <string-name><surname>Ciston</surname> <given-names>A</given-names></string-name>, <string-name><surname>Haggard</surname> <given-names>P</given-names></string-name>, <string-name><surname>Charles</surname> <given-names>L</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Exposure to misleading and unreliable information reduces active information-seeking</article-title>. <source>PsyArXiv</source>; <year>2023</year>. <ext-link ext-link-type="uri" xlink:href="https://osf.io/preprints/psyarxiv/4zkxw/">https://osf.io/preprints/psyarxiv/4zkxw/</ext-link></mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sharot</surname> <given-names>T</given-names></string-name></person-group>. <article-title>The optimism bias</article-title>. <source>Curr Biol</source>. <year>2011</year> <month>Dec</month>;<volume>21</volume>(<issue>23</issue>):<fpage>R941</fpage>–<lpage>5</lpage>.</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sharot</surname> <given-names>T</given-names></string-name>, <string-name><surname>Garrett</surname> <given-names>N</given-names></string-name></person-group>. <article-title>Forming Beliefs: Why Valence Matters</article-title>. <source>Trends Cogn Sci</source>. <year>2016</year> <month>Jan</month>;<volume>20</volume>(<issue>1</issue>):<fpage>25</fpage>–<lpage>33</lpage>.</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sharot</surname> <given-names>T</given-names></string-name>, <string-name><surname>Korn</surname> <given-names>CW</given-names></string-name>, <string-name><surname>Dolan</surname> <given-names>RJ</given-names></string-name></person-group>. <article-title>How unrealistic optimism is maintained in the face of reality</article-title>. <source>Nat Neurosci</source>. <year>2011</year> <month>Nov</month>;<volume>14</volume>(<issue>11</issue>):<fpage>1475</fpage>–<lpage>9</lpage>.</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hughes</surname> <given-names>BL</given-names></string-name>, <string-name><surname>Zaki</surname> <given-names>J</given-names></string-name></person-group>. <article-title>The neuroscience of motivated cognition</article-title>. <source>Trends Cogn Sci</source>. <year>2015</year> <month>Feb</month> <day>1</day>;<volume>19</volume>(<issue>2</issue>):<fpage>62</fpage>–<lpage>4</lpage>.</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="data"><person-group person-group-type="author"><string-name><surname>Sutton</surname> <given-names>RS</given-names></string-name>, <string-name><surname>Barto</surname> <given-names>AG</given-names></string-name></person-group>. <article-title>Reinforcement Learning: An Introduction</article-title>. <year>2014</year></mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Schulz</surname> <given-names>L</given-names></string-name>, <string-name><surname>Schulz</surname> <given-names>E</given-names></string-name>, <string-name><surname>Bhui</surname> <given-names>R</given-names></string-name>, <string-name><surname>Dayan</surname> <given-names>P</given-names></string-name></person-group>. <article-title>Mechanisms of Mistrust: A Bayesian Account of Misinformation Learning </article-title>. <publisher-name>OSF</publisher-name>; <year>2023</year>. <ext-link ext-link-type="uri" xlink:href="https://osf.io/8egxh">https://osf.io/8egxh</ext-link></mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Aston</surname> <given-names>AT</given-names></string-name></person-group>. <article-title>Modeling the Social Reinforcement of Misinformation Dissemination on Social Media</article-title>. <source>J Behav Brain Sci</source>. <year>2022</year> <month>Nov</month> <day>4</day>;<volume>12</volume>(<issue>11</issue>):<fpage>533</fpage>–<lpage>47</lpage>.</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Aymanns</surname> <given-names>C</given-names></string-name>, <string-name><surname>Foerster</surname> <given-names>J</given-names></string-name>, <string-name><surname>Georg</surname> <given-names>CP</given-names></string-name>, <string-name><surname>Weber</surname> <given-names>M</given-names></string-name></person-group>. <article-title>Fake News in Social Networks</article-title>. <publisher-loc>Rochester, NY</publisher-loc>; <year>2022</year>, <ext-link ext-link-type="uri" xlink:href="https://papers.ssrn.com/abstract=4173312">https://papers.ssrn.com/abstract=4173312</ext-link></mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lindström</surname> <given-names>B</given-names></string-name>, <string-name><surname>Bellander</surname> <given-names>M</given-names></string-name>, <string-name><surname>Schultner</surname> <given-names>DT</given-names></string-name>, <string-name><surname>Chang</surname> <given-names>A</given-names></string-name>, <string-name><surname>Tobler</surname> <given-names>PN</given-names></string-name>, <string-name><surname>Amodio</surname> <given-names>DM</given-names></string-name></person-group>. <article-title>A computational reward learning account of social media engagement</article-title>. <source>Nat Commun</source>. <year>2021</year> <month>Feb</month> <day>26</day>;<volume>12</volume>(<issue>1</issue>):<fpage>1311</fpage>.</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Vidal-Perez</surname> <given-names>J</given-names></string-name>, <string-name><surname>Dolan</surname> <given-names>RJ</given-names></string-name>, <string-name><surname>Moran</surname> <given-names>R</given-names></string-name></person-group>. <article-title>Biased Misinformation Distorts Beliefs </article-title>. <publisher-name>OSF</publisher-name>; <year>2025</year>, <ext-link ext-link-type="uri" xlink:href="https://osf.io/rk52q_v1">https://osf.io/rk52q_v1</ext-link></mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Palminteri</surname> <given-names>S</given-names></string-name>, <string-name><surname>Lefebvre</surname> <given-names>G</given-names></string-name>, <string-name><surname>Kilford</surname> <given-names>EJ</given-names></string-name>, <string-name><surname>Blakemore</surname> <given-names>SJ</given-names></string-name></person-group>. <article-title>Confirmation bias in human reinforcement learning: Evidence from counterfactual feedback processing</article-title>. <source>PLOS Comput Biol</source>. <year>2017</year> <month>Aug</month> <day>1</day>;<volume>13</volume>(<issue>8</issue>):<elocation-id>e1005684</elocation-id>.</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lefebvre</surname> <given-names>G</given-names></string-name>, <string-name><surname>Lebreton</surname> <given-names>M</given-names></string-name>, <string-name><surname>Meyniel</surname> <given-names>F</given-names></string-name>, <string-name><surname>Bourgeois-Gironde</surname> <given-names>S</given-names></string-name>, <string-name><surname>Palminteri</surname> <given-names>S</given-names></string-name></person-group>. <article-title>Behavioural and neural characterization of optimistic reinforcement learning</article-title>. <source>Nat Hum Behav</source>. <year>2017</year> <month>Mar</month> <day>20</day>;<volume>1</volume>(<issue>4</issue>):<fpage>1</fpage>–<lpage>9</lpage>.</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Palminteri</surname> <given-names>S</given-names></string-name>, <string-name><surname>Lebreton</surname> <given-names>M</given-names></string-name></person-group>. <article-title>The computational roots of positivity and confirmation biases in reinforcement learning</article-title>. <source>Trends Cogn Sci</source>. <year>2022</year> <month>Jul</month> <day>1</day>;<volume>26</volume>(<issue>7</issue>):<fpage>607</fpage>–<lpage>21</lpage>.</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brady</surname> <given-names>WJ</given-names></string-name>, <string-name><surname>McLoughlin</surname> <given-names>K</given-names></string-name>, <string-name><surname>Doan</surname> <given-names>TN</given-names></string-name>, <string-name><surname>Crockett</surname> <given-names>MJ</given-names></string-name></person-group>. <article-title>How social learning amplifies moral outrage expression in online social networks</article-title>. <source>Sci Adv</source>. <year>2021</year> <month>Aug</month> <day>13</day>;<volume>7</volume>(<issue>33</issue>):<elocation-id>eabe5641</elocation-id>.</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wilson</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Collins</surname> <given-names>AG</given-names></string-name></person-group>. <article-title>Ten simple rules for the computational modeling of behavioral data</article-title>. <source>eLife</source>. <volume>8</volume>:<elocation-id>e49547</elocation-id>. <year>2019</year> <pub-id pub-id-type="doi">10.7554/eLife.49547</pub-id></mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Reyna</surname> <given-names>VF</given-names></string-name>, <string-name><surname>Brainerd</surname> <given-names>CJ</given-names></string-name></person-group>. <article-title>Numeracy, gist, literal thinking and the value of nothing in decision making</article-title>. <source>Nat Rev Psychol</source>. <year>2023</year> <month>Jul</month>;<volume>2</volume>(<issue>7</issue>):<fpage>421</fpage>–<lpage>39</lpage>.</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Moran</surname> <given-names>R</given-names></string-name>, <string-name><surname>Dayan</surname> <given-names>P</given-names></string-name>, <string-name><surname>Dolan</surname> <given-names>RJ</given-names></string-name></person-group>. <article-title>Human subjects exploit a cognitive map for credit assignment</article-title>. <source>Proc Natl Acad Sci</source>. <year>2021</year> <month>Jan</month> <day>26</day>;<volume>118</volume>(<issue>4</issue>):<elocation-id>e2016884118</elocation-id>.</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sugawara</surname> <given-names>M</given-names></string-name>, <string-name><surname>Katahira</surname> <given-names>K</given-names></string-name></person-group>. <article-title>Dissociation between asymmetric value updating and perseverance in human reinforcement learning</article-title>. <source>Sci Rep</source>. <year>2021</year> <month>Feb</month> <day>11</day>;<volume>11</volume>(<issue>1</issue>):<fpage>3574</fpage>.</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Palminteri</surname> <given-names>S</given-names></string-name></person-group>. <article-title>Choice-Confirmation Bias and Gradual Perseveration in Human Reinforcement Learning</article-title>. <source>Behav Neurosci</source>. <year>2022</year> <month>Nov</month> <day>18</day>;<fpage>137</fpage>.</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Vidal-Perez</surname> <given-names>J</given-names></string-name>, <string-name><surname>Dolan</surname> <given-names>R</given-names></string-name>, <string-name><surname>Moran</surname> <given-names>R</given-names></string-name></person-group>. <article-title>Learning asymmetry or perseveration? A critical re-evaluation and solution to a pervasive confound </article-title>. <publisher-name>OSF</publisher-name>; <year>2025</year>, <ext-link ext-link-type="uri" xlink:href="https://osf.io/xdse5_v1">https://osf.io/xdse5_v1</ext-link></mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wilson</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Geana</surname> <given-names>A</given-names></string-name>, <string-name><surname>White</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Ludvig</surname> <given-names>EA</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>JD</given-names></string-name></person-group>. <article-title>Humans Use Directed and Random Exploration to Solve the Explore-Exploit Dilemma</article-title>. <source>J Exp Psychol Gen</source>. <year>2014</year> <month>Dec</month>;<volume>143</volume>(<issue>6</issue>):<fpage>2074</fpage>–<lpage>81</lpage>.</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Niv</surname> <given-names>Y</given-names></string-name></person-group>. <article-title>Reinforcement learning in the brain</article-title>. <source>J Math Psychol</source>. <year>2009</year> <month>Jun</month> <day>1</day>;<volume>53</volume>(<issue>3</issue>):<fpage>139</fpage>–<lpage>54</lpage>.</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bennett</surname> <given-names>D</given-names></string-name>, <string-name><surname>Bode</surname> <given-names>S</given-names></string-name>, <string-name><surname>Brydevall</surname> <given-names>M</given-names></string-name>, <string-name><surname>Warren</surname> <given-names>H</given-names></string-name>, <string-name><surname>Murawski</surname> <given-names>C</given-names></string-name></person-group>. <article-title>Intrinsic Valuation of Information in Decision Making under Uncertainty</article-title>. <source>PLOS Comput Biol</source>. <year>2016</year> <month>Jul</month> <day>14</day>;<volume>12</volume>(<issue>7</issue>):<elocation-id>e1005020</elocation-id>.</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bromberg-Martin</surname> <given-names>ES</given-names></string-name>, <string-name><surname>Monosov</surname> <given-names>IE</given-names></string-name></person-group>. <article-title>Neural circuitry of information seeking</article-title>. <source>Curr Opin Behav Sci</source>. <year>2020</year> <month>Oct</month>;<volume>35</volume>:<fpage>62</fpage>–<lpage>70</lpage>.</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Glaze</surname> <given-names>CM</given-names></string-name>, <string-name><surname>Kable</surname> <given-names>JW</given-names></string-name>, <string-name><surname>Gold</surname> <given-names>JI</given-names></string-name></person-group>. <article-title>Normative evidence accumulation in unpredictable environments</article-title>. <source>eLife</source>. <year>2015</year> <month>Aug</month> <day>31</day>;<volume>4</volume>:<elocation-id>e08825</elocation-id>. <pub-id pub-id-type="doi">10.7554/eLife.08825</pub-id></mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Glaze</surname> <given-names>CM</given-names></string-name>, <string-name><surname>Filipowicz</surname> <given-names>ALS</given-names></string-name>, <string-name><surname>Kable</surname> <given-names>JW</given-names></string-name>, <string-name><surname>Balasubramanian</surname> <given-names>V</given-names></string-name>, <string-name><surname>Gold</surname> <given-names>JI</given-names></string-name></person-group>. <article-title>A bias-variance trade-off governs individual differences in on-line learning in an unpredictable environment</article-title>. <source>Nat Hum Behav</source>. <year>2018</year> <month>Mar</month>;<volume>2</volume>(<issue>3</issue>):<fpage>213</fpage>–<lpage>24</lpage>.</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Behrens</surname> <given-names>TEJ</given-names></string-name>, <string-name><surname>Hunt</surname> <given-names>LT</given-names></string-name>, <string-name><surname>Woolrich</surname> <given-names>MW</given-names></string-name>, <string-name><surname>Rushworth</surname> <given-names>MFS</given-names></string-name></person-group>. <article-title>Associative learning of social value</article-title>. <source>Nature</source>. <year>2008</year> <month>Nov</month>;<volume>456</volume>(<issue>7219</issue>):<fpage>245</fpage>–<lpage>9</lpage>.</mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Friston</surname> <given-names>K</given-names></string-name>, <string-name><surname>FitzGerald</surname> <given-names>T</given-names></string-name>, <string-name><surname>Rigoli</surname> <given-names>F</given-names></string-name>, <string-name><surname>Schwartenbeck</surname> <given-names>P</given-names></string-name>, <string-name><surname>Pezzulo</surname> <given-names>G</given-names></string-name></person-group>. <article-title>Active Inference: A Process Theory</article-title>. <source>Neural Comput</source>. <year>2017</year> <month>Jan</month> <day>1</day>;<volume>29</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>49</lpage>.</mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Johnson</surname> <given-names>HM</given-names></string-name>, <string-name><surname>Seifert</surname> <given-names>CM</given-names></string-name></person-group>. <article-title>Sources of the continued influence effect: When misinformation in memory affects later inferences</article-title>. <source>J Exp Psychol Learn Mem Cogn</source>. <year>1994</year>;<volume>20</volume>(<issue>6</issue>):<fpage>1420</fpage>–<lpage>36</lpage>.</mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Walter</surname> <given-names>N</given-names></string-name>, <string-name><surname>Tukachinsky</surname> <given-names>R</given-names></string-name></person-group>. <article-title>A Meta-Analytic Examination of the Continued Influence of Misinformation in the Face of Correction: How Powerful Is It, Why Does It Happen, and How to Stop It?</article-title> <source>Commun Res</source>. <year>2020</year> <month>Mar</month> <day>1</day>;<volume>47</volume>(<issue>2</issue>):<fpage>155</fpage>–<lpage>77</lpage>.</mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Collins</surname> <given-names>AGE</given-names></string-name>, <string-name><surname>Frank</surname> <given-names>MJ</given-names></string-name></person-group>. <article-title>How much of reinforcement learning is working memory, not reinforcement learning? A behavioral, computational, and neurogenetic analysis</article-title>. <source>Eur J Neurosci</source>. <year>2012</year>;<volume>35</volume>(<issue>7</issue>):<fpage>1024</fpage>–<lpage>35</lpage>.</mixed-citation></ref>
<ref id="c63"><label>63.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chambon</surname> <given-names>V</given-names></string-name>, <string-name><surname>Thero</surname> <given-names>H</given-names></string-name>, <string-name><surname>Vidal</surname> <given-names>M</given-names></string-name>, <string-name><surname>Vandendriessche</surname> <given-names>H</given-names></string-name>, <string-name><surname>Haggard</surname> <given-names>P</given-names></string-name>, <string-name><surname>Palminteri</surname> <given-names>S</given-names></string-name></person-group>. <article-title>Information about action outcomes differentially affects learning from self-determined versus imposed choices</article-title>. <source>Nat Hum Behav</source>. <year>2020</year> <month>Oct</month>;<volume>4</volume>(<issue>10</issue>):<fpage>1067</fpage>–<lpage>79</lpage>.</mixed-citation></ref>
<ref id="c64"><label>64.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Westerwick</surname> <given-names>A</given-names></string-name>, <string-name><surname>Sude</surname> <given-names>D</given-names></string-name>, <string-name><surname>Robinson</surname> <given-names>M</given-names></string-name>, <string-name><surname>Knobloch-Westerwick</surname> <given-names>S</given-names></string-name></person-group>. <article-title>Peers Versus Pros: Confirmation Bias in Selective Exposure to User-Generated Versus Professional Media Messages and Its Consequences</article-title>. <source>Mass Commun Soc</source>. <year>2020</year> <month>Jul</month> <day>3</day>;<volume>23</volume>(<issue>4</issue>):<fpage>510</fpage>–<lpage>36</lpage>.</mixed-citation></ref>
<ref id="c65"><label>65.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Gallo</surname> <given-names>E</given-names></string-name>, <string-name><surname>Langtry</surname> <given-names>A</given-names></string-name></person-group>. <article-title>Social Networks, Confirmation Bias and Shock Elections</article-title>. <year>2020</year> <month>Nov</month> <day>2</day>, <ext-link ext-link-type="uri" xlink:href="https://www.repository.cam.ac.uk/handle/1810/315203">https://www.repository.cam.ac.uk/handle/1810/315203</ext-link></mixed-citation></ref>
<ref id="c66"><label>66.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lefebvre</surname> <given-names>G</given-names></string-name>, <string-name><surname>Deroy</surname> <given-names>O</given-names></string-name>, <string-name><surname>Bahrami</surname> <given-names>B</given-names></string-name></person-group>. <article-title>The roots of polarization in the individual reward system</article-title>. <source>Proc R Soc B Biol Sci</source>. <year>2024</year> <month>Feb</month> <day>28</day>;<volume>291</volume>(<issue>2017</issue>):<fpage>20232011</fpage>.</mixed-citation></ref>
<ref id="c67"><label>67.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Meppelink</surname> <given-names>CS</given-names></string-name>, <string-name><surname>Smit</surname> <given-names>EG</given-names></string-name>, <string-name><surname>Fransen</surname> <given-names>ML</given-names></string-name>, <string-name><surname>Diviani</surname> <given-names>N</given-names></string-name></person-group>. <article-title>“I was Right about Vaccination”: Confirmation Bias and Health Literacy in Online Health Information Seeking</article-title>. <source>J Health Commun</source>. <year>2019</year> <month>Feb</month> <day>1</day>;<volume>24</volume>(<issue>2</issue>):<fpage>129</fpage>–<lpage>40</lpage>.</mixed-citation></ref>
<ref id="c68"><label>68.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Malthouse</surname> <given-names>E</given-names></string-name></person-group>. <article-title>Confirmation bias and vaccine-related beliefs in the time of COVID-19</article-title>. <source>J Public Health</source>. <year>2023</year> <month>Jun</month> <day>1</day>;<volume>45</volume>(<issue>2</issue>):<fpage>523</fpage>–<lpage>8</lpage>.</mixed-citation></ref>
<ref id="c69"><label>69.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>W</given-names></string-name></person-group>. <article-title>Overcoming Confirmation Bias in Misinformation Correction: Effects of Processing Motive and Jargon on Climate Change Policy Support</article-title>. <source>Sci Commun</source>. <year>2024</year> <month>Feb</month> <day>20</day>;<fpage>10755470241229452</fpage>.</mixed-citation></ref>
<ref id="c70"><label>70.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sunstein</surname> <given-names>CR</given-names></string-name>, <string-name><surname>Bobadilla-Suarez</surname> <given-names>S</given-names></string-name>, <string-name><surname>Lazzaro</surname> <given-names>SC</given-names></string-name>, <string-name><surname>Sharot</surname> <given-names>T</given-names></string-name></person-group>. <article-title>How People Update Beliefs about Climate Change: Good News and Bad News</article-title>. <source>CORNELL LAW Rev</source>. <fpage>102</fpage>. <year>2017</year></mixed-citation></ref>
<ref id="c71"><label>71.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Shen</surname> <given-names>L</given-names></string-name></person-group>. <article-title>Confirmation Bias and the Persistence of Misinformation on Climate Change</article-title>. <source>Commun Res</source>. <year>2022</year> <month>Jun</month> <day>1</day>;<volume>49</volume>(<issue>4</issue>):<fpage>500</fpage>–<lpage>23</lpage>.</mixed-citation></ref>
<ref id="c72"><label>72.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hart</surname> <given-names>PS</given-names></string-name>, <string-name><surname>Nisbet</surname> <given-names>EC</given-names></string-name></person-group>. <article-title>Boomerang Effects in Science Communication: How Motivated Reasoning and Identity Cues Amplify Opinion Polarization About Climate Mitigation Policies</article-title>. <source>Commun Res</source>. <year>2012</year> <month>Dec</month> <day>1</day>;<volume>39</volume>(<issue>6</issue>):<fpage>701</fpage>–<lpage>23</lpage>.</mixed-citation></ref>
<ref id="c73"><label>73.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Diaconescu</surname> <given-names>AO</given-names></string-name>, <string-name><surname>Mathys</surname> <given-names>C</given-names></string-name>, <string-name><surname>Weber</surname> <given-names>LAE</given-names></string-name>, <string-name><surname>Daunizeau</surname> <given-names>J</given-names></string-name>, <string-name><surname>Kasper</surname> <given-names>L</given-names></string-name>, <string-name><surname>Lomakina</surname> <given-names>EI</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>Inferring on the Intentions of Others by Hierarchical Bayesian Learning</article-title>. <source>PLOS Comput Biol</source>. <year>2014</year> <month>Sep</month> <day>4</day>;<volume>10</volume>(<issue>9</issue>):<elocation-id>e1003810</elocation-id>.</mixed-citation></ref>
<ref id="c74"><label>74.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname> <given-names>L</given-names></string-name>, <string-name><surname>Glascher</surname> <given-names>J</given-names></string-name></person-group>. <article-title>A brain network supporting social influences in human decision-making</article-title>. <source>Sci Adv</source>. <year>2020</year> <month>Aug</month>;<volume>6</volume>(<issue>34</issue>):<elocation-id>eabb4159</elocation-id>.</mixed-citation></ref>
<ref id="c75"><label>75.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Burke</surname> <given-names>CJ</given-names></string-name>, <string-name><surname>Tobler</surname> <given-names>PN</given-names></string-name>, <string-name><surname>Baddeley</surname> <given-names>M</given-names></string-name>, <string-name><surname>Schultz</surname> <given-names>W</given-names></string-name></person-group>. <article-title>Neural mechanisms of observational learning</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2010</year> <month>Aug</month> <day>10</day>;<volume>107</volume>(<issue>32</issue>):<fpage>14431</fpage>–<lpage>6</lpage>.</mixed-citation></ref>
<ref id="c76"><label>76.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Chelarescu</surname> <given-names>P</given-names></string-name></person-group>. <article-title>Deception in Social Learning: A Multi-Agent Reinforcement Learning Perspective</article-title>. <source>arXiv</source>; <year>2021</year>. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2106.05402">http://arxiv.org/abs/2106.05402</ext-link></mixed-citation></ref>
<ref id="c77"><label>77.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Charpentier</surname> <given-names>CJ</given-names></string-name>, <string-name><surname>Iigaya</surname> <given-names>K</given-names></string-name>, <string-name><surname>O’Doherty</surname> <given-names>JP</given-names></string-name></person-group>. <article-title>A Neuro-computational Account of Arbitration between Choice Imitation and Goal Emulation during Human Observational Learning</article-title>. <source>Neuron</source>. <year>2020</year> <month>May</month> <day>20</day>;<volume>106</volume>(<issue>4</issue>):<elocation-id>687–699.e7</elocation-id>.</mixed-citation></ref>
<ref id="c78"><label>78.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Garrett</surname> <given-names>RK</given-names></string-name></person-group>. <article-title>Echo chambers online?: Politically motivated selective exposure among Internet news users1</article-title>. <source>J Comput-Mediat Commun</source>. <year>2009</year> <month>Jan</month> <day>1</day>;<volume>14</volume>(<issue>2</issue>):<fpage>265</fpage>–<lpage>85</lpage>.</mixed-citation></ref>
<ref id="c79"><label>79.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Ross Arguedas</surname> <given-names>A</given-names></string-name>, <string-name><surname>Robertson</surname> <given-names>C</given-names></string-name>, <string-name><surname>Fletcher</surname> <given-names>R</given-names></string-name>, <string-name><surname>Nielsen</surname> <given-names>R</given-names></string-name></person-group>. <article-title>Echo chambers, filter bubbles, and polarisation: a literature review </article-title>. <source>Reuters Institute for the Study of Journalism</source>; <year>2022</year>, <ext-link ext-link-type="uri" xlink:href="https://ora.ox.ac.uk/objects/uuid:6e357e97-7b16-450a-a827-a92c93729a08">https://ora.ox.ac.uk/objects/uuid:6e357e97-7b16-450a-a827-a92c93729a08</ext-link></mixed-citation></ref>
<ref id="c80"><label>80.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cardenal</surname> <given-names>AS</given-names></string-name>, <string-name><surname>Aguilar-Paredes</surname> <given-names>C</given-names></string-name>, <string-name><surname>Galais</surname> <given-names>C</given-names></string-name>, <string-name><surname>Perez-Montoro</surname> <given-names>M</given-names></string-name></person-group>. <article-title>Digital Technologies and Selective Exposure: How Choice and Filter Bubbles Shape News Media Exposure</article-title>. <source>Int J Press</source>. <year>2019</year> <month>Oct</month> <day>1</day>;<volume>24</volume>(<issue>4</issue>):<fpage>465</fpage>–<lpage>86</lpage>.</mixed-citation></ref>
<ref id="c81"><label>81.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brady</surname> <given-names>WJ</given-names></string-name>, <string-name><surname>Jackson</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Lindstrom</surname> <given-names>B</given-names></string-name>, <string-name><surname>Crockett</surname> <given-names>MJ</given-names></string-name></person-group>. <article-title>Algorithm-mediated social learning in online social networks</article-title>. <source>Trends Cogn Sci</source>. <year>2023</year> <month>Oct</month> <day>1</day>;<volume>27</volume>(<issue>10</issue>):<fpage>947</fpage>–<lpage>60</lpage>.</mixed-citation></ref>
<ref id="c82"><label>82.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bakshy</surname> <given-names>E</given-names></string-name>, <string-name><surname>Messing</surname> <given-names>S</given-names></string-name>, <string-name><surname>Adamic</surname> <given-names>LA</given-names></string-name></person-group>. <article-title>Exposure to ideologically diverse news and opinion on Facebook</article-title>. <source>Science</source>. <year>2015</year> <month>Jun</month> <day>5</day>;<volume>348</volume>(<issue>6239</issue>):<fpage>1130</fpage>–<lpage>2</lpage>.</mixed-citation></ref>
<ref id="c83"><label>83.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Anwyl-Irvine</surname> <given-names>AL</given-names></string-name>, <string-name><surname>Massonnie</surname> <given-names>J</given-names></string-name>, <string-name><surname>Flitton</surname> <given-names>A</given-names></string-name>, <string-name><surname>Kirkham</surname> <given-names>N</given-names></string-name>, <string-name><surname>Evershed</surname> <given-names>JK</given-names></string-name></person-group>. <article-title>Gorilla in our midst: An online behavioral experiment builder</article-title>. <source>Behav Res Methods</source>. <year>2020</year> <month>Feb</month> <day>1</day>;<volume>52</volume>(<issue>1</issue>):<fpage>388</fpage>–<lpage>407</lpage>.</mixed-citation></ref>
<ref id="c84"><label>84.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Foa</surname> <given-names>EB</given-names></string-name>, <string-name><surname>Huppert</surname> <given-names>JD</given-names></string-name>, <string-name><surname>Leiberg</surname> <given-names>S</given-names></string-name>, <string-name><surname>Langner</surname> <given-names>R</given-names></string-name>, <string-name><surname>Kichic</surname> <given-names>R</given-names></string-name>, <string-name><surname>Hajcak</surname> <given-names>G</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>The Obsessive-Compulsive Inventory: Development and validation of a short version</article-title>. <source>Psychol Assess</source>. <year>2002</year>;<volume>14</volume>(<issue>4</issue>):<fpage>485</fpage>–<lpage>96</lpage>.</mixed-citation></ref>
<ref id="c85"><label>85.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Freeman</surname> <given-names>D</given-names></string-name>, <string-name><surname>Loe</surname> <given-names>BS</given-names></string-name>, <string-name><surname>Kingdon</surname> <given-names>D</given-names></string-name>, <string-name><surname>Startup</surname> <given-names>H</given-names></string-name>, <string-name><surname>Molodynski</surname> <given-names>A</given-names></string-name>, <string-name><surname>Rosebrock</surname> <given-names>L</given-names></string-name>, <etal>et al.</etal></person-group> <article-title>The revised Green et al., Paranoid Thoughts Scale (R-GPTS): psychometric properties, severity ranges, and clinical cutoffs</article-title>. <source>Psychol Med</source>. <volume>51</volume>(<issue>2</issue>):<fpage>244</fpage>–<lpage>53</lpage>. <year>2021</year></mixed-citation></ref>
<ref id="c86"><label>86.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Altemeyer</surname> <given-names>B</given-names></string-name></person-group>. <article-title>Dogmatic behavior among students: testing a new measure of dogmatism</article-title>. <source>J Soc Psychol</source>. <year>2002</year> <month>Dec</month>;<volume>142</volume>(<issue>6</issue>):<fpage>713</fpage>–<lpage>21</lpage>.</mixed-citation></ref>
<ref id="c87"><label>87.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wagenmakers</surname> <given-names>EJ</given-names></string-name>, <string-name><surname>Ratcliff</surname> <given-names>R</given-names></string-name>, <string-name><surname>Gomez</surname> <given-names>P</given-names></string-name>, <string-name><surname>Iverson</surname> <given-names>GJ</given-names></string-name></person-group>. <article-title>Assessing model mimicry using the parametric bootstrap</article-title>. <source>J Math Psychol</source>. <year>2004</year> <month>Feb</month> <day>1</day>;<volume>48</volume>(<issue>1</issue>):<fpage>28</fpage>–<lpage>50</lpage>.</mixed-citation></ref>
<ref id="c88"><label>88.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Moran</surname> <given-names>R</given-names></string-name>, <string-name><surname>Keramati</surname> <given-names>M</given-names></string-name>, <string-name><surname>Dayan</surname> <given-names>P</given-names></string-name>, <string-name><surname>Dolan</surname> <given-names>RJ</given-names></string-name></person-group>. <article-title>Retrospective model-based inference guides modelfree credit assignment</article-title>. <source>Nat Commun</source>. <year>2019</year> <month>Feb</month> <day>14</day>;<volume>10</volume>(<issue>1</issue>):<fpage>750</fpage>.</mixed-citation></ref>
<ref id="c89"><label>89.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Moran</surname> <given-names>R</given-names></string-name>, <string-name><surname>Goshen-Gottstein</surname> <given-names>Y</given-names></string-name></person-group>. <article-title>Old processes, new perspectives: Familiarity is correlated with (not independent of) recollection and is more (not equally) variable for targets than for lures</article-title>. <source>Cognit Psychol</source>. <year>2015</year> <month>Jun</month> <day>1</day>;<volume>79</volume>:<fpage>40</fpage>—<lpage>67</lpage>.</mixed-citation></ref>
<ref id="c90"><label>90</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Baron-Cohen</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Wheelwright</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Skinner</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Martin</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Clubley</surname>, <given-names>E.</given-names></string-name></person-group> <article-title>The autism-spectrum quotient (AQ): evidence from Asperger syndrome/high-functioning autism, males and females, scientists and mathematicians</article-title>. <source>J. Autism Dev. Disord</source>. <volume>31</volume>, <fpage>5</fpage>–<lpage>17</lpage> (<year>2001</year>).</mixed-citation></ref>
<ref id="c91"><label>91</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kessler</surname>, <given-names>R. C.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>The World Health Organization Adult ADHD Self-Report Scale (ASRS): a short screening scale for use in the general population</article-title>. <source>Psychol Med</source>. <volume>35</volume>, <fpage>245</fpage>–<lpage>256</lpage> (<year>2005</year>).</mixed-citation></ref>
<ref id="c92"><label>92</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Spitzer</surname>, <given-names>R. L.</given-names></string-name>, <string-name><surname>Kroenke</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Williams</surname>, <given-names>J. B. W.</given-names></string-name> &amp; <string-name><surname>Löwe</surname>, <given-names>B.</given-names></string-name></person-group> <article-title>A brief measure for assessing generalized anxiety disorder: the GAD-7</article-title>. <source>Arch. Intern. Med</source>. <volume>166</volume>, <fpage>1092</fpage>–<lpage>1097</lpage> (<year>2006</year>).</mixed-citation></ref>
<ref id="c93"><label>93</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zung</surname>, <given-names>W. W.</given-names></string-name></person-group> <article-title>A Self-Rating Depression Scale</article-title>. <source>Arch. Gen. Psychiatry</source> <volume>12</volume>, <fpage>63</fpage>–<lpage>70</lpage> (<year>1965</year>).</mixed-citation></ref>
<ref id="c94"><label>94</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stanford</surname>, <given-names>M. S.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Fifty years of the Barratt Impulsiveness Scale: An update and review</article-title>. <source>Personal Individ Differ</source>. <volume>47</volume>, <fpage>385</fpage>–<lpage>395</lpage> (<year>2009</year>).</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106073.3.sa4</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Diaconescu</surname>
<given-names>Andreea Oliviana</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/03dbr7087</institution-id><institution>University of Toronto</institution>
</institution-wrap>
<city>Toronto</city>
<country>Canada</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Compelling</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study provides an <bold>important</bold> advance in credibility-based learning research by demonstrating how feedback reliability can shape reward learning biases within a carefully controlled bandit task. The strength of the main findings, namely greater learning from credible feedback and robust computational modeling supported by strong parameter recovery and cross-fitting analyses, is <bold>compelling</bold>. The integration of reinforcement learning and Bayesian benchmark models is methodologically rigorous and well-executed, yielding reliable and interpretable results. The revised manuscript shows clear improvements in theoretical framing and transparency regarding limitations. While additional work is warranted to confirm the role of disinformation in amplifying positivity bias and to explore symptom-related variability or richer Bayesian comparators, this paper represents a high-quality and impactful contribution to the study of learning under uncertainty and misinformation.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106073.3.sa3</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This is a well-designed and very interesting study examining the impact of imprecise feedback on outcomes on decision-making. I think this is an important addition to the literature and the results here, which provide a computational account of several decision-making biases, are insightful and interesting.</p>
<p>I do not believe I have substantive concerns related to the actual results presented; my concerns are more related to the framing of some of the work. My main concern is regarding the assertion that the results prove that non-normative and non-Bayesian learning is taking place. I agree with the authors that their results demonstrate that people will make decisions in ways that demonstrate deviations from what would be optimal for maximizing reward in their task under a strict application of Bayes rule. I also agree that they have built reinforcement learning models which do a good job of accounting for the observed behavior. However, the Bayesian models included are rather simple- per the author descriptions, applications of Bayes' rule with either fixed or learned credibility for the feedback agents. In contrast, several versions of the RL models are used, each modified to account for different possible biases. However more complex Bayes-based models exist, notably active inference but even the hierarchical gaussian filter. These formalisms are able to accommodate more complex behavior, such as affect and habits, which might make them more competitive with RL models. I think it is entirely fair to say that these results demonstrate deviations from an idealized and strict Bayesian context; however, the equivalence here of Bayesian and normative is I think misleading or at least requires better justification/explanation. This is because a great deal of work has been done to show that Bayes optimal models can generate behavior or other outcomes that are clearly not optimal to an observer within a given context (consider hallucinations for example) but which make sense in the context of how the model is constructed as well as the priors and desired states the model is given.</p>
<p>As such, I would recommend that the language be adjusted to carefully define what is meant by normative and Bayesian and to recognize that work that is clearly Bayesian could potentially still be competitive with RL models if implemented to model this task. An even better approach would be to directly use one of these more complex modelling approaches, such as active inference, as the comparator to the RL models, though I would understand if the authors would want this to be a subject for future work.</p>
<p>Abstract:</p>
<p>The abstract is lacking in some detail about the experiments done, but this may be a limitation of the required word count? If word count is not an issue, I would recommend adding details of the experiments done and the results.
One comment is that there is an appeal to normative learning patterns, but this suggests that learning patterns have a fixed optimal nature, which may not be true in cases where the purpose of the learning (e.g. to confirm the feeling of safety of being in an in-group) may not be about learning accurately to maximize reward. This can be accommodated in a Bayesian framework by modelling priors and desired outcomes. As such the central premise that biased learning is inherently non-normative or non-Bayesian I think would require more justification. This is true in the introduction as well.</p>
<p>Introduction:</p>
<p>As noted above the conceptualization of Bayesian learning being equivalent to normative learning I think requires either further justification. Bayesian belief updating can be biased an non-optimal from an observer perspective, while being optimal within the agent doing the updating if the priors/desired outcomes are set up to advantage these &quot;non-optimal&quot; modes of decision making.</p>
<p>Results:</p>
<p>I wonder why the agent was presented before the choice - since the agent is only relevant to the feedback after the choice is made. I wonder if that might have induced any false association between the agent identity and the choice itself. This is by no means a critical point but would be interesting to get the authors' thoughts.</p>
<p>The finding that positive feedback increases learning is one that has been shown before and depends on valence, as the authors note. They expanded their reinforcement learning model to include valence; but they did not modify the Bayesian model in a similar manner. This lack of a valence or recency effect might also explain the failure of the Bayesian models in the preceding section where the contrast effect is discussed. It is not unreasonable to imagine that if humans do employ Bayesian reasoning that this reasoning system has had parameters tuned based on the real world, where recency of information does matter; affect has also been shown to be incorporable into Bayesian information processing (see the work by Hesp on affective charge and the large body of work by Ryan Smith). It may be that the Bayesian models chosen here require further complexity to capture the situation, just like some of the biases required updates to the RL models. This complexity, rather than being arbitrary, may be well justified by decision-making in the real world.</p>
<p>The methods mention several symptom scales- it would be interesting to have the results of these and any interesting correlations noted. It is possible that some of individual variability here could be related to these symptoms, which could introduce precision parameter changes in a Bayesian context and things like reward sensitivity changes in an RL context.</p>
<p>Discussion:</p>
<p>(For discussion, not a specific comment on this paper): One wonders also about participant beliefs about the experiment or the intent of the experimenters. I have often had participants tell me they were trying to &quot;figure out&quot; a task or find patterns even when this was not part of the experiment. This is not specific to this paper, but it may be relevant in the future to try and model participant beliefs about the experiment especially in the context of disinformation, when they might be primed to try and &quot;figure things out&quot;.</p>
<p>As a general comment, in the active inference literature, there has been discussion of state-dependent actions, or &quot;habits&quot;, which are learned in order to help agents more rapidly make decisions, based on previous learning. It is also possible that what is being observed is that these habits are at play, and that they represent the cognitive biases. This is likely especially true given, as the authors note, the high cognitive load of the task. It is true that this would mean that full-force Bayesian inference is not being used in each trial, or in each experience an agent might have in the world, but this is likely adaptive on the longer timescale of things, considering resource requirements. I think in this case you could argue that we have a departure from &quot;normative&quot; learning, but that is not necessarily a departure from any possible Bayesian framework, since these biases could potentially be modified by the agent or eschewed in favor of more expensive full-on Bayesian learning when warranted.
Indeed in their discussion on the strategy of amplifying credible news sources to drown out low-credibility sources, the authors hint to the possibility of longer term strategies that may produce optimal outcomes in some contexts, but which were not necessarily appropriate to this task. As such, the performance on this task- and the consideration of true departure from Bayesian processing- should be considered in this wider context.
Another thing to consider is that Bayesian inference is occurring, but that priors present going in produce the biases, or these biases arise from another source, for example factoring in epistemic value over rewards when the actual reward is not large. This again would be covered under an active inference approach, depending on how the priors are tuned. Indeed, given the benefit of social cohesion in an evolutionary perspective, some of these &quot;biases&quot; may be the result of adaptation. For example, it might be better to amplify people's good qualities and minimize their bad qualities in order to make it easier to interact with them; this entails a cost (in this case, not adequately learning from feedback and potentially losing out sometimes), but may fulfill a greater imperative (improved cooperation on things that matter). Given the right priors/desired states, this could still be a Bayes-optimal inference at a social level and as such may be ingrained as a habit which requires effort to break at the individual level during a task such as this.</p>
<p>The authors note that this task does not relate to &quot;emotional engagement&quot; or &quot;deep, identity-related, issues&quot;. While I agree that this is likely mostly true, it is also possible that just being told one is being lied to might elicit an emotional response that could bias responses, even if this is a weak response.</p>
<p>Comments on first revisions:</p>
<p>In their updated version the authors have made some edits to address my concerns regarding the framing of the 'normative' Bayesian model, clarifying that they utilized a simple Bayesian model which is intended to adhere in an idealized manner to the intended task structure, though further simulations would have been ideal.</p>
<p>The authors, however, did not take my recommendation to explore the symptoms in the symptom scales they collected as being a potential source of variability. They note that these were for hypothesis generation and were exploratory, fair enough, but this study is not small and there should have been sufficient sample size for a very reasonable analysis looking at symptom scores.</p>
<p>However, overall the toned-down claims and clarifications of intent are adequate responses to my previous review.</p>
<p>Comments on second revisions:</p>
<p>While I believe an exploration of symptom scores would have been a valuable addition, this is not required for the purpose of the paper, and as such, I have no further comments.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106073.3.sa2</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This important paper studies the problem of learning from feedback given by sources of varying credibility. The convincing combination of experiment and computational modeling helps to pin down properties of learning, while opening unresolved questions for future research.</p>
<p>Summary:</p>
<p>This paper studies the problem of learning from feedback given by sources of varying credibility. Two bandit-style experiments are conducted in which feedback is provided with uncertainty, but from known sources. Bayesian benchmarks are provided to assess normative facets of learning, and alternative credit assignment models are fit for comparison. Some aspects of normativity appear, in addition to possible deviations such as asymmetric updating from positive and negative outcomes.</p>
<p>Strengths:</p>
<p>The paper tackles an important topic, with a relatively clean cognitive perspective. The construction of the experiment enables the use of computational modeling. This helps to pinpoint quantitatively the properties of learning and formally evaluate their impact and importance. The analyses are generally sensible, and advanced parameter recovery analyses (including cross-fitting procedure) provide confidence in the model estimation and comparison. The authors have very thoroughly revised the paper in response to previous comments.</p>
<p>Weaknesses:</p>
<p>The authors acknowledge the potential for cognitive load and the interleaved task structure to play a meaningful role in the results, though leave this for future work. This is entirely reasonable, but remains a limitation in our ability to generalize the results. Broadly, some of the results obtained in cases where the extent of generalization is not always addressed and remains uncertain.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106073.3.sa1</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary</p>
<p>This paper investigates how disinformation affects reward learning processes in the context of a two-armed bandit task, where feedback is provided by agents with varying reliability (with lying probability explicitly instructed). They find that people learn more from credible sources, but also deviate systematically from optimal Bayesian learning: They learned from uninformative random feedback and updated too quickly from fully credible feedback (especially following low-credibility feedback). People also appeared to learn more from positive feedback and there is tentative evidence that this bias is exacerbated for less credible feedback.</p>
<p>Overall, this study highlights how misinformation could distort basic reward learning processes, without appeal to higher order social constructs like identity.</p>
<p>Strengths</p>
<list list-type="bullet">
<list-item><p>The experimental design is simple and well-controlled; in particular, it isolates basic learning processes by abstracting away from social context</p>
</list-item><list-item><p>Modeling and statistics meet or exceed standards of rigor</p>
</list-item><list-item><p>Limitations are acknowledged where appropriate, especially those regarding external validity and challenges in dissociating positivity bias from perseveration</p>
</list-item><list-item><p>The comparison model, Bayes with biased credibility estimates, is strong; deviations are much more compelling than e.g. a purely optimal model</p>
</list-item><list-item><p>The conclusions are of substantial interest from both a theoretical and applied perspective</p>
</list-item></list>
<p>Weaknesses</p>
<p>The authors have done a great job addressing my concerns with the two previous submission. The one issue that they were not able to truly address is the challenge of dissociating positivity bias from perseveration; this challenge weakens evidence for the conclusion that less credible feedback yields a stronger positivity bias. However, the authors have clearly acknowledged this limitation and tempered their conclusions accordingly. Furthermore, the supplementary analyses on this point are suggestive (if not fully conclusive) and do a better job of at least trying to address the confound than most work on positivity/confirmation bias.</p>
<p>I include my previous review describing the challenge in more detail for reference. I encourage interested readers to see the author response as well. It has convinced me that this weakness is not a reflection of the work, but is instead a fundamental challenge for research on positivity bias.</p>
<p>Absolute or relative positivity bias?</p>
<p>The conclusion of greater positivity bias for lower credible feedback (Fig 5) hinges on the specific way in which positivity bias is defined. Specifically, we only see the effect when normalizing the difference in sensitivity to positive vs. negative feedback by the sum. I appreciate that the authors present both and add the caveat whenever they mention the conclusion. However, without an argument that the relative definition is more appropriate, the fact of the matter is that the evidence is equivocal.</p>
<p>There is also a good reason to think that the <italic>absolute</italic> definition is more appropriate. As expected, participants learn more from credible feedback. Thus, normalizing by average learning (as in the relative definition) amounts to dividing the absolute difference by increasingly large numbers for more credible feedback. If there is a fixed absolute positivity bias (or something that looks like it), the relative bias will necessarily be lower for more credible feedback. In fact, the authors own results demonstrate this phenomenon (see below). A reduction in relative bias thus provides weak evidence for the claim.</p>
<p>It is interesting that the discovery study shows evidence of a drop in absolute bias. However, for me, this just raises questions. Why is there a difference? Was one just a fluke? If so, which one?</p>
<p>Positivity bias or perseveration?</p>
<p>Positivity bias and perseveration will both predict a stronger relationship between positive (vs. negative) feedback and future choice. They can thus be confused for each other when inferred from choice data. This potentially calls into question all the results on positivity bias.</p>
<p>The authors clearly identify this concern in the text and go to considerable lengths to rule it out. However, the new results (in revision 1) show that a perseveration-only model can in fact account for the qualitative pattern in the human data (the CA parameters). This contradicts the current conclusion:</p>
<disp-quote content-type="editor-comment">
<p>Critically, however, these analyses also confirmed that perseveration cannot account for our main finding of increased positivity bias, relative to the overall extent of CA, for low-credibility feedback.</p>
</disp-quote>
<p>Figure 24c shows that the credibility-CA model does in fact show stronger positivity bias for less credible feedback. The model distribution for credibility 1 is visibly lower than for credibilities 0.5 and 0.75.</p>
<p>The authors need to be clear that it is the <italic>magnitude</italic> of the effect that the perseveration-only model cannot account for. Furthermore, they should additionally clarify that this is true only for models fit to data; it is possible that the credibility-CA model could capture the full size of the effect with different parameters (which could fit best if the model was implemented slightly differently).</p>
<p>The authors could make the new analyses somewhat stronger by using parameters optimized to capture just the pattern in CA parameters (for example by MSE). This would show that the models are in principle incapable of capturing the effect. However, this would be a marginal improvement because the conclusion would still rest on a quantitative difference that depends on specific modeling assumptions.</p>
<p>New simulations clearly demonstrate the confound in relative bias</p>
<p>Figure 24 also speaks to the relative vs. absolute question. The model without positivity bias shows a slightly <italic>stronger</italic> absolute &quot;positivity bias&quot; for the most credible feedback, but a <italic>weaker</italic> relative bias. This is exactly in line with the logic laid out above. In standard bandit tasks, perseveration can be quite well-captured by a fixed absolute positivity bias, which is roughly what we see in the simulations (I'm not sure what to make of the slight increase; perhaps a useful lead for the authors). However, when we divide by average credit assignment, we now see a reduction. This clearly demonstrates that a reduction in relative bias can emerge without any true differences in positivity bias.</p>
<p>Given everything above, I think it is unlikely that the present data can provide even &quot;solid&quot; evidence for the claim that positivity bias is greater with less credible feedback. This confound could be quickly ruled out, however, by a study in which feedback is sometimes provided in the absence of a choice. This would empirically isolate positivity bias from choice-related effects, including perseveration.</p>
<p>Comments on revisions:</p>
<p>Great work on this. The new paper is very interesting as well. I'm delighted to see that the excessive amount of time I spent on this review has had a concrete impact.</p>
</body>
</sub-article>
<sub-article id="sa4" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.106073.3.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Vidal-Perez</surname>
<given-names>Juan</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Dolan</surname>
<given-names>Raymond J</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Moran</surname>
<given-names>Rani</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>The following is the authors’ response to the previous reviews</p>
<disp-quote content-type="editor-comment">
<p><bold>eLife Assessment</bold></p>
<p>This study provides an important extension of credibility-based learning research with a well-controlled paradigm by showing how feedback reliability can distort reward-learning biases in a disinformation-like bandit task. The strength of evidence is convincing for the core effects reported (greater learning from credible feedback; robust computational accounts, parameter recovery) but incomplete for the specific claims about heightened positivity bias at low credibility, which depend on a single dataset, metric choices (absolute vs relative), and potential perseveration or cueing confounds. Limitations concerning external validity and task-induced cognitive load, and the use of relatively simple Bayesian comparators, suggest that incorporating richer active-inference/HGF benchmarks and designs that dissociate positivity bias from choice history would further strengthen this paper.</p>
</disp-quote>
<p>We thank the editors and reviewers for a careful assessment.</p>
<p>In response, we have toned down our claims regarding heightened positivity biases, explicitly stating that the findings are equivocal and depend on the scale (i.e., metric) and study (whereas previously we stated our hypothesis was supported). We have also clarified which aspects of the findings extend beyond perseveration. We believe the evidence now presented provides convincing support for this more nuanced claim.</p>
<p>We wish to emphasize that dissociating positivity bias from perseveration is a challenge not just for our work, but for the entire field of behavioral reinforcement learning. In fact, in a recent preprint (Learning asymmetry or perseveration? A critical re-evaluation and solution to a pervasive confound, Vidal-Perez et al., 2025; <ext-link ext-link-type="uri" xlink:href="https://osf.io/preprints/psyarxiv/xdse5_v1">https://osf.io/preprints/psyarxiv/xdse5_v1</ext-link>) we argue that, to date, all studies claiming evidence for positivity bias beyond perseveration suffered flaws, and that there are currently no robust, behavioral, model-agnostic signatures that dissociate effects of positivity bias from perseveration. While this remains a limitation, we would stress that, relative to the state of the art in the field, our work goes beyond what has previously been reported. We believe this should also be reflected in the assessment of our work.</p>
<p>We elaborate more on these issues in our responses to R3 below.</p>
<disp-quote content-type="editor-comment">
<p><bold>Public Reviews:</bold></p>
<p><bold>Reviewer #1 (Public review):</bold></p>
<p>Comments on revisions:</p>
<p>In their updated version the authors have made some edits to address my concerns regarding the framing of the 'normative' bayesian model, clarifying that they utilized a simple bayesian model which is intended to adhere in an idealized manner to the intended task structure, though further simulations would have been ideal.</p>
<p>The authors, however, did not take my recommendation to explore the symptoms in the symptom scales they collected as being a potential source of variability. They note that these were for hypothesis generation and were exploratory, fair enough, but this study is not small and there should have been sufficient sample size for a very reasonable analysis looking at symptom scores.</p>
<p>However, overall the toned down claims and clarifications of intent are adequate responses to my previous review.</p>
</disp-quote>
<p>We thank the reviewer. We remain convinced that targeted hypotheses tested using  betterpowered designs is the most effective way to examine how our findings relate to symptom scales, something  we hope to pursue in future studies.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public review):</bold></p>
<p>This important paper studies the problem of learning from feedback given by sources of varying credibility. The convincing combination of experiment and computational modeling helps to pin down properties of learning, while opening unresolved questions for future research.</p>
<p>Summary:</p>
<p>This paper studies the problem of learning from feedback given by sources of varying credibility. Two bandit-style experiments are conducted in which feedback is provided with uncertainty, but from known sources. Bayesian benchmarks are provided to assess normative facets of learning, and alternative credit assignment models are fit for comparison. Some aspects of normativity appear, in addition to possible deviations such as asymmetric updating from positive and negative outcomes.</p>
<p>Strengths:</p>
<p>The paper tackles an important topic, with a relatively clean cognitive perspective. The construction of the experiment enables the use of computational modeling. This helps to pinpoint quantitatively the properties of learning and formally evaluate their impact and importance. The analyses are generally sensible, and advanced parameter recovery analyses (including cross-fitting procedure) provide confidence in the model estimation and comparison. The authors have very thoroughly revised the paper in response to previous comments.</p>
<p>Weaknesses:</p>
<p>The authors acknowledge the potential for cognitive load and the interleaved task structure to play a meaningful role in the results, though leave this for future work. This is entirely reasonable, but remains a limitation in our ability to generalize the results. Broadly, some of the results obtain in cases where the extent of generalization is not always addressed and remains uncertain.</p>
</disp-quote>
<p>We thank the reviewer once more for a thoughtful assessment of our work.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #3 (Public review):</bold></p>
<p>Summary</p>
<p>This paper investigates how disinformation affects reward learning processes in the context of a twoarmed bandit task, where feedback is provided by agents with varying reliability (with lying probability explicitly instructed). They find that people learn more from credible sources, but also deviate systematically from optimal Bayesian learning: They learned from uninformative random feedback, learned more from positive feedback, and updated too quickly from fully credible feedback (especially following low-credibility feedback). Overall, this study highlights how misinformation could distort basic reward learning processes, without appeal to higher order social constructs like identity.</p>
<p>Strengths</p>
<list list-type="bullet">
<list-item><p>The experimental design is simple and well-controlled; in particular, it isolates basic learning processes by abstracting away from social context</p>
</list-item></list>
<list list-type="bullet">
<list-item><p>Modeling and statistics meet or exceed standards of rigor</p>
</list-item></list>
<list list-type="bullet">
<list-item><p>Limitations are acknowledged where appropriate, especially those regarding external validity  - The comparison model, Bayes with biased credibility estimates, is strong; deviations are much more compelling than e.g. a purely optimal model</p>
</list-item></list>
<list list-type="bullet">
<list-item><p>The conclusions are of substantial interest from both a theoretical and applied perspective</p>
</list-item></list>
<p>Weaknesses</p>
<p>The authors have addressed most of my concerns with the initial submission. However, in my view, evidence for the conclusion that less credible feedback yields a stronger positivity bias remains weak. This is due to two issues.</p>
<p>Absolute or relative positivity bias?</p>
<p>The conclusion of greater positivity bias for lower credible feedback (Fig 5) hinges on the specific way in which positivity bias is defined. Specifically, we only see the effect when normalizing the difference in sensitivity to positive vs. negative feedback by the sum. I appreciate that the authors present both and add the caveat whenever they mention the conclusion. However, without an argument that the relative definition is more appropriate, the fact of the matter is that the evidence is equivocal.</p>
</disp-quote>
<p>We thank the reviewer for an insightful engagement with our manuscript. The reviewer’s comments on the subtle interplay between perseveration and learning asymmetries were so thought-provoking that they have inspired a new article that delves deeply into how gradual choice-perseveration can lead to spurious conclusions about learning asymmetries in Reinforcement Learning (Learning asymmetry or perseveration? A critical re-evaluation and solution to a pervasive confound, Vidal-Perez et al., 2025; <ext-link ext-link-type="uri" xlink:href="https://osf.io/preprints/psyarxiv/xdse5_v1">https://osf.io/preprints/psyarxiv/xdse5_v1</ext-link>).</p>
<p>To the point- we agree with the reviewer the evidence for this hypothesis is equivocal, and we took on board the suggestion to tone down our  interpretation of the findings. We now state explicitly, both in the results section (“Positivity bias in learning and credibility”) and in the Discussion, that the results provide equivocal support for our hypothesis:</p>
<p>RESULTS</p>
<p>“However, we found evidence for agent-based modulation of positivity bias when this bias was measured in relative terms. Here we calculated, for each participant and agent, a relative Valence Bias Index (rVBI) as the difference between the Credit Assignment for positive feedback (CA+) and negative feedback (CA-), relative to the overall magnitude of CA (i.e., |CA+| + |CA-|) (Fig. 5c). Using a mixed effects model, we regressed rVBIs on their associated credibility (see Methods), revealing a relative positivity bias for all credibility levels [overall rVBI (b=0.32, F(1,609)=68.16), 50% credibility (b=0.39, t(609)=8.00), 75% credibility (b=0.41, F(1,609)=73.48) and 100% credibility (b=0.17, F(1,609)=12.62), all p’s&lt;0.001]. Critically, the rVBI varied depending on the credibility of feedback (F(2,609)=14.83, p&lt;0.001), such that the rVBI for the 3-star agent was lower than that for both the 1-star (b=-0.22, t(609)=-4.41, p&lt;0.001) and 2-start agent (b=-0.24, F(1,609)=24.74, p&lt;0.001). Feedback with 50% and 75% credibility yielded similar rVBI values (b=0.028, t(609)=0.56,p=0.57). Finally, a positivity bias could not stem from a Bayesian strategy as both Bayesian models predicted a negativity bias (Fig. 5b-c; Fig. S8; and SI 3.1.1.3 Table S11-S12, 3.2.1.1, and 3.2.1.2). Taken together, this provides equivocal support for our initial hypothesis, depending on the measurement scale used to assess  the effect (absolute or relative).”</p>
<p>“Previous research has suggested that positivity bias may spuriously arise from pure choice-perseveration (i.e., a tendency to repeat previous choices regardless of outcome) (49–51). While our models included a perseveration-component, this control may not be perfect. Therefore, in additional control analyses, we generated (using ex-post simulations based on best fitting parameters) synthetic datasets using models including choice-perseveration but devoid of feedback-valence bias, and fitted them with our credibilityvalence model (see SI 3.6.1). These analyses confirmed that a pure perseveration account can  masquerade as an apparent positivity bias and even predict the qualitative pattern of results related to credibility (i.e., a higher relative positivity bias for low-credibility feedback). Critically, however, this account consistently predicted a reduced magnitude of credibility-effect on relative positivity bias as compared to the one we observed in participants, suggesting some of the relative amplification of positivity bias goes above and beyond a contribution from perseveration.”</p>
<p>DISCUSSION</p>
<p>“Previous reinforcement learning studies, report greater credit-assignment based on positive compared to negative feedback, albeit only in the context of veridical feedback (43,44,63). Here, we investigated whether a positivity bias is amplified for information of low credibility, but our findings are equivocal and vary  as a function of scaling (absolute or relative) and study. We observe selective absolute amplification of a  positivity bias for information of low and intermediate credibility in the discovery study alone. In contrast, we find a relative (to the overall extent of CA) amplification of confirmation bias in both studies. Importantly, the magnitude of these amplification effects cannot be reproduced in ex-post simulations of a model incorporating simple choice perseveration without an explicit positivity bias, suggesting that at least part of the amplification reflects a genuine increase in positivity bias.”</p>
<disp-quote content-type="editor-comment">
<p>There is also a good reason to think that the <italic>absolute</italic> definition is more appropriate. As expected, participants learn more from credible feedback. Thus, normalizing by average learning (as in the relative definition) amounts to dividing the absolute difference by increasingly large numbers for more credible feedback. If there is a fixed absolute positivity bias (or something that looks like it), the relative bias will necessarily be lower for more credible feedback. In fact, the authors own results demonstrate this phenomenon (see below). A reduction in relative bias thus provides weak evidence for the claim.</p>
</disp-quote>
<p>We agree with the reviewer that absolute and relative measures can yield conflicting impressions. To some extent, this is precisely why we report both (i.e., if the two would necessarily agree, reporting both would be redundant). However, we are  unconvinced that one measure is inherently more appropriate than the other. In our view, both are valid as long as they are interpreted carefully and in the right context. To illustrate, consider salary changes, which can be expressed on either an absolute or a relative scale. If Bob’s £100 salary increases to £120 and Alice’s £1000 salary increases to £1050, then Bob’s raise is absolutely smaller but relatively larger. Is one measure more appropriate than the other? Economists would argue not; rather, the choice of scale depends on the question at hand.</p>
<p>In the same spirit, we have aimed to be as clear and transparent as possible in stating that 1) in the main study, there is no effect in the absolute sense, and 2) framing positivity bias in relative terms is akin to expressing it as a percentage change.</p>
<disp-quote content-type="editor-comment">
<p>It is interesting that the discovery study shows evidence of a drop in absolute bias. However, for me, this just raises questions. Why is there a difference? Was one a just a fluke? If so, which one?</p>
</disp-quote>
<p>We are unsure why we didn’t find absolute amplification effect within  the main studies. However, we don’t think the results from the preliminary study were just a ‘fluke’. We have recently conducted two new studies  (in preparation  for publication), where we have been able to replicate the finding of increased positivity bias for lower-credibility sources in both absolute and relative terms. We agree current results leave unresolved  questions and we hope to follow up on these in the near future.</p>
<disp-quote content-type="editor-comment">
<p>Positivity bias or perseveration?</p>
<p>Positivity bias and perseveration will both predict a stronger relationship between positive (vs. negative) feedback and future choice. They can thus be confused for each other when inferred from choice data. This potentially calls into question all the results on positivity bias.</p>
<p>The authors clearly identify this concern in the text and go to considerable lengths to rule it out. However, the new results (in revision 1) show that a perseveration-only model can in fact account for the qualitative pattern in the human data (the CA parameters). This contradicts the current conclusion:</p>
<p>Critically, however, these analyses also confirmed that perseveration cannot account for our main finding of increased positivity bias, relative to the overall extent of CA, for low-credibility feedback.</p>
<p>Figure 24c shows that the credibility-CA model does in fact show stronger positivity bias for less credible feedback. The model distribution for credibility 1 is visibly lower than for credibilities 0.5 and 0.75.</p>
<p>The authors need to be clear that it is the <italic>magnitude</italic> of the effect that the perseveration-only model cannot account for. Furthermore, they should additionally clarify that this is true only for models fit to data; it is possible that the credibility-CA model could capture the full size of the effect with different parameters (which could fit best if the model was implemented slightly differently).</p>
<p>The authors could make the new analyses somewhat stronger by using parameters optimized to capture just the pattern in CA parameters (for example by MSE). This would show that the models are in principle incapable of capturing the effect. However, this would be a marginal improvement because the conclusion would still rest on a quantitative difference that depends on specific modeling assumptions.</p>
</disp-quote>
<p>We thank the reviewer for raising this important point. We agree our original wording could have been more carefully formulated and are grateful for this opportunity to refine this. The reviewer is correct that a model with only perseveration can qualitatively reproduce the pattern of increased relative positivity bias for less credible feedback in the main study (but not in the discovery study), and our previous text did not acknowledge this. As stated in the previous section, we have revised the manuscript (in the Results, Discussion, and SI) to ensure we address this in full. Our revised text now makes it explicit that while a pure perseveration account predicts the qualitative pattern, it does not predict the magnitude of the effects we observe in our data.</p>
<p>RESULTS</p>
<p>“Previous research has suggested that positivity bias may spuriously arise from pure choice-perseveration (i.e., a tendency to repeat previous choices regardless of outcome) (49–51). While our models included a perseveration-component, we acknowledge this control is not perfect. Therefore, in additional control analyses, we generated (using ex-post simulations based on best fitting parameters) synthetic datasets using models including choice-perseveration, but devoid of feedback-valence bias, and fitted these  with our credibility-valence model (see SI 3.6.1). These analyses confirmed  that a pure perseveration account can  masquerade as an apparent positivity bias, and even predict the qualitative pattern of results related to credibility (i.e., a higher relative positivity bias for low-credibility feedback). Critically, however, this account consistently predicted a reduced magnitude of credibility-effect on relative positivity bias as compared to the one we observed in participants, suggesting at least some of the relative amplification of positivity bias goes above and beyond contributions from perseveration.”</p>
<p>DISCUSSION</p>
<p>“Previous reinforcement learning studies, report greater credit-assignment based on positive compared to negative feedback, albeit only in the context of veridical feedback (43,44,63). Here, we investigated whether a positivity bias is amplified for information of low credibility, but our findings on this matter were equivocal and varied as a function of  scaling (absolute or relative) and study. We observe selective absolute amplification of the positivity bias for information of low and intermediate credibility in the discovery study only. In contrast, we find a relative (to the overall extent of CA) amplification of confirmation bias in both studies. Importantly, the magnitude of these amplification effects cannot be reproduced in ex-post simulations of a model incorporating simple choice perseveration without an explicit positivity bias, suggesting that at least part of the amplification reflects a genuine increase in positivity bias.”</p>
<p>SI (3.6.1)</p>
<p>“Interestingly, a pure perseveration account predicted an amplification of the relative positivity bias under low (compared to full) credibility (with the two rightmost histograms in Fig. S24d falling in the positive range). However, the magnitude of this effect was significantly smaller than the empirical effect (as the bulk of these same histograms lies below the green points). Moreover, this account predicted a negative amplification (i.e., attenuation) of an  absolute positivity bias, which was again significantly smaller than the empirical effect (see corresponding histograms in S24b). This pattern raises an intriguing possibility that perseveration may, at least partially, mask a true amplification of absolute positivity bias.”</p>
<p>Furthermore, our revisions  make it now explicit that these analyses are based on ex-post simulations using the model best-fitting parameters. We do not argue that this pattern can’t be captured by other parameters crafted specifically to capture this pattern. However, we believe that the ex-post fitting is the best practice to check whether a model can produce an effect of interest (see for example The Importance of Falsification in Computational Cognitive Modeling, Palminteri et al., 2017; <ext-link ext-link-type="uri" xlink:href="https://www.sciencedirect.com/science/article/pii/S1364661317300542?via%3Dihub">https://www.sciencedirect.com/science/article/pii/S1364661317300542?via%3Dihub</ext-link>). Based on this we agree with the reviewer the benefit from the suggested additional analyses is minimal.</p>
<disp-quote content-type="editor-comment">
<p>New simulations clearly demonstrate the confound in relative bias</p>
<p>Figure 24 also speaks to the relative vs. absolute question. The model without positivity bias shows a slightly <italic>stronger</italic> absolute &quot;positivity bias&quot; for the most credible feedback, but a <italic>weaker</italic> relative bias. This is exactly in line with the logic laid out above. In standard bandit tasks, perseveration can be quite well-captured by a fixed absolute positivity bias, which is roughly what we see in the simulations (I'm not sure what to make of the slight increase; perhaps a useful lead for the authors). However, when we divide by average credit assignment, we now see a reduction. This clearly demonstrates that a reduction in relative bias can emerge without any true differences in positivity bias.</p>
</disp-quote>
<p>This relates back to the earlier point about scaling. However, we wish to clarify that this is not a confound in the usual sense i.e., an external variable that varies systematically with the independent variable (credibility) and influences the dependent variable (positivity bias), thereby undermining causal inference. Rather, we consider it is a scaling issue: measuring absolute versus relative changes in the same variable can yield conflicting impressions.</p>
<disp-quote content-type="editor-comment">
<p>Given everything above, I think it is unlikely that the present data can provide even &quot;solid&quot; evidence for the claim that positivity bias is greater with less credible feedback. This confound could be quickly ruled out, however, by a study in which feedback is sometimes provided in the absence of a choice. This would empirically isolate positivity bias from choice-related effects, including perseveration.</p>
</disp-quote>
<p>We trust  our responses  make clear we have tempered our claims and stated explicitly where a  conclusion is equivocal. We believe we have convincing evidence for a nuanced claim regarding how credibility affects positivity bias.</p>
<p>We are grateful for the reviewer’s suggestion of a study design to empirically isolate positivity bias from choice-related effects. We have considered this carefully, but do not believe the issue is as straightforward as suggested. As we understand it,  the suggestion assumes that positivity bias should persist when people process feedback in the absence of choice (where perseverative tendencies would not be elicited). While this is possible, there is existing work that indicates otherwise. In particular, Chambon et al. (2020, Nature Human Behavior) compared learning following free versus forced choices and found that learning asymmetries, including a positivity bias, were selectively evident in free-choice trials but not in forced-choice trials. This implies that a positivity bias is intricately tied to the act of choosing, rather than a general learning artifact that emerges independently of choice context. This is further supported by arguments that the positivity bias in reinforcement learning is better understood as a form of confirmation bias, whereby feedback confirming a choice is weighted more heavily (Palminteri et al., 2017, Plos Comp. Bio.). In other words, it is unclear whether one should expect positivity/confirmation bias to emerge when feedback is provided in the absence of choice.</p>
<p>That said, we agree fully with a  need to have task designs that better dissociate positivity bias from perseveration. We now acknowledge in our Discussion that such designs can  benefit future studies on this topic:</p>
<disp-quote content-type="editor-comment">
<p>Future studies could also benefit from using designs that are better suited for dissociating learning asymmetries from gradual perseveration (51).</p>
</disp-quote>
<p>We hope to be able to pursue this direction in the future.</p>
<disp-quote content-type="editor-comment">
<p><bold>Recommendations for the Authors:</bold></p>
<p>I greatly appreciate the care with which you responded to my comments. I'm sorry that I can't improve my overall evaluation, given the seriousness of the concerns in the public review (which the new results have unfortunately bolstered more than assuaged). If it were me, I would definitely collect more data because both issues could very likely be strongly addressed with slight modifications of the current task.</p>
<p>Alternatively, you could just dramatically de-emphasize the claim that positivity bias is higher for less credible feedback. I will be sad because it was my favorite result, but you have many other strong results, and I would still label the paper &quot;important&quot; without this one.</p>
</disp-quote>
<p>We thank the reviewer for an  exceptionally thorough and insightful engagement with our manuscript. Your meticulous attention to detail, and sharp conceptual critiques, have been invaluable, and our  paper is immeasurably stronger and more rigorous as a direct result of this  input. Indeed, the referee’s comments inspired us to prepare a new article that delves deeply into the confound of dissociating between gradual choice-perseveration and learning asymmetries in RL (Learning asymmetry or perseveration? A critical re-evaluation and solution to a pervasive confound, Vidal-Perez et al., 2025; <ext-link ext-link-type="uri" xlink:href="https://osf.io/preprints/psyarxiv/xdse5_v1">https://osf.io/preprints/psyarxiv/xdse5_v1</ext-link>).</p>
<p>Specifically, in this new paper we address the point that dissociating positivity bias from perseveration is a challenge not just for our work, but for the entire field of behavioral reinforcement learning. In fact, we argue that all studies claiming evidence for positivity bias, over and above an effect of perseveration, are subject to  flaws,  including being biased to find evidence for positivity/confirmation bias. Furthermore, we agree with the reviewer’s wish to see modelagnostic support and note there are currently no robust, behavioral, model-agnostic signatures implicating positivity bias over and above an effect of perseveration. While this remains an acknowledged limitation within  our current work, we trust the reviewer will agree that relative to other efforts in the field, our current work pushes the boundary and takes several important steps beyond what has previously been done in this area.</p>
<disp-quote content-type="editor-comment">
<p>Below are some minor notes, mostly on the new content-hopefully easy; please don't put much time into addressing these!</p>
<p>Main text</p>
<p>where individuals preferably learn from . Perhaps &quot;preferentially&quot;?</p>
</disp-quote>
<p>The text has been modified to accommodate the reviewer’s comment:</p>
<p>“Additionally, in both experiments, participants exhibited increased learning from trustworthy information when it was preceded by non-credible information and an amplified normalized positivity bias for noncredible sources, where individuals preferentially learn from positive compared to negative feedback (relative to the overall extent of learning).”</p>
<disp-quote content-type="editor-comment">
<p>One interpretation of this model is as a &quot;sophisticated&quot; logistic ... the CA parameters take the role of &quot;regression coefficients&quot;</p>
<p>Consider removing &quot;sophisticated&quot; and also the quotations around &quot;regression coefficients&quot;. This came across as unprofessional to me.</p>
</disp-quote>
<p>The text has been modified to accommodate the reviewer’s comment:</p>
<p>“The probability to choose a bandit (say A over B) in this family of models is a logistic function of the contrast choice-propensities between these two bandits.  One interpretation of this model is as a logistic regression, where the CA parameters take the role of regression coefficients corresponding to the change in log odds of repeating  the just-taken action in future trials based on the feedback (+/- CA for positive or negative feedback, respectively; the model also includes gradual perseveration which allows for constant log-odd changes that are not affected by choice feedback).”</p>
<disp-quote content-type="editor-comment">
<p>These models operate as our instructed-credibility and free-credibility Bayesian models, but also incorporate a perseveration values, updated in each trial as in our CA models (Eqs. 3 and 5).</p>
<p>Is Eq 3 supposed to be Eq 4 here? I don't see how Eq 3 is relevant. Relatedly, please use a variable other than P for perseveration because P(chosen) reads as &quot;probability chosen&quot; - and you actually use P in latter sense in e.g. Eq 11</p>
</disp-quote>
<p>The text has been modified to accommodate the reviewer’s comment. P values have been changed to Pers and P(bandit) has been replaced by Prob(bandit).
“All models also included gradual perseveration for each bandit. In each trial the perseveration values (Pers) were updated according to</p>
<disp-formula id="sa4equ1">
<graphic mime-subtype="jpg" xlink:href="elife-106073-sa4-equ1.jpg" mimetype="image"/>
</disp-formula>
<p>Where PERS is a free parameter representing the P-value change for the chosen bandit, and fP (Î[0,1]) is the free parameter denoting the forgetting rate applied to the Pers value. Additionally, the Pers-values of all the non-chosen bandits (i.e., again, the unchosen bandit of the current pair, and all the bandits from the not-shown pairs) were forgotten as follows:</p>
<disp-formula id="sa4equ2">
<graphic mime-subtype="jpg" xlink:href="elife-106073-sa4-equ2.jpg" mimetype="image"/>
</disp-formula>
<p>We modelled choices using a softmax decision rule, representing the probability of the participant to choose a given bandit over the alternative:</p>
<disp-formula id="sa4equ3">
<graphic mime-subtype="jpg" xlink:href="elife-106073-sa4-equ3.jpg" mimetype="image"/>
</disp-formula>
<disp-quote content-type="editor-comment">
<p>SI</p>
<p>Figure 24 and Figure 26: in the x tick labels, consider using e.g. &quot;0.5 vs 1&quot; rather than &quot;0.5-1&quot;. I initially read this as a bin range.</p>
</disp-quote>
<p>We thank the reviewer for pointing this out. Our intention was to denote a direct subtraction (i.e., the effect for 0.5 credibility minus the effect for 1.0 credibility). We were  concerned that not noting the subtraction might confuse readers about the direction of the plotted effect. We have clarified this in the figure legends:</p>
<p>“Figure 24: Predicted positivity bias results for participants and for simulations of the Credibility-CA (including perseveration, but no valence-bias component). a, Valence bias results measured in absolute terms (by regressing the ML CA parameters, on their associated valence and credibility).  b, Difference in positivity bias (measured in absolute terms) across credibility levels. On the x-axis, the hyphen (-) represents subtraction, such that a label of '0.5-1' indicates the difference in the measurement for the 0.5 and 1.0 credibility conditions. Such differences are again based in the same mixed effects model as plot a. The inflation of aVBI for lower-credibility agents is larger than the one predicted by a pure perseveration account.  c, Valence bias results measured in relative terms (by regressing the rVBIs on their associated credibility). Participants present a higher rVBI than what would be predicted by a perseveration account (except for the completely credible agent). d, Difference in rVBI across credibility levels. Such differences are again based in the same mixed effects model as plot c. The inflation of rVBI for lower-credibility agents is larger than the one predicted by a pure perseveration account. Histograms depict the distribution of coefficients from 101 simulated group-level datasets generated by the Credibility-CA model and fitted with the Credibility-Valence CA model. Gray circles represent the mean coefficient from these simulations, while black/green circles show the actual regression coefficients from participant behaviour (green for significant effects in participants, black for non-significant). Significance markers (* p&lt;.05, ** p&lt;.01) indicate that fewer than 5% or 1% of simulated datasets, respectively, predicted an effect as strong as or stronger than that observed in participants, and in the same direction as the participant effect.”</p>
<disp-quote content-type="editor-comment">
<p>However, importantly, these simulations did not predict a change in the level of positivity bias as a function of feedback credibility</p>
<p>You're confirming the null hypothesis here; running more simulations would likely yield a significant effect. The simulation shows a pretty clear pattern of increasing positivity bias with higher credibility. Crucially, this is the opposite of what people show. Please adjust the language accordingly.</p>
</disp-quote>
<p>The text has been modified to accommodate the reviewer’s comment.</p>
<p>“However, importantly, these simulations did not reveal a significant change in the level of positivity bias as a function of feedback credibility, neither at an absolute level (F(3,412)=1.43,p=0.24), nor at a relative level (F(3,412)=2.06,p=0.13) (Fig. S25a-c). Numerically, the trend was towards an increasing (rather than decreasing) positivity bias as a function of credibility.”</p>
<disp-quote content-type="editor-comment">
<p>More importantly, the inflation in positivity bias for lower credibility feedback is substantially higher in participants than what would be predicted by a pure perseveration account, a finding that holds true for both absolute (Fig. S24b) and relative (Fig. S24d) measures.</p>
<p>A statistical test would be nice here, e.g. a regression like <code>rVBI ~ credibility_1 * is_model</code>. Alternatively, clearly state what to look for in the figure, where it is pretty clear when you know exactly what you're looking for.</p>
</disp-quote>
<p>The text has been modified to make sure that the figure is easier to interpret (we pointed out to readers what they should look at):</p>
<p>“Interestingly, a pure perseveration account predicted an amplification of the relative positivity bias under low (compared to full) credibility (with the two rightmost histograms in Fig. S24c falling in the positive range). However, the magnitude of this effect was significantly smaller than the empirical effect (as the bulk of these same histograms lies below the green points). Moreover, this account predicted a negative amplification (i.e., attenuation) of an  absolute positivity bias, which was again significantly smaller than the empirical effect (see corresponding histograms in S24b). This pattern raises an intriguing possibility that perseveration may partially mask a true amplification of absolute positivity bias.”</p>
</body>
</sub-article>
</article>