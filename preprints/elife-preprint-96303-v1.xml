<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">96303</article-id>
<article-id pub-id-type="doi">10.7554/eLife.96303</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.96303.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Geometry and dynamics of representations in a precisely balanced memory network related to olfactory cortex</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0007-2038-8398</contrib-id>
<name>
<surname>Meissner-Bernard</surname>
<given-names>Claire</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1883-644X</contrib-id>
<name>
<surname>Zenke</surname>
<given-names>Friedemann</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9107-0482</contrib-id>
<name>
<surname>Friedrich</surname>
<given-names>Rainer W.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Friedrich Miescher Institute for Biomedical Research</institution>, Maulbeerstrasse 66, 4058 Basel, <country>Switzerland</country></aff>
<aff id="a2"><label>2</label><institution>University of Basel</institution>, 4003 Basel, <country>Switzerland</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Gjorgjieva</surname>
<given-names>Julijana</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Technical University of Munich</institution>
</institution-wrap>
<city>Freising</city>
<country>Germany</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Poirazi</surname>
<given-names>Panayiota</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>FORTH Institute of Molecular Biology and Biotechnology</institution>
</institution-wrap>
<city>Heraklion</city>
<country>Greece</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>Correspondence: <email>rainer.friedrich@fmi.ch</email></corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-05-09">
<day>09</day>
<month>05</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP96303</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-01-30">
<day>30</day>
<month>01</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-01-18">
<day>18</day>
<month>01</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.12.12.571272"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Meissner-Bernard et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Meissner-Bernard et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-96303-v1.pdf"/>
<abstract>
<title>Abstract</title><p>Biological memory networks are thought to store information in the synaptic connectivity between assemblies of neurons. Recent models suggest that these assemblies contain both excitatory and inhibitory neurons (E/I assemblies), resulting in co-tuning and precise balance of excitation and inhibition. To understand computational consequences of E/I assemblies under biologically realistic constraints we created a spiking network model based on experimental data from telencephalic area Dp of adult zebrafish, a precisely balanced recurrent network homologous to piriform cortex. We found that E/I assemblies stabilized firing rate distributions compared to networks with excitatory assemblies and global inhibition. Unlike classical memory models, networks with E/I assemblies did not show discrete attractor dynamics. Rather, responses to learned inputs were locally constrained onto manifolds that “focused” activity into neuronal subspaces. The covariance structure of these manifolds supported pattern classification when information was retrieved from selected neuronal subsets. Networks with E/I assemblies therefore transformed the geometry of neuronal coding space, resulting in continuous representations that reflected both relatedness of inputs and an individual’s experience. Such continuous internal representations enable fast pattern classification, can support continual learning, and may provide a basis for higher-order learning and cognitive computations.</p>
</abstract>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Supplementary Figure added and minor changes to the text</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Autoassociative memory establishes internal representations of specific inputs that may serve as a basis for higher brain functions including classification and prediction. Representational learning in autoassociative memory networks is thought to involve spike timing-dependent synaptic plasticity and potentially other mechanisms that enhance connectivity among assemblies of excitatory neurons (<xref ref-type="bibr" rid="c30">Hebb, 1949</xref>; <xref ref-type="bibr" rid="c46">Miehl et al., 2022</xref>; <xref ref-type="bibr" rid="c59">Ryan et al., 2015</xref>). Classical theories proposed that assemblies define discrete attractor states and map related inputs onto a common stable output pattern. Hence, neuronal assemblies are thought to establish internal representations, or memories, that classify inputs relative to previous experience via attractor dynamics (<xref ref-type="bibr" rid="c33">Hopfield, 1982</xref>; <xref ref-type="bibr" rid="c37">Kohonen, 1984</xref>). However, brain areas with memory functions such as the hippocampus or neocortex often exhibit dynamics that is atypical of attractor networks including irregular firing patterns, transient responses to inputs, and high trial-to-trial variability (<xref ref-type="bibr" rid="c34">Iurilli and Datta, 2017</xref>; <xref ref-type="bibr" rid="c54">Renart et al., 2010</xref>; <xref ref-type="bibr" rid="c67">Shadlen and Newsome, 1994</xref>).</p>
<p>Irregular, fluctuation-driven firing reminiscent of cortical activity emerges in recurrent networks when neurons receive strong excitatory (E) and inhibitory (I) synaptic input (<xref ref-type="bibr" rid="c67">Shadlen and Newsome, 1994</xref>; <xref ref-type="bibr" rid="c71">Van Vreeswijk and Sompolinsky, 1996</xref>). In such “balanced state” networks, enhanced connectivity among assemblies of E neurons is prone to generate runaway activity unless matched I connectivity establishes co-tuning of E and I inputs in individual neurons. The resulting state of “precise” synaptic balance stabilizes firing rates because inhomogeneities or fluctuations in excitation are tracked by correlated inhibition (<xref ref-type="bibr" rid="c31">Hennequin et al., 2017</xref>). E/I co-tuning has been observed experimentally in cortical brain areas (<xref ref-type="bibr" rid="c7">Bhatia et al., 2019</xref>; <xref ref-type="bibr" rid="c26">Froemke et al., 2007</xref>; <xref ref-type="bibr" rid="c50">Okun and Lampl, 2008</xref>; <xref ref-type="bibr" rid="c58">Rupprecht and Friedrich, 2018</xref>; <xref ref-type="bibr" rid="c74">Wehr and Zador, 2003</xref>) and emerged in simulations that included spike-timing dependent plasticity at I synapses (<xref ref-type="bibr" rid="c39">Lagzi and Fairhall, 2022</xref>; <xref ref-type="bibr" rid="c41">Litwin-Kumar and Doiron, 2014</xref>; <xref ref-type="bibr" rid="c72">Vogels et al., 2011</xref>; <xref ref-type="bibr" rid="c79">Zenke et al., 2015</xref>). In simulations, E/I co-tuning can be established by including I neurons in assemblies, resulting in “E/I assemblies” where I neurons track activity of E neurons (<xref ref-type="bibr" rid="c6">Barron et al., 2017</xref>; <xref ref-type="bibr" rid="c39">Lagzi and Fairhall, 2022</xref>; <xref ref-type="bibr" rid="c43">Mackwood et al., 2021</xref>). Exploring the structural basis of E/I co-tuning in biological networks is challenging because it requires the dense reconstruction of large neuronal circuits at synaptic resolution (<xref ref-type="bibr" rid="c25">Friedrich and Wanner, 2021</xref>).</p>
<p>Modeling studies started to investigate effects of E/I assemblies on network dynamics (<xref ref-type="bibr" rid="c13">Chenkov, 2017</xref>; <xref ref-type="bibr" rid="c43">Mackwood et al., 2021</xref>; <xref ref-type="bibr" rid="c62">Sadeh and Clopath, 2020a</xref>; <xref ref-type="bibr" rid="c66">Schulz et al., 2021</xref>) but the impact on neuronal computations in the brain remains unclear. Balanced state networks can exhibit a broad range of dynamical behaviors, including chaotic firing, transient responses and stable states (<xref ref-type="bibr" rid="c19">Festa et al., 2018</xref>; <xref ref-type="bibr" rid="c32">Hennequin et al., 2014</xref>; <xref ref-type="bibr" rid="c42">Litwin-Kumar and Doiron, 2012</xref>; <xref ref-type="bibr" rid="c49">Murphy and Miller, 2009</xref>; <xref ref-type="bibr" rid="c55">Rost et al., 2018</xref>; <xref ref-type="bibr" rid="c56">Roudi and Latham, 2007</xref>), implying that computational consequences of E/I assemblies depend on network parameters. We therefore examined effects of E/I assemblies on autoassociative memory in a spiking network model that was constrained by experimental data from telencephalic area Dp of adult zebrafish, which is homologous to piriform cortex (<xref ref-type="bibr" rid="c48">Mueller et al., 2011</xref>).</p>
<p>Dp and piriform cortex receive direct input from mitral cells in the olfactory bulb (OB) and have been proposed to function as autoassociative memory networks (<xref ref-type="bibr" rid="c29">Haberly, 2001</xref>; <xref ref-type="bibr" rid="c76">Wilson and Sullivan, 2011</xref>). Consistent with this hypothesis, manipulations of neuronal activity in piriform cortex affected olfactory memory (<xref ref-type="bibr" rid="c45">Meissner-Bernard et al., 2018</xref>; <xref ref-type="bibr" rid="c60">Sacco and Sacchetti, 2010</xref>). In both brain areas, odors evoke temporally patterned, distributed activity patterns (<xref ref-type="bibr" rid="c8">Blazing and Franks, 2020</xref>; <xref ref-type="bibr" rid="c68">Stettler and Axel, 2009</xref>; <xref ref-type="bibr" rid="c78">Yaksi et al., 2009</xref>) that are dominated by synaptic inputs from recurrent connections (<xref ref-type="bibr" rid="c21">Franks et al., 2011</xref>; <xref ref-type="bibr" rid="c58">Rupprecht and Friedrich, 2018</xref>) and modified by experience (<xref ref-type="bibr" rid="c12">Chapuis and Wilson, 2011</xref>; <xref ref-type="bibr" rid="c20">Frank et al., 2019</xref>; <xref ref-type="bibr" rid="c35">Jacobson et al., 2018</xref>; <xref ref-type="bibr" rid="c51">Pashkovski et al., 2020</xref>). Whole-cell voltage clamp recordings revealed that neurons in posterior Dp (pDp) received large E and I synaptic inputs during odor responses. These inputs were co-tuned in odor space and correlated on fast timescales, demonstrating that pDp enters a transient state of precise synaptic balance during odor stimulation (<xref ref-type="bibr" rid="c58">Rupprecht and Friedrich, 2018</xref>).</p>
<p>We found that network models of pDp without E/I co-tuning generated persistent attractor dynamics and exhibited a biologically unrealistic broadening of the firing rate distribution. Introducing E/I assemblies established E/I co-tuning, stabilized the firing rate distribution, and abolished persistent attractor states. In networks with E/I assemblies, population activity was locally constrained onto manifolds that represented learned and related inputs by “focusing” activity into neuronal subspaces. The covariance structure of manifolds supported pattern classification when information was retrieved from selected neuronal subsets. These results show that autoassociative memory networks constrained by biological data operate in a balanced regime where information is contained in the geometry of neuronal manifolds. Predictions derived from these analyses may be tested experimentally by measurements of neuronal population activity in zebrafish.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>A spiking network model based on pDp</title>
<p>To analyze memory-related computational functions of E/I assemblies under biologically realistic constraints we created a spiking neural network model, pDp<sub>sim</sub>, based on experimental data from pDp (<xref rid="fig1" ref-type="fig">Figure 1A</xref>) (<xref ref-type="bibr" rid="c9">Blumhagen et al., 2011</xref>; <xref ref-type="bibr" rid="c58">Rupprecht and Friedrich, 2018</xref>; <xref ref-type="bibr" rid="c78">Yaksi et al., 2009</xref>). pDp<sub>sim</sub> comprised 4000 E neurons and 1000 I neurons, consistent with the estimated total number of 4000 – 10000 neurons in adult zebrafish pDp (unpublished observations). The network received afferent input from 1500 mitral cells in the OB with a mean spontaneous firing rate of 6 Hz (<xref ref-type="bibr" rid="c23">Friedrich and Laurent, 2004</xref>, <xref ref-type="bibr" rid="c24">2001</xref>; <xref ref-type="bibr" rid="c69">Tabor and Friedrich, 2008</xref>). Odors were modeled by increasing the firing rates of 10% of mitral cells to a mean of 15 Hz and decreasing the firing rates of 5% of mitral cells to a mean of 2 Hz (Methods, <xref rid="fig1" ref-type="fig">Figure 1B</xref>). As a result, the mean activity increased only slightly while the variance of firing rates across the mitral cell population increased approximately 7-fold, consistent with experimental observations (<xref ref-type="bibr" rid="c23">Friedrich and Laurent, 2004</xref>; <xref ref-type="bibr" rid="c73">Wanner and Friedrich, 2020</xref>).</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Spiking network model of pDp.</title>
<p><bold>A</bold>. Schematic of pDp<sub>sim</sub>. OB, Olfactory bulb; E, excitatory; I, inhibitory neurons. <bold>B</bold>. Spike raster of a random subset of 50 mitral cells in the OB representing 2 odors. During odor stimulation, firing rates of 10% of mitral cells were increased and firing rates of 5% of mitral cells were decreased (baseline rate, 6 Hz). <bold>C</bold>. Spike raster of random subsets of 50 E and I neurons in response to 2 odors. <bold>D</bold>. Representative membrane potential trace (top) and excitatory (EPSC, black) and inhibitory (IPSC, red) currents (bottom) in one excitatory neuron in response to 2 odors. Purple trace shows net current (EPSC + IPSC). <bold>E</bold>. Odor-evoked inhibitory (red) and excitatory (black and blue) currents as measured in a hypothetical voltage clamp experiment (conductance multiplied by 70 mV, the absolute difference between holding potential and reversal potential; Rupprecht et al., 2018). Representative example of 1 network, averaged across neurons and odors. <bold>F-H</bold>. Measured values of the observables used to match pDp<sub>sim</sub> to experimental data. Each dot represents one network (average over 10 odors); n = 20 networks. Pink shading shows the experimentally observed range of values. <bold>F</bold>. Baseline and odor-evoked population firing rate. <bold>G.</bold> Left: g<sub>OE</sub> is the synaptic conductance in E neurons contributed by afferents from the OB during odor stimulation. Middle: g<sub>syn</sub> is the total odor-evoked synaptic conductance. Right: % recurrent input quantifies the percentage of E input contributed by recurrent connections during odor stimulation. <bold>H</bold>. Correlation coefficient between odor-evoked activity patterns in Dp. The dotted line indicates the mean correlation between odor patterns in the OB.</p></caption>
<graphic xlink:href="571272v2_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>pDp<sub>sim</sub> consisted of sparsely connected integrate-and-fire neurons with conductance-based synapses (connection probability ≤5%). Model parameters were taken from the literature when available and otherwise determined to reproduce experimentally accessible observables (<xref rid="fig1" ref-type="fig">Figure 1F-H</xref>; Methods). The mean firing rate was &lt;0.1 Hz in the absence of stimulation and increased to ~1 Hz during odor presentation (<xref rid="fig1" ref-type="fig">Figure 1C, F</xref>) (<xref ref-type="bibr" rid="c9">Blumhagen et al., 2011</xref>; <xref ref-type="bibr" rid="c57">Rupprecht et al., 2021</xref>; <xref ref-type="bibr" rid="c58">Rupprecht and Friedrich, 2018</xref>). Population activity was odor-specific and activity patterns evoked by uncorrelated OB inputs remained uncorrelated in Dp (<xref rid="fig1" ref-type="fig">Figure 1H</xref>) (<xref ref-type="bibr" rid="c78">Yaksi et al., 2009</xref>). The synaptic conductance during odor presentation substantially exceeded the resting conductance and inputs from other E neurons contributed &gt;80% of the excitatory synaptic conductance (<xref rid="fig1" ref-type="fig">Figure 1G</xref>). Hence, pDp<sub>sim</sub> entered an inhibition-stabilized balanced state (<xref ref-type="bibr" rid="c63">Sadeh and Clopath, 2020b</xref>) during odor stimulation (<xref rid="fig1" ref-type="fig">Figure 1D, E</xref>) with recurrent input dominating over afferent input, as observed in Dp (<xref ref-type="bibr" rid="c58">Rupprecht and Friedrich, 2018</xref>). Shuffling spike times of inhibitory neurons resulted in runaway activity with a probability of ~80%, demonstrating that activity was indeed inhibition-stabilized. These results were robust against parameter variations (Methods). pDp<sub>sim</sub> therefore reproduced key features of pDp.</p>
</sec>
<sec id="s2b">
<title>Co-tuning and stability of networks with E/I assemblies</title>
<p>To create networks with defined neuronal assemblies we re-wired a small subset of the connections in randomly connected (<italic>rand</italic>) networks. An assembly representing a “learned” odor was generated by identifying the 100 E neurons that received the largest number of connections from the activated mitral cells representing this odor and increasing the probability of E-E connectivity among these neurons by the factor <italic>α</italic> (<xref rid="fig2" ref-type="fig">Figure 2A</xref>). The number of incoming connections per neuron was maintained by randomly eliminating connections from neurons outside the assembly. In each network, we created 15 assemblies representing uncorrelated odors. As a consequence, ~30% of E neurons were part of an assembly with few neurons participating in multiple assemblies. Odor-evoked activity within assemblies was higher than the population mean and increased with <italic>α</italic> (<xref rid="fig2" ref-type="fig">Figure 2B</xref>). When <italic>α</italic> reached a critical value of ~6, networks became unstable and generated runaway activity (<xref rid="fig2" ref-type="fig">Figure 2B</xref>).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Neuronal assemblies (memories).</title>
<p><bold>A</bold>. Schematic of assemblies. Each assembly contains the 100 E neurons that are most densely connected to the mitral cells activated by a given odor. Connection probability between these E neurons is increased by a factor <italic>α</italic>. In <italic>Scaled I</italic> networks, weights of all I-to-E synapses are increased by a factor <italic>χ</italic>. In <italic>Tuned</italic> networks, the 25 I neurons that are most densely connected to the 100 E neurons are included in each assembly. In <italic>Tuned I</italic> networks, the probability of I-to-E connections within the assembly is increased by a factor <italic>β</italic>. In <italic>Tuned I+E</italic> networks, probabilities of I-to-E and E-to-I connectivity within the assembly are increased by factors <italic>β</italic> and <italic>γ</italic>, respectively. n = 20 networks with 15 assemblies each were simulated for each group. <bold>B.</bold> Firing rates averaged over all E or I neurons (full lines) and over all assembly neurons (dashed lines) as a function of <italic>α</italic> (mean ± SD. across 20 networks). <bold>C</bold>. Mean E neurons firing rates of <italic>Scaled</italic> (left) and <italic>Tuned</italic> (right) networks in response to learned odors as a function of connection strength and probability, respectively. Squares depict parameters used in following figures unless stated otherwise. <bold>D</bold>. Spike raster plots showing responses of 50 E neurons to two odors in a <italic>Scaled I</italic> and the corresponding <italic>Tuned E+I</italic> network (same neurons and odors in the corresponding <italic>rand</italic> network are shown in <xref rid="fig1" ref-type="fig">Fig. 1C</xref>). <bold>E</bold>. Top: Mean firing rates in response to learned odors as a function of time, averaged across assembly or non-assembly neurons. Bottom: Correlation between activity patterns evoked by different trials of the same learned odor as a function of time. The pink bar indicates odor presentation. <bold>F</bold>. Mean firing rate in response to learned odors or novel odors. Each data point represents one network-odor pair (n=20 networks, 10 odors). <bold>G</bold>. Amplification within and outside (non-A.) assemblies, calculated as the ratio between mean firing rates in response to learned odors averaged across the same populations of neurons in a given structured network (<italic>Scaled I</italic>, <italic>Tuned I</italic>, or <italic>Tuned E+I</italic>) and the corresponding <italic>rand</italic> network. <bold>H</bold>. Quantification of co-tuning by the correlation between time-averaged E and I conductances in response to different odors, average across neurons (n = 20 networks). <bold>I.</bold> Quantification of co-tuning by the ratio of dispersion of joint conductances along balanced and counter-balanced axes (Methods). Each data point corresponds to one network (n = 20). Mean +/- SD.</p></caption>
<graphic xlink:href="571272v2_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We first set <italic>α</italic> = 5 and scaled I-to-E connection weights uniformly by a factor <italic>χ</italic> (“<italic>Scaled I</italic>” networks) until population firing rates in response to learned odors were similar to firing rates in <italic>rand</italic> networks (<xref rid="fig2" ref-type="fig">Figure 2A, C, D, F</xref>). Under these conditions, activity within assemblies was still amplified substantially in comparison to the corresponding neurons in <italic>rand</italic> networks (“pseudo-assembly”) whereas activity outside assemblies was substantially reduced (<xref rid="fig2" ref-type="fig">Figure 2E, G</xref>). Hence, non-specific scaling of inhibition resulted in a divergence of firing rates that exhausted the dynamic range of individual neurons in the population, implying that homeostatic global inhibition is insufficient to maintain a stable firing rate distribution. We further observed that neurons within activated assemblies produced regular spike trains (<xref ref-type="fig" rid="figS2II">Supplementary Figure 2IIA, B</xref>), indicating that the balanced regime was no longer maintained.</p>
<p>In <italic>rand</italic> networks, correlations between E and I synaptic conductances in individual neurons were slightly above zero (<xref rid="fig2" ref-type="fig">Figure 2H</xref>), presumably as a consequence of stochastic inhomogeneities in the connectivity (<xref ref-type="bibr" rid="c52">Pehlevan and Sompolinsky, 2014</xref>). In <italic>Scaled I</italic> networks, correlations remained near zero, indicating that E assemblies by themselves did not enhance E/I co-tuning (<xref rid="fig2" ref-type="fig">Figure 2H</xref>). <italic>Scaled I</italic> networks with structured E but random I connectivity can therefore not account for the stability, synaptic balance, and E/I co-tuning observed experimentally (<xref ref-type="bibr" rid="c58">Rupprecht and Friedrich, 2018</xref>).</p>
<p>We next created structured networks with more precise E/I balance by including I neurons within assemblies. We first selected the 25 I neurons that received the largest number of connections from the 100 E neurons of an assembly. The connectivity between these two sets of neurons was then enhanced by two procedures: (1) in “<italic>Tuned I</italic>” networks, the probability of I-to-E connections was increased by a factor <italic>β</italic> while E-to-I connections remained unchanged. (2) In “<italic>Tuned E+I</italic>” networks, the probability of I-to-E connections was increased by <italic>β</italic> and the probability of E-to-I connections was increased by <italic>γ</italic> (<xref rid="fig2" ref-type="fig">Figure 2A</xref>, <xref ref-type="fig" rid="figS2I">Supplementary Figure 2IA</xref>). As for “<italic>Scaled I</italic>” networks, <italic>β</italic> and <italic>γ</italic> were adjusted to obtain mean population firing rates of ~1 Hz in response to learned odors (<xref rid="fig2" ref-type="fig">Figure 2F</xref>). The other observables used to constrain the <italic>rand</italic> networks remained unaffected (<xref rid="figS2I" ref-type="fig">Supplementary Figure 2I B-D</xref>).</p>
<p>In <italic>Tuned</italic> networks, correlations between E and I conductances in individual neurons were significantly higher than in <italic>rand</italic> or <italic>Scaled I</italic> networks (<xref rid="fig2" ref-type="fig">Figure 2H</xref>. To further analyze E/I co-tuning we projected synaptic conductances of each neuron onto a line representing the E/I ratio expected in a balanced network (“balanced axis”) and onto an orthogonal line (“counter-balanced axis”; <xref rid="fig2" ref-type="fig">Figure 2I</xref>). The ratio between the standard deviations along these axes has been used previously to quantify E/I co-tuning in experimental studies (<xref ref-type="bibr" rid="c58">Rupprecht and Friedrich, 2018</xref>). This ratio was close to 1 in <italic>rand</italic> and <italic>Scaled I</italic> networks but significantly higher in <italic>Tuned I</italic> and <italic>Tuned E+I</italic> networks (<xref rid="fig2" ref-type="fig">Figure 2I</xref>). Hence, <italic>Tuned</italic> networks exhibited significant co-tuning along the balanced axis, as observed in pDp (<xref ref-type="bibr" rid="c58">Rupprecht and Friedrich, 2018</xref>).</p>
<p>In <italic>Tuned</italic> networks, activity within assemblies was higher than the mean activity but substantially lower and more irregular than in <italic>Scaled I</italic> networks (<xref rid="fig2" ref-type="fig">Figure 2D, G</xref>; <xref ref-type="fig" rid="figS2II">Supplementary Figure 2IIA,B</xref>). Unlike in <italic>Scaled I</italic> networks, mean firing rates evoked by novel odors were indistinguishable from those evoked by learned odors and from mean firing rates in <italic>rand</italic> networks (<xref rid="fig2" ref-type="fig">Figure 2F</xref>). Hence, E/I co-tuning prevented excessive amplification of activity in assemblies without affecting global network activity.</p>
</sec>
<sec id="s2c">
<title>Effects of E/I assemblies on attractor dynamics</title>
<p>We next explored effects of assemblies on network dynamics. In <italic>rand</italic> networks, firing rates increased after stimulus onset and rapidly returned to a low baseline after stimulus offset. Correlations between activity patterns evoked by the same odor at different time points and in different trials were positive but substantially lower than unity, indicating high variability. Hence, <italic>rand</italic> networks showed transient and variable responses to input patterns, consistent with the typical behavior of generic balanced state networks (<xref ref-type="bibr" rid="c67">Shadlen and Newsome, 1994</xref>; <xref ref-type="bibr" rid="c71">Van Vreeswijk and Sompolinsky, 1996</xref>). <italic>Scaled</italic> networks responded to learned odors with persistent firing of assembly neurons and high pattern correlations across trials and time, implying attractor dynamics (<xref ref-type="bibr" rid="c33">Hopfield, 1982</xref>; <xref ref-type="bibr" rid="c36">Khona and Fiete, 2022</xref>), whereas <italic>Tuned</italic> networks exhibited transient responses and modest pattern correlations similar to <italic>rand</italic> networks. Hence, <italic>Tuned</italic> networks did not exhibit stable attractor states, presumably because precise synaptic balance prevented strong recurrent amplification within E/I assemblies.</p>
<p>In classical memory networks, attractor dynamics mediates autoassociative pattern classification because noisy or corrupted versions of learned inputs converge onto a consistent output. Hence, classical attractor memory networks perform pattern completion, which may be assessed by different procedures. Completion of partial input patterns can be examined by stimulating subsets of E neurons in an assembly during baseline activity and testing for the recruitment of the remaining assembly neurons (<xref ref-type="bibr" rid="c61">Sadeh and Clopath, 2021</xref>; <xref ref-type="bibr" rid="c72">Vogels et al., 2011</xref>). We found that assemblies were recruited by partial inputs in all structured pDp<sub>sim</sub> networks (<italic>Scaled</italic> and <italic>Tuned</italic>) without a significant increase in the overall population activity (<xref rid="figS3" ref-type="fig">Supplementary Figure 3A</xref>).</p>
<p>To assess pattern completion under more biologically realistic conditions, we morphed a novel odor into a learned odor (<xref rid="fig3" ref-type="fig">Figure 3A</xref>), or a learned odor into another learned odor. In <italic>rand</italic> networks, correlations between activity patterns across E neurons (output correlations) increased approximately linearly as a morphed odor approached a learned odor and remained lower than the corresponding pattern correlations in the OB (input correlations, <xref rid="fig3" ref-type="fig">Figure 3B</xref> and <xref rid="figS3" ref-type="fig">Supplementary Figure 3B</xref>). This is consistent with the absence of pattern completion in generic random networks (<xref ref-type="bibr" rid="c3">Babadi and Sompolinsky, 2014</xref>; <xref ref-type="bibr" rid="c44">Marr, 1969</xref>; <xref ref-type="bibr" rid="c64">Schaffer et al., 2018</xref>; <xref ref-type="bibr" rid="c75">Wiechert et al., 2010</xref>). <italic>Scaled I</italic> networks in contrast, showed typical signatures of pattern completion: output correlations increased abruptly as the learned odor was approached and eventually exceeded the corresponding input correlations (<xref rid="fig3" ref-type="fig">Figure 3B</xref> and <xref rid="figS3" ref-type="fig">Supplementary Figure 3B</xref>). In <italic>Tuned</italic> networks, output correlations changed approximately linearly and never exceeded input correlations, similar to observations in <italic>rand</italic> networks (<xref rid="fig3" ref-type="fig">Figure 3B</xref> and <xref rid="figS3" ref-type="fig">Supplementary Figure 3B</xref>). Similarly, firing rates of assembly neurons increased abruptly as the learned odor was approached in <italic>Scaled I</italic> networks but not in <italic>Tuned</italic> or <italic>rand</italic> networks (<xref rid="fig3" ref-type="fig">Figure 3C</xref>). Hence, networks with E/I assemblies did not perform pattern completion in response to naturalistic stimuli, consistent with the absence of stable attractor dynamics.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Changes of output activity to gradual modifications of inputs.</title>
<p><bold>A</bold>. Morphing of a novel odor N into a learned odor L. Intermediate mixtures were generated by gradually decreasing/increasing the fractions of active mitral cells defining odors N/L. <bold>B</bold>. Pearson correlation between activity patterns evoked by the learned (full line) or novel (dotted line) odor and the intermediate odors in pDp as a function of the corresponding correlations in the OB. <bold>C</bold>. Firing rates in response to intermediate odors averaged across assembly neurons (learned odor, full line) or pseudo-assembly neurons (novel odor, dotted line) as a function of correlations between the OB activity patterns representing the intermediate odors and the OB activity pattern representing the learned odor. B, C: averages over 8 networks.</p></caption>
<graphic xlink:href="571272v2_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2d">
<title>Geometry of activity patterns in networks with E/I assemblies</title>
<p>We next examined how E/I assemblies transform the geometry of neuronal representations, i.e their organization in a state space where each axis represents the activity of one neuron or one pattern of neural covariance (<xref ref-type="bibr" rid="c14">Chung and Abbott, 2021</xref>; <xref ref-type="bibr" rid="c27">Gallego et al., 2017</xref>; <xref ref-type="bibr" rid="c40">Langdon et al., 2023</xref>). To address this general question, we created an odor subspace and examined its transformation by pDp<sub>sim</sub>. The subspace consisted of a set of OB activity patterns representing four uncorrelated pure odors, which were assigned to the corners of a square. Mixtures between the pure odors were represented by pixels inside the square. OB activity patterns representing mixtures were generated by selecting active mitral cells from each of the pure odors’ patterns with probabilities depending on the relative distances from the corners (Methods). Correlations between OB activity patterns representing pure odors and mixtures decreased approximately linearly as a function of distance in the subspace (<xref rid="fig4" ref-type="fig">Figure 4B</xref>). The odor subspace therefore represented a hypothetical olfactory environment with four odor sources at the corners of a square arena. Locations in the odor subspace were visualized by the color code depicted in <xref rid="fig4" ref-type="fig">Figure 4A</xref>.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Geometry of odor representations in pDp<sub>sim</sub>.</title>
<p><bold>A.</bold> Odor subspace delineated by 2 learned (L, M) and 2 novel (N, O) pure odors at the vertices of a square. Pixels within the square represent odor mixtures. <bold>B.</bold> Left: Pearson correlations between OB activity patterns defining pure odors. Right: Correlation between one pure odor (L; top left vertex) and all other odors. The odor from one vertex gradually morphs into the odor from another vertex. <bold>C.</bold> Projection of activity patterns in the OB onto the first 2 principal components (PCs). Colors represent patterns in the odor subspace shown in <bold>A</bold>. <bold>D.</bold> Projection of activity patterns in pDp in response to the odor subspace onto the first 2 PCs. Representative examples of different pDp networks. <bold>E.</bold> Density plot showing distribution of data points and demonstrating clustering at distinct locations in PC space for <italic>Scaled I</italic> networks. <bold>F.</bold> Quantification of dimensionality of neural activity by the participation ratio: activity evoked by novel odors and related mixtures (left), activity evoked by learned odors and related mixtures (center), and activity evoked by all stimuli (right). Each data point represents one network; dotted line represents the participation ratio of OB activity. <bold>G.</bold> Variance along the first 40 PCs extracted from activity patterns in <italic>Rand</italic> and <italic>Tuned E+I</italic> networks. Insets: variance along PCs 200 - 400. <bold>H.</bold> Angles between edges connecting a pure odor response and related versions thereof (see inset). The analysis was performed using the first 400 PCs, which explained &gt;75% of the variance in all networks. n = 21 angles per pure odor in each of 8 networks (Methods). Similar results were obtained in the full-dimensional space.</p></caption>
<graphic xlink:href="571272v2_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To examine how pDp<sub>sim</sub> transforms this odor subspace we projected time-averaged activity patterns onto the first two principal components (PCs). As expected, the distribution of OB activity patterns in PC space closely reflected the geometry of the square (<xref rid="fig4" ref-type="fig">Figure 4C</xref>). This geometry was largely maintained in the output of <italic>rand</italic> networks, consistent with the notion that random networks tend to preserve similarity relationships between input patterns (<xref ref-type="bibr" rid="c3">Babadi and Sompolinsky, 2014</xref>; <xref ref-type="bibr" rid="c44">Marr, 1969</xref>; <xref ref-type="bibr" rid="c64">Schaffer et al., 2018</xref>; <xref ref-type="bibr" rid="c75">Wiechert et al., 2010</xref>). We next examined outputs of <italic>Scaled</italic> or <italic>Tuned</italic> networks containing 15 assemblies, two of which were aligned with pure odors. The four odors delineating the odor subspace therefore consisted of two learned and two novel odors. In <italic>Scaled I</italic> networks, odor inputs were discretely distributed between three locations in state space representing the two learned odors and the residual odors, consistent with the expected attractor states (<xref rid="fig4" ref-type="fig">Figure 4D, E</xref>). <italic>Tuned</italic> networks, in contrast, generated continuous representations of the odor subspace (<xref rid="fig4" ref-type="fig">Figure 4D</xref>). The geometry of these representations was distorted in the vicinity of learned odors, which were further removed from most of the mixtures than novel odors. These geometric transformations were less obvious when activity patterns of <italic>Tuned</italic> networks were projected onto the first two PCs extracted from <italic>rand</italic> networks (<xref rid="figS4" ref-type="fig">Supplementary Figure 4A</xref>). Hence, E/I assemblies introduced local curvature into the coding space that partially separated learned from novel odors without disrupting the continuity of the subspace representation.</p>
<p>The curvature of the representation manifold in <italic>Tuned</italic> networks suggests that E/I assemblies confine activity along specific dimensions of the state space, indicating that activity was locally constrained onto manifolds. To test this hypothesis, we first quantified the dimensionality of odor-evoked activity by the participation ratio, a measure that depends on the eigenvalue distribution of the pairwise neuronal covariance matrix (<xref ref-type="bibr" rid="c2">Altan et al., 2021</xref>) (Methods). As expected, dimensionality was highest in <italic>rand</italic> networks and very low in <italic>Scaled I</italic> networks, reflecting the discrete attractor states (<xref rid="fig4" ref-type="fig">Figure 4F</xref>). In <italic>Tuned</italic> networks, dimensionality was high compared to <italic>Scaled I</italic> networks but lower than in <italic>rand</italic> networks (<xref rid="fig4" ref-type="fig">Figure 4F</xref>). The same trend was observed when we sampled data from a limited number of neurons to mimic experimental conditions (<xref rid="figS4" ref-type="fig">Supplementary Figure 4D</xref>). Furthermore, when restraining the analysis to activity evoked by novel odors and related mixtures, dimensionality was similar between <italic>rand</italic> and <italic>Tuned</italic> networks (<xref rid="fig4" ref-type="fig">Figure 4F</xref>). These observations, together with additional analyses of dimensionality (<xref rid="figS4" ref-type="fig">Supplementary Figure 4B, C</xref>), support the hypothesis that E/I assemblies locally constrain neuronal dynamics onto manifolds without establishing discrete attractor states. Generally, these observations are consistent with recent findings showing effects of specific circuit motifs on the dimensionality of neural activity (<xref ref-type="bibr" rid="c15">Dahmen et al., 2023</xref>; <xref ref-type="bibr" rid="c53">Recanatesi et al., 2019</xref>).</p>
<p>We further tested this hypothesis by examining the local geometry of activity patterns around representations of learned and novel odors. If E/I assemblies locally confine activity onto manifolds, small changes of input patterns should modify output patterns along preferred dimensions near representations of learned but not novel odors. To test this prediction, we selected sets of input patterns including each pure odor and the seven most closely related mixtures. We then quantified the variance of the projections of their corresponding output patterns onto the first 40 PCs (<xref rid="fig4" ref-type="fig">Figure 4G</xref>). This variance decreased only slightly as a function of PC rank for activity patterns related to novel odors, indicating that patterns varied similarly in all directions. For patterns related to learned odors, in contrast, the variance was substantially higher in the direction of the first few PCs, implying variation along preferred dimensions. In addition, we measured the distribution of angles between edges connecting activity patterns representing pure odors and their corresponding related mixtures in high-dimensional PC space (<xref rid="fig4" ref-type="fig">Figure 4H</xref>, inset; Methods; <xref ref-type="bibr" rid="c65">Schoonover et al., 2021</xref>). Angles were narrowly distributed around 1 rad in <italic>rand</italic> networks but smaller in the vicinity of learned patterns in <italic>Tuned</italic> networks (<xref rid="fig4" ref-type="fig">Figure 4 H</xref>). These observations further support the conclusion that E/I assemblies locally constrain neuronal dynamics onto manifolds.</p>
<p>Activity may be constrained non-isotropically by amplification along a subset of dimensions, by inhibition along other dimensions, or both. E neurons participating in E/I assemblies had large loadings on the first two PCs (<xref rid="figS4" ref-type="fig">Supplementary Figure 4 E-F</xref>) and responded to learned odors with increased firing rates as compared to the mean rates in <italic>Tuned E+I</italic> and <italic>rand</italic> networks. Firing rates of the remaining neurons, in contrast, were slightly lower than the corresponding mean rates in <italic>rand</italic> networks (<xref rid="fig2" ref-type="fig">Figure 2G</xref>). Consistent with these observations, the variance of activity projected onto the first few PCs was higher in <italic>Tuned E+I</italic> than in <italic>rand</italic> networks (<xref rid="fig4" ref-type="fig">Figure 4G</xref>) while the variance along higher-order PCs was lower (<xref rid="fig4" ref-type="fig">Figure 4G</xref>, inset). These observations indicate that activity manifolds are delineated both by amplification of activity along preferred directions and by suppression of activity along other dimensions.</p>
</sec>
<sec id="s2e">
<title>Pattern classification by networks with E/I assemblies</title>
<p>The lack of stable attractor states raises the question how transformations of activity patterns by <italic>Tuned</italic> networks affect pattern classification. To quantify the association between an activity pattern and a class of patterns representing a pure odor we computed the Mahalanobis distance (d<sub>M</sub>). This measure quantifies the distance between the pattern and the class center, normalized by the intra-class variability along the relevant direction. Hence, d<sub>M</sub> is a measure for the discriminability of a given pattern from a given class. In bidirectional comparisons between patterns from different classes, the mean d<sub>M</sub> may be asymmetric when the distributions of patterns within the classes are different.</p>
<p>We first quantified d<sub>M</sub> between representations of pure odors based on activity patterns across 80 E neurons drawn from the corresponding (pseudo-) assemblies. d<sub>M</sub> was asymmetrically increased in <italic>Tuned E+I</italic> networks as compared to <italic>rand</italic> networks. Large increases were observed for distances between patterns related to learned odors and reference classes representing novel odors (<xref rid="fig5" ref-type="fig">Figure 5A, B</xref>). In the other direction, increases in d<sub>M</sub> were smaller. Moreover, distances between patterns related to novel odors were almost unchanged (<xref rid="fig5" ref-type="fig">Figure 5B</xref>). Further analyses showed that increases in d<sub>M</sub> in <italic>Tuned E+I</italic> networks involved both increases in the Euclidean distance between class centers and non-isotropic scaling of intra-class variability (<xref rid="figS5" ref-type="fig">Supplementary Figure 5</xref>). The geometric transformation of odor representations by E/I assemblies therefore facilitated pattern classification and particularly enhanced the discriminability of patterns representing learned odors.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Distance relationships and classification of odor representations.</title>
<p><bold>A</bold>. Activity patterns used as class distributions and vectors (B) or training and test sets (C). Same odor subspace as in <xref rid="fig4" ref-type="fig">Figure 4</xref>. <bold>B</bold>. Left: schematic illustration of Mahalanobis distance d<sub>M</sub>. Right: d<sub>M</sub> between one activity vector (v) and reference classes (Q) in <italic>rand</italic> and <italic>Tuned E+I</italic> networks. d<sub>M</sub> was computed based on activity across subsets of 80 E neurons drawn from the four (pseudo-) assemblies with equal probability (top) or from the whole population (bottom). Note that d<sub>M</sub> between patterns related to a learned odor and non-matching reference classes was higher in <italic>Tuned E+I</italic> networks, particularly when E neurons were drawn from assemblies. <bold>C</bold>. Pattern classification probability quantified by QDA. P<sub>Target</sub> quantifies the probability that an activity pattern from the test set (odor mixtures, see <bold>A</bold>) is assigned to a target class from the training set (pure or closely related odor; see <bold>A</bold>). Left: classification probability as a function of the similarity (Pearson correlation) between the test and target odors in the OB (input patterns). Note enhanced classification probability for patterns evoked by odors similar to learned odors in <italic>Tuned E+I</italic> networks. Right: Classification probability for patterns similar to the training set (see <bold>A</bold>).</p></caption>
<graphic xlink:href="571272v2_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To further analyze pattern classification, we performed multi-class quadratic discriminant analysis (QDA), an extension of linear discriminant analysis for classes with unequal variance. Using QDA, we determined the probabilities that an activity pattern evoked by a mixture is classified as being a member of each of four classes representing the pure odors, thus mimicking a 4-way forced choice odor classification task in the olfactory environment. The four classes were defined by the distributions of activity patterns evoked by the pure and closely related odors. We then examined the classification probability of patterns evoked by mixtures with respect to a given class as a function of the similarity between the mixture and the corresponding pure odor (“target”) in the OB. As expected, the classification probability increased with similarity. Furthermore, in <italic>Tuned E+I</italic> networks, the classification probability of mixtures similar to a pure odor was significantly higher when the pure odor was learned (<xref rid="fig5" ref-type="fig">Figure 5C</xref>). Hence, E/I assemblies enhanced the classification of inputs related to learned patterns.</p>
<p>When neuronal subsets were randomly drawn not from assemblies but from the entire population, d<sub>M</sub> was generally lower (<xref rid="fig5" ref-type="fig">Figure 5B</xref>). These results indicate that assembly neurons convey higher-than-average information about learned odors. Together, these observations imply that pDp<sub>sim</sub> did not function as a categorical classifier but nonetheless supported the classification of learned odors, particularly when the readout focused on assembly neurons. Conceivably, classification may be further enhanced by optimizing the readout strategy, for example, by a learning-based approach. However, modeling biologically realistic readout mechanisms requires further experimental insights into the underlying circuitry.</p>
</sec>
<sec id="s2f">
<title>Stability of networks with E/I assemblies against addition of memories</title>
<p>When networks successively learn multiple inputs over time, the divergence of firing rates and the risk of network instability is expected to increase as assemblies are accumulated. We surmised that <italic>Tuned</italic> networks should be more resistant against these risks than <italic>Scaled</italic> networks because activity is controlled more precisely, particularly when assemblies overlap. To test this hypothesis, we examined responses of <italic>Tuned E+I</italic> and <italic>Scaled I</italic> networks to an additional odor subspace where four of the six pairwise correlations between the pure odors were clearly positive (range, 0.27 – 0.44; <xref rid="fig6" ref-type="fig">Figure 6A</xref>). We then compared networks with 15 randomly created assemblies to networks with two additional assemblies aligned to two of the correlated pure odors. In <italic>Scaled I</italic> networks, creating two additional memories resulted in a substantial increase in firing rates, particularly in response to the learned and related odors. In <italic>Tuned E+I</italic> networks, in contrast, firing rates remained almost unchanged despite the increased memory load, and representations of learned odors were well separated in PC space, despite the overlap between assemblies (<xref rid="fig6" ref-type="fig">Figure 6B, C</xref>). These observations are consistent with the assumption that precise balance in E/I assemblies protects networks against instabilities during continual learning, even when memories overlap. Furthermore, in this regime of higher pattern similarity, d<sub>M</sub> was again increased upon learning, particularly between learned odors and reference classes representing other odors (not shown). E/I assemblies therefore consistently increased d<sub>M</sub> in a directional manner under different conditions.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Representation of correlated patterns and resilience against additional memories.</title>
<p><bold>A</bold>. Subspace delineated by four positively correlated odors. Top: Correlations between pure odors. Bottom: Projection of OB activity patterns onto the first two PCs. <bold>B</bold>. Firing rates (top) and PC projection of output activity of a <italic>Tuned E+I</italic> network with 15 E/I assemblies that were not aligned to any of the four pure odors of the subspace. <bold>C.</bold> Firing rates (top) and PC projection of output activity after creation of two additional assemblies representing two of the pure odors (Y and Z). Left: <italic>Tuned E+I</italic> network. Right: <italic>Scaled I</italic> network. Note that in the <italic>Scaled I</italic> network, but not in the <italic>Tuned E+I</italic> network, firing rates evoked by newly learned odors were increased and patterns evoked by these odors were not well separated in PC space.</p></caption>
<graphic xlink:href="571272v2_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<sec id="s3a">
<title>A precisely balanced memory network constrained by pDp</title>
<p>Autoassociative memory networks map inputs onto output patterns representing learned information. Classical models proposed this mapping to be accomplished by discrete attractor states that are defined by assemblies of E neurons and stabilized by global homeostatic inhibition. However, as seen in <italic>Scaled I</italic> networks, global inhibition is insufficient to maintain a stable, biologically plausible firing rate distribution. This problem can be overcome by including I neurons in assemblies, which leads to precise synaptic balance. To explore network behavior in this regime under biologically relevant conditions we created a spiking network model constrained by experimental data from pDp. The resulting <italic>Tuned</italic> networks reproduced additional experimental observations that were not used as constraints including irregular firing patterns, lower output than input correlations, and the absence of persistent activity. Hence, pDp<sub>sim</sub> recapitulated characteristic properties of a biological memory network with precise synaptic balance.</p>
</sec>
<sec id="s3b">
<title>Neuronal dynamics and representations in precisely balanced memory networks</title>
<p>Simulated networks with global inhibition showed attractor dynamics and pattern completion, consistent with classical attractor memory. However, the distribution of firing rates broadened as connection density within assemblies increased, resulting in unrealistically high (low) rates inside (outside) assemblies and, consequently, in a loss of synaptic balance. Hence, global inhibition was insufficient to stabilize population activity against basic consequences of structured connectivity. In networks with E/I assemblies, in contrast, firing rates remained within a realistic range and the inhibition-stabilized balanced state was maintained. Such <italic>Tuned</italic> networks showed no discrete attractor states but transformed the geometry of the coding space by confining activity to continuous manifolds near representations of learned inputs.</p>
<p>Geometrical transformations in <italic>Tuned</italic> networks may be considered as intermediate between two extremes: (1) geometry-preserving transformations as, for example, performed by many random networks (<xref ref-type="bibr" rid="c3">Babadi and Sompolinsky, 2014</xref>; <xref ref-type="bibr" rid="c44">Marr, 1969</xref>; <xref ref-type="bibr" rid="c64">Schaffer et al., 2018</xref>; <xref ref-type="bibr" rid="c75">Wiechert et al., 2010</xref>), and (2) discrete maps as, for example, generated by discrete attractor networks (<xref ref-type="bibr" rid="c22">Freeman and Skarda, 1985</xref>; <xref ref-type="bibr" rid="c33">Hopfield, 1982</xref>; <xref ref-type="bibr" rid="c36">Khona and Fiete, 2022</xref>) (<xref rid="fig7" ref-type="fig">Figure 7</xref>). We found that transformations became more discrete map-like when amplification within assemblies was increased and precision of synaptic balance was reduced. Likewise, decreasing amplification in assemblies of <italic>Scaled</italic> networks changed transformations towards the intermediate behavior, albeit with broader firing rate distributions than in <italic>Tuned</italic> networks (not shown). Hence, precise synaptic balance may be expected to generally favor intermediate over discrete transformations because this regime tends to linearize input-output functions (<xref ref-type="bibr" rid="c4">Baker et al., 2020</xref>; <xref ref-type="bibr" rid="c17">Denève and Machens, 2016</xref>).</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7.</label>
<caption><title>Schematic of geometric transformations.</title>
<p><bold>A</bold>. Randomly connected networks tend to preserve the geometry of coding space. Such networks can support neuronal computations, e.g., by projecting activity patterns in a higher-dimensional coding space for pattern classification. <bold>B</bold>. We found that balanced networks with E/I assemblies transform the geometry of representations by locally restricting activity onto manifolds. These networks stored information about learned inputs while preserving continuity of the coding space. Such a geometry may support fast classification, continual learning and cognitive computations. Note that the true manifold geometry cannot be visualized appropriately in 2D because activity was “focused” in different subsets of dimensions at different locations of coding space. As a consequence, the dimensionality of activity remained substantial. <bold>C</bold>. Neuronal assemblies without precise balance established discrete attractor states, as observed in memory networks that store information as discrete items. Networks establishing locally defined activity manifolds (<bold>B</bold>) may thus be considered as intermediates between networks generating continuous representations without memories (<bold>A</bold>) and classical memory networks with discrete attractor dynamics (<bold>C</bold>).</p></caption>
<graphic xlink:href="571272v2_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>E/I assemblies increased variability of activity patterns along preferred directions of state space and reduced their dimensionality in comparison to <italic>rand</italic> networks. Nonetheless, dimensionality remained high compared to <italic>Scaled</italic> networks with discrete attractor states. These observations indicate that geometric transformations in <italic>Tuned</italic> networks involved (1) a modest amplification of activity in one or a few directions aligned to the assembly, and (2) a modest reduction of activity in other directions. E/I assemblies therefore created a local curvature of coding space that “focused” activity in a subset of dimensions and, thus, stored information in the geometry of coding space.</p>
<p>As E/I assemblies were small relative to the total size of the E neuron population, stored information may be represented predominantly by small neuronal subsets. Consistent with this hypothesis, d<sub>M</sub> was increased and the classification of learned inputs by QDA was enhanced when activity was read out from subsets of assembly neurons as compared to random neuronal subsets. Moreover, signatures of pattern completion were found in the activity of assemblies but not in global pattern correlations. The retrieval of information from networks with small E/I assemblies therefore depends on the selection of informative neurons for readout. Unlike in networks with global attractor states, signatures of memory storage may thus be difficult to detect experimentally without specific knowledge of assembly memberships.</p>
</sec>
<sec id="s3c">
<title>Computational functions of networks with E/I assemblies</title>
<p>In theory, precisely balanced networks with E/I assemblies may support pattern classification despite high variability and the absence of discrete attractor states (<xref ref-type="bibr" rid="c17">Denève and Machens, 2016</xref>). Indeed, we found in <italic>Tuned E+I networks</italic> that input patterns were classified successfully by a generic classifier (QDA) based on selected neuronal subsets, particularly relative to learned inputs. Analyses based on the Mahalanobis distance d<sub>M</sub> indicate that classification of learned inputs was enhanced by two effects: (1) local manifolds representing learned odors became more distant from representations of other odors due to a modest increase in firing rates within E/I assemblies, and (2) the concomitant increase in variability was not isotropic, remaining sufficiently low in directions that separated novel from learned patterns. Hence, information contained in the geometry of coding space can be retrieved by readout mechanisms aligned to activity manifolds. Efficient readout mechanisms may thus integrate activity primarily from assembly neurons, as mimicked in our QDA-based pattern classification. This notion is consistent with the finding that the integrated activity of E/I assemblies can be highly informative despite variable firing of individual neurons (<xref ref-type="bibr" rid="c10">Boerlin et al., 2013</xref>; <xref ref-type="bibr" rid="c16">Denève et al., 2017</xref>; <xref ref-type="bibr" rid="c17">Denève and Machens, 2016</xref>). It will thus be interesting to explore how the readout of information from local manifolds could be further optimized.</p>
<p>Representations by local manifolds and discrete attractor states exhibit additional differences affecting neuronal computation: (1) <italic>Tuned</italic> networks do not mediate short-term memory functions based on persistent activity. Such networks may therefore support fast memoryless classification to interpret dynamical sensory inputs on a moment-to-moment basis. (2) The representation of learned inputs by small neuronal subsets, rather than global activity states, raises the possibility that multiple inputs can be classified simultaneously. (3) The stabilization of firing rate distributions by precise synaptic balance may prevent catastrophic network failures when memories are accumulated during continual learning. (4) The continuous nature of local manifolds indicates that information is not stored in the form of distinct items. Moreover, the coding space provides, in principle, a distance metric reflecting both relatedness in the feature space of sensory inputs and an individual’s experience. Internal representations generated by precisely balanced memory networks may therefore provide a basis for higher-order learning and cognitive computations.</p>
</sec>
<sec id="s3d">
<title>Balanced state networks with E/I assemblies as models for olfactory cortex</title>
<p>Piriform cortex and Dp have been proposed to function as attractor-based memory networks for odors. Consistent with this hypothesis, pattern completion and its modulation by learning has been observed in piriform cortex of rodents (<xref ref-type="bibr" rid="c5">Barnes et al., 2008</xref>; <xref ref-type="bibr" rid="c12">Chapuis and Wilson, 2011</xref>). However, odor-evoked firing patterns in piriform cortex and Dp are typically irregular, variable, transient and less reproducible than in the OB even after learning (<xref ref-type="bibr" rid="c35">Jacobson et al., 2018</xref>; <xref ref-type="bibr" rid="c51">Pashkovski et al., 2020</xref>; <xref ref-type="bibr" rid="c65">Schoonover et al., 2021</xref>; <xref ref-type="bibr" rid="c78">Yaksi et al., 2009</xref>), indicating that activity does not converge onto stable attractor states. Balanced networks with E/I assemblies, in contrast, are generally consistent with these experimental observations. Alternative models for pattern classification in the balanced state include networks endowed with adaptation, which respond to stimuli with an initial transient followed by a tonic non-balanced activity state (<xref ref-type="bibr" rid="c77">Wu and Zenke, 2021</xref>), or mechanisms related to “balanced amplification”, which typically generate pronounced activity transients (<xref ref-type="bibr" rid="c1">Ahmadian and Miller, 2021</xref>; <xref ref-type="bibr" rid="c49">Murphy and Miller, 2009</xref>). However, it has not been explored whether these models can be adapted to reproduce characteristic features of Dp or piriform cortex.</p>
<p>Our results generate predictions to test the hypothesis that E/I assemblies establish local manifolds in Dp: (1) odor-evoked population activity should be constrained onto manifolds, particularly in response to learned odors. (2) Learning should increase the magnitude and asymmetry of d<sub>M</sub> between odor representations. (3) Activity evoked by learned and related odors should exhibit lower dimensionality and more directional variability than activity evoked by novel odors. (4) Careful manipulations of inhibition may unmask assemblies by increasing amplification. These predictions may be addressed experimentally by large-scale measurements of odor-evoked activity after learning. The direct detection of E/I assemblies will ultimately require dense reconstructions of large neuronal networks at synaptic resolution. Given the small size of Dp, this challenge may be addressed in zebrafish by connectomics approaches based on volume electron microscopy (<xref ref-type="bibr" rid="c18">Denk et al., 2012</xref>; <xref ref-type="bibr" rid="c25">Friedrich and Wanner, 2021</xref>; <xref ref-type="bibr" rid="c38">Kornfeld and Denk, 2018</xref>).</p>
<p>The hypothesis that memory networks contain E/I assemblies and operate in a state of precise synaptic balance can be derived from the basic assumptions that synaptic plasticity establishes assemblies and that firing rate distributions remain stable as network structure is modified by experience (<xref ref-type="bibr" rid="c6">Barron et al., 2017</xref>; <xref ref-type="bibr" rid="c31">Hennequin et al., 2017</xref>). Hence, <italic>Tuned</italic> networks based on Dp may also reproduce features of other recurrently connected brain areas such as hippocampus and neocortex, which also operate in a balanced state (<xref ref-type="bibr" rid="c54">Renart et al., 2010</xref>; <xref ref-type="bibr" rid="c63">Sadeh and Clopath, 2020b</xref>; <xref ref-type="bibr" rid="c67">Shadlen and Newsome, 1994</xref>) Future experiments may therefore explore representations of learned information by local manifolds also in cortical brain areas.</p>
</sec>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>pDp spiking network model</title>
<p>pDp<sub>sim</sub> consisted of 4000 excitatory (E) and 1000 inhibitory (I) neurons which were modeled as adaptive leaky integrate-and-fire units with conductance-based synapses of strength <italic>w</italic>. A spike emitted by the presynaptic neuron y from population Y triggered an increase in the conductance <italic>g<sub>Yx</sub></italic> in the postsynaptic neuron x:
<disp-formula id="eqn1">
<graphic xlink:href="571272v2_eqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Neuron x received synaptic inputs from the olfactory bulb OB as well as from the different local neuronal populations P. Its membrane potential <italic>V<sub>x</sub></italic> evolved according to:
<disp-formula id="eqn2">
<graphic xlink:href="571272v2_eqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
When the membrane potential reached a threshold V<sub>th</sub>, the neuron emitted a spike and its membrane potential was reset to <italic>E<sub>rest</sub></italic> and clamped to this value during a refractory period <italic>τ</italic><sub>ref</sub>. Excitatory neurons were endowed with adaptation with the following dynamics (<xref ref-type="bibr" rid="c11">Brette and Gerstner, 2005</xref>):
<disp-formula id="eqn3">
<graphic xlink:href="571272v2_eqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
In inhibitory neurons, <italic>z</italic> was set to 0 for simplicity.</p>
<p>The neuronal parameters of the model are summarized in <xref rid="tbl1" ref-type="table">Table 1</xref>. The values of the membrane time constant, resting conductance, inhibitory and excitatory reversal potential are in the range of experimentally measured values (<xref ref-type="bibr" rid="c58">Rupprecht and Friedrich, 2018</xref> and Blumhagen et al., 2011). The remaining parameters were then fitted such as to fulfill two conditions (derived from unpublished experimental observations): (1) the neuron should not generate action potentials in response to a step current injection of duration 500 ms and amplitude 15 nA, and (2) the mean firing rate should be on the order of tens of Hz when the amplitude of the step current is 100 nA. Furthermore, the firing rates of inhibitory neurons should be higher than the firing rates of excitatory neurons, as observed experimentally (unpublished data).</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1</label>
<caption><title>Values of the neuronal parameters.</title>
<p>The superscripts indicate the reference where the experimental measurements can be found. <sup>1</sup> <xref ref-type="bibr" rid="c58">Rupprecht and Friedrich, 2018</xref> <sup>2</sup> <xref ref-type="bibr" rid="c9">Blumhagen et al., 2011</xref></p></caption>
<graphic xlink:href="571272v2_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>The time constants of inhibitory and excitatory synapses (<italic>τ<sub>syn,I</sub></italic> and <italic>τ<sub>syn,E</sub></italic>) were 10 ms and 30 ms, respectively. To verify that the behavior of pDp<sub>sim</sub> was robust, we simulated 20 networks with different connection probabilities p<sub>YX</sub> and synaptic strengths w<sub>YX</sub> (<xref rid="tbl2" ref-type="table">Table 2</xref>). The connections between neurons were drawn from a Bernoulli distribution with a predefined p<sub>YX</sub> ≤0.05 (<xref ref-type="bibr" rid="c80">Zou, 2014</xref>). As a consequence, each neuron received the same number of input connections. Care was also taken to ensure that the variation in the number of output connections was low across neurons.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2</label>
<caption><title>Values of the connectivity parameters of different networks {probability p<sub>YX</sub> and synaptic strength w<sub>YX</sub> in pS}</title></caption>
<graphic xlink:href="571272v2_tbl2.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>The connection strengths w<sub>YX</sub> were then fitted to reproduce experimental observations in pDp (five observables in total, see below and <xref rid="fig1" ref-type="fig">Figure 1</xref>). For this purpose, a lower and upper bound for w<sub>YX</sub> were set such that the amplitude of single EPSPs and IPSPs was in the biologically plausible range of 0.2 to 2 mV. w<sub>OE</sub> was then further constrained to maintain the odor-evoked, time-averaged g<sub>OE</sub> in the range of experimental values (<xref ref-type="bibr" rid="c58">Rupprecht and Friedrich, 2018</xref>). Once w<sub>OE</sub> was fixed, the lower bound of w<sub>EE</sub> was increased to obtain a network rate &gt;10 Hz in the absence of inhibition. A grid search was then used to refine the remaining w<sub>YX</sub>.</p>
</sec>
<sec id="s4b">
<title>Olfactory bulb input</title>
<p>Each pDp neuron received external input from the OB, which consisted of 1500 mitral cells spontaneously active at 6 Hz. Odors were simulated by increasing the firing rate of 150 randomly selected mitral cells. Firing rates of these “activated” mitral cells were drawn from a discrete uniform distribution ranging from 8 to 32 Hz and their onset latencies were drawn from a discrete uniform distribution ranging from 0 to 200 ms. An additional 75 mitral cells were inhibited. Firing rates and latencies of these neurons were drawn from discrete uniform distributions ranging from 0 to 5 Hz and from 0 to 200 ms, respectively. After odor onset, firing rates decreased with a time constant of 1, 2 or 4 s (equally distributed). Spikes were generated from a Poisson distribution. Because all odors had almost identical firing patterns, the total OB input did not vary much across odors. In <xref rid="fig1" ref-type="fig">Figures 1</xref>–<xref rid="fig3" ref-type="fig">3</xref>, the odor set consisted of 10 novel and/or 10 learned odors, all of which were uncorrelated (pattern correlations near zero). Odors were presented for 2 seconds and separated by 1 second of baseline activity.</p>
<p>Olfactory subspaces comprised 121 OB activity patterns. Each pattern was represented by a pixel in a 11 x 11 square. The pixel at each vertex corresponded to one pure odor with 150 excited and 75 inhibited mitral cells as described above, and the remaining pixels corresponded to mixtures. The fraction of activated and inhibited mitral from a given pure odor decreased with the distance from the corresponding vertex as shown in <xref rid="tbl3" ref-type="table">Table 3</xref>. The total number of activated and inhibited mitral cells at each location in the virtual square remained within the range of 150 ± 10% and 75 ± 10%, respectively. To generate activity patterns representing mixtures, activated mitral cells were sorted by onset latencies for each pure odor. At each location within the square and for each trial, mitral cells that remained activated in the mixture response were randomly selected from the pool of C mitral cells with the shortest latencies from each odor. C decreased with the distance from the vertices representing pure odors as shown in <xref rid="tbl4" ref-type="table">Table 4</xref>. The firing rate of each selected mitral cell varied ±1 Hz around its rate in response to the pure odor. The identity, but not the firing rate, of the activated mitral cells therefore changed gradually within the odor subspace. This procedure reflects the experimental observation that responses of zebrafish mitral cells to binary odor mixtures often resemble responses to one of the pure components (<xref ref-type="bibr" rid="c70">Tabor et al., 2004</xref>). We generated 8 different trajectories within the virtual square, each visiting all possible virtual odor locations for 1s. Each trajectory (trial) thus consisted of 121s of odor presentation, and trajectories were separated by 2 seconds of baseline activity. The dataset for analysis therefore comprised 968 activity patterns (8 trials x 121 odors).</p>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3</label>
<caption><title>Percentage of cells selected from the 150 activated mitral cells defining one pure odor (vertex at top left) for uncorrelated pure odors.</title></caption>
<graphic xlink:href="571272v2_tbl3.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tbl4" orientation="portrait" position="float">
<label>Table 4</label>
<caption><title>Percentage of activated cells available for selection for uncorrelated pure odors.</title>
<p>C is obtained by multiplying the values by 1.5.</p></caption>
<graphic xlink:href="571272v2_tbl4.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s4c">
<title>Assemblies</title>
<p>Unless noted otherwise, <italic>Scaled</italic> and <italic>Tuned</italic> networks contained 15 assembles (“memories”). An assembly representing a given odor contained the 100 E neurons that received the highest density of inputs from the corresponding active mitral cells. Hence, the size of assemblies was substantially smaller than the total population, consistent with the observation that only a minority of neurons in Dp or piriform cortex are activated during odor stimulation (<xref ref-type="bibr" rid="c47">Miura et al., 2012</xref>; <xref ref-type="bibr" rid="c68">Stettler and Axel, 2009</xref>; <xref ref-type="bibr" rid="c78">Yaksi et al., 2009</xref>) and upregulate <italic>cfos</italic> during olfactory learning (<xref ref-type="bibr" rid="c45">Meissner-Bernard et al., 2018</xref>). We then rewired assembly neurons: additional connections were created between assembly neurons, and a matching number of existing connections between non-assembly and assembly neurons were eliminated. The number of input connections per neuron therefore remained unchanged. A new connection between two assembly neurons doubled the synaptic strength w<sub>EE</sub> if it added to an existing connection. As a result of this rewiring, the connection probability within the assembly increased by a factor <italic>α</italic> relative to the baseline connection probability.</p>
<p>In <italic>Scaled</italic> networks, w<sub>IE</sub> was increased globally by a constant factor <italic>χ</italic>. In <italic>Tuned</italic> networks, connections were modified between the 100 E neurons of an assembly and the 25 I neurons that were most densely connected to these E neurons, using the same procedure as for E-to-E connections. In <italic>Tuned I</italic> networks, only I-to-E connections were rewired, while in <italic>Tuned E+I networks</italic>, both I-to-E and E-to-I connections were rewired (<xref rid="tbl5" ref-type="table">Table 5</xref>). Whenever possible, networks with less than 15% change in population firing rates compared to the corresponding <italic>rand</italic> network were selected. In <xref rid="fig6" ref-type="fig">Figure 6</xref>, two additional assemblies were created in <italic>Scaled</italic> or <italic>Tuned</italic> networks without adjusting any parameters.</p>
<table-wrap id="tbl5" orientation="portrait" position="float">
<label>Table 5</label>
<caption><title>Values of <italic>α</italic>, <italic>β</italic>, <italic>γ</italic>, <italic>χ</italic> used in the simulations. <italic>α</italic>: increase in E-E connection probability within assemblies.</title>
<p><italic>β</italic>: increase in I to E connection probability. <italic>γ</italic>: increase in E to I connection probability.</p></caption>
<graphic xlink:href="571272v2_tbl5.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s4d">
<title>Observables</title>
<p>All variables were measured in the E population and time-averaged over the first 1.5 seconds of odor presentations, unless otherwise stated.
<list list-type="order">
<list-item><p>The <italic>firing rate</italic> is the number of spikes in a time interval T divided by T.</p></list-item>
<list-item><p><italic>g<sub>OE</sub></italic> is the mean conductance change in E neurons triggered by spikes from the OB.</p></list-item>
<list-item><p><italic>g<sub>syn</sub></italic> is the total synaptic conductance change due to odor stimulation, calculated as the sum of <italic>g<sub>OE</sub>, g<sub>EE</sub></italic> and <italic>g<sub>IE.</sub> g<sub>EE</sub></italic> and <italic>g<sub>IE</sub></italic> are the conductance changes contributed by E synapses and I synapses, respectively.</p></list-item>
<list-item><p>The <italic>percentage of recurrent input</italic> quantifies the average contribution of the recurrent excitatory input to the total excitatory input in E neurons. It was defined for each excitatory neuron as the ratio of the time-averaged <italic>g<sub>EE</sub></italic> to the time-averaged total excitatory conductance (<italic>g<sub>EE</sub></italic>+<italic>g<sub>OE</sub></italic>) multiplied by 100. In (2,3,4), the time-averaged E and I synaptic conductances during the 500 ms before odor presentation were subtracted from the E and I conductances measured during odor presentation for each neuron.</p></list-item>
<list-item><p>In addition, we required the Pearson correlation between activity patterns to be close to zero in response to uncorrelated inputs. The Pearson correlation between pairs of activity vectors composed of the firing rate of E neurons was averaged over all possible odor pairs.</p></list-item>
</list>
</p>
</sec>
<sec id="s4e">
<title>Co-tuning</title>
<p><italic>Co-tuning</italic> was quantified in 2 different ways: (1) For each neuron, we calculated the Pearson correlation between the time-averaged E and I conductances in response to 10 learned odors. (2) As described in (<xref ref-type="bibr" rid="c58">Rupprecht and Friedrich, 2018</xref>), we projected observed pairs of E and I conductances onto a “balanced” and “counter-balanced” axis. The balanced axis was obtained by fitting a linear model without constant to the E and I conductances of 4000*10 neuron-learned odor pairs. The resulting model was a constant I/E ratio (~1.2) that defined a membrane potential close to spike threshold. The counter-balanced axis was orthogonal to the balanced axis. For each neuron, synaptic conductances were projected onto these axes and their dispersions quantified by the standard deviations.</p>
</sec>
<sec id="s4f">
<title>Characterization of population activity in state space</title>
<p><italic>Principal Component Analysis</italic> (PCA) was applied to the OB activity patterns from the square subspace or to the corresponding activity patterns across E neurons in pDp<sub>sim</sub> (8 x 121 = 968 patterns, each averaged over 1s).</p>
<p>The <italic>participation ratio</italic> PR provides an estimate of the maximal number of principal components (PC) required to recapitulate the observed neuronal activity. It is defined as <inline-formula><inline-graphic xlink:href="571272v2_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, where <italic>λ<sub>i</sub></italic> are the eigenvalues obtained from PCA (variance along each PC).</p>
<p>For angular analyses we projected activity patterns onto the first 400 PCs, which was the number of PCs required to explain at least 75% of the variance in all networks. We measured the <italic>angle θ</italic> between the edges connecting the trial-averaged pattern <bold>p</bold> evoked by a pure odor to two patterns <bold>s<sub>y</sub></bold> and <bold>s<sub>z.</sub> s<sub>y</sub></bold> and <bold>s<sub>z</sub></bold> were trial-averaged patterns evoked by 2 out of the 7 odors that were most similar to the pure odor (21 angles in total). <italic>θ</italic> was defined as <inline-formula><inline-graphic xlink:href="571272v2_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. This metric is sensitive to non-uniform expansion and other non-linear transformations.</p>
<p>The <italic>Mahalanobis distance</italic> d<sub>M</sub> is defined as <inline-formula><inline-graphic xlink:href="571272v2_inline3.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, where <italic>ν</italic> is a vector representing an activity pattern, and <italic>Q</italic> a reference class consisting of a distribution of activity patterns with mean <italic>μ</italic> and covariance matrix <italic>S</italic>.</p>
</sec>
<sec id="s4g">
<title>Classification</title>
<p>To assess the assignment of odor-evoked patterns to representations of pure odors in the odor subspace, we used <italic>Quadratic Linear Discriminant</italic> (QDA) analysis, a non-linear classifier that takes into account the separation and covariance patterns of different classes (<xref ref-type="bibr" rid="c28">Ghojogh and Crowley, 2019</xref>). The training set consisted of the population response to multiple trials of each of the 4 pure odors, averaged over the first and second half of the 1-s odor presentation. To increase the number of training data in each of the 4 odor classes, the training set also included population response to odors that were closely related to the pure odor (Pearson correlation between OB response patterns &gt;0.6). Analyses were performed using subsets of 80 neurons (similar results were obtained using 50 – 100 neurons). These neurons were randomly selected (50 iterations) either from the (pseudo-) assemblies representing the pure odors (400 E neurons; pseudo-assemblies in <italic>rand</italic> networks and for novel odors) or from the entire population of E neurons. We verified that the data came from a Gaussian mixture model. The trained classifier was then applied to activity patterns evoked by the remaining odors of the subspace (correlation with pure odors &lt; 0.6). Each pattern was then assigned to the class x that maximized the discriminant function <inline-formula><inline-graphic xlink:href="571272v2_inline4.gif" mimetype="image" mime-subtype="gif"/></inline-formula> where S<sub>L</sub> is the covariance matrix of each odor class k (subsampling of neurons ensured invertibility) and π<sub>L</sub> is the prior probability of class k. This discriminant function is closely related to d<sub>M</sub>.</p>
</sec>
<sec id="s4h">
<title>Simulations</title>
<p>Simulations were performed using Matlab and Python. Differential equations were solved using the forward Euler method and an integration time step of dt = 0.1 ms.</p>
</sec>
</sec>
<sec id="s5">
<title>Supplementary Figure Legends</title>
<fig id="figS2I" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 2I.</label>
<caption><title>Structured networks reproduce key features of Dp.</title>
<p><bold>A</bold>. Connection probability between classes of E and I neurons in a <italic>rand</italic>, a <italic>Tuned I</italic>, and a <italic>Tuned E+I</italic> network. <bold>B.</bold> EPSCs and IPSCs in a <italic>Tuned I</italic> network as observed in a hypothetical voltage clamp recording, averaged across neurons and odors. An equivalent plot for a <italic>rand</italic> network is shown in <xref rid="fig1" ref-type="fig">Figure 1E</xref>. <bold>C</bold>,<bold>D</bold>. Values of observables for <italic>rand</italic> networks (same as <xref rid="fig1" ref-type="fig">Figure 1G-H</xref>) and different structured networks (<italic>Scaled I</italic>, <italic>Tuned I</italic>, <italic>Tuned E+I</italic>). <bold>E</bold>. Network with increased connectivity between the E assembly neurons (<italic>α</italic>=5) and the 25 I neurons that are most densely connected to the mitral cells activated by a given odor. <bold>F.</bold> Mean firing rate of the network in <bold>E</bold> in response to learned odors as a function of connection probability. Selecting I neurons based on their afferent connectivity could not stabilize activity efficiently.</p></caption>
<graphic xlink:href="571272v2_figS2I.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS2II" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 2II.</label>
<caption><title>Structured networks: additional results.</title>
<p><bold>A</bold>. Raster plots showing responses of assembly (A) or non-assembly neurons to a learned odor. <bold>B</bold>. Coefficients of variation of the inter-spike interval (ISI) in assembly neurons. <bold>C</bold>. Correlation between activity patterns across E neurons evoked by the same novel odor in different trials as a function of time. Pink bar indicates odor presentation. Note that correlations in response to novel odors are similar across networks and different from responses to learned odors in <italic>Scaled</italic> and <italic>Tuned</italic> networks (<xref rid="fig2" ref-type="fig">Fig. 2E</xref>) <bold>D</bold>. Population firing rate in response to learned odors for networks with different probability of E-E connectivity within assemblies (<italic>α</italic>). <bold>E</bold>. Co-tuning (correlation between E and I currents in individual neurons) as a function of <italic>α</italic>.</p></caption>
<graphic xlink:href="571272v2_figS2II.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS3" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 3.</label>
<caption><title>Pattern completion: additional results.</title>
<p><bold>A</bold>. Artificial reactivation of E assemblies. During 6 Hz baseline activity of the olfactory bulb, a subset of the assembly neurons was artificially reactivated by current injection (500 ms, 28 nA). Mean firing rates were quantified in the injected assembly neurons (i), in the remaining, non-injected assembly or pseudo-assembly neurons (ii), and in the non-assembly neurons (iii) as a function of time. The orange bar indicates duration of current injection. <bold>B</bold>. Correlation between activity patterns across E neurons (output patterns) evoked by a series of input patterns representing a morph of one learned odor into another learned odor. Correlations between output patterns are plotted as a function of the correlation between the corresponding OB patterns.</p></caption>
<graphic xlink:href="571272v2_figS3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS4" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 4.</label>
<caption><title>Transformations and dimensionality of activity patterns: additional results.</title>
<p><bold>A</bold>. Projection of activity patterns representing the odor subspace (<xref rid="fig4" ref-type="fig">Fig. 4A</xref>) onto the first 2 PCs of the corresponding <italic>rand</italic> networks (representative examples of one network each). <bold>B</bold>. Scree plot for the PCA results shown in <xref rid="fig4" ref-type="fig">Figure 4D</xref>. <bold>C</bold>. Error in the reconstruction of odor-evoked activity patterns as a function of the number of PCs. Euclidean distances between all pairs of activity patterns were calculated in the full-dimensional state space (Df) and in reduced-dimensional embedding spaces (Dl). The reconstruction error was defined as 1 – (correlation between Df and Dl). <bold>D</bold>. Participation ratio of the neural activity sampled from different numbers of neurons (50 iterations). <bold>E</bold>. Loadings of neurons on the first two PCs of a <italic>rand</italic> and a <italic>Tuned E+I</italic> network (<xref rid="fig4" ref-type="fig">Figure 4D</xref>). Each line represents one neuron. Neurons that are part of the assemblies representing the two learned odors are color-coded in magenta. <bold>F</bold>. For each network and PC, the 100 E neurons with the highest absolute loadings were selected and grouped into 3 categories: neurons part of the two assemblies representing the learned odors, neurons part of the two “pseudo-assemblies” representing the two novel odors, and the remaining neurons (non-assembly).</p></caption>
<graphic xlink:href="571272v2_figS4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS5" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 5.</label>
<caption><title>Further analyses of pattern distances.</title>
<p>Differences in d<sub>M</sub> between <italic>rand</italic> and <italic>Tuned</italic> networks may involve differences in the distance between class centers and/or differences in intra-class variability. To dissect the contributions of these effects we compared three distance measures:
<list list-type="order">
<list-item><p>The Euclidean distance between class centers:
<disp-formula>
<graphic xlink:href="571272v2_ueqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula></p></list-item>
<list-item><p>The mean Euclidean distance between patterns of one class and the center of another class (<italic>d<sub>Ê</sub></italic>):
<disp-formula>
<graphic xlink:href="571272v2_ueqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula></p></list-item>
<list-item><p>The Mahalanobis distance d<sub>M</sub>:
<disp-formula>
<graphic xlink:href="571272v2_ueqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula></p></list-item>
</list></p>
<p>Here, <italic>μ</italic><sub>V</sub> and <italic>μ<sub>Q</sub></italic> are the centers (average patterns) of classes V and Q, respectively; v is a vector from V = [v<sub>1,</sub>v<sub>2,</sub>…,v<sub>n</sub>], and <italic>S</italic><sup>AB</sup> is the inverse of the covariance matrix of the neuronal population within reference class Q. Note that <italic>d<sub>Ê</sub></italic> corresponds to d<sub>M</sub> without normalization by variability (covariance).</p><p><bold>A</bold>. Analysis of d<sub>E</sub>. Left: d<sub>E</sub> in <italic>rand</italic> and <italic>Tuned E+I</italic> networks based on 80 E neurons drawn from (pseudo-) assemblies. Right: same based on 80 E neurons drawn from the entire population. Note that d<sub>E</sub> between learned and other odors was increased in <italic>Tuned E+I</italic> networks as compared to <italic>rand</italic> networks, particularly when neurons were drawn from assemblies. <bold>B</bold>. Equivalent plots for <italic>d<sub>Ê</sub></italic>. Note that distances were increased nearly symmetrically, similar to d<sub>E</sub>. <bold>C</bold>. Equivalent plots for d<sub>M</sub> (same plots as in <xref rid="fig5" ref-type="fig">Fig. 5B</xref>). Note that d<sub>M</sub> was increased asymmetrically. These observations show that the changes in d<sub>M</sub> relative to <italic>rand</italic> networks involved an increase in the distance between class centers (d<sub>E</sub>) and a non-isotropic change in intra-class variability (comparison between <italic>d<sub>Ê</sub></italic> and d<sub>M</sub>). These effects were prominent when E neurons were drawn from assemblies. An important contribution to the increase in d<sub>M</sub> in the direction from learned odors to reference classes representing novel odors was made by the increased distance between class centers. In the other direction, d<sub>M</sub> was smaller, implying that variability in the reference class was higher. Nonetheless, variability in the relevant direction did not fully counteract the increased distance between class centers in <italic>Tuned E+I</italic> networks. As a consequence, d<sub>M</sub> was still increased slightly relative to the corresponding <italic>rand</italic> networks. Most of these effects were still observed, albeit weakly, when E neurons were drawn from the whole population.</p></caption>
<graphic xlink:href="571272v2_figS5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>We thank the Friedrich lab for insightful discussions. This work was supported by the Novartis Research Foundation, by the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation program (grant agreement no. 742576), and by the Swiss National Science Foundation (grants no. 31003A_172925/1, PCEFP3_202981).</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Ahmadian</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Miller</surname> <given-names>KD</given-names></string-name>. <year>2021</year>. <article-title>What is the dynamical regime of cerebral cortex?</article-title> <source>Neuron</source> <volume>109</volume>:<fpage>3373</fpage>– <lpage>3391</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2021.07.031</pub-id></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Altan</surname> <given-names>E</given-names></string-name>, <string-name><surname>Solla</surname> <given-names>SA</given-names></string-name>, <string-name><surname>Miller</surname> <given-names>LE</given-names></string-name>, <string-name><surname>Perreault</surname> <given-names>EJ</given-names></string-name>. <year>2021</year>. <article-title>Estimating the dimensionality of the manifold underlying multi-electrode neural recordings</article-title>. <source>Plos Comput Biol</source> <volume>17</volume>:<fpage>e1008591</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pcbi.1008591</pub-id></mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Babadi</surname> <given-names>B</given-names></string-name>, <string-name><surname>Sompolinsky</surname> <given-names>H</given-names></string-name>. <year>2014</year>. <article-title>Sparseness and Expansion in Sensory Representations</article-title>. <source>Neuron</source> <volume>83</volume>:<fpage>1213</fpage>–<lpage>1226</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2014.07.035</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Baker</surname> <given-names>C</given-names></string-name>, <string-name><surname>Zhu</surname> <given-names>V</given-names></string-name>, <string-name><surname>Rosenbaum</surname> <given-names>R</given-names></string-name>. <year>2020</year>. <article-title>Nonlinear stimulus representations in neural circuits with approximate excitatory-inhibitory balance</article-title>. <source>Plos Comput Biol</source> <volume>16</volume>:<fpage>e1008192</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pcbi.1008192</pub-id></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Barnes</surname> <given-names>DC</given-names></string-name>, <string-name><surname>Hofacer</surname> <given-names>RD</given-names></string-name>, <string-name><surname>Zaman</surname> <given-names>AR</given-names></string-name>, <string-name><surname>Rennaker</surname> <given-names>RL</given-names></string-name>, <string-name><surname>Wilson</surname> <given-names>DA</given-names></string-name>. <year>2008</year>. <article-title>Olfactory perceptual stability and discrimination</article-title>. <source>Nat Neurosci</source> <volume>11</volume>:<fpage>1378</fpage>–<lpage>1380</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.2217</pub-id></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Barron</surname> <given-names>HC</given-names></string-name>, <string-name><surname>Vogels</surname> <given-names>TP</given-names></string-name>, <string-name><surname>Behrens</surname> <given-names>TE</given-names></string-name>, <string-name><surname>Ramaswami</surname> <given-names>M</given-names></string-name>. <year>2017</year>. <article-title>Inhibitory engrams in perception and memory</article-title>. <source>Proc National Acad Sci</source> <volume>114</volume>:<fpage>6666</fpage>–<lpage>6674</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1701812114</pub-id></mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Bhatia</surname> <given-names>A</given-names></string-name>, <string-name><surname>Moza</surname> <given-names>S</given-names></string-name>, <string-name><surname>Bhalla</surname> <given-names>US</given-names></string-name>. <year>2019</year>. <article-title>Precise excitation-inhibition balance controls gain and timing in the hippocampus</article-title>. <source>eLife</source> <fpage>1</fpage>–<lpage>29</lpage>. doi:<pub-id pub-id-type="doi">10.7554/elife.43415.001</pub-id></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="book"><string-name><surname>Blazing</surname> <given-names>RM</given-names></string-name>, <string-name><surname>Franks</surname> <given-names>KM</given-names></string-name>. <year>2020</year>. <source>ScienceDirect Odor coding in piriform cortex: mechanistic insights into distributed coding</source>. <publisher-name>Elsevier Ltd</publisher-name> <fpage>1</fpage>–<lpage>7</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.conb.2020.03.001</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Blumhagen</surname> <given-names>F</given-names></string-name>, <string-name><surname>Zhu</surname> <given-names>P</given-names></string-name>, <string-name><surname>Shum</surname> <given-names>J</given-names></string-name>, <string-name><surname>Schärer</surname> <given-names>Y-PZ</given-names></string-name>, <string-name><surname>Yaksi</surname> <given-names>E</given-names></string-name>, <string-name><surname>Deisseroth</surname> <given-names>K</given-names></string-name>, <string-name><surname>Friedrich</surname> <given-names>RW</given-names></string-name>. <year>2011</year>. <article-title>Neuronal filtering of multiplexed odour representations</article-title>. <source>Nature</source> <volume>479</volume>:<fpage>493</fpage>–<lpage>498</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nature10633</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Boerlin</surname> <given-names>M</given-names></string-name>, <string-name><surname>Machens</surname> <given-names>CK</given-names></string-name>, <string-name><surname>Denève</surname> <given-names>S</given-names></string-name>. <year>2013</year>. <article-title>Predictive Coding of Dynamical Variables in Balanced Spiking Networks</article-title>. <source>PLoS Comput Biol</source> <volume>9</volume>:<fpage>e1003258</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pcbi.1003258</pub-id></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Brette</surname> <given-names>R</given-names></string-name>, <string-name><surname>Gerstner</surname> <given-names>W</given-names></string-name>. <year>2005</year>. <article-title>Adaptive Exponential Integrate-and-Fire Model as an Effective Description of Neuronal Activity</article-title>. <source>J Neurophysiol</source> <fpage>1</fpage>–<lpage>6</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.00686.2005</pub-id></mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Chapuis</surname> <given-names>J</given-names></string-name>, <string-name><surname>Wilson</surname> <given-names>DA</given-names></string-name>. <year>2011</year>. <article-title>Bidirectional plasticity of cortical pattern recognition and behavioral sensory acuity</article-title>. <source>Nat Neurosci</source> <volume>15</volume>:<fpage>155</fpage>–<lpage>161</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.2966</pub-id></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="other"><string-name><surname>Chenkov</surname> <given-names>HSRKN</given-names></string-name>. <year>2017</year>. <article-title>Memory replay in balanced recurrent networks</article-title> <fpage>1</fpage>–<lpage>36</lpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pcbi.1005359</pub-id></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Chung</surname> <given-names>S</given-names></string-name>, <string-name><surname>Abbott</surname> <given-names>LF</given-names></string-name>. <year>2021</year>. <article-title>Neural population geometry: An approach for understanding biological and artificial neural networks</article-title>. <source>Curr Opin Neurobiol</source> <volume>70</volume>:<fpage>137</fpage>–<lpage>144</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.conb.2021.10.010</pub-id></mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Dahmen</surname> <given-names>D</given-names></string-name>, <string-name><surname>Recanatesi</surname> <given-names>S</given-names></string-name>, <string-name><surname>Jia</surname> <given-names>X</given-names></string-name>, <string-name><surname>Ocker</surname> <given-names>GK</given-names></string-name>, <string-name><surname>Campagnola</surname> <given-names>L</given-names></string-name>, <string-name><surname>Seeman</surname> <given-names>S</given-names></string-name>, <string-name><surname>Jarsky</surname> <given-names>T</given-names></string-name>, <string-name><surname>Helias</surname> <given-names>M</given-names></string-name>, <string-name><surname>Shea-Brown</surname> <given-names>E</given-names></string-name>. <year>2023</year>. <article-title>Strong and localized recurrence controls dimensionality of neural activity across brain areas</article-title>. <source>bioRxiv</source> <fpage>2020.11.02.365072</fpage>. doi:<pub-id pub-id-type="doi">10.1101/2020.11.02.365072</pub-id></mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Denève</surname> <given-names>S</given-names></string-name>, <string-name><surname>Alemi</surname> <given-names>A</given-names></string-name>, <string-name><surname>Bourdoukan</surname> <given-names>R</given-names></string-name>. <year>2017</year>. <article-title>The Brain as an Efficient and Robust Adaptive Learner</article-title>. <source>Neuron</source> <volume>94</volume>:<fpage>969</fpage>–<lpage>977</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2017.05.016</pub-id></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Denève</surname> <given-names>S</given-names></string-name>, <string-name><surname>Machens</surname> <given-names>CK</given-names></string-name>. <year>2016</year>. <article-title>Efficient codes and balanced networks</article-title>. <source>Nat Neurosci</source> <volume>19</volume>:<fpage>375</fpage>–<lpage>382</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.4243</pub-id></mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Denk</surname> <given-names>W</given-names></string-name>, <string-name><surname>Briggman</surname> <given-names>KL</given-names></string-name>, <string-name><surname>Helmstaedter</surname> <given-names>M</given-names></string-name>. <year>2012</year>. <article-title>Structural neurobiology: missing link to a mechanistic understanding of neural computation</article-title>. <source>Nat Rev Neurosci</source> <volume>13</volume>:<fpage>351</fpage>–<lpage>358</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nrn3169</pub-id></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="other"><string-name><surname>Festa</surname> <given-names>D</given-names></string-name>, <string-name><surname>Hennequin</surname> <given-names>G</given-names></string-name>, <string-name><surname>Lengyel</surname> <given-names>M</given-names></string-name>. <year>2018</year>. <article-title>Analog Memories in a Balanced Rate-Based Network of E-I Neurons</article-title> <fpage>1</fpage>–<lpage>9</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Frank</surname> <given-names>T</given-names></string-name>, <string-name><surname>Mönigl</surname> <given-names>NR</given-names></string-name>, <string-name><surname>Satoul</surname> <given-names>C</given-names></string-name>, <string-name><surname>Friedrich</surname> <given-names>SH</given-names></string-name>, <string-name><surname>Rainer</surname> <given-names>W</given-names></string-name>, <string-name><surname>Friedrich</surname> <given-names>RW</given-names></string-name>. <year>2019</year>. <article-title>Associative conditioning remaps odor representations and modifies inhibition in a higher olfactory brain area</article-title>. <source>Nat Neurosci</source> <fpage>1</fpage>–<lpage>12</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41593-019-0495-z</pub-id></mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Franks</surname> <given-names>KM</given-names></string-name>, <string-name><surname>Russo</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Sosulski</surname> <given-names>DL</given-names></string-name>, <string-name><surname>Mulligan</surname> <given-names>AA</given-names></string-name>, <string-name><surname>Siegelbaum</surname> <given-names>SA</given-names></string-name>, <string-name><surname>Axel</surname> <given-names>R</given-names></string-name>. <year>2011</year>. <article-title>Recurrent Circuitry Dynamically Shapes the Activation of Piriform Cortex</article-title>. <source>Neuron</source> <volume>72</volume>:<fpage>49</fpage>–<lpage>56</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2011.08.020</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Freeman</surname> <given-names>WJ</given-names></string-name>, <string-name><surname>Skarda</surname> <given-names>CA</given-names></string-name>. <year>1985</year>. <article-title>Spatial EEG patterns, non-linear dynamics and perception: the neo-sherringtonian view</article-title>. <source>Brain Res Rev</source> <volume>10</volume>:<fpage>147</fpage>–<lpage>175</lpage>. doi:<pub-id pub-id-type="doi">10.1016/0165-0173(85)90022-0</pub-id></mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Friedrich</surname> <given-names>RW</given-names></string-name>, <string-name><surname>Laurent</surname> <given-names>G</given-names></string-name>. <year>2004</year>. <article-title>Dynamics of Olfactory Bulb Input and Output Activity During Odor Stimulation in Zebrafish</article-title>. <source>Journal of Neurophysiology</source> <volume>91</volume>:<fpage>2658</fpage>–<lpage>2669</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.01143.2003</pub-id></mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Friedrich</surname> <given-names>RW</given-names></string-name>, <string-name><surname>Laurent</surname> <given-names>G</given-names></string-name>. <year>2001</year>. <article-title>Dynamic Optimization of Odor Representations by Slow Temporal Patterning of Mitral Cell Activity</article-title>. <source>Science</source> <volume>291</volume>:<fpage>1</fpage>–<lpage>7</lpage>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Friedrich</surname> <given-names>RW</given-names></string-name>, <string-name><surname>Wanner</surname> <given-names>A</given-names></string-name>. <year>2021</year>. <article-title>Dense Circuit Reconstruction to Understand Neuronal Computation: Focus on Zebrafish</article-title>. <source>Annual Review of Neuroscience</source> <volume>44</volume>:<fpage>1</fpage>–<lpage>19</lpage>. doi:<pub-id pub-id-type="doi">10.1146/annurev-neuro-110220-013050</pub-id></mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>Froemke</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Merzenich</surname> <given-names>MM</given-names></string-name>, <string-name><surname>Schreiner</surname> <given-names>CE</given-names></string-name>. <year>2007</year>. <article-title>A synaptic memory trace for cortical receptive field plasticity</article-title>. <source>Nature</source> <volume>450</volume>:<fpage>425</fpage>–<lpage>429</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nature06289</pub-id></mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>Gallego</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Perich</surname> <given-names>MG</given-names></string-name>, <string-name><surname>Miller</surname> <given-names>LE</given-names></string-name>, <string-name><surname>Solla</surname> <given-names>SA</given-names></string-name>. <year>2017</year>. <article-title>Neural Manifolds for the Control of Movement</article-title>. <source>Neuron</source> <volume>94</volume>:<fpage>978</fpage>–<lpage>984</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2017.05.025</pub-id></mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="other"><string-name><surname>Ghojogh</surname> <given-names>B</given-names></string-name>, <string-name><surname>Crowley</surname> <given-names>M</given-names></string-name>. <year>2019</year>. <article-title>Linear and Quadratic Discriminant Analysis: Tutorial</article-title>. <italic>arXiv</italic>. doi:<pub-id pub-id-type="doi">10.48550/arxiv.1906.02590</pub-id></mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><string-name><surname>Haberly</surname> <given-names>LB</given-names></string-name>. <year>2001</year>. <article-title>Parallel-distributed Processing in Olfactory Cortex: New Insights from Morphological and Physiological Analysis of Neuronal Circuitry</article-title>. <source>Chem Senses</source> <volume>26</volume>:<fpage>551</fpage>–<lpage>576</lpage>. doi:<pub-id pub-id-type="doi">10.1093/chemse/26.5.551</pub-id></mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="book"><string-name><surname>Hebb</surname> <given-names>DO</given-names></string-name>. <year>1949</year>. <source>The organization of behavior; a neuropsychological theory</source>. <publisher-name>Wiley</publisher-name>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>Hennequin</surname> <given-names>G</given-names></string-name>, <string-name><surname>Agnes</surname> <given-names>EJ</given-names></string-name>, <string-name><surname>Vogels</surname> <given-names>TP</given-names></string-name>. <year>2017</year>. <article-title>Inhibitory Plasticity: Balance, Control, and Codependence</article-title>. <source>Annu Rev Neurosci</source> <volume>40</volume>:<fpage>557</fpage>–<lpage>579</lpage>. doi:<pub-id pub-id-type="doi">10.1146/annurev-neuro-072116-031005</pub-id></mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><string-name><surname>Hennequin</surname> <given-names>G</given-names></string-name>, <string-name><surname>Vogels</surname> <given-names>TP</given-names></string-name>, <string-name><surname>Gerstner</surname> <given-names>W</given-names></string-name>. <year>2014</year>. <article-title>Optimal Control of Transient Dynamics in Balanced Networks Supports Generation of Complex Movements</article-title>. <source>Neuron</source> <volume>82</volume>:<fpage>1394</fpage>–<lpage>1406</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2014.04.045</pub-id></mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><string-name><surname>Hopfield</surname> <given-names>JJ</given-names></string-name>. <year>1982</year>. <article-title>Neural networks and physical systems with emergent collective computational abilities</article-title>. <source>Proc Natl Acad Sci</source> <fpage>2554</fpage>–<lpage>2558</lpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Iurilli</surname> <given-names>G</given-names></string-name>, <string-name><surname>Datta</surname> <given-names>SR</given-names></string-name>. <year>2017</year>. <article-title>Population Coding in an Innately Relevant Olfactory Area</article-title>. <source>Neuron</source> <volume>93</volume>:<fpage>1180</fpage>–<lpage>1197.e7</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2017.02.010</pub-id></mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>Jacobson</surname> <given-names>GA</given-names></string-name>, <string-name><surname>Rupprecht</surname> <given-names>P</given-names></string-name>, <string-name><surname>Friedrich</surname> <given-names>RW</given-names></string-name>. <year>2018</year>. <article-title>Experience-Dependent Plasticity of Odor Representations in the Telencephalon of Zebrafish</article-title>. <source>Curr Biol</source> <volume>28</volume>:<fpage>1</fpage>–<lpage>14.e3</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cub.2017.11.007</pub-id></mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><string-name><surname>Khona</surname> <given-names>M</given-names></string-name>, <string-name><surname>Fiete</surname> <given-names>IR</given-names></string-name>. <year>2022</year>. <article-title>Attractor and integrator networks in the brain</article-title>. <source>Nat Rev Neurosci</source> <volume>23</volume>:<fpage>744</fpage>– <lpage>766</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41583-022-00642-0</pub-id></mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="other"><string-name><surname>Kohonen</surname> <given-names>T</given-names></string-name>. <year>1984</year>. <article-title>Self-Organzation and Associative Memory</article-title>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><string-name><surname>Kornfeld</surname> <given-names>J</given-names></string-name>, <string-name><surname>Denk</surname> <given-names>W</given-names></string-name>. <year>2018</year>. <article-title>Progress and remaining challenges in high-throughput volume electron microscopy</article-title>. <source>Curr Opin Neurobiol</source> <volume>50</volume>:<fpage>261</fpage>–<lpage>267</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.conb.2018.04.030</pub-id></mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><string-name><surname>Lagzi</surname> <given-names>F</given-names></string-name>, <string-name><surname>Fairhall</surname> <given-names>A</given-names></string-name>. <year>2022</year>. <article-title>Tuned inhibitory firing rate and connection weights as emergent network properties</article-title>. <source>bioRxiv</source> <fpage>2022.04.12.488114</fpage>. doi:<pub-id pub-id-type="doi">10.1101/2022.04.12.488114</pub-id></mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><string-name><surname>Langdon</surname> <given-names>C</given-names></string-name>, <string-name><surname>Genkin</surname> <given-names>M</given-names></string-name>, <string-name><surname>Engel</surname> <given-names>TA</given-names></string-name>. <year>2023</year>. <article-title>A unifying perspective on neural manifolds and circuits for cognition</article-title>. <source>Nat Rev Neurosci</source> <volume>24</volume>:<fpage>363</fpage>–<lpage>377</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41583-023-00693-x</pub-id></mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><string-name><surname>Litwin-Kumar</surname> <given-names>A</given-names></string-name>, <string-name><surname>Doiron</surname> <given-names>B</given-names></string-name>. <year>2014</year>. <article-title>Formation and maintenance of neuronal assemblies through synaptic plasticity</article-title>. <source>Nature Communications</source> <volume>5</volume>:<fpage>1</fpage>–<lpage>12</lpage>. doi:<pub-id pub-id-type="doi">10.1038/ncomms6319</pub-id></mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><string-name><surname>Litwin-Kumar</surname> <given-names>A</given-names></string-name>, <string-name><surname>Doiron</surname> <given-names>B</given-names></string-name>. <year>2012</year>. <article-title>Slow dynamics and high variability in balanced cortical networks with clustered connections</article-title>. <source>Nat Neurosci</source> <volume>15</volume>:<fpage>1498</fpage>–<lpage>1505</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.3220</pub-id></mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><string-name><surname>Mackwood</surname> <given-names>O</given-names></string-name>, <string-name><surname>Naumann</surname> <given-names>LB</given-names></string-name>, <string-name><surname>Sprekeler</surname> <given-names>H</given-names></string-name>. <year>2021</year>. <article-title>Learning excitatory-inhibitory neuronal assemblies in recurrent networks</article-title>. <source>Elife</source> <volume>10</volume>:<fpage>e59715</fpage>. doi:<pub-id pub-id-type="doi">10.7554/elife.59715</pub-id></mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><string-name><surname>Marr</surname> <given-names>D</given-names></string-name>. <year>1969</year>. <article-title>A theory of cerebellar cortex</article-title>. <source>J Physiol</source> <volume>202</volume>:<fpage>437</fpage>–<lpage>470</lpage>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><string-name><surname>Meissner-Bernard</surname> <given-names>C</given-names></string-name>, <string-name><surname>Dembitskaya</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Venance</surname> <given-names>L</given-names></string-name>, <string-name><surname>Fleischmann</surname> <given-names>A</given-names></string-name>. <year>2018</year>. <article-title>Encoding of Odor Fear Memories in the Mouse Olfactory Cortex</article-title>. <source>Current Biology</source> <volume>29</volume>:<fpage>1</fpage>–<lpage>19</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cub.2018.12.003</pub-id></mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><string-name><surname>Miehl</surname> <given-names>C</given-names></string-name>, <string-name><surname>Onasch</surname> <given-names>S</given-names></string-name>, <string-name><surname>Festa</surname> <given-names>D</given-names></string-name>, <string-name><surname>Gjorgjieva</surname> <given-names>J</given-names></string-name>. <year>2022</year>. <article-title>Formation and computational implications of assemblies in neural circuits</article-title>. <source>J Physiology</source>. doi:<pub-id pub-id-type="doi">10.1113/jp282750</pub-id></mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><string-name><surname>Miura</surname> <given-names>K</given-names></string-name>, <string-name><surname>Mainen</surname> <given-names>ZF</given-names></string-name>, <string-name><surname>Uchida</surname> <given-names>N</given-names></string-name>. <year>2012</year>. <article-title>Odor Representations in Olfactory Cortex: Distributed Rate Coding and Decorrelated Population Activity</article-title>. <source>Neuron</source> <volume>74</volume>:<fpage>1087</fpage>–<lpage>1098</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2012.04.021</pub-id></mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><string-name><surname>Mueller</surname> <given-names>T</given-names></string-name>, <string-name><surname>Dong</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Berberoglu</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Guo</surname> <given-names>S</given-names></string-name>. <year>2011</year>. <article-title>The dorsal pallium in zebrafish, Danio rerio (Cyprinidae</article-title>, <source>Teleostei). Brain Res</source> <volume>1381</volume>:<fpage>95</fpage>–<lpage>105</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.brainres.2010.12.089</pub-id></mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><string-name><surname>Murphy</surname> <given-names>BK</given-names></string-name>, <string-name><surname>Miller</surname> <given-names>KD</given-names></string-name>. <year>2009</year>. <article-title>Balanced Amplification: A New Mechanism of Selective Amplification of Neural Activity Patterns</article-title>. <source>Neuron</source> <volume>61</volume>:<fpage>635</fpage>–<lpage>648</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2009.02.005</pub-id></mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><string-name><surname>Okun</surname> <given-names>M</given-names></string-name>, <string-name><surname>Lampl</surname> <given-names>I</given-names></string-name>. <year>2008</year>. <article-title>Instantaneous correlation of excitation and inhibition during ongoing and sensory-evoked activities</article-title>. <source>Nat Neurosci</source> <volume>11</volume>:<fpage>535</fpage>–<lpage>537</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.2105</pub-id></mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><string-name><surname>Pashkovski</surname> <given-names>SL</given-names></string-name>, <string-name><surname>Iurilli</surname> <given-names>G</given-names></string-name>, <string-name><surname>Brann</surname> <given-names>D</given-names></string-name>, <string-name><surname>Chicharro</surname> <given-names>D</given-names></string-name>, <string-name><surname>Drummey</surname> <given-names>K</given-names></string-name>, <string-name><surname>Franks</surname> <given-names>K</given-names></string-name>, <string-name><surname>Panzeri</surname> <given-names>S</given-names></string-name>, <string-name><surname>Datta</surname> <given-names>SR</given-names></string-name>. <year>2020</year>. <article-title>Structure and flexibility in cortical representations of odour space</article-title>. <source>Nature</source> <fpage>1</fpage>–<lpage>28</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41586-020-2451-1</pub-id></mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="other"><string-name><surname>Pehlevan</surname> <given-names>C</given-names></string-name>, <string-name><surname>Sompolinsky</surname> <given-names>H</given-names></string-name>. <year>2014</year>. <article-title>Selectivity and Sparseness in Randomly Connected Balanced Networks</article-title> <fpage>1</fpage>–<lpage>15</lpage>.</mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><string-name><surname>Recanatesi</surname> <given-names>S</given-names></string-name>, <string-name><surname>Ocker</surname> <given-names>GK</given-names></string-name>, <string-name><surname>Buice</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Shea-Brown</surname> <given-names>E</given-names></string-name>. <year>2019</year>. <article-title>Dimensionality in recurrent spiking networks: Global trends in activity and local origins in connectivity</article-title>. <source>PLoS Comput Biol</source> <volume>15</volume>:<fpage>e1006446</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pcbi.1006446</pub-id></mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><string-name><surname>Renart</surname> <given-names>A</given-names></string-name>, <string-name><surname>Rocha</surname> <given-names>J de la</given-names></string-name>, <string-name><surname>Bartho</surname> <given-names>P</given-names></string-name>, <string-name><surname>Hollender</surname> <given-names>L</given-names></string-name>, <string-name><surname>Parga</surname> <given-names>N</given-names></string-name>, <string-name><surname>Reyes</surname> <given-names>A</given-names></string-name>, <string-name><surname>Harris</surname> <given-names>KD</given-names></string-name>. <year>2010</year>. <article-title>The Asynchronous State in Cortical Circuits</article-title>. <source>Science</source> <volume>327</volume>:<fpage>587</fpage>–<lpage>590</lpage>. doi:<pub-id pub-id-type="doi">10.1126/science.1179850</pub-id></mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><string-name><surname>Rost</surname> <given-names>T</given-names></string-name>, <string-name><surname>Deger</surname> <given-names>M</given-names></string-name>, <string-name><surname>Nawrot</surname> <given-names>MP</given-names></string-name>. <year>2018</year>. <article-title>Winnerless competition in clustered balanced networks: inhibitory assemblies do the trick</article-title>. <source>Biol Cybern</source> <volume>112</volume>:<fpage>81</fpage>–<lpage>98</lpage>. doi:<pub-id pub-id-type="doi">10.1007/s00422-017-0737-7</pub-id></mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><string-name><surname>Roudi</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Latham</surname> <given-names>PE</given-names></string-name>. <year>2007</year>. <article-title>A Balanced Memory Network</article-title>. <source>PLoS Comput Biol</source> <volume>3</volume>:<fpage>e141</fpage>–<lpage>22</lpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pcbi.0030141</pub-id></mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><string-name><surname>Rupprecht</surname> <given-names>P</given-names></string-name>, <string-name><surname>Carta</surname> <given-names>S</given-names></string-name>, <string-name><surname>Hoffmann</surname> <given-names>A</given-names></string-name>, <string-name><surname>Echizen</surname> <given-names>M</given-names></string-name>, <string-name><surname>Blot</surname> <given-names>A</given-names></string-name>, <string-name><surname>Kwan</surname> <given-names>AC</given-names></string-name>, <string-name><surname>Dan</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Hofer</surname> <given-names>SB</given-names></string-name>, <string-name><surname>Kitamura</surname> <given-names>K</given-names></string-name>, <string-name><surname>Helmchen</surname> <given-names>F</given-names></string-name>, <string-name><surname>Friedrich</surname> <given-names>RW</given-names></string-name>. <year>2021</year>. <article-title>A database and deep learning toolbox for noise-optimized, generalized spike inference from calcium imaging</article-title>. <source>Nat Neurosci</source> <volume>24</volume>:<fpage>1324</fpage>–<lpage>1337</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41593-021-00895-5</pub-id></mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><string-name><surname>Rupprecht</surname> <given-names>P</given-names></string-name>, <string-name><surname>Friedrich</surname> <given-names>RW</given-names></string-name>. <year>2018</year>. <article-title>Precise Synaptic Balance in the Zebrafish Homolog of Olfactory Cortex</article-title>. <source>Neuron</source> <volume>100</volume>:<fpage>1</fpage>–<lpage>29</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2018.09.013</pub-id></mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><string-name><surname>Ryan</surname> <given-names>TJ</given-names></string-name>, <string-name><surname>Roy</surname> <given-names>DS</given-names></string-name>, <string-name><surname>Pignatelli</surname> <given-names>M</given-names></string-name>, <string-name><surname>Arons</surname> <given-names>A</given-names></string-name>, <string-name><surname>Tonegawa</surname> <given-names>S</given-names></string-name>. <year>2015</year>. <article-title>Engram Cells Retain Memory Under Retrograde Amnesia</article-title>. <source>Science</source> <fpage>1007</fpage>–<lpage>1013</lpage>.</mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><string-name><surname>Sacco</surname> <given-names>T</given-names></string-name>, <string-name><surname>Sacchetti</surname> <given-names>B</given-names></string-name>. <year>2010</year>. <article-title>Role of Secondary Sensory Cortices in Emotional Memory Storage and Retrieval in Rats</article-title>. <source>Science</source> <volume>329</volume>:<fpage>649</fpage>–<lpage>656</lpage>. doi:<pub-id pub-id-type="doi">10.1126/science.1183165</pub-id></mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><string-name><surname>Sadeh</surname> <given-names>S</given-names></string-name>, <string-name><surname>Clopath</surname> <given-names>C</given-names></string-name>. <year>2021</year>. <article-title>Excitatory-inhibitory balance modulates the formation and dynamics of neuronal assemblies in cortical networks</article-title>. <source>Sci Adv</source> <volume>7</volume>:<fpage>eabg8411</fpage>. doi:<pub-id pub-id-type="doi">10.1126/sciadv.abg8411</pub-id></mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><string-name><surname>Sadeh</surname> <given-names>S</given-names></string-name>, <string-name><surname>Clopath</surname> <given-names>C</given-names></string-name>. <year>2020a</year>. <article-title>Patterned perturbation of inhibition can reveal the dynamical structure of neural processing</article-title>. <source>eLife</source> <volume>9</volume>:<fpage>226</fpage>–<lpage>29</lpage>. doi:<pub-id pub-id-type="doi">10.7554/elife.52757</pub-id></mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><string-name><surname>Sadeh</surname> <given-names>S</given-names></string-name>, <string-name><surname>Clopath</surname> <given-names>C</given-names></string-name>. <year>2020b</year>. <article-title>Inhibitory stabilization and cortical computation</article-title>. <source>Nat Rev Neurosci</source> <fpage>1</fpage>–<lpage>17</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41583-020-00390-z</pub-id></mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><string-name><surname>Schaffer</surname> <given-names>ES</given-names></string-name>, <string-name><surname>Stettler</surname> <given-names>DD</given-names></string-name>, <string-name><surname>Kato</surname> <given-names>D</given-names></string-name>, <string-name><surname>Choi</surname> <given-names>GB</given-names></string-name>, <string-name><surname>Axel</surname> <given-names>R</given-names></string-name>, <string-name><surname>Abbott</surname> <given-names>LF</given-names></string-name>. <year>2018</year>. <article-title>Odor Perception on the Two Sides of the Brain: Consistency Despite Randomness</article-title>. <source>Neuron</source> <volume>98</volume>:<fpage>736</fpage>–<lpage>742.e3</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2018.04.004</pub-id></mixed-citation></ref>
<ref id="c65"><mixed-citation publication-type="journal"><string-name><surname>Schoonover</surname> <given-names>CE</given-names></string-name>, <string-name><surname>Ohashi</surname> <given-names>SN</given-names></string-name>, <string-name><surname>Axel</surname> <given-names>R</given-names></string-name>, <string-name><surname>Fink</surname> <given-names>AJP</given-names></string-name>. <year>2021</year>. <article-title>Representational drift in primary olfactory cortex</article-title>. <source>Nature</source> <fpage>1</fpage>–<lpage>34</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41586-021-03628-7</pub-id></mixed-citation></ref>
<ref id="c66"><mixed-citation publication-type="journal"><string-name><surname>Schulz</surname> <given-names>A</given-names></string-name>, <string-name><surname>Miehl C</surname>, <given-names>II MJB</given-names></string-name>, <string-name><surname>Gjorgjieva</surname> <given-names>J</given-names></string-name>. <year>2021</year>. <article-title>The generation of cortical novelty responses through inhibitory plasticity</article-title>. <source>eLife</source> <volume>10</volume>:<fpage>e65309</fpage>:1–28. doi:<pub-id pub-id-type="doi">10.1101/2020.11.30.403840</pub-id></mixed-citation></ref>
<ref id="c67"><mixed-citation publication-type="journal"><string-name><surname>Shadlen</surname> <given-names>MN</given-names></string-name>, <string-name><surname>Newsome</surname> <given-names>WT</given-names></string-name>. <year>1994</year>. <article-title>Noise, neural codes and cortical organization</article-title>. <source>Curr Opin Neurobiol</source> <volume>4</volume>:<fpage>569</fpage>–<lpage>579</lpage>. doi:<pub-id pub-id-type="doi">10.1016/0959-4388(94)90059-0</pub-id></mixed-citation></ref>
<ref id="c68"><mixed-citation publication-type="journal"><string-name><surname>Stettler</surname> <given-names>DD</given-names></string-name>, <string-name><surname>Axel</surname> <given-names>R</given-names></string-name>. <year>2009</year>. <article-title>Representations of Odor in the Piriform Cortex</article-title>. <source>Neuron</source> <volume>63</volume>:<fpage>854</fpage>–<lpage>864</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2009.09.005</pub-id></mixed-citation></ref>
<ref id="c69"><mixed-citation publication-type="journal"><string-name><surname>Tabor</surname> <given-names>R</given-names></string-name>, <string-name><surname>Friedrich</surname> <given-names>RW</given-names></string-name>. <year>2008</year>. <article-title>Pharmacological Analysis of Ionotropic Glutamate Receptor Function in Neuronal Circuits of the Zebrafish Olfactory Bulb</article-title>. <source>PLoS ONE</source> <volume>3</volume>:<fpage>e1416</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0001416</pub-id></mixed-citation></ref>
<ref id="c70"><mixed-citation publication-type="journal"><string-name><surname>Tabor</surname> <given-names>R</given-names></string-name>, <string-name><surname>Yaksi</surname> <given-names>E</given-names></string-name>, <string-name><surname>Weislogel</surname> <given-names>J-M</given-names></string-name>, <string-name><surname>Friedrich</surname> <given-names>RW</given-names></string-name>. <year>2004</year>. <article-title>Processing of Odor Mixtures in the Zebrafish Olfactory Bulb</article-title>. <source>The Journal of Neuroscience</source> <volume>24</volume>(<issue>29</issue>):<fpage>6611</fpage>– <lpage>6620</lpage>. doi:<pub-id pub-id-type="doi">10.1523/jneurosci.1834-04.2004</pub-id></mixed-citation></ref>
<ref id="c71"><mixed-citation publication-type="journal"><string-name><surname>Van Vreeswijk</surname> <given-names>C</given-names></string-name>, <string-name><surname>Sompolinsky</surname> <given-names>H</given-names></string-name>. <year>1996</year>. <article-title>Chaos in Neuronal Networks with Balanced Excitatory and Inhibitory Activity</article-title>. <source>Science</source> <volume>274</volume>:<fpage>1724</fpage>–<lpage>1726</lpage>. doi:<pub-id pub-id-type="doi">10.1126/science.274.5293.1724</pub-id></mixed-citation></ref>
<ref id="c72"><mixed-citation publication-type="journal"><string-name><surname>Vogels</surname> <given-names>TP</given-names></string-name>, <string-name><surname>Sprekeler</surname> <given-names>H</given-names></string-name>, <string-name><surname>Zenke</surname> <given-names>F</given-names></string-name>, <string-name><surname>Clopath</surname> <given-names>C</given-names></string-name>, <string-name><surname>Gerstner</surname> <given-names>W</given-names></string-name>. <year>2011</year>. <article-title>Inhibitory Plasticity Balances Excitation and Inhibition in Sensory Pathways and Memory Networks</article-title>. <source>Science</source> <volume>334</volume>:<fpage>1</fpage>–<lpage>7</lpage>. doi:<pub-id pub-id-type="doi">10.1126/science.1212991</pub-id></mixed-citation></ref>
<ref id="c73"><mixed-citation publication-type="journal"><string-name><surname>Wanner</surname> <given-names>AA</given-names></string-name>, <string-name><surname>Friedrich</surname> <given-names>RW</given-names></string-name>. <year>2020</year>. <article-title>Whitening of odor representations by the wiring diagram of the olfactory bulb</article-title>. <source>Nat Neurosci</source> <fpage>1</fpage>–<lpage>24</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41593-019-0576-z</pub-id></mixed-citation></ref>
<ref id="c74"><mixed-citation publication-type="journal"><string-name><surname>Wehr</surname> <given-names>M</given-names></string-name>, <string-name><surname>Zador</surname> <given-names>AM</given-names></string-name>. <year>2003</year>. <article-title>Balanced inhibition underlies tuning and sharpens spike timing in auditory cortex</article-title>. <source>Nature</source> <volume>426</volume>:<fpage>1</fpage>–<lpage>5</lpage>.</mixed-citation></ref>
<ref id="c75"><mixed-citation publication-type="journal"><string-name><surname>Wiechert</surname> <given-names>MT</given-names></string-name>, <string-name><surname>Judkewitz</surname> <given-names>B</given-names></string-name>, <string-name><surname>Riecke</surname> <given-names>H</given-names></string-name>, <string-name><surname>Friedrich</surname> <given-names>RW</given-names></string-name>. <year>2010</year>. <article-title>Mechanisms of pattern decorrelation by recurrent neuronal circuits</article-title>. <source>Nat Neurosci</source> <volume>13</volume>:<fpage>1003</fpage>–<lpage>1010</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.2591</pub-id></mixed-citation></ref>
<ref id="c76"><mixed-citation publication-type="journal"><string-name><surname>Wilson</surname> <given-names>DA</given-names></string-name>, <string-name><surname>Sullivan</surname> <given-names>RM</given-names></string-name>. <year>2011</year>. <article-title>Cortical Processing of Odor Objects</article-title>. <source>Neuron</source> <volume>72</volume>:<fpage>506</fpage>–<lpage>519</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2011.10.027</pub-id></mixed-citation></ref>
<ref id="c77"><mixed-citation publication-type="journal"><string-name><surname>Wu</surname> <given-names>YK</given-names></string-name>, <string-name><surname>Zenke</surname> <given-names>F</given-names></string-name>. <year>2021</year>. <article-title>Nonlinear transient amplification in recurrent neural networks with short-term plasticity</article-title>. <source>eLife</source> <fpage>2021.06.09.447718</fpage>. doi:<pub-id pub-id-type="doi">10.1101/2021.06.09.447718</pub-id></mixed-citation></ref>
<ref id="c78"><mixed-citation publication-type="journal"><string-name><surname>Yaksi</surname> <given-names>E</given-names></string-name>, <string-name><surname>Paul</surname> <given-names>F von S</given-names></string-name>, <string-name><surname>Niessing</surname> <given-names>J</given-names></string-name>, <string-name><surname>Bundschuh</surname> <given-names>ST</given-names></string-name>, <string-name><surname>Friedrich</surname> <given-names>RW</given-names></string-name>. <year>2009</year>. <article-title>Transformation of odor representations in target areas of the olfactory bulb</article-title>. <source>Nat Neurosci</source> <volume>12</volume>:<fpage>474</fpage>–<lpage>482</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.2288</pub-id></mixed-citation></ref>
<ref id="c79"><mixed-citation publication-type="journal"><string-name><surname>Zenke</surname> <given-names>F</given-names></string-name>, <string-name><surname>Agnes</surname> <given-names>EJ</given-names></string-name>, <string-name><surname>Gerstner</surname> <given-names>W</given-names></string-name>. <year>2015</year>. <article-title>Diverse synaptic plasticity mechanisms orchestrated to form and retrieve memories in spiking neural networks</article-title>. <source>Nature Communications</source> <volume>6</volume>:<fpage>1</fpage>–<lpage>13</lpage>. doi:<pub-id pub-id-type="doi">10.1038/ncomms7922</pub-id></mixed-citation></ref>
<ref id="c80"><mixed-citation publication-type="other"><string-name><surname>Zou</surname> <given-names>M</given-names></string-name>. <year>2014</year>. <article-title>Connectivity, Plasticity, and Function of Neuronal Circuits in the Zebrafish Olfactory Forebrain</article-title>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.96303.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Gjorgjieva</surname>
<given-names>Julijana</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Technical University of Munich</institution>
</institution-wrap>
<city>Freising</city>
<country>Germany</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>important</bold> study introduces a biologically constrained model of telencephalic area of adult zebrafish to highlight the significance of precisely balanced memory networks in olfactory processing. The authors <bold>convincingly</bold> show that their model performs better in multiple situations (for e.g. in terms of network stability and shaping the geometry of representations), compared to traditional attractor networks and persistent activity. However the study lacks a mechanistic understanding of the results in terms of parameter sensitivity analysis. The work supports recent studies reporting functional E/I subnetworks in several sensory cortexes, and will be of interest to both theoretical and experimental neuroscientists studying network dynamics based on structured excitatory and inhibitory interactions.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.96303.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Meissner-Bernard et al present a biologically constrained model of telencephalic area of adult zebrafish, a homologous area to the piriform cortex, and argue for the role of precisely balanced memory networks in olfactory processing.</p>
<p>This is interesting as it can add to recent evidence on the presence of functional subnetworks in multiple sensory cortices. It is also important in deviating from traditional accounts of memory systems as attractor networks. Evidence for attractor networks has been found in some systems, like in the head direction circuits in the flies. However, the presence of attractor dynamics in other modalities, like sensory systems, and their role in computation has been more contentious. This work contributes to this active line of research in experimental and computational neuroscience by suggesting that, rather than being represented in attractor networks and persistent activity, olfactory memories might be coded by balanced excitation-inhibitory subnetworks.</p>
<p>Strengths:</p>
<p>The main strength of the work is in: (1) direct link to biological parameters and measurements, (2) good controls and quantification of the results, and (3) comparison across multiple models.</p>
<p>(1) The authors have done a good job of gathering the current experimental information to inform a biological-constrained spiking model of the telencephalic area of adult zebrafish. The results are compared to previous experimental measurements to choose the right regimes of operation.</p>
<p>
(2) Multiple quantification metrics and controls are used to support the main conclusions and to ensure that the key parameters are controlled for - e.g. when comparing across multiple models.</p>
<p>
(3) Four specific models (random, scaled I / attractor, and two variant of specific E-I networks - tuned I and tuned E+I) are compared with different metrics, helping to pinpoint which features emerge in which model.</p>
<p>Weaknesses:</p>
<p>Major problems with the work are: (1) mechanistic explanation of the results in specific E-I networks, (2) parameter exploration, and (3) the functional significance of the specific E-I model.</p>
<p>(1) The main problem with the paper is a lack of mechanistic analysis of the models. The models are treated like biological entities and only tested with different assays and metrics to describe their different features (e.g. different geometry of representation in Fig. 4). Given that all the key parameters of the models are known and can be changed (unlike biological networks), it is expected to provide a more analytical account of why specific networks show the reported results. For instance, what is the key mechanism for medium amplification in specific E/I network models (Fig. 3)? How does the specific geometry of representation/manifolds (in Fig. 4) emerge in terms of excitatory-inhibitory interactions, and what are the main mechanisms/parameters? Mechanistic account and analysis of these results are missing in the current version of the paper.</p>
<p>(2) The second major issue with the study is a lack of systematic exploration and analysis of the parameter space. Some parameters are biologically constrained, but not all the parameters. For instance, it is not clear what the justification for the choice of synaptic time scales are (with E synaptic time constants being larger than inhibition: tau_syn_i = 10 ms, tau_syn_E = 30 ms). How would the results change if they are varying these - and other unconstrained - parameters? It is important to show how the main results, especially the manifold localisation, would change by doing a systematic exploration of the key parameters and performing some sensitivity analysis. This would also help to see how robust the results are, which parameters are more important and which parameters are less relevant, and to shed light on the key mechanisms.</p>
<p>(3) It is not clear what the main functional advantage of the specific E-I network model is compared to random networks. In terms of activity, they show that specific E-I networks amplify the input more than random networks (Fig. 3). But when it comes to classification, the effect seems to be very small (Fig. 5c). Description of different geometry of representation and manifold localization in specific networks compared to random networks is good, but it is more of an illustration of different activity patterns than proving a functional benefit for the network. The reader is still left with the question of what major functional benefits (in terms of computational/biological processing) should be expected from these networks, if they are to be a good model for olfactory processing and learning.</p>
<p>
One possibility for instance might be that the tasks used here are too easy to reveal the main benefits of the specific models - and more complex tasks would be needed to assess the functional enhancement (e.g. more noisy conditions or more combination of odours). It would be good to show this more clearly - or at least discuss it in relation to computation and function.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.96303.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The authors conducted a comparative analysis of four networks, varying in the presence of excitatory assemblies and the architecture of inhibitory cell assembly connectivity. They found that co-tuned E-I assemblies provide network stability and a continuous representation of input patterns (on locally constrained manifolds), contrasting with networks with global inhibition that result in attractor networks.</p>
<p>Strengths:</p>
<p>The findings presented in this paper are very interesting and cutting-edge. The manuscript effectively conveys the message and presents a creative way to represent high-dimensional inputs and network responses. Particularly, the result regarding the projection of input patterns onto local manifolds and continuous representation of input/memory is very Intriguing and novel. Both computational and experimental neuroscientists would find value in reading the paper.</p>
<p>Weaknesses:</p>
<p>Intuitively, classification (decodability) in discrete attractor networks is much better than in networks that have continuous representations. This could also be shown in Figure 5B, along with the performance of the random and tuned E-I networks. The latter networks have the advantage of providing network stability compared to the Scaled I network, but at the cost of reduced network salience and, therefore, reduced input decodability. The authors may consider designing a decoder to quantify and compare the classification performance of all four networks.</p>
<p>Networks featuring E/I assemblies could potentially represent multistable attractors by exploring the parameter space for their reciprocal connectivity and connectivity with the rest of the network. However, for co-tuned E-I networks, the scope for achieving multistability is relatively constrained compared to networks employing global or lateral inhibition between assemblies. It would be good if the authors mentioned this in the discussion. Also, the fact that reciprocal inhibition increases network stability has been shown before and should be cited in the statements addressing network stability (e.g., some of the citations in the manuscript, including Rost et al. 2018, Lagzi &amp; Fairhall 2022, and Vogels et al. 2011 have shown this).</p>
<p>Providing raster plots of the pDp network for familiar and novel inputs would help with understanding the claims regarding continuous versus discrete representation of inputs, allowing readers to visualize the activity patterns of the four different networks. (similar to Figure 1B).</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.96303.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This work investigates the computational consequences of assemblies containing both excitatory and inhibitory neurons (E/I assembly) in a model with parameters constrained by experimental data from the telencephalic area Dp of zebrafish. The authors show how this precise E/I balance shapes the geometry of neuronal dynamics in comparison to unstructured networks and networks with more global inhibitory balance. Specifically, E/I assemblies lead to the activity being locally restricted onto manifolds - a dynamical structure in between high-dimensional representations in unstructured networks and discrete attractors in networks with global inhibitory balance. Furthermore, E/I assemblies lead to smoother representations of mixtures of stimuli while those stimuli can still be reliably classified, and allow for more robust learning of additional stimuli.</p>
<p>Strengths:</p>
<p>Since experimental studies do suggest that E/I balance is very precise and E/I assemblies exist, it is important to study the consequences of those connectivity structures on network dynamics. The authors convincingly show that E/I assemblies lead to different geometries of stimulus representation compared to unstructured networks and networks with global inhibition. This finding might open the door for future studies for exploring the functional advantage of these locally defined manifolds, and how other network properties allow to shape those manifolds.</p>
<p>The authors also make sure that their spiking model is well-constrained by experimental data from the zebrafish pDp. Both spontaneous and odor stimulus triggered spiking activity is within the range of experimental measurements. But the model is also general enough to be potentially applied to findings in other animal models and brain regions.</p>
<p>Weaknesses:</p>
<p>I find the point about pattern completion a bit confusing. In Fig. 3 the authors argue that only the Scaled I network can lead to pattern completion for morphed inputs since the output correlations are higher than the input correlations. For me, this sounds less like the network can perform pattern completion but it can nonlinearly increase the output correlations. Furthermore, in Suppl. Fig. 3 the authors show that activating half the assembly does lead to pattern completion in the sense that also non-activated assembly cells become highly active and that this pattern completion can be seen for Scaled I, Tuned E+I, and Tuned I networks. These two results seem a bit contradictory to me and require further clarification, and the authors might want to clarify how exactly they define pattern completion.</p>
<p>The authors argue that Tuned E+I networks have several advantages over Scaled I networks. While I agree with the authors that in some cases adding this localized E/I balance is beneficial, I believe that a more rigorous comparison between Tuned E+I networks and Scaled I networks is needed: quantification of variance (Fig. 4G) and angle distributions (Fig. 4H) should also be shown for the Scaled I network. Similarly in Fig. 5, what is the Mahalanobis distance for Scaled I networks and how well can the Scaled I network be classified compared to the Tuned E+I network? I suspect that the Scaled I network will actually be better at classifying odors compared to the E+I network. The authors might want to speculate about the benefit of having networks with both sources of inhibition (local and global) and hence being able to switch between locally defined manifolds and discrete attractor states.</p>
<p>At a few points in the manuscript, the authors use statements without actually providing evidence in terms of a Figure. Often the authors themselves acknowledge this, by adding the term &quot;not shown&quot; to the end of the sentence. I believe it will be helpful to the reader to be provided with figures or panels in support of the statements.</p>
</body>
</sub-article>
<sub-article id="sa4" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.96303.1.sa4</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Meissner-Bernard</surname>
<given-names>Claire</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0007-2038-8398</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Zenke</surname>
<given-names>Friedemann</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1883-644X</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Friedrich</surname>
<given-names>Rainer W.</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9107-0482</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<disp-quote content-type="editor-comment">
<p><bold>Public Reviews:</bold></p>
<p><bold>Reviewer #1 (Public Review):</bold></p>
<p>Summary:</p>
<p>Meissner-Bernard et al present a biologically constrained model of telencephalic area of adult zebrafish, a homologous area to the piriform cortex, and argue for the role of precisely balanced memory networks in olfactory processing.</p>
<p>This is interesting as it can add to recent evidence on the presence of functional subnetworks in multiple sensory cortices. It is also important in deviating from traditional accounts of memory systems as attractor networks. Evidence for attractor networks has been found in some systems, like in the head direction circuits in the flies. However, the presence of attractor dynamics in other modalities, like sensory systems, and their role in computation has been more contentious. This work contributes to this active line of research in experimental and computational neuroscience by suggesting that, rather than being represented in attractor networks and persistent activity, olfactory memories might be coded by balanced excitation-inhibitory subnetworks.</p>
<p>Strengths:</p>
<p>The main strength of the work is in: (1) direct link to biological parameters and measurements, (2) good controls and quantification of the results, and (3) comparison across multiple models.</p>
<p>(1) The authors have done a good job of gathering the current experimental information to inform a biological-constrained spiking model of the telencephalic area of adult zebrafish. The results are compared to previous experimental measurements to choose the right regimes of operation.</p>
<p>(2) Multiple quantification metrics and controls are used to support the main conclusions and to ensure that the key parameters are controlled for - e.g. when comparing across multiple models.</p>
<p>(3) Four specific models (random, scaled I / attractor, and two variant of specific E-I networks - tuned I and tuned E+I) are compared with different metrics, helping to pinpoint which features emerge in which model.</p>
<p>Weaknesses:</p>
<p>Major problems with the work are: (1) mechanistic explanation of the results in specific E-I networks, (2) parameter exploration, and (3) the functional significance of the specific E-I model.</p>
<p>(1) The main problem with the paper is a lack of mechanistic analysis of the models. The models are treated like biological entities and only tested with different assays and metrics to describe their different features (e.g. different geometry of representation in Fig. 4). Given that all the key parameters of the models are known and can be changed (unlike biological networks), it is expected to provide a more analytical account of why specific networks show the reported results. For instance, what is the key mechanism for medium amplification in specific E/I network models (Fig. 3)? How does the specific geometry of representation/manifolds (in Fig. 4) emerge in terms of excitatory-inhibitory interactions, and what are the main mechanisms/parameters? Mechanistic account and analysis of these results are missing in the current version of the paper.</p>
</disp-quote>
<p>We agree with the reviewer that a mechanistic analysis of manifold geometry is of high interest and we will address this issue in our revisions. We are currently exploring approaches to better understand how amplification of activity is controlled in E/I assemblies, and how geometric modifications can be described in terms of elementary excitatory and inhibitory interactions. We expect these approaches to provide new mechanistic insights into representational manifolds.</p>
<disp-quote content-type="editor-comment">
<p>(2) The second major issue with the study is a lack of systematic exploration and analysis of the parameter space. Some parameters are biologically constrained, but not all the parameters. For instance, it is not clear what the justification for the choice of synaptic time scales are (with E synaptic time constants being larger than inhibition: tau_syn_i = 10 ms, tau_syn_E = 30 ms). How would the results change if they are varying these - and other unconstrained - parameters? It is important to show how the main results, especially the manifold localisation, would change by doing a systematic exploration of the key parameters and performing some sensitivity analysis. This would also help to see how robust the results are, which parameters are more important and which parameters are less relevant, and to shed light on the key mechanisms.</p>
</disp-quote>
<p>We varied neuronal and network parameters in the past and we are currently performing additional systematic parameter variations to further address this comment. Preliminary results indicate that networks with similar properties can be obtained with equal synaptic time constants and biophysical parameters for all E and I neurons, thus supporting the notion that representational geometry is determined primarily by connectivity. Results of parameter variations will be reported in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p>(3) It is not clear what the main functional advantage of the specific E-I network model is compared to random networks. In terms of activity, they show that specific E-I networks amplify the input more than random networks (Fig. 3). But when it comes to classification, the effect seems to be very small (Fig. 5c). Description of different geometry of representation and manifold localization in specific networks compared to random networks is good, but it is more of an illustration of different activity patterns than proving a functional benefit for the network. The reader is still left with the question of what major functional benefits (in terms of computational/biological processing) should be expected from these networks, if they are to be a good model for olfactory processing and learning.</p>
<p>One possibility for instance might be that the tasks used here are too easy to reveal the main benefits of the specific models - and more complex tasks would be needed to assess the functional enhancement (e.g. more noisy conditions or more combination of odours). It would be good to show this more clearly - or at least discuss it in relation to computation and function.</p>
</disp-quote>
<p>We agree that further insights into potential benefits of manifold representations would be interesting. In the initial manuscript we performed analyses of pattern classification primarily to examine whether the structured E/I networks studied here can support pattern classification at all, given that they do not exhibit discrete attractor states or global pattern completion. As structured E/I networks still support pattern classification when activity is read out from neuronal subsets, we concluded that structured E/I networks are not in conflict with the general notion of pattern classification by autoassociation. In addition, manifold representations may support a variety of other computations that we discussed only superficially.  In the revised we are planning to address this issue in more depth by additional discussion and analyses. In particular, we are planning to address the hypothesis that manifold geometry provides a continuous distance metric to analyze relationships between inputs and relevant stimuli (learned odors) in the presence of irrelevant stimulus components (non-learned odors).</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public Review):</bold></p>
<p>Summary:</p>
<p>The authors conducted a comparative analysis of four networks, varying in the presence of excitatory assemblies and the architecture of inhibitory cell assembly connectivity. They found that co-tuned E-I assemblies provide network stability and a continuous representation of input patterns (on locally constrained manifolds), contrasting with networks with global inhibition that result in attractor networks.</p>
<p>Strengths:</p>
<p>The findings presented in this paper are very interesting and cutting-edge. The manuscript effectively conveys the message and presents a creative way to represent high-dimensional inputs and network responses. Particularly, the result regarding the projection of input patterns onto local manifolds and continuous representation of input/memory is very Intriguing and novel. Both computational and experimental neuroscientists would find value in reading the paper.</p>
<p>Weaknesses:</p>
<p>Intuitively, classification (decodability) in discrete attractor networks is much better than in networks that have continuous representations. This could also be shown in Figure 5B, along with the performance of the random and tuned E-I networks. The latter networks have the advantage of providing network stability compared to the Scaled I network, but at the cost of reduced network salience and, therefore, reduced input decodability. The authors may consider designing a decoder to quantify and compare the classification performance of all four networks.</p>
</disp-quote>
<p>As suggested by the reviewer, we will explicitly examine decodability by different types of networks in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p>Networks featuring E/I assemblies could potentially represent multistable attractors by exploring the parameter space for their reciprocal connectivity and connectivity with the rest of the network. However, for co-tuned E-I networks, the scope for achieving multistability is relatively constrained compared to networks employing global or lateral inhibition between assemblies. It would be good if the authors mentioned this in the discussion. Also, the fact that reciprocal inhibition increases network stability has been shown before and should be cited in the statements addressing network stability (e.g., some of the citations in the manuscript, including Rost et al. 2018, Lagzi &amp; Fairhall 2022, and Vogels et al. 2011 have shown this).</p>
</disp-quote>
<p>We thank the reviewer for this comment and will revise the manuscript accordingly.</p>
<disp-quote content-type="editor-comment">
<p>Providing raster plots of the pDp network for familiar and novel inputs would help with understanding the claims regarding continuous versus discrete representation of inputs, allowing readers to visualize the activity patterns of the four different networks. (similar to Figure 1B).</p>
<p>We will follow the suggestion by the reviewer and include raster plots of responses to both familiar and novel inputs in the revised manuscript.</p>
<p><bold>Reviewer #3 (Public Review):</bold></p>
<p>Summary:</p>
<p>This work investigates the computational consequences of assemblies containing both excitatory and inhibitory neurons (E/I assembly) in a model with parameters constrained by experimental data from the telencephalic area Dp of zebrafish. The authors show how this precise E/I balance shapes the geometry of neuronal dynamics in comparison to unstructured networks and networks with more global inhibitory balance. Specifically, E/I assemblies lead to the activity being locally restricted onto manifolds - a dynamical structure in between high-dimensional representations in unstructured networks and discrete attractors in networks with global inhibitory balance. Furthermore, E/I assemblies lead to smoother representations of mixtures of stimuli while those stimuli can still be reliably classified, and allow for more robust learning of additional stimuli.</p>
<p>Strengths:</p>
<p>Since experimental studies do suggest that E/I balance is very precise and E/I assemblies exist, it is important to study the consequences of those connectivity structures on network dynamics. The authors convincingly show that E/I assemblies lead to different geometries of stimulus representation compared to unstructured networks and networks with global inhibition. This finding might open the door for future studies for exploring the functional advantage of these locally defined manifolds, and how other network properties allow to shape those manifolds.</p>
<p>The authors also make sure that their spiking model is well-constrained by experimental data from the zebrafish pDp. Both spontaneous and odor stimulus triggered spiking activity is within the range of experimental measurements. But the model is also general enough to be potentially applied to findings in other animal models and brain regions.</p>
<p>Weaknesses:</p>
<p>I find the point about pattern completion a bit confusing. In Fig. 3 the authors argue that only the Scaled I network can lead to pattern completion for morphed inputs since the output correlations are higher than the input correlations. For me, this sounds less like the network can perform pattern completion but it can nonlinearly increase the output correlations. Furthermore, in Suppl. Fig. 3 the authors show that activating half the assembly does lead to pattern completion in the sense that also non-activated assembly cells become highly active and that this pattern completion can be seen for Scaled I, Tuned E+I, and Tuned I networks. These two results seem a bit contradictory to me and require further clarification, and the authors might want to clarify how exactly they define pattern completion.</p>
</disp-quote>
<p>We believe that this comment concerns a semantic misunderstanding and apologize for any lack of clarity. The reviewer is correct that “pattern completion” in morphing experiments can be described as a nonlinear increase in output correlations in response to related inputs. This is different from the results obtained by simulated current injections because currents were targeted to subsets of assembly neurons and the analysis focused on firing rates within and outside assemblies. We referred to results of both experiments as “pattern completion” because this has been standard in the neurobiological and in the computer science literature, respectively. However, we agree that this can cause confusion and we will revise the manuscript to clarify this issue.</p>
<disp-quote content-type="editor-comment">
<p>The authors argue that Tuned E+I networks have several advantages over Scaled I networks. While I agree with the authors that in some cases adding this localized E/I balance is beneficial, I believe that a more rigorous comparison between Tuned E+I networks and Scaled I networks is needed: quantification of variance (Fig. 4G) and angle distributions (Fig. 4H) should also be shown for the Scaled I network. Similarly in Fig. 5, what is the Mahalanobis distance for Scaled I networks and how well can the Scaled I network be classified compared to the Tuned E+I network? I suspect that the Scaled I network will actually be better at classifying odors compared to the E+I network. The authors might want to speculate about the benefit of having networks with both sources of inhibition (local and global) and hence being able to switch between locally defined manifolds and discrete attractor states.</p>
</disp-quote>
<p>As pointed out already in response to reviewer 1, we agree that the potential computational benefits of continuous manifold representations in comparison to discrete attractor states is an important point that merits further exploration and discussion. We are therefore planning to include a more in-depth discussion and to perform further analyses. The specific suggestions of the reviewer will be addressed.</p>
<disp-quote content-type="editor-comment">
<p>At a few points in the manuscript, the authors use statements without actually providing evidence in terms of a Figure. Often the authors themselves acknowledge this, by adding the term &quot;not shown&quot; to the end of the sentence. I believe it will be helpful to the reader to be provided with figures or panels in support of the statements.</p>
</disp-quote>
<p>Thank you for this comment. We shall be happy to include additional data figures in the revised manuscript.</p>
</body>
</sub-article>
</article>