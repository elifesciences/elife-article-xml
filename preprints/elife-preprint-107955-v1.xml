<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">107955</article-id>
<article-id pub-id-type="doi">10.7554/eLife.107955</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.107955.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories><title-group>
<article-title>Multiple event segmentation mechanisms in the human brain</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8433-4678</contrib-id>
<name>
<surname>Nguyen</surname>
<given-names>Tan T</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>n.tan@wustl.edu</email>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3694-8277</contrib-id>
<name>
<surname>Etzel</surname>
<given-names>Joset A</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-0080-9366</contrib-id>
<name>
<surname>Bezdek</surname>
<given-names>Matthew A</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1171-3690</contrib-id>
<name>
<surname>Zacks</surname>
<given-names>Jeffrey M</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01yc7t268</institution-id><institution>Psychological and Brain Sciences, Washington University in St. Louis</institution></institution-wrap>, <city>St. Louis</city>, <country country="US">United States</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Peelle</surname>
<given-names>Jonathan Erik</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Northeastern University</institution>
</institution-wrap>
<city>Boston</city>
<country country="US">United States</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country country="US">United States</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-09-30">
<day>30</day>
<month>09</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP107955</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-07-07">
<day>07</day>
<month>07</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-07-10">
<day>10</day>
<month>07</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.07.07.663487"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Nguyen et al</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Nguyen et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-107955-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>The human brain segments continuous experience into discrete events, with theoretical accounts proposing two distinct mechanisms: creating boundaries at points of high <italic>prediction error</italic> (mismatch between expected and observed information) or high <italic>prediction uncertainty</italic> (reduced precision in predictions). Using fMRI and computational modeling, we investigated the neural correlates of error-driven and uncertainty-driven boundaries. We developed computational models that generate boundaries based on prediction error or prediction uncertainty, and examined how both types of boundaries, and human-identified boundaries, related to fMRI pattern shifts and evoked responses. Multivariate analysis revealed a specific temporal sequence of neural pattern changes around human boundaries: early pattern shifts in anterior temporal regions (−11.9s), followed by shifts in parietal areas (−4.5s), and subsequent whole-brain pattern stabilization (+11.8s). The core of this dynamic response was associated with both error-driven and uncertainty-driven boundaries. Critically, both error- and uncertainty-driven boundaries were associated with unique pattern shifts. Error-driven boundaries were associated with early pattern shifts in ventrolateral prefrontal areas, followed by pattern stabilization in prefrontal and temporal areas. Uncertainty-driven boundaries were linked to shifts in parietal regions within the dorsal attention network, with minimal subsequent stabilization. In addition, within the core regions responsive to both types of boundaries, the timing differed significantly. These findings provide evidence for two overlapping brain networks that maintain and update representations of the environment, controlled by two distinct prediction quality signals: prediction error and prediction uncertainty.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>

</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>To act effectively in dynamic environments, humans use memory and knowledge to predict how activity will unfold over time (<xref ref-type="bibr" rid="c11">Clark, 2013</xref>; <xref ref-type="bibr" rid="c19">Friston et al., 2016</xref>; <xref ref-type="bibr" rid="c28">Knott &amp; Takac, 2021</xref>; <xref ref-type="bibr" rid="c32">Niv &amp; Schoenbaum, 2008</xref>). Contemporary cognitive models propose that perception is guided by event models—stable representations of the current situation (<xref ref-type="bibr" rid="c44">Zacks, 2020</xref>). These event models integrate sensory information with prior schematic knowledge—structured representations that encode knowledge about event classes (<xref ref-type="bibr" rid="c1">Anderson, 1978</xref>; <xref ref-type="bibr" rid="c5">Bartlett, 1932</xref>; <xref ref-type="bibr" rid="c23">Graesser &amp; Nakamura, 1982</xref>). For example, when serving coffee, an event model helps predict that the recipient will pick up the cup and how they will move to do so. However, for such models to remain effective, they must update appropriately when one event ends and another begins—once the coffee has been taken, a coffee-serving model becomes unhelpful (<xref ref-type="bibr" rid="c16">DuBrow et al., 2017</xref>); this is known as <italic>event segmentation</italic>. There has been considerable recent interest in the features that predict event segmentation (<xref ref-type="bibr" rid="c2">Bailey &amp; Zacks, 2015</xref>; <xref ref-type="bibr" rid="c9">Brunec et al., 2018</xref>; <xref ref-type="bibr" rid="c30">Magliano et al., 1999</xref>; <xref ref-type="bibr" rid="c39">Su &amp; Swallow, 2024</xref>; <xref ref-type="bibr" rid="c41">Wang &amp; Egner, 2022</xref>), in the effects of segmentation on immediate access to information in working memory (<xref ref-type="bibr" rid="c34">Radvansky et al., 2010</xref>; <xref ref-type="bibr" rid="c33">Radvansky &amp; Copeland, 2006</xref>), and in the role of segmentation in shaping long-term memory (<xref ref-type="bibr" rid="c12">Clewett et al., 2019</xref>; <xref ref-type="bibr" rid="c13">Ding &amp; Zacks, 2025</xref>; <xref ref-type="bibr" rid="c15">DuBrow &amp; Davachi, 2013</xref>; <xref ref-type="bibr" rid="c36">Sargent et al., 2013</xref>; <xref ref-type="bibr" rid="c40">Swallow et al., 2009</xref>). Individual and group differences in segmentation are robust predictors of memory and action performance. However, an important open question is: What control signal or signals does the cognitive system use to determine when to update event models?</p>
<p>One potential signal to control event model updating is <italic>prediction error</italic>—the difference between the system’s prediction and what actually occurs. A transient increase in prediction error is a valid indicator that the current model no longer adequately captures the current activity. Event Segmentation Theory (EST; <xref ref-type="bibr" rid="c45">Zacks et al., 2007</xref>) proposes that event models are updated when prediction error increases beyond a threshold, indicating that the current model no longer adequately captures ongoing activity. A related but computationally distinct proposal is that prediction <italic>uncertainty</italic> (also termed &quot;unpredictability&quot;), rather than error, serves as the control signal (<xref ref-type="bibr" rid="c4">Baldwin &amp; Kosie, 2021</xref>). Building on this idea, <xref ref-type="bibr" rid="c24">Gumbsch et al. (2022)</xref> developed a computational model in which uncertainty dynamically directs the model’s gaze, which successfully predicted infant gaze allocation.</p>
<p>In naturalistic activity, prediction error and prediction uncertainty tend to co-occur. In a recent study (<xref ref-type="bibr" rid="c31">Nguyen et al., 2024</xref>), we used a large corpus and a formal computational model to assay the joint potential contributions of prediction error and prediction uncertainty on human event segmentation. We found that both error-driven and uncertainty-driven updating signals aligned with human segmentation and categorization judgments, but that uncertainty-driven segmentation aligned significantly better. This result argues for a unique role for prediction uncertainty in event model updating. However, it also opens up the possibility that multiple control mechanisms could govern updating of stable brain representations. One possibility is that representational updates in some brain areas may be triggered by either prediction error spikes or prediction uncertainty spikes. Another possibility (not mutually exclusive) is that updates in some brain areas may be uniquely triggered by prediction error or prediction uncertainty.</p>
<p>A body of fMRI research has shown that event boundaries evoke responses in multiple brain regions. Early univariate analyses found transient increases in BOLD activity at event boundaries within visual and parietal areas, including medial visual cortex, the precuneus, and intraparietal sulcus (<xref ref-type="bibr" rid="c29">Kurby &amp; Zacks, 2018</xref>; <xref ref-type="bibr" rid="c38">Speer et al., 2007</xref>; <xref ref-type="bibr" rid="c43">Zacks, 2010</xref>). Moreover, regions within the default mode network showed decreased activity at musical and movie event boundaries (<xref ref-type="bibr" rid="c10">Burunat et al., 2024</xref>; <xref ref-type="bibr" rid="c43">Zacks, 2010</xref>). Boundary-related activity is predictive of subsequent memory, supporting a causal role for segmentation in memory formation (<xref ref-type="bibr" rid="c6">Ben-Yakov &amp; Dudai, 2011</xref>). Recent research has further revealed that hippocampal responses at movie event boundaries show a graded profile, wherein greater univariate activity is associated with greater perceived boundary &quot;salience,&quot; measured by agreement across a separate group of individuals that a boundary occurred (<xref ref-type="bibr" rid="c7">Ben-Yakov &amp; Henson, 2018</xref>).</p>
<p>More recently, multivariate approaches have provided deeper insights into neural representations during event segmentation. One prominent approach uses hidden Markov models (HMMs) to detect moments when the brain switches from one stable activity pattern to another (<xref ref-type="bibr" rid="c3">Baldassano et al., 2017</xref>) during movie viewing. These periods of relative stability (which were referred to as &quot;neural states&quot; to distinguish them from subjectively perceived events) in multimodal brain regions such as precuneus, angular gyrus, and posterior medial cortex, aligned with subjectively reported event boundaries. <xref ref-type="bibr" rid="c22">Geerligs et al. (2021</xref>, <xref ref-type="bibr" rid="c21">2022</xref>) employed a different analytical approach called Greedy State Boundary Search (GSBS) to identify neural state boundaries. They found that transitions between neural states in the default mode network (DMN) significantly coincide with human-identified event boundaries. <xref ref-type="bibr" rid="c21">Geerligs et al. (2022)</xref> further mapped the specific brain regions showing statistically significant overlap between neural state boundaries and perceived event boundaries, identifying the anterior cingulate cortex, dorsal medial prefrontal cortex, left superior and middle frontal gyrus, and anterior insula as areas with particularly strong alignment. These findings suggest that the subjective experience of event boundaries may be supported by shifts in neural activity patterns in these brain regions.</p>
<p>The previous evidence about evoked responses at event boundaries indicates that these are dynamic phenomena evolving over many seconds, with different brain areas showing different dynamics (<xref ref-type="bibr" rid="c7">Ben-Yakov &amp; Henson, 2018</xref>; <xref ref-type="bibr" rid="c10">Burunat et al., 2024</xref>; <xref ref-type="bibr" rid="c29">Kurby &amp; Zacks, 2018</xref>; <xref ref-type="bibr" rid="c38">Speer et al., 2007</xref>; <xref ref-type="bibr" rid="c43">Zacks, 2010</xref>). Less is known about the dynamics of pattern shifts at event boundaries, because the HMM and GSBS analysis methods do not directly provide moment-by-moment measures of pattern shifts. Both the spatial and temporal aspects of evoked responses and pattern shifts at event boundaries have the potential to provide evidence about potential control processes for event model updating. However, this requires an approach that can model each potential mechanism independently and predict when event model updating driven by each mechanism should happen. Here, we combined fMRI with quantitative computational models of event segmentation that had been previously validated against human behavior (<xref ref-type="bibr" rid="c31">Nguyen et al., 2024</xref>). The models make predictions about when error-driven updating or uncertainty-driven updating should lead to fMRI evoked responses and pattern shifts. This approach allowed us to characterize the spatiotemporal profiles of neural dynamics associated with event segmentation.</p>
<p>Our study addresses three main research questions. First, how do neural activity and neural activity pattern change before, during, and after human-identified event boundaries? We aimed to replicate and extend previous findings using both univariate and multivariate analyses. Second, are human-identified boundaries predicted by both error- and uncertainty-driven computational models? We compared the alignment between our model-derived boundaries and the segmentation judgments of human observers, testing whether both error and uncertainty signals contribute uniquely to subjective experience of event boundaries. Third, and most importantly, do error- and uncertainty-driven boundaries engage distinct brain networks with different temporal dynamics? By comparing brain regions whose neural pattern changes are related to error-driven or uncertainty-driven boundaries and the temporal profiles of neural pattern changes, we can determine whether these computational processes rely on separate neural systems with distinct temporal signatures.</p>
</sec>
<sec id="s2">
<title>Results</title>
<p>In this study, we examined brain responses around event boundaries during naturalistic video viewing. Forty-five participants watched four videos depicting everyday activities while undergoing fMRI scanning (see Methods). For each activity, a separate group of 30 participants had previously segmented each movie to identify fine-grained event boundaries (<xref ref-type="bibr" rid="c8">Bezdek et al., 2022</xref>). The mean event length was 21.4 s (median 22.2 s, SD 16.1 s). We applied Finite Impulse Response (FIR) models to analyze brain activity changes and neural pattern shifts within a window of approximately 20 seconds before and after human boundaries, error-driven boundaries, and uncertainty-driven boundaries. For all analyses, we described activity within regions defined by the Schaefer 400-parcel atlas (<xref ref-type="bibr" rid="c37">Schaefer et al., 2018</xref>).</p>
<p>Our analyses below addressed three main questions about the neural mechanisms of event segmentation. We first characterized how the magnitude and pattern of neural activity change around human-identified event boundaries. Next, we tested whether human event segmentation might be supported by one or both candidate cognitive mechanisms by examining the extent to which error-driven and uncertainty-driven boundaries could predict human boundaries. Finally, we investigated whether these two potential control mechanisms engage separate neural systems by comparing the brain networks and temporal dynamics associated with error-driven and uncertainty-driven boundaries.</p>
<sec id="s2a">
<title>Event boundaries were associated with increased activity in regions within the visual and dorsal attention networks, and decreased activity in regions within the default network</title>
<p>We first analyzed the BOLD response around human-identified event boundaries. We analyzed two effects: changes in BOLD magnitude (this section) and in local patterns of activity (in the next section). The magnitude analyses are a replication of previous studies (<xref ref-type="bibr" rid="c10">Burunat et al., 2024</xref>; <xref ref-type="bibr" rid="c29">Kurby &amp; Zacks, 2018</xref>; <xref ref-type="bibr" rid="c38">Speer et al., 2007</xref>; <xref ref-type="bibr" rid="c43">Zacks, 2010</xref>): We time-locked the magnitude of the evoked response to the identified boundaries. Whereas previous studies were analyzed at the voxel level, here we took advantage of modern functional anatomic parcellation (<xref ref-type="bibr" rid="c37">Schaefer et al., 2018</xref>) to improve sensitivity. The pattern-based analyses represent a significant new view of the brain’s response to event boundaries. In the next section, we time-locked the rate of pattern change to the event boundary. This constitutes a valuable complement to methods based on the HMM (<xref ref-type="bibr" rid="c3">Baldassano et al., 2017</xref>) or GSBS (<xref ref-type="bibr" rid="c22">Geerligs et al., 2021</xref>) by providing a continuous time course of pattern change around the boundary.</p>
<p>To analyze BOLD magnitude, we employed a FIR model (see Methods) over a time window spanning approximately 20 seconds before and 20 seconds after human-identified event boundaries. This analysis revealed brain regions whose BOLD activity changes significantly (FDR with alpha &lt; 0.001, corrected-p-value &lt; 0.001) around event boundaries. The strongest changes were in areas within the visual and dorsal attention networks; the precuneus and medial prefrontal cortex (PFC) within the default network, and lateral PFC within the control network also had significant activity changes (<xref rid="fig1" ref-type="fig">Figure 1</xref>). The spatial distribution of these responses are similar to previous results (<xref ref-type="bibr" rid="c10">Burunat et al., 2024</xref>; <xref ref-type="bibr" rid="c29">Kurby &amp; Zacks, 2018</xref>; <xref ref-type="bibr" rid="c38">Speer et al., 2007</xref>; <xref ref-type="bibr" rid="c43">Zacks, 2010</xref>).</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Regions where BOLD activity changed significantly (corrected p &lt; 0.001) around human boundaries.</title>
<p>FIR models were used to predict parcel-wise BOLD activity within a time window spanning approximately 20 seconds before and 20 seconds after human-identified event boundaries. The z-statistics revealed significant activity changes across multiple brain networks, with particularly strong changes in the visual and dorsal attention networks, and moderate changes in the precuneus and medial PFC within the default model network, and lateral PFC within the control network.</p></caption>
<graphic xlink:href="663487v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We then examined these evoked responses in detail, extracting FIR-estimated BOLD activity timecourses for each parcel showing significant change over time. Parcels in the visual, dorsal, and control networks showed an increase in BOLD activity around event boundaries, whereas many default network parcels showed decreases in BOLD activity around event boundaries (<xref rid="fig2" ref-type="fig">Figure 2</xref>). Interestingly, some regions, such as the precuneus, displayed a biphasic response characterized by an initial increase in activity at the event boundary followed by a subsequent decrease (<xref rid="fig2" ref-type="fig">Figure 2</xref>, bottom). Again, these findings are consistent with prior studies examining brain activity at event boundaries (<xref ref-type="bibr" rid="c10">Burunat et al., 2024</xref>; <xref ref-type="bibr" rid="c29">Kurby &amp; Zacks, 2018</xref>; <xref ref-type="bibr" rid="c38">Speer et al., 2007</xref>; <xref ref-type="bibr" rid="c43">Zacks, 2010</xref>), and suggest that event segmentation is a process that unfolds over more than 20 seconds, involving multiple brain networks.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Brain activity relative to estimated baseline activity −11.9s before event boundary (top), at event boundary (middle), and 11.8s after event boundary (bottom).</title>
<p>Brain maps display BOLD signal changes across multiple networks, with warm colors (red/yellow) indicating increased activity and cool colors (blue) indicating decreased activity. Visual, dorsal attention, and control network parcels tend to show increased BOLD activity around event boundaries, while default network regions exhibit decreased activity. Time courses (right panels) illustrate activity patterns in specific parcels (representative timecourses observed) within control network and default network (shades indicate plus and minus 2 standard errors). Parcel labels are from the Schaefer 400×7 parcellation atlas (<xref ref-type="bibr" rid="c37">Schaefer et al., 2018</xref>); for example LH_Cont_PFCl_7 indicates a parcel which is in the left lateral prefrontal cortex and is a component of the Control network. Some regions, notably the precuneus (bottom line graph), display a biphasic response characterized by initial activity increase at the boundary followed by subsequent decrease. Frame-by-frame brain maps and BOLD activity around boundaries for all parcels can be found at <ext-link ext-link-type="uri" xlink:href="https://openneuro.org/datasets/ds005551">https://openneuro.org/datasets/ds005551</ext-link> under derivatives/figures/brain_maps_and_timecourses/ directory.</p></caption>
<graphic xlink:href="663487v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2b">
<title>Prefrontal and anterior temporal regions show early pattern shifts, followed by parietal shifts near boundaries, and whole-brain stabilization post-boundary</title>
<p>To model the effect of event boundaries on shifts in the local pattern of activity, we first calculated the amount of frame-to-frame change in the pattern of activity within each parcel and then fit FIR models to this pattern dissimilarity measure. Pattern dissimilarity was calculated as 1 - <italic>r</italic>, where <italic>r</italic> is the Pearson correlation between the voxel-wise activity patterns in the parcel for the two successive timepoints (see Methods for details). High pattern dissimilarity indicates that the neural patterns are more unstable (pattern shift), whereas low pattern dissimilarity indicates that neural patterns are more stable (pattern stabilization). As with the magnitude analyses, we fit the FIR model to a time window spanning approximately 20 seconds before and 20 seconds after human-identified boundaries for each parcel. This analysis revealed brain regions whose neural patterns shifted (increased dissimilarity) or stabilized (decreased dissimilarity) significantly (FDR with alpha &lt; 0.001, corrected-p-value &lt; 0.001) around event boundaries; these brain regions belong to the control (lateral PFC), default (medial PFC, posterior cingulate cortex, and temporal areas), dorsal attention (superior parietal lobule and posterior cortex) and visual (temporal occipital areas) networks (<xref rid="fig3" ref-type="fig">Figure 3</xref>).</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3:</label>
<caption><title>Regions where pattern dissimilarity changed significantly (corrected p &lt; 0.001) around event boundaries.</title>
<p>FIR models were used to predict pattern dissimilarity within a time window spanning approximately 20 seconds before and 20 seconds after human-identified event boundaries. Results show degree of changes in pattern dissimilarity relative to estimated baseline pattern dissimilarity in parcels across multiple brain networks, including the control network (lateral PFC), default network (medial PFC, posterior cingulate cortex, and temporal areas), dorsal attention network (superior parietal lobule and posterior cortex), and visual network (temporal occipital areas).</p></caption>
<graphic xlink:href="663487v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Next, we examined the same FIR model output for timecourses of pattern dissimilarity around event boundaries. <xref rid="fig4" ref-type="fig">Figure 4</xref> shows changes in pattern dissimilarity relative to estimated baseline dissimilarity over time. The analysis revealed three salient phenomena. First, early pre-boundary temporal pole pattern shifts: At the early pre-boundary timepoint (−11.9s), pattern dissimilarity in the anterior temporal pole and orbitofrontal cortex significantly increased compared to estimated baseline dissimilarity, indicating substantial pattern shifts in this region. Second, immediate pre-boundary parietal pattern shifts: At the immediate pre-boundary timepoint (−4.5s), pattern dissimilarity in post central and superior parietal lobule areas (part of the dorsal attention network) increased significantly compared to estimated baseline dissimilarity, reflecting notable pattern shifts. Third, post-boundary whole-brain pattern stabilization: At the post-boundary timepoint (+11.8s), pattern dissimilarity across the whole brain decreased compared to estimated baseline dissimilarity, indicating pattern stabilization. This period of stability may represent the establishment and maintenance of a new event model. The widespread nature of this stabilization suggests a global reconfiguration of brain states, consistent with theories proposing that event boundaries mark transitions between distinct neural states representing different events.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4:</label>
<caption><title>Event boundaries are characterized by increases in pattern dissimilarity, followed by post-boundary stability.</title>
<p>Brain surface maps show deviations from baseline pattern dissimilarity (orange: increased dissimilarity/pattern shifts; blue: decreased dissimilarity/pattern stabilization) at three points in time. Line plots for selected regions show pattern dissimilarity for selected parcels over time, illustrating the representative timecourses observed (shades indicate plus and minus 2 standard errors). Baseline dissimilarity levels are indicated by horizontal purple lines. Higher values reflect greater pattern shifts, while lower values indicate more stable patterns. Parcel labels followed the Schaefer 400×7 parcellation atlas (<xref ref-type="bibr" rid="c37">Schaefer et al., 2018</xref>). Three key phenomena emerge: (1) At early pre-boundary (−11.9s), anterior temporal pole regions and orbitofrontal cortex showed significantly increased dissimilarity relative to baseline dissimilarity, indicating pattern shifts; (2) At immediate pre-boundary (−4.5s), superior parietal lobule and postcentral areas within the dorsal attention network exhibited increased pattern dissimilarity, indicating pattern shifts; (3) At post-boundary (+11.8s), pattern dissimilarity across the whole brain decreased, indicating widespread pattern stabilization. Brain maps and pattern dissimilarity around boundaries for all parcels can be found at <ext-link ext-link-type="uri" xlink:href="https://openneuro.org/datasets/ds005551">https://openneuro.org/datasets/ds005551</ext-link> under derivatives/figures/brain_maps_and_timecourses/ directory.</p></caption>
<graphic xlink:href="663487v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The sequence of changes we observed—from temporal areas to parietal regions and finally to global stabilization—may reflect different stages of event model updating. The engagement of multiple brain regions at different time points also suggests that event segmentation may involve several distinct cognitive processes, each potentially implemented by different brain networks. This possibility sets the stage for our subsequent investigation of two potential event model updating control mechanisms: error-driven updating and uncertainty-driven updating. By examining the neural correlates of error-driven and uncertainty-driven updating separately, we can potentially identify dissociable neural mechanisms underlying human event segmentation.</p>
</sec>
<sec id="s2c">
<title>Error-driven boundaries and uncertainty-driven boundaries uniquely predict human boundaries</title>
<p>To investigate error-driven and uncertainty-driven event segmentation, we developed two computational models—one in which event model updating is triggered by an increase in prediction error and another in which event model updating is triggered by an increase in prediction uncertainty (<xref ref-type="bibr" rid="c31">Nguyen et al., 2024</xref>). The models generated error-driven or uncertainty-driven boundaries (see Methods). Discrete human and model event boundaries were transformed into boundary densities by applying a Gaussian density kernel (bandwidth = 4.45 seconds). Model-derived boundary densities were then employed to jointly predict human boundary density (see Methods), an analysis not performed in the previous work (<xref ref-type="bibr" rid="c31">Nguyen et al., 2024</xref>). This analysis revealed that boundary densities from both uncertainty-driven and error-driven models uniquely predicted human boundary density (t-statistics are 14.32 and 5.14 respectively, p &lt; .001, df = 1636), even though error-driven boundary density is correlated with uncertainty-driven boundary density (mean correlation: 0.499, 95% CI: [0.401, 0.607]). This finding suggests that humans might rely on both types of prediction quality signals – errors in prediction and uncertainty about predictions – when segmenting events in continuous experience. Quantitatively, the combination of error-driven and uncertainty-driven boundaries explained approximately 20% of the variance in human-identified boundaries. To contextualize this result, human behavioral boundary identification typically has a reliability of approximately 0.6, which sets an upper limit of 36% for explainable variance. The relatively high explained variance suggests that our model-estimated error-driven and uncertainty-driven boundaries are good candidates for representing human error-driven and uncertainty-driven event updating processes. Model boundary densities and human boundary densities for four videos are depicted in <xref rid="fig5" ref-type="fig">Figure 5</xref>; boundary density peaks were used for all Finite Impulse Response analyses (see Methods). Based on these findings, we proceeded to use our model-estimated error-driven and uncertainty-driven boundaries as proxies for human cognitive processes in subsequent analyses. This approach allows us to investigate the neural correlates of error-driven and uncertainty-driven event segmentation separately, potentially revealing distinct brain networks associated with these two complementary processes.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5:</label>
<caption><title>Error-model, uncertainty-model, and human boundary density and peaks in the four movie stimuli.</title>
<p>Error-model boundary density and uncertainty-model boundary density both uniquely predict human boundary density. Boundary peaks were used for all FIR analyses.</p></caption>
<graphic xlink:href="663487v1_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2d">
<title>Error-driven and uncertainty-driven boundaries are associated with distinct brain networks and temporal dynamics</title>
<p>Building on the observation that human-identified boundaries are associated with pattern shifts in prefrontal, parietal, and temporal regions, and on our hypothesis that these regions might be responsible for distinct event model updating mechanisms, we sought to disentangle the neural correlates of error-driven and uncertainty-driven event model updating. Our first aim was to identify whether two qualitatively different types of boundaries are linked to pattern shifting and stabilization in overlapping or distinct brain areas. Thus, for each brain parcel, we fitted two FIR models to predict pattern dissimilarity: one using only error-driven boundaries and another using only uncertainty-driven boundaries, and compared their performance.</p>
<p>This analysis revealed a dissociation between brain regions showing significant (FDR with alpha &lt; 0.001, corrected-p-value &lt; 0.001) neural pattern shift or stabilization around error-driven versus uncertainty-driven boundaries (<xref rid="fig6" ref-type="fig">Figure 6</xref>). Regions exhibiting strong neural pattern shift or stabilization around error-driven boundaries included the ventrolateral PFC (<xref rid="fig6" ref-type="fig">Figure 6</xref>, reddish regions). Regions exhibiting strong neural pattern shift or stabilization around uncertainty-driven boundaries included the postcentral gyrus, particularly those associated with the dorsal attention network, areas in the mid cingulate cortex associated with the ventral attention network, and areas within the visual network (<xref rid="fig6" ref-type="fig">Figure 6</xref>, blueish regions). Regions exhibiting strong neural pattern shift or stabilization around both types of boundaries included the medial PFC and temporal components of the default network (<xref rid="fig6" ref-type="fig">Figure 6</xref>, magenta regions). These results reveal distinct brain networks whose neural pattern shifted or stabilized around error-driven or uncertainty-driven boundaries, each partially aligning with regions showing neural pattern shift or stabilization around human boundaries (<xref rid="fig3" ref-type="fig">Figure 3</xref>). The identification of two dissociable sets of brain regions associated with each boundary type, and the finding that both sets partially overlapped with regions involved in human-identified boundaries, suggests that both error-driven and uncertainty-driven signals play roles in event model updating. This neural evidence corroborates and extends the behavioral findings that both types of boundaries uniquely predict human-identified boundaries.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6:</label>
<caption><title>Regions showing significant (corrected p &lt; 0.001) changes in pattern dissimilarity relative to estimated baseline dissimilarity for error-driven and/or uncertainty-driven boundaries.</title>
<p>Regions in red show stronger changes in pattern dissimilarity relative to estimated baseline pattern dissimilarity for error-driven boundaries, while regions in blue show stronger changes in pattern dissimilarity relative to estimated baseline pattern dissimilarity for uncertainty-driven boundaries, and regions in magenta show strong changes in pattern dissimilarity for both boundary types.</p></caption>
<graphic xlink:href="663487v1_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Next, we investigated the time-course of changes in pattern dissimilarity around error-driven and uncertainty-driven boundaries, estimated by the same two FIR models as used in previous analyses. This analysis is crucial for understanding the temporal sequence of cognitive processes involved in event segmentation and how they might differ between these two mechanisms. It revealed distinct spatial and temporal changes in pattern dissimilarity, which partially overlap with the changes observed for human-identified boundaries discussed previously. Some regions showed early pre-boundary (−11.9s) neural pattern shifts: For error-driven boundaries, increased pattern dissimilarity was observed in the ventrolateral PFC, which is part of the control network (<xref rid="fig7" ref-type="fig">Figure 7A</xref>, top). For uncertainty-driven boundaries, we observed increased pattern dissimilarity (indicating pattern shifts) in temporal areas and the PFC (<xref rid="fig7" ref-type="fig">Figure 7B</xref>, top). These early pattern shifts associated with error-driven and uncertainty-driven boundaries corresponded to subcomponents of the early shifts observed before human-identified boundaries (<xref rid="fig4" ref-type="fig">Figure 4</xref>, top). Another group of regions showed immediate pre-boundary (−4.5s) pattern shifts: error-driven boundaries were associated with increased pattern dissimilarity primarily in the left ventrolateral PFC and anterior temporal pole (<xref rid="fig7" ref-type="fig">Figure 7A</xref>, middle). Uncertainty-driven boundaries were associated with increased pattern dissimilarity in parietal areas, occipital areas, temporal areas, and prefrontal areas, with strong shifts in regions within the dorsal attention network (<xref rid="fig7" ref-type="fig">Figure 7B</xref>, middle). These pattern shifts for uncertainty-driven boundaries corresponded to our second observation from human boundaries, for which parietal regions showed significant pattern shifts (<xref rid="fig4" ref-type="fig">Figure 4</xref>, middle). Finally, many regions showed post-boundary (+11.8s) pattern stabilization: error-driven boundaries were followed by widespread decreases in pattern dissimilarity in prefrontal, temporal, and occipital parcels, with strongest stabilization in the prefrontal cortex (<xref rid="fig7" ref-type="fig">Figure 7A</xref>, bottom). The pattern stabilization following error-driven boundaries corresponds with our third observation from human boundaries, where pattern stabilization was strongest for the PFC (<xref rid="fig4" ref-type="fig">Figure 4</xref>, bottom). For uncertainty-driven boundaries, we only observed decreased pattern dissimilarity in part of the medial PFC (<xref rid="fig7" ref-type="fig">Figure 7B</xref>, bottom).</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7:</label>
<caption><title>Changes in pattern dissimilarity relative to baseline dissimilarity around boundaries identified by (A) error-driven model and (B) uncertainty-driven model.</title>
<p>Brain surface maps show deviations from baseline pattern dissimilarity (orange: increased dissimilarity/pattern shifts; blue: decreased dissimilarity/pattern stabilization). Line plots for selected regions show pattern dissimilarity over time, with baseline dissimilarity levels indicated by horizontal blue (uncertainty-driven) or red (error-driven) lines (shades indicate plus and minus 2 standard errors). Higher dissimilarity values reflect greater pattern shifts, while lower dissimilarity values indicate more stable patterns. Parcel labels followed the Schaefer 400×7 parcellation atlas (<xref ref-type="bibr" rid="c37">Schaefer et al., 2018</xref>). At early pre-boundary (−11.9s), error-driven boundaries corresponded to increased pattern dissimilarity primarily in ventrolateral PFC, while uncertainty-driven boundaries corresponded to more widespread pattern shifts in temporal areas, dorsomedial and dorsolateral prefrontal regions, and anterior temporal cortex. At immediate pre-boundary (−4.5s), error-driven boundaries corresponded to pattern shifts predominantly in the left ventrolateral PFC and anterior temporal pole, whereas uncertainty-driven boundaries corresponded to more extensive pattern shifts across parietal, occipital, temporal, and prefrontal areas, particularly strong within the dorsal attention network. At post-boundary timepoints (+11.8s), error-driven boundaries corresponded to widespread pattern stabilization (decreased dissimilarity) across prefrontal, temporal, and occipital areas with strongest effects in prefrontal cortex, while uncertainty-driven boundaries show limited pattern stabilization restricted primarily to portions of the medial PFC. Brain maps and pattern dissimilarity around error-driven boundaries or uncertainty-driven boundaries for all parcels can be found at <ext-link ext-link-type="uri" xlink:href="https://openneuro.org/datasets/ds005551">https://openneuro.org/datasets/ds005551</ext-link> under derivatives/figures/brain_maps_and_timecourses/ directory.</p></caption>
<graphic xlink:href="663487v1_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The above analysis revealed shared brain regions whose changes in pattern dissimilarity were associated with both error-driven and uncertainty-driven boundaries (magenta regions in <xref rid="fig6" ref-type="fig">Figure 6</xref>). Although these two boundary types evoked neural pattern shift or stabilization in overlapping brain regions, they may drive distinct temporal dynamics of pattern shift and stabilization. To test this hypothesis, for each parcel that showed significant changes in pattern dissimilarity for both boundary types (FDR with alpha &lt; 0.001, corrected-p-value &lt; 0.001 for both error-driven and uncertainty-driven FIR models), we computed correlations between pattern dissimilarity timecourses for error-driven and uncertainty-driven boundaries and compared them against a null distribution. This null distribution was constructed from within-boundary-type correlations, using bootstrapped timecourses for both error-driven and uncertainty-driven boundaries separately. The resulting z-statistic maps (<xref rid="fig8" ref-type="fig">Figure 8</xref>) revealed statistically significant (FDR with alpha &lt; 0.001, corrected-p-value &lt; 0.001) differences in temporal dynamics between the two boundary types, particularly in prefrontal and temporal regions. For example, two parcels in the left medial PFC (LH_Default_PFCm_4) and in the right anterior temporal pole (RH_Default_Temp_1), whose changes in pattern dissimilarity were associated with both error-driven and uncertainty-driven boundaries, had different temporal dynamics for each boundary type (<xref rid="fig7" ref-type="fig">Figure 7A</xref> middle and 7B top). This result suggests that even though error-driven and uncertainty-driven event model updating were associated with the same brain regions, the two updating mechanisms were associated with distinct temporal dynamics of pattern shift and stabilization in these shared regions.</p>
<fig id="fig8" position="float" orientation="portrait" fig-type="figure">
<label>Figure 8:</label>
<caption><title>Comparison of pattern dissimilarity timecourses between error-driven and uncertainty-driven boundaries.</title>
<p>Z-statistics maps show regions where pattern dissimilarity timecourses differ between the two boundary types, with higher values (more orange) indicating stronger differences in temporal dynamics. The most pronounced differences observed in the prefrontal cortex, posterior parietal regions, and portions of the temporal cortex.</p></caption>
<graphic xlink:href="663487v1_fig8.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Humans and other animals navigate a world that is complex and dynamic, but that is also characterized by stable dynamical regimes during which sequential activity is predictable. To cope with the complexity of experience and to leverage the intervals of predictability, the nervous system constructs stable models of the current situation on a hierarchy of timescales from seconds to tens of minutes (<xref ref-type="bibr" rid="c3">Baldassano et al., 2017</xref>; <xref ref-type="bibr" rid="c26">Hasson et al., 2015</xref>; <xref ref-type="bibr" rid="c35">Richmond &amp; Zacks, 2017</xref>). The present study addressed a central question about these event models: What control mechanism determines when they are updated?</p>
<p>We first characterized the neural signatures of human event segmentation by examining both univariate activity changes and multivariate pattern changes around subjectively identified event boundaries. Using multivariate pattern dissimilarity, we observed a structured progression of neural reconfiguration surrounding human-identified event boundaries. Roughly 12 seconds prior to event boundaries, the first detectable neural pattern shifts occurred in anterior temporal regions, followed by shifts in dorsal attention and parietal regions closer to the boundary (about 4.5 seconds before). Then, in the period after a boundary (around +12 seconds), we found widespread stabilization of neural patterns across the brain, suggesting the establishment of a new event model.</p>
<p>We then took a computational cognitive neuroscience approach to disentangle the contributions of two potential updating mechanisms—prediction error and prediction uncertainty—in driving event model updating. Building on the theoretical framework proposed by <xref ref-type="bibr" rid="c4">Baldwin and Kosie (2021)</xref>, we developed two computational models to generate boundaries driven by prediction error or prediction uncertainty. Both models uniquely explained variance in human boundary judgments. Together, these model-derived boundaries explained approximately 20% of the variance in human judgments—a substantial proportion given that the theoretical maximum explainable variance is limited to 36% based on the reliability of human boundary identification. This result provides evidence that both prediction error and prediction uncertainty contribute to how observers parse ongoing experience into events. More importantly, error-driven and uncertainty-driven boundaries were associated with distinct brain networks exhibiting different temporal dynamics. Error-driven boundaries were linked to early neural pattern shifts in ventrolateral prefrontal areas, followed by pronounced pattern stabilization in prefrontal and temporal regions. In contrast, uncertainty-driven boundaries were associated with pattern shifts in across wide areas of the brain, especially in parietal regions within the dorsal attention network, and with minimal subsequent stabilization in part of the medial PFC. Interestingly, both boundary types evoked pattern shifts in overlapping regions within the default network, but with different temporal dynamics. The dissociations in both spatial and temporal neural signatures provide evidence for the theoretical distinction proposed by <xref ref-type="bibr" rid="c4">Baldwin and Kosie (2021)</xref>, that humans rely on both prediction error and prediction uncertainty to parse continuous activities into meaningful events. Our findings suggest that event segmentation is supported by two separate but complementary brain networks, each responsive to a different prediction quality signal. This dual-network architecture represents a significant advancement in our understanding of event segmentation, extending the claim of EST that declines in prediction quality trigger event model updating (<xref ref-type="bibr" rid="c45">Zacks et al. 2007</xref>) to encompass these two aspects of prediction quality: accuracy and certainty.</p>
<p>Previous studies using HMMs (<xref ref-type="bibr" rid="c3">Baldassano et al., 2017</xref>) and GSBS (<xref ref-type="bibr" rid="c22">Geerligs et al., 2021</xref>, <xref ref-type="bibr" rid="c21">2022</xref>) have identified neural state boundaries in multimodal regions that align closely with subjectively perceived event boundaries. Consistent with these findings, our multivariate analyses also reveal pattern shifts around human boundaries in regions previously identified, including areas within the default mode network (medial prefrontal cortex, posterior cingulate cortex, and anterior temporal regions) and dorsal attention network. Despite the advances made in this study, several limitations and open questions remain. Although our computational models successfully captured a substantial portion of variance in human boundary judgments, approximately 16% of the explainable variance remains unaccounted for. This suggests that additional mechanisms beyond prediction error and prediction uncertainty may contribute to event segmentation. One candidate mechanism comes from latent cause inference models (Kuperberg, 2021; Shin &amp; DuBrow, 2021). Whereas <xref ref-type="bibr" rid="c45">Zacks et al. (2007)</xref> and <xref ref-type="bibr" rid="c4">Baldwin and Kosie (2021)</xref> assume the cognitive system maintains an event model and uses prediction error or prediction uncertainty from that model to segment events, latent cause inference models start from a different assumption. These models posit that the cognitive system monitors a probability distribution over unobservable latent causes that are most likely to generate current sensory observations. Event boundaries in this framework correspond to moments of high uncertainty over which latent cause is currently active. Future studies could develop computational models based on latent cause inference principles and compare their neural signatures with those of error-driven and uncertainty-driven boundaries identified in our study.</p>
<p>Although our error-driven and uncertainty-driven models segmented and categorized continuous experience in a manner that aligns with human behavior (<xref ref-type="bibr" rid="c31">Nguyen et al., 2024</xref>), the correspondence is far from perfect. Consequently, the event boundaries identified by these two models might not fully capture the actual error-driven and uncertainty-driven processes that humans employ. The current evidence for more than one model updating mechanism opens the door for an architecture in which a handful of different triggers may govern different components of event model updating. Such an architecture would be inelegant—but evolution’s engineering solutions are sometimes complex and kludgy rather than simple and sleek.</p>
<p>In conclusion, this study provides behavioral and neural evidence for two overlapping brain networks that maintain and update representations of the environment, controlled by either prediction error or prediction uncertainty. Error-driven boundaries were uniquely associated with representational shifts in ventrolateral prefrontal cortex and subsequent pattern stabilization in temporal and prefrontal areas. Uncertainty-driven boundaries were uniquely linked to representational shifts in dorsal attention network with minimal subsequent stabilization. Both boundary types were associated with pattern shifts in regions within the default mode network, such as medial PFC and temporal areas, which have previously been hypothesized to maintain and update event representations. By identifying the neural correlates of theoretically distinct updating mechanisms, these results form a basis for an integrative account of the computational and neurophysiological aspects of how the brain maintains stable representations of complex everyday activity.</p>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Human and model segmentation</title>
<p>Human event boundaries for four activities were obtained from a norming study in which 30 online participants (from Mechanical Turk) watched each activity and marked event boundaries (<xref ref-type="bibr" rid="c8">Bezdek et al., 2022</xref>). Error-driven boundaries and uncertainty-driven boundaries were generated by two computational models developed previously (<xref ref-type="bibr" rid="c31">Nguyen et al., 2024</xref>). Both models maintain an active event representation that continuously predicts how activity will unfold. The error-driven model triggers event boundary detection when prediction error— operationalized as the Euclidean distance between observed and predicted scene vectors— exceeds a threshold. In contrast, the uncertainty-driven model triggers event boundary detection based on prediction uncertainty, conceptualized as epistemic uncertainty that reflects the model’s confidence in its own predictions given its current knowledge state. This prediction uncertainty is computed by generating 32 different predictions using random dropout on the model weights and measuring the variance across these predictions (<xref ref-type="bibr" rid="c20">Gal &amp; Ghahramani, 2016</xref>; <xref ref-type="bibr" rid="c27">Kendall &amp; Gal, 2017</xref>). When their respective thresholds are exceeded, each model initiates an inference process to evaluate alternative event representations. Event boundaries are identified at moments when this inference process results in a switch from one event representation to another, reflecting the model’s decision that the current event representation no longer adequately captures ongoing activity. To account for model random initialization, we ran 16 simulations for each model, and we used event boundaries from all 16 simulations. To analyze the relationships between the three kinds of boundaries, we applied a Gaussian kernel density function (bandwidth = 4.45 seconds) on the human, error-driven, and uncertainty-driven event boundaries to obtain continuous event boundary densities. In later analyses, error-driven and uncertainty-driven boundary densities were used as continuous predictors of the normed human boundary density.</p>
<p>To model the effects of human and model event boundaries on fMRI magnitude and pattern dissimilarity, we identified normative boundaries by selecting peaks in the event boundary densities. To identify peaks from continuous boundary densities, we ran a greedy algorithm to iteratively select one peak at a time with the highest density value, with a condition that the current peak is more than 7 seconds away from already selected peaks. The number of peaks for each movie was set to the median number of boundaries identified by the Bezdek (2022) study participants for each movie (<xref rid="fig5" ref-type="fig">Figure 5</xref>). These peaks were used in the Finite Impulse Response analyses as reference points, such that each “trial” in the analysis represented a window around the event boundary (see below).</p>
</sec>
<sec id="s4b">
<title>Imaging Session</title>
<sec id="s4b1">
<title>fMRI Participants</title>
<p>Imaging data were collected from 47 participants (age mean=23.3 years, SD=4.3, range 18-35; 32 female). Their self-reported demographic groupings were 14 Asian, 2 Black/African-American, 26 white (5 Hispanic/Latino), and 5 More Than One Race. Imaging data from two additional participants (both white males, one Hispanic/Latino, 19 and 23 years) could not be obtained (equipment failure, incidental finding) and are not included here. All participants were right-handed, fluent English speakers, and without MRI safety contraindications or neurological impairments. Participants provided written informed consent in accordance with the Institutional Review Board at Washington University in St. Louis, and received $125 compensation for completion of all sessions.</p>
</sec>
<sec id="s4b2">
<title>Acquisition parameters</title>
<p>All scans were acquired using a 3T Siemens Prisma with a 64-channel head coil in the East Building MR Facility of the Washington University Medical Center, between May 2021 and May 2022. Imaging files were sent from the scanner to the Washington University Central Neuroimaging Data Archive (<xref ref-type="bibr" rid="c25">Gurney, 2017</xref>) XNAT (RRID:SCR_003048) database for permanent archiving. FIRMM (<xref ref-type="bibr" rid="c14">Dosenbach et al., 2017</xref>) was used to monitor participant motion throughout the imaging session. Scan duration was not modified by FIRMM, but if it indicated excessive movement the experimenter notified the participant and repositioned them, as needed.</p>
<p>Each imaging session began with T1 and T2-weighted high-resolution ABCD MPRAGE+PMC structural scans (T1: 1 mm isotropic voxels; 2.5 s TR, 2.9 msec TE, 1.07 s TI, 8° flip angle; T2: 1 mm isotropic voxels; 3.2 s TR, 0.565 s TE, 120° flip angle), followed by four functional task runs. The functional (BOLD, blood oxygenation level dependent) scans were acquired with CMRR multiband sequences (University of Minnesota Center for Magnetic Resonance Research) (<xref ref-type="bibr" rid="c18">Feinberg et al., 2010</xref>; <xref ref-type="bibr" rid="c42">Xu et al., 2013</xref>), multiband (simultaneous multislice; SMS) factor 4, without in-plane acceleration (iPat = none), resulting in 2.08 mm isotropic voxels, 1.483 s TR (TE 37 msec, flip angle 52°; protocol sheets at <ext-link ext-link-type="uri" xlink:href="https://openneuro.org/datasets/ds005551">https://openneuro.org/datasets/ds005551</ext-link> under derivatives/ Scanning_parameters_NP1157new_May8_2021.pdf). All functional runs were collected with Anterior to Posterior (“AP”) encoding direction, and proceeded by a pair (AP, PA) of spin echo field maps and a single-band reference (“SBRef”) image.</p>
</sec>
<sec id="s4b3">
<title>Task runs</title>
<p>All participants completed four task fMRI runs, each of which consisted of watching a silent video. The four video stimuli (and accompanying normative event boundaries used for later analyses) are from the Multi-angle Extended Three-dimensional Activity (META) stimulus set (<xref ref-type="bibr" rid="c8">Bezdek et al., 2022</xref>). Each video depicts a different actor carrying out different everyday activities (exercising, cleaning a room, making breakfast, bathroom grooming), all filmed from a fixed camera position.</p>
<p>A different video was shown in each fMRI run, with all participants viewing the same four videos in the same order (<xref rid="tbl1" ref-type="table">Table 1</xref>). Participants were instructed, “As you watch, please pay attention and try to remember what occurs, as your memory will be tested later.” A brief (8-11 second) fixation cross proceeded the start of each film and reappeared when the film completed.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><title>Video stimuli characteristics and fMRI scanning parameters for each run</title></caption>
<graphic xlink:href="663487v1_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s4b4">
<title>Image processing</title>
<p>Image preprocessing was performed by <italic>fMRIPrep</italic> 20.2.3 (<xref ref-type="bibr" rid="c51">Esteban, Markiewicz, et al. (2018)</xref>; <xref ref-type="bibr" rid="c50">Esteban, Blair, et al. (2018)</xref>; RRID:SCR_016216), which is based on <italic>Nipype</italic> 1.6.1 (<xref ref-type="bibr" rid="c53">Gorgolewski et al. (2011)</xref>; <xref ref-type="bibr" rid="c54">Gorgolewski et al. (2018)</xref>; RRID:SCR_002502); boilerplate text at Supplemental Information. Both the preprocessed images (spatially normalized to the MNI152NLin2009cAsym template) and realignment parameters (_desc-confounds_timeseries.tsv) were used in later analyses. Image quality was evaluated by reviewing temporal mean and standard deviation images (<xref ref-type="bibr" rid="c17">Etzel, 2023</xref>) and deemed acceptable in all participants. Frames with more than 0.5 mm FD were censored. Participants were retained only if more than half their data was usable; two participants had two or more runs at the 20% censoring threshold and so were dropped from analysis. Quality control summary files are available at <ext-link ext-link-type="uri" xlink:href="https://openneuro.org/datasets/ds005551">https://openneuro.org/datasets/ds005551</ext-link> under derivatives/QCKnitrs/ directory.</p>
<p>Preprocessed fMRI data was further processed by regressing drifts (linear, polynomial, and cubic) and 6 motion confounds from every voxel BOLD timeseries. Next, a standard parcellation was used: the Schaefer 400 parcels (17-network labels) for cortex (<xref ref-type="bibr" rid="c37">Schaefer et al., 2018</xref>). All analyses were performed at the parcel-level. All voxel BOLD timeseries were shifted by 4 TR (approximately 5.93s) to account for hemodynamic lag.</p>
</sec>
</sec>
<sec id="s4c">
<title>Parcel BOLD activity and parcel pattern dissimilarity</title>
<p>To quantify parcel BOLD activity we averaged across all voxels in every parcel, resulting in a single value for each parcel in each timepoint (TR) of the four functional runs.</p>
<p>To quantify parcel neural pattern shifts, we calculated temporal pattern dissimilarity for each brain parcel using the Schaefer 400-parcel atlas (<xref ref-type="bibr" rid="c37">Schaefer et al., 2018</xref>). For each timepoint (TR t), we computed the dissimilarity between patterns before and after that timepoint. Specifically, we first created stable pattern representations by averaging voxel activities across three consecutive TRs preceding the timepoint (TRs t-3, t-2, and t-1) and three consecutive TRs following the timepoint (TRs t+1, t+2, and t+3). This average approach reduces noise inherent in single-TR measurements. We then calculated the Pearson correlation between these two averaged patterns and subtracted the correlation value from 1 to obtain a dissimilarity measure.</p>
</sec>
<sec id="s4d">
<title>Finite impulse response analysis</title>
<p>For each parcel, we employed finite impulse response (FIR) analysis to examine the temporal dynamics of BOLD activity (average across voxels) and pattern shifts around event boundaries. The FIR model is a flexible extension of the general linear model (GLM) commonly used in fMRI analysis. Whereas GLM approaches to fMRI modeling often assume a fixed hemodynamic response function (HRF), the FIR model makes no assumptions about the shape of the response, instead estimating separate coefficients for each time point (lag) relative to event boundaries. This approach is particularly valuable for investigating neural responses to event boundaries, where the temporal profile may differ from canonical HRF shapes and vary across brain regions. In our study, there were three types of boundary: human-annotated boundaries, and computationally derived boundaries(error-driven and uncertainty-driven models). We constructed separate FIR models for each boundary type, allowing us to compare how different types of event segmentation relate to brain responses in different parcels. This approach enabled us to distinguish between neural responses associated with computationally derived error-driven versus uncertainty-driven boundaries.</p>
<p>Individual FIR models were fit for each subject (first-level analysis) to estimate coefficients for each time lag relative to each type of boundary onsets. There were 10 time lags before the event boundary and 20 time lags after the event boundary, and successive time lags are 1.483 seconds apart (1 TR). FIR models were applied separately to both BOLD activity and pattern dissimilarity measures. After first-level analysis, we performed second-level analysis across subjects. Z-statistics were calculated by comparing the full FIR model to an intercept-only model that assumed no changes in BOLD activity or pattern dissimilarity in response to boundaries. These z-statistics were used to identify brain regions that showed significant BOLD activity changes and/or pattern shifts in response to different boundary types. Instead of considering only across-subject variance when estimating standard errors for coefficients, we incorporated both within-subject and across-subject variance components to better estimate the standard errors associated with coefficients at different lags. The custom R code to estimate both within-subject and across-subject variance is available at: <ext-link ext-link-type="uri" xlink:href="https://openneuro.org/datasets/ds005551">https://openneuro.org/datasets/ds005551</ext-link> under derivatives/scripts/fir_analyses.Rmd.</p>
</sec>
</sec>
</body>
<back>
<sec id="s7">
<title>Supplemental Information</title>
<sec id="s7a">
<title>fMRIprep boilerplate</title>
<sec id="s7a1">
<title>Anatomical data preprocessing</title>
<p>A total of 1 T1-weighted (T1w) images were found within the input BIDS dataset. The T1-weighted (T1w) image was corrected for intensity non-uniformity (INU) with N4BiasFieldCorrection (<xref ref-type="bibr" rid="c61">Tustison et al. 2010</xref>), distributed with ANTs 2.3.3 (<xref ref-type="bibr" rid="c47">Avants et al. 2008</xref>, RRID:SCR_004757), and used as T1w-reference throughout the workflow. The T1w-reference was then skull-stripped with a <italic>Nipype</italic> implementation of the antsBrainExtraction.sh workflow (from ANTs), using OASIS30ANTs as target template. Brain tissue segmentation of cerebrospinal fluid (CSF), white-matter (WM) and gray-matter (GM) was performed on the brain-extracted T1w using fast (FSL 5.0.9, RRID:SCR_002823, <xref ref-type="bibr" rid="c62">Zhang, Brady, and Smith 2001</xref>). Volume-based spatial normalization to one standard space (MNI152NLin2009cAsym) was performed through nonlinear registration with antsRegistration (ANTs 2.3.3), using brain-extracted versions of both T1w reference and the T1w template. The following template was selected for spatial normalization: <italic>ICBM 152 Nonlinear Asymmetrical template version 2009c</italic> [<xref ref-type="bibr" rid="c52">Fonov et al. (2009)</xref>, RRID:SCR_008796; TemplateFlow ID: MNI152NLin2009cAsym].</p>
</sec>
<sec id="s7a2">
<title>Functional data preprocessing</title>
<p>For each of the 4 BOLD runs found per subject (across all tasks and sessions), the following preprocessing was performed. First, a reference volume and its skull-stripped version were generated by aligning and averaging 1 single-band references (SBRefs). Susceptibility distortion correction (SDC) was omitted. The BOLD reference was then co-registered to the T1w reference using flirt (FSL 5.0.9, <xref ref-type="bibr" rid="c57">Jenkinson and Smith 2001</xref>) with the boundary-based registration (<xref ref-type="bibr" rid="c55">Greve and Fischl 2009</xref>) cost-function. Co-registration was configured with nine degrees of freedom to account for distortions remaining in the BOLD reference. Head-motion parameters with respect to the BOLD reference (transformation matrices, and six corresponding rotation and translation parameters) are estimated before any spatiotemporal filtering using mcflirt (FSL 5.0.9, <xref ref-type="bibr" rid="c56">Jenkinson et al. 2002</xref>). BOLD runs were slice-time corrected using 3dTshift from AFNI 20160207 (<xref ref-type="bibr" rid="c49">Cox and Hyde 1997</xref>, RRID:SCR_005927). First, a reference volume and its skull-stripped version were generated using a custom methodology of <italic>fMRIPrep</italic>. The BOLD time-series (including slice-timing correction when applied) were resampled onto their original, native space by applying the transforms to correct for head-motion. These resampled BOLD time-series will be referred to as <italic>preprocessed BOLD in original space</italic>, or just <italic>preprocessed BOLD</italic>. The BOLD time-series were resampled into standard space, generating a <italic>preprocessed BOLD run in MNI152NLin2009cAsym space</italic>. First, a reference volume and its skull-stripped version were generated using a custom methodology of <italic>fMRIPrep</italic>. Several confounding time-series were calculated based on the <italic>preprocessed BOLD</italic>: framewise displacement (FD), DVARS and three region-wise global signals. FD was computed using two formulations following Power (absolute sum of relative motions, <xref ref-type="bibr" rid="c59">Power et al. (2014)</xref>) and Jenkinson (relative root mean square displacement between affines, <xref ref-type="bibr" rid="c56">Jenkinson et al. (2002)</xref>). FD and DVARS are calculated for each functional run, both using their implementations in <italic>Nipype</italic> (following the definitions by <xref ref-type="bibr" rid="c59">Power et al. 2014</xref>). The three global signals are extracted within the CSF, the WM, and the whole-brain masks. Additionally, a set of physiological regressors were extracted to allow for component-based noise correction (<italic>CompCor</italic>, <xref ref-type="bibr" rid="c48">Behzadi et al. 2007</xref>). Principal components are estimated after high-pass filtering the <italic>preprocessed BOLD</italic> time-series (using a discrete cosine filter with 128s cut-off) for the two <italic>CompCor</italic> variants: temporal (tCompCor) and anatomical (aCompCor). tCompCor components are then calculated from the top 2% variable voxels within the brain mask. For aCompCor, three probabilistic masks (CSF, WM and combined CSF+WM) are generated in anatomical space. The implementation differs from that of Behzadi et al. in that instead of eroding the masks by 2 pixels on BOLD space, the aCompCor masks are subtracted a mask of pixels that likely contain a volume fraction of GM. This mask is obtained by thresholding the corresponding partial volume map at 0.05, and it ensures components are not extracted from voxels containing a minimal fraction of GM. Finally, these masks are resampled into BOLD space and binarized by thresholding at 0.99 (as in the original implementation). Components are also calculated separately within the WM and CSF masks. For each CompCor decomposition, the <italic>k</italic> components with the largest singular values are retained, such that the retained components’ time series are sufficient to explain 50 percent of variance across the nuisance mask (CSF, WM, combined, or temporal). The remaining components are dropped from consideration. The head-motion estimates calculated in the correction step were also placed within the corresponding confounds file. The confound time series derived from head motion estimates and global signals were expanded with the inclusion of temporal derivatives and quadratic terms for each (<xref ref-type="bibr" rid="c60">Satterthwaite et al. 2013</xref>). Frames that exceeded a threshold of 0.5 mm FD or 1.5 standardised DVARS were annotated as motion outliers. All resamplings can be performed with <italic>a single interpolation step</italic> by composing all the pertinent transformations (i.e. head-motion transform matrices, susceptibility distortion correction when available, and co-registrations to anatomical and output spaces). Gridded (volumetric) resamplings were performed using antsApplyTransforms (ANTs), configured with Lanczos interpolation to minimize the smoothing effects of other kernels (<xref ref-type="bibr" rid="c58">Lanczos 1964</xref>). Non-gridded (surface) resamplings were performed using mri_vol2surf (FreeSurfer).</p>
<p>Many internal operations of <italic>fMRIPrep</italic> use <italic>Nilearn</italic> 0.6.2 (<xref ref-type="bibr" rid="c46">Abraham et al. 2014</xref>, RRID:SCR_001362), mostly within the functional processing workflow. For more details of the pipeline, see <ext-link ext-link-type="uri" xlink:href="https://fmriprep.readthedocs.io/en/latest/workflows.html">the section corresponding to workflows in <italic>fMRIPrep</italic>’s documentation</ext-link>.</p>
</sec>
<sec id="s7a3">
<title>Copyright Waiver</title>
<p>The above boilerplate text was automatically generated by fMRIPrep with the express intention that users should copy and paste this text into their manuscripts <italic>unchanged</italic>. It is released under the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/">CC0</ext-link> license.</p>
</sec>
</sec>
</sec>
<ack>
<title>Acknowledgements</title>
<p>The authors would like to thank Sarah Morse and Grace Zhou for fMRI data collection, Todd S. Braver for helpful feedback on data analyses, Hayoung Song for feedback on the manuscript, and the members of the Dynamic Cognition Laboratory for their thoughtful input.</p>
</ack>
<sec id="s5">
<title>Additional information</title>
<sec id="s5a">
<title>Funding</title>
<table-wrap id="utbl1" orientation="portrait" position="float">
<graphic xlink:href="663487v1_utbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s5b">
<title>Author Contributions</title>
<p>T.T.N.: conceptualization, data curation, formal analysis, investigation, methodology, visualization, writing—original draft, writing—review &amp; editing. M.A.B.: conceptualization, data curation, formal analysis, investigation, methodology, visualization. J.E.B.: conceptualization, data curation, formal analysis, investigation, methodology, visualization, writing—review &amp; editing. J.M.Z.: conceptualization, funding acquisition, project administration, supervision, writing—review &amp; editing.</p>
</sec>
<sec sec-type="data-availability" id="das21">
<title>Data Availability</title>
<p>BIDS data for this project can be found at <ext-link ext-link-type="uri" xlink:href="https://openneuro.org/datasets/ds005551">https://openneuro.org/datasets/ds005551</ext-link> under sub-&lt;participant_id&gt; directories.</p>
<p>All the data and analysis scripts used for this project can be found at <ext-link ext-link-type="uri" xlink:href="https://openneuro.org/datasets/ds005551">https://openneuro.org/datasets/ds005551</ext-link> under derivatives/scripts/ directory.</p>
</sec>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Anderson</surname>, <given-names>R. C.</given-names></string-name></person-group> (<year>1978</year>). <chapter-title>Schema-Directed Processes in Language Comprehension</chapter-title>. In <person-group person-group-type="editor"><string-name><surname>Lesgold</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Pellegrino</surname>, <given-names>J. W.</given-names></string-name>, <string-name><surname>Fokkema</surname>, <given-names>S. D.</given-names></string-name>, <string-name><surname>Glaser</surname>, <given-names>R.</given-names></string-name></person-group> <source>Cognitive Psychology and Instruction</source> (pp. <fpage>67</fpage>–<lpage>82</lpage>). <publisher-name>Springer US</publisher-name>. <pub-id pub-id-type="doi">10.1007/978-1-4684-2535-2_8</pub-id></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bailey</surname>, <given-names>H. R.</given-names></string-name>, &amp; <string-name><surname>Zacks</surname>, <given-names>J. M</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Situation Model Updating in Young and Older Adults: Global versus Incremental Mechanisms</article-title>. <source>Psychology and Aging</source>, <volume>30</volume>(<issue>2</issue>), <fpage>232</fpage>–<lpage>244</lpage>. <pub-id pub-id-type="doi">10.1037/a0039081</pub-id></mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Baldassano</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Zadbood</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Pillow</surname>, <given-names>J. W.</given-names></string-name>, <string-name><surname>Hasson</surname>, <given-names>U.</given-names></string-name>, &amp; <string-name><surname>Norman</surname>, <given-names>K. A</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Discovering Event Structure in Continuous Narrative Perception and Memory</article-title>. <source>Neuron</source>, <volume>95</volume>(<issue>3</issue>), <fpage>709</fpage>–<lpage>721.e5</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.041</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Baldwin</surname>, <given-names>D. A.</given-names></string-name>, &amp; <string-name><surname>Kosie</surname>, <given-names>J. E</given-names></string-name></person-group>. (<year>2021</year>). <article-title>How Does the Mind Render Streaming Experience as Events?</article-title> <source>Topics in Cognitive Science</source>, <volume>13</volume>(<issue>1</issue>), <fpage>79</fpage>–<lpage>105</lpage>. <pub-id pub-id-type="doi">10.1111/tops.12502</pub-id></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Bartlett</surname>, <given-names>F. C</given-names></string-name></person-group>. (<year>1932</year>). <source>Remembering: A study in experimental and social psychology</source>. <publisher-name>Cambridge university press</publisher-name>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ben-Yakov</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Dudai</surname>, <given-names>Y</given-names></string-name></person-group>. (<year>2011</year>). <article-title>Constructing realistic engrams: Poststimulus activity of hippocampus and dorsal striatum predicts subsequent episodic memory</article-title>. <source>The Journal of Neuroscience</source>, <volume>31</volume>(<issue>24</issue>), <fpage>9032</fpage>–<lpage>9042</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.0702-11.2011</pub-id></mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ben-Yakov</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Henson</surname>, <given-names>R. N.</given-names></string-name></person-group> (<year>2018</year>). <article-title>The Hippocampal Film Editor: Sensitivity and Specificity to Event Boundaries in Continuous Experience</article-title>. <source>The Journal of Neuroscience</source>, <volume>38</volume>(<issue>47</issue>), <fpage>10057</fpage>–<lpage>10068</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.0524-18.2018</pub-id></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bezdek</surname>, <given-names>M. A.</given-names></string-name>, <string-name><surname>Nguyen</surname>, <given-names>T. T.</given-names></string-name>, <string-name><surname>Hall</surname>, <given-names>C. S.</given-names></string-name>, <string-name><surname>Braver</surname>, <given-names>T. S.</given-names></string-name>, <string-name><surname>Bobick</surname>, <given-names>A. F.</given-names></string-name>, &amp; <string-name><surname>Zacks</surname>, <given-names>J. M</given-names></string-name></person-group>. (<year>2022</year>). <article-title>The multi-angle extended three-dimensional activities (META) stimulus set: A tool for studying event cognition</article-title>. <source>Behavior Research Methods</source>. <pub-id pub-id-type="doi">10.3758/s13428-022-01980-8</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brunec</surname>, <given-names>I. K.</given-names></string-name>, <string-name><surname>Moscovitch</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Barense</surname>, <given-names>M. D</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Boundaries Shape Cognitive Representations of Spaces and Events</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>22</volume>(<issue>7</issue>), <fpage>637</fpage>–<lpage>650</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2018.03.013</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Burunat</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Levitin</surname>, <given-names>D. J.</given-names></string-name>, &amp; <string-name><surname>Toiviainen</surname>, <given-names>P</given-names></string-name></person-group>. (<year>2024</year>). <article-title>Breaking (musical) boundaries by investigating brain dynamics of event segmentation during real-life music-listening</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>121</volume>(<issue>36</issue>), <fpage>e2319459121</fpage>. <pub-id pub-id-type="doi">10.1073/pnas.2319459121</pub-id></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Clark</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2013</year>). <article-title>Whatever next? Predictive brains, situated agents, and the future of cognitive science</article-title>. <source>Behavioral and Brain Sciences</source>, <volume>36</volume>(<issue>3</issue>), <fpage>181</fpage>–<lpage>204</lpage>. <pub-id pub-id-type="doi">10.1017/S0140525X12000477</pub-id></mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Clewett</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>DuBrow</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Davachi</surname>, <given-names>L.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Transcending time in the brain: How event memories are constructed from experience</article-title>. <source>Hippocampus</source>, <volume>29</volume>(<issue>3</issue>), <fpage>162</fpage>–<lpage>183</lpage>. <pub-id pub-id-type="doi">10.1002/hipo.23074</pub-id></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Ding</surname>, <given-names>Y.</given-names></string-name>, &amp; <string-name><surname>Zacks</surname>, <given-names>J. M</given-names></string-name></person-group>. (<year>2025</year>). <article-title>Temporal order memory in naturalistic events is scaffolded by semantic knowledge and hierarchical event structure</article-title>. <source>PsyArXiv</source> <pub-id pub-id-type="doi">10.31234/osf.io/scaf8_v1</pub-id></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dosenbach</surname>, <given-names>N. U. F.</given-names></string-name>, <string-name><surname>Koller</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Earl</surname>, <given-names>E. A.</given-names></string-name>, <string-name><surname>Miranda-Dominguez</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Klein</surname>, <given-names>R. L.</given-names></string-name>, <string-name><surname>Van</surname>, <given-names>A. N.</given-names></string-name>, <string-name><surname>Snyder</surname>, <given-names>A. Z.</given-names></string-name>, <string-name><surname>Nagel</surname>, <given-names>B. J.</given-names></string-name>, <string-name><surname>Nigg</surname>, <given-names>J. T.</given-names></string-name>, <string-name><surname>Nguyen</surname>, <given-names>A. L.</given-names></string-name>, <string-name><surname>Wesevich</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Greene</surname>, <given-names>D. J.</given-names></string-name>, &amp; <string-name><surname>Fair</surname>, <given-names>D. A</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Real-time motion analytics during brain MRI improve data quality and reduce costs</article-title>. <source>NeuroImage</source>, <volume>161</volume>, <fpage>80</fpage>–<lpage>93</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.08.025</pub-id></mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>DuBrow</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Davachi</surname>, <given-names>L</given-names></string-name></person-group>. (<year>2013</year>). <article-title>The influence of context boundaries on memory for the sequential order of events</article-title>. <source>Journal of Experimental Psychology: General</source>, <volume>142</volume>(<issue>4</issue>), <fpage>1277</fpage>–<lpage>1286</lpage>. <pub-id pub-id-type="doi">10.1037/a0034024</pub-id></mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>DuBrow</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Rouhani</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Niv</surname>, <given-names>Y.</given-names></string-name>, &amp; <string-name><surname>Norman</surname>, <given-names>K. A</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Does mental context drift or shift?</article-title> <source>Current Opinion in Behavioral Sciences</source>, <volume>17</volume>, <fpage>141</fpage>–<lpage>146</lpage>. <pub-id pub-id-type="doi">10.1016/j.cobeha.2017.08.003</pub-id></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Etzel</surname>, <given-names>J. A</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Efficient evaluation of the Open QC task fMRI dataset</article-title>. <source>Frontiers in Neuroimaging</source>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Feinberg</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Moeller</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Auerbach</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Ramanna</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>K. L.</given-names></string-name>, <string-name><surname>Ugurbil</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Yacoub</surname>, <given-names>E</given-names></string-name></person-group>. (<year>2010</year>). <article-title>Multiplexed Echo Planar Imaging for Sub-Second Whole Brain FMRI and Fast Diffusion Imaging</article-title>. <source>PLoS ONE</source>, <volume>5</volume>(<issue>12</issue>):<elocation-id>e15710</elocation-id>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Friston</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>FitzGerald</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Rigoli</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Schwartenbeck</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>O⿿Doherty</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Pezzulo</surname>, <given-names>G.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Active inference and learning</article-title>. <source>Neuroscience &amp; Biobehavioral Reviews</source>, <volume>68</volume>, <fpage>862</fpage>–<lpage>879</lpage>. <pub-id pub-id-type="doi">10.1016/j.neubiorev.2016.06.022</pub-id></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Gal</surname>, <given-names>Y.</given-names></string-name>, &amp; <string-name><surname>Ghahramani</surname>, <given-names>Z</given-names></string-name></person-group>. (<year>2016</year>). <article-title>Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning</article-title>. <conf-name>Proceedings of the 33 Rd International Conference on Machine Learning</conf-name>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Geerligs</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Gözükara</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Oetringer</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Campbell</surname>, <given-names>K. L.</given-names></string-name>, <string-name><surname>Van Gerven</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Güçlü</surname>, <given-names>U.</given-names></string-name></person-group> (<year>2022</year>). <article-title>A partially nested cortical hierarchy of neural states underlies event segmentation in the human brain</article-title>. <source>eLife</source>, <volume>11</volume>, <elocation-id>e77430</elocation-id>. <pub-id pub-id-type="doi">10.7554/eLife.77430</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Geerligs</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>van Gerven</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Güçlü</surname>, <given-names>U.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Detecting neural state transitions underlying event segmentation</article-title>. <source>NeuroImage</source>, <volume>236</volume>, <fpage>118085</fpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2021.118085</pub-id></mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Graesser</surname>, <given-names>A. C.</given-names></string-name>, &amp; <string-name><surname>Nakamura</surname>, <given-names>G. V</given-names></string-name></person-group>. (<year>1982</year>). <chapter-title>The Impact of a Schema on Comprehension and Memory</chapter-title>. In <source>Psychology of Learning and Motivation</source> (Vol. <volume>16</volume>, pp. <fpage>59</fpage>–<lpage>109</lpage>). <publisher-name>Elsevier</publisher-name>. <pub-id pub-id-type="doi">10.1016/S0079-7421(08)60547-2</pub-id></mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Gumbsch</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Adam</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Elsner</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Martius</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Butz</surname>, <given-names>M. V</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Developing hierarchical anticipations via neural network-based event segmentation</article-title>. <volume>2022</volume> <conf-name>IEEE International Conference on Development and Learning (ICDL)</conf-name>, <fpage>1</fpage>–<lpage>8</lpage>. <pub-id pub-id-type="doi">10.1109/ICDL53763.2022.9962224</pub-id></mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="data"><person-group person-group-type="author"><string-name><surname>Gurney</surname>, <given-names>J.</given-names></string-name></person-group> (<year>2017</year>). <source>The Washington University Central Neuroimaging Data Archive</source>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hasson</surname>, <given-names>U.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Honey</surname>, <given-names>C. J</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Hierarchical process memory: Memory as an integral component of information processing</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>19</volume>(<issue>6</issue>), <fpage>304</fpage>–<lpage>313</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2015.04.006</pub-id></mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kendall</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Gal</surname>, <given-names>Y</given-names></string-name></person-group>. (<year>2017</year>). <article-title>What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?</article-title> <source>Advances in Neural Information Processing Systems</source>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Knott</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Takac</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Roles for Event Representations in Sensorimotor Experience, Memory Formation, and Language Processing</article-title>. <source>Topics in Cognitive Science</source>, <volume>13</volume>(<issue>1</issue>), <fpage>187</fpage>–<lpage>205</lpage>. <pub-id pub-id-type="doi">10.1111/tops.12497</pub-id></mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kurby</surname>, <given-names>C. A.</given-names></string-name>, &amp; <string-name><surname>Zacks</surname>, <given-names>J. M</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Preserved neural event segmentation in healthy older adults</article-title>. <source>Psychology and Aging</source>, <volume>33</volume>(<issue>2</issue>), <fpage>232</fpage>–<lpage>245</lpage>. <pub-id pub-id-type="doi">10.1037/pag0000226</pub-id></mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Magliano</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Trabasso</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Graesser</surname>, <given-names>A</given-names></string-name></person-group>. (<year>1999</year>). <article-title>Strategic Processing During Comprehension</article-title>. <source>Journal of Educational Psychology</source>, <volume>91</volume>, <fpage>615</fpage>–<lpage>629</lpage>. <pub-id pub-id-type="doi">10.1037/0022-0663.91.4.615</pub-id></mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nguyen</surname>, <given-names>T. T.</given-names></string-name>, <string-name><surname>Bezdek</surname>, <given-names>M. A.</given-names></string-name>, <string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>Bobick</surname>, <given-names>A. F.</given-names></string-name>, <string-name><surname>Braver</surname>, <given-names>T. S.</given-names></string-name>, &amp; <string-name><surname>Zacks</surname>, <given-names>J. M</given-names></string-name></person-group>. (<year>2024</year>). <article-title>Modeling human activity comprehension at human scale: Prediction, segmentation, and categorization</article-title>. <source>PNAS Nexus</source>, <volume>3</volume>(<issue>10</issue>), <fpage>pgae459</fpage>. <pub-id pub-id-type="doi">10.1093/pnasnexus/pgae459</pub-id></mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Niv</surname>, <given-names>Y.</given-names></string-name>, &amp; <string-name><surname>Schoenbaum</surname>, <given-names>G</given-names></string-name></person-group>. (<year>2008</year>). <article-title>Dialogues on prediction errors</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>12</volume>(<issue>7</issue>), <fpage>265</fpage>–<lpage>272</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2008.03.006</pub-id></mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Radvansky</surname>, <given-names>G. A.</given-names></string-name>, &amp; <string-name><surname>Copeland</surname>, <given-names>D. E</given-names></string-name></person-group>. (<year>2006</year>). <article-title>Walking through doorways causes forgetting: Situation models and experienced space</article-title>. <source>Memory &amp; Cognition</source>, <volume>34</volume>(<issue>5</issue>), <fpage>1150</fpage>–<lpage>1156</lpage>. <pub-id pub-id-type="doi">10.3758/BF03193261</pub-id></mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Radvansky</surname>, <given-names>G. A.</given-names></string-name>, <string-name><surname>Tamplin</surname>, <given-names>A. K.</given-names></string-name>, &amp; <string-name><surname>Krawietz</surname>, <given-names>S. A</given-names></string-name></person-group>. (<year>2010</year>). <article-title>Walking through doorways causes forgetting: Environmental integration</article-title>. <source>Psychonomic Bulletin &amp; Review</source>, <volume>17</volume>(<issue>6</issue>), <fpage>900</fpage>–<lpage>904</lpage>. <pub-id pub-id-type="doi">10.3758/PBR.17.6.900</pub-id></mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Richmond</surname>, <given-names>L. L.</given-names></string-name>, &amp; <string-name><surname>Zacks</surname>, <given-names>J. M</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Constructing experience: Event models from perception to action</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>21</volume>(<issue>12</issue>), <fpage>962</fpage>–<lpage>980</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2017.08.005</pub-id></mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sargent</surname>, <given-names>J. Q.</given-names></string-name>, <string-name><surname>Zacks</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Hambrick</surname>, <given-names>D. Z.</given-names></string-name>, <string-name><surname>Zacks</surname>, <given-names>R. T.</given-names></string-name>, <string-name><surname>Kurby</surname>, <given-names>C. A.</given-names></string-name>, <string-name><surname>Bailey</surname>, <given-names>H. R.</given-names></string-name>, <string-name><surname>Eisenberg</surname>, <given-names>M. L.</given-names></string-name>, &amp; <string-name><surname>Beck</surname>, <given-names>T. M</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Event segmentation ability uniquely predicts event memory</article-title>. <source>Cognition</source>, <volume>129</volume>(<issue>2</issue>), <fpage>241</fpage>–<lpage>255</lpage>. <pub-id pub-id-type="doi">10.1016/j.cognition.2013.07.002</pub-id></mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schaefer</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kong</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Gordon</surname>, <given-names>E. M.</given-names></string-name>, <string-name><surname>Laumann</surname>, <given-names>T. O.</given-names></string-name>, <string-name><surname>Zuo</surname>, <given-names>X.-N.</given-names></string-name>, <string-name><surname>Holmes</surname>, <given-names>A. J.</given-names></string-name>, <string-name><surname>Eickhoff</surname>, <given-names>S. B.</given-names></string-name>, &amp; <string-name><surname>Yeo</surname>, <given-names>B. T. T</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Local-Global Parcellation of the Human Cerebral Cortex from Intrinsic Functional Connectivity MRI</article-title>. <source>Cerebral Cortex</source>, <volume>28</volume>(<issue>9</issue>), <fpage>3095</fpage>–<lpage>3114</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhx179</pub-id></mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Speer</surname>, <given-names>N. K.</given-names></string-name>, <string-name><surname>Zacks</surname>, <given-names>J. M.</given-names></string-name>, &amp; <string-name><surname>Reynolds</surname>, <given-names>J. R</given-names></string-name></person-group>. (<year>2007</year>). <article-title>Human Brain Activity Time-Locked to Narrative Event Boundaries</article-title>. <source>Psychological Science</source>, <volume>18</volume>(<issue>5</issue>), <fpage>449</fpage>–<lpage>455</lpage>. <pub-id pub-id-type="doi">10.1111/j.1467-9280.2007.01920.x</pub-id></mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Su</surname>, <given-names>X.</given-names></string-name>, &amp; <string-name><surname>Swallow</surname>, <given-names>K. M</given-names></string-name></person-group>. (<year>2024</year>). <article-title>People can reliably detect action changes and goal changes during naturalistic perception</article-title>. <source>Memory &amp; Cognition</source>, <volume>52</volume>(<issue>5</issue>), <fpage>1093</fpage>–<lpage>1111</lpage>. <pub-id pub-id-type="doi">10.3758/s13421-024-01525-8</pub-id></mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Swallow</surname>, <given-names>K. M.</given-names></string-name>, <string-name><surname>Zacks</surname>, <given-names>J. M.</given-names></string-name>, &amp; <string-name><surname>Abrams</surname>, <given-names>R. A</given-names></string-name></person-group>. (<year>2009</year>). <article-title>Event boundaries in perception affect memory encoding and updating</article-title>. <source>Journal of Experimental Psychology: General</source>, <volume>257</volume>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname>, <given-names>Y. C.</given-names></string-name>, &amp; <string-name><surname>Egner</surname>, <given-names>T</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Switching task sets creates event boundaries in memory</article-title>. <source>Cognition</source>, <volume>221</volume>, <fpage>104992</fpage>. <pub-id pub-id-type="doi">10.1016/j.cognition.2021.104992</pub-id></mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xu</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Moeller</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Auerbach</surname>, <given-names>E. J.</given-names></string-name>, <string-name><surname>Strupp</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Feinberg</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Yacoub</surname>, <given-names>E.</given-names></string-name>, &amp; <string-name><surname>Uğurbil</surname>, <given-names>K</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Evaluation of slice accelerations using multiband echo planar imaging at 3T</article-title>. <source>NeuroImage</source>, <volume>83</volume>, <fpage>991</fpage>–<lpage>1001</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.07.055</pub-id></mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zacks</surname>, <given-names>J. M</given-names></string-name></person-group>. (<year>2010</year>). <article-title>The brain’s cutting-room floor: Segmentation of narrative cinema</article-title>. <source>Frontiers in Human Neuroscience</source>, <volume>4</volume>. <pub-id pub-id-type="doi">10.3389/fnhum.2010.00168</pub-id></mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zacks</surname>, <given-names>J. M</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Event perception and memory</article-title>. <source>Annual Review of Psychology</source>, <volume>71</volume>(<issue>1</issue>), <fpage>165</fpage>–<lpage>191</lpage>. <pub-id pub-id-type="doi">10.1146/annurev-psych-010419-051101</pub-id></mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zacks</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Speer</surname>, <given-names>N. K.</given-names></string-name>, <string-name><surname>Swallow</surname>, <given-names>K. M.</given-names></string-name>, <string-name><surname>Braver</surname>, <given-names>T. S.</given-names></string-name>, &amp; <string-name><surname>Reynolds</surname>, <given-names>J. R</given-names></string-name></person-group>. (<year>2007</year>). <article-title>Event perception: A mind-brain perspective</article-title>. <source>Psychological Bulletin</source>, <volume>133</volume>(<issue>2</issue>), <fpage>273</fpage>–<lpage>293</lpage>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Abraham</surname>, <given-names>Alexandre</given-names></string-name>, <string-name><given-names>Fabian</given-names> <surname>Pedregosa</surname></string-name>, <string-name><given-names>Michael</given-names> <surname>Eickenberg</surname></string-name>, <string-name><given-names>Philippe</given-names> <surname>Gervais</surname></string-name>, <string-name><given-names>Andreas</given-names> <surname>Mueller</surname></string-name>, <string-name><given-names>Jean</given-names> <surname>Kossaifi</surname></string-name>, <string-name><given-names>Alexandre</given-names> <surname>Gramfort</surname></string-name>, <string-name><given-names>Bertrand</given-names> <surname>Thirion</surname></string-name>, and <string-name><given-names>Gael</given-names> <surname>Varoquaux</surname></string-name></person-group>. <year>2014</year>. “<article-title>Machine Learning for Neuroimaging with Scikit-Learn</article-title>.” <source>Frontiers in Neuroinformatics</source> <volume>8</volume>. <pub-id pub-id-type="doi">10.3389/fninf.2014.00014</pub-id>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Avants</surname>, <given-names>B.B.</given-names></string-name>, <string-name><given-names>C.L.</given-names> <surname>Epstein</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Grossman</surname></string-name>, and <string-name><given-names>J.C.</given-names> <surname>Gee</surname></string-name></person-group>. <year>2008</year>. “<article-title>Symmetric Diffeomorphic Image Registration with Cross-Correlation: Evaluating Automated Labeling of Elderly and Neurodegenerative Brain</article-title>.” <source>Medical Image Analysis</source> <volume>12</volume> (<issue>1</issue>): <fpage>26</fpage>–<lpage>41</lpage>. <pub-id pub-id-type="doi">10.1016/j.media.2007.06.004</pub-id>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Behzadi</surname>, <given-names>Yashar</given-names></string-name>, <string-name><given-names>Khaled</given-names> <surname>Restom</surname></string-name>, <string-name><given-names>Joy</given-names> <surname>Liau</surname></string-name>, and <string-name><given-names>Thomas T.</given-names> <surname>Liu</surname></string-name></person-group>. <year>2007</year>. “<article-title>A Component Based Noise Correction Method (CompCor) for BOLD and Perfusion Based fMRI</article-title>.” <source>NeuroImage</source> <volume>37</volume> (<issue>1</issue>): <fpage>90</fpage>–<lpage>101</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.04.042</pub-id>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cox</surname>, <given-names>Robert W.</given-names></string-name>, and <string-name><given-names>James S.</given-names> <surname>Hyde</surname></string-name></person-group>. <year>1997</year>. “<article-title>Software Tools for Analysis and Visualization of fMRI Data</article-title>.” <source>NMR in Biomedicine</source> <volume>10</volume> (<issue>4-5</issue>): <fpage>171</fpage>–<lpage>78</lpage>. <pub-id pub-id-type="doi">10.1002/(SICI)1099-1492(199706/08)10:4/5&lt;171::AID-NBM453&gt;3.0.CO;2-L</pub-id>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="software"><person-group person-group-type="author"><string-name><surname>Esteban</surname>, <given-names>Oscar</given-names></string-name>, <string-name><given-names>Ross</given-names> <surname>Blair</surname></string-name>, <string-name><given-names>Christopher J.</given-names> <surname>Markiewicz</surname></string-name>, <string-name><given-names>Shoshana L.</given-names> <surname>Berleant</surname></string-name>, <string-name><given-names>Craig</given-names> <surname>Moodie</surname></string-name>, <string-name><given-names>Feilong</given-names> <surname>Ma</surname></string-name>, <string-name><given-names>Ayse Ilkay</given-names> <surname>Isik</surname></string-name>, <etal>et al.</etal></person-group> <year>2018</year>. “<article-title>FMRIPrep</article-title>.” <source>Zenodo</source>. <pub-id pub-id-type="doi">10.5281/zenodo.852659</pub-id>.</mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Esteban</surname>, <given-names>Oscar</given-names></string-name>, <string-name><given-names>Christopher</given-names> <surname>Markiewicz</surname></string-name>, <string-name><given-names>Ross W</given-names> <surname>Blair</surname></string-name>, <string-name><given-names>Craig</given-names> <surname>Moodie</surname></string-name>, <string-name><given-names>Ayse Ilkay</given-names> <surname>Isik</surname></string-name>, <string-name><given-names>Asier Erramuzpe</given-names> <surname>Aliaga</surname></string-name>, <string-name><given-names>James</given-names> <surname>Kent</surname></string-name>, <etal>et al.</etal></person-group> <year>2018</year>. “<article-title>fMRIPrep: A Robust Preprocessing Pipeline for Functional MRI</article-title>.” <source>Nature Methods</source>. <pub-id pub-id-type="doi">10.1038/s41592-018-0235-4</pub-id>.</mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fonov</surname>, <given-names>VS</given-names></string-name>, <string-name><given-names>AC</given-names> <surname>Evans</surname></string-name>, <string-name><given-names>RC</given-names> <surname>McKinstry</surname></string-name>, <string-name><given-names>CR</given-names> <surname>Almli</surname></string-name>, and <string-name><given-names>DL</given-names> <surname>Collins</surname></string-name></person-group>. <year>2009</year>. “<article-title>Unbiased Nonlinear Average Age-Appropriate Brain Templates from Birth to Adulthood</article-title>.” <source>NeuroImage</source> <volume>47, Supplement</volume> <issue>1</issue>: <fpage>S102</fpage>. <pub-id pub-id-type="doi">10.1016/S1053-8119(09)70884-5</pub-id>.</mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gorgolewski</surname>, <given-names>K.</given-names></string-name>, <string-name><given-names>C. D.</given-names> <surname>Burns</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Madison</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Clark</surname></string-name>, <string-name><given-names>Y. O.</given-names> <surname>Halchenko</surname></string-name>, <string-name><given-names>M. L.</given-names> <surname>Waskom</surname></string-name>, and <string-name><given-names>S.</given-names> <surname>Ghosh</surname></string-name></person-group>. <year>2011</year>. “<article-title>Nipype: A Flexible, Lightweight and Extensible Neuroimaging Data Processing Framework in Python</article-title>.” <source>Frontiers in Neuroinformatics</source> <volume>5</volume>: <fpage>13</fpage>. <pub-id pub-id-type="doi">10.3389/fninf.2011.00013</pub-id>.</mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="software"><person-group person-group-type="author"><string-name><surname>Gorgolewski</surname>, <given-names>Krzysztof J.</given-names></string-name>, <string-name><given-names>Oscar</given-names> <surname>Esteban</surname></string-name>, <string-name><given-names>Christopher J.</given-names> <surname>Markiewicz</surname></string-name>, <string-name><given-names>Erik</given-names> <surname>Ziegler</surname></string-name>, <string-name><given-names>David Gage</given-names> <surname>Ellis</surname></string-name>, <string-name><given-names>Michael Philipp</given-names> <surname>Notter</surname></string-name>, <string-name><given-names>Dorota</given-names> <surname>Jarecka</surname></string-name>, <etal>et al.</etal></person-group> <year>2018</year>. “<article-title>Nipype</article-title>.” <source>Zenodo</source>. <pub-id pub-id-type="doi">10.5281/zenodo.596855</pub-id>.</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Greve</surname>, <given-names>Douglas N</given-names></string-name>, and <string-name><given-names>Bruce</given-names> <surname>Fischl</surname></string-name></person-group>. <year>2009</year>. “<article-title>Accurate and Robust Brain Image Alignment Using Boundary-Based Registration</article-title>.” <source>NeuroImage</source> <volume>48</volume> (<issue>1</issue>): <fpage>63</fpage>–<lpage>72</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.06.060</pub-id>.</mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jenkinson</surname>, <given-names>Mark</given-names></string-name>, <string-name><given-names>Peter</given-names> <surname>Bannister</surname></string-name>, <string-name><given-names>Michael</given-names> <surname>Brady</surname></string-name>, and <string-name><given-names>Stephen</given-names> <surname>Smith</surname></string-name></person-group>. <year>2002</year>. “<article-title>Improved Optimization for the Robust and Accurate Linear Registration and Motion Correction of Brain Images</article-title>.” <source>NeuroImage</source> <volume>17</volume> (<issue>2</issue>): <fpage>825</fpage>–<lpage>41</lpage>. <pub-id pub-id-type="doi">10.1006/nimg.2002.1132</pub-id>.</mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jenkinson</surname>, <given-names>Mark</given-names></string-name>, and <string-name><given-names>Stephen</given-names> <surname>Smith</surname></string-name></person-group>. <year>2001</year>. “<article-title>A Global Optimisation Method for Robust Affine Registration of Brain Images</article-title>.” <source>Medical Image Analysis</source> <volume>5</volume> (<issue>2</issue>): <fpage>143</fpage>–<lpage>56</lpage>. <pub-id pub-id-type="doi">10.1016/S1361-8415(01)00036-6</pub-id>.</mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lanczos</surname>, <given-names>C</given-names></string-name></person-group>. <year>1964</year>. “<article-title>Evaluation of Noisy Data</article-title>.” <source>Journal of the Society for Industrial and Applied Mathematics Series B Numerical Analysis</source> <volume>1</volume> (<issue>1</issue>): <fpage>76</fpage>–<lpage>85</lpage>. <pub-id pub-id-type="doi">10.1137/0701007</pub-id>.</mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Power</surname>, <given-names>Jonathan D.</given-names></string-name>, <string-name><given-names>Anish</given-names> <surname>Mitra</surname></string-name>, <string-name><given-names>Timothy O.</given-names> <surname>Laumann</surname></string-name>, <string-name><given-names>Abraham Z.</given-names> <surname>Snyder</surname></string-name>, <string-name><given-names>Bradley L.</given-names> <surname>Schlaggar</surname></string-name>, and <string-name><given-names>Steven E.</given-names> <surname>Petersen</surname></string-name></person-group>. <year>2014</year>. “<article-title>Methods to Detect, Characterize, and Remove Motion Artifact in Resting State fMRI</article-title>.” <source>NeuroImage</source> <volume>84</volume> (<issue>Supplement C</issue>): <fpage>320</fpage>–<lpage>41</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.08.048</pub-id>.</mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Satterthwaite</surname>, <given-names>Theodore D.</given-names></string-name>, <string-name><given-names>Mark A.</given-names> <surname>Elliott</surname></string-name>, <string-name><given-names>Raphael T.</given-names> <surname>Gerraty</surname></string-name>, <string-name><given-names>Kosha</given-names> <surname>Ruparel</surname></string-name>, <string-name><given-names>James</given-names> <surname>Loughead</surname></string-name>, <string-name><given-names>Monica E.</given-names> <surname>Calkins</surname></string-name>, <string-name><given-names>Simon B.</given-names> <surname>Eickhoff</surname></string-name>, <etal>et al.</etal></person-group> <year>2013</year>. “<article-title>An improved framework for confound regression and filtering for control of motion artifact in the preprocessing of resting-state functional connectivity data</article-title>.” <source>NeuroImage</source> <volume>64</volume> (<issue>1</issue>): <fpage>240</fpage>–<lpage>56</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.08.052</pub-id>.</mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tustison</surname>, <given-names>N. J.</given-names></string-name>, <string-name><given-names>B. B.</given-names> <surname>Avants</surname></string-name>, <string-name><given-names>P. A.</given-names> <surname>Cook</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Zheng</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Egan</surname></string-name>, <string-name><given-names>P. A.</given-names> <surname>Yushkevich</surname></string-name>, and <string-name><given-names>J. C.</given-names> <surname>Gee</surname></string-name></person-group>. <year>2010</year>. “<article-title>N4ITK: Improved N3 Bias Correction</article-title>.” <source>IEEE Transactions on Medical Imaging</source> <volume>29</volume> (<issue>6</issue>): <fpage>1310</fpage>–<lpage>20</lpage>. <pub-id pub-id-type="doi">10.1109/TMI.2010.2046908</pub-id>.</mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname>, <given-names>Y.</given-names></string-name>, <string-name><given-names>M.</given-names> <surname>Brady</surname></string-name>, and <string-name><given-names>S.</given-names> <surname>Smith</surname></string-name></person-group>. <year>2001</year>. “<article-title>Segmentation of Brain MR Images Through a Hidden Markov Random Field Model and the Expectation-Maximization Algorithm</article-title>.” <source>IEEE Transactions on Medical Imaging</source> <volume>20</volume> (<issue>1</issue>): <fpage>45</fpage>–<lpage>57</lpage>. <pub-id pub-id-type="doi">10.1109/42.906424</pub-id>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107955.1.sa9</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Peelle</surname>
<given-names>Jonathan Erik</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Northeastern University</institution>
</institution-wrap>
<city>Boston</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>valuable</bold> study tests whether prediction error or prediction uncertainty controls how the brain segments continuous experience into events. The paper uses validated models that predict human behavior to analyze multivariate neural pattern changes during naturalistic movie watching. The authors provide <bold>solid</bold> evidence that there are overlapping but partially distinct brain dynamics for each signal.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107955.1.sa8</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This paper investigates the control signals that drive event model updating during continuous experience. The authors apply predictions from previously published computational models to fMRI data acquired while participants watched naturalistic video stimuli. They first examine the time course of BOLD pattern changes around human-annotated event boundaries, revealing pattern changes preceding the boundary in anterior temporal and then parietal regions, followed by pattern stabilization across many regions. The authors then analyze time courses around boundaries generated by a model that updates event models based on prediction error and another that uses prediction uncertainty. These analyses reveal overlapping but partially distinct dynamics for each boundary type, suggesting that both signals may contribute to event segmentation processes in the brain.</p>
<p>Strengths:</p>
<p>(1) The question addressed by this paper is of high interest to researchers working on event cognition, perception, and memory. There has been considerable debate about what kinds of signals drive event boundaries, and this paper directly engages with that debate by comparing prediction error and prediction uncertainty as candidate control signals.</p>
<p>(2) The authors use computational models that explain significant variance in human boundary judgments, and they report the variance explained clearly in the paper.</p>
<p>(3) The authors' method of using computational models to generate predictions about when event model updating should occur is a valuable mechanistic alternative to methods like HMM or GSBS, which are data-driven.</p>
<p>(4) The paper utilizes an analysis framework that characterizes how multivariate BOLD pattern dissimilarity evolves before and after boundaries. This approach offers an advance over previous work focused on just the boundary or post-boundary points.</p>
<p>Weaknesses:</p>
<p>(1) While the paper raises the possibility that both prediction error and uncertainty could serve as control signals, it does not offer a strong theoretical rationale for why the brain would benefit from multiple (empirically correlated) signals. What distinct advantages do these signals provide? This may be discussed in the authors' prior modeling work, but is left too implicit in this paper.</p>
<p>(2) Boundaries derived from prediction error and uncertainty are correlated for the naturalistic stimuli. This raises some concerns about how well their distinct contributions to brain activity can be separated. The authors should consider whether they can leverage timepoints where the models make different predictions to make a stronger case for brain regions that are responsive to one vs the other.</p>
<p>(3) The authors refer to a baseline measure of pattern dissimilarity, which their dissimilarity measure of interest is relative to, but it's not clear how this baseline is computed. Since the interpretation of increases or decreases in dissimilarity depends on this reference point, more clarity is needed.</p>
<p>(4) The authors report an average event length of ~20 seconds, and they also look at +20 and -20 seconds around each event boundary. Thus, it's unclear how often pre- and post-boundary timepoints are part of adjacent events. This complicates the interpretations of the reported time courses.</p>
<p>(5) The authors describe a sequence of neural pattern shifts during each type of boundary, but offer little setup of what pattern shifts we might expect or why. They also offer little discussion of what cognitive processes these shifts might reflect. The paper would benefit from a more thorough setup for the neural results and a discussion that comments on how the results inform our understanding of what these brain regions contribute to event models.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107955.1.sa7</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Tan et al. examined how multivoxel patterns shift in time windows surrounding event boundaries caused by both prediction errors and prediction uncertainty. They observed that some regions of the brain show earlier pattern shifts than others, followed by periods of increased stability. The authors combine their recent computational model to estimate event boundaries that are based on prediction error vs. uncertainty and use this to examine the moment-to-moment dynamics of pattern changes. I believe this is a meaningful contribution that will be of interest to memory, attention, and complex cognition research.</p>
<p>Strengths:</p>
<p>The authors have shown exceptional transparency in terms of sharing their data, code, and stimuli, which is beneficial to the field for future examinations and to the reproduction of findings. The manuscript is well written with clear figures. The study starts from a strong theoretical background to understand how the brain represents events and has used a well-curated set of stimuli. Overall, the authors extend the event segmentation theory beyond prediction error to include prediction uncertainty, which is an important theoretical shift that has implications in episodic memory encoding, the use of semantic and schematic knowledge, and attentional processing.</p>
<p>Weaknesses:</p>
<p>The data presented is limited to the cortex, and subcortical contributions would be interesting to explore. Further, the temporal window around event boundaries of 20 seconds is approximately the length of the average event (21.4 seconds), and many of the observed pattern effects occur relatively distal from event boundaries themselves, which makes the link to the theoretical background challenging. Finally, while multivariate pattern shifts were examined at event boundaries related to either prediction error or prediction uncertainty, there was no exploration of univariate activity differences between these two different types of boundaries, which would be valuable.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107955.1.sa6</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The aim of this study was to investigate the temporal progression of the neural response to event boundaries in relation to uncertainty and error. Specifically, the authors asked (1) how neural activity changes before and after event boundaries, (2) if uncertainty and error both contribute to explaining the occurrence of event boundaries, and (3) if uncertainty and error have unique contributions to explaining the temporal progression of neural activity.</p>
<p>Strengths:</p>
<p>One strength of this paper is that it builds on an already validated computational model. It relies on straightforward and interpretable analysis techniques to answer the main question, with a smart combination of pattern similarity metrics and FIR. This combination of methods may also be an inspiration to other researchers in the field working on similar questions. The paper is well written and easy to follow. The paper convincingly shows that (1) there is a temporal progression of neural activity change before and after an event boundary, and (2) event boundaries are predicted best by the combination of uncertainty and error signals.</p>
<p>Weaknesses:</p>
<p>Regarding question 3, I am less convinced by the results. They show that overlapping but somewhat distinct sets of brain regions relate to uncertainty and error boundaries over time. And that some regions show distinct patterns of temporal progressions in pattern change with both types of boundaries. However, most of the effects they observe in this analysis may still be driven by shared variance, as suggested by the results in Figure 6 and the high correlation between the two boundary time series. More specific comments are provided below.</p>
<p>Impact:</p>
<p>If these comments can be addressed sufficiently, I expect that this work will impact the field in its thinking on what drives event boundaries and spur interest in understanding the mechanisms behind the temporal progression of neural activity around these boundaries.</p>
<p>Comments</p>
<p>(1) The current analysis of the neural data does not convincingly show that uncertainty and prediction error both contribute to the neural responses. As both terms are modelled in separate FIR models, it may be that the responses we see for both are mostly driven by shared variance. Given that the correlation between the two is very high (r=0.49), this seems likely. The strong overlap in the neural responses elicited by both, as shown in Figure 6, also suggests that what we see may mainly be shared variance. To improve the interpretability of these effects, I think it is essential to know whether uncertainty and error explain similar or unique parts of the variance. The observation that they have distinct temporal profiles is suggestive of some dissociation, but not as convincing as adding them both to a single model.</p>
<p>(2) The results for uncertainty and error show that uncertainty has strong effects before or at boundary onset, while error is related to more stabilization after boundary onset. This makes me wonder about the temporal contribution of each of these. Could it be the case that increases in uncertainty are early indicators of a boundary, and errors tend to occur later?</p>
<p>(3) Given that there is a 24-second period during which the neural responses are shaped by event boundaries, it would be important to know more about the average distance between boundaries and the variability of this distance. This will help establish whether the FIR model can properly capture a return to baseline.</p>
<p>(4) Given that there is an early onset and long-lasting response of the brain to these event boundaries, I wonder what causes this. Is it the case that uncertainty or errors already increase at 12 seconds before the boundaries occur? Or if there are other makers in the movie that the brain can use to foreshadow an event boundary? And if uncertainty or errors do increase already 12 seconds before an event boundary, do you see a similar neural response at moments with similar levels of error or uncertainty, which are not followed by a boundary? This would reveal whether the neural activity patterns are specific to event boundaries or whether these are general markers of error and uncertainty.</p>
<p>(5) It is known that different brain regions have different delays of their BOLD response. Could these delays contribute to the propagation of the neural activity across different brain areas in this study?</p>
<p>(6) In the FIR plots, timepoints -12, 0, and 12 are shown. These long intervals preclude an understanding of the full temporal progression of these effects.</p>
</body>
</sub-article>
<sub-article id="sa4" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107955.1.sa5</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Nguyen</surname>
<given-names>Tan T</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8433-4678</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Etzel</surname>
<given-names>Joset A</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3694-8277</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Bezdek</surname>
<given-names>Matthew A</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0080-9366</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Zacks</surname>
<given-names>Jeffrey M</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1171-3690</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Public review):</bold></p>
<p>Summary:</p>
<p>This paper investigates the control signals that drive event model updating during continuous experience. The authors apply predictions from previously published computational models to fMRI data acquired while participants watched naturalistic video stimuli. They first examine the time course of BOLD pattern changes around human-annotated event boundaries, revealing pattern changes preceding the boundary in anterior temporal and then parietal regions, followed by pattern stabilization across many regions. The authors then analyze time courses around boundaries generated by a model that updates event models based on prediction error and another that uses prediction uncertainty. These analyses reveal overlapping but partially distinct dynamics for each boundary type, suggesting that both signals may contribute to event segmentation processes in the brain.</p>
<p>Strengths:</p>
<p>(1) The question addressed by this paper is of high interest to researchers working on event cognition, perception, and memory. There has been considerable debate about what kinds of signals drive event boundaries, and this paper directly engages with that debate by comparing prediction error and prediction uncertainty as candidate control signals.</p>
<p>(2) The authors use computational models that explain significant variance in human boundary judgments, and they report the variance explained clearly in the paper.</p>
<p>(3) The authors' method of using computational models to generate predictions about when event model updating should occur is a valuable mechanistic alternative to methods like HMM or GSBS, which are data-driven.</p>
<p>(4) The paper utilizes an analysis framework that characterizes how multivariate BOLD pattern dissimilarity evolves before and after boundaries. This approach offers an advance over previous work focused on just the boundary or post-boundary points.</p>
</disp-quote>
<p>We appreciate this reviewer’s recognition of the significance of this research problem, and of the value of the approach taken by this paper.</p>
<disp-quote content-type="editor-comment">
<p>Weaknesses:</p>
<p>(1) While the paper raises the possibility that both prediction error and uncertainty could serve as control signals, it does not offer a strong theoretical rationale for why the brain would benefit from multiple (empirically correlated) signals. What distinct advantages do these signals provide? This may be discussed in the authors' prior modeling work, but is left too implicit in this paper.</p>
</disp-quote>
<p>We added a brief discussion in the introduction highlighting the complementary advantages of prediction error and prediction uncertainty, and cited prior theoretical work that elaborates on this point. Specifically, we now note that prediction error can act as a reactive trigger, signaling when the current event model is no longer sufficient (Zacks et al., 2007). In contrast, prediction uncertainty is framed as proactive, allowing the system to prepare for upcoming changes even before they occur (Baldwin &amp; Kosie, 2021; Kuperberg, 2021). Together, this makes clearer why these two signals could each provide complementary benefits for effective event model updating.</p>
<p>&quot;One potential signal to control event model updating is prediction error—the difference between the system’s prediction and what actually occurs. A transient increase in prediction error is a valid indicator that the current model no longer adequately captures the current activity. Event Segmentation Theory (EST; Zacks et al., 2007) proposes that event models are updated when prediction error increases beyond a threshold, indicating that the current model no longer adequately captures ongoing activity. A related but computationally distinct proposal is that prediction uncertainty (also termed &quot;unpredictability&quot;), in addition to error, serves as the control signal (Baldwin &amp; Kosie, 2021). The advantage of relying on prediction uncertainty to detect event boundaries is that it is inherently proactive: the cognitive system can start looking for cues about what might come next before the next event starts (Baldwin &amp; Kosie, 2021; Kuperberg, 2021).&quot;</p>
<disp-quote content-type="editor-comment">
<p>(2) Boundaries derived from prediction error and uncertainty are correlated for the naturalistic stimuli. This raises some concerns about how well their distinct contributions to brain activity can be separated. The authors should consider whether they can leverage timepoints where the models make different predictions to make a stronger case for brain regions that are responsive to one vs the other.</p>
</disp-quote>
<p>We addressed this concern by adding an analysis that explicitly tests the unique contributions of prediction error– and prediction uncertainty–driven boundaries to neural pattern shifts. In the revised manuscript, we describe how we fit a combined FIR model that included both boundary types as predictors and then compared this model against versions with only one predictor. This allowed us to identify the variance explained by each boundary type over and above the other. The results revealed two partially dissociable sets of brain regions sensitive to error- versus uncertainty-driven boundaries (see Figure S1), strengthening our argument that these signals make distinct contributions.</p>
<p>&quot;To account for the correlation between uncertainty-driven boundaries and error-driven boundaries, we also fitted a FIR model that predicts pattern dissimilarity from both types of boundaries (combined FIR) for each parcel. Then, we performed two likelihood ratio tests: combined FIR to error FIR, which measures the unique contribution of uncertainty boundaries to pattern dissimilarity, and combined FIR to uncertainty FIR, which measures the unique contribution of error boundaries to pattern dissimilarity. The analysis also revealed two dissociable sets of brain regions associated with each boundary type (see Figure S1).&quot;</p>
<disp-quote content-type="editor-comment">
<p>(3) The authors refer to a baseline measure of pattern dissimilarity, which their dissimilarity measure of interest is relative to, but it's not clear how this baseline is computed. Since the interpretation of increases or decreases in dissimilarity depends on this reference point, more clarity is needed.</p>
</disp-quote>
<p>We clarified how the FIR baseline is estimated in the methods section. Specifically, we now explain that the FIR coefficients should be interpreted relative to a reference level, which reflects the expected dissimilarity when timepoints are far from an event boundary. This makes it clear what serves as the comparison point for observed increases or decreases in dissimilarity.</p>
<p>&quot;The coefficients from the FIR model indicates changes relative to baseline, which can be conceptualized as the expected value when far from the boundary.&quot;</p>
<disp-quote content-type="editor-comment">
<p>(4) The authors report an average event length of ~20 seconds, and they also look at +20 and -20 seconds around each event boundary. Thus, it's unclear how often pre- and post-boundary timepoints are part of adjacent events. This complicates the interpretations of the reported time courses.</p>
</disp-quote>
<p>This is related to reviewer's 2 comment, and it will be addressed below.</p>
<disp-quote content-type="editor-comment">
<p>(5) The authors describe a sequence of neural pattern shifts during each type of boundary, but offer little setup of what pattern shifts we might expect or why. They also offer little discussion of what cognitive processes these shifts might reflect. The paper would benefit from a more thorough setup for the neural results and a discussion that comments on how the results inform our understanding of what these brain regions contribute to event models.</p>
</disp-quote>
<p>We thank the reviewer for this advice on how better to set the context for the different potential outcomes of the study. We expanded both the introduction and discussion to better set up expectations for neural pattern shifts and to interpret what these shifts may reflect. In the introduction, we now describe prior findings showing that sensory regions tend to update more quickly than higher-order multimodal regions (Baldassano et al., 2017; Geerligs et al., 2021, 2022), and we highlight that it remains unclear whether higher-order updates precede or follow those in lower-order regions. We also note that our analytic approach is well-suited to address this open question. In the discussion, we then interpret our results in light of this framework. Specifically, we describe how we observed early shifts in higher-order areas such as anterior temporal and prefrontal cortex, followed by shifts in parietal and dorsal attention regions closer to event boundaries. This pattern runs counter to the traditional bottom-up temporal hierarchy view and instead supports a model of top-down updating, where high-level representations are updated first and subsequently influence lower-level processing (Friston, 2005; Kuperberg, 2021). To make this interpretation concrete, we added an example: in a narrative where a goal is reached midway—for instance, a mystery solved before the story formally ends—higher-order regions may update the event representation at that point, and this updated model then cascades down to shape processing in lower-level regions. Finally, we note that the widespread stabilization of neural patterns after boundaries may signal the establishment of a new event model.</p>
<p>Excerpt from Introduction:</p>
<p>“More recently, multivariate approaches have provided insights into neural representations during event segmentation. One prominent approach uses hidden Markov models (HMMs) to detect moments when the brain switches from one stable activity pattern to another (Baldassano et al., 2017) during movie viewing; these periods of relative stability were referred to as &quot;neural states&quot; to distinguish them from subjectively perceived events. Sensory regions like visual and auditory cortex showed faster transitions between neural states. Multi-modal regions like the posterior medial cortex, angular gyrus, and intraparietal sulcus showed slower neural state shifts, and these shifts aligned with subjectively reported event boundaries. Geerligs et al. (2021, 2022) employed a different analytical approach called Greedy State Boundary Search (GSBS) to identify neural state boundaries. Their findings echoed the HMM results: short-lived neural states were observed in early sensory areas (visual, auditory, and somatosensory cortex), while longer-lasting states appeared in multi-modal regions, including the angular gyrus, posterior middle/inferior temporal cortex, precuneus, anterior temporal pole, and anterior insula. Particularly prolonged states were found in higher-order regions such as lateral and medial prefrontal cortex...</p>
<p>The previous evidence about evoked responses at event boundaries indicates that these are dynamic phenomena evolving over many seconds, with different brain areas showing different dynamics (Ben-Yakov &amp; Henson, 2018; Burunat et al., 2024; Kurby &amp; Zacks, 2018; Speer et al., 2007; Zacks, 2010). Less is known about the dynamics of pattern shifts at event boundaries, because the HMM and GSBS analysis methods do not directly provide moment-by-moment measures of pattern shifts. For example, one question is whether shifts in higher-order regions precedes or follow shifts in lower-level regions. Both the spatial and temporal aspects of evoked responses and pattern shifts at event boundaries have the potential to provide evidence about potential control processes for event model updating.”</p>
<p>Excerpt from Discussion:</p>
<p>“We first characterized the neural signatures of human event segmentation by examining both univariate activity changes and multivariate pattern changes around subjectively identified event boundaries. Using multivariate pattern dissimilarity, we observed a structured progression of neural reconfiguration surrounding human-identified event boundaries. The largest pattern shifts were observed near event boundaries (~4.5s before) in dorsal attention and parietal regions; these correspond with regions identified by Geerligs et al. as shifting their patterns on an intermediate timescale (2022). We also observed smaller pattern shifts roughly 12 seconds prior to event boundaries in higher-order regions within anterior temporal cortex and prefrontal cortex, and these are slow-changing regions identified by Geerligs et al. (2022). This is puzzling. One prevalent proposal, based on the idea of a cortical hierarchy of increasing temporal receptive windows (TRWs), suggests that higher-order regions should update representations after lower-order regions do (Chang et al., 2021). In this view, areas with shorter TRWs (e.g., word-level processors) pass information upward, where it is integrated into progressively larger narrative units (phrases, sentences, events). This proposal predicts neural shifts in higher-order regions to follow those in lower-order regions. By contrast, our findings indicate the opposite sequence. Our findings suggest that the brain might engage in top-down event representation updating, with changes in coarser-grain representations propagating downward to influence finer-grain representations. (Friston, 2005; Kuperberg, 2021). For example, in a narrative where the main goal is achieved midway—such as a detective solving a mystery before the story formally ends—higher-order regions might update the overarching event representation at that point, and this updated model could then cascade down to reconfigure how lower-level regions process the remaining sensory and contextual details. In the period after a boundary (around +12 seconds), we found widespread stabilization of neural patterns across the brain, suggesting the establishment of a new event model. Future work could focus on understanding the mechanisms behind the temporal progression of neural pattern changes around event boundaries.”</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public review):</bold></p>
<p>Summary:</p>
<p>Tan et al. examined how multivoxel patterns shift in time windows surrounding event boundaries caused by both prediction errors and prediction uncertainty. They observed that some regions of the brain show earlier pattern shifts than others, followed by periods of increased stability. The authors combine their recent computational model to estimate event boundaries that are based on prediction error vs. uncertainty and use this to examine the moment-to-moment dynamics of pattern changes. I believe this is a meaningful contribution that will be of interest to memory, attention, and complex cognition research.</p>
<p>Strengths:</p>
<p>The authors have shown exceptional transparency in terms of sharing their data, code, and stimuli, which is beneficial to the field for future examinations and to the reproduction of findings. The manuscript is well written with clear figures. The study starts from a strong theoretical background to understand how the brain represents events and has used a well-curated set of stimuli. Overall, the authors extend the event segmentation theory beyond prediction error to include prediction uncertainty, which is an important theoretical shift that has implications in episodic memory encoding, the use of semantic and schematic knowledge, and attentional processing.</p>
<p>We thank the reader for their support for our use of open science practices, and for their appreciation of the importance of incorporating prediction uncertainty into models of event comprehension.</p>
<p>Weaknesses:</p>
<p>The data presented is limited to the cortex, and subcortical contributions would be interesting to explore. Further, the temporal window around event boundaries of 20 seconds is approximately the length of the average event (21.4 seconds), and many of the observed pattern effects occur relatively distal from event boundaries themselves, which makes the link to the theoretical background challenging. Finally, while multivariate pattern shifts were examined at event boundaries related to either prediction error or prediction uncertainty, there was no exploration of univariate activity differences between these two different types of boundaries, which would be valuable.</p>
</disp-quote>
<p>The fact that we observed neural pattern shifts well before boundaries was indeed unexpected, and we now offer a more extensive interpretation in the discussion section. Specifically, we added text noting that shifts emerged in higher-order anterior temporal and prefrontal regions roughly 12 seconds before boundaries, whereas shifts occurred in lower-level dorsal attention and parietal regions closer to boundaries. This sequence contrasts with the traditional bottom-up temporal hierarchy view and instead suggests a possible top-down updating mechanism, in which higher-order representations reorganize first and propagate changes to lower-level areas (Friston, 2005; Kuperberg, 2021). (See excerpt for Reviewer 1’s comment #5.)</p>
<p>With respect to univariate activity, we did not find strong differences between error-driven and uncertainty-driven boundaries. This makes the multivariate analyses particularly informative for detecting differences in neural pattern dynamics. To support further exploration, we have also shared the temporal progression of univariate BOLD responses on OpenNeuro for interested researchers.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #3 (Public review):</bold></p>
<p>Summary:</p>
<p>The aim of this study was to investigate the temporal progression of the neural response to event boundaries in relation to uncertainty and error. Specifically, the authors asked (1) how neural activity changes before and after event boundaries, (2) if uncertainty and error both contribute to explaining the occurrence of event boundaries, and (3) if uncertainty and error have unique contributions to explaining the temporal progression of neural activity.</p>
<p>Strengths:</p>
<p>One strength of this paper is that it builds on an already validated computational model. It relies on straightforward and interpretable analysis techniques to answer the main question, with a smart combination of pattern similarity metrics and FIR. This combination of methods may also be an inspiration to other researchers in the field working on similar questions. The paper is well written and easy to follow. The paper convincingly shows that (1) there is a temporal progression of neural activity change before and after an event boundary, and (2) event boundaries are predicted best by the combination of uncertainty and error signals.</p>
</disp-quote>
<p>We thank the reviewer for their thoughtful and supportive comments, particularly regarding the use of the computational model and the analysis approaches.</p>
<disp-quote content-type="editor-comment">
<p>Weaknesses:</p>
<p>(1) The current analysis of the neural data does not convincingly show that uncertainty and prediction error both contribute to the neural responses. As both terms are modelled in separate FIR models, it may be that the responses we see for both are mostly driven by shared variance. Given that the correlation between the two is very high (r=0.49), this seems likely. The strong overlap in the neural responses elicited by both, as shown in Figure 6, also suggests that what we see may mainly be shared variance. To improve the interpretability of these effects, I think it is essential to know whether uncertainty and error explain similar or unique parts of the variance. The observation that they have distinct temporal profiles is suggestive of some dissociation, but not as convincing as adding them both to a single model.</p>
</disp-quote>
<p>We appreciate this point. It is closely related to Reviewer 1's comment 2; please refer to our response above.</p>
<disp-quote content-type="editor-comment">
<p>(2) The results for uncertainty and error show that uncertainty has strong effects before or at boundary onset, while error is related to more stabilization after boundary onset. This makes me wonder about the temporal contribution of each of these. Could it be the case that increases in uncertainty are early indicators of a boundary, and errors tend to occur later?</p>
</disp-quote>
<p>We also share the intuition that increases in uncertainty are early indicators of a boundary, and errors tend to occur later. If that is the case, we would expect some lags between prediction uncertainty and prediction error. We examined lagged correlation between prediction uncertainty and prediction error, and the optimal lag is 0 for both uncertainty-driven and error-driven models. This indicates that when prediction uncertainty rises, prediction error also simultaneously rises.</p>
<fig id="sa4fig1">
<label>Author response image 1.</label>
<graphic mime-subtype="jpg" xlink:href="elife-107955-sa4-fig1.jpg" mimetype="image"/>
</fig>
<disp-quote content-type="editor-comment">
<p>(3) Given that there is a 24-second period during which the neural responses are shaped by event boundaries, it would be important to know more about the average distance between boundaries and the variability of this distance. This will help establish whether the FIR model can properly capture a return to baseline.</p>
</disp-quote>
<p>We have added details about the distribution of event lengths. Specifically, we now report that the mean length of subjectively identified events was 21.4 seconds (median 22.2 s, SD 16.1 s). For model-derived boundaries, the average event lengths were 28.96 seconds for the uncertainty-driven model and 24.7 seconds for the error-driven model.</p>
<p>&quot;For each activity, a separate group of 30 participants had previously segmented each movie to identify fine-grained event boundaries (Bezdek et al., 2022). The mean event length was 21.4 s (median 22.2 s, SD 16.1 s). Mean event lengths for uncertainty-driven model and error-driven model were 28.96s, and 24.7s, respectively.&quot;</p>
<disp-quote content-type="editor-comment">
<p>(4) Given that there is an early onset and long-lasting response of the brain to these event boundaries, I wonder what causes this. Is it the case that uncertainty or errors already increase at 12 seconds before the boundaries occur? Or if there are other makers in the movie that the brain can use to foreshadow an event boundary? And if uncertainty or errors do increase already 12 seconds before an event boundary, do you see a similar neural response at moments with similar levels of error or uncertainty, which are not followed by a boundary? This would reveal whether the neural activity patterns are specific to event boundaries or whether these are general markers of error and uncertainty.</p>
</disp-quote>
<p>We appreciate this point; it is similar to reviewer 2’s comment 2. Please see our response to that comment above.</p>
<disp-quote content-type="editor-comment">
<p>(5) It is known that different brain regions have different delays of their BOLD response. Could these delays contribute to the propagation of the neural activity across different brain areas in this study?</p>
</disp-quote>
<p>Our analyses use ±20 s FIR windows, and the key effects we report include shifts ~12s before boundaries in higher-order cortex and ~4.5s pre-boundary in dorsal attention/parietal areas. Given the literature above, region-dependent BOLD delays are much smaller (~1–2s) than the temporal structure we observe (Taylor et al., 2018), making it unlikely that HRF lag alone explains our multi-second, region-specific progression.</p>
<disp-quote content-type="editor-comment">
<p>(6) In the FIR plots, timepoints -12, 0, and 12 are shown. These long intervals preclude an understanding of the full temporal progression of these effects.</p>
</disp-quote>
<p>For page length purposes, we did not include all timepoints. We uploaded an animation of all timepoints in Openneuro for interested researchers.</p>
<p>References</p>
<p>Taylor, A. J., Kim, J. H., &amp; Ress, D. (2018). Characterization of the hemodynamic response function across the majority of human cerebral cortex. NeuroImage, 173, 322–331. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2018.02.061">https://doi.org/10.1016/j.neuroimage.2018.02.061</ext-link></p>
</body>
</sub-article>
</article>