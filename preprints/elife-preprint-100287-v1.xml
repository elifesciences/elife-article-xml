<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">100287</article-id>
<article-id pub-id-type="doi">10.7554/eLife.100287</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.100287.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Stimulus representation in human frontal cortex supports flexible control in working memory</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0006-0886-4606</contrib-id>
<name>
<surname>Shao</surname>
<given-names>Zhujun</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n1">3</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0006-9197-1698</contrib-id>
<name>
<surname>Zhang</surname>
<given-names>Mengya</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">3</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8480-7634</contrib-id>
<name>
<surname>Yu</surname>
<given-names>Qing</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Institute of Neuroscience, Key Laboratory of Brain Cognition and Brain-inspired Intelligence Technology, Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences</institution>, <city>Shanghai</city>, <country>China</country></aff>
<aff id="a2"><label>2</label><institution>University of Chinese Academy of Sciences</institution>, <city>Beijing</city>, <country>China</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Xue</surname>
<given-names>Gui</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Beijing Normal University</institution>
</institution-wrap>
<city>Beijing</city>
<country>China</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>Correspondence should be addressed to: Qing Yu Institute of Neuroscience, Key Laboratory of Brain Cognition and Brain-inspired Intelligence Technology, Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, Shanghai 200031, China Email: <email>qingyu@ion.ac.cn</email></corresp>
<fn id="n1" fn-type="equal"><label>3</label><p>These authors contributed equally</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-09-03">
<day>03</day>
<month>09</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP100287</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-06-06">
<day>06</day>
<month>06</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-06-07">
<day>07</day>
<month>06</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.07.28.551058"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Shao et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Shao et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-100287-v1.pdf"/>
<abstract>
<title>Abstract</title><p>When holding visual information temporarily in working memory (WM), the neural representation of the memorandum is distributed across various cortical regions, including visual and frontal cortices. However, the role of stimulus representation in visual and frontal cortices during WM has been controversial. Here we tested the hypothesis that stimulus representation persists in the frontal cortex to facilitate flexible control demands in WM. During functional MRI, participants flexibly switched between simple WM maintenance of visual stimulus or more complex rule-based categorization of maintained stimulus on a trial-by-trial basis. Our results demonstrated enhanced stimulus representation in the frontal cortex that tracked demands for active WM control and enhanced stimulus representation in the visual cortex that tracked demands for precise WM maintenance. This differential frontal stimulus representation traded off with the newly-generated category representation with varying control demands. Simulation using multi-module recurrent neural networks replicated human neural patterns when stimulus information was preserved for network readout. Altogether, these findings help reconcile the long-standing debate in WM research, and provide empirical and computational evidence that flexible stimulus representation in the frontal cortex during WM serves as a potential neural coding scheme to accommodate the ever-changing environment.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>visual working memory</kwd>
<kwd>cognitive flexibility</kwd>
<kwd>frontal cortex</kwd>
<kwd>visual cortex</kwd>
<kwd>fMRI</kwd>
<kwd>recurrent neural network</kwd>
</kwd-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>An additional experiment conducted; paper revised;</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Real-world flexible behavior relies largely on working memory (WM), which allows the maintenance and manipulation of information in the brain in order to serve diverse behavioral goals (<xref ref-type="bibr" rid="c2">Baddeley, 2003</xref>). One central problem in the field of WM is to understand how stimulus information is represented and maintained in WM. Over the past decade, mounting evidence has demonstrated stimulus-specific representation during WM maintenance in a distributed cortical network, including sensory, parietal, and frontal cortices (<xref ref-type="bibr" rid="c11">Christophel et al., 2012</xref>; <xref ref-type="bibr" rid="c21">Ester et al., 2015</xref>; <xref ref-type="bibr" rid="c29">Gosseries et al., 2018</xref>; <xref ref-type="bibr" rid="c32">Harrison &amp; Tong, 2009</xref>; <xref ref-type="bibr" rid="c50">Riggall &amp; Postle, 2012</xref>; <xref ref-type="bibr" rid="c51">Serences et al., 2009</xref>; <xref ref-type="bibr" rid="c53">Sprague &amp; Serences, 2013</xref>; <xref ref-type="bibr" rid="c57">Yu &amp; Shim, 2017</xref>, <xref ref-type="bibr" rid="c58">2019</xref>). However, the exact nature and functions of stimulus representation in different cortical regions remain controversial. Specifically, while neurophysiological studies in non-human primates have mostly emphasized stimulus representation in the frontal cortex (<xref ref-type="bibr" rid="c26">Funahashi et al., 1989</xref>; <xref ref-type="bibr" rid="c28">Fuster &amp; Alexander, 1971</xref>; <xref ref-type="bibr" rid="c36">Leavitt et al., 2017</xref>), neuroimaging work in humans has reported disparate findings. During maintenance of simple visual features, stimulus representation is robustly encoded in the early visual cortex (EVC), which has been taken as the evidence in support of the sensorimotor recruitment hypothesis of WM (<xref ref-type="bibr" rid="c32">Harrison &amp; Tong, 2009</xref>; <xref ref-type="bibr" rid="c50">Riggall &amp; Postle, 2012</xref>; <xref ref-type="bibr" rid="c51">Serences et al., 2009</xref>). Meanwhile, those in the higher-order frontoparietal cortex are typically weaker and less stable (<xref ref-type="bibr" rid="c18">Emrich et al., 2013</xref>; <xref ref-type="bibr" rid="c29">Gosseries et al., 2018</xref>; <xref ref-type="bibr" rid="c50">Riggall &amp; Postle, 2012</xref>; <xref ref-type="bibr" rid="c58">Yu &amp; Shim, 2019</xref>). However, in dynamic environments such as those involving distraction, stimulus representation in EVC could be greatly interrupted or biased (<xref ref-type="bibr" rid="c6">Bettencourt &amp; Xu, 2016</xref>; <xref ref-type="bibr" rid="c31">Hallenbeck et al., 2021</xref>; <xref ref-type="bibr" rid="c40">Lorenc et al., 2018</xref>). In contrast, stimulus representation in the frontal cortex could be robust under certain circumstances including attentional prioritization (<xref ref-type="bibr" rid="c12">Christophel et al., 2018</xref>), categorization (<xref ref-type="bibr" rid="c37">Lee et al., 2013</xref>) and after extensive training (<xref ref-type="bibr" rid="c45">Miller et al., 2022</xref>). To summarize, stimulus representation could vary markedly depending on specific brain regions and memory tasks, complicating the interpretation of potential functions of stimulus representation in WM.</p>
<p>In this study, we consider these apparent discrepancies from the perspective of cognitive flexibility (<xref ref-type="bibr" rid="c4">Badre et al., 2021</xref>; <xref ref-type="bibr" rid="c27">Fusi et al., 2016</xref>; <xref ref-type="bibr" rid="c47">Musslick &amp; Cohen, 2021</xref>). We propose that changes in stimulus representation in different cortical regions might reflect a global reconfiguration in coding strategy and resource allocation in response to varied WM functions (<xref ref-type="bibr" rid="c33">Henderson et al., 2022</xref>; <xref ref-type="bibr" rid="c37">Lee et al., 2013</xref>). To elaborate, beyond the passive maintenance of incoming sensory information, WM provides an online mental workspace for active manipulation and control of stimulus contents (<xref ref-type="bibr" rid="c2">Baddeley, 2003</xref>; <xref ref-type="bibr" rid="c44">Miller &amp; Cohen, 2001</xref>). As control functions often result in the generation and maintenance of new information, the brain needs to manage not only the original stimulus information but also the newly generated information in WM. Due to the limited cognitive resources available, it is likely that original stimulus representation in WM could adapt flexibly to various task goals beyond simple maintenance of WM contents, which might also co-vary with changes in the representation of the newly-generated information, leading to a systematic reconfiguration in representations of all levels across various cortices. We make two specific predictions from this account. First, in accordance with the findings of elevated neural activity in the frontal cortex with increasing demand for memory manipulation (<xref ref-type="bibr" rid="c16">D’Esposito et al., 1999</xref>; <xref ref-type="bibr" rid="c17">D’Esposito et al., 2000</xref>) and cognitive control (<xref ref-type="bibr" rid="c3">Badre, 2008</xref>; <xref ref-type="bibr" rid="c5">Badre et al., 2010</xref>; <xref ref-type="bibr" rid="c44">Miller &amp; Cohen, 2001</xref>), stimulus representation in frontal cortex should be enhanced for active-control-related functions in WM. By contrast, due to the precise nature of stimulus representation in visual cortex, stimulus representation in this region should be enhanced for precise-maintenance-related functions in WM (<xref ref-type="bibr" rid="c33">Henderson et al., 2022</xref>; <xref ref-type="bibr" rid="c37">Lee et al., 2013</xref>). Second, within the brain regions that encode the newly generated information, a dynamic tradeoff between representations of original and new information should be observed to achieve flexible allocation of limited cognitive resources (<xref ref-type="bibr" rid="c4">Badre et al., 2021</xref>; <xref ref-type="bibr" rid="c23">Flesch et al., 2022</xref>).</p>
<p>Using functional magnetic resonance imaging (fMRI), we directly tested this account by systematically investigating stimulus representation in visual, parietal, and frontal cortices during WM tasks with varying demands for active control. In particular, we surmised that stimulus representation in the frontal cortex would increase to accommodate complex control demands such as rule-based categorization. To this end, we employed a visual WM paradigm that required flexible switching between maintenance and categorization tasks. Specifically, in the maintenance task, participants maintained one visual orientation throughout a delay period, whereas in the categorization task participants were required to categorize the remembered orientation into one of two categories in accordance with previously learned rules, which could be either switched randomly between two rules on a block-by-block basis (Experiment 1) or fixed with one rule (Experiment 2). Thus, compared with the maintenance task, the categorization task imposed additional control demand of WM information at two different levels.</p>
<p>In line with our prediction, our results showed that stimulus information was more prominently represented in the frontal cortex during categorization than maintenance task, and this differential representation was enhanced with increasing demands for control. Importantly, the strength of stimulus representation in the frontal cortex was predictive of WM behavioral performance in the categorization but not in the maintenance task, implicating a selective involvement of the frontal cortex in control functions. By contrast, stimulus representation in the visual cortex was found to exhibit an opposite pattern, with higher strength for maintenance than categorization task. Moreover, varying control demands across experiments revealed a dynamic tradeoff between stimulus and the newly-generated category representations. To further examine whether the enhanced stimulus representation in the frontal cortex during categorization task could be explained by global coding strategy, we simulated our flexible WM tasks with multi-module recurrent neural networks (RNNs). The results of this computational modeling well replicated our human data when precise stimulus information was preserved at the output during network training. Taken together, our results indicate the importance of the frontal cortex for flexible control in WM and highlight the relative changes of stimulus representation in different cortical regions for varying task demands of WM.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Behavioral learning and performance of WM tasks</title>
<p>In the fMRI session of Experiment 1, human participants (n = 24) completed two tasks, maintenance and categorization, inside an MRI scanner. The maintenance task was a delayed match-to-sample working memory task of orientations. Participants only needed to maintained the cued orientation throughout a memory delay. In categorization task, participants also started with maintaining an orientation. After the task cue, they needed to categorize the remembered orientation into one of two categories using the cued categorization rule. Within an experimental block of nine trials, participants randomly switched between the two tasks. Across blocks, participants randomly switched between two categorization rules acquired during a preceding learning session. We randomized response mapping across trials to avoid potential influence by motor-planning signals (see <xref rid="fig1" ref-type="fig">Figure 1A</xref> for probe design). Prior to the main session, participants first completed a behavioral learning session to learn two categorization rules (Rule A and Rule B, see <xref rid="fig1" ref-type="fig">Figure 1B</xref>) that were orthogonal to each other. Participants acquired the two rules with equal familiarity (<italic>t</italic>(23) = 0.24, <italic>p</italic> = 0.813; for Rule A, <italic>M</italic> = 0.85, <italic>SD</italic> = 0.050; for Rule B, <italic>M</italic> = 0.85, <italic>SD</italic> = 0.05; <xref rid="fig1" ref-type="fig">Figure 1C</xref>) and comparable precision (averaged error in reported boundaries for Rule A were 8.80° ± 6.29° and that for Rule B was 9.02° ± 5.69°; <xref rid="fig1" ref-type="fig">Figure 1D</xref>).</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Experimental design and behavioral performance.</title>
<p>(A) Main task procedure. Each block started with a rule cue indicating the categorization rule for this block. On each trial, participants saw two orientations consecutively and were then cued to remember one of the orientations. In maintenance task (cued by letter ‘P’), participants needed to maintain the remembered orientation as precisely as possible. In categorization task (cued by letter ‘C’), participants needed to categorize the remembered orientation following the categorization rule of the current block. maintenance and categorization trials were interleaved within an experimental block of nine trials. Categorization rule (Rule A or Rule B) switched randomly on a block-by-block basis. Response keys (‘F’ and ’J’) for categorization task were randomly assigned to the two categories. Each pair of keys displayed at random locations within the category to eliminate information on rule boundaries. (B) Illustration of the two orthogonal categorization rules (Rule A and Rule B). (C) Rule learning performance during learning session for Rule A (purple) and Rule B (pink). (D) Errors in participants’ self-reported rule boundaries. Errors were calculated as the average distance from reported boundaries to ground truth boundaries. (E) Accuracy compared between tasks. Boxplots show the median and the 25<sup>th</sup> and 75<sup>th</sup> percentiles. Whiskers extend to 1.5 Inter quartile range (IQR) from the quartiles. Asterisks denote significant results, n.s.: not significant; **: <italic>p</italic> &lt; 0.01. (F) Reaction time compared between tasks. Same conventions as (E). (G) Upper panel: accuracy in relation to distance from categorization boundaries. Lower panel: reaction time in relation to distance from categorization boundaries. Shaded areas represent ± SEM.</p></caption>
<graphic xlink:href="551058v2_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Overall, participants performed equally well on both tasks in the fMRI session. Accuracy for the maintenance task (<italic>M</italic> ± <italic>SD</italic>: 0.81 ± 0.07) and that for the categorization task (0.82 ± 0.05) did not significantly differ (<italic>t</italic>(23) = 1.51, <italic>p</italic> = 0.144; <xref rid="fig1" ref-type="fig">Figure 1E</xref>), suggesting that the two tasks were matched in terms of task difficulty. In line with previous categorization studies (<xref ref-type="bibr" rid="c22">Ester et al., 2020</xref>; <xref ref-type="bibr" rid="c24">Freedman &amp; Assad, 2006</xref>) demonstrating a boundary effect, only in the categorization task but not in the maintenance task did participants perform better for trials distant from category boundaries in terms of both accuracy and reaction time (see <xref rid="fig1" ref-type="fig">Figure 1G</xref>). These results demonstrated the effect of categorization and confirmed that participants faithfully followed task instructions.</p>
</sec>
<sec id="s2b">
<title>Enhanced stimulus representation in frontal cortex during categorization task</title>
<p>The primary goal of this study was to determine the role of stimulus representation in various cortices in WM. Using conventional multivariate encoding and decoding methods, we tracked stimulus (i.e., orientation) representation in three brain regions of interest (ROIs) that have been implicated in representing WM information, including early visual cortex (EVC), intraparietal sulcus (IPS), and superior precentral sulcus (sPCS) (<xref ref-type="bibr" rid="c12">Christophel et al., 2018</xref>; <xref ref-type="bibr" rid="c21">Ester et al., 2015</xref>; <xref ref-type="bibr" rid="c31">Hallenbeck et al., 2021</xref>; <xref ref-type="bibr" rid="c57">Yu &amp; Shim, 2017</xref>).</p>
<p>First, we used multivariate inverted encoding models (IEMs) (<xref ref-type="bibr" rid="c9">Brouwer &amp; Heeger, 2009</xref>, <xref ref-type="bibr" rid="c10">2011</xref>; <xref ref-type="bibr" rid="c21">Ester et al., 2015</xref>; <xref ref-type="bibr" rid="c49">Rademaker et al., 2019</xref>; <xref ref-type="bibr" rid="c57">Yu &amp; Shim, 2017</xref>) to reconstruct orientation representation at the population level in each ROI. <xref rid="fig2" ref-type="fig">Figure 2A</xref> shows example orientation reconstructions from representative time points, and <xref rid="fig2" ref-type="fig">Figure 2C</xref> demonstrates the time course of orientation reconstruction as quantified by representational fidelity. A larger fidelity value indicates a stronger orientation representation (<xref rid="fig2" ref-type="fig">Figure 2B</xref>). In EVC, we found significant orientation representation in both maintenance and categorization tasks starting from the sample period (<xref rid="fig2" ref-type="fig">Figure 2C</xref> left panel; see <xref ref-type="table" rid="tbls1">Supplemental Table 1</xref> for full statistics), even when the categorization task did not require explicit memory of stimulus information. Additionally, the strength of orientation representation in the maintenance task became significantly higher than that in the categorization task after the task cue during the delay, suggesting the strength of orientation representations in EVC reflected the degrees of task demands for maintaining visual details. In IPS, orientation representation was significant in both tasks, but did not differ from each other at most time points (<xref rid="fig2" ref-type="fig">Figure 2C</xref> middle panel). In sPCS, a reversed pattern was observed. In the maintenance task, orientation information was maintained during early delay period and then dropped to baseline level during late delay period. By contrast, in the categorization task, orientation representation was persistent throughout the delay and response periods. The strength of orientation representation in the categorization task became statistically higher than that in the maintenance task in late delay period (<xref rid="fig2" ref-type="fig">Figure 2C</xref> right panel), suggesting that this differential representations of visual stimulus in the frontal cortex reflected the demand for active control of memory contents. To facilitate comparison of the differential stimulus representation across ROIs, we averaged the difference in representational strength across a late task epoch (11 – 16 s), and the difference in stimulus representation between ROIs remained (<xref rid="fig2" ref-type="fig">Figure 2D</xref>).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Orientation reconstructions at the population level using IEMs.</title>
<p>(A) Reconstructed population-level orientation representations from selected time points at EVC, IPS, and sPCS for maintenance (blue) and categorization (orange) tasks, respectively. X axis represents distance from the cued orientation (at 0°), and y axis represents reconstructed channel responses in arbitrary units. Significant orientation representation was observed at 6 s and 12 s but not at 0 s. Shaded areas represent ± SEM. (B) To quantify the strength of orientation reconstructions, we calculated the reconstruction fidelity by first projecting the channel response at each orientation onto a vector at the cued orientation and then averaging the projected vectors. (C) Time course of representational strength of orientations at EVC, IPS and sPCS. Gray shaded areas indicate the entire memory delay following task cue. Blue and orange dots at the bottom indicate the FDR-corrected significance of representational fidelity at each time point of the corresponding task at <italic>p</italic> &lt; 0.05 (small), <italic>p</italic> &lt; 0.01 (medium), and <italic>p</italic> &lt; 0.001 (large). The bottom black dots indicate significant difference in representational fidelity between tasks (uncorrected). Horizontal dashed lines represent a baseline of 0. Shaded areas represent ± SEM. (D) Average difference of representational strength across 11 – 16 s in each ROI (from EVC to sPCS: <italic>p</italic> &lt; 0.00001, <italic>p</italic> = 0.063, <italic>p</italic> = 0.007, respectively). Positive difference indicates higher representational strength for categorization, and vice versa for negative difference. Black asterisks denote FDR-corrected significance, *: <italic>p</italic> &lt; 0.05; **: <italic>p</italic> &lt; 0.01; ***: <italic>p</italic> &lt; 0.001.</p></caption>
<graphic xlink:href="551058v2_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We validated the difference in stimulus representations through a series of control analyses. First, we demonstrated that these results cannot be explained by the specific model used to train the data (<xref ref-type="bibr" rid="c39">Liu et al., 2018</xref>; <xref ref-type="bibr" rid="c52">Sprague et al., 2018</xref>) nor the specific analytical approach used, because similar patterns were observed when we trained the IEM separately for each condition (<xref ref-type="fig" rid="figs2">Figure S2A</xref>) or adopted a Support Vector Machine (SVM) decoding approach (<xref ref-type="fig" rid="figs2">Figure S2D</xref>) (<xref ref-type="bibr" rid="c33">Henderson et al., 2022</xref>; <xref ref-type="bibr" rid="c49">Rademaker et al., 2019</xref>). Mean activation differences between tasks cannot account for the results either, because when we removed the mean differences in BOLD activity between tasks, the difference in representational strength remained (<xref ref-type="fig" rid="figs2">Figure S2C</xref>). Furthermore, to remove the potential impact of voxel number on IEM, we selected the top 500 of most sample- or delay-selective voxels from each ROI and trained IEM using the selected voxels. Again, this analysis yielded similar findings (<xref ref-type="fig" rid="figs2">Figure S2B</xref>). Together, these results demonstrated enhanced stimulus representation in the frontal cortex with increased demand for active control, as well as those in the visual cortex with increased demand for precise WM maintenance.</p>
</sec>
<sec id="s2c">
<title>Prediction of categorization behavior by frontal stimulus representation</title>
<p>Previous WM studies have shown that the strength of stimulus representation in EVC positively correlated with memory performance (<xref ref-type="bibr" rid="c18">Emrich et al., 2013</xref>; <xref ref-type="bibr" rid="c20">Ester et al., 2013</xref>; <xref ref-type="bibr" rid="c29">Gosseries et al., 2018</xref>), suggesting that EVC plays an important role in precise WM maintenance. However, stimulus representation in the frontal cortex rarely predicted behavioral performance in maintenance task (<xref ref-type="bibr" rid="c31">Hallenbeck et al., 2021</xref>). Nevertheless, if frontal stimulus representation is involved in WM control, its behavioral relevance should be subject to observation with increased control demands. Therefore, we assessed the behavioral predictability of stimulus representation during the delay period in EVC, IPS, and sPCS (<xref rid="fig3" ref-type="fig">Figure 3</xref>). Consistent with previous findings, we found the strength of stimulus representation in EVC during the early delay period predicted behavioral accuracies in both maintenance and categorization tasks (see <xref ref-type="table" rid="tbls2">Supplemental Table 2</xref> for full statistics). Similar predictability was found in IPS, with stimulus representation predicted behavior in the maintenance task during early delay and in the categorization task throughout the entire memory delay. Interestingly, we found that, throughout the entire memory delay, the strength of stimulus representation in sPCS predicted behavioral accuracies only in the categorization task but not in the maintenance task. These results highlighted the functional significance of stimulus representation in sPCS exclusively for the categorization task.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Behavioral correlation of stimulus representation for maintenance (blue) and categorization (orange) tasks.</title>
<p>(A) Time course of correlation coefficients in EVC, IPS, and sPCS. Gray shaded areas indicate the entire memory delay following task cue. Blue and orange dots at the top indicate significance of correlation (uncorrected) at each time point at <italic>p</italic> &lt; 0.05 (small), <italic>p</italic> &lt; 0.01 (medium), and <italic>p</italic> &lt; 0.001 (large). (B) Correlation scatter plots at representative time points (7 s and at 12 s) in EVC, IPS, and sPCS. R denotes Pearson correlation coefficients. Asterisks denote significant results, *: <italic>p</italic> &lt; 0.05; **: <italic>p</italic> &lt; 0.01.</p></caption>
<graphic xlink:href="551058v2_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2d">
<title>Reduced frontal stimulus representation with lower control demand</title>
<p>In Experiment 1, participants flexibly switched between two categorization rules to prompt the manipulation of WM content on a trial-by-trial basis. The rule switching increased control demand but also complicated the interpretation of our results. To exclude potential impact of rule switching, we conducted Experiment 2, in which participants performed maintenance and categorization tasks with only one fixed rule. Behavioral results of Experiment 2 again demonstrated a classic boundary effect and were comparable to Experiment 1 (<xref ref-type="fig" rid="figs1">Figure S1</xref>), with no significant difference between experiments in terms of either accuracy or reaction time (<italic>F</italic>s &lt; 1.28, <italic>p</italic>s &gt; 0.26). When using IEMs to reconstruct stimulus representation, we found EVC and IPS both showed patterns similar to those in Experiment 1 (<xref rid="fig4" ref-type="fig">Figure 4A</xref>), with stimulus representation decreased in EVC in categorization task and remained at the same level in IPS between the two tasks (see <xref ref-type="table" rid="tbls3">Supplemental Table 3</xref> for full statistics). The frontal region, sPCS, also showed a differential enhancement of stimulus representation in categorization task as in Experiment 1, but in an earlier delay period (<xref rid="fig4" ref-type="fig">Figure 4A</xref>). To validate such a temporal difference, we defined an additional early task period (5 – 10 s), and confirmed a significant difference in stimulus representation in sPCS during the early (<italic>p</italic> = 0.015; <xref rid="fig4" ref-type="fig">Figure 4B</xref>) but not during the late epoch (<italic>p</italic> = 0.372; <xref rid="fig4" ref-type="fig">Figure 4C</xref>). In addition, we performed a mixed ANOVA on experiments (Experiment 1 vs. 2) and epochs (early vs. late epoch) and observed a significant interaction effect between the two, <italic>F</italic>(1, 46) = 7.43, <italic>p</italic> = 0.009, suggesting that the two experiments differed in terms of the temporal emergence of the differential stimulus representation in the frontal cortex. Taken together, these results are consistent with our expectation that, with reduced control demand, the differential enhancement of stimulus representation in frontal cortex was still present but decreased during late memory delay. Nevertheless, stimulus representation in Experiment 2 still predicted behavioral performance as in Experiment 1, although the difference between task was reduced (<xref ref-type="fig" rid="figs3">Figure S3</xref>).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Orientation reconstructions in Experiment 2 at the population level using IEMs.</title>
<p>(A) Time course of representational strength of orientations at EVC, IPS and sPCS. Gray shaded areas indicate the entire memory delay following task cue. Blue and orange dots at the bottom indicate the FDR-corrected significance of representational fidelity at each time point of the corresponding task at <italic>p</italic> &lt; 0.05 (small), <italic>p</italic> &lt; 0.01 (medium), and <italic>p</italic> &lt; 0.001 (large). The bottom black dots indicate significant difference in representational fidelity between tasks (uncorrected). Horizontal dashed lines represent a baseline of 0. Shaded areas represent ± SEM. (B) Average difference of representational strength across an early task epoch (5 – 10 s) in each ROI. Positive difference indicates higher representational strength for categorization, and vice versa for negative difference (FDR-corrected). n.s.: not significant; *: <italic>p</italic> &lt; 0.05; ***: <italic>p</italic> &lt; 0.001. (C) Average difference of representational strength across a late task epoch (11 – 16 s) in each ROI. Same conventions as (B).</p></caption>
<graphic xlink:href="551058v2_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2e">
<title>Category representation in WM in various cortices</title>
<p>Having observed a differential representation of stimulus in the frontal cortex, we next asked how newly generated information in WM during the categorization task emerged and sustained in the distributed WM network and how representations of the original stimulus and new information interacted. The categorization task could demand additional generation of category information in WM. We therefore trained SVMs to decode category information during the categorization task. For each rule, the SVM decoder was trained to discriminate between the two categories. In both experiments, we found that during the late epoch, category information could be well decoded across ROIs (<italic>ps</italic> &lt; 0.044, <xref rid="fig5" ref-type="fig">Figure 5A</xref>; also see <xref ref-type="fig" rid="figs4">Figure S4A</xref> for full decoding time course), with a marginal difference between experiments in sPCS (<italic>p</italic> = 0.055).</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Decoding performance for category and abstract category information.</title>
<p>(A) Average category decoding accuracy across the delay period (11 – 16 s) in each ROI of both experiments, black asterisks denote FDR-corrected significance, n.s.: not significant; *: <italic>p</italic> &lt; 0.05; ***: <italic>p</italic> &lt; 0.001. (B) Schematic illustration of abstract category decoding. In categorization task, category information can be decoded using category labels according to the true categorization rule. On the other hand, category can also be decoded due to stimulus similarity. Thus, to remove stimulus-dependent categorical information, we calculated an abstract category index by removing decoding accuracy using orthogonal category boundaries (assuming comparable stimulus-dependent effect) from that using true rule boundaries. (C) Average abstract category decoding index across the delay period (11 – 16 s) in each ROI of both experiments, black asterisks denote FDR-corrected significance, n.s.: not significant; *: <italic>p</italic> &lt; 0.05; **: <italic>p</italic> &lt; 0.01.</p></caption>
<graphic xlink:href="551058v2_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>One might argue that the category decoding results could at least be partially attributed to stimulus similarity. To minimize the impact of stimulus similarity on category decoding, we additionally trained another decoder using the opposite rule (i.e., using category labels from the orthogonal rule). We then calculated an abstract category index by subtracting decoding accuracy under the opposite rule from that under the true rule (<xref ref-type="bibr" rid="c46">Mok &amp; Love, 2020</xref>) (<xref rid="fig5" ref-type="fig">Figure 5B</xref>). The rationale was that the amount of stimulus similarity would be comparable for the opposite rule, but additional category information, if existed, should result in higher decoding accuracy for the true rule. After removing stimulus-related signals, average decoding performance of abstract category was only evident in Experiment 2 (<italic>p</italic>s &lt; 0.017) but not in Experiment 1 (<italic>p</italic>s &gt; 0.14) for all ROIs. Moreover, decoding performance of abstract category was significantly higher in Experiment 2 than Experiment 1 in sPCS (<italic>p</italic> = 0.034; <xref rid="fig5" ref-type="fig">Figure 5C</xref>). These results together suggest a potential tradeoff between stimulus difference and category representation in the frontal cortex.</p>
</sec>
<sec id="s2f">
<title>Differential stimulus representation in frontal cortex replicated by RNN modeling</title>
<p>Lastly, we tested how stimulus representation could emerge in frontal cortex at the mechanistic level using recurrent neural network (RNN) models. Our hypothesis is that precise stimulus representation during WM might emerge in frontal cortex in response to complex task demands such as rule-based categorization. In other words, instead of relying (solely) on category representations, the cortical network might have adopted a different strategy to accommodate the flexible task requirements in the current study, for instance, by preserving stimulus information until a later stage of information processing. This different strategy can be implemented by altering the RNN’s output structure. Therefore, the logic of this modeling analysis was to examine whether explicitly placing a demand for the model to preserve stimulus representation would recapitulate our fMRI findings in frontal cortex, in comparison to a model that did not specify such a demand.</p>
<p>Two types of modular RNNs were trained on the maintenance and categorization tasks simultaneously (<xref ref-type="bibr" rid="c42">Masse et al., 2019</xref>; <xref ref-type="bibr" rid="c59">Zhou et al., 2021</xref>). The networks shared common input and hidden layer structures (i.e., orientation-tuned and retro/task cue-related units as the input layer, recurrent units with short-term synaptic plasticity in the hidden layer (80% excitatory + 20% inhibitory units, equally distributed in three separate modules). The only difference was in the structure of the output layer. The first type of RNN (RNN1; n = 20) had only two units in the output layer to indicate networks’ choice (<xref rid="fig6" ref-type="fig">Figure 6A</xref>), whereas the second type of RNN (RNN2; n = 20) had additional units in the output layer corresponding to the original stimulus information. In other words, the second RNN was designed to maintain stimulus information throughout the network modules. For the common hidden layer, we included three hierarchically organized (posterior, middle, and anterior) modules of recurrent units generated according to neurobiological principles of neuronal connections (e.g., denser connectivity within than between modules) to simulate the interconnected brain areas in our ROI-based fMRI analyses above: the posterior module (Module 1, simulating EVC) was directly connected with the input layer, the middle module (Module 2, simulating IPS) received projections from the posterior module and relaying information to the anterior module, and the anterior module (Module 3, simulating sPCS) projected to the output layer. Task events were simulated as numerical inputs to the model, matching the procedures of Experiment 1 (see Methods for details).</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Architecture of RNNs and simulation results.</title>
<p>(A) All networks consist of 3 layers of artificial units: the input, hidden and output layers. For both RNN1 and RNN2, the input layer contains 20 units including 15 orientation-tuned, red) units and 5 cue units (retro-cue and task cue, orange and yellow). The hidden layer consists of three modules of 200 recurrent units with short-term synaptic plasticity (STSP), further divided into 80% excitatory (black) and 20% inhibitory (white). Connectivity within each module (black arrow) is denser compared to between modules (red and green arrows), which only occur between excitatory units. Only excitatory units in module 1 receive projections from the input layer and only excitatory units in module 3 project to the output units. For RNN1, networks output (0,1) or (1,0) through the 2 units in the output layer to indicate responses. For RNN2, the network output (0,1) or (1,0) to report the category to which the cued orientation belonged in the categorization task, or (0,0) in the maintenance task (blue units). Importantly, the models also output the orientation itself through 15 additional orientation-tuned units (red). (B) Difference in orientation decoding between tasks in RNN1 and RNN2. Results were averaged across the delay period. Positive difference indicates higher decoding accuracy for categorization, and negative difference indicates higher decoding accuracy for maintenance. Error bars represent ± SEM. Black asterisks denote FDR-corrected significance, n.s.: not significant; *: <italic>p</italic> &lt; 0.05; **: <italic>p</italic> &lt; 0.01; ***: <italic>p</italic> &lt; 0.001. (C) Average abstract category information across the delay period for RNN1 and RNN2. Same conventions as (B).</p></caption>
<graphic xlink:href="551058v2_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>After successful training, defined as reaching at least 90% accuracies in all tasks in the same training batch, we applied an SVM decoding approach to investigate population-level stimulus representations in neuronal spiking activities of the RNNs. We found that in RNN1, both the middle and anterior modules showed stronger stimulus representation in the maintenance task than the categorization task during the delay period (<italic>p<sub>posterior</sub></italic> = 0.09, <italic>p</italic><sub>middle</sub> = 0.011, <italic>p</italic><sub>anterior</sub> = 0.007; <xref rid="fig6" ref-type="fig">Figure 6B</xref> and Figure S7A), opposite to our fMRI observation in IPS and sPCS. In comparison, decoding performance in RNN2, which was explicitly required to maintain stimulus information for the output, yielded results consistent with our human findings, with increased stimulus decoding performance during categorization only in the anterior module (<italic>p</italic><sub>posterior</sub> = 0.436<italic>, p</italic><sub>middle</sub> = 0.212, <italic>p</italic><sub>anterior</sub> = 0.026; <xref rid="fig6" ref-type="fig">Figure 6B</xref>).</p>
<p>Besides difference in stimulus representation, we further tested whether RNN2 could also replicate the human results on category representation. For this analysis we focused on abstract category representation to fully remove the impact of stimulus on category decoding. To examine the influence of control demand on category decoding, following our fMRI experiment we trained 20 additional RNNs with the same output structure as RNN2 (preserving stimulus information) to perform the tasks with a fixed categorization rule, mimicking the task structure of Experiment 2. Consistent with our human findings, we observed increased abstract category decoding performance in the fixed-rule RNNs compared to the flexible-rule RNNs, throughout the modules (<italic>p<sub>posterior</sub> =</italic> 0.045<italic>, p</italic><sub>middle</sub> = 0.003, <italic>p</italic><sub>anterior</sub> &lt; 0.001; <xref rid="fig6" ref-type="fig">Figure 6C</xref>). By contrast, abstract category decoding in RNN1 across modules demonstrated a distinct pattern from human data, with numerically increasing decoding accuracy towards later modules (<xref rid="fig6" ref-type="fig">Figure 6C</xref>).</p>
<p>Altogether, these findings demonstrated that our fMRI results could be simulated by RNN models when stimulus information for readout was preserved, suggesting that the requirement for flexible control of WM content could demand high-fidelity stimulus representation at the output stage of the model. Notably, we found that RNN2 generally took less iterations for training and had fewer failures in learning the task (with a defined maximal number of iterations).</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>In this study, we investigated the emergence and maintenance of stimulus representation with varied control demands of WM. In a distributed human cortical network encompassing visual, parietal, and frontal cortex, we found enhanced stimulus representations in the frontal cortex that tracked increasing demands on active WM control, as well as enhanced stimulus representations in the visual cortex that tracked the demand for the precise maintenance of WM content. The enhanced stimulus representation in frontal cortex was well predicted by RNNs that preserved stimulus information for readout at the output stage. Together, these results highlight the unique and critical contributions of stimulus representations in different cortical regions for distinct aspects of WM, and help to resolve the current controversy in the roles of various cortices in WM.</p>
<sec id="s3a">
<title>Role of visual cortex in WM maintenance</title>
<p>The visual cortex has been considered a critical site for maintaining visual WM in the context of sensorimotor recruitment hypothesis (<xref ref-type="bibr" rid="c15">D’Esposito &amp; Postle, 2015</xref>; <xref ref-type="bibr" rid="c32">Harrison &amp; Tong, 2009</xref>). This idea, however, has been challenged in recent years due to some seemingly contradictory findings from the human neuroimaging studies. For example, compared to the frontoparietal cortex, mnemonic representations in EVC were found to be more vulnerable to distractors (<xref ref-type="bibr" rid="c6">Bettencourt &amp; Xu, 2016</xref>; <xref ref-type="bibr" rid="c31">Hallenbeck et al., 2021</xref>; <xref ref-type="bibr" rid="c40">Lorenc et al., 2018</xref>). The decodability of memory contents in visual cortex also depends on the specific task type. A previous study showed that in nonvisual tasks that required judgements on object category instead of visual details, memory contents were no longer decodable in the visual cortex (<xref ref-type="bibr" rid="c37">Lee et al., 2013</xref>). In this study, we found that, although the strength of stimulus representation in EVC differed between WM maintenance and categorization tasks, a copy of stimulus representation remained in EVC during the categorization task. Moreover, stimulus representations in both tasks were equally predictive of subsequent memory performance, suggesting the functional significance of EVC representations in WM.</p>
<p>The discrepancy between our results and that of the previous work (<xref ref-type="bibr" rid="c37">Lee et al., 2013</xref>) could be attributed to the fact that our categorization task required participants to manipulate remembered information according to arbitrary yet flexible categorization rules, rather than simply paying selective attention to different aspects (visual details vs. category membership) of everyday objects. In our case, maintaining visual details of the memoranda was critical for accurate behavioral responses. Our finding is consistent with the prediction of sensorimotor recruitment hypothesis that representation of memory contents in the visual cortex is necessary for the precise maintenance of visual information. The observation of robust category representation in early visual cortex during the response period further indicated the recruitment of EVC in categorization, possibly for boundary comparison and rule implementation. In fact, our results are consistent with a recent study demonstrating significant stimulus representation in EVC even when memoranda had been transformed into a motor format (<xref ref-type="bibr" rid="c33">Henderson et al., 2022</xref>). In addition, electrophysiological research in non-human primates has also shown robust feature selectivity in the visual cortex during a categorization task (<xref ref-type="bibr" rid="c8">Brincat et al., 2018</xref>), and recent computational modeling work has suggested intact maintenance of sensory information during categorical judgements (<xref ref-type="bibr" rid="c41">Luu &amp; Stocker, 2021</xref>).</p>
</sec>
<sec id="s3b">
<title>Role of frontal cortex in active WM control</title>
<p>Compared to the prominent role of EVC in memory maintenance, sPCS in the frontal cortex played a dominant role in WM tasks that require active control of memory contents such as categorization. Although stimulus representations in sPCS have been observed during WM in previous studies, the nature of these representations remained debatable. In WM tasks that required mere maintenance of memoranda, stimulus was not always decodable in the frontal cortex (<xref ref-type="bibr" rid="c18">Emrich et al., 2013</xref>; <xref ref-type="bibr" rid="c29">Gosseries et al., 2018</xref>; <xref ref-type="bibr" rid="c50">Riggall &amp; Postle, 2012</xref>), raising the issue of functional significance of stimulus representation in the frontal cortex. On the other hand, stimulus representation in the frontal cortex could become robust in the face of tasks that require attentional prioritization and extensive training (<xref ref-type="bibr" rid="c6">Bettencourt &amp; Xu, 2016</xref>; <xref ref-type="bibr" rid="c12">Christophel et al., 2018</xref>; <xref ref-type="bibr" rid="c31">Hallenbeck et al., 2021</xref>; <xref ref-type="bibr" rid="c40">Lorenc et al., 2018</xref>; <xref ref-type="bibr" rid="c45">Miller et al., 2022</xref>). Our current study contributes to the resolution of this issue by demonstrating that stimulus representation in sPCS increased with increasing demands for WM control. This finding is in line with recent computational studies proposing that active WM functions may involve neuronal mechanisms different from that for passive maintenance. For example, passive maintenance could rely mainly on synaptic plasticity mechanisms, whereas active control functions such as distractor resistance and information manipulation involve more neuronal spiking activity (<xref ref-type="bibr" rid="c42">Masse et al., 2019</xref>; <xref ref-type="bibr" rid="c55">Wang, 2021</xref>). In this study, we provided the first empirical evidence that the frontal cortex exhibits enhanced stimulus representation in categorization task requiring active WM control and this representation is predictive of WM performance. In contrast, stimulus representation of WM maintenance failed to predict WM performance at high control demand. It would be of interest to further investigate whether this active control in the frontal cortex could be generalized to tasks that require other types of WM control such as mental rotation.</p>
</sec>
<sec id="s3c">
<title>WM representations in frontal cortex support cognitive flexibility</title>
<p>Our results in the frontal cortex are also in line with recent theoretical proposals in the field of cognitive flexibility. To behave flexibly in complex environments with limited cognitive resources, two mechanisms have been proposed: low-dimensional abstraction of stimulus representation for generalization and efficient learning, and high-dimensional stimulus representation for separability and flexible readout (<xref ref-type="bibr" rid="c4">Badre et al., 2021</xref>; <xref ref-type="bibr" rid="c23">Flesch et al., 2022</xref>; <xref ref-type="bibr" rid="c27">Fusi et al., 2016</xref>). Within this framework, high-dimensional stimulus representations during WM might emerge in the frontal cortex in response to complex control demands such as rule-based categorization. The results of the two fMRI experiments in the current study jointly demonstrate a dynamic tradeoff between high-dimensional stimulus and low-dimensional category representations depending on the control demand. Specifically, when control demand was reduced with a single categorization rule in Experiment 2 compared to Experiment 1, the differential stimulus representation in the frontal cortex was also reduced during the late delay period, accompanied by an increase in category decoding performance especially in the frontal cortex. This result is consistent with neurophysiological findings in non-human primates: while robust category selectivity was observed in frontoparietal cortex during the delay period of categorization tasks when the animal was trained on the categorization task only (<xref ref-type="bibr" rid="c8">Brincat et al., 2018</xref>; <xref ref-type="bibr" rid="c24">Freedman &amp; Assad, 2006</xref>; <xref ref-type="bibr" rid="c25">Freedman et al., 2001</xref>; <xref ref-type="bibr" rid="c43">McKee et al., 2014</xref>), category selectivity in the parietal cortex was significantly reduced when the animal had been exposed to a maintenance task prior to categorization training (<xref ref-type="bibr" rid="c35">Latimer &amp; Freedman, 2023</xref>). Our RNN simulation further confirmed that this dynamic reconfiguration in information coding at the network level can be well explained by a change in the coding strategy for the network readout. In other words, in flexible environments, and with rich prior experience, the brain might adopt an entirely different strategy for processing information in WM. High-dimensional stimulus information might be preserved in its original identity in the higher-order cortex, potentially reducing processing demands in dealing with each task and thereby facilitating efficiency and flexibility (<xref ref-type="bibr" rid="c4">Badre et al., 2021</xref>; <xref ref-type="bibr" rid="c23">Flesch et al., 2022</xref>; <xref ref-type="bibr" rid="c27">Fusi et al., 2016</xref>). One important future direction would be to further address the meta-control mechanisms that determine the flexible selection of coding strategies for WM (<xref ref-type="bibr" rid="c19">Eppinger et al., 2021</xref>).</p>
</sec>
<sec id="s3d">
<title>Differentiating between frontal and parietal cortex in WM functions</title>
<p>While many previous WM studies have focused on the functional distinction between sensory and frontoparietal cortex, it has remained less clear how frontal and parietal cortex might differ in terms of WM functions. Some studies have reported stimulus representations with similar functionality in frontal and parietal cortex (<xref ref-type="bibr" rid="c12">Christophel et al., 2018</xref>; <xref ref-type="bibr" rid="c58">Yu &amp; Shim, 2019</xref>), while others have observed differential patterns (<xref ref-type="bibr" rid="c34">Hu &amp; Yu, 2023</xref>; <xref ref-type="bibr" rid="c37">Lee et al., 2013</xref>; <xref ref-type="bibr" rid="c38">Li et al., 2023</xref>). We interpret the differential patterns as reflecting a difference in the potential origin of the corresponding cognitive functions. For example, in our study, sPCS demonstrated the most prominent effect for enhanced stimulus representation during categorization as well as the tradeoff between stimulus difference and category representation, suggesting that sPCS might serve as the source region for such effects. On the other hand, IPS did show visually similar patterns to sPCS in some analyses. For instance, stimulus representation in IPS was visually but not statistically higher in the categorization task. These results together support the view that our findings in sPCS do not occur in isolation, but rather reflect a dynamic reconfiguration of functional gradients along the cortical hierarchy from early visual to parietal and then to frontal cortex.</p>
</sec>
</sec>
<sec id="s4">
<title>Conclusion</title>
<p>In conclusion, we observed a distributed cortical network, including early visual, parietal, and frontal cortex, in representing stimulus-specific information in WM. These stimulus representations in visual and frontal cortex played distinct functional roles, with those in EVC contributing primarily to precise maintenance and those in frontal cortex contributing primarily to active control in WM. RNN simulations indicated that the stimulus representation in the frontal cortex might have emerged as a result of output selection to facilitate cognitive flexibility. Collectively, these results help to reconcile current debates on the functional roles of different cortical regions in WM, and provide new insights into how a unified WM framework could support varied control demands.</p>
</sec>
<sec id="s5">
<title>Methods</title>
<sec id="s5a">
<title>Participants</title>
<p>A total of 54 participants were recruited at Chinese Academy of Sciences, Shanghai Branch. Twenty-six healthy participants (21 female, all right-handed, mean age = 24.0 ± 1.4 years) were recruited for Experiment 1. Two were excluded due to failure in completing the experiment or low conformity to task instructions, remaining 24 participants who completed the main experiment (19 female, mean age = 23.92 ± 1.41 years). Twenty-eight (22 female, mean age = 24.14 ± 1.51 years) participants were recruited for Experiment 2. Two quitted after behavioral training and two did not finish scanning due to technical problems with the scanner, resulting in 24 participants (20 female, mean age = 24.13 ± 1.60 years) in the final analyses. All participants were neurologically healthy and eligible for MRI, had normal or corrected-to-normal vision, provided written informed consent approved by the Ethics Committee of Institute of Neuroscience, Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, and were monetarily compensated for their participation. Sample sizes were not estimated a priori but were comparable and even superior to those in previous studies.</p>
</sec>
<sec id="s5b">
<title>Stimuli and Procedure</title>
<p>All stimuli were generated and presented using MATLAB (The MathWorks) and Psychtoolbox 3 extensions (<xref ref-type="bibr" rid="c7">Brainard, 1997</xref>; <xref ref-type="bibr" rid="c48">Pelli, 1997</xref>). During behavioral training, stimuli were presented on a ThinkVision monitor at a viewing distance of 45 cm. Behavioral responses were acquired with a keyboard. During scanning, stimuli were projected onto a SinoRad monitor (1280 x 1024 pixels, refreshing at 60 Hz) viewed through a coil-mounted mirror in the scanner at a viewing distance of 90.5 cm. Participants’ behavioral responses were acquired with a Sinorad MRI-compatible button box.</p>
<sec id="s5b1">
<title>Behavioral Training</title>
<p>In Experiment 1, prior to scanning, participants were trained to learn two novel rules, Rule A and Rule B, for categorizing orientations. Thirty oriented bars were used as sample stimuli, ranging from 5° to 179° (in increments of 6°; two participants used another set of thirty orientations ranging from 4° to 178°). Each abstract rule was constructed by two orthogonal boundaries that divided the thirty orientations into two categories with fifteen orientations each. Rule A and Rule B were orthogonal to each other. Corresponding boundaries were 20°/110° and 65°/155° (15°/105° and 60°/150° for the two participants using different stimuli sets).</p>
<p>Participants learned new rules through a rule learning task. Each run of learning started with a rule disk informing the target rule. To avoid any potential verbal coding, rule specifics were visually illustrated as rule disks containing two distinct colors (colors randomly assigned to categories every time; see <xref rid="fig1" ref-type="fig">Figure 1A</xref> for an example). Rule disk was presented on the screen for 2 s followed by 1 s of fixation. On each trial, an oriented bar (radius=7°) was presented for 1 s followed by a delay of 1 s. Participants were instructed to report the category of the orientation by pressing a response key (‘F’ or ‘J’). To avoid category-response mapping, we randomized the relationship between categories and key buttons across trials. Moreover, to avoid presenting rule boundaries explicitly, we presented key names at random positions within the range defining each category. In other words, participants had to memorize the exact rule boundaries as accurately as possible in order to find the correct key buttons for each trial. Feedback was given at the end of each trial to assist learning.</p>
<p>Participants completed 30 learning trials in each run. They reviewed rule disks after every 10 trials for memory reconsolidation. Each participant completed at least two runs for each rule. After achieving an average accuracy above 86% (26 out of 30 trials) for the first rule, they proceeded to learn the other rule and then to practice the main task for scanning (see next section). Learning order of rules was counterbalanced across subjects. Upon completion of practicing, participants needed to report the boundaries of learned rules as a qualification of behavioral training. If the total error in reported boundaries had exceeded 20°, participants had one more chance to learn by repeating the learning task. Two participants completed one additional behavioral training to recap rule knowledge prior to scanning.</p>
<p>Behavioral training for Experiment 2 followed the same procedure and used the identical sample set (30 orientations ranging from 4° to 178°) as Experiment 1, except that only one rule was trained. Half of the participants in Experiment 2 learned rule boundaries of 19°/109°; the other half learned rule boundaries of 67°/157°.</p>
</sec>
<sec id="s5b2">
<title>Flexible WM Task (fMRI Task)</title>
<p>In Experiment 1, during scanning, participants completed a flexible WM task which implemented levels of control demand with different rules. To be specific, participants randomly switched between a maintenance task and a categorization task. In the maintenance task, participants needed to memorize stimulus information (i.e., orientations). In the categorization task, participants needed to categorize orientations following the rule that was randomly assigned and cued on a block basis. Procedure of the main task was visualized in <xref rid="fig1" ref-type="fig">Figure 1A</xref>. At the beginning of each block, participants were presented with a rule disk for 3 s, followed by a 2-s interval, instructing the categorization rule of the current block. For each trial, participants saw two oriented bars presented successively. Each bar was presented for 0.75 s, with an inter-stimulus-interval of 0.5 s. Sample sets were the same as those used in behavioral training. After a 0.5-s interval, a retro-cue occurred for 0.5 s, indicating the orientation of which participants should remember. After a 1.5-s delay, a task cue was displayed at fixation for 0.5 s, following by an 8-s memory delay. The task cue was either a letter ‘P’ on maintenance trials, instructing participants to maintain the cued orientation during memory delay as precisely as possible; or the task cue was a letter ‘C’ on categorization trials, asking participants to categorize the cued orientation using the block rule during the delay. Then, participants were probed to respond within 2 s. On maintenance trials, participants needed to select the memorized orientation from two probe orientations; while on categorization trials, participants needed to report the category of the cued orientation. Response mapping followed the same operation as in the learning tasks. Inter-trial-intervals were randomly selected from 3, 5, and 7 s with an equal trial number, resulting in an average trial length of 20 s. Participants switched to the next block after every six categorization trials and three maintenance trials. Each run contained two blocks (i.e., 18 trials).</p>
<p>In Experiment 2, to isolate potential effect of rule switching, the categorization rule stayed the same throughout the experiment. In Experiment 2, participants randomly switched between the maintenance task and the categorization task. Each trial followed the same procedure as Experiment 1.</p>
<p>In Experiment 1, orientations, tasks, and cued target order (1st or 2nd) were counterbalanced across trials, resulting in an equal trial number of 90 across all three conditions (categorization-Rule A, categorization-Rule B, and maintenance). Nineteen out of the twenty-four participants completed 15 runs of the main task. One participant completed 13 runs due to technical difficulties with the scanner. Another four participants completed 30 runs across two scan sessions. The same counterbalancing procedure was conducted for Experiment 2 (90 trials for maintenance task and 180 trials for categorization task). In Experiment 2, six participants completed 15 runs of 18 trials; the other seven completed 18 runs of 15 trials each due to scanner limitations. At the end of scanning, participants reported the rule boundaries three times as a final check of their rule memory.</p>
</sec>
</sec>
<sec id="s5c">
<title>Data Acquisition</title>
<p>MRI data of Experiment 1 were collected using a 3 Tesla Siemens MRI scanner (Tim Trio; Siemens Healthineers) with a 32-channel head coil at the Functional Brain Imaging Platform at Institute of Neuroscience, Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences. Functional scanning was performed using a gradient-echo echo-planar sequence with the following parameters: repetition time (TR) = 1000 ms; echo time (TE) = 30 ms; flip angle (FA) = 40°; voxel size = 3 x 3 x 3 mm; multi-band accelerate factor = 4; matrix size = 74 x 74; slice number = 60. A high-resolution anatomical T1 image was collected before functional scanning (TR = 2300 ms; TE = 2.98 ms; FOV = 256 x 240 x 192 mm; voxel size = 1 x 1 x 1 mm). During scanning, participants’ head positions were restricted with surrounding paddings to prevent head movements. MRI data of Experiment 2 were collected using identical procedure and settings except that the last eleven participants were scanned using a newly installed 3 Tesla Siemens MRI scanner (Prisma; Siemens Healthineers) at the Functional Brain Imaging Platform.</p>
</sec>
<sec id="s5d">
<title>Preprocessing</title>
<p>All preprocessing of individual MRI data was performed using AFNI (afni.nimh.nih.gov) (<xref ref-type="bibr" rid="c13">Cox, 1996</xref>; <xref ref-type="bibr" rid="c14">Cox &amp; Hyde, 1997</xref>). Functional data of all runs were registered to the last volume of the final run with the first eight volumes of each run removed. Then, individuals’ aligned functional data were registered to their corresponding T1 volume. Alignment of registration was manually checked for each subject to ensure quality. The registered data were further motion corrected and detrended.</p>
</sec>
<sec id="s5e">
<title>ROI Definition</title>
<p>Our primary ROI-based analyses focused on three most commonly-studied, WM-related brain areas: early visual cortex (EVC), intraparietal sulcus (IPS) in parietal cortex, and superior precentral sulcus (sPCS) in frontal cortex (<xref ref-type="bibr" rid="c21">Ester et al., 2015</xref>; <xref ref-type="bibr" rid="c31">Hallenbeck et al., 2021</xref>; <xref ref-type="bibr" rid="c57">Yu &amp; Shim, 2017</xref>). We created anatomical ROI masks based on the probabilistic atlas by Wang and colleagues (<xref ref-type="bibr" rid="c54">Wang et al., 2015</xref>). EVC (merging bilateral V1, V2, and V3), IPS (merging bilateral IPS0-5), and sPCS masks were generated by warping masks from the probabilistic atlas to individuals’ anatomical image in their native space. In order to generate functional ROI masks, we then performed general linear models (GLMs) to quantify task-related univariate activity changes in each voxel. Task events were modeled using boxcar functions convolved with a canonical hemodynamic response function (durations of event epochs for sample, post retro-cue delay, memory delay, and response were 2.5 s, 2 s, 8.5 s, and 2 s, respectively). Six nuisance regressors were also included to account for head motion artifacts in the six dimensions of rigid body motion. Functional EVC mask was defined by the 500 most active voxels during sample display. Functional IPS and sPCS masks were defined by the 500 most active voxels during memory delay.</p>
</sec>
<sec id="s5f">
<title>MRI Data Analyses</title>
<sec id="s5f1">
<title>Multivariate Inverted Encoding Modeling (IEM)</title>
<p>Neural representations of orientations were reconstructed using inverted encoding modeling (IEM) (<xref ref-type="bibr" rid="c9">Brouwer &amp; Heeger, 2009</xref>, <xref ref-type="bibr" rid="c10">2011</xref>; <xref ref-type="bibr" rid="c21">Ester et al., 2015</xref>; <xref ref-type="bibr" rid="c49">Rademaker et al., 2019</xref>; <xref ref-type="bibr" rid="c57">Yu &amp; Shim, 2017</xref>) with custom MATLAB scripts on individuals’ BOLD activation patterns in the three ROIs. IEM provides an estimate of population-level reconstructions of stimulus-specific information. The general procedure for IEM includes using training data to train model weights and then applying weights to testing data to obtain reconstructed channel responses. For the main analyses, we used trials from all conditions to train and to test IEM in order to avoid potential biases from a specific task condition. Results for categorization task were averaged across rules for Experiment 1. Training and testing were performed for each TR separately. As a control, IEMs were also estimated for each condition separately (within-condition IEM). Training and testing underwent a leave-one-run-out cross-validation procedure, in which each run was taken out as the testing run, and the rest of the data served as the training run. This procedure was iterated until all runs had served as training and testing runs. Results from all cross-validated folds were averaged. Detailed computations for each fold were elucidated below:</p>
<p>We first modeled responses of voxels into nine equidistant orientation channels (initial channels were 1°, 21°, 41°, 61°, 81°, 101°, 121°, 141°, 161°), characterizing voxel selectivity for orientations. At each channel, the modeled orientation tuning curve was a half-wave-rectified and squared sinusoid raised to eighth power, defined as the function below (<italic>c</italic> was the center of the channel):
<disp-formula id="eqn1">
<graphic xlink:href="551058v2_eqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Population-level tuning responses of voxels was described using the function:
<disp-formula id="eqn2">
<graphic xlink:href="551058v2_eqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<italic>B</italic><sub>1</sub> was the training dataset from our fMRI data (ν voxels × <italic>n</italic> trials). <italic>C</italic><sub>1</sub> represented the hypothesized channel responses (<italic>k</italic> channels × <italic>n</italic> trials) which were modulated by <italic>W</italic>, a weight matrix (<italic>ν</italic> voxels × <italic>k</italic> channels).</p>
<p>The least-squared estimates of the weight matrix (<italic>Ŵ</italic>) was computed using linear regression:
<disp-formula id="eqn3">
<graphic xlink:href="551058v2_eqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The weight matrix was then applied on the test dataset to reconstruct estimated channel responses (<italic>Ĉ</italic><sub>2</sub>):
<disp-formula id="eqn4">
<graphic xlink:href="551058v2_eqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The analysis above were repeated for 20 times in step of 1° using leave-one-run-out cross-validation so that the nine channel centers covered all 180 orientations (<xref ref-type="bibr" rid="c49">Rademaker et al., 2019</xref>; <xref ref-type="bibr" rid="c56">Yu &amp; Postle, 2021</xref>). All channel responses were combined to create responses for all 180 orientation channels. For statistical comparisons and for visualization, all channel responses were shifted to a common center of 0° (true orientation of trials). The responses from all trials were averaged to obtain reconstructed orientation representations for the test datasets.</p>
<p>To quantify the strength of each IEM reconstruction, we calculated reconstruction fidelity of channel responses. First, all channel responses were projected to the vector at the true orientation. Then the reconstruction fidelity was calculated as the mean of all projected vectors (<xref ref-type="bibr" rid="c49">Rademaker et al., 2019</xref>). A larger fidelity value indicates a stronger positive representation of orientation.</p>
</sec>
<sec id="s5f2">
<title>Multivariate Pattern Analysis (MVPA)</title>
<p>Besides IEM, we tracked neural representations of stimulus and of category using linear Support Vector Machine (SVM) decoders. All decoding analyses were performed using the templateSVM and fitcecoc functions in MATLAB.</p>
<p>Decoding of stimulus was performed for every TR. We divided the thirty orientations into four bins of 45° each, two cardinal bins centered at 90° or 180° and two oblique bins centered at 45° or 135°. We then performed two two-way classifications, one trained and tested on cardinal bins, and the other trained and tested on oblique bins. We trained and tested decoders separately for each condition using the same leave-one-run-out cross-validation procedure as in IEM analyses. To avoid biases in model training, we randomly balanced the trial numbers for each bin in the training set. Decoding accuracies were then computed by averaging performance of cardinal and oblique classifiers. For the categorization task, we averaged accuracies across rules.</p>
<p>Decoding of category information for Experiment 1 was performed under each rule (90 trials for each rule) using a leave-one-trial-out cross-validation procedure (see next paragraph for details), and the decoding accuracies were then averaged across rules. Since Experiment 2 adopted a fixed rule with 180 trials in the categorization task, we randomly divided categorization trials into two halves with 90 trials each, and decoded category information for Experiment 2 using identical procedures as for Experiment 1.</p>
<p>Because closer orientations are more similar to each other inherently, orientations per se could contain categorical information by visual similarity. Thus, to isolate the influence of stimulus on category, in addition to the decoder using true category labels, we trained an opposite category decoder using category labels based on the opposite rule. If the two-way classification on categories only captured stimulus information, then true category and opposite category decoding should have had comparable performance. If abstract category information existed beyond stimulus information, then true category decoder should have outperformed the opposite category decoder. Thus, an abstract category index was calculated by subtracting opposite category decoding accuracy from true category decoding accuracy (i.e., chance level = 0). Since the opposite category decoding used re-assigned labels, to eliminate imbalance in trial number between true and opposite categories, we used a leave-one-trial-out cross-validation procedure for true category and opposite category decoders. Decoding for Experiment 1 was performed separately for each rule and were then averaged. Decoding for Experiment 2 was performed separately for randomly divided halves and averaged.</p>
</sec>
<sec id="s5f3">
<title>Recurrent Neural Network Simulations</title>
<sec id="s5f3a">
<title>RNN architecture</title>
<p>The network model was built following the details in previous work (<xref ref-type="bibr" rid="c42">Masse et al., 2019</xref>), and implemented in TensorFlow (version: Nvidia-tensorflow 1.15.0) (<xref ref-type="bibr" rid="c1">Abadi et al., 2016</xref>). The general network architecture consisted of three layers of artificial units: the input, hidden, and output layers. The input layer contains units served to present various task-related signals corresponding to those in the fMRI paradigm, including orientations, retro-cues, task cues. In order to simulate neural activity patterns in hierarchically connected brain regions (EVC, IPS and sPCS), we separated the hidden layer into three modules, each containing 200 recurrent units with short-term synaptic plasticity (STSP). Within each module, units were further divided into 80% excitatory and 20% inhibitory following Dale’s principle. Similar to previous work (<xref ref-type="bibr" rid="c59">Zhou et al., 2021</xref>), modularity was achieved by constraining the recurrent connectivity in the hidden layer. Specifically, only posterior module’s (module 1) excitatory units received inputs from the input layer and only anterior module’s (module 3) excitatory units projected to the output units. Between-module connections were culled so that only 50% of a module’s excitatory units were randomly connected to their counterparts in the neighboring module(s), and vice versa (feedforward and feedback connections). Connections among inhibitory units remained strictly within-module in accordance with the observation that inhibitory connections in cortex are largely local. Thus, posterior, middle and anterior modules were intended to simulate the three interconnected ROIs we used in the fMRI analyses that posited differently at the processing hierarchy. We specifically manipulated the output demand to investigate whether it would alter similarity of the results to the fMRI observations. To this end, one type of network architecture (RNN1) implemented a two-unit output layer with each unit corresponding to one of two possible response options, presented through the input units before the test period; In contrast, the other type of RNN architecture (RNN2) had additional units in the output layer, creating a demand for preserving the original stimulus information alongside categorical representations.</p>
</sec>
</sec>
<sec id="s5f4">
<title>Task simulation</title>
<p>Orientations were simulated as Gaussian signals from 15 orientation-tuned units in the input layer distributed equally across 0-180 degrees, forming a ring of receptive field. The magnitude of an orientation-tuned input unit represented the closeness of its preferred orientation to the input angle. Stimulus values were selected from an array of 20 orientations evenly spanned from [0 to 180) degrees. The sequentially-presented stimuli were presented through the same receptive field, followed by retro-cue and task cue indicated through the separate input units. For RNN1, before the test period when the network was required to make a choice, two response options were presented sequentially through the same input receptive field. The selection of the options varied slightly between the maintenance and categorization tasks: in maintenance, one orientation was always the cued sample while the other was randomly chosen from all other possible angles. In categorization, one option was taken from the same category as the cued sample but not necessarily the exact angle, while the other option was randomly chosen from orientations belonging to the other category. The network output (0,1) or (1,0) in the output units to report its choice. In comparison, RNN2 output (0,1) or (1,0) to report the category to which the cued orientation belonged in the categorization task, or (0,0) in the maintenance task. Importantly, the model also needed to report the cued orientation itself through a receptive field consisting of 15 orientation-tuned units in the output layer.</p>
</sec>
<sec id="s5f5">
<title>Training parameters and procedure</title>
<p>The hyperparameters and procedure for training the models were consistent with those detailed in previous work (<xref ref-type="bibr" rid="c42">Masse et al., 2019</xref>), with the following exceptions: standard deviations of input and recurrent noise were set to 0.01 as our tasks were much harder to train compared to those used in the reference study (especially networks were trained on both tasks simultaneously). Lowering the noise level may provide an edge for the models to successfully learn to perform the tasks. In a similar vein, we also expanded the number of hidden units to 600 and number of training iteration to a maximum of 10000. Additionally, spike penalty was set to 0 for both RNN models to remove constraints on neuronal activity.</p>
<p>We trained 20 models for each type of RNN and results were obtained by averaging over all of them (for single-rule RNN, 10 models for each categorization rule). The goal of the training process was to minimize the mean square error between the model outputs and correct outputs during the test period via back propagation (with a 50 ms grace period at onset when model output was not taken into account in calculating error). Training was conducted in a block-interleaved fashion in which each gradient batch consisted of 300 maintenance, 300 categorization Rule A and 300 categorization Rule B trials, with the task block order randomized (for single rule RNN, each batch consisted of 300 maintenance and 300 categorization trials). Training would automatically stop if the model achieved 90% accuracy in the last training batch on all tasks. For RNN2, the accuracies for category and stimulus outputs were calculated separately to ensure precision of the stimulus outputs.</p>
</sec>
<sec id="s5f6">
<title>Population decoding</title>
<p>We measured the strength of stimulus and category representations through training SVMs on time-resolved neuronal activity. Activities were obtained by feeding new batches of tasks into the already-successfully trained networks after freezing all connection weights to prevent further changes to the models’ behaviors. The intrinsic noise for the recurrent layer was also set to 0 for decoding analyses. To ensure accurate decoding results, we sampled large number of trials (900 trials for each condition) and implemented a 5-fold cross-validation procedure in which 80% of trials were used as training set and the remaining 20% as testing set in each fold. Decoders were trained separately for each module and time point.</p>
</sec>
<sec id="s5f7">
<title>Statistical Testing</title>
<p>Participants’ behavioral performance for the main task was assessed using accuracy and reaction time. Paired t-test was conducted for the two task types (maintenance &amp; categorization) to evaluate differences between conditions.</p>
<p>Statistical significance was evaluated via a sign-flip permutation procedure for all other analyses. For example, to characterize the significance of IEM fidelity, we computed the p-value by comparing the true mean fidelity of our sample with a null distribution reflecting no IEM fidelity. The null distribution was created by randomly assigning 1 or -1 to fidelity scores of our sample and then averaging the sign-flipped samples for 10,000 times, resulting in a null distribution of 10,000 fidelity scores. To characterize the difference of IEM fidelity between tasks, we sign-flipped the fidelity sample for each condition and then averaged the difference for 10,000 times. The p-value was calculated by comparing the true mean difference with the generated null distribution of difference. P-values were corrected using FDR across ROIs, time (TRs), and tasks for all analyses unless specified. An early (5-10 s; 6<sup>th</sup>-11<sup>th</sup> TR) and late (11-16 s; 12<sup>th</sup>-17<sup>th</sup> TR) task epoch was also defined to facilitate comparisons between ROIs and experiments when needed.</p>
<p>For RNN decoding results, we adopted a cluster-based permutation approach (using MNE-Python (<xref ref-type="bibr" rid="c30">Gramfort et al., 2013</xref>) function <italic>permutation_cluster_1samp_test</italic> to accommodate the large number of time points to be corrected for) to determine statistical significance of the time course, for stimulus decoding accuracies in maintenance/categorization, difference between stimulus decoding accuracies between tasks, and abstract category decoding accuracy in categorization task. Moreover, we also pooled decoding accuracies across a critical task period (50-75 time points during delay) to produce summary statistics aligning with what was reported in the fMRI results. Average decoding results were corrected using the FDR method.</p>
</sec>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>We would like to thank Dr. Mu-ming Poo for valuable comments on an earlier version of the manuscript, and Dr. Tianming Yang for helpful discussions. This work was supported by the Ministry of Science and Technology of China (STI2030-Major Projects 2021ZD0203701, 2021ZD0204202), the National Natural Science Foundation of China (32271089), CAS Project for Young Scientists in Basic Research (YSBR-071), and Shanghai Pujiang Program (22PJ1414400) to Q.Y.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Abadi</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Barham</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Davis</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Dean</surname>, <given-names>J.</given-names></string-name>, . . . <string-name><surname>Zheng</surname>, <given-names>X</given-names></string-name></person-group>. (<year>2016</year>). <article-title>TensorFlow: A System for Large-Scale Machine Learning</article-title>. <source>12th USENIX Symposium on Operating Systems Design and Implementation</source>, <fpage>265</fpage>–<lpage>283</lpage>.</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Baddeley</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2003</year>). <article-title>Working memory: looking back and looking forward</article-title>. <source>Nat Rev Neurosci</source>, <volume>4</volume>(<issue>10</issue>), <fpage>829</fpage>–<lpage>839</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nrn1201</pub-id></mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Badre</surname>, <given-names>D</given-names></string-name></person-group>. (<year>2008</year>). <article-title>Cognitive control, hierarchy, and the rostro-caudal organization of the frontal lobes</article-title>. <source>Trends Cogn Sci</source>, <volume>12</volume>(<issue>5</issue>), <fpage>193</fpage>–<lpage>200</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.tics.2008.02.004</pub-id></mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Badre</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Bhandari</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Keglovits</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Kikumoto</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2021</year>). <article-title>The dimensionality of neural representations for control</article-title>. <source>Curr Opin Behav Sci</source>, <volume>38</volume>, <fpage>20</fpage>–<lpage>28</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cobeha.2020.07.002</pub-id></mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Badre</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Kayser</surname>, <given-names>A. S.</given-names></string-name>, &amp; <string-name><surname>D’Esposito</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2010</year>). <article-title>Frontal cortex and the discovery of abstract action rules</article-title>. <source>Neuron</source>, <volume>66</volume>(<issue>2</issue>), <fpage>315</fpage>–<lpage>326</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2010.03.025</pub-id></mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bettencourt</surname>, <given-names>K. C.</given-names></string-name>, &amp; <string-name><surname>Xu</surname>, <given-names>Y</given-names></string-name></person-group>. (<year>2016</year>). <article-title>Decoding the content of visual short-term memory under distraction in occipital and parietal areas</article-title>. <source>Nat Neurosci</source>, <volume>19</volume>(<issue>1</issue>), <fpage>150</fpage>–<lpage>157</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.4174</pub-id></mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brainard</surname>, <given-names>D. H</given-names></string-name></person-group>. (<year>1997</year>). <article-title>The Psychophysics Toolbox</article-title>. <source>Spat Vis</source>, <volume>10</volume>(<issue>4</issue>), <fpage>433</fpage>–<lpage>436</lpage>. Retrieved from <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pubmed/9176952">https://www.ncbi.nlm.nih.gov/pubmed/9176952</ext-link></mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brincat</surname>, <given-names>S. L.</given-names></string-name>, <string-name><surname>Siegel</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>von Nicolai</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Miller</surname>, <given-names>E. K.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Gradual progression from sensory to task-related processing in cerebral cortex</article-title>. <source>Proc Natl Acad Sci U S A</source>, <volume>115</volume>(<issue>30</issue>), <fpage>E7202</fpage>–<lpage>E7211</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1717075115</pub-id></mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brouwer</surname>, <given-names>G. J.</given-names></string-name>, &amp; <string-name><surname>Heeger</surname>, <given-names>D. J</given-names></string-name></person-group>. (<year>2009</year>). <article-title>Decoding and reconstructing color from responses in human visual cortex</article-title>. <source>J Neurosci</source>, <volume>29</volume>(<issue>44</issue>), <fpage>13992</fpage>–<lpage>14003</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.3577-09.2009</pub-id></mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brouwer</surname>, <given-names>G. J.</given-names></string-name>, &amp; <string-name><surname>Heeger</surname>, <given-names>D. J</given-names></string-name></person-group>. (<year>2011</year>). <article-title>Cross-orientation suppression in human visual cortex</article-title>. <source>J Neurophysiol</source>, <volume>106</volume>(<issue>5</issue>), <fpage>2108</fpage>–<lpage>2119</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.00540.2011</pub-id></mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Christophel</surname>, <given-names>T. B.</given-names></string-name>, <string-name><surname>Hebart</surname>, <given-names>M. N.</given-names></string-name>, &amp; <string-name><surname>Haynes</surname>, <given-names>J. D</given-names></string-name></person-group>. (<year>2012</year>). <article-title>Decoding the contents of visual short-term memory from human visual and parietal cortex</article-title>. <source>J Neurosci</source>, <volume>32</volume>(<issue>38</issue>), <fpage>12983</fpage>–<lpage>12989</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.0184-12.2012</pub-id></mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Christophel</surname>, <given-names>T. B.</given-names></string-name>, <string-name><surname>Iamshchinina</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Yan</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Allefeld</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Haynes</surname>, <given-names>J. D</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Cortical specialization for attended versus unattended working memory</article-title>. <source>Nat Neurosci</source>, <volume>21</volume>(<issue>4</issue>), <fpage>494</fpage>–<lpage>496</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41593-018-0094-4</pub-id></mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cox</surname>, <given-names>R. W</given-names></string-name></person-group>. (<year>1996</year>). <article-title>AFNI: software for analysis and visualization of functional magnetic resonance neuroimages</article-title>. <source>Comput Biomed Res</source>, <volume>29</volume>(<issue>3</issue>), <fpage>162</fpage>–<lpage>173</lpage>. Retrieved from <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pubmed/8812068">https://www.ncbi.nlm.nih.gov/pubmed/8812068</ext-link></mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cox</surname>, <given-names>R. W.</given-names></string-name>, &amp; <string-name><surname>Hyde</surname>, <given-names>J. S</given-names></string-name></person-group>. (<year>1997</year>). <article-title>Software tools for analysis and visualization of FMRI Data</article-title>. <source>NMR in Biomedicine</source>, <volume>10</volume>, <fpage>171</fpage>–<lpage>178</lpage>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>D’Esposito</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Postle</surname>, <given-names>B. R</given-names></string-name></person-group>. (<year>2015</year>). <article-title>The cognitive neuroscience of working memory</article-title>. <source>Annu Rev Psychol</source>, <volume>66</volume>, <fpage>115</fpage>–<lpage>142</lpage>. doi:<pub-id pub-id-type="doi">10.1146/annurev-psych-010814-015031</pub-id></mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>D’Esposito</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Postle</surname>, <given-names>B. R.</given-names></string-name>, <string-name><surname>Ballard</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Lease</surname>, <given-names>J</given-names></string-name></person-group>. (<year>1999</year>). <article-title>Maintenance versus manipulation of information held in working memory: an event-related fMRI study</article-title>. <source>Brain Cogn</source>, <volume>41</volume>(<issue>1</issue>), <fpage>66</fpage>–<lpage>86</lpage>. doi:<pub-id pub-id-type="doi">10.1006/brcg.1999.1096</pub-id></mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>D’Esposito</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Postle</surname>, <given-names>B. R.</given-names></string-name>, &amp; <string-name><surname>Rypma</surname>, <given-names>B</given-names></string-name></person-group>. (<year>2000</year>). <article-title>Prefrontal cortical contributions to working memory: evidence from event-related fMRI studies</article-title>. <source>Exp Brain Res</source>, <volume>133</volume>(<issue>1</issue>), <fpage>3</fpage>–<lpage>11</lpage>. doi:<pub-id pub-id-type="doi">10.1007/s002210000395</pub-id></mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Emrich</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Riggall</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Larocque</surname>, <given-names>J. J.</given-names></string-name>, &amp; <string-name><surname>Postle</surname>, <given-names>B. R</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Distributed patterns of activity in sensory cortex reflect the precision of multiple items maintained in visual short-term memory</article-title>. <source>J Neurosci</source>, <volume>33</volume>(<issue>15</issue>), <fpage>6516</fpage>–<lpage>6523</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.5732-12.2013</pub-id></mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eppinger</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Goschke</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Musslick</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Meta-control: From psychology to computational neuroscience</article-title>. <source>Cogn Affect Behav Neurosci</source>, <volume>21</volume>(<issue>3</issue>), <fpage>447</fpage>–<lpage>452</lpage>. doi:<pub-id pub-id-type="doi">10.3758/s13415-021-00919-4</pub-id></mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ester</surname>, <given-names>E. F.</given-names></string-name>, <string-name><surname>Anderson</surname>, <given-names>D. E.</given-names></string-name>, <string-name><surname>Serences</surname>, <given-names>J. T.</given-names></string-name>, &amp; <string-name><surname>Awh</surname>, <given-names>E</given-names></string-name></person-group>. (<year>2013</year>). <article-title>A neural measure of precision in visual working memory</article-title>. <source>J Cogn Neurosci</source>, <volume>25</volume>(<issue>5</issue>), <fpage>754</fpage>–<lpage>761</lpage>. doi:<pub-id pub-id-type="doi">10.1162/jocn_a_00357</pub-id></mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ester</surname>, <given-names>E. F.</given-names></string-name>, <string-name><surname>Sprague</surname>, <given-names>T. C.</given-names></string-name>, &amp; <string-name><surname>Serences</surname>, <given-names>J. T</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Parietal and Frontal Cortex Encode Stimulus-Specific Mnemonic Representations during Visual Working Memory</article-title>. <source>Neuron</source>, <volume>87</volume>(<issue>4</issue>), <fpage>893</fpage>–<lpage>905</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2015.07.013</pub-id></mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ester</surname>, <given-names>E. F.</given-names></string-name>, <string-name><surname>Sprague</surname>, <given-names>T. C.</given-names></string-name>, &amp; <string-name><surname>Serences</surname>, <given-names>J. T</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Categorical Biases in Human Occipitoparietal Cortex</article-title>. <source>J Neurosci</source>, <volume>40</volume>(<issue>4</issue>), <fpage>917</fpage>–<lpage>931</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2700-19.2019</pub-id></mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Flesch</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Juechems</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Dumbalska</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Saxe</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Summerfield</surname>, <given-names>C</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Orthogonal representations for robust context-dependent task performance in brains and neural networks</article-title>. <source>Neuron</source>, <volume>110</volume>(<issue>7</issue>), <fpage>1258</fpage>–<lpage>1270.e1211.</lpage> doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2022.01.005</pub-id></mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Freedman</surname>, <given-names>D. J.</given-names></string-name>, &amp; <string-name><surname>Assad</surname>, <given-names>J. A</given-names></string-name></person-group>. (<year>2006</year>). <article-title>Experience-dependent representation of visual categories in parietal cortex</article-title>. <source>Nature</source>, <volume>443</volume>(<issue>7107</issue>), <fpage>85</fpage>–<lpage>88</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nature05078</pub-id></mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Freedman</surname>, <given-names>D. J.</given-names></string-name>, <string-name><surname>Riesenhuber</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Poggio</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Miller</surname>, <given-names>E. K</given-names></string-name></person-group>. (<year>2001</year>). <article-title>Categorical representation of visual stimuli in the primate prefrontal cortex</article-title>. <source>Science</source>, <volume>291</volume>(<issue>5502</issue>), <fpage>312</fpage>–<lpage>316</lpage>. doi:<pub-id pub-id-type="doi">10.1126/science.291.5502.312</pub-id></mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Funahashi</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Bruce</surname>, <given-names>C. J.</given-names></string-name>, &amp; <string-name><surname>Goldman-Rakic</surname>, <given-names>P. S</given-names></string-name></person-group>. (<year>1989</year>). <article-title>Mnemonic coding of visual space in the monkey’s dorsolateral prefrontal cortex</article-title>. <source>J Neurophysiol</source>, <volume>61</volume>(<issue>2</issue>), <fpage>331</fpage>–<lpage>349</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.1989.61.2.331</pub-id></mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fusi</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>E. K.</given-names></string-name>, &amp; <string-name><surname>Rigotti</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2016</year>). <article-title>Why neurons mix: high dimensionality for higher cognition</article-title>. <source>Curr Opin Neurobiol</source>, <volume>37</volume>, <fpage>66</fpage>–<lpage>74</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.conb.2016.01.010</pub-id></mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fuster</surname>, <given-names>J. M.</given-names></string-name>, &amp; <string-name><surname>Alexander</surname>, <given-names>G. E</given-names></string-name></person-group>. (<year>1971</year>). <article-title>Neuron activity related to short-term memory</article-title>. <source>Science</source>, <volume>173</volume>(<issue>3997</issue>), <fpage>652</fpage>–<lpage>654</lpage>. Retrieved from <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pubmed/4998337">https://www.ncbi.nlm.nih.gov/pubmed/4998337</ext-link></mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gosseries</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Yu</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>LaRocque</surname>, <given-names>J. J.</given-names></string-name>, <string-name><surname>Starrett</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Rose</surname>, <given-names>N. S.</given-names></string-name>, <string-name><surname>Cowan</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Postle</surname>, <given-names>B. R</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Parietal-Occipital Interactions Underlying Control- and Representation-Related Processes in Working Memory for Nonspatial Visual Features</article-title>. <source>J Neurosci</source>, <volume>38</volume>(<issue>18</issue>), <fpage>4357</fpage>–<lpage>4366</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2747-17.2018</pub-id></mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gramfort</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Luessi</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Larson</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Engemann</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Strohmeier</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Brodbeck</surname>, <given-names>C.</given-names></string-name>, . . . <string-name><surname>Hamalainen</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2013</year>). <article-title>MEG and EEG data analysis with MNE-Python</article-title>. <source>Front Neurosci</source>, <volume>7</volume>, <fpage>267</fpage>. doi:<pub-id pub-id-type="doi">10.3389/fnins.2013.00267</pub-id></mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hallenbeck</surname>, <given-names>G. E.</given-names></string-name>, <string-name><surname>Sprague</surname>, <given-names>T. C.</given-names></string-name>, <string-name><surname>Rahmati</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Sreenivasan</surname>, <given-names>K. K.</given-names></string-name>, &amp; <string-name><surname>Curtis</surname>, <given-names>C. E</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Working memory representations in visual cortex mediate distraction effects</article-title>. <source>Nat Commun</source>, <volume>12</volume>(<issue>1</issue>), <fpage>4714</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41467-021-24973-1</pub-id></mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Harrison</surname>, <given-names>S. A.</given-names></string-name>, &amp; <string-name><surname>Tong</surname>, <given-names>F</given-names></string-name></person-group>. (<year>2009</year>). <article-title>Decoding reveals the contents of visual working memory in early visual areas</article-title>. <source>Nature</source>, <volume>458</volume>(<issue>7238</issue>), <fpage>632</fpage>–<lpage>635</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nature07832</pub-id></mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Henderson</surname>, <given-names>M. M.</given-names></string-name>, <string-name><surname>Rademaker</surname>, <given-names>R. L.</given-names></string-name>, &amp; <string-name><surname>Serences</surname>, <given-names>J. T</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Flexible utilization of spatial- and motor-based codes for the storage of visuo-spatial information</article-title>. <source>Elife</source>, <volume>11</volume>. doi:<pub-id pub-id-type="doi">10.7554/eLife.75688</pub-id></mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hu</surname>, <given-names>Y.</given-names></string-name>, &amp; <string-name><surname>Yu</surname>, <given-names>Q</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Spatiotemporal dynamics of self-generated imagery reveal a reverse cortical hierarchy from cue-induced imagery</article-title>. <source>Cell Rep</source>, <volume>42</volume>(<issue>10</issue>), <fpage>113242</fpage>. doi:<pub-id pub-id-type="doi">10.1016/j.celrep.2023.113242</pub-id></mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Latimer</surname>, <given-names>K. W.</given-names></string-name>, &amp; <string-name><surname>Freedman</surname>, <given-names>D. J</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Low-dimensional encoding of decisions in parietal cortex reflects long-term training history</article-title>. <source>Nat Commun</source>, <volume>14</volume>(<issue>1</issue>), <fpage>1010</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41467-023-36554-5</pub-id></mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Leavitt</surname>, <given-names>M. L.</given-names></string-name>, <string-name><surname>Mendoza-Halliday</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Martinez-Trujillo</surname>, <given-names>J. C</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Sustained Activity Encoding Working Memories: Not Fully Distributed</article-title>. <source>Trends Neurosci</source>, <volume>40</volume>(<issue>6</issue>), <fpage>328</fpage>–<lpage>346</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.tins.2017.04.004</pub-id></mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lee</surname>, <given-names>S. H.</given-names></string-name>, <string-name><surname>Kravitz</surname>, <given-names>D. J.</given-names></string-name>, &amp; <string-name><surname>Baker</surname>, <given-names>C. I</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Goal-dependent dissociation of visual and prefrontal cortices during working memory</article-title>. <source>Nat Neurosci</source>, <volume>16</volume>(<issue>8</issue>), <fpage>997</fpage>–<lpage>999</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.3452</pub-id></mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Zeng</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Shao</surname>, <given-names>Z.</given-names></string-name>, &amp; <string-name><surname>Yu</surname>, <given-names>Q</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Neural Representations in Visual and Parietal Cortex Differentiate between Imagined, Perceived, and Illusory Experiences</article-title>. <source>J Neurosci</source>, <volume>43</volume>(<issue>38</issue>), <fpage>6508</fpage>–<lpage>6524</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.0592-23.2023</pub-id></mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Cable</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Gardner</surname>, <given-names>J. L</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Inverted Encoding Models of Human Population Response Conflate Noise and Neural Tuning Width</article-title>. <source>J Neurosci</source>, <volume>38</volume>(<issue>2</issue>), <fpage>398</fpage>–<lpage>408</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2453-17.2017</pub-id></mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lorenc</surname>, <given-names>E. S.</given-names></string-name>, <string-name><surname>Sreenivasan</surname>, <given-names>K. K.</given-names></string-name>, <string-name><surname>Nee</surname>, <given-names>D. E.</given-names></string-name>, <string-name><surname>Vandenbroucke</surname>, <given-names>A. R. E.</given-names></string-name>, &amp; <string-name><surname>D’Esposito</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Flexible coding of visual working memory representations during distraction</article-title>. <source>J Neurosci</source>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.3061-17.2018</pub-id></mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Luu</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>Stocker</surname>, <given-names>A. A</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Categorical judgments do not modify sensory representations in working memory</article-title>. <source>PLoS Comput Biol</source>, <volume>17</volume>(<issue>6</issue>), <fpage>e1008968</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pcbi.1008968</pub-id></mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Masse</surname>, <given-names>N. Y.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>G. R.</given-names></string-name>, <string-name><surname>Song</surname>, <given-names>H. F.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>X. J.</given-names></string-name>, &amp; <string-name><surname>Freedman</surname>, <given-names>D. J</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Circuit mechanisms for the maintenance and manipulation of information in working memory</article-title>. <source>Nat Neurosci</source>, <volume>22</volume>(<issue>7</issue>), <fpage>1159</fpage>–<lpage>1167</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41593-019-0414-3</pub-id></mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McKee</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Riesenhuber</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>E. K.</given-names></string-name>, &amp; <string-name><surname>Freedman</surname>, <given-names>D. J</given-names></string-name></person-group>. (<year>2014</year>). <article-title>Task dependence of visual and category representations in prefrontal and inferior temporal cortices</article-title>. <source>J Neurosci</source>, <volume>34</volume>(<issue>48</issue>), <fpage>16065</fpage>–<lpage>16075</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.1660-14.2014</pub-id></mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Miller</surname>, <given-names>E. K.</given-names></string-name>, &amp; <string-name><surname>Cohen</surname>, <given-names>J. D</given-names></string-name></person-group>. (<year>2001</year>). <article-title>An integrative theory of prefrontal cortex function</article-title>. <source>Annu Rev Neurosci</source>, <volume>24</volume>, <fpage>167</fpage>–<lpage>202</lpage>. doi:<pub-id pub-id-type="doi">10.1146/annurev.neuro.24.1.167</pub-id></mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Miller</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Tambini</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kiyonaga</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>D’Esposito</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Long-term learning transforms prefrontal cortex representations during working memory</article-title>. <source>Neuron</source>, <volume>110</volume>(<issue>22</issue>), <fpage>3805</fpage>–<lpage>3819 e3806</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2022.09.019</pub-id></mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mok</surname>, <given-names>R. M.</given-names></string-name>, &amp; <string-name><surname>Love</surname>, <given-names>B. C</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Abstract Neural Representations of Category Membership beyond Information Coding Stimulus or Response</article-title>. <source>J Cogn Neurosci</source>, <fpage>1</fpage>–<lpage>17</lpage>. doi:<pub-id pub-id-type="doi">10.1162/jocn_a_01651</pub-id></mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Musslick</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Cohen</surname>, <given-names>J. D.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Rationalizing constraints on the capacity for cognitive control</article-title>. <source>Trends Cogn Sci</source>, <volume>25</volume>(<issue>9</issue>), <fpage>757</fpage>–<lpage>775</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.tics.2021.06.001</pub-id></mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pelli</surname>, <given-names>D. G</given-names></string-name></person-group>. (<year>1997</year>). <article-title>The VideoToolbox software for visual psychophysics: transforming numbers into movies</article-title>. <source>Spat Vis</source>, <volume>10</volume>(<issue>4</issue>), <fpage>437</fpage>–<lpage>442</lpage>. Retrieved from <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pubmed/9176953">https://www.ncbi.nlm.nih.gov/pubmed/9176953</ext-link></mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rademaker</surname>, <given-names>R. L.</given-names></string-name>, <string-name><surname>Chunharas</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Serences</surname>, <given-names>J. T</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Coexisting representations of sensory and mnemonic information in human visual cortex</article-title>. <source>Nat Neurosci</source>, <volume>22</volume>(<issue>8</issue>), <fpage>1336</fpage>–<lpage>1344</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41593-019-0428-x</pub-id></mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Riggall</surname>, <given-names>A. C.</given-names></string-name>, &amp; <string-name><surname>Postle</surname>, <given-names>B. R</given-names></string-name></person-group>. (<year>2012</year>). <article-title>The Relationship between Working Memory Storage and Elevated Activity as Measured with Functional Magnetic Resonance Imaging</article-title>. <source>Journal of Neuroscience</source>, <volume>32</volume>(<issue>38</issue>), <fpage>12990</fpage>–<lpage>12998</lpage>. doi:<pub-id pub-id-type="doi">10.1523/Jneurosci.1892-12.2012</pub-id></mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Serences</surname>, <given-names>J. T.</given-names></string-name>, <string-name><surname>Ester</surname>, <given-names>E. F.</given-names></string-name>, <string-name><surname>Vogel</surname>, <given-names>E. K.</given-names></string-name>, &amp; <string-name><surname>Awh</surname>, <given-names>E</given-names></string-name></person-group>. (<year>2009</year>). <article-title>Stimulus-specific delay activity in human primary visual cortex</article-title>. <source>Psychol Sci</source>, <volume>20</volume>(<issue>2</issue>), <fpage>207</fpage>–<lpage>214</lpage>. doi:<pub-id pub-id-type="doi">10.1111/j.1467-9280.2009.02276.x</pub-id></mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sprague</surname>, <given-names>T. C.</given-names></string-name>, <string-name><surname>Adam</surname>, <given-names>K. C. S.</given-names></string-name>, <string-name><surname>Foster</surname>, <given-names>J. J.</given-names></string-name>, <string-name><surname>Rahmati</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Sutterer</surname>, <given-names>D. W.</given-names></string-name>, &amp; <string-name><surname>Vo</surname>, <given-names>V. A</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Inverted Encoding Models Assay Population-Level Stimulus Representations, Not Single-Unit Neural Tuning</article-title>. <source>eNeuro</source>, <volume>5</volume>(<issue>3</issue>). doi:<pub-id pub-id-type="doi">10.1523/ENEURO.0098-18.2018</pub-id></mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sprague</surname>, <given-names>T. C.</given-names></string-name>, &amp; <string-name><surname>Serences</surname>, <given-names>J. T</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Attention modulates spatial priority maps in the human occipital, parietal and frontal cortices</article-title>. <source>Nat Neurosci</source>, <volume>16</volume>(<issue>12</issue>), <fpage>1879</fpage>–<lpage>1887</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.3574</pub-id></mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Mruczek</surname>, <given-names>R. E.</given-names></string-name>, <string-name><surname>Arcaro</surname>, <given-names>M. J.</given-names></string-name>, &amp; <string-name><surname>Kastner</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Probabilistic Maps of Visual Topography in Human Cortex</article-title>. <source>Cereb Cortex</source>, <volume>25</volume>(<issue>10</issue>), <fpage>3911</fpage>–<lpage>3931</lpage>. doi:<pub-id pub-id-type="doi">10.1093/cercor/bhu277</pub-id></mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wang</surname>, <given-names>X. J</given-names></string-name></person-group>. (<year>2021</year>). <article-title>50 years of mnemonic persistent activity: quo vadis?</article-title> <source>Trends Neurosci</source>, <volume>44</volume>(<issue>11</issue>), <fpage>888</fpage>–<lpage>902</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.tins.2021.09.001</pub-id></mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yu</surname>, <given-names>Q.</given-names></string-name>, &amp; <string-name><surname>Postle</surname>, <given-names>B. R</given-names></string-name></person-group>. (<year>2021</year>). <article-title>The Neural Codes Underlying Internally Generated Representations in Visual Working Memory</article-title>. <source>J Cogn Neurosci</source>, <fpage>1</fpage>–<lpage>16</lpage>. doi:<pub-id pub-id-type="doi">10.1162/jocn_a_01702</pub-id></mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yu</surname>, <given-names>Q.</given-names></string-name>, &amp; <string-name><surname>Shim</surname>, <given-names>W. M</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Occipital, parietal, and frontal cortices selectively maintain task-relevant features of multi-feature objects in visual working memory</article-title>. <source>Neuroimage</source>, <volume>157</volume>, <fpage>97</fpage>–<lpage>107</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.05.055</pub-id></mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yu</surname>, <given-names>Q.</given-names></string-name>, &amp; <string-name><surname>Shim</surname>, <given-names>W. M</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Temporal-Order-Based Attentional Priority Modulates Mnemonic Representations in Parietal and Frontal Cortices</article-title>. <source>Cereb Cortex</source>, <volume>29</volume>(<issue>7</issue>), <fpage>3182</fpage>–<lpage>3192</lpage>. doi:<pub-id pub-id-type="doi">10.1093/cercor/bhy184</pub-id></mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Rosen</surname>, <given-names>M. C.</given-names></string-name>, <string-name><surname>Swaminathan</surname>, <given-names>S. K.</given-names></string-name>, <string-name><surname>Masse</surname>, <given-names>N. Y.</given-names></string-name>, <string-name><surname>Zhu</surname>, <given-names>O.</given-names></string-name>, &amp; <string-name><surname>Freedman</surname>, <given-names>D. J</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Distributed functions of prefrontal and parietal cortices during sequential categorical decisions</article-title>. <source>Elife</source>, <volume>10</volume>. doi:<pub-id pub-id-type="doi">10.7554/eLife.58782</pub-id></mixed-citation></ref>
</ref-list>
<sec>
<fig id="figs1" position="float" orientation="portrait" fig-type="figure">
<label>Figure S1.</label>
<caption><title>Behavioral performance of Experiment 2.</title>
<p>(A) Accuracy (upper) and reaction time (lower) of Maintenance (blue) and Categorization (orange) tasks in Experiment 2. Asterisks denote significant results, n.s.: not significant; **: <italic>p</italic> &lt; 0.01. (B) Accuracy (upper) and reaction time (lower) for orientations based on their distances from category center for Categorization task. Shaded areas represent ± SEM. Vertical dashed line represents category center.</p></caption>
<graphic xlink:href="551058v2_figs1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs2" position="float" orientation="portrait" fig-type="figure">
<label>Figure S2.</label>
<caption><title>Control analyses for stimulus representation results.</title>
<p>(A) Time course of representational strength of orientations in EVC, IPS and sPCS using IEMs trained separately for each condition. Bar plot on the right showing corresponding averaged difference between tasks. Average difference of representational strength across later delay period (11 – 16 s) in each ROI. Positive difference indicates higher representational strength for categorization, and vice versa for negative difference. (B) Time course of representational strength of orientations in functional ROIs defined by top 500 most selective voxels during sample or delay period. Bar plot same as (A). (C) Time course of representational strength of orientations after removing voxel-wise mean activation for each condition at each TR. Bar plot same as (A). (D) Time course of stimulus decoding accuracy. Bar plot same as (A). Gray shaded areas indicate the entire memory delay following task cue. Horizontal dashed lines represent a baseline of 0 or 0.5. Blue and orange dots at the bottom indicate the significance of representational fidelity at each time point of the corresponding task at <italic>p</italic> &lt; 0.05 (small), <italic>p</italic> &lt; 0.01 (medium), and <italic>p</italic> &lt; 0.001 (large). The bottom black dots indicate significant difference in representational fidelity between tasks. Shaded areas represent ± SEM. n.s.: not significant; black asterisks denote significance, *: <italic>p</italic> &lt; 0.05; **: <italic>p</italic> &lt; 0.01; ***: <italic>p</italic> &lt; 0.001. Gray asterisk denotes marginal significance p &lt; 0.1.</p></caption>
<graphic xlink:href="551058v2_figs2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs3" position="float" orientation="portrait" fig-type="figure">
<label>Figure S3.</label>
<caption><title>Behavioral correlation of stimulus representation in Experiment 2.</title>
<p>(A) Time course of correlation coefficients in EVC, IPS, and sPCS. Correlation was performed between strength of stimulus representations and behavioral performance (accuracy) for Maintenance (blue) and Categorization (orange) tasks. Gray shaded areas indicate the entire memory delay following task cue. Horizontal dashed lines represent a baseline of 0. Bottom dots indicate the significance of corresponding analyses at each time point of the corresponding task at <italic>p</italic> &lt; 0.05 (small), <italic>p</italic> &lt; 0.01 (medium), and <italic>p</italic> &lt; 0.001 (large). Shaded areas represent ± SEM.</p></caption>
<graphic xlink:href="551058v2_figs3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs4" position="float" orientation="portrait" fig-type="figure">
<label>Figure S4.</label>
<caption><title>Category, Abstract Category and Rule Information in Experiment 1 and 2.</title>
<p>(A) Time course of category decoding strength in Experiment 1 with flexible rule (orange) and in Experiment 2 with fixed rule (light orange). Horizontal dashed lines represent the chance level of 0.5. Gray shaded areas indicate the entire memory delay following task cue. Bottom dots indicate FDR-corrected significance of decoding accuracy at each time point at <italic>p</italic> &lt; 0.05 (small), <italic>p</italic> &lt; 0.01 (medium), and <italic>p</italic> &lt; 0.001 (large). Error bars represent ± SEM. (B) Time course of abstract category decoding strength in Experiment 1 (dark blue) and in Experiment 2 (light blue). Horizontal dashed lines represent a baseline of 0. Gray shaded areas indicate the entire memory delay following task cue. Bottom dots indicate uncorrected significance of decoding accuracy at each time point at <italic>p</italic> &lt; 0.05 (small), <italic>p</italic> &lt; 0.01 (medium), and <italic>p</italic> &lt; 0.001 (large). Error bars represent ± SEM.</p></caption>
<graphic xlink:href="551058v2_figs4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<table-wrap id="tbls1" orientation="portrait" position="float">
<label>Supplemental Table 1.</label>
<caption><title>P-values for the time course of IEM results in Figure 2. Underline denotes significant results (<italic>p</italic> &lt; 0.05).</title></caption>
<graphic xlink:href="551058v2_tbls1.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<table-wrap id="tbls2" orientation="portrait" position="float">
<label>Supplemental Table 2.</label>
<caption><title>P-values for the time course of correlation results in Figure 3. Underline denotes significant results (<italic>p</italic> &lt; 0.05).</title></caption>
<graphic xlink:href="551058v2_tbls2.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<table-wrap id="tbls3" orientation="portrait" position="float">
<label>Supplemental Table 3.</label>
<caption><title>P-values for the time course of IEM results in Figure 4. Underline denotes significant results (<italic>p</italic> &lt; 0.05).</title></caption>
<graphic xlink:href="551058v2_tbls3.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
</sec>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100287.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Xue</surname>
<given-names>Gui</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Beijing Normal University</institution>
</institution-wrap>
<city>Beijing</city>
<country>China</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This work presents <bold>valuable</bold> findings that the human frontal cortex is involved in a flexible, dual role in both maintaining information in short-term memory, and controlling this memory content to guide adaptive behavior and decisions. The evidence supporting the conclusions is <bold>convincing</bold>, with a well-designed task, best-practice decoding methods, and careful control analyses. The work will be of broad interest to cognitive neuroscience researchers working on working memory and cognitive control.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100287.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>In this manuscript, Shao et al. investigate the contribution of different cortical areas to working memory maintenance and control processes, an important topic involving different ideas about how the human brain represents and uses information when it is no longer available to sensory systems. In two fMRI experiments, they demonstrate that the human frontal cortex (area sPCS) represents stimulus (orientation) information both during typical maintenance, but even more so when a categorical response demand is present. That is, when participants have to apply an added level of decision control to the WM stimulus, sPCS areas encode stimulus information more than conditions without this added demand. These effects are then expanded upon using multi-area neural network models, recapitulating the empirical gradient of memory vs control effects from visual to parietal and frontal cortices. In general, the experiments and analyses provide solid support for the authors' conclusions, and control experiments and analyses are provided to help interpret and isolate the frontal cortex effect of interest. However, I suggest some alternative explanations and important additional analyses that would help ensure an even stronger level of support for these results and interpretations.</p>
<p>Strengths:</p>
<p>- The authors use an interesting and clever task design across two fMRI experiments that is able to parse out contributions of WM maintenance alone along with categorical, rule-based decisions. Importantly, the second experiment only uses one fixed rule, providing both an internal replication of Experiment 1's effects and extending them to a different situation when rule-switching effects are not involved across mini-blocks.</p>
<p>- The reported analyses using both inverted encoding models (IEM) and decoders (SVM) demonstrate the stimulus reconstruction effects across different methods, which may be sensitive to different aspects of the relationship between patterns of brain activity and the experimental stimuli.</p>
<p>- Linking the multivariate activity patterns to memory behavior is critical in thinking about the potential differential roles of cortical areas in sub-serving successful working memory. Figure 3 nicely shows a similar interaction to that of Figure 2 in the role of sPCS in the categorization vs. maintenance tasks.</p>
<p>- The cross-decoding analysis in Figure 4 is a clever and interesting way to parse out how stimulus and rule/category information may be intertwined, which would have been one of the foremost potential questions or analyses requested by careful readers. However, I think more additional text in the Methods and Results to lay out the exact logic of this abstract category metric will help readers better interpret the potential importance of this analysis and result.</p>
<p>Weaknesses:</p>
<p>- Selection and presentation of regions of interest: I appreciate the authors' care in separating the sPCS region as &quot;frontal cortex&quot;, which is not necessarily part of the prefrontal cortex, on which many ideas of working memory maintenance activity are based. However, to help myself and readers interpret these findings, at a minimum the boundaries of each ROI should be provided as part of the main text or extended data figures. Relatedly, the authors use a probabilistic visual atlas to define ROIs in the visual, parietal, and frontal cortices. But other regions of both lateral frontal and parietal cortices show retinotopic responses (Mackey and Curtis, eLife, 2017: <ext-link ext-link-type="uri" xlink:href="https://elifesciences.org/articles/22974">https://elifesciences.org/articles/22974</ext-link>) and are perhaps worth considering. Do the inferior PCS regions or inferior frontal sulcus show a similar pattern of effects across tasks? And what about the middle frontal gyrus areas of the prefrontal cortex, which are most analogous to the findings in NHP studies that the authors mention in their discussion, but do not show retinotopic responses? Reporting the effects (or lack thereof) in other areas of the frontal cortex will be critical for readers to interpret the role of the frontal cortex in guiding WM behavior and supporting the strongly worded conclusions of broad frontal cortex functioning in the paper. For example, to what extent can sPCS results be explained by visual retinotopic responses? (Mackey and Curtis, eLife, 2017: <ext-link ext-link-type="uri" xlink:href="https://elifesciences.org/articles/22974">https://elifesciences.org/articles/22974</ext-link>).</p>
<p>- When looking at the time course of effects in Figure 2, for example, the sPCS maintenance vs categorization effects occur very late into the WM delay period. More information is needed to help separate this potential effect from that of the response period and potential premotor/motor-related influences. For example, are the timecourses shifted to account for hemodynamic lag, and if so, by how much? Do the sPCS effects blend into the response period? This is critical, too, for a task that does not use a jittered delay period, and potential response timing and planning can be conducted by participants near the end of the WM delay. Regardless, parsing out the timing and relationship to response planning is important, and an ROI for M1 or premotor cortex could also help as a control comparison point, as in reference (24).</p>
<p>- Interpreting effect sizes of IEM and decoding analysis in different ROIs. Here, the authors are interested in the interaction effects across maintenance and categorization tasks (bar plots in Figure 2), but the effect sizes in even the categorization task (y-axes) are always larger in EVC and IPS than in the sPCS region... To what extent do the authors think this representational fidelity result can or cannot be compared across regions? For example, a reader may wonder how much the sPCS representation matters for the task, perhaps, if memory access is always there in EVC and IPS? Or perhaps late sPCS representations are borrowing/accessing these earlier representations? Giving the reader some more intuition for the effect sizes of representational fidelity will be important. Even in Figure 3 for the behavior, all effects are also seen in IPS as well. More detail or context at minimum is needed about the representational fidelity metric, which is cited in ref (35) but not given in detail. These considerations are important given the claims of the frontal cortex serving such an important for flexible control, here.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100287.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The authors provide evidence that helps resolve long-standing questions about the differential involvement of the frontal and posterior cortex in working memory. They show that whereas the early visual cortex shows stronger decoding of memory content in a memorization task vs a more complex categorization task, the frontal cortex shows stronger decoding during categorization tasks than memorization tasks. They find that task-optimized RNNs trained to reproduce the memorized orientations show some similarities in neural decoding to people. Together, this paper presents interesting evidence for differential responsibilities of brain areas in working memory.</p>
<p>Strengths:</p>
<p>This paper was strong overall. It had a well-designed task, best-practice decoding methods, and careful control analyses. The neural network modelling adds additional insight into the potential computational roles of different regions.</p>
<p>Weaknesses:</p>
<p>While the RNN model matches some of the properties of the task and decoding, its ability to reproduce the detailed findings of the paper was limited. Overall, the RRN model was not as well-motivated as the fMRI analyses.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.100287.1.sa3</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Shao</surname>
<given-names>Zhujun</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0006-0886-4606</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Zhang</surname>
<given-names>Mengya</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0006-9197-1698</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Yu</surname>
<given-names>Qing</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8480-7634</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>(1) Reviewer 1 suggested that we repeat the analyses in additional ROIs in the prefrontal cortex (PFC). We appreciate this suggestion and believe it will contribute to a comprehensive understanding of the current findings. These results will be included in the revision.</p>
<p>(2) Reviewer 1 suggested that we also examine results in motor-related ROIs to rule out influences from response planning. We would like to note that our experimental design makes it unlikely that response planning would have influenced our results, as participants were unable to plan their motor responses in advance due to randomized response mapping on a trial-by-trial basis. Nevertheless, we agree with the reviewer that showing results from motor-related ROIs is important, and will include these results in the revision.</p>
<p>(3) Reviewer 1 raised a question about the effect size of the results across different ROIs. In our manuscript, we tried to avoid direct comparisons of representational strength across ROIs, by focusing on the differences in representational strength between conditions within the same ROI. Nevertheless, we agree that clarifying this issue is important, which we will address in the revision.</p>
<p>(4) Reviewer 2 raised a concern about the similarity between the RNN and fMRI results. We acknowledge that the complexity of our results makes it challenging to replicate all fMRI findings within a single RNN (e.g., simulating three brain regions in a single network with distinct result patterns). Nonetheless, the current RNNs effectively captured our key fMRI findings, including increased stimulus representation in frontal cortex as well as the tradeoff in category representation with varying levels of flexible control. Reviewer 2 also made several suggestions in tweaking the RNN structure and in choosing alternative analysis methods. We are happy to carry out these points as we think they could potentially increase the alignment between the two modalities.</p>
</body>
</sub-article>
</article>