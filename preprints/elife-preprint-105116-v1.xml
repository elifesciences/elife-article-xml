<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">105116</article-id>
<article-id pub-id-type="doi">10.7554/eLife.105116</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.105116.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.3</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>A cross-species framework for investigating perceptual evidence accumulation</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1022-393X</contrib-id>
<name>
<surname>Chakravarty</surname>
<given-names>Sucheta</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">*</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2202-1043</contrib-id>
<name>
<surname>Delgado-Sallent</surname>
<given-names>Cristina</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n1">*</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7703-5055</contrib-id>
<name>
<surname>Kane</surname>
<given-names>Gary A</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Xia</surname>
<given-names>Hongjie</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2723-2579</contrib-id>
<name>
<surname>Do</surname>
<given-names>Quan H</given-names>
</name>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3776-4576</contrib-id>
<name>
<surname>Senne</surname>
<given-names>Ryan A</given-names>
</name>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2741-7215</contrib-id>
<name>
<surname>Scott</surname>
<given-names>Benjamin B</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<email>bbs@bu.edu</email>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05qwgg493</institution-id><institution>Psychological &amp; Brain Sciences, Boston University</institution></institution-wrap>, <city>Boston</city>, <country country="US">United States</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05qwgg493</institution-id><institution>Center for Systems Neuroscience, Boston University</institution></institution-wrap>, <city>Boston</city>, <country country="US">United States</country></aff>
<aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05qwgg493</institution-id><institution>Department of Biology, Boston University</institution></institution-wrap>, <city>Boston</city>, <country country="US">United States</country></aff>
<aff id="a4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05qwgg493</institution-id><institution>Graduate Program in Neuroscience, Boston University</institution></institution-wrap>, <city>Boston</city>, <country country="US">United States</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Donner</surname>
<given-names>Tobias H</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University Medical Center Hamburg-Eppendorf</institution>
</institution-wrap>
<city>Hamburg</city>
<country>Germany</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Gold</surname>
<given-names>Joshua I</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Pennsylvania</institution>
</institution-wrap>
<city>Philadelphia</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes><fn id="n1" fn-type="equal"><label>*</label><p>These authors contributed equally.</p></fn>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-04-11">
<day>11</day>
<month>04</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP105116</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-12-10">
<day>10</day>
<month>12</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-11-21">
<day>21</day>
<month>11</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.04.17.589945"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Chakravarty et al</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Chakravarty et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-105116-v1.pdf"/>
<abstract>
<title>Summary</title>
<p>Cross-species studies are important for a comprehensive understanding of brain functions. However, direct quantitative comparison of behaviors across species presents a significant challenge. To enable such comparisons in perceptual decision-making, we developed a synchronized evidence accumulation task for human and non-human animals, by aligning mechanics, stimuli, and training. The task was readily learned by rats, mice and humans, with each species exhibiting qualitatively similar performance. Quantitative model comparison revealed that all three species employed an evidence accumulation strategy, but differed in speed, accuracy, and key decision parameters. Human performance prioritized accuracy, whereas rodent performance was limited by internal time-pressure. Rats optimized reward rate, while mice appeared to switch between evidence accumulation and other strategies trial-to-trial. Together, these results reveal striking similarities and species-specific priorities in decision-making. Furthermore, the synchronized behavioral framework we present may facilitate future studies involving cross-species comparisons, such as evaluating the face validity of animal models of neuropsychiatric disorders.</p>
</abstract>
<abstract abstract-type="summary">
<title>Highlights</title>
<list list-type="order">
<list-item><p>Development of an evidence accumulation task for rats and mice</p></list-item>
<list-item><p>Synchronized video game allows direct comparisons with humans</p></list-item>
<list-item><p>Rat, mouse and human behavior are well fit by the same decision models</p></list-item>
<list-item><p>Model parameters reveal species-specific priorities in accumulation strategy</p></list-item>
</list>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>perception</kwd>
<kwd>cognition</kwd>
<kwd>evidence accumulation</kwd>
<kwd>cross-species</kwd>
<kwd>computational modeling</kwd>
</kwd-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>The revised manuscript contains updated figures with better resolution</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Quantitative comparisons of behavior across species are crucial to understand complex cognitive processes (<xref ref-type="bibr" rid="c3">Badre et al., 2015</xref>; <xref ref-type="bibr" rid="c14">Esteves et al., 2021</xref>; <xref ref-type="bibr" rid="c43">Schmack et al., 2021</xref>; <xref ref-type="bibr" rid="c53">Young, 2023</xref>). However, such comparisons are challenging for several reasons (<xref ref-type="bibr" rid="c4">Barron et al., 2020</xref>; <xref ref-type="bibr" rid="c39">Redish et al., 2021</xref>). Research in individual laboratories commonly focuses on single species, leading to marked differences in experimental techniques across species (<xref ref-type="bibr" rid="c3">Badre et al., 2015</xref>). These experiments often exploit the innate abilities of individual species. For example, humans are commonly provided with verbal task instructions, which is not possible with other animals. The disconnect between human and animal research can be costly, since animal models serve an important role in preclinical research of human neuropsychiatric disorders (<xref ref-type="bibr" rid="c24">Markou et al., 2009</xref>; <xref ref-type="bibr" rid="c26">Nestler &amp; Hyman, 2010</xref>).</p>
<p>One domain where significant progress in cross species analysis has been made is perceptual decision making (<xref ref-type="bibr" rid="c7">Brunton et al., 2013</xref>; <xref ref-type="bibr" rid="c27">Nguyen &amp; Reinagel, 2022</xref>; <xref ref-type="bibr" rid="c29">Pedrosa et al., 2023</xref>; <xref ref-type="bibr" rid="c43">Schmack et al., 2021</xref>; <xref ref-type="bibr" rid="c46">Shevinsky &amp; Reinagel, 2019</xref>). Perceptual decision making is a core behavior observed in many species, and alterations have been observed across a range of human neuropsychological disorders (<xref ref-type="bibr" rid="c19">Horga &amp; Abi-Dargham, 2019</xref>; <xref ref-type="bibr" rid="c22">Kavcic et al., 2011</xref>; <xref ref-type="bibr" rid="c40">Rizzo &amp; Nawrot, 1998</xref>; <xref ref-type="bibr" rid="c41">Robertson &amp; Baron-Cohen, 2017</xref>; <xref ref-type="bibr" rid="c50">van den Boogert et al., 2022</xref>). Previous research has investigated perceptual decisions in humans, non-human primates, and rodents, using similar stimuli (<xref ref-type="bibr" rid="c9">Carandini &amp; Churchland, 2013</xref>; <xref ref-type="bibr" rid="c17">Hanks &amp; Summerfield, 2017</xref>; <xref ref-type="bibr" rid="c45">Shadlen &amp; Kiani, 2013</xref>). However, direct comparisons of cross-species behavior based on previous studies is difficult, due to marked differences in the paradigms and the training protocols.</p>
<p>Here we present a behavioral framework for investigating perceptual decision making in mice, rats and humans. We implemented a free response version of the pulse-based evidence accumulation task, previously used in rodents, especially in rats (<xref ref-type="bibr" rid="c7">Brunton et al., 2013</xref>; <xref ref-type="bibr" rid="c16">Gupta et al., 2024</xref>; <xref ref-type="bibr" rid="c44">Scott et al., 2015</xref>; Kane et al. 2023) and mice (<xref ref-type="bibr" rid="c28">Odoemene et al., 2018</xref>; <xref ref-type="bibr" rid="c31">Pinto et al., 2018</xref>). Briefly, the task uses sequences of brief visual pulses (flashes), presented to the left and right sides while the subject must choose the side with the higher pulse probability to obtain the reward. This task offers a speed-accuracy trade off as longer response times allow the observer to sample more pulses, which enables better estimates of the relative pulse probability. We trained rats and mice to perform this task using computer controlled 3-port light chambers, and an automated training facility. In parallel, we developed a video game based on the same task to gather data from human participants online. We synchronized task parameters and training protocols between the rodent task and the human video game; we used non-verbal, reward feedback-driven training in all three species. Further, the high-throughput rodent training facility, and the online game facilitated large-scale data collection.</p>
<p>All three species learned to perform the task and relied on evidence accumulation as a choice strategy. However, there were cross-species differences in several key aspects of the accumulation process. Overall, humans were slower and more accurate than rodents, particularly mice. Drift diffusion models (DDM) revealed highest decision thresholds in humans, and lowest thresholds in mice. Further, collapsing boundary model fits indicated that rodent behavior may be limited by internal time-pressures. Interestingly, rats appeared to optimize response times to maximize reward rate, whereas humans opted for better accuracy. Mice showed high animal-to-animal and trial-to-trial variability in choice behavior and model fits suggested they alternated between evidence accumulation- and other strategies across trials. Together these data reveal important similarities and species-specific priorities in decision making across rodents and humans, and highlight the value of synchronized behavioral frameworks for cross-species studies.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>A synchronized framework for cross-species studies of perceptual decision making</title>
<p>We developed a free-response version of the pulse-based evidence accumulation task (Kane et al. 2023) that was synchronized across rodents and humans (<xref rid="fig1" ref-type="fig">Figure 1</xref>; see methods for details). In this task, sensory information was presented as a sequence of randomly-timed pulses of light from two sources, one to the left and one to the right (<xref rid="fig1" ref-type="fig">Figure 1B</xref>). Pulses were brief (10 <italic>ms</italic>) and binned into 100 <italic>ms</italic> bins—the odds were set so that the probability (<italic>p</italic>) of a flash on one side in a bin was complementary to the flash probability on the other side for the same bin (1 − <italic>p</italic>). The pulses continued until the subject selected one of the light sources. Identification of the light source with the greater probability of pulsing yielded a correct response.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Synchronized pulse-based evidence accumulation task for humans and rodents.</title>
<p>A) During perceptual decision-making, choices are influenced by perceptual factors, for example sensory noise and sensitivity, as well as cognitive factors, including decision thresholds and working memory. Pulse based evidence accumulation tasks were developed to discriminate the relative contributions of perceptual and cognitive factors on behavioral choice across individuals. B) Schematic of the pulse-based evidence accumulation task for cross-species studies. The goal of the task is to identify the side with the higher probability of visual stimuli. The task structure is the same across species and consists of 4 different phases: <italic>Initiation</italic>: the subject starts the task by clicking an asteroid (humans) or poking in the center (rodents), <italic>Evidence</italic>: the visual stimuli will be presented in the right or left side. <italic>Choice</italic>: during the evidence period, the subject observes the cues and responds by selecting a side. Cues continue until the side is selected. The correct choice is the side with the greater underlying probability of cue presentation. <italic>Feedback</italic>: the subject will receive a reward (increase of the score for humans and sugar water for the rodents) for a correct choice or a time-out (TO) delay for an incorrect choice. C) <italic>Left:</italic> The human version consists of an online video game format in which the player controls a spaceship in an asteroid field. The player gets points by destroying asteroids with a laser beam. <italic>Right:</italic> In the rodent version, mice and rats play the task in a 3-port operant training chamber, in which the center port is used for initiation and the left and right ports are used for making choices. D) <italic>Left:</italic> For humans, data was collected using remote video calls format. <italic>Right</italic>: For rodents, behavioral sessions were conducted from multiple animals in parallel in a semi-automated operant facility.</p></caption>
<graphic xlink:href="589945v3_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Rodents performed the task in a three port operant chamber; they initiated each trial with a nose poke at the center port, followed by a cue period during which sequences of brief light flashes were presented in the left and right light ports, the flashes continued until the animal poked on one of the side ports. Rodents were rewarded with a drop of sugar water for poking on the side with greater flash probability (<xref rid="fig1" ref-type="fig">Figure 1C</xref>). For the human experiments, we designed an online video game that preserved the same mechanics and stimulus statistics (flash duration, flash rate, and generative flash probability) from the rodent task (<xref rid="fig1" ref-type="fig">Figure 1C</xref>). In the video game, participants were presented with a field of asteroids, each trial started when they mouse-clicked on any asteroid, following which sequences of brief flashes in the form of an alien spaceship were presented bilaterally—this was the cue period; the flashes continued until the participant mouse-clicked on one of the sides. If they chose the side with the greater flash probability, the initially selected asteroid would be destroyed (<xref rid="fig1" ref-type="fig">Figure 1C</xref>). Importantly, both the rodent task and the human video game offered a speed-accuracy tradeoff. Longer response times facilitated greater probability of choosing the correct side, due to greater opportunity for accumulating evidence from the flashes.</p>
<p>Both the rodent task and the human video game used a non-verbal, feedback-based training pipeline (<xref ref-type="bibr" rid="c12">Do et al., 2023</xref>; Kane et al. 2023). This pipeline consisted of progressive phases to familiarize subjects to task mechanics and game rules (<xref rid="figs1" ref-type="fig">Supplementary Figure 1</xref>). Correct choices were rewarded with positive feedback—a drop of sugar water for the rodents and point bonuses for the humans. Importantly, humans did not receive verbal instructions about the game rule. Rodents underwent multiple sessions of training over the course of many days (4 − 5 weeks for mice and 1 − 3 weeks for rats), while humans completed 1-2 sessions (several minutes).</p>
</sec>
<sec id="s2b">
<title>Rodents and humans solved the task using an evidence accumulation strategy</title>
<p>We trained 21 rats, 95 mice and 18 adolescent humans on the task. All three species performed well during the testing phase and were above the criteria for chance performance (upper bound of the 99% binomial confidence interval, see methods). There was substantial heterogeneity in performance across individuals of a species, revealed by their overall accuracy, response time (RT), bias and reward rate (<xref rid="fig2" ref-type="fig">Figure 2A-D</xref>). On average, humans were slower and more accurate, mice were the fastest and least accurate (One-way ANOVA for accuracy: <italic>p</italic> &lt; 0.0005, <italic>F</italic> = 271.84; for RT: <italic>p</italic> &lt; 0.0005, <italic>F</italic> = 236.39, see <xref rid="fig2" ref-type="fig">Figure 2A-B, E</xref>). Interestingly, there was overlap in performance across species (e.g. <xref rid="fig2" ref-type="fig">Figure 2A-2C</xref>). There were no detectable differences between males and females in any species (<xref rid="figs2" ref-type="fig">Supplementary Figure 2</xref>).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Humans, mice and rats accumulate evidence over time to solve the task.</title>
<p>A) Accuracy varies significantly across species (One-way ANOVA; p &lt; 0.0005, F = 271.84), with mice exhibiting the lowest performance and humans demonstrating the highest. B) Mice exhibit faster response times compared to humans and rats, which display similar response times (One-way ANOVA; p &lt; 0.0005, F = 236.39). C) Normalized bias is comparable between humans and rats but is higher in mice (One-way ANOVA; p &lt; 0.0005, F = 11.13). D) Reward rate was similar for rodents but larger for humans (One-way ANOVA; p &lt; 0.0005, F = 1060.97). E) Histogram of response times across species reveals that rats and humans respond at similar speeds during correct or incorrect trials, whereas mice respond faster in error trials than in correct trials (Paired t-student; p &lt; 0.0005). Note that positive values represent correct trials, while negative values represent incorrect trials. F) Accuracy vs response time derived from a generalized additive mixed model on the three species in which we can observe the evidence accumulation process in each of the species. All of the species peak between 0.7-1 seconds but the humans present a higher peak than the rodents. Each dot represents the averaged accuracy per each 0.2-second bin for each species (Pearson Correlations Accuracy-RT, see methods; Mouse: <italic>p</italic> &lt; 0.017, <italic>R</italic> = 0.80, Rat: <italic>p</italic> &lt; 0.011, <italic>R</italic> = 0.83, Human: <italic>p</italic> &lt; 0.033, <italic>R</italic> = 0.85). All comparisons are unpaired two-sample t-tests, corrected for multiple comparisons with Bonferroni correction. Notations: * = p&lt;0.05, ** = p&lt;0.01, *** = p&lt;0.005, **** = p&lt;0.001.</p></caption>
<graphic xlink:href="589945v3_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Importantly, two pieces of evidence suggested that all three species used a similar evidence accumulation strategy. First, across species, trials with longer RTs yielded increased accuracy (Pearson correlations between accuracy and RT, see methods; Mouse: <italic>p</italic> &lt; 0.017, <italic>R</italic> = 0.80, Rat: <italic>p</italic> &lt; 0.011, <italic>R</italic> = 0.83, Human: <italic>p</italic> &lt; 0.033, <italic>R</italic> = 0.85). This was illustrated with a generalized additive mixture model (GAMM), fit to the choice and RT data (<xref rid="fig2" ref-type="fig">Figure 2F</xref>). Second, choice and RT data from individuals of each species were well fit by the drift diffusion model (DDM; <xref ref-type="bibr" rid="c5">Bogacz et al., 2006</xref>; <xref ref-type="bibr" rid="c33">Ratcliff, 1978</xref>; <xref ref-type="bibr" rid="c35">Ratcliff &amp; McKoon, 2008</xref>), which showed relatively high decision bounds (<xref rid="fig3" ref-type="fig">Figure 3A-C</xref>).</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3:</label>
<caption><title>Drift diffusion models explain the choice and response time data for all three species.</title>
<p>A) Illustration of the diffusion model: two boundaries indicate decision thresholds for left and right choice, greater distance between boundaries would mean more separability between the two choice decisions. Drift rate is the average rate of evidence accumulation, the model assumes drift rate varies from trial to trial, following a normal distribution. Starting point measures the bias in choosing one side over the other. Starting point is also assumed to vary from trial to trial, following a uniform distribution. Non-decision time indexes time spent in processes other than the decision process. Trial to trial variability in non-decision time follows a half-normal distribution. Evidence on each trial is accumulated until a decision boundary is reached, evidence accumulation is governed by non-decision time, starting point bias, drift rate; drift across time is subject to a diffusion noise. B) Fit of the diffusion model to one example subject from each species, response time distributions are plotted separately for correct and error responses. C) Comparison of model performance across species. Rats are better fitted by the model than mice and humans (DDM BIC; Humans: 2772 ± 262, Rats: 1492 ± 403, Mice: 2778 ± 136; One-way ANOVA; p &lt; 0.0005, F = 10.97). D-G) Estimates of model parameters compared across species. Rodents present lower drift (One-way ANOVA; p &lt; 0.0005, F = 77.72) and boundaries (One-way ANOVA; p &lt; 0.0005, F = 88.29) than humans. Rats show the slower non-decision time (One-way ANOVA; p &lt; 0.0005, F = 347.26). All comparisons are unpaired two-sample t-tests, corrected for multiple comparisons with Bonferroni correction. Notations: * = p&lt;0.05, ** = p&lt;0.01, *** = p&lt;0.005, **** = p&lt;0.001.</p></caption>
<graphic xlink:href="589945v3_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2c">
<title>Species differ in key model parameters revealing differences in the accumulation process</title>
<p>While all three species were well fit by the DDM, our initial investigation showed cross-species differences in RT, suggesting possible differences in the accumulation process across species. To further explore cross-species differences, we examined how DDM parameters varied across species. The DDM assumes that the accumulation process is governed by four main parameters: <bold>boundary separation</bold> (<italic>a</italic>), <bold>drift rate</bold> (<italic>v</italic>), <bold>non-decision time</bold> (<italic>ndt</italic>), and <bold>starting point bias</bold> (<italic>x</italic><sub>0</sub>); these were estimated for individual subjects (<xref rid="fig3" ref-type="fig">Figure 3A</xref>). Comparison of the DDM parameters showed that humans were characterized by the largest drift rate (<italic>v</italic>) and boundary separation (<italic>a</italic>), whereas mice had the lowest drift rate and boundary separation (Drift rate: <italic>p</italic> &lt; 0.0005, <italic>F</italic> = 77.72; Boundary separation: <italic>p</italic> &lt; 0.0005, <italic>F</italic> = 88.29; <xref rid="fig3" ref-type="fig">Figure 3D-E</xref>). Rats showed the greatest non-decision time (<italic>ndt</italic>), while mice had the shortest non-decision time (<italic>p</italic> &lt; 0.0005, <italic>F</italic> = 347.26; <xref rid="fig3" ref-type="fig">Figure 3F</xref>). There was also a trend effect for greater starting point bias (<italic>x</italic><sub>0</sub>) in rodents (<italic>p</italic> = 0.053, <italic>F</italic> = 2.99; <xref rid="fig3" ref-type="fig">Figure 3G</xref>).</p>
<p>Thus, the DDM parameters suggested key differences in the accumulation process across species. The higher boundary separation in humans suggested a higher threshold for perceptual evidence before commitment to a decision, leading to more accurate but slower responses. The greater non-decision time and lesser boundary separation in rats suggested that rats accumulated less evidence, but spent more time in processes unrelated to decision making (for example, motor movements). Finally, mice had the least boundary separation indicating less evidence accumulation, also less time spent in non-decision processes. Accordingly, mice were the fastest and least accurate of the three species.</p>
</sec>
<sec id="s2d">
<title>Rodents’ choices were limited by time-pressures</title>
<p>Given the faster RT in mice, and model-based evidence for faster decision times in rats, we asked if rodents’ choices were limited by internal time-pressures. The classic version of the DDM discussed above, does not readily account for this possibility, for it assumes that with time in a trial, the amount of evidence required to make a decision remains the same. This assumption is implemented in the model through a fixed decision boundary (<italic>a</italic>). To test if rodents experienced time-pressures, we considered two additional variants of the DDM (see methods and <xref rid="figs2" ref-type="fig">Supplementary Figures 2</xref>, <xref rid="figs3" ref-type="fig">3</xref> and <xref rid="figs4" ref-type="fig">4</xref>), a collapsing boundary model (<xref ref-type="bibr" rid="c6">Bowman et al., 2012</xref>; <xref ref-type="bibr" rid="c46">Shevinsky &amp; Reinagel, 2019</xref>), and an urgency model (<xref ref-type="bibr" rid="c11">Ditterich, 2006</xref>).</p>
<p>The collapsing boundary DDM assumes that with time in a trial, the decision boundary collapses, and thus, less evidence is required to make a decision. It included three additional parameters: <bold>initial boundary separation</bold> (<italic>a</italic><sub>0</sub>), <bold>semi-saturation constant</bold> (<italic>t</italic><sub>0.5</sub>), and <bold>amount of collapse</bold> (<italic>k</italic>) of the boundary (see methods and <xref rid="fig4" ref-type="fig">Figure 4A</xref>). The urgency model incorporates an urgency signal that increases with time, raising the probability of a choice. The collapsing boundary- and urgency models are mathematically similar, but the collapsing boundary model can better explain faster RTs on more difficult trials. The urgency DDM also included three additional parameters: <bold>slope</bold> (<italic>u</italic><sub><italic>slope</italic></sub>), <bold>magnitude</bold> (<italic>u</italic><sub><italic>mag</italic></sub>), and <bold>onset</bold> (<italic>τ</italic>) of the urgency signal (<xref rid="fig4" ref-type="fig">Figure 4B</xref>).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4:</label>
<caption><title>Response times for rats and mice are well described by collapsing bounds.</title>
<p>A) Illustration of the diffusion model with collapsing boundary, three (free) parameters are used to estimate the boundary: initial boundary separation, semi-saturation constant, and amount of collapse; the model is otherwise the same as the fixed boundary model. B) Illustration of the diffusion model with an urgency signal, three (free) parameters are used to estimate the (linear) urgency signal: slope of the signal, magnitude of the signal, and onset delay for the signal. C) Comparison of model performance for the three diffusion models: fixed boundary model, collapsing boundary model, and the urgency model, for each species. Rats and mice were better fitted by the collapsing boundaries (Repeated measures ANOVA; Mice: p &lt; 0.0005, F = 22.12; Rats: p = 0.0014, F = 11.12). D-F) Comparison of boundary related parameters of the collapsing boundary model, across species. Mice show the lowest semi-saturation constant (One-way ANOVA; p = 0.004, F = 5.69). G-I) Comparison of urgency related parameters of the urgency model across species. Mice present the highest urgency-slope (One-way ANOVA; p = 0.027, F = 3.71) and urgency delay (One-way ANOVA; p = 0.003, F = 6.06). Notations: * = p&lt;0.05, ** = p&lt;0.01, *** = p&lt;0.005, **** = p&lt;0.001.</p></caption>
<graphic xlink:href="589945v3_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Model comparison using the BIC revealed that the collapsing boundary DDM fit rodent data significantly better than the classic- or the urgency DDM (Repeated measures ANOVA; Mice: <italic>p</italic> &lt; 0.0005, <italic>F</italic> = 22.12; Rats: <italic>p</italic> = 0.0014, <italic>F</italic> = 11.12; <xref rid="fig4" ref-type="fig">Figure 4C</xref>). However, for humans, the collapsing boundary- or the urgency model was not better than the classic DDM (One-way ANOVA; <italic>p</italic> = 0.13, <italic>F</italic> = 2.31; <xref rid="fig4" ref-type="fig">Figure 4C</xref>). These results suggest that rodents’ behavior was limited by internal time-pressures. Further, the collapsing boundary DDM showed the lowest semi-saturation constant (<italic>t</italic><sub>0.5</sub>) for mice, which suggests that the boundary collapse was fastest for mice (<italic>p</italic> = 0.004, <italic>F</italic> = 5.69; <xref rid="fig4" ref-type="fig">Figure 4E</xref>), producing the fastest responses.</p>
<p>Overall, these results supported the hypothesis that internal time-pressures limited rodents’ performance in the current task.</p>
</sec>
<sec id="s2e">
<title>Rats balance speed and accuracy near optimally to maximize the reward rate</title>
<p>Summary performance measures suggested cross-species differences in accuracy and RT, and the DDMs helped explain the differences in the underlying decision parameters. However, it remains unclear how each species settled on their particular speed-accuracy tradeoffs (<xref rid="fig5" ref-type="fig">Figure 5A</xref>). One possibility is that they chose an RT that maximized their reward rate (<xref rid="fig5" ref-type="fig">Figure 5B-C</xref> and <xref rid="figs6" ref-type="fig">Supplementary Figure 6</xref>, see also <xref ref-type="bibr" rid="c5">Bogacz et al. 2006</xref>).</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5:</label>
<caption><title>Rats balance speed and accuracy near optimally to maximize reward rate.</title>
<p>A) The speed-accuracy trade-off plot illustrates the relationship between response time and accuracy across species, each dot represents the mean accuracy and response time of an individual. The dashed line represents the accuracy as a function of different choices of RT for a perfect accumulator. B-C) Representations of accuracy (B) and reward rate (C) as a function of different choice of RT for a perfect accumulator, incorporating the average trial initiation time observed in mice, which was different for correct and error responses. In the simulations, flash ratio was kept at 80% vs 20%, and flash rate was 10 Hz. The red line marks the RT associated with the peak reward rate of the accumulator. D-F) Histograms illustrate the distribution of RT observed in humans (D), mice (E), and rats (F) in comparison to the RT associated with the peak reward rate of the perfect accumulator (black dashed lines).</p></caption>
<graphic xlink:href="589945v3_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>To investigate this possibility, we simulated a perfect accumulator for each species, accounting for cross-species differences in the inter-trial interval (<xref rid="figs6" ref-type="fig">Supplementary Figure 6G-I</xref>, also see methods). Interestingly rats were close to the simulated optimal RT, while humans responded slower than the optimal RT and mice were faster (<xref rid="fig5" ref-type="fig">Figure 5D-F</xref>). These observations suggested that rats may balance speed and accuracy to maximize reward rate.</p>
</sec>
<sec id="s2f">
<title>Mice were more influenced by alternate strategies across latent states</title>
<p>Previous research suggests existence of alternate decision strategies in evidence accumulation tasks (<xref ref-type="bibr" rid="c1">Ashwood et al., 2020</xref>; <xref ref-type="bibr" rid="c9">Carandini &amp; Churchland, 2013</xref>; <xref ref-type="bibr" rid="c42">Roy et al., 2021</xref>). To investigate if subjects in our task displayed shifts in strategy, we used a generalized linear model (GLM) that estimated the binomial probability of choosing the right-over the left side, as a linear function of perceptual evidence and the following alternate strategies: <bold>win-stay-lose-switch</bold> (determined by the choice and reward), and <bold>previous choice</bold> (determined by choice independent of reward). Perceptual evidence was the flash difference, divided by total flashes <inline-formula><inline-graphic xlink:href="589945v3_inline1.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. The intercept term represented side-bias (<xref rid="fig6" ref-type="fig">Figure 6A</xref>, also see methods). The GLM suggested that rats and humans relied more on perceptual evidence, but mice were influenced by alternate strategies (<italic>p</italic> &lt; 0.0005, <italic>F</italic> = 156.28; <xref rid="fig6" ref-type="fig">Figure 6D-E</xref>). The GLM predicted the psychometric curve for rats and humans well, but for mice the fit was poorer (<italic>p</italic> &lt; 0.0005, <italic>F</italic> = 38.67; <xref rid="fig6" ref-type="fig">Figure 6B-C</xref>).</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6:</label>
<caption><title>Mice alternate between different strategies while performing the task.</title>
<p>A) Generalized linear model with 4 parameters: Bias (Intercept), Flash Ratio (Right flashes - Left Flashes) / Total flashes), Win-stay Lose-switch, and Previous choice. B) Goodness of fit of the GLM presents a better fit for the human data compared to mice or rats. Test log-likelihood is in units of bits per trial, and is relative to a ‘null’ Bernoulli coin-flip model (One-way ANOVA; p &lt; 0.0005, F = 38.67). C) Psychometric curve fits, and mean predictive accuracy across species. D) Estimated GLM weights showed that humans relied on the flash ratio more than the rodents, followed by the rats (One-way ANOVA; p &lt; 0.0005, F = 156.28), whereas mice tended to use a previous choice strategy (One-way ANOVA; p &lt; 0.0005, F = 18.2). E) Mean estimated GLM weights across species. F) Model comparisons among the one-state GLM, the classic lapse model (’L’), and multiple GLM-HMMs with different numbers of latent states. To compare across species, we measured the change in test log-likelihood, as a function of the number of states included in the model, relative to a one-state GLM, separately for each species. Mice showed greater increase in LL for a GLM-HMM with 3 latent states, suggesting that mice transitioned through multiple latent states while performing the task. All comparisons are based on unpaired two-sample t-tests, corrected for multiple comparisons with Bonferroni correction. Notations: * = p&lt;0.05, ** = p&lt;0.01, *** = p&lt;0.005, **** = p&lt;0.001.</p></caption>
<graphic xlink:href="589945v3_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>The influence of multiple strategies on decisions may suggest that subjects dynamically switch behavioral strategies on a trial by trial basis (<xref ref-type="bibr" rid="c2">Ashwood et al., 2022</xref>). To test this hypothesis, we used a modeling framework previously proposed by <xref ref-type="bibr" rid="c2">Ashwood et al., (2022)</xref> that combined a hidden Markov model (HMM) with a GLM. Using this GLM-HMM, we investigated the number of latent states underlying choice behavior in each species. We considered the original GLM, a GLM with lapse states, and multiple GLM-HMMs with increasing latent states—2, 3, 4, and 5 states, respectively. Model comparison showed that the original GLM fit the data from rats and humans better (<xref rid="fig6" ref-type="fig">Figure 6F</xref>). However, mice data were better fit by a 3-state GLM-HMM (<xref rid="fig6" ref-type="fig">Figure 6F</xref>); the 3 states were evidence accumulation, and left- and right side biases (<xref rid="figs7" ref-type="fig">Supplementary Figure 7</xref>). Thus, mice appeared to alternate between different latent states that prioritized evidence accumulation or alternate decision strategies.</p>
<p>In line with the above results, we also found interesting, time-varying trends in raw behavior (<xref rid="figs8" ref-type="fig">Supplementary Figure 8</xref>). Rats were remarkably stable in maintaining a constant RT and accuracy across their 120-minute session. Rats performed similar numbers of trials across time and had a stable reward rate across the session. In contrast, in mice, RT, accuracy and reward rate changed over the course of a session. Thus, mouse behavior in this task was more variable trial-to-trial when compared to rats or humans.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>We present a behavioral framework, synchronized across rodents and humans, for investigations of perceptual decision making. Inspired by pulse-based evidence accumulation tasks, previously used in rats, we designed a free response task that offered a speed-accuracy trade-off. In parallel, we developed a video game based on the same task to test humans online. Together we used this task and game to assess species-specific priorities in decision making. Task parameters and training procedures were deliberately synchronized across species, facilitating direct, quantitative comparisons of behavior. All three species learned to perform the task, their behavior was well fit by evidence accumulation models, and we found significant species-specific differences in key parameters. Unlike humans, rodents were best fit by a collapsing boundary DDM suggesting that their performance was limited by internal time-pressures. Rat’s response times were close to optimal to maximize reward rate. Mice alternated between evidence accumulation- and other strategies, and exhibited more variable behavior. Overall, this study highlights the importance of a synchronized behavioral framework for meaningful, quantitative comparisons of cross-species perceptual decision making.</p>
<p>Our framework has several key attributes to facilitate quantitative comparisons of behavior across species. First, to minimize training differences, we used a similar non-verbal feedback-based training strategy in which difficulty was slowly increased to facilitate learning. Second, in humans we used an online video game-based approach. Video games can be advantageous over traditional psychological experiments; games are engaging and can be used to collect objective behavioral measures with well-controlled stimuli. Also, online games are helpful for collecting larger datasets (see also, <xref ref-type="bibr" rid="c12">Do et al., 2023</xref>). Finally, the short, self-paced nature of the video game enabled data collection within a relatively brief period of time (mean completion time = 11.06 minutes +/- 2.26 S.D., while the task could be implemented in a high-throughput, semi-automated rodent training facility allowing collection of behavioral data from many animals. Together, this framework is advantageous for collecting larger datasets across different species within a relatively short amount of time.</p>
<p>An interesting result revealed by this approach is that rodent performance was best fit by a collapsing bound model, suggesting their decisions were limited by internal time-pressures. This was revealed by a comparison of the classic- (<xref ref-type="bibr" rid="c33">Ratcliff, 1978</xref>) and the collapsing boundary (<xref ref-type="bibr" rid="c6">Bowman et al., 2012</xref>; <xref ref-type="bibr" rid="c46">Shevinsky &amp; Reinagel, 2019</xref>) version of the DDM. The classic DDM, a highly successful model for explaining perceptual decision making behavior (<xref ref-type="bibr" rid="c34">Ratcliff, 2014</xref>; <xref ref-type="bibr" rid="c38">Ratcliff et al., 1999</xref>; <xref ref-type="bibr" rid="c36">Ratcliff &amp; Rouder, 1998</xref>), assumes that the amount of evidence required to make a decision remains constant. Others have suggested situations in which less evidence is required with time (<xref ref-type="bibr" rid="c8">Busemeyer &amp; Rapoport, 1988</xref>; <xref ref-type="bibr" rid="c13">Drugowitsch et al., 2012</xref>; <xref ref-type="bibr" rid="c48">Thura et al., 2012</xref>, <xref ref-type="bibr" rid="c11">Ditterich, 2006</xref>). However, experimental evidence for the collapsing boundary model has been inconclusive (<xref ref-type="bibr" rid="c18">Hawkins et al., 2015</xref>; <xref ref-type="bibr" rid="c51">Voskuilen et al., 2016</xref>). Notably, while previous studies used these models to explain human and non-human primate data, here we show that rodents decisions are best fit by a collapsing bound model</p>
<p>While humans and rats were best fit by a single perceptual accumulation strategy across all trials, we found that mice were best fit by a model that alternated between evidence-accumulation and other strategies across different latent states. This finding is consistent with previous studies that have examined mouse behavior in other perceptual decision tasks (<xref ref-type="bibr" rid="c2">Ashwood et al., 2022</xref>; <xref ref-type="bibr" rid="c9">Carandini &amp; Churchland, 2013</xref>; <xref ref-type="bibr" rid="c16">Gupta et al., 2024</xref>; <xref ref-type="bibr" rid="c17">Hanks &amp; Summerfield, 2017</xref>).</p>
<p>The framework we provide here provides a complement to cross species studies using ethological approaches. Recent research has highlighted the importance of focusing on ethological behaviors in different species (<xref ref-type="bibr" rid="c20">Juavinett et al., 2018</xref>). Indeed, focus on ethological behaviors can provide unique insights into cross-species comparisons. However, this rarely allows for direct, quantitative cross-species comparisons as ethologically-relevant behaviors are often species-specific, reflecting adaptations to that organism’s particular niche. Here, we followed an approach that is complementary to the ethological focus, by designing a task that can be performed in similar ways by multiple species, in order to better appreciate the unique and common aspects of behavior.</p>
<sec id="s3a">
<title>Limitations</title>
<p>Species specific differences we report here could reflect uncontrolled environmental variables rather than genetic differences. Despite a deliberate attempt to synchronize most aspects of our task and training across species, there were several differences in the human and rodent setups that could have contributed to the cross-species behavioral differences. First, rewards were different for rodents and humans; drops of sugar water for rodents vs point bonuses for humans. Moreover, while mice were water scheduled to increase motivation and rats were food scheduled. Second, rodents and humans performed the task for different durations, which could have impacted their motivational states differentially. Third, humans participated in the task from their home environment, with the experimenter only present remotely via Zoom. In contrast, the rodent underwent requisite animal handling procedures which were conducted by trained researchers.</p>
</sec>
<sec id="s3b">
<title>Conclusion</title>
<p>In sum, we present a synchronized behavioral framework for high-throughput data, and direct, quantitative comparisons of perceptual decision-making across species. This pulse-based free response evidence accumulation task is designed to differentiate between perceptual (sensory noise) and cognitive components (decision thresholds), which are distinct yet interacting processes affected in neuropsychiatric conditions such as autism spectrum disorder (<xref ref-type="bibr" rid="c41">Robertson &amp; Baron-Cohen, 2017</xref>), Schizophrenia (<xref ref-type="bibr" rid="c19">Horga &amp; Abi-Dargham, 2019</xref>), and Alzheimer’s disease (<xref ref-type="bibr" rid="c22">Kavcic et al., 2011</xref>; <xref ref-type="bibr" rid="c40">Rizzo &amp; Nawrot, 1998</xref>). For example, in autism, perceptual symptoms are characterized by sensory hypersensitivity and hyposensitivity, altered sensory integration, and cognitive difficulties in filtering information, each of which can contribute to challenges in adapting to dynamic environments (<xref ref-type="bibr" rid="c15">Green et al., 2015</xref>; <xref ref-type="bibr" rid="c23">Keehn et al., 2013</xref>; <xref ref-type="bibr" rid="c30">Pellicano &amp; Burr, 2012</xref>). The non-verbal, feedback-driven training pipeline for humans may allow inclusion of participants with communication difficulties, such as non-verbal autistic individuals, improving the reach of this research to underrepresented groups (<xref ref-type="bibr" rid="c25">McKinney et al., 2021</xref>). Moreover, such a framework not only supports basic neuroscience inquiries but also holds translational potential, enabling the quantification of behaviorally relevant traits that serve as objective benchmarks or biomarkers, to aid in better selection and assessment of genetic animal models. Finally, as this task is amenable to neurophysiological investigations, circuit mechanisms of behavioral traits can be followed up in the preclinical animal model.</p>
</sec>
</sec>
<sec id="s5">
<title>Materials and methods</title>
<sec id="s5a">
<title>Rodents</title>
<p>All experiments and procedures were performed in accordance with protocols approved by the Boston University Animal Care and Use Committee. Long Evans adult rats (N=21; aged 3 months to 2 years) were purchased from Taconic or bred in house. C57BL/6NJ adult mice (N=95; aged 2 to 8 months) were purchased from Jackson Laboratory. Both male and female rats or mice were utilized and trained simultaneously in the same room, albeit in separate operant chambers. Rats were food restricted to 80-100% of their body weight and fed once per day (typically 3-4 pellets of food per day). Mice were water restricted to 80-90% of their body weight and received a minimum of 1mL of water a day. Rats received 0.03 mL reward, whereas mice received 0.005 mL reward (10% sucrose solution; 100g/L in water). Reward volume was consistent within a session. Both rats and mice were housed on a 14:10 ON:OFF light schedule with the ON phase corresponding to daylight hours in Boston, MA USA.</p>
</sec>
<sec id="s5b">
<title>Rodent behavioral control system</title>
<p>Behavioral control system was inspired by <xref ref-type="bibr" rid="c10">Dhawale et al., 2017</xref> and <xref ref-type="bibr" rid="c32">Poddar et al., 2013</xref>. Rodents were trained in custom acrylic chambers with three nose ports. Nose ports were 3D printed (Sanworks or custom made) and equipped with a visible LED for stimulus delivery (Sanworks), peristaltic pump for reward delivery, and an IR LED and photodetector as a beam break (Sanworks). Behavioral control software to implement the task and control individual boxes was written in MATLAB. Boxes were controlled through a Teensy-based microcontroller system (Bpod Sanworks). A custom written python application was used to control multiple Bpod instances from a single control computer, requiring an edited version of the Bpod MATLAB software library (edited Bpod library: <ext-link ext-link-type="uri" xlink:href="https://github.com/RatAcad/Bpod_Gen2">https://github.com/RatAcad/Bpod_Gen2</ext-link>; Custom python application: <ext-link ext-link-type="uri" xlink:href="https://github.com/RatAcad/BpodAcademy">https://github.com/RatAcad/BpodAcademy</ext-link>). Further details about the software implementation can be found in the respective code repositories. The floor of the chambers contained bedding.</p>
</sec>
<sec id="s5c">
<title>Rodent daily training</title>
<p>Mice were housed in groups of 2-4 mice per cage whereas rats were housed in pairs in an animal facility. Both were moved to the training room in the laboratory each morning for training. Mice ran for 1 hour shifts and rats ran for 2 hour shifts, 5 days per week in the late morning (10am-noon) or early afternoon (12pm-3pm). Rat feeding was conducted in the late afternoon after behavioral training (1-4pm).</p>
</sec>
<sec id="s5d">
<title>Rodent training pipeline</title>
<p>Rats and mice were rewarded with 10% sucrose at all stages of training and testing. Training took 1-4 weeks depending on the rodent and progressed through 3 stages. In the first stage (1-3 days) rodents were rewarded for inserting their nose into a side port with an illuminated LED (400 trials). In the second stage rodents received reward for inserting their nose into the center port and then the side port with an illuminated LED (400 trials). In the third stage, they received a reward for inserting their nose into the center port and then the side port with a flashing LED. Once rodents reached criterion 90 −100% correct over 400 trials, the probability of flashes on the incorrect side increased in the following way 100:0 -&gt; 90:10 -&gt; 80:20. Progression through this third stage took 1-5 days per condition. After completion of all stages and conditions rodents performed the task with a flash probability of 80:20.</p>
</sec>
<sec id="s5e">
<title>Rodent behavioral task</title>
<p>Rodents were free to move within their cage during the task. At the start of a trial, the light in the center port turned on indicating that the rodent could initiate the trial at its leisure. Once the rodent nose poked in the center port, a single flash would occur simultaneously in both the left and right ports. After this one light flash on both sides, the rodent would see a series of light flashes according to a Bernoulli process – every 100 ms, the rodent would see a flash on either the right or the left side with a probability of 80:20 that the flash would occur on the correct side vs. the incorrect side. The correct side was drawn randomly on each trial. To record a response, the rodent nose poked in either the left or right port and the series of light flashes would terminate as soon as this decision was recorded. If the rodent responded correctly, the light in the correct side port turned on for 3 s and a 30uL-rat or 5uL-mice sucrose water reward was delivered immediately. If the rodent responded incorrectly, all lights turned off for a 5 s time-out and no reward was delivered, and new trials would start after a 2s delay. Trials had an external response deadline of 8 seconds, after which it would be counted as an omission.</p>
</sec>
<sec id="s5f">
<title>Human participants</title>
<p>All experiments and procedures were performed in accordance with protocols approved by the Boston University Institutional Review Board. Players consisted of 18 adolescent male and females, ages 11-17, who had previous experience with different online non-verbal evidence accumulation games (e.g. <xref ref-type="bibr" rid="c12">Do et al. 2023</xref>). Players with a history of seizures were excluded. Players were recruited from Boston University and SPARK, had at least one sibling with a clinical diagnosis of autism, however, players themselves did not have an autism diagnosis.</p>
</sec>
<sec id="s5g">
<title>Human video-game and experimental procedure</title>
<p>The video game was developed using a JavaScript application called PixiJS, and run online using the cloud platform Heroku; data was saved online using the no-SQL database application MongoDB, in JSON format. Demographic and survey data were collected separately using Boston University’s REDCap platform. Each online game session was supervised by a member of the lab, trained in human behavioral testing procedures. This experimenter was present on video call (zoom) and provided guidance on the game setup, game rule was not disclosed; sessions were recorded. During the game, players destroyed asteroids. The first 10 trials served as learning trials, where participants needed to achieve above 90% accuracy to be included in the study. The remaining trials were test trials (80:20 generative flash probability). In each trial, participants selected the asteroid they wanted to destroy. Subsequently, a series of alien-shaped stimuli were presented according to a Poisson process, with an 80% probability of appearing on the correct side and a 20% probability of appearing on the incorrect side, or not at all, every 100 ms. The correct side was randomly determined for each trial. Participants responded by selecting the alien on the correct side, concluding the stimuli presentation. A correct response resulted in the destruction of the asteroid, awarded points, and a wait time of approximately 1 second before the next trial. An incorrect response led to the asteroid remaining intact, no points awarded, and a wait time of approximately 3 seconds before the next trial. If participants failed to respond within 8 seconds, the trial was counted as an omission.</p>
</sec>
<sec id="s5h">
<title>Synchronization of the free response pulse-based evidence accumulation task across species</title>
<p>We developed a cross-species free-response evidence accumulation task originally developed for rodents (Kane et al. 2023). In this task two competing streams of visual pulses were presented on the left and right sides of the subject’s visual field. Subjects were rewarded to select the side with a highly likelihood of pulsing to receive a reward. Pulses were generated using a Poisson process for humans and a Bernoulli process for rodents, with the pulse probability manipulated across task stages. The task maintained consistent stimulus statistics, including flash duration, flash rate, and generative probability, for both rodents and humans—specifically, a 10 Hz flash rate and an 80% flash probability on the rewarded side versus a 20% flash probability on the other side in the testing stage.</p>
<p>The task structure remained uniform across species, comprising four stages: initiation, free-response cue period, choice, and reward/time-out (<xref rid="fig1" ref-type="fig">Figure 1A</xref>). Human participants engaged in a single session (consisting of 200 trials) of the video game online under the supervision of a researcher via video call (<xref rid="fig1" ref-type="fig">Figure 1B</xref>). Multiple rodents performed the task in a 3-port chamber on a daily basis, with data transferred on the same day using Datajoint (<xref rid="fig1" ref-type="fig">Figure 1C</xref>).</p>
</sec>
<sec id="s5i">
<title>Data analyses</title>
<p>Data analysis was conducted using Python version 3.7.1 and R version 4.3.1. Multiple sessions were introduced per rodent, resulting in an average of 3605 ± 231 total trials per mouse and 4107 ± 549 total trials per rat. Chance performance of the task was determined by calculating the upper bound of the 99% binomial confidence interval for each species performing at chance, yielding an estimated chance performance of 52% for rodents and 60% for humans.</p>
<p>Accuracy was calculated by dividing the number of correct trials by the total number of trials and then multiplying the result by 100. Response time is defined as the average duration between the initiation of a stimulus and the subsequent response. Percentage bias was calculated by extracting the absolute difference between right and left trials and dividing by the total number of trials, the result was multiplied by 100. The average accuracy, response time, and reward rate during a session and across sessions were computed using a rolling average of 5 minutes during the 60 (mouse) or 120 (rat) minutes of the session. Trials across the session were calculated by counting the trials per minute and averaging them across sessions and subjects (<xref rid="figs8" ref-type="fig">Supplementary Figure 8</xref>). Standard statistical tests (e.g., One-way ANOVAs, Pearson and Spearman correlations, multiple comparisons and t-students) were conducted using the pingouin package (<xref ref-type="bibr" rid="c49">Vallat, 2018</xref>).</p>
<p>To model the accuracy versus response time relationship shown in <xref rid="fig2" ref-type="fig">Figure 2F</xref>, a generalized additive mixed model (GAMM) was utilized, employing the mgcv package (<xref ref-type="bibr" rid="c52">Wood et al., 2017</xref>). The data points on the plot represent the average accuracy of all trials at each response time, calculated using 0.2-second bins over a span of 3 seconds; only bins that presented more than 50 trials were selected. Pearson correlations were performed using the bins within the first 1.5 seconds for each species. All trials for each species were collectively fitted within the model framework and the data.</p>
</sec>
<sec id="s5j">
<title>Drift diffusion models</title>
<p>Drift diffusion models (DDMs) are widely utilized to characterize decision-making in two-choice paradigms. The DDM assumes that decision-makers accumulate noisy evidence for each choice option over time, ultimately committing to a response when a predefined decision threshold is reached. In our study, we employed three variants of DDMs: the classic DDM (<xref ref-type="bibr" rid="c5">Bogacz et al., 2006</xref>; <xref ref-type="bibr" rid="c33">Ratcliff, 1978</xref>; <xref ref-type="bibr" rid="c35">Ratcliff &amp; McKoon, 2008</xref>), the collapsing boundary DDM (<xref ref-type="bibr" rid="c6">Bowman et al., 2012</xref>; <xref ref-type="bibr" rid="c18">Hawkins et al., 2015</xref>; <xref ref-type="bibr" rid="c46">Shevinsky &amp; Reinagel, 2019</xref>; <xref ref-type="bibr" rid="c51">Voskuilen et al., 2016</xref>) and the urgency DDM (<xref ref-type="bibr" rid="c11">Ditterich, 2006</xref>; <xref ref-type="bibr" rid="c18">Hawkins et al., 2015</xref>). The classic DDM assumes that the amount of evidence required to reach a decision is fixed over time, and implements it with fixed decision boundaries (<italic>a</italic>). By convention, we assume the lower boundary to be 0, which sets a total boundary separation of <italic>a</italic> − 0 = <italic>a</italic>. In addition, it includes the following parameters:</p>
<list list-type="simple">
<list-item><p>1) The drift rate (<italic>v</italic>), which is the rate at which information is sampled; evidence (<italic>x</italic>) grows linearly with time (<italic>t</italic>): the change in evidence (<italic>dx</italic>), is updated by the drift rate (<italic>v</italic>), and a gaussian noise (<italic>W</italic>) scaled with a constant (<italic>c</italic>):</p>
<p><italic>dx</italic> = <italic>v<sub>i</sub></italic> * <italic>dt</italic> + <italic>cdW</italic></p>
<p>Here, <italic>i</italic> represents a trial.</p></list-item>
<list-item><p>2) The non-decision time (<italic>ndt</italic>), which is the time taken up by processes not-related to evidence accumulation.</p></list-item>
<list-item><p>3) The starting point bias (<italic>z</italic>), which determines the location on the distance between the two boundaries from which the evidence accumulation process starts, it reflects a bias to choose one option over the other one. <italic>z</italic> is relative to <italic>a</italic>.</p></list-item>
</list>
<p>Thus, evidence is accumulated over time using the drift rate embedded with noise. Evidence is accumulated until the decision threshold is reached. We fit this model to the choice-RT data of individuals from each species. For each model we also assumed that drift rate, non-decision time and starting point bias can vary from trial-to-trial following normal, half-normal and uniform distributions, respectively:</p>
<p>Drift rate: <italic>v<sub>i</sub> ∼ N(v, theta<sub>v</sub>);</italic></p>
<p><italic>Starting point: x</italic>0<italic><sub>i</sub> ∼ Unif (x</italic>0 - <italic>theta<sub>x</sub></italic>0, <italic>x</italic>0 + <italic>theta<sub>x</sub></italic>0);</p>
<p><italic>Non-decision time: ndt<sub>i</sub> ∼ Unif (ndt</italic> - <italic>theta<sub>n</sub>dt</italic>, <italic>ndt + theta<sub>n</sub>dt</italic>).</p>
<p>Unlike the classic DDM, both collapsing boundary model and the urgency model assume that the amount of evidence required to reach a decision is not fixed over time. The collapsing boundary model included three additional parameters— 1) initial boundary separation (<italic>a</italic><sub>0</sub>), 2) the semi-saturation constant (<italic>t</italic><sub>0.5</sub>), or the time when the boundary had collapsed by half, and 3) the total amount of collapse (<italic>k</italic>). The urgency model also included three additional parameters— 1) the slope of a (linear) urgency signal (<italic>u</italic><sub><italic>slope</italic></sub>), 2) total amount of urgency (<italic>u</italic><sub><italic>mag</italic></sub>), and 3) the onset delay of urgency (<italic>τ</italic>).</p>
<p>The basic idea behind fitting a DDM to experimental data is to find a set of parameters which can simulate trials with the same accuracy and RT distributions as the experimental data. This is done iteratively, by perturbing the parameters, starting from an initial set of values, and comparing the fit between the simulated and experimental trials. Here, we used the <italic>χ</italic><sup>2</sup> method to compare between the RT histograms of the simulated- and experimental data, because the method is relatively fast and less prone to outlier RTs (<xref ref-type="bibr" rid="c37">Ratcliff &amp; Tuerlinckx, 2002</xref>). All models were fitted using a custom R package (rddm; <ext-link ext-link-type="uri" xlink:href="https://github.com/gkane26/rddm">https://github.com/gkane26/rddm</ext-link>).</p>
</sec>
<sec id="s5k">
<title>Simulation analyses</title>
<p>For all simulations with the perfect accumulator, we included 10,000 trials for each choice of RT; RT typically varied between 100 ms and 4 s, with an increment of 200 ms. For each choice of RT, we calculated the accuracy and/or reward rate of the accumulator, considering the 10,000 trials. Consistent with the current task, each trial had a generative flash probability (<italic>p</italic>) of 80%. For each trial, the correct side (left or right) was pre-determined with a coin flip. Individual flashes were generated with a Bernoulli process for the simulations for rodents and a Poisson process for the simulations for humans. Sequence of flashes continued only up to the choice of RT. The perfect accumulator always chose the side with greater total number of flashes. If the trial ended with the same flash counts on each side, the perfect accumulator randomly picked a side. We also considered a noisy accumulator, which was informed by the accuracy of each species at specific RTs; this was obtained from the accuracy predictions of the GAMM (<xref rid="figs7" ref-type="fig">Supplementary Figure 7</xref>).</p>
<p>For simulations of the reward-rate, in addition to RT, we considered species-specific choices of inter-trial intervals (ITI). As mentioned in the results, ITI was the interval between the response and the next stimulus onset; it included the time to initiate a trial and the time spent in post-response events, such as rewards, timeouts etc. The average ITI was different across species, there was also a difference in the average ITI for rewarded and unrewarded trials. These differences were accounted for in the simulations. In the current experiment, each correct response produced the same amount of rewards, assuming each reward to be of 1 <italic>unit</italic>, a total accuracy of <italic>N</italic> would produce a total of <italic>N</italic> rewards. For each choice of RT, reward-rate was calculated for the 10,000 trials as:
<disp-formula>
<graphic xlink:href="589945v3_ueqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The optimal RT was the RT corresponding to the peak reward-rate in the RT versus reward-rate plot. Note that these simulations assumed that RT included the decision- or evidence-accumulation process only, whereas other models have also incorporated periods of non-accumulation (<xref ref-type="bibr" rid="c47">Simen et al., 2009</xref>).</p>
</sec>
<sec id="s5l">
<title>GLM and GLM-HMM</title>
<p>The generalized linear model (GLM) was utilized to elucidate choice probability, specifically the tendency to select the right option over the left option. This model incorporated three main predictors as a linear function:
<disp-formula>
<graphic xlink:href="589945v3_ueqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<list list-type="order">
<list-item><p>Pulse or flash difference: Calculated as the disparity between flashes on the two sides, normalized by the total number of flashes on both sides.</p></list-item>
<list-item><p>Win-stay or lose-switch strategy: Reflecting the tendency to stick with a chosen side after a win or switch sides after a loss.</p></list-item>
<list-item><p>Previous choice strategy: Indicating the inclination to follow the previous choice made.</p></list-item>
</list>
<p>The intercept term in the model represented the inherent bias towards one side over the other. Notably, this analysis was restricted to data from the 80% versus 20% flash stage.</p>
<p>To compare model fit across species with varying trial numbers, we employed the log-likelihood per trial in bits, as outlined by <xref ref-type="bibr" rid="c2">Ashwood et al. (2022)</xref>. This is calculated as follows:
<disp-formula>
<graphic xlink:href="589945v3_ueqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>LL</italic><sub><italic>data</italic></sub> is the log-likelihood of the entire data per species. <italic>n</italic><sub><italic>test</italic></sub> is the number of trials in the data. Predictive accuracy, following the methodology of <xref ref-type="bibr" rid="c2">Ashwood et al. (2022)</xref>, was also utilized to gauge the goodness of fit.</p>
<p>Afterward, we compared these fits with a 2-state classic lapse model, which posits that subjects transition between two latent states. In one state, termed the engaged state, decisions are influenced by the stimuli, leading to dependent probabilities associated with the left and right stimuli. In the other state, referred to as the disengaged or lapse stage, decisions are entirely independent of the stimuli. In this scenario, subjects essentially flip a biased coin on each trial, with a fixed probability (γr+γl), and subsequently adopt one of two strategies based on the outcome: a strategy contingent on the stimulus or a strategy that disregards the stimulus entirely.
<disp-formula>
<graphic xlink:href="589945v3_ueqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Furthermore, to elucidate potential transitions through different task stages, we applied a modeling framework incorporating hidden Markov models (HMMs). This framework, known as GLM-HMM, assumes distinct latent states that animals may inhabit during task performance, each potentially influencing decision strategies differently. This model comprises multiple independent GLMs, each corresponding to a latent state and characterizing choice outcomes as a Bernoulli process. Transition between states is governed by transition probabilities, and weight vectors within each state capture the relative influence of decision strategies. We fitted the GLM-HMM to cross-species data, varying the number of latent states and employing hyperparameters σ = 2 and α = 2 to govern the prior. A detailed description of the model is presented in <xref ref-type="bibr" rid="c2">Ashwood et al., (2022)</xref>,</p>
</sec>
</sec>
</body>
<back>
<sec id="s6">
<title>Supplementary information</title>
<fig id="figs1" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 1:</label>
<caption><title>Learning curricula in the cross-species task.</title>
<p>A) Experiments occurred in multiple phases: Shaping (rodents only), Training and Testing. Prior to training, rodents transitioned through three shaping stages to familiarize them with the operant chamber. In shaping stage 1 they received reward for inserting their noise in an illuminated noise poke. In shaping stage 2 they received reward for first poking in the center port to initiate a trial and then in the illuminated side port with the light. In shaping stage 3 they received reward for first poking in the center port to initiate a trial and then in the flashing side port. During the first stage of training both humans and rodents performed a simple version of the task in which the probability of cue presentation was high on the correct side (90% per time point) and low on the incorrect side (10% per time point). After completion of training, subjects transitioned to the testing phase in which the probability of cue presentation was 80% on the correct side, and 20% on the incorrect side. B) Table showing the number of subjects and training criteria for each species across the learning curricula. C) Evolution of averaged accuracy, response time and number of trials across learning in mice, rats and humans. D) Example mouse, rat and human evolution across stages and sessions. The red dashed lines represent the transitions across stages.</p></caption>
<graphic xlink:href="589945v3_figs1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs2" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 2:</label>
<caption><title>Comparison of accuracy, response time and bias across species, separately for female and male subjects.</title>
<p>Notations: * = p&lt;0.05, ** = p&lt;0.01, *** = p&lt;0.005, **** = p&lt;0.001.</p></caption>
<graphic xlink:href="589945v3_figs2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs3" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 3:</label>
<caption><title>Parameter recovery for the DDM.</title>
<p>Based on the parameters observed with the empirical data, we simulated 50 datasets per species with 600 trials each. After fitting the DDM to each of these simulated datasets, we compared the generative and fitted parameters.</p></caption>
<graphic xlink:href="589945v3_figs3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs4" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 4:</label>
<caption><title>Comparison of drift rate, non-decision time and starting point bias across species, separately for the collapsing boundary DDM and the urgency DDM.</title>
<p>Both models present similar parameter estimates and cross-species trends as the base DDM. Notations: * = p&lt;0.05, ** = p&lt;0.01, *** = p&lt;0.005, **** = p&lt;0.001.</p></caption>
<graphic xlink:href="589945v3_figs4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs5" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 5:</label>
<caption><title>Comparison of DDM parameters that control the trial-to-trial variability of its main parameters, such as drift rate, non-decision time and starting point bias.</title>
<p>We assumed variability of drift rate from trial to trial follows a normal distribution, that for non-decision time follows a half-normal distribution, and for starting point bias, trial-to-trial variability follows a uniform distribution. A) corresponds to the original DDM, B) corresponds to the collapsing boundary model, C) corresponds to the urgency DDM. Notations: * = p&lt;0.05, ** = p&lt;0.01, *** = p&lt;0.005, **** = p&lt;0.001.</p></caption>
<graphic xlink:href="589945v3_figs5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs6" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 6:</label>
<caption><title>Differences in intertrial intervals across species and its effects on the reward rate simulations.</title>
<p>A-C) Distributions of initiation times across all correct and erroneous responses, separately for mice, rats and humans. Initiation time was the period between the start of a trial and the center poke, after the center poke, flash stimuli were presented; for humans this was the time to choose an asteroid. D) Reward rate (rewards/min) as a function of different choices of RT for a perfect accumulator, simulated separately for humans (green line) and rodents (purple line). RT corresponding to the peak reward rate is noted. E) Reward rate of a perfect accumulator taking into account different initiation times. F) Reward rate as a function of different choices of RT for noisy (animal) accumulators. Separate simulations were run to account for average trial initiation times observed in rats and in mice, for correct and error responses. In the simulations, flash ratio was kept at 80% vs 20%, and flash rate was 10 Hz, same as that for the actual experiments. In addition to initiation time, choice accuracy for at different RT levels was predicted by the GAMM, previously fit to animal choice/RT data (see <xref rid="fig2" ref-type="fig">Figure 2F</xref>). G-I) Reward rate as a function of different choices of RT for humans (G), mice (H) and rats (I) based on a perfect accumulator, incorporating the average trial initiation time observed in each species, for correct and error responses. The black dashed line represents the response time where the reward rate of the accumulator peaks and the colored line is the average response time of each species.</p></caption>
<graphic xlink:href="589945v3_figs6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs7" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 7:</label>
<caption><title>Mouse data is better fit with a hidden Markov model with 3 latent states.</title>
<p>A) Change in test log-likelihood as a function of the number of states included in the GLM-HMM, relative to a (one-state) GLM, modeled separately for each mouse. The classic lapse model, a restricted form of the two-state model, is labeled as ‘L’. Each trace represents a single mouse and the solid black line indicates the mean across animals. B) Change in predictive accuracy relative to a one-state GLM for each mouse, indicating the percentage improvement in predicting choice. C) Gray dots correspond to individual sessions across all mice, indicating the fraction of trials spent in state 1 (engaged) and state 2 (biased left). Points at the vertices (1,0), (0,1) or (0,0) indicate sessions with no state changes, whereas points along the sides of the triangle indicate sessions that involve only two of the three states. Red dots correspond to the same fractional occupancies for each of the mice, revealing that the engaged state predominated but that all mice spent time in all three states. D) Inferred GLM weights for each mouse, for each of the three states in the three-state model. The solid black curve represents a global fit using pooled data from all mice. E) Psychometric curve for each state, conditioned on previous reward (solid line if right and dashed line if left) and previous choice (darker color if rewarded and dashed line if not rewarded) and all the states combined.</p></caption>
<graphic xlink:href="589945v3_figs7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs8" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 8:</label>
<caption><title>Rats exhibited stability throughout the entire session, whereas mice displayed greater variability.</title>
<p>A-D) Averaged accuracy (A), response time (B), number of trials (C), and reward rate (D) across a session. It is important to note that mouse sessions lasted for 60 minutes and rat sessions for 120 minutes.</p></caption>
<graphic xlink:href="589945v3_figs8.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<ack>
<title>Acknowledgements</title>
<p>We thank Christa Rose, Arielle Rubel, Julie Gomez, Sanaa Ahmed, Anosha Khawaja-Lopez, Benjamin Lee and Sina Analoui for help with collection of rodent data, and Vanessa Torres-Lacarra and Phoebe Lesk for collection of human data. We thank Helen Tager-Flusberg for feedback on human data collection, Joseph McGuire for feedback on the analyses, and Josh Sanders for feedback on the behavioral training software. This work was supported by NIMH award number R56MH132732 and SFARI award number 874568 to BBS and a Center for Systems Neuroscience distinguished fellowship award to CDS and GAK.</p>
</ack>
<sec id="d1e1157" sec-type="additional-information">
<title>Additional information</title>
<sec id="s4">
<title>Contributions</title>
<p>SC, CDS, GAK, HX and QHD designed the experiments. SC and CDS analyzed the data. SC, CDS and BBS wrote the manuscript. All authors contributed to the conceptualization and execution of the study and edited the manuscript.</p>
</sec>
<glossary>
<title>Abbreviations</title>
<def-list>
<def-item><term>DDM</term><def><p>drift diffusion model</p></def></def-item>
<def-item><term>GAMM</term><def><p>generalized additive mixture model</p></def></def-item>
<def-item><term>GLM</term><def><p>generalized linear model</p></def></def-item>
<def-item><term>GLM-HMM</term><def><p>generalized linear model-hidden markov model</p></def></def-item>
<def-item><term>ITI</term><def><p>inter-trial interval</p></def></def-item>
<def-item><term>RT</term><def><p>response time</p></def></def-item>
</def-list>
</glossary>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ashwood</surname>, <given-names>Z. C.</given-names></string-name>, <string-name><surname>Roy</surname>, <given-names>N. A.</given-names></string-name>, <string-name><surname>Bak</surname>, <given-names>J. H.</given-names></string-name>, &amp; <string-name><surname>Pillow</surname>, <given-names>J. W</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Inferring learning rules from animal decision-making</article-title>. <source>Advances in Neural Information Processing Systems</source>, <volume>33</volume>, <fpage>3442</fpage>–<lpage>3453</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ashwood</surname>, <given-names>Z. C.</given-names></string-name>, <string-name><surname>Roy</surname>, <given-names>N. A.</given-names></string-name>, <string-name><surname>Stone</surname>, <given-names>I. R.</given-names></string-name>, <string-name><surname>Urai</surname>, <given-names>A. E.</given-names></string-name>, <string-name><surname>Churchland</surname>, <given-names>A. K.</given-names></string-name>, <string-name><surname>Pouget</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Pillow</surname>, <given-names>J. W</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Mice alternate between discrete strategies during perceptual decision-making</article-title>. <source>Nature Neuroscience</source>, <volume>25</volume>(<issue>2</issue>), <elocation-id>Article 2</elocation-id>. <pub-id pub-id-type="doi">10.1038/s41593-021-01007-z</pub-id></mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Badre</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Frank</surname>, <given-names>M. J.</given-names></string-name>, &amp; <string-name><surname>Moore</surname>, <given-names>C. I</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Interactionist Neuroscience</article-title>. <source>Neuron</source>, <volume>88</volume>(<issue>5</issue>), <fpage>855</fpage>– <lpage>860</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2015.10.021</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barron</surname>, <given-names>H. C.</given-names></string-name>, <string-name><surname>Reeve</surname>, <given-names>H. M.</given-names></string-name>, <string-name><surname>Koolschijn</surname>, <given-names>R. S.</given-names></string-name>, <string-name><surname>Perestenko</surname>, <given-names>P. V.</given-names></string-name>, <string-name><surname>Shpektor</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Nili</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Rothaermel</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Campo-Urriza</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>O’Reilly</surname>, <given-names>J. X.</given-names></string-name>, <string-name><surname>Bannerman</surname>, <given-names>D. M.</given-names></string-name>, <string-name><surname>Behrens</surname>, <given-names>T. E. J.</given-names></string-name>, &amp; <string-name><surname>Dupret</surname>, <given-names>D</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Neuronal Computation Underlying Inferential Reasoning in Humans and Mice</article-title>. <source>Cell</source>, <volume>183</volume>(<issue>1</issue>), <fpage>228</fpage>–<lpage>243.e21.</lpage> <pub-id pub-id-type="doi">10.1016/j.cell.2020.08.035</pub-id></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bogacz</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Brown</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Moehlis</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Holmes</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Cohen</surname>, <given-names>J. D</given-names></string-name></person-group>. (<year>2006</year>). <article-title>The physics of optimal decision making: A formal analysis of models of performance in two-alternative forced-choice tasks</article-title>. <source>Psychological Review</source>, <volume>113</volume>(<issue>4</issue>), <fpage>700</fpage>–<lpage>765</lpage>. <pub-id pub-id-type="doi">10.1037/0033-295X.113.4.700</pub-id></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bowman</surname>, <given-names>N. E.</given-names></string-name>, <string-name><surname>Kording</surname>, <given-names>K. P.</given-names></string-name>, &amp; <string-name><surname>Gottfried</surname>, <given-names>J. A</given-names></string-name></person-group>. (<year>2012</year>). <article-title>Temporal Integration of Olfactory Perceptual Evidence in Human Orbitofrontal Cortex</article-title>. <source>Neuron</source>, <volume>75</volume>(<issue>5</issue>), <fpage>916</fpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2012.06.035</pub-id></mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brunton</surname>, <given-names>B. W.</given-names></string-name>, <string-name><surname>Botvinick</surname>, <given-names>M. M.</given-names></string-name>, &amp; <string-name><surname>Brody</surname>, <given-names>C. D</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Rats and humans can optimally accumulate evidence for decision-making</article-title>. <source>Science (New York, N.Y.)</source>, <volume>340</volume>(<issue>6128</issue>), <fpage>95</fpage>–<lpage>98</lpage>. <pub-id pub-id-type="doi">10.1126/science.1233912</pub-id></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Busemeyer</surname>, <given-names>J. R.</given-names></string-name>, &amp; <string-name><surname>Rapoport</surname>, <given-names>A</given-names></string-name></person-group>. (<year>1988</year>). <article-title>Psychological models of deferred decision making</article-title>. <source>Journal of Mathematical Psychology</source>, <volume>32</volume>(<issue>2</issue>), <fpage>91</fpage>–<lpage>134</lpage>. <pub-id pub-id-type="doi">10.1016/0022-2496(88)90042-9</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carandini</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Churchland</surname>, <given-names>A. K</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Probing perceptual decisions in rodents</article-title>. <source>Nature Neuroscience</source>, <volume>16</volume>(<issue>7</issue>), <elocation-id>Article 7</elocation-id>. <pub-id pub-id-type="doi">10.1038/nn.3410</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dhawale</surname>, <given-names>A. K.</given-names></string-name>, <string-name><surname>Poddar</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Wolff</surname>, <given-names>S. B.</given-names></string-name>, <string-name><surname>Normand</surname>, <given-names>V. A.</given-names></string-name>, <string-name><surname>Kopelowitz</surname>, <given-names>E.</given-names></string-name>, &amp; <string-name><surname>Ölveczky</surname>, <given-names>B. P</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Automated long-term recording and analysis of neural activity in behaving animals</article-title>. <source>eLife</source>, <volume>6</volume>, <elocation-id>e27702</elocation-id>. <pub-id pub-id-type="doi">10.7554/eLife.27702</pub-id></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ditterich</surname>, <given-names>J</given-names></string-name></person-group>. (<year>2006</year>). <article-title>Stochastic models of decisions about motion direction: Behavior and physiology</article-title>. <source>Neural Networks: The Official Journal of the International Neural Network Society</source>, <volume>19</volume>(<issue>8</issue>), <fpage>981</fpage>–<lpage>1012</lpage>. <pub-id pub-id-type="doi">10.1016/j.neunet.2006.05.042</pub-id></mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Do</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Kane</surname>, <given-names>G. A.</given-names></string-name>, <string-name><surname>McGuire</surname>, <given-names>J. T.</given-names></string-name>, &amp; <string-name><surname>Scott</surname>, <given-names>B. B</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Assessing evidence accumulation and rule learning in humans with an online game</article-title>. <source>Journal of Neurophysiology</source>, <volume>129</volume>(<issue>1</issue>), <fpage>131</fpage>–<lpage>143</lpage>. <pub-id pub-id-type="doi">10.1152/jn.00124.2022</pub-id></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Drugowitsch</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Moreno-Bote</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Churchland</surname>, <given-names>A. K.</given-names></string-name>, <string-name><surname>Shadlen</surname>, <given-names>M. N.</given-names></string-name>, &amp; <string-name><surname>Pouget</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2012</year>). <article-title>The Cost of Accumulating Evidence in Perceptual Decision Making</article-title>. <source>Journal of Neuroscience</source>, <volume>32</volume>(<issue>11</issue>), <fpage>3612</fpage>–<lpage>3628</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.4010-11.2012</pub-id></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Esteves</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Moreira</surname>, <given-names>P. S.</given-names></string-name>, <string-name><surname>Sousa</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Leite-Almeida</surname>, <given-names>H</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Assessing Impulsivity in Humans and Rodents: Taking the Translational Road</article-title>. <source>Frontiers in Behavioral Neuroscience</source>, <volume>15</volume>. <pub-id pub-id-type="doi">10.3389/fnbeh.2021.647922</pub-id></mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Green</surname>, <given-names>S. A.</given-names></string-name>, <etal>et al.</etal></person-group> (<year>2015</year>). <article-title>Reduced habituation of autonomic responses in children with autism spectrum disorder</article-title>. <source>Developmental Cognitive Neuroscience</source>, <volume>6</volume>, <fpage>29</fpage>–<lpage>37</lpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gupta</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>DePasquale</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Kopec</surname>, <given-names>C. D.</given-names></string-name>, &amp; <string-name><surname>Brody</surname>, <given-names>C. D</given-names></string-name></person-group>. (<year>2024</year>). <article-title>Trial-history biases in evidence accumulation can give rise to apparent lapses in decision-making</article-title>. <source>Nature Communications</source>, <volume>15</volume>(<issue>1</issue>), <fpage>662</fpage>. <pub-id pub-id-type="doi">10.1038/s41467-024-44880-5</pub-id></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hanks</surname>, <given-names>T. D.</given-names></string-name>, &amp; <string-name><surname>Summerfield</surname>, <given-names>C</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Perceptual Decision Making in Rodents, Monkeys, and Humans</article-title>. <source>Neuron</source>, <volume>93</volume>(<issue>1</issue>), <fpage>15</fpage>–<lpage>31</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2016.12.003</pub-id></mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hawkins</surname>, <given-names>G. E.</given-names></string-name>, <string-name><surname>Forstmann</surname>, <given-names>B. U.</given-names></string-name>, <string-name><surname>Wagenmakers</surname>, <given-names>E.-J.</given-names></string-name>, <string-name><surname>Ratcliff</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Brown</surname>, <given-names>S. D</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Revisiting the Evidence for Collapsing Boundaries and Urgency Signals in Perceptual Decision-Making</article-title>. <source>The Journal of Neuroscience</source>, <volume>35</volume>(<issue>6</issue>), <fpage>2476</fpage>–<lpage>2484</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.2410-14.2015</pub-id></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Horga</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Abi-Dargham</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2019</year>). <article-title>An integrative framework for perceptual disturbances in psychosis</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>20</volume>(<issue>12</issue>), <fpage>763</fpage>–<lpage>778</lpage>. <pub-id pub-id-type="doi">10.1038/s41583-019-0234-1</pub-id></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Juavinett</surname>, <given-names>A. L.</given-names></string-name>, <string-name><surname>Erlich</surname>, <given-names>J. C.</given-names></string-name>, &amp; <string-name><surname>Churchland</surname>, <given-names>A. K</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Decision-making behaviors: Weighing ethology, complexity, and sensorimotor compatibility</article-title>. <source>Current Opinion in Neurobiology</source>, <volume>49</volume>, <fpage>42</fpage>–<lpage>50</lpage>. <pub-id pub-id-type="doi">10.1016/j.conb.2017.11.001</pub-id></mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kane</surname>, <given-names>G.A.</given-names></string-name>, <string-name><surname>Senne</surname>, <given-names>R.A.</given-names></string-name> and <string-name><surname>Scott</surname>, <given-names>B.B</given-names></string-name></person-group>., (<year>2024</year>). <article-title>Rat movements reflect internal decision dynamics in an evidence accumulation task</article-title>. <source>Journal of Neurophysiology</source>. In press. <pub-id pub-id-type="doi">10.1152/jn.00181.2024</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kavcic</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Vaughn</surname>, <given-names>W.</given-names></string-name>, &amp; <string-name><surname>Duffy</surname>, <given-names>C. J</given-names></string-name></person-group>. (<year>2011</year>). <article-title>Distinct Visual Motion Processing Impairments In Aging and Alzheimer’s Disease</article-title>. <source>Vision Research</source>, <volume>51</volume>(<issue>3</issue>), <fpage>386</fpage>–<lpage>395</lpage>. <pub-id pub-id-type="doi">10.1016/j.visres.2010.12.004</pub-id></mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Keehn</surname>, <given-names>B.</given-names></string-name>, <etal>et al.</etal></person-group> (<year>2013</year>). <article-title>Intersecting the social and cognitive neuroscience of autism spectrum disorders: An integrative approach</article-title>. <source>Frontiers in Human Neuroscience</source>, <volume>7</volume>, <fpage>748</fpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Markou</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Chiamulera</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Geyer</surname>, <given-names>M. A.</given-names></string-name>, <string-name><surname>Tricklebank</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Steckler</surname>, <given-names>T</given-names></string-name></person-group>. (<year>2009</year>). <article-title>Removing Obstacles in Neuroscience Drug Discovery: The Future Path for Animal Models</article-title>. <source>Neuropsychopharmacology</source>, <volume>34</volume>(<issue>1</issue>), <fpage>74</fpage>–<lpage>89</lpage>. <pub-id pub-id-type="doi">10.1038/npp.2008.173</pub-id></mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McKinney</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Weisblatt</surname>, <given-names>E. J.</given-names></string-name>, <string-name><surname>Hotson</surname>, <given-names>K. L.</given-names></string-name>, <string-name><surname>Bilal Ahmed</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Dias</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>BenShalom</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Foster</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Murphy</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Villar</surname>, <given-names>S. S.</given-names></string-name>, &amp; <string-name><surname>Belmonte</surname>, <given-names>M. K</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Overcoming hurdles to intervention studies with autistic children with profound communication difficulties and their families</article-title>. <source>Autism</source>, <volume>25</volume>(<issue>6</issue>), <fpage>1627</fpage>–<lpage>1639</lpage>. <pub-id pub-id-type="doi">10.1177/1362361321998916</pub-id></mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nestler</surname>, <given-names>E. J.</given-names></string-name>, &amp; <string-name><surname>Hyman</surname>, <given-names>S. E</given-names></string-name></person-group>. (<year>2010</year>). <article-title>Animal models of neuropsychiatric disorders</article-title>. <source>Nature Neuroscience</source>, <volume>13</volume>(<issue>10</issue>), <fpage>1161</fpage>–<lpage>1169</lpage>. <pub-id pub-id-type="doi">10.1038/nn.2647</pub-id></mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nguyen</surname>, <given-names>Q. N.</given-names></string-name>, &amp; <string-name><surname>Reinagel</surname>, <given-names>P</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Different Forms of Variability Could Explain a Difference Between Human and Rat Decision Making</article-title>. <source>Frontiers in Neuroscience</source>, <volume>16</volume>. <pub-id pub-id-type="doi">10.3389/fnins.2022.794681</pub-id></mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Odoemene</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Pisupati</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Nguyen</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Churchland</surname>, <given-names>A. K</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Visual Evidence Accumulation Guides Decision-Making in Unrestrained Mice</article-title>. <source>The Journal of Neuroscience</source>, <volume>38</volume>(<issue>47</issue>), <fpage>10143</fpage>–<lpage>10155</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.3478-17.2018</pub-id></mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Pedrosa</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Menichini</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Pajot-Moric</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Vincent</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Zhou</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Teachen</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Latham</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Akrami</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Humans, rats and mice show species-specific adaptations to sensory statistics in categorisation behaviour</article-title> (p. <fpage>2023.01.30.526119</fpage>). <source>bioRxiv</source>. <pub-id pub-id-type="doi">10.1101/2023.01.30.526119</pub-id></mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pellicano</surname>, <given-names>E.</given-names></string-name>, &amp; <string-name><surname>Burr</surname>, <given-names>D</given-names></string-name></person-group>. (<year>2012</year>). <article-title>When the world becomes ‘too real’: A Bayesian explanation of autistic perception</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>16</volume>(<issue>10</issue>), <fpage>504</fpage>–<lpage>510</lpage>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pinto</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Koay</surname>, <given-names>S. A.</given-names></string-name>, <string-name><surname>Engelhard</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Yoon</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Deverett</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Thiberge</surname>, <given-names>S. Y.</given-names></string-name>, <string-name><surname>Witten</surname>, <given-names>I. B.</given-names></string-name>, <string-name><surname>Tank</surname>, <given-names>D. W.</given-names></string-name>, &amp; <string-name><surname>Brody</surname>, <given-names>C. D</given-names></string-name></person-group>. (<year>2018</year>). <article-title>An Accumulation-of-Evidence Task Using Visual Pulses for Mice Navigating in Virtual Reality</article-title>. <source>Frontiers in Behavioral Neuroscience</source>, <volume>12</volume>. <ext-link ext-link-type="uri" xlink:href="https://www.frontiersin.org/articles/10.3389/fnbeh.2018.00036">https://www.frontiersin.org/articles/10.3389/fnbeh.2018.00036</ext-link></mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Poddar</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Kawai</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Ölveczky</surname>, <given-names>B. P</given-names></string-name></person-group>. (<year>2013</year>). <article-title>A Fully Automated High-Throughput Training System for Rodents</article-title>. <source>PLOS One</source>, <volume>8</volume>(<issue>12</issue>), <fpage>e83171</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0083171</pub-id></mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ratcliff</surname>, <given-names>R</given-names></string-name></person-group>. (<year>1978</year>). <article-title>A theory of memory retrieval</article-title>. <source>Psychological Review</source>, <volume>85</volume>(<issue>2</issue>), <fpage>59</fpage>–<lpage>108</lpage>. <pub-id pub-id-type="doi">10.1037/0033-295X.85.2.59</pub-id></mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ratcliff</surname>, <given-names>R</given-names></string-name></person-group>. (<year>2014</year>). <article-title>Measuring psychometric functions with the diffusion model</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source>, <volume>40</volume>(<issue>2</issue>), <fpage>870</fpage>–<lpage>888</lpage>. <pub-id pub-id-type="doi">10.1037/a0034954</pub-id></mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ratcliff</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>McKoon</surname>, <given-names>G</given-names></string-name></person-group>. (<year>2008</year>). <article-title>The Diffusion Decision Model: Theory and Data for Two-Choice Decision Tasks</article-title>. <source>Neural Computation</source>, <volume>20</volume>(<issue>4</issue>), <fpage>873</fpage>–<lpage>922</lpage>. <pub-id pub-id-type="doi">10.1162/neco.2008.12-06-420</pub-id></mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ratcliff</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Rouder</surname>, <given-names>J. N</given-names></string-name></person-group>. (<year>1998</year>). <article-title>Modeling Response Times for Two-Choice Decisions</article-title>. <source>Psychological Science</source>, <volume>9</volume>(<issue>5</issue>), <fpage>347</fpage>–<lpage>356</lpage>. <pub-id pub-id-type="doi">10.1111/1467-9280.00067</pub-id></mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ratcliff</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Tuerlinckx</surname>, <given-names>F</given-names></string-name></person-group>. (<year>2002</year>). <article-title>Estimating parameters of the diffusion model: Approaches to dealing with contaminant reaction times and parameter variability</article-title>. <source>Psychonomic Bulletin &amp; Review</source>, <volume>9</volume>(<issue>3</issue>), <fpage>438</fpage>–<lpage>481</lpage>. <pub-id pub-id-type="doi">10.3758/bf03196302</pub-id></mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ratcliff</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Van Zandt</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>McKoon</surname>, <given-names>G.</given-names></string-name></person-group> (<year>1999</year>). <article-title>Connectionist and diffusion models of reaction time</article-title>. <source>Psychological Review</source>, <volume>106</volume>(<issue>2</issue>), <fpage>261</fpage>–<lpage>300</lpage>. <pub-id pub-id-type="doi">10.1037/0033-295X.106.2.261</pub-id></mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Redish</surname>, <given-names>A. D.</given-names></string-name>, <string-name><surname>Sweis</surname>, <given-names>B. M.</given-names></string-name>, <string-name><surname>Abram</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Duin</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kazinka</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Kocharian</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>MacDonald</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Schmidt</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Schmitzer-Tobert</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Thomas</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Sunk cost sensitivity in mice, rats, and humans on the Restaurant Row and WebSurf tasks cannot be explained by attrition biases alone</article-title> (p. <fpage>2021.10.07.462802</fpage>). <source>bioRxiv</source>. <pub-id pub-id-type="doi">10.1101/2021.10.07.462802</pub-id></mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rizzo</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Nawrot</surname>, <given-names>M</given-names></string-name></person-group>. (<year>1998</year>). <article-title>Perception of movement and shape in Alzheimer’s disease</article-title>. <source>Brain: A Journal of Neurology</source>, <volume>121</volume>(<issue>12</issue>), <fpage>2259</fpage>–<lpage>2270</lpage>. <pub-id pub-id-type="doi">10.1093/brain/121.12.2259</pub-id></mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Robertson</surname>, <given-names>C. E.</given-names></string-name>, &amp; <string-name><surname>Baron-Cohen</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Sensory perception in autism</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>18</volume>(<issue>11</issue>), <fpage>671</fpage>–<lpage>684</lpage>. <pub-id pub-id-type="doi">10.1038/nrn.2017.112</pub-id></mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Roy</surname>, <given-names>N. A.</given-names></string-name>, <string-name><surname>Bak</surname>, <given-names>J. H.</given-names></string-name>, <string-name><surname>Akrami</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Brody</surname>, <given-names>C. D.</given-names></string-name>, &amp; <string-name><surname>Pillow</surname>, <given-names>J. W</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Extracting the dynamics of behavior in sensory decision-making experiments</article-title>. <source>Neuron</source>, <volume>109</volume>(<issue>4</issue>), <fpage>597</fpage>–<lpage>610.e6.</lpage> <pub-id pub-id-type="doi">10.1016/j.neuron.2020.12.004</pub-id></mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schmack</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Bosc</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Ott</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Sturgill</surname>, <given-names>J. F.</given-names></string-name>, &amp; <string-name><surname>Kepecs</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Striatal dopamine mediates hallucination-like perception in mice</article-title>. <source>Science (New York, N.Y.)</source>, <volume>372</volume>(<issue>6537</issue>), <fpage>eabf4740</fpage>. <pub-id pub-id-type="doi">10.1126/science.abf4740</pub-id></mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Scott</surname>, <given-names>B. B.</given-names></string-name>, <string-name><surname>Constantinople</surname>, <given-names>C. M.</given-names></string-name>, <string-name><surname>Erlich</surname>, <given-names>J. C.</given-names></string-name>, <string-name><surname>Tank</surname>, <given-names>D. W.</given-names></string-name>, &amp; <string-name><surname>Brody</surname>, <given-names>C. D</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Sources of noise during accumulation of evidence in unrestrained and voluntarily head-restrained rats</article-title>. <source>eLife</source>, <volume>4</volume>, <elocation-id>e11308</elocation-id>. <pub-id pub-id-type="doi">10.7554/eLife.11308</pub-id></mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shadlen</surname>, <given-names>M. N.</given-names></string-name>, &amp; <string-name><surname>Kiani</surname>, <given-names>R</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Decision making as a window on cognition</article-title>. <source>Neuron</source>, <volume>80</volume>(<issue>3</issue>), <fpage>791</fpage>–<lpage>806</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2013.10.047</pub-id></mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shevinsky</surname>, <given-names>C. A.</given-names></string-name>, &amp; <string-name><surname>Reinagel</surname>, <given-names>P</given-names></string-name></person-group>. (<year>2019</year>). <article-title>The Interaction Between Elapsed Time and Decision Accuracy Differs Between Humans and Rats</article-title>. <source>Frontiers in Neuroscience</source>, <volume>13</volume>, <fpage>1211</fpage>. <pub-id pub-id-type="doi">10.3389/fnins.2019.01211</pub-id></mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Simen</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Contreras</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Buck</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Hu</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Holmes</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Cohen</surname>, <given-names>J. D</given-names></string-name></person-group>. (<year>2009</year>). <article-title>Reward rate optimization in two-alternative decision making: Empirical tests of theoretical predictions</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source>, <volume>35</volume>(<issue>6</issue>), <fpage>1865</fpage>– <lpage>1897</lpage>. <pub-id pub-id-type="doi">10.1037/a0016926</pub-id></mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Thura</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Beauregard-Racine</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Fradet</surname>, <given-names>C.-W.</given-names></string-name>, &amp; <string-name><surname>Cisek</surname>, <given-names>P</given-names></string-name></person-group>. (<year>2012</year>). <article-title>Decision making by urgency gating: Theory and experimental support</article-title>. <source>Journal of Neurophysiology</source>, <volume>108</volume>(<issue>11</issue>), <fpage>2912</fpage>–<lpage>2930</lpage>. <pub-id pub-id-type="doi">10.1152/jn.01071.2011</pub-id></mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vallat</surname>, <given-names>R</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Pingouin: Statistics in Python</article-title>. <source>Journal of Open Source Software</source>, <volume>3</volume>(<issue>31</issue>), <fpage>1026</fpage>. <pub-id pub-id-type="doi">10.21105/joss.01026</pub-id></mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>van den Boogert</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Klein</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Spaan</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Sizoo</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Bouman</surname>, <given-names>Y. H. A.</given-names></string-name>, <string-name><surname>Hoogendijk</surname>, <given-names>W. J. G.</given-names></string-name>, &amp; <string-name><surname>Roza</surname>, <given-names>S. J.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Sensory processing difficulties in psychiatric disorders: A meta-analysis</article-title>. <source>Journal of Psychiatric Research</source>, <volume>151</volume>, <fpage>173</fpage>–<lpage>180</lpage>. <pub-id pub-id-type="doi">10.1016/j.jpsychires.2022.04.020</pub-id></mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Voskuilen</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Ratcliff</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Smith</surname>, <given-names>P. L</given-names></string-name></person-group>. (<year>2016</year>). <article-title>Comparing fixed and collapsing boundary versions of the diffusion model</article-title>. <source>Journal of Mathematical Psychology</source>, <volume>73</volume>, <fpage>59</fpage>–<lpage>79</lpage>. <pub-id pub-id-type="doi">10.1016/j.jmp.2016.04.008</pub-id></mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wood</surname>, <given-names>S. N.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Shaddick</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Augustin</surname>, <given-names>N. H</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Generalized Additive Models for Gigadata: Modeling the U</article-title>.<source>K. Black Smoke Network Daily Data. Journal of the American Statistical Association</source>, <volume>112</volume>(<issue>519</issue>), <fpage>1199</fpage>–<lpage>1210</lpage>. <pub-id pub-id-type="doi">10.1080/01621459.2016.1195744</pub-id></mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Young</surname>, <given-names>J. W</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Development of cross-species translational paradigms for psychiatric research in the Research Domain Criteria era</article-title>. <source>Neuroscience and Biobehavioral Reviews</source>, <volume>148</volume>, <fpage>105119</fpage>. <pub-id pub-id-type="doi">10.1016/j.neubiorev.2023.105119</pub-id></mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.105116.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Donner</surname>
<given-names>Tobias H</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University Medical Center Hamburg-Eppendorf</institution>
</institution-wrap>
<city>Hamburg</city>
<country>Germany</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
</front-stub>
<body>
<p>This translational study presents a direct cross-species comparison (between mice, rats, and humans) of choice behavior in the same perceptual decision-making task. The study is rare in opening a window on the evolution of decision-making, and the results will be <bold>important</bold> for many disciplines including behavioral sciences, psychology, neuroscience, and psychiatry. While the strength of the evidence presented is <bold>solid</bold>, the manuscript would benefit from additional information and analyses to strengthen and clarify its main conclusions.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.105116.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This work presents data from three species (mice, rats, and humans) performing an evidence accumulation task, that has been designed to be as similar as possible between species (and is based on a solid foundation of previous work on decision-making). The tasks are well-designed, and the analyses are solid and clearly presented - showing that there are differences in the overall parameters of the decision-making process between the species. This is valuable to neuroscientists who aim to translate behavioral and neuroscientific findings from rodents to humans and offers a word of caution for the field in readily claiming that behavioral strategies and computations are representative of all mammals. The dataset would be of great interest to the community and may be a source of further modelling of across-species behavior, but unfortunately, neither data or code are currently shared.</p>
<p>A few other questions remain, that make the conclusions of the paper a bit hard to assess:</p>
<p>(1) The main weakness is that the authors claim that all species rely on evidence accumulation as a strategy, but this is not tested against other models (see e.g. Stine et al. <ext-link ext-link-type="uri" xlink:href="https://elifesciences.org/articles/55365">https://elifesciences.org/articles/55365</ext-link>): the fact that the DDM fits rather well does not mean that this is the strategy that each species was carrying out.</p>
<p>(2) In all main analyses, it is unclear what the effect is of the generative flash rate and how this has been calibrated between species. Only in Figure 6C do we see basic psychometric functions, but these should presumably also feature as a crucial variable dominating the accuracy and RTs (chronometric functions) across species. The very easy trials are useful to constrain the basic sensorimotor differences that may account for RT variability, e.g. perhaps the small body of mice requires them to move a relatively longer distance to trigger the response.</p>
<p>(3) The GLM-HMM results (that mice are not engaged in all trials) are very important, but they imply that mouse DDM fits may well be more similar to rats and humans if done only on engaged trials. Could it be that the main species differences are driven by different engagement state occupations?</p>
<p>(4) It would be very helpful if the authors could present a comprehensive overview (perhaps a table) of the factors that may be relevant for explaining the observed species differences. This may include contextual/experimental variables (age range (adolescent humans vs. mice/rats, see <ext-link ext-link-type="uri" xlink:href="https://www.jax.org/news-and-insights/jax-blog/2017/november/when-are-mice-considered-old">https://www.jax.org/news-and-insights/jax-blog/2017/november/when-are-mice-considered-old</ext-link>; reward source, etc) and also outcomes (e.g. training time required to learn the task, # trials per session and in total).</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.105116.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Chakravarty et al. propose a 'synchronized framework' for studying perceptual decision-making (DM) across species -namely humans, rats, and mice. Although all species shared hallmarks of evidence accumulation, the results highlighted species-specific differences. Humans were the slowest and most accurate, rats optimized the speed-accuracy tradeoff to maximize the reward rate and mice were the fastest but least accurate. In addition, while humans were better fit by a classic DDM with fixed bounds, rodents were better fit by a DDM with collapsing bounds. While comparing behavioral strategies in evidence accumulation tasks across species is an important and timely question, some of the presented differences across species lack a clear interpretation and could be simply caused by differences in the task design. There is important information and analyses missing about the DDM and the other models used, which lowers the confidence and enthusiasm about the results.</p>
<p>Strengths:</p>
<p>The comparison of behavior across species, including humans and commonly used laboratory species like rats and mice, is a fundamental step in neuroscience to establish more informed links between animal experiments and human cognition. In this work, Chakravarty et al. analyze and model the behavior of three species during the same evidence accumulation task. They draw conclusions about the different strategies used in each case.</p>
<p>Weaknesses:</p>
<p>Novelty:</p>
<p>
While quite relevant, some parts of the work presented are more novel than others. That EA drives choice behavior and these choices can be described with a DDM have been shown before (see e.g. (Kane et al. 2023; Brunton et al. in 2013; Pinto et al 2018)). The novelty here mostly lies in the comparison of three species in the same task and in fitting the same exact model (close quantitative comparison of behavioral strategies). However, some of the differences lack a clear interpretation. For instance, the values of some of the DDM fitted parameters between the three species are not ordered &quot;as expected&quot; (e.g. non-decision time or DDM BIC). Other comparison results completely lack an explanation (e.g. rats' RT are near optimal while humans and mice are not). The aspect that I found most novel and exciting is the application of HMMs to each of the species. However, this part comes at the end of the paper and has been done without sufficient depth. There is almost no explanation for the results. I would suggest the authors bring up this part and move back to other aspects which are, in my opinion, less novel or interpretable (e.g. results around the optimality of RT).</p>
<p>Task design:</p>
<p>
Since there is no fixation, the response time (RT) reflects both the evidence integration time plus the motor time (stimuli are played until a response is given). This design makes it hard to compare RTs between species. While humans just had to press a button, rodents had to move their whole bodies from a central port to a side port. When comparing rats and mice, their difference in size relative to port distance could explain different RTs. This could for example explain the large difference in non-decision time (ndt) in Figure 3F between mice and rats. Are the measurements of the rat and the mouse boxes comparable? The authors should explain this difference more openly and discuss its implications when interpreting the results. The Methods should also provide information about the distance between ports for each species. I also strongly recommend including a few videos of rats and mice performing the task to have a sense of the movements involved in the task in each species.</p>
<p>(1) DDM</p>
<p>Goodness of fit:</p>
<p>
The authors conclude that the three species use an accumulation of evidence strategy because they can fit a DDM. However, there is little information about the goodness of these fits. They only show the RT distributions for one example subject (too small to distinguish whether the fit of the histograms is good or not). We suggest they make a figure showing in more detail the match of the RT distributions across subjects (e.g. they can compare RT quartiles for data and model for the entire group of subjects). Then they provide BIC which is a measure that depends on the number of trials. Were the number of trials matched across subjects/species? Could the authors provide a measure independent of the number of trials (e.g. cross-validated log-likelihood per trial)? Moreover, is this BIC computed only on the RTs, mouse responses, or both?</p>
<p>Overparameterization:</p>
<p>
The authors chose to include as DDM parameters the variability of the initial offset, the variability in non-decision time, and the variability of the drift rate. Having so many parameters with just one stimulus condition (80:20 ratio of flashes) may lead to unidentifiability problems as recognized previously (e.g. see M. Jones (2021) here osf.io/preprints/psyarxiv/gja3u). Their parameter recovery Supplementary Figure 3 shows that at least two of these variability parameters can not be recovered. I also couldn't find the values of these parameters for the fitted DDM. So I was wondering the extent to which adding these parameters improves the fits and is overall necessary.</p>
<p>Tachometric curves:</p>
<p>
The authors show increasing tachometric curves (i.e. Accuracy vs RT) and use this finding as proof of accumulation. They fit these curves using a GAAM with little justification or detail (in fact the GAAM seems to over-fit the data a bit). The authors do not say, however, that the other model used, i.e. the DDM, may not reproduce these increasing tachometric curves because &quot;in its basic form&quot;, the DDM gives flat tachometric curves. Does the DDM fitted to the individual RT and choice data capture the monotonic increase observed in the tachometric curves?</p>
<p>Correct vs Error trials:</p>
<p>
In a similar line, the authors do not test the fitted DDM separately in correct vs error trials, which is a classical distinction that most DDMs can't capture. It would be good to know if: (1) the RT in the data of correct vs error responses are similar (quantified in panel Figure 2B because in 2E it is not clear) and (2) the same trend between correct and error RTs are observed in the fitted DDMs.</p>
<p>Urgency model:</p>
<p>
It is not clear how the urgency model used works. The authors cite Ditterich (2006), but in that paper, the urgency signal was applied to a race model with two decision variables: the urgency signal &quot;accelerated&quot; both DVs equally and sped up the race without favoring one DV versus the other. In a one-dimensional DDM, it is not clear where the urgency is applied. We assume it is applied in the direction of the stimulus, but then it is unclear how the urgency knows about the stimulus, which is what the DDM is trying to estimate in the first place. The authors should explain this model in greater detail and try to resolve this question.</p>
<p>Despite finding differences between species, the analyses seem mostly exploratory instead of hypothesis-driven. There is little justification for why differences in some DDM parameters across species would be expected.</p>
<p>(2) GLM and HMM</p>
<p>The GLM fits show nicely that humans, rats, and mice weigh differently the total provided evidence (Figures 6C-D). This may be because the internal noise in the accumulation of evidence is higher but also it could simply be because animals do not weigh the evidence that is presented when they are already moving towards the side ports. A parsimonious alternative to the &quot;more noisy&quot; species is simply that they only consider the first part of the stimulus. Extending the GLM to capture the differential weighting of each sequential sample (what is called the Psychophysical kernel, PK) should be straightforward and would provide a more fair comparison between species (i.e. perhaps the slope of the psychometric curves is not that different, once evidence is weighted in each species with its corresponding PK.</p>
<p>Choice Bias:</p>
<p>
Panel 3G (DDM starting point) shows that both rats and mice are slightly but systematically biased to the Left (x0 &lt; 0.5). Panel 6D &quot;Bias&quot; seems to be showing the absolute value of the GLM bias parameter. It would be nice to (i) show the signed GLM bias parameter. (ii) Compare that the biases computed in the DDM and GLM are comparable across species and subjects; it looks like from the GLM they are comparable in magnitude across species whereas the in DDM they weren't (mice had a much bigger |x0| in the DDM), (iii) explain (or at least comment) on why animals show a systematic bias to one side.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.105116.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This study directly compares decision-making strategies between three species, humans, rats, and mice. Based on a new and common behavioral task that is largely shared across species, specific features of evidence accumulation could be quantified and compared between species. The authors argue their work provides a framework to study decision-making across species, which can be studied by the same decision models. The authors report specific features of decision-making strategies, such as humans having a larger decision threshold leading to more accurate responses, and rodents deciding under time pressure.</p>
<p>Strengths:</p>
<p>The behavioral task is set up in similar, comparable ways across species, allowing for employing the same decision models and directly comparing specific features of decision behavior. This approach is compelling since it is otherwise challenging to compare behavior between species. Data analysis is solid and does not only quantify features of classic drift-diffusion models, but also additional commonly applied behavior models or features such as win-stay/lose-shift strategies, reward-maximization behavior, and slow, latent changes in behavior strategies. This approach reveals some interesting species differences, which are a starting point to investigate species-specific decision strategies more deeply and could inform a broad set of past and future behavior studies commonly used in cognitive and neuroscience.</p>
<p>Weaknesses:</p>
<p>(1) The choice of the stimulus difficulty is unclear, as choosing a single, specific evidence strength (80:20) could limit model fitting performance and interpretation of psychometric curves. This could also limit conclusions about species differences since the perceptual sensitivity seems quite different between species. Thus, the 80:20 lies at different uncertainty levels for the different species, which are known to influence behavioral strategies. This might be addressed by exploiting the distribution of actually delivered flashes, but it remained unclear to me to what degree this is the case. Previous perceptual discrimination studies typically sample multiple evidence levels to differentiate the source of variability in choice behavior.</p>
<p>(2) The authors argue that their task is novel and that their task provides a framework to investigate perceptual decision-making. However, very similar, and potentially more powerful, perceptual decision-making tasks (e.g., using several evidence strength levels) have been used in humans, non-human primates, rats, mice, and other species. In some instances, analogous behavioral tasks, including studies using the same sensory stimulus, have been used across multiple species. While these may have been published in different papers, they have been conducted in some instances by the same lab and using the same analyses. Further, much of this work is not referenced here. This limits the impact of this work.</p>
<p>(3) The employed drift-diffusion model has many parameters, which are not discussed in detail. Results in Supplementary Figures 3-5 are not explained or discussed, including the interpretation that model recovery tests fail to recover some of the parameters (eg, Figures S3E, G). This makes the interpretation of such models more difficult.</p>
<p>(4) The results regarding potential reward-maximization strategies are compelling and connect perceptual and normative decision models. The results are however limited by the different inter-trial intervals and trial initiation times between species, which are shown in Figure S6. It's unclear to me how to interpret, for example, how the long trial initiation times in rats relate to a putative reward-maximizing strategy. This compares to the very low trial initiation times (ie, very 'efficient') of humans, even though they are 'too accurate' in terms of their sampling time. Reward-maximizing strategies seem difficult with such different trial times and in the absence of experimental manipulation.</p>
</body>
</sub-article>
</article>