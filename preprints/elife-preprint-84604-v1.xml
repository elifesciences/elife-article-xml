<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">84604</article-id>
<article-id pub-id-type="doi">10.7554/eLife.84604</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.84604.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>A stable, distributed code for cue value in mouse cortex during reward learning</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4882-1898</contrib-id>
<name>
<surname>Ottenheimer</surname>
<given-names>David J.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="author-notes" rid="n1">5</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9932-2349</contrib-id>
<name>
<surname>Hjort</surname>
<given-names>Madelyn M.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n1">5</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8911-2572</contrib-id>
<name>
<surname>Bowen</surname>
<given-names>Anna J.</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="author-notes" rid="n1">5</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7029-2908</contrib-id>
<name>
<surname>Steinmetz</surname>
<given-names>Nicholas A.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="corresp" rid="cor1">6</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1730-4855</contrib-id>
<name>
<surname>Stuber</surname>
<given-names>Garret D.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="corresp" rid="cor1">6</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Center for the Neurobiology of Addiction, Pain, and Emotion, University of Washington</institution>, Seattle</aff>
<aff id="a2"><label>2</label><institution>Anesthesiology and Pain Medicine, University of Washington</institution>, Seattle</aff>
<aff id="a3"><label>3</label><institution>Biological Structure, University of Washington</institution>, Seattle</aff>
<aff id="a4"><label>4</label><institution>Pharmacology, University of Washington</institution>, Seattle</aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Eisen</surname>
<given-names>Michael B</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of California, Berkeley</institution>
</institution-wrap>
<city>Berkeley</city>
<country>United States of America</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Eisen</surname>
<given-names>Michael B</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of California, Berkeley</institution>
</institution-wrap>
<city>Berkeley</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="equal"><label>5</label><p>These authors contributed equally</p></fn>
<corresp id="cor1"><label>6</label>Corresponding authors: <email>nick.steinmetz@gmail.com</email>, <email>gstuber@uw.edu</email></corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2023-02-24">
<day>24</day>
<month>02</month>
<year>2023</year>
</pub-date>
<volume>12</volume>
<elocation-id>RP84604</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2022-11-18">
<day>18</day>
<month>11</month>
<year>2022</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2022-11-10">
<day>10</day>
<month>11</month>
<year>2022</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.07.13.499930"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2023, Ottenheimer et al</copyright-statement>
<copyright-year>2023</copyright-year>
<copyright-holder>Ottenheimer et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-84604-v1.pdf"/>
<abstract>
<title>Summary</title>
<p>The ability to associate reward-predicting stimuli with adaptive behavior is frequently attributed to the prefrontal cortex, but the stimulus-specificity, spatial distribution, and stability of pre-frontal cue-reward associations are unresolved. We trained headfixed mice on an olfactory Pavlovian conditioning task and measured the coding properties of individual neurons across space (prefrontal, olfactory, and motor cortices) and time (multiple days). Neurons encoding cues or licks were most common in olfactory and motor cortex, respectively. By quantifying the responses of cue-encoding neurons to six cues with varying probabilities of reward, we unexpectedly found value coding, including coding of trial-by-trial reward history, in all regions we sampled. We further found that prefrontal cue and lick codes were preserved across days. Our results demonstrate that individual prefrontal neurons stably encode components of cue-reward learning within a larger spatial gradient of coding properties.</p>
</abstract>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Clarification of motivation for and interpretation of experiments. Expanded comparison of electrophysiology and imaging. Expanded analysis of value coding.</p></fn>
</fn-group>
<fn-group content-type="external-links">
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.6686927">https://doi.org/10.5281/zenodo.6686927</ext-link>
</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Association of environmental stimuli with rewards and the subsequent orchestration of value-guided reward-seeking behavior are crucial functions of the nervous system linked to the pre-frontal cortex (PFC) (<xref ref-type="bibr" rid="c34">Klein-Flügge et al., 2022</xref>; <xref ref-type="bibr" rid="c44">Miller and Cohen, 2001</xref>). PFC is heterogeneous, with many studies noting subregional differences in both neural coding of (<xref ref-type="bibr" rid="c25">Hunt et al., 2018</xref>; <xref ref-type="bibr" rid="c31">Kennerley et al., 2009</xref>; <xref ref-type="bibr" rid="c70">Sul et al., 2010</xref>; <xref ref-type="bibr" rid="c74">Wang et al., 2020a</xref>) and functional impact on (<xref ref-type="bibr" rid="c5">Buckley et al., 2009</xref>; <xref ref-type="bibr" rid="c10">Dalley et al., 2004</xref>; <xref ref-type="bibr" rid="c32">Kesner and Churchwell, 2011</xref>; <xref ref-type="bibr" rid="c56">Rudebeck et al., 2008</xref>) value-based reward seeking in primates and rodents. Further, functional manipulations of PFC subregions exhibiting robust value signals do not always cause a discernible impact on reward-guided behavior (<xref ref-type="bibr" rid="c8">Chudasama and Robbins, 2003</xref>; <xref ref-type="bibr" rid="c11">Dalton et al., 2016</xref>; <xref ref-type="bibr" rid="c62">St. Onge and Floresco, 2010</xref>; <xref ref-type="bibr" rid="c73">Verharen et al., 2020</xref>; <xref ref-type="bibr" rid="c74">Wang et al., 2020a</xref>), encouraging investigation of differences between value signals across PFC. Within individual PFC subregions, multiple studies have observed evolving neural representations across time, calling into question the stability PFC signaling (<xref ref-type="bibr" rid="c26">Hyman et al., 2012</xref>; <xref ref-type="bibr" rid="c43">Malagon-Vina et al., 2018</xref>). A systematic comparison of coding properties across rodent PFC and related motor and sensory regions, as well as across days and stimulus sets, is necessary to provide a full context for the contributions of PFC subregions to reward processing.</p>
<p>Identifying neural signals for value requires a number of considerations. One issue is that other task features can vary either meaningfully or spuriously with value. In particular, action coding is difficult to parse from value signaling, given the high correlations between behavior and task events (<xref ref-type="bibr" rid="c46">Musall et al., 2019</xref>; <xref ref-type="bibr" rid="c77">Zagha et al., 2022</xref>) and widespread neural coding of reward-seeking actions (<xref ref-type="bibr" rid="c67">Steinmetz et al., 2019</xref>). Additionally, without a sufficiently rich value axis, it is possible to misidentify neurons as ‘value’ coding even though they do not generalize to valuations in other contexts (<xref ref-type="bibr" rid="c22">Hayden and Niv, 2021</xref>; <xref ref-type="bibr" rid="c64">Stalnaker et al., 2015</xref>; <xref ref-type="bibr" rid="c78">Zhou et al., 2021</xref>). Because reports of value have come from different experiments across different species, it is difficult to compare the presence of value signaling even across regions within prefrontal cortex (<xref ref-type="bibr" rid="c22">Hayden and Niv, 2021</xref>; <xref ref-type="bibr" rid="c25">Hunt et al., 2018</xref>; <xref ref-type="bibr" rid="c31">Kennerley et al., 2009</xref>; <xref ref-type="bibr" rid="c48">Namboodiri et al., 2019</xref>; <xref ref-type="bibr" rid="c49">Otis et al., 2017</xref>; <xref ref-type="bibr" rid="c64">Stalnaker et al., 2015</xref>; <xref ref-type="bibr" rid="c70">Sul et al., 2010</xref>; <xref ref-type="bibr" rid="c74">Wang et al., 2020a</xref>; <xref ref-type="bibr" rid="c78">Zhou et al., 2021</xref>).</p>
<p>In this work, we sought to address the existing ambiguity in the distribution and stability of value signaling. We implemented an olfactory Pavlovian conditioning task that permitted identification of value correlates within the domain of reward probability across two separate stimulus sets. With acute in vivo electrophysiology recordings, we were able to assess coding of this task across 11 brain regions, including five PFC subregions, as well as olfactory and motor cortex, in a single group of mice, permitting a well-controlled comparison of coding patterns across a large group of task-relevant regions in the same subjects. Unexpectedly, in contrast to the graded cue and lick coding across these regions, there was a similar proportion of neurons encoding cue value in all regions. A subset of value coding neurons were sensitive to trial-by-trial fluctuations in value according to reward history. To assess coding stability, we performed 2-photon imaging of neurons in PFC for multiple days and determined that the cue and lick codes we identified were stable over time. Our data demonstrate universality and stability of cue-reward coding in mouse cortex.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Distributed neural activity during an olfactory Pavlovian conditioning task</title>
<p>We trained mice on an olfactory Pavlovian conditioning task with three cue (conditioned stimulus) types that predicted reward on 100% (‘CS+’), 50% (‘CS50’), or 0% (‘CS−’) of trials (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>). Each mouse learned two odor sets, trained and imaged on separate days and then, for electrophysiology experiments, presented in six alternating blocks of 51 trials during recording sessions (<xref rid="fig1" ref-type="fig">Fig. 1B</xref>). Mice developed anticipatory licking (<xref rid="fig1" ref-type="fig">Fig. 1C-D</xref>), and the rate of this licking correlated with reward probability (<xref rid="figS1" ref-type="fig">Fig. S1</xref>), indicating that subjects successfully learned the meaning of all six odors.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Electrophysiology and imaging during olfactory Pavlovian conditioning.</title>
<p>(A) Trial structure in Pavlovian conditioning task.</p><p>(B) Timeline for mouse training.</p>
<p>(C) Mean (+/− standard error of the mean (SEM)) lick rate across mice (<italic>n</italic> = 5) on each trial type for each odor set during electrophysiology sessions. CS50(r) and CS50(u) are rewarded and unrewarded trials, respectively. Inset: mean anticipatory licks (change from baseline) for the CS+ and CS50 cues for every session, color-coded by mouse. <italic>F</italic> (1, 66) = 36.6 for a main effect of cue in a two-way ANOVA including an effect of subject.</p>
<p>(D) Same as (C), for Day 3 imaging sessions (<italic>n</italic> = 5 mice). <italic>t</italic>(4) = −5.4 for a t-test comparing anticipatory licks on CS+ and CS50 trials.</p>
<p>(E) Neuropixels probe tracks labeled with fluorescent dye (red) in cleared brain (autofluorescence, green). AP, anterior/posterior; ML, medial/lateral; DV, dorsal/ventral. Allen CCF regions delineated in gray. Outline of prelimbic area in purple.</p>
<p>(F) Reconstructed recording sites from all tracked probe insertions (<italic>n</italic> = 44 insertions, <italic>n</italic> = 5 mice), colored by mouse.</p>
<p>(G) Sample histology image of lens placement. Visualization includes DAPI (blue) and GCaMP (green) signal with lines indicating cortical regions from Allen Mouse Brain Common Coordinate Framework.</p>
<p>(H) Location of all lenses from experimental animals registered to Allen Mouse Brain Common Coordinate Framework. Blue line indicates location of lens in (A). The dotted black line represents approximate location of tissue that was too damaged to reconstruct an accurate lens track. The white dotted line indicates PL borders.</p>
<p>(I) ML and DV coordinates of all neurons recorded in one example session, colored by region, and spike raster from example PL neurons.</p>
<p>(J) ROI masks for identified neurons and fluorescence traces from 5 example neurons.</p></caption>
<graphic xlink:href="499930v2_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Using Neuropixels 1.0 and 2.0 probes (<xref ref-type="bibr" rid="c30">Jun et al., 2017</xref>; <xref ref-type="bibr" rid="c65">Steinmetz et al., 2021</xref>), we recorded the activity of individual neurons in <bold>PFC</bold>, including anterior cingulate area (ACA), frontal pole (FRP), prelimbic area (PL), infralimbic area (ILA), and orbital area (ORB) (<xref ref-type="bibr" rid="c38">Laubach et al., 2018</xref>; <xref ref-type="bibr" rid="c75">Wang et al., 2020b</xref>). We also recorded from: secondary <bold>motor cortex</bold> (MOs), including anterolateral motor cotex (ALM), which has a well-characterized role in licking (<xref ref-type="bibr" rid="c6">Chen et al., 2017</xref>); <bold>olfactory cortex</bold> (OLF), including dorsal peduncular area (DP), dorsal taenia tecta (TTd), and anterior olfactory nucleus (AON), which receive input from the olfactory bulb (<xref ref-type="bibr" rid="c27">Igarashi et al., 2012</xref>; <xref ref-type="bibr" rid="c45">Mori and Sakano, 2021</xref>); and <bold>striatum</bold>, including caudoputamen (CP) and nucleus accumbens (ACB) (<xref rid="fig1" ref-type="fig">Fig. 1E-F</xref>), which are major outputs of PFC (<xref ref-type="bibr" rid="c23">Heilbronner et al., 2016</xref>). In a separate group of mice, we performed longitudinal 2-photon imaging through a GRIN lens to track the activity of individual neurons in PL across several days of behavioral training (<xref rid="fig1" ref-type="fig">Fig. 1G-H</xref>). Both techniques permitted robust measurement of the activity of neurons of interest and generated complementary results (<xref rid="fig1" ref-type="fig">Figs. 1I-J</xref>, <xref rid="figS2" ref-type="fig">S2</xref>).</p>
</sec>
<sec id="s2b">
<title>Graded cue and lick coding across the recorded regions</title>
<p>In the electrophysiology experiment, we isolated the spiking activity of 5332 individual neurons in regions of interest across 5 mice (449-1550 neurons per mouse, <xref rid="fig2" ref-type="fig">Figs. 2A</xref>, <xref ref-type="fig" rid="figS3">S3A</xref>). The activity of neurons in all regions exhibited varying degrees of modulation in response to the six trial types (<xref rid="fig2" ref-type="fig">Fig. 2B</xref>). Broadly, there was strong modulation on CS+ and CS50 trials that appeared to be common to both odor sets (<xref ref-type="fig" rid="figS3">Fig. S3B</xref>). Across regions, there was heterogeneity in both the magnitude and the timing of the neural modulation relative to odor onset (<xref ref-type="fig" rid="figS3">Fig. S3C</xref>).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Graded cue and lick coding across the recorded regions.</title>
<p>(A) Location of each recorded neuron relative to bregma, projected onto 1 hemisphere. Each neuron is colored by CCF region. Numbers indicate total neurons passing quality control from each region.</p>
<p>(B) Mean normalized activity of all neurons from each region, aligned to odor onset, grouped by whether peak cue activity (0 - 2.5 s) was above (top) or below (bottom) baseline in held out trials. Number of neurons noted for each plot.</p>
<p>(C) Example kernel regression prediction of an individual neuron’s normalized activity on an example trial.</p>
<p>(D) CS+ trial activity from an example neuron and predictions with full model and with cues, licks, and reward removed. Numbers in parentheses are model performance (fraction of variance explained).</p>
<p>(E) Coordinates relative to bregma of every neuron encoding only cues or only licks, projected onto one hemisphere.</p>
<p>(F) Fraction of neurons in each region and region group classified as coding cues, licks, reward, or all combinations of the three.</p>
<p>(G) Additional cue (left) or lick (right) neurons in region on Y-axis compared to region on X-axis as a fraction of all neurons, for regions with non-overlapping 95% confidence intervals (see Methods).</p></caption>
<graphic xlink:href="499930v2_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>To quantify the relative contribution of cues and conditioned responding (licking) to the activity of neurons in each region, we implemented reduced rank kernel regression (<xref ref-type="bibr" rid="c67">Steinmetz et al., 2019</xref>), using cues, licks, and rewards to predict neurons’ activity on held out trials (<xref rid="fig2" ref-type="fig">Figs. 2C</xref>, <xref ref-type="fig" rid="figS4">S4A</xref>). To determine the contribution of cues, licks, and rewards to each neuron’s activity, we calculated unique variance explained by individually removing each predictor from the model and calculating the reduction in model performance (<xref rid="fig2" ref-type="fig">Fig. 2D</xref>).</p>
<p>We identified individual neurons encoding cues, licks, or rewards as those for which that predictor uniquely contributed to 2% or more of their variance (a cutoff with an estimated false positive rate of 0.02%, see Methods). Neurons encoding cues (24% of all neurons), licks (11%), or both (16%) were most common. Neurons with any response to reward (independent of licking) were rare (5%) (<xref ref-type="bibr" rid="c24">Horst and Laubach, 2013</xref>). Cue neurons were characterized by sharp responses aligned to odor onset; in contrast, lick neurons’ responses were delayed and peaked around reward delivery (<xref ref-type="fig" rid="figS4">Fig. S4B-C</xref>), consistent with the timing of licks (<xref rid="fig1" ref-type="fig">Fig. 1C</xref>). The activity of cue neurons on rewarded and unrewarded CS50 trials validated our successful isolation of neurons with cue but not lick responses (<xref ref-type="fig" rid="figS4">Fig. S4D</xref>). The spatial distributions of cue and lick cells were noticeably different (<xref rid="fig2" ref-type="fig">Fig. 2E</xref>). The differences could be described as graded across regions, with the most lick neurons in ALM, and the most cue neurons in olfactory cortex and ORB, though each type of neuron was observed in every region (<xref rid="fig2" ref-type="fig">Fig. 2F-G</xref>, <xref rid="figS5" ref-type="fig">S5</xref>). Thus, our quantification of task encoding revealed varying prioritization of cue and lick signaling across all regions.</p>
</sec>
<sec id="s2c">
<title>Cue value coding is present in all regions</title>
<p>To expand upon our analysis identifying cue-responsive neurons, we next assessed the presence of cue value coding in this population. The three cue types (CS+, CS50, or CS−) in our behavioral task varied in relative value according to the predicted probability of reward (<xref ref-type="bibr" rid="c17">Eshel et al., 2016</xref>; <xref ref-type="bibr" rid="c18">Fiorillo et al., 2003</xref>; <xref ref-type="bibr" rid="c76">Winkelmeier et al., 2022</xref>). We reasoned that a neuron encoding cue value should have activity that scaled with the relative value of the cues (<xref rid="fig3" ref-type="fig">Fig. 3A</xref>). We modeled this relationship on a per-neuron basis by scaling a single cue kernel by the typical number of anticipatory licks for each cue (see Methods, <xref rid="fig3" ref-type="fig">Fig. 3B</xref>). This model describes cue activity as similar across odors of the same value, and scaling in magnitude according to each odor’s value. As a shuffle control, we also fit each neuron with 89 additional models containing all possible permutations of reassigning the original values across the six odors, as well as an ‘untuned’ model with the same value for all odors (<xref rid="figS6" ref-type="fig">Fig. S6</xref>). After removing neurons best fit by the untuned model, the remaining 90 models would be equally likely to fit each neuron best if cue responses were independent of cue association, as would be expected with a sensory olfactory code (<xref ref-type="bibr" rid="c52">Pashkovski et al., 2020</xref>; <xref ref-type="bibr" rid="c68">Stettler and Axel, 2009</xref>). We found, however, that the original model with cue responses that scale directly with value (CS+ <italic>&gt;</italic> CS50 <italic>&gt;</italic> CS−) was the best model for a large fraction of cue neurons (30%), far exceeding chance (1%) (<xref rid="fig3" ref-type="fig">Fig. 3C</xref>). We refer to these neurons as <bold>value</bold> cells (<xref ref-type="fig" rid="figS7">Fig. S7A</xref>). Interestingly, five additional models stood out as the best model for sizable fractions of cue neurons. These models corresponded to the five alternative rankings of cue types (for example, CS50 <italic>&gt;</italic> CS− <italic>&gt;</italic> CS+ rather than CS+ <italic>&gt;</italic> CS50 <italic>&gt;</italic> CS−) irrespective of odor set (<xref rid="fig3" ref-type="fig">Fig. 3D</xref>) and accounted for 22% of cue neurons. This population of cells, which we refer to as <bold>trial type</bold> cells (<xref ref-type="fig" rid="figS7">Fig. S7B</xref>), encoded each cue’s reward probability independent of its particular odor, but with firing rates not proportional to value. The difference between value and trial type cells, therefore, is that value cells have both CS− activity closer to baseline and CS+ and CS50 activity occurring along the same dimension relative to CS− activity, evident in a smaller angle between CS+ and CS50 population response vectors for value cells (<xref ref-type="fig" rid="figS7">Fig. S7C-E</xref>).</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Widespread cue value coding.</title>
<p>(A) Normalized activity of an example value cell with increasing modulation for cues of higher value.</p>
<p>(B) For the same neuron, model-fit cue kernel for the original value model and with one of the 89 alternatively-permuted value models.</p>
<p>(C) Distribution of best model fits across all cue neurons. Light blue is value model, purple is trial type models, gray is untuned model, and the remaining models are dark blue.</p>
<p>(D) First principal component of all neurons best fit by the original value model or other trial type and untuned models.</p>
<p>(E) Fraction of neurons in each region and region group classified as value cells (blue) and other cue neurons (gray), as well as fraction (+/− 95% CI) estimated from a linear mixed effects model with random effect of session (see Methods). n.s. indicates overlapping 95% CI for all three region groups.</p>
<p>(F) Additional value cells in region on Y-axis compared to region on X-axis as a fraction of all neurons, for regions with non-overlapping 95% confidence intervals. * indicates non-overlapping 95% CI for all three region groups.</p>
<p>(G) Principal component most related to value for value cells from all regions (2nd component in ACA, 1st component in all others).</p>
<p>(H) Same as (F), for region groups.</p>
<p>(I) PL population activity 0 to 2.5 s from odor onset projected onto first 3 principal components, defined on odor set 1 activity.</p>
<p>(J) Normalized distance (+/− SD) from baseline firing in odor set 1 PCA space (first 3 components) for odor set 2 trial types for value cells (top) and other cue cells (bottom) for 5000 selections of neurons (see Methods).</p></caption>
<graphic xlink:href="499930v2_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>The frequency of value cells was similar across the recorded regions (<xref rid="fig3" ref-type="fig">Fig. 3E</xref>). Indeed, despite the regional variability in number of cue cells broadly (<xref rid="fig2" ref-type="fig">Fig. 2F-G</xref>), there were no regions that statistically differed in their proportions of value cells (<xref rid="fig3" ref-type="fig">Figs. 3E</xref>, <xref ref-type="fig" rid="figS8">S8</xref>). Though there were fewest cue neurons in motor cortex, they were more likely than cue neurons in other regions to encode value, followed by PFC (<xref ref-type="fig" rid="figS9">Fig. S9</xref>). The frequency of trial type cells was more variable, peaking in DP (<xref rid="fig3" ref-type="fig">Fig. 3F</xref>) and decreasing from olfactory to PFC to motor cortex (<xref ref-type="fig" rid="figS8">Fig. S8</xref>).</p>
<p>We next investigated the robustness of the value representation in each of our recorded regions. Principal component analysis on value cells from each region revealed similarly strong value-related dynamics across motor, prefrontal, and olfactory regions (<xref rid="fig3" ref-type="fig">Fig. 3G-H</xref>). Within the population space defined by the first 3 principal components of odor set 1 activity of value cells in each region, odor set 2 activity of this population showed strong value features; specifically, population activity deflected furthest from baseline for CS+ trials, less for CS50 trials, and least for CS− trials, with similar robustness in ALM, FRP, PL, ILA, ORB, and TTd (<xref rid="fig3" ref-type="fig">Fig. 3I-J</xref>). Taken together, these data illustrate that, in contrast to cue and lick coding broadly, and in contrast to trial type cue coding, value coding is similarly represented across the regions we sampled. In fact, this observation extended to the striatal regions we sampled as well, indicating that such value coding is widespread even beyond cortex (<xref ref-type="fig" rid="figS10">Fig. S10</xref>).</p>
<p>Because cue valuations can be influenced by preceding reward outcomes, We next considered whether the cue value signaling we detected was sensitive to the history of reinforcement (<xref ref-type="bibr" rid="c47">Nakahara et al., 2004</xref>; <xref ref-type="bibr" rid="c50">Ottenheimer et al., 2020</xref>; <xref ref-type="bibr" rid="c76">Winkelmeier et al., 2022</xref>). To estimate the subjects’ trial-by-trial cue valuation, we fit a linear model predicting the number of anticipatory licks on each trial from cue type, overall reward history, and cue type-specific reward history; we used the model prediction of licks per trial as our estimate of value. We found a strong influence of cue type-specific reward history and a more modest influence of overall reward history (<xref rid="fig4" ref-type="fig">Fig. 4A</xref>). These effects of reward history on lick rate are also visible when comparing the lick rate on trials grouped by the model-estimated value (<xref rid="fig4" ref-type="fig">Fig. 4B</xref>). Thus our behavioral model revealed that subjects more highly valued trials preceded by rewards.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>A subset of value cells incorporate reward history.</title>
<p>(A) Coefficient weight (+/− standard error from model fit) for reward outcome on the previous 10 trials of any type (left) and on the previous 10 trials of the same cue type (right) for a linear model predicting the number of anticipatory licks on every trial of every session. Lick rates were normalized so that the maximum lick rate for each session was equal to 1. Colored lines are models fit to each individual mouse.</p>
<p>(B) Mean (+/− SEM) lick rate across mice (<italic>n</italic> = 5 mice) on trials binned according to value estimated from the lick model, incorporating recent reward history.</p>
<p>(C) Normalized activity of an example history value cell with increasing modulation for cues of higher value.</p>
<p>(D) For the same neuron, model-predicted activity with the original value model (left) and with trial-by-trial value estimates from the lick model (right).</p>
<p>(E) The activity of all cells in each category projected onto the coding dimension maximally separating CS− and CS+ for CS50 trials binned by value estimated from the lick model.</p>
<p>(F) The mean (+/− std across 5000 bootstrapped selections of neurons) activity (1 - 2.5 s from odor onset) along the coding dimension maximally separating CS− and CS+ for CS50 trials binned by value estimated from the lick model. * = <italic>p &lt;</italic> 10<sup>−7</sup> comparing highest and lowest value CS50 trials (other categories <italic>p &gt;</italic> 0.23).</p>
<p>(G) Fraction of neurons in each region and region group classified as history value (light blue), non-history value (blue), and other cue neurons (gray), as well as estimated fraction (+/−95% CI) with random effect of session (see Methods). * indicates non-overlapping 95% CI for PFC and olfactory regions.</p>
<p>(H) Fraction of value neurons in each region group with history effect and estimated fraction (+/− 95% CI) with random effect of session. * indicates non-overlapping 95% CI for olfactory compared to PFC and motor regions.</p></caption>
<graphic xlink:href="499930v2_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We therefore investigated whether value cells showed similar trial-by-trial differences in their firing rates (<xref rid="fig4" ref-type="fig">Fig. 4C</xref>). To test this, we compared the fit of our original value model (<xref rid="fig3" ref-type="fig">Fig. 3B</xref>) with an alternative model in which the kernel scaled with the per-trial value estimates from our lick regression (<xref rid="fig4" ref-type="fig">Fig. 4D</xref>). Overall, 30% of value cells were better fit by the history-dependent value model than by the model without history dependence. To further evaluate the history component, we calculated these neurons’ activity on CS50 trials of varying value and projected it onto the population dimension maximizing the separation between CS+ and CS−. We hypothesized that high value CS50 trials would be closer to CS+ activity while low value CS50 trials would be closer to CS− activity. Indeed, history value cells (and lick cells) demonstrated graded activity along this dimension, in contrast to non-history value cells and trial type cells (<xref rid="fig4" ref-type="fig">Fig. 4E-F</xref>). Finally, we examined the spatial distribution of history value cells and found similar, low numbers across all regions, but with higher prevalence overall in PFC than in olfactory cortex (<xref rid="fig4" ref-type="fig">Fig. 4G</xref>). Also, as a fraction of all value cells, history cells were least common in olfactory cortex (<xref rid="fig4" ref-type="fig">Fig. 4H</xref>), providing evidence for less dynamic task-centric cue signaling there.</p>
</sec>
<sec id="s2d">
<title>Cue coding emerges along with behavioral learning</title>
<p>To determine the timescales over which these coding schemes emerged and persisted, we performed longitudinal 2-photon imaging and tracked the activity of individual neurons across several days of behavioral training (<xref rid="fig5" ref-type="fig">Fig. 5A</xref>). We targeted our GRIN lenses to PL, a location with robust cue and lick coding (<xref rid="fig2" ref-type="fig">Fig. 2F</xref>) and where cue responses predominantly encode cue trial type and value (<xref rid="fig3" ref-type="fig">Fig. 3E-F</xref>). Mice (<italic>n</italic> = 8) developed anticipatory licking on day 1 that differentiated CS+ trials from CS50 (<italic>t</italic>(7) = 3.2, <italic>p</italic> = 0.015) and CS− (<italic>t</italic>(7) = 7.0, <italic>p</italic> = 0.0002) trials and CS50 trials from CS− (<italic>t</italic>(7) = 3.7, <italic>p</italic> = 0.008) trials (<xref rid="fig5" ref-type="fig">Fig. 5B-C</xref>). Visualizing the normalized activity across the imaging plane following CS+ presentation early and late on day 1 revealed a pronounced increase in modulation in this first session (<xref rid="fig5" ref-type="fig">Fig. 5D-E</xref>). Individual neurons (<italic>n</italic> = 705, 41-165 per mouse) also displayed a notable increase in modulation in response to the CS+ after task learning (<xref rid="fig5" ref-type="fig">Fig. 5F</xref>).</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Acquisition of conditioned behavior and cue encoding in PFC.</title>
<p>(A) Training schedule for 5 of the mice in the imaging experiment. An additional 3 were trained only on odor set 1.</p>
<p>(B) Mean (+/− SEM) licking on early (first 60) and late (last 60) trials from day 1 of odor set 1 (<italic>n</italic> = 8 mice).</p>
<p>(C) Mean (+/− SEM) baseline-subtracted anticipatory licks for early and late trials from each day of odor set 1. Thin lines are individual mice (<italic>n</italic> = 8 mice).</p>
<p>(D) Standard deviation of fluorescence from example imaging plane.</p>
<p>(E) Normalized activity of each pixel following CS+ presentation in early and late day 1 trials.</p>
<p>(F) Normalized deconvolved spike rate of all individual neurons for early and late trials on day 1.</p>
<p>(G) Proportion of neurons classified as coding cues, licks, rewards, and all combinations for each third of day 1.</p>
<p>(H) Mean(+/− SEM) unique variance explained by cues, licks, and rewards for neurons from each mouse. Thin lines are individual mice. Unique variance was significantly different across session thirds for cues (<italic>F</italic> (2, 21) = 3.71, <italic>p</italic> = 0.04) but not licks (<italic>F</italic> (2, 21) = 0.37, <italic>p</italic> = 0.69) or reward (<italic>F</italic> (2, 21) = 0.65, <italic>p</italic> = 0.53, <italic>n</italic> = 8 mice, one-way ANOVA).</p>
<p>(I) Mean (+/− SEM) normalized deconvolved spike rate for cells coding cues, licks, both, or neither on early and late trials, sorted by whether peak cue activity (0 - 2.5 s) was above (top) or below (bottom) baseline for late trials.</p></caption>
<graphic xlink:href="499930v2_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>To determine whether this increase in activity was best explained by a cue-evoked response, licking, or both, we again used kernel regression to fit and predict the activity of each neuron for early, middle, and late trials on day 1. The number of individual neurons encoding cues more than doubled from early to late day 1 trials (<xref rid="fig5" ref-type="fig">Fig. 5G</xref>). The unique variance cues increased across this first session, in contrast to licks and reward (<xref rid="fig5" ref-type="fig">Fig. 5H</xref>). This stark change in cue coding was also noticeable when plotting neurons encoding cues, licks, or both, as defined at the end of the session, on both early and late trials (<xref rid="fig5" ref-type="fig">Fig. 5I</xref>). These data indicated that PFC neural activity related to cues (but not licks) rapidly emerges during initial learning of the behavioral task.</p>
</sec>
<sec id="s2e">
<title>Cue and lick coding is stable across days</title>
<p>We next assessed whether cue and lick coding were stable across days. By revisiting the same imaging plane on each day of training, we were able to identify neurons that were present on all three days of odor set 1 training (<italic>n</italic> = 371, 20-65 per mouse) (<xref rid="fig6" ref-type="fig">Fig. 6A-B</xref>). There was remarkable conservation of task responding across days, both on an individual neuron level (<xref rid="fig6" ref-type="fig">Fig. 6C</xref>) and across all imaged neurons (<xref rid="fig6" ref-type="fig">Fig. 6D</xref>). To quantify coding stability, we fit our kernel regression to the activity of each neuron on day 3 (<xref rid="fig6" ref-type="fig">Fig. 6E</xref>) and then used these models to predict activity on early, middle, and late trials on days 1-3 (<xref rid="fig6" ref-type="fig">Fig. 6F</xref>). Day 3 model predictions were most highly correlated with true activity on day 3, but they outperformed shuffle controls at all time points except early day 1, demonstrating preservation of a learned coding scheme. We then asked more specifically whether cells coding cues, licks, and both maintained their coding preferences across days. For each group of cells, we calculated their unique cue, lick, and reward variance at each time point. The preferred coding of each group, as defined on day 3, was preserved in earlier days (<xref rid="fig6" ref-type="fig">Fig. 6G</xref>). Thus, cue and lick coding are stable properties of PFC neurons across multiple days of behavioral training.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Cue and lick coding is stable across days.</title>
<p>(A) Standard deviation fluorescence from example imaging plane.</p>
<p>(B) Masks (randomly colored) for all tracked neurons from this imaging plane.</p>
<p>(C) Deconvolved spike rate on every CS+ trial from all three days of odor set 1 for an example neuron. Vertical dashed line is reward delivery. Color axis as in (D).</p>
<p>(D) Normalized deconvolved spike rate for all tracked neurons on all three days of odor set 1.</p>
<p>(E) Fraction of tracked neurons coding cues, licks, rewards, and their combinations on day 3.</p>
<p>(F) Model performance when using day 3 models to predict the activity of individual neurons across odor set 1 training, plotted as mean (+/− SEM) correlation between true and predicted activity across mice. Thin lines are individual mice. Performance was greater than shuffled data at all time points (<italic>p &lt;</italic> 0.0001) except early day 1 (<italic>p</italic> = 0.21, Bonferroni-corrected, <italic>n</italic> = 8 mice).</p>
<p>(G) Mean (+/− SEM) unique cue, lick, and reward variance for cells classified as coding cues, licks, both, or neither on day 3. Day 3 cue cells had increased cue variance on day 2 (<italic>p &lt;</italic> 10<sup>−7</sup>, see Methods) and 1 (<italic>p &lt;</italic> 0.03) relative to lick and reward variance. Same pattern for lick cells on day 2 (<italic>p &lt;</italic> 0.0001) and day 1 (<italic>p &lt;</italic> 0.01).</p></caption>
<graphic xlink:href="499930v2_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>A subset of mice (<italic>n</italic> = 5) also learned a second odor set, presented on separate days. Activity was very similar for both odor sets, evident across the entire imaging plane (<xref rid="fig7" ref-type="fig">Fig. 7A</xref>), for individual tracked neurons (<italic>n</italic> = 594, 81-153 per mouse) (<xref ref-type="fig" rid="figS2">Fig. S2B</xref>), and for kernel regression classification of these neurons (<xref rid="fig7" ref-type="fig">Fig. 7B</xref>). Notably, odor set 1 models performed similarly well at predicting both odor set 1 and odor set 2 activity (<xref rid="fig7" ref-type="fig">Fig. 7C</xref>). Moreover, cue, lick and both neurons maintained their unique variance preference across odor sets (<xref rid="fig7" ref-type="fig">Fig. 7D</xref>). Finally, to investigate the presence of value coding across odor sets over separate days, we fit tracked cue neurons with the value model and its shuffles. Even with odor sets imaged on separate days, we again found that the value model was the best model for a sizable fraction (27%) of cue neurons, demonstrating that value coding is conserved across stimulus sets and days (<xref rid="fig7" ref-type="fig">Fig. 7E</xref>).</p>
<fig id="fig7" position="float" orientation="portrait" fig-type="figure">
<label>Figure 7.</label>
<caption><title>Cue and lick coding in separately trained odor sets.</title>
<p>(A) Normalized activity of all pixels in the imaging plane following CS+ presentation on day 3 of each odor set.</p>
<p>(B) Fraction of neurons coding for cues, licks, rewards, and their combinations for day 3 of each odor set.</p>
<p>(C) Mean(+/− SEM, across mice) correlation between activity predicted by odor set 1 models and true data, for real (black) and trial shuffled (gray) activity. Thin lines are individual mice. <italic>F</italic> (1, 16) = 3.2, <italic>p</italic> = 0.09 for main effect of odor set, <italic>F</italic> (1, 16) = 135, <italic>p &lt;</italic> 10<sup>−8</sup> for main effect of shuffle, <italic>F</italic> (1, 16) = 2.2, <italic>p</italic> = 0.16 for interaction, <italic>n</italic> = 5 mice, two-way ANOVA.</p>
<p>(D) Mean(+/− SEM, across mice) unique cue, lick, and reward variance for cells classified as coding cues, licks, both, or neither for odor set 1. For each category, odor set 1 unique variance preference was maintained for odor set 2 (<italic>p &lt;</italic> 0.04) except for both cells, for which lick and reward variance were not different in odor set 2 (<italic>p</italic> = 0.22, Bonferroni-corrected, <italic>n</italic> = 5 mice).</p>
<p>(E) Distribution of best model fits across all cue neurons, and the first principal component of the activity of all neurons best fit by the top 3 models.</p></caption>
<graphic xlink:href="499930v2_fig7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Our experiments assessed how coding for reward-predicting cues and reward-seeking actions differed across brain regions and across multiple days of training. We found coding for cues and licks in all regions we sampled, but their proportions varied in a graded way across those regions. In contrast to regional differences in the proportion of cue-responsive cells, cue value coding was similarly represented in all regions. Coding for cue value was robust, occurring with far greater frequency than chance, and, in a subset of neurons, incorporated the recent reward history. Cue coding was established within the first day of training and neurons encoding cues or licks maintained their coding preference across multiple days of the task. These results demonstrate a lack of regional specialization in value coding and the stability of cue and lick codes in PFC.</p>
<sec id="s3a">
<title>Graded cue and lick coding across regions</title>
<p>We found robust and separable coding for licks and cues (and combined coding of both) in all regions using electrophysiology and in PL using calcium imaging. The widespread presence of lick coding is consistent with recent reports of distributed movement and action coding (<xref ref-type="bibr" rid="c46">Musall et al., 2019</xref>; <xref ref-type="bibr" rid="c67">Steinmetz et al., 2019</xref>; <xref ref-type="bibr" rid="c69">Stringer et al., 2019</xref>); however, we saw sizable differences in the amount of lick coding across recorded regions. Notably, ALM had the greatest number of lick neurons, as well as the fewest cue neurons, perhaps reflecting its specialized role in the preparation and execution of licking behavior (<xref ref-type="bibr" rid="c6">Chen et al., 2017</xref>). Conversely, the olfactory cortical regions DP, TTd, and AON had the most cue neurons (especially non-value coding cue neurons), suggesting a role in early odor identification and processing (<xref ref-type="bibr" rid="c45">Mori and Sakano, 2021</xref>). PFC subregions balanced lick and cue coding, consistent with their proposed roles as association areas (Klein-Fluügge et al., 2022; <xref ref-type="bibr" rid="c44">Miller and Cohen, 2001</xref>), but there was variability within PFC as well. In particular, ORB had a greater fraction of cue cells than any other subregions, consistent with its known dense inputs from the olfactory system (<xref ref-type="bibr" rid="c14">Ekstrand et al., 2001</xref>; <xref ref-type="bibr" rid="c53">Price, 1985</xref>; <xref ref-type="bibr" rid="c54">Price et al., 1991</xref>). Thus, our results establish that the neural correlates of this Pavlovian conditioned behavior consist of a gradient of cue and response coding rather than segmentation of sensory and motor responses.</p>
</sec>
<sec id="s3b">
<title>Widespread value signaling</title>
<p>Value signals can take on many forms and occur throughout task epochs. In our experiments, we focused on the predicted value associated with each conditioned stimulus, which is crucial for understanding how predictive stimuli produce motivated behavior (<xref ref-type="bibr" rid="c3">Berridge, 2004</xref>). Most comparisons of single neuron stimulus-value signaling across PFC have been conducted in primates. These studies have found neurons correlated with stimulus-predicted value in many subregions, with the strongest representations typically in ORB (<xref ref-type="bibr" rid="c25">Hunt et al., 2018</xref>; <xref ref-type="bibr" rid="c31">Kennerley et al., 2009</xref>; <xref ref-type="bibr" rid="c55">Roesch and Olson, 2004</xref>; <xref ref-type="bibr" rid="c57">Sallet et al., 2007</xref>). In rodents, there is also a rich history of studying value signaling in ORB (<xref ref-type="bibr" rid="c37">Kuwabara et al., 2020</xref>; <xref ref-type="bibr" rid="c48">Namboodiri et al., 2019</xref>; <xref ref-type="bibr" rid="c59">Schoenbaum et al., 2003</xref>; <xref ref-type="bibr" rid="c63">Stalnaker et al., 2014</xref>; <xref ref-type="bibr" rid="c70">Sul et al., 2010</xref>; <xref ref-type="bibr" rid="c72">van Duuren et al., 2009</xref>; <xref ref-type="bibr" rid="c74">Wang et al., 2020a</xref>), but there have been many reports of value-like signals in frontal cortical regions beyond ORB, as well (<xref ref-type="bibr" rid="c1">Allen et al., 2019</xref>; <xref ref-type="bibr" rid="c36">Kondo and Matsuzaki, 2021</xref>; <xref ref-type="bibr" rid="c49">Otis et al., 2017</xref>; <xref ref-type="bibr" rid="c74">Wang et al., 2020a</xref>). In our present experiment, we sought to expand upon the results from the rodent literature by separating cue activity from licking, which can track with value and may confound interpretation of the signal, by including more than two cue types, which provided a rich space to assess value coding, and by sampling from many frontal regions in the same experiment.</p>
<p>When considering the number of neurons responsive to cues rather than licks, our data confirmed the importance of ORB, which has more cue-responsive neurons than motor and other prefrontal regions. However, by analyzing the activity of cue-responsive neurons across all 6 odors predicting varying probabilities of reward, we were able to separate out neurons coding value from other neurons, which included a population that had consistent responses for odors with the same associated reward probability (trial type) but activity that did not scale according to probability, consistent with the possibility of nonlinear value coding (<xref ref-type="bibr" rid="c15">Enel et al., 2021</xref>). When only considering cue neurons with linear coding of value, the distribution was even across regions. One consequence of a widely distributed value signal is that manipulating only one subregion would be less likely to fully disrupt value representations, which is consistent with the results of studies comparing functional manipulations of different PFC subregions (<xref ref-type="bibr" rid="c8">Chudasama and Robbins, 2003</xref>; <xref ref-type="bibr" rid="c11">Dalton et al., 2016</xref>; St. Onge and Floresco, 2010; <xref ref-type="bibr" rid="c73">Verharen et al., 2020</xref>; <xref ref-type="bibr" rid="c74">Wang et al., 2020a</xref>). Different subregional impacts on behavior may reveal biases in how the value signal in each region contributes to reward-related behaviors, for instance during learning or expression of a reward association (<xref ref-type="bibr" rid="c48">Namboodiri et al., 2019</xref>; <xref ref-type="bibr" rid="c49">Otis et al., 2017</xref>; <xref ref-type="bibr" rid="c74">Wang et al., 2020a</xref>). A related interpretation is that, in this task, there may be other properties that correlate with cue value, and the homogeneous value representation we observed across regions masks regional differences in tuning to these other correlated features, such as motivation (<xref ref-type="bibr" rid="c55">Roesch and Olson, 2004</xref>) and a host of related concepts, including salience, uncertainty, vigor, and arousal (<xref ref-type="bibr" rid="c22">Hayden and Niv, 2021</xref>; <xref ref-type="bibr" rid="c64">Stalnaker et al., 2015</xref>; <xref ref-type="bibr" rid="c78">Zhou et al., 2021</xref>), which can have different contributions to behavior. This interpretation is consistent with broader views that observations of ‘value’ signals are often misconstrued (<xref ref-type="bibr" rid="c78">Zhou et al., 2021</xref>) and that pure abstract value may not be encoded in the brain at all (<xref ref-type="bibr" rid="c22">Hayden and Niv, 2021</xref>). Although the identification of value in our task was robust to three levels of reward probability across two stimulus sets, the fact that this signal was widespread contributes to the case for revisiting the definition and interpretation of value to better understand regional specialization.</p>
<p>In our analysis, we uncovered a distinction between neurons encoding the overall value of cues and those with value representations that incorporated the recent reward history. Neurons with history effects were rarer but also widespread. These neurons may have a more direct impact on behavioral output in this task, because the lick rate also incorporated recent reward history. Notably, the impact of reward history on these neurons was noticeable even prior to cue onset, consistent with a previously proposed mechanism for persistent value representations encoded in the baseline firing rates of PFC neurons (<xref ref-type="bibr" rid="c2">Bari et al., 2019</xref>).</p>
<p>Given the presence of value coding in olfactory cortex, the question remains of where odor information is first transformed into a value signal. In fact, there have been multiple reports of some association-related modification of odor representations as early as the olfactory bulb (<xref ref-type="bibr" rid="c7">Chu et al., 2016</xref>; <xref ref-type="bibr" rid="c13">Doucette et al., 2011</xref>; <xref ref-type="bibr" rid="c35">Koldaeva et al., 2019</xref>; <xref ref-type="bibr" rid="c40">Li et al., 2015</xref>). Considering the prevalence of value and non-value trial type coding we observed in AON, DP, and TTd, perhaps these regions are a crucial first step in processing and amplifying task-related input from the olfactory bulb. Because they provide input to PFC (<xref ref-type="bibr" rid="c4">Bhattarai et al., 2021</xref>; <xref ref-type="bibr" rid="c27">Igarashi et al., 2012</xref>), they may be an important source of the odor coding we observed there. Previous recordings in AON, DP, and TTd were in anesthetized rodents (<xref ref-type="bibr" rid="c9">Cousens, 2020</xref>; <xref ref-type="bibr" rid="c33">Kikuta et al., 2008</xref>; <xref ref-type="bibr" rid="c39">Lei et al., 2006</xref>; <xref ref-type="bibr" rid="c71">Tsuji et al., 2019</xref>); as the first recordings in awake behaving animals, our results bring these regions into focus for future work on the transformation of odor information into task-relevant coding.</p>
</sec>
<sec id="s3c">
<title>Stability of PFC codes</title>
<p>Previous reports have observed drifting representations in PFC across time (<xref ref-type="bibr" rid="c26">Hyman et al., 2012</xref>; <xref ref-type="bibr" rid="c43">Malagon-Vina et al., 2018</xref>), and there is compelling evidence that odor representations in piriform drift over weeks when odors are experienced infrequently (<xref ref-type="bibr" rid="c60">Schoonover et al., 2021</xref>). On the other hand, it has been shown that coding for odor association is stable in ORB and PL, and that coding for odor identity is stable in piriform (<xref ref-type="bibr" rid="c74">Wang et al., 2020a</xref>), with similar findings for auditory Pavlovian cue encoding in PL (<xref ref-type="bibr" rid="c19">Grant et al., 2021</xref>; <xref ref-type="bibr" rid="c49">Otis et al., 2017</xref>) and ORB (<xref ref-type="bibr" rid="c48">Namboodiri et al., 2019</xref>). We were able to expand upon these data in PL by identifying both cue and lick coding and showing separable, stable coding of cues and licks across days and across sets of odors trained on separate days. We were also able to detect value coding common to two stimulus sets presented on separate days. This consistency in cue and lick representations indicates that PL serves as a reliable source of information about cue associations and licking during reward seeking tasks, perhaps contrasting with other representations in PFC (<xref ref-type="bibr" rid="c26">Hyman et al., 2012</xref>; <xref ref-type="bibr" rid="c43">Malagon-Vina et al., 2018</xref>). Interestingly, the presence of lick, but not cue coding at the very beginning of day 1 of training suggests that lick cells in PL are not specific to the task but that cue cells are specific to the learned cue-reward associations.</p>
<p>Overall, our work emphasizes the importance of evaluating regional specialization of neural encoding with systematic recordings in many regions using the same task. Future work will clarify whether cue value is similarly widely represented in other reward-seeking settings and whether there are regional differences in the function of the value signal.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>Thank you to Vijay Namboodiri and Charles Zhou for assistance with the imaging. Thank you to Noam Roth for the spike sorting quality control metrics. This work was supported by National Institutes of Health grants F32DA053714 (D.O.), F31DA053706 (M.H.), T32DK007247 (A.B.), R37DA032750 (G.S.), and P30DA048736 (G.S.), a UW Center for the Neurobiology of Addiction, Pain, and Emotion 2-photon pilot project grant (D.O.), a Klingenstein-Simons Fellowship in Neuroscience (N.S.), and the Pew Biomedical Scholars Program (N.S.).</p>
</ack>
<sec id="s4">
<title>Author contributions</title>
<p>Conceptualization: D.O., M.H., N.S., G.S.; data collection: D.O., M.H., A.B.; data curation: D.O., A.B.; data interpretation: D.O., M.H., N.S., A.B., G.S.; formal analysis: D.O.; visualization: D.O., M.H., A.B.; writing - original draft: D.O., M.H., A.B.; writing - review &amp; editing: D.O., M.H., A.B., N.S., G.S.; funding acquisition: N.S., G.S..</p>
</sec>
<sec id="s5">
<title>Declaration of interests</title>
<p>The authors declare no competing interests.</p>
</sec>
<sec id="s6">
<title>Data and code availability</title>
<p>The data and code for this manuscript are publicly available at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.6686927">https://doi.org/10.5281/zenodo.6686927</ext-link> (<xref ref-type="bibr" rid="c51">Ottenheimer et al., 2022</xref>).</p>
</sec>
<sec id="s7">
<title>Methods</title>
<sec id="s7a">
<title>Subjects</title>
<p>Subjects (<italic>n</italic> = 5 for electrophysiology, <italic>n</italic> = 8 for imaging) were male and female C57BL/6 mice single-housed on a 12hr light/dark cycle and aged 12-28 weeks at the time of recordings. Imaging experiments were performed during the dark cycle, electrophysiology during light cycle. Mice were given free access to food in their home cages for the duration of the experiment. Mice were water restricted for the duration of the experiments and maintained around 85% of their baseline weight (<xref ref-type="bibr" rid="c20">Guo et al., 2014a</xref>). All experimental procedures were performed in strict accordance with protocols approved by the Animal Care and Use Committee at the University of Washington.</p>
</sec>
<sec id="s7b">
<title>Surgical procedures</title>
<p>Mice were anesthetized with isoflurane (5%) and maintained under anesthesia for the duration of the surgery (1-2%). Mice received injections of carprofen (5 mg/kg) prior to incision.</p>
<sec id="s7b1">
<title>Electrophysiology</title>
<p>A brief (1 h) initial surgery was performed, as described in (<xref ref-type="bibr" rid="c21">Guo et al., 2014b</xref>; <xref ref-type="bibr" rid="c66">Steinmetz et al., 2017</xref>, <xref ref-type="bibr" rid="c67">2019</xref>), to implant a steel headplate (approximately 15 <italic>×</italic> 3 <italic>×</italic> 0.5 mm, 1 g) and a 3D-printed recording chamber that exposed the skull for subsequent craniotomies. Briefly, an incision was made around the circumference of the dorsal surface of the skull, from the interparietal bone to the frontonasal suture. The skin and periosteum were removed to expose the dorsal surface of the skull. Skull yaw, pitch, and roll were leveled, and exposed bone was texturized with a brief application of green activator (Super-Bond C&amp;B, Sun Medical). The incised skin was secured around the circumference of exposed skull with application of cyanoacrylate (VetBond; World Precision Instruments), and the chamber was attached to the skull with L-type radiopaque polymer (Super-Bond C&amp;B). A thin layer of cyanoacrylate was applied to the skull inside the chamber and allowed to dry. Multiple (2-4) thin layers of UV-curing optical glue (Norland Optical Adhesives #81, Norland Products) were applied inside the chamber to cover the entire exposed surface of the skull and cured with UV light. The headplate was attached to the skull over the interparietal bone posterior to the chamber with Super-Bond polymer, and more polymer was applied around the headplate and chamber. A second brief (15-30 min) surgery was conducted to perform craniotomies for probe insertion. Briefly, following induction of anesthesia a small (2 <italic>×</italic> 1.5 mm (w <italic>×</italic> h) craniotomy was made over frontal cortex (+2.5 - 1 mm AP, <italic>±</italic>2.5 - 0.3 mm ML) with a handheld dental drill. The craniotomy was covered with silicone gel (DOWSIL 3-4680) and the recording chamber was covered with a 3D-printed lid sealed with Kwik-Cast elastomer for protection.</p>
</sec>
<sec id="s7b2">
<title>Imaging</title>
<p>A GRIN lens and metal headcap were implanted following previously described procedures (<xref ref-type="bibr" rid="c48">Namboodiri et al., 2019</xref>) with the following modifications. In most mice, once the dura was removed from the craniotomy, we injected, 0.5 <italic>µL</italic> of virus containing the GCaMP gene construct (AAVDJ-CamKIIa-GCaMP6s, 5.3 <italic>∗</italic> 10<sup>12</sup> viral particles/mL from UNC Vector core lot AV6364) using a glass pipette microinjector (Nanoject II) targeted at Bregma +1.94 mm AP, 0.3 and 1.2 mm ML, −2 mm DV. Ten minues elapsed before microinjector withdrawal to allow virus to diffuse away from the infusion site. Then, mice were implanted with a 1×4mm GRIN lens (Inscopix) aimed at +1.94 mm AP, 0.3 and 1.2 mm ML, −1.8 mm DV. A subset of mice did not receive viral injections; instead, a lens with the imaging face coated 1 <italic>µL</italic> of the GCaMP6s virus mixed with 5 percent aqueous silk fibroin solution (<xref ref-type="bibr" rid="c29">Jackman et al., 2018</xref>) was implanted at the same coordinate. GCaMP expression and transients were similar in both preparations. Mice were allowed to recover for at least 5 weeks before experiments began.</p>
</sec>
</sec>
<sec id="s7c">
<title>Behavioral training</title>
<p>Mice were headfixed during training and recording sessions using either a headring (imaging experiments) or headbar (electrophysiology experiments). After initial habituation to head fixation, mice were first trained to lick for 2.5<italic>µL</italic> rewards of 10% sucrose solution, delivered every 8 - 12 s through a miniature inert liquid valve (Parker 003-0257-900). After 4 - 5 days of lick training, mice experienced their first odor exposure (without reward delivery). Odors were delivered for a total of 1.5 s using a 4-channel olfactometer (Aurora 206A) with 10% odor flow rate and 800 SCCM overall flow rate of medical air. Odors were randomly assigned to sets and cue identities, counterbalanced across mice. Odors were -carvone, -limonene, alphapinene, butanol, benzaldehyde, and geranyl acetate (Sigma Aldrich 124931, 218367, 147524, 281549, 418099, 173495, respectively), selected because of they are of neutral valence to naive mice (<xref ref-type="bibr" rid="c12">Devore et al., 2013</xref>; <xref ref-type="bibr" rid="c58">Saraiva et al., 2016</xref>). Odors were diluted 1:10 in mineral oil and 10 <italic>µ</italic>L was pipetted onto filter paper within the odor delivery vials (Thermo Fisher SS246-0040) prior to each session. Airflow was constant onto the mouse’s nose throughout the session and switched from clean air to scented air for the duration of odor delivery on each trial.</p>
<p>On days 1 - 2 of Pavlovian conditioning, mice received 50-75 trials each of 3 odor cues, followed by reward on 100% (CS+), 50% (CS50), or 0% (CS−) of trials, 2.5 s following odor onset, with 8 - 12 s between odor presentations. Mice then received training days 1 - 2 with a second odor set with three new odors. For electrophysiology experiments, the odors were subsequently presented in the same sessions in 6 blocks of 51 trials. Odor set order alternated and was counterbalanced across days. For imaging experiments, mice received day 3 of odor set 1 and then day 3 of odor set 2. An additional 3 imaging mice were only trained on one odor set.</p>
</sec>
<sec id="s7d">
<title>Electrophysiological recording and spike sorting</title>
<p>During recording sessions, mice were headfixed. Recordings were made using either Neuropixels 1.0 or Neuropixels 2.0 electrode arrays (<xref ref-type="bibr" rid="c30">Jun et al., 2017</xref>; <xref ref-type="bibr" rid="c65">Steinmetz et al., 2021</xref>), which have 384 selectable recording sites. Recordings were made with either 1.0 (1 shank, 960 sites, 2.1 (1 shank, 1280 sites) or 2.4 (4 shanks, 5120 sites) probes, depending on the regions of interest. Probes were mounted to a dovetail and affixed to a steel rod held by a micromanipulator (uMP-4, Sensapex Inc.). To allow later track localization, probes were coated with a solution of DiI (ThermoFisher Vybrant V22888) by holding 2 <italic>µl</italic> in a droplet on the end of a micropipette and painting the probe shank. In each session, one or two probes were advanced through the Duragel covering the craniotomy over frontal cortex, then advanced to their final position at approximately 3 <italic>µm</italic> s<sup>−1</sup>. Electrodes were allowed to settle for around 15 min before starting recording. Recordings were made in internal reference mode using the ‘tip’ reference site, with a 30 kHz sampling rate. Recordings were repeated at different locations on each of multiple subsequent days, performing an additional craniotomy over contralateral frontal cortex. The resulting data were automatically spike sorted with Kilosort2.5 and Kilosort3 (<ext-link ext-link-type="uri" xlink:href="https://github.com/MouseLand/Kilosort">https://github.com/MouseLand/Kilosort</ext-link>). Extracellular voltage traces were preprocessed with common-average referencing by subtracting each channel’s median to remove baseline offsets, then subtracting the median across all channels at each time point to remove artifacts. Sorted units were curated using automated quality control (<xref ref-type="bibr" rid="c28">International-Brain-Laboratory et al., 2022</xref>): exclusions were based on spike floor violations (the estimated proportion of spikes that were missed because they fell below the noise level of the recording, i.e. esatimed false negative rate), and refractory period violations (the estimated proportion of spikes which did not arise from the primary neuron, i/e/ the estimate false positive rate due to contamination, with a 10% cutoff). Quality control accuracy was assessed by manually reviewing a subset of the data using the phy GUI (<ext-link ext-link-type="uri" xlink:href="https://github.com/kwikteam/phy">https://github.com/kwikteam/phy</ext-link>). Because Kilosort2.5 and Kilosort3 use different clustering algorithms that can be advantageous for different types of recordings (stability, region, number of channels), for each session, we used units sorted with either Kilosort2.5 or Kilosort3 depending on which yielded the greatest number of high quality units for that session. Brain regions were only included for subsequent analysis if there were recordings from at least three subjects and in total over 100 neurons in the region. When we analyzed all of motor cortex together, we included ALM and MOs neurons. When we analyzed all of olfactory cortex, we included DP, TTd, AON, and other neurons in PIR, EPd, and OLF. We relabeled PIR and EPd as OLF because there were not enough neurons to analyze them as separate regions.</p>
</sec>
<sec id="s7e">
<title>Imaging and ROI extraction</title>
<p>During imaging sessions, mice were headfixed and positioned under the 2-photon microscope (Bruker Ultima2P Plus) using a 20x air objective (Olympus LCPLN20XIR). A Spectra-Physics InSight X3 tuned to 920nm was used to excite GCaMP6s through the GRIN lens. Synchronization of odor and 10 percent sucrose delivery, lick behavior recordings, and 2-photon recordings was achieved with custom Arduino code. After recording, raw TIF files were imported into suite2p (<ext-link ext-link-type="uri" xlink:href="https://github.com/MouseLand/suite2p">https://github.com/MouseLand/suite2p</ext-link>). We used their registration, region-of-interest (ROI) extraction, and spike deconvolution algorithms, inputting a decay factor of <italic>τ</italic> = 1.3 to reflect the dynamics of GCaMP6s, and manually reviewed putative neuron ROIs for appropriate morphology and dynamics. To find changes in activity across the entire imaging plane, found the mean pixel intensity for frames in the time of interest (2 to 2.5 s from CS+), subtracted the mean intensity of each pixel prior to cue onset (−2 to 0 s from all cues), and divided by the standard deviation for each pixel across those frames prior to cue onset.</p>
</sec>
<sec id="s7f">
<title>Histology</title>
<p>Animals were anesthetized with pentobarbital or isoflurane. Mice were perfused intracardially with 0.9% saline followed by 4% paraformaldehyde (PFA).</p>
<sec id="s7f1">
<title>Electrophysiology</title>
<p>Brains were extracted immediately following perfusion and post-fixed in 4% paraformaldehyde for 24 h. In preparation for light sheet imaging brains were cleared using organic solvents following the 3DISCO protocol (<xref ref-type="bibr" rid="c16">Ertürk et al., 2012</xref>) (<ext-link ext-link-type="uri" xlink:href="https://idisco.info/">https://idisco.info/</ext-link>), with some modification. Briefly, on day 1 brains were washed 3<italic>×</italic> in PBS, then dehydrated in a series of increasing MeOH concentrations (20%, 40%, 60%, 80%, 100%, 100%; 1-h each) and incubated overnight for lipid extraction in 66% dichloromethane (DCM) in MeOH. On day 2 the brains were washed twice for 1-h each in 100% MeOH, then bleached in 5% H<sub>2</sub>O<sub>2</sub> in MeOH at 4<italic><sup>◦</sup></italic>C overnight. On day 3 brains were washed 2<italic>×</italic> in 100% MeOH, then final lipid extraction was accomplished in a series of DCM incubations (3-h in 66% DCM in MeOH, 2<italic>×</italic> 100% DCM for 15 min each) before immersion in dibenzyl ether (DBE) for refractive index matching. Brains were imaged on a light sheet microscope (LaVIsion Biotec UltraScope II) 2-7 days after clearing. Brains were immersed in DBE in the imaging well secured in the horizontal position, and illuminated by a single light sheet (100% width, 4 <italic>µm</italic> thick) from the right. Images were collected through the 2X objective at 1X magnification, from the dorsal surface of the brain to the ventral surface in 10 <italic>µm</italic> steps in 488 <italic>nm</italic> (autofluorescence, 30% power) and 594 <italic>nm</italic> (DiI, 2-10% power) excitation channels. The approximately 1000 raw TIF images were compiled into a single multi-image file with 10 <italic>µm</italic> voxels, then spatially downsampled to 25 <italic>µm</italic> voxels for transformation to the Allen common-coordinate framework (CCF) volume (<xref ref-type="bibr" rid="c75">Wang et al., 2020b</xref>) using the Elastix algorithm (<xref ref-type="bibr" rid="c61">Shamonin et al., 2014</xref>). Transformed volumes were used to track fluorescent probe tract locations in CCF using Lasagna (<ext-link ext-link-type="uri" xlink:href="https://github.com/SainsburyWellcomeCentre/lasagna">https://github.com/SainsburyWellcomeCentre/lasagna</ext-link>), generating a series of CCF pixel coordinates for points along each probe tract. CCF pixel coordinates (origin front, top, left) were transformed to bregma coordinates (x==ML, y==AP and z==DV) in preparation for final integration with electrophysiology recordings using the International Brain Lab electrophysiology GUI (Faulkner M, Ephys Atlas GUI; 2020. <ext-link ext-link-type="uri" xlink:href="https://github.com/int-brain-lab/iblapps/tree/master/atlaselectrophysiology">https://github.com/int-brain-lab/iblapps/tree/master/atlaselectrophysiology</ext-link>). For recording alignment, sorted spikes and RMS voltage on each channel were displayed spatially in relation to the estimated channel locations in Atlas space from the tracked probe. The recording sites were then aligned to the Atlas by by manually identifying a warping such that recording sites were best fit to the electrophysiological characteristics of the brain regions (e.g. matching location of ventricles or white matter tracts with low firing activity bands). This procedure has been estimated to have 70 µm error (<xref ref-type="bibr" rid="c42">Liu et al., 2021</xref>; <xref ref-type="bibr" rid="c67">Steinmetz et al., 2019</xref>). Brain regions were then ascribed to each unit based on location of the recording site with maximum waveform. We additionally assigned MOs neurons to anterolateral motor cortex (ALM) if they were within a 0.75 mm radius of 2.5 mm AP, 1.5 mm ML (<xref ref-type="bibr" rid="c6">Chen et al., 2017</xref>).</p>
</sec>
<sec id="s7f2">
<title>Imaging</title>
<p>Following perfusion, intact heads were left in PFA for an additional week before brain extraction. Brains were then sliced on a Leica Vibratome (VT1000S) at 70 <italic>µm</italic> before mounting and nuclear staining via Fluoroshield with DAPI (Sigma-Aldrich F6057-20ML). Slices with GRIN lens tracks were then imaged on a Zeiss Axio Imager M2 Upright Trinocular Phase Contrast Fluorescence Microscope with ApoTome. The resulting images were manually aligned to the to the Allen Brain Atlas to reconstruct the location of each GRIN lens.</p>
</sec>
</sec>
<sec id="s7g">
<title>Neuron tracking</title>
<p>To identify the same neurons across imaging sessions, we used two approaches. To track neurons across the two odor sets on day 3, we concatenated the TIF files from each session and extracted ROIs simultaneously. To track neurons across days 1 - 3, we manually identified ROIs from the ROI masks outputted by suite2p. We linked the ROIs using a custom Python script that permitted selection of the same ROI across the 3 imaging planes using OpenCV and saved the coordinates on each day. The tracking results across days 1 - 3 from one of the mice is displayed in <xref rid="fig6" ref-type="fig">Fig. 6B</xref>.</p>
</sec>
<sec id="s7h">
<title>Behavioral analysis</title>
<p>For electrophysiology experiments, eye and face movements were monitored by illuminating the subject with infrared light (850 nm, CMVision IR30). The right eye was monitored with a camera (FLIR CM3-U3-13Y3M-CS) fitted with a zoom lens (Thorlabs MVL7000) and long-pass filter (Thorlabs FEL0750), recording at 70 Hz. Face movements were monitored with another camera (same model with a different lens, Thorlabs MVL16M23) directed at a 2 <italic>×</italic> 2 cm mirror reflecting the left side of the face, recording at 70 Hz. Licks were detected by thresholding the average intensity of an ROI centered between the lips and the lick spout, calculated for every frame. For imaging experiments, licks were detected with a capacitance sensor (MPR121, Adafruit Industries) connected to an Arduino board. To determine the impact of cues and previous outcomes on anticipatory licking, we fit a linear model on all electrophysiology sessions simultaneously (and for each mouse). We predicted the number of licks 0 to 2.5 s from odor onset using cue identity, outcomes on previous 10 trials, outcomes on previous 10 of that cue type, and total number of presentations of that cue type so far (to account for cue-specific satiety) using ‘fitlm’ in MATLAB. When dividing sessions into ‘early’ and ‘late’, we used the first 60 and last 60 trials of the session. When dividing sessions into thirds for the GLM (‘early’, ‘middle’, ‘late’), we used even splits of trials into thirds.</p>
</sec>
<sec id="s7i">
<title>PSTH creation</title>
<p>Peri-stimulus time histograms (PSTHs) were constructed using 0.1s bins surrounding cue onset.</p>
<sec id="s7i1">
<title>Electrophysiology</title>
<p>Neuron spike times were first binned in to 0.02s bins and smoothed with a half-normal causal filter (<italic>σ</italic> = 300 ms) across 50 bins. PSTHs were then constructed in 0.1s bins surrounding each cue onset. Each bin of the PSTH was z-scored by subtracting the mean firing rate and dividing the standard deviation across the 0.1s bins in the 2s before all trials. When splitting responses by polarity (above/below baseline, <xref rid="fig2" ref-type="fig">Figs. 2B</xref>, <xref ref-type="fig" rid="figS4">S4B</xref>), we used half of trials to determine polarity and plotted the mean across the other half of trials.</p>
</sec>
<sec id="s7i2">
<title>Imaging</title>
<p>Frames were collected at 30Hz with 2-frame averaging, so the fluorescence for each neuron and the estimated deconvolved spiking were collected at 15Hz. We interpolated the smoothing filter from the electrophysiology analysis (which was calculated at 50Hz) and applied it to the deconvolved spiking traces. We then constructed PSTHs in 0.1s bins surrounding each cue onset and z-scored (same as electrophysiology).</p>
</sec>
<sec id="s7i3">
<title>Licks</title>
<p>Licking PSTHS were constructed in 0.1s bins surrounding cue onset. Each trial was then smoothed with a half-normal filter (<italic>σ</italic> = 800 ms) across the previous (but not upcoming) 10 bins. For the GLM, the lick rate was calculated across the whole session by first counting licks in either the 0.02s (electrophysiology) or 15Hz (imaging) bins, smoothed with a half-normal filter over 25 previous bins, and then converted to 0.1s bins relative to each cue.</p>
</sec>
</sec>
<sec id="s7j">
<title>Kernel regression</title>
<p>To identify coding for cues, licks, and rewards in individual neurons, we fit reduced rank kernel-based linear model (<xref ref-type="bibr" rid="c67">Steinmetz et al., 2019</xref>).</p>
<sec id="s7j1">
<title>Data preparation</title>
<p>The discretized firing rates <italic>f<sub>n</sub></italic>(<italic>t</italic>) for each neuron <italic>n</italic> were calculated as described above for PSTH creation. We used the activity −1 to 6.5 s from each cue onset for our GLM analysis.</p>
</sec>
<sec id="s7j2">
<title>Predictor matrix</title>
<p>The model included predictor kernels for cues (CS+, CS50, and CS− for each odor set, as relevant), licks (individual licks, lick bout start, and lick rate), and reward (initiation of consummatory bout). The cue kernels were supported over the window 0 to 5s relative to stimulus onset. The lick predictor kernels were supported from −0.3 to 0.3 s relative to each lick, from −0.3 to 2 s relative to lick bout start, and lick rate was shifted from −0.4 to 0.6 s in 0.2 s increments from original rate. The reward kernel was supported 0 to 4s relative to first lick following reward delivery. For electrophysiology experiments, the model also included 6 constants that identified the block number, accounting for changes in firing rate across blocks. For each kernel to be fit we constructed a Toeplitz predictor matrix of size <italic>T × l</italic>, in which <italic>T</italic> is the total number of time bins and <italic>l</italic> is the number of lags required for the kernel. The predictor matrix contains diagonal stripes starting each time an event occurs and 0 otherwise. The predictor matrices were horizontally concatenated to yield a global prediction matrix <bold>P</bold> of size <italic>T × L</italic> containing all predictor kernels. Rate vectors of all <italic>N</italic> neurons were horizontally concatenated to form <bold>F</bold>, a <italic>T × N</italic> matrix.</p>
</sec>
<sec id="s7j3">
<title>Reduced-rank regression</title>
<p>To prevent noisy and overfit kernels we implemented reduced-rank regression (<xref ref-type="bibr" rid="c67">Steinmetz et al., 2019</xref>), which allows regularized estimation by factorizing the kernel matrix <bold>K</bold> into the product of a <italic>L × r</italic> matrix <bold>B</bold> and a <italic>r × N</italic> matrix <bold>W</bold>, minimizing the total error: <italic>E</italic> = ||<bold>F</bold> − <bold>PBW</bold>||<sup>2</sup>. The <italic>T × r</italic> matrix <bold>PB</bold> may be considered as a set of ordered temporal basis functions, which can be linearly combined to estimate the neuron’s firing rate over the whole training set, resulting in the best possible prediction from any rank <italic>r</italic> matrix. To estimate each neuron’s kernel functions we generated the reduced rank predictor matrix <bold>PB</bold> for <italic>r</italic> = 20, estimated the weights <bold>w<sub>n</sub></bold> to minimize the squared error <italic>E<sub>n</sub></italic> = |<bold>f<sub>n</sub></bold> − <bold>PBw<sub>n</sub></bold>|<bold><sup>2</sup></bold> with lasso regularization (using the MATLAB function ‘lassoglm’) with parameters <italic>α</italic> = 0.5 and <italic>λ</italic> = [0.001, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5], using 4-fold cross-validation to determine the optimal value for <italic>λ</italic> for each neuron. The kernel functions for neuron <italic>n</italic> were then unpacked from the L-length vector obtained by multiplying the first <italic>r</italic> = 20 columns of <bold>B</bold> by <bold>w<sub>n</sub></bold>.</p>
</sec>
<sec id="s7j4">
<title>Predictor unique contributions</title>
<p>To assess the importance of each group of kernels for predicting a neuron’s activity we first fit the activity of each neuron using the reduced-rank regression procedure, then fit the model (with 4-fold cross-validation) again excluding the kernels belonging to the predictor to be tested (cues, licks, rewards). If the difference in variance explained between the full and held-out model was <italic>&gt;</italic> 2%, and the total variance explained by the full model was <italic>&gt;</italic> 2%, the neuron was deemed selective for those predictors (<xref ref-type="bibr" rid="c67">Steinmetz et al., 2019</xref>). We validated this cutoff by randomly shuffling the onset time of each trial, which resulted in only 1<italic>/</italic>5332 neurons with <italic>&gt;</italic> 2% unique variance explained by any variable.</p>
</sec>
<sec id="s7j5">
<title>Training and testing on other time points</title>
<p>In the imaging experiments, we also fit the models independently to each session third (early, middle, late) of days 1-3 with odor set 1 to determine how fits and unique contributions evolved over time. To assess coding stability of individual neurons in the imaging experiment, we used the kernels resulting from fitting the full model on day 3 and the predictors from each session third to predict neural activity at those time points. We assessed the the accuracy of the prediction by correlating it with the true activity and comparing that to the correlation with trial-shuffled data. We also did this with models trained on day 3 odor set 1 and tested on day 3 odor set 1 and 2.</p>
</sec>
<sec id="s7j6">
<title>Cue coding models</title>
<p>To assess cue coding schemes, we fit a new set of models focusing on a more restricted time window (−1 to 2.5 s from cue onset) using only cues and licks as predictors. Cue and lick neurons were identified as before, and subsequent cue characterization was performed on neurons with only a unique contribution of cues. To identify value coding among cue neurons, we fit an additional version of the kernel model with only one cue kernel that scaled according to cue value. We estimated cue value for each cue type in each session by finding the mean value predicted by the lick linear model (described in section ‘Behavioral analysis’), using cue type, 10 previous outcomes, and 10 previous cue outcomes as predictors. These values were used to scale the height of cue kernel for each trial type and were approximately 0.05, 0.35, and 0.5 for CS−, CS50, and CS+, respectively. We also fit 89 additional versions of this model consisting of all permutations of cue value assignment to the 6 odors. We further fit each neuron with an ‘untuned’ model that had the same value for all cues. These models are visualized in <xref rid="figS6" ref-type="fig">Fig. S6</xref>. After removing neurons best fit with the untuned model (signifying non-specific odor responses), we classified the remaining neurons according to which of the 90 models best fit an individual neuron. For neurons where the value model was the best, we also fit another version of the model where instead of scaling the cue kernel by mean value, we scaled it by the trial-by-trial prediction of value from the lick linear model, which we called the history value model. For neurons better fit by the history model, we also fit 1000 additional models with shuffled trial values within each cue. The median percentage of shuffles that the true history model improved upon was 96.5% across all neurons for which the history model improved over the mean model. All value neurons best fit by the history model and improving over <italic>&gt;</italic> 65% shuffles (<italic>&lt;</italic> 8% of value neurons better fit by the history model than the mean model were below 65%) were classified as history coding. We also fit the value model and its 89 shuffles to the neurons imaged on separate days (<xref rid="fig7" ref-type="fig">Fig. 7E</xref>), concatenating the data from each odor set and adding a constant for each day to account for day differences.</p>
</sec>
</sec>
<sec id="s7k">
<title>Principal component analysis</title>
<p>To visualize the dominant firing pattern of PL neurons (<xref rid="figS2" ref-type="fig">Fig. S2</xref>), and of value and trial type cells (<xref rid="fig3" ref-type="fig">Fig. 3</xref>), irrespective of direction (excitation or inhibition), we performed principal component analysis (‘PCA’ in MATLAB) on the concatenated PSTHs across all 6 cues for the neurons of interest, with each neuron’s activity normalized by peak modulation so that each neuron’s concatenated PSTH peaked at −1 or 1. We then plotted the score of the first components. To visualize the value dynamics of value neurons from each region (<xref rid="fig3" ref-type="fig">Fig. 3</xref>), we performed PCA as before on this subset and plotted the component most related to value (first component for all regions except ACA, which was second). To quantify value dynamics within PCA space for each region, we randomly selected 10 neurons from each region (or 60 neurons from region group) and performed PCA as before but using only the 3 cues from odor set 1. We then projected the activity of those neurons during odor set 2 cues onto the first 3 components. We then calculated the distance between baseline (0 to 0.5 s) and cue (1 to 2.5 s) activity for each odor set 2 cue in this 3-dimensional space as a fraction of maximum total distance spanned across all time points. We performed this 5000 times with different selections of neurons to estimate the distribution of differences between cue distances.</p>
</sec>
<sec id="s7l">
<title>Cue coding dimension</title>
<p>To project population activity onto the coding dimensions separating CS− activity from CS+ and CS50 activity, respectively, we adapted an approach from <xref ref-type="bibr" rid="c41">Li et al. (2016)</xref>. We first normalized the odor set 1 PSTH activity of each neuron by dividing all of that neurons’ activity by its peak activity across odor set 1 PSTHs. This prevented neurons with particularly large z-score values from dominating the dimension. We then used half of odor set 1 trials to define the dimensions. For each neuron, we found the 0.5s bin in the range 0 to 2.5s from cue onset that maximally separated CS− activity from CS+ or CS50 activity, respectively. The difference between the normalized CS+ and CS− activity for all neurons in their preferred bins comprised a vector defining the coding dimension for each group of neurons of interest. We then multiplied that difference vector by the original z-score values of each neuron in their peak bins to find the values of peak CS+ and CS− coding; we used these values to transform the data onto a 0 to 1 scale for CS− to CS+ activity. To find population activity along that dimension at each moment in CS+, CS50, and CS− trials, we multiplied the activity of all neurons in each 0.1s bin of the other half of odor set 1 trials (z-score) by the difference vector and used the same conversion to 0 to 1 scale (‘same odor set’). We also multiplied the activity of neurons for cues in the other odor set by the difference vector (‘other odor set’). We repeated the same process for CS− and CS50 activity. To find the baseline distance from CS−, we bootstrapped (5000 iterations of selecting which neurons to include in the analysis, with replacement) the euclidean distance of the average baseline values for all 3 cues from odor set 1 from the CS− position (0, 0). To find the angle between the CS+ and CS50 projections, we bootstrapped the vectors that connected baseline activity to peak activity of CS50 and CS+ along the CS− / CS+ and CS− / CS50 axes and found the angle between these vectors. To find population activity along the CS+ / CS− dimension at each moment for CS50 trials of various values, we multiplied the activity of all neurons in each 0.1s bin of the CS50 PSTH from each value level (z-score) by the difference vector and used the same conversion to 0 to 1 scale. To estimate the distribution of values along the CS+ / CS− dimension for each CS50 value condition, we bootstrapped (5000 iterations, with replacement) the population projection and took the mean 1 - 2.5 s from odor onset. We calculated a p-value by finding the bootstrapped distribution of differences between CS50 high value projections and CS50 low value projections and calculating the fraction of the distribution that was less than 0 (supporting the null hypothesis that CS50 high value activity is not greater than CS50 low value activity).</p>
</sec>
<sec id="s7m">
<title>Statistics</title>
<p>All statistical tests were performed in MATLAB (MathWorks). To compare the fraction of neurons of a specific coding type across regions, we fit a generalized linear mixed-effects model (‘fitglme’ in MATLAB) with logit link function and with fixed effects of intercept and region and a random effect of session and then found the estimated mean and 95% confidence interval for each region. Regions with non-overlapping CIs were considered to have significantly different fractions of neurons of that coding type. To compare the number of anticipatory licks on different trial types, we found the mean number of anticipatory licks for each cue in each session and then performed a two-way ANOVA with effects of cue and subject and session as our n (<xref rid="fig1" ref-type="fig">Fig. 1C</xref>). To compare variance explained during each third of the first session, we found the mean value across neurons from each mouse and then performed a one-way ANOVA on those means with mouse as our n (<xref rid="fig5" ref-type="fig">Fig. 5H</xref>). To compare day 3 model performance on true and shuffled data across each time point (<xref rid="fig6" ref-type="fig">Fig. 6F</xref>), we found the mean value across neurons from each mouse at each time point and then performed a two-way ANOVA with main effects of shuffle and time point, with mouse as our n. We then calculated pairwise statistics using ‘mult-compare’ in MATLAB with Bonferroni correction. To compare cue, lick, and reward unique variance at each time point for each cell category (determined on day 3, <xref rid="fig6" ref-type="fig">Fig. 6G</xref>), we found the mean from the cells in that category in each mouse at each time point and performed a two-way ANOVA with main effects of variable and day, with mouse as our n. We then calculated pairwise statistics using ‘multcompare’ in MATLAB with Bonferroni correction.</p>
</sec>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Allen</surname> <given-names>WE</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>MZ</given-names></string-name>, <string-name><surname>Pichamoorthy</surname> <given-names>N</given-names></string-name>, <string-name><surname>Tien</surname> <given-names>RH</given-names></string-name>, <string-name><surname>Pachitariu</surname> <given-names>M</given-names></string-name>, <string-name><surname>Luo</surname> <given-names>L</given-names></string-name>, <string-name><surname>Deisseroth</surname> <given-names>K</given-names></string-name>. <article-title>Thirst regulates motivated behavior through modulation of brainwide neural population dynamics</article-title>. <source>Science</source> <volume>364</volume>: <fpage>253</fpage>–<lpage>253</lpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Bari</surname> <given-names>BA</given-names></string-name>, <string-name><surname>Grossman</surname> <given-names>CD</given-names></string-name>, <string-name><surname>Lubin</surname> <given-names>EE</given-names></string-name>, <string-name><surname>Rajagopalan</surname> <given-names>AE</given-names></string-name>, <string-name><surname>Cressy</surname> <given-names>JI</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>JY</given-names></string-name>. <article-title>Stable representations of decision variables for flexible behavior</article-title>. <source>Neuron</source> <volume>103</volume>: <fpage>922</fpage>–<lpage>933</lpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Berridge</surname> <given-names>KC</given-names></string-name>. <article-title>Motivation concepts in behavioral neuroscience</article-title>. <source>Physiology &amp; behavior</source> <volume>81</volume>: <fpage>179</fpage>–<lpage>209</lpage>, <year>2004</year>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="book"><string-name><surname>Bhattarai</surname> <given-names>JP</given-names></string-name>, <string-name><surname>Etyemez</surname> <given-names>S</given-names></string-name>, <string-name><surname>Jaaro-Peled</surname> <given-names>H</given-names></string-name>, <string-name><surname>Janke</surname> <given-names>E</given-names></string-name>, <string-name><surname>Tolosa</surname> <given-names>UDL</given-names></string-name>, <string-name><surname>Kamiya</surname> <given-names>A</given-names></string-name>, <string-name><surname>Gottfried</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Sawa</surname> <given-names>A</given-names></string-name>, <string-name><surname>Ma</surname> <given-names>M</given-names></string-name>. <chapter-title>Olfactory modulation of the medial prefrontal cortex circuitry: Implications for social cognition</chapter-title>. In <source>Seminars in Cell &amp; Developmental Biology</source>. <publisher-name>Elsevier</publisher-name>, <year>2021</year>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Buckley</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Mansouri</surname> <given-names>FA</given-names></string-name>, <string-name><surname>Hoda</surname> <given-names>H</given-names></string-name>, <string-name><surname>Mahboubi</surname> <given-names>M</given-names></string-name>, <string-name><surname>Browning</surname> <given-names>PG</given-names></string-name>, <string-name><surname>Kwok</surname> <given-names>SC</given-names></string-name>, <string-name><surname>Phillips</surname> <given-names>A</given-names></string-name>, <string-name><surname>Tanaka</surname> <given-names>K</given-names></string-name>. <article-title>Dissociable components of rule-guided behavior depend on distinct medial and prefrontal regions</article-title>. <source>Science</source> <volume>325</volume>: <fpage>52</fpage>–<lpage>58</lpage>, <year>2009</year>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Chen</surname> <given-names>TW</given-names></string-name>, <string-name><surname>Li</surname> <given-names>N</given-names></string-name>, <string-name><surname>Daie</surname> <given-names>K</given-names></string-name>, <string-name><surname>Svoboda</surname> <given-names>K</given-names></string-name>. <article-title>A map of anticipatory activity in mouse motor cortex</article-title>. <source>Neuron</source> <volume>94</volume>: <fpage>866</fpage>–<lpage>879</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Chu</surname> <given-names>MW</given-names></string-name>, <string-name><surname>Li</surname> <given-names>WL</given-names></string-name>, <string-name><surname>Komiyama</surname> <given-names>T</given-names></string-name>. <article-title>Balancing the robustness and efficiency of odor representations during learning</article-title>. <source>Neuron</source> <volume>92</volume>: <fpage>174</fpage>–<lpage>186</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Chudasama</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Robbins</surname> <given-names>TW</given-names></string-name>. <article-title>Dissociable contributions of the orbitofrontal and infralimbic cortex to pavlovian autoshaping and discrimination reversal learning: further evidence for the functional heterogeneity of the rodent frontal cortex</article-title>. <source>Journal of Neuroscience</source> <volume>23</volume>: <fpage>8771</fpage>–<lpage>8780</lpage>, <year>2003</year>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Cousens</surname> <given-names>GA</given-names></string-name>. <article-title>Characterization of odor-evoked neural activity in the olfactory peduncle</article-title>. <source>IBRO reports</source> <volume>9</volume>: <fpage>157</fpage>–<lpage>163</lpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Dalley</surname> <given-names>JW</given-names></string-name>, <string-name><surname>Cardinal</surname> <given-names>RN</given-names></string-name>, <string-name><surname>Robbins</surname> <given-names>TW</given-names></string-name>. <article-title>Prefrontal executive and cognitive functions in rodents: neural and neurochemical substrates</article-title>. <source>Neuroscience &amp; Biobehavioral Reviews</source> <volume>28</volume>: <fpage>771</fpage>–<lpage>784</lpage>, <year>2004</year>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Dalton</surname> <given-names>GL</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>NY</given-names></string-name>, <string-name><surname>Phillips</surname> <given-names>AG</given-names></string-name>, <string-name><surname>Floresco</surname> <given-names>SB</given-names></string-name>. <article-title>Multifaceted contributions by different regions of the orbitofrontal and medial prefrontal cortex to probabilistic reversal learning</article-title>. <source>Journal of Neuroscience</source> <volume>36</volume>: <fpage>1996</fpage>–<lpage>2006</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Devore</surname> <given-names>S</given-names></string-name>, <string-name><surname>Lee</surname> <given-names>J</given-names></string-name>, <string-name><surname>Linster</surname> <given-names>C</given-names></string-name>. <article-title>Odor preferences shape discrimination learning in rats</article-title>. <source>Behavioral neuroscience</source> <volume>127</volume>: <fpage>498</fpage>, <year>2013</year>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>Doucette</surname> <given-names>W</given-names></string-name>, <string-name><surname>Gire</surname> <given-names>DH</given-names></string-name>, <string-name><surname>Whitesell</surname> <given-names>J</given-names></string-name>, <string-name><surname>Carmean</surname> <given-names>V</given-names></string-name>, <string-name><surname>Lucero</surname> <given-names>MT</given-names></string-name>, <string-name><surname>Restrepo</surname> <given-names>D</given-names></string-name>. <article-title>Associative cortex features in the first olfactory brain relay station</article-title>. <source>Neuron</source> <volume>69</volume>: <fpage>1176</fpage>–<lpage>1187</lpage>, <year>2011</year>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Ekstrand</surname> <given-names>JJ</given-names></string-name>, <string-name><surname>Domroese</surname> <given-names>ME</given-names></string-name>, <string-name><surname>Johnson</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Feig</surname> <given-names>SL</given-names></string-name>, <string-name><surname>Knodel</surname> <given-names>SM</given-names></string-name>, <string-name><surname>Behan</surname> <given-names>M</given-names></string-name>, <string-name><surname>Haberly</surname> <given-names>LB</given-names></string-name>. <article-title>A new subdivision of anterior piriform cortex and associated deep nucleus with novel features of interest for olfaction and epilepsy</article-title>. <source>Journal of Comparative Neurology</source> <volume>434</volume>: <fpage>289</fpage>–<lpage>307</lpage>, <year>2001</year>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Enel</surname> <given-names>P</given-names></string-name>, <string-name><surname>Perkins</surname> <given-names>AQ</given-names></string-name>, <string-name><surname>Rich</surname> <given-names>EL</given-names></string-name>. <article-title>Heterogeneous value coding in orbitofrontal populations</article-title>. <source>Behavioral neuroscience</source> <volume>135</volume>: <fpage>245</fpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Ertürk</surname> <given-names>A</given-names></string-name>, <string-name><surname>Becker</surname> <given-names>K</given-names></string-name>, <string-name><surname>Jährling</surname> <given-names>N</given-names></string-name>, <string-name><surname>Mauch</surname> <given-names>C</given-names></string-name>, <string-name><surname>Hojer</surname> <given-names>C</given-names></string-name>, <string-name><surname>Egen</surname> <given-names>J</given-names></string-name>, <string-name><surname>Hellal</surname> <given-names>F</given-names></string-name>, <string-name><surname>Bradke</surname> <given-names>F</given-names></string-name>, <string-name><surname>Sheng</surname> <given-names>M</given-names></string-name>, <string-name><surname>Dodt</surname> <given-names>HU</given-names></string-name>. <article-title>Three-dimensional imaging of solvent-cleared organs using 3DISCO</article-title>. <source>Nature protocols</source> <volume>7</volume>: <fpage>1983</fpage>–<lpage>95</lpage>, <year>2012</year>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Eshel</surname> <given-names>N</given-names></string-name>, <string-name><surname>Tian</surname> <given-names>J</given-names></string-name>, <string-name><surname>Bukwich</surname> <given-names>M</given-names></string-name>, <string-name><surname>Uchida</surname> <given-names>N</given-names></string-name>. <article-title>Dopamine neurons share common response function for reward prediction error</article-title>. <source>Nature neuroscience</source> <volume>19</volume>: <issue>479</issue>, <year>2016</year>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Fiorillo</surname> <given-names>CD</given-names></string-name>, <string-name><surname>Tobler</surname> <given-names>PN</given-names></string-name>, <string-name><surname>Schultz</surname> <given-names>W</given-names></string-name>. <article-title>Discrete coding of reward probability and uncertainty by dopamine neurons</article-title>. <source>Science</source> <volume>299</volume>: <fpage>1898</fpage>–<lpage>1902</lpage>, <year>2003</year>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Grant</surname> <given-names>RI</given-names></string-name>, <string-name><surname>Doncheck</surname> <given-names>EM</given-names></string-name>, <string-name><surname>Vollmer</surname> <given-names>KM</given-names></string-name>, <string-name><surname>Winston</surname> <given-names>KT</given-names></string-name>, <string-name><surname>Romanova</surname> <given-names>EV</given-names></string-name>, <string-name><surname>Siegler</surname> <given-names>PN</given-names></string-name>, <string-name><surname>Holman</surname> <given-names>H</given-names></string-name>, <string-name><surname>Bowen</surname> <given-names>CW</given-names></string-name>, <string-name><surname>Otis</surname> <given-names>JM</given-names></string-name>. <article-title>Specialized coding patterns among dorsomedial prefrontal neuronal ensembles predict conditioned reward seeking</article-title>. <source>Elife</source> <volume>10</volume>: <fpage>e65764</fpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Guo</surname> <given-names>ZV</given-names></string-name>, <string-name><surname>Hires</surname> <given-names>SA</given-names></string-name>, <string-name><surname>Li</surname> <given-names>N</given-names></string-name>, <string-name><surname>O’Connor</surname> <given-names>DH</given-names></string-name>, <string-name><surname>Komiyama</surname> <given-names>T</given-names></string-name>, <string-name><surname>Ophir</surname> <given-names>E</given-names></string-name>, <string-name><surname>Huber</surname> <given-names>D</given-names></string-name>, <string-name><surname>Bonardi</surname> <given-names>C</given-names></string-name>, <string-name><surname>Morandell</surname> <given-names>K</given-names></string-name>, <string-name><surname>Gutnisky</surname> <given-names>D</given-names></string-name>, <etal>et al.</etal> <article-title>Procedures for behavioral experiments in head-fixed mice</article-title>. <source>PloS one</source> <volume>9</volume>: <fpage>e88678</fpage>, <year>2014a</year>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Guo</surname> <given-names>ZV</given-names></string-name>, <string-name><surname>Li</surname> <given-names>N</given-names></string-name>, <string-name><surname>Huber</surname> <given-names>D</given-names></string-name>, <string-name><surname>Ophir</surname> <given-names>E</given-names></string-name>, <string-name><surname>Gutnisky</surname> <given-names>D</given-names></string-name>, <string-name><surname>Ting</surname> <given-names>JT</given-names></string-name>, <string-name><surname>Feng</surname> <given-names>G</given-names></string-name>, <string-name><surname>Svoboda</surname> <given-names>K</given-names></string-name>. <article-title>Flow of cortical activity underlying a tactile decision in mice</article-title>. <source>Neuron</source> <volume>81</volume>: <fpage>179</fpage>–<lpage>194</lpage>, <year>2014b</year>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Hayden</surname> <given-names>BY</given-names></string-name>, <string-name><surname>Niv</surname> <given-names>Y</given-names></string-name>. <article-title>The case against economic values in the orbitofrontal cortex (or anywhere else in the brain)</article-title>. <source>Behavioral Neuroscience</source> <volume>135</volume>: <fpage>192</fpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Heilbronner</surname> <given-names>SR</given-names></string-name>, <string-name><surname>Rodriguez-Romaguera</surname> <given-names>J</given-names></string-name>, <string-name><surname>Quirk</surname> <given-names>GJ</given-names></string-name>, <string-name><surname>Groenewegen</surname> <given-names>HJ</given-names></string-name>, <string-name><surname>Haber</surname> <given-names>SN</given-names></string-name>. <article-title>Circuit-based corticostriatal homologies between rat and primate</article-title>. <source>Biological psychiatry</source> <volume>80</volume>: <fpage>509</fpage>–<lpage>521</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Horst</surname> <given-names>NK</given-names></string-name>, <string-name><surname>Laubach</surname> <given-names>M</given-names></string-name>. <article-title>Reward-related activity in the medial prefrontal cortex is driven by consumption</article-title>. <source>Frontiers in neuroscience</source> <volume>7</volume>: <fpage>56</fpage>, <year>2013</year>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Hunt</surname> <given-names>LT</given-names></string-name>, <string-name><surname>Malalasekera</surname> <given-names>W</given-names></string-name>, <string-name><surname>de Berker</surname> <given-names>AO</given-names></string-name>, <string-name><surname>Miranda</surname> <given-names>B</given-names></string-name>, <string-name><surname>Farmer</surname> <given-names>SF</given-names></string-name>, <string-name><surname>Behrens</surname> <given-names>TE</given-names></string-name>, <string-name><surname>Kennerley</surname> <given-names>SW</given-names></string-name>. <article-title>Triple dissociation of attention and decision computations across prefrontal cortex</article-title>. <source>Nature neuroscience</source> <volume>21</volume>: <fpage>1471</fpage>–<lpage>1481</lpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>Hyman</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Ma</surname> <given-names>L</given-names></string-name>, <string-name><surname>Balaguer-Ballester</surname> <given-names>E</given-names></string-name>, <string-name><surname>Durstewitz</surname> <given-names>D</given-names></string-name>, <string-name><surname>Seamans</surname> <given-names>JK</given-names></string-name>. <article-title>Contextual encoding by ensembles of medial prefrontal cortex neurons</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>109</volume>: <fpage>5086</fpage>–<lpage>5091</lpage>, <year>2012</year>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>Igarashi</surname> <given-names>KM</given-names></string-name>, <string-name><surname>Ieki</surname> <given-names>N</given-names></string-name>, <string-name><surname>An</surname> <given-names>M</given-names></string-name>, <string-name><surname>Yamaguchi</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Nagayama</surname> <given-names>S</given-names></string-name>, <string-name><surname>Kobayakawa</surname> <given-names>K</given-names></string-name>, <string-name><surname>Kobayakawa</surname> <given-names>R</given-names></string-name>, <string-name><surname>Tanifuji</surname> <given-names>M</given-names></string-name>, <string-name><surname>Sakano</surname> <given-names>H</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>WR</given-names></string-name>, <etal>et al.</etal> <article-title>Parallel mitral and tufted cell pathways route distinct odor information to different targets in the olfactory cortex</article-title>. <source>Journal of Neuroscience</source> <volume>32</volume>: <fpage>7970</fpage>–<lpage>7985</lpage>, <year>2012</year>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><string-name><surname>International-Brain-Laboratory</surname>, <given-names>Banga K</given-names></string-name>, <string-name><surname>Benson</surname> <given-names>J</given-names></string-name>, <string-name><surname>Bonacchi</surname> <given-names>N</given-names></string-name>, <string-name><surname>Bruijns</surname> <given-names>SA</given-names></string-name>, <string-name><surname>Campbell</surname> <given-names>R</given-names></string-name>, <string-name><surname>Chapuis</surname> <given-names>GA</given-names></string-name>, <string-name><surname>Churchland</surname> <given-names>AK</given-names></string-name>, <string-name><surname>Davatolhagh</surname> <given-names>MF</given-names></string-name>, <string-name><surname>Lee</surname> <given-names>HD</given-names></string-name>, <string-name><surname>Faulkner</surname> <given-names>M</given-names></string-name>, <etal>et al.</etal> <article-title>Reproducibility of in-vivo electrophysiological measurements in mice</article-title>. <source>bioRxiv</source>, <year>2022</year>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><string-name><surname>Jackman</surname> <given-names>SL</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>CH</given-names></string-name>, <string-name><surname>Chettih</surname> <given-names>SN</given-names></string-name>, <string-name><surname>Neufeld</surname> <given-names>SQ</given-names></string-name>, <string-name><surname>Drew</surname> <given-names>IR</given-names></string-name>, <string-name><surname>Agba</surname> <given-names>CK</given-names></string-name>, <string-name><surname>Flaquer</surname> <given-names>I</given-names></string-name>, <string-name><surname>Stefano</surname> <given-names>AN</given-names></string-name>, <string-name><surname>Kennedy</surname> <given-names>TJ</given-names></string-name>, <string-name><surname>Belinsky</surname> <given-names>JE</given-names></string-name>, <etal>et al.</etal> <article-title>Silk fibroin films facilitate single-step targeted expression of optogenetic proteins</article-title>. <source>Cell reports</source> <volume>22</volume>: <fpage>3351</fpage>–<lpage>3361</lpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>Jun</surname> <given-names>JJ</given-names></string-name>, <string-name><surname>Steinmetz</surname> <given-names>NA</given-names></string-name>, <string-name><surname>Siegle</surname> <given-names>JH</given-names></string-name>, <string-name><surname>Denman</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Bauza</surname> <given-names>M</given-names></string-name>, <string-name><surname>Barbarits</surname> <given-names>B</given-names></string-name>, <string-name><surname>Lee</surname> <given-names>AK</given-names></string-name>, <string-name><surname>Anastassiou</surname> <given-names>CA</given-names></string-name>, <string-name><surname>Andrei</surname> <given-names>A</given-names></string-name>, <string-name><surname>Aydın</surname> <given-names>Ç</given-names></string-name>, <etal>et al.</etal> <article-title>Fully integrated silicon probes for high-density recording of neural activity</article-title>. <source>Nature</source> <volume>551</volume>: <fpage>232</fpage>–<lpage>236</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>Kennerley</surname> <given-names>SW</given-names></string-name>, <string-name><surname>Dahmubed</surname> <given-names>AF</given-names></string-name>, <string-name><surname>Lara</surname> <given-names>AH</given-names></string-name>, <string-name><surname>Wallis</surname> <given-names>JD</given-names></string-name>. <article-title>Neurons in the frontal lobe encode the value of multiple decision variables</article-title>. <source>Journal of cognitive neuroscience</source> <volume>21</volume>: <fpage>1162</fpage>–<lpage>1178</lpage>, <year>2009</year>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><string-name><surname>Kesner</surname> <given-names>RP</given-names></string-name>, <string-name><surname>Churchwell</surname> <given-names>JC</given-names></string-name>. <article-title>An analysis of rat prefrontal cortex in mediating executive function</article-title>. <source>Neurobiology of learning and memory</source> <volume>96</volume>: <fpage>417</fpage>–<lpage>431</lpage>, <year>2011</year>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><string-name><surname>Kikuta</surname> <given-names>S</given-names></string-name>, <string-name><surname>Kashiwadani</surname> <given-names>H</given-names></string-name>, <string-name><surname>Mori</surname> <given-names>K</given-names></string-name>. <article-title>Compensatory rapid switching of binasal inputs in the olfactory cortex</article-title>. <source>Journal of Neuroscience</source> <volume>28</volume>: <fpage>11989</fpage>–<lpage>11997</lpage>, <year>2008</year>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Klein-Flügge</surname> <given-names>MC</given-names></string-name>, <string-name><surname>Bongioanni</surname> <given-names>A</given-names></string-name>, <string-name><surname>Rushworth</surname> <given-names>MF</given-names></string-name>. <article-title>Medial and orbital frontal cortex in decision-making and flexible behavior</article-title>. <source>Neuron</source>, <year>2022</year>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>Koldaeva</surname> <given-names>A</given-names></string-name>, <string-name><surname>Schaefer</surname> <given-names>AT</given-names></string-name>, <string-name><surname>Fukunaga</surname> <given-names>I</given-names></string-name>. <article-title>Rapid task-dependent tuning of the mouse olfactory bulb</article-title>. <source>Elife</source> <volume>8</volume>: <fpage>e43558</fpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><string-name><surname>Kondo</surname> <given-names>M</given-names></string-name>, <string-name><surname>Matsuzaki</surname> <given-names>M</given-names></string-name>. <article-title>Neuronal representations of reward-predicting cues and outcome history with movement in the frontal cortex</article-title>. <source>Cell Reports</source> <volume>34</volume>: <fpage>108704</fpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><string-name><surname>Kuwabara</surname> <given-names>M</given-names></string-name>, <string-name><surname>Kang</surname> <given-names>N</given-names></string-name>, <string-name><surname>Holy</surname> <given-names>TE</given-names></string-name>, <string-name><surname>Padoa-Schioppa</surname> <given-names>C</given-names></string-name>. <article-title>Neural mechanisms of economic choices in mice</article-title>. <source>Elife</source> <volume>9</volume>: <fpage>e49669</fpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><string-name><surname>Laubach</surname> <given-names>M</given-names></string-name>, <string-name><surname>Amarante</surname> <given-names>LM</given-names></string-name>, <string-name><surname>Swanson</surname> <given-names>K</given-names></string-name>, <string-name><surname>White</surname> <given-names>SR</given-names></string-name>. <article-title>What, if anything, is rodent prefrontal cortex?</article-title> <source>eneuro</source> <volume>5</volume>, <year>2018</year>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><string-name><surname>Lei</surname> <given-names>H</given-names></string-name>, <string-name><surname>Mooney</surname> <given-names>R</given-names></string-name>, <string-name><surname>Katz</surname> <given-names>LC</given-names></string-name>. <article-title>Synaptic integration of olfactory information in mouse anterior olfactory nucleus</article-title>. <source>Journal of Neuroscience</source> <volume>26</volume>: <fpage>12023</fpage>–<lpage>12032</lpage>, <year>2006</year>.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><string-name><surname>Li</surname> <given-names>A</given-names></string-name>, <string-name><surname>Gire</surname> <given-names>DH</given-names></string-name>, <string-name><surname>Restrepo</surname> <given-names>D</given-names></string-name>. <article-title>Υ spike-field coherence in a population of olfactory bulb neurons differentiates between odors irrespective of associated outcome</article-title>. <source>Journal of Neuroscience</source> <volume>35</volume>: <fpage>5808</fpage>–<lpage>5822</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><string-name><surname>Li</surname> <given-names>N</given-names></string-name>, <string-name><surname>Daie</surname> <given-names>K</given-names></string-name>, <string-name><surname>Svoboda</surname> <given-names>K</given-names></string-name>, <string-name><surname>Druckmann</surname> <given-names>S</given-names></string-name>. <article-title>Robust neuronal dynamics in premotor cortex during motor planning</article-title>. <source>Nature</source> <volume>532</volume>: <fpage>459</fpage>–<lpage>464</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><string-name><surname>Liu</surname> <given-names>LD</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>S</given-names></string-name>, <string-name><surname>Hou</surname> <given-names>H</given-names></string-name>, <string-name><surname>West</surname> <given-names>SJ</given-names></string-name>, <string-name><surname>Faulkner</surname> <given-names>M</given-names></string-name>, <string-name><surname>Laboratory</surname> <given-names>TIB</given-names></string-name>, <string-name><surname>Economo</surname> <given-names>MN</given-names></string-name>, <string-name><surname>Li</surname> <given-names>N</given-names></string-name>, <string-name><surname>Svoboda</surname> <given-names>K</given-names></string-name>. <article-title>Accurate localization of linear probe electrode arrays across multiple brains</article-title>. <source>Eneuro</source> <volume>8</volume>, <year>2021</year>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><string-name><surname>Malagon-Vina</surname> <given-names>H</given-names></string-name>, <string-name><surname>Ciocchi</surname> <given-names>S</given-names></string-name>, <string-name><surname>Passecker</surname> <given-names>J</given-names></string-name>, <string-name><surname>Dorffner</surname> <given-names>G</given-names></string-name>, <string-name><surname>Klausberger</surname> <given-names>T</given-names></string-name>. <article-title>Fluid network dynamics in the prefrontal cortex during multiple strategy switching</article-title>. <source>Nature communications</source> <volume>9</volume>: <fpage>1</fpage>–<lpage>13</lpage>, <year>2018</year>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><string-name><surname>Miller</surname> <given-names>EK</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>JD</given-names></string-name>. <article-title>An integrative theory of prefrontal cortex function</article-title>. <source>Annual review of neuroscience</source> <volume>24</volume>: <fpage>167</fpage>–<lpage>202</lpage>, <year>2001</year>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><string-name><surname>Mori</surname> <given-names>K</given-names></string-name>, <string-name><surname>Sakano</surname> <given-names>H</given-names></string-name>. <article-title>Olfactory circuitry and behavioral decisions</article-title>. <source>Annual Review of Physiology</source> <volume>83</volume>: <fpage>231</fpage>–<lpage>256</lpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><string-name><surname>Musall</surname> <given-names>S</given-names></string-name>, <string-name><surname>Kaufman</surname> <given-names>MT</given-names></string-name>, <string-name><surname>Juavinett</surname> <given-names>AL</given-names></string-name>, <string-name><surname>Gluf</surname> <given-names>S</given-names></string-name>, <string-name><surname>Churchland</surname> <given-names>AK</given-names></string-name>. <article-title>Single-trial neural dynamics are dominated by richly varied movements</article-title>. <source>Nature neuroscience</source> <volume>22</volume>: <fpage>1677</fpage>–<lpage>1686</lpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><string-name><surname>Nakahara</surname> <given-names>H</given-names></string-name>, <string-name><surname>Itoh</surname> <given-names>H</given-names></string-name>, <string-name><surname>Kawagoe</surname> <given-names>R</given-names></string-name>, <string-name><surname>Takikawa</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Hikosaka</surname> <given-names>O</given-names></string-name>. <article-title>Dopamine neurons can represent context-dependent prediction error</article-title>. <source>Neuron</source> <volume>41</volume>: <fpage>269</fpage>–<lpage>280</lpage>, <year>2004</year>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><string-name><surname>Namboodiri</surname> <given-names>VMK</given-names></string-name>, <string-name><surname>Otis</surname> <given-names>JM</given-names></string-name>, <string-name><surname>van Heeswijk</surname> <given-names>K</given-names></string-name>, <string-name><surname>Voets</surname> <given-names>ES</given-names></string-name>, <string-name><surname>Alghorazi</surname> <given-names>RA</given-names></string-name>, <string-name><surname>Rodriguez-Romaguera</surname> <given-names>J</given-names></string-name>, <string-name><surname>Mihalas</surname> <given-names>S</given-names></string-name>, <string-name><surname>Stuber</surname> <given-names>GD</given-names></string-name>. <article-title>Single-cell activity tracking reveals that orbitofrontal neurons acquire and maintain a long-term memory to guide behavioral adaptation</article-title>. <source>Nature neuroscience</source> <volume>22</volume>: <fpage>1110</fpage>–<lpage>1121</lpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><string-name><surname>Otis</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Namboodiri</surname> <given-names>VM</given-names></string-name>, <string-name><surname>Matan</surname> <given-names>AM</given-names></string-name>, <string-name><surname>Voets</surname> <given-names>ES</given-names></string-name>, <string-name><surname>Mohorn</surname> <given-names>EP</given-names></string-name>, <string-name><surname>Kosyk</surname> <given-names>O</given-names></string-name>, <string-name><surname>McHenry</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Robinson</surname> <given-names>JE</given-names></string-name>, <string-name><surname>Resendez</surname> <given-names>SL</given-names></string-name>, <string-name><surname>Rossi</surname> <given-names>MA</given-names></string-name>, <etal>et al.</etal> <article-title>Prefrontal cortex output circuits guide reward seeking through divergent cue encoding</article-title>. <source>Nature</source> <volume>543</volume>: <fpage>103</fpage>–<lpage>107</lpage>, <year>2017</year>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><string-name><surname>Ottenheimer</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Bari</surname> <given-names>BA</given-names></string-name>, <string-name><surname>Sutlief</surname> <given-names>E</given-names></string-name>, <string-name><surname>Fraser</surname> <given-names>KM</given-names></string-name>, <string-name><surname>Kim</surname> <given-names>TH</given-names></string-name>, <string-name><surname>Richard</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>JY</given-names></string-name>, <string-name><surname>Janak</surname> <given-names>PH</given-names></string-name>. <article-title>A quantitative reward prediction error signal in the ventral pallidum</article-title>. <source>Nature neuroscience</source> <volume>23</volume>: <fpage>1267</fpage>–<lpage>1276</lpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><string-name><surname>Ottenheimer</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Hjort</surname> <given-names>MM</given-names></string-name>, <string-name><surname>Bowen</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>Steinmetz</surname> <given-names>NA</given-names></string-name>, <string-name><surname>Stuber</surname> <given-names>GD.</given-names></string-name> <article-title>Data and code for <xref ref-type="bibr" rid="c51">Ottenheimer, et al 2022</xref></article-title>. <source>Zenodo</source> DOI: <pub-id pub-id-type="doi">10.5281/zenodo.6686927</pub-id>, <year>2022</year>.</mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><string-name><surname>Pashkovski</surname> <given-names>SL</given-names></string-name>, <string-name><surname>Iurilli</surname> <given-names>G</given-names></string-name>, <string-name><surname>Brann</surname> <given-names>D</given-names></string-name>, <string-name><surname>Chicharro</surname> <given-names>D</given-names></string-name>, <string-name><surname>Drummey</surname> <given-names>K</given-names></string-name>, <string-name><surname>Franks</surname> <given-names>KM</given-names></string-name>, <string-name><surname>Panzeri</surname> <given-names>S</given-names></string-name>, <string-name><surname>Datta</surname> <given-names>SR</given-names></string-name>. <article-title>Structure and flexibility in cortical representations of odour space</article-title>. <source>Nature</source> <volume>583</volume>: <fpage>253</fpage>–<lpage>258</lpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><string-name><surname>Price</surname> <given-names>JL</given-names></string-name>. <article-title>Beyond the primary olfactory cortex: olfactory-related areas in the neocortex, thalamus and hypothalamus</article-title>. <source>Chemical Senses</source> <volume>10</volume>: <fpage>239</fpage>–<lpage>258</lpage>, <year>1985</year>.</mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><string-name><surname>Price</surname> <given-names>JL</given-names></string-name>, <string-name><surname>Carmichael</surname> <given-names>ST</given-names></string-name>, <string-name><surname>Carnes</surname> <given-names>K</given-names></string-name>, <string-name><surname>Clugnet</surname> <given-names>M</given-names></string-name>, <string-name><surname>Kuroda</surname> <given-names>M</given-names></string-name>, <string-name><surname>Ray</surname> <given-names>J</given-names></string-name>. <article-title>Olfactory input to the prefrontal cortex</article-title>. <source>Olfaction: A model system for computational neuroscience</source> pp. <fpage>101</fpage>–<lpage>20</lpage>, <year>1991</year>.</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><string-name><surname>Roesch</surname> <given-names>MR</given-names></string-name>, <string-name><surname>Olson</surname> <given-names>CR</given-names></string-name>. <article-title>Neuronal activity related to reward value and motivation in primate frontal cortex</article-title>. <source>Science</source> <volume>304</volume>: <fpage>307</fpage>–<lpage>310</lpage>, <year>2004</year>.</mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><string-name><surname>Rudebeck</surname> <given-names>PH</given-names></string-name>, <string-name><surname>Behrens</surname> <given-names>TE</given-names></string-name>, <string-name><surname>Kennerley</surname> <given-names>SW</given-names></string-name>, <string-name><surname>Baxter</surname> <given-names>MG</given-names></string-name>, <string-name><surname>Buckley</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Walton</surname> <given-names>ME</given-names></string-name>, <string-name><surname>Rushworth</surname> <given-names>MF</given-names></string-name>. <article-title>Frontal cortex subregions play distinct roles in choices between actions and stimuli</article-title>. <source>Journal of Neuroscience</source> <volume>28</volume>: <fpage>13775</fpage>–<lpage>13785</lpage>, <year>2008</year>.</mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><string-name><surname>Sallet</surname> <given-names>J</given-names></string-name>, <string-name><surname>Quilodran</surname> <given-names>R</given-names></string-name>, <string-name><surname>Rothé</surname> <given-names>M</given-names></string-name>, <string-name><surname>Vezoli</surname> <given-names>J</given-names></string-name>, <string-name><surname>Joseph</surname> <given-names>JP</given-names></string-name>, <string-name><surname>Procyk</surname> <given-names>E</given-names></string-name>. <article-title>Expectations, gains, and losses in the anterior cingulate cortex</article-title>. <source>Cognitive, Affective, &amp; Behavioral Neuroscience</source> <volume>7</volume>: <fpage>327</fpage>–<lpage>336</lpage>, <year>2007</year>.</mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><string-name><surname>Saraiva</surname> <given-names>LR</given-names></string-name>, <string-name><surname>Kondoh</surname> <given-names>K</given-names></string-name>, <string-name><surname>Ye</surname> <given-names>X</given-names></string-name>, <string-name><given-names>Yoon</given-names> <surname>Kh</surname></string-name>, <string-name><surname>Hernandez</surname> <given-names>M</given-names></string-name>, <string-name><surname>Buck</surname> <given-names>LB</given-names></string-name>. <article-title>Combinatorial effects of odorants on mouse behavior</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>113</volume>: <fpage>E3300</fpage>– <lpage>E3306</lpage>, <year>2016</year>.</mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><string-name><surname>Schoenbaum</surname> <given-names>G</given-names></string-name>, <string-name><surname>Setlow</surname> <given-names>B</given-names></string-name>, <string-name><surname>Saddoris</surname> <given-names>MP</given-names></string-name>, <string-name><surname>Gallagher</surname> <given-names>M</given-names></string-name>. <article-title>Encoding predicted outcome and acquired value in orbitofrontal cortex during cue sampling depends upon input from basolateral amygdala</article-title>. <source>Neuron</source> <volume>39</volume>: <fpage>855</fpage>–<lpage>867</lpage>, <year>2003</year>.</mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><string-name><surname>Schoonover</surname> <given-names>CE</given-names></string-name>, <string-name><surname>Ohashi</surname> <given-names>SN</given-names></string-name>, <string-name><surname>Axel</surname> <given-names>R</given-names></string-name>, <string-name><surname>Fink</surname> <given-names>AJ</given-names></string-name>. <article-title>Representational drift in primary olfactory cortex</article-title>. <source>Nature</source> <volume>594</volume>: <fpage>541</fpage>–<lpage>546</lpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><string-name><surname>Shamonin</surname> <given-names>DP</given-names></string-name>, <string-name><surname>Bron</surname> <given-names>EE</given-names></string-name>, <string-name><surname>Lelieveldt</surname> <given-names>BP</given-names></string-name>, <string-name><surname>Smits</surname> <given-names>M</given-names></string-name>, <string-name><surname>Klein</surname> <given-names>S</given-names></string-name>, <string-name><surname>Staring</surname> <given-names>M</given-names></string-name>, <string-name><surname>Initiative</surname> <given-names>ADN</given-names></string-name>. <article-title>Fast parallel image registration on CPU and GPU for diagnostic classification of Alzheimer’s disease</article-title>. <source>Frontiers in neuroinformatics</source> <volume>7</volume>: <fpage>50</fpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><string-name><surname>St Onge</surname> <given-names>JR</given-names></string-name>, <string-name><surname>Floresco</surname> <given-names>SB</given-names></string-name>. <article-title>Prefrontal cortical contribution to risk-based decision making</article-title>. <source>Cerebral cortex</source> <volume>20</volume>: <fpage>1816</fpage>–<lpage>1828</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><string-name><surname>Stalnaker</surname> <given-names>TA</given-names></string-name>, <string-name><surname>Cooch</surname> <given-names>NK</given-names></string-name>, <string-name><surname>McDannald</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>TL</given-names></string-name>, <string-name><surname>Wied</surname> <given-names>H</given-names></string-name>, <string-name><surname>Schoenbaum</surname> <given-names>G</given-names></string-name>. <article-title>Orbitofrontal neurons infer the value and identity of predicted outcomes</article-title>. <source>Nature communications</source> <volume>5</volume>: <fpage>1</fpage>–<lpage>13</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><string-name><surname>Stalnaker</surname> <given-names>TA</given-names></string-name>, <string-name><surname>Cooch</surname> <given-names>NK</given-names></string-name>, <string-name><surname>Schoenbaum</surname> <given-names>G</given-names></string-name>. <article-title>What the orbitofrontal cortex does not do</article-title>. <source>Nature neuroscience</source> <volume>18</volume>: <fpage>620</fpage>–<lpage>627</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c65"><mixed-citation publication-type="journal"><string-name><surname>Steinmetz</surname> <given-names>NA</given-names></string-name>, <string-name><surname>Aydin</surname> <given-names>C</given-names></string-name>, <string-name><surname>Lebedeva</surname> <given-names>A</given-names></string-name>, <string-name><surname>Okun</surname> <given-names>M</given-names></string-name>, <string-name><surname>Pachitariu</surname> <given-names>M</given-names></string-name>, <string-name><surname>Bauza</surname> <given-names>M</given-names></string-name>, <string-name><surname>Beau</surname> <given-names>M</given-names></string-name>, <string-name><surname>Bhagat</surname> <given-names>J</given-names></string-name>, <string-name><surname>Böhm</surname> <given-names>C</given-names></string-name>, <string-name><surname>Broux</surname> <given-names>M</given-names></string-name>, <etal>et al.</etal> <article-title>Neuropixels 2.0: A miniaturized high-density probe for stable, long-term brain recordings</article-title>. <source>Science</source> <volume>372</volume>: <fpage>eabf4588</fpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c66"><mixed-citation publication-type="journal"><string-name><surname>Steinmetz</surname> <given-names>NA</given-names></string-name>, <string-name><surname>Buetfering</surname> <given-names>C</given-names></string-name>, <string-name><surname>Lecoq</surname> <given-names>J</given-names></string-name>, <string-name><surname>Lee</surname> <given-names>CR</given-names></string-name>, <string-name><surname>Peters</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>Jacobs</surname> <given-names>EA</given-names></string-name>, <string-name><surname>Coen</surname> <given-names>P</given-names></string-name>, <string-name><surname>Ollerenshaw</surname> <given-names>DR</given-names></string-name>, <string-name><surname>Valley</surname> <given-names>MT</given-names></string-name>, <string-name><surname>De Vries</surname> <given-names>SE</given-names></string-name>, <etal>et al.</etal> <article-title>Aberrant cortical activity in multiple GCaMP6-expressing transgenic mouse lines</article-title>. <source>eneuro</source> <volume>4</volume>, <year>2017</year>.</mixed-citation></ref>
<ref id="c67"><mixed-citation publication-type="journal"><string-name><surname>Steinmetz</surname> <given-names>NA</given-names></string-name>, <string-name><surname>Zatka-Haas</surname> <given-names>P</given-names></string-name>, <string-name><surname>Carandini</surname> <given-names>M</given-names></string-name>, <string-name><surname>Harris</surname> <given-names>KD</given-names></string-name>. <article-title>Distributed coding of choice, action and engagement across the mouse brain</article-title>. <source>Nature</source> <volume>576</volume>: <fpage>266</fpage>–<lpage>273</lpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c68"><mixed-citation publication-type="journal"><string-name><surname>Stettler</surname> <given-names>DD</given-names></string-name>, <string-name><surname>Axel</surname> <given-names>R</given-names></string-name>. <article-title>Representations of odor in the piriform cortex</article-title>. <source>Neuron</source> <volume>63</volume>: <fpage>854</fpage>–<lpage>864</lpage>, <year>2009</year>.</mixed-citation></ref>
<ref id="c69"><mixed-citation publication-type="journal"><string-name><surname>Stringer</surname> <given-names>C</given-names></string-name>, <string-name><surname>Pachitariu</surname> <given-names>M</given-names></string-name>, <string-name><surname>Steinmetz</surname> <given-names>N</given-names></string-name>, <string-name><surname>Reddy</surname> <given-names>CB</given-names></string-name>, <string-name><surname>Carandini</surname> <given-names>M</given-names></string-name>, <string-name><surname>Harris</surname> <given-names>KD</given-names></string-name>. <article-title>Spontaneous behaviors drive multidimensional, brainwide activity</article-title>. <source>Science</source> <volume>364</volume>: <fpage>eaav7893</fpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c70"><mixed-citation publication-type="journal"><string-name><surname>Sul</surname> <given-names>JH</given-names></string-name>, <string-name><surname>Kim</surname> <given-names>H</given-names></string-name>, <string-name><surname>Huh</surname> <given-names>N</given-names></string-name>, <string-name><surname>Lee</surname> <given-names>D</given-names></string-name>, <string-name><surname>Jung</surname> <given-names>MW</given-names></string-name>. <article-title>Distinct roles of rodent orbitofrontal and medial prefrontal cortex in decision making</article-title>. <source>Neuron</source> <volume>66</volume>: <fpage>449</fpage>–<lpage>460</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c71"><mixed-citation publication-type="journal"><string-name><surname>Tsuji</surname> <given-names>T</given-names></string-name>, <string-name><surname>Tsuji</surname> <given-names>C</given-names></string-name>, <string-name><surname>Lozic</surname> <given-names>M</given-names></string-name>, <string-name><surname>Ludwig</surname> <given-names>M</given-names></string-name>, <string-name><surname>Leng</surname> <given-names>G</given-names></string-name>. <article-title>Coding of odors in the anterior olfactory nucleus</article-title>. <source>Physiological reports</source> <volume>7</volume>: <fpage>e14284</fpage>, <year>2019</year>.</mixed-citation></ref>
<ref id="c72"><mixed-citation publication-type="journal"><string-name><surname>van Duuren</surname> <given-names>E</given-names></string-name>, <string-name><surname>van der Plasse</surname> <given-names>G</given-names></string-name>, <string-name><surname>Lankelma</surname> <given-names>J</given-names></string-name>, <string-name><surname>Joosten</surname> <given-names>RN</given-names></string-name>, <string-name><surname>Feenstra</surname> <given-names>MG</given-names></string-name>, <string-name><surname>Pennartz</surname> <given-names>CM</given-names></string-name>. <article-title>Single-cell and population coding of expected reward probability in the orbitofrontal cortex of the rat</article-title>. <source>Journal of Neuroscience</source> <volume>29</volume>: <fpage>8965</fpage>–<lpage>8976</lpage>, <year>2009</year>.</mixed-citation></ref>
<ref id="c73"><mixed-citation publication-type="journal"><string-name><surname>Verharen</surname> <given-names>JP</given-names></string-name>, <string-name><surname>den Ouden</surname> <given-names>HE</given-names></string-name>, <string-name><surname>Adan</surname> <given-names>RA</given-names></string-name>, <string-name><surname>Vanderschuren</surname> <given-names>LJ</given-names></string-name>. <article-title>Modulation of value-based decision making behavior by subregions of the rat prefrontal cortex</article-title>. <source>Psychopharmacology</source> <volume>237</volume>: <fpage>1267</fpage>–<lpage>1280</lpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c74"><mixed-citation publication-type="journal"><string-name><surname>Wang</surname> <given-names>PY</given-names></string-name>, <string-name><surname>Boboila</surname> <given-names>C</given-names></string-name>, <string-name><surname>Chin</surname> <given-names>M</given-names></string-name>, <string-name><surname>Higashi-Howard</surname> <given-names>A</given-names></string-name>, <string-name><surname>Shamash</surname> <given-names>P</given-names></string-name>, <string-name><surname>Wu</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Stein</surname> <given-names>NP</given-names></string-name>, <string-name><surname>Abbott</surname> <given-names>L</given-names></string-name>, <string-name><surname>Axel</surname> <given-names>R</given-names></string-name>. <article-title>Transient and persistent representations of odor value in prefrontal cortex</article-title>. <source>Neuron</source> <volume>108</volume>: <fpage>209</fpage>–<lpage>224</lpage>, <year>2020a</year>.</mixed-citation></ref>
<ref id="c75"><mixed-citation publication-type="journal"><string-name><surname>Wang</surname> <given-names>Q</given-names></string-name>, <string-name><surname>Ding</surname> <given-names>SL</given-names></string-name>, <string-name><surname>Li</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Royall</surname> <given-names>J</given-names></string-name>, <string-name><surname>Feng</surname> <given-names>D</given-names></string-name>, <string-name><surname>Lesnar</surname> <given-names>P</given-names></string-name>, <string-name><surname>Graddis</surname> <given-names>N</given-names></string-name>, <string-name><surname>Naeemi</surname> <given-names>M</given-names></string-name>, <string-name><surname>Facer</surname> <given-names>B</given-names></string-name>, <string-name><surname>Ho</surname> <given-names>A</given-names></string-name>, <etal>et al.</etal> <article-title>The Allen mouse brain common coordinate framework: a 3D reference atlas</article-title>. <source>Cell</source> <volume>181</volume>: <fpage>936</fpage>–<lpage>953</lpage>, <year>2020b</year>.</mixed-citation></ref>
<ref id="c76"><mixed-citation publication-type="journal"><string-name><surname>Winkelmeier</surname> <given-names>L</given-names></string-name>, <string-name><surname>Filosa</surname> <given-names>C</given-names></string-name>, <string-name><surname>Hartig</surname> <given-names>R</given-names></string-name>, <string-name><surname>Scheller</surname> <given-names>M</given-names></string-name>, <string-name><surname>Sack</surname> <given-names>M</given-names></string-name>, <string-name><surname>Reinwald</surname> <given-names>JR</given-names></string-name>, <string-name><surname>Becker</surname> <given-names>R</given-names></string-name>, <string-name><surname>Wolf</surname> <given-names>D</given-names></string-name>, <string-name><surname>Gerchen</surname> <given-names>MF</given-names></string-name>, <string-name><surname>Sartorius</surname> <given-names>A</given-names></string-name>, <etal>et al.</etal> <article-title>Striatal hub of dynamic and stabilized prediction coding in forebrain networks for olfactory reinforcement learning</article-title>. <source>Nature Communications</source> <volume>13</volume>: <fpage>1</fpage>–<lpage>21</lpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c77"><mixed-citation publication-type="journal"><string-name><surname>Zagha</surname> <given-names>E</given-names></string-name>, <string-name><surname>Erlich</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Lee</surname> <given-names>S</given-names></string-name>, <string-name><surname>Lur</surname> <given-names>G</given-names></string-name>, <string-name><surname>O’Connor</surname> <given-names>DH</given-names></string-name>, <string-name><surname>Steinmetz</surname> <given-names>NA</given-names></string-name>, <string-name><surname>Stringer</surname> <given-names>C</given-names></string-name>, <string-name><surname>Yang</surname> <given-names>H</given-names></string-name>. <article-title>The importance of accounting for movement when relating neuronal activity to sensory and cognitive processes</article-title>. <source>Journal of Neuroscience</source> <volume>42</volume>: <fpage>1375</fpage>–<lpage>1382</lpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c78"><mixed-citation publication-type="journal"><string-name><surname>Zhou</surname> <given-names>J</given-names></string-name>, <string-name><surname>Gardner</surname> <given-names>MP</given-names></string-name>, <string-name><surname>Schoenbaum</surname> <given-names>G</given-names></string-name>. <article-title>Is the core function of orbitofrontal cortex to signal values or make predictions?</article-title> <source>Current Opinion in Behavioral Sciences</source> <volume>41</volume>: <fpage>1</fpage>–<lpage>9</lpage>, <year>2021</year>.</mixed-citation></ref>
</ref-list>
<sec>
<fig id="figS1" position="float" orientation="portrait" fig-type="figure">
<label>Figure S1.</label>
<caption><title>Anticipatory licking during the electrophysiology sessions.</title>
<p>(A) Mean anticipatory licks (change from baseline) for the CS+ and CS50 from odor set 1 (left) and 2 (right) for every session, color-coded by mouse. <italic>F</italic> (1, 66) = 32.07 and <italic>F</italic> (1, 66) = 26.93 in each odor set for a main effect of cue in a two-way ANOVA including an effect of subject.</p>
<p>(B) As above, for the CS+ and CS− from odor set 1 (left) and 2 (right). <italic>F</italic> (1, 66) = 433.1 and <italic>F</italic> (1, 66) = 574.6 in each odor set for a main effect of cue in a two-way ANOVA including an effect of subject.</p>
<p>(C) As above, for the CS50 and CS− from odor set 1 (left) and 2 (right). <italic>F</italic> (1, 66) = 252.3 and <italic>F</italic> (1, 66) = 450.1 in each odor set for a main effect of cue in a two-way ANOVA including an effect of subject.</p></caption>
<graphic xlink:href="499930v2_figS1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS2" position="float" orientation="portrait" fig-type="figure">
<label>Figure S2.</label>
<caption><title>Similar neural activity in prelimbic area using electrophysiology and imaging.</title>
<p>(A) Heatmap of the normalized activity of each neuron recorded with electrophysiology in PL, aligned to each of the 6 odors. All columns sorted by mean firing 0 - 1.5 s following odor onset for odor set 1 CS+ trials.</p>
<p>(B) As in (A), for all neurons imaged in PL on day 3 of each odor set.</p>
<p>(C) The score from the first 4 principal components of the normalized activity presented in (A), with variance explained in parentheses.</p>
<p>(D) As in (C), for the activity in (B).</p></caption>
<graphic xlink:href="499930v2_figS2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS3" position="float" orientation="portrait" fig-type="figure">
<label>Figure S3.</label>
<caption><title>Task-related neural activity across brain regions.</title>
<p>(A) For each of the 5 mice in the electrophysiology experiment, the number of neurons recorded in each region.</p>
<p>(B) Heatmap of the normalized activity of each neuron (<italic>n</italic> = 51 trials per cue). All columns sorted by region and then by mean firing 0 - 1.5 s following odor onset for odor set 1 CS+ trials.</p>
<p>(C) Mean (+/− SEM) activity of neurons from 4 regions aligned to each cue type, grouped by whether peak cue activity (0 - 2.5 s) was above (top) or below (bottom) baseline in held out trials.</p></caption>
<graphic xlink:href="499930v2_figS3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS4" position="float" orientation="portrait" fig-type="figure">
<label>Figure S4.</label>
<caption><title>Identification of cue and lick cells with GLM.</title>
<p>(A) Mean variance explained (fraction) by linear models in each region for each session (x) and the mean (+/− SEM) across those sessions.</p>
<p>(B) Mean (+/− SEM) activity of neurons encoding cues, licks, both, or neither aligned to each cue type, grouped by whether peak cue activity (0 - 2.5 s) was above (top) or below (bottom) baseline in held out trials.</p>
<p>(C) Normalized activity of every neuron encoding cues, licks, or both, aligned to CS+ onset, sorted by mean firing 0 - 1.5 s following odor onset.</p>
<p>(D) Mean (+/− SEM) activity of neurons encoding cues or licks, grouped as in (B), on CS50 trials, divided into rewarded (lighter colors) or unrewarded (darker colors) trials.</p></caption>
<graphic xlink:href="499930v2_figS4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS5" position="float" orientation="portrait" fig-type="figure">
<label>Figure S5.</label>
<caption><title>Comparing proportions of cue and lick neurons across regions.</title>
<p>(A) Fraction of neurons in each region classified as coding cues (left), licks (middle), or both (right), as well as estimated fraction(+/−95% CI) with random effect of session (see Methods).</p>
<p>(B) Additional cue/lick/both cells in region on Y-axis compared to region on X-axis as a fraction of all neurons, for regions with non-overlapping 95% confidence intervals.</p>
<p>(C) As in (A), for region groups.</p>
<p>(D) As in (B), for region groups.</p></caption>
<graphic xlink:href="499930v2_figS5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS6" position="float" orientation="portrait" fig-type="figure">
<label>Figure S6.</label>
<caption><title>Schematic of value model shuffles.</title>
<p>(A) For each of the 90 permutations of the Value model, the value taken on by the variable cue kernel on trials corresponding to each of the 6 cue types. Value is determined in units of predicted anticipatory licks, from 0 to 1 (maximum number of anticipatory licks made). Additionally, there is an Untuned model, where all cues take on the same value.</p></caption>
<graphic xlink:href="499930v2_figS6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS7" position="float" orientation="portrait" fig-type="figure">
<label>Figure S7.</label>
<caption><title>Additional analysis of odor coding schemes.</title>
<p>(A) Normalized activity of every value neuron, sorted by mean firing 0 - 1.5 s following odor set 1 CS+ onset.</p>
<p>(B) Normalized activity of every trial type neuron, sorted by model and then by mean firing 0 - 1.5 s following odor set 1 CS+ onset.</p>
<p>(C) Projecting the activity of all trial type and value cells onto the coding dimensions maximally separating CS− and CS+ (x-axis) and CS− and CS50 (y-axis). Solid line is activity during cue, dashed line is activity following reward delivery. X marks baseline activity.</p>
<p>(D) For the odor set 1 projection, distribution of 5000 bootstrapped distances between baseline activity (prior to odor onset) and the CS− representation (0, 0). Value cells were closer to CS− at baseline than trial type cells.</p>
<p>(E) For the odor set 1 projection, distribution of 5000 bootstrapped angles between CS+ and CS50 vectors (baseline to peak). Value cells had a smaller angle than trial type cells.</p></caption>
<graphic xlink:href="499930v2_figS7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS8" position="float" orientation="portrait" fig-type="figure">
<label>Figure S8.</label>
<caption><title>Relative proportions of value and trial type cells across regions.</title>
<p>(A) Additional cue value (left) or trial type (right) neurons in region on Y-axis compared to region on X-axis as a fraction of all neurons, for regions with non-overlapping 95% confidence intervals.</p>
<p>(B) As in (A), for region groups.</p></caption>
<graphic xlink:href="499930v2_figS8.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS9" position="float" orientation="portrait" fig-type="figure">
<label>Figure S9.</label>
<caption><title>Value coding as a proportion of cue cells.</title>
<p>(A) Fraction of cue neurons in each region classified as coding value (left) or trial type (right), as well as estimated fraction(+/−95% CI) with random effect of session (see Methods).</p>
<p>(B) Additional value/trial type cue neurons in region on Y-axis compared to region on X-axis as a fraction of all cue neurons, for regions with non-overlapping 95% confidence intervals.</p>
<p>(C) As in (A), for region groups.</p>
<p>(D) As in (B), for region groups.</p></caption>
<graphic xlink:href="499930v2_figS9.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS10" position="float" orientation="portrait" fig-type="figure">
<label>Figure S10.</label>
<caption><title>Comparing PFC and striatum.</title>
<p>(A) Fraction of neurons in each region and region group classified as coding cues (left), licks (middle), or both (right), as well as estimated fraction(+/−95% CI) with random effect of session (see Methods).</p>
<p>(B) Fraction of neurons in each region and region group classified as coding value (left) or trial type (right), as well as estimated fraction(+/−95% CI) with random effect of session. Light gray bars are remaining cue neurons not in that category.</p></caption>
<graphic xlink:href="499930v2_figS10.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.84604.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Eisen</surname>
<given-names>Michael B</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of California, Berkeley</institution>
</institution-wrap>
<city>Berkeley</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study makes <bold>valuable</bold> observations about the representation of &quot;value&quot; in the mouse brain by using a nice task design and recording from an impressive number of brain regions. The combination of state-of-the-art imaging and electrophysiology data offer <bold>solid</bold> support for the authors' conclusions. If more thorough statistical analysis of the response of neuronal populations supports the claims, the paper will be of interest to a broad audience of neuroscientists interested in reward processing in the brain.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.84604.1.sa1</article-id>
<title-group>
<article-title>Consensus Public Review:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Ottenheimer et al., present an interesting study looking at the neural representation of value in mice performing a pavlovian association task. The task is repeated in the same animals using two odor sets, allowing a distinction between odor identity coding and value coding. The authors use state-of-the-art electrophysiological techniques to record thousands of neurons from 11 frontal cortical regions to conclude that 1) licking is represented more strongly in dorsal frontal regions, 2) odor cues are represented more strongly in ventral frontal regions, 3) cue values are evenly distributed across regions. They separately perform a calcium imaging study to track coding across days and conclude that the representation of task features increments with learning and remains stable thereafter.</p>
<p>Overall, these conclusions are interesting and mostly well supported by the data, although there are some doubts about their definition of value coding. One limitation is the lack of focus on population-level dynamics from the perspective of decoding, with the analysis focusing primarily on encoding analyses within individual neurons.</p>
<p>Some specific comments:</p>
<p>The authors use reduced-rank kernel regression to characterize the 5332 recorded neurons on a cell-by-cell basis in terms of their responses to cues, licks, and reward, with a cell characterized as encoding one of these parameters if it accounts for at least 2% of the observed variance. At least 50% of cells met this inclusion criterion in each recorded area. 2% feels like a lenient cutoff, and it is unclear how sensitive the results are to this cutoff, though the authors argue that this cutoff should still only allow a false positive rate of 0.02% (determined by randomly shuffling the onset time of each trial).</p>
<p>Having identified lick, reward, and cue cells, the authors next select the 24% of &quot;cue-only&quot; neurons and look for cells that specifically encode cue value. Because the animal's perception of stimulus value can't be measured directly, the authors created a linear model that predicts the amount of anticipatory licking in the interval between odor cue and reward presentations. The session-average-predicted lick rate by this model is used as an estimate of cue value and is used in the regression analysis that identified value cells. (Hence, the authors' definition of value is dependent on the average amount of anticipatory behavior ahead of a reward, which indicates that compared to the CS+, mice licked around 70% as much to the CS50 and 10% as much to the CS-.) The claim that this is an encoding of value is strengthened by the fact that cells show similar scaling of responses to two odor sets tested. Whereas the authors found more &quot;lick&quot; cells in motor regions and more &quot;cue&quot; cells in sensory regions, they find a consistent percentage of &quot;value&quot; cells (that is, cells found to be cue-only in the initial round of analysis that is subsequently found to encode anticipatory lick rate) across all 11 recorded regions, leading to their claim of a distributed code of value.</p>
<p>In subsequent sections, the authors expand their model of anticipatory-licking-as-value by incorporating trial and stimulus history terms into the model, allowing them to predict the anticipatory lick rate on individual trials within a session. They also use 2-photon imaging in PFC to demonstrate that neural coding of cue and lick are stable across three days of imaging, supported by two lines of evidence. First, they show that the correlation between cell responses on all periods except for the start of day 1 is more correlated with day 3 responses than expected by chance (although the correlation is still quite low, for example, 0.2 on day 2). Second, they show that cue identity is able to capture the highest unique fraction of variance (around 8%) in day 3 cue cells across three days of imaging, and similarly for lick behavior in lick cells and cue+lick in cue+lick cells. Nonetheless, their sample rasters for all imaged cells also indicate that representations are not perfectly stable, and it will be interesting to see what *does* change across the three days of imaging.</p>
<p>Importantly, the authors do not present evidence that value itself is stably encoded across days, despite the paper's title. The more conservative in its claims in the Discussion seems more appropriate: &quot;these results demonstrate a lack of regional specialization in value coding and the stability of cue and lick [(not value)] codes in PFC.&quot;</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.84604.1.sa0</article-id>
<title-group>
<article-title>Author Response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Ottenheimer</surname>
<given-names>David J.</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4882-1898</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Hjort</surname>
<given-names>Madelyn M.</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9932-2349</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Bowen</surname>
<given-names>Anna J.</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8911-2572</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Steinmetz</surname>
<given-names>Nicholas A.</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7029-2908</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Stuber</surname>
<given-names>Garret D.</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1730-4855</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>We thank the eLife editorial board and the reviewers for the assessment of our article. We look forward to thoroughly addressing their comments and concerns. We would like to correct one factual error in the consensus public review:</p>
<disp-quote content-type="editor-comment">
<p>“Importantly, the authors do not present evidence that value itself is stably encoded across days, despite the paper's title. The more conservative in its claims in the Discussion seems more appropriate: &quot;these results demonstrate a lack of regional specialization in value coding and the stability of cue and lick [(not value)] codes in PFC.&quot;</p>
</disp-quote>
<p>The imaging sessions in which we identify value coding cells were in fact performed on separate days: Experimental Days 6 and 7 (see Figure 1b), which is evidence of the stability of value coding across consecutive days. Days 6 and 7 correspond to the third day of Odor Set 1 and the third day of Odor Set 2, respectively, which is why we referred to them both as “Day 3” in the manuscript, and this may have led to the confusion about the temporal relationship between these sessions. We will clarify this terminology in the revised manuscript.</p>
</body>
</sub-article>
</article>