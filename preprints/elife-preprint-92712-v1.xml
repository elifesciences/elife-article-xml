<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">92712</article-id>
<article-id pub-id-type="doi">10.7554/eLife.92712</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.92712.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Predictive learning rules generate a cortical-like replay of probabilistic sensory experiences</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0951-5791</contrib-id>
<name>
<surname>Asabuki</surname>
<given-names>Toshitake</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6977-5638</contrib-id>
<name>
<surname>Fukai</surname>
<given-names>Tomoki</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Okinawa Institute of Science and Technology Graduate University</institution>, <city>Okinawa</city>, <country>Japan</country></aff>
<aff id="a2"><label>2</label><institution>RIKEN Center for Brain Science, RIKEN ECL Research Unit</institution>, <country>Japan</country></aff>
<aff id="a3"><label>3</label><institution>RIKEN Cluster for Pioneering Research</institution>, <country>Japan</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Poirazi</surname>
<given-names>Panayiota</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>FORTH Institute of Molecular Biology and Biotechnology</institution>
</institution-wrap>
<city>Heraklion</city>
<country>Greece</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Poirazi</surname>
<given-names>Panayiota</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>FORTH Institute of Molecular Biology and Biotechnology</institution>
</institution-wrap>
<city>Heraklion</city>
<country>Greece</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>Correspondence to: <email>tomoki.fukai@oist.jp</email> (T.F.); <email>toshitake.asabuki@riken.jp</email> (T.A.)</corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-08-07">
<day>07</day>
<month>08</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP92712</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-03-11">
<day>11</day>
<month>03</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-07-29">
<day>29</day>
<month>07</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.02.17.528958"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Asabuki &amp; Fukai</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Asabuki &amp; Fukai</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-92712-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>The brain is thought to construct an optimal internal model representing the probabilistic structure of the environment accurately. Evidence suggests that spontaneous brain activity gives such a model by cycling through activity patterns evoked by previous sensory experiences with the experienced probabilities. The brain’s spontaneous activity emerges from internally-driven neural population dynamics. However, how cortical neural networks encode internal models into spontaneous activity is poorly understood. Recent computational and experimental studies suggest that a cortical neuron can implement complex computations, including predictive responses, through soma-dendrite interactions. Here, we show that a recurrent network of spiking neurons subject to the same predictive learning principle provides a novel mechanism to learn the spontaneous replay of probabilistic sensory experiences. In this network, the learning rules minimize probability mismatches between stimulus-evoked and internally driven activities in all excitatory and inhibitory neurons. This learning paradigm generates stimulus-specific cell assemblies that internally remember their activation probabilities using within-assembly recurrent connections. The plasticity of cells’ intrinsic excitabilities normalizes neurons’ dynamic ranges to further improve the accuracy of probability coding. Our model contrasts previous models that encode the statistical structure of sensory experiences into Markovian transition patterns among cell assemblies. We demonstrate that the spontaneous activity of our model well replicates the behavioral biases of monkeys performing perceptual decision making. Our results suggest that interactions between intracellular processes and recurrent network dynamics are more crucial for learning cognitive behaviors than previously thought.</p>
</abstract>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>The title was changed and additional results were included</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>The brain is believed to construct an internal statistical model of an uncertain environment from sensory information streams for predicting the external events that are likely to occur. Evidence suggests that spontaneous brain activity learns the representation of such a model through repeated experiences of sensory events. In the cat visual cortex, spontaneously emerging activity patterns cycle through cortical states that include neural response patterns to oriented bars (<xref ref-type="bibr" rid="c38">Kenet et al., 2003</xref>). In the ferret visual cortex, spontaneous activity gradually resembles a superposition of activity patterns evoked by natural scenes, eventually giving an optimal model of the visual experience (<xref ref-type="bibr" rid="c6">Berkes et al., 2011</xref>). As replay activities can provide prior information for hierarchical Bayesian computation by the brain (<xref ref-type="bibr" rid="c13">Ernst &amp; Banks, 2002</xref>; <xref ref-type="bibr" rid="c41">Kording &amp; Wolpert, 2004</xref>; <xref ref-type="bibr" rid="c16">Friston, 2010</xref>; <xref ref-type="bibr" rid="c14">Fiser et al., 2010</xref>; <xref ref-type="bibr" rid="c5">Bastos et al., 2012</xref>; <xref ref-type="bibr" rid="c53">Orban et al., 2016</xref>; <xref ref-type="bibr" rid="c42">Legaspi &amp; Toyoizumi, 2019</xref>), clarifying how the brain learns the spontaneous replay of optimal internal models is crucial for understanding whole-brain computing. However, the neural mechanisms underlying this modeling process are only poorly understood.</p>
<p>Several mechanisms of the brain’s probabilistic computation have been explored (<xref ref-type="bibr" rid="c31">Jimenez Rezende &amp; Gerstner, 2014</xref>; <xref ref-type="bibr" rid="c43">Li et al., 2022</xref>). Models with reverberating activity are particularly interesting owing to their potential ability to generate spontaneous activity. For instance, spiking neuron networks with symmetric recurrent connections were proposed for Markov Chain Monte Carlo sampling of stochastic events (<xref ref-type="bibr" rid="c8">Buesing et al, 2011</xref>; <xref ref-type="bibr" rid="c7">Bill et al., 2015</xref>). Spike-timing-dependent plasticity was used to organize spontaneous sequential activity patterns, providing a predictive model of sequence input (<xref ref-type="bibr" rid="c24">Hartmann et al., 2015</xref>). However, previous models did not clarify how recurrent neural networks learn the spontaneous replay of the probabilistic structure of sensory experiences, for which these networks should learn the accurate probabilities of sensory stimuli and an appropriate excitation-inhibition balance simultaneously. Moreover, previous models assumed that each statistically salient stimulus in temporal input is already segregated and is delivered to a pre-assigned assembly of coding neurons, implying that the recurrent network, at least partly, knows the stochastic events to be modeled before learning. How the brain extracts salient events for statistical modeling has not been addressed.</p>
<p>Here, we present a learning principle to encode the experiences’ probability structure into spontaneous network activity. To this end, we extensively use the synaptic plasticity rule proposed previously based on the hypothesis that the dendrites of a cortical neuron learn to predict its somatic responses (<xref ref-type="bibr" rid="c67">Urbanczik &amp; Senn, 2014</xref>; <xref ref-type="bibr" rid="c2">Asabuki &amp; Fukai, 2020</xref>). We generalize the hypothetical predictive learning to a learning principle at the entire network level. Namely, in a recurrent network driven by external input, we ask all synapses on the dendrites of each excitatory or inhibitory neuron to learn to predict its somatic responses (although the dendrites will not be explicitly modeled). This enables the network model to simultaneously learn the events’ probabilistic structure and the excitation-inhibition balance required to replay this structure. Further, our network model requires no pre-assigned cell assemblies since the model neuron can automatically segment statistically salient events in temporal input (<xref ref-type="bibr" rid="c2">Asabuki &amp; Fukai, 2020</xref>) - a cognitive process known as “chunking” (<xref ref-type="bibr" rid="c18">Fujii &amp; Graybiel, 2003</xref>; <xref ref-type="bibr" rid="c32">Jin &amp; Costa, 2010</xref>; <xref ref-type="bibr" rid="c33">Jin et al., 2014</xref>; <xref ref-type="bibr" rid="c59">Schapiro et al., 2013</xref>; <xref ref-type="bibr" rid="c70">Zacks et al., 2001</xref>). Intriguingly, the cell assemblies generated by our model store their replay probabilities primarily in the within-assembly network structure, and intrinsic dynamical properties of membership neurons also contribute to this coding. This is in striking contrast to other network models that encode probabilities into the Markovian transition dynamics among cell assemblies (<xref ref-type="bibr" rid="c8">Buesing et al., 2011</xref>; <xref ref-type="bibr" rid="c24">Hartmann et al., 2015</xref>).</p>
<p>Our model trained on a perceptual decision-making task can replicate both unbiased and biased decision behaviors of monkeys without fine-tuning of parameters (<xref ref-type="bibr" rid="c23">Hanks et al., 2011</xref>). In addition, in a network model consisting of distinct excitatory and inhibitory neural populations, our learning rule predicts the emergence of two types of inhibitory connections with different computational roles. We show that the emergence of the two inhibitory connection types is crucial for robust learning of an optimal internal model.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Replay of probabilistic sensory experiences - A toy example</title>
<p>We first explain the task our model solves with a toy example. Consider a task in which the animal should decide whether a given stimulus coincides with or resembles any of two previously learned stimuli. Whether the animal learned these stimuli with a 50-50 chance or a 30-70 chance should affect the animal’s anticipation of their occurrence and hence affect its decision.</p>
<p>It has been suggested that spontaneous activity expresses an optimal internal model of the sensory environment (<xref ref-type="bibr" rid="c6">Berkes et al., 2011</xref>). In our toy example, the evoked activity patterns of the two stimuli should be spontaneously replayed with the same probabilities as these stimuli were experienced during learning:
<disp-formula id="ueqn1">
<graphic xlink:href="528958v2_ueqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where features = {stimulus 1, stimulus 2} and the right-hand side expresses the probabilities of replayed activities. The angular brackets indicate averaging over the stimuli. According to Hebb’s hypothesis, two cell assemblies should be formed to memorize the two stimuli in the toy example. Moreover, the spontaneous replay of these cell assemblies should represent the probabilities given in the right-hand side of the above equation. Below, we propose a mathematical principle of learning to achieve these requirements.</p>
</sec>
<sec id="s2b">
<title>Prediction-driven synaptic plasticity for encoding an internal model</title>
<p>We previously proposed a learning rule for a single two-compartment neuron (<xref ref-type="bibr" rid="c2">Asabuki &amp; Fukai, 2020</xref>). Briefly, our previous model learns statistically salient features repeated in input sequences by minimizing the error between somatic and dendritic response probabilities without external supervision to identify the temporal locations of these features. In this study, we extend this plasticity rule to recurrent networks by asking all neurons in a network to minimize the error in response probabilities between the internally generated and stimulus-evoked activities (<xref rid="fig1" ref-type="fig">Fig. 1</xref>). Our central interest is whether this learning principle generates spontaneous activity representing the statistical model of previous experiences.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Unsupervised prior learning in a recurrent neural network.</title>
<p>(a) A schematic of a network model is shown. The interconnected circles denote the model neurons, of which the activities are controlled by two types of inputs: feedforward (FF) and recurrent (REC) inputs. Colored circles indicate active neurons. Here, <bold>W</bold> denotes FF, and <bold>M</bold> and <bold>G</bold> denote REC connections. We considered two modes of activity (i.e., evoked and spontaneous activity). In the evoked mode, the membrane potential u of a network neuron was calculated as a linear combination of inputs across all different connections (v<sup>W</sup>, v<sup>M</sup>, and v<sup>G</sup>). This evoked mode is considered during the learning phase, when all synapses attempt to predict the network activity, as we will explain in the main text. Once all synapses are sufficiently learned, all FF inputs are removed, and the network is driven spontaneously (spontaneous mode). Our interest lies in the statistical similarity of the network activity in these two modes. (b) The gain and threshold of output response function was controlled by a dynamic variable, h, which tracks the history of the membrane potential. (c) A schematic of the learning rule for a network neuron is shown (top). During learning, for each type of connection on a postsynaptic neuron, synaptic plasticity minimizes the error between output (gray diamond) and synaptic prediction (colored diamonds). Note that all types of synapses share the common plasticity rule, where weight updates are calculated as the multiplication of the error term and the presynaptic activities (bottom). Our hypothesis is that such plasticity rule allows a recurrent neural network to spontaneously replay the learned stochastic activity patterns without external input.</p></caption>
<graphic xlink:href="528958v2_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We first introduce our learning principle using a recurrent network model (nDL model) that does not obey Dale’s law for distinguishing between excitatory and inhibitory neurons (Materials and Methods). A more realistic model with distinct excitatory and inhibitory neuron pools will be shown later. The nDL model consists of Poisson spiking neurons, each receiving Poisson spike trains from all input neurons via a modifiable all-to-all afferent feedforward (FF) connection matrix <bold>W</bold> (<xref rid="fig1" ref-type="fig">Fig. 1a</xref>). These input neurons may be grouped into multiple input neuron groups responding to different sensory features. Due to the all-to-all connectivity, the afferent input has no specific predefined structure. Two types of all-to-all modifiable recurrent connections (REC), <bold>M</bold> and <bold>G</bold>, exist among the neurons. Matrix <bold>M</bold> is a mixture of excitatory and inhibitory connections, and matrix <bold>G</bold> represents inhibitory-only connections. Due to a minus sign for V<sup>G</sup>, all components of <bold>G</bold> are positive. The firing rate of neurons are defined as a modifiable sigmoidal function of the membrane potential (<xref rid="fig1" ref-type="fig">Fig.1b</xref>), which we will explain later in detail. All types of connections, both afferent and recurrent ones, are modifiable by unsupervised learning rules derived from a common principle: on each neuron, all synapses learn to predict the neuron’s response optimally (<xref rid="fig1" ref-type="fig">Fig. 1c</xref>: see Materials and Methods). In reality, all synaptic inputs may be terminated on the dendrites, although they are not modeled explicitly.</p>
<p>Without a teaching signal, predictive learning may suffer a trivial solution problem in which all synapses vanish, and hence all neurons become silent (<xref ref-type="bibr" rid="c2">Asabuki &amp; Fukai, 2020</xref>). To avoid it, we homeostatically regulate the dynamic range of each neuron (i.e., the slope and threshold of the response function) according to the history <italic>h</italic> of its subthreshold activity (see <xref ref-type="disp-formula" rid="eqn10">Eqs. 10</xref>-<xref ref-type="disp-formula" rid="eqn12">12</xref>). When the value of <italic>h</italic> is increased, the neuron’s excitability is lowered (<xref rid="fig1" ref-type="fig">Fig.1b</xref>). The input-output curves of neurons are known to undergo homeostatic regulations through various mechanisms (<xref ref-type="bibr" rid="c9">Chance et al., 2002</xref>; <xref ref-type="bibr" rid="c49">Mitchell and Silver, 2003</xref>; <xref ref-type="bibr" rid="c64">Torres-Torrelo et al., 2014</xref>). Though no direct experimental evidence is available for our homeostatic process via <italic>h</italic>, it mathematically avoids saturating neuronal activity.</p>
<p>Note that the present homeostatic regulation of intrinsic excitability differs from the homeostatic synaptic scaling mechanism. The role of homeostatic synaptic scaling in generating irregular cell-assembly activity patterns was previously studied computationally (<xref ref-type="bibr" rid="c26">Hiratani and Fukai, 2014</xref>; <xref ref-type="bibr" rid="c44">Litwin-Kumar and Doiron, 2014</xref>; <xref ref-type="bibr" rid="c71">Zenke et al., 2015</xref>). However, unlike the present model, the previous models did not address whether and how synaptic scaling contributes to statistical modeling by recurrent neural networks. Furthermore, unlike our model, in which neurons in the recurrent layer and input neurons are initially connected in an all-to-all manner, most previous models assumed preconfigured receptive fields for recurrent-layer neurons, implying that these models had predefined stimulus-specific cell assemblies.</p>
</sec>
<sec id="s2c">
<title>Cell assembly formation for learning statistically salient stimuli</title>
<p>We first explain how our network segments salient stimuli and forms stimulus-specific cell assemblies via network-wide predictive learning rules. To this end, we tested a simple case in which two non-overlapping input groups are intermittently and repeatedly activated with equal probabilities. The two input patterns were separated by irregular, low-frequency, unrepeated spike trains of all input neurons (Materials and Methods). We will consider input patterns with unequal occurrence probabilities later. After several presentations of individual input patterns, each network neuron responded selectively to one of the repeated patterns (<xref rid="fig2" ref-type="fig">Figure 2a</xref>). This result is consistent with our previous results (<xref ref-type="bibr" rid="c2">Asabuki &amp; Fukai, 2020</xref>) that the plasticity of feedforward connections segments input patterns. Indeed, feedforward synapses W on each neuron were strengthened or weakened when they mediated its preferred or non-preferred stimulus, respectively (<xref rid="fig2" ref-type="fig">Fig. 2b</xref>, left; <xref rid="fig2" ref-type="fig">Fig. 2c</xref>). Inhibitory connections G grew between neurons within the same assembly but not between assemblies (<xref rid="fig2" ref-type="fig">Fig. 2b</xref>, right; <xref rid="fig2" ref-type="fig">Fig. 2c</xref>, bottom), enhancing the decorrelation of within-assembly neural activities (<xref ref-type="bibr" rid="c2">Asabuki &amp; Fukai, 2020</xref>). Recurrent connections M were modified to form stimulus-specific cell assemblies, as evidenced by the self-organization of excitatory (<xref rid="fig2" ref-type="fig">Fig. 2c</xref>, top) and inhibitory (<xref rid="fig2" ref-type="fig">Fig. 2c</xref>, bottom) recurrent connections within and between cell assemblies, respectively. The inhibitory components are necessary for suppressing the simultaneous replay of different cell assemblies, as shown later.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Formation of stimulus-selective assemblies in a recurrent network.</title>
<p>(a) Example dynamics of neuronal output and synaptic predictions are shown before (left) and after (right) learning. Colored bars at the top of the figures represent periods of stimulus presentations. (b) Example dynamics of feedforward connection W and inhibitory connection G are shown. W-connections onto neurons organizing to encode the same or different input patterns are shown in red and blue, respectively. Similarly, the same colors are used to represent G connections within and between assemblies. (c) Dynamics of the mean connection strengths are shown on neuron in cell assembly 1. Shaded areas represent SDs. In the schematic, triangles indicate input neurons and circles indicate network neurons. The color of each neuron indicates the stimulus preference of each neuron. (d) Example dynamics of the averaged dynamical variable <inline-formula><inline-graphic xlink:href="528958v2_inline23.gif" mimetype="image" mime-subtype="gif"/></inline-formula> (top) and the learned network activity (bottom) are shown. The dynamical variables are averaged over the entire network. Neurons are sorted according to their preferred stimuli. During the spontaneous activity, afferent inputs to the network were removed. (e) Correlation coefficients of spontaneous activities of every pair of neurons are shown.</p></caption>
<graphic xlink:href="528958v2_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We then investigated whether and how spontaneous activity preserves and replays these cell assemblies in the absence of afferent input. To demonstrate this in a more complex task, we trained the network with afferent input involving five repeated patterns and then removed the input and observed post-training spontaneous network activity (<xref rid="fig2" ref-type="fig">Fig. 2d</xref>). The termination of afferent input initially lowered the activities of neurons, but their dynamic ranges gradually recovered with the excitability of the neural population (indicated by the population-averaged <italic>h</italic> value), and the network eventually started spontaneously replaying the learned cell assemblies. All plasticity rules were turned off during the recovery period (about 20 seconds from the input termination), after which the network settled in a stable spontaneous firing state (plasticity off). Then, the plasticity rules could be turned on (plasticity on) without drastically destroying the structure of spontaneous replay. Intriguingly, spontaneous neuronal activities were highly correlated within each cell assembly but were uncorrelated between different cell assemblies (<xref rid="fig2" ref-type="fig">Fig. 2e</xref>). This was because self-organized recurrent connections <bold>M</bold> were excitatory within each cell assembly, whereas the between-assembly recurrent connections were inhibitory, as in <xref rid="fig2" ref-type="fig">Fig. 2c</xref>.</p>
<p>Thus, the network model successfully segregates, remembers, and replays stimulus-evoked activity patterns in temporal input. The loss of between-assembly excitatory connections is interesting as it indicates that the present spontaneous reactivation is not due to the sequential activation of cell assemblies. This can also be seen from the relatively long intervals between consecutive cell-assembly activations: spontaneous neural activity does not propagate directly from one cell assembly to another (<xref rid="fig2" ref-type="fig">Fig. 2d</xref>). Indeed, within-assembly excitation is the major cause of spontaneous replay in this model, which we will study later in detail.</p>
<p>In summary, we have proposed the predictive learning rules as a novel plasticity mechanism for all types of synapses (i.e., feedforward and recurrent connections). We have shown that the plasticity rules in our model learn the segmentation of salient patterns in input sequences and form pattern-specific cell assemblies without preconfigured structures. We also showed that our model replays the learned assemblies even when external inputs were removed.</p>
</sec>
<sec id="s2d">
<title>Replays of cell assemblies reflect a learned statistical model</title>
<p>We now turn to the central question of this study. We asked whether internally generated network dynamics through recurrent synapses (i.e., spontaneous replay of cell assemblies) can represent an optimal model of previous sensory experiences. Specifically, we examined whether the network spontaneously reactivates learned cell assemblies with relative frequencies proportional to the probabilities with which external stimuli activated these cell assemblies during learning. We addressed these questions in slightly more complex cases with increased numbers of external stimuli.</p>
<p>We first examined a case with five stimuli in which stimulus 1 was presented twice as often as the other four stimuli (<xref rid="fig3" ref-type="fig">Fig. 3a</xref>). Hereafter, the probability ratio refers to the relative number of times stimulus 1 is presented during learning. For instance, the case shown in <xref rid="fig2" ref-type="fig">Fig. 2d</xref> represents the probability ratio one. As in <xref rid="fig2" ref-type="fig">Fig. 2d</xref>, the network self-organized five cell assemblies to encode stimuli 1 to 5 and replayed all of them in subsequent spontaneous activity (<xref rid="fig3" ref-type="fig">Fig. 3b</xref>). We found that output neurons were activated more frequently and strongly in cell assembly 1 than in other cell assemblies. Therefore, we accessed quantitative differences in neuronal activity between different cell assemblies by varying the probability ratio. The neuronal firing rate of cell assembly 1 relative to other cell assemblies increased approximately linearly with an increase in the probability ratio (<xref rid="fig3" ref-type="fig">Fig. 3c</xref>). Similarly, the size of cell assembly 1 relative to other cell assemblies also increased with the probability ratio (<xref rid="fig3" ref-type="fig">Fig. 3d</xref>). However, neither the relative firing rate nor the relative assembly size faithfully reflects changes in the probability ratio: scaling the probability ratio with a multiplicative factor does not scale these quantities with this factor. Therefore, we further investigated whether the assembly activity ratio, the ratio in the total firing rate of cell assembly 1 to other cell assemblies (Materials and Methods), scales faithfully with the probability ratio of cell assembly 1. This was the case: the scaling was surprisingly accurate (<xref rid="fig3" ref-type="fig">Fig. 3e</xref>).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Priors coded in spontaneous activity.</title>
<p>An nDL network was trained with five probabilistic inputs. (a) Stimulus 1 appeared twice as often as the other four stimuli during learning. The example empirical probabilities of the stimuli used for learning are shown. (b) The spontaneous activity of the trained network shows distinct assembly structures. (c) The mean ratio of the population-averaged firing rate of assembly 1 to those of the other assemblies is shown for different values of the occurrence probability of stimulus 1. Vertical bars show SDs over five trials. A diagonal dashed line is a ground truth. (d) Similarly, the mean ratios of the size of assembly 1 to those of the other assemblies are shown. (e) The mean ratios of the total activities of neurons in assembly 1 to those of the other assemblies are shown. (f) Five stimuli occurring with different probabilities were used for training the nDL model. (g) The population firing rates are shown for five self-organized cell assemblies encoding the stimulus probabilities shown in (f).</p></caption>
<graphic xlink:href="528958v2_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To examine the ability of the nDL network further, we trained it with five stimuli occurring with various probabilities (<xref rid="fig3" ref-type="fig">Fig. 3f</xref> and Supplementary Fig. 1a). After learning, the spontaneous activity of the model replayed the learned cell assemblies at the desired ratios of population firing rates (<xref rid="fig3" ref-type="fig">Fig. 3g</xref> and Supplementary Fig. 1b).</p>
<p>We then asked whether our model would learn a prior distribution for more stimuli. To this end, we presented seven stimulus patterns to the same network with graded probabilities (Supplementary Fig. 1c). The self-organized spontaneous activity exhibited cell assemblies that well learned the graded probability distribution of these stimuli (Supplementary Fig. 1d). These results demonstrate that the trained network remembers the probabilities of repetitively experienced stimuli by the spontaneous firing rates of the encoding cell assemblies and that this dynamical coding scheme has a certain degree of scalability.</p>
<p>So far, we have represented external stimuli with non-overlapping subgroups of input neurons. However, in biologically realistic situations, input neuron groups may share part of their membership neurons. We tested whether the proposed model could learn the probability structure of overlapping input patterns in a case where two input neuron groups shared half of their members. The two patterns were presented with probabilities of 30% and 70%, respectively (Supplementary Fig. 2a). After sufficient learning, the network model generated two assemblies that encoded the two stimuli without sharing the coding neurons (Supplementary Fig. 2b) and replayed these assemblies with frequencies proportional to the stimulus presentation probabilities (Supplementary Fig. 2c). The results look reasonable because each neuron in the network segments one of the stimulus patterns and recurrent connections within each non-overlapping assembly can encode the probability of its replay.</p>
<p>Altogether, these results suggest that our model spontaneously replays learned cell assemblies with relative frequencies proportional to the probability that each cell assembly was activated during the learning phase. We have shown that the population activities of assemblies, rather than the firing rates of individual neurons, encode the occurrence probabilities of stimulus patterns.</p>
</sec>
<sec id="s2e">
<title>Within-assembly recurrent connections encode probabilistic sensory experiences</title>
<p>To understand the mechanism underlying the statistical similarity between the evoked patterns and spontaneous activity, we then investigated whether and how biases in probabilistic sensory experiences influence the strengths of recurrent connections. To this end, we compared two cases in which two input patterns (stim 1 and stim 2) occurred with equal (50% vs. 50%) and different (30% vs. 70%) probabilities during learning (<xref rid="fig4" ref-type="fig">Fig. 4a</xref>). From the results shown in <xref rid="fig3" ref-type="fig">Fig. 3</xref>, we hypothesized that within-assembly learned connections should reflect the stimulus occurrence probabilities and hence the activation probabilities of the corresponding cell assemblies during spontaneous activity. Therefore, we calculated the total strengths of incoming recurrent synapses on each neuron within the individual cell assemblies (<xref rid="fig4" ref-type="fig">Fig. 4b</xref>). While the distributions of incoming synaptic strengths are similar between cell assemblies coding stimulus 1 and stimulus 2 in the 50-vs-50 case, they look different in the 30-vs-70 case (<xref rid="fig4" ref-type="fig">Fig. 4c</xref>).</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Probability encoding by learned within-assembly synapses.</title>
<p>(a) Two input stimuli were presented in two protocols: uniform (50% vs. 50%) or biased (30% vs. 70%). (b) The total incoming synaptic strength on each neuron was calculated within each cell assembly. (c) <italic>left</italic>, The distributions of incoming synaptic strength are shown for the learned assemblies in the 50-vs-50 case. <italic>right</italic>, Same as in the left figure, but in the 30-vs-70 case. (d) <italic>left</italic>, The empirical probabilities of stimuli 1 and 2 and the normalized excitatory incoming weights within assemblies are compared in the 50-vs-50 case. <italic>right</italic>, Same as in the left figure, but in the 30-vs-70 case.</p></caption>
<graphic xlink:href="528958v2_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Since incoming weights increased more significantly in the cell assembly activated by a more frequent stimulus (i.e., the assembly encoding stimulus 2 in the 30-vs-70 case), we expect that the degree of positive shifts in incoming weight distributions will reflect stimulus probabilities. To examine whether this is indeed the case, we computed the sum of total excitatory incoming weights (i.e., the sum of positive elements of M) over neurons belonging to each assembly after training. We then normalized these excitatory incoming weights over the two assemblies.</p>
<p>Interestingly, we found that the normalized excitatory incoming weights for the two assemblies well approximates the empirical probabilities of the two stimuli in both the 50-vs-50 and 30-vs-70 cases (<xref rid="fig4" ref-type="fig">Figure 4d</xref>). These analyses revealed that recurrent connections learned within assemblies encode biases in probabilistic sensory experiences.</p>
</sec>
<sec id="s2f">
<title>Roles of inhibitory plasticity for stabilizing cell assemblies</title>
<p>Experimental and computational results suggest that inhibitory synapses are more robust to spontaneous activity than excitatory synapses and are crucial for maintaining cortical circuit function (<xref ref-type="bibr" rid="c50">Mongillo et al., 2018</xref>). To see the crucial role of the inhibitory plasticity of G for cell assembly formation, we compared the spontaneously driven activities in the learned network between two cases, plastic inhibitory connection G versus fixed G, in the 30-vs-70 case. The results show that only a single, highly active assembly self-organizes for fixed inhibitory synapses (Supplementary Fig. 3a). In contrast, such winner-take-all dynamics do not emerge from plastic inhibitory synapses (Supplementary Fig. 3b), suggesting the crucial role of inhibitory plasticity in stabilizing spontaneous activity.</p>
<p>To further clarify the functional role of inhibitory plasticity in regulating spontaneous activity, we compared how the self-organized assembly structure of recurrent connections <bold>M</bold> evolves in the two simulation settings shown in Supplementary Fig. 4a. In the control model, we turned off the plasticity of <bold>G</bold> for a while after the cessation of external stimuli but again switched it on, as was previously in <xref rid="fig2" ref-type="fig">Fig. 2</xref>. The cell-assembly structure initially dissipated but eventually reached a well-defined equilibrium structure (Supplementary Fig. 4b, magenta). Consistent with this, the postsynaptic potentials mediated by connections <bold>M</bold> and <bold>G</bold> predicted the normalized firing rate of a postsynaptic excitatory neuron in the control model (Supplementary Fig. 4c). In striking contrast, the cell-assembly structure rapidly dissipated in the truncated model in which the G-plasticity was kept turned off after the cessation of external stimuli (Supplementary Fig. 4b, blue). Accordingly, the postsynaptic potentials induced by <bold>M</bold> and <bold>G</bold>, so was the normalized firing rate, evolved into trivial solutions and almost vanished in the truncated model (Supplementary Fig. 4d). Only the control model, but not the truncated model, could maintain prediction errors small and nearly constant after the termination of the stimuli (Supplementary Fig. 4e). These results indicate that maintaining the learned representations requires the continuous tuning of within-assembly inhibition.</p>
</sec>
<sec id="s2g">
<title>The role of homeostatic regulation of neural activities</title>
<p>As indicated by the weak couplings between cell assemblies, the present mechanism of probability learning differs from the conventional sequence learning mechanisms. Consistent with this, the network trained repetitively by a fixed sequence of patterned inputs does not exhibit stereotyped sequential transitions among cell assemblies (due to the lack of strong inter-assembly excitatory connections; Supplementary Fig. 5). Indeed, the probability-encoding spontaneous activity emerges in the present model mainly from the intra-assembly dynamics driven by strong within-assembly reverberating synaptic input. However, homeostatic variable <italic>h</italic> also plays a role in maintaining a stable spontaneous network activity after learning (see <xref rid="fig2" ref-type="fig">Fig. 2d</xref>; activity pattern from 5 to 10 sec). This is achieved by the time evolution of <italic>h</italic>, which maintains the firing rate of each neuron in a suitable range by adjusting the threshold and gain of the somatic sigmoidal response function (<xref rid="fig1" ref-type="fig">Fig. 1b</xref>).</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Simulations of biased perception of visual motion coherence.</title>
<p>(a) The network model simulated perceptual decision-making of coherence in random dot motion patterns. In the network shown here, network neurons have already learned two assemblies encoding leftward or rightward movements from input neuron groups L and R. The firing rates of input neuron groups were modulated according to the coherence level Coh of random dot motion patterns (Materials and Methods). (b) The choice probabilities of monkeys (circles) and the network model (solid lines) are plotted against the motion coherence in two learning protocols with different prior probabilities. The experimental data were taken from <xref ref-type="bibr" rid="c23">Hanks et al. (2011)</xref>. In the 50:50 protocol, moving dots in the “R” (Coh = 0.5) and “L” (Coh = -0.5) directions were presented randomly with equal probabilities, while in the 80:20 protocol, the “R” and “L” directions were trained with 80% and 20% probabilities, respectively. Shaded areas represent SDs over 20 independent simulations. The computational and experimental results show surprising coincidence without curve fitting. (c) Spontaneous and evoked activities of the trained networks are shown for the 50:50 (left) and 80:20 (right) protocols. Evoked responses were calculated for three levels of coherence: Coh = - 50%, 0%, and 50%. In both protocols, the activity ratio in spontaneous activity matches the prior probability and gives the baseline for evoked responses. In the 80:20 protocol, the biased priors of “R” and “L” motion stimuli shift the activity ratio in spontaneous activity to an “R”-dominant regime.</p></caption>
<graphic xlink:href="528958v2_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Therefore, we explored the role of the homeostatic variable in learning an accurate internal model of the sensory environment. In each neuron, the variable <italic>h</italic> is updated whenever the membrane potential undergoes an abrupt increase (<xref ref-type="disp-formula" rid="eqn10">Eq. 10</xref>). Therefore, the time evolution of <italic>h</italic> monitors the approximate duration of active epochs of the neuron and, consequently, its membership cell assembly (Supplementary Fig. 6a). The total duration of active epochs determines the activation probability of each cell assembly. Furthermore, when the instantaneous value of <italic>h</italic> is high, the neuron’s excitability is lowered (namely, the gain and threshold of the response function are decreased or increased, respectively: see <xref ref-type="disp-formula" rid="eqn11">Eqs. 11</xref> and <xref ref-type="disp-formula" rid="eqn12">12</xref>). The gain modulation enables the neuron to homeostatically regulate its susceptibility to patterned inputs and hence is crucial for measuring the duration of its active epochs. Actually, a model with fixed value of <italic>h</italic> showed spontaneous replay with less accurate estimates of the true probability distribution (Supplementary Fig. 6b: cf. <xref rid="fig3" ref-type="fig">Fig. 3f</xref>). In addition, the elimination of between-assembly excitatory connections did not significantly affect the replay probabilities, as the variable <italic>h</italic> is driven by strong within-assembly recurrent inputs after learning (Supplementary Fig. 6c).</p>
<p>As demonstrated above, the mechanism underlying our learning rule is significantly different from the previously proposed rule. Most previous models perform stochastic sampling based on Markov chains of network dynamics, which requires precise wiring patterns between assemblies. In contrast, in our model, individual assemblies sample independently via homeostatically regulated activities, and within-assembly connectivity alone is sufficient to perform such sampling.</p>
</sec>
<sec id="s2h">
<title>Learning conditioned prior distributions</title>
<p>The predictive coding hypothesizes that top-down input from higher cortical areas provides prior knowledge about computations in lower cortical areas. This implies in the brain’s hierarchical computation that the top-down input conditions the prior distributions in local cortical areas to those relevant to the given context. The proposed learning rules can account for how a conditioned input from other cortical areas conditions the prior distribution in a local cortical circuit.</p>
<p>The neural network consists of two mutually interacting non-overlapping subnetworks of equal sizes, where the subnetworks may represent different cortical areas (Supplementary Fig. 7a). Subnetwork A was randomly exposed to stimuli 1 and 2 (S1 and S2) with equal probabilities 1/2, whereas subnetwork B was to stimuli 3 and 4 (S3 and S4) with the conditional probabilities 1/3 and 2/3 if S1 was presented to subnetwork A and the conditional probabilities 2/3 and 1/3 if S2 was presented to subnetwork A. After learning, the network model self-organized four cell assemblies each of which responded preferentially to one of the four stimuli (Supplementary Fig. 7b). Consistent with this, the self-organized connection matrix represented strong within-assembly connections within each cell assembly and weak between-assembly connections (Supplementary Fig. 7c). Note that between-assembly connections were inhibitory between assemblies encoding mutually exclusive stimuli, i.e., S1 and S2 and S3 and S4, as they should be. Now, we turned off S3 and S4 to subnetwork B and only applied S1 or S2 to subnetwork A each at one time. Applying the same stimulus (i.e., S1 or S2) to subnetwork A activated either S3- or S4-coding cell assembly in subnetwork B in a probabilistic manner (Supplementary Fig. 7d). The cell assemblies evoked in subnetwork B by S1 or S2 to subnetwork A varied the total firing rates approximately in proportion to the conditional probabilities (e.g., P(S3|S1) = 1/3 vs. P(S4|S1) = 2/3) used during learning (Supplementary Fig. 7e). Note that S3- and S4-coding cell assemblies could become simultaneously active to represent the desired activation probabilities (e.g., a vertical arrow in Supplementary Fig. 7d). Together, these results indicate that our network can learn prior distributions conditioned by additional inputs through different pathways.</p>
</sec>
<sec id="s2i">
<title>Replication of biased perceptual decision making in monkeys</title>
<p>Prior knowledge about the environment often biases our percept of the external world. For instance, if we know that two possible stimuli exist and that stimulus A appears more often than stimulus B, we tend to feel that a given stimulus is more likely to be stimulus A than stimulus B. Previously, a similar bias was quantitatively studied in monkeys performing a perceptual decision making task (<xref ref-type="bibr" rid="c23">Hanks et al., 2011</xref>). In the experiment, monkeys had to judge the direction (right or left) of the coherent motion of moving dots on a display. When both directions of coherent motion appeared randomly during learning, the monkey showed unbiased choice behaviors. However, if the frequencies of the two motion directions were different, the monkey’s choice was biased toward the direction of a more frequent motion stimulus.</p>
<p>We constructed a network model shown in <xref rid="fig5" ref-type="fig">Fig. 5a</xref> to examine whether the present mechanism of spontaneous replay could account for the behavioral bias. The model comprises a recurrent network similar to that used in <xref rid="fig2" ref-type="fig">Fig. 2</xref> and two input neuron groups, L and R, encoding leftward or rightward coherent dot movements, respectively. We modulated the firing rates of these input neurons in proportion to the coherence of moving dots (Materials and Methods). During learning, we trained this model with external stimuli having input coherence Coh of either -0.5 or +0.5 (Materials and Methods), where all dots move leftward in the former or rightward in the latter. In so doing, we mimicked the two protocols used in the behavioral experiment of monkeys: in the 50:50 protocol, two stimuli with Coh = ±0.5 were presented randomly with equal probabilities, while in the 80:20 protocol, stimuli with Coh = +0.5 and -0.5 were delivered with probabilities of 80% and 20%, respectively. In the 80:20 protocol, stimuli were highly biased toward a coherent rightward motion.</p>
<p>The network model could explain the biased choices of monkeys surprisingly well. In either training protocol, the recurrent network self-organized two cell assemblies responding selectively to one of the R and L input neuron groups. Then, we examined whether the responses of the self-organized network are consistent with experimental observations by stimulating it with external inputs having various degrees of input coherence. The resultant psychometric curves almost perfectly coincide with those obtained in the experiment (<xref rid="fig5" ref-type="fig">Fig. 5b</xref>). We note that the psychometric curves of the model do not significantly depend on the specific choices of parameter values as far as the network learned stable spontaneous activity. We did not perform any curve fitting to experimental data, implying that the psychometric curves are free from parameter finetuning.</p>
<p>Biases in the psychometric curves emerged from biased firing rates of spontaneous activity of the self-organized cell assemblies. To show this, we investigated how the activities of the two self-organized cell assemblies change before and after the onset of test stimuli in three relatively simple cases, i.e., Coh = -0.5, 0, and +0.5. <xref rid="fig5" ref-type="fig">Figure 5c</xref> shows the activity ratio AR between the R-encoding cell assembly and the entire network (Materials and Methods) in pre-stimulus spontaneous and post-stimulus evoked activity. When the network was trained in a non-biased fashion (i.e., in the 50:50 protocol), the activity ratio was close to 0.5 in spontaneous activity, implying that the two cell assemblies had similar activity levels. In contrast, when the network was trained in a biased fashion (i.e., in the 80:20 protocol), the activity ratio in spontaneous activity was close to 0.8, implying that the total spontaneous firing rate of R-encoding cell assembly was four times higher than that of L-encoding cell assembly. Our results show that the spontaneous activity generated by the proposed mechanism can account for the precise relationship between motion coherence and perceptual biases in decision making by monkeys.</p>
</sec>
<sec id="s2j">
<title>An elaborate network model with distinct excitatory and inhibitory neuron pools</title>
<p>The predictive learning rule performed well in training the nDL model to learn the probabilistic structure of the stimulus-evoked activity patterns. However, whether the same learning rule works in a more realistic neural network is yet to be investigated. To examine this, we constructed an elaborate network model (DL model) consisting of distinct excitatory and inhibitory neuron pools, obeying Dale’s law (Supplementary Fig. 8a). The nDL model suggested the essential roles of inhibitory plasticity in maintaining excitation-inhibition balance and generating an appropriate number of cell assemblies. To achieve these functions, inhibitory neurons in the DL model project to excitatory and other inhibitory neurons via two synaptic paths (Supplementary Fig. 8b). In path1, inhibitory connections alone predict the postsynaptic activity, whereas inhibitory and excitatory connections jointly predict the activity of the postsynaptic neuron in path2 (Materials and Methods). All synapses in the DL model are subject to the predictive learning rule. We trained the DL model with three input neuron groups while varying their activation probabilities. As in the nDL model, the DL model self-organized three cell assemblies activated selectively by the three input neuron groups (Supplementary Fig. 9a). Furthermore, in the absence of external stimuli, the DL model spontaneously replayed these assemblies with the assembly activity ratios in proportion to the occurrence probabilities of the corresponding stimuli during learning (Supplementary Fig. 8c).</p>
<p>The two inhibitory paths divided their labors in a somewhat complex manner. To see this, we investigated the connectivity structures learned by these paths. In path 1, inhibitory connections were primarily found on excitatory neurons in the same assemblies (Supplementary Fig. 8d, top). In contrast, in path 2, inhibitory connections were stronger on excitatory neurons in different assemblies than those in the same assemblies (Supplementary Fig. 8d, bottom). On both excitatory and inhibitory neurons, the total inhibition (i.e., path 1 + path 2) was balanced with excitation (Supplementary Fig. 8e). Supplementary Figure 8f summarizes the connectivity structure of the DL model. Excitatory neurons in a cell assembly project to inhibitory neurons in the same assembly. Then, these inhibitory neurons project back to excitatory neurons in the same or different assemblies via paths 1 and 2. Interestingly, lateral inhibition through path 1 is more potent between excitatory neurons within each cell assembly than between different assemblies (Supplementary Fig. 8g). In contrast, path 2 mediates equally strong within-assembly and between-assembly inhibition.</p>
<p>We can understand the necessity of the two inhibitory paths based on the dynamical properties of competitive neural networks. Supplementary Figure 8h displays the effective competitive network of excitatory cell assemblies suggested by the above results. Both paths 1 and 2 contribute to within-assembly inhibition among excitatory neurons, whereas between-assembly inhibition (i.e., lateral inhibition) mainly comes from path 2. In a competitive network, the lateral inhibition to self-inhibition strength ratio determines the number of winners having non-vanishing activities: the higher the ratio is, the smaller the number of winners is (<xref ref-type="bibr" rid="c19">Fukai &amp; Tanaka, 1997</xref>). Therefore, self-organizing the same number of excitatory cell assemblies as that of external stimuli requires tuning the balance between the within-assembly and between-assembly inhibitions. This tuning during learning is likely easier when the network has two independently learnable inhibitory circuits. Indeed, a network model with only one inhibitory path rarely succeeded in encoding and replaying all stimuli used in learning (Supplementary Fig. 9b, c).</p>
<p>In summary, we have shown the roles of distinct recurrent inhibitory connections. Using a network consisting of excitatory and inhibitory populations, we have shown that distinct inhibitory circuits are necessary to generate within- and between-assembly competition crucial to maintain the stability of learned multiple assemblies.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Having proper generative models is crucial for accurately predicting statistical events. The brain is thought to improve the prediction accuracy of inference by learning internal generative models of the environment. These models are presumably generated through multiple mechanisms. For instance, the predictive coding hypothesizes that top-down cortical inputs provide lower sensory areas with prior information about sensory experiences (<xref ref-type="bibr" rid="c16">Friston, 2010</xref>; <xref ref-type="bibr" rid="c5">Bastos et al., 2012</xref>; <xref ref-type="bibr" rid="c36">Keller &amp; Mrsic-Flogel, 2018</xref>). However, experimental evidence also suggests that spontaneous activity represents an optimal model of the environment in sensory cortices. This study proposed a biologically plausible mechanism to learn such a model, or priors for experiences, with the brain’s internal dynamics.</p>
<p>Our model adopted a single predictive learning principle for the plasticity of excitatory and inhibitory synapses to learn the replay of probabilistic experiences. On each neuron, excitatory and inhibitory synaptic weights undergo plastic changes to improve their independent predictions on the cell’s firing. This was done by minimizing the mismatch between the prior distribution and posterior distribution of the membrane potentials (Eq. 4). This simple learning rule showed excellent performance in a simplified network model and in a more realistic model obeying Dale’s law. The latter model predicts a division of labor between two inhibitory paths. Intriguingly, the inhibitory path 2 of this model resembles interpyramidal inhibitory connections driven directly by nearby pyramidal cells (<xref ref-type="bibr" rid="c57">Ren et al., 2007</xref>). In both models, inhibitory synaptic plasticity plays a crucial role in learning an accurate internal model by maintaining excitation-inhibition balance and decorrelating cell-assembly activities (<xref ref-type="bibr" rid="c69">Vogels et al., 2013</xref>; <xref ref-type="bibr" rid="c61">Sprekeler, 2017</xref>).Various models have been proposed to account for neural mechanisms of Bayesian computation by the brain (<xref ref-type="bibr" rid="c66">Tully et al., 2014</xref>; <xref ref-type="bibr" rid="c34">Kappel et al., 2015</xref>; <xref ref-type="bibr" rid="c27">Hiratani &amp; Fukai, 2018</xref>; <xref ref-type="bibr" rid="c28">Hiratani &amp; Latham, 2020</xref>; <xref ref-type="bibr" rid="c1">Aitchison et al., 2021</xref>; <xref ref-type="bibr" rid="c46">Ma et al., 2006</xref>; <xref ref-type="bibr" rid="c12">Deneve, 2008</xref>; <xref ref-type="bibr" rid="c52">Nessler et al., 2013</xref>; <xref ref-type="bibr" rid="c25">Hiratani &amp; Fukai, 2016</xref>; <xref ref-type="bibr" rid="c29">Huang &amp; Rao, 2016</xref>; <xref ref-type="bibr" rid="c30">Isomura et al., 2022</xref>; <xref ref-type="bibr" rid="c16">Friston, 2010</xref>; <xref ref-type="bibr" rid="c5">Bastos et al., 2012</xref>; <xref ref-type="bibr" rid="c36">Keller &amp; Mrsic-Flogel, 2018</xref>). Typically, these models embed prior knowledge on sensory experiences into the wiring patterns of afferent (and sometimes also recurrent) synaptic inputs such that these inputs can evoke the learned activity patterns associated with the prior knowledge. The present model differs from the previous models in several aspects: i) First, the model segments repeated stimuli to be remembered in an unsupervised fashion; ii) Then it generates cell assemblies encoding the segmented stimuli; (iii) Finally, it replays these cell assemblies spontaneously with learned probabilities. Note that the same learning rules enable the network to perform all necessary computations for (i) to (iii). To our knowledge, our model is the first to perform all these steps for encoding an optimal model of the environment into spontaneous network activity.</p>
<p>The present mechanism of memory formation differs from the previous ones that self-organize cell assemblies through Hebbian learning rules (<xref ref-type="bibr" rid="c68">Vogels et al., 2011</xref>; <xref ref-type="bibr" rid="c26">Hiratani and Fukai, 2014</xref>; <xref ref-type="bibr" rid="c44">Litwin-Kumar and Doiron, 2014</xref>; <xref ref-type="bibr" rid="c71">Zenke et al., 2015</xref>; <xref ref-type="bibr" rid="c65">Triplett et al., 2018</xref>; <xref ref-type="bibr" rid="c51">Montangie 2020</xref>). Firstly, these mechanisms did not aim for explicit statistical modeling of the environment. Secondly, the previous studies suggested that the orchestration of multiple plasticity rules, including inhibitory plasticity and homeostatic synaptic scaling, enables the maintenance of cell assemblies (however, see <xref ref-type="bibr" rid="c47">Manz et al., 2023</xref>). For instance, in spike-timing-dependent plasticity (STDP), slight changes in the relative times of pre and postsynaptic spikes can change the polarity of synaptic modifications, implying that STDP requires a mechanism to keep synaptic weights finite (<xref ref-type="bibr" rid="c37">Kempter et al., 1999</xref>; <xref ref-type="bibr" rid="c60">Song et al., 2000</xref>; <xref ref-type="bibr" rid="c48">Masquelier et al., 2008</xref>). In contrast, our learning rule, which induces either long-term potentiation or depression according to the sign of the prediction error calculated independently within each postsynaptic neuron, does not suffer such instability.</p>
<p>Our model predicts a novel intracellular process that regulates the neuron’s dynamic range according to the history of its subthreshold dynamics. This process plays two important roles in the statistical modeling of our model. First, it avoids the trivial solution (i.e., the zero-weight solution) of our unsupervised predictive learning by homeostatically regulating neurons’ intrinsic excitability. Second, the intracellular process cooperates with reverberating synaptic inputs within each cell assembly to generate spontaneous replay activity. Owing to the intracellular homeostasis, our model can sample from the learned distribution without relying on the recurrences among assemblies. This mechanism contrasts with the previous sampling-based models that rely on the transition dynamics between cell assemblies (<xref ref-type="bibr" rid="c8">Buesing et al., 2011</xref>; <xref ref-type="bibr" rid="c7">Bill et al., 2015</xref>). How neural systems implement the proposed homeostasis is an open question.</p>
<p>The proposed mechanism can account for the behavioral biases observed in perceptual decision making (<xref ref-type="bibr" rid="c23">Hanks et al., 2011</xref>). This behavioral experiment quantitatively clarified how the difference in the probability between sensory experiences during learning biases the alternative choice behavior of monkeys. In our model, two cell assemblies encoding the different stimuli are replayed at the total firing rates proportional to the corresponding occurrence probabilities. Our results suggest that the difference in spontaneous firing rates of cell assemblies is sufficient to explain the behavioral biases of monkeys. However, other mechanisms, such as biased top-down input, cannot be excluded.</p>
<p>What could be the advantages of coding prior distributions into spontaneous activity over other ways of probability coding? First, spontaneous replay activities in lower cortical areas may provide training data for modeling by higher cortical areas, promoting hierarchical statistical modeling in predictive coding. This is analogous to the situation where hippocampal engram cells are replayed to reinforce the activity patterns of cortical engrams for memory consolidation during sleep (<xref ref-type="bibr" rid="c63">Tonegawa et al., 2018</xref>; <xref ref-type="bibr" rid="c20">Ghandour et al., 2019</xref>; <xref ref-type="bibr" rid="c40">Klinzing et al., 2019</xref>; <xref ref-type="bibr" rid="c62">Takehara-Nishiuchi, 2021</xref>). Memory reinforcement by activity replay has also been studied in machine intelligence (<xref ref-type="bibr" rid="c10">Dayan et al., 1995</xref>; <xref ref-type="bibr" rid="c21">Goodfellow et al., 2014</xref>; <xref ref-type="bibr" rid="c45">Luczak et al., 2022</xref>). Second, spontaneous replay of internal models may support knowledge generalization during sleep. It was recently reported that a transitive inference task requires post-learning sleep (Kareem et al., 2021). In this task, mice had to infer a correct reward delivery rule in a novel behavioral situation from the outcomes of past experiences. The mice failed to generalize the learned rules if the activity of the anterior cingulate cortex was suppressed during post-learning sleep, suggesting that dynamic interactions among rule-coding cortical neurons in spontaneous activity are crucial for rule generalization. Clarifying how spontaneous brain activity generalizes the learned internal models is an intriguing open question.</p>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Neural network model</title>
<p>Below, we first describe the model architecture and learning rule for the nDL model (i.e., single population violating the Dale’s law). Details of simulation of distinct excitatory and inhibitory populations will be explained later. Unless other-wise stated, recurrent neural networks used in this study consist of <italic>N</italic>(= 500) Poisson neurons, which generate spikes according to a non-stationary Poisson process with rate <inline-formula><inline-graphic xlink:href="528958v2_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="528958v2_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is a dynamics sigmoidal function, which we will explain later. The membrane potential <italic>u</italic> of neuron <italic>i</italic> at time <italic>t</italic> is given as follows:
<disp-formula id="eqn5">
<graphic xlink:href="528958v2_eqn5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>K</italic> is the number of input neurons. In some simulations, the network model had more than one input neuron group although the number of input neuron groups is not explicitly shown in <xref ref-type="disp-formula" rid="eqn5">Eq. 5</xref>. Three matrices <bold>W</bold> ∈ ℝ<sup><italic>N</italic>×<italic>K</italic></sup>, <bold>M</bold> ∈ ℝ<sup><italic>N</italic>×<italic>K</italic></sup>, and <bold>G</bold> ∈ ℝ<sup><italic>N</italic>×<italic>K</italic></sup> represent the weights of afferent synaptic connections, recurrent synaptic connections and inhibitory-only connections, respectively, on neurons in the recurrent network. These synaptic connections are all-to-all. In terms of the kernel function
<disp-formula id="eqn6">
<graphic xlink:href="528958v2_eqn6.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
recurrent input and afferent input to neuron <italic>i</italic> are calculated as
<disp-formula id="eqn7a">
<graphic xlink:href="528958v2_eqn7a.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn7b">
<graphic xlink:href="528958v2_eqn7b.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where τ stands for the membrane time constant, <inline-formula><inline-graphic xlink:href="528958v2_inline3.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="528958v2_inline4.gif" mimetype="image" mime-subtype="gif"/></inline-formula> for the time sets of afferent and recurrent presynaptic spikes, and Θ(·) for the Heaviside function. Throughout this study, τ = 15 ms.</p>
<p>The instantaneous firing rate <italic>f</italic><sub><italic>i</italic></sub> (<italic>t</italic>) of each neuron is given as
<disp-formula id="eqn8">
<graphic xlink:href="528958v2_eqn8.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
in terms of a dynamical sigmoidal response function <inline-formula><inline-graphic xlink:href="528958v2_inline5.gif" mimetype="image" mime-subtype="gif"/></inline-formula> :
<disp-formula id="eqn9">
<graphic xlink:href="528958v2_eqn9.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
with a constant value of <italic>g</italic> = 3. Here, the dynamical variable <italic>h</italic> is determined by the history of the membrane potential:
<disp-formula id="eqn10">
<graphic xlink:href="528958v2_eqn10.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
<p>The maximum instantaneous firing rate <italic>φ</italic><sub>0</sub> is 50 Hz and <italic>τ</italic><sub><italic>h</italic></sub> = 10 s. Through <xref ref-type="disp-formula" rid="eqn10">Eq. 10</xref>, <italic>h</italic><sub><italic>i</italic></sub> tracks the maximum value of the membrane potential <italic>u</italic><sub><italic>i</italic></sub> in a time window of approximately the length <italic>τ</italic><sub><italic>h</italic></sub> in the immediate past. The value of <italic>h</italic> is utilized to regulate the gain <italic>β</italic> and threshold <italic>θ</italic> of the sigmoidal response function as follows:
<disp-formula id="eqn11">
<graphic xlink:href="528958v2_eqn11.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn12">
<graphic xlink:href="528958v2_eqn12.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where the values of constant parameters are <italic>β</italic><sub>0</sub> = 5, and <italic>θ</italic><sub>0</sub> = 1. Neuron <italic>i</italic> generates a Poisson spike train at the instantaneous firing rate of <italic>f</italic><sub><italic>i</italic></sub>(<italic>t</italic>).</p>
</sec>
<sec id="s4b">
<title>Learning rules</title>
<p>To predict the firing rate of the postsynaptic neuron, the different types of synapses obey similar learning rules in the present network model. Given the postsynaptic potentials as
<disp-formula id="eqn13a">
<graphic xlink:href="528958v2_eqn13a.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn13b">
<graphic xlink:href="528958v2_eqn13b.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn13c">
<graphic xlink:href="528958v2_eqn13c.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
the weights of the corresponding synapses are modified according to the following equations:
<disp-formula id="eqn14a">
<graphic xlink:href="528958v2_eqn14a.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn14b">
<graphic xlink:href="528958v2_eqn14b.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn14c">
<graphic xlink:href="528958v2_eqn14c.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where the error term ε(<italic>f</italic><sub><italic>i</italic></sub>, V<sub><italic>i</italic></sub>) is defined as
<disp-formula id="eqn15">
<graphic xlink:href="528958v2_eqn15.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
with a static sigmoidal function:
<disp-formula id="ueqn2">
<graphic xlink:href="528958v2_ueqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
<p>Throughout this study, the learning rate η = 10<sup>−4</sup>, for which the typical time length required for the convergence of learning is 1,000 s.</p>
<p>Initial values of <bold>W</bold> and <bold>M</bold> are sampled from gaussian distributions with the mean 0 and variances <inline-formula><inline-graphic xlink:href="528958v2_inline6.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="528958v2_inline7.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, respectively. During learning, the elements of <bold>W</bold> and <bold>M</bold> can take both positive and negative values. After sufficient learning, the postsynaptic potentials <inline-formula><inline-graphic xlink:href="528958v2_inline8.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="528958v2_inline9.gif" mimetype="image" mime-subtype="gif"/></inline-formula> on neuron on neuron <italic>i</italic> converge to a common value of <inline-formula><inline-graphic xlink:href="528958v2_inline10.gif" mimetype="image" mime-subtype="gif"/></inline-formula> .Therefore, <inline-formula><inline-graphic xlink:href="528958v2_inline11.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, implying that the postsynaptic potentials of afferent and recurrent synaptic inputs to neuron <italic>i</italic> can both predict its output <italic>f</italic><sub><italic>i</italic></sub> after learning. The initial values of <bold>G</bold> are uniformly set to <inline-formula><inline-graphic xlink:href="528958v2_inline12.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, and its elements are truncated to non-negative values during learning. This implies that <inline-formula><inline-graphic xlink:href="528958v2_inline13.gif" mimetype="image" mime-subtype="gif"/></inline-formula> does not become negative. After learning, <inline-formula><inline-graphic xlink:href="528958v2_inline14.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is satisfied. Although some elements of <bold>M</bold> may give recurrent inhibitory connections, modifiable connections in <bold>G</bold> are necessary to encode all external inputs into specific cell assemblies.</p>
</sec>
<sec id="s4c">
<title>Stimulation protocols</title>
<p>Feedforward input to the recurrent network consisted of <italic>K</italic> Poisson spike trains with a background firing rate of 2Hz. The input randomly presented <italic>n</italic> non-over-lapping patterns of 100 spike trains (the duration 100 ms and the mean frequency 50 Hz), one at a time, with pattern-to-pattern intervals of 100 ms. Therefore, the number of input neurons and patterns satisfy the relationship of <italic>K</italic> = 100 × <italic>n</italic>. For simplicity, we simulated the constant-interval case, but using irregular intervals does not change the essential results. The value of <italic>n</italic> varies from task to task, and the values for each figure are as follows: <italic>n</italic> = 5 (<xref rid="fig2" ref-type="fig">Fig. 2c-e</xref>, <xref rid="fig3" ref-type="fig">Fig. 3</xref>); <italic>n</italic> = 2 (<xref rid="fig2" ref-type="fig">Fig. 2a-b</xref>, <xref rid="fig4" ref-type="fig">Figs. 4</xref>-<xref rid="fig5" ref-type="fig">5</xref>).</p>
</sec>
<sec id="s4d">
<title>Measures for cell assembly activities</title>
<p>Here, we explain the measures used in <xref rid="fig3" ref-type="fig">Fig. 3</xref>. We calculated the firing rate ratio of cell assembly 1 in <xref rid="fig3" ref-type="fig">Fig. 3c</xref> as follows:
<disp-formula id="eqn16">
<graphic xlink:href="528958v2_eqn16.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
using the average firing rate <inline-formula><inline-graphic xlink:href="528958v2_inline15.gif" mimetype="image" mime-subtype="gif"/></inline-formula> of the <italic>i</italic>-th neuron in cell assembly <italic>j</italic> and the number <italic>N</italic><sub><italic>j</italic> =</sub> of neurons belonging to the cell assembly. Similarly, we defined the assembly size ratio of cell assembly 1 as .
<disp-formula id="eqn17">
<graphic xlink:href="528958v2_eqn17.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
in <xref rid="fig3" ref-type="fig">Fig.3d</xref> and assembly activity ratio of cell assembly 1 as
<disp-formula id="eqn18">
<graphic xlink:href="528958v2_eqn18.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
in <xref rid="fig3" ref-type="fig">Fig. 3e</xref>. Here, <inline-formula><inline-graphic xlink:href="528958v2_inline16.gif" mimetype="image" mime-subtype="gif"/></inline-formula> represents the population neural activity of cell assembly <italic>i</italic>:
<disp-formula id="eqn19">
<graphic xlink:href="528958v2_eqn19.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
</sec>
<sec id="s4e">
<title>Simulations of perceptual decision making</title>
<p>In each learning trial, we trained the network with either leftward or rightward dot movement represented by the corresponding input neurons firing at <italic>r</italic><sub>max</sub> = 50 Hz. In test trials, we defined input coherence as Coh = Ρ<sub><italic>R</italic></sub> − 0.5 according to <xref ref-type="bibr" rid="c23">Hanks et al. (2011)</xref>, where Ρ<sub><italic>R</italic></sub> is the ratio of R input neurons to the sum of R and L input neurons in firing rate. The value of Coh ranges between -0.5 (all dots moving leftward) and +0.5 (all dots moving rightward). Then, in test trials for input coherence Coh, we generated Poisson spike trains of R and L input neurons at the rates (Coh + 0.5)<italic>r</italic><sub>max</sub> and (−Coh + 0.5)<italic>r</italic><sub>max</sub>, respectively.</p>
<p>In <xref rid="fig5" ref-type="fig">Fig. 5c</xref>, we calculated the activity ratio (AR) as
<disp-formula id="eqn20">
<graphic xlink:href="528958v2_eqn20.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <inline-formula><inline-graphic xlink:href="528958v2_inline17.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="528958v2_inline18.gif" mimetype="image" mime-subtype="gif"/></inline-formula> represent the average population firing rates of R-encoding and L-encoding cell assemblies, respectively. In <xref rid="fig5" ref-type="fig">Fig. 5b</xref>, we defined “choices to right” as
<disp-formula id="eqn21">
<graphic xlink:href="528958v2_eqn21.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
</sec>
<sec id="s4f">
<title>A network model with distinct excitatory and inhibitory neuron populations</title>
<p>Here, we explain the architecture of the model used in Supplementary Fig.8. The network consists of <italic>N</italic><sub><italic>E</italic></sub> (= 500) excitatory and <italic>N</italic><sub><italic>I</italic></sub> (= 500) inhibitory neurons. The membrane potential of a neuron <italic>i</italic> of a population X (= E or I) at time <italic>t</italic> is given as follows:
<disp-formula id="eqn22">
<graphic xlink:href="528958v2_eqn22.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <inline-formula><inline-graphic xlink:href="528958v2_inline19.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is afferent synaptic weights, which are a mixture of excitatory and inhibitory connections as in the nDL model. The weights of recurrent excitatory synapses are <inline-formula><inline-graphic xlink:href="528958v2_inline20.gif" mimetype="image" mime-subtype="gif"/></inline-formula> .Here, we considered two types of recurrent inhibitory connections (i.e., path 1 and path 2), denoted by <inline-formula><inline-graphic xlink:href="528958v2_inline21.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and<inline-formula><inline-graphic xlink:href="528958v2_inline22.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, respectively. Using the same definitions of kernel function of synaptic inputs and the error term as in <xref ref-type="disp-formula" rid="eqn15">Eq. 15</xref>, we modified these weights according to the following equations:
<disp-formula id="eqn23a">
<graphic xlink:href="528958v2_eqn23a.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn23b">
<graphic xlink:href="528958v2_eqn23b.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn23c">
<graphic xlink:href="528958v2_eqn23c.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn23d">
<graphic xlink:href="528958v2_eqn23d.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
<p>To satisfy the Dale’s law, we truncated all weights of recurrent connections to non-negative values during learning.</p>
<p>In Supplementary Fig. 8g, we measured the lateral inhibition between excitatory neurons via path 1 by calculating:
<disp-formula id="eqn24">
<graphic xlink:href="528958v2_eqn24.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
<p>Lateral inhibition via path 2 was calculated in a similar fashion.</p>
</sec>
<sec id="s4g">
<title>Simulation details</title>
<p>All simulations were performed in customized Python3 code written by TA with numpy 1.17.3 and scipy 0.18. Differential equations were numerically integrated using a Euler method with integration time steps of 1 ms.</p>
</sec>
</sec>
<sec id="d1e1443" sec-type="supplementary-material">
<title>Supporting information</title>
<supplementary-material id="d1e1526">
<label>Supplementary Figure 1</label>
<media xlink:href="supplements/528958_file03.pdf"/>
</supplementary-material>
<supplementary-material id="d1e1533">
<label>Supplementary Figure 2</label>
<media xlink:href="supplements/528958_file04.pdf"/>
</supplementary-material>
<supplementary-material id="d1e1540">
<label>Supplementary Figure 3</label>
<media xlink:href="supplements/528958_file05.pdf"/>
</supplementary-material>
<supplementary-material id="d1e1547">
<label>Supplementary Figure 4</label>
<media xlink:href="supplements/528958_file06.pdf"/>
</supplementary-material>
<supplementary-material id="d1e1555">
<label>Supplementary Figure 5</label>
<media xlink:href="supplements/528958_file07.pdf"/>
</supplementary-material>
<supplementary-material id="d1e1562">
<label>Supplementary Figure 6</label>
<media xlink:href="supplements/528958_file08.pdf"/>
</supplementary-material>
<supplementary-material id="d1e1569">
<label>Supplementary Figure 7</label>
<media xlink:href="supplements/528958_file09.pdf"/>
</supplementary-material>
<supplementary-material id="d1e1576">
<label>Supplementary Figure 8</label>
<media xlink:href="supplements/528958_file10.pdf"/>
</supplementary-material>
<supplementary-material id="d1e1583">
<label>Supplementary Figure 9</label>
<media xlink:href="supplements/528958_file11.pdf"/>
</supplementary-material>
</sec>
</body>
<back>
<sec id="s5">
<title>Author Contributions</title>
<p>T.A. and T.F. conceived the study and wrote the paper.</p>
<p>T.A. performed the simulations and data analyses.</p>
</sec>
<sec id="s6">
<title>Competing Interest Statement</title>
<p>The authors declare no competing interests.</p>
</sec>
<ack>
<title>Acknowledgments</title>
<p>The authors express their sincere thanks to Yukiko Goda for her valuable comments on our manuscript. This work was supported by KAKENHI (nos. 18H05213 and 19H04994) to T.F.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>Aitchison</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Jegminat</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Menendez</surname>, <given-names>J.A.</given-names></string-name>, <string-name><surname>Pfister</surname>, <given-names>J.P.</given-names></string-name>, <string-name><surname>Pouget</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Latham</surname>, <given-names>P.E.</given-names></string-name> <etal>et al.</etal> <article-title>Synaptic plasticity as Bayesian inference</article-title>. <source>Nat. Neurosci</source>. <volume>24</volume>, <fpage>565</fpage>–<lpage>571</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Asabuki</surname>, <given-names>T.</given-names></string-name> &amp; <string-name><surname>Fukai</surname>, <given-names>T.</given-names></string-name> <article-title>Somatodendritic consistency check for temporal feature segmentation</article-title>. <source>Nat. Commun</source>. <volume>11</volume>, <fpage>1554</fpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>Ashourian</surname>, <given-names>P.</given-names></string-name> &amp; <string-name><surname>Loewenstein</surname>, <given-names>Y.</given-names></string-name> <article-title>Bayesian inference underlies the contraction bias in delayed comparison tasks</article-title>. <source>PLoS One</source> <volume>6</volume>, <fpage>e19551</fpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Baldassano</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Zadbood</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Pillow</surname>, <given-names>J.W.</given-names></string-name>, <string-name><surname>Hasson</surname>, <given-names>U.</given-names></string-name>, <string-name><surname>Norman</surname>, <given-names>K.A.</given-names></string-name> <article-title>Discovering event structure in continuous narrative perception and memory</article-title>. <source>Neuron</source> <volume>95</volume>, <fpage>709</fpage>–<lpage>721 e705</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Bastos</surname>, <given-names>A.M.</given-names></string-name>, <string-name><surname>Usrey</surname>, <given-names>W.M.</given-names></string-name>, <string-name><surname>Adams</surname>, <given-names>R.A.</given-names></string-name>, <string-name><surname>Mangun</surname>, <given-names>G.R.</given-names></string-name>, <string-name><surname>Fries</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Friston</surname>, <given-names>K.J.</given-names></string-name> <article-title>Canonical microcircuits for predictive coding</article-title>. <source>Neuron</source> <volume>76</volume>, <fpage>695</fpage>–<lpage>711</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Berkes</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Orban</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Lengyel</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Fiser</surname>, <given-names>J.</given-names></string-name> <article-title>Spontaneous cortical activity reveals hallmarks of an optimal internal model of the environment</article-title>. <source>Science</source> <volume>331</volume>, <fpage>83</fpage>–<lpage>87</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Bill</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Buesing</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Habenschuss</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Nessler</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Maass</surname>, <given-names>W.</given-names></string-name>, &amp; <string-name><surname>Legenstein</surname>, <given-names>R.</given-names></string-name> <article-title>Distributed bayesian computation and self-organized learning in sheets of spiking neurons with local lateral inhibition</article-title>. <source>PloS one</source>, <volume>10</volume>, <fpage>e0134356</fpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Buesing</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Bill</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Nessler</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Maass</surname>, <given-names>W.</given-names></string-name> <article-title>Neural dynamics as sampling: a model for stochastic computation in recurrent networks of spiking neurons</article-title>. <source>PLoS computational biology</source>, <volume>7</volume>, <fpage>e1002211</fpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Chance</surname>, <given-names>F. S.</given-names></string-name>, <string-name><surname>Abbott</surname>, <given-names>L. F.</given-names></string-name>, &amp; <string-name><surname>Reyes</surname>, <given-names>A. D.</given-names></string-name> <article-title>Gain modulation from background synaptic input</article-title>. <source>Neuron</source>, <volume>35</volume>, <fpage>773</fpage>–<lpage>782</lpage> (<year>2002</year>).</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Hinton</surname>, <given-names>G.E.</given-names></string-name>, <string-name><surname>Neal</surname>, <given-names>R.M.</given-names></string-name> &amp; <string-name><surname>Zemel</surname>, <given-names>R.S.</given-names></string-name> <article-title>The Helmholtz machine</article-title>. <source>Neural Comput</source>. <volume>7</volume>, <fpage>889</fpage>–<lpage>904</lpage> (<year>1995</year>).</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>Dehaene</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Meyniel</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Wacongne</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>L.</given-names></string-name> &amp; <string-name><surname>Pallier</surname>, <given-names>C.</given-names></string-name> <article-title>The neural representation of sequences: from transition probabilities to algebraic patterns and linguistic trees</article-title>. <source>Neuron</source> <volume>88</volume>, <fpage>2</fpage>–<lpage>19</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>Deneve</surname>, <given-names>S.</given-names></string-name> <article-title>Bayesian spiking neurons I: inference</article-title>. <source>Neural Comput</source>. <volume>20</volume>, <fpage>91</fpage>–<lpage>117</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Ernst</surname>, <given-names>M.O.</given-names></string-name> &amp; <string-name><surname>Banks</surname>, <given-names>M.S.</given-names></string-name> <article-title>Humans integrate visual and haptic information in a statistically optimal fashion</article-title>. <source>Nature</source> <volume>415</volume>, <fpage>429</fpage>–<lpage>433</lpage> (<year>2002</year>).</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><string-name><surname>Fiser</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Berkes</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Orban</surname>, <given-names>G.</given-names></string-name> &amp; <string-name><surname>Lengyel</surname>, <given-names>M.</given-names></string-name> <article-title>Statistically optimal perception and learning: from behavior to neural representations</article-title>. <source>Trends Cogn. Sci</source>. <volume>14</volume>, <fpage>119</fpage>–<lpage>130</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Fonollosa</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Neftci</surname>, <given-names>E.</given-names></string-name>, &amp; <string-name><surname>Rabinovich</surname>, <given-names>M.</given-names></string-name> <article-title>Learning of chunking sequences in cognition and behavior</article-title>. <source>PLoS computational biology</source>, <volume>11</volume>, <fpage>e1004592</fpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>Friston</surname>, <given-names>K.</given-names></string-name> <article-title>The free-energy principle: a unified brain theory?</article-title> <source>Nat. Rev. Neurosci</source>. <volume>11</volume>, <fpage>127</fpage>–<lpage>138</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><surname>Fritsche</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Spaak</surname>, <given-names>E.</given-names></string-name> &amp; <string-name><surname>de Lange</surname>, <given-names>F.P.</given-names></string-name> <article-title>A Bayesian and efficient observer model explains concurrent attractive and repulsive history biases in visual perception</article-title>. <source>Elife</source> <volume>9</volume>, <fpage>e55389</fpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><string-name><surname>Fujii</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Graybiel</surname>, <given-names>A. M.</given-names></string-name> <article-title>Representation of action sequence boundaries by macaque prefrontal cortical neurons</article-title>. <source>Science</source> <volume>301</volume>, <fpage>1246</fpage>–<lpage>1249</lpage> (<year>2003</year>).</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><surname>Fukai</surname> <given-names>T</given-names></string-name>, <string-name><surname>Tanaka</surname> <given-names>S.</given-names></string-name> <article-title>A simple neural network exhibiting selective activation of neuronal ensembles: from winner-take-all to winners-share-all</article-title>. <source>Neural Comput</source>. <volume>9</volume>:<fpage>77</fpage>–<lpage>97</lpage> (<year>1997</year>).</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><string-name><surname>Ghandour</surname> <given-names>K</given-names></string-name>, <string-name><surname>Ohkawa</surname> <given-names>N</given-names></string-name>, <string-name><surname>Fung</surname> <given-names>CCA</given-names></string-name>, <string-name><surname>Asai</surname> <given-names>H</given-names></string-name>, <string-name><surname>Saitoh</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Takekawa</surname> <given-names>T</given-names></string-name>, <string-name><surname>Okubo-Suzuki</surname> <given-names>R</given-names></string-name>, <string-name><surname>Soya</surname> <given-names>S</given-names></string-name>, <string-name><surname>Nishizono</surname> <given-names>H</given-names></string-name>, <string-name><surname>Matsuo</surname> <given-names>M</given-names></string-name>, <string-name><surname>Osanai</surname> <given-names>M</given-names></string-name>, <string-name><surname>Sato</surname> <given-names>M</given-names></string-name>, <string-name><surname>Ohkura</surname> <given-names>M</given-names></string-name>, <string-name><surname>Nakai</surname> <given-names>J</given-names></string-name>, <string-name><surname>Hayashi</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Sakurai</surname> <given-names>T</given-names></string-name>, <string-name><surname>Kitamura</surname> <given-names>T</given-names></string-name>, <string-name><surname>Fukai</surname> <given-names>T</given-names></string-name>, <string-name><surname>Inokuchi</surname> <given-names>K.</given-names></string-name> <article-title>Orchestrated ensemble activities constitute a hippocampal memory engram</article-title>. <source>Nat Commun</source>. <volume>10</volume>, <fpage>2637</fpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Goodfellow</surname>, <given-names>I.</given-names></string-name>, <etal>et al.</etal> <article-title>Generative Adversarial Nets</article-title>. in <source>Proceedings of the International Conference on Neural Information Processing Systems</source> (NIPS 2014) <fpage>2672</fpage>–<lpage>2680</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>Hachen</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Reinartz</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Brasselet</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Stroligo</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Diamond</surname>, <given-names>M.E.</given-names></string-name> <article-title>Dynam-ics of history-dependent perceptual judgment</article-title>. <source>Nat. Commun</source>. <volume>12</volume>, <fpage>6036</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Hanks</surname>, <given-names>T.D.</given-names></string-name>, <string-name><surname>Mazurek</surname>, <given-names>M.E.</given-names></string-name>, <string-name><surname>Kiani</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Hopp</surname>, <given-names>E.</given-names></string-name> &amp; <string-name><surname>Shadlen</surname>, <given-names>M.N.</given-names></string-name> <article-title>Elapsed decision time affects the weighting of prior probability in a perceptual decision task</article-title>. <source>J. Neurosci</source>. <volume>31</volume>, <fpage>6339</fpage>–<lpage>6352</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><surname>Hartmann</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Lazar</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Nessler</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Triesch</surname>, <given-names>J.</given-names></string-name> <article-title>Where’s the noise? Key features of spontaneous activity and neural variability arise through learning in a deterministic network</article-title>. <source>PLoS computational Computational bBiology</source>, <volume>11</volume>, <fpage>e1004640</fpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Hiratani</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Fukai</surname>, <given-names>T.</given-names></string-name> <article-title>Hebbian wiring plasticity generates efficient network structures for robust inference with synaptic weight plasticity</article-title>. <source>Front. Neural Circuits</source> <volume>10</volume>, <fpage>41</fpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><string-name><surname>Hiratani</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Fukai</surname>, <given-names>T.</given-names></string-name> <article-title>Interplay between short- and long-term plasticity in cell-assembly formation</article-title>. <source>PLoS One</source> <volume>9</volume>, <fpage>e101535</fpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><string-name><surname>Hiratani</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Fukai</surname>, <given-names>T.</given-names></string-name> <article-title>Redundancy in synaptic connections enables neurons to learn optimally</article-title>. <source>Proc. Natl. Acad. Sci. U. S. A</source>. <volume>115</volume>, <fpage>E6871</fpage>–<lpage>E6879</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><string-name><surname>Hiratani</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Latham</surname>, <given-names>P.E.</given-names></string-name> <article-title>Rapid Bayesian learning in the mammalian olfactory system</article-title>. <source>Nat. Commun</source>. <volume>11</volume>, <fpage>3845</fpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><string-name><surname>Huang</surname>, <given-names>Y.</given-names></string-name> &amp; <string-name><surname>Rao</surname>, <given-names>R.P.</given-names></string-name> <article-title>Bayesian Inference and Online learning in Poisson neuronal networks</article-title>. <source>Neural Comput</source>. <volume>28</volume>, <fpage>1503</fpage>–<lpage>1526</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><string-name><surname>Isomura</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Shimazaki</surname>, <given-names>H.</given-names></string-name> &amp; <string-name><surname>Friston</surname>, <given-names>K.J.</given-names></string-name> <article-title>Canonical neural networks perform active inference</article-title>. <source>Commun. Biol</source>. <volume>5</volume>, <fpage>55</fpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><string-name><surname>Jimenez Rezende</surname> <given-names>D.</given-names></string-name> &amp; <string-name><surname>Gerstner</surname> <given-names>W.</given-names></string-name> <article-title>Stochastic variational learning in recurrent spiking networks</article-title>. <source>Front Comput Neurosci</source>. <volume>8</volume>:<fpage>38</fpage> doi: <pub-id pub-id-type="doi">10.3389/fncom.2014.00038</pub-id> (<year>2014</year>).</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><string-name><surname>Jin.</surname>, <given-names>X.</given-names></string-name> &amp; <string-name><surname>Costa</surname>, <given-names>R. M.</given-names></string-name> <article-title>Start/stop signals emerge in nigrostriatal circuits during sequence learning</article-title>. <source>Nature</source> <volume>466</volume>, <fpage>457</fpage>–<lpage>462</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><string-name><surname>Jin.</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Tecuapetla</surname>, <given-names>F.</given-names></string-name> &amp; <string-name><surname>Costa</surname>, <given-names>R. M.</given-names></string-name> <article-title>Basal ganglia subcircuits distinctively encode the parsing and concatenation of action sequences</article-title>. <source>Nat. Neurosci</source>. <volume>17</volume>, <fpage>423</fpage>–<lpage>430</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><string-name><surname>Kappel</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Habenschuss</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Legenstein</surname>, <given-names>R.</given-names></string-name> &amp; <string-name><surname>Maass</surname>, <given-names>W.</given-names></string-name> <article-title>Network plasticity as Bayesian inference</article-title>. <source>PLoS Comput. Biol</source>. <volume>11</volume>, <fpage>e1004485</fpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="preprint"><string-name><given-names>Kareem</given-names> <surname>Abdou</surname></string-name>, <string-name><given-names>Kiriko</given-names> <surname>Choko</surname></string-name>, <string-name><given-names>Mohamed H.</given-names> <surname>Aly</surname></string-name>, <string-name><given-names>Reiko</given-names> <surname>Okubo-Suzuki</surname></string-name>, <string-name><given-names>Shin ichi</given-names> <surname>Muramatsu</surname></string-name>, <string-name><given-names>Kaoru</given-names> <surname>Inokuchi</surname></string-name>. <article-title>Inspiring cognitive inference in a cortical network during REM sleep</article-title>. <source>bioRxiv</source> <elocation-id>2021.04.08.439095</elocation-id>.</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><string-name><surname>Keller</surname>, <given-names>G.B.</given-names></string-name> &amp; <string-name><surname>Mrsic-Flogel</surname>, <given-names>T.D.</given-names></string-name> <article-title>Predictive processing: a canonical cortical computation</article-title>. <source>Neuron</source> <volume>100</volume>, <fpage>424</fpage>–<lpage>435</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><string-name><surname>Kempter</surname> <given-names>R.</given-names></string-name>, <string-name><surname>Gerstner</surname> <given-names>W.</given-names></string-name> &amp; <string-name><surname>Van Hemmen</surname>, <given-names>J. L.</given-names></string-name> <article-title>Hebbian learning and spiking neurons</article-title>. <source>Physical Review E</source>. <volume>59</volume>, <fpage>4498</fpage> (<year>1999</year>).</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><string-name><surname>Kenet</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Bibitchkov</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Tsodyks</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Grinvald</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Arieli</surname>, <given-names>A.</given-names></string-name> <article-title>Spontaneously emerging cortical representations of visual attributes</article-title>. <source>Nature</source> <volume>425</volume>, <fpage>954</fpage>–<lpage>956</lpage> (<year>2003</year>).</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><string-name><surname>Kiebel</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>von Kriegstein</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Daunizeau</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Friston</surname>, <given-names>K. J.</given-names></string-name> <article-title>Recognizing sequences of sequences</article-title>. <source>PLoS computational biology</source>, <volume>5</volume>, <fpage>e1000464</fpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><string-name><surname>Klinzing</surname>, <given-names>J.G.</given-names></string-name>, <string-name><surname>Niethard</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Born</surname>, <given-names>J.</given-names></string-name> <article-title>Mechanisms of systems memory consolidation during sleep</article-title>. <source>Nat. Neurosci</source>. <volume>22</volume>, <fpage>1598</fpage>–<lpage>1610</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><string-name><surname>Kording</surname>, <given-names>K.P.</given-names></string-name> &amp; <string-name><surname>Wolpert</surname>, <given-names>D.M.</given-names></string-name> <article-title>Bayesian integration in sensorimotor learning</article-title>. <source>Nature</source> <volume>427</volume>, <fpage>244</fpage>–<lpage>247</lpage> (<year>2004</year>).</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><string-name><surname>Legaspi</surname>, <given-names>R.</given-names></string-name> &amp; <string-name><surname>Toyoizumi</surname>, <given-names>T.</given-names></string-name> <article-title>A Bayesian psychophysics model of sense of agency</article-title>. <source>Nat. Commun</source>. <volume>10</volume>, <fpage>4250</fpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><string-name><surname>Li</surname>, <given-names>A.A.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Wu</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Zhang</surname>, <given-names>X.</given-names></string-name> <article-title>Emergence of probabilistic representation in the neural network of primary visual cortex</article-title>. <source>iScience</source> <volume>25</volume>, <fpage>103975</fpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><string-name><surname>Litwin-Kumar</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Doiron</surname>, <given-names>B.</given-names></string-name> <article-title>Formation and maintenance of neuronal as-semblies through synaptic plasticity</article-title>. <source>Nat Commun</source>. <volume>5</volume>, <fpage>1</fpage>–<lpage>12</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><string-name><surname>Luczak</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>McNaughton</surname>, <given-names>B.L.</given-names></string-name> &amp; <string-name><surname>Kubo</surname>, <given-names>Y.</given-names></string-name> <article-title>Neurons learn by predicting future activity</article-title>. <source>Nat. Mach. Intell</source>. <volume>4</volume>, <fpage>62</fpage>–<lpage>72</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><string-name><surname>Ma</surname>, <given-names>W.J.</given-names></string-name>, <string-name><surname>Beck</surname>, <given-names>J.M.</given-names></string-name>, <string-name><surname>Latham</surname>, <given-names>P.E.</given-names></string-name> &amp; <string-name><surname>Pouget</surname>, <given-names>A.</given-names></string-name> <article-title>Bayesian inference with probabilistic population codes</article-title>. <source>Nat. Neurosci</source>. <volume>9</volume>, <fpage>1432</fpage>–<lpage>1438</lpage> (<year>2006</year>).</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><string-name><surname>Manz</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Memmesheimer</surname>, <given-names>R.M.</given-names></string-name> <article-title>Purely STDP-based assembly dynamics: Stability, learning, overlaps, drift and aging</article-title>. <source>PLoS Comput Biol</source>. <volume>19</volume>, <fpage>e1011006</fpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><string-name><surname>Masquelier</surname> <given-names>T.</given-names></string-name>, <string-name><surname>Guyonneau</surname> <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Thorpe</surname> <given-names>S. J.</given-names></string-name> <article-title>Spike timing dependent plasticity finds the start of repeating patterns in continuous spike trains</article-title>. <source>PloS one</source>. <volume>3</volume>, <fpage>e1377</fpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><string-name><surname>Mitchell</surname>, <given-names>S. J.</given-names></string-name>, &amp; <string-name><surname>Silver</surname>, <given-names>R. A.</given-names></string-name> <article-title>Shunting inhibition modulates neuronal gain during synaptic excitation</article-title>. <source>Neuron</source>, <volume>38</volume>, <fpage>433</fpage>–<lpage>445</lpage> (<year>2003</year>).</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><string-name><surname>Mongillo</surname> <given-names>G</given-names></string-name>, <string-name><surname>Rumpel</surname> <given-names>S</given-names></string-name>, <string-name><surname>Loewenstein</surname> <given-names>Y.</given-names></string-name> <article-title>Inhibitory connectivity defines the realm of excitatory plasticity</article-title>. <source>Nat Neurosci</source>. <volume>21</volume>:<fpage>1463</fpage>–<lpage>1470</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><string-name><surname>Montangie</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Miehl</surname>, <given-names>C.</given-names></string-name> &amp; <string-name><surname>Gjorgjieva</surname>, <given-names>J.</given-names></string-name> <article-title>Autonomous emergence of connectivity assemblies via spike triplet interactions</article-title>. <source>PLoS Comput Biol</source>.<volume>16</volume>, <fpage>e1007835</fpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><string-name><surname>Nessler</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Pfeiffer</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Buesing</surname>, <given-names>L.</given-names></string-name> &amp; <string-name><surname>Maass</surname>, <given-names>W.</given-names></string-name> <article-title>Bayesian computation emerges in generic cortical microcircuits through spike-timing-dependent plasticity</article-title>. <source>PLoS Comput. Biol</source>. <volume>9</volume>, <fpage>e1003037</fpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><string-name><surname>Orban</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Berkes</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Fiser</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Lengyel</surname>, <given-names>M.</given-names></string-name> <article-title>Neural variability and sampling-based probabilistic representations in the visual cortex</article-title>. <source>Neuron</source> <volume>92</volume>, <fpage>530</fpage>–<lpage>543</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><string-name><surname>Orban</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Fiser</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Aslin</surname>, <given-names>R.N.</given-names></string-name> &amp; <string-name><surname>Lengyel</surname>, <given-names>M.</given-names></string-name> <article-title>Bayesian learning of visual chunks by human observers</article-title>. <source>Proc. Natl. Acad. Sci. U. S. A</source>. <volume>105</volume>, <fpage>2745</fpage>–<lpage>2750</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><string-name><surname>Orbán</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Fiser</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Aslin</surname>, <given-names>R. N.</given-names></string-name>, &amp; <string-name><surname>Lengyel</surname>, <given-names>M.</given-names></string-name> <article-title>Bayesian learning of visual chunks by human observers</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>105</volume>, <fpage>2745</fpage>–<lpage>2750</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><string-name><surname>Rabinovich</surname>, <given-names>M. I.</given-names></string-name>, <string-name><surname>Varona</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Tristan</surname>, <given-names>I.</given-names></string-name>, &amp; <string-name><surname>Afraimovich</surname>, <given-names>V. S.</given-names></string-name> <article-title>Chunking dynamics: heteroclinics in mind</article-title>. <source>Frontiers in computational neuroscience</source>, <volume>8</volume> (<year>2014</year>).</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><string-name><surname>Ren</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Yoshimura</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Takada</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Horibe</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Komatsu</surname>, <given-names>Y.</given-names></string-name> (<year>2007</year>). <article-title>Specialized inhibitory synaptic actions between nearby neocortical pyramidal neurons</article-title>. <source>Science</source>, <volume>316</volume>(<issue>5825</issue>), <fpage>758</fpage>–<lpage>761</lpage>.</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><string-name><surname>Reynolds</surname>, <given-names>J. R.</given-names></string-name>, <string-name><surname>Zacks</surname>, <given-names>J. M.</given-names></string-name>, &amp; <string-name><surname>Braver</surname>, <given-names>T. S.</given-names></string-name> <article-title>A computational model of event segmentation from perceptual prediction</article-title>. <source>Cognitive science</source>, <volume>31</volume>, <fpage>613</fpage>–<lpage>643</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="journal"><string-name><surname>Schapiro</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Rogers</surname>, <given-names>T. T.</given-names></string-name>, <string-name><surname>Cordova</surname>, <given-names>N. I.</given-names></string-name>, <string-name><surname>Turk-Browne</surname>, <given-names>N. B.</given-names></string-name> &amp; <string-name><surname>Botvinick</surname>, <given-names>M. M.</given-names></string-name> <article-title>Neural representations of events arise from temporal community structure</article-title>. <source>Nat. Neurosci</source>. <volume>16</volume>, <fpage>486</fpage>–<lpage>492</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="journal"><string-name><surname>Song</surname> <given-names>S.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>K. D.</given-names></string-name> &amp; <string-name><surname>Abbott</surname>, <given-names>L. F.</given-names></string-name> <article-title>Competitive Hebbian learning through spike-timing-dependent synaptic plasticity</article-title>. <source>Nature neuroscience</source>. <volume>3</volume>, <fpage>919</fpage>–<lpage>926</lpage> (<year>2000</year>).</mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="journal"><string-name><surname>Sprekeler</surname>, <given-names>H.</given-names></string-name> <article-title>Functional consequences of inhibitory plasticity: homeostasis, the excitation-inhibition balance and beyond</article-title>. <source>Curr. Opin. Neurobiol</source>. <volume>43</volume>, <fpage>198</fpage>–<lpage>203</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="journal"><string-name><surname>Takehara-Nishiuchi</surname>, <given-names>K.</given-names></string-name> <article-title>Neurobiology of systems memory consolidation</article-title>. <source>Eur. J. Neurosci</source>. <volume>54</volume>, <fpage>6850</fpage>–<lpage>6863</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c63"><label>63.</label><mixed-citation publication-type="journal"><string-name><surname>Tonegawa</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Morrissey</surname>, <given-names>M.D.</given-names></string-name> &amp; <string-name><surname>Kitamura</surname>, <given-names>T.</given-names></string-name> <article-title>The role of engram cells in the systems consolidation of memory</article-title>. <source>Nat. Rev. Neurosci</source>. <volume>19</volume>, <fpage>485</fpage>–<lpage>498</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c64"><label>64.</label><mixed-citation publication-type="journal"><string-name><surname>Torres-Torrelo</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Torres</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Carrascal</surname>, <given-names>L.</given-names></string-name> <article-title>Modulation of the input-output function by GABAA receptor-mediated currents in rat oculomotor nucleus motoneurons</article-title>. <source>The Journal of physiology</source>, <volume>592</volume>, <fpage>5047</fpage>–<lpage>5064</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c65"><label>65.</label><mixed-citation publication-type="journal"><string-name><surname>Triplett</surname>, <given-names>M.A.</given-names></string-name>, <string-name><surname>Avitan</surname>, <given-names>L.</given-names></string-name> &amp; <string-name><surname>Goodhill</surname>, <given-names>G.J.</given-names></string-name> <article-title>Emergence of spontaneous assembly activity in developing neural networks without afferent input</article-title>. <source>PLoS Comput Biol</source>. <volume>14</volume>, <fpage>e1006421</fpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c66"><label>66.</label><mixed-citation publication-type="journal"><string-name><surname>Tully</surname>, <given-names>P.J.</given-names></string-name>, <string-name><surname>Hennig</surname>, <given-names>M.H.</given-names></string-name> &amp; <string-name><surname>Lansner</surname>, <given-names>A.</given-names></string-name> <article-title>Synaptic and nonsynaptic plasticity approximating probabilistic inference</article-title>. <source>Front. Synaptic Neurosci</source>. <volume>6</volume>, <fpage>8</fpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c67"><label>67.</label><mixed-citation publication-type="journal"><string-name><surname>Urbanczik</surname>, <given-names>R.</given-names></string-name> &amp; <string-name><surname>Senn</surname>, <given-names>W.</given-names></string-name> <article-title>Learning by the dendritic prediction of somatic spiking</article-title>. <source>Neuron</source>. <volume>81</volume>, <fpage>521</fpage>–<lpage>528</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c68"><label>68.</label><mixed-citation publication-type="journal"><string-name><surname>Vogels</surname> <given-names>T. P.</given-names></string-name>, <string-name><surname>Sprekeler</surname> <given-names>H.</given-names></string-name>, <string-name><surname>Zenke</surname> <given-names>F.</given-names></string-name>, <string-name><surname>Clopath</surname> <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Gerstner</surname> <given-names>W.</given-names></string-name> <article-title>Inhibitory plasticity balances excitation and inhibition in sensory pathways and memory networks</article-title>. <source>Science</source>. <volume>334</volume>, <fpage>1569</fpage>–<lpage>1573</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c69"><label>69.</label><mixed-citation publication-type="journal"><string-name><surname>Vogels</surname>, <given-names>T.P.</given-names></string-name>, <etal>et al.</etal> <article-title>Inhibitory synaptic plasticity: spike timing-dependence and putative network function</article-title>. <source>Front. Neural Circuits</source> <volume>7</volume>, <fpage>119</fpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c70"><label>70.</label><mixed-citation publication-type="journal"><string-name><surname>Zacks</surname>, <given-names>J. M.</given-names></string-name> <etal>et al.</etal> <article-title>Human brain activity time-locked to perceptual event boundaries</article-title>. <source>Nat. Neurosci</source>. <volume>18</volume>, <fpage>449</fpage>–<lpage>455</lpage> (<year>2001</year>).</mixed-citation></ref>
<ref id="c71"><label>71.</label><mixed-citation publication-type="journal"><string-name><surname>Zenke</surname> <given-names>F</given-names></string-name>, <string-name><surname>Agnes</surname> <given-names>EJ</given-names></string-name>, <string-name><surname>Gerstner</surname> <given-names>W.</given-names></string-name> <article-title>Diverse synaptic plasticity mechanisms or-chestrated to form and retrieve memories in spiking neural networks</article-title>. <source>Nat Commun</source>. <volume>6</volume>, <fpage>1</fpage>–<lpage>13</lpage> (<year>2015</year>).</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.92712.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Poirazi</surname>
<given-names>Panayiota</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>FORTH Institute of Molecular Biology and Biotechnology</institution>
</institution-wrap>
<city>Heraklion</city>
<country>Greece</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>The study by Asabuki et al. is a <bold>valuable</bold> contribution to understanding how cortical neural networks encode internal models into spontaneous activity. It uses a recurrent network of spiking neurons subject to predictive learning principles and provides a novel mechanism to learn the spontaneous replay of probabilistic sensory experiences. While promising in its ability to explain spontaneous network dynamics, the manuscript is <bold>incomplete</bold> in terms of the strength of support for its main findings. The difference of the proposed sampling dynamics from Markovian types of sampling is unclear and the use of non-negative synaptic strengths is applied in a non-biological manner.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.92712.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>In their manuscript, the authors propose a learning scheme to enable spiking neurons to learn the appearance probability of inputs to the network. To this end, the neurons rely on error-based plasticity rules for feedforward and recurrent connections. The authors show that this enables the networks to spontaneously sample assembly activations according to the occurrence probability of the input patterns they respond to. They also show that the learning scheme could explain biases in decision-making, as observed in monkey experiments. While the task of neural sampling has been solved before in other models, the novelty here is the proposal that the main drivers of sampling are within-assembly connections, and not between-assembly (Markov chains) connections as in previous models. This could provide a new understanding of how spontaneous activity in the cortex is shaped by synaptic plasticity.</p>
<p>The manuscript is well written and the results are presented in a clear and understandable way. The main results are convincing, concerning the spontaneous firing rate dependence of assemblies on input probability, as well as the replication of biases in the decision-making experiment. Nevertheless, the manuscript and model leave open several important questions. The main problem is the unclarity, both in theory and intuitively, of how the sampling exactly works. This also makes it difficult to assess the claims of novelty the authors make, as it is not clear how their work relates to previous models of neural sampling.</p>
<p>Regarding the unclarity of the sampling mechanism, the authors state that within-assembly excitatory connections are responsible for activating the neurons according to stimulus probability. However, the intuition for this process is not made clear anywhere in the manuscript. How do the recurrent connections lead to the observed effect of sampling? How exactly do assemblies form from feedforward plasticity? This intuitive unclarity is accompanied by a lack of formal justification for the plasticity rules. The authors refer to a previous publication from the same lab, but it is difficult to connect these previous results and derivations to the current manuscript. The manuscript should include a clear derivation of the learning rules, as well as an (ideally formal) intuition of how this leads to the sampling dynamics in the simulation.</p>
<p>Some of the model details should furthermore be cleared up. First, recurrent connections transmit signals instantaneously, which is implausible. Is this required, would the network dynamics change significantly if, e.g., excitation arrives slightly delayed? Second, why is the homeostasis on h required for replay? The authors show that without it the probabilities of sampling are not matched, but it is not clear why, nor how homeostasis prevents this. Third, G and M have the same plasticity rule except for G being confined to positive values, but there is no formal justification given for this quite unusual rule. The authors should clearly justify (ideally formally) the introduction of these inhibitory weights G, which is also where the manuscript deviates from their previous 2020 work. My feeling is that inhibitory weights have to be constrained in the current model because they have a different goal (decorrelation, not prediction) and thus should operate with a completely different plasticity mechanism. The current manuscript doesn't address this, as there is no overall formal justification for the learning algorithm.</p>
<p>Finally, the authors should make the relation to previous models of sampling and error-based plasticity more clear. Since there is no formal derivation of the sampling dynamics, it is difficult to assess how they differ exactly from previous (Markov-based) approaches, which should be made more precise. Especially, it would be important to have concrete (ideally experimentally testable) predictions on how these two ideas differ. As a side note, especially in the introduction (line 90), this unclarity about the sampling made it difficult to understand the contrast to Markovian transition models.</p>
<p>There are also several related models that have not been mentioned and should be discussed. In 663 ff. the authors discuss the contributions of their model which they claim are novel, but in Kappel et al (STDP Installs in Winner-Take-All Circuits an Online Approximation to Hidden Markov Model Learning) similar elements seem to exist as well, and the difference should be clarified. There is also a range of other models with lateral inhibition that make use of error-based plasticity (most recently reviewed in Mikulasch et al, Where is the error? Hierarchical predictive coding through dendritic error computation), and it should be discussed how the proposed model differs from these.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.92712.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The paper considers a recurrent network with neurons driven by external input. During the external stimulation predictive synaptic plasticity adapts the forward and recurrent weights. It is shown that after the presentation of constant stimuli, the network spontaneously samples the states imposed by these stimuli. The probability of sampling stimulus x^(i) is proportional to the relative frequency of presenting stimulus x^(i) among all stimuli i=1,..., 5.</p>
<p>Methods:</p>
<p>Neuronal dynamics:</p>
<p>For the main simulation (Figure 3), the network had 500 neurons, and 5 non-overlapping stimuli with each activating 100 different neurons where presented. The voltage u of the neurons is driven by the forward weights W via input rates x, the inhibitory recurrent weights G, are restricted to have non-negative weights (Dale's law), and the other recurrent weights M had no sign-restrictions. Neurons were spiking with an instantaneous Poisson firing rate, and each spike-triggered an exponentially decaying postsynaptic voltage deflection. Neglecting time constants of the postsynaptic responses, the expected postsynaptic voltage reads (in vectorial form) as</p>
<p>u = W x + (M - G) f (Eq. 5)</p>
<p>where f =; phi(u) represents the instantaneous Poisson rate, and phi a sigmoidal nonlinearity. The rate f is only an approximation (symbolized by =;) of phi(u) since an additional regularization variable h enters (taken up in Point 4 below). The initialisation of W and M is Gaussian with mean 0 and variance 1/sqrt(N), N the number of neurons in the network. The initial entries of G are all set to 1/sqrt(N).</p>
<p>Predictive synaptic plasticity:</p>
<p>The 3 types of synapses were each adapted so that they individually predict the postsynaptic firing rate f, in matrix form</p>
<p>ΔW ≈ (f - phi( W x ) ) x^T</p>
<p>
ΔM ≈ (f - phi( M f ) ) f^T</p>
<p>
ΔG ≈ (f - phi( M f ) ) f^T but confined to non-negative values of G (Dale's law).</p>
<p>The ^T tells us to take the transpose, and the ≈ again refers to the fact that the ϕ entering in the learning rule is not exactly the ϕ determining the rate, only up to the regularization (see Point 4).</p>
<p>Main formal result:</p>
<p>As the authors explain, the forward weight W and the unconstrained weight M develop such that, in expectations,</p>
<p>f =; phi( W x ) =; phi( M f ) =; phi( G f ) ,</p>
<p>consistent with the above plasticity rules. Some elements of M remain negative. In this final state, the network displays the behaviour as explained in the summary.</p>
<p>Major issues:</p>
<p>Point 1: Conceptual inconsistency</p>
<p>The main results seem to arise from unilaterally applying Dale's law only to the inhibitory recurrent synapses G, but not to the excitatory recurrent synapses M.</p>
<p>In fact, if the same non-negativity restriction were also imposed on M (as it is on G), then their learning rules would become identical, likely leading to M=G. But in this case, the network becomes purely forward, u = W x, and no spontaneous recall would arise. Of course, this should be checked in simulations.</p>
<p>Because Dale's law was only applied to G, however, M and G cannot become equal, and the remaining differences seem to cause the effect.</p>
<p>Predictive learning rules are certainly powerful, and it is reasonable to consider the same type of error-correcting predictive learning rule, for instance for different dendritic branches that both should predict the somatic activity. Or one may postulate the same type of error-correcting predictive plasticity for inhibitory and excitatory synapses, but then the presynaptic neurons should not be identical, as it is assumed here. Both these types of error-correcting and error-forming learning rules for same-branches and inhibitory/excitatory inputs have been considered already (but with inhibitory input being itself restricted to local input, for instance).</p>
<p>Point 2: Main result as an artefact of an inconsistently applied Dale's law?</p>
<p>The main result shows that the probability of a spontaneous recall for the 5 non-overlapping stimuli is proportional to the relative time the stimulus was presented. This is roughly explained as follows: each stimulus pushes the activity from 0 up towards f =; phi( W x ) by the learning rule (roughly). Because the mean weights W are initialized to 0, a stimulus that is presented longer will have more time to push W up so that positive firing rates are reached (assuming x is non-negative). The recurrent weights M learn to reproduce these firing rates too, while the plasticity in G tries to prevent that (by its negative sign, but with the restriction to non-negative values). Stimuli that are presented more often, on average, will have more time to reach the positive target and hence will form a stronger and wider attractor. In spontaneous recall, the size of the attractor reflects the time of the stimulus presentation. This mechanism so far is fine, but the only problem is that it is based on restricting G, but not M, to non-negative values.</p>
<p>Point 3: Comparison of rates between stimulation and recall.</p>
<p>The firing rates with external stimulations will be considerably larger than during replay (unless the rates are saturated).</p>
<p>This is a prediction that should be tested in simulations. In fact, since the voltage roughly reads as</p>
<p>
u = W x + (M - G) f,</p>
<p>
and the learning rules are such that eventually M =; G, the recurrences roughly cancel and the voltage is mainly driven by the external input x. In the state of spontaneous activity without external drive, one has</p>
<p>
u = (M - G) f ,</p>
<p>
and this should generate considerably smaller instantaneous rates f =; phi(u) than in the case of the feedforward drive (unless f is in both cases at the upper or lower ceiling of phi). This is a prediction that can also be tested.</p>
<p>Because the figures mostly show activity ratios or normalized activities, it was not possible for me to check this hypothesis with the current figures. So please show non-normalized activities for comparing stimulation and recall for the same patterns.</p>
<p>Point 4: Unclear definition of the variable h.</p>
<p>
The formal definition of h = hi is given by (suppressing here the neuron index i and the h-index of tau)</p>
<p>tau dh/dt = -h if h&gt;u, (Eq. 10)</p>
<p>
h = u otherwise.</p>
<p>But if it is only Equation 10 (nothing else is said), h will always become equal to u, or will vanish, i.e. either h=u or h=0 after some initial transient. In fact, as soon as h&gt;u, h is decaying to 0 according to the first line. If u is &gt;0, then it stops at u=h according to the second line. No reason to change h=u further. If u&lt;=0 while h&gt;u, then h is converging to 0 according to the first line and will stay there. I guess the authors had issues with the recurrent spiking simulations and tried to fix this with some regularization. However as presented, it does not become clear how their regulation works.</p>
<p>BTW: In Eq. 11 the authors set the gain beta to beta = beta0/h which could become infinite and, putatively more problematic, negative, depending on the value of h. Maybe some remark would convince a reader that no issues emerge from this.</p>
<p>Added from discussions with the editor and the other reviewers:</p>
<p>Thanks for alerting me to this Supplementary Figure 8. Yes, it looks like the authors did apply there Dale's law for both the excitatory and inhibitory synapses. Yet, they also introduced two types of inhibitory pathways converging both to the excitatory and inhibitory neurons. For me, this is a confirmation that applying Dale's law to both excitatory and inhibitory synapses, with identical learning rules as explained in the main part of the paper, does not work.</p>
<p>Adding such two pathways is a strong change from the original model as introduced before, and based on which all the Figures in the main text are based. Supplementary Figure 8 should come with an analysis of why a single inhibitory pathway does not work. I guess I gave the reason in my Points 1-3. Some form of symmetry breaking between the recurrent excitation and recurrent inhibition is required so that, eventually, the recurrent excitatory connection will dominate.</p>
<p>Making the inhibitory plasticity less expressive by applying Dale's law to only those inhibitory synapses seems to be the answer chosen in the Figures of the main text (but then the criticism of unilaterally applying Dale's law).</p>
<p>Applying Dale's law to both types of synapses, but dividing the labor of inhibition into two strictly separate and asymmetric pathways, and hence asymmetric development of excitatory and inhibitory weights, seems to be another option. However, introducing such two separate inhibitory pathways, just to rescue the fact that Dale's law is applied to both types of synapses, is a bold assumption. Is there some biological evidence of such two pathways in the inhibitory, but not the excitatory connections? And what is the computational reasoning to have such a separation, apart from some form of symmetry breaking between excitation and inhibition? I guess, simpler solutions could be found, for instance by breaking the symmetry between the plasticity rules for the excitatory and inhibitory neurons. All these questions, in my view, need to be addressed to give some insights into why the simulations do work.</p>
<p>Overall, Supplementary Figure 8 seems to me too important to be deferred to the Supplement. The reasoning behind the two inhibitory pathways should appear more prominently in the main text. Without this, important questions remain. For instance, when thinking in a rate-based framework, the two inhibitory pathways twice try to explain the somatic firing rate away. Doesn't this lead to a too strong inhibition? Can some steady state with a positive firing rate caused by the recurrence, in the absence of an external drive, be proven? The argument must include the separation into Path 1 and Path 2. So far, this reasoning has not been entered.</p>
<p>In fact, it might be that, in a spiking implementation, some sparse spikes will survive. I wonder whether at least some of these spikes survive because of the other rescuing construction with the dynamic variable h (Equation 10, which is not transparent, and that is not taken up in the reasoning either, see my Point 4).</p>
<p>Perhaps it is helpful for the authors to add this text in the reply to them.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.92712.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The work shows how learned assembly structure and its influence on replay during spontaneous activity can reflect the statistics of stimulus input. In particular, stimuli that are more frequent during training elicit stronger wiring and more frequent activation during replay. Past works (Litwin-Kumar and Doiron, 2014; Zenke et al., 2015) have not addressed this specific question, as classic homeostatic mechanisms forced activity to be similar across all assemblies. Here, the authors use a dynamic gain and threshold mechanism to circumnavigate this issue and link this mechanism to cellular monitoring of membrane potential history.</p>
<p>Strengths:</p>
<p>(1) This is an interesting advance, and the authors link this to experimental work in sensory learning in environments with non-uniform stimulus probabilities.</p>
<p>(2) The authors consider their mechanism in a variety of models of increasing complexity (simple stimuli, complex stimuli; ignoring Dale's law, incorporating Dale's law).</p>
<p>(3) Links a cellular mechanism of internal gain control (their variable h) to assembly formation and the non-uniformity of spontaneous replay activity. Offers a promise of relating cellular and synaptic plasticity mechanisms under a common goal of assembly formation.</p>
<p>Weaknesses:</p>
<p>(1) However, while the manuscript does show that assembly wiring does follow stimulus likelihood, it is not clear how the assembly-specific statistics of h reflect these likelihoods. I find this to be a key issue.</p>
<p>(2) The authors' model does take advantage of the sigmoidal transfer function, and after learning an assembly is either fully active or nearly fully silent (Figure 2a). This somewhat artificial saturation may be the reason that classic homeostasis is not required since runaway activity is not as damaging to network activity.</p>
<p>(3) Classic mechanisms of homeostatic regulation (synaptic scaling, inhibitory plasticity) try to ensure that firing rates match a target rate (on average). If the target rate is the same for all neurons then having elevated firing rates for one assembly compared to others during spontaneous activity would be difficult. If these homeostatic mechanisms were incorporated, how would they permit the elevated firing rates for assemblies that represent more likely stimuli?</p>
</body>
</sub-article>
</article>