<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">96402</article-id>
<article-id pub-id-type="doi">10.7554/eLife.96402</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.96402.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Nonlinear feedback modulation contributes to the optimization of flexible decision-making</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Wu</surname>
<given-names>Xuanyu</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Zhou</surname>
<given-names>Yang</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Peking-Tsinghua Center for Life Sciences, Peking University</institution>, Beijing, 100871, <country>China</country></aff>
<aff id="a2"><label>2</label><institution>School of Psychological and Cognitive Sciences, Peking University</institution>, Beijing, 100871, <country>China</country></aff>
<aff id="a3"><label>3</label><institution>PKU-IDG/McGovern Institute for Brain Research, Peking University</institution>, Beijing, 100871, <country>China</country></aff>
<aff id="a4"><label>4</label><institution>Department of Neurobiology, The University of Chicago</institution>, Chicago, Illinois 60637</aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Krug</surname>
<given-names>Kristine</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Otto-von-Guericke University Magdeburg</institution>
</institution-wrap>
<city>Magdeburg</city>
<country>Germany</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Bi</surname>
<given-names>Yanchao</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Beijing Normal University</institution>
</institution-wrap>
<city>Beijing</city>
<country>China</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label><bold>Corresponding author:</bold> Yang Zhou <bold>Email:</bold> <email>yangzhou1@pku.edu.cn</email></corresp>
<fn fn-type="con" id="n1"><p><bold>Author Contributions:</bold> Y.Z. designed the experiments and wrote the manuscript. Y.Z. trained monkeys and collected the behavioral and neuronal data, Y.Z. and X.W. analyzed the data and made the figures. Y.Z. and X.W. designed the network models, X.W. trained the RNNs, analyzed the RNNs and implemented the RNN inactivation experiment. Y.Z. supervised the project.</p></fn>
<fn fn-type="coi-statement" id="n2"><p><bold>Competing Interest Statement:</bold> The authors declare no competing financial interests.</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-06-13">
<day>13</day>
<month>06</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP96402</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-02-05">
<day>05</day>
<month>02</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-03-25">
<day>25</day>
<month>03</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.07.15.549136"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Wu &amp; Zhou</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Wu &amp; Zhou</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-96402-v1.pdf"/>
<abstract>
<title>Abstract</title><p>Neural activity in the primate brain correlates with both sensory evaluation and action selection aspects of decision-making. However, the intricate interaction between these distinct neural processes and their impact on decision behaviors remains unexplored. Here, we examined the interplay of these decision processes in posterior parietal cortex (PPC) when monkeys performed a flexible decision task. We found that the PPC activity related to monkeys’ abstract decisions about visual stimuli was nonlinearly modulated by monkeys’ following saccade choices directing outside each neuron’s response field. Recurrent neural network modeling indicated that the feedback connections, matching the learned stimuli-response associations during the task, mediated such feedback modulation. Further analysis on network dynamics revealed that selectivity-specific feedback connectivity intensified the attractor basins of population activity underlying saccade choices, thereby increasing the consistency of flexible decisions. These results highlight an iterative computation between different decision processes, mediated primarily by precise feedback connectivity, contributing to the optimization of flexible decision-making.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>Decision-making</kwd>
<kwd>Monkey electrophysiology</kwd>
<kwd>Posterior parietal cortex</kwd>
<kwd>Feedback modulation</kwd>
<kwd>Artificial neural network. attractor basin</kwd>
</kwd-group>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>The revised manuscript is titled 'Nonlinear feedback modulation contributes to the optimization of flexible decision-making'. It incorporates changes to all sections of the text, modifications to Main Figures 2, 5, and the addition of a new Figure 6, along with extended data figures. Specifically, to uncover the computational mechanisms behind nonlinear feedback modulation in flexible decision-making, we added new analyses focusing on attractor dynamics in the state space of network activity. These analyses reveal that the observed nonlinear feedback modulation, primarily mediated by selectivity-specific feedback connectivity, enhances the attractor basins of population activity guiding action choices, thereby increasing the consistency of flexible decisions.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Perceptual decisions typically involve the transformation of sensory inputs to discrete motor responses. Consequently, sensory evaluation and action selection emerge as two fundamental processes essential for implementing perceptual decision behavior<sup><xref ref-type="bibr" rid="c1">1</xref>–<xref ref-type="bibr" rid="c7">7</xref></sup>. Neural activity associated with either the sensory or motor aspects of decision-making is widely distributed across different brain areas, such as PPC <sup><xref ref-type="bibr" rid="c8">8</xref>–<xref ref-type="bibr" rid="c22">22</xref></sup>, frontal cortex <sup><xref ref-type="bibr" rid="c18">18</xref>,<xref ref-type="bibr" rid="c23">23</xref>–<xref ref-type="bibr" rid="c28">28</xref></sup>, superior colliculus <sup><xref ref-type="bibr" rid="c29">29</xref>,<xref ref-type="bibr" rid="c30">30</xref></sup>, and caudate <sup><xref ref-type="bibr" rid="c31">31</xref></sup>. A recent inactivation study has shown that the lateral intraparietal area (LIP), a subregion of PPC, plays a causal role in flexible visuomotor decisions, with preferential involvement in sensory evaluation rather than action selection <sup><xref ref-type="bibr" rid="c14">14</xref></sup>. Meanwhile, areas outside PPC, like frontal eye field and superior colliculus, have been shown to be causally involved in the action selection aspect of decision-making <sup><xref ref-type="bibr" rid="c32">32</xref>,<xref ref-type="bibr" rid="c33">33</xref></sup>. These findings suggest that sensory evaluation and action selection likely involve distinct neural processing in the primate brain during flexible decision-making.</p>
<p>However, previous reports have also shown that neural activity related to sensory evaluation and action selection overlaps temporally and spatially in the brain <sup><xref ref-type="bibr" rid="c34">34</xref></sup>. This leaves open the possibility of interplay between these distinct processes during decision-making. From the perspective of information processing, the abstract result of sensory evaluation should be transmitted to the motor planning circuits to guide the action selection process in a feedforward manner, although both processes could proceed in parallel in the brain. However, whether and how action selection processes might exert a feedback influence on sensory evaluation have not been explicitly studied.</p>
<p>In this study, we examined the activities of single LIP neurons during a flexible decision task in which monkeys needed to report their decisions about a motion stimulus with a saccade to one of two color targets. Specifically, we arranged the motion stimuli inside each neuron’s response field (RF), and positioned the saccade targets in the direction perpendicular to the axis of neural RFs. We found that LIP activity responded to visual motion was nonlinearly modulated by the monkeys’ following saccade choice direction relative to the recorded brain hemisphere. Notably, this modulation was aligned precisely with the functional properties of each neuron, as well as specifically impacted the decision-correlated but not the stimulus-correlated activity of LIP neurons. This suggests a precise ‘feedback’ modulation from action selection process to the neural processing of sensory evaluation during decision-making.</p>
<p>RNN models trained on complex behavioral tasks have shown promise for understanding neural computations and circuit mechanisms underlying cognitive functions <sup><xref ref-type="bibr" rid="c35">35</xref>–<xref ref-type="bibr" rid="c37">37</xref></sup>. To further explore how action selection can modulate sensory evaluation during decision-making, we trained multi-module RNNs, which consist of different hemispheres and RF structures, to perform the same decision task and analyzed the activity of network units during task performance. These RNNs exhibited similar behavioral performance and neural activity patterns as observed in the monkey electrophysiology experiment, including patterns of nonlinear feedback modulation from action selection to sensory evaluation. Combining analysis on network activity and connectivity with projection-specific inactivation experiments in the RNNs, we further showed that the precise feedback connections between units that showed matched functional properties within different network modules were the key circuit mechanism for mediating the modulation of sensory evaluation by action selection. Such feedback modulation significantly enhanced the consistency of the RNNs’ decisions by strengthening the attractor basins of network dynamics underlying saccade choices.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Nonlinear feedback modulation of saccade choice on visual motion selectivity in LIP</title>
<p>To test the mechanisms underlying the feedback modulation of action selection on sensory evaluation, we trained two monkeys to perform a reaction-time version of the flexible visual-motion discrimination (FVMD) task, in which they needed to choose one of two colored saccade targets based on their decisions about the motion direction of a sample stimulus shown at different coherence levels (<bold><xref rid="fig1" ref-type="fig">Figure 1A</xref></bold>). Monkeys learned the mappings between the two motion directions (315° and 135°) and two target colors (red and green) at the start of training, and the mappings were fixed across the study. Because the locations of the red and green targets were randomly interleaved across trials, neither of the motion directions was directly linked with one specific saccade direction. Both the performance accuracy and the reaction time (RT) changed systematically as a function of motion coherence levels (<bold><xref rid="fig1" ref-type="fig">Figure 1B</xref>-<xref rid="fig1" ref-type="fig">1E</xref></bold>): as the motion coherence increased, both monkeys chose the correct target more frequently and more rapidly.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Behavioral task.</title>
<p>(<bold>A</bold>) The flexible visual-motion discrimination (FVMD) task. Monkeys needed to report their decision about the direction of the visual motion stimuli by choosing either the green or red saccade target. The appearance of the two color targets preceded that of the visual-motion stimulus, and the target positions were randomly chosen on each trial to avoid fixed mapping between motion stimulus and saccade direction. Monkeys could initiate their saccade as soon as they had made their decision. (<bold>B-C</bold>) Psychometric curves for the two monkeys. The performance accuracy for each monkey is plotted as the proportion of trials in which 315° was chosen as a function of the directions and coherence levels of the motion stimuli. (<bold>D-E</bold>) Chronometric curves are shown separately for the two monkeys. (<bold>F-G</bold>) Two trial conditions, contralateral (F) and ipsilateral (G), defined according to the spatial configurations of task stimuli during neural recording.</p></caption>
<graphic xlink:href="549136v2_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We recorded single-neuron activity from the LIP while the monkeys performed the FVMD task. To examine the neural activity related to the evaluation of stimulus motion, we presented the motion stimuli within the RF of each neuron but arranged the saccade targets at locations orthogonal to the axis of the neural RF. In total, 104 of 194 visually responsive LIP neurons (monkey M: 50/78; monkey B: 54/116) showed significant direction selectivity (DS) to the motion stimuli (one-way ANOVA, P &lt; 0.01). To examine the influence of action selection on sensory evaluation, we analyzed data from the subset of sessions in which the saccade targets were aligned more closely with the horizontal direction than the vertical direction (83 of 104 neurons). In these sessions, the motor planning corresponding to a saccade to either target would be mediated primarily by one brain hemisphere. We therefore defined the conditions under which the correct target was contralateral or ipsilateral to the recorded hemisphere as the contralateral target (CT) condition or ipsilateral target (IT) condition, respectively (<bold><xref rid="fig1" ref-type="fig">Figure 1F</xref></bold> and <bold><xref rid="fig1" ref-type="fig">1G</xref></bold>).</p>
<p><bold><xref rid="fig2" ref-type="fig">Figure 2A</xref>-<xref rid="fig2" ref-type="fig">2F</xref></bold> shows three example LIP neurons that exhibited significant motion coherence correlated DS. Surprisingly, LIP neurons showed greater DS in the CT condition than in the IT condition, even though the same motion stimuli were used in the same spatial location for both conditions. The averaged population activity showed this DS difference between CT and IT conditions for all four coherence levels (<bold><xref rid="fig2" ref-type="fig">Figure 2G</xref>, <xref rid="fig2" ref-type="fig">2H</xref></bold>). During presentation of their preferred motion direction, LIP neurons showed significantly elevated activity in the CT relative to the IT at all coherence levels (<bold>Figure S1A, S1B</bold>, nested ANOVA: P<sub>(high)</sub> = 0.0326, F = 4.65; P<sub>(medium)</sub> = 0.0088, F = 7.03; P<sub>(low)</sub> = 0.0076, F = 7.32; P<sub>(zero)</sub> = 0.0124, F = 6.4), and a trend toward lower activity to the nonpreferred direction for CT vs. IT (<bold>Figure S1C, S1D,</bold> nested ANOVA: P<sub>(high)</sub> = 0.0994, F = 2.75; P<sub>(medium)</sub> = 0.0649, F = 3.12; P<sub>(low)</sub> = 0.0311, F = 4.73; P<sub>(zero)</sub> = 0.0273, F = 4.96). Most of the LIP neurons (48 of 83) showed such opposing trends in activity modulation between the preferred and nonpreferred directions (<xref rid="fig2" ref-type="fig">Figure 2I</xref>). Receiver operating characteristic (ROC) analysis further confirmed significantly greater motion DS in the CT condition than in the IT condition (<bold><xref rid="fig2" ref-type="fig">Figure 2J</xref></bold> and <bold><xref rid="fig2" ref-type="fig">2K</xref></bold>; nested ANOVA: P<sub>(high)</sub> = 5.0e-4, F= 12.44; P<sub>(medium)</sub> = 9.53e-6, F = 20.91; P<sub>(low)</sub> = 9.33e-7, F = 26.03; P<sub>(zero)</sub> = 2.56e-8, F= 34.3). Such DS differences were observed even before stimulus onset. Meanwhile, LIP neurons exhibited similar levels of mean activity between different saccade directions (CT vs. IT) before monkeys’ saccade choice (<bold>Figure S1E</bold>). These results indicated a nonlinear modulation of saccade choice on motion DS in LIP, aligned precisely with the response property of each neuron. Furthermore, a demixed principal component analysis on the pseudo-population activity (STAR Methods) revealed that the saccade direction related representation was a substantial component of LIP activity, as the saccade direction and motion–saccade interaction together explained a similar amount of variance in the population activity as the stimulus motion direction did (<bold><xref rid="fig2" ref-type="fig">Figure 2L</xref></bold> and <bold>Figure S2</bold>). In contrast, we did not observe significant DS differences between the CT and IT conditions in the data sessions in which the saccade targets were aligned close to the vertical direction (21 of 104 neurons, <bold>Figure S3</bold>).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Nonlinear feedback modulation of saccade choice on sensory evaluation in LIP.</title>
<p><bold>(A)</bold> The activity of one example neuron in the CT condition of the FVMD task is shown for each motion-coherence level. The zero-coherence trials were grouped based on the monkey’s choices. The two vertical dashed lines denote the time of target and motion stimulus onset, respectively. <bold>(B)</bold> The same example neuron’s activity in the IT condition of the FVMD task. <bold>(C-F)</bold> The activities of two more example neurons<bold>. (G-H)</bold> The averaged population activities of all direction-selective neurons (n = 83) that were collected during the recording sessions in which the saccade targets were arranged in either horizontal or oblique directions. The activity to each motion direction and coherence level is shown separately for the CT condition (G) and IT condition (H). (I) The activity differences between CT and IT conditions (CT minus IT) of single LIP neurons were plotted for both preferred and nonpreferred motion directions. Each dot represents the activity of a single neuron. The histograms in horizontal and vertical axis represent the distribution of activity difference between CT and IT conditions for preferred and nonpreferred motion directions, respectively. (J) An ROC analysis was used for quantifying the motion DS for both CT (solid) and IT (dashed) conditions. The colored dots denote the time points for which there was a significant difference between the CT and IT conditions (paired t-test: P &lt; 0.01). <bold>(K)</bold> The average DS for low- and zero-coherence trials is shown as in (J). <bold>(L)</bold> Variance in LIP population activity as explained by the individual demixed principal components. Each bar shows the proportion of total explained variance that was contributed by the four task variables. The pie chart shows the total variance explained by each task variable. H, high; M, medium; L, low; 0, zero; P, preferred; NP nonpreferred.</p></caption>
<graphic xlink:href="549136v2_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2b">
<title>Feedback modulation specifically impacted the decision-correlated activity in LIP</title>
<p>We then examined the impact of nonlinear feedback modulation on the correlation between LIP DS and monkeys’ choice behavior. We found that LIP DS was more decision-correlated in the CT condition than in the IT condition. Illustrated in <xref rid="fig2" ref-type="fig">Figure 2K</xref>, the LIP DS on zero-coherence trials, which reflected monkeys’ trial-by-trial categorical choice, was significantly greater in the CT condition than in the IT condition (nested ANOVA: P = 2.56e-8, F= 34.3). We also quantified the correlation between LIP neural activity and the trial-by-trial categorical choice or the physical motion direction by comparing LIP neural activity on correct versus incorrect trials. We used low-coherence trials, as monkeys made enough errors in these trials. In the CT condition but not the IT condition, LIP DS at the population level was significantly reversed in sign on incorrect trials as compared to correct trials (<bold><xref rid="fig3" ref-type="fig">Figure 3A</xref></bold> and <bold><xref rid="fig3" ref-type="fig">3B</xref></bold>; nested ANOVA: P<sub>(CT)</sub> = 0.0045, F = 8.32). Accordingly, in the CT condition but not in the IT condition, LIP activity correlated more closely with the monkeys’ trial-by-trial abstract decisions about motion direction, as opposed to the physical motion direction (<bold><xref rid="fig3" ref-type="fig">Figure 3C</xref></bold> and <bold><xref rid="fig3" ref-type="fig">3D</xref></bold>; nested ANOVA, P<sub>(CT)</sub> = 0.0016, F = 10.31; P<sub>(IT)</sub> = 0.443, F = 0.59). Meanwhile, LIP activity correlated more closely with the trial-by-trial abstract decisions during the CT condition relative to the IT condition on the low coherence trials (nested ANOVA: P = 1.95e-8, F = 34.94). Furthermore, we used partial correlation analysis to examine decision- and stimulus-related components of DS (i.e., r-decision and r-stimulus, <bold><xref rid="fig3" ref-type="fig">Figure 3E</xref></bold> and <bold><xref rid="fig3" ref-type="fig">3F</xref></bold>) using all four coherence levels. The decision-related component of LIP DS was significantly greater in the CT condition than in the IT condition (<bold><xref rid="fig3" ref-type="fig">Figure 3E</xref></bold>; nested ANOVA: P = 1.07e-6, F= 25.72), and this difference emerged even before motion stimulus onset. This suggests that the LIP DS was more closely correlated with monkeys’ decisions in the CT condition than in the IT condition. However, the stimulus-related component of the LIP DS was similar at the population level between the two conditions (<bold><xref rid="fig3" ref-type="fig">Figure 3F</xref></bold>; nested ANOVA: P = 0.7606, F = 0.09), suggesting that the modulation of LIP DS by the later saccade choice was primarily related to a decision process rather than basic sensory processing.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Feedback modulation specifically impacted the decision-correlated activity.</title>
<p>(<bold>A-B</bold>) Averaged population activities on low-coherence trials in the CT condition (A) and IT condition (B) are shown separately for correct (corr) and error (err) trials. (<bold>C-D</bold>) An ROC analysis quantified the stimulus-related and decision-related LIP DS on low-coherence trials. The correlations between LIP neural activity and the monkeys’ decisions about motion direction (red) or the physical direction of the motion stimulus (blue) in both the CT (C) and IT (D) conditions are shown over time. (<bold>E-F</bold>) Partial correlation analysis revealed the decision-related and stimulus-related components of LIP activity. The values for r-decision (E) (the partial correlation between neuronal activity and monkeys’ choice, given the stimulus direction) and r-stimulus (F) (partial correlation between neuronal activity and stimulus direction, given the monkeys’ choices) were compared between the IT and CT conditions. (<bold>G-H</bold>) Correlation between LIP DS and the monkeys’ RTs on zero-coherence trials. The choice selectivity on zero-coherence trials is shown for the faster RT and slower RT trials. Shaded areas denote ±SEM. The black stars indicate time periods in which there was a significant difference (paired t-test: P &lt; 0.01).</p></caption>
<graphic xlink:href="549136v2_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We further examined the impact of nonlinear feedback modulation on the correlation between LIP DS and the monkeys’ RTs. Shortly after motion stimulus onset, LIP neurons showed greater population response to their preferred motion direction on shorter versus longer RT trials for all motion coherence levels in the CT condition (<bold>Figure S4</bold>) but not in the IT condition (<bold>Figure S5</bold>). On zero-coherence trials (<bold><xref rid="fig3" ref-type="fig">Figure 3G</xref></bold> and <bold><xref rid="fig3" ref-type="fig">3H</xref></bold>), DS evolved more rapidly on shorter vs. longer RT trials in the CT condition but not in the IT condition (bootstrap: P<sub>(CT)</sub> &lt; 0.01, P<sub>(IT)</sub> = 0.87). Together, these results indicated that the feedback modulation of saccade choice on sensory evaluation predominantly impacted the decision-correlated activity in LIP.</p>
</sec>
<sec id="s2c">
<title>Trained multi-module RNNs replicated the nonlinear feedback modulation</title>
<p>Our electrophysiology data show that action selection nonlinearly modulates the neural processing of sensory evaluation, which indicates a complex, iterative computation for flexible decision-making. Training RNNs on behavioral tasks used in experimental neurophysiological studies has proven to be helpful for exploring putative circuit computations underlying cognitive tasks<sup><xref ref-type="bibr" rid="c28">28</xref>,<xref ref-type="bibr" rid="c36">36</xref>,<xref ref-type="bibr" rid="c37">37</xref></sup>. Therefore, we trained multi-module RNNs to perform the FVMD task to examine the circuits and computation mechanisms underlying the interplay of different decision processes. We adopted simple neurobiological principles to constrain the connection structure but not the functional roles to generate recurrently connected modules (STAR Methods). Because our neurophysiological results showed that the modulation effect of action selection on sensory evaluation depended on the saccade direction relative to the recorded brain hemisphere, we implemented RNNs composed of two main modules organized in parallel to simulate two brain hemispheres. Each main module consisted of two nominal modules, with each nominal module receiving the visual motion input (motion module) or the target color input (target module), corresponding to the two neuron populations whose RFs covered the motion stimulus or saccade targets, respectively (<bold><xref rid="fig4" ref-type="fig">Figure 4A</xref></bold>).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Multi-module RNNs trained with the FVMD task.</title>
<p><bold>(A)</bold> Model schematic of the RNNs. Each RNN consists of nine motion direction tuned input units, eight color tuned target input units, 200 hidden units, and two response units. The hidden layer of each RNN consists of two main modules. Each main module consists of two nominal modules, each of which receives either the visual motion input (motion module) or the target color input (target module). Only the target modules project to the two response units, and each main module projects primarily to one response unit. All four nominal modules were assigned with equal number of units (25%) in the network, which consisted of 80% excitatory and 20% inhibitory units. <bold>(B-C)</bold> The performance accuracies (B) and RTs (C) of all 50 trained RNNs are shown separately for each motion coherence level. <bold>(D-E)</bold> Two example units from an example RNN. (<bold>D)</bold> The neural activity of an example unit from the motion module is shown for each motion direction and coherence level. <bold>(E)</bold> The neural activity of an example unit from the target module is shown for each saccade direction and coherence level. (<bold>F-G)</bold> The motion DS for the motion module (F) and saccade DS for the target module (G) for the example RNN. <bold>(H-I)</bold> The averaged population activities of all direction-selective units in the motion module of the example RNN are shown for the CT condition (H) and IT condition (I). <bold>(J-K)</bold> The averaged motion DS in the motion module of the example RNN for both the CT (solid) and IT (dashed) conditions was quantified by ROC analysis<bold>. (L-M)</bold> Partial correlation analysis. The values for r-decision (L) and r-stimulus (M) are compared between the IT and CT conditions for the example RNN<bold>. (N)</bold> A comparison of the motion DS in the motion module of all trained RNNs between the CT and IT conditions is shown for each coherence level. (<bold>O)</bold> A comparison of the r-decision and r-stimulus between the IT and CT conditions is shown for all trained RNNs. (Paired t-test: ***, P &lt; 0.001).</p></caption>
<graphic xlink:href="549136v2_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We independently trained 50 such networks with randomly initialized weights and identical hyperparameters to perform the FVMD task. The FVMD task setup used for training RNNs was tailored to match the monkey experiments. Specifically, the RNNs were trained using motion stimuli with two high-coherence levels and were tested using stimuli with another four different coherence levels (high, medium, low, and zero). After training, all 50 networks converged to perform the FVMD task with high accuracies (&gt;99%) on the training coherence and exhibited coherence-dependent performances when tested with untrained stimuli (<bold><xref rid="fig4" ref-type="fig">Figure 4B</xref></bold> and <bold><xref rid="fig4" ref-type="fig">4C</xref></bold>): accuracy increased and RT decreased with motion coherence.</p>
<p>We then analyzed the unit activity in different modules when the trained RNNs were tested with untrained motion stimuli. Across all networks, the units in the motion module and target modules exhibited activity corresponding to sensory evaluation and action selection, respectively. Specifically, units in the motion modules showed coherence-correlated motion DS (<bold><xref rid="fig4" ref-type="fig">Figure 4D</xref></bold> and <bold><xref rid="fig4" ref-type="fig">4F</xref></bold> and <bold>Figure S6</bold> and <bold>S7</bold>; mean r = 0.29; one-sample t-test: P = 4.09e-42, t(49) = 46.31), and neuronal activity on zero-coherence motion trials reflected the trial-by-trial abstract decisions of the networks (t-test: P<sub>(example RNN)</sub> = 5.97e-27, t(91) = 15.33; P<sub>(population)</sub> = 1.05e-31, t(49) = 27.86). Such motion DS resembled our electrophysiology data when the motion stimuli were presented within the RFs of the LIP neurons. Meanwhile, units in the target modules showed coherence-correlated saccade DS (<bold><xref rid="fig4" ref-type="fig">Figure 4E</xref></bold> and <bold><xref rid="fig4" ref-type="fig">4G</xref></bold> and <bold>Figure S6</bold> and <bold>S7</bold>), and the neuronal activity on zero-coherence motion trials also showed significant choice probability (t-test: P<sub>(example RNN)</sub> = 7.06e-8, t(68) =15.83; P<sub>(population)</sub> = 2.08e-22, t(49) = 17.21). Such saccade DS was consistent with the commonly observed decision-related activity in previous studies in which the saccade target was presented within the RFs of LIP neurons<sup><xref ref-type="bibr" rid="c9">9</xref>–<xref ref-type="bibr" rid="c11">11</xref></sup>.</p>
<p>Furthermore, we found that the motion DS of units in the motion modules was significantly greater in the CT condition than in the IT condition for the majority of RNNs (<bold><xref rid="fig4" ref-type="fig">Figure 4H</xref></bold> and <bold><xref rid="fig4" ref-type="fig">4I</xref></bold> and <bold>Figure S8A</bold> and <bold>S8B</bold>): in the CT condition relative to the IT condition, activity was significantly greater for the preferred motion direction but weaker for the nonpreferred direction (<bold>Figure S9</bold>). ROC analysis confirmed that the motion DS in the motion module was significantly greater for all four coherence levels in the CT vs. IT conditions in most RNNs (<bold><xref rid="fig4" ref-type="fig">Figure 4J</xref>, <xref rid="fig4" ref-type="fig">4K</xref></bold> and <bold><xref rid="fig4" ref-type="fig">4N</xref></bold> and <bold>Figure S8C</bold> and <bold>S8D</bold>; two-way ANOVA: P<sub>(example RNN)</sub> = 1.53e-11, F = 47.49; P<sub>(population)</sub> = 3.50e-77, F = 660.84). Similar to the monkey electrophysiology data, the decision-correlated motion DS (r-decision) in the motion module was dramatically reduced in the IT versus CT condition (paired t-test: P = 6.84e-17, t(49)= -12.53), and this difference was substantially greater than the difference in the stimulus-related (r-stimulus) motion DS between the two conditions (paired t-test: P = 2.02e-14, t(49) = -10.70; <bold><xref rid="fig4" ref-type="fig">Figure 4L</xref>, <xref rid="fig4" ref-type="fig">4M</xref></bold>and <bold><xref rid="fig4" ref-type="fig">4O</xref></bold> and <bold>Figure S8E</bold> and <bold>S8F</bold>). These results indicated that action selection also nonlinearly modulated the neural processing of sensory evaluation during decision-making in the RNNs.</p>
</sec>
<sec id="s2d">
<title>Selectivity-specific feedback connections mediate the modulation of sensory evaluation by action selection</title>
<p>Our multi-module RNNs showed a remarkable similarity to both the behavioral performances and the neural activity patterns in the monkey electrophysiology data, suggesting that these networks may have adopted mechanisms similar to those in the monkey brain to mediate the decision processes in the FVMD task. Therefore, we explored the potential circuit mechanisms underlying the modulation of action selection on sensory evaluation in RNNs. We hypothesized that this modulation might result from the feedback connections from the target module to the motion module. To test this hypothesis, we examined the recurrent weights of the cross-module connections (STAR Methods). Both the feedback and feedforward cross-module connection weights were significantly greater between the selectivity-matched unit pairs (e.g., units in the motion module preferred to encode 315° and units in the target module preferred to encode red) than the selectivity-nonmatched unit pairs (e.g., units in the motion module preferred to encode 315° while units in the target module preferred to encode green) (<bold><xref rid="fig5" ref-type="fig">Figure 5A</xref></bold>; paired t-test: P<sub>(feedforward)</sub> = 7.18e-16, t(49) = -11.76; P<sub>(feedback)</sub> = 5.26e-18, t(49) = -13.40). In particular, the average feedback connectivity was primarily excitatory between the selectivity-matched unit pairs but was inhibitory on average between the selectivity-nonmatched unit pairs. Furthermore, most of the networks exhibited positive correlations between the connection weight and the match extent of the neural selectivity of each cross-module unit pair (<bold><xref rid="fig5" ref-type="fig">Figure 5B</xref></bold>; mean r = 0.11; one-sample t-test: P = 6.39e-16; t(49) = 11.79; STAR Methods), indicating that units that exhibited stronger encoding preference to one motion direction in the motion module were more likely to receive more extensive feedback projections from the units that exhibited stronger encoding on the matched target color in the target module. These results suggested precise feedback connections between RNN modules that were aligned with the functional properties of different units.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><title>The circuit mechanisms underlying the nonlinear feedback modulation in RNNs.</title>
<p><bold>(A)</bold> The averaged cross-module connection weights are shown for both feedforward and feedback connections. Units in the motion module (M) and target module (T) were grouped based on their preferences for motion DS (315° vs. 135°) and target color selectivity (red [r] vs. green [g]), respectively. <bold>(B)</bold> The correlation between the match extent of the neural encoding between units in the motion module and those in target modules and the connection weights between them. Each dot denotes data from one RNN. (<bold>C-D)</bold> A comparison of the performance accuracy (C) and RT (D) of the full-model RNNs, RNNs without feedback connections, and RNNs with shuffled feedback connections. (<bold>E-F</bold>) The averaged activity of units in the motion module of the example RNN after the feedback connections were ablated is shown for CT (E) and IT (F) conditions. (<bold>G</bold>) The comparison of the averaged motion DS between CT and IT conditions for all trained RNNs after feedback connections were ablated. An ROC analysis was used to quantify the motion DS. (<bold>H)</bold> The differences in motion DS between CT and IT conditions were compared between full-model RNNs and RNNs with shuffled feedback connectivity.</p></caption>
<graphic xlink:href="549136v2_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To test the causal contribution of the selectivity-specific feedback connections to the modulation of action selection on sensory evaluation, we conducted three projection-specific inactivation experiments in the RNNs (STAR Methods). First, we performed nonspecific ablation of all the feedback projections from the target module to the motion module when testing with untrained motion stimuli. In most of the tested RNNs, this caused a dramatic reduction in their performance in all nonzero-coherence stimulus conditions (<bold><xref rid="fig5" ref-type="fig">Figure 5C</xref></bold>; two-way ANOVA: P = 4.74e-80, F = 704.65) as well as significantly prolonged RTs for high- and medium-coherence stimulus conditions (<bold><xref rid="fig5" ref-type="fig">Figure 5D</xref></bold>; two-way ANOVA: P = 2.45e-4, F = 13.79). The mean RTs became more dispersed across all the trained RNNs and did not differ among different motion coherences after ablation (one-way ANOVA: P = 0.68, F = 0.50). Ablating feedback connections significantly affected the motion DS in the motion module. On average, although the averaged motion DS did not decrease after ablation (<bold>Figure S10A</bold> and <bold>S10C</bold>), the difference in the motion DS between the CT and IT conditions vanished (<bold><xref rid="fig5" ref-type="fig">Figure 5E</xref>-<xref rid="fig5" ref-type="fig">5G</xref></bold> and <bold>Figure S11A</bold> and <bold>S11B</bold>; two-way ANOVA: P<sub>(CT vs. IT)</sub> = 0.14, F = 2.21). These results indicated a dramatic reduction in the nonlinear feedback modulation on sensory evaluation by action selection in the RNNs. To further test the importance of different patterns of feedback connectivity for the RNNs to solve the FVDM task, we next performed pattern-specific ablation of the feedback connections in RNNs. We separated the feedback projections in each RNN into specific (i.e., the feedback connection weights were positive or negative between the selectivity-matched or selectivity-nonmatched unit pairs, respectively) and nonspecific groups. Despite similar numbers and weights of the feedback connections in these two groups (<bold>Figure S12A</bold> and <bold>S12B</bold>), ablating the feedback connection in the specific group versus the nonspecific group resulted in much more severe impairments in the RNNs’ behavior performance (<bold>Figure S12C</bold> and <bold>S12D</bold>). These results indicated that the feedback connections that reflected the learned stimulus–response association was crucial for the RNNs to solve the FVDM task.</p>
<p>Second, we disrupted the selectivity-specific feedback connectivity without changing the total strength of the feedback connections by randomly rearranging the feedback connection weights. This also resulted in a significant reduction in the RNNs’ performance accuracy for nonzero-coherence motion stimuli (<bold><xref rid="fig5" ref-type="fig">Figure 5C</xref></bold>; two-way ANOVA: P = 1.38e-90, F = 883.61) and prolonged RTs for high- and medium-coherence motion stimuli (<bold><xref rid="fig5" ref-type="fig">Figure 5D</xref></bold>; two-way ANOVA: P = 1.94e-12, F = 54.06). The changes of RNN units’ activity patterns after scrambling feedback connections were similar to the effects after feedback connectivity was fully ablated (<bold>Figure S10B</bold>, <bold>S10C, S13A, S13B, S13D</bold> and <bold>S13E</bold>). Particularly, the levels of nonlinear modulation of sensory evaluation by saccade selection dramatically decreased, as evident by the diminished difference in the motion DS between the CT and IT conditions (<bold><xref rid="fig5" ref-type="fig">Figure 5H</xref></bold>, two-way ANOVA: P = 5.81e-12, F = 51.52).</p>
<p>Third, we trained another 50 RNNs without feedback connectivity to learn the FVMD task. Similar to the full-model RNNs, all 50 networks converged to perform the FVMD task with high accuracies (&gt;99%) after training and exhibited coherence-dependent performances when tested with untrained stimuli (<bold>Figure S14A</bold> and <bold>S14B</bold>). Meanwhile, units in the motion module and target modules exhibited coherence-dependent motion DS and saccade DS, respectively (<bold>Figure S14C</bold> and <bold>S14D</bold>). Consistent with the above connectivity ablation experiment, units in the motion module of these RNNs did not exhibit different levels of motion DS between CT and IT conditions (<bold>Figure S14E-S14G</bold>; two-way ANOVA: P = 0.63, F = 0.24), indicating no noticeable nonlinear feedback modulation on sensory evaluation by action selection. Importantly, the performance accuracies of these RNNs decreased significantly when tested with untrained nonzero-coherence stimuli (<bold>Figure S14H</bold>; two-way ANOVA: P = 1.46e-14, F = 65.64), as compared to the full-model RNNs. Furthermore, we trained an additional 50 RNNs without feedback connections to learn the FVMD task. These RNNs were initialized with greater recurrent connection probabilities than the full-model RNNs, such that the number of total trainable connection weights matched that in the full-model RNNs. Interestingly, these RNNs still exhibited significantly lower performance accuracies when tested with high- and medium-coherence stimuli relative to the full-model RNNs (<bold>Figure S15</bold>; two-way ANOVA: P = 8.24e-6, F = 20.60). Together, these results suggested that the nonlinear feedback modulation, which was mediated by the selectivity-specific feedback connections, were important for the RNNs to efficiently solve flexible decision tasks.</p>
</sec>
<sec id="s2e">
<title>Nonlinear feedback modulation enhanced the decision consistency by strengthening the attractor basins of network dynamics</title>
<p>Our RNN modeling indicates a crucial role for nonlinear feedback modulation in optimizing flexible decision-making. Subsequently, we delved into the computational mechanisms embodied by nonlinear feedback modulation during the decision-making process. Specifically, we examined the unit activity in the target module, a direct contributor to the decision outputs of RNNs. Strikingly, the projection-specific inactivation experiments led to a significant reduction in the magnitude of saccade DS in the nonzero-coherence trials (<bold><xref rid="fig6" ref-type="fig">Figure 6A</xref>-<xref rid="fig6" ref-type="fig">6C</xref></bold>, P<sub>(ablating feedback)</sub> = 6.90e-5, F = 16.29; P<sub>(shuffling feedback)</sub> = 1.2e-19, F = 95.08; two-way ANOVA). Additionally, saccade DS emerged earlier than the motion stimulus onset in the nonzero-coherence trials, and its positive correlation with the motion coherence levels diminished after the projection-specific inactivation (<bold><xref rid="fig6" ref-type="fig">Figure 6A-C</xref></bold> and <bold>Figure S11C, S13C</bold> and <bold>S13F</bold>; mean r<sub>(ablating feedback)</sub> = -0.034; mean r<sub>(shuffling feedback)</sub> = –0.030). These disrupted patterns of saccade DS observed in the target module following projection-specific inactivation aligned with the decreased decision consistency of RNNs, indicating a diminished reliance on sensory input and an increased dependence on internal noise in the decision-making process.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6.</label>
<caption><title>The computational mechanisms underlying the nonlinear feedback modulation in decision-making.</title>
<p><bold>(A)</bold> The averaged activity of units in the target module of the example RNN, after the feedback connections were ablated, is shown separately for different saccade directions and coherence levels. <bold>(B)</bold> The averaged saccade DS in the target module of the example RNN after full feedback ablation. (<bold>C)</bold> The averaged saccade DS in the target module of the full-model RNNs, RNNs without feedback connections, and RNNs with shuffled feedback connections. (Paired t-test: *, P &lt; 0.05; **, P &lt; 0.01; ***, P &lt; 0.001; n.s., not significant). (<bold>D-G</bold>) The evolution of the averaged energy landscapes was shown over time. A numerical approximation of the energy landscape in the 1-D decision (saccade choice) subspace is constructed for both full-model RNNs and RNNs with various types of projection-specific inactivation. Each plot represents the averaged results of 50 RNNs, where Position 0 signifies the SVM decision boundary, and the vertical dashed line marks the time of motion stimulus onset. Unvisited portions of the state space are left blank as there is no gradient or potential estimate. (<bold>H-k</bold>) Averaged numerical estimate of energy landscapes for trials with different task difficulty levels (motion coherence). Results from two different saccade choices were average together. Only the potential values at positions continuously visited by four or more models were retained. Shaded areas denote ±SEM.</p></caption>
<graphic xlink:href="549136v2_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Previous studies have demonstrated that attractor dynamics in networks can explain choice consistency, with steeper landscapes around attractor basins reflecting consistent decisions<sup><xref ref-type="bibr" rid="c38">38</xref>–<xref ref-type="bibr" rid="c42">42</xref></sup>. Consequently, we investigated attractor dynamics in the state space of network activity that underlies decision-making variability in RNNs with different types of feedback connectivity. Similar to prior studies<sup><xref ref-type="bibr" rid="c40">40</xref></sup>, we examined the neural dynamics underlying decisions in a 1-D neural subspace using unit activity in the target module responsible for saccade choices (see methods). Beginning with the reconstruction of a numerical approximation of the energy landscape in this 1-D subspace, we explored changes in this landscape after different types of projection-specific inactivation. This revealed a dramatic reduction in the depth of attractor basins in the energy landscape of population activity after ablating all feedback connectivity (<bold><xref rid="fig6" ref-type="fig">Fig. 6D-E</xref></bold>, paired t-test: P = 2.28e-11, t(49) = -8.61). Moreover, ablating the feedback connections led to a more severe reduction in the depth of attractor basins in the network dynamics within the specific group compared to the nonspecific groups (<bold><xref rid="fig6" ref-type="fig">Fig. 6F-G</xref></bold>, paired t-test: P = 1.59e-6, t(49) =-5.46).</p>
<p>We further examined how the energy landscape in the 1-D subspace changed in relation to task difficulty (motion coherence). Consistent with prior findings<sup><xref ref-type="bibr" rid="c40">40</xref></sup>, trials with lower decision consistency (trials using lower motion coherence) exhibited shallower attractor basins at the time of decision for all types of RNNs (<bold><xref rid="fig6" ref-type="fig">Fig. 6H-K</xref></bold>). However, both the depth and the positional separation of attractor basins in the network dynamics significantly decreased for all non-zero motion coherence levels after the ablation of all feedback connections (P<sub>(depth)</sub> = 5.20e-25, F = 122.80; P<sub>(position)</sub> = 1.82e-27, F = 137.75; two-way ANOVA). Notably, this reduction in basin depth and separation was more pronounced in the specific group compared to the nonspecific groups after ablating the feedback connections (<bold><xref rid="fig6" ref-type="fig">Fig. 6J-K</xref></bold>, P<sub>(depth)</sub> = 2.65e-13, F =57.35; P<sub>(position)</sub> = 3.73e-14, F = 61.79; two-way ANOVA). These results might underlie the computational mechanisms that explain the observed reduction in the decision consistency of RNNs following projection-specific inactivation: the shallower and closer attractor basins after ablating feedback connections resulted in less consistent decisions. This happened because the variability in neural activity made it more likely for population activity to stochastically shift out of the shallower basins and into nearby alternative ones.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Here we show that primate LIP activity related to evaluating the visual motion stimulus was nonlinearly modulated by an impending saccade choice that was used to report decisions during a FVMD task, even though the saccades were toward non-RF locations. This suggests that the sensory evaluation and action selection may proceed iteratively during decision-making. This view is also consistent with the common observation that action selection related activity arises at the early stage of evidence accumulation during decision-making<sup><xref ref-type="bibr" rid="c3">3</xref>,<xref ref-type="bibr" rid="c9">9</xref>,<xref ref-type="bibr" rid="c34">34</xref></sup>, as well as our observation that the modulation of action selection on sensory evaluation emerged during the early task period even before motion stimulus onset in the FVMD task. Brain areas that are related to different decision processes, although spatially separated<sup><xref ref-type="bibr" rid="c14">14</xref>,<xref ref-type="bibr" rid="c21">21</xref>,<xref ref-type="bibr" rid="c33">33</xref></sup>, likely form a real-time associated network to solve current decision tasks. The instantaneous result of sensory evaluation may be transmitted to the brain areas responsible for action selection during decision-making in a feedforward manner, and the action selection process may also exert a real-time modulation on the neural processing of sensory evaluation in a feedback manner.</p>
<p>The feedback modulation we observed during decision-making was distinct from the modulation of feature-based attention in early sensory cortex. Although both modulation effects match the stimulus tuning of recipient cells<sup><xref ref-type="bibr" rid="c43">43</xref>–<xref ref-type="bibr" rid="c47">47</xref></sup>, only the feedback modulation observed in the current study reflects the neural processing of decision-making. This is because only the decision-related component, not the stimulus-related component, of LIP activity was modulated by the monkeys’ later saccade choice during the FVMD task (<bold><xref rid="fig3" ref-type="fig">Figure 3</xref></bold>). This suggests that the feedback modulation from action selection to LIP activity was primarily related to the decision process rather than low-level sensory processing.</p>
<p>The selectivity-specific feedback modulation from action selection to sensory evaluation emerged in our multi-module RNNs during training, although the cross-module connections were randomly initialized before training. Importantly, our causal in-silico experiments demonstrated that these precise feedback connections played an essential role in mediating the modulation of action selection on sensory evaluation while solving the FVDM task. Previous studies showed that both the corticocortical feedback from the secondary visual cortex to the primary visual cortex and the corticogeniculate feedback in primates are organized into parallel streams resembling the reciprocal feedforward pathways<sup><xref ref-type="bibr" rid="c48">48</xref>–<xref ref-type="bibr" rid="c50">50</xref></sup>, suggesting a potential functionally specific feedback connection in visual processing. However, to the best of our knowledge, a similar segregation of feedback that reflects the encoding properties of the target neurons has not been evident in decision network in vivo. Therefore, it will be important for future studies to examine the connectivity and correlation of neural activity among neural groups related to different decision processes through sophisticated anatomical experimental approaches as well as multi-channel recordings in vivo.</p>
<p>Our brain includes extensive feedback connections across different brain areas, which, in some cases, even outnumber the feedforward connections<sup><xref ref-type="bibr" rid="c50">50</xref>,<xref ref-type="bibr" rid="c51">51</xref></sup>. However, compared to the feedforward connections, much less is known about the function of feedback connections. Feedback modulation has been implicated in top-down modulation of neuronal responses in the early sensory cortex, such as attention and expectation, which facilitate the processing of important stimuli and suppress distractors<sup><xref ref-type="bibr" rid="c52">52</xref>–<xref ref-type="bibr" rid="c54">54</xref></sup>. Furthermore, both experimental and computational studies have shown that weak decision-correlated neural activity (i.e., choice probability) as well as the correlated firing of pairs of neurons (i.e., noise correlation) in the early sensory cortex might partially result from feedback input in decision tasks<sup><xref ref-type="bibr" rid="c55">55</xref>–<xref ref-type="bibr" rid="c57">57</xref></sup>, suggesting a potential role for feedback connection in modulating early sensory processing during decision-making. Consistently, the nonlinear feedback modulation, mediated primarily by selectivity-specific feedback connections, were important for our multi-module RNNs to efficiently solve the FVMD task, as the RNNs’ decision behavior became more stochastic following ablating/disrupting the feedback connectivity. This was evident not only in the diminished behavioral performance of the RNNs but also in the disrupted patterns of activity related to saccade choice in the target module. Notably, the nonlinear feedback modulation intensified the attractor basins of the population activity associated with saccade choice, led to more reliable decisions based on sensory input. Our results unveil a novel pattern of feedback modulation during the neural processing of decision-making, and suggest a potentially critical role that feedback modulation plays in increasing the consistency of flexible sensorimotor decisions.</p>
<p>Two-state attractor models have been widely employed to elucidate two-alternative forced decision-making processes<sup><xref ref-type="bibr" rid="c38">38</xref>–<xref ref-type="bibr" rid="c42">42</xref>,<xref ref-type="bibr" rid="c58">58</xref>,<xref ref-type="bibr" rid="c59">59</xref></sup>. In these models, decisions arise when network activity falls into one of two attractor basins. Previous studies have posited that decision consistency is influenced by the configuration of the energy landscape surrounding these attractor basins<sup><xref ref-type="bibr" rid="c40">40</xref>,<xref ref-type="bibr" rid="c42">42</xref>,<xref ref-type="bibr" rid="c59">59</xref></sup>. Essentially, steep-sided and deep-basin energy landscapes contribute to consistent decision-making, as it becomes challenging for internal noise to shift activity between basins. Conversely, when energy landscapes are relatively flat and attractor basins are shallow, decisions are generated more stochastically, as it is easier for internal noise to drive activity out of the attractor basins and into alternative ones. Consistently, our RNNs modelling showed that shallower and less separated attractor basins were associated with decreased decision consistency in more difficult trials. Building upon previous research, our results provide in-silico evidence supporting the notion that the energy landscape within the state space of population activity causally influences decision consistency. Moreover, our findings present the initial circuit mechanism through which the configuration of the energy landscape for decision-related activity is modulated by feedback modulation, to our knowledge. Future studies are needed to explore the connections between different types of circuit connectivity and population activity dynamics in cognitive processing in vivo.</p>
<p>Our results are consistent with predictive coding theories of feedback function, which propose that an internal model of the world is generated in the brain based on sensory data and prior experience and is refined by incoming sensory data<sup><xref ref-type="bibr" rid="c60">60</xref>–<xref ref-type="bibr" rid="c63">63</xref></sup>. In terms of the architecture of hierarchical predictive coding schemes, different neuronal ensembles encode different attributes/choices in either the action selection or sensory evaluation process at each level of the cortical hierarchy during flexible decision-making. Meanwhile, the conditionally independent expectations are functionally segregated, so that descending predictions from the action selection process are limited to the sensory evaluation process on the matched\associated stimulus attribute but not the opposite attribute. The selectivity-specific feedback connectivity in our RNNs fits the functional segregation of expectation very well during the interplay between distinct neural processes of decision-making. Specifically, the neural ensembles related to either sensory evaluation or action selection processes for the same choice might form precise recurrently connected loops. The prediction signal carried by the precise feedback connections might facilitate sensory evaluation of the associated stimulus but prohibit evaluation of the nonmatched stimulus. This could, in turn, amplify the task-relevant sensory input, facilitate the sensorimotor transformation, and ultimately result in faster and more accurate action choice in flexible decisions. In future work, it will be important to use techniques such as projection-specific inactivation and microstimulation in vivo to test the causal contribution of feedback connectivity in decision-making and other cognitive functions.</p>
</sec>
<sec id="s4">
<title>Materials and Methods</title>
<sec id="s4a">
<title>Behavioral task, stimulus display, and animal preparation</title>
<p>The flexible visual motion discrimination (FVMD) task (<bold><xref rid="fig1" ref-type="fig">Figure 1A</xref></bold>) has been reported previously<sup><xref ref-type="bibr" rid="c14">14</xref></sup> and is briefly summarized below. In this task, monkeys were required to saccade to either the green or red targets based on the direction of the visual motion stimulus. Two motion directions (135°, 315°) were used, each with four different coherence levels (0%, 9%, 18%, 36% for monkey M; and 0%, 13%, 25%, 50% for monkey B) were tested. If the sample direction was 135°, the monkeys must saccade to the green target to receive a juice reward, whereas the 315° direction was associated with the red target. The rewarded target (red or green) was randomly chosen (with 50% probability) on each zero-coherence trial. The positions of red and green targets were randomly chosen between the two positions on each trial at each recording session. Therefore, there is no fixed mapping between motion stimulus and saccade direction.</p>
<p>To initiate each trial, monkeys must hold a touch-bar and acquire gaze fixation. They then needed to maintain fixation within a 2.0-2.5° window throughout the trial before their saccade choice. After a 500ms fixation period, two colored saccade targets appeared simultaneously at opposite positions relative to the fixation point with equal eccentricities (8° and 9° for Monkey M and B, respectively). 400ms later, a sample motion stimulus was presented at a location orthogonal to the axis of, but at the same eccentricity as, the saccade targets. We used motion stimuli that were full contrast, 8° diameter, random-dot movies composed of 190 dots per frame, and the dots moved at 10°/s. Monkeys needed to saccade to either red or green targets within a 60-2000ms window after sample stimulus onset. A juice reward would be delivered to the monkeys if they made correct saccade choice.</p>
<p>Two male monkeys (Macaca mulatta, 15∼16 years old, 8–14 kg) were trained on the FVMD task and implanted with a head post as well as a recording chamber positioned over PPC. Our surgical, behavioral, and neurophysiological approach has been described in detail in a previous study<sup><xref ref-type="bibr" rid="c14">14</xref></sup> . Stereotaxic coordinates for chamber placement were determined from magnetic resonance imaging (MRI) scans obtained before chamber implantation. LIP chambers were centered on the intraparietal sulcus (IPS), 4.0 mm posterior to the intra-aural line and 1.0 mm lateral from the midline for monkey M, and 0 mm anterior to the intra-aural line and 15.0 mm lateral from the midline for monkey B. Monkeys were housed in individual cages under a 12-hour light/dark cycle. Behavioral training and experimental recordings were conducted during the light portion of the cycle. Monkeys sat comfortably while head-fixed in a custom-made primate chair inside a dark experiment rig. The task stimuli were displayed on a 21-inch color CRT monitor (1280*1024 resolution, 75 Hz refresh rate, 57 cm viewing distance). Both monkeys were tested with identical stimuli and timing. A solenoid-operated reward system was used to deliver juice reward to the monkeys. Monkeys’ eye positions were monitored by an optical eye tracker (SR Research) at a sampling rate of 1 kHz and stored for offline analysis. Stimulus presentation, task events, rewards, and behavioral data acquisition were accomplished using an Intel-based PC equipped with MonkeyLogic software running in MATLAB (<ext-link ext-link-type="uri" xlink:href="http://www.monkeylogic.net">http://www.monkeylogic.net</ext-link>). All experimental and surgical procedures were in accordance with the University of Chicago Animal Care and Use Committee and National Institutes of Health guidelines.</p>
</sec>
<sec id="s4b">
<title>Electrophysiological recording</title>
<p>We used either 75-μm tungsten microelectrodes (FHC, ∼1 MΩ) or 16-channel V-Probes (Plexon) to record single neuron activity in LIP. Neurophysiological signals were amplified, digitized, and stored for offline spike sorting (Plexon) to verify the quality and stability of neuronal isolations. We recorded neuronal activity in a memory-guided saccade task to map LIP RF locations before each FVMD recording session.</p>
<p>Our LIP recordings targeted different hemispheres in the two monkeys (monkey M: left hemisphere; monkey Q: right hemisphere). Therefore, the contralateral target (CT) condition and ipsilateral target (IT) conditions in <bold><xref rid="fig1" ref-type="fig">Figure 1F</xref></bold> and <bold><xref rid="fig1" ref-type="fig">1G</xref></bold> referred to opposite saccade directions (target locations) between the two monkeys. For monkey M, the CT condition corresponded to the trials in which the correct saccade target was on the right visual field, whereas the CT condition for monkey Q referred to the trials in which the correct saccade was toward the left visual field. We localized LIP in each monkey according to the patterns of neuronal activity in the MGS task (i.e., spatial selectivity during stimulus presentation and delay). All neurons included in the dataset were recorded from the same locations (the same grid holes and similar depths: ∼5-10 mm from the cortical surface) where we encountered spatial selectivity in the MGS task. LIP neurons were also identified based on anatomical criteria, such as the location of each electrode track relative to that expected from the MRI scans, the pattern of gray–white matter transitions encountered on each electrode penetration, and the relative depths of each neuron.</p>
<p>We aimed to present the visual motion stimulus inside the RFs of the identified neurons during each recording session. For single-channel electrode recording, only neurons exhibited visual responses to the motion stimuli during prescreening (tested with the FVMD task) were recorded with sufficient trials (∼300-600) of the FVDM task. For neurons exhibiting clear spatial RFs during the MGS task, we presented the motion stimulus inside LIP neurons’ RFs; while for those neurons which did not show a clear RF during the MGS task, we presented motion stimuli in the positions (always in the visual field contralateral to the recorded hemisphere) in which neurons exhibited the strongest response to the motion stimuli. For the multi-channel recordings, we recorded all neurons isolated across all channels and presented the motion stimulus inside one of the isolated neurons’ RFs. Because adjacent recording sites were located 100µm apart, nearby neurons typically showed similar RF locations.</p>
</sec>
<sec id="s4c">
<title>Data analysis</title>
<sec id="s4c1">
<title>Neuronal pre-screening</title>
<p>While part of the neural data was presented in a previous report<sup><xref ref-type="bibr" rid="c14">14</xref></sup>, the current analysis focuses on a different phenomenon which was not examined previously. We included all neurons recorded from single-channel electrodes for the analysis. For multi-channel recordings, we only included the neurons which showed significant modulation (different from fixation period activity, one-way ANOVA, p &lt; 0.01) of their averaged activity across all motion stimuli because the stimulus could not always be presented within the RF of all the recorded neurons. The low-firing neurons whose maximum firing rates were less than 2.0 spikes/s (to the direction producing greater average responses) during stimulus presentation were also excluded for further analysis. We then applied a one-way ANOVA test to compare activity between the two different motion directions during the period following motion stimulus onset (50-250 ms after motion stimulus onset) to select neurons that showed significant motion direction selectivity (DS) during the decision period. Only neurons that showed significant (p &lt; 0.01) DS were used for further analysis.</p>
</sec>
<sec id="s4c2">
<title>Receiver operating characteristic (ROC) analysis</title>
<p>To quantify each neuron’s DS in the FVMD task, we applied an ROC analysis to the distribution of firing rates within sliding windows (100 ms width, 5 ms steps). The ROC value, which ranges between 0.0 and 1.0, indicates the performance of an ideal observer in assigning motion direction based on each neuron’s trial-by-trial firing rates. Values of 1.0 and 0.0 correspond to perfect classification (i.e., strong DS), while a value of 0.5 indicates chance-level classification performance (i.e., no DS). For trials with zero coherence motion, we assigned direction labels on each trial based on the monkey’s choice.</p>
<p>In <bold><xref rid="fig3" ref-type="fig">Figure 3</xref></bold>, in order to test whether DS reflected monkeys’ trial-by-trial choices, we used an ROC analysis to quantify whether LIP activity correlated with monkeys’ trial-by-trial categorical choices more than the physical direction of motion stimulus by analyzing both correct and error trials. We only included low coherence trials in this analysis because there were sufficient numbers of error trials (average performance: Monkey M: 74% correct, Monkey B: 67% correct). LIP neuronal activity was analyzed by ROC according to either the monkey’s trial-by-trial categorical choices or the direction of the sample stimulus on each trial. Furthermore, for this analysis, we only used neurons for which we recorded sufficient trials (for both correct and error trials, N&gt;4) for the low coherence condition of each motion direction (n = 45).</p>
</sec>
<sec id="s4c3">
<title>Partial correlation analysis</title>
<p>We performed a partial correlation analysis to quantify the correlation between LIP neural activity and the monkeys’ trial-by-trial categorical choices or the physical motion direction of the stimulus using all trials. For each trial, we obtained three parameters for the calculation: the stimulus direction, the pre-choice neuronal activity, and the monkeys’ choice. We assigned the stimulus directions with different values for different directions and coherence levels: positive and negative values were used for preferred and nonpreferred directions, respectively; while 4, 2, 1 and 0 are used for code the high, medium, low, and zero coherence levels. We also assigned different values to different choice directions (−2 for choosing the preferred direction, and + 2 for choosing the nonpreferred direction). Two measures were then calculated: r stimulus = r (neuronal activity, stimulus direction| choice direction), the partial correlation between neuronal activity and stimulus direction given the monkeys’ choices; and r choice = r (neuronal activity, choice direction | stimulus direction), the partial correlation between neuronal activity and the monkeys’ categorical choice given the stimulus direction. In <bold><xref rid="fig3" ref-type="fig">Figure 3</xref></bold>, we used the mean activity within a sliding window (100ms width, sliding with 5ms steps) for each neuron to perform the partial correlation analysis.</p>
</sec>
<sec id="s4c4">
<title>dPCA analysis</title>
<p>We conducted demixed principal component analysis using the methodology and the code from a previous study<sup><xref ref-type="bibr" rid="c64">64</xref></sup> (<ext-link ext-link-type="uri" xlink:href="http://github.com/machenslab/dPCA">http://github.com/machenslab/dPCA</ext-link>) to reduce the dimensionality of the population activity as the standard PCA and demixes all task variables. Specifically, we tested how much each task variable (motion direction of sample stimuli, saccade direction, motion-saccade interaction, timing) contributes to the LIP population activity during the DMC task.</p>
<p>As demonstrated in the previous study, the dPCA finds separate decoder (F) and encoder (D) matrices for each task variable (Φ) by minimizing the loss function:
<disp-formula id="ueqn1">
<graphic xlink:href="549136v2_ueqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where X is a linear decomposition of the data matrix, which contains the instantaneous firing rate of the recorded neurons, into variable-specific averages:
<disp-formula id="ueqn2">
<graphic xlink:href="549136v2_ueqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Here, we decomposed the neural activities into four parts: condition-independent, stimulus-dependent (two motion directions with four coherence levels), saccade-dependent (two saccade directions), dependent on the stimulus-saccade interaction, and noise. The decoder and encoder axes permit us to reduce the data into a few components capturing the majority of the variance of the data dependent on each task variable.</p>
</sec>
</sec>
<sec id="s4d">
<title>Recurrent neural network (RNN) training</title>
<sec id="s4d1">
<title>Network Implementation</title>
<p>We trained biologically inspired networks to perform the FVMD task using methodology similar to previous studies<sup><xref ref-type="bibr" rid="c28">28</xref>,<xref ref-type="bibr" rid="c36">36</xref></sup>. We implemented multiple modules in the networks through constraints on the input/output structure and the initial recurrent connectivity of the hidden layer. Specifically, we built excitatory-inhibitory networks with 200 hidden units divided into two equal-size main modules to simulate two brain hemispheres. Each main module was further divided into two nominal modules, with each one only receiving the visual motion input (motion module) or target color input (target module), respectively. This design was intended to simulate the two neuron populations whose RFs covered the motion stimulus or saccade target in the monkey electrophysiology experiment (<bold><xref rid="fig4" ref-type="fig">Figure 4A</xref></bold>). Every nominal module was allocated one quarter of the excitatory units (40) and one quarter of the inhibitory units (10) in the overall network to ensure that the modules did not differ in their balance of excitation/inhibition prior to training. Meanwhile, in order to simulate the local and long-range connection structures in the brain, we set different levels of recurrent connectivity within and between different modules: the local (connectivity within each nominal module) recurrent connection density (probability) was the highest (50%); the across-RF (connectivity between the two nominal modules within the same main module) connection density was set to be in the medium level (25%); the cross-hemisphere (connectivity between either the motion modules or the target modules across different main modules) connection density was the lowest (10%). Only excitatory neurons could have “cross-hemisphere” projections to the corresponding nominal module (e.g., from the motion module of the “left hemisphere” to the motion module of the “right hemisphere”). Only the connection weight within the hidden layer was updated during training following methods described previously<sup><xref ref-type="bibr" rid="c28">28</xref></sup>. In addition, the connection weights between network units are endowed with short-term synaptic plasticity, which is aimed to provide connection weights with activity-dependent fluctuation over short timescales within each trial.</p>
<p>The input to the network consisted of two parts: 9 motion input units and 8 target color input units. The preferred directions of motion input units were evenly spaced across 360°, with response tuning distributed according to a von Mises function. The value of the nth motion input unit was set to
<disp-formula id="ueqn3">
<graphic xlink:href="549136v2_ueqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
<p>,where <inline-formula><inline-graphic xlink:href="549136v2_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, is the direction of motion stimulus in radian, θ<sub><italic>pref</italic></sub> is the preferred direction of this motion input unit, <inline-formula><inline-graphic xlink:href="549136v2_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula> after stimulus onset but 0 elsewhere, c ∈ [0, 1] is the coherence of the dot motion stimulus, <italic>b</italic> is a binary value that equals 0 before stimulus onset and 1 after that, and <italic>d</italic> is a constant visual input signal with an amplitude of 2 that decays with time. Specifically, for zero-coherence input, since <italic>ace</italic><sup>(<italic>kcos</italic>(θ−θ<italic><sub>pref</sub></italic>))</sup> would be zero, we set this term as 0.4<italic>max</italic>(<italic>c</italic>).</p>
<p>The target input units were initially evenly divided into two groups projected to the two target modules of hidden units. Each group was further divided into red and green subgroups. The color subgroup was set as active with an amplitude of <inline-formula><inline-graphic xlink:href="549136v2_inline3.gif" mimetype="image" mime-subtype="gif"/></inline-formula> to represent the color within the projected target module, while the other color group remained silent (amplitude =0). An exponential decay filter was also used to fit the activity of sensory neurons in the early sensory cortex across time:
<disp-formula id="ueqn4">
<graphic xlink:href="549136v2_ueqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
, where <italic>x</italic> is the constant visual input for motion input and the color signal for color input, <italic>t</italic> is time in miliseconds.</p>
<p>The two output units of the network simulate two different saccade directions. In order to simulate the oculomotor control in the brain, each brain hemisphere (main module) projects much more densely to the contralateral response units (probability = 0.32) than the ipsilateral response units (probability = 0.08). To generate a probability distribution over output values at each time point, we also applied a softmax function to scale the response unit activities in the output layer. To reduce the stochasticity of the network activity brought by input and output connections, we randomly sampled input and output weights from a normal distribution (<italic>N</italic>(0.2, 0.05)). In addition, the input weights were re-initialized if there were extreme values (the minimum value was smaller than ¾ of the maximum value) after multiplying the stimulus signal and weight of motion or target input. Similarly, the output weights were re-initialized if there were extreme values in the output weight values. The input units had excitatory and random projections to the recurrent units with a probability of 0.32. However, only the excitatory units in the target modules of each “hemisphere” could project to the output units. Both the input and output weights were fixed for each network during task training.</p>
</sec>
<sec id="s4d2">
<title>Network training</title>
<p>The networks were trained using BrainPy<sup><xref ref-type="bibr" rid="c65">65</xref></sup> on an Intel(R) Core(TM) i9-9900K CPU (3.60GHz, 8 cores). The network was optimized using backpropagation through time (BPTT) and stochastic gradient descent with an Adam optimizer (default setting, first moment estimates decay rate=0.9, second moment estimates decay rate =0.999) to minimize a loss function. The network parameters (recurrent weights/biases) were optimized to minimize a loss function with three parts as in a previous study<sup><xref ref-type="bibr" rid="c28">28</xref></sup>: (a) a performance loss; (b) a metabolic cost on mean neuronal activity; and (c) a metabolic cost on connectivity. The gradient was clipped to a maximum L2 value of 0.1 to avoid the exploding gradient problem. During training, only the hidden unit related parameters (weights, bias, and initial activities) were updated. The training process was terminated when the network’s performance accuracy reached 99% or till the maximum number of iterations (2000).</p>
<p>During each trial of the training and testing of the FVMD task, networks were first presented with two color targets through the target input units, and then presented with the motion direction through the motion input units. Both the motion and target inputs persisted until the end of each trial. A short time after the motion input (100ms, 5 time steps), the networks were required to report the direction of the stimulus motion by choosing the saccade target with the appropriate color. Specifically, each element of the task design in the FVMD task that the models were trained to perform was tailored to match those used in the monkey experiments: the directions of the motion stimuli, the target colors, as well as the task (stimulus) durations were the same as that used in monkey electrophysiology experiments. Trials were programmatically generated by constructing motion/target inputs to the networks at each timestep and the desired response (left saccade, right saccade) at each timestep. In total, we trained 50 networks to perform the FVDM task. All networks were first trained using motion directions with two coherence levels (60% and 90%) and were then tested using motion stimuli with another four different coherence levels (75%, 55%, 35%, and zero), which had never been presented during training. Besides the difference in the coherence of motion input, the color inputs remained the same during the testing period. All the networks achieved consistently high performance by the end of training (&gt; 99% accuracy). All the important model hyperparameters were listed in <bold>Table S1</bold>.</p>
</sec>
<sec id="s4d3">
<title>Quantification of the networks’ behavioral performance</title>
<p>To test whether our multi-module RNNs exhibited decision behavior similar to monkey subjects, we examined their performance accuracies and RTs when tested by novel stimuli with different coherence levels. The performance accuracy was defined as whether the output of the response units (starting from 100ms after stimulus onset to the trial end) matched the desired output. Furthermore, we defined the networks’ RTs as the time point from which the differences between two output units were greater than a threshold (0.8) for three consecutive time points after the stimulus onset. During some trials, the threshold was never reached until the end of the trial (500ms after the motion stimulus onset). In these cases, we artificially set the RT to be 600ms in these trials for further analysis.</p>
</sec>
<sec id="s4d4">
<title>Analysis of RNN activity</title>
<p>We performed the same analyses on the RNN units as we did on the neurophysiology data. In <bold><xref rid="fig4" ref-type="fig">Figure 4</xref>-<xref rid="fig5" ref-type="fig">5</xref></bold>, data from both the example network and averaged results across all the networks were shown. For every network, we only included the units which exhibited at least one kind of task-related modulation during the test period (i.e., motion direction selectivity or saccade direction selectivity, one-way ANOVA test, p &lt; 0.01). In order to quantify the activity related to evaluating motion stimulus, we analyzed the motion DS only including the units in the motion modules, whereas only the saccade DS of units in the target modules were calculated to quantify the activity related to saccade selection during the decision-making.</p>
</sec>
<sec id="s4d5">
<title>Analysis of RNN connectivity</title>
<p>To examine the potential circuit mechanisms underlying the modulation of action selection on sensory evaluation during decision-making in the RNNs, we examined the cross-module connection weights in the trained networks. Specifically, we defined the feedforward connection as the projection from units in the motion module to units in the target module within the same main module (hemisphere). We also defined the feedback connection as the projection from units in the target module to units in the motion module within the same main module. Furthermore, we grouped the cross-module connections into the selectivity-matched and selectivity-mismatched groups based on the preferences of the neural encoding of units in the motion and target modules. The selectivity-matched group included two types of unit pairs: 1) units in the motion module preferred to encode 315° and units in the target module preferred to encode red, 2) units in the motion module preferred to encode 135° and units in the target module preferred to encode green. The selectivity-mismatched group includes the other two types of unit pairs: 3) units in the motion module preferred to encode 315° while units in the target module preferred to encode green, and 4) units in the motion module preferred to encode 135°while units in the target module preferred to encode red. The values of connection weights projected from excitatory and inhibitory units were set as positive and negative, respectively.</p>
<p>We also examined the correlation between the similarity of neural selectivity and connection strength for different unit pairs in the RNNs based on the following steps: First, both the preference and strength of motion direction encoding or target color encoding were quantified for units in the motion module or target module, respectively. This was done by calculating the averaged differential activity to the 315° and 135° motion stimuli after motion stimulus onset or calculating the averaged differential activity to the red and green targets after target onset. In this case, the unit pairs that exhibited matched selectivity would show selectivity values with the same sign (positive or negative), whereas the unit pairs that exhibited mismatched selectivity would show selectivity values with the opposite signs. Second, the units in both the motion module and target modules were ranked based on selectivity values. Third, the selectivity similarity of each cross-module unit pair was quantified by calculating the reverse value of the absolute differences between the target color selectivity rank and the motion direction selectivity rank. The rank of the weight value of each pair was calculated and then reversed to give the lower weight value a higher rank score. Finally, we calculated the Pearson correlation between weight rank and selectivity similarity. A positive correlation indicates that units that exhibited stronger encoding preference to one motion direction in the motion module were more likely to connect with the units in the target module that exhibited stronger encoding on the matched target color.</p>
</sec>
<sec id="s4d6">
<title>Inactivation experiments in silico</title>
<p>Our examination of the network connectivity within the hidden layer of the RNNs revealed that the selectivity-specific top-down connections originated from the target module to the motion module. To assess the causal contribution of such precise feedback connections to the modulation of action selection on sensory evaluation, we performed two in-silico analogues of neuronal inactivation experiments similar to a previous study<sup><xref ref-type="bibr" rid="c28">28</xref></sup>. We hypothesized that ablating or disrupting the precise feedback connection from the target module to the motion module would significantly impact the activity patterns of the units in the motion module. Specifically, such inactivation on connectivity was expected to reduce the difference in motion DS in the notion module between CT and IT conditions. To test this hypothesis, we performed the projection-specific inactivation experiments in the RNNs in three different ways. First, we ablated all the feedback projections from the target module to the motion module while keeping all the other network parameters unchanged after the networks were fully trained. We then tested the networks with the untrained motion stimuli used in the normal experiment. The connectivity ablation was implemented by directly setting the connection weights from units in the target module to units in the motion module to zero. Second, we randomly rearranged the connection weights from the target module to the motion module after the network was fully trained by shuffling the corresponding weights in the weight matrix. Then, we tested the networks with the testing motion stimuli. This was aimed to disrupt the selectivity-specific feedback connection without changing the total strength of the feedback connection. We repeated this random feedback weight rearrangement process 100 times for each of the 50 trained networks. Subsequently, we measured the impact on the networks’ behavior performance and the activity patterns in both the motion and saccade modules. In particular, for each network, we tested whether there were still different levels of motion direction selectivity of units in the motion module between CT and IT conditions after inactivating the feedback connectivity.</p>
<p>We further performed pattern-specific ablation of the feedback connections in the RNNs, in order to examine the causal roles of different patterns of feedback connectivity in solving the FVDM task. Specifically, we separated the feedback projections in each RNN into the specific group and the nonspecific group. The specific group included two conditions: 1) the feedback connection weight was positive between the selectivity-matched unit pairs, and 2) the feedback connection weight was negative between the selectivity-nonmatched unit pairs; whereas the nonspecific group included the rest of the feedback conditions in each RNN. We then tested the effects of the pattern-specific connectivity inactivation on the RNNs’ behavior performance when tested with the untrained motion stimuli.</p>
<p>In the third inactivation experiment, we trained 50 additional RNNs without feedback connections to learn the FVMD task, in order to test the importance of feedback connectivity in solving the flexible decision task. These networks were initialized using identical hyperparameters and trained with the same methodology as the normal RNNs, except that the feedback connections from the target module to the motion module were ablated before training. We then examined these RNNs’ behavior performance and unit activity when testing with the untrained motion stimuli used in the normal experiment. Furthermore, we trained another 50 RNNs without feedback connection to learn the FVMD task. These RNNs were initialized with higher recurrent connection probabilities than the full-model RNNs to keep the number of the total trainable connection weight comparable to that in the full-model RNNs. We raised the recurrent connection probability by a factor of 1.176 after removing feedback connections (average number of connections in 50 normal RNNs = 8193, average number of connections in 50 networks without feedback = 8184, p = 0.53, independent sample t-test). Except for the recurrent connection probability, all the other hyperparameters and the training methodology were the same as the normal RNNs. We then compared the behavior performance of these RNNs with that of the normal RNNS when testing with the untrained motion stimuli.</p>
</sec>
<sec id="s4d7">
<title>Analysis of neural landscape</title>
<p>For each network, we adopted a methodology similar to a previous study (cite) to reconstruct the energy landscape of population activity within the target module. Initially, units in the target module exhibiting saccade direction selectivity were identified. Subsequently, we employed principal component analysis (PCA) to reduce the dimensionality of the population activity. Specifically, PCA was performed on the average activity across these units, considering each stimulus motion direction, coherence level, and choice. We retained the first five principal components (PCs) for further analysis, as they explained over 90% of the total variance in population activity. Following this, the trial-by-trial population activities were transformed into 5-dimensional data using the aforementioned five PCs.</p>
<p>To predict trial-by-trial choice, we employed a linear Support Vector Machine (SVM) classifier with 10-fold cross-validation. Specifically, we utilized the average activity of the last 100 ms of each trial as input for the classifier. The choice axis was determined by selecting the normal vector of the separating hyperplane from the SVM classifier that demonstrated the best performance. Subsequently, the 5-dimensional data points were projected onto the choice axis, resulting in 1-dimensional projections. These projections represented the positions along the choice axis, with the intersection between the normal vector and the hyperplane serving as the zero point.</p>
<p>The potential in this context is determined by integrating the spatial component of the time derivative of the population activity, denoted as <italic>X</italic><sub><italic>t</italic></sub>, for a given condition. To be more precise, we began by computing the expected value across trials of the time derivative of the unit activities for each choice. Subsequently, we employed the potential function <italic>V</italic>(<italic>x</italic>, <italic>t</italic>) to to evaluate the potential at position x and time t,
<disp-formula id="ueqn5">
<graphic xlink:href="549136v2_ueqn5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Crucially, we computed the potential separately for each choice, establishing the potential at position 0 as the zero-potential reference. To provide a holistic evaluation of the potential landscape, we combined the potentials of both choices at position 0.</p>
<p>Furthermore, we expanded the computation of potentials to encompass each stimulus coherence level using the aforementioned approach. Similar to the prior analysis, the time derivatives were still derived from the 1-D projections of each data point onto the choice axis. However, in this instance, the conditions were based on the stimulus coherence level rather than the choice. For a representative potential value for each model, we averaged the potentials at the time point of 300ms after the stimulus onset. Additionally, recognizing that the positions visited by each model might differ, we ensured the accuracy of standard error estimation by retaining only the potential values at positions continuously visited by four or more models.</p>
</sec>
</sec>
</sec>
<sec id="d1e1361" sec-type="supplementary-material">
<title>Supporting information</title>
<supplementary-material id="d1e1440">
<label>supplementary figures</label>
<media xlink:href="supplements/549136_file02.pdf"/>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>We thank Tianming Yang, Matthew Rosen, Siyu Wang, Cheng Xue, Gongcheng Yu, Mingze Li and Ou Zhu for their comments on an earlier version of this manuscript. We also thank the veterinary staff at The University of Chicago Animal Resources Center for expert assistance.</p>
<p>This study was supported by STI2030-Major Projects (2021ZD0203800), NSFC32171036.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><label>1</label><mixed-citation publication-type="journal"><string-name><surname>O’Connell</surname>, <given-names>R. G.</given-names></string-name>, <string-name><surname>Shadlen</surname>, <given-names>M. N.</given-names></string-name>, <string-name><surname>Wong-Lin</surname>, <given-names>K.</given-names></string-name> &amp; <string-name><surname>Kelly</surname>, <given-names>S. P.</given-names></string-name> <article-title>Bridging Neural and Computational Viewpoints on Perceptual Decision-Making</article-title>. <source>Trends Neurosci</source> <volume>41</volume>, <fpage>838</fpage>–<lpage>852</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.tins.2018.06.005</pub-id> (<year>2018</year>).</mixed-citation></ref>
<ref id="c2"><label>2</label><mixed-citation publication-type="journal"><string-name><surname>Freedman</surname>, <given-names>D. J.</given-names></string-name> &amp; <string-name><surname>Assad</surname>, <given-names>J. A.</given-names></string-name> <article-title>Neuronal Mechanisms of Visual Categorization: An Abstract View on Decision Making</article-title>. <source>Annu Rev Neurosci</source> <volume>39</volume>, <fpage>129</fpage>–<lpage>147</lpage>, doi:<pub-id pub-id-type="doi">10.1146/annurev-neuro-071714-033919</pub-id> (<year>2016</year>).</mixed-citation></ref>
<ref id="c3"><label>3</label><mixed-citation publication-type="journal"><string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name> &amp; <string-name><surname>Shadlen</surname>, <given-names>M. N.</given-names></string-name> <article-title>The neural basis of decision making</article-title>. <source>Annu Rev Neurosci</source> <volume>30</volume>, <fpage>535</fpage>–<lpage>574</lpage>, doi:<pub-id pub-id-type="doi">10.1146/annurev.neuro.29.051605.113038</pub-id> (<year>2007</year>).</mixed-citation></ref>
<ref id="c4"><label>4</label><mixed-citation publication-type="journal"><string-name><surname>Huk</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Katz</surname>, <given-names>L. N.</given-names></string-name> &amp; <string-name><surname>Yates</surname>, <given-names>J. L.</given-names></string-name> <article-title>The Role of the Lateral Intraparietal Area in (the Study of) Decision Making</article-title>. <source>Annu Rev Neurosci</source> <volume>40</volume>, <fpage>349</fpage>–<lpage>372</lpage>, doi:<pub-id pub-id-type="doi">10.1146/annurev-neuro-072116-031508</pub-id> (<year>2017</year>).</mixed-citation></ref>
<ref id="c5"><label>5</label><mixed-citation publication-type="journal"><string-name><surname>Hanks</surname>, <given-names>T. D.</given-names></string-name> &amp; <string-name><surname>Summerfield</surname>, <given-names>C.</given-names></string-name> <article-title>Perceptual Decision Making in Rodents, Monkeys, and Humans</article-title>. <source>Neuron</source> <volume>93</volume>, <fpage>15</fpage>–<lpage>31</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2016.12.003</pub-id> (<year>2017</year>).</mixed-citation></ref>
<ref id="c6"><label>6</label><mixed-citation publication-type="journal"><string-name><surname>Shadlen</surname>, <given-names>M. N.</given-names></string-name> &amp; <string-name><surname>Kiani</surname>, <given-names>R.</given-names></string-name> <article-title>Decision making as a window on cognition</article-title>. <source>Neuron</source> <volume>80</volume>, <fpage>791</fpage>–<lpage>806</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2013.10.047</pub-id> (<year>2013</year>).</mixed-citation></ref>
<ref id="c7"><label>7</label><mixed-citation publication-type="journal"><string-name><surname>Freedman</surname>, <given-names>D. J.</given-names></string-name> &amp; <string-name><surname>Assad</surname>, <given-names>J. A.</given-names></string-name> <article-title>A proposed common neural mechanism for categorization and perceptual decisions</article-title>. <source>Nat Neurosci</source> <volume>14</volume>, <fpage>143</fpage>–<lpage>146</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nn.2740</pub-id> (<year>2011</year>).</mixed-citation></ref>
<ref id="c8"><label>8</label><mixed-citation publication-type="journal"><string-name><surname>Platt</surname>, <given-names>M. L.</given-names></string-name> &amp; <string-name><surname>Glimcher</surname>, <given-names>P. W.</given-names></string-name> <article-title>Neural correlates of decision variables in parietal cortex</article-title>. <source>Nature</source> <volume>400</volume>, <fpage>233</fpage>–<lpage>238</lpage>, doi:<pub-id pub-id-type="doi">10.1038/22268</pub-id> (<year>1999</year>).</mixed-citation></ref>
<ref id="c9"><label>9</label><mixed-citation publication-type="journal"><string-name><surname>Roitman</surname>, <given-names>J. D.</given-names></string-name> &amp; <string-name><surname>Shadlen</surname>, <given-names>M. N.</given-names></string-name> <article-title>Response of neurons in the lateral intraparietal area during a combined visual discrimination reaction time task</article-title>. <source>J Neurosci</source> <volume>22</volume>, <fpage>9475</fpage>–<lpage>9489</lpage> (<year>2002</year>).</mixed-citation></ref>
<ref id="c10"><label>10</label><mixed-citation publication-type="journal"><string-name><surname>Shadlen</surname>, <given-names>M. N.</given-names></string-name> &amp; <string-name><surname>Newsome</surname>, <given-names>W. T.</given-names></string-name> <article-title>Motion perception: seeing and deciding</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source> <volume>93</volume>, <fpage>628</fpage>–<lpage>633</lpage>, doi:<pub-id pub-id-type="doi">10.1073/pnas.93.2.628</pub-id> (<year>1996</year>).</mixed-citation></ref>
<ref id="c11"><label>11</label><mixed-citation publication-type="journal"><string-name><surname>Shadlen</surname>, <given-names>M. N.</given-names></string-name> &amp; <string-name><surname>Newsome</surname>, <given-names>W. T.</given-names></string-name> <article-title>Neural basis of a perceptual decision in the parietal cortex (area LIP) of the rhesus monkey</article-title>. <source>J Neurophysiol</source> <volume>86</volume>, <fpage>1916</fpage>–<lpage>1936</lpage>, doi:<pub-id pub-id-type="doi">10.1152/jn.2001.86.4.1916</pub-id> (<year>2001</year>).</mixed-citation></ref>
<ref id="c12"><label>12</label><mixed-citation publication-type="journal"><string-name><surname>Sugrue</surname>, <given-names>L. P.</given-names></string-name>, <string-name><surname>Corrado</surname>, <given-names>G. S.</given-names></string-name> &amp; <string-name><surname>Newsome</surname>, <given-names>W. T.</given-names></string-name> <article-title>Matching behavior and the representation of value in the parietal cortex</article-title>. <source>Science</source> <volume>304</volume>, <fpage>1782</fpage>–<lpage>1787</lpage>, doi:<pub-id pub-id-type="doi">10.1126/science.1094765</pub-id> (<year>2004</year>).</mixed-citation></ref>
<ref id="c13"><label>13</label><mixed-citation publication-type="journal"><string-name><surname>Yates</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Park</surname>, <given-names>I. M.</given-names></string-name>, <string-name><surname>Katz</surname>, <given-names>L. N.</given-names></string-name>, <string-name><surname>Pillow</surname>, <given-names>J. W.</given-names></string-name> &amp; <string-name><surname>Huk</surname>, <given-names>A. C.</given-names></string-name> <article-title>Functional dissection of signal and noise in MT and LIP during decision-making</article-title>. <source>Nat Neurosci</source> <volume>20</volume>, <fpage>1285</fpage>–<lpage>1292</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nn.4611</pub-id> (<year>2017</year>).</mixed-citation></ref>
<ref id="c14"><label>14</label><mixed-citation publication-type="journal"><string-name><surname>Zhou</surname>, <given-names>Y.</given-names></string-name> &amp; <string-name><surname>Freedman</surname>, <given-names>D. J.</given-names></string-name> <article-title>Posterior parietal cortex plays a causal role in perceptual and categorical decisions</article-title>. <source>Science</source> <volume>365</volume>, <fpage>180</fpage>–<lpage>185</lpage>, doi:<pub-id pub-id-type="doi">10.1126/science.aaw8347</pub-id> (<year>2019</year>).</mixed-citation></ref>
<ref id="c15"><label>15</label><mixed-citation publication-type="journal"><string-name><surname>Freedman</surname>, <given-names>D. J.</given-names></string-name> &amp; <string-name><surname>Assad</surname>, <given-names>J. A.</given-names></string-name> <article-title>Experience-dependent representation of visual categories in parietal cortex</article-title>. <source>Nature</source> <volume>443</volume>, <fpage>85</fpage>–<lpage>88</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nature05078</pub-id> (<year>2006</year>).</mixed-citation></ref>
<ref id="c16"><label>16</label><mixed-citation publication-type="journal"><string-name><surname>Freedman</surname>, <given-names>D. J.</given-names></string-name> &amp; <string-name><surname>Assad</surname>, <given-names>J. A.</given-names></string-name> <article-title>Distinct encoding of spatial and nonspatial visual information in parietal cortex</article-title>. <source>J Neurosci</source> <volume>29</volume>, <fpage>5671</fpage>–<lpage>5680</lpage>, doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2878-08.2009</pub-id> (<year>2009</year>).</mixed-citation></ref>
<ref id="c17"><label>17</label><mixed-citation publication-type="journal"><string-name><surname>Bennur</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name> <article-title>Distinct representations of a perceptual decision and the associated oculomotor plan in the monkey lateral intraparietal area</article-title>. <source>J Neurosci</source> <volume>31</volume>, <fpage>913</fpage>–<lpage>921</lpage>, doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.4417-10.2011</pub-id> (<year>2011</year>).</mixed-citation></ref>
<ref id="c18"><label>18</label><mixed-citation publication-type="journal"><string-name><surname>Swaminathan</surname>, <given-names>S. K.</given-names></string-name> &amp; <string-name><surname>Freedman</surname>, <given-names>D. J.</given-names></string-name> <article-title>Preferential encoding of visual categories in parietal cortex compared with prefrontal cortex</article-title>. <source>Nat Neurosci</source> <volume>15</volume>, <fpage>315</fpage>–<lpage>320</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nn.3016</pub-id> (<year>2012</year>).</mixed-citation></ref>
<ref id="c19"><label>19</label><mixed-citation publication-type="journal"><string-name><surname>Zhou</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Mohan</surname>, <given-names>K.</given-names></string-name> &amp; <string-name><surname>Freedman</surname>, <given-names>D. J.</given-names></string-name> <article-title>Abstract Encoding of Categorical Decisions in Medial Superior Temporal and Lateral Intraparietal Cortices</article-title>. <source>J Neurosci</source> <volume>42</volume>, <fpage>9069</fpage>–<lpage>9081</lpage>, doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.0017-22.2022</pub-id> (<year>2022</year>).</mixed-citation></ref>
<ref id="c20"><label>20</label><mixed-citation publication-type="journal"><string-name><surname>Kiani</surname>, <given-names>R.</given-names></string-name> &amp; <string-name><surname>Shadlen</surname>, <given-names>M. N.</given-names></string-name> <article-title>Representation of confidence associated with a decision by neurons in the parietal cortex</article-title>. <source>Science</source> <volume>324</volume>, <fpage>759</fpage>–<lpage>764</lpage>, doi:<pub-id pub-id-type="doi">10.1126/science.1169405</pub-id> (<year>2009</year>).</mixed-citation></ref>
<ref id="c21"><label>21</label><mixed-citation publication-type="journal"><string-name><surname>Katz</surname>, <given-names>L. N.</given-names></string-name>, <string-name><surname>Yates</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Pillow</surname>, <given-names>J. W.</given-names></string-name> &amp; <string-name><surname>Huk</surname>, <given-names>A. C.</given-names></string-name> <article-title>Dissociated functional significance of decision-related activity in the primate dorsal stream</article-title>. <source>Nature</source> <volume>535</volume>, <fpage>285</fpage>–<lpage>288</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nature18617</pub-id> (<year>2016</year>).</mixed-citation></ref>
<ref id="c22"><label>22</label><mixed-citation publication-type="journal"><string-name><surname>Zhou</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Zhu</surname>, <given-names>O.</given-names></string-name> &amp; <string-name><surname>Freedman</surname>, <given-names>D. J.</given-names></string-name> <article-title>Posterior Parietal Cortex Plays a Causal Role in Abstract Memory-Based Visual Categorical Decisions</article-title>. <source>J Neurosci</source> <volume>43</volume>, <fpage>4315</fpage>–<lpage>4328</lpage>, doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2241-22.2023</pub-id> (<year>2023</year>).</mixed-citation></ref>
<ref id="c23"><label>23</label><mixed-citation publication-type="journal"><string-name><surname>Kim</surname>, <given-names>J. N.</given-names></string-name> &amp; <string-name><surname>Shadlen</surname>, <given-names>M. N.</given-names></string-name> <article-title>Neural correlates of a decision in the dorsolateral prefrontal cortex of the macaque</article-title>. <source>Nat Neurosci</source> <volume>2</volume>, <fpage>176</fpage>–<lpage>185</lpage>, doi:<pub-id pub-id-type="doi">10.1038/5739</pub-id> (<year>1999</year>).</mixed-citation></ref>
<ref id="c24"><label>24</label><mixed-citation publication-type="journal"><string-name><surname>Rossi-Pool</surname>, <given-names>R.</given-names></string-name> <etal>et al.</etal> <article-title>Decoding a Decision Process in the Neuronal Population of Dorsal Premotor Cortex</article-title>. <source>Neuron</source> <volume>96</volume>, <fpage>1432</fpage>–<lpage>1446 e1437</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2017.11.023</pub-id> (<year>2017</year>).</mixed-citation></ref>
<ref id="c25"><label>25</label><mixed-citation publication-type="journal"><string-name><surname>Ding</surname>, <given-names>L.</given-names></string-name> &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name> <article-title>Neural correlates of perceptual decision making before, during, and after decision commitment in monkey frontal eye field</article-title>. <source>Cereb Cortex</source> <volume>22</volume>, <fpage>1052</fpage>–<lpage>1067</lpage>, doi:<pub-id pub-id-type="doi">10.1093/cercor/bhr178</pub-id> (<year>2012</year>).</mixed-citation></ref>
<ref id="c26"><label>26</label><mixed-citation publication-type="journal"><string-name><surname>Ferrera</surname>, <given-names>V. P.</given-names></string-name>, <string-name><surname>Yanike</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Cassanello</surname>, <given-names>C.</given-names></string-name> <article-title>Frontal eye field neurons signal changes in decision criteria</article-title>. <source>Nat Neurosci</source> <volume>12</volume>, <fpage>1458</fpage>–<lpage>1462</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nn.2434</pub-id> (<year>2009</year>).</mixed-citation></ref>
<ref id="c27"><label>27</label><mixed-citation publication-type="journal"><string-name><surname>Heitz</surname>, <given-names>R. P.</given-names></string-name> &amp; <string-name><surname>Schall</surname>, <given-names>J. D.</given-names></string-name> <article-title>Neural mechanisms of speed-accuracy tradeoff</article-title>. <source>Neuron</source> <volume>76</volume>, <fpage>616</fpage>–<lpage>628</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2012.08.030</pub-id> (<year>2012</year>).</mixed-citation></ref>
<ref id="c28"><label>28</label><mixed-citation publication-type="journal"><string-name><surname>Zhou</surname>, <given-names>Y.</given-names></string-name> <etal>et al.</etal> <article-title>Distributed functions of prefrontal and parietal cortices during sequential categorical decisions</article-title>. <source>Elife</source> <volume>10</volume>, doi:<pub-id pub-id-type="doi">10.7554/eLife.58782</pub-id> (<year>2021</year>).</mixed-citation></ref>
<ref id="c29"><label>29</label><mixed-citation publication-type="journal"><string-name><surname>Horwitz</surname>, <given-names>G. D.</given-names></string-name> &amp; <string-name><surname>Newsome</surname>, <given-names>W. T.</given-names></string-name> <article-title>Separate signals for target selection and movement specification in the superior colliculus</article-title>. <source>Science</source> <volume>284</volume>, <fpage>1158</fpage>–<lpage>1161</lpage>, doi:<pub-id pub-id-type="doi">10.1126/science.284.5417.1158</pub-id> (<year>1999</year>).</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><string-name><surname>Peysakhovich</surname>, <given-names>B</given-names></string-name>. <etal>et al.</etal> <article-title>Primate superior colliculus is engaged in abstract higher-order cognition</article-title>. <source>bioRxiv</source>, doi:<pub-id pub-id-type="doi">10.1101/2023.01.17.524416</pub-id> (<year>2023</year>).</mixed-citation></ref>
<ref id="c31"><label>31</label><mixed-citation publication-type="journal"><string-name><surname>Ding</surname>, <given-names>L.</given-names></string-name> &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name> <article-title>Caudate encodes multiple computations for perceptual decisions</article-title>. <source>J Neurosci</source> <volume>30</volume>, <fpage>15747</fpage>–<lpage>15759</lpage>, doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2894-10.2010</pub-id> (<year>2010</year>).</mixed-citation></ref>
<ref id="c32"><label>32</label><mixed-citation publication-type="journal"><string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name> &amp; <string-name><surname>Shadlen</surname>, <given-names>M. N.</given-names></string-name> <article-title>Representation of a perceptual decision in developing oculomotor commands</article-title>. <source>Nature</source> <volume>404</volume>, <fpage>390</fpage>–<lpage>394</lpage>, doi:<pub-id pub-id-type="doi">10.1038/35006062</pub-id> (<year>2000</year>).</mixed-citation></ref>
<ref id="c33"><label>33</label><mixed-citation publication-type="journal"><string-name><surname>Jun</surname>, <given-names>E. J.</given-names></string-name> <etal>et al.</etal> <article-title>Causal role for the primate superior colliculus in the computation of evidence for perceptual decisions</article-title>. <source>Nat Neurosci</source> <volume>24</volume>, <fpage>1121</fpage>–<lpage>1131</lpage>, doi:<pub-id pub-id-type="doi">10.1038/s41593-021-00878-6</pub-id> (<year>2021</year>).</mixed-citation></ref>
<ref id="c34"><label>34</label><mixed-citation publication-type="journal"><string-name><surname>Shushruth</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Mazurek</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Shadlen</surname>, <given-names>M. N.</given-names></string-name> <article-title>Comparison of Decision-Related Signals in Sensory and Motor Preparatory Responses of Neurons in Area LIP</article-title>. <source>J Neurosci</source> <volume>38</volume>, <fpage>6350</fpage>–<lpage>6365</lpage>, doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.0668-18.2018</pub-id> (<year>2018</year>).</mixed-citation></ref>
<ref id="c35"><label>35</label><mixed-citation publication-type="journal"><string-name><surname>Engel</surname>, <given-names>T. A.</given-names></string-name>, <string-name><surname>Chaisangmongkon</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Freedman</surname>, <given-names>D. J.</given-names></string-name> &amp; <string-name><surname>Wang</surname>, <given-names>X. J.</given-names></string-name> <article-title>Choice-correlated activity fluctuations underlie learning of neuronal category representation</article-title>. <source>Nat Commun</source> <volume>6</volume>, <fpage>6454</fpage>, doi:<pub-id pub-id-type="doi">10.1038/ncomms7454</pub-id> (<year>2015</year>).</mixed-citation></ref>
<ref id="c36"><label>36</label><mixed-citation publication-type="journal"><string-name><surname>Masse</surname>, <given-names>N. Y.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>G. R.</given-names></string-name>, <string-name><surname>Song</surname>, <given-names>H. F.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>X. J.</given-names></string-name> &amp; <string-name><surname>Freedman</surname>, <given-names>D. J.</given-names></string-name> <article-title>Circuit mechanisms for the maintenance and manipulation of information in working memory</article-title>. <source>Nat Neurosci</source> <volume>22</volume>, <fpage>1159</fpage>–<lpage>1167</lpage>, doi:<pub-id pub-id-type="doi">10.1038/s41593-019-0414-3</pub-id> (<year>2019</year>).</mixed-citation></ref>
<ref id="c37"><label>37</label><mixed-citation publication-type="journal"><string-name><surname>Song</surname>, <given-names>H. F.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>G. R.</given-names></string-name> &amp; <string-name><surname>Wang</surname>, <given-names>X. J.</given-names></string-name> <article-title>Training Excitatory-Inhibitory Recurrent Neural Networks for Cognitive Tasks: A Simple and Flexible Framework</article-title>. <source>PLoS Comput Biol</source> <volume>12</volume>, <fpage>e1004792</fpage>, doi:<pub-id pub-id-type="doi">10.1371/journal.pcbi.1004792</pub-id> (<year>2016</year>).</mixed-citation></ref>
<ref id="c38"><label>38</label><mixed-citation publication-type="journal"><string-name><surname>Deco</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Rolls</surname>, <given-names>E. T.</given-names></string-name>, <string-name><surname>Albantakis</surname>, <given-names>L.</given-names></string-name> &amp; <string-name><surname>Romo</surname>, <given-names>R.</given-names></string-name> <article-title>Brain mechanisms for perceptual and reward-related decision-making</article-title>. <source>Prog Neurobiol</source> <volume>103</volume>, <fpage>194</fpage>–<lpage>213</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.pneurobio.2012.01.010</pub-id> (<year>2013</year>).</mixed-citation></ref>
<ref id="c39"><label>39</label><mixed-citation publication-type="journal"><string-name><surname>Finkelstein</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal> <article-title>Attractor dynamics gate cortical information flow during decision-making</article-title>. <source>Nat Neurosci</source> <volume>24</volume>, <fpage>843</fpage>–<lpage>850</lpage>, doi:<pub-id pub-id-type="doi">10.1038/s41593-021-00840-6</pub-id> (<year>2021</year>).</mixed-citation></ref>
<ref id="c40"><label>40</label><mixed-citation publication-type="journal"><string-name><surname>Wang</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Falcone</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Richmond</surname>, <given-names>B.</given-names></string-name> &amp; <string-name><surname>Averbeck</surname>, <given-names>B. B.</given-names></string-name> <article-title>Attractor dynamics reflect decision confidence in macaque prefrontal cortex</article-title>. <source>Nat Neurosci</source> <volume>26</volume>, <fpage>1970</fpage>–<lpage>1980</lpage>, doi:<pub-id pub-id-type="doi">10.1038/s41593-023-01445-x</pub-id> (<year>2023</year>).</mixed-citation></ref>
<ref id="c41"><label>41</label><mixed-citation publication-type="journal"><string-name><surname>Wang</surname>, <given-names>X. J.</given-names></string-name> <article-title>Probabilistic decision making by slow reverberation in cortical circuits</article-title>. <source>Neuron</source> <volume>36</volume>, <fpage>955</fpage>–<lpage>968</lpage>, doi:<pub-id pub-id-type="doi">10.1016/s0896-6273(02)01092-9</pub-id> (<year>2002</year>).</mixed-citation></ref>
<ref id="c42"><label>42</label><mixed-citation publication-type="journal"><string-name><surname>Wong</surname>, <given-names>K. F.</given-names></string-name>, <string-name><surname>Huk</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Shadlen</surname>, <given-names>M. N.</given-names></string-name> &amp; <string-name><surname>Wang</surname>, <given-names>X. J.</given-names></string-name> <article-title>Neural circuit dynamics underlying accumulation of time-varying evidence during perceptual decision making</article-title>. <source>Front Comput Neurosci</source> <volume>1</volume>, <fpage>6</fpage>, doi:<pub-id pub-id-type="doi">10.3389/neuro.10.006.2007</pub-id> (<year>2007</year>).</mixed-citation></ref>
<ref id="c43"><label>43</label><mixed-citation publication-type="journal"><string-name><surname>Motter</surname>, <given-names>B. C.</given-names></string-name> <article-title>Neural correlates of attentive selection for color or luminance in extrastriate area V4</article-title>. <source>J Neurosci</source> <volume>14</volume>, <fpage>2178</fpage>–<lpage>2189</lpage>, doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.14-04-02178.1994</pub-id> (<year>1994</year>).</mixed-citation></ref>
<ref id="c44"><label>44</label><mixed-citation publication-type="journal"><string-name><surname>Motter</surname>, <given-names>B. C.</given-names></string-name> <article-title>Neural correlates of feature selective memory and pop-out in extrastriate area V4</article-title>. <source>J Neurosci</source> <volume>14</volume>, <fpage>2190</fpage>–<lpage>2199</lpage>, doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.14-04-02190.1994</pub-id> (<year>1994</year>).</mixed-citation></ref>
<ref id="c45"><label>45</label><mixed-citation publication-type="journal"><string-name><surname>Martinez-Trujillo</surname>, <given-names>J. C.</given-names></string-name> &amp; <string-name><surname>Treue</surname>, <given-names>S.</given-names></string-name> <article-title>Feature-based attention increases the selectivity of population responses in primate visual cortex</article-title>. <source>Curr Biol</source> <volume>14</volume>, <fpage>744</fpage>–<lpage>751</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.cub.2004.04.028</pub-id> (<year>2004</year>).</mixed-citation></ref>
<ref id="c46"><label>46</label><mixed-citation publication-type="journal"><string-name><surname>Bichot</surname>, <given-names>N. P.</given-names></string-name>, <string-name><surname>Rossi</surname>, <given-names>A. F.</given-names></string-name> &amp; <string-name><surname>Desimone</surname>, <given-names>R.</given-names></string-name> <article-title>Parallel and serial neural mechanisms for visual search in macaque area V4</article-title>. <source>Science</source> <volume>308</volume>, <fpage>529</fpage>–<lpage>534</lpage>, doi:<pub-id pub-id-type="doi">10.1126/science.1109676</pub-id> (<year>2005</year>).</mixed-citation></ref>
<ref id="c47"><label>47</label><mixed-citation publication-type="journal"><string-name><surname>Maunsell</surname>, <given-names>J. H.</given-names></string-name> &amp; <string-name><surname>Treue</surname>, <given-names>S.</given-names></string-name> <article-title>Feature-based attention in visual cortex</article-title>. <source>Trends Neurosci</source> <volume>29</volume>, <fpage>317</fpage>–<lpage>322</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.tins.2006.04.001</pub-id> (<year>2006</year>).</mixed-citation></ref>
<ref id="c48"><label>48</label><mixed-citation publication-type="journal"><string-name><surname>Federer</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Ta’afua</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Merlin</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Hassanpour</surname>, <given-names>M. S.</given-names></string-name> &amp; <string-name><surname>Angelucci</surname>, <given-names>A.</given-names></string-name> <article-title>Stream-specific feedback inputs to the primate primary visual cortex</article-title>. <source>Nat Commun</source> <volume>12</volume>, <fpage>228</fpage>, doi:<pub-id pub-id-type="doi">10.1038/s41467-020-20505-5</pub-id> (<year>2021</year>).</mixed-citation></ref>
<ref id="c49"><label>49</label><mixed-citation publication-type="journal"><string-name><surname>Briggs</surname>, <given-names>F.</given-names></string-name> &amp; <string-name><surname>Usrey</surname>, <given-names>W. M.</given-names></string-name> <article-title>Parallel processing in the corticogeniculate pathway of the macaque monkey</article-title>. <source>Neuron</source> <volume>62</volume>, <fpage>135</fpage>–<lpage>146</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2009.02.024</pub-id> (<year>2009</year>).</mixed-citation></ref>
<ref id="c50"><label>50</label><mixed-citation publication-type="journal"><string-name><surname>Briggs</surname>, <given-names>F.</given-names></string-name> <article-title>Role of Feedback Connections in Central Visual Processing</article-title>. <source>Annu Rev Vis Sci</source> <volume>6</volume>, <fpage>313</fpage>–<lpage>334</lpage>, doi:<pub-id pub-id-type="doi">10.1146/annurev-vision-121219-081716</pub-id> (<year>2020</year>).</mixed-citation></ref>
<ref id="c51"><label>51</label><mixed-citation publication-type="journal"><string-name><surname>Harris</surname>, <given-names>K. D.</given-names></string-name> &amp; <string-name><surname>Mrsic-Flogel</surname>, <given-names>T. D.</given-names></string-name> <article-title>Cortical connectivity and sensory coding</article-title>. <source>Nature</source> <volume>503</volume>, <fpage>51</fpage>–<lpage>58</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nature12654</pub-id> (<year>2013</year>).</mixed-citation></ref>
<ref id="c52"><label>52</label><mixed-citation publication-type="journal"><string-name><surname>Moore</surname>, <given-names>T.</given-names></string-name> &amp; <string-name><surname>Armstrong</surname>, <given-names>K. M.</given-names></string-name> <article-title>Selective gating of visual signals by microstimulation of frontal cortex</article-title>. <source>Nature</source> <volume>421</volume>, <fpage>370</fpage>–<lpage>373</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nature01341</pub-id> (<year>2003</year>).</mixed-citation></ref>
<ref id="c53"><label>53</label><mixed-citation publication-type="journal"><string-name><surname>Gilbert</surname>, <given-names>C. D.</given-names></string-name> &amp; <string-name><surname>Li</surname>, <given-names>W.</given-names></string-name> <article-title>Top-down influences on visual processing</article-title>. <source>Nature reviews. Neuroscience</source> <volume>14</volume>, <fpage>350</fpage>–<lpage>363</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nrn3476</pub-id> (<year>2013</year>).</mixed-citation></ref>
<ref id="c54"><label>54</label><mixed-citation publication-type="journal"><string-name><surname>McManus</surname>, <given-names>J. N.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>W.</given-names></string-name> &amp; <string-name><surname>Gilbert</surname>, <given-names>C. D.</given-names></string-name> <article-title>Adaptive shape processing in primary visual cortex</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source> <volume>108</volume>, <fpage>9739</fpage>–<lpage>9746</lpage>, doi:<pub-id pub-id-type="doi">10.1073/pnas.1105855108</pub-id> (<year>2011</year>).</mixed-citation></ref>
<ref id="c55"><label>55</label><mixed-citation publication-type="journal"><string-name><surname>Nienborg</surname>, <given-names>H.</given-names></string-name> &amp; <string-name><surname>Cumming</surname>, <given-names>B. G.</given-names></string-name> <article-title>Decision-related activity in sensory neurons reflects more than a neuron’s causal effect</article-title>. <source>Nature</source> <volume>459</volume>, <fpage>89</fpage>–<lpage>92</lpage>, doi:<pub-id pub-id-type="doi">10.1038/nature07821</pub-id> (<year>2009</year>).</mixed-citation></ref>
<ref id="c56"><label>56</label><mixed-citation publication-type="journal"><string-name><surname>Bondy</surname>, <given-names>A. G.</given-names></string-name>, <string-name><surname>Haefner</surname>, <given-names>R. M.</given-names></string-name> &amp; <string-name><surname>Cumming</surname>, <given-names>B. G.</given-names></string-name> <article-title>Feedback determines the structure of correlated variability in primary visual cortex</article-title>. <source>Nat Neurosci</source> <volume>21</volume>, <fpage>598</fpage>–<lpage>606</lpage>, doi:<pub-id pub-id-type="doi">10.1038/s41593-018-0089-1</pub-id> (<year>2018</year>).</mixed-citation></ref>
<ref id="c57"><label>57</label><mixed-citation publication-type="journal"><string-name><surname>Wimmer</surname>, <given-names>K.</given-names></string-name> <etal>et al.</etal> <article-title>Sensory integration dynamics in a hierarchical network explains choice probabilities in cortical area MT</article-title>. <source>Nat Commun</source> <volume>6</volume>, <fpage>6177</fpage>, doi:<pub-id pub-id-type="doi">10.1038/ncomms7177</pub-id> (<year>2015</year>).</mixed-citation></ref>
<ref id="c58"><label>58</label><mixed-citation publication-type="journal"><string-name><surname>Prat-Ortega</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Wimmer</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Roxin</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>de la Rocha</surname>, <given-names>J.</given-names></string-name> <article-title>Flexible categorization in perceptual decision making</article-title>. <source>Nat Commun</source> <volume>12</volume>, <fpage>1283</fpage>, doi:<pub-id pub-id-type="doi">10.1038/s41467-021-21501-z</pub-id> (<year>2021</year>).</mixed-citation></ref>
<ref id="c59"><label>59</label><mixed-citation publication-type="journal"><string-name><surname>Wong</surname>, <given-names>K. F.</given-names></string-name> &amp; <string-name><surname>Wang</surname>, <given-names>X. J.</given-names></string-name> <article-title>A recurrent network mechanism of time integration in perceptual decisions</article-title>. <source>J Neurosci</source> <volume>26</volume>, <fpage>1314</fpage>–<lpage>1328</lpage>, doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.3733-05.2006</pub-id> (<year>2006</year>).</mixed-citation></ref>
<ref id="c60"><label>60</label><mixed-citation publication-type="journal"><string-name><surname>Rao</surname>, <given-names>R. P.</given-names></string-name> &amp; <string-name><surname>Ballard</surname>, <given-names>D. H.</given-names></string-name> <article-title>Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects</article-title>. <source>Nat Neurosci</source> <volume>2</volume>, <fpage>79</fpage>–<lpage>87</lpage>, doi:<pub-id pub-id-type="doi">10.1038/4580</pub-id> (<year>1999</year>).</mixed-citation></ref>
<ref id="c61"><label>61</label><mixed-citation publication-type="journal"><string-name><surname>Friston</surname>, <given-names>K.</given-names></string-name> &amp; <string-name><surname>Kiebel</surname>, <given-names>S.</given-names></string-name> <article-title>Predictive coding under the free-energy principle</article-title>. <source>Philos Trans R Soc Lond B Biol Sci</source> <volume>364</volume>, <fpage>1211</fpage>–<lpage>1221</lpage>, doi:<pub-id pub-id-type="doi">10.1098/rstb.2008.0300</pub-id> (<year>2009</year>).</mixed-citation></ref>
<ref id="c62"><label>62</label><mixed-citation publication-type="journal"><string-name><surname>Bastos</surname>, <given-names>A. M.</given-names></string-name> <etal>et al.</etal> <article-title>Canonical microcircuits for predictive coding</article-title>. <source>Neuron</source> <volume>76</volume>, <fpage>695</fpage>–<lpage>711</lpage>, doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2012.10.038</pub-id> (<year>2012</year>).</mixed-citation></ref>
<ref id="c63"><label>63</label><mixed-citation publication-type="journal"><string-name><surname>Shipp</surname>, <given-names>S.</given-names></string-name> <article-title>Neural Elements for Predictive Coding</article-title>. <source>Front Psychol</source> <volume>7</volume>, <fpage>1792</fpage>, doi:<pub-id pub-id-type="doi">10.3389/fpsyg.2016.01792</pub-id> (<year>2016</year>).</mixed-citation></ref>
<ref id="c64"><label>64</label><mixed-citation publication-type="journal"><string-name><surname>Kobak</surname>, <given-names>D.</given-names></string-name> <etal>et al.</etal> <article-title>Demixed principal component analysis of neural population data</article-title>. <source>Elife</source> <volume>5</volume>, doi:<pub-id pub-id-type="doi">10.7554/eLife.10989</pub-id> (<year>2016</year>).</mixed-citation></ref>
<ref id="c65"><label>65.</label><mixed-citation publication-type="web"><string-name><surname>Chaoming Wang</surname>, <given-names>X. C.</given-names></string-name>, <string-name><surname>Tianqiu Zhang</surname>, <given-names>Si Wu.</given-names></string-name> <article-title>BrainPy: a flexible, integrative, efficient, and extensible framework towards general-purpose brain dynamics programming</article-title>. <source>bioRxiv</source>, <pub-id pub-id-type="doi">10.1101/2022.10.28.514024</pub-id> (<year>2022</year>).</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.96402.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Krug</surname>
<given-names>Kristine</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Otto-von-Guericke University Magdeburg</institution>
</institution-wrap>
<city>Magdeburg</city>
<country>Germany</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>valuable</bold> study by Wu and Zhou combines neurophysiological recordings and computational modelling to address an interesting question regarding the sequence of events from sensing to action. Neurophysiological evidence remains <bold>incomplete</bold>: explicit mapping of saccade-related activity in the same neurons and a better understanding of the influence of the spatial configuration of stimulus and targets would be required to pinpoint whether such activity might contribute, even partially, to the observed results and interpretations. These results are of interest for neuroscientists investigating decision-making.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.96402.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This valuable study by Wu and Zhou combined neurophysiological recordings and computational modelling to investigate the neural mechanisms that underpin the interaction between sensory evaluation and action selection. The neurophysiological results suggest non-linear modulation of decision-related LIP activity by action selection, but some further analysis would be helpful in order to understand whether these results can be generalised to LIP circuitry or might be dependent on specific spatial task configurations. The authors present solid computational evidence that this might be due to projections from choice target representations. These results are of interest for neuroscientists investigating decision-making.</p>
<p>Strengths:</p>
<p>Wu and Zhou combine awake behaving neurophysiology for a sophisticated, flexible visual-motion discrimination task and a recurrent network model to disentangle the contribution of sensory evaluation and action selection to LIP firing patterns. The correct saccade response direction for preferred motion direction choices is randomly interleaved between contralateral and ipsilateral response targets, which allows the dissociation of perceptual choice from saccade direction.</p>
<p>
The neurophysiological recordings from area LIP indicate non-linear interaction between motion categorisation decisions and saccade choice direction.</p>
<p>The careful investigation of a recurrent network model suggests that feedback from choice target representations to an earlier sensory evaluation stage might be the source for this non-linear modulation and that it is an important circuit component for behavioural performance.</p>
<p>The paper presents a possible solution to a central controversy about the role of LIP in perceptual decision-making, but see below.</p>
<p>Weaknesses:</p>
<p>The paper presents a possible solution to a central controversy about the role of LIP in perceptual decision-making. However, the authors could be more clear and upfront about their interpretational framework and potential alternative interpretations.</p>
<p>
Centrally, the authors' model and experimental data appears to test only that LIP carries out sensory evaluation in its RFs. The model explicitly parks the representation of choice targets outside the &quot;LIP&quot; module receiving sensory input. The feedback from this separate target representation provides then the non-linear modulation that matches the neurophysiology. However, they ignore the neurophysiological results that LIP neurons can also represent motor planning to a saccade target.</p>
<p>
The neurophysiological results with a modulation of the direction tuning by choice direction (contralateral vs ipsilateral) are intriguing. However, the evaluation of the neurophysiological results are difficult, because some of the necessary information is missing to exclude alternative explanations. It would be good to see the actual distributions and sizes of the RF, which were determined based on visual responses not with a delayed saccade task. There might be for example a simple spatial configuration, for example, RF and preferred choice target in the same (contralateral) hemifield, for which there is an increase in firing. It is a shame that we do not see what these neurons would do if only a choice target would be put in the RF, as has been done in so many previous LIP experiments. The authors exclude also some spatial task configurations (vertical direction decisions), which makes it difficult to judge whether these data and models can be generalised. The whole section is difficult to follow, partly also because it appears to mix reporting results with interpretation (e.g. &quot;feedback&quot;).</p>
<p>The model and its investigation is very interesting and thorough, but given the neurophysiological literature on LIP, it is not clear that the target module would need to be in a separate brain area, but could be local circuitry within LIP between different neuron types.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.96402.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>In this manuscript, the authors recorded activity in the posterior parietal cortex (PPC) of monkeys performing a perceptual decision-making task. The monkeys were first shown two choice dots of two different colors. Then, they saw a random dot motion stimulus. They had to learn to categorize the direction of motion as referring to either the right or left dot. However, the rule was based on the color of the dot and not its location. So, the red dot could either be to the right or left, but the rule itself remained the same. It is known from past work that PPC neurons would code the learned categorization. Here, the authors showed that the categorization signal depended on whether the executed saccade was in the same hemifield as the recorded PPC neuron or in the opposite one. That is, if a neuron categorized the two motion directions such that it responded stronger for one than the other, then this differential motion direction coding effect was amplified if the subsequent choice saccade was in the same hemifield. The authors then built a computational RNN to replicate the results and make further tests by simulated &quot;lesions&quot;.</p>
<p>Strengths:</p>
<p>Linking the results to RNN simulations and simulated lesions.</p>
<p>Weaknesses:</p>
<p>Potential interpretational issues due to a lack of evidence on what happens at the time of the saccades.</p>
</body>
</sub-article>
</article>