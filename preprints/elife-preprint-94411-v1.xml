<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">94411</article-id>
<article-id pub-id-type="doi">10.7554/eLife.94411</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.94411.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Indistinguishable network dynamics can emerge from unalike plasticity rules</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Ramesh</surname>
<given-names>Poornima</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Confavreux</surname>
<given-names>Basile</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Gonçalves</surname>
<given-names>Pedro J.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="author-notes" rid="n1">†</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3295-6181</contrib-id>
<name>
<surname>Vogels</surname>
<given-names>Tim P.</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n1">†</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5154-8912</contrib-id>
<name>
<surname>Macke</surname>
<given-names>Jakob H.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a5">5</xref>
<xref ref-type="author-notes" rid="n1">†</xref>
</contrib>
<aff id="a1"><label>1</label><institution>University of Tübingen</institution>, <country>Germany</country></aff>
<aff id="a2"><label>2</label><institution>Institute of Science and Technology</institution>, <country>Austria</country></aff>
<aff id="a3"><label>3</label><institution>VIB-Neuroelectronics Research Flanders (NERF)</institution>, <country>Belgium</country></aff>
<aff id="a4"><label>4</label><institution>imec</institution>, <country>Belgium</country></aff>
<aff id="a5"><label>5</label><institution>Max Planck Institute for Intelligent Systems</institution>, Tübingen, <country>Germany</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Gjorgjieva</surname>
<given-names>Julijana</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Technical University of Munich</institution>
</institution-wrap>
<city>Freising</city>
<country>Germany</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Poirazi</surname>
<given-names>Panayiota</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>FORTH Institute of Molecular Biology and Biotechnology</institution>
</institution-wrap>
<city>Heraklion</city>
<country>Greece</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>For correspondence: <email>poornimaramesh1995@gmail.com</email>, <email>basile.confavreux@gmail.com</email></corresp>
<fn id="n1" fn-type="equal"><label>†</label><p>These authors contributed equally to this work.</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-03-13">
<day>13</day>
<month>03</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP94411</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-11-30">
<day>30</day>
<month>11</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-11-04">
<day>04</day>
<month>11</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.11.01.565168"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Ramesh et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Ramesh et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-94411-v1.pdf"/>
<abstract>
<p>Synaptic plasticity is thought to be critical for building and maintaining brain circuits. Models of plasticity, or plasticity rules, are typically designed by hand, and evaluated based on their ability to elicit similar neuron or circuit properties to ground truth. While this approach has provided crucial insights into plasticity mechanisms, it is limited in its scope by human intuition and cannot identify <italic>all</italic> plasticity mechanisms that are consistent with the empirical data of interest. In other words, focusing on individual hand-crafted rules ignores the potential degeneracy of plasticity mechanisms that explain the same empirical data, and may thus lead to inaccurate experimental predictions. Here, we use an unsupervised, adversarial approach to infer plasticity rules directly from neural activity recordings. We show that even in a simple, idealised network model, many mechanistically different plasticity rules are equally compatible with empirical data. Our results suggest the need for a shift in the study of plasticity rules, considering as many degenerate plasticity mechanisms consistent with data as possible, before formulating experimental predictions.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title><italic>K</italic>eywords</title>
<kwd>Computational Neuroscience</kwd>
<kwd>Meta-learning</kwd>
<kwd>Synaptic plasticity</kwd>
<kwd>Generative adversarial networks</kwd>
</kwd-group>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<label>1</label>
<title>Introduction</title>
<p>Synaptic plasticity is the ability of synapses to change their efficacy based on their pre- and postsynaptic environments and it is thought to be critical for the brain’s ability to learn from and remember past experiences [<xref ref-type="bibr" rid="c1">1</xref>, <xref ref-type="bibr" rid="c2">2</xref>]. Experimental efforts to understand the “plasticitome”, i.e., the combined action of many synapses [<xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c4">4</xref>, <xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c6">6</xref>] are still hampered by the inability to record from multiple synapses simultaneously, <italic>in vivo</italic>, during learning. Theoretical models fill this void, allowing us to link analytical arguments and the available empirical data to propose putative mechanistic plasticity rules to serve a given network function [<xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c8">8</xref>, <xref ref-type="bibr" rid="c9">9</xref>, <xref ref-type="bibr" rid="c10">10</xref>, <xref ref-type="bibr" rid="c11">11</xref>].</p>
<p>Critically, such rules rely on human intuition and hand-tuning [<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c13">13</xref>], but they rarely test if more than a <italic>single</italic> plasticity rule could produce a desired network effect (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>). Indeed, any possible degeneracy is difficult to explore in hand-tuned systems. On the other hand, degeneracy is so widely observed in neuroscience [<xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c15">15</xref>, <xref ref-type="bibr" rid="c16">16</xref>] — and biology more generally — that it would be erroneous to assume singular solutions for a given plastic system.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1:</label>
<caption><p>(A) We hypothesise that multiple plasticity mechanisms could lead to the same neural network activities, i.e., there is degeneracy of plasticity mechanisms. (B) Adversarial learning of plasticity rules: empirical data are simulations of the postsynaptic activity of a rate network with plastic synapses evolving according to Oja’s rule. The generator G is a rate network with synapses evolving according to a tunable MLP rule. The discriminator D is a flexible network trained to distinguish empirical data from the generator output. In our framework, the generator and discriminator are trained so that at convergence, the learned MLP rule makes the generator produce postsynaptic neural activity traces indistinguishable from the empirical data.</p></caption>
<graphic xlink:href="565168v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>A promising approach to unveil potential degeneracy in plasticity is to use automated methods to either propose a range of potential plasticity rules for further hand-crafted modelling, or to systematically explore the space of plausible plasticity rules underlying empirical observations or subserving network computations. Such recent attempts to infer plasticity mechanisms with automated methods [<xref ref-type="bibr" rid="c17">17</xref>, <xref ref-type="bibr" rid="c18">18</xref>, <xref ref-type="bibr" rid="c19">19</xref>, <xref ref-type="bibr" rid="c20">20</xref>, <xref ref-type="bibr" rid="c21">21</xref>] use flexible parametrizations of plasticity rules, such as Volterra expansions [<xref ref-type="bibr" rid="c17">17</xref>, <xref ref-type="bibr" rid="c18">18</xref>, <xref ref-type="bibr" rid="c20">20</xref>] or neural networks [<xref ref-type="bibr" rid="c19">19</xref>, <xref ref-type="bibr" rid="c21">21</xref>], to capture the widest possible range of plasticity mechanisms. Handcrafted loss functions (or meta-objectives) are then used to shape the parameters of these rules to satisfy a given biological constraint, e.g., network stability or familiarity detection. Unfortunately, hand-crafted loss functions come with similar issues as hand-crafted rules, in that they can only produce the results within reach of human intuition. For instance, it is difficult to glean a comprehensive loss function from given experimentally recorded neural activity. What’s more, it is near impossible to exclude non-plasticity-related contributions to network activity such as changes in state or input to the network, or measurement variability (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>).</p>
<p>Here, we propose to deduce both plasticity rules <italic>and</italic> loss functions directly from empirical data in an adversarial game in which a <italic>generative</italic> Deep Neural Network (DNN) produces plasticity rules that create simulated data good enough to trick a second, <italic>discriminative</italic> DNN into classifying it as empirical. This pair of DNNs, termed Generative Adversarial Networks [<xref ref-type="bibr" rid="c22">22</xref>, GANs] attempt to reproduce the statistical properties — rather than achieve a point-to-point match — of a specified dataset.</p>
<p>We hypothesise that this approach allows us to unveil degeneracy in meta-learned plasticity rules while disregarding confounding factors not related to plasticity. Indeed, by construction, GANs enforce a separation between a systematic component due to the plasticity mechanisms and a noisy component due to other confounding factors: since the adversarial game trains the generative DNN to match the distribution of activity traces [<xref ref-type="bibr" rid="c22">22</xref>], and the only tunable parameters are associated with the systematic component, i.e., the plasticity mechanisms, the generator is forced to disregard the confounding factors while updating the plasticity rule parameters.</p>
<p>In a proof-of-principle, we show that GANs find multiple, mechanistically different plasticity rules that can produce activity consistent with synthetic empirical dynamics. More specifically, our adversarial approach identifies degenerate plasticity rules on synthetic data simulated with a known plasticity rule, i.e., Oja’s rule [<xref ref-type="bibr" rid="c23">23</xref>]. Using synthetic data from a known rule allows us to compare the rules learned with our framework to the ground-truth rule without any unknown additional factors. All the plasticity rules learned by our approach plausibly and robustly generate activity traces that are statistically indistinguishable from the training data, even though their synaptic weight dynamics differ substantially from those produced with Oja’s rule. Our findings point towards a necessary shift from looking for the correct synaptic plasticity rule for a given network function, to inferring entire families of rules with similar network-level function.</p>
</sec>
<sec id="s2">
<label>2</label>
<title>Results</title>
<p>To investigate if multiple plasticity rules could achieve similar neural dynamics, we used an adversarial approach to deduce both the plasticity rules and the loss function from (simulated) <italic>empirical</italic> neural activity. The GAN approach implicitly selects the features of the empirical data [<xref ref-type="bibr" rid="c24">24</xref>, <xref ref-type="bibr" rid="c25">25</xref>, <xref ref-type="bibr" rid="c26">26</xref>] relevant to the determine the plasticity mechanisms at play, thus requiring no additional pre-specified constraints on the data (<xref rid="fig1" ref-type="fig">Fig. 1B</xref>, but see discussion). We show that our approach reveals many mechanistically different rules consistent with the empirical data, indicating that the plasticity mechanisms are degenerate, even in the idealised setting of our rate networks. Moreover, the recovered rules exhibit similar generalization properties to the ground-truth rule, such as scale-invariance and robustness to measurement noise.</p>
<sec id="s2a">
<label>2.1</label>
<title>Model set-up and empirical data collection</title>
<p>We considered an idealized setting with a two-layer linear feedforward network with plastic weights (<xref rid="fig1" ref-type="fig">Fig. 1B</xref>). We then produced an ensemble of weight- and activity traces using a known plasticity rule, i.e., Oja’s rule [<xref ref-type="bibr" rid="c23">23</xref>] (<xref rid="fig2" ref-type="fig">Fig. 2</xref>, top row; Sec. Empirical data and Oja’s rule), in which the weights converge to the first principal vector of the input data (<xref rid="fig2" ref-type="fig">Fig. 2C</xref>) while the postsynaptic activity assumes the value of the first principal component (<xref rid="fig2" ref-type="fig">Fig. 2B</xref>, black traces, Methods). Subsequently, we used this empirical data to train and evaluate our GAN-based solutions. We flexibly parameterized plasticity rules with a multi-layer perceptron (MLP, 3-layers, Methods, Parametrized learning rules). This MLP approximates local plasticity rules, i.e., it updates each synapse in the linear network at timepoint <italic>t</italic> based on the pre-synaptic activity <inline-formula><inline-graphic xlink:href="565168v1_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, postsynaptic activity <inline-formula><inline-graphic xlink:href="565168v1_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and current synaptic weight of the given synapse <inline-formula><inline-graphic xlink:href="565168v1_inline3.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. As a control, we confirmed that the plasticity parameterization with the MLP is flexible enough to approximate Oja’s rule, and that the GAN approach is capable of rediscovering Oja’s rule using a constrained search space (Supp. Fig. 5).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Disparate plasticity rules with same postsynaptic activity.</title>
<p>(A) Investigated plasticity rule. (B) Postsynaptic activity traces of a rate network simulated with Oja’s rule (black) and local MLP rule (blue) for different initial synaptic weights (top). Learned-rule activities versus the original Oja’s rule activities at different time points and for different initial synaptic weights (bottom). (C) Weight trajectories, as measured by ||<italic>PC</italic><sub>1</sub> − <italic>ω</italic> || . Oja’s rule (top), local MLP (bottom). (D) Synaptic weight updates Δ<italic>ω</italic> for a range of presynaptic activities <italic>x</italic> and postsynaptic activities <italic>y</italic> and <italic>ω</italic> = 0.01. Oja’s rule (top), local MLP (bottom). (E) Vector field of <italic>ω</italic> versus postsynaptic activity <italic>y</italic> with presynaptic activity fixed at <italic>x</italic> = 0.5 (nullclines in black, fixed points in red). Oja’s rule (top), local MLP (bottom).</p></caption>
<graphic xlink:href="565168v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2b">
<label>2.2</label>
<title>Disparate plasticity rules with same postsynaptic activity</title>
<p>We began our investigation by adversarially training the MLP-rule on a large collection of (synthetic) empirical data (<xref rid="fig2" ref-type="fig">Fig. 2</xref>, bottom row). The thus-trained MLP-rule elicited activity traces that qualitatively captured the salient features of the empirical postsynaptic activity, e.g., the transient increase in postsynaptic activity at earlier timepoints, and the convergence to a stable value at later time points (Supp. Fig. 6). Importantly, the MLP rule reproduced the statistics of held-out empirical data (<xref rid="fig2" ref-type="fig">Fig 2B</xref>, bottom panels), even when single trials diverged from the empirical activity traces, in line with our expectation that GANs train on the ensemble rather than on the individual trials.</p>
<p>However, the evolution of the synaptic weights dictated by the trained MLP-rule diverged from the trajectories predicted by Oja’s rule (<xref rid="fig2" ref-type="fig">Fig. 2C</xref>), as quantified by the Euclidean distance between the synaptic weights and the first principal component of the pre-synaptic activity PC<sub>1</sub> at each time point [<xref ref-type="bibr" rid="c17">17</xref>]. As expected this distance decayed to 0 for Oja’s rule [<xref ref-type="bibr" rid="c23">23</xref>] but not for the trained MLP-rule (<xref rid="fig2" ref-type="fig">Fig 2C</xref>), indicating that although the network activity was similar, the synaptic weights evolving with the trained MLP rule never converged to PC<sub>1</sub>.</p>
<p>We could also compare the ground-truth and trained MLP rules more systematically by computing the hypothetical synaptic weight update for a range of presynaptic <italic>x</italic><sub><italic>j</italic></sub> and postsynaptic <italic>y</italic><sub><italic>i</italic></sub> activities — the observable network variables — at the fixed synaptic weight <italic>ω</italic><sub><italic>ij</italic></sub> = 0.01. The resulting heatmap of synaptic weight-updates Δ<italic>ω</italic><sub><italic>ij</italic></sub> = <italic>f</italic> (<italic>x</italic><sub><italic>j</italic></sub>, <italic>y</italic><sub><italic>i</italic></sub>, <italic>ω</italic><sub><italic>ij</italic></sub> = 0.01) shows a large qualitative difference between Oja’s rule (used to produce the empirical data) and the trained MLP rule, both regarding the magnitude of weight updates and the ranges of pre- and post-synaptic firing rates leading to potentiation (Δ<italic>ω</italic><sub><italic>ij</italic></sub> <italic>&gt;</italic> 0) and depression (Δ<italic>ω</italic><sub><italic>ij</italic></sub> <italic>&lt;</italic> 0) (<xref rid="fig2" ref-type="fig">Fig. 2D</xref>). For instance, Oja’s rule is symmetric along the diagonal and anti-diagonal, whereas no such symmetry could be observed in the trained MLP rule.</p>
<p>In order to further compare the interaction of synaptic weights and post-synaptic activity of Oja’s and the MLP rule, we computed the vector-field of the postsynaptic activity and the synaptic weight for a fixed pre-synaptic activity of 0.5 (<xref rid="fig2" ref-type="fig">Fig. 2E</xref>). Plotting this vector-field allowed us to understand how the coupled dynamical system of weights and network activity evolved, and thus compare different rules. Like for other measures, the weight update diagrams and their subsequent dynamics of the MLP rule showed large differences from Oja’s rule. Interestingly, the trained MLP rule had only one stable fixed point. Collectively, our results suggest that there exists at least one plasticity rule that is mechanistically different from Oja’s rule but produces statistically indistinguishable activity.</p>
</sec>
<sec id="s2c">
<label>2.3</label>
<title>Learned rules with same generalisation properties as Oja’s rule</title>
<p>Plasticity is only one of many neural mechanisms underlying network dynamics. Thus, it is plausible that two networks with the same plasticity rule have different recorded dynamics, due to a plethora of other sources of variability such as changing inputs, noisy individual neuron dynamics, and noisy measurements. We wondered whether our GAN approach is able to ignore contributions to neural variability from sources unrelated to plasticity.</p>
<p>In order to address this, we generated data from two networks with Oja’s rule, with different settings compared to the original network: additive noise in the post-synaptic neuron (<xref rid="fig3" ref-type="fig">Fig 3A</xref>); and increased number of pre-synaptic neurons (from 3 to 39, <xref rid="fig3" ref-type="fig">Fig 3B</xref>, see Methods for details). We trained a local MLP rule with the GAN approach on each of these two different datasets. We then used the two resulting MLP rules to generate post-synaptic activity in the original setting, i.e., rate networks with only 3 pre-synaptic neurons and noiseless post-synaptic activity. Note that the rules were <italic>not</italic> trained on the original setting.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3:</label>
<caption><title>Learned rules have same generalisation properties as Oja’s rule.</title>
<p>(A) MLP rule on 3 presynaptic neurons and a noisy postsynaptic neuron: trained with GAN and tested on the same network (top, light brown), trained with a mean-squared error loss and tested on the same network (middle, brown), and trained with GAN and tested on a network with 3 presynaptic neurons and a noiseless postsynaptic neuron (bottom, dark brown). (B) MLP rule on 39 presynaptic neurons and a noiseless postsynaptic neuron: trained with GAN and tested on the same network (top, pink) and on a network with 3 presynaptic neurons and a noiseless postsynaptic neuron (bottom, red). (I) Trajectories of postsynaptic activity for various synaptic weight initialisations generated with GAN-learned MLP rules are qualitatively similar to those from Oja’s rule. (II) Activites from GAN-learned rule at different time points match the statistics of Oja’s rule for both held-out data from the training network and test network. (III) Weight trajectories for learned plasticity rules. Oja’s rule in black.</p></caption>
<graphic xlink:href="565168v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We found that the two MLP rules, specifically the <italic>same</italic> rules that captured the activity statistics of the training data, accurately reproduced the statistics of the empirical activity traces from the original test dataset, and therefore successfully ignored the perturbations included in both training datasets (<xref rid="fig3" ref-type="fig">Fig. 3 I, II</xref>). As before, the evolution of the weights of the two learned rules and their vector-field dynamics differed substantially from Oja’s rule (<xref rid="fig3" ref-type="fig">Fig. 3III</xref> and Supp. Fig. 7). In addition, the ability of our GAN-learned MLP rules to generalise over different datasets such as the perturbed datasets used above was not matched by MLP rules trained with supervised loss functions (<xref rid="fig3" ref-type="fig">Fig. 3A</xref>, Mean Squared Error on the activity trajectories), highlighting again that selecting the features of the data, and by extension, crafting a loss function to fit plasticity — and avoid overfitting — is crucial and non-trivial.</p>
<p>Collectively, these findings confirm that multiple, mechanistically different plasticity rules can shape networks to elicit similar activity as Oja’s rule. Moreover, our adversarially-trained plasticity rules exhibit remarkable generalization properties between disparate training data and succeed in retaining only the features from the training data that are directly connected to the plasticity mechanisms. In other words, the variety of learned rules we observed stems from a degeneracy in plausible plasticity mechanisms and not from other sources of variability in the data.</p>
</sec>
<sec id="s2d">
<label>2.4</label>
<title>Different learned rules due to modeller bias</title>
<p>Next we considered the effect of training different classes of plasticity rules on the same empirical data. So far, we used a parametrization that relied exclusively on local synaptic information, i.e., pre- and post-synaptic activity, and the synaptic weight. We expanded the parametrization so that the weight-update was also dependent on the average pre-synaptic activity and average synaptic weight of all synapses at the time of the update. We called this parametrization “semi global”. In addition, we considered a “global” parametrization in which all neurons’ rates and all synaptic weights were available to every synaptic weight update. Finally, we considered a local MLP biased towards Oja’s rule (see Methods).</p>
<p>As before, the trained rules reproduced the statistics of the empirical data (<xref rid="fig4" ref-type="fig">Fig 4B</xref>), while their weight dynamics differed from Oja’s rule (<xref rid="fig4" ref-type="fig">Fig 4C</xref>). Notably, they also differed from the weight dynamics of the previously learned rules (<xref rid="fig4" ref-type="fig">Fig 4D,E</xref>), showing that different rule parametrizations lead to different learned rules, and thus suggesting the existence of several optimum points in the landscape of learning rules that are all equally consistent with the empirical data. Varying model architectures may nudge the parametrized rule closer to one of these points in the rule landscape, resulting in convergence to a different plasticity rule depending on the model architecture.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4:</label>
<caption><title>Different learned rules due to modeller bias.</title>
<p>(A) Parametrized plasticity rules. Oja+Local MLP (top), semi-global MLP (middle) and global MLP (bottom). (B) Learned-rule activities versus the original Oja’s rule activities at different time points and for different initial synaptic weights. (C) Weight trajectories, as measured by ||<italic>PC</italic><sub>1</sub> – <italic>ω</italic> || for Oja + local MLP (top, purple), semi-global MLP (middle, green), global MLP (bottom, yellow). (D) Synaptic weight updates Δ<italic>ω</italic> for a range of presynaptic activities <italic>x</italic> and postsynaptic activities <italic>y</italic> and <italic>ω</italic> = 0.01. (E) Vector field of <italic>ω</italic> versus postsynaptic activity <italic>y</italic> with presynaptic activity fixed at <italic>x</italic> = 0.5.</p></caption>
<graphic xlink:href="565168v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</sec>
<sec id="s3">
<label>3</label>
<title>Discussion</title>
<p>Theoretical studies about synaptic plasticity typically postulate specific, biologically plausible network functions and hand-design rules to produce them. They often focus on small numbers of canonical rules, with a few terms capturing first-order dependencies on synaptic variables [<xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c8">8</xref>, <xref ref-type="bibr" rid="c11">11</xref>]. However, each specific rule provides only one of potentially many consistent explanations for a given dataset, and might overfit to confounding factors inherent to the empirical data. Without exploring the space of possible solutions, it is difficult to assess the validity, completeness, and robustness of a given rule, or to judge its role in memory and learning.</p>
<p>Here, we introduced a GAN framework that allowed us to flexibly explore a larger and less biased space of solutions by algorithmically identifying plasticity rules directly from data. By adversarially training the plasticity rule and the loss function, we found a multitude of rules that captured the same neural dynamics. Crucially, these GAN-learned rules were not variations of the same rule with multiplicative or additive factors, but exhibited a wide range of different weight dynamics and fixed points. Furthermore, these novel rules also differed depending on the rule parametrizations, i.e., modeller bias. Finally, we showed that under subsampling conditions or added observation noise, the inferred rules still captured the statistics of the original unperturbed test dataset. This robustness to different sources of variability in the empirical data indicated that the underlying plasticity mechanisms were truly degenerate.</p>
<p>Degeneracy is present all throughout biology, and more specifically in neuroscience [<xref ref-type="bibr" rid="c14">14</xref>], and it would be surprising if synaptic plasticity mechanisms were the exception. Our study shows that degeneracy is present even in idealized systems, and that learned plasticity rules are strongly influenced by modeller bias. Our results suggest that we must account for degeneracy in plasticity mechanisms in order to gain meaningful insights about their role in neural computations. However, the theoretical possibility of degenerate solutions as shown here does not prove their biological implementation, and several more steps are necessary to provide experimentally tractable rules and testable predictions. Since the number of observable neurons in a given experiment is much smaller than the number of synaptic variables in the system, constraining plasticity rules by neural activity measurements alone may not resolve the issue. It will thus be helpful to build more biologically detailed models to make predictions on what experimental features to focus our attention on. Alternatively, some of these issues might be resolved by adopting probabilistic machine learning approaches to obtain uncertainty estimates for plasticity rules inferred from neural activity [<xref ref-type="bibr" rid="c28">28</xref>], although this remains a subject for future work.</p>
<p>Our investigations focused solely on Oja’s rule: while this is a canonical rule which has been extensively studied, it is likely too simple to form a realistic representation of plasticity mechanisms in the brain. In principle, it is conceivable that more complex rules [<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c13">13</xref>], operating in larger neural populations implementing more sophisticated computations, could be inferred from data unambiguously. However, it is possible (and we would argue probable) that adding complexity in the system will make degeneracy even more likely.</p>
<p>We chose GANs because of their ability to automatically and implicitly select features from data, thus removing the need to hand-craft loss functions. In addition, since GANs attempt to capture <italic>distributions</italic> of activity traces rather than specific traces, the learned rules are largely agnostic to trial-specific features which are uncontrolled for in the experimental setting and independent of synaptic plasticity, such as e.g., the attentional state of an animal [<xref ref-type="bibr" rid="c29">29</xref>], or experimental noise. However, despite the flexibility to learn synaptic plasticity rules that GANs enable, their application can be technically demanding: they are notoriously hard to train, sensitive to initial conditions, and prone to mode collapse [<xref ref-type="bibr" rid="c30">30</xref>, <xref ref-type="bibr" rid="c31">31</xref>, <xref ref-type="bibr" rid="c32">32</xref>]. Furthermore, GANs only provide one consistent plasticity rule per training run, such that full exploration of the space of solutions is arduous. How this approach scales to more complex, higher-dimensional systems is a question for future work.</p>
</sec>
<sec id="s4">
<title>Conclusion</title>
<p>Degeneracy is an ubiquitous phenomenon in neuroscience, and its implications are crucial for our understanding of neural computation in general and the mechanisms of plasticity in particular. Our attempt to flexibly learn rules directly from data in a simple scenario reveals that different plasticity rules can explain the same data equally well, provided the generative model of plasticity is expressive enough. This suggests we should shift the way we think about plasticity rules: not as a singular mechanism implemented by every synapse, but rather as families of rules with similar network-level function and with potential mechanistic differences across different synapses. And rather than studying one rule at a time, one might attempt to characterize properties across ranges of rules, and potentially derive predictions <italic>shared</italic> across plasticity rules. These predictions are likely to be more robust than predictions idiosyncratic to a specific rule, and also suggest a more topological view of plasticity.</p>
</sec>
<sec id="d1e773" sec-type="supplementary-material">
<title>Supporting information</title>
<supplementary-material id="d1e861">
<label>Supplementary material</label>
<media xlink:href="supplements/565168_file02.pdf"/>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>We thank Everton J. Agnes, Friedemann Zenke, Chaintanya Chintaluri, Auguste Schulz, Richard Gao and Julius Vetter for helpful discussions and feedback on the manuscript. This work was funded by the German Research Foundation (DFG; Germany’s Excellence Strategy MLCoE – EXC number 2064/1 PN 390727645), the German Federal Ministry of Education and Research (BMBF; Tübingen AI Center, FKZ: 01IS18039A) and the European Reseach Council (ERC consolidator grant SYNAPSEEK).</p>
</ack>
<sec id="s5">
<label>4</label>
<title>Methods</title>
<p>Below, we introduce the rate network model, Oja’s rule: the rule underlying our empirical (synthetic) data, the different parametrizations of the learning rules and the GAN-based meta-learning framework.</p>
<sec id="s5a">
<label>4.1</label>
<title>Network model</title>
<p>We consider a linear feedforward rate network with <italic>N</italic> presynaptic neurons with activity <italic>x</italic><sub><italic>j</italic></sub>(<italic>j</italic> = 1 … <italic>N</italic>), <italic>M</italic> postsynaptic neurons with activity <italic>y</italic><sub><italic>i</italic></sub>(<italic>i</italic> = 1 … <italic>M</italic>), and synaptic weights <italic>ω</italic><sub><italic>ij</italic></sub>. The postsynaptic activity at (discretized) time <italic>t</italic> is updated as follows:
<disp-formula id="eqn1">
<graphic xlink:href="565168v1_eqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
</sec>
<sec id="s5b">
<label>4.2.</label>
<title>Empirical data and Oja’s rule</title>
<p>In lieu of experimental data, and to test our framework, empirical data consisted of activity traces from the rate network defined above, evolving with Oja’s rule. This rule consists of a Hebbian term, with an added normalization term for stability:
<disp-formula id="eqn2">
<graphic xlink:href="565168v1_eqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
This Hebbian plasticity rule, when used to update the synaptic weights <italic>ω</italic><sub><italic>ij</italic></sub> of the feedforward rate network in <xref ref-type="disp-formula" rid="eqn1">Eqn 1</xref>, causes <italic>ω</italic><sub><italic>ij</italic></sub> to converge to the first principal component PC<sub>1</sub> of the presynaptic activity <inline-formula><inline-graphic xlink:href="565168v1_inline4.gif" mimetype="image" mime-subtype="gif"/></inline-formula> [<xref ref-type="bibr" rid="c23">23</xref>]. Concurrently, under Oja’s rule, the postsynaptic activity <italic>y</italic> converges to a projection of <italic>x</italic> onto its first principal component. In order to simulate activity traces <italic>y</italic><sub><italic>i</italic></sub>, we sampled presynaptic activity <italic>x</italic> from a N-dimensional Gaussian distribution, with a given covariance structure (details in Supp. Sec. B.1). Note that we fixed the presynaptic activity to be constant across time, and that the synaptic weight update Δ<italic>ω</italic><sub><italic>ij</italic></sub> at each time step was computed by averaging over an ensemble of pre- and postsynaptic activities corresponding to <italic>K</italic> = 100 different <italic>x</italic> samples from the multivariate Gaussian distribution. In other words, we have implicit batch learning for the synaptic weights:
<disp-formula id="eqn3">
<graphic xlink:href="565168v1_eqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
We simulated the plastic network for <italic>T</italic> = 200 time steps. The empirical data consisted of the postsynaptic activity at every time step for each of <italic>K</italic> = 100 different 3-dimensional presynaptic activities and randomly initialised synaptic weights <inline-formula><inline-graphic xlink:href="565168v1_inline5.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.</p>
<p>In <xref rid="fig3" ref-type="fig">Fig 3</xref>, we used two other types of data: (1) we introduced noise in the postsynaptic activity: <inline-formula><inline-graphic xlink:href="565168v1_inline6.gif" mimetype="image" mime-subtype="gif"/></inline-formula>; (2) 39 input neurons instead of 3 were simulated, the training was otherwise similar.</p>
</sec>
<sec id="s5c">
<label>4.3</label>
<title>Parametrized learning rules</title>
<p>In order to meta-learn the synaptic plasticity rules from the empirical data, we formalized the learning rule with a parametrized function <italic>h</italic><sub><italic>θ</italic></sub>:
<disp-formula id="eqn4">
<graphic xlink:href="565168v1_eqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
First, for a proof of principle (Supp. Fig. 5), we parametrized Oja’s rule with learnable coefficients <italic>θ</italic><sub>1</sub> and <italic>θ</italic><sub>2</sub>:
<disp-formula id="eqn5">
<graphic xlink:href="565168v1_eqn5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
For all other experiments, the plasticity rules were parametrized using multi-layer perceptrons [MLPs, 33], with different inputs from the rate network, depending on the chosen model:</p>
<list list-type="bullet">
<list-item><p><italic>Local MLP</italic>: the plasticity rule is parametrized by a 3-layer MLP, i.e., <inline-formula><inline-graphic xlink:href="565168v1_inline7.gif" mimetype="image" mime-subtype="gif"/></inline-formula> This MLP represents a <italic>local update</italic>, i.e., it transforms each <inline-formula><inline-graphic xlink:href="565168v1_inline8.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula><inline-graphic xlink:href="565168v1_inline9.gif" mimetype="image" mime-subtype="gif"/></inline-formula> in the same way, independently of the indices <italic>i, j</italic> and <italic>t</italic>.</p></list-item>
<list-item><p><italic>Oja</italic> + <italic>local MLP</italic>: <inline-formula><inline-graphic xlink:href="565168v1_inline10.gif" mimetype="image" mime-subtype="gif"/></inline-formula> . This learning rule is “biased” since, by construction, it is initialised close to the ground-truth solution and any non-zero outputs of the MLP are perturbations to Oja’s rule.</p></list-item>
<list-item><p><italic>Semi-global MLP</italic> computes the synaptic weight update <inline-formula><inline-graphic xlink:href="565168v1_inline11.gif" mimetype="image" mime-subtype="gif"/></inline-formula> for a single synapse. It takes into account the mean presynaptic activity and the mean across the network synaptic weights at the current time step, in addition to the local presynaptic activity <inline-formula><inline-graphic xlink:href="565168v1_inline12.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, synaptic weight <inline-formula><inline-graphic xlink:href="565168v1_inline13.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and postsynaptic activity <inline-formula><inline-graphic xlink:href="565168v1_inline14.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.</p></list-item>
<list-item><p><italic>Global MLP</italic> takes into account all pre- and postsynaptic activities and synaptic weights: <inline-formula><inline-graphic xlink:href="565168v1_inline15.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.</p></list-item>
</list>
<p>Note that these parametrized rules are progressively less constrained, and that each MLP could, in principle, be reduced to the one above it.</p>
</sec>
<sec id="s5d">
<label>4.4.</label>
<title>Meta-learning framework</title>
<p>Our meta-learning framework uses a GAN to learn the parameters <italic>θ</italic> of the plasticity rule <italic>h</italic><sub><italic>θ</italic></sub>, given neural activity. Below, we first introduce the GAN formalism, and then show how one can recast the problem of meta-learning within this formalism.</p>
<p>GANs are a machine learning approach to obtain generative models of data, by training a model to match a target distribution <italic>p</italic>(<italic>d</italic><sup><italic>t</italic></sup>), which we only have access to via samples <italic>d</italic><sup><italic>t</italic></sup> from the distribution. GANs consist of two deep neural networks: a generator network <italic>g</italic><sub><italic>θ</italic></sub> that produces data <italic>d</italic> = <italic>g</italic><sub><italic>θ</italic></sub>(<italic>z</italic>), by deterministically transforming latent random variables <italic>z</italic> sampled from a known distribution <italic>p</italic>(<italic>z</italic>). The second network is a discriminator D<sub><italic>Ψ</italic></sub> which aims to classify generated samples <italic>d</italic> as fake (i.e., from the generator), and <italic>d</italic><sup><italic>t</italic></sup> as real (i.e., from the target distribution, <xref rid="fig1" ref-type="fig">Fig. 1B</xref>). After the two networks have been trained with a minimax loss
<disp-formula id="eqn6">
<graphic xlink:href="565168v1_eqn6.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
in the limit of infinite data, the generator implicitly represents <italic>p</italic>(<italic>d</italic><sup><italic>t</italic></sup>) at convergence. Thus, convergence yields a generative model of <italic>d</italic><sup><italic>t</italic></sup>. Note that the GAN does not impose any restrictions on the architecture of the generator network. Furthermore, it does not define an explicit loss function for the target data <italic>d</italic><sup><italic>t</italic></sup> and generated data <italic>d</italic>: instead, the discriminator implicitly represents a distance function between the two data distributions, and this function is also learned end-to-end with the generator. This leads to GANs not attempting to reproduce the data <italic>d</italic><sup><italic>t</italic></sup> in minute detail, but rather to capture the general statistics of the data. In other words, the GAN matches the distributions <italic>p</italic>(<italic>d</italic>) and <italic>p</italic>(<italic>d</italic><sup><italic>t</italic></sup>), rather than individual samples <italic>d</italic> and <italic>d</italic><sup><italic>t</italic></sup>.</p>
<p>This flexibility in the GAN framework is advantageous for meta-learning plasticity rules from neural activity. We first recast the system composed of the postsynaptic update (<xref ref-type="disp-formula" rid="eqn1">Eqn 1</xref>) and the plasticity rule (<xref ref-type="disp-formula" rid="eqn4">Eqn 4</xref>) as a generative model of postsynaptic activity traces for <italic>T</italic> time steps, i.e., <inline-formula><inline-graphic xlink:href="565168v1_inline16.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="565168v1_inline17.gif" mimetype="image" mime-subtype="gif"/></inline-formula>and <inline-formula><inline-graphic xlink:href="565168v1_inline18.gif" mimetype="image" mime-subtype="gif"/></inline-formula> (<xref rid="fig1" ref-type="fig">Fig. 1B</xref>). We then define a discriminator D<sub><italic>Ψ</italic></sub> that differentiates between generated activity traces y and empirical activity traces y<sup><italic>t</italic></sup> <italic>∼p</italic>(y<sup><italic>t</italic></sup>). Note that y is a random variable, since the rate network is initialised randomly before every forward pass from the generative model. We learn the parameters of the plasticity rule <italic>θ</italic> and the discriminator <italic>Ψ</italic> using the same minimax loss as in <xref ref-type="disp-formula" rid="eqn6">Eqn 6</xref>:
<disp-formula id="eqn7">
<graphic xlink:href="565168v1_eqn7.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
At convergence, the GAN will have learned a plasticity rule <italic>h</italic><sub><italic>θ</italic></sub> that is consistent with the empirical neural activity <bold>y</bold><sup><italic>t</italic></sup>. The GAN framework thus allows us to flexibly parametrize the plasticity rule. It also allows us to learn the rule from neural activity, without having to specify a loss function on the neural activity. Details on method implementation and numerical experiments are in Supp. Sec. B.</p>
</sec>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="journal"><string-name><given-names>Larry F</given-names> <surname>Abbott</surname></string-name> and <string-name><given-names>Sacha B</given-names> <surname>Nelson</surname></string-name>. <article-title>Synaptic plasticity: taming the beast</article-title>. <source>Nature neuroscience</source>, <volume>3</volume>(<issue>11</issue>):<fpage>1178</fpage>–<lpage>1183</lpage>, <year>2000</year>.</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="journal"><string-name><given-names>Ami</given-names> <surname>Citri</surname></string-name> and <string-name><surname>Robert</surname> <given-names>C.</given-names></string-name> <article-title>Malenka. Synaptic plasticity: Multiple forms, functions, and mechanisms</article-title>. <source>Neuropsychopharmacology</source>, <volume>33</volume>:<fpage>18</fpage>–<lpage>41</lpage>, <year>2008</year>.</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><string-name><given-names>Christina Y. C.</given-names> <surname>McFarlan</surname></string-name>, <string-name><given-names>Amanda R.</given-names>and <surname>Chou</surname></string-name>, <string-name><given-names>Airi</given-names> <surname>Watanabe</surname></string-name>, <string-name><given-names>Nicole</given-names> <surname>Cherepacha</surname></string-name>, <string-name><given-names>Maria</given-names> <surname>Haddad</surname></string-name>, <string-name><given-names>Hannah</given-names> <surname>Owens</surname></string-name>, and <string-name><given-names>P.</given-names> <surname>Jesper Sjöström</surname></string-name>. <article-title>The plasticitome of cortical interneurons</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>24</volume>:<fpage>80</fpage>–<lpage>97</lpage>, <year>2022</year>.</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="journal"><string-name><given-names>Tim VP</given-names> <surname>Bliss</surname></string-name> and <string-name><given-names>Terje</given-names> <surname>Lømo</surname></string-name>. <article-title>Long-lasting potentiation of synaptic transmission in the dentate area of the anaesthetized rabbit following stimulation of the perforant path</article-title>. <source>The Journal of physiology</source>, <volume>232</volume>(<issue>2</issue>):<fpage>331</fpage>–<lpage>356</lpage>, <year>1973</year>.</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="journal"><string-name><surname>Jeffrey</surname> <given-names>C.</given-names></string-name> <article-title>Magee and Christine Grienberger. Synaptic plasticity forms and functions</article-title>. <source>Annual Review of Neuroscience</source>, <volume>43</volume>(<issue>1</issue>):<fpage>95</fpage>–<lpage>117</lpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="journal"><string-name><given-names>James A</given-names> <surname>D’amour</surname></string-name> and <string-name><given-names>Robert C</given-names> <surname>Froemke</surname></string-name>. <article-title>Inhibitory and excitatory spike-timing-dependent plasticity in the auditory cortex</article-title>. <source>Neuron</source>, <volume>86</volume>(<issue>2</issue>):<fpage>514</fpage>–<lpage>528</lpage>, <year>2015</year>.</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="journal"><string-name><given-names>Wulfram</given-names> <surname>Gerstner</surname></string-name>, <string-name><given-names>Richard</given-names> <surname>Kempter</surname></string-name>, <string-name><given-names>J. Leo</given-names> <surname>van Hemmen</surname></string-name>, and <string-name><given-names>Hermann</given-names> <surname>Wagner</surname></string-name>. <article-title>A neuronal learning rule for sub-millisecond temporal coding</article-title>. <source>Nature</source>, <volume>383</volume>:<fpage>76</fpage>–<lpage>78</lpage>, <year>1996</year>.</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="journal"><string-name><given-names>Jean-Pascal</given-names> <surname>Pfister</surname></string-name> and <string-name><given-names>Wulfram</given-names> <surname>Gerstner</surname></string-name>. <article-title>Triplets of spikes in a model of spike timing-dependent plasticity</article-title>. <source>Journal of Neuroscience</source>, <volume>26</volume>(<issue>38</issue>):<fpage>9673</fpage>–<lpage>9682</lpage>, <year>2006</year>.</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="journal"><string-name><given-names>Claudia</given-names> <surname>Clopath</surname></string-name>, <string-name><given-names>Lars</given-names> <surname>Büsing</surname></string-name>, <string-name><given-names>Eleni</given-names> <surname>Vasilaki</surname></string-name>, and <string-name><given-names>Wulfram</given-names> <surname>Gerstner</surname></string-name>. <article-title>Connectivity reflects coding: a model of voltage-based stdp with homeostasis</article-title>. <source>Nature Neuroscience</source>, <volume>13</volume>:<fpage>344</fpage>–<lpage>352</lpage>, <year>2010</year>.</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="journal"><string-name><given-names>Michael</given-names> <surname>Graupner</surname></string-name> and <string-name><given-names>Nicolas</given-names> <surname>Brunel</surname></string-name>. <article-title>Calcium-based plasticity model explains sensitivity of synaptic changes to spike pattern, rate, and dendritic location</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>109</volume>(<issue>10</issue>):<fpage>3991</fpage>–<lpage>3996</lpage>, <year>2012</year>.</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="journal"><string-name><given-names>Tim P.</given-names> <surname>Vogels</surname></string-name>, <string-name><given-names>Henning</given-names> <surname>Sprekeler</surname></string-name>, <string-name><given-names>Claudia</given-names> <surname>Clopath</surname></string-name>, and <string-name><given-names>Wulfram</given-names> <surname>Gerstner</surname></string-name>. <article-title>Inhibitory plasticity balances excitation and inhibition in sensory pathways and memory networks</article-title>. <source>Science</source>, <volume>334</volume>, <year>2011</year>.</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="journal"><string-name><given-names>Friedemann</given-names> <surname>Zenke</surname></string-name>, <string-name><given-names>Everton J</given-names> <surname>Agnes</surname></string-name>, and <string-name><given-names>Wulfram</given-names> <surname>Gerstner</surname></string-name>. <article-title>Diverse synaptic plasticity mechanisms orchestrated to form and retrieve memories in spiking neural networks</article-title>. <source>Nature Communications</source>, <volume>6</volume>, <year>2015</year>.</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="journal"><string-name><given-names>Ashok</given-names> <surname>Litwin-Kumar</surname></string-name> and <string-name><given-names>Brent</given-names> <surname>Doiron</surname></string-name>. <article-title>Formation and maintenance of neuronal assemblies through synaptic plasticity</article-title>. <source>Nature Communications</source>, <volume>5</volume>, <year>2014</year>.</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="journal"><string-name><given-names>Dirk Bucher Astrid A</given-names> <surname>Prinz</surname></string-name> and <string-name><given-names>Eve</given-names> <surname>Marder</surname></string-name>. <article-title>Similar network activity from disparate circuit parameters</article-title>. <source>Nature Neuroscience</source>, <volume>7</volume>(<issue>12</issue>):<fpage>1345</fpage>–<lpage>1352</lpage>, <year>2004</year>.</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="journal"><string-name><given-names>Jean-Marc</given-names> <surname>Goaillard</surname></string-name>, <string-name><given-names>Adam L</given-names> <surname>Taylor</surname></string-name>, <string-name><given-names>David J</given-names> <surname>Schulz</surname></string-name>, and <string-name><given-names>Eve</given-names> <surname>Marder</surname></string-name>. <article-title>Functional consequences of animal-to-animal variation in circuit parameters</article-title>. <source>Nature neuroscience</source>, <volume>12</volume>(<issue>11</issue>):<fpage>1424</fpage>–<lpage>1430</lpage>, <year>2009</year>.</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="journal"><string-name><given-names>Simone</given-names> <surname>Temporal</surname></string-name>, <string-name><given-names>Mohati</given-names> <surname>Desai</surname></string-name>, <string-name><given-names>Olga</given-names> <surname>Khorkova</surname></string-name>, <string-name><given-names>Gladis</given-names> <surname>Varghese</surname></string-name>, <string-name><given-names>Aihua</given-names> <surname>Dai</surname></string-name>, <string-name><given-names>David J</given-names> <surname>Schulz</surname></string-name>, and <string-name><given-names>Jorge</given-names> <surname>Golowasch</surname></string-name>. <article-title>Neuromodulation independently determines correlated channel expression and conductance levels in motor neurons of the stomatogastric ganglion</article-title>. <source>Journal of neurophysiology</source>, <volume>107</volume>(<issue>2</issue>):<fpage>718</fpage>–<lpage>727</lpage>, <year>2012</year>.</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="journal"><string-name><given-names>Basile</given-names> <surname>Confavreux</surname></string-name>, <string-name><given-names>Friedemann</given-names> <surname>Zenke</surname></string-name>, <string-name><given-names>Everton J</given-names> <surname>Agnes</surname></string-name>, <string-name><given-names>Timothy</given-names> <surname>Lillicrap</surname></string-name>, and <string-name><given-names>Tim P</given-names> <surname>Vogels</surname></string-name>. <article-title>A meta-learning approach to (re) discover plasticity rules that carve a desired function into a neural network</article-title>. <source>Advances in Neural Information Processing Systems</source> <volume>34</volume> (NeurIPS), <year>2020</year>.</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="journal"><string-name><given-names>Danil</given-names> <surname>Tyulmankov</surname></string-name>, <string-name><given-names>Guangyu Robert</given-names> <surname>Yang</surname></string-name>, and <string-name><given-names>L.F.</given-names> <surname>Abbott</surname></string-name>. <article-title>Meta-learning synaptic plasticity and memory addressing for continual familiarity detection</article-title>. <source>Neuron</source>, <volume>110</volume>(<issue>3</issue>):<fpage>544</fpage>–<lpage>557</lpage>.e8, <year>2022</year>.</mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="journal"><string-name><given-names>Jack</given-names> <surname>Lindsey</surname></string-name> and <string-name><given-names>Ashok</given-names> <surname>Litwin-Kumar</surname></string-name>. <article-title>Learning to learn with feedback and local plasticity</article-title>. <source>Advances in Neural Information Processing Systems</source> <volume>34</volume> (NeurIPS), <year>2020</year>.</mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="journal"><string-name><given-names>Jakob</given-names> <surname>Jordan</surname></string-name>, <string-name><given-names>Maximilian</given-names> <surname>Schmidt</surname></string-name>, <string-name><given-names>Walter</given-names> <surname>Senn</surname></string-name>, and <string-name><given-names>Mihai A</given-names> <surname>Petrovici</surname></string-name>. <article-title>Evolving interpretable plasticity for spiking networks</article-title>. <source>eLife</source>, <volume>10</volume>:<fpage>e66273</fpage>, <year>2021</year>.</mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="other"><string-name><given-names>Luke</given-names> <surname>Metz</surname></string-name>, <string-name><given-names>Niru</given-names> <surname>Maheswaranathan</surname></string-name>, <string-name><given-names>Brian</given-names> <surname>Cheung</surname></string-name>, and <string-name><given-names>Jascha</given-names> <surname>Sohl-Dickstein</surname></string-name>. <article-title>Learning unsupervised learning rules</article-title>. <source>arXiv</source>, <year>2018</year>.</mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="other"><string-name><given-names>Ian J</given-names> <surname>Goodfellow</surname></string-name>, <string-name><given-names>Jean</given-names> <surname>Pouget-Abadie</surname></string-name>, <string-name><given-names>Mehdi</given-names> <surname>Mirza</surname></string-name>, <string-name><given-names>Bing</given-names> <surname>Xu</surname></string-name>, <string-name><given-names>David</given-names> <surname>Warde-Farley</surname></string-name>, <string-name><given-names>Sherjil</given-names> <surname>Ozair</surname></string-name>, <string-name><given-names>Aaron</given-names> <surname>Courville</surname></string-name>, and <string-name><given-names>Yoshua</given-names> <surname>Bengio</surname></string-name>. <article-title>Generative adversarial networks</article-title>. <source>arXiv preprint</source> arXiv:1406.2661, <year>2014</year>.</mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="journal"><string-name><given-names>Erkki</given-names> <surname>Oja</surname></string-name>. <article-title>Simplified neuron model as a principal component analyzer</article-title>. <source>Journal of mathematical biology</source>, <volume>15</volume>(<issue>3</issue>):<fpage>267</fpage>–<lpage>273</lpage>, <year>1982</year>.</mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="other"><string-name><given-names>Bryan M</given-names> <surname>Li</surname></string-name>, <string-name><given-names>Theoklitos</given-names> <surname>Amvrosiadis</surname></string-name>, <string-name><given-names>Nathalie</given-names> <surname>Rochefort</surname></string-name>, and <string-name><given-names>Arno</given-names> <surname>Onken</surname></string-name>. <article-title>Calciumgan: a generative adversarial network model for synthesising realistic calcium imaging data of neuronal populations</article-title>. <source>arXiv preprint</source> arXiv:2009.02707, <year>2020</year>.</mixed-citation></ref>
<ref id="c25"><label>[25]</label><mixed-citation publication-type="other"><string-name><given-names>Alec</given-names> <surname>Radford</surname></string-name>, <string-name><given-names>Luke</given-names> <surname>Metz</surname></string-name>, and <string-name><given-names>Soumith</given-names> <surname>Chintala</surname></string-name>. <source>Unsupervised representation learning with deep convolutional generative adversarial networks</source>, <year>2016</year>.</mixed-citation></ref>
<ref id="c26"><label>[26]</label><mixed-citation publication-type="other"><string-name><given-names>Xi</given-names> <surname>Chen</surname></string-name>, <string-name><given-names>Yan</given-names> <surname>Duan</surname></string-name>, <string-name><given-names>Rein</given-names> <surname>Houthooft</surname></string-name>, <string-name><given-names>John</given-names> <surname>Schulman</surname></string-name>, <string-name><given-names>Ilya</given-names> <surname>Sutskever</surname></string-name>, and <string-name><given-names>Pieter</given-names> <surname>Abbeel</surname></string-name>. <source>Infogan: Interpretable representation learning by information maximizing generative adversarial nets</source>, <year>2016</year>.</mixed-citation></ref>
<ref id="c27"><label>[27]</label><mixed-citation publication-type="journal"><string-name><given-names>Wulfram</given-names> <surname>Gerstner</surname></string-name> and <string-name><given-names>Werner M</given-names> <surname>Kistler</surname></string-name>. <article-title>Mathematical formulations of hebbian learning</article-title>. <source>Biological cybernetics</source>, <volume>87</volume>(<issue>5</issue>):<fpage>404</fpage>–<lpage>415</lpage>, <year>2002</year>.</mixed-citation></ref>
<ref id="c28"><label>[28]</label><mixed-citation publication-type="journal"><string-name><given-names>Pedro J</given-names> <surname>Gonçalves</surname></string-name>, <string-name><given-names>Jan-Matthis</given-names> <surname>Lueckmann</surname></string-name>, <string-name><given-names>Michael</given-names> <surname>Deistler</surname></string-name>, <string-name><given-names>Marcel</given-names> <surname>Nonnenmacher</surname></string-name>, <string-name><given-names>Kaan</given-names> <surname>Öcal</surname></string-name>, <string-name><given-names>Giacomo</given-names> <surname>Bassetto</surname></string-name>, <string-name><given-names>Chaitanya</given-names> <surname>Chintaluri</surname></string-name>, <string-name><given-names>William F</given-names> <surname>Podlaski</surname></string-name>, <string-name><given-names>Sara A</given-names> <surname>Haddad</surname></string-name>, <string-name><given-names>Tim P</given-names> <surname>Vogels</surname></string-name>, <etal>et al.</etal> <article-title>Training deep neural density estimators to identify mechanistic models of neural dynamics</article-title>. <source>Elife</source>, <volume>9</volume>:<fpage>e56261</fpage>, <year>2020</year>.</mixed-citation></ref>
<ref id="c29"><label>[29]</label><mixed-citation publication-type="journal"><string-name><given-names>Alfonso</given-names> <surname>Renart</surname></string-name> and <string-name><given-names>Christian K</given-names> <surname>Machens</surname></string-name>. <article-title>Variability in neural activity and behavior</article-title>. <source>Current opinion in neurobiology</source>, <volume>25</volume>:<fpage>211</fpage>–<lpage>220</lpage>, <year>2014</year>.</mixed-citation></ref>
<ref id="c30"><label>[30]</label><mixed-citation publication-type="other"><string-name><given-names>Tim</given-names> <surname>Salimans</surname></string-name>, <string-name><given-names>Ian</given-names> <surname>Goodfellow</surname></string-name>, <string-name><given-names>Wojciech</given-names> <surname>Zaremba</surname></string-name>, <string-name><given-names>Vicki</given-names> <surname>Cheung</surname></string-name>, <string-name><given-names>Alec</given-names> <surname>Radford</surname></string-name>, and <string-name><given-names>Xi</given-names> <surname>Chen</surname></string-name>. <source>Improved techniques for training gans</source>, <year>2016</year>.</mixed-citation></ref>
<ref id="c31"><label>[31]</label><mixed-citation publication-type="other"><string-name><given-names>Akash</given-names> <surname>Srivastava</surname></string-name>, <string-name><given-names>Lazar</given-names> <surname>Valkov</surname></string-name>, <string-name><given-names>Chris</given-names> <surname>Russell</surname></string-name>, <string-name><given-names>Michael U</given-names> <surname>Gutmann</surname></string-name>, and <string-name><given-names>Charles</given-names> <surname>Sutton</surname></string-name>. <article-title>Veegan: Reducing mode collapse in gans using implicit variational learning</article-title>. <source>arXiv preprint</source> arXiv:1705.07761, <year>2017</year>.</mixed-citation></ref>
<ref id="c32"><label>[32]</label><mixed-citation publication-type="other"><string-name><given-names>Ferenc</given-names> <surname>Huszár</surname></string-name>. <source>How (not) to train your generative model: Scheduled sampling, likelihood, adversary?</source>, <year>2015</year>.</mixed-citation></ref>
<ref id="c33"><label>[33]</label><mixed-citation publication-type="book"><string-name><given-names>Christopher M</given-names> <surname>Bishop</surname></string-name> <etal>et al.</etal> <source>Neural networks for pattern recognition</source>. <publisher-name>Oxford university press</publisher-name>, <year>1995</year>.</mixed-citation></ref>
<ref id="c34"><label>[34]</label><mixed-citation publication-type="book"><string-name><given-names>Adam</given-names> <surname>Paszke</surname></string-name>, <string-name><given-names>Sam</given-names> <surname>Gross</surname></string-name>, <string-name><given-names>Francisco</given-names> <surname>Massa</surname></string-name>, <string-name><given-names>Adam</given-names> <surname>Lerer</surname></string-name>, <string-name><given-names>James</given-names> <surname>Bradbury</surname></string-name>, <string-name><given-names>Gregory</given-names> <surname>Chanan</surname></string-name>, <string-name><given-names>Trevor</given-names> <surname>Killeen</surname></string-name>, <string-name><given-names>Zeming</given-names> <surname>Lin</surname></string-name>, <string-name><given-names>Natalia</given-names> <surname>Gimelshein</surname></string-name>, <string-name><given-names>Luca</given-names> <surname>Antiga</surname></string-name>, <string-name><given-names>Alban</given-names> <surname>Desmaison</surname></string-name>, <string-name><given-names>Andreas</given-names> <surname>Kopf</surname></string-name>, <string-name><given-names>Edward</given-names> <surname>Yang</surname></string-name>, <string-name><given-names>Zachary</given-names> <surname>DeVito</surname></string-name>, <string-name><given-names>Martin</given-names> <surname>Raison</surname></string-name>, <string-name><given-names>Alykhan</given-names> <surname>Tejani</surname></string-name>, <string-name><given-names>Sasank</given-names> <surname>Chilamkurthy</surname></string-name>, <string-name><given-names>Benoit</given-names> <surname>Steiner</surname></string-name>, <string-name><given-names>Lu</given-names> <surname>Fang</surname></string-name>, <string-name><given-names>Junjie</given-names> <surname>Bai</surname></string-name>, and <string-name><given-names>Soumith</given-names> <surname>Chintala</surname></string-name>. <chapter-title>Pytorch: An imperative style, high-performance deep learning library</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>H.</given-names> <surname>Wallach</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Larochelle</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Beygelzimer</surname></string-name>, <string-name><given-names>F.</given-names> <surname>d’Alché Buc</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Fox</surname></string-name>, and <string-name><given-names>R.</given-names> <surname>Garnett</surname></string-name></person-group>, editors, <source>Advances in Neural Information Processing Systems</source> <volume>32</volume>, pages <fpage>8024</fpage>–<lpage>8035</lpage>. <publisher-name>Curran Associates, Inc</publisher-name>., <year>2019</year>.</mixed-citation></ref>
<ref id="c35"><label>[35]</label><mixed-citation publication-type="other"><collab>Lukas Biewald</collab>. <source>Experiment tracking with weights and biases</source>, <year>2020</year>.</mixed-citation></ref>
<ref id="c36"><label>[36]</label><mixed-citation publication-type="other"><string-name><given-names>Takeru</given-names> <surname>Miyato</surname></string-name>, <string-name><given-names>Toshiki</given-names> <surname>Kataoka</surname></string-name>, <string-name><given-names>Masanori</given-names> <surname>Koyama</surname></string-name>, and <string-name><given-names>Yuichi</given-names> <surname>Yoshida</surname></string-name>. <source>Spectral normalization for generative adversarial networks</source>. CoRR, abs/1802.05957, <year>2018</year>.</mixed-citation></ref>
</ref-list>
<fn-group>
<fn><p>To lighten the notation, we elide the dependence on time <italic>t</italic> in this equation.</p></fn>
</fn-group>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94411.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Gjorgjieva</surname>
<given-names>Julijana</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Technical University of Munich</institution>
</institution-wrap>
<city>Freising</city>
<country>Germany</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This work presents a <bold>valuable</bold> data-driven method to extract the &quot;true&quot; synaptic plasticity rule (or learning rule) operating in a neural circuit from empirical measurements of neural activity. The approach aims to train a generative adversarial network (GAN) to match neural activity measurements in terms of statistics, learning them from the data, rather than being pre-determined by the experimenter. The main conclusion is that the extracted learning rules are not unique, but rather degenerate, meaning that multiple plasticity rules can produce the same neural activity. Although the paper presents a thorough investigation using one learning rule as a case study (the Oja rule), the evidence that the results can be inferred beyond the specific numerical experiments presented in the paper is <bold>incomplete</bold>.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94411.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The pioneering work of Eve Marder on central pattern generators in the stomatogastric ganglion (STG) has made a strong case for redundancy as a biological mechanism for ensuring functional robustness, where multiple configurations of biophysical parameters are equivalent in terms of their ability to generate desired patterns of periodic circuit activity. In parallel, normative theories of synaptic plasticity have argued for functional equivalences between learning objectives and corresponding plasticity rules in implementing simple unsupervised learning (see Brito &amp; Gerstner 2016, although similar arguments have been made long before e.g. in Aapo Hyvarinen's ICA book). This manuscript argues that similar notions of redundancy need to be taken into account in the study of synaptic plasticity rules in the brain, more specifically in the context of data-driven approaches to extract the &quot;true&quot; synaptic plasticity rule operating in a neural circuit from neural activity recordings. Concretely, the modeling approach takes a set of empirical measurements of the evolution of neural activity and trains a flexibly parametrized model to match that in statistical terms. Instead of being predefined by the experimenter, the features that determine this match are themselves extracted from data using a generative adversarial network framework (GAN). They show that the flexible models manage to reproduce the neural activity to a reasonable degree (though not perfectly), but lead to very different synaptic trajectories.</p>
<p>Strengths:</p>
<p>The idea of learning rule redundancy is a good one, and the use of GANs for the learning rule estimation is a good complement to other data-driven approaches to extract synaptic plasticity ruled from neural data.</p>
<p>Weaknesses:</p>
<p>(1) Numerics provide only partial support to the statements describing the results.</p>
<p>(2) Even if believing the results, I don't necessarily agree with the interpretation. First: unlike the Marder example where there is complementary evidence to argue that the parameter variations actually reflect across animal biophysical variations, here the statements are really about uncertainty that the experimenter has about what is going on in a circuit observed through a certain measurement lens. Second, while taking into account this uncertainty when using the outcomes of this analysis for subsequent scientific goals is certainly sensible, the biggest punchline for me is that simply observing neural activity in a simple and very restricted context does not provide enough information about the underlying learning mechanism, especially when the hypothesis space is very large (as is the case for the MLP). So it seems more useful to use this framework to think about how to enrich the experimental design/ learning paradigms/ or the measurements themselves to make the set of hypotheses more discriminable (in the spirit of the work by Jacob Portes et al, 2022 for instance). Conversely, one should perhaps think about other ways in which to use other forms of experimental data to reasonably constrain the hypothesis space in the first place.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94411.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This paper poses the interesting and important question of whether plasticity rules are mathematically degenerate, which would mean that multiple plasticity rules can give rise to the same changes in neural activity. They claim that the answer is &quot;yes,&quot; which would have major implications for many researchers studying the biological mechanisms of learning and memory. Unfortunately, I found the evidence for the claim to be weak and confusing, and I don't think that readers can currently infer much beyond the results of the specific numerical experiments reported in the paper.</p>
<p>Strengths:</p>
<p>I love the premise of the paper. I agree with the authors that neuroscientists often under-emphasize the range of possible models that are consistent with empirical findings and/or theoretical demands. I like their proposal that the field is shifting its thinking towards characterizing the space of plasticity rules. I do not doubt the accuracy of most reported numerical results, just their meaning and interpretation. I therefore think that readers can safely use most of the the numerical results to revise their thinking about plasticity mechanisms and draw their own conclusions.</p>
<p>Weaknesses:</p>
<p>Unfortunately, I found many aspects of the paper to be problematic. As a result, I did not find the overarching conclusions drawn by the authors to be convincing.</p>
<p>First, the authors aren't consistent in how they mathematically define and conceptually interpret the &quot;degeneracy&quot; of plasticity mechanisms. In practice, they say that two plasticity mechanisms are &quot;degenerate&quot; if they can't build a neural network to distinguish between a set of neural trajectories generated by them. Their interpretation extrapolates far beyond this, and they seem to conclude that such plasticity rules are in principle indistinguishable. I think that this conclusion is wrong. Plasticity rules are simply mathematical functions that specify how the magnitude of a synaptic weight changes due to other factors, here presynaptic activity (x), postsynaptic activity (y), and the current value of the weight (w). Centuries-old mathematics proves that very broad classes of functions can be parameterized in a variety of non-degenerate ways (e.g., by their Taylor series or Fourier series). It seems unlikely to me that biology has developed plasticity rules that fall outside this broad class. Moreover, the paper's numerical results are all for Oja's plasticity rule, which is a third-order polynomial function of x, y, and w. That polynomial functions cannot be represented by any other Taylor series is a textbook result from calculus. One might wonder if this unique parameterization is somehow lost when many synapses combine to produce neural activity, but the neuron model used in this work is linear, so the function that specifies how the postsynaptic activity changes is simply a fourth-order polynomial in 3N+1 variables (i.e., the presynaptic activities of N neurons prior to the plasticity event, the weights of N synapses prior to the plasticity event, the postsynaptic activity prior to the plasticity event, the presynaptic activities of N neurons after the plasticity event). The same fundamental results from calculus apply to the weight trajectories and the activity trajectories, and a non-degenerate plasticity rule could in principle be inferred from either. What the authors instead show is that their simulated datasets, chosen parameterizations for the plasticity rule, and fitting procedures fail to reveal a non-degenerate representation of the plasticity rule. To what extent this failure is due to the nature of the simulated datasets (e.g., their limited size), the chosen parameterization (e.g., an overparameterized multi-layer perceptron), and their fitting procedure (e.g., their generative adversarial network framework) is unclear. I suspect that all three aspects contribute.</p>
<p>Second, I am concerned by the authors' decision to use a generative adversarial network (GAN) to fit the plasticity rule. Practically speaking, the quality of the fits shown in the figures seems unimpressive to me, and I am left wondering if the authors could have gotten better fits with other fitting routines. For example, other authors fit plasticity rules through gradient descent learning, and these authors claimed to accurately recover Oja's rule and other plasticity rules (Mehta et al., &quot;Model-based inference of synaptic plasticity rules,&quot; bioRxiv, 2023). Whether this difference is one of author interpretation or method accuracy is not currently clear. The authors do include some panels in Figure 3A and Figure 8 that explore more standard gradient descent learning, but their networks don't seem to be well-trained. Theoretically speaking, Eqn. (7) in Section 4.4 indicates that the authors only try to match p(\vec y) between the data and generator network, rather than p(\vec x, \vec y). If this equation is an accurate representation of the authors' method, then the claimed &quot;degeneracy&quot; of the learning rule may simply mean that many different joint distributions for \vec x and \vec y can produce the same marginal distribution for \vec y. This is true, but then the &quot;degeneracy&quot; reported in the paper is due to hidden presynaptic variables. I don't think that most readers would expect that learning rules could be inferred by measuring postsynaptic activity alone.</p>
<p>Third, it's important for readers to note that the 2-dimensional dynamical systems representations shown in figures like Figures 2E are incomplete. Learning rules are N-dimensional nonlinear dynamical systems. The learning rule of any individual synapse depends only on the current presynaptic activity, the current postsynaptic activity, and the current weight magnitude, and slices through this function are shown in figures like Figure 2D. However, the postsynaptic activity is itself a dynamical variable that depends on all N synaptic weights. It's therefore unclear how one is supposed to interpret figures like Figure 2E, because the change in y is not a function of y and any single w. My best guess is that figures like Figure 2E are generated for the case of a single presynaptic neuron, but the degeneracies observed in this reduced system need not match those found when fitting the larger network.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94411.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The authors show that a GAN can learn to reproduce the distribution of outputs of a neuron endowed with Oja's plasticity rule throughout its learning process by learning a plasticity rule. The GAN does not, however, learn Oja's rule. Indeed, the plasticity dynamics it infers can differ dramatically from the true dynamics. The authors propose this approach as a way to uncover families of putative plasticity rules consistent with observed activity patterns in biological systems.</p>
<p>Oja's rule was a great choice for the comparison because it makes explicit, I think, the limitations of this approach. As is well known, Oja's rule allows a (linear) neuron to learn the first principal component of its inputs; the synaptic weights converge to the first eigenvector of the input covariance. After this learning process, the response of a neuron to a particular input sample measures the weighted angle between that input and that principal component.</p>
<p>The other, meta-learned plasticity rules that the authors' GAN uncovers notably do not learn the same computation as Oja's rule (Figure 2). This is, to me, the central finding of the paper and fleshed out nicely. It seems to me that this may be because the objective of the GAN is only to reproduce the marginal output statistics of the neuron. It is, if I understand correctly, blind to the input samples, the inputs' marginal statistics, and to correlations between the input and output. I wonder if a GAN that also had some knowledge of the correlation between input and outputs might be more successful at learning the underlying true dynamics.</p>
<p>The focus on reproducing output statistics has some similarity to some types of experiments (e.g., in vivo recordings) but also seems willfully blind to other aspects of these experiments. In my experience, experimentalists are well aware that the circuits they record receive external inputs. Those inputs are often recorded (perhaps in separate experiments or studies). The point being that I'm not sure that this is an entirely fair comparison to the field.</p>
<p>Finally, the plasticity models studied by theoreticians are not only constructed by intuition and hand-tuning. They also draw, often heavily, on biological data and principles. Oja's rule, for example, is simply the combination of Hebbian learning with a homeostatic constraint on the total synaptic weight amplitude (under the choice of a Euclidean norm).</p>
<p>To me, this study very nicely exposes the caveats and risks associated with a blind machine-learning approach to model specification in biology and highlights the need for understanding underlying biological mechanisms and principles. I agree with the authors that heterogeneity and degeneracy in plasticity rules deserve much more attention in the field.</p>
</body>
</sub-article>
</article>