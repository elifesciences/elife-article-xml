<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">89311</article-id>
<article-id pub-id-type="doi">10.7554/eLife.89311</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.89311.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.3</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Finding structure during incremental speech comprehension</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8554-5138</contrib-id>
<name>
<surname>Lyu</surname>
<given-names>Bingjiang</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Marslen-Wilson</surname>
<given-names>William D.</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Fang</surname>
<given-names>Yuxing</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Tyler</surname>
<given-names>Lorraine K.</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Changping Laboratory</institution>, Beijing, 102206, <country>China</country></aff>
<aff id="a2"><label>2</label><institution>Centre for Speech, Language and the Brain, Department of Psychology, University of Cambridge</institution>, Cambridge, CB2 3EB, <country>United Kingdom</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Ding</surname>
<given-names>Nai</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Zhejiang University</institution>
</institution-wrap>
<city>Hangzhou</city>
<country>China</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Bi</surname>
<given-names>Yanchao</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Beijing Normal University</institution>
</institution-wrap>
<city>Beijing</city>
<country>China</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>Correspondence: <email>bingjiang.lyu@gmail.com</email> (BL), <email>lkt10@cam.ac.uk</email> (LKT).</corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2023-08-10">
<day>10</day>
<month>08</month>
<year>2023</year>
</pub-date>
<volume>12</volume>
<elocation-id>RP89311</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-05-22">
<day>22</day>
<month>05</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-05-11">
<day>11</day>
<month>05</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2021.10.25.465687"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2023, Lyu et al</copyright-statement>
<copyright-year>2023</copyright-year>
<copyright-holder>Lyu et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-89311-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>A core aspect of human speech comprehension is the incremental combination of consecutive words into a structured and coherent interpretation of the speaker’s intended meaning. This rapid process is subject to multi-dimensional probabilistic constraints, including both linguistic and non-linguistic knowledge in the specific context, and it is their interpretative coherence that drives successful comprehension. To unveil the neural substrates of this process, we extracted word-by-word measures of sentential structure from artificial neural networks, approximating a coherent outcome of the dynamic interplay between various types of constraints that is difficult to model with traditional methods. Using representational similarity analysis, we tested these structural measures and relevant lexical properties against the spatiotemporally resolved brain activity recorded by electro/magnetoencephalography when participants were listening to the same sentences. Our results reveal a detailed picture of the neurobiological processes involved in building structured interpretations through the integration across multifaceted constraints, including an extensive set of bilateral brain regions beyond the classical fronto-temporal language system, which sheds light on the distributed nature of language processing in the brain. This study also highlights the power of combining multiple methodologies to uncover the neural dynamics of complex cognitive processes.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>incremental speech comprehension</kwd>
<kwd>artificial neural networks</kwd>
<kwd>deep language models</kwd>
<kwd>representational similarity analysis</kwd>
<kwd>computational cognitive neuroscience</kwd>
<kwd>EEG/MEG</kwd>
</kwd-group>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Paper revised</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Human speech comprehension involves a complex set of processes that transform an auditory input into the speaker’s intended meaning, wherein each word is sequentially recognized and integrated with the preceding words to obtain a coherent interpretation<sup><xref ref-type="bibr" rid="c1">1</xref>-<xref ref-type="bibr" rid="c3">3</xref></sup>. Crucially, rather than simple linear concatenation, individual words are combined according to the nonlinear and often discontinuous structure embedded in an utterance as it is delivered over time<sup><xref ref-type="bibr" rid="c4">4</xref></sup>. For example, in the sentence <italic>“The boy who chased the cat was…”</italic>, it is the structurally close word <italic>“boy”</italic>, rather than the linearly close word <italic>“cat”</italic>, that is combined with <italic>“was”</italic>. However, the neural dynamics underpinning the incremental construction of a structured interpretation from a spoken sentence is still unclear.</p>
<p>Previous neuroimaging studies on the structure of language primarily focused on syntax<sup><xref ref-type="bibr" rid="c5">5</xref></sup>, contrasting grammatical sentences against word lists or sentences with syntactic violations<sup><xref ref-type="bibr" rid="c6">6</xref>, <xref ref-type="bibr" rid="c7">7</xref></sup>, manipulating the syntactic complexity in sentences<sup><xref ref-type="bibr" rid="c8">8</xref></sup>, or studying artificial grammatical rules elicited by structured nonsense strings<sup><xref ref-type="bibr" rid="c9">9</xref></sup>. Nevertheless, finding the structure in an unfolding sentence also depends on the constraints jointly placed by other linguistic properties and broad world knowledge<sup><xref ref-type="bibr" rid="c10">10</xref>, <xref ref-type="bibr" rid="c11">11</xref></sup>. According to the widely accepted <italic>constraint-based</italic> approach to sentence processing<sup><xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c13">13</xref></sup>, human real-time interpretation of an utterance is subject to multiple types of probabilistic constraints (e.g., syntax, semantics, world knowledge) generated by individual words as they are sequentially heard in an spoken sentence, and where it is the <italic>interpretative coherence</italic> of these constraints that forms the basis for successful language comprehension<sup><xref ref-type="bibr" rid="c14">14</xref></sup>. Although lexical constraints of individual words can be estimated from large corpora data, it has historically been challenging to model the dynamic interplay between various types of linguistic and nonlinguistic information in a specific context, especially at the sentence level and beyond.</p>
<p>Contemporary deep language models (DLMs) have made great strides in a wide array of natural language processing tasks, including text generation, parsing and translation<sup><xref ref-type="bibr" rid="c15">15</xref>-<xref ref-type="bibr" rid="c18">18</xref></sup>. While current DLMs are still imperfect in terms of human-level language understanding related to reasoning and complex physical and social situations<sup><xref ref-type="bibr" rid="c19">19</xref></sup>, they are arguably valuable models of general linguistic capacities, due to their ability to identify and leverage relevant statistical regularities of linguistic and non-linguistic knowledge present in massive training data<sup><xref ref-type="bibr" rid="c20">20</xref>-<xref ref-type="bibr" rid="c22">22</xref></sup>. Human language comprehension seems to require an apparently analogous contextualized integration of multifaceted constraints<sup><xref ref-type="bibr" rid="c11">11</xref>, <xref ref-type="bibr" rid="c23">23</xref>, <xref ref-type="bibr" rid="c24">24</xref></sup>. In this regard, DLMs excel in flexible combination of different types of features embedded in their rich internal representations<sup><xref ref-type="bibr" rid="c25">25</xref></sup>. Their deep contextualized representations capture the distributed regularities that jointly determine the coherent interpretation of a given sentence, providing context-dependent composition and quantitative measures of the underlying sentential structure. These properties relate back to Elman’s recurrent neural network<sup><xref ref-type="bibr" rid="c26">26</xref>, <xref ref-type="bibr" rid="c27">27</xref></sup> which automatically picks up and encodes lexical syntactic/semantic information in the hidden states.</p>
<p>Recent studies have revealed an overall congruence between language representations in DLMs and those observed in the human brain while processing the same spoken or written input<sup><xref ref-type="bibr" rid="c28">28</xref>-<xref ref-type="bibr" rid="c34">34</xref></sup>, suggesting the potential value of DLMs as a computational tool to investigate the neural basis of language comprehension. To move beyond comparing the similarities between entire model hidden states and brain activity, probing techniques that can extract specific contents from DLMs<sup><xref ref-type="bibr" rid="c35">35</xref>, <xref ref-type="bibr" rid="c36">36</xref></sup> make it possible to study the neural dynamics relevant to processing such information. The important advance here is that we can leverage the deep learning strengths of DLMs to create rigorously quantified models of the broader and multifaceted constraint environment in which a structured interpretation is constructed. Such models can be compared, dynamically, with more restricted and interpretable factors that capture the specific linguistic combinatorial constraints necessary for successful language comprehension.</p>
<p>Here, we take this approach further by designing sentences with contrasting linguistic structures and using a structural probe technique<sup><xref ref-type="bibr" rid="c37">37</xref></sup> to extract word-by-word contextualized representations of sentential structures from a widely-used DLM, namely, BERT<sup><xref ref-type="bibr" rid="c16">16</xref></sup>. This provides the neurocomputational model specificity required to elucidate the neural dynamics underlying the online construction of a structured interpretation from an unfolding spoken sentence. After a detailed evaluation of BERT structural measures according to the hypothesized <italic>constraint-based</italic> approach and human behavioral results, we used spatiotemporal searchlight representational similarity analysis (ssRSA)<sup><xref ref-type="bibr" rid="c38">38</xref></sup> to test these quantitative structural measures and relevant lexical properties against source-localized EMEG data recorded while participants were listening to the same sentences. These tests reveal how the structured interpretation of a spoken sentence is incrementally built under multifaceted probabilistic constraints in the brain.</p>
</sec>
<sec id="s2">
<title>Results</title>
<p>We constructed 60 sets of sentences with varying sentential structures (see Methods) and presented them to human listeners. We also input them word-by-word to BERT to extract incremental structural representations. These natural spoken sentences were constructed to balance off specifically linguistic constraints on interpretation against varying non-linguistic constraints as the sentence is incrementally interpreted, providing a realistic simulation of the environment of daily language use. In each stimulus set, there are two target sentences differing only in the transitivity of the first verb (Verb1) encountered, i.e., how likely it is that Verb1 takes a direct object [see (1) and (2) below and <xref rid="fig1" ref-type="fig">Fig. 1A</xref>]:</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Fig. 1.</label>
<caption><title>Human incremental structural interpretations derived from continuation pre-tests.</title>
<p><bold>(A)</bold> An example set of target sentences differing only in the transitivity of Verb1, HiTrans: high transitivity, LoTrans: low transitivity. Det: determiner, SN: subject noun, V1: Verb1, PP1-PP3: prepositional phrase, MV: main verb, END: the last word in the sentence. <bold>(B)</bold> Probability of a direct object (left) and a prepositional phrase (right) in the continuations after Verb1. <bold>(C)</bold> Probability of a main verb in the continuations after Verb1, which indicates an Active interpretation. <bold>(D)</bold> Correlations between multifaceted lexical constraints and probabilistic interpretations in the two pre-tests. (Spearman rank correlation, black dots indicate significance determined by 10,000 permutations, <italic>P</italic><sub><italic>FDR</italic></sub> &lt; 0.05 corrected).</p></caption>
<graphic xlink:href="465687v3_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<list list-type="order">
<list-item><p><italic>The dog found in the park was covered in mud</italic>.</p></list-item>
<list-item><p><italic>The dog walked in the park was covered in mud</italic>.</p></list-item>
</list>
<p>In the first sentence, Verb1 (i.e., <italic>“found”</italic>) has high transitivity (HiTrans) and strongly prefers a direct object (e.g., ball), while in the second sentence, Verb1 (i.e., <italic>“walked”</italic>) has relatively low transitivity (LoTrans) and is often used without a following direct object. Critically, (a) the structural interpretation of these sentences is ambiguous at the point Verb1 is encountered and (b) the preferred human resolution of this ambiguity depends on the real-time integration of linguistic and non-linguistic probabilistic constraints as more of the sentence is heard. In the example above, the sequence <italic>“The dog found</italic>…” could initially have either an Active interpretation – where the dog has found something, or a Passive interpretation – where the dog is found by someone (<xref rid="fig1" ref-type="fig">Fig. 1B</xref>). Because <italic>“find”</italic> is primarily a transitive verb, the human listener is likely to be biased towards an initial Active interpretation. Similarly, the sequence <italic>“The dog walked…”</italic>, where <italic>walk</italic> is primarily used as an intransitive verb (without a direct object), could also bias the listener to an Active interpretation, where the dog is doing the walking, rather than the less frequent Passive interpretation where someone is taking the dog for a walk (i.e., walking the dog).</p>
<p>This initial structural interpretation up to Verb1 does not, however, just depend on linguistic knowledge such as Verb1 transitivity. It also depends on how likely the subject is (or is not) to adopt the Active (agent) role to perform the specified action<sup><xref ref-type="bibr" rid="c39">39</xref>, <xref ref-type="bibr" rid="c40">40</xref></sup>, that is, “thematic role” properties of the subject noun. This likelihood, of the event structure implied by the different structural combinations of the subject noun and Verb1, will depend on wide ranging knowledge of the world, linked to the specific words being heard. So, regardless of Verb1 transitivity, the Active interpretation should be more strongly favored in <italic>“The king found/walked</italic>…<italic>”</italic> given the higher agenthood of the <italic>“king”</italic> and thus the greater implausibility of a Passive interpretation involving a <italic>“king”</italic> relative to a <italic>“dog”</italic>. Hence, the word-by-word interpretation of the sentential structure – and of the real-world event structure evoked by this interpretation – is determined by the constraints jointly placed by the subject noun and Verb1, which is manifested by the interpretative coherence between linguistic knowledge and world knowledge.</p>
<p>As the sentence evolves, and the prepositional phrase <italic>“in the park”</italic> that follows Verb1 is incrementally processed, there is further modulation of the preferred interpretation, again reflecting both Verb1 transitivity and the plausibility of the event being constructed. Specifically, the Passive interpretation will become more preferred in a HiTrans sentence, given the absence of an expected direct object for the highly transitive Verb1, so Verb1 tends to be interpreted as a passive verb [i.e., the head of a reduced relative clause in <italic>“The dog (that was) found in the park…”</italic>]. Conversely, in a LoTrans sentence, the Active interpretation of Verb1 is strengthened by the incoming prepositional phrase, which is in accord with the verb’s intransitive use and the event conjured up by the sequence of words heard so far (e.g., <italic>“The dog walked in the park…”</italic>). Hence, these two sentence types are likely to differ in the structural interpretation preferred by the end of the prepositional phrase. However, with the appearance of the actual main verb (e.g., <italic>“was covered”</italic> in the example sentences), the Active interpretation of Verb1 as the main verb will be completely rejected, which resolves the potential ambiguity and confirms the Passive interpretation in both HiTrans and LoTrans sentences.</p>
<p>In brief, understanding these complex sentences require listeners to integrate discontinuous words to solve a long-distance dependency between the subject noun and the actual main verb separated by an intervening clause. This engages the neurobiological processes of integration across multiple levels of the sentence processing system and different lexical constraints, for example, the incremental building, maintenance and update of sentential structure over time might primarily involve activity in the fronto-temporal regions<sup><xref ref-type="bibr" rid="c41">41</xref></sup>, while estimating the plausibility of the event interpreted from the sentence with prior knowledge of the world may elicit neural responses in the default mode network<sup><xref ref-type="bibr" rid="c42">42</xref></sup>.</p>
<sec id="s2a">
<title>Human incremental structural interpretations</title>
<p>As the first step, and to quantify how the stimulus sentences exemplified a constraint-based account of incremental structural interpretation, we conducted two pre-tests where participants listened to sentence fragments, starting from sentence onset and continuing either until the end of Verb1 or to the end of the prepositional phrase (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>), and then produced a continuation to complete the sentence (see Methods). Based on the continuations provided by the listeners at these two gating points, we can infer their online structural interpretations.</p>
<p>In the continuations after Verb1, a direct object was more likely to be found in HiTrans sentences, indicating a transitive use of Verb1, while an opposite pattern was found for a PP continuation, indicating an intransitive use of Verb1 (<xref rid="fig1" ref-type="fig">Fig. 1B</xref>). As expected, the probability of a main verb (MV) in the continuations after the prepositional phrase was lower in LoTrans sentences (<xref rid="fig1" ref-type="fig">Fig. 1C</xref>), suggesting that listeners preferred the Active interpretation and tended to interpret Verb1 as the main verb by the end of the prepositional phrase in LoTrans sentences, and vice versa in HiTrans sentences.</p>
<p>Crucially, neither of the two pre-tests resulted in a complete separation between HiTrans and LoTrans sentences; instead, they were characterized by two different but overlapping probabilistic distributions. This suggests that Passive and Active interpretations varied in plausibility in each sentence type before the actual main verb was presented, reflecting the probabilistic constraints jointly placed by the combination of the specific subject noun, Verb1, and the prepositional phrase in each sentence.</p>
<p>To relate these human interpretative preferences to the broader landscape of distributional language data, we developed corpus-based measures of the thematic role preference of the subject noun (i.e., how likely it is interpreted as an agent that conducts an action) and the transitivity of Verb1 in each sentence, from which we derived a Passive index and an Active index. These indices separately capture the interpretative coherence between these two types of lexical properties towards Passive and Active interpretations (see Methods). Both high subject noun agenthood and low Verb1 transitivity coherently preferred an Active interpretation as the prepositional phrase was heard (i.e., a high Active index), and vice versa for the Passive interpretation (i.e., a high Passive index). In accord with the <italic>constraint-based</italic> hypothesis, we found that human interpretative preference for the two types of sentences was significantly correlated with the lexical constraints generated by the subject noun and Verb1 (<xref rid="fig1" ref-type="fig">Fig. 1D</xref>).</p>
</sec>
<sec id="s2b">
<title>Incremental structural representations extracted from BERT</title>
<p>Next, we extracted structural representations at various positions in the same sentences from BERT and evaluated them according to the <italic>constraint-based</italic> hypothesis and human behavioral results. This motivates the use of BERT structural measures to reveal how the structured interpretation of a spoken sentence is incrementally built in the brain.</p>
<p>Typically, the structure of a sentence can be represented by a dependency parse tree<sup><xref ref-type="bibr" rid="c43">43</xref></sup> (<xref rid="fig2" ref-type="fig">Fig. 2A</xref>) where words are situated at different depths given their structural dependency. Each edge links two structurally proximate words as being the head and the dependent separately (e.g., a verb and its direct object). However, such a parse tree is context-free, that is, it only captures the syntactic relation between each pair of words and abstracts away from the specific lexical (and higher order) contents of the sentence that constrain its actual online structural interpretation. This context-free parse depth is always the same for words at the same position in sentences with the same structural interpretation (e.g., <italic>“found”</italic> and <italic>“walked”</italic> in either of the two parse trees in <xref rid="fig2" ref-type="fig">Fig. 2A</xref>).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Fig. 2.</label>
<caption><title>Incremental interpretation of sentential structure by BERT.</title>
<p><bold>(A)</bold> Context-free dependency parse trees of two plausible structural interpretations. Left: Passive interpretation where V1 is the head of a reduced relative clause. Right: Active interpretation where V1 is the main verb. <bold>(B)</bold> Incremental input to BERT, with the lightness of dots encoding different positions in the target sentences. Det: determiner, SN: subject noun, V1: Verb1, PP1-PP3: prepositional phrase, MV: main verb, END: the last word in the sentence. <bold>(C)</bold> Incremental interpretations of the dependency between SN and V1 in the model space consisting of the parse depth of Det, SN and V1. Upper: Each colored circle represents the parse depth vector up to V1 derived at a certain position in the sentence [with the same color scheme as in (A)]. The hollow triangle and circle represent the context-free dependency parse vectors for Passive and Active interpretations in (B). Lower: incremental interpretations of the two types of target sentences represented by the trajectories of median parse depth. <bold>(D)</bold> Distance from Passive and Active landmarks in the model space as the sentence unfolds [between each colored circle and the two landmarks in the upper panel of (C)] (two-tailed two-sample t-test, *: <italic>P</italic> &lt; 0.05, **: <italic>P</italic> &lt; 0.001, error bars represent SEM).</p></caption>
<graphic xlink:href="465687v3_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To obtain structural measures that also encode the specific lexical and higher order contents in a sentence, we adopted a structural probing technique<sup><xref ref-type="bibr" rid="c37">37</xref></sup> to reconstruct a sentence’s structure by estimating each word’s parse depth based on their contextualized representations generated by BERT (see Methods). Note that BERT is a multi-layer DLM (24 layers in the version used in this study) which may distribute different aspects of its computational solutions over multiple layers. Accordingly, we trained a structural probing model for each layer, and selected the one with the most accurate structural representations while also including its neighboring layers to cover relevant upstream and downstream information. Following this strategy, we used the BERT structural measures obtained from layers 12-16 with the best performance achieved in layer 14 (see Fig. S1 and Methods).</p>
<p>We input each sentence word-by-word to the trained BERT structural probing models, focusing on the incremental structural representation being built as it progressed from Verb1 to the main verb (see the sequence in <xref rid="fig2" ref-type="fig">Fig. 2B</xref>). Note that we defined the first word after the prepositional phrase as the main verb since its appearance is sufficient to resolve the intended structure where Verb1 is a passive verb. We found that, for each type of sentences, the BERT parse depth of words at the same position formed a distribution ranging around the corresponding context-free parse depths in either the Passive or the Active interpretation (see Fig. S2), suggesting a word-specific rather than position-specific structural representation.</p>
<p>Next, we visualized BERT’s word-by-word structural measures, focusing on the dependency between the subject noun and Verb1 that is core to the current interpretation of the sentence – whether the subject noun is the agent or the patient of Verb1. To this end, we built a 3-dimensional vector including BERT parse depths of the first three words up to Verb1 for each sentence (e.g., <italic>“The dog found</italic>…<italic>”</italic>). This 3D vector was kept updated every time the input increased by one word in length, capturing the dynamic interpretation of the structural dependency between the subject noun and Verb1 given the contents of the subsequent words in a specific sentence. Similar to the probabilistic interpretation found within each type of sentences in human listeners, trajectories of individual HiTrans and LoTrans sentences are considerably distributed and intertwined (<xref rid="fig2" ref-type="fig">Fig. 2C</xref>, upper), suggesting that BERT structural interpretations are sensitive to the idiosyncratic contents in each sentence.</p>
<p>To make sense of these trajectories, we also vectorized the context-free parse depth of the first three words indicating Passive and Active interpretations separately and located them in the 3D vector space as landmarks (hollow triangle and circle in <xref rid="fig2" ref-type="fig">Fig. 2C</xref>), so that the plausibility of either interpretation can be estimated by a sentence’s distance from the corresponding landmark. As shown by the trajectories of the median BERT parse depth of the two sentence types (<xref rid="fig2" ref-type="fig">Fig. 2C</xref>, lower), in general, HiTrans sentences continuously moved towards the Passive interpretation landmark after Verb1, with a significant change of distances detected at the main verb (<xref rid="fig2" ref-type="fig">Fig. 2D</xref>, orange bars). LoTrans sentences started by approaching the Active interpretation landmark but were reorientated to the Passive counterpart with the appearance of the actual main verb, with significant changes of distances detected at both Verb1 and main verb (<xref rid="fig2" ref-type="fig">Fig. 2D</xref>, purple bars). These results resemble the pattern of human interpretative preference observed in the continuation pre-tests, where the Passive and Active interpretations were separately preferred in HiTrans and LoTrans sentences by the end of the prepositional phrase in a probabilistic manner (<xref rid="fig1" ref-type="fig">Fig. 1</xref>), before the Passive interpretation was established with the appearance of the actual main verb.</p>
</sec>
<sec id="s2c">
<title>BERT structural measures are correlated with constraints driving human interpretation</title>
<p>Moreover, similar to human listeners, we found that BERT’s preference for structural interpretation was also correlated with the constraints placed by the subject noun and Verb1 (see Methods). We first focused on BERT’s interpretative mismatch quantified as the distance between an unfolding sentence and each of the two landmarks in the model space, which was dynamically updated as the sentence unfolded (<xref rid="fig2" ref-type="fig">Fig. 2C</xref>). Consistently, from the incoming prepositional phrase to the main verb, sentences that are closer to the Passive landmark in the vector space have higher Verb1 transitivity, a higher Passive index but a lower Active index, sentences closer to the Active interpretation landmark exhibited higher Active index and lower Passive index (<xref rid="fig3" ref-type="fig">Figs. 3A</xref> and <xref ref-type="fig" rid="fig3">3B</xref>). Moreover, at the beginning of the prepositional phrase, the change of distance towards either interpretation landmark between two consecutive words is also correlated with these constraints (<xref rid="fig3" ref-type="fig">Figs. 3C</xref> and <xref ref-type="fig" rid="fig3">3D</xref>), suggesting an immediate update in the structural interpretation in combination with the accumulated constraints from the preceding subject noun and Verb1.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Fig. 3.</label>
<caption><title>Correlation between incremental BERT structural measures and explanatory variables.</title>
<p>BERT structural measures include <bold>(A, B)</bold> BERT interpretative mismatch represented by each sentence’s distance from the two landmarks in model space (Fig. 1C); <bold>(C, D)</bold> Dynamic updates of BERT interpretative mismatch represented by each sentence’s movement to the two landmarks; <bold>(E, F)</bold> Overall structural representations captured by the first two principal components (i.e., PC1 and PC2) of BERT parse depth vectors; <bold>(G, H)</bold> BERT Verb1 (V1) parse depth and its dynamic updates. Explanatory variables include lexical constraints derived from massive corpora and the main verb probability derived from human continuation pre-tests (Spearman correlation, permutation test, <italic>P</italic><sub>FDR</sub> &lt; 0.05, multiple comparisons corrected for all BERT layers, results shown here are based on layer 14, see Figs. S3-S5 for the results of all layers); PP1-PP3: prepositional phrase, MV: main verb, END: the last word in the sentence.</p></caption>
<graphic xlink:href="465687v3_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Similarly, we found that both the incremental BERT parse depth vectors as a whole (which are captured by their principal components) and the BERT parse depth of Verb1 (which is the most indicative marker of the interpretation preferred) are correlated with the constraints placed by the subject noun and Verb1 (<xref rid="fig3" ref-type="fig">Figs. 3E</xref> to 3H). Moreover, the significant effects consistently found as the sentence unfolds suggest that properties of preceding words are used to constrain the interpretation of the upcoming input, which is key to resolving discontinuous structural dependencies. In addition, we found that BERT structural interpretations were also correlation with the main verb probability in the continuation pre-test which directly reflects human interpretation preferences (black bars in <xref rid="fig3" ref-type="fig">Fig. 3</xref>).</p>
<p>Overall, these results illustrated, at which position in a sentence, relevant lexical constraints started being encoded by BERT, which also validated the contextualized BERT structural measures in terms of the <italic>constraint-based</italic> hypothesis and human behavioral results, and motivated the use of them to probe the neural processes involved during the incremental interpretation of sentence structure.</p>
</sec>
<sec id="s2d">
<title>Neural dynamics of incremental structural interpretation</title>
<p>To study how the structured interpretation of a spoken sentence is built word-by-word in the brain, we used ssRSA to test the incremental BERT structural measures in source-localized EMEG collected when the same sentences were delivered to human listeners. This combination of methods gains improved neurocomputational specificity by probing the spatiotemporally resolved neural activity with detailed structural representations rather than the entire hidden states. We compared the representational geometry of BERT structural measures with that of neural responses inside a spatiotemporal searchlight moving across the brain, significant similarity fits showed when and where the incremental structural interpretations emerge and update in the brain. Given the probabilistic interpretations in BERT and human listeners reported above, we combined HiTrans and LoTrans sentences as one group to increase the range of pair-wise dissimilarity to be modelled in RSA.</p>
<p>We began with the BERT parse depth vector containing the parse depth of each word in an incremental input, providing a dynamic structural representation updated as the sentence unfolded. Then, we tested the interpretative mismatch between the incremental BERT parse depth vector and the corresponding context-free parse depth vector for the Passive or the Active interpretation. The degree of this mismatch is proportional to the evidence for or against the two interpretations, i.e., the smaller the distance, the more positively loaded this interpretation. Besides these two measures based on the entire incremental input, we also focused on Verb1 since the potential structural ambiguity lies in whether Verb1 is interpreted as a passive verb or the main verb. Given the context-free parse depth of Verb1 that is 2 in the passive interpretation and 0 in the Active interpretation (<xref rid="fig2" ref-type="fig">Fig. 2B</xref>), with each incoming later word, an increased BERT Verb1 parse depth towards 2 or a decreased value towards 0 reflects separately the preference biased to a Passive or an Active interpretation (Fig. S6, see Table S1 for a summary of all BERT measures tested).</p>
<p>For the listener’s neural activity, we focused on three critical epochs in each sentence: (a) Verb1 – when its structural dependency with the preceding subject noun was initially established despite potential ambiguity, (b) the preposition – when the initial structural interpretation started being updated, to be either strengthened or weakened by the incoming preposition phrase, and (c) main verb – when the intended Passive interpretation was finally confirmed. We aligned the continuous EMEG data to the onset of Verb1, the preposition, and the main verb respectively and obtained three 600-ms epochs.</p>
<p>We found that the incremental BERT parse depth vectors exhibited significant fits to brain activity consistently in all three epochs, as the corresponding word was being heard at that time (<xref rid="fig4" ref-type="fig">Figs. 4A</xref> to 4C). In Verb1 epoch, effects in bilateral frontal and anterior-to-middle temporal regions started immediately from Verb1 onset and continued until the uniqueness point – the point at which the word has been uniquely identified – while the BERT parse depth of Verb1 <italic>per se</italic> showed similar but with greater duration which peaked exactly at Verb1 uniqueness point (Fig. S7). As the sentence unfolded, effects were found in the left fronto-temporal regions in the two later epochs, starting after the recognition of the preposition or the main verb separately.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Fig. 4.</label>
<caption><title>Neural dynamics underpinning the emerging structure and interpretation of an unfolding sentence.</title>
<p><bold>(A-C)</bold> ssRSA results of BERT parse depth vector up to Verb1 (V1), the preposition (PP1) and the main verb (MV) in epochs separately time-locked to their onsets. <bold>(D-F)</bold> ssRSA results of the mismatch for the preferred structural interpretation (the specific BERT layer from which BERT structural measures were derived was denoted in parentheses). From top to bottom in each panel: vertex t-mass (each vertex’s summed t-value during its significant period); heatmap of time-series of ROI peak t-value (the highest t-value in an ROI at each time-point) with a green bar indicating effect onset and ROI t-mass (each ROI’s summed mean t-value during its significant period); cluster t-mass time-series (summed t-value of all the significant vertices of a cluster at each time-point). [cluster-based permutation test, vertex-wise <italic>P</italic> &lt; 0.01, cluster-wise <italic>P</italic> &lt; 0.05 in (A-E); marginally significance in (F) with cluster-wise <italic>P</italic> = 0.06]. Solid vertical lines indicate the timings of onset, average uniqueness point (UP), and average offset of the word time-locked in the epoch with grey shades indicating the range of one SD. LH/RH: left/right hemisphere. See Table S2 for full anatomical labels. See Fig. S8 for the significant results of other BERT layers in the MV epoch.</p></caption>
<graphic xlink:href="465687v3_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Turning to the interpretative mismatch for the two possible interpretations, we only observed significant effects of the mismatch for Active interpretation in Verb1 epoch (<xref rid="fig4" ref-type="fig">Fig. 4D</xref>). However, it was the mismatch for Passive interpretation that fitted brain activity in the preposition and main verb epochs (<xref rid="fig4" ref-type="fig">Figs. 4E</xref> and <xref ref-type="fig" rid="fig4">4F</xref>, marginal significance in main verb epoch with cluster-wise P = 0.06). These results suggest that listeners, in general, tended to have an initial preference for an Active interpretation but might start favoring a Passive interpretation when the prepositional phrase began to be heard. This finding is consistent with the tendency to process the first noun encountered in a sentence as the agent<sup><xref ref-type="bibr" rid="c10">10</xref>, <xref ref-type="bibr" rid="c44">44</xref></sup>.</p>
<p>Effects of the BERT parse depth vectors and those of the interpretative mismatch for the preferred structural interpretation have substantial overlaps in terms of their spatiotemporal patterns in the brain, characterized primarily by a transition from bilateral to left-lateralized fronto-temporal regions as the sentence unfolds. Across the three epochs, the most sustained effects were observed in the left inferior frontal gyrus (IFG) and the anterior temporal lobe (ATL). Notably, with the identification of the actual main verb, effects of the eventually resolved structure also involved regions in the left prefrontal and inferior parietal regions (<xref rid="fig4" ref-type="fig">Fig. 4C</xref>) which belong to the multiple-demand network<sup><xref ref-type="bibr" rid="c45">45</xref></sup>.</p>
</sec>
<sec id="s2e">
<title>Structural ambiguity resolution probed using BERT Verb1 parse depth</title>
<p>As mentioned above, the potential ambiguity between a Passive and an Active interpretation centers around whether Verb1 is considered as a passive verb or the main verb, which is resolved upon the appearance of the actual main verb. We probed how this is implemented in the brain using the dynamic BERT parse depth of Verb1. Specifically, the cognitive demands required by this resolution process can be characterized by the change between the updated BERT parse depth of Verb1 when the actual main verb is presented and its initial value when Verb1 is first encountered (see Fig. S6 for the dynamic change of BERT V1 parse depth).</p>
<p>We first tested the change of Verb1 parse depth in the main verb epoch. Significant fits to brain activity emerged in the left posterior temporal and inferior parietal regions upon the main verb uniqueness point, and then extended to more anterior temporal regions (<xref rid="fig5" ref-type="fig">Fig. 5A</xref>). After the main verb offset, the declining effects of the Verb1 parse depth change in the left anterior temporal region seamlessly overlapped with the arising effects of the updated Verb1 parse depth (<xref rid="fig5" ref-type="fig">Figs. 5B</xref> and <xref ref-type="fig" rid="fig5">5C</xref>). These results indicate that the recognition of the actual main verb immediately triggered an update of the previous interpretation of Verb1, with the resolved interpretation emerged in the left temporal lobe and was later delivered to the right posterior temporal and parietal areas. It is also worth noting that the left hippocampus was activated for both measures of Verb1 parse depth after the actual main verb is recognized, suggesting that the episodic memory of experienced events might contribute to the updating of structural interpretations (46, 51, 52).</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Fig. 5.</label>
<caption><title>Neural dynamics updating the incremental structural interpretation.</title>
<p><bold>(A)</bold> ssRSA results of BERT Verb1 (V1) parse depth change at the main verb (MV) relative to the parse depth V1 when it is first encountered. <bold>(B)</bold> ssRSA results of the updated BERT V1 parse depth when the input sentence reaches MV. <bold>(C)</bold> Spatiotemporal overlap between the effects in (A) and (B). (cluster-based permutation test, vertex-wise <italic>P</italic> &lt; 0.01, cluster-wise <italic>P</italic> &lt; 0.05).</p></caption>
<graphic xlink:href="465687v3_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2f">
<title>Emergent structural interpretations driven by multifaceted constraints in the brain</title>
<p>Next, we further asked how the multifaceted constraints, which are also incorporated into BERT structural measures, drive the interpretation made by human listeners. When and where in the brain do these constraints emerge? How are their neural effects related to those of the final resolved sentential structure? To address these questions, we first tested the subject noun thematic role properties. Significant effects of agenthood and patienthood were found in the preposition epoch (<xref rid="fig6" ref-type="fig">Fig. 6A</xref>) and in the main verb epoch (<xref rid="fig6" ref-type="fig">Fig. 6B</xref>) separately. Notably, effects of the subject noun itself preceded those of incremental BERT parse depth vectors modelling the sentence fragments in the same epoch (compare <xref rid="fig6" ref-type="fig">Fig. 6A</xref> with <xref rid="fig4" ref-type="fig">Fig. 4B</xref>, and <xref rid="fig6" ref-type="fig">Fig. 6B</xref> with <xref rid="fig4" ref-type="fig">Fig. 4C</xref>). This indicates that subject noun thematic role might be evaluated before building the overall structural interpretation of the utterance delivered so far. Specifically, the initial preference for an Active interpretation during Verb1, while present as the prepositional phrase started (<xref rid="fig6" ref-type="fig">Fig. 6A</xref>), was superseded by the preference for a Passive interpretation as the rest of the phrase (<xref rid="fig4" ref-type="fig">Fig. 4E</xref>) and the main verb (<xref rid="fig6" ref-type="fig">Fig. 6B</xref>) were heard.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Fig. 6.</label>
<caption><title>Neural dynamics of multifaceted probabilistic constraints underpinning incremental structural interpretations.</title>
<p><bold>(A, B)</bold> ssRSA results of SN agenthood and SN patienthood (i.e., plausibility of SN being the agent or the patient of V1) in PP1 and MV epochs separately. <bold>(C)</bold> ssRSA results of non-directional index (i.e., interpretative coherence between SN and V1 regardless of the structure preferred) in MV epoch. <bold>(D)</bold> ssRSA results of Passive index (i.e., interpretative coherence for the Passive interpretation) in MV epoch. <bold>(E)</bold> Influence of the Passive interpretative coherence on the emerging sentential structure in MV epoch revealed by the Granger causal analysis (GCA) based on the non-negative matrix factorization (NMF) components of whole-brain ssRSA results (see Fig. S9 for more details) [(A-D) cluster-based permutation test, vertex-wise <italic>P</italic> &lt; 0.01, cluster-wise <italic>P</italic> &lt; 0.05; (E) permutation test <italic>P</italic><sub>FDR</sub> &lt; 0.05].</p></caption>
<graphic xlink:href="465687v3_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Despite being jointly constrained by subject noun thematic role preference and Verb1 transitivity in a probabilistic manner, the structural interpretation temporarily held just before the recognition of the actual main verb could differ across sentences (e.g., Passive interpretation in “<italic>The dog found in the park</italic>…” and Active interpretation in “<italic>The dog walked in the park</italic>…”). Therefore, in contrast to the Passive or Active index specialized for one particular structural interpretation, we constructed a non-directional index that merely quantifies the degree of interpretative coherence for one interpretation, whether Passive or Active (see Methods). Thus, a higher value only indicates greater interpretative coherence between the subject noun and Verb1 regardless of which interpretation is preferred.</p>
<p>Effects of this non-directional measure of interpretative coherence appeared very soon after the main verb onset in both hemispheres and lasted till its offset (<xref rid="fig6" ref-type="fig">Fig. 6C</xref>), suggesting an immediate evaluation of the previously integrated constraints from the subject noun and Verb1 when a listener realized that the sentence had not finished yet. Moreover, these effects roughly co-occurred with the effects of subject noun patienthood (compare <xref rid="fig6" ref-type="fig">Figs. 6B</xref> and <xref ref-type="fig" rid="fig6">6C</xref>), indicating that a patient role for the subject noun was considered as the main verb was being recognized. Intriguingly, the most sustained regions associated with this non-directional index, including the left ATL, angular gyrus (AG) and precuneus, are also the classical areas of the default mode network (DMN). This finding is consistent with recent claims that the DMN integrates external input with internal prior knowledge to make sense of an input stimulus such as speech<sup><xref ref-type="bibr" rid="c42">42</xref></sup>. In particular, precuneus and AG have been found to be involved in building thematic relationships and event structures from episodic memory<sup><xref ref-type="bibr" rid="c46">46</xref>, <xref ref-type="bibr" rid="c47">47</xref></sup>.</p>
<p>Following the declining effects of the non-directional index upon the recognition of the main verb, we found significant effects of the Passive index in right anterior fronto-temporal regions (<xref rid="fig6" ref-type="fig">Fig. 6D</xref>), suggesting that the intended Passive interpretation was eventually established in all sentences. Previous studies have revealed that the relatively narrow sentence-specific information and the broad world knowledge are processed in the left and right hemispheres separately<sup><xref ref-type="bibr" rid="c48">48</xref>-<xref ref-type="bibr" rid="c50">50</xref></sup>. Relevant to this, in the main verb epoch, we found effects of the BERT parse depth vector and those of the Passive index in the left and right hemispheres respectively, arising almost at the same time as the main verb was recognized (compare <xref rid="fig4" ref-type="fig">Fig. 4C</xref> with <xref rid="fig6" ref-type="fig">Fig. 6D</xref>). Therefore, a critical question is whether and how the online structural interpretation of a specific sentence is facilitated by the interpretative coherence conjured up from lexical constraints that also depend on broad world knowledge (e.g., thematic role).</p>
<p>To address this question, we adopted non-negative matrix factorization to decompose the whole-brain RSA fits of the Passive index and the BERT parse depth vector found in the main verb epoch into two sets of components given their temporal synchronizations (see Methods). We then conducted multivariate Granger causality analyses (MGCA) to infer directed connections among them. We found only GC connections from the components of Passive index to those of BERT parse depth vector (<xref rid="fig6" ref-type="fig">Fig. 6E</xref>). Specifically, we identified information flows from the right hemisphere components of the Passive index to the left hemisphere components of BERT parse depth vector, suggesting that a specific sentence’s structure represented in the left hemisphere might be influenced by the coarse estimate of the event plausibility concurrently determined by broad world knowledge in the right hemisphere<sup><xref ref-type="bibr" rid="c48">48</xref></sup> (see Fig. S9 for more details).</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>In this study, we investigated the neural dynamics involved in constructing structured interpretations of spoken sentences on a word-by-word basis. We combined spatiotemporally resolved brain activity of human listeners, quantitative structural representations derived from a DLM (i.e., BERT), and measures of lexical constraints estimated from corpora data. Our study revealed the emergence and update of a structured interpretation, jointly constrained by various lexical properties related to both linguistic and non-linguistic knowledge, in an extensive set of brain regions beyond the core fronto-temporal language network. These findings provide empirical evidence for the constraint-based approach to sentence processing and deepen the understanding of specific spatiotemporal patterning and neuro-computational properties underpinning incremental speech comprehension.</p>
<p>Using artificial neural networks (ANNs) to study the neural substrates of human cognition complements the long-time pursuit of generative rules and interpretable models<sup><xref ref-type="bibr" rid="c51">51</xref></sup>. ANNs have informed our understanding of various cognitive processes in the brain by providing quantifiable predictions that aim to connect behaviors and relevant neural activity<sup><xref ref-type="bibr" rid="c52">52</xref>-<xref ref-type="bibr" rid="c59">59</xref></sup>. This is crucial for quantifying the outcome of complex, interrelated constraints that arise in specific contexts, such as spoken sentences, and constructing the representational geometry to be probed in the brain. Where DLMs are concerned, recent studies have systematically compared the internal representations of DLMs to those observed in the human brain during language processing, which highlights the importance of predictive coding and contextual information<sup><xref ref-type="bibr" rid="c28">28</xref>-<xref ref-type="bibr" rid="c34">34</xref></sup>. Furthermore, these studies have motivated the use of DLMs as a computational tool, or hypothesis, to study the neural basis of language.</p>
<p>Here we asked a more specific question, that is, how a sequence of spoken words is incrementally structured and coherently interpreted in the brain. Our goal was to develop quantitative measures of sentence structure that capture the interplay between different types of constraints that simultaneously influence this process. As a potential solution, we extracted detailed structural measures specific to the contents in each sentence from the hidden states of BERT, which was trained on massive corpora from real-life language use. Although DLMs such as BERT are not specifically designed to parse sentences, they can learn from training corpora the multi-dimensional properties related to sentence structure and dependency<sup><xref ref-type="bibr" rid="c60">60</xref></sup>. In line with this, our analyses confirmed that BERT structural measures incorporate relevant lexical constraints and that they exhibit both behavioral and neural alignments with human listeners.</p>
<p>Taking advantage of the contextualized BERT structural measures, our RSA results provide neural evidence for the construction of a coherent interpretation driven by the interaction between linguistic and non-linguistic knowledge evoked by individual words as they are heard sequentially in a spoken sentence. Specifically, neural representations of an unfolding sentence’s structure initially emerged in bilateral fronto-temporal regions and became left-lateralized when more complex syntactic properties, rather than canonical linear adjacency, were considered to build a structured interpretation (e.g., beyond Verb1 in our stimulus sentences). Meanwhile, we found considerable right-hemisphere effects for computations associated with broad world knowledge, which is essential for understanding the intended meaning conveyed by the speaker<sup><xref ref-type="bibr" rid="c61">61</xref></sup>. In addition to the core fronto-temporal language network, we found that the multiple-demand network and the default mode network were also involved during online construction of structured interpretations, which may reflect additional cognitive demands for resolving potential structural ambiguity and evaluating the plausibility of underlying events<sup><xref ref-type="bibr" rid="c62">62</xref></sup>.</p>
<p>There are two points to note about the use of BERT. Firstly, unlike autoregressive DLMs trained using left-to-right attention and next-word prediction, BERT is trained to predict masked words in a sentence with a bi-directional attention mechanism. The additional right- to-left attention provides updated representations of preceding words every time an incoming word is added to the input (e.g., representation of <italic>“dog”</italic> in <italic>“The dog…”</italic> is different from that in <italic>“The dog found…”</italic>). This feature of BERT is useful for tracking the dynamic change of the representation of a specific word as its context evolves, particularly in sentences with structural ambiguity. Although autoregressive DLMs also update hidden states as the input unfolds and could be used to study complex sentential structures<sup><xref ref-type="bibr" rid="c63">63</xref></sup>, the updated contextual effects are reflected in the hidden states of the right-most incoming word, while those of the preceding words on the left remain unchanged (i.e., the representation of <italic>“dog”</italic> is the same in <italic>“The dog…”</italic> and <italic>“The dog found…”</italic>). This is different from BERT, where the updated contextual effects are reflected in the hidden states of all preceding words in both directions.</p>
<p>Secondly, although we input each sentence word-by-word to BERT, however, unlike human listeners or recurrent neural networks, BERT process two consecutive inputs (e.g., <italic>“The dog…”</italic> and <italic>“The dog found…”</italic>) independently in a parallel manner, and there is no direct relationship between these two inputs. In fact, human listeners would not start over from the beginning of a sentence as it unfolds word-by-word, but update it continually as each word is heard. They use whatever information currently available to build a coherent interpretation<sup><xref ref-type="bibr" rid="c64">64</xref></sup>. Nevertheless, this discrepancy does not hinder our goal of extracting contextualized structural measures from sentence fragments that approximate the current structured interpretation. The representation of each word is continuously updated in a bi-directional way as a new word is added to the input, taking into account the constraints placed by the specific words and their interaction to form a coherent interpretation.</p>
<p>In summary, recent developments in DLMs have shown great potential in capturing the dynamic interplay between syntax, semantics, and world knowledge that is essential for successful language comprehension. As demonstrated in this study, when considered as putative brain-computational models and combined with advanced neuroimaging methods within an appropriate framework<sup><xref ref-type="bibr" rid="c51">51</xref></sup>, future DLMs, with more human-like model architecture<sup><xref ref-type="bibr" rid="c65">65</xref></sup> and rigorous evaluation<sup><xref ref-type="bibr" rid="c66">66</xref></sup>, may provide new insights into the neural implementation of the various incremental processing operations that support the rapid transition from sound to meaning in the brain.</p>
</sec>
<sec id="s4">
<title>Materials and Methods</title>
<p>Details of materials and methods are provided in Supplementary Materials.</p>
</sec>
<sec id="d1e1019" sec-type="supplementary-material">
<title>Supporting information</title>
<supplementary-material id="d1e1104">
<label>Supplementary Materials</label>
<media xlink:href="supplements/465687_file02.pdf"/>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>This research was funded by European Research Council Advanced Investigator Grant to L.K.T. under the European Community’s Horizon 2020 Research and Innovation Programme (2014-2022 ERC Grant Agreement 669820). B.L. was supported by Changping Laboratory. We thank Billi Randall and Barry Devereux for their valuable contributions to early experimental design and to stimulus development; and Hun S. Choi, Benedict Vassileiou, John Hewitt, Tao Li, Yi Zhu, Nai Ding and Giorgio Marinato for helpful discussions.</p>
</ack>
<sec id="s5">
<title>Author contributions</title>
<p>Conceptualization: L.K.T., W.D.M., B.L.</p>
<p>Investigation, Data curation: B.L., Y.F.</p>
<p>Methodology, Formal Analysis &amp; Visualization: B.L.</p>
<p>Funding acquisition &amp; Project administration: L.K.T</p>
<p>Supervision: L.K.T., W.D.M.</p>
<p>Writing – original draft, review &amp; editing: B.L., W.D.M., L.K.T.</p>
</sec>
<sec id="s6">
<title>Declaration of interests</title>
<p>Authors declare no competing interests.</p>
</sec>
<sec id="s7">
<title>Data and materials availability</title>
<p>Upon publication, data and code will be made available online.</p>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>Marslen-Wilson</surname>, <given-names>W.</given-names></string-name> &amp; <string-name><surname>Tyler</surname>, <given-names>L.K.</given-names></string-name> <article-title>The temporal structure of spoken language understanding</article-title>. <source>Cognition</source> <volume>8</volume>, <fpage>1</fpage>–<lpage>71</lpage> (<year>1980</year>).</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Choi</surname>, <given-names>H.S.</given-names></string-name>, <string-name><surname>Marslen-Wilson</surname>, <given-names>W.D.</given-names></string-name>, <string-name><surname>Lyu</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Randall</surname>, <given-names>B.</given-names></string-name> &amp; <string-name><surname>Tyler</surname>, <given-names>L.K.</given-names></string-name> <article-title>Decoding the Real-Time Neurobiological Properties of Incremental Semantic Interpretation</article-title>. <source>Cereb Cortex</source> <volume>31</volume>, <fpage>233</fpage>–<lpage>247</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>Lyu</surname>, <given-names>B.</given-names></string-name>, <etal>et al.</etal> <article-title>Neural dynamics of semantic composition</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>116</volume>, <fpage>21318</fpage>–<lpage>21327</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Everaert</surname>, <given-names>M.B.H.</given-names></string-name>, <string-name><surname>Huybregts</surname>, <given-names>M.A.C.</given-names></string-name>, <string-name><surname>Chomsky</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Berwick</surname>, <given-names>R.C.</given-names></string-name> &amp; <string-name><surname>Bolhuis</surname>, <given-names>J.J.</given-names></string-name> <article-title>Structures, Not Strings: Linguistics as Part of the Cognitive Sciences</article-title>. <source>Trends Cogn Sci</source> <volume>19</volume>, <fpage>729</fpage>–<lpage>743</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Matchin</surname>, <given-names>W.</given-names></string-name> &amp; <string-name><surname>Hickok</surname>, <given-names>G.</given-names></string-name> <article-title>The Cortical Organization of Syntax</article-title>. <source>Cereb Cortex</source> <volume>30</volume>, <fpage>1481</fpage>–<lpage>1498</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Nelson</surname>, <given-names>M.J.</given-names></string-name>, <etal>et al.</etal> <article-title>Neurophysiological dynamics of phrase-structure building during sentence processing</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>114</volume>, <fpage>E3669</fpage>–<lpage>E3678</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Law</surname>, <given-names>R.</given-names></string-name> &amp; <string-name><surname>Pylkkanen</surname>, <given-names>L.</given-names></string-name> <article-title>Lists with and without Syntax: A New Approach to Measuring the Neural Processing of Syntax</article-title>. <source>J Neurosci</source> <volume>41</volume>, <fpage>2186</fpage>–<lpage>2196</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Pallier</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Devauchelle</surname>, <given-names>A.D.</given-names></string-name> &amp; <string-name><surname>Dehaene</surname>, <given-names>S.</given-names></string-name> <article-title>Cortical representation of the constituent structure of sentences</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>108</volume>, <fpage>2522</fpage>–<lpage>2527</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Friederici</surname>, <given-names>A.D.</given-names></string-name>, <string-name><surname>Bahlmann</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Heim</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Schubotz</surname>, <given-names>R.I.</given-names></string-name> &amp; <string-name><surname>Anwander</surname>, <given-names>A.</given-names></string-name> <article-title>The brain differentiates human and non-human grammars: functional localization and structural connectivity</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>103</volume>, <fpage>2458</fpage>–<lpage>2463</lpage> (<year>2006</year>).</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="book"><string-name><surname>Bever</surname>, <given-names>T.G.</given-names></string-name> <chapter-title>The cognitive basis for linguistic structures</chapter-title>. <source>in Cognition and the Development of Language</source> (ed. <person-group person-group-type="editor"><string-name><given-names>J.R.</given-names> <surname>Hayes</surname></string-name></person-group>) (<publisher-name>John Wiley</publisher-name>, <publisher-loc>New York</publisher-loc>, <year>1970</year>).</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>Tyler</surname>, <given-names>L.K.</given-names></string-name> &amp; <string-name><surname>Marslen-Wilson</surname>, <given-names>W.D.</given-names></string-name> <article-title>The On-Line Effects of Semantic Context on Syntactic Processing</article-title>. <source>J Verbal Learn Verbal Behav</source> <volume>16</volume>, <fpage>683</fpage>–<lpage>692</lpage> (<year>1977</year>).</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>MacDonald</surname>, <given-names>M.C.</given-names></string-name>, <string-name><surname>Pearlmutter</surname>, <given-names>N.J.</given-names></string-name> &amp; <string-name><surname>Seidenberg</surname>, <given-names>M.S.</given-names></string-name> <article-title>The lexical nature of syntactic ambiguity resolution</article-title>. <source>Psychol Rev</source> <volume>101</volume>, <fpage>676</fpage>–<lpage>703</lpage> (<year>1994</year>).</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="book"><string-name><surname>Trueswell</surname>, <given-names>J.C.</given-names></string-name> &amp; <string-name><surname>Tanenhaus</surname>, <given-names>M.K.</given-names></string-name> <chapter-title>Toward a lexicalist framework of constraint-based syntactic ambiguity resolution</chapter-title>. <source>in Perspectives on sentence processing</source>. <fpage>155</fpage>–<lpage>179</lpage> (<publisher-name>Lawrence Erlbaum Associates, Inc</publisher-name>, <publisher-loc>Hillsdale, NJ, US</publisher-loc>, <year>1994</year>).</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><string-name><surname>Altmann</surname>, <given-names>G.T.</given-names></string-name> <article-title>Ambiguity in sentence processing</article-title>. <source>Trends Cogn Sci</source> <volume>2</volume>, <fpage>146</fpage>–<lpage>152</lpage> (<year>1998</year>).</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Vaswani</surname>, <given-names>A.</given-names></string-name>, <etal>et al.</etal> <article-title>Attention is all you need</article-title>. <source>Advances in neural information processing systems</source> <volume>30</volume> (<year>2017</year>).</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="book"><string-name><surname>Devlin</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Chang</surname>, <given-names>M.-W.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>K.</given-names></string-name> &amp; <string-name><surname>Toutanova</surname>, <given-names>K.</given-names></string-name> <chapter-title>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</chapter-title>. <source>in Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</source> <fpage>4171</fpage>–<lpage>4186</lpage> (<publisher-name>Association for Computational Linguistics</publisher-name>, <publisher-loc>Minneapolis, MN, USA</publisher-loc>, <year>2019</year>).</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><surname>Brown</surname>, <given-names>T.</given-names></string-name>, <etal>et al.</etal> <article-title>Language models are few-shot learners</article-title>. <source>Advances in neural information processing systems</source> <volume>33</volume>, <fpage>1877</fpage>–<lpage>1901</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="other"><string-name><surname>Ouyang</surname>, <given-names>L.</given-names></string-name>, <etal>et al.</etal> <article-title>Training language models to follow instructions with human feedback</article-title>. <source>Advances in neural information processing systems</source> (<year>2022</year>).</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="book"><string-name><surname>Bisk</surname>, <given-names>Y.</given-names></string-name>, <etal>et al.</etal> <chapter-title>Experience Grounds Language</chapter-title>. <source>in Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</source> <fpage>8718</fpage>–<lpage>8735</lpage> (<publisher-name>Association for Computational Linguistics</publisher-name>, Online, <year>2020</year>).</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><string-name><surname>Linzen</surname>, <given-names>T.</given-names></string-name> &amp; <string-name><surname>Baroni</surname>, <given-names>M.</given-names></string-name> <article-title>Syntactic Structure from Deep Learning</article-title>. <source>Annu Rev Linguist</source> <volume>7</volume>, <fpage>195</fpage>–<lpage>212</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Pavlick</surname>, <given-names>E.</given-names></string-name> <article-title>Semantic Structure in Deep Learning</article-title>. <source>Annu Rev Linguist</source> <volume>8</volume>, <fpage>447</fpage>–<lpage>471</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="other"><string-name><surname>Mahowald</surname>, <given-names>K.</given-names></string-name>, <etal>et al.</etal> <article-title>Dissociating language and thought in large language models: a cognitive perspective</article-title>. <source>arXiv</source> (<year>2023</year>).</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Marslen-Wilson</surname>, <given-names>W.D.</given-names></string-name> <article-title>Sentence perception as an interactive parallel process</article-title>. <source>Science</source> <volume>189</volume>, <fpage>226</fpage>–<lpage>228</lpage> (<year>1975</year>).</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><surname>Kuperberg</surname>, <given-names>G.R.</given-names></string-name> <article-title>Neural mechanisms of language comprehension: challenges to syntax</article-title>. <source>Brain Res</source> <volume>1146</volume>, <fpage>23</fpage>–<lpage>49</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Bengio</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Lecun</surname>, <given-names>Y.</given-names></string-name> &amp; <string-name><surname>Hinton</surname>, <given-names>G.</given-names></string-name> <article-title>Deep Learning for AI</article-title>. <source>Commun Acm</source> <volume>64</volume>, <fpage>58</fpage>–<lpage>65</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><string-name><surname>Elman</surname>, <given-names>J.L.</given-names></string-name> <article-title>Finding Structure in Time</article-title>. <source>Cognitive Sci</source> <volume>14</volume>, <fpage>179</fpage>–<lpage>211</lpage> (<year>1990</year>).</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><string-name><surname>Elman</surname>, <given-names>J.L.</given-names></string-name> <article-title>Learning and development in neural networks: the importance of starting small</article-title>. <source>Cognition</source> <volume>48</volume>, <fpage>71</fpage>–<lpage>99</lpage> (<year>1993</year>).</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><string-name><surname>Schrimpf</surname>, <given-names>M.</given-names></string-name>, <etal>et al.</etal> <article-title>The neural architecture of language: Integrative modelling converges on predictive processing</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>118</volume>, <fpage>e2105646118</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><string-name><surname>Goldstein</surname>, <given-names>A.</given-names></string-name>, <etal>et al.</etal> <article-title>Shared computational principles for language processing in humans and deep language models</article-title>. <source>Nat Neurosci</source> <volume>25</volume>, <fpage>369</fpage>–<lpage>380</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><string-name><surname>Heilbron</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Armeni</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Schoffelen</surname>, <given-names>J.M.</given-names></string-name>, <string-name><surname>Hagoort</surname>, <given-names>P.</given-names></string-name> &amp; <string-name><surname>de Lange</surname>, <given-names>F.P.</given-names></string-name> <article-title>A hierarchy of linguistic predictions during natural language comprehension</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>119</volume>, <fpage>e2201968119</fpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><string-name><surname>Toneva</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Mitchell</surname>, <given-names>T.M.</given-names></string-name> &amp; <string-name><surname>Wehbe</surname>, <given-names>L.</given-names></string-name> <article-title>Combining computational controls with natural text reveals aspects of meaning composition</article-title>. <source>Nat Comput Sci</source> <volume>2</volume>, <fpage>745</fpage>–<lpage>757</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><string-name><surname>Caucheteux</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Gramfort</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>King</surname>, <given-names>J.R.</given-names></string-name> <article-title>Deep language algorithms predict semantic comprehension from brain activity</article-title>. <source>Sci Rep</source> <volume>12</volume>, <fpage>16327</fpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><string-name><surname>Caucheteux</surname>, <given-names>C.</given-names></string-name> &amp; <string-name><surname>King</surname>, <given-names>J.R.</given-names></string-name> <article-title>Brains and algorithms partially converge in natural language processing</article-title>. <source>Commun Biol</source> <volume>5</volume>, <fpage>134</fpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><string-name><surname>Caucheteux</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Gramfort</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>King</surname>, <given-names>J.R.</given-names></string-name> <article-title>Evidence of a predictive coding hierarchy in the human brain listening to speech</article-title>. <source>Nat Hum Behav</source> <volume>7</volume>, <fpage>430</fpage>–<lpage>441</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="book"><string-name><surname>Hewitt</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Liang</surname>, <given-names>P.</given-names></string-name> <chapter-title>Designing and interpreting probes with control tasks</chapter-title>. <source>in Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</source> <fpage>2733</fpage>–<lpage>2743</lpage> (<publisher-name>Association for Computational Linguistics</publisher-name>, <publisher-loc>Hong Kong, China</publisher-loc>, <year>2019</year>).</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="book"><string-name><surname>Tenney</surname>, <given-names>I.</given-names></string-name>, <etal>et al.</etal> <chapter-title>What do you learn from context? probing for sentence structure in contextualized word representations</chapter-title>. <source>in the 7th International Conference on Learning Representations</source> (<publisher-loc>New Orleans, LA, USA</publisher-loc>, <year>2019</year>).</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="book"><string-name><surname>Hewitt</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Manning</surname>, <given-names>C.D.</given-names></string-name> <chapter-title>A structural probe for finding syntax in word representations</chapter-title>. <source>in Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</source> <fpage>4129</fpage>–<lpage>4138</lpage> (<publisher-name>Association for Computational Linguistics</publisher-name>, <publisher-loc>Minneapolis, MN, USA</publisher-loc>, <year>2019</year>).</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Mur</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Bandettini</surname>, <given-names>P.</given-names></string-name> <article-title>Representational similarity analysis - connecting the branches of systems neuroscience</article-title>. <source>Front Syst Neurosci</source> <volume>2</volume>, <fpage>4</fpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><string-name><surname>Dowty</surname>, <given-names>D.</given-names></string-name> <article-title>Thematic Proto-Roles and Argument Selection</article-title>. <source>Language</source> <volume>67</volume>, <fpage>547</fpage>–<lpage>619</lpage> (<year>1991</year>).</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><string-name><surname>Marslen-Wilson</surname>, <given-names>W.D.</given-names></string-name>, <string-name><surname>Tyler</surname>, <given-names>L.K.</given-names></string-name> &amp; <string-name><surname>Koster</surname>, <given-names>C.</given-names></string-name> <article-title>Integrative Processes in Utterance Resolution</article-title>. <source>J Mem Lang</source> <volume>32</volume>, <fpage>647</fpage>–<lpage>666</lpage> (<year>1993</year>).</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><string-name><surname>Friederici</surname>, <given-names>A.D.</given-names></string-name> <article-title>The cortical language circuit: from auditory perception to sentence comprehension</article-title>. <source>Trends in Cognitive Sciences</source> <volume>16</volume>, <fpage>262</fpage>–<lpage>268</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><string-name><surname>Yeshurun</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Nguyen</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Hasson</surname>, <given-names>U.</given-names></string-name> <article-title>The default mode network: where the idiosyncratic self meets the shared social world</article-title>. <source>Nat Rev Neurosci</source> <volume>22</volume>, <fpage>181</fpage>–<lpage>192</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="book"><string-name><surname>De Marneffe</surname>, <given-names>M.-C.</given-names></string-name>, <string-name><surname>MacCartney</surname>, <given-names>B.</given-names></string-name> &amp; <string-name><surname>Manning</surname>, <given-names>C.D.</given-names></string-name> <chapter-title>Generating typed dependency parses from phrase structure parses</chapter-title>. <source>in Proceedings of the 5th International Conference on Language Resources and Evaluation</source> <fpage>449</fpage>–<lpage>454</lpage> (<publisher-name>European Language Resources Association</publisher-name>, <publisher-loc>Genoa, Italy</publisher-loc>, <year>2006</year>).</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="book"><string-name><surname>Jackendoff</surname>, <given-names>R.</given-names></string-name> &amp; <string-name><surname>Jackendoff</surname>, <given-names>R.S.</given-names></string-name> <source>Foundations of language: Brain, meaning, grammar, evolution</source> (<publisher-name>Oxford University Press</publisher-name>, <publisher-loc>USA</publisher-loc>, <year>2002</year>).</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><string-name><surname>Duncan</surname>, <given-names>J.</given-names></string-name> <article-title>The multiple-demand (MD) system of the primate brain: mental programs for intelligent behaviour</article-title>. <source>Trends Cogn Sci</source> <volume>14</volume>, <fpage>172</fpage>–<lpage>179</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><string-name><surname>Baldassano</surname>, <given-names>C.</given-names></string-name>, <etal>et al.</etal> <article-title>Discovering Event Structure in Continuous Narrative Perception and Memory</article-title>. <source>Neuron</source> <volume>95</volume>, <fpage>709</fpage>–<lpage>721 e705</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><string-name><surname>Humphreys</surname>, <given-names>G.F.</given-names></string-name>, <string-name><surname>Lambon Ralph</surname>, <given-names>M.A.</given-names></string-name> &amp; <string-name><surname>Simons</surname>, <given-names>J.S.</given-names></string-name> <article-title>A Unifying Account of Angular Gyrus Contributions to Episodic and Semantic Cognition</article-title>. <source>Trends Neurosci</source> <volume>44</volume>, <fpage>452</fpage>–<lpage>463</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><string-name><surname>Jung-Beeman</surname>, <given-names>M.</given-names></string-name> <article-title>Bilateral brain processes for comprehending natural language</article-title>. <source>Trends Cogn Sci</source> <volume>9</volume>, <fpage>512</fpage>–<lpage>518</lpage> (<year>2005</year>).</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><string-name><surname>Metusalem</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Kutas</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Urbach</surname>, <given-names>T.P.</given-names></string-name> &amp; <string-name><surname>Elman</surname>, <given-names>J.L.</given-names></string-name> <article-title>Hemispheric asymmetry in event knowledge activation during incremental language comprehension: A visual half-field ERP study</article-title>. <source>Neuropsychologia</source> <volume>84</volume>, <fpage>252</fpage>–<lpage>271</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><string-name><surname>Troyer</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>McRae</surname>, <given-names>K.</given-names></string-name> &amp; <string-name><surname>Kutas</surname>, <given-names>M.</given-names></string-name> <article-title>Wrong or right? Brain potentials reveal hemispheric asymmetries to semantic relations during word-by-word sentence reading as a function of (fictional) knowledge</article-title>. <source>Neuropsychologia</source> <volume>170</volume>, <fpage>108215</fpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Douglas</surname>, <given-names>P.K.</given-names></string-name> <article-title>Cognitive computational neuroscience</article-title>. <source>Nat Neurosci</source> <volume>21</volume>, <fpage>1148</fpage>–<lpage>1160</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><string-name><surname>Yamins</surname>, <given-names>D.L.</given-names></string-name> &amp; <string-name><surname>DiCarlo</surname>, <given-names>J.J.</given-names></string-name> <article-title>Using goal-driven deep learning models to understand sensory cortex</article-title>. <source>Nat Neurosci</source> <volume>19</volume>, <fpage>356</fpage>–<lpage>365</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><string-name><surname>Rabovsky</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Hansen</surname>, <given-names>S.S.</given-names></string-name> &amp; <string-name><surname>McClelland</surname>, <given-names>J.L.</given-names></string-name> <article-title>Modelling the N400 brain potential as change in a probabilistic representation of meaning</article-title>. <source>Nat Hum Behav</source> <volume>2</volume>, <fpage>693</fpage>–<lpage>705</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="other"><string-name><surname>Donhauser</surname>, <given-names>P.W.</given-names></string-name> &amp; <string-name><surname>Baillet</surname>, <given-names>S.</given-names></string-name> <article-title>Two Distinct Neural Timescales for Predictive Speech Processing</article-title>. <source>Neuron</source> (<year>2019</year>).</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><string-name><surname>Yang</surname>, <given-names>G.R.</given-names></string-name>, <string-name><surname>Joglekar</surname>, <given-names>M.R.</given-names></string-name>, <string-name><surname>Song</surname>, <given-names>H.F.</given-names></string-name>, <string-name><surname>Newsome</surname>, <given-names>W.T.</given-names></string-name> &amp; <string-name><surname>Wang</surname>, <given-names>X.J.</given-names></string-name> <article-title>Task representations in neural networks trained to perform many cognitive tasks</article-title>. <source>Nat Neurosci</source> <volume>22</volume>, <fpage>297</fpage>–<lpage>306</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><string-name><surname>Kietzmann</surname>, <given-names>T.C.</given-names></string-name>, <etal>et al.</etal> <article-title>Recurrence is required to capture the representational dynamics of the human visual system</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>116</volume>, <fpage>21854</fpage>–<lpage>21863</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><string-name><surname>Bao</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>She</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>McGill</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Tsao</surname>, <given-names>D.Y.</given-names></string-name> <article-title>A map of object space in primate inferotemporal cortex</article-title>. <source>Nature</source> <volume>583</volume>, <fpage>103</fpage>–<lpage>108</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><string-name><surname>Sheahan</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Luyckx</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Nelli</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Teupe</surname>, <given-names>C.</given-names></string-name> &amp; <string-name><surname>Summerfield</surname>, <given-names>C.</given-names></string-name> <article-title>Neural state space alignment for magnitude generalization in humans and recurrent networks</article-title>. <source>Neuron</source> <volume>109</volume>, <fpage>1214</fpage>–<lpage>1226 e1218</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="other"><string-name><surname>Giordano</surname>, <given-names>B.L.</given-names></string-name>, <string-name><surname>Esposito</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Valente</surname>, <given-names>G.</given-names></string-name> &amp; <string-name><surname>Formisano</surname>, <given-names>E.</given-names></string-name> <article-title>Intermediate acoustic-to-semantic representations link behavioral and neural responses to natural sounds</article-title>. <source>Nat Neurosci</source> (<year>2023</year>).</mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="journal"><string-name><surname>Manning</surname>, <given-names>C.D.</given-names></string-name>, <string-name><surname>Clark</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Hewitt</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Khandelwal</surname>, <given-names>U.</given-names></string-name> &amp; <string-name><surname>Levy</surname>, <given-names>O.</given-names></string-name> <article-title>Emergent linguistic structure in artificial neural networks trained by self-supervision</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>117</volume>, <fpage>30046</fpage>–<lpage>30054</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="journal"><string-name><surname>Bicknell</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Elman</surname>, <given-names>J.L.</given-names></string-name>, <string-name><surname>Hare</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>McRae</surname>, <given-names>K.</given-names></string-name> &amp; <string-name><surname>Kutas</surname>, <given-names>M.</given-names></string-name> <article-title>Effects of event knowledge in processing verbal arguments</article-title>. <source>J Mem Lang</source> <volume>63</volume>, <fpage>489</fpage>–<lpage>505</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="journal"><string-name><surname>Smallwood</surname>, <given-names>J.</given-names></string-name>, <etal>et al.</etal> <article-title>The default mode network in cognition: a topographical perspective</article-title>. <source>Nature Reviews Neuroscience</source> <volume>22</volume>, <fpage>503</fpage>–<lpage>513</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c63"><label>63.</label><mixed-citation publication-type="book"><string-name><surname>Jurayj</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Rudman</surname>, <given-names>W.</given-names></string-name> &amp; <string-name><surname>Eickhof</surname>, <given-names>C.</given-names></string-name> <chapter-title>Garden Path Traversal in GPT-2</chapter-title>. <source>In Proceedings of the 5th BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP</source> <fpage>305</fpage>–<lpage>313</lpage> (<publisher-name>Association for Computational Linguistics</publisher-name>, <publisher-loc>Abu Dhabi, United Arab Emirates</publisher-loc>, <year>2022</year>).</mixed-citation></ref>
<ref id="c64"><label>64.</label><mixed-citation publication-type="journal"><string-name><surname>Frazier</surname>, <given-names>L.</given-names></string-name> &amp; <string-name><surname>Rayner</surname>, <given-names>K.</given-names></string-name> <article-title>Making and correcting errors during sentence comprehension: Eye movements in the analysis of structurally ambiguous sentences</article-title>. <source>Cogn Psychol</source> <volume>14</volume>, <fpage>178</fpage>–<lpage>210</lpage> (<year>1982</year>).</mixed-citation></ref>
<ref id="c65"><label>65.</label><mixed-citation publication-type="journal"><string-name><surname>McClelland</surname>, <given-names>J.L.</given-names></string-name>, <string-name><surname>Hill</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Rudolph</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Baldridge</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Schutze</surname>, <given-names>H.</given-names></string-name> <article-title>Placing language in an integrated understanding system: Next steps toward human-level performance in neural language models</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>117</volume>, <fpage>25966</fpage>–<lpage>25974</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c66"><label>66.</label><mixed-citation publication-type="journal"><string-name><surname>Binz</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Schulz</surname>, <given-names>E.</given-names></string-name> <article-title>Using cognitive psychology to understand GPT-3</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>120</volume>, <fpage>e2218523120</fpage> (<year>2023</year>).</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.89311.1.sa4</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Ding</surname>
<given-names>Nai</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Zhejiang University</institution>
</institution-wrap>
<city>Hangzhou</city>
<country>China</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study provides <bold>valuable</bold> insights into how the brain parses the syntactic structure of a spoken sentence. A unique contribution of the work is to use a large language model to quantify how the mental representation of syntactic structure updates as a sentence unfolds in time. <bold>Solid</bold> evidence is provided that distributive cortical networks are engaged for incremental parsing of a sentence, although the contribution could be further strengthened if the authors would further highlight the main results and clarify the benefit of using a large language model.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.89311.1.sa3</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>In this study, the authors investigate where and when brain activity is modulated by incoming linguistic cues during sentence comprehension. Sentence stimuli were designed such that incoming words had varying degrees of constraint on the sentence's structural interpretation as participants listened to them unfolding, i.e. due to varying degrees of verb transitivity and the noun's likelihood of assuming a specific thematic role. Word-by-word &quot;online&quot; structural interpretations for each sentence were extracted from a deep neural network model trained to reproduce language statistics. The authors relate the various metrics of word-by-word predicted sentence structure to brain data through a standard RSA approach at three distinct points of time throughout sentence presentation. The data provide convincing evidence that brain activity reflects preceding linguistic constraints as well as integration difficulty immediately after word onset of disambiguating material.</p>
<p>The authors confirm that their sentence stimuli vary in degree of constraint on sentence structure through independent behavioral data from a sentence continuation task. They also show a compelling correlation of these behavioral data with the online structure metric extracted from the deep neural network, which seems to pick up on the variation in constraints. In the introduction, the authors argue for the potential benefits of using deep neural network-derived metrics given that it has &quot;historically been challenging to model the dynamic interplay between various types of linguistic and nonlinguistic information&quot;. Similarly, they later conclude that &quot;future DLMs (...) may provide new insights into the neural implementation of the various incremental processing operations(...)&quot;.</p>
<p>By incorporating structural probing of a deep neural network, a technique developed in the field of natural language processing, into the analysis pipeline for investigating brain data, the authors indeed take an important step towards establishing advanced machine learning techniques for researching the neurobiology of language. However, given the popularity of deep neural networks, an argument for their utility should be carefully evidenced. However, the data presented here don't directly test how large the benefit provided by this tool really is. In fact, the authors show compelling correlations of the neural network-derived metrics with both the behavioral cloze-test data as well as several (corpus-)derived metrics. While this is a convincing illustration of how deep language models can be made more interpretable, it is in itself not novel. The correlation with behavioral data and corpus statistics also raises the question of what is the additional benefit of the computational model? Is it simply saving us the step of not having to collect the behavioral data, not having to compute the corpus statistics or does the model potentially uncover a more nuanced representation of the online comprehension process? This remains unclear because we are lacking a direct comparison of how much variance in the neural data is explained by the neural network-derived metrics beyond those other metrics (for example the main verb probability or the corpus-derived &quot;active index&quot; following the prepositional phrase).</p>
<p>With regards to the neural data, the authors show convincing evidence for early modulations of brain activity by linguistic constraints on sentence structure and importantly early modulation by the coherence between multiple constraints to be integrated. Those modulations can be observed across bilateral frontal and temporal areas as well as parts of the default mode network. The methods used are clear and rigorous and allow for a detailed exploration of how multiple linguistic cues are neurally encoded and dynamically shape the final representation of a sentence in the brain. However, at times the consequences of the RSA results remain somewhat vague with regard to the motivation behind different metrics and how they differ from each other. Therefore, some results seem surprising and warrant further discussion, for example:</p>
<p>Why does the neural network-derived parse depth metric fit neural data before the V1 uniqueness point if the sentence pairs begin with the same noun phrase? This suggests that the lexical information preceding V1, is driving the results. However, given the additional results, we can already exclude an influence of subject likelihood for a specific thematic role as this did not model the neural data in the V1 epoch to a significant degree. Relatedly, In Fig 2C it seems there are systematic differences between HiTrans and LoTrans sentences regarding the parse depth of determiner and subject noun according to the neural network model, while this is not expected according to the context-free parse.</p>
<p>&quot;The degree of this mismatch is proportional to the evidence for or against the two interpretations (...). Besides these two measures based on the entire incremental input, we also focused on Verb1 since the potential structural ambiguity lies in whether Verb1 is interpreted as a passive verb or the main verb.&quot;</p>
<p>The neural data fits in V1 epoch differ in their temporal profile for the mismatch metrics and the Verb 1 depth respectively. I understand the &quot;degree of mismatch&quot; to be a measure of how strongly the neural network's hidden representations align with the parse depth of an active or passive sentence structure. If this is correct, then it is not clear from the text how far this measure differs from the Verb 1 depth alone, which is also indicating either an active or passive structure.</p>
<p>In previous studies, differences in neural activity related to distinct amounts of open nodes in the parse tree have been interpreted in terms of distinct working memory demands (Nelson et al. pnas 2017, Udden et al tics 2020). It seems that some of the metrics, for example the neural network-derived parse depth or the V1 depth may be similarly interpreted in the light of working memory demands. After all, during V1 epoch, the sentences do not only differ with respect to predicted sentence structure, but also in the amount of open nodes that need to be maintained. In the discussion, however, the authors interpret these results as &quot;neural representations of an unfolding sentence's structure&quot;.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.89311.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This article is focused on investigating incremental speech processing, as it pertains to building higher-order syntactic structure. This is an important question because speech processing in general is lesser studied as compared to reading, and syntactic processes are lesser studied than lower-level sensory processes. The authors claim to shed light on the neural processes that build structured linguistic interpretations. The authors apply modern analysis techniques, and use state-of-the-art large language models in order to facilitate this investigation. They apply this to a cleverly designed experimental paradigm of EMEG data, and compare neural responses of human participants to the activation profiles in different layers of the BERT language model.</p>
<p>Strengths:</p>
<p>[1] The study aims to investigate an under-explored aspect of language processing, namely syntactic operations during speech processing</p>
<p>[2] The study is taking advantage of technological advancements in large language models, while also taking linguistic theory into account in building the hypothesis space</p>
<p>[3] The data combine EEG and MEG, which provides a valuable spatio-temporally resolved dataset</p>
<p>[4] The use of behavioural validation of high/low transitive was an elegant demonstration of the validity of their stimuli</p>
<p>Weaknesses:</p>
<p>[1] The manuscript is quite hard to understand, even for someone well-versed in both linguistic theory and LLMs. The questions, design, analysis approach, and conclusions are all quite dense and not easy to follow.</p>
<p>[2] The analyses end up seeming overly complicated when the underlying difference between sentence types is a simple categorical distinction between high and low transitivity. I am not sure why tree depth and BERT are being used to evaluate the degree to which a sentence is being processed as active or passive. If this is necessary, it would be helpful for the authors to motivate this more clearly.</p>
<p>[3] The main data result figures comparing BERT and the EMEG brain data are hard to evaluate because only t-values are provided, and those, only for significant clusters. It would be helpful to see the full 600 ms time course of rho values, with error bars across subjects, to really be able to evaluate it visually. This is a summary statistic that is very far away from the input data</p>
<p>[4] Some details are omitted or not explained clearly. For example, how was BERT masked to give word-by-word predictions? In its default form, I believe that BERT takes in a set of words before and after the keyword that it is predicting. But I assume that here the model is not allowed to see linguistic information in the future. How were the auditory stimuli recorded? Was it continuous speech or silences between each word? How was prosody controlled? Was it a natural speaker or a speech synthesiser?</p>
<p>It is difficult for me to fully assess the extent to which the authors achieved their aims, because I am missing important information about the setup of the experiment and the distribution of test statistics across subjects.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.89311.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Syntactic parsing is a highly dynamic process: When an incoming word is inconsistent with the presumed syntactic structure, the brain has to reanalyze the sentence and construct an alternative syntactic structure. Since syntactic parsing is a hidden process, it is challenging to describe the syntactic structure a listener internally constructs at each time moment. Here, the authors overcome this problem by (1) asking listeners to complete a sentence at some break point to probe the syntactic structure mentally constructed at the break point, and (2) using a DNN model to extract the most likely structure a listener may extract at a time moment. After obtaining incremental syntactic features using the DNN model, the authors analyze how these syntactic features are represented in the brain using MEG.</p>
<p>Although the analyses are detailed, the current conclusion needs to be further specified. For example, in the abstract, it is concluded that &quot;Our results reveal a detailed picture of the neurobiological processes involved in building structured interpretations through the integration across multifaceted constraints&quot;. The readers may remain puzzled after reading this conclusion.</p>
<p>Similarly, for the second part of the conclusion, i.e., &quot;including an extensive set of bilateral brain regions beyond the classical fronto-temporal language system, which sheds light on the distributed nature of language processing in the brain.&quot;</p>
<p>
The more extensive cortical activation may be attributed to the spatial resolution of MEG, and it is quite well acknowledged that language processing is quite distributive in the brain.</p>
<p>The authors should also discuss:</p>
<p>(1) individual differences (whether the BERT representation is a good enough approximation of the mental representation of individual listeners).</p>
<p>(2) parallel parsing (I think the framework here should allow the brain to maintain parallel representations of different syntactic structures but the analysis does not consider parallel representations).</p>
</body>
</sub-article>
</article>