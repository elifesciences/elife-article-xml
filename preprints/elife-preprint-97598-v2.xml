<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">97598</article-id>
<article-id pub-id-type="doi">10.7554/eLife.97598</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.97598.2</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.5</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Noisy neuronal populations effectively encode sound localization in the dorsal inferior colliculus of awake mice</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0116-6892</contrib-id>
<name>
<surname>Boffi</surname>
<given-names>Juan C</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
<email>juan.boffi@embl.de</email>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Bathellier</surname>
<given-names>Brice</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3396-1935</contrib-id>
<name>
<surname>Asari</surname>
<given-names>Hiroki</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3366-4703</contrib-id>
<name>
<surname>Prevedel</surname>
<given-names>Robert</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="aff" rid="a5">5</xref>
<xref ref-type="aff" rid="a6">6</xref>
<email>prevedel@embl.de</email>
</contrib>
<aff id="a1"><label>1</label><institution>Cell Biology and Biophysics Unit, European Molecular Biology Laboratory</institution>, <city>Heidelberg</city>, <country>Germany</country></aff>
<aff id="a2"><label>2</label><institution>Institut Pasteur, Université Paris-Cité, INSERM, Institut de l’Audition</institution>, <city>Paris</city>, <country>France</country></aff>
<aff id="a3"><label>3</label><institution>Epigenetics and Neurobiology Unit, European Molecular Biology Laboratory</institution>, <city>Monterotondo</city>, <country>Italy</country></aff>
<aff id="a4"><label>4</label><institution>Developmental Biology Unit, European Molecular Biology Laboratory</institution>, <city>Heidelberg</city>, <country>Germany</country></aff>
<aff id="a5"><label>5</label><institution>Molecular Medicine Partnership Unit, European Molecular Biology Laboratory</institution>, <city>Heidelberg</city>, <country>Germany</country></aff>
<aff id="a6"><label>6</label><institution>Interdisciplinary Center for Neurosciences, Heidelberg University</institution>, <city>Heidelberg</city>, <country>Germany</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Petreanu</surname>
<given-names>Leopoldo</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Champalimaud Center for the Unknown</institution>
</institution-wrap>
<city>Lisbon</city>
<country>Portugal</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Shinn-Cunningham</surname>
<given-names>Barbara G</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Carnegie Mellon University</institution>
</institution-wrap>
<city>Pittsburgh</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<pub-date date-type="original-publication" iso-8601-date="2024-06-17">
<day>17</day>
<month>06</month>
<year>2024</year>
</pub-date>
<pub-date date-type="update" iso-8601-date="2024-10-22">
<day>22</day>
<month>10</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP97598</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-03-19">
<day>19</day>
<month>03</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-03-01">
<day>01</day>
<month>03</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.08.19.504510"/>
</event>
<event>
<event-desc>Reviewed preprint v1</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2024-06-17">
<day>17</day>
<month>06</month>
<year>2024</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.97598.1"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.97598.1.sa3">eLife assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.97598.1.sa2">Reviewer #1 (Public Review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.97598.1.sa1">Reviewer #2 (Public Review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.97598.1.sa0">Reviewer #3 (Public Review):</self-uri>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Boffi et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Boffi et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-97598-v2.pdf"/>
<abstract>
<title>Abstract</title><p>Sound location coding has been extensively studied at the central nucleus of the mammalian inferior colliculus (CNIC), supporting a population code. However, this population code has not been extensively characterized on the single-trial level with simultaneous recordings or at other anatomical regions like the dorsal cortex of inferior colliculus (DCIC), which is relevant for learning-induced experience dependent plasticity. To address these knowledge gaps, here we made in two complementary ways large-scale recordings of DCIC populations from awake mice in response to sounds delivered from 13 different frontal horizontal locations (azimuths): volumetric two-photon calcium imaging with ∼700 cells simultaneously recorded at a relatively low temporal resolution, and high-density single-unit extracellular recordings with ∼20 cells simultaneously recorded at a high temporal resolution. Independent of the method, the recorded DCIC population responses revealed substantial trial-to-trial variation (neuronal noise) which was significantly correlated across pairs of neurons (noise correlations) in the passively listening condition. Nevertheless, decoding analysis supported that these noisy response patterns encode sound location on the single-trial basis, reaching errors that match the discrimination ability of mice. The detected noise correlations contributed to minimize the error of the DCIC population code of sound azimuth. Altogether these findings point out that DCIC can encode sound location in a similar format to what has been proposed for CNIC, opening exciting questions about how noise correlations could shape this code in the context of cortico-collicular input and experience dependent plasticity.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>Volumetric calcium imaging</kwd>
<kwd>neuropixels</kwd>
<kwd>inferior colliculus</kwd>
<kwd>DCIC</kwd>
<kwd>sound location</kwd>
<kwd>population code</kwd>
<kwd>noise correlations</kwd>
</kwd-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Small modifications to the text addressing reviewer comments and suggestions.</p></fn>
</fn-group>
<fn-group content-type="external-links">
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://www.ebi.ac.uk/biostudies/bioimages/studies/S-BIAD1064">https://www.ebi.ac.uk/biostudies/bioimages/studies/S-BIAD1064</ext-link>
</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Locating a sound source facilitates essential behaviors such as foraging, mating and predator avoidance, thanks to the omni-directionality and long reach of the auditory system (<xref ref-type="bibr" rid="c35">King et al., 2001</xref>). In vertebrates, sound localization relies on both binaural cues such as interaural level and time differences (ILD, ITD) (<xref ref-type="bibr" rid="c36">Knudsen and Konishi, 1979</xref>) and monaural cues including spectral notches (SN) (<xref ref-type="bibr" rid="c38">Kulkarni and Colburn, 1998</xref>). These sound localization cues are processed independently at brainstem nuclei in the ascending auditory pathway and integrated altogether for the first time at the inferior colliculus (IC) (<xref ref-type="bibr" rid="c1">Adams, 1979</xref>; <xref ref-type="bibr" rid="c9">Brunso-Bechtold et al., 1981</xref>; <xref ref-type="bibr" rid="c22">Felix et al., 2018</xref>; <xref ref-type="bibr" rid="c27">Grothe et al., 2010</xref>). This makes the IC a crucial early relay of the ascending auditory pathway to study how a primary neural representation of auditory space is formed (<xref ref-type="bibr" rid="c22">Felix et al., 2018</xref>; <xref ref-type="bibr" rid="c27">Grothe et al., 2010</xref>). Furthermore, the IC is also targeted by cortico-fugal interactions involved in higher order functions concerning sound localization information like experience dependent plasticity (<xref ref-type="bibr" rid="c4">Bajo et al., 2019</xref>, <xref ref-type="bibr" rid="c5">2010</xref>; <xref ref-type="bibr" rid="c3">Bajo and King, 2012</xref>), supporting that IC plays a complex part in the sound localization processing network, contributing from primary representation to shaping behavior.</p>
<p>Previous studies involving extracellular recordings from the mammalian IC revealed that average responses from IC neurons were tuned to multiple sound location cues, evidencing the integration of such cues at IC (<xref ref-type="bibr" rid="c11">Chase and Young, 2005</xref>). However, the amount of sound location information carried by individual neurons throughout the auditory pathway is limited and quite variable, suggesting that the sound location information is distributed into a population code for auditory space (<xref ref-type="bibr" rid="c13">Clarey et al., 1995</xref>; <xref ref-type="bibr" rid="c17">Day and Delgutte, 2016</xref>; <xref ref-type="bibr" rid="c26">Groh et al., 2003</xref>; <xref ref-type="bibr" rid="c46">Panniello et al., 2018</xref>). Fundamental work by <xref ref-type="bibr" rid="c18">Day and Delgutte (2013)</xref> supports that sound location in the horizontal plane (azimuth) is represented at the mammalian IC by the activity patterns of populations of neurons that display average response tuning to azimuth, while ruling out other possibilities such as a topological code, an opposing two channel model or a population vector code (<xref ref-type="bibr" rid="c24">Georgopoulos et al., 1986</xref>, <xref ref-type="bibr" rid="c23">1982</xref>). Nevertheless, this knowledge stems from prospective IC population activity patterns that were approximated by pooling non-simultaneous extracellular recordings and relied on extensive resampling of the pooled recordings to increase the number of “virtual” trials analyzed. Therefore, it remains an open question whether the actual activity patterns occurring in the IC of awake animals during single-trials can encode sound location given emerging properties such as correlated neuronal noise (<xref ref-type="bibr" rid="c2">Averbeck et al., 2006</xref>; <xref ref-type="bibr" rid="c37">Kohn et al., 2016</xref>; <xref ref-type="bibr" rid="c53">Sadeghi et al., 2019</xref>). Trial-to-trial response variability (neuronal noise) and neuronal noise correlation can have a profound impact on the neural representations of sensory information, but this can only be determined through simultaneous large-scale recordings (<xref ref-type="bibr" rid="c2">Averbeck et al., 2006</xref>; <xref ref-type="bibr" rid="c37">Kohn et al., 2016</xref>). Finally, traditional microelectrode recordings were mostly performed at a relatively deep anatomical subdivision of IC (central nucleus, CNIC), usually not targeting superficial regions (dorsal cortex, DCIC; external cortex, ECIC) (<xref ref-type="bibr" rid="c10">Chase and Young, 2008</xref>, <xref ref-type="bibr" rid="c11">2005</xref>; <xref ref-type="bibr" rid="c18">Day and Delgutte, 2013</xref>; <xref ref-type="bibr" rid="c29">Guo et al., 2016</xref>; <xref ref-type="bibr" rid="c40">Lesica et al., 2010</xref>; <xref ref-type="bibr" rid="c55">Schnupp and King, 1997</xref>). To overcome these limitations and explore the importance of trial-to-trial response variability, noise correlation and dorsal IC populations on sound location coding, we monitored DCIC population response patterns on the single-trial basis and interrogated the population code for sound location at the DCIC from passively listening awake mice.</p>
<p>Recent technical developments, including multichannel silicon probes (<xref ref-type="bibr" rid="c34">Jun et al., 2017</xref>) and fast volumetric Ca<sup>2+</sup> imaging (<xref ref-type="bibr" rid="c50">Prevedel et al., 2016</xref>; <xref ref-type="bibr" rid="c58">Stringer et al., 2019</xref>; <xref ref-type="bibr" rid="c61">Weisenburger et al., 2019</xref>) enable routine simultaneous recordings from large numbers of neurons <italic>in vivo</italic>. Beyond their high throughput, volumetric methods are also a promising approach to precisely interrogate the topological distribution of neurons sensitive to sound azimuth, which has been reported to be random at CNIC (<xref ref-type="bibr" rid="c18">Day and Delgutte, 2013</xref>), but is understudied at DCIC. In this work, we implemented scanned temporal focusing two-photon microscopy (sTeFo 2P) (<xref ref-type="bibr" rid="c50">Prevedel et al., 2016</xref>), an advanced volumetric Ca<sup>2+</sup> imaging modality, to simultaneously record the activity of unprecedentedly large DCIC populations. Here we refer to DCIC as the dorsomedial IC region covering CNIC (<xref ref-type="bibr" rid="c64">Zhou and Shore, 2006</xref>). Our approach produced direct evidence supporting that the response patterns from mammalian DCIC populations effectively encode sound location on the single-trial basis in spite of their variability across trials. We also detected the occurrence of substantial noise correlations which can contribute to reducing the error of this population code. Furthermore, we complemented our imaging results with electrophysiological recordings with neuropixels probes (<xref ref-type="bibr" rid="c34">Jun et al., 2017</xref>), reaching conclusions that were generally aligned across imaging and electrophysiological experiments. Altogether, our findings point to a functional role of DCIC in sound location coding following a similar population coding mechanism to what has been proposed for CNIC (<xref ref-type="bibr" rid="c18">Day and Delgutte, 2013</xref>). While CNIC is the main ascending relay carrying sound location information from brainstem auditory nuclei to the cortex through the auditory thalamus (<xref ref-type="bibr" rid="c1">Adams, 1979</xref>; <xref ref-type="bibr" rid="c9">Brunso-Bechtold et al., 1981</xref>; <xref ref-type="bibr" rid="c22">Felix et al., 2018</xref>), DCIC is a higher order relay receiving profuse descending corticofugal inputs influencing auditory information processing including sound location (<xref ref-type="bibr" rid="c4">Bajo et al., 2019</xref>, <xref ref-type="bibr" rid="c5">2010</xref>; <xref ref-type="bibr" rid="c3">Bajo and King, 2012</xref>; <xref ref-type="bibr" rid="c41">Lesicko et al., 2022</xref>; <xref ref-type="bibr" rid="c62">Winer et al., 2002</xref>). This knowledge sets forth exciting possibilities about the mechanisms by which cortico-collicular interactions involving DCIC and perhaps noise correlations affect relevant processes involving sound location information like experience dependent plasticity (<xref ref-type="bibr" rid="c4">Bajo et al., 2019</xref>, <xref ref-type="bibr" rid="c5">2010</xref>; <xref ref-type="bibr" rid="c3">Bajo and King, 2012</xref>).</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Simultaneous recordings of DCIC population activity</title>
<p>Since the abundance and distribution of sound localization sensitive neurons at DCIC is not fully characterized, in a first instance we implemented sTeFo 2P for volumetric Ca<sup>2+</sup> imaging to simultaneously record the activity from samples of DCIC neurons as large as technically possible. Moreover, TeFo based methods have been shown to be more resilient to highly scattering (optically opaque) tissues such as the IC (<xref ref-type="bibr" rid="c16">Dana and Shoham, 2012</xref>). Adeno-associated viral vector (AAV) transduced IC neurons expressing jRGECO1a (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>) were imaged through a cranial window in awake head-fixed mice, passively listening to 500 ms-long broad-band noise stimuli (20-40 kHz band-passed white noise) delivered by a motorized speaker every 5 s located at one of 13 different frontal azimuth angles in a random order covering the frontal hemifield in 15° steps (<xref rid="fig1" ref-type="fig">Fig. 1B</xref>). We performed volumetric Ca<sup>2+</sup> imaging (4 Hz volume rate) simultaneously sampling the activity of up to 2535 (643 ± 427, median ± median absolute deviation, n = 12 mice) regions-of-interest (ROIs) that had a shape and size consistent with an IC neuronal soma (12-30μm diameter, <xref rid="figs1" ref-type="fig">Suppl. Fig. 1A</xref>) (<xref ref-type="bibr" rid="c56">Schofield and Beebe, 2019</xref>), within a 470x470x500 µm volume from the right IC unilaterally, covering most of the dorso-ventral span of the anterior DCIC (<xref rid="fig1" ref-type="fig">Fig. 1A-C</xref>) and perhaps reaching the upper surface of CNIC below DCIC at more posterior locations (<xref ref-type="bibr" rid="c48">Paxinos and Franklin, 2001</xref>). Since sTeFo 2P trades off spatial resolution for acquisition speed to produce volume rates compatible with the kinetics of Ca<sup>2+</sup> sensors (voxel size: 3.7x3.7x15 μm) (<xref ref-type="bibr" rid="c50">Prevedel et al., 2016</xref>), we could not resolve fine spatial features of neurons such as dendrites or synaptic structures like spines in our images to unequivocally identify the segmented ROIs as individual neurons (<xref rid="figs1" ref-type="fig">Suppl. Fig. 1A</xref>). For this reason, we refer to these ROIs as “Units”, in an analogous fashion to extracellular electrode recordings studies. To compensate for the relatively slow decay time of the Ca<sup>2+</sup> indicator signal and non-linearities in the summation of Ca<sup>2+</sup> events, we evaluated the spike probabilities associated to the neuronal Ca<sup>2+</sup> signals (<xref ref-type="bibr" rid="c21">Deneux et al., 2016</xref>) (<xref rid="fig1" ref-type="fig">Fig. 1D</xref>, <xref rid="figs1" ref-type="fig">Suppl. Fig. 1B</xref>). The spike probability estimation does not involve predicting precise spike timings (<xref ref-type="bibr" rid="c21">Deneux et al., 2016</xref>; <xref ref-type="bibr" rid="c31">Huang et al., 2021</xref>; <xref ref-type="bibr" rid="c45">Pachitariu et al., 2018</xref>; <xref ref-type="bibr" rid="c52">Rupprecht et al., 2021</xref>; <xref ref-type="bibr" rid="c59">Vanwalleghem et al., 2021</xref>). Hence, we do not make any observation or interpretation of spike probabilities in relation to the fine temporal structure of neuronal spiking. Instead, we treated the spike probabilities as a measure proportional to the spike count evaluated within the time interval set by our volumetric imaging rate (4 Hz). Taking into account that the main carrier of sound location information is IC neuron firing rate (<xref ref-type="bibr" rid="c10">Chase and Young, 2008</xref>), we defined the evoked DCIC population responses as the total (summed) spike probability of each imaged unit during the sound stimulation epoch (500 ms). In this way, we systematically collected the simultaneous response patterns of DCIC populations to every azimuth trial.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Simultaneous recording of DCIC population responses to sound azimuth through sTeFo-2P Ca<sup>2+</sup> imaging and neuropixels probes.</title>
<p>A) Representative histological section showing AAV transduced jRGECO1a expression across IC. Middle panel inset: Contrast enhanced commissure region of the slice to visualize commissural projections from jRGECO1a expressing IC neurons. Bottom panel: Dotted lines delimit anatomical IC regions according to Paxinos et al. (2001); dashed lines delimit approximate area targeted for imaging. Scale bar: 200μm. DCIC: dorsal cortex from inferior colliculus. CNIC: Central nucleus from inferior colliculus. ECIC: External cortex from inferior colliculus. Com.: Commissure from inferior colliculus. B) Schematic representation of the experimental design, incorporating sTeFo 2P for Ca<sup>2+</sup> imaging. C) Neuropil-corrected and denoised jRGECO1a signals extracted from a representative full dataset. Extracted signals are arranged from dorsal (top) to ventral (bottom) ROI position across the DCIC volume imaged. D) Representative neuropil corrected and denoised jRGECO1a traces (blue) with their corresponding spike probability traces (gray) and stimulation epochs (color-coded based on stimulus azimuth angle according to (B)) super-imposed. E) Representative simultaneous recording of a DCIC population from an awake, passively listening mouse, displaying spontaneous, on-going activity (not synchronized to stimulation, arrowheads) and variable sound-evoked response patterns (during sound stimuli). Top trace is the population average response. Sound stimulation epochs are color-coded based on azimuth. F) Representative histological section showing DiI labeled neuropixels electrode tract across IC. Dotted lines delimit anatomical IC regions according to Paxinos et al. (2001). Scale bar: 500μm. G) Same as (B) but representing integration with electrophysiological recording of DCIC population activity with a neuropixels probe. H) Representative high pass filtered (&gt; 300 Hz) voltage traces simultaneously recorded from 100 channels spanning across DCIC in a neuropixels probe shank during an experiment displaying clear unit waveforms captured across neighbouring channels. I) Same as (E) but showing a representative raster plot of the spike sorted DCIC single-unit activity simultaneously recorded during an experiment.</p></caption>
<graphic xlink:href="504510v5_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>The DCIC populations simultaneously imaged from passively listening awake mice displayed spontaneous activity that was not time-locked to the stimulation (on-going activity) and sound-evoked response patterns that varied markedly across trials, as did the overall, average response of the complete imaged population (<xref rid="fig1" ref-type="fig">Fig. 1E</xref>). By monitoring face movements videographically, we observed that the overall average population activity shows significant correlation to facial movements, specifically of the snout region (<xref rid="figs2" ref-type="fig">Suppl. Fig 2A-C</xref>). On the other hand, the correlation between the recorded activity from the individual units imaged and face movements was generally low with narrow distributions centered at 0 (<xref rid="figs2" ref-type="fig">Suppl. Fig 2D</xref>), pointing out that correlation to face movement is more evident at the population level.</p>
<p>To further corroborate our volumetric imaging data, we recorded DCIC population activity electrophysiologically through single-unit recordings with neuropixels probes in passively listening mice stimulated with 200 ms-long broad-band noise stimuli (15-50 kHz band-passed white noise) delivered by a motorized speaker every 3 s from 13 different frontal azimuth angles in a random order covering the frontal hemifield in 15° steps (<xref rid="fig1" ref-type="fig">Fig. 1F-H</xref>). The higher time resolution from the electrophysiological approach (30kHz acquisition rate) allowed us to deliver more frequent trials with shorter stimuli to effectively collect more trials following the same head fixation paradigm as the one used for imaging (see methods). The electrophysiology setup also produced lower background noise sound pressure level (SPL, 35.96 dB R.M.S.) in comparison to the sTeFo scope (44.83 dB R.M.S.), which enabled the use of a broader band stimulus favoring sound location cues at appropriate levels above background noise (at least 10 dB R.M.S., see methods). We simultaneously recorded up to 43 (21 ± 9, median ± median absolute deviation, n = 4 mice) spike sorted and manually curated DCIC single-units (<xref rid="figs1" ref-type="fig">Suppl. Fig. 1C-E</xref>). We defined sound evoked responses from electrophysiologically recorded single-units as the spike count observed during sound stimulus presentation (<xref ref-type="bibr" rid="c10">Chase and Young, 2008</xref>; <xref ref-type="bibr" rid="c17">Day and Delgutte, 2016</xref>, <xref ref-type="bibr" rid="c18">2013</xref>). We determined which recording channels from the probe were located within DCIC both histologically with respect to the reference atlas (<xref ref-type="bibr" rid="c48">Paxinos and Franklin, 2001</xref>) (<xref rid="fig1" ref-type="fig">Fig. 1F</xref>) and functionally by analyzing the arrangement of sound frequency sensitive units along the shank of the probe. We detected sound frequency sensitive single-units as units that displayed significant response dependency to sound frequency (pure tone stimuli) through χ<sup>2</sup> tests. The detected frequency dependent single-units displayed Gaussian tuning with clear peak best frequencies (<xref rid="figs1" ref-type="fig">Suppl. Fig. 1F, G</xref>). The observed relationship between frequency dependent DCIC unit best frequency and recording depth was not tonotopically arranged like in CNIC, which is consistent with DCIC location (<xref ref-type="bibr" rid="c6">Barnstedt et al., 2015</xref>; <xref ref-type="bibr" rid="c63">Wong and Borst, 2019</xref>) (<xref rid="figs1" ref-type="fig">Suppl. Fig. 1H</xref>). The simultaneous, electrophysiologically recorded DCIC population activity from awake passively listening mice also displayed spontaneous on-going activity, which reflected in the overall average response of the complete recorded population, and sound-evoked response patterns that varied markedly across trials (<xref rid="fig1" ref-type="fig">Fig. 1I</xref>). In this section we used the word “noise” to refer to the sound stimuli used, the recording setup background sound levels or recording noise in the acquired signals. To avoid confusion, from now on the word “noise” will be used in the context of neuronal noise, which is the trial-to-trial variation in neuronal responses unrelated to stimuli, unless otherwise noted.</p>
</sec>
<sec id="s2b">
<title>Decoding sound azimuth from single-trial DCIC population responses</title>
<p>The observed variability in our imaging and electrophysiological data raised the following question: To what extent do the single-trial responses of the DCIC units carry information about stimulus azimuth? Since the number of DCIC neurons needed to effectively encode sound azimuth is not known, we first evaluated how accurately stimulus azimuth can be predicted from the high throughput single-trial DCIC population response patterns volumetrically imaged, without taking resampling strategies or pooling recorded responses across animals or recording sessions as in previous electrophysiological and imaging studies (<xref ref-type="bibr" rid="c18">Day and Delgutte, 2013</xref>; <xref ref-type="bibr" rid="c32">Jazayeri and Movshon, 2006</xref>; <xref ref-type="bibr" rid="c46">Panniello et al., 2018</xref>). We performed cross-validated, multi-class classification of the single-trial population responses (decoding, <xref rid="fig2" ref-type="fig">Fig. 2A</xref>) using a naive Bayes classifier to evaluate the prediction errors as the absolute difference between the stimulus azimuth and the predicted azimuth (<xref rid="fig2" ref-type="fig">Fig. 2A</xref>). We chose this classification algorithm over others due to its generally good performance with limited available data. We visualized the cross-validated prediction error distribution in cumulative plots where the observed prediction errors were compared to the distribution of errors for random azimuth sampling (<xref rid="fig2" ref-type="fig">Fig. 2B</xref>). When decoding all simultaneously recorded units, the observed classifier output was not significantly better (shifted towards smaller prediction errors) than the chance level distribution (<xref rid="fig2" ref-type="fig">Fig. 2B</xref>). The classifier also failed to decode complete DCIC population responses recorded with neuropixels probes (<xref rid="fig3" ref-type="fig">Fig. 3A</xref>). Given the high dimensionality of our datasets (number of simultaneously recorded units) and the relatively low number of azimuth presentations collected (10-20 repetitions of each), we reasoned that the classification failure could be due to overfitting rather than to a lack of azimuth information in the dataset. Thus, we tested if reducing the dimension of the dataset helps avoid overfitting. Specifically, we used the same decoder after dimensionality reduction through principal component analysis (PCA) with both PCA and classifier fit being cross-validated (<xref rid="fig2" ref-type="fig">Fig. 2C</xref>). For both our imaging and electrophysiological datasets, we observed that decoding based on subsets of first principal components (PCs) produced absolute cross-validated single-trial prediction error distributions significantly better than the chance level distribution (<xref rid="fig2" ref-type="fig">Fig. 2</xref> D, E, <xref rid="fig3" ref-type="fig">Fig. 3</xref> B-D); and that using larger numbers of PCs for model fitting and decoding decreased the performance (<xref rid="fig2" ref-type="fig">Fig. 2D</xref>, E, <xref rid="fig3" ref-type="fig">Fig. 3C</xref>, D). Altogether, these results support that DCIC population responses indeed carry stimulus azimuth information which can be effectively decoded on a single-trial basis; and that the failure of decoding from the full population was merely due to overfitting.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Decoding single-trial DCIC population responses to sound azimuth.</title>
<p>A) Schematic representation of the decoding strategy using multi-class classification on the recorded simultaneous population responses. B) Cumulative distribution plots of the absolute cross-validated single-trial prediction errors obtained using naive Bayes classification (blue) and chance level distribution associated with our stimulation paradigm obtained by considering all possible prediction errors for the 13 azimuths tested (gray). K.S.: Kolmogorov-Smirnov test, n.s.: (p &gt; 0.05). C) Schematic representation of the decoding strategy using the first PCs of the recorded population responses. Inset: % of explained variance obtained using PCA for dimensionality reduction on the complete population responses. Median (blue line) and median absolute deviation (shaded blue area) are plotted for (n = 12 mice/imaging sessions). D) Same as (B) but for decoding different numbers of first PCs from the recorded complete population responses. E) Significance of classification performance with respect to chance level for different numbers of first PCs, determined via Kolmogorov-Smirnov tests with Sidak correction for multiple comparisons. Arrowhead indicates model loss of performance associated with fitting more parameters for a larger feature space (# PCs) with the same dataset size (# trials collected).</p></caption>
<graphic xlink:href="504510v5_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3:</label>
<caption><p>A) Cumulative distribution plots of the absolute cross-validated single-trial prediction errors obtained decoding the complete simultaneously recorded population responses with neuropixels probes across mice (blue) and chance level distribution associated with our stimulation paradigm (gray). K.S.: Kolmogorov-Smirnov test, n.s.: (p &gt; 0.05). B) % of observed variance explained across PC number for the complete population responses recorded with neuropixels. Median (blue line) and median absolute deviation (shaded blue area) are plotted for n = 4 mice. C) Same as (A) but for decoding different numbers of first PCs. D) Significance of decoding performance shown in (C) with respect to chance level for different numbers of first PCs, determined via Kolmogorov-Smirnov tests with Sidak correction for multiple comparisons. Shaded areas show the corresponding median decoding errors to the points within the area.</p></caption>
<graphic xlink:href="504510v5_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2c">
<title>Sound azimuth information is carried redundantly by specific DCIC units</title>
<p>The decoded PCs consist of linear combinations of the responses from the units in the imaged or recorded DCIC population. Then the following questions arise: To what extent is the sound azimuth information distributed across the DCIC populations? Is it fully distributed across most units or specific to some of them, such as azimuth tuned neurons?</p>
<p>Since the abundance or distribution of azimuth sensitive units across DCIC is not fully known, we firstly asked if any fraction of the volumetrically imaged DCIC units carried more azimuth information in their responses than other simultaneously imaged units in the volume. We calculated the signal-to-noise ratio for the responses of each imaged unit (“neuronal” S/N, nS/N), defined as the ratio between the mean (signal) and the standard deviation (noise) of the responses to the azimuth trials evoking maximal responses (best azimuth). Imaged DCIC units generally showed a relatively low nS/N during sound stimulations (&lt; 1, <xref rid="fig4" ref-type="fig">Fig. 4A</xref>). Nevertheless, this nS/N was significantly larger than the one registered in the absence of sound stimulation (on-going activity from the periods between sound stimuli, <xref rid="fig1" ref-type="fig">Fig. 1D</xref>, 4A), indicating that sound responses across the sampled units were often noisy. However, the broad distribution of nS/N also suggested that a sparse population of neurons responded more robustly. Next, we evaluated azimuth tuning to delimit subpopulations with higher azimuth selectivity. Using non-parametric one-way ANOVA (Kruskal-Wallis test), we identified the imaged units whose median responses changed significantly based on stimulus azimuth, which we defined as azimuth tuned units (<xref rid="fig4" ref-type="fig">Fig. 4B</xref>). The units with significant azimuth tuning represented only 8 ± 3% (median ± median absolute deviation, n = 12 mice) of the DCIC units simultaneously-imaged in one session (mouse; <xref rid="fig4" ref-type="fig">Fig. 4C</xref>). This is not significantly different from the false positive detection rate of our ANOVA tests (α = 0.05, <xref rid="fig4" ref-type="fig">Fig. 4C</xref>). Given that a large number of trials showed no response at all in many units, it is possible that the large trial-to-trial variability in the imaged DCIC responses made it difficult to detect response specificity based on differences in median activity. We thus employed more sensitive χ<sup>2</sup> tests to determine the statistical dependence between the recorded DCIC responses and presented stimulus azimuth. We then ranked the units in our simultaneously imaged samples based on the p-value of the χ<sup>2</sup> tests (<xref rid="fig4" ref-type="fig">Fig. 4D</xref>) to delimit subsamples of DCIC units showing the strongest azimuth-dependent responses. The units with significant response dependency to stimulus azimuth (p &lt; 0.05) represented 32 ± 6% (median ± median absolute deviation, n = 12 mice) of the units simultaneously-imaged in one session (mouse, <xref rid="fig4" ref-type="fig">Fig. 4E</xref>). Even the top ranked units typically did not respond in many trials; nevertheless, their evoked responses showed a tendency to be more selective towards contralateral or central stimulus azimuths (<xref rid="fig4" ref-type="fig">Fig. 4D</xref> left inset). The nS/N of top ranked units was also significantly larger than the one registered in the absence of sound stimulation, but these units did not display a major improvement in nS/N with respect to the complete population of imaged units, indicating that despite their response dependency to stimulus azimuth their responses are also noisy (<xref rid="fig4" ref-type="fig">Fig. 4A, D</xref> right inset).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4:</label>
<caption><title>Sound azimuth information is carried by specific units from the imaged DCIC populations.</title>
<p>A) Histogram of the nS/N ratios from the recorded units across mice during sound stimulation or during the inter trial periods without sound stimulation (on going). B) Representative stimulus azimuth tuning curves from units with significant median response tuning detected using non-parametric one way ANOVA (Kruskal-Wallis test). Median and absolute median deviation are plotted. The imaging depth from the corresponding units is displayed in gray. Azimuth selectivity is color-coded based on <xref rid="fig1" ref-type="fig">Fig. 1B</xref>. C) Percentage of the simultaneously recorded units across mice that showed significant median response tuning, compared to false positive detection rate (α = 0.05, chance level). D) Response dependency to stimulus azimuth, determined via χ<sup>2</sup> tests (see methods), for simultaneously recorded units ranked in descending order of significance. Left inset: Representative responses from the top ranked 7 units with significant response dependency to stimulus azimuth. Response amplitudes are displayed with a continuous trace for visualization purposes, the displayed response order was sorted as a function of stimulus azimuth and does not represent the experimental stimulus delivery order (random). Right inset: Same as (A) but for the subset of units displaying response dependency to stimulus azimuth. E) Percentage of the simultaneously recorded units across mice that showed significant response dependency to stimulus azimuth, compared to false positive detection rate (α = 0.05, chance level). F) Schematic representation of the decoding strategy using the top ranked units from the recorded population responses. G) Top: Cumulative distribution plot of the absolute cross-validated single-trial prediction errors obtained with a Bayes classifier (N. Bayes, naive approximation for computation efficiency). The number of top ranked units considered for decoding their simultaneously recorded single-trial population response patterns is color coded from cyan (4 top ranked units) to purple (10 top ranked units) and the chance level distribution associated to our stimulation paradigm, obtained by considering all possible prediction errors for the 13 azimuths tested, is displayed in gray. Bottom: Significance of classification performance with respect to chance level for 4 to 30 decoded top ranked units, determined via Kolmogorov-Smirnov tests with Sidak correction for multiple comparisons. Arrowhead indicates model loss of performance associated with fitting more parameters for a larger feature space (# units) with the same dataset size (# trials collected).</p></caption>
<graphic xlink:href="504510v5_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>To test if the single-trial response patterns from simultaneously imaged units with top response dependency to stimulus azimuth carry enough information to generate better azimuth predictions than the ones observed with the complete samples (<xref rid="fig2" ref-type="fig">Fig. 2</xref>), we evaluated the prediction errors obtained by decoding them. In doing so, we cross-validated both unit ranking based on response dependency (feature selection) and decoder fit (<xref rid="fig4" ref-type="fig">Fig. 4F</xref>). From this point on, we will refer to groups of units showing maximum response dependency to stimulus azimuth as “top ranked units”. To evaluate the minimum number of top ranked units necessary to generate stimulus azimuth predictions significantly better than the chance level, we decoded different sized subsamples of these units. We found that the single-trial response patterns of at least the 7 top ranked units produced stimulus azimuth prediction errors that were significantly smaller than chance level (p = 6 x 10<sup>-4</sup>, Kolmogorov-Smirnov with Sidak) using Bayes classification (naive approximation, for computation efficiency) (<xref rid="fig4" ref-type="fig">Fig 4G</xref>). Increasing the number of top ranked units decoded did not bring major improvements in decoder performance (plateau), up to a point where performance dropped, due to classifier overfitting likely caused by the relatively small number of collected trials per class (<xref rid="fig4" ref-type="fig">Fig 4G</xref>, bottom). If we consider the median of the prediction error distribution as an overall measure of decoding performance, the single-trial response patterns from subsamples of at least the 7 top ranked units produced median decoding errors that coincidentally matched the reported azimuth discrimination ability of mice (<xref rid="fig4" ref-type="fig">Fig 4G</xref>, minimum audible angle = 31°) (<xref ref-type="bibr" rid="c39">Lauer et al., 2011</xref>).</p>
<p>To further characterize the identified top ranked units, we studied how they are distributed across the imaged DCIC volume, which was positioned roughly at the center from the surface of the mouse dorsal IC (<xref rid="fig1" ref-type="fig">Fig. 1A, B</xref>). By comparing the positions of top ranked units to those of the complete samples of simultaneously imaged units across mice, we observed that the top ranked units (∼32% from the complete DCIC populations imaged) are scattered across the imaged volumes following the same distributions across the anatomical axes of the complete imaged populations (<xref rid="figs3" ref-type="fig">Suppl. Fig. 3</xref>). This observation suggests that the subpopulations of top ranked DCIC units associated with the population code of sound azimuth scatter across the DCIC without following a specific spatial pattern. We observed a tendency for a small shift towards positive correlations in the correlation coefficient distribution between snout movement and the imaged activity of individual top ranked units, however this distribution was narrow and centered close to 0 (<xref rid="figs2" ref-type="fig">Suppl. Fig. 2E</xref>).</p>
<p>The observed broad distribution across DCIC and the relatively small number of top ranked units necessary to decode stimulus azimuth supports the characterization of this subpopulation with neuropixels data. Top ranked units detected in our neuropixels datasets also displayed response selectivity towards contralateral and central azimuths and did not respond in many trials (<xref rid="fig5" ref-type="fig">Fig. 5</xref> A, B). The nS/N of the DCIC single-units recorded with neuropixels was again significantly larger than the one registered without sound stimulation, with a distribution tailing above 1. Top ranked units displayed a further shift towards higher nS/N with respect to the complete population of neuropixels recorded DCIC single-units. Still the medians of these nS/N distributions was below 1, supporting that DCIC single-unit responses are noisy (<xref rid="fig5" ref-type="fig">Fig. 5C</xref>). Top ranked units detected with neuropixels recordings represented 40 ± 2 % (median ± median absolute deviation, n = 4 mice) of the units simultaneously-recorded in an experiment (mouse, <xref rid="fig5" ref-type="fig">Fig. 5D</xref>).</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5:</label>
<caption><title>Neuropixels recordings support observations drawn from sTeFo 2P Ca<sup>2+</sup> imaging experiments.</title>
<p>A) Representative responses to stimulus azimuth of a top ranked unit recorded with neuropixels. Top panels show the peri-stimulus time histograms and the bottom panels show the corresponding spike raster plots across trials. B) Left: Schematic representation of a neuropixels probe shank highlighting in different colors the position from channels where representative top ranked single-units were detected across DCIC (approximated histologically, same units as displayed in <xref rid="figs1" ref-type="fig">Suppl. Fig 1C-E</xref>). Right Representative azimuth tuning curves from three DCIC top ranked single-units recorded with neuropixels, plot colors correspond to position in the shank schematic. Mean and standard deviation are plotted. C) Neuronal signal to noise level (nS/N) histograms from neuropixels recorded DCIC single-units in the absence of sound stimuli (on going activity, gray) and in response to the best azimuth trials, for all collected single-units (blue) and the top ranked single-unit subset (red). D) Percentages of sound azimuth dependent units (top ranked units), sound frequency dependent units and both azimuth and frequency dependent units across mice. Median value across mice is represented by a horizontal line. E) Relationship between azimuth sensitivity and best frequency of DCIC sound frequency and azimuth dependent single-units across mice. Data from n = 4 mice, point color corresponds to the same mouse. X axis scale is logarithmic. F) Cumulative distribution plots of the absolute cross-validated single-trial prediction errors obtained by decoding the responses from different numbers of top ranked units simultaneously recorded with neuropixels probes across mice and chance level distribution associated with our stimulation paradigm (gray). G) Significance of decoding performance shown in (F) with respect to chance level for different numbers of top ranked units decoded, determined via Kolmogorov-Smirnov tests with Sidak correction for multiple comparisons. Shaded areas show the corresponding median decoding errors to the points within the area. Sample sizes (number of mice) is informed at the top of the graph for each point.</p></caption>
<graphic xlink:href="504510v5_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Interestingly, the nS/N distributions of neuropixels recorded DCIC single-units in response to pure tone stimuli were similar to those observed for broadband stimulus azimuth (<xref rid="figs1" ref-type="fig">Suppl. Fig. 1I</xref>, <xref rid="fig5" ref-type="fig">Fig 5C</xref>), suggesting that the observed nS/N levels in our imaging and electrophysiological recordings might be a property of the DCIC network (and not due to the recording method’s sensitivity) which is noisy independently of the stimulus presented, at least in the passively listening condition. The percentage of sound frequency dependent units was 42 ± 15 % (median ± median absolute deviation, n = 4 mice, <xref rid="fig5" ref-type="fig">Fig. 5D</xref>). Out of the DCIC single-units from our neuropixels recordings, 19 ± 6 % (median ± median absolute deviation, n = 4 mice, <xref rid="fig5" ref-type="fig">Fig. 5D</xref>) displayed significant response dependency to both broadband stimulus azimuth and pure tone stimulus frequency, pointing out that not all DCIC azimuth dependent units are sensitive to sound frequency and vice-versa. To explore a possible relationship between the best frequency and azimuth sensitivity of these units in the context of the duplex theory (<xref ref-type="bibr" rid="c51">Rayleigh, 1907</xref>), we evaluated the correlation between their best frequency and the significance level of their response dependency to azimuth (-log(p value) of the χ<sup>2</sup> test). This correlation was low (R = 0.03, 17 single-units from 4 mice), but we could observe that the clear majority of these units had best frequencies above ∼10kHz, where the main sound location cues used by mice are carried (<xref ref-type="bibr" rid="c39">Lauer et al., 2011</xref>) (Fig, 5E).</p>
<p>Decoding analysis (<xref rid="fig4" ref-type="fig">Fig. 4F</xref>) of the population response patterns from azimuth dependent top ranked units simultaneously recorded with neuropixels probes showed that the 4 top ranked units are the smallest subsample necessary to produce a significant decoding performance that coincidentally matches the discrimination ability of mice (31° (<xref ref-type="bibr" rid="c39">Lauer et al., 2011</xref>)) (<xref rid="fig5" ref-type="fig">Fig. 5F, G</xref>). Altogether, the close resemblance of the results obtained through volumetric imaging and electrophysiologically with neuropixels support that, even though noisy DCIC single-units can encode sound location individually with low performance (<xref rid="fig5" ref-type="fig">Fig. 5F, G</xref>, first top ranked unit), a population code consisting of the simultaneous response patterns from small subsets of top ranked units occurs at DCIC, achieving more effective encoding errors.</p>
</sec>
<sec id="s2d">
<title>Noise correlations and their contribution to the population code of sound azimuth at DCIC</title>
<p>We next investigated the occurrence of correlated variation in the trial-to-trial responses to each stimulus azimuth from pairs of simultaneously imaged or electrophysiologically recorded top ranked units as the occurrence of such neuronal noise correlations, which have been previously reported to occur at mammalian IC populations (<xref ref-type="bibr" rid="c53">Sadeghi et al., 2019</xref>), can influence the accuracy of the DCIC population code for sound azimuth (<xref ref-type="bibr" rid="c2">Averbeck et al., 2006</xref>; <xref ref-type="bibr" rid="c37">Kohn et al., 2016</xref>) (<xref rid="fig6" ref-type="fig">Fig. 6A</xref>). We evaluated the Kendall Tau as an unbiased, non-parametric pairwise correlation coefficient for the neuronal noise from all possible pairs of simultaneously recorded DCIC units across trial repetitions for each stimulus azimuth. Using cross-validated hierarchical clustering of the simultaneously imaged or neuropixels recorded top ranked units based on noise correlation, we observed no clear groups (clusters, subpopulations) of highly noise correlated units across the trial repetitions from each stimulus azimuth (<xref rid="fig6" ref-type="fig">Fig. 6B, C</xref>). However, the pairwise noise correlation coefficients observed across datasets (mice) showed a distribution that was significantly shifted towards positive values with respect to chance level, calculated from the same datasets subjected to randomization of each unit’s responses across trial repetitions for each stimulus azimuth (decorrelated, <xref rid="fig6" ref-type="fig">Fig. 6A-C</xref>). Nevertheless, this shift was much smaller for ipsilateral and central azimuths in our neuropixels data (<xref rid="fig6" ref-type="fig">Fig. 6B, C</xref>). Altogether these observations suggest that pairs of the DCIC top ranked units associated with the population code for sound azimuth display positive noise correlations with a likelihood that is higher than chance.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6:</label>
<caption><title>Noise correlations in DCIC population activity contribute to encode sound azimuth.</title>
<p>A) Simplified schematic representation of the possible effects from (positive) noise correlations on the response separability of a theoretical population consisting of 2 units, and within class randomization strategy to model decorrelated datasets lacking noise correlations. B, C) Left top: Representative correlation matrices of pairwise correlations between the responses of top ranked units detected in simultaneous recordings during sound stimuli for representative azimuths. The simultaneously imaged units are sorted in the correlation matrices based on cross validated hierarchical clustering (see methods). Left bottom: Distribution histograms for the pairwise correlation coefficients (Kendall tau) from pairs of simultaneously recorded top ranked units across mice (blue) compared to the chance level distribution obtained through randomization of the temporal structure of each unit’s activity to break correlations (purple). Vertical dashed lines show the medians of these distributions. *: p&lt; 0.05, ***: p &lt; 0.0001, Kolmogorov-Smirnov with Sidak. Right: Cumulative distribution plots of the absolute cross-validated single-trial prediction errors obtained using a Bayes classifier (naive approximation for computation efficiency) to decode the single-trial response patterns from the 6 (neuropixels) or 7 (sTeFo 2P imaging) top ranked units in the simultaneously acquired datasets across mice (cyan), modeled decorrelated datasets (orange) and the chance level distribution associated with our stimulation paradigm (gray).</p></caption>
<graphic xlink:href="504510v5_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>To characterize how the observed positive noise correlations could affect the representation of stimulus azimuth by DCIC top ranked unit population responses, we compared the decoding performance obtained by classifying the single-trial response patterns from top ranked units in the modeled decorrelated datasets versus the acquired data (with noise correlations). With the intention to characterize this with a conservative approach that would be less likely to find a contribution of noise correlations as it assumes response independence, we relied on the naive Bayes classifier for decoding throughout the study. Using this classifier, we observed that the modeled decorrelated datasets produced stimulus azimuth prediction error distributions that were significantly shifted towards higher decoding errors (<xref rid="fig6" ref-type="fig">Fig. 6B, C</xref>) and, in our imaging datasets, were not significantly different from chance level (<xref rid="fig6" ref-type="fig">Fig. 6B</xref>). Altogether, these results suggest that the detected noise correlations in our simultaneously acquired datasets can help reduce the error of the IC population code for sound azimuth.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>By performing fast volumetric Ca<sup>2+</sup> imaging through sTeFo 2P microscopy (<xref ref-type="bibr" rid="c50">Prevedel et al., 2016</xref>) and single-unit recordings with neuropixel probes (<xref ref-type="bibr" rid="c34">Jun et al., 2017</xref>), here we tackled the technical challenge to simultaneously record the activity of a large number of DCIC units in response to sound azimuth. We show that sTeFo 2P effectively achieved high throughput sampling across large imaging depths in a highly light-scattering tissue such as the mouse IC (<xref rid="fig1" ref-type="fig">Fig. 1</xref>), showcasing the capability of sTeFo 2P for interrogating neuronal population activity over large volumes. Despite the advantages of volumetric sTeFo 2P, it also has limitations. In particular, large-scale volumetric imaging has a low temporal resolution, reaching sampling rates of 4 volumes per second, and requires the use of an indirect method of monitoring neuronal activity via Ca<sup>2+</sup> sensors. The low temporal resolution effectively produces a low-pass filtering of neuronal activity, misrepresenting peak responses. Furthermore, indirectly inferring neuronal spiking responses from Ca<sup>2+</sup> sensor signals can cause further information loss. Nevertheless, the main observations drawn from sTeFo 2P imaged population response patterns could be validated via single-unit recordings with new generation multichannel silicon probes (neuropixels), which have excellent temporal resolution but markedly lower throughput. This supports that the sTeFo imaging datasets still carried sufficient information about stimulus azimuth (<xref rid="fig2" ref-type="fig">Fig. 2</xref>, 4), showcasing how sTeFo 2P opens new possibilities for future studies requiring high-throughput recordings of simultaneous population activity, especially considering the advantages brought by further technical improvements such as multiplexing or larger fields of view (<xref ref-type="bibr" rid="c14">Clough et al., 2021</xref>; <xref ref-type="bibr" rid="c20">Demas et al., 2021</xref>; <xref ref-type="bibr" rid="c44">Ota et al., 2021</xref>; <xref ref-type="bibr" rid="c61">Weisenburger et al., 2019</xref>) and 3P excitation (<xref ref-type="bibr" rid="c60">Weisenburger et al., 2017</xref>).</p>
<p>The imaged or electrophysiologically recorded population activity datasets here described support with simultaneous recordings that the single-trial response patterns from subsets of neurons with response dependency to stimulus azimuth (top ranked units) constitute a population code for sound azimuth at the DCIC of awake, passively listening mice (<xref rid="fig4" ref-type="fig">Fig. 4</xref>-<xref rid="fig5" ref-type="fig">5</xref>). This finding complements previous studies analyzing pooled, non-simultaneous extracellular recordings from the CNIC of passively listening animals (<xref ref-type="bibr" rid="c19">Day et al., 2012</xref>; <xref ref-type="bibr" rid="c17">Day and Delgutte, 2016</xref>, <xref ref-type="bibr" rid="c18">2013</xref>), which could have potentially exciting implications, as DCIC represents a higher order relay of the auditory pathway, with respect to CNIC, and receives more profuse descending corticofugal inputs involved in sound location experience dependent plasticity (<xref ref-type="bibr" rid="c4">Bajo et al., 2019</xref>, <xref ref-type="bibr" rid="c5">2010</xref>; <xref ref-type="bibr" rid="c41">Lesicko et al., 2022</xref>; <xref ref-type="bibr" rid="c62">Winer et al., 2002</xref>). Concretely, we show that sound location coding does indeed occur at DCIC on the single trial basis, and that this follows a comparable mechanism to the characterized population code at CNIC (<xref ref-type="bibr" rid="c18">Day and Delgutte, 2013</xref>). However, it remains to be determined if indeed the DCIC network is physiologically capable of Bayesian decoding computations. Interestingly, the small number of DCIC top ranked units necessary to effectively decode stimulus azimuth suggests that sound azimuth information is redundantly distributed across DCIC top ranked units, which points out that mechanisms beyond coding efficiency could be relevant for this population code.</p>
<p>While the decoding error observed from our DCIC datasets obtained in passively listening, untrained mice coincidentally matches the discrimination ability of highly trained, motivated mice (<xref ref-type="bibr" rid="c39">Lauer et al., 2011</xref>), a relationship between decoding error and psychophysical performance remains to be determined. Interestingly, a primary sensory representations should theoretically be even more precise than the behavioral performance as reported in the visual system (<xref ref-type="bibr" rid="c57">Stringer et al., 2021</xref>). One possible explanation could be that the population code of sound azimuth at DCIC is likely not a primary representation, as DCIC is reported to be involved in higher order functions including experience dependent plasticity, is influenced by auditory cortex (<xref ref-type="bibr" rid="c4">Bajo et al., 2019</xref>, <xref ref-type="bibr" rid="c5">2010</xref>; <xref ref-type="bibr" rid="c3">Bajo and King, 2012</xref>) and is associated to non-auditory processes (<xref ref-type="bibr" rid="c28">Gruters and Groh, 2012</xref>; <xref ref-type="bibr" rid="c63">Wong and Borst, 2019</xref>). In this respect, we observed a correlation between the recorded DCIC population activity and snout movements, suggesting that non-auditory processes are likely influencing the recorded responses (<xref rid="figs2" ref-type="fig">Suppl. Fig. 2</xref>). On the other hand, our observations were drawn from unilateral datasets from a single IC. It has been reported that the population responses of a single IC (unilateral recordings from CNIC) can produce a complete representation of sound location throughout the frontal hemifield (<xref ref-type="bibr" rid="c17">Day and Delgutte, 2016</xref>, <xref ref-type="bibr" rid="c18">2013</xref>). Our observations support this notion, showing that unilateral subpopulations of top ranked DCIC units carry enough information to generate a representation of the complete frontal hemifield that is accurate enough to match the discrimination ability of mice (<xref ref-type="bibr" rid="c39">Lauer et al., 2011</xref>). Discrepancies with respect to unilateral lesion studies (<xref ref-type="bibr" rid="c18">Day and Delgutte, 2013</xref>; <xref ref-type="bibr" rid="c33">Jenkins and Masterton, 1982</xref>), suggesting that one IC would carry information about the contralateral hemifield only, could be explained by the loss of commissural interactions between both ICs that contribute to sound location processing (<xref ref-type="bibr" rid="c43">Orton et al., 2016</xref>). In this respect, we observed that the jRGECO1a-labeled neurons we imaged could project contralaterally (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>, inset), suggesting that the imaged DCIC populations would be involved in commissural interactions. This is particularly interesting in the context of the opposing two channel model of sound location coding proposed for the mammalian auditory brainstem (<xref ref-type="bibr" rid="c27">Grothe et al., 2010</xref>; <xref ref-type="bibr" rid="c47">Park et al., 2004</xref>), which was ruled out for azimuth coding at the rabbit CNIC (<xref ref-type="bibr" rid="c18">Day and Delgutte, 2013</xref>), but could still be relevant for understanding DCIC population coding of sound location. Thus, we cannot rule out that the actual accuracy of the DCIC population code for sound azimuth, on the single-trial basis, would only be reached if we considered bilateral DCIC recordings. These open questions about the transformations undergone by the neural code for sound location across the relays of the auditory pathway and the influence of bilateral interactions are exciting subjects for future study.</p>
<p>Both our imaging and neuropixels datasets show that the responses from DCIC neurons are noisy, independently of the recording methodology or stimulus (<xref rid="fig4" ref-type="fig">Fig. 4</xref>, 5, <xref rid="figs1" ref-type="fig">Suppl. Fig. 1</xref>), and that this neuronal noise is often positively correlated across simultaneously recorded pairs of top ranked units, which are involved in the population code of sound azimuth (<xref rid="fig6" ref-type="fig">Fig. 6</xref>). Interestingly, these noise correlations can contribute to reducing the error of the DCIC population code for sound azimuth (<xref rid="fig6" ref-type="fig">Fig. 6</xref>). In low dimensional samples of ∼two neurons this could only be justified by concomitant negative signal correlations with positively correlated noise (middle scenario in <xref rid="fig5" ref-type="fig">figure 5A</xref>). However, the recorded top ranked units typically showed contralateral sensitivity, which means generally positive signal correlation instead. Nevertheless, in larger samples this relationship between signal and noise correlations seems to be more complex, supporting that these assumptions do not necessarily apply in a complex multidimensional representation like the population code here studied, where empirical determination of the impact of noise correlations are more informative (<xref ref-type="bibr" rid="c42">Montijn et al., 2016</xref>). Noise correlations have been reported to occur at the mammalian CNIC and have a role in sound categorization (<xref ref-type="bibr" rid="c53">Sadeghi et al., 2019</xref>), however their influence on the population code for sound location remained unexplored (<xref ref-type="bibr" rid="c19">Day et al., 2012</xref>; <xref ref-type="bibr" rid="c17">Day and Delgutte, 2016</xref>, <xref ref-type="bibr" rid="c18">2013</xref>). Thus, our data supports that response sensitivity to azimuth might not be the only feature of IC neurons carrying information about stimulus azimuth, as considered in previous studies (<xref ref-type="bibr" rid="c10">Chase and Young, 2008</xref>, <xref ref-type="bibr" rid="c11">2005</xref>; <xref ref-type="bibr" rid="c19">Day et al., 2012</xref>; <xref ref-type="bibr" rid="c17">Day and Delgutte, 2016</xref>, <xref ref-type="bibr" rid="c18">2013</xref>), but noise correlations across the population responses could also be a relevant factor. This implication might extend to other brain regions relevant for sound location coding or perhaps also to different sensory modalities.</p>
<p>It is worth mentioning that many discrepancies exist in the labeling and segmentation boundaries of the anatomical subdivisions of IC between the most commonly used mouse brain reference atlases (<xref ref-type="bibr" rid="c12">Chon et al., 2019</xref>), like the Franklin-Paxinos atlas (<xref ref-type="bibr" rid="c48">Paxinos and Franklin, 2001</xref>) and the Allen atlas (<ext-link ext-link-type="uri" xlink:href="http://atlas.brain-map.org">atlas.brain-map.org</ext-link>), which can lead to conflicting interpretations of experimental data (<xref ref-type="bibr" rid="c7">Bjerke et al., 2018</xref>). These differences could arise due to different criteria employed by the expert neuroanatomists to segment anatomical subdivisions (histological stainings or magnetic resonance imaging) different tissue preparation (PFA fixed vs. fresh frozen) or intrinsic variability in the colonies of the animals employed (<xref ref-type="bibr" rid="c12">Chon et al., 2019</xref>). Here we adopted the IC segmentation boundaries and labels from the Franklin-Paxinos atlas, due to the extensive previous research employing it and the fact that we followed a compatible tissue preparation procedure for determining the anatomical location of our imaged volumes and electrode tracts (PFA fixed tissue slices). Recent efforts implementing the widely used segmentation and labeling from the Franklin-Paxinos atlas into the Allen common coordinate framework are a step in the right direction to circumvent this issue (<xref ref-type="bibr" rid="c12">Chon et al., 2019</xref>). Taking this into consideration, we report that DCIC top ranked units scatter across the imaged volume with no specificity in their location across the anatomical axes (<xref rid="fig6" ref-type="fig">Fig. 6</xref>). Interestingly, <italic>in vivo</italic> imaging studies report that the mouse dorsal IC processes sound frequency information topographically (tonotopy), showing a distinct tonotopic arrangement of neurons across the rostromedial-caudolateral and dorso-ventral axes (<xref ref-type="bibr" rid="c6">Barnstedt et al., 2015</xref>; <xref ref-type="bibr" rid="c63">Wong and Borst, 2019</xref>). Beyond the mouse model, a hypothetical functional relationship between the distribution of sound location encoding DCIC neuronal subpopulations and DCIC tonotopic gradients of sound frequency tuning could shed light into how the DCIC subpopulation code of sound azimuth relates to the duplex theory of sound location (<xref ref-type="bibr" rid="c51">Rayleigh, 1907</xref>). Nevertheless, we observed that not all DCIC azimuth sensitive units show pure tone sound frequency sensitivity, whereas a fraction of units showing both azimuth and sound frequency sensitivity displayed selectivity for high sound frequencies &gt; 10kHz, making this argument only relevant to perhaps the latter subset of DCIC neurons. Technical improvements realizing larger fields of view to interrogate the wide-stretching tonotopic DCIC map in simultaneous recordings would be key to further explore this relationship (<xref ref-type="bibr" rid="c20">Demas et al., 2021</xref>; <xref ref-type="bibr" rid="c44">Ota et al., 2021</xref>).</p>
<p>In conclusion, our simultaneous recordings from passively listening mice directly support that population response patterns from a subset of DCIC noisy neurons effectively encode sound location on the single-trial basis with an error that matches the discrimination ability of trained mice (<xref ref-type="bibr" rid="c39">Lauer et al., 2011</xref>). Specifically, we report that azimuth information is redundantly distributed across the subset of DCIC azimuth sensitive units (top ranked units), which rely not only on response dependency to sound location but also on noise-correlations to accurately encode this information and are randomly scattered across DCIC. An important open question remains about the behavioral relevance of this code and the noise correlations. We hope that this study paves the way to explore this question in detail, together with the wealth of knowledge available about cortico-collicular interactions involved in experience dependent plasticity in the context of sound localization (<xref ref-type="bibr" rid="c4">Bajo et al., 2019</xref>, <xref ref-type="bibr" rid="c5">2010</xref>).</p>
</sec>
<sec id="s4">
<title>Materials and methods</title>
<sec id="s4a">
<title>Animals and ethics statement</title>
<p>This work was performed in compliance to the European Communities Council Directive (2010/63/EU) to minimize animal pain and discomfort. EMBL’s committee for animal welfare and institutional animal care and use (IACUC) approved all experimental procedures under protocol number 2019-04-15RP. Experiments were performed on 7-16-week-old CBA/j mice obtained from Charles River Laboratories and housed in groups of 1-5 in makrolon type 2L cages on ventilated racks at room temperature and 50% humidity with a 12 hr light cycle. Food and water were available ad libitum. Experimental subjects consisted of 12 mice for imaging and 4 mice for electrophysiological recordings.</p>
</sec>
<sec id="s4b">
<title>Surgical procedures</title>
<sec id="s4b1">
<title>For microscopy</title>
<p>Cranial window surgeries were performed on 7-8-week-old mice of either sex following procedures published elsewhere (<xref ref-type="bibr" rid="c8">Boffi et al., 2018</xref>). Briefly, anesthesia consisted of a mixture of 40 µl fentanyl (0.1 mg/ml; Janssen), 160 µl midazolam (5 mg/ml; Hameln) and 60 µl medetomidin (1 mg/ml; Pfizer), dosed in 5 µl/g body weight and injected i.p.. Hair removal cream was used to remove the fur over the scalp of anesthetized mice and eye ointment was applied (Bepanthen, Bayer). 1% xylocain (AstraZeneca) was injected as preincisional anesthesia under the scalp. Prepared mice were then placed in a stereotaxic apparatus (David Kopf Instruments, model 963) with their bodies on a heating pad (37°C). The scalp was surgically removed to expose the dorsal cranium. The periosteum was removed with fine forceps and scissors to prepare the surface for cranial window implantation and stereotaxic delivery of viral vectors. Post-surgical pain relief was provided (Metacam, Boehringer Ingelheim) through s.c. injections (0.1 mg/ml, dosed 10μl/g body weight).</p>
<p>The Ca<sup>2+</sup> indicator jRGECO1a (<xref ref-type="bibr" rid="c15">Dana et al., 2016</xref>) was expressed in IC neurons through transduction with AAV vectors (Addgene #100854-AAV1), which were stereotaxically delivered as follows. A 4mm diameter circular craniectomy centered over IC (∼1mm posterior to lambda (<italic>34</italic>)) was produced using a dental drill (Microtorque, Harvard Apparatus) with care to avoid bleeding and damage of the dura, which was not removed and left intact. Stereotaxic injections were performed at the right IC (from bregma: -5.2 mm AP, 0.5 mm ML) with pulled glass pipettes lowered to depths of 300, 400 and 500 μm, at a rate of ∼4ul/hr using a 10 ml syringe (to generate pressure) coupled o the glass needle through a silicon tubing via a luer 3-way T valve. ∼300nl were injected per site. After injection, the craniectomy was sealed with a round 4mm coverslip (∼170μm thick, disinfected with 70% ethanol), with a drop of saline between the glass and the dura, and dental acrylic cement (Hager Werken Cyano Fast and Paladur acrylic powder). A head fixation bar was also cemented. The open skin wound was also closed with acrylic cement. At the end of the surgery anesthesia was antagonized with a subcutaneous injection of a mixture of 120 µl sterile saline, 800 µl flumazenil (0.1 mg/ml; Fresenius Kabi), and 60 µl atipamezole (5 mg/ml; Pfizer) dosed in 10 µl/g body weight. Mice were single housed after surgery to minimize the chance of cage mates compromising each others implantations and were allowed to recover for at least 4 weeks before imaging, providing time for Ca<sup>2+</sup> indicator expression and for the inflammation associated with this surgery to resolve (<xref ref-type="bibr" rid="c30">Holtmaat et al., 2009</xref>).</p>
</sec>
<sec id="s4b2">
<title>For electrophysiology</title>
<p>Acute craniectomy surgeries were performed on 7-15-week-old mice of either sex following procedures published elsewhere (<xref ref-type="bibr" rid="c8">Boffi et al., 2018</xref>). Briefly, anesthesia was induced with 5% isoflurane (Baxter) in O<sub>2</sub>, and maintained at 1.5-2% with a flow rate of 0.4-0.6 LPM. Hair removal cream was used to remove the fur over the scalp, eye ointment was applied (Bepanthen, Bayer) and 1% xylocain (AstraZeneca) was injected under the scalp as preincisional anesthesia. Mice were set in the stereotaxic apparatus with their bodies on a heating pad (37°C) and their scalp and periosteum removed to expose the dorsal cranium. A custom made head bar was cemented to the exposed cranium, sealing the skin wound, with UV cured dental acrylic to reduce curing time (Loctite 4305 LC). A ∼4mm diameter circular craniectomy centered over IC (∼1mm posterior to lambda (<xref ref-type="bibr" rid="c48">Paxinos and Franklin, 2001</xref>)) was produced using a dental drill (Microtorque, Harvard Apparatus) with care to avoid bleeding and damage of the dura. The surface of the brain was kept moist at all times with sterile cortex buffer (mM: NaCl 125, KCl 5, Glucose 10, Hepes 10, CaCl<sub>2</sub> 2, MgCl<sub>2</sub> 2, pH 7.4). The dura was carefully ripped open at a small site over DCIC for electrode insertion, through an incision made with a sterile G27 needle. The dura was not completely removed and the rest was left intact. Post-surgical pain relief was provided (Metacam, Boehringer Ingelheim) through s.c. injections (0.1 mg/ml, dosed 10μl/g body weight).</p>
<p>Craniectomy surgeries typically lasted 30 min since the induction of anesthesia, after which the mouse was allowed to recover headfixed at the recording setup (same as for Ca<sup>2+</sup> imaging, see below). Typically ∼5 minutes after isoflurane removal the mice displayed awake behaviors like whisking, blinking, grooming and body movements. The craniectomy was kept submerged in a well of cortex buffer throughout the experiment. We began recording at least 40 minutes after the mouse showed signs of being fully awake. During this period the neuropixel probe was inserted into the DCIC at 10μm/s rate using a micromanipulatior (Sutter MPC-385 system, coupled to a Sensapex uMp-NPH Neuropixel 1.0 probe holder). After insertion, neuropixel probes were allowed to settle in the tissue for 10 min. The metal headbar was left exposed to the cortex buffer close to the edge of the craniectomy and was used as reference.</p>
</sec>
</sec>
<sec id="s4c">
<title>sTeFo 2P microscopy</title>
<p>We built a bespoke scanned temporal focusing (sTeFo) 2 photon microscope for fast volumetric in vivo Ca<sup>2+</sup> imaging of large IC neuronal populations from awake mice. Technical details and detailed working principle are extensively described elsewhere (<xref ref-type="bibr" rid="c50">Prevedel et al., 2016</xref>). The main difference with respect to the microscope design published by <xref ref-type="bibr" rid="c50">Prevedel et al. (2016)</xref> was a higher repetition laser (10 MHz, FemtoTrain, Spectra Physics). Laser power while scanning was kept below 191 mW, measured after the objective, to avoid heating the brain tissue excessively (<xref ref-type="bibr" rid="c50">Prevedel et al., 2016</xref>). 470 μm<sup>2</sup> fields of view were imaged at 128 px<sup>2</sup> resolution and spaced in 15 μm z steps to cover 570 μm in depth (38 z steps) at a volume rate of 4.01 Hz. Artifacts produced by objective piezo z drive flyback were excluded from analysis.</p>
<p>In a typical imaging session, cranial window implanted mice were briefly (&lt; 1 min) anesthetized with 5% isoflurane in O<sub>2</sub> for quick head fixation at a custom stage, slightly restraining their bodies inside a 5 cm diameter acrylic tube, and positioned under our custom 2P microscope. Mice fully recovered from the brief isoflurane anesthesia, showing a clear blinking reflex, whisking and sniffing behaviors and normal body posture and movements, immediately after head fixation. A pilot group of mice were habituated to the head fixed condition in daily 20 min sessions for 3 days, however we did not observe a marked contrast in the behavior of habituated versus unhabituated mice during our relatively short 25 min imaging sessions. In consequence imaging sessions never surpassed a maximum of 25 min, after which the mouse was returned to its home cage. Typically, mice were imaged a total of 2-11 times (sessions), one to three times a week. Datasets here analyzed and reported come from the imaging session in which we observed maximal calcium sensor signal (peak AAV expression) and maximum number of detected units. Volumetric imaging data was visualized and rendered using FIJI (<xref ref-type="bibr" rid="c54">Schindelin et al., 2012</xref>). Motion correction was performed using NoRMCorre (<xref ref-type="bibr" rid="c49">Pnevmatikakis and Giovannucci, 2017</xref>) on individual imaging planes from the volumetric datasets. We used the CaImAn package (<xref ref-type="bibr" rid="c25">Giovannucci et al., 2019</xref>) for automatic ROI segmentation through constrained non negative matrix factorization and selected ROIs (Units) showing clear Ca transients consistent with neuronal activity, and IC neuron somatic shape and size (<xref ref-type="bibr" rid="c56">Schofield and Beebe, 2019</xref>). jRGECO1a signal from the segmented ROIs was extracted, denoised and neuropil corrected from each individual imaging plane using CaImAn (<xref ref-type="bibr" rid="c25">Giovannucci et al., 2019</xref>). Spike probabilities were estimated using MLSpike (<xref ref-type="bibr" rid="c21">Deneux et al., 2016</xref>).</p>
</sec>
<sec id="s4d">
<title>Extracellular electrophysiological recordings</title>
<p>We performed acute extracellular single-unit recordings using the Neuropixles (<xref ref-type="bibr" rid="c34">Jun et al., 2017</xref>) 1.0 system (PRB_1_4_0480_1, PXIe_1000, HST_1000, IMEC). Reference and ground pads on the band connector of the probe were bridged and grounded. The probe shank was coated before recordings by dipping 10 times every 5 s in DiI (V22885, ThermoFisher) for post hoc histological assessment of electrode tracks. Recordings were performed using SpikeGLX software (<ext-link ext-link-type="uri" xlink:href="https://billkarsh.github.io/SpikeGLX/">https://billkarsh.github.io/SpikeGLX/</ext-link>). Mice were recorded for ∼25min after successful electrode insertion (see surgical procedures), after which they were placed in an empty cage, and their behavior monitored for 10-15 minutes. We only considered recordings from mice that displayed normal behaviors (locomotion, exploration, sniffing, whisking), with no clear signs of pain or discomfort (freezing, shivering, raised fur) at this stage. Mice were sacrificed after this with CO<sub>2</sub> for transcardial perfusion and tissue preparation to trace electrode tracks (see below). After retrieval, neuropixels probes were cleaned through immersion in 1% Tergazime (Z742918, Merck) for some minutes, followed by washes in distilled water and reused multiple times. Recordings were preprocessed for spike sorting with CatGT (<ext-link ext-link-type="uri" xlink:href="https://billkarsh.github.io/SpikeGLX/#catgt">https://billkarsh.github.io/SpikeGLX/#catgt</ext-link>) for high pass filtering, common average referencing of the demultiplexed channels and file concatenation. Spike sorting with drift correction was performed using kilosort 2.5 (<ext-link ext-link-type="uri" xlink:href="https://github.com/MouseLand/Kilosort/releases/tag/v2.5">https://github.com/MouseLand/Kilosort/releases/tag/v2.5</ext-link>). The output of kilosort was manually curated using Phy (<ext-link ext-link-type="uri" xlink:href="https://github.com/cortex-lab/phy">https://github.com/cortex-lab/phy</ext-link>), selecting only single-units with somatic AP waveforms with good waveform consistency (amplitude) across spikes, showing few or no refractory period violations (2ms refractory period violation time window) in their correlogram plots and firing a minimum of 150 times in 20 min of recording. Stimulus times collected as digital channel inputs and recorded clock signals from the neuropixles headstage were temporaly aligned to a reference clock with Tprime (<ext-link ext-link-type="uri" xlink:href="https://billkarsh.github.io/SpikeGLX/#tprime">https://billkarsh.github.io/SpikeGLX/#tprime</ext-link>).</p>
</sec>
<sec id="s4da">
<title>Sound Stimulation</title>
<p>A custom sound-attenuating chamber was incorporated to the microscope/electrophysiology setup, allowing only the objective or cables to access the inside, to attenuate room and microscope scanner noise reaching the mouse. All possible sound reflecting surfaces were lined with 1 cm or 0.5 cm thick foam to preserve free-field conditions. SPL was measured using a free-field prepolarized measurement microphone (PCB Piezotronics, 378C01, with signal conditioner 482A21) placed on the setup stage in the position of the head of the mouse. For imaging experiments, background R.M.S. SPL measurements during imaging without sound stimuli delivery was (20-40 kHz) 44.83 dB (79.5 dB total SPL summed across the band). Sound stimulus (20-40 kHz) R.M.S. SPL during imaging was 56.83 dB (96.2 dB total SPL summed across the band), ensuring that SPL was at least 10 dB above background SPL for sound stimuli to be salient. Background R.M.S. SPL during imaging across the mouse hearing range (2.5-80kHz) was 44.53 dB.</p>
<p>Electrophysiological experiments were performed at the same setup, without the microscope running. For broadband stimuli applied in our electrophysiological experiments, background R.M.S. SPL (15-50 kHz) was 35.96 dB (89.9 dB total SPL summed across the band). Broadband stimulus (15-50kHz) R.M.S. SPL was 62.5 dB (102 dB total SPL summed across the band). Pure tone stimuli consisted on 4-48kHz tones, making 3.5 octaves split into steps of 4. Peak SPL of the pure tone stimuli was calibrated to 65 ± 3 dB. R.M.S. background noise across the 4-48kHz band was 35.1 dB. Background R.M.S. SPL across the mouse hearing range (2.5-80kHz) was 34.68 dB.</p>
<p>Broadband sound stimuli consisted of band-passed frozen noise. Stimulus duration was 500 ms for imaging experiments and 200 ms for electrophysiological experiments, including 10 ms up and down ramps. Sound stimuli were delivered through an electrostatic speaker (Tucker Davis Technologies, ES1 coupled to a ED1 speaker driver) mounted on an arm at an 8.5 cm distance away from the head of the mouse, which was mounted on a NEMA17 bipolar stepper motor (26 Ncm, 1.8 deg/step) placed under the head of the mouse to position the speaker around the frontal hemifield. The motor was controlled using an Arduino UNO microcontroller, running GRBL v0.9 (G-code interpreter, <ext-link ext-link-type="uri" xlink:href="https://github.com/grbl/grbl">https://github.com/grbl/grbl</ext-link>) and coupled with the Arduino CNC Shield V3.10 (<ext-link ext-link-type="uri" xlink:href="https://blog.protoneer.co.nz/arduino-cnc-controller/">https://blog.protoneer.co.nz/arduino-cnc-controller/</ext-link>) running A4988 motor drivers. To control and program speaker positioning, we used the universal G-code sender (<ext-link ext-link-type="uri" xlink:href="https://winder.github.io/ugs_website/">https://winder.github.io/ugs_website/</ext-link>). Synchronization of speaker positioning and sound stimulus delivery to data acquisition was done through a second Arduino UNO board receiving a scan start TTL from the microscope to trigger stimulation programs or by recording the sound delivery TTL signal with a DAQ board (National Instruments, PXIe-6341) through a digital channel in SpikeGLX. Pure tone stimuli were presented with the speaker parked at 0° azimuth, in front of the mouse.</p>
<p>Audio stimuli (including 10 ms up and down ramps) were synthesized using MATLAB (0.5 MHz sampling rate). Sound delivery was performed using a DAQ board (National Instruments, PXIe-6341) interfaced to MATLAB using the DAQmx wrapper from scanimage (<ext-link ext-link-type="uri" xlink:href="https://vidriotechnologies.com/scanimage/">https://vidriotechnologies.com/scanimage/</ext-link>).</p>
<p>A typical stimulation protocol consisted of a series of presentations of a sound stimulus in which azimuth angles varied randomly from 13 different frontal positions (frontal 180° split into 15° steps). For imaging experiments, stimuli were presented every 5 seconds and each azimuth angle was presented on average 14 times per session. Minimum number of same-azimuth trials collected was 8. For electrophysiological experiments, firstly pure tone stimuli were applied every 2 seconds in pseudo-random order to obtain 10 trial repetitions (14 sound frequencies, 140 trials), and after that broadband stimulus azimuth trials were applied every 3 seconds (to allow the motor to complete speaker movements) in pseudo-random order to obtain 20 trial repetitions (13 azimuths, 260 trials).</p>
</sec>
<sec id="s4e">
<title>Histology</title>
<p>At the end of the experiment mice were transcardially perfused with phosphate-buffered saline (PBS) followed by 4% paraformaldehyde at room temperature to fixate the brain. The perfused brain was dissected and post-fixed in 4% paraformaldehyde for 24 h at 4 °C. After post-fixation, brains were washed with PBS saline and stored at 4 °C. 100-μm-thick free-floating vibratome (Leica VT1200) coronal sections were cut at room temperature, mounted on slides using Vectashield with DAPI (H-1200-10, Vector Laboratories) and imaged in a NIKON Ti-E epifluorescence microscope equipped with a LUMENCOR SPECTRA X module for illumination, standard DAPI and mCherry filter cubes, and a pco.edge 4.2 CL sCMOS camera; using a CFI P-Apo 4x Lambda/ 0.20/ 20,00 objective. Images of brain slices were aligned to the mouse brain reference atlas manually following anatomical landmarks.</p>
</sec>
<sec id="s4f">
<title>Face movement videography</title>
<p>Videos from one side of the mouse face, ipsilateral to the imaged IC, were recorded with an IR sensitive camera equipped with a CMOS OV2710 sensor, IR LEDs for illumination, a 25mm M12 objective (ELP, USBFHD05MT-KL36IR), using a sampling rate of 30 fps at 720p resolution. Video acquisition was synchronized to the microscope acquisition start. Video image analysis based on intensity change between successive frames was performed following a similar approach as described by <xref ref-type="bibr" rid="c63">Wong and Borst (2019)</xref> using FIJI (<xref ref-type="bibr" rid="c54">Schindelin et al., 2012</xref>) and custom MATLAB scripts. For correlations between face movements and imaged neuronal activity, the Pearson correlation coefficient was used.</p>
</sec>
<sec id="s4g">
<title>Statistical analyses</title>
<p>Each mouse was considered a replicate. Datasets obtained in one imaging/recording session from each mouse, consisting of ∼200 azimuth trials were analyzed. We did not perform any form of data augmentation through resampling with restitution of the recorded responses to virtually increase the number of trials (<xref ref-type="bibr" rid="c18">Day and Delgutte, 2013</xref>). Statistical analyses were performed using MATLAB (2023a,b) functions and custom scripts. For hypothesis testing, a p value &lt; 0.05 was considered significant. Sidak’s correction of p values was used for multiple comparisons. nS/N ratios were evaluated as the inverse of the coefficient of variation of the recorded responses of each cell across azimuth trials.</p>
<p>For our imaging data, since many units failed to respond across many trials, we did not perform baseline spike probability subtraction as this frequently led to negative spike probabilities that were hard to interpret. For our neuropixels experiments, we generally did not perform baseline firing subtraction from the responses as the average baseline firing in the 200ms before stimuli was quite low and close to 0 (<xref rid="figs1" ref-type="fig">Suppl. Fig. 1F</xref>, <xref rid="fig5" ref-type="fig">Fig. 5A</xref>). Nevertheless, we did subtract baseline firing for the determination of the nS/N (<xref rid="fig5" ref-type="fig">Fig. 5C</xref>), as the on going activity varied extensively across the recordings (in the absence of sound stimulation, <xref rid="fig1" ref-type="fig">Fig. 1I</xref>) and this could lead to nS/N values that were artificially high. On going activity was estimated as the spike count determined in 200ms time windows during the inter trial periods (2.8s, no sound stimulation), 1s before each stimulation trial. “Baseline on-going firing” was determined as the spike count 200ms previous to that. For fairness of comparisons, we also subtracted baseline firing determined during the 200ms pre response for nS/N determination from the sound stimulated condition.</p>
<p>One sided Kruskal-Wallis tests were performed to determine median response tuning to stimulus azimuth, with 12 degrees of freedom (13 tested azimuths). Two sample Kolmogorov-Smirnov and Wilcoxon rank sum tests were two sided. To find units with single-trial responses that were statistically dependent on stimulus azimuth (feature selection) we performed χ<sup>2</sup> independency tests using the function fscchi2 from the statistics and machine learning toolbox from MATLAB with default parameters, which binned the responses into 10 bins. Cross validated sorting of noise correlation matrices was obtained by performing hierarchical clustering on half of the trials recorded based on pairwise neuronal noise correlations (using the Kendall tau as a non parametric correlation coefficient) as a distance metric, and plotting the pairwise correlation coefficient matrix registered for the other half of the trials, sorting the units based on the clustering. IC population response classification (decoding) was performed using the naive Bayes classifier algorithm implemented in MATLAB, using the fitcnb function from the statistics and machine learning toolbox. For the latter function, model fit involved Bayesian hyperparameter optimization for all eligible parameters. This MATLAB function performs 3 steps: 1) Estimation of the densities of the units’ responses (predictors) within each class (stimulus azimuth) through kernel smoothing density estimation. Uniform, Epanechnikov, Gaussian or triangular smoothing kernels and Kernel smoothing window width were set through hyperparameter optimization. 2) Use the Bayes rule to estimate the posterior probability ^<italic>P</italic> for all possible azimuth classes <italic>k</italic> =1, …, 13 (-90° to 90° in 15° steps) as:
<disp-formula>
<graphic xlink:href="504510v5_ueqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>Y</italic> is the possible azimuth class being evaluated<italic>, X<sub>1</sub>,…,X<sub>p</sub> a</italic>re the simultaneously acquired responses from the units in a population of size <italic>p</italic> during a single azimuth trial, <italic>π</italic> (<italic>Y</italic> =<italic>k</italic>) is the prior probability that the azimuth class is <italic>k,</italic> determined as the relative frequencies of each azimuth class in the training dataset. 3) Determine the azimuth class of a single trial response pattern as the class with maximum posterior probability (maximum <italic>a posteriori</italic> decision rule).</p>
<p>For dimensionality reduction, feature selection and classification (decoding) a “leave one out” cross-validation strategy was implemented for the whole process, in which dimensionality reduction (PCA) or feature selection (top ranked cell selection, if applicable) was performed and then the models were fitted to the population responses collected in all trials except one (for each imaging session) and the one population response left out was decoded as is or using the selected features (best cells) or using the PCA loadings matrix to calculate PC scores, and fitted model. This procedure was iterated until all population responses simultaneously recorded in an experiment (mouse) were decoded.</p>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>We acknowledge Lina Streich and Ling Wang for their contribution to microscope assembly and setup, the mechanical and electronics workshops and the laboratory animal resource facility of EMBL Heidelberg for technical assistance. Evan Harrell for input on motorized speaker design and Jacques Bourg for input on IC cranial window surgeries. Peter Rupprecht and Alejandro Tlaie-Boria for helpful comments on the manuscript. JCB acknowledges supporting fellowships from the EMBL Interdisciplinary Postdoc (EIPOD) Programme under Marie Skłodowska Curie Cofund Actions MSCA-COFUND-FP (664726). This work was funded by the European Molecular Biology Laboratory (EMBL) and the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) – project 458898724 awarded to RP.</p>
</ack>
<sec id="s5">
<title>Additional information</title>
<sec id="s5a">
<title>Authorship contributions</title>
<p>JCB, BB, HA, and RP conceptualized the study. JCB performed experiments. JCB, BB, HA and RP analyzed and interpreted data. JCB wrote preliminary manuscript draft and prepared figures. JCB, BB, HA, and RP edited and finalized manuscript.</p>
</sec>
<sec id="s6">
<title>Competing interests</title>
<p>The authors declare no competing financial interests.</p>
</sec>
<sec id="s7">
<title>Materials &amp; correspondence</title>
<p>Datasets and code supporting this study are available from <ext-link ext-link-type="uri" xlink:href="https://www.ebi.ac.uk/biostudies/bioimages/studies/S-BIAD1064">https://www.ebi.ac.uk/biostudies/bioimages/studies/S-BIAD1064</ext-link>.</p>
</sec>
</sec>
<sec id="s8">
<title>Supplemental figures</title>
<fig id="figs1" position="float" orientation="portrait" fig-type="figure">
<label>Supplemental figure 1:</label>
<caption><p>A) Representative median intensity projection from one sTeFo 2P imaging plane timelapse, extracted from one of our volumetric imaging datasets (left panel, scale bar 100μm) with superimposed footprints from CaImAn segmented and manually curated ROIs corresponding to recorded units (right panel). B) Representative raw dF/F<sub>0</sub> traces extracted from CaImAn segmented and manually curated ROIs (units, blue) with CaImAn neuropil corrected and denoised output superimposed (red). C) Schematic representation of a neuropixels probe shank location across DCIC (approximated histologically) highlighting in different colors the channels across which curated single-units were detected after spike sorting with kilosort 2.5 and manual curation with Phy. D) 100 superimposed traces from aligned spikes recorded from the color coded channels highlighted in (C), displaying spike amplitude and somatic waveform consistency and spatial attenuation. E) Correlogram plots from the curated single-units shown in (C,D), displaying very few refractory period violations (vertical dotted lines: 2ms refractory period time window considered). F) Representative responses to sound frequency (pure tone stimuli) of a frequency sensitive single-unit. Top panels show the peri-stimulus time histograms and the bottom panels show the corresponding spike raster plots across trials. G) Representative sound frequency tuning curves from two DCIC sound frequency dependent single-units recorded with neuropixels. Mean and standard deviation are plotted. H) Relationship between the best frequency of DCIC sound frequency dependent single-units and recording depth. Data from n = 4 mice, point color corresponds to the same mouse. X axis is in logarithmic scale. I) Neuronal signal to noise level (nS/N) histograms from neuropixels recorded DCIC single-units in the absence of sound stimuli (on going activity, gray) and in response to pure tone stimuli trials at the best frequency for all collected single-units (blue) and the sound frequency sensitive subset (red).</p></caption>
<graphic xlink:href="504510v5_figs1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs2" position="float" orientation="portrait" fig-type="figure">
<label>Supplemental figure 2:</label>
<caption><p>A) Schematic representation of the strategy employed to videographically track face movements (ear and snout) during imaging experiments. B) Representative traces of imaged population activity and ear or snout movement across stimulus azimuth trials. C) Correlation between the average population activity trace and ear or snout movements across mice. Median value across mice is represented by a horizontal line. D, E) Histograms of the correlation coefficients between ear or snout movement and the imaged activity of each unit (D) or the top ranked unit subset (azimuth dependent, E) across mice.</p></caption>
<graphic xlink:href="504510v5_figs2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figs3" position="float" orientation="portrait" fig-type="figure">
<label>Supplemental figure 3:</label>
<caption><title>Top ranked units are scattered throughout the imaged DCIC volumes.</title>
<p>A) Histogram plots of the distribution of top ranked unit position in the imaged volume across each anatomical axis (20μm bins) obtained from all imaged mice, either for the complete sample of units (purple) or the subsample of top ranked units (∼32% of all the units imaged per mice, blue). K.S.: Kolmogorov-Smirnov test. B) Scatter plots of the centroid position throughout the anatomical axes in the imaged volume from the detected top ranked units across mice.</p></caption>
<graphic xlink:href="504510v5_figs3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Adams</surname> <given-names>JC</given-names></string-name></person-group>. <year>1979</year>. <article-title>Ascending projections to the inferior colliculus</article-title>. <source>J Comp Neurol</source> <volume>183</volume>:<fpage>519</fpage>–<lpage>538</lpage>. doi:<pub-id pub-id-type="doi">10.1002/cne.901830305</pub-id></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Averbeck</surname> <given-names>BB</given-names></string-name>, <string-name><surname>Latham</surname> <given-names>PE</given-names></string-name>, <string-name><surname>Pouget</surname> <given-names>A</given-names></string-name></person-group>. <year>2006</year>. <article-title>Neural correlations, population coding and computation</article-title>. <source>Nat Rev Neurosci</source> <volume>7</volume>:<fpage>358</fpage>–<lpage>366</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nrn1888</pub-id></mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bajo</surname> <given-names>VM</given-names></string-name>, <string-name><surname>King</surname> <given-names>AJ</given-names></string-name></person-group>. <year>2012</year>. <article-title>Cortical modulation of auditory processing in the midbrain</article-title>. <source>Front Neural Circuits</source> <volume>6</volume>:<fpage>1</fpage>–<lpage>12</lpage>. doi:<pub-id pub-id-type="doi">10.3389/fncir.2012.00114</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bajo</surname> <given-names>VM</given-names></string-name>, <string-name><surname>Nodal</surname> <given-names>FR</given-names></string-name>, <string-name><surname>Korn</surname> <given-names>C</given-names></string-name>, <string-name><surname>Constantinescu</surname> <given-names>AO</given-names></string-name>, <string-name><surname>Mann</surname> <given-names>EO</given-names></string-name>, <string-name><surname>Boyden</surname> <given-names>ES</given-names></string-name>, <string-name><surname>King</surname> <given-names>AJ</given-names></string-name></person-group>. <year>2019</year>. <article-title>Silencing cortical activity during sound-localization training impairs auditory perceptual learning</article-title>. <source>Nat Commun</source> <volume>10</volume>. doi:<pub-id pub-id-type="doi">10.1038/s41467-019-10770-4</pub-id></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bajo</surname> <given-names>VM</given-names></string-name>, <string-name><surname>Nodal</surname> <given-names>FR</given-names></string-name>, <string-name><surname>Moore</surname> <given-names>DR</given-names></string-name>, <string-name><surname>King</surname> <given-names>AJ</given-names></string-name></person-group>. <year>2010</year>. <article-title>The descending corticocollicular pathway mediates learning-induced auditory plasticity</article-title>. <source>Nat Neurosci</source> <volume>13</volume>:<fpage>253</fpage>–<lpage>260</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn.2466</pub-id></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barnstedt</surname> <given-names>O</given-names></string-name>, <string-name><surname>Keating</surname> <given-names>P</given-names></string-name>, <string-name><surname>Weissenberger</surname> <given-names>Y</given-names></string-name>, <string-name><surname>King</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>Dahmen</surname> <given-names>JC</given-names></string-name></person-group>. <year>2015</year>. <article-title>Functional Microarchitecture of the Mouse Dorsal Inferior Colliculus Revealed through In Vivo Two-Photon Calcium Imaging</article-title>. <source>J Neurosci</source> <volume>35</volume>:<fpage>10927</fpage>–<lpage>10939</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.0103-15.2015</pub-id></mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bjerke</surname> <given-names>IE</given-names></string-name>, <string-name><surname>Øvsthus</surname> <given-names>M</given-names></string-name>, <string-name><surname>Andersson</surname> <given-names>KA</given-names></string-name>, <string-name><surname>Blixhavn</surname> <given-names>CH</given-names></string-name>, <string-name><surname>Kleven</surname> <given-names>H</given-names></string-name>, <string-name><surname>Yates</surname> <given-names>SC</given-names></string-name>, <string-name><surname>Puchades</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Bjaalie</surname> <given-names>JG</given-names></string-name>, <string-name><surname>Leergaard</surname> <given-names>TB</given-names></string-name></person-group>. <year>2018</year>. <article-title>Navigating the murine brain: Toward best practices for determining and documenting neuroanatomical locations in experimental studies</article-title>. <source>Front Neuroanat</source> <volume>12</volume>:<fpage>1</fpage>–<lpage>15</lpage>. doi:<pub-id pub-id-type="doi">10.3389/fnana.2018.00082</pub-id></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Boffi</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Knabbe</surname> <given-names>J</given-names></string-name>, <string-name><surname>Kaiser</surname> <given-names>M</given-names></string-name>, <string-name><surname>Kuner</surname> <given-names>T</given-names></string-name></person-group>. <year>2018</year>. <article-title>KCC2-dependent Steady-state Intracellular Chloride Concentration and pH in Cortical Layer 2/3 Neurons of Anesthetized and Awake Mice</article-title>. <source>Front Cell Neurosci</source> <volume>12</volume>:<fpage>1</fpage>–<lpage>14</lpage>. doi:<pub-id pub-id-type="doi">10.3389/fncel.2018.00007</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brunso-Bechtold</surname> <given-names>JK</given-names></string-name>, <string-name><surname>Thompson</surname> <given-names>GC</given-names></string-name>, <string-name><surname>Masterton</surname> <given-names>RB</given-names></string-name></person-group>. <year>1981</year>. <article-title>HRP study of the organization of auditory afferents ascending to central nucleus of inferior colliculus in cat</article-title>. <source>J Comp Neurol</source> <volume>197</volume>:<fpage>705</fpage>–<lpage>722</lpage>. doi:<pub-id pub-id-type="doi">10.1002/cne.901970410</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chase</surname> <given-names>SM</given-names></string-name>, <string-name><surname>Young</surname> <given-names>ED</given-names></string-name></person-group>. <year>2008</year>. <article-title>Cues for Sound Localization Are Encoded in Multiple Aspects of Spike Trains in the Inferior Colliculus</article-title>. <source>J Neurophysiol</source> <volume>99</volume>:<fpage>1672</fpage>–<lpage>1682</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.00644.2007</pub-id></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chase</surname> <given-names>SM</given-names></string-name>, <string-name><surname>Young</surname> <given-names>ED</given-names></string-name></person-group>. <year>2005</year>. <article-title>Limited segregation of different types of sound localization information among classes of units in the inferior colliculus</article-title>. <source>J Neurosci</source> <volume>25</volume>:<fpage>7575</fpage>–<lpage>7585</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.0915-05.2005</pub-id></mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chon</surname> <given-names>U</given-names></string-name>, <string-name><surname>Vanselow</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Cheng</surname> <given-names>KC</given-names></string-name>, <string-name><surname>Kim</surname> <given-names>Y</given-names></string-name></person-group>. <year>2019</year>. <article-title>Enhanced and unified anatomical labeling for a common mouse brain atlas</article-title>. <source>Nat Commun</source> <volume>10</volume>. doi:<pub-id pub-id-type="doi">10.1038/s41467-019-13057-w</pub-id></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Clarey</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Barone</surname> <given-names>P</given-names></string-name>, <string-name><surname>Irons</surname> <given-names>WA</given-names></string-name>, <string-name><surname>Samson</surname> <given-names>FK</given-names></string-name>, <string-name><surname>Imig</surname> <given-names>TJ</given-names></string-name></person-group>. <year>1995</year>. <article-title>Comparison of Noise and Tone Azimuth Tuning of Neurons in Cat Primary Auditory-Cortex and Medial Geniculate-Body</article-title>. <source>J Neurophysiol</source> <volume>74</volume>:<fpage>961</fpage>–<lpage>980</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.1995.74.3.961</pub-id></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Clough</surname> <given-names>M</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>IA</given-names></string-name>, <string-name><surname>Park</surname> <given-names>SW</given-names></string-name>, <string-name><surname>Ahrens</surname> <given-names>AM</given-names></string-name>, <string-name><surname>Stirman</surname> <given-names>JN</given-names></string-name>, <string-name><surname>Smith</surname> <given-names>SL</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>JL</given-names></string-name></person-group>. <year>2021</year>. <article-title>Flexible simultaneous mesoscale two-photon imaging of neural activity at high speeds</article-title>. <source>Nat Commun</source> <volume>12</volume>:<fpage>1</fpage>–<lpage>7</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41467-021-26737-3</pub-id></mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dana</surname> <given-names>H</given-names></string-name>, <string-name><surname>Mohar</surname> <given-names>B</given-names></string-name>, <string-name><surname>Sun</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Narayan</surname> <given-names>S</given-names></string-name>, <string-name><surname>Gordus</surname> <given-names>A</given-names></string-name>, <string-name><surname>Hasseman</surname> <given-names>JP</given-names></string-name>, <string-name><surname>Tsegaye</surname> <given-names>G</given-names></string-name>, <string-name><surname>Holt</surname> <given-names>GT</given-names></string-name>, <string-name><surname>Hu</surname> <given-names>A</given-names></string-name>, <string-name><surname>Walpita</surname> <given-names>D</given-names></string-name>, <string-name><surname>Patel</surname> <given-names>R</given-names></string-name>, <string-name><surname>Macklin</surname> <given-names>JJ</given-names></string-name>, <string-name><surname>Bargmann</surname> <given-names>CI</given-names></string-name>, <string-name><surname>Ahrens</surname> <given-names>MB</given-names></string-name>, <string-name><surname>Schreiter</surname> <given-names>ER</given-names></string-name>, <string-name><surname>Jayaraman</surname> <given-names>V</given-names></string-name>, <string-name><surname>Looger</surname> <given-names>LL</given-names></string-name>, <string-name><surname>Svoboda</surname> <given-names>K</given-names></string-name>, <string-name><surname>Kim</surname> <given-names>DS</given-names></string-name></person-group>. <year>2016</year>. <article-title>Sensitive red protein calcium indicators for imaging neural activity</article-title>. <source>Elife</source> <volume>5</volume>:<fpage>1</fpage>–<lpage>24</lpage>. doi:<pub-id pub-id-type="doi">10.7554/eLife.12727</pub-id></mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dana</surname> <given-names>H</given-names></string-name>, <string-name><surname>Shoham</surname> <given-names>S</given-names></string-name></person-group>. <year>2012</year>. <article-title>Numerical evaluation of temporal focusing characteristics in transparent and scattering media: erratum</article-title>. <source>Opt Express</source> <volume>20</volume>:<fpage>28281</fpage>. doi:<pub-id pub-id-type="doi">10.1364/oe.20.028281</pub-id></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Day</surname> <given-names>ML</given-names></string-name>, <string-name><surname>Delgutte</surname> <given-names>B</given-names></string-name></person-group>. <year>2016</year>. <article-title>Neural population encoding and decoding of sound source location across sound level in the rabbit inferior colliculus</article-title>. <source>J Neurophysiol</source> <volume>115</volume>:<fpage>193</fpage>–<lpage>207</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.00643.2015</pub-id></mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Day</surname> <given-names>ML</given-names></string-name>, <string-name><surname>Delgutte</surname> <given-names>B</given-names></string-name></person-group>. <year>2013</year>. <article-title>Decoding Sound Source Location and Separation Using Neural Population Activity Patterns</article-title>. <source>J Neurosci</source> <volume>33</volume>:<fpage>15837</fpage>–<lpage>15847</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2034-13.2013</pub-id></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Day</surname> <given-names>ML</given-names></string-name>, <string-name><surname>Koka</surname> <given-names>K</given-names></string-name>, <string-name><surname>Delgutte</surname> <given-names>B</given-names></string-name></person-group>. <year>2012</year>. <article-title>Neural encoding of sound source location in the presence of a concurrent, spatially separated source</article-title>. <source>J Neurophysiol</source> <volume>108</volume>:<fpage>2612</fpage>–<lpage>2628</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.00303.2012</pub-id></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Demas</surname> <given-names>J</given-names></string-name>, <string-name><surname>Manley</surname> <given-names>J</given-names></string-name>, <string-name><surname>Tejera</surname> <given-names>F</given-names></string-name>, <string-name><surname>Barber</surname> <given-names>K</given-names></string-name>, <string-name><surname>Kim</surname> <given-names>H</given-names></string-name>, <string-name><surname>Traub</surname> <given-names>FM</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>B</given-names></string-name>, <string-name><surname>Vaziri</surname> <given-names>A</given-names></string-name></person-group>. <year>2021</year>. <article-title>High-speed, cortex-wide volumetric recording of neuroactivity at cellular resolution using light beads microscopy</article-title>. <source>Nature Methods</source> <volume>18</volume>:<fpage>1103</fpage>–<lpage>1111</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41592-021-01239-8</pub-id></mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Deneux</surname> <given-names>T</given-names></string-name>, <string-name><surname>Kaszas</surname> <given-names>A</given-names></string-name>, <string-name><surname>Szalay</surname> <given-names>G</given-names></string-name>, <string-name><surname>Katona</surname> <given-names>G</given-names></string-name>, <string-name><surname>Lakner</surname> <given-names>T</given-names></string-name>, <string-name><surname>Grinvald</surname> <given-names>A</given-names></string-name>, <string-name><surname>Rozsa</surname> <given-names>B</given-names></string-name>, <string-name><surname>Vanzetta</surname> <given-names>I</given-names></string-name></person-group>. <year>2016</year>. <article-title>Accurate spike estimation from noisy calcium signals for ultrafast three-dimensional imaging of large neuronal populations in vivo</article-title>. <source>Nat Commun</source> <volume>7</volume>. doi:<pub-id pub-id-type="doi">10.1038/ncomms12190</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Felix</surname> <given-names>RA</given-names></string-name>, <string-name><surname>Gourévitch</surname> <given-names>B</given-names></string-name>, <string-name><surname>Portfors C</surname> <given-names>V</given-names></string-name></person-group>. <year>2018</year>. <article-title>Subcortical pathways: Towards a better understanding of auditory disorders</article-title>. <source>Hear Res</source> <volume>362</volume>:<fpage>48</fpage>–<lpage>60</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.heares.2018.01.008</pub-id></mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Georgopoulos</surname> <given-names>AP</given-names></string-name>, <string-name><surname>Kalaska</surname> <given-names>JF</given-names></string-name>, <string-name><surname>Caminiti</surname> <given-names>R</given-names></string-name>, <string-name><surname>Massey</surname> <given-names>JT</given-names></string-name></person-group>. <year>1982</year>. <article-title>ON THE RELATIONS BETWEEN THE DIRECTION TWO-DIMENSIONAL ARM MOVEMENTS AND CELL DISCHARGE PRIMATE MOTOR CORTEX1 IN</article-title>. <source>J Neurosci</source> <volume>2</volume>:<fpage>1527</fpage>–<lpage>1537</lpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Georgopoulos</surname> <given-names>AP</given-names></string-name>, <string-name><surname>Schwartz</surname> <given-names>AB</given-names></string-name>, <string-name><surname>Kettner</surname> <given-names>RE</given-names></string-name></person-group>. <year>1986</year>. <article-title>Neuronal Population Coding of Movement Direction</article-title>. <source>Science</source> <volume>233</volume>:<fpage>1416</fpage>–<lpage>1419</lpage>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Giovannucci</surname> <given-names>A</given-names></string-name>, <string-name><surname>Friedrich</surname> <given-names>J</given-names></string-name>, <string-name><surname>Gunn</surname> <given-names>P</given-names></string-name>, <string-name><surname>Kalfon</surname> <given-names>J</given-names></string-name>, <string-name><surname>Brown</surname> <given-names>BL</given-names></string-name>, <string-name><surname>Koay</surname> <given-names>SA</given-names></string-name>, <string-name><surname>Taxidis</surname> <given-names>J</given-names></string-name>, <string-name><surname>Najafi</surname> <given-names>F</given-names></string-name>, <string-name><surname>Gauthier</surname> <given-names>JL</given-names></string-name>, <string-name><surname>Zhou</surname> <given-names>P</given-names></string-name>, <string-name><surname>Khakh</surname> <given-names>BS</given-names></string-name>, <string-name><surname>Tank</surname> <given-names>DW</given-names></string-name>, <string-name><surname>Chklovskii</surname> <given-names>DB</given-names></string-name>, <string-name><surname>Pnevmatikakis</surname> <given-names>EA</given-names></string-name></person-group>. <year>2019</year>. <article-title>CaImAn an open source tool for scalable calcium imaging data analysis</article-title>. <source>Elife</source> <volume>8</volume>:<fpage>1</fpage>–<lpage>45</lpage>. doi:<pub-id pub-id-type="doi">10.7554/eLife.38173</pub-id></mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Groh</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Kelly</surname> <given-names>KA</given-names></string-name>, <string-name><surname>Underhill</surname> <given-names>AM</given-names></string-name></person-group>. <year>2003</year>. <article-title>A Monotonic Code for Sound Azimuth in Primate Inferior Colliculus</article-title>. <source>J Cogn Neurosci</source> <volume>15</volume>:<fpage>1217</fpage>–<lpage>1231</lpage>. doi:<pub-id pub-id-type="doi">10.1162/089892903322598166</pub-id></mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Grothe</surname> <given-names>B</given-names></string-name>, <string-name><surname>Pecka</surname> <given-names>M</given-names></string-name>, <string-name><surname>McAlpine</surname> <given-names>D</given-names></string-name></person-group>. <year>2010</year>. <article-title>Mechanisms of Sound Localization in Mammals</article-title>. <source>Physiol Rev</source> <volume>90</volume>:<fpage>983</fpage>–<lpage>1012</lpage>. doi:<pub-id pub-id-type="doi">10.1152/physrev.00026.2009</pub-id></mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gruters</surname> <given-names>KG</given-names></string-name>, <string-name><surname>Groh</surname> <given-names>JM</given-names></string-name></person-group>. <year>2012</year>. <article-title>Sounds and beyond: Multisensory and other non-auditory signals in the inferior colliculus</article-title>. <source>Front Neural Circuits</source> <volume>6</volume>:<fpage>1</fpage>–<lpage>39</lpage>. doi:<pub-id pub-id-type="doi">10.3389/fncir.2012.00096</pub-id></mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Guo</surname> <given-names>F</given-names></string-name>, <string-name><surname>Yu</surname> <given-names>J</given-names></string-name>, <string-name><surname>Jung</surname> <given-names>HJ</given-names></string-name>, <string-name><surname>Abruzzi</surname> <given-names>KC</given-names></string-name>, <string-name><surname>Luo</surname> <given-names>W</given-names></string-name>, <string-name><surname>Griffith</surname> <given-names>LC</given-names></string-name>, <string-name><surname>Rosbash</surname> <given-names>M</given-names></string-name></person-group>. <year>2016</year>. <article-title>Circadian neuron feedback controls the Drosophila sleep-activity profile</article-title>. <source>Nature</source> <volume>536</volume>:<fpage>292</fpage>–<lpage>297</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nature19097</pub-id></mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Holtmaat</surname> <given-names>A</given-names></string-name>, <string-name><surname>Bonhoeffer</surname> <given-names>T</given-names></string-name>, <string-name><surname>Chow</surname> <given-names>DK</given-names></string-name>, <string-name><surname>Chuckowree</surname> <given-names>J</given-names></string-name>, <string-name><surname>De Paola</surname> <given-names>V</given-names></string-name>, <string-name><surname>Hofer</surname> <given-names>SB</given-names></string-name>, <string-name><surname>Hübener</surname> <given-names>M</given-names></string-name>, <string-name><surname>Keck</surname> <given-names>T</given-names></string-name>, <string-name><surname>Knott</surname> <given-names>G</given-names></string-name>, <string-name><surname>Lee</surname> <given-names>WCA</given-names></string-name>, <string-name><surname>Mostany</surname> <given-names>R</given-names></string-name>, <string-name><surname>Mrsic-Flogel</surname> <given-names>TD</given-names></string-name>, <string-name><surname>Nedivi</surname> <given-names>E</given-names></string-name>, <string-name><surname>Portera-Cailliau</surname> <given-names>C</given-names></string-name>, <string-name><surname>Svoboda</surname> <given-names>K</given-names></string-name>, <string-name><surname>Trachtenberg</surname> <given-names>JT</given-names></string-name>, <string-name><surname>Wilbrecht</surname> <given-names>L.</given-names></string-name></person-group> <year>2009</year>. <article-title>Long-term, high-resolution imaging in the mouse neocortex through a chronic cranial window</article-title>. <source>Nat Protoc</source> <volume>4</volume>:<fpage>1128</fpage>–<lpage>1144</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nprot.2009.89</pub-id></mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname> <given-names>L</given-names></string-name>, <string-name><surname>Ledochowitsch</surname> <given-names>P</given-names></string-name>, <string-name><surname>Knoblich</surname> <given-names>U</given-names></string-name>, <string-name><surname>Lecoq</surname> <given-names>J</given-names></string-name>, <string-name><surname>Murphy</surname> <given-names>GJ</given-names></string-name>, <string-name><surname>Reid</surname> <given-names>RC</given-names></string-name>, <string-name><surname>de Vries</surname> <given-names>SEJ</given-names></string-name>, <string-name><surname>Koch</surname> <given-names>C</given-names></string-name>, <string-name><surname>Zeng</surname> <given-names>H</given-names></string-name>, <string-name><surname>Buice</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Waters</surname> <given-names>J</given-names></string-name>, <string-name><surname>Li</surname> <given-names>L.</given-names></string-name></person-group> <year>2021</year>. <article-title>Relationship between simultaneously recorded spiking activity and fluorescence signal in gcamp6 transgenic mice</article-title>. <source>Elife</source> <volume>10</volume>:<fpage>1</fpage>–<lpage>19</lpage>. doi:<pub-id pub-id-type="doi">10.7554/eLife.51675</pub-id></mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jazayeri</surname> <given-names>M</given-names></string-name>, <string-name><surname>Movshon</surname> <given-names>JA</given-names></string-name></person-group>. <year>2006</year>. <article-title>Optimal representation of sensory information by neural populations</article-title>. <source>Nat Neurosci</source> <volume>9</volume>:<fpage>690</fpage>–<lpage>696</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn1691</pub-id></mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jenkins</surname> <given-names>WM</given-names></string-name>, <string-name><surname>Masterton</surname> <given-names>B</given-names></string-name></person-group>. <year>1982</year>. <article-title>Sound Localization: Effects Of Unilateral Lesions in Central Auditory System</article-title>. <source>J Neurophysiol</source> <volume>47</volume>:<fpage>978</fpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jun</surname> <given-names>JJ</given-names></string-name>, <string-name><surname>Steinmetz</surname> <given-names>NA</given-names></string-name>, <string-name><surname>Siegle</surname> <given-names>JH</given-names></string-name>, <string-name><surname>Denman</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Bauza</surname> <given-names>M</given-names></string-name>, <string-name><surname>Barbarits</surname> <given-names>B</given-names></string-name>, <string-name><surname>Lee</surname> <given-names>AK</given-names></string-name>, <string-name><surname>Anastassiou</surname> <given-names>CA</given-names></string-name>, <string-name><surname>Andrei</surname> <given-names>A</given-names></string-name>, <string-name><surname>Aydin</surname> <given-names>Ç</given-names></string-name>, <string-name><surname>Barbic</surname> <given-names>M</given-names></string-name>, <string-name><surname>Blanche</surname> <given-names>TJ</given-names></string-name>, <string-name><surname>Bonin</surname> <given-names>V</given-names></string-name>, <string-name><surname>Couto</surname> <given-names>J</given-names></string-name>, <string-name><surname>Dutta</surname> <given-names>B</given-names></string-name>, <string-name><surname>Gratiy</surname> <given-names>SL</given-names></string-name>, <string-name><surname>Gutnisky</surname> <given-names>DA</given-names></string-name>, <string-name><surname>Häusser</surname> <given-names>M</given-names></string-name>, <string-name><surname>Karsh</surname> <given-names>B</given-names></string-name>, <string-name><surname>Ledochowitsch</surname> <given-names>P</given-names></string-name>, <string-name><surname>Lopez</surname> <given-names>CM</given-names></string-name>, <string-name><surname>Mitelut</surname> <given-names>C</given-names></string-name>, <string-name><surname>Musa</surname> <given-names>S</given-names></string-name>, <string-name><surname>Okun</surname> <given-names>M</given-names></string-name>, <string-name><surname>Pachitariu</surname> <given-names>M</given-names></string-name>, <string-name><surname>Putzeys</surname> <given-names>J</given-names></string-name>, <string-name><surname>Rich</surname> <given-names>PD</given-names></string-name>, <string-name><surname>Rossant</surname> <given-names>C</given-names></string-name>, <string-name><surname>Sun</surname> <given-names>WL</given-names></string-name>, <string-name><surname>Svoboda</surname> <given-names>K</given-names></string-name>, <string-name><surname>Carandini</surname> <given-names>M</given-names></string-name>, <string-name><surname>Harris</surname> <given-names>KD</given-names></string-name>, <string-name><surname>Koch</surname> <given-names>C</given-names></string-name>, <string-name><surname>O’Keefe</surname> <given-names>J</given-names></string-name>, <string-name><surname>Harris</surname> <given-names>TD</given-names></string-name></person-group>. <year>2017</year>. <article-title>Fully integrated silicon probes for high-density recording of neural activity</article-title>. <source>Nature</source> <volume>551</volume>:<fpage>232</fpage>–<lpage>236</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nature24636</pub-id></mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>King</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>Schnupp</surname> <given-names>JWH</given-names></string-name>, <string-name><surname>Doubell</surname> <given-names>TP</given-names></string-name></person-group>. <year>2001</year>. <article-title>The shape of ears to come: Dynamic coding of auditory space</article-title>. <source>Trends Cogn Sci</source> <volume>5</volume>:<fpage>261</fpage>–<lpage>270</lpage>. doi:<pub-id pub-id-type="doi">10.1016/S1364-6613(00)01660-0</pub-id></mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Knudsen</surname> <given-names>EI</given-names></string-name>, <string-name><surname>Konishi</surname> <given-names>M</given-names></string-name></person-group>. <year>1979</year>. <article-title>Mechanisms of sound localization in the barn owl (Tyto alba)</article-title>. <source>J Comp Physiol</source> <volume>133</volume>:<fpage>13</fpage>–<lpage>21</lpage>. doi:<pub-id pub-id-type="doi">10.1007/BF00663106</pub-id></mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kohn</surname> <given-names>A</given-names></string-name>, <string-name><surname>Coen-Cagli</surname> <given-names>R</given-names></string-name>, <string-name><surname>Kanitscheider</surname> <given-names>I</given-names></string-name>, <string-name><surname>Pouget</surname> <given-names>A</given-names></string-name></person-group>. <year>2016</year>. <article-title>Correlations and Neuronal Population Information</article-title>. <source>Annu Rev Neurosci</source> <volume>39</volume>:<fpage>237</fpage>–<lpage>256</lpage>. doi:<pub-id pub-id-type="doi">10.1146/annurev-neuro-070815-013851</pub-id></mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kulkarni</surname> <given-names>A</given-names></string-name>, <string-name><surname>Colburn</surname> <given-names>HS</given-names></string-name></person-group>. <year>1998</year>. <article-title>Role of spectral detail in sound-source localization</article-title>. <source>Nature</source> <volume>396</volume>:<fpage>747</fpage>–<lpage>749</lpage>. doi:<pub-id pub-id-type="doi">10.1038/25526</pub-id></mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lauer</surname> <given-names>AM</given-names></string-name>, <string-name><surname>Slee</surname> <given-names>SJ</given-names></string-name>, <string-name><surname>May</surname> <given-names>BJ</given-names></string-name></person-group>. <year>2011</year>. <article-title>Acoustic basis of directional acuity in laboratory mice</article-title>. <source>JARO - J Assoc Res Otolaryngol</source> <volume>12</volume>:<fpage>633</fpage>–<lpage>645</lpage>. doi:<pub-id pub-id-type="doi">10.1007/s10162-011-0279-y</pub-id></mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lesica</surname> <given-names>NA</given-names></string-name>, <string-name><surname>Lingner</surname> <given-names>A</given-names></string-name>, <string-name><surname>Grothe</surname> <given-names>B</given-names></string-name></person-group>. <year>2010</year>. <article-title>Population coding of interaural time differences in gerbils and barn owls</article-title>. <source>J Neurosci</source> <volume>30</volume>:<fpage>11696</fpage>–<lpage>11702</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.0846-10.2010</pub-id></mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lesicko</surname> <given-names>AMH</given-names></string-name>, <string-name><surname>Angeloni</surname> <given-names>CF</given-names></string-name>, <string-name><surname>Blackwell</surname> <given-names>JM</given-names></string-name>, <string-name><surname>De Biasi</surname> <given-names>M</given-names></string-name>, <string-name><surname>Geffen</surname> <given-names>MN</given-names></string-name></person-group>. <year>2022</year>. <article-title>Cortico-Fugal Regulation of Predictive Coding</article-title>. <source>Elife</source> <volume>11</volume>:<fpage>1</fpage>–<lpage>29</lpage>. doi:<pub-id pub-id-type="doi">10.7554/eLife.73289</pub-id></mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Montijn</surname> <given-names>JS</given-names></string-name>, <string-name><surname>Meijer</surname> <given-names>GT</given-names></string-name>, <string-name><surname>Lansink</surname> <given-names>CS</given-names></string-name>, <string-name><surname>Pennartz</surname> <given-names>CMA</given-names></string-name></person-group>. <year>2016</year>. <article-title>Population-Level Neural Codes Are Robust to Single-Neuron Variability from a Multidimensional Coding Perspective</article-title>. <source>Cell Rep</source> <volume>16</volume>:<fpage>2486</fpage>–<lpage>2498</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.celrep.2016.07.065</pub-id></mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Orton</surname> <given-names>LD</given-names></string-name>, <string-name><surname>Papasavvas</surname> <given-names>CA</given-names></string-name>, <string-name><surname>Rees</surname> <given-names>A</given-names></string-name></person-group>. <year>2016</year>. <article-title>Commissural Gain Control Enhances the Midbrain Representation of Sound Location</article-title>. <source>J Neurosci</source> <volume>36</volume>:<fpage>4470</fpage>–<lpage>4481</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.3012-15.2016</pub-id></mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ota</surname> <given-names>K</given-names></string-name>, <string-name><surname>Oisi</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Suzuki</surname> <given-names>T</given-names></string-name>, <string-name><surname>Ikeda</surname> <given-names>M</given-names></string-name>, <string-name><surname>Ito</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Ito</surname> <given-names>T</given-names></string-name>, <string-name><surname>Uwamori</surname> <given-names>H</given-names></string-name>, <string-name><surname>Kobayashi</surname> <given-names>K</given-names></string-name>, <string-name><surname>Kobayashi</surname> <given-names>M</given-names></string-name>, <string-name><surname>Odagawa</surname> <given-names>M</given-names></string-name>, <string-name><surname>Matsubara</surname> <given-names>C</given-names></string-name>, <string-name><surname>Kuroiwa</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Horikoshi</surname> <given-names>M</given-names></string-name>, <string-name><surname>Matsushita</surname> <given-names>J</given-names></string-name>, <string-name><surname>Hioki</surname> <given-names>H</given-names></string-name>, <string-name><surname>Ohkura</surname> <given-names>M</given-names></string-name>, <string-name><surname>Nakai</surname> <given-names>J</given-names></string-name>, <string-name><surname>Oizumi</surname> <given-names>M</given-names></string-name>, <string-name><surname>Miyawaki</surname> <given-names>A</given-names></string-name>, <string-name><surname>Aonishi</surname> <given-names>T</given-names></string-name>, <string-name><surname>Ode</surname> <given-names>T</given-names></string-name>, <string-name><surname>Murayama</surname> <given-names>M</given-names></string-name></person-group>. <year>2021</year>. <article-title>Fast, cell-resolution, contiguous-wide two-photon imaging to reveal functional network architectures across multi-modal cortical areas</article-title>. <source>Neuron</source> <volume>109</volume>:<fpage>1810</fpage>–<lpage>1824.e9.</lpage> doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2021.03.032</pub-id></mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pachitariu</surname> <given-names>M</given-names></string-name>, <string-name><surname>Stringer</surname> <given-names>C</given-names></string-name>, <string-name><surname>Harris</surname> <given-names>KD</given-names></string-name></person-group>. <year>2018</year>. <article-title>Robustness of spike deconvolution for neuronal calcium imaging</article-title>. <source>J Neurosci</source> <volume>38</volume>:<fpage>7976</fpage>–<lpage>7985</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.3339-17.2018</pub-id></mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Panniello</surname> <given-names>M</given-names></string-name>, <string-name><surname>King</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>Dahmen</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Walker</surname> <given-names>KMM</given-names></string-name></person-group>. <year>2018</year>. <article-title>Local and global spatial organization of interaural level difference and frequency preferences in auditory cortex</article-title>. <source>Cereb Cortex</source> <volume>28</volume>:<fpage>350</fpage>–<lpage>369</lpage>. doi:<pub-id pub-id-type="doi">10.1093/cercor/bhx295</pub-id></mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Park</surname> <given-names>TJ</given-names></string-name>, <string-name><surname>Klug</surname> <given-names>A</given-names></string-name>, <string-name><surname>Holinstat</surname> <given-names>M</given-names></string-name>, <string-name><surname>Grothe</surname> <given-names>B</given-names></string-name></person-group>. <year>2004</year>. <article-title>Interaural level difference processing in the lateral superior olive and the inferior colliculus</article-title>. <source>J Neurophysiol</source> <volume>92</volume>:<fpage>289</fpage>–<lpage>301</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.00961.2003</pub-id></mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Paxinos</surname> <given-names>G</given-names></string-name>, <string-name><surname>Franklin</surname> <given-names>K</given-names></string-name></person-group>. <year>2001</year>. <source>The Mouse brain in Stereotaxic Coordinates, Second Edi. ed</source>. <publisher-name>Academic Press</publisher-name>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pnevmatikakis</surname> <given-names>EA</given-names></string-name>, <string-name><surname>Giovannucci</surname> <given-names>A</given-names></string-name></person-group>. <year>2017</year>. <article-title>NoRMCorre: An online algorithm for piecewise rigid motion correction of calcium imaging data</article-title>. <source>J Neurosci Methods</source> <volume>291</volume>:<fpage>83</fpage>–<lpage>94</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.jneumeth.2017.07.031</pub-id></mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Prevedel</surname> <given-names>R</given-names></string-name>, <string-name><surname>Verhoef</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>Pernía-Andrade</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>Weisenburger</surname> <given-names>S</given-names></string-name>, <string-name><surname>Huang</surname> <given-names>BS</given-names></string-name>, <string-name><surname>Nöbauer</surname> <given-names>T</given-names></string-name>, <string-name><surname>Fernández</surname> <given-names>A</given-names></string-name>, <string-name><surname>Delcour</surname> <given-names>JE</given-names></string-name>, <string-name><surname>Golshani</surname> <given-names>P</given-names></string-name>, <string-name><surname>Baltuska</surname> <given-names>A</given-names></string-name>, <string-name><surname>Vaziri</surname> <given-names>A</given-names></string-name></person-group>. <year>2016</year>. <article-title>Fast volumetric calcium imaging across multiple cortical layers using sculpted light</article-title>. <source>Nat Methods</source> <volume>13</volume>:<fpage>1021</fpage>–<lpage>1028</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nmeth.4040</pub-id></mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rayleigh</surname> <given-names>L</given-names></string-name></person-group>. <year>1907</year>. <article-title>On our perception of sound direction</article-title>. <source>Philos Mag</source> <volume>13</volume>:<fpage>214</fpage>–<lpage>232</lpage>.</mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rupprecht</surname> <given-names>P</given-names></string-name>, <string-name><surname>Carta</surname> <given-names>S</given-names></string-name>, <string-name><surname>Hoffmann</surname> <given-names>A</given-names></string-name>, <string-name><surname>Echizen</surname> <given-names>M</given-names></string-name>, <string-name><surname>Blot</surname> <given-names>A</given-names></string-name>, <string-name><surname>Kwan</surname> <given-names>AC</given-names></string-name>, <string-name><surname>Dan</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Hofer</surname> <given-names>SB</given-names></string-name>, <string-name><surname>Kitamura</surname> <given-names>K</given-names></string-name>, <string-name><surname>Helmchen</surname> <given-names>F</given-names></string-name>, <string-name><surname>Friedrich</surname> <given-names>RW</given-names></string-name></person-group>. <year>2021</year>. <article-title>A database and deep learning toolbox for noise-optimized, generalized spike inference from calcium imaging</article-title>. <source>Nat Neurosci</source> <volume>24</volume>:<fpage>1324</fpage>–<lpage>1337</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41593-021-00895-5</pub-id></mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sadeghi</surname> <given-names>M</given-names></string-name>, <string-name><surname>Zhai</surname> <given-names>X</given-names></string-name>, <string-name><surname>Stevenson</surname> <given-names>IH</given-names></string-name>, <string-name><surname>Escabí</surname> <given-names>MA</given-names></string-name></person-group>. <year>2019</year>. <article-title>A neural ensemble correlation code for sound category identification</article-title>, <source>PLoS Biology</source>. doi:<pub-id pub-id-type="doi">10.1371/journal.pbio.3000449</pub-id></mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schindelin</surname> <given-names>J</given-names></string-name>, <string-name><surname>Arganda-Carreras</surname> <given-names>I</given-names></string-name>, <string-name><surname>Frise</surname> <given-names>E</given-names></string-name>, <string-name><surname>Kaynig</surname> <given-names>V</given-names></string-name>, <string-name><surname>Longair</surname> <given-names>M</given-names></string-name>, <string-name><surname>Pietzsch</surname> <given-names>T</given-names></string-name>, <string-name><surname>Preibisch</surname> <given-names>S</given-names></string-name>, <string-name><surname>Rueden</surname> <given-names>C</given-names></string-name>, <string-name><surname>Saalfeld</surname> <given-names>S</given-names></string-name>, <string-name><surname>Schmid</surname> <given-names>B</given-names></string-name>, <string-name><surname>Tinevez</surname> <given-names>JY</given-names></string-name>, <string-name><surname>White</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Hartenstein</surname> <given-names>V</given-names></string-name>, <string-name><surname>Eliceiri</surname> <given-names>K</given-names></string-name>, <string-name><surname>Tomancak</surname> <given-names>P</given-names></string-name>, <string-name><surname>Cardona</surname> <given-names>A</given-names></string-name></person-group>. <year>2012</year>. <article-title>Fiji: An open-source platform for biological-image analysis</article-title>. <source>Nat Methods</source> <volume>9</volume>:<fpage>676</fpage>–<lpage>682</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nmeth.2019</pub-id></mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schnupp</surname> <given-names>JW</given-names></string-name>, <string-name><surname>King a</surname> <given-names>J</given-names></string-name></person-group>. <year>1997</year>. <article-title>Coding for auditory space in the nucleus of the brachium of the inferior colliculus in the ferret</article-title>. <source>J Neurophysiol</source> <volume>78</volume>:<fpage>2717</fpage>–<lpage>2731</lpage>. doi:<pub-id pub-id-type="doi">10.1152/jn.1997.78.5.2717</pub-id></mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schofield</surname> <given-names>BR</given-names></string-name>, <string-name><surname>Beebe</surname> <given-names>NL</given-names></string-name></person-group>. <year>2019</year>. <article-title>Subtypes of GABAergic Cells in the Inferior Colliculus</article-title>. <source>Hear Res</source> <volume>376</volume>:<fpage>1</fpage>–<lpage>10</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.heares.2018.10.001</pub-id></mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stringer</surname> <given-names>C</given-names></string-name>, <string-name><surname>Michaelos</surname> <given-names>M</given-names></string-name>, <string-name><surname>Tsyboulski</surname> <given-names>D</given-names></string-name>, <string-name><surname>Lindo</surname> <given-names>SE</given-names></string-name>, <string-name><surname>Pachitariu</surname> <given-names>M</given-names></string-name></person-group>. <year>2021</year>. <article-title>High-precision coding in visual cortex</article-title>. <source>Cell</source> <volume>184</volume>:<fpage>2767</fpage>–<lpage>2778.e15.</lpage> doi:<pub-id pub-id-type="doi">10.1016/j.cell.2021.03.042</pub-id></mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stringer</surname> <given-names>C</given-names></string-name>, <string-name><surname>Pachitariu</surname> <given-names>M</given-names></string-name>, <string-name><surname>Steinmetz</surname> <given-names>N</given-names></string-name>, <string-name><surname>Reddy</surname> <given-names>CB</given-names></string-name>, <string-name><surname>Carandini</surname> <given-names>M</given-names></string-name>, <string-name><surname>Harris</surname> <given-names>KD</given-names></string-name></person-group>. <year>2019</year>. <article-title>Spontaneous behaviors drive multidimensional, brainwide activity</article-title>. <source>Science</source> <volume>364</volume>. doi:<pub-id pub-id-type="doi">10.1126/science.aav7893</pub-id></mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vanwalleghem</surname> <given-names>G</given-names></string-name>, <string-name><surname>Constantin</surname> <given-names>L</given-names></string-name>, <string-name><surname>Scott</surname> <given-names>EK</given-names></string-name></person-group>. <year>2021</year>. <article-title>Calcium Imaging and the Curse of Negativity</article-title>. <source>Front Neural Circuits</source> <volume>14</volume>:<fpage>1</fpage>–<lpage>10</lpage>. doi:<pub-id pub-id-type="doi">10.3389/fncir.2020.607391</pub-id></mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Weisenburger</surname> <given-names>S</given-names></string-name>, <string-name><surname>Prevedel</surname> <given-names>R</given-names></string-name>, <string-name><surname>Vaziri</surname> <given-names>A</given-names></string-name></person-group>. <year>2017</year>. <article-title>Quantitative evaluation of two-photon calcium imaging modalities for high-speed volumetric calcium imaging in scattering brain tissue</article-title>. <source>bioRxiv</source> <elocation-id>115659</elocation-id>. doi:<pub-id pub-id-type="doi">10.1101/115659</pub-id></mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Weisenburger</surname> <given-names>S</given-names></string-name>, <string-name><surname>Tejera</surname> <given-names>F</given-names></string-name>, <string-name><surname>Demas</surname> <given-names>J</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>B</given-names></string-name>, <string-name><surname>Manley</surname> <given-names>J</given-names></string-name>, <string-name><surname>Sparks</surname> <given-names>FT</given-names></string-name>, <string-name><surname>Martínez Traub</surname> <given-names>F</given-names></string-name>, <string-name><surname>Daigle</surname> <given-names>T</given-names></string-name>, <string-name><surname>Zeng</surname> <given-names>H</given-names></string-name>, <string-name><surname>Losonczy</surname> <given-names>A</given-names></string-name>, <string-name><surname>Vaziri</surname> <given-names>A</given-names></string-name></person-group>. <year>2019</year>. <article-title>Volumetric Ca<sup>2+</sup> Imaging in the Mouse Brain Using Hybrid Multiplexed Sculpted Light Microscopy</article-title>. <source>Cell</source> <volume>177</volume>:<fpage>1050</fpage>–<lpage>1066.e14.</lpage> doi:<pub-id pub-id-type="doi">10.1016/j.cell.2019.03.011</pub-id></mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Winer</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Chernock</surname> <given-names>ML</given-names></string-name>, <string-name><surname>Larue</surname> <given-names>DT</given-names></string-name>, <string-name><surname>Cheung</surname> <given-names>SW</given-names></string-name></person-group>. <year>2002</year>. <article-title>Descending projections to the inferior colliculus from the posterior thalamus and the auditory cortex in rat, cat, and monkey</article-title>. <source>Hear Res</source> <volume>168</volume>:<fpage>181</fpage>–<lpage>195</lpage>. doi:<pub-id pub-id-type="doi">10.1016/S0378-5955(02)00489-6</pub-id></mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wong</surname> <given-names>AB</given-names></string-name>, <string-name><surname>Borst</surname> <given-names>JGG</given-names></string-name></person-group>. <year>2019</year>. <article-title>Tonotopic and non-auditory organization of the mouse dorsal inferior colliculus revealed by two-photon imaging</article-title>. <source>Elife</source> <volume>8</volume>:<fpage>1</fpage>–<lpage>50</lpage>. doi:<pub-id pub-id-type="doi">10.7554/eLife.49091</pub-id></mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname> <given-names>J</given-names></string-name>, <string-name><surname>Shore</surname> <given-names>S</given-names></string-name></person-group>. <year>2006</year>. <article-title>Convergence of spinal trigeminal and cochlear nucleus projections in the inferior colliculus of the guinea pig</article-title>. <source>J Comp Neurol</source> <volume>495</volume>:<fpage>100</fpage>–<lpage>112</lpage>. doi:<pub-id pub-id-type="doi">10.1002/cne.20863</pub-id></mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.97598.2.sa4</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Petreanu</surname>
<given-names>Leopoldo</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Champalimaud Center for the Unknown</institution>
</institution-wrap>
<city>Lisbon</city>
<country>Portugal</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
</front-stub>
<body>
<p>The paper reports the <bold>important</bold> discovery that the mouse dorsal inferior colliculus, an auditory midbrain area, encodes sound location. The evidence supporting the claims is <bold>solid</bold>, being supported by both optical and electrophysiological recordings. The observations described should be of interest to auditory researchers studying the neural mechanisms of sound localization and the role of noise correlations in population coding.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.97598.2.sa3</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>In this study, the authors address whether the dorsal nucleus of the inferior colliculus (DCIC) in mice encodes sound source location within the front horizontal plane (i.e., azimuth). They do this using volumetric two-photon Ca2+ imaging and high-density silicon probes (Neuropixels) to collect single-unit data. Such recordings are beneficial because they allow large populations of simultaneous neural data to be collected. Their main results and the claims about those results are the following:</p>
<p>
(1) DCIC single-unit responses have high trial-to-trial variability (i.e., neural noise);</p>
<p>
(2) approximately 32% to 40% of DCIC single units have responses that are sensitive to sound source azimuth;</p>
<p>
(3) single-trial population responses (i.e., the joint response across all sampled single units in an animal) encode sound source azimuth &quot;effectively&quot; (as stated in the title) in that localization decoding error matches average mouse discrimination thresholds;</p>
<p>
(4) DCIC can encode sound source azimuth in a similar format to that in the central nucleus of the inferior colliculus (as stated in the Abstract);</p>
<p>
(5) evidence of noise correlation between pairs of neurons exists;</p>
<p>
and 6) noise correlations between responses of neurons help reduce population decoding error.</p>
<p>
While simultaneous recordings are not necessary to demonstrate results #1, #2, and #4, they are necessary to demonstrate results #3, #5, and #6.</p>
<p>Strengths:</p>
<p>
- Important research question to all researchers interested in sensory coding in the nervous system.</p>
<p>
- State-of-the-art data collection: volumetric two-photon Ca2+ imaging and extracellular recording using high-density probes. Large neuronal data sets.</p>
<p>
- Confirmation of imaging results (lower temporal resolution) with more traditional microelectrode results (higher temporal resolution).</p>
<p>
- Clear and appropriate explanation of surgical and electrophysiological methods. I cannot comment on the appropriateness of the imaging methods.</p>
<p>Strength of evidence for the claims of the study:</p>
<p>(1) DCIC single-unit responses have high trial-to-trial variability -</p>
<p>
The authors' data clearly shows this.</p>
<p>(2) Approximately 32% to 40% of DCIC single units have responses that are sensitive to sound source azimuth -</p>
<p>
The sensitivity of each neuron's response to sound source azimuth was tested with a Kruskal-Wallis test, which is appropriate since response distributions were not normal. Using this statistical test, only 8% of neurons (median for imaging data) were found to be sensitive to azimuth, and the authors noted this was not significantly different than the false positive rate. The Kruskal-Wallis test was not reported for electrophysiological data. The authors suggested that low numbers of azimuth-sensitive units resulting from the statistical analysis may be due to the combination of high neural noise and relatively low number of trials, which would reduce statistical power of the test. This is likely true, and highlights a weakness in the experimental design (i.e., relatively small number of trials). The authors went on to perform a second test of azimuth sensitivity-a chi-squared test-and found 32% (imaging) and 40% (e-phys) of single units to have statistically significant sensitivity. However, the use of a chi-squared test is questionable because it is meant to be used between two categorical variables, and neural response had to be binned before applying the test.</p>
<p>(3) Single-trial population responses encode sound source azimuth &quot;effectively&quot; in that localization decoding error matches average mouse discrimination thresholds -</p>
<p>
If only one neuron in a population had responses that were sensitive to azimuth, we would expect that decoding azimuth from observation of that one neuron's response would perform better than chance. By observing the responses of more than one neuron (if more than one were sensitive to azimuth), we would expect performance to increase. The authors found that decoding from the whole population response was no better than chance. They argue (reasonably) that this is because of overfitting of the decoder model-too few trials were used to fit too many parameters-and provide evidence from decoding combined with principal components analysis which suggests that overfitting is occurring. What is troubling is the performance of the decoder when using only a handful of &quot;top-ranked&quot; neurons (in terms of azimuth sensitivity) (Fig. 4F and G). Decoder performance seems to increase when going from one to two neurons, then decreases when going from two to three neurons, and doesn't get much better for more neurons than for one neuron alone. It seems likely there is more information about azimuth in the population response, but decoder performance is not able to capture it because spike count distributions in the decoder model are not being accurately estimated due to too few stimulus trials (14, on average). In other words, it seems likely that decoder performance is underestimating the ability of the DCIC population to encode sound source azimuth.</p>
<p>To get a sense of how effective a neural population is at coding a particular stimulus parameter, it is useful to compare population decoder performance to psychophysical performance. Unfortunately, mouse behavioral localization data do not exist. Instead, the authors compare decoder error to mouse left-right discrimination thresholds published previously by a different lab. However, this comparison is inappropriate because the decoder and the mice were performing different perceptual tasks. The decoder is classifying sound sources to 1 of 13 locations from left to right, whereas the mice were discriminating between left or right sources centered around zero degrees. The errors in these two tasks represent different things. The two data sets may potentially be more accurately compared by extracting information from the confusion matrices of population decoder performance. For example, when the stimulus was at -30 deg, how often did the decoder classify the stimulus to a lefthand azimuth? Likewise, when the stimulus was +30 deg, how often did the decoder classify the stimulus to a righthand azimuth?</p>
<p>(4) DCIC can encode sound source azimuth in a similar format to that in the central nucleus of the inferior colliculus -</p>
<p>
It is unclear what exactly the authors mean by this statement in the Abstract. There are major differences in the encoding of azimuth between the two neighboring brain areas: a large majority of neurons in the CNIC are sensitive to azimuth (and strongly so), whereas the present study shows a minority of azimuth-sensitive neurons in the DCIC. Furthermore, CNIC neurons fire reliably to sound stimuli (low neural noise), whereas the present study shows that DCIC neurons fire more erratically (high neural noise).</p>
<p>(5) Evidence of noise correlation between pairs of neurons exists -</p>
<p>
The authors' data and analyses seem appropriate and sufficient to justify this claim.</p>
<p>(6) Noise correlations between responses of neurons help reduce population decoding error -</p>
<p>
The authors show convincing analysis that performance of their decoder increased when simultaneously measured responses were tested (which include noise correlation) than when scrambled-trial responses were tested (eliminating noise correlation). This makes it seem likely that noise correlation in the responses improved decoder performance. The authors mention that the naïve Bayesian classifier was used as their decoder for computational efficiency, presumably because it assumes no noise correlation and, therefore, assumes responses of individual neurons are independent of each other across trials to the same stimulus. The use of a decoder that assumes independence seems key here in testing the hypothesis that noise correlation contains information about sound source azimuth. The logic of using this decoder could be more clearly spelled out to the reader. For example, if the null hypothesis is that noise correlations do not carry azimuth information, then a decoder that assumes independence should perform the same whether population responses are simultaneous or scrambled. The authors' analysis showing a difference in performance between these two cases provides evidence against this null hypothesis.</p>
<p>Minor weakness:</p>
<p>
- Most studies of neural encoding of sound source azimuth are done in a noise-free environment, but the experimental setup in the present study had substantial background noise. This complicates comparison of the azimuth tuning results in this study to those of other studies. One is left wondering if azimuth sensitivity would have been greater in the absence of background noise, particularly for the imaging data where the signal was only about 12 dB above the noise.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.97598.2.sa2</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>In the present study, Boffi et al. investigate the manner in which the dorsal cortex of the of the inferior colliculus (DCIC), an auditory midbrain area, encodes sound location azimuth in awake, passively listening mice. By employing volumetric calcium imaging (scanned temporal focusing or s-TeFo), complemented with high-density electrode electrophysiological recordings (neuropixels probes), they show that sound-evoked responses are exquisitely noisy, with only a small portion of neurons (units) exhibiting spatial sensitivity. Nevertheless, a naïve Bayesian classifier was able to predict the presented azimuth based on the responses from small populations of these spatially sensitive units. A portion of the spatial information was provided by correlated trial-to-trial response variability between individual units (noise correlations). The study presents a novel characterization of spatial auditory coding in a non-canonical structure, representing a noteworthy contribution specifically to the auditory field and generally to systems neuroscience, due to its implementation of state-of-the-art techniques in an experimentally challenging brain region. However, nuances in the calcium imaging dataset and the naïve Bayesian classifier warrant caution when interpreting some of the results.</p>
<p>Strengths:</p>
<p>The primary strength of the study lies in its methodological achievements, which allowed the authors to collect a comprehensive and novel dataset. While the DCIC is a dorsal structure, it extends up to a millimetre in depth, making it optically challenging to access in its entirety. It is also more highly myelinated and vascularised compared to e.g., the cerebral cortex, compounding the problem. The authors successfully overcame these challenges and present an impressive volumetric calcium imaging dataset. Furthermore, they corroborated this dataset with electrophysiological recordings, which produced overlapping results. This methodological combination ameliorates the natural concerns that arise from inferring neuronal activity from calcium signals alone, which are in essence an indirect measurement thereof.</p>
<p>Another strength of the study is its interdisciplinary relevance. For the auditory field, it represents a significant contribution to the question of how auditory space is represented in the mammalian brain. &quot;Space&quot; per se is not mapped onto the basilar membrane of the cochlea and must be computed entirely within the brain. For azimuth, this requires the comparison between miniscule differences between the timing and intensity of sounds arriving at each ear. It is now generally thought that azimuth is initially encoded in two, opposing hemispheric channels, but the extent to which this initial arrangement is maintained throughout the auditory system remains an open question. The authors observe only a slight contralateral bias in their data, suggesting that sound source azimuth in the DCIC is encoded in a more nuanced manner compared to earlier processing stages of the auditory hindbrain. This is interesting because it is also known to be an auditory structure to receive more descending inputs from the cortex.</p>
<p>Systems neuroscience continues to strive for the perfection of imaging novel, less accessible brain regions. Volumetric calcium imaging is a promising emerging technique, allowing the simultaneous measurement of large populations of neurons in three dimensions. But this necessitates corroboration with other methods, such as electrophysiological recordings, which the authors achieve. The dataset moreover highlights the distinctive characteristics of neuronal auditory representations in the brain. Its signals can be exceptionally sparse and noisy, which provide an additional layer of complexity in the processing and analysis of such datasets. This will undoubtedly be useful for future studies of other less accessible structures with sparse responsiveness.</p>
<p>Weaknesses:</p>
<p>Although the primary finding that small populations of neurons carry enough spatial information for a naïve Bayesian classifier to reasonably decode the presented stimulus is not called into question, certain idiosyncrasies, in particular the calcium imaging dataset and model, complicate specific interpretations of the model output, and the readership is urged to interpret these aspects of the study's conclusions with caution.</p>
<p>I remain in favour of volumetric calcium imaging as a suitable technique for the study, but the presently constrained spatial resolution is insufficient to unequivocally identify regions of interest as cell bodies (and are instead referred to as &quot;units&quot; akin to those of electrophysiological recordings). It remains possible that the imaging set is inadvertently influenced by non-somatic structures (including neuropil), which could report neuronal activity differently than cell bodies. Due to the lack of a comprehensive ground-truth comparison in this regard (which to my knowledge is impossible to achieve with current technology), it is difficult to imagine how many informative such units might have been missed because their signals were influenced by spurious, non-somatic signals, which could have subsequently misled the models. The authors reference the original Nature Methods article (Prevedel et al., 2016) throughout the manuscript, presumably in order to avoid having to repeat previously published experimental metrics. But the DCIC is neither the cortex nor hippocampus (for which the method was originally developed) and may not have the same light scattering properties (not to mention neuronal noise levels). Although the corroborative electrophysiology data largely eleviates these concerns for this particular study, the readership should be cognisant of such caveats, in particular those who are interested in implementing the technique for their own research.</p>
<p>A related technical limitation of the calcium imaging dataset is the relatively low number of trials (14) given the inherently high level of noise (both neuronal and imaging). Volumetric calcium imaging, while offering a uniquely expansive field of view, requires relatively high average excitation laser power (in this case nearly 200 mW), a level of exposure the authors may have wanted to minimise by maintaining a low number of repetitions, but I yield to them to explain. Calcium imaging is also inherently slow, requiring relatively long inter-stimulus intervals (in this case 5 s). This unfortunately renders any model designed to predict a stimulus (in this case sound azimuth) from particularly noisy population neuronal data like these as highly prone to overfitting, to which the authors correctly admit after a model trained on the entire raw dataset failed to perform significantly above chance level. This prompted them to feed the model only with data from neurons with the highest spatial sensitivity. This ultimately produced reasonable performance (and was implemented throughout the rest of the study), but it remains possible that if the model was fed with more repetitions of imaging data, its performance would have been more stable across the number of units used to train it. (All models trained with imaging data eventually failed to converge.) However, I also see these limitations as an opportunity to improve the technology further, which I reiterate will be generally important for volume imaging of other sparse or noisy calcium signals in the brain.</p>
<p>Indeed, in separate comments to these remarks, the authors confirmed that the low number of trials was technically limited, to which I emphasise is to no fault of their own. However, they also do not report this as a typical imaging constraint, such as photobleaching, but rather because the animals exhibited signs of stress and discomfort at longer imaging periods. From an animal welfare perspective, I would encourage the authors to state this in the methods for transparency. It would demonstrate their adherence to animal welfare policies, which I find to be an incredibly strong argument for limiting the number of trials in their study.</p>
<p>Transitioning to the naïve Bayesian classifier itself, I first openly ask the authors to justify their choice of this specific model. There are countless types of classifiers for these data, each with their own pros and cons. Did they actually try other models (such as support vector machines), which ultimately failed? If so, these negative results (even if mentioned en passant) would be extremely valuable to the community, in my view. I ask this specifically because different methods assume correspondingly different statistical properties of the input data, and to my knowledge naïve Bayesian classifiers assume that predictors (neuronal responses) are assumed to be independent within a class (azimuth). As the authors show that noise correlations are informative in predicting azimuth, I wonder why they chose a model that doesn't take advantage of these statistical regularities. It could be because of technical considerations (they mention computing efficiency), but I am left generally uncertain about the specific logic that was used to guide the authors through their analytical journey.</p>
<p>In a revised version of the manuscript, the authors indeed justify their choice of the naïve Bayesian classifier as a conservative approach (not taking into account noise correlations), which could only improve with other models (that do). They even tested various other commonly used models, such as support vector machines and k-nearest neighbours, to name a few, but do not report these efforts in the main manuscript. Interestingly, these models, which I supposed would perform better in fact did not overall - a finding that I have no way of interpreting but nevertheless find interesting. I would thus encourage the authors to include these results in a figure supplement and mention it en passant while justifying their selection of model (but please include detailed model parameters in the methods section).</p>
<p>That aside, there remain other peculiarities in model performance that warrant further investigation. For example, what spurious features (or lack of informative features) in these additional units prevented the models of imaging data from converging? In an orthogonal question, did the most spatially sensitive units share any detectable tuning features? A different model trained with electrophysiology data in contrast did not collapse in the range of top-ranked units plotted. Did this model collapse at some point after adding enough units, and how well did that correlate with the model for the imaging data? How well did the form (and diversity) of the spatial tuning functions as recorded with electrophysiology resemble their calcium imaging counterparts? These fundamental questions could be addressed with more basic, but transparent analyses of the data (e.g., the diversity of spatial tuning functions of their recorded units across the population). Even if the model extracts features that are not obvious to the human eye in traditional visualisations, I would still find this interesting.</p>
<p>Although these questions were not specifically addressed in the revised version of the manuscript, I also admit that I did not indent do assert that these should necessarily fall within the scope of the present study. I rather posed them as hypothetical directions one could pursue in future studies. Finally, further concerns I had with statements regarding the physiological meaning of the findings have been ameliorated by nicely modified statements, thus bringing transparency to the readership, which I appreciate.</p>
<p>In summary, the present study represents a significant body of work that contributes substantially to the field of spatial auditory coding and systems neuroscience. However, limitations of the imaging dataset and model as applied in the study muddles concrete conclusions about how the DCIC precisely encodes sound source azimuth and even more so to sound localisation in a behaving animal. Nevertheless, it presents a novel and unique dataset, which, regardless of secondary interpretation, corroborates the general notion that auditory space is encoded in an extraordinarily complex manner in the mammalian brain.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.97598.2.sa1</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Boffi and colleagues sought to quantify the single-trial, azimuthal information in the dorsal cortex of the inferior colliculus (DCIC), a relatively understudied subnucleus of the auditory midbrain. They accomplished this by using two complementary recording methods while mice passively listened to sounds at different locations: calcium imaging that recorded large neuronal populations but with poor temporal precision and multi-contact electrode arrays that recorded smaller neuronal populations with exact temporal precision. DCIC neurons respond variably, with inconsistent activity to sound onset and complex azimuthal tuning. Some of this variably was explained by ongoing head movements. The authors used a naïve Bayes decoder to probe the azimuthal information contained in the response of DCIC neurons on single trials. The decoder failed to classify sound location better than chance when using the raw population responses but performed significantly better than chance when using the top principal components of the population. Units with the most azimuthal tuning were distributed throughout the DCIC, possessed contralateral bias, and positively correlated responses. Interestingly, inter-trial shuffling decreased decoding performance, indicating that noise correlations contributed to decoder performance. Overall, Boffi and colleagues, quantified the azimuthal information available in the DCIC while mice passively listened to sounds, a first step in evaluating if and how the DCIC could contribute to sound localization.</p>
<p>Strengths:</p>
<p>The authors should be commended for collection of this dataset. When done in isolation (which is typical), calcium imaging and linear array recordings have intrinsic weaknesses. However, those weaknesses are alleviated when done in conjunction - especially when the data is consistent. This data set is extremely rich and will be of use for those interested in auditory midbrain responses to variable sound locations, correlations with head movements, and neural coding.</p>
<p>The DCIC neural responses are complex with variable responses to sound onset, complex azimuthal tuning and large inter-sound interval responses. Nonetheless, the authors do a decent job in wrangling these complex responses: finding non-canonical ways of determining dependence on azimuth and using interpretable decoders to extract information from the population.</p>
<p>Weaknesses:</p>
<p>The decoding results are a bit strange, likely because the population response is quite noisy on any given trial. Raw population responses failed to provide sufficient information concerning azimuth for significant decoding. Importantly, the decoder performed better than chance when certain principal components or top ranked units contributed but did not saturate with the addition of components or top ranked units. So, although there is azimuthal information in the recorded DCIC populations - azimuthal information appears somewhat difficult to extract.</p>
<p>Although necessary given the challenges associated with sampling many conditions with technically difficult recording methods, the limited number of stimulus repeats precludes interpretable characterization of the heterogeneity across the population. Nevertheless, the dataset is public so those interested can explore the diversity of the responses.</p>
<p>The observations from Boffi and colleagues raises the question: what drives neurons in the DCIC to respond? Sound azimuth appears to be a small aspect of the DCIC response. For example, the first 20 principal components which explain roughly 80% of the response variance are insufficient input for the decoder to predict sound azimuth above chance. Furthermore, snout and ear movements correlate with the population response in the DCIC (the ear movements are particularly peculiar given they seem to predict sound presentation). Other movements may be of particular interest to control for (e.g. eye movements are known to interact with IC responses in the primate). These observations, along with reported variance to sound onsets and inter-sound intervals, question the impact of azimuthal information emerging from DCIC responses. This is certainly out of scope for any one singular study to answer, but, hopefully, future work will elucidate the dominant signals in the DCIC population. It may be intuitive that engagement in a sound localization task may push azimuthal signals to the forefront of DCIC response, but azimuthal information could also easily be overtaken by other signals (e.g. movement, learning).</p>
<p>Boffi and colleagues set out to parse the azimuthal information available in the DCIC on a single trial. They largely accomplish this goal and are able to extract this information when allowing the units that contain more information about sound location to contribute to their decoding (e.g., through PCA or decoding on their activity specifically). Interestingly, they also found that positive noise correlations between units with similar azimuthal preferences facilitate this decoding - which is unusual given that this is typically thought to limit information. The dataset will be of value to those interested in the DCIC and to anyone interested in the role of noise correlations in population coding. Although this work is first step into parsing the information available in the DCIC, it remains difficult to interpret if/how this azimuthal information is used in localization behaviors of engaged mice.</p>
</body>
</sub-article>
<sub-article id="sa4" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.97598.2.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Boffi</surname>
<given-names>Juan C</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0116-6892</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Bathellier</surname>
<given-names>Brice</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Asari</surname>
<given-names>Hiroki</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3396-1935</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Prevedel</surname>
<given-names>Robert</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3366-4703</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>The following is the authors’ response to the original reviews.</p>
<disp-quote content-type="editor-comment">
<p><bold>Public Reviews:</bold></p>
<p><bold>Reviewer #1 (Public Review):</bold></p>
<p>Summary:</p>
<p>In this study, the authors address whether the dorsal nucleus of the inferior colliculus (DCIC) in mice encodes sound source location within the front horizontal plane (i.e., azimuth). They do this using volumetric two-photon Ca2+ imaging and high-density silicon probes (Neuropixels) to collect single-unit data. Such recordings are beneficial because they allow large populations of simultaneous neural data to be collected. Their main results and the claims about those results are the following:</p>
<p>(1) DCIC single-unit responses have high trial-to-trial variability (i.e., neural noise);</p>
<p>(2) approximately 32% to 40% of DCIC single units have responses that are sensitive tosound source azimuth;</p>
<p>(3) single-trial population responses (i.e., the joint response across all sampled single unitsin an animal) encode sound source azimuth &quot;effectively&quot; (as stated in title) in that localization decoding error matches average mouse discrimination thresholds;</p>
<p>(4) DCIC can encode sound source azimuth in a similar format to that in the central nucleusof the inferior colliculus (as stated in Abstract);</p>
<p>(5) evidence of noise correlation between pairs of neurons exists;</p>
<p>and 6) noise correlations between responses of neurons help reduce population decoding error.</p>
<p>While simultaneous recordings are not necessary to demonstrate results #1, #2, and #4, they are necessary to demonstrate results #3, #5, and #6.</p>
<p>Strengths:</p>
<list list-type="bullet">
<list-item><p>Important research question to all researchers interested in sensory coding in the nervous system.</p>
</list-item></list>
<p>- State-of-the-art data collection: volumetric two-photon Ca2+ imaging and extracellularrecording using high-density probes. Large neuronal data sets.</p>
<p>- Confirmation of imaging results (lower temporal resolution) with more traditionalmicroelectrode results (higher temporal resolution).</p>
<p>- Clear and appropriate explanation of surgical and electrophysiological methods. I cannot comment on the appropriateness of the imaging methods.</p>
<p>Strength of evidence for claims of the study:</p>
<p>(1) DCIC single-unit responses have high trial-to-trial variability - The authors' data clearlyshows this.</p>
<p>(2) Approximately 32% to 40% of DCIC single units have responses that are sensitive tosound source azimuth - The sensitivity of each neuron's response to sound source azimuth was tested with a Kruskal-Wallis test, which is appropriate since response distributions were not normal. Using this statistical test, only 8% of neurons (median for imaging data) were found to be sensitive to azimuth, and the authors noted this was not significantly different than the false positive rate. The Kruskal-Wallis test was not performed on electrophysiological data. The authors suggested that low numbers of azimuth-sensitive units resulting from the statistical analysis may be due to the combination of high neural noise and relatively low number of trials, which would reduce statistical power of the test. This may be true, but if single-unit responses were moderately or strongly sensitive to azimuth, one would expect them to pass the test even with relatively low statistical power. At best, if their statistical test missed some azimuthsensitive units, they were likely only weakly sensitive to azimuth. The authors went on to perform a second test of azimuth sensitivity-a chi-squared test-and found 32% (imaging) and 40% (e-phys) of single units to have statistically significant sensitivity. This feels a bit like fishing for a lower p-value. The Kruskal-Wallis test should have been left as the only analysis. Moreover, the use of a chi-squared test is questionable because it is meant to be used between two categorical variables, and neural response had to be binned before applying the test.</p>
</disp-quote>
<p>The determination of what is a physiologically relevant “moderate or strong azimuth sensitivity” is not trivial, particularly when comparing tuning across different relays of the auditory pathway like the CNIC, auditory cortex, or in our case DCIC, where physiologically relevant azimuth sensitivities might be different. This is likely the reason why azimuth sensitivity has been defined in diverse ways across the bibliography (see Groh, Kelly &amp; Underhill, 2003 for an early discussion of this issue). These diverse approaches include reaching a certain percentage of maximal response modulation, like used by Day et al. (2012, 2015, 2016) in CNIC, and ANOVA tests, like used by Panniello et al. (2018) and Groh, Kelly &amp; Underhill (2003) in auditory cortex and IC respectively. Moreover, the influence of response variability and biases in response distribution estimation due to limited sampling has not been usually accounted for in the determination of azimuth sensitivity.</p>
<p>As Reviewer #1 points out, in our study we used an appropriate ANOVA test (KruskalWallis) as a starting point to study response sensitivity to stimulus azimuth at DCIC. Please note that the alpha = 0.05 used for this test is not based on experimental evidence about physiologically relevant azimuth sensitivity but instead is an arbitrary p-value threshold. Using this test on the electrophysiological data, we found that ~ 21% of the simultaneously recorded single units reached significance (n = 4 mice). Nevertheless these percentages, in our small sample size (n = 4) were not significantly different from our false positive detection rate (p = 0.0625, Mann-Whitney, See Author response image 1 below).  In consequence, for both our imaging (Fig. 3C) and electrophysiological data, we could not ascertain if the percentage of neurons reaching significance in these ANOVA tests were indeed meaningfully sensitive to azimuth or this was due to chance.</p>
<fig id="sa4fig1">
<label>Author response image 1.</label>
<caption>
<title>Percentage of the neuropixels recorded DCIC single units across mice that showed significant median response tuning, compared to false positive detection rate (α = 0.</title>
<p>05, chance level).</p>
</caption>
<graphic mime-subtype="jpg" xlink:href="elife-97598-sa4-fig1.jpg" mimetype="image"/>
</fig>
<p>We reasoned that the observed markedly variable responses from DCIC units, which frequently failed to respond in many trials (Fig. 3D, 4A), in combination with the limited number of trial repetitions we could collect, results in under-sampled response distribution estimations. This under-sampling can bias the determination of stochastic dominance across azimuth response samples in Kruskal-Wallis tests. We would like to highlight that we decided not to implement resampling strategies to artificially increase the azimuth response sample sizes with “virtual trials”, in order to avoid “fishing for a smaller p-value”, when our collected samples might not accurately reflect the actual response population variability.</p>
<p>As an alternative to hypothesis testing based on ranking and determining stochastic dominance of one or more azimuth response samples (Kruskal-Wallis test), we evaluated the overall statistical dependency to stimulus azimuth of the collected responses.  To do this we implement the Chi-square test by binning neuronal responses into categories. Binning responses into categories can reduce the influence of response variability to some extent, which constitutes an advantage of the Chi-square approach, but we note the important consideration that these response categories are arbitrary.</p>
<p>Altogether, we acknowledge that our Chi-square approach to define azimuth sensitivity is not free of limitations and despite enabling the interrogation of azimuth sensitivity at DCIC, its interpretability might not extend to other brain regions like CNIC or auditory cortex. Nevertheless we hope the aforementioned arguments justify why the Kruskal-Wallis test simply could not “have been left as the only analysis”.</p>
<disp-quote content-type="editor-comment">
<p>(3) Single-trial population responses encode sound source azimuth &quot;effectively&quot; in that localization decoding error matches average mouse discrimination thresholds - If only one neuron in a population had responses that were sensitive to azimuth, we would expect that decoding azimuth from observation of that one neuron's response would perform better than chance. By observing the responses of more than one neuron (if more than one were sensitive to azimuth), we would expect performance to increase. The authors found that decoding from the whole population response was no better than chance. They argue (reasonably) that this is because of overfitting of the decoder modeltoo few trials used to fit too many parameters-and provide evidence from decoding combined with principal components analysis which suggests that overfitting is occurring. What is troubling is the performance of the decoder when using only a handful of &quot;topranked&quot; neurons (in terms of azimuth sensitivity) (Fig. 4F and G). Decoder performance seems to increase when going from one to two neurons, then decreases when going from two to three neurons, and doesn't get much better for more neurons than for one neuron alone. It seems likely there is more information about azimuth in the population response, but decoder performance is not able to capture it because spike count distributions in the decoder model are not being accurately estimated due to too few stimulus trials (14, on average). In other words, it seems likely that decoder performance is underestimating the ability of the DCIC population to encode sound source azimuth.</p>
<p>To get a sense of how effective a neural population is at coding a particular stimulus parameter, it is useful to compare population decoder performance to psychophysical performance. Unfortunately, mouse behavioral localization data do not exist. Therefore, the authors compare decoder error to mouse left-right discrimination thresholds published previously by a different lab. However, this comparison is inappropriate because the decoder and the mice were performing different perceptual tasks. The decoder is classifying sound sources to 1 of 13 locations from left to right, whereas the mice were discriminating between left or right sources centered around zero degrees. The errors in these two tasks represent different things. The two data sets may potentially be more accurately compared by extracting information from the confusion matrices of population decoder performance. For example, when the stimulus was at -30 deg, how often did the decoder classify the stimulus to a lefthand azimuth? Likewise, when the stimulus was +30 deg, how often did the decoder classify the stimulus to a righthand azimuth?</p>
</disp-quote>
<p>The azimuth discrimination error reported by Lauer et al. (2011) comes from engaged and highly trained mice, which is a very different context to our experimental setting with untrained mice passively listening to stimuli from 13 random azimuths. Therefore we did not perform analyses or interpretations of our results based on the behavioral task from Lauer et al. (2011) and only made the qualitative observation that the errors match for discussion.</p>
<p>We believe it is further important to clarify that Lauer et al. (2011) tested the ability of mice to discriminate between a positively conditioned stimulus (reference speaker at 0º center azimuth associated to a liquid reward) and a negatively conditioned stimulus (coming from one of five comparison speakers positioned at 20º, 30º, 50º, 70 and 90º azimuth, associated to an electrified lickport) in a conditioned avoidance task. In this task, mice are not precisely “discriminating between left or right sources centered around zero degrees”, making further analyses to compare the experimental design of Lauer et al (2011) and ours even more challenging for valid interpretation.</p>
<disp-quote content-type="editor-comment">
<p>(4) DCIC can encode sound source azimuth in a similar format to that in the central nucleusof the inferior colliculus - It is unclear what exactly the authors mean by this statement in the Abstract. There are major differences in the encoding of azimuth between the two neighboring brain areas: a large majority of neurons in the CNIC are sensitive to azimuth (and strongly so), whereas the present study shows a minority of azimuth-sensitive neurons in the DCIC. Furthermore, CNIC neurons fire reliably to sound stimuli (low neural noise), whereas the present study shows that DCIC neurons fire more erratically (high neural noise).</p>
</disp-quote>
<p>Since sound source azimuth is reported to be encoded by population activity patterns at CNIC (Day and Delgutte, 2013), we refer to a population activity pattern code as the “similar format” in which this information is encoded at DCIC. Please note that this is a qualitative comparison and we do not claim this is the “same format”, due to the differences the reviewer precisely describes in the encoding of azimuth at CNIC where a much larger majority of neurons show stronger azimuth sensitivity and response reliability with respect to our observations at DCIC. By this qualitative similarity of encoding format we specifically mean the similar occurrence of activity patterns from azimuth sensitive subpopulations of neurons in both CNIC and DCIC, which carry sufficient information about the stimulus azimuth for a sufficiently accurate prediction with regard to the behavioral discrimination ability.</p>
<disp-quote content-type="editor-comment">
<p>(5) Evidence of noise correlation between pairs of neurons exists - The authors' data andanalyses seem appropriate and sufficient to justify this claim.</p>
<p>(6) Noise correlations between responses of neurons help reduce population decodingerror - The authors show convincing analysis that performance of their decoder increased when simultaneously measured responses were tested (which include noise correlation) than when scrambled-trial responses were tested (eliminating noise correlation). This makes it seem likely that noise correlation in the responses improved decoder performance. The authors mention that the naïve Bayesian classifier was used as their decoder for computational efficiency, presumably because it assumes no noise correlation and, therefore, assumes responses of individual neurons are independent of each other across trials to the same stimulus. The use of decoder that assumes independence seems key here in testing the hypothesis that noise correlation contains information about sound source azimuth. The logic of using this decoder could be more clearly spelled out to the reader. For example, if the null hypothesis is that noise correlations do not carry azimuth information, then a decoder that assumes independence should perform the same whether population responses are simultaneous or scrambled. The authors' analysis showing a difference in performance between these two cases provides evidence against this null hypothesis.</p>
</disp-quote>
<p>We sincerely thank the reviewer for this careful and detailed consideration of our analysis approach. Following the reviewer’s constructive suggestion, we justified the decoder choice in the results section at the last paragraph of page 18:</p>
<p>“To characterize how the observed positive noise correlations could affect the representation of stimulus azimuth by DCIC top ranked unit population responses, we compared the decoding performance obtained by classifying the single-trial response patterns from top ranked units in the modeled decorrelated datasets versus the acquired data (with noise correlations). With the intention to characterize this with a conservative approach that would be less likely to find a contribution of noise correlations as it assumes response independence, we relied on the naive Bayes classifier for decoding throughout the study. Using this classifier, we observed that the modeled decorrelated datasets produced stimulus azimuth prediction error distributions that were significantly shifted towards higher decoding errors (Fig. 5B, C) and, in our imaging datasets, were not significantly different from chance level (Fig. 5B). Altogether, these results suggest that the detected noise correlations in our simultaneously acquired datasets can help reduce the error of the IC population code for sound azimuth.”</p>
<disp-quote content-type="editor-comment">
<p>Minor weakness:</p>
<p>- Most studies of neural encoding of sound source azimuth are done in a noise-free environment, but the experimental setup in the present study had substantial background noise. This complicates comparison of the azimuth tuning results in this study to those of other studies. One is left wondering if azimuth sensitivity would have been greater in the absence of background noise, particularly for the imaging data where the signal was only about 12 dB above the noise. The description of the noise level and signal + noise level in the Methods should be made clearer. Mice hear from about 2.5 - 80 kHz, so it is important to know the noise level within this band as well as specifically within the band overlapping with the signal.</p>
</disp-quote>
<p>We agree with the reviewer that this information is useful. In our study, the background R.M.S. SPL during imaging across the mouse hearing range (2.5-80kHz) was 44.53 dB and for neuropixels recordings 34.68 dB. We have added this information to the methods section of the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public Review):</bold></p>
<p>In the present study, Boffi et al. investigate the manner in which the dorsal cortex of the of the inferior colliculus (DCIC), an auditory midbrain area, encodes sound location azimuth in awake, passively listening mice. By employing volumetric calcium imaging (scanned temporal focusing or s-TeFo), complemented with high-density electrode electrophysiological recordings (neuropixels probes), they show that sound-evoked responses are exquisitely noisy, with only a small portion of neurons (units) exhibiting spatial sensitivity. Nevertheless, a naïve Bayesian classifier was able to predict the presented azimuth based on the responses from small populations of these spatially sensitive units. A portion of the spatial information was provided by correlated trial-to-trial response variability between individual units (noise correlations). The study presents a novel characterization of spatial auditory coding in a non-canonical structure, representing a noteworthy contribution specifically to the auditory field and generally to systems neuroscience, due to its implementation of state-of-the-art techniques in an experimentally challenging brain region. However, nuances in the calcium imaging dataset and the naïve Bayesian classifier warrant caution when interpreting some of the results.</p>
<p>Strengths:</p>
<p>The primary strength of the study lies in its methodological achievements, which allowed the authors to collect a comprehensive and novel dataset. While the DCIC is a dorsal structure, it extends up to a millimetre in depth, making it optically challenging to access in its entirety. It is also more highly myelinated and vascularised compared to e.g., the cerebral cortex, compounding the problem. The authors successfully overcame these challenges and present an impressive volumetric calcium imaging dataset. Furthermore, they corroborated this dataset with electrophysiological recordings, which produced overlapping results. This methodological combination ameliorates the natural concerns that arise from inferring neuronal activity from calcium signals alone, which are in essence an indirect measurement thereof.</p>
<p>Another strength of the study is its interdisciplinary relevance. For the auditory field, it represents a significant contribution to the question of how auditory space is represented in the mammalian brain. &quot;Space&quot; per se is not mapped onto the basilar membrane of the cochlea and must be computed entirely within the brain. For azimuth, this requires the comparison between miniscule differences between the timing and intensity of sounds arriving at each ear. It is now generally thought that azimuth is initially encoded in two, opposing hemispheric channels, but the extent to which this initial arrangement is maintained throughout the auditory system remains an open question. The authors observe only a slight contralateral bias in their data, suggesting that sound source azimuth in the DCIC is encoded in a more nuanced manner compared to earlier processing stages of the auditory hindbrain. This is interesting, because it is also known to be an auditory structure to receive more descending inputs from the cortex.</p>
<p>Systems neuroscience continues to strive for the perfection of imaging novel, less accessible brain regions. Volumetric calcium imaging is a promising emerging technique, allowing the simultaneous measurement of large populations of neurons in three dimensions. But this necessitates corroboration with other methods, such as electrophysiological recordings, which the authors achieve. The dataset moreover highlights the distinctive characteristics of neuronal auditory representations in the brain. Its signals can be exceptionally sparse and noisy, which provide an additional layer of complexity in the processing and analysis of such datasets. This will be undoubtedly useful for future studies of other less accessible structures with sparse responsiveness.</p>
<p>Weaknesses:</p>
<p>Although the primary finding that small populations of neurons carry enough spatial information for a naïve Bayesian classifier to reasonably decode the presented stimulus is not called into question, certain idiosyncrasies, in particular the calcium imaging dataset and model, complicate specific interpretations of the model output, and the readership is urged to interpret these aspects of the study's conclusions with caution.</p>
<p>I remain in favour of volumetric calcium imaging as a suitable technique for the study, but the presently constrained spatial resolution is insufficient to unequivocally identify regions of interest as cell bodies (and are instead referred to as &quot;units&quot; akin to those of electrophysiological recordings). It remains possible that the imaging set is inadvertently influenced by non-somatic structures (including neuropil), which could report neuronal activity differently than cell bodies. Due to the lack of a comprehensive ground-truth comparison in this regard (which to my knowledge is impossible to achieve with current technology), it is difficult to imagine how many informative such units might have been missed because their signals were influenced by spurious, non-somatic signals, which could have subsequently misled the models. The authors reference the original Nature Methods article (Prevedel et al., 2016) throughout the manuscript, presumably in order to avoid having to repeat previously published experimental metrics. But the DCIC is neither the cortex nor hippocampus (for which the method was originally developed) and may not have the same light scattering properties (not to mention neuronal noise levels). Although the corroborative electrophysiology data largely eleviates these concerns for this particular study, the readership should be cognisant of such caveats, in particular those who are interested in implementing the technique for their own research.</p>
<p>A related technical limitation of the calcium imaging dataset is the relatively low number of trials (14) given the inherently high level of noise (both neuronal and imaging). Volumetric calcium imaging, while offering a uniquely expansive field of view, requires relatively high average excitation laser power (in this case nearly 200 mW), a level of exposure the authors may have wanted to minimise by maintaining a low the number of repetitions, but I yield to them to explain.</p>
</disp-quote>
<p>We assumed that the levels of heating by excitation light measured at the neocortex in Prevedel et al. (2016), were representative for DCIC also. Nevertheless, we recognize this approximation might not be very accurate, due to the differences in tissue architecture and vascularization from these two brain areas, just to name a few factors. The limiting factor preventing us from collecting more trials in our imaging sessions was that we observed signs of discomfort or slight distress in some mice after ~30 min of imaging in our custom setup, which we established as a humane end point to prevent distress. In consequence imaging sessions were kept to 25 min in duration, limiting the number of trials collected. However we cannot rule out that with more extensive habituation prior to experiments the imaging sessions could be prolonged without these signs of discomfort or if indeed influence from our custom setup like potential heating of the brain by illumination light might be the causing factor of the observed distress. Nevertheless, we note that previous work has shown that ~200mW average power is a safe regime for imaging in the cortex by keeping brain heating minimal (Prevedel et al., 2016), without producing the lasting damages observed by immunohistochemisty against apoptosis markers above 250mW (Podgorski and Ranganathan 2016, <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00275.2016">https://doi.org/10.1152/jn.00275.2016</ext-link>).</p>
<disp-quote content-type="editor-comment">
<p>Calcium imaging is also inherently slow, requiring relatively long inter-stimulus intervals (in this case 5 s). This unfortunately renders any model designed to predict a stimulus (in this case sound azimuth) from particularly noisy population neuronal data like these as highly prone to overfitting, to which the authors correctly admit after a model trained on the entire raw dataset failed to perform significantly above chance level. This prompted them to feed the model only with data from neurons with the highest spatial sensitivity. This ultimately produced reasonable performance (and was implemented throughout the rest of the study), but it remains possible that if the model was fed with more repetitions of imaging data, its performance would have been more stable across the number of units used to train it. (All models trained with imaging data eventually failed to converge.) However, I also see these limitations as an opportunity to improve the technology further, which I reiterate will be generally important for volume imaging of other sparse or noisy calcium signals in the brain.</p>
<p>Transitioning to the naïve Bayesian classifier itself, I first openly ask the authors to justify their choice of this specific model. There are countless types of classifiers for these data, each with their own pros and cons. Did they actually try other models (such as support vector machines), which ultimately failed? If so, these negative results (even if mentioned en passant) would be extremely valuable to the community, in my view. I ask this specifically because different methods assume correspondingly different statistical properties of the input data, and to my knowledge naïve Bayesian classifiers assume that predictors (neuronal responses) are assumed to be independent within a class (azimuth). As the authors show that noise correlations are informative in predicting azimuth, I wonder why they chose a model that doesn't take advantage of these statistical regularities. It could be because of technical considerations (they mention computing efficiency), but I am left generally uncertain about the specific logic that was used to guide the authors through their analytical journey.</p>
</disp-quote>
<p>One of the main reasons we chose the naïve Bayesian classifier is indeed because it assumes that the responses of the simultaneously recorded neurons are independent and therefore it does not assume a contribution of noise correlations to the estimation of the posterior probability of each azimuth. This model would represent the null hypothesis that noise correlations do not contribute to the encoding of stimulus azimuth, which would be verified by an equal decoding outcome from correlated or decorrelated datasets. Since we observed that this is not the case, the model supports the alternative hypothesis that noise correlations do indeed influence stimulus azimuth encoding. We wanted to test these hypotheses with the most conservative approach possible that would be least likely to find a contribution of noise correlations. Other relevant reasons that justify our choice of the naive Bayesian classifier are its robustness against the limited numbers of trials we could collect in comparison to other more “data hungry” classifiers like SVM, KNN, or artificial neuronal nets. We did perform preliminary tests with alternative classifiers but the obtained decoding errors were similar when decoding the whole population activity (Author response image 2A). Dimensionality reduction following the approach described in the manuscript showed a tendency towards smaller decoding errors observed with an alternative classifier like KNN, but these errors were still larger than the ones observed with the naive Bayesian classifier (median error 45º). Nevertheless, we also observe a similar tendency for slightly larger decoding errors in the absence of noise correlations (decorrelated, Author response image 2B). Sentences detailing the logic of classifier choice are now included in the results section at page 10 and at the last paragraph of page 18 (see responses to Reviewer 1).</p>
<fig id="sa4fig2">
<label>Author response image 2.</label>
<caption>
<title>A) Cumulative distribution plots of the absolute cross-validated single-trial prediction errors obtained using different classifiers (blue; KNN: K-nearest neighbors; SVM: support vector machine ensemble) and chance level distribution (gray) on the complete populations of imaged units.</title>
<p>Cumulative distribution plots of the absolute cross-validated singletrial prediction errors obtained using a Bayes classifier (naive approximation for computation efficiency) to decode the single-trial response patterns from the 31 top ranked units in the simultaneously imaged datasets across mice (cyan), modeled decorrelated datasets (orange) and the chance level distribution associated with our stimulation paradigm (gray). Vertical dashed lines show the medians of cumulative distributions. K.S. w/Sidak: Kolmogorov-Smirnov with Sidak.</p>
</caption>
<graphic mime-subtype="jpg" xlink:href="elife-97598-sa4-fig2.jpg" mimetype="image"/>
</fig>
<disp-quote content-type="editor-comment">
<p>That aside, there remain other peculiarities in model performance that warrant further investigation. For example, what spurious features (or lack of informative features) in these additional units prevented the models of imaging data from converging?</p>
</disp-quote>
<p>Considering the amount of variability observed throughout the neuronal responses both in imaging and neuropixels datasets, it is easy to suspect that the information about stimulus azimuth carried in different amounts by individual DCIC neurons can be mixed up with information about other factors (Stringer et al., 2019). In an attempt to study the origin of these features that could confound stimulus azimuth decoding we explored their relation to face movement (Supplemental Figure 2), finding a correlation to snout movements, in line with previous work by Stringer et al. (2019).</p>
<disp-quote content-type="editor-comment">
<p>In an orthogonal question, did the most spatially sensitive units share any detectable tuning features? A different model trained with electrophysiology data in contrast did not collapse in the range of top-ranked units plotted. Did this model collapse at some point after adding enough units, and how well did that correlate with the model for the imaging data?</p>
</disp-quote>
<p>Our electrophysiology datasets were much smaller in size (number of simultaneously recorded neurons) compared to our volumetric calcium imaging datasets, resulting in a much smaller total number of top ranked units detected per dataset. This precluded the determination of a collapse of decoder performance due to overfitting beyond the range plotted in Fig 4G.</p>
<disp-quote content-type="editor-comment">
<p>How well did the form (and diversity) of the spatial tuning functions as recorded with electrophysiology resemble their calcium imaging counterparts? These fundamental questions could be addressed with more basic, but transparent analyses of the data (e.g., the diversity of spatial tuning functions of their recorded units across the population). Even if the model extracts features that are not obvious to the human eye in traditional visualisations, I would still find this interesting.</p>
</disp-quote>
<p>The diversity of the azimuth tuning curves recorded with calcium imaging (Fig. 3B) was qualitatively larger than the ones recorded with electrophysiology (Fig. 4B), potentially due to the larger sampling obtained with volumetric imaging. We did not perform a detailed comparison of the form and a more quantitative comparison of the diversity of these functions because the signals compared are quite different, as calcium indicator signal is subject to non linearities due to Ca2+ binding cooperativity and low pass filtering due to binding kinetics. We feared this could lead to misleading interpretations about the similarities or differences between the azimuth tuning functions in imaged and electrophysiology datasets. Our model uses statistical response dependency to stimulus azimuth, which does not rely on features from a descriptive statistic like mean response tuning. In this context, visualizing the trial-to-trial responses as a function of azimuth shows “features that are not obvious to the human eye in traditional visualizations” (Fig. 3D, left inset).</p>
<disp-quote content-type="editor-comment">
<p>Finally, the readership is encouraged to interpret certain statements by the authors in the current version conservatively. How the brain ultimately extracts spatial neuronal data for perception is anyone's guess, but it is important to remember that this study only shows that a naïve Bayesian classifier could decode this information, and it remains entirely unclear whether the brain does this as well. For example, the model is able to achieve a prediction error that corresponds to the psychophysical threshold in mice performing a discrimination task (~30 {degree sign}). Although this is an interesting coincidental observation, it does not mean that the two metrics are necessarily related. The authors correctly do not explicitly claim this, but the manner in which the prose flows may lead a non-expert into drawing that conclusion.</p>
</disp-quote>
<p>To avoid misleading the non-expert readers, we have clarified in the manuscript that the observed correspondence between decoding error and psychophysical threshold is explicitly coincidental.</p>
<p>Page 13, end of middle paragraph:</p>
<p>“If we consider the median of the prediction error distribution as an overall measure of decoding performance, the single-trial response patterns from subsamples of at least the 7 top ranked units produced median decoding errors that coincidentally matched the reported azimuth discrimination ability of mice (Fig 4G, minimum audible angle = 31º) (Lauer et al., 2011).”</p>
<p>Page 14, bottom paragraph:</p>
<p>“Decoding analysis (Fig. 4F) of the population response patterns from azimuth dependent top ranked units simultaneously recorded with neuropixels probes showed that the 4 top ranked units are the smallest subsample necessary to produce a significant decoding performance that coincidentally matches the discrimination ability of mice (31° (Lauer et al., 2011)) (Fig. 5F, G).”</p>
<p>We also added to the Discussion sentences clarifying that a relationship between these two variables remains to be determined and it also remains to be determined if the DCIC indeed performs a bayesian decoding computation for sound localization.</p>
<p>Page 20, bottom:</p>
<p>“… Concretely, we show that sound location coding does indeed occur at DCIC on the single trial basis, and that this follows a comparable mechanism to the characterized population code at CNIC (Day and Delgutte, 2013). However, it remains to be determined if indeed the DCIC network is physiologically capable of Bayesian decoding computations. Interestingly, the small number of DCIC top ranked units necessary to effectively decode stimulus azimuth suggests that sound azimuth information is redundantly distributed across DCIC top ranked units, which points out that mechanisms beyond coding efficiency could be relevant for this population code.</p>
<p>While the decoding error observed from our DCIC datasets obtained in passively listening, untrained mice coincidentally matches the discrimination ability of highly trained, motivated mice (Lauer et al., 2011), a relationship between decoding error and psychophysical performance remains to be determined. Interestingly, a primary sensory representations should theoretically be even more precise than the behavioral performance as reported in the visual system (Stringer et al., 2021).”</p>
<disp-quote content-type="editor-comment">
<p>Moreover, the concept of redundancy (of spatial information carried by units throughout the DCIC) is difficult for me to disentangle. One interpretation of this formulation could be that there are non-overlapping populations of neurons distributed across the DCIC that each could predict azimuth independently of each other, which is unlikely what the authors meant. If the authors meant generally that multiple neurons in the DCIC carry sufficient spatial information, then a single neuron would have been able to predict sound source azimuth, which was not the case. I have the feeling that they actually mean &quot;complimentary&quot;, but I leave it to the authors to clarify my confusion, should they wish.</p>
</disp-quote>
<p>We observed that the response patterns from relatively small fractions of the azimuth sensitive DCIC units (4-7 top ranked units) are sufficient to generate an effective code for sound azimuth, while 32-40% of all simultaneously recorded DCIC units are azimuth sensitive. In light of this observation, we interpreted that the azimuth information carried by the population should be redundantly distributed across the complete subpopulation of azimuth sensitive DCIC units.</p>
<disp-quote content-type="editor-comment">
<p>In summary, the present study represents a significant body of work that contributes substantially to the field of spatial auditory coding and systems neuroscience. However, limitations of the imaging dataset and model as applied in the study muddles concrete conclusions about how the DCIC precisely encodes sound source azimuth and even more so to sound localisation in a behaving animal. Nevertheless, it presents a novel and unique dataset, which, regardless of secondary interpretation, corroborates the general notion that auditory space is encoded in an extraordinarily complex manner in the mammalian brain.</p>
<p><bold>Reviewer #3 (Public Review):</bold></p>
<p>Summary:</p>
<p>Boffi and colleagues sought to quantify the single-trial, azimuthal information in the dorsal cortex of the inferior colliculus (DCIC), a relatively understudied subnucleus of the auditory midbrain. They used two complementary recording methods while mice passively listened to sounds at different locations: a large volume but slow sampling calcium-imaging method, and a smaller volume but temporally precise electrophysiology method. They found that neurons in the DCIC were variable in their activity, unreliably responding to sound presentation and responding during inter-sound intervals. Boffi and colleagues used a naïve Bayesian decoder to determine if the DCIC population encoded sound location on a single trial. The decoder failed to classify sound location better than chance when using the raw single-trial population response but performed significantly better than chance when using intermediate principal components of the population response. In line with this, when the most azimuth dependent neurons were used to decode azimuthal position, the decoder performed equivalently to the azimuthal localization abilities of mice. The top azimuthal units were not clustered in the DCIC, possessed a contralateral bias in response, and were correlated in their variability (e.g., positive noise correlations). Interestingly, when these noise correlations were perturbed by inter-trial shuffling decoding performance decreased. Although Boffi and colleagues display that azimuthal information can be extracted from DCIC responses, it remains unclear to what degree this information is used and what role noise correlations play in azimuthal encoding.</p>
<p>Strengths:</p>
<p>The authors should be commended for collection of this dataset. When done in isolation (which is typical), calcium imaging and linear array recordings have intrinsic weaknesses. However, those weaknesses are alleviated when done in conjunction with one another - especially when the data largely recapitulates the findings of the other recording methodology. In addition to the video of the head during the calcium imaging, this data set is extremely rich and will be of use to those interested in the information available in the DCIC, an understudied but likely important subnucleus in the auditory midbrain.</p>
<p>The DCIC neural responses are complex; the units unreliably respond to sound onset, and at the very least respond to some unknown input or internal state (e.g., large inter-sound interval responses). The authors do a decent job in wrangling these complex responses: using interpretable decoders to extract information available from population responses.</p>
<p>Weaknesses:</p>
<p>The authors observe that neurons with the most azimuthal sensitivity within the DCIC are positively correlated, but they use a Naïve Bayesian decoder which assume independence between units. Although this is a bit strange given their observation that some of the recorded units are correlated, it is unlikely to be a critical flaw. At one point the authors reduce the dimensionality of their data through PCA and use the loadings onto these components in their decoder. PCA incorporates the correlational structure when finding the principal components and constrains these components to be orthogonal and uncorrelated. This should alleviate some of the concern regarding the use of the naïve Bayesian decoder because the projections onto the different components are independent. Nevertheless, the decoding results are a bit strange, likely because there is not much linearly decodable azimuth information in the DCIC responses. Raw population responses failed to provide sufficient information concerning azimuth for the decoder to perform better than chance. Additionally, it only performed better than chance when certain principal components or top ranked units contributed to the decoder but not as more components or units were added. So, although there does appear to be some azimuthal information in the recoded DCIC populations - it is somewhat difficult to extract and likely not an 'effective' encoding of sound localization as their title suggests.</p>
</disp-quote>
<p>As described in the responses to reviewers 1 and 2, we chose the naïve Bayes classifier as a decoder to determine the influence of noise correlations through the most conservative approach possible, as this classifier would be least likely to find a contribution of correlated noise. Also, we chose this decoder due to its robustness against limited numbers of trials collected, in comparison to “data hungry” non linear classifiers like KNN or artificial neuronal nets. Lastly, we observed that small populations of noisy, unreliable (do not respond in every trial) DCIC neurons can encode stimulus azimuth in passively listening mice matching the discrimination error of trained mice. Therefore, while this encoding is definitely not efficient, it can still be considered effective.</p>
<disp-quote content-type="editor-comment">
<p>Although this is quite a worthwhile dataset, the authors present relatively little about the characteristics of the units they've recorded. This may be due to the high variance in responses seen in their population. Nevertheless, the authors note that units do not respond on every trial but do not report what percent of trials that fail to evoke a response. Is it that neurons are noisy because they do not respond on every trial or is it also that when they do respond they have variable response distributions? It would be nice to gain some insight into the heterogeneity of the responses.</p>
</disp-quote>
<p>The limited number of azimuth trial repetitions that we could collect precluded us from making any quantification of the unreliability (failures to respond) and variability in the response distributions from the units we recorded, as we feared they could be misleading. In qualitative terms, “due to the high variance in responses seen” in the recordings and the limited trial sampling, it is hard to make any generalization. In consequence we referred to the observed response variance altogether as neuronal noise. Considering these points, our datasets are publicly available for exploration of the response characteristics.</p>
<disp-quote content-type="editor-comment">
<p>Additionally, is there any clustering at all in response profiles or is each neuron they recorded in the DCIC unique?</p>
</disp-quote>
<p>We attempted to qualitatively visualize response clustering using dimensionality reduction, observing different degrees of clustering or lack thereof across the azimuth classes in the datasets collected from different mice. It is likely that the limited number of azimuth trials we could collect and the high response variance contribute to an inconsistent response clustering across datasets.</p>
<disp-quote content-type="editor-comment">
<p>They also only report the noise correlations for their top ranked units, but it is possible that the noise correlations in the rest of the population are different.</p>
</disp-quote>
<p>For this study, since our aim was to interrogate the influence of noise correlations on stimulus azimuth encoding by DCIC populations, we focused on the noise correlations from the top ranked unit subpopulation, which likely carry the bulk of the sound location information.  Noise correlations can be defined as correlation in the trial to trial response variation of neurons. In this respect, it is hard to ascertain if the rest of the population, that is not in the top rank unit percentage, are really responding and showing response variation to evaluate this correlation, or are simply not responding at all and show unrelated activity altogether. This makes observations about noise correlations from “the rest of the population” potentially hard to interpret.</p>
<disp-quote content-type="editor-comment">
<p>It would also be worth digging into the noise correlations more - are units positively correlated because they respond together (e.g., if unit x responds on trial 1 so does unit y) or are they also modulated around their mean rates on similar trials (e.g., unit x and y respond and both are responding more than their mean response rate). A large portion of trial with no response can occlude noise correlations. More transparency around the response properties of these populations would be welcome.</p>
</disp-quote>
<p>Due to the limited number of azimuth trial repetitions collected, to evaluate noise correlations we used the non parametric Kendall tau correlation coefficient which is a measure of pairwise rank correlation or ordinal association in the responses to each azimuth. Positive rank correlation would represent neurons more likely responding together. Evaluating response modulation “around their mean rates on similar trials” would require assumptions about the response distributions, which we avoided due to the potential biases associated with limited sample sizes.</p>
<disp-quote content-type="editor-comment">
<p>It is largely unclear what the DCIC is encoding. Although the authors are interested in azimuth, sound location seems to be only a small part of DCIC responses. The authors report responses during inter-sound interval and unreliable sound-evoked responses. Although they have video of the head during recording, we only see a correlation to snout and ear movements (which are peculiar since in the example shown it seems the head movements predict the sound presentation). Additional correlates could be eye movements or pupil size. Eye movement are of particular interest due to their known interaction with IC responses - especially if the DCIC encodes sound location in relation to eye position instead of head position (though much of eye-position-IC work was done in primates and not rodent). Alternatively, much of the population may only encode sound location if an animal is engaged in a localization task. Ideally, the authors could perform more substantive analyses to determine if this population is truly noisy or if the DCIC is integrating un-analyzed signals.</p>
</disp-quote>
<p>We unsuccessfully attempted eye tracking and pupillometry in our videos. We suspect that the reason behind this is a generally overly dilated pupil due to the low visible light illumination conditions we used which were necessary to protect the PMT of our custom scope.</p>
<p>It is likely that DCIC population activity is integrating un-analyzed signals, like the signal associated with spontaneous behaviors including face movements (Stringer et al., 2019), which we observed at the level of spontaneous snout movements. However investigating if and how these signals are integrated to stimulus azimuth coding requires extensive behavioral testing and experimentation which is out of the scope of this study. For the purpose of our study, we referred to trial-to-trial response variation as neuronal noise. We note that this definition of neuronal noise can, and likely does, include an influence from un-analyzed signals like the ones from spontaneous behaviors.</p>
<disp-quote content-type="editor-comment">
<p>Although this critique is ubiquitous among decoding papers in the absence of behavioral or causal perturbations, it is unclear what - if any - role the decoded information may play in neuronal computations. The interpretation of the decoder means that there is some extractable information concerning sound azimuth - but not if it is functional. This information may just be epiphenomenal, leaking in from inputs, and not used in computation or relayed to downstream structures. This should be kept in mind when the authors suggest their findings implicate the DCIC functionally in sound localization.</p>
</disp-quote>
<p>Our study builds upon previous reports by other independent groups relying on “causal and behavioral perturbations” and implicating DCIC in sound location learning induced experience dependent plasticity (Bajo et al., 2019, 2010; Bajo and King, 2012), which altogether argues in favor of DCIC functionality in sound localization.</p>
<p>Nevertheless, we clarified in the discussion of the revised manuscript that a relationship between the observed decoding error and the psychophysical performance, or the ability of the DCIC network to perform Bayesian decoding computations, both remain to be determined (please see responses to Reviewer #2).</p>
<disp-quote content-type="editor-comment">
<p>It is unclear why positive noise correlations amongst similarly tuned neurons would improve decoding. A toy model exploring how positive noise correlations in conjunction with unreliable units that inconsistently respond may anchor these findings in an interpretable way. It seems plausible that inconsistent responses would benefit from strong noise correlations, simply by units responding together. This would predict that shuffling would impair performance because you would then be sampling from trials in which some units respond, and trials in which some units do not respond - and may predict a bimodal performance distribution in which some trials decode well (when the units respond) and poor performance (when the units do not respond).</p>
</disp-quote>
<p>In samples with more that 2 dimensions, the relationship between signal and noise correlations is more complex than in two dimensional samples (Montijn et al., 2016) which makes constructing interpretable and simple toy models of this challenging. Montijn et al. (2016) provide a detailed characterization and model describing how the accuracy of a multidimensional population code can improve when including “positive noise correlations amongst similarly tuned neurons”. Unfortunately we could not successfully test their model based on Mahalanobis distances as we could not verify that the recorded DCIC population responses followed a multivariate gaussian distribution, due to the limited azimuth trial repetitions we could sample.</p>
<disp-quote content-type="editor-comment">
<p>Significance:</p>
<p>Boffi and colleagues set out to parse the azimuthal information available in the DCIC on a single trial. They largely accomplish this goal and are able to extract this information when allowing the units that contain more information about sound location to contribute to their decoding (e.g., through PCA or decoding on top unit activity specifically). The dataset will be of value to those interested in the DCIC and also to anyone interested in the role of noise correlations in population coding. Although this work is first step into parsing the information available in the DCIC, it remains difficult to interpret if/how this azimuthal information is used in localization behaviors of engaged mice.</p>
<p><bold>Recommendations for the authors:</bold></p>
<p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p>
<p>General:</p>
<p>The manuscript is generally well written, but could benefit from a quick proof by a native English speaker (e.g., &quot;the&quot; inferior colliculus is conventionally used with its article). The flow of arguments is also generally easy to follow, but I would kindly ask the authors to consider elaborating or clarifying the following points (including those already mentioned in my public review).</p>
<p>(1) Choice of model:</p>
<p>There are countless ways one can construct a decoder or classifier that can predict a presented sensory stimulus based on a population neuronal response. Given the assumptions of independence as mentioned in my public review, I would ask the authors to explicitly justify their choice of a naïve Bayesian classifier.</p>
</disp-quote>
<p>A section detailing the logic of classifier choice is now included in the results section at page 10 and the last paragraph of page 18 from the revised version of the manuscript.</p>
<disp-quote content-type="editor-comment">
<p>(2) Number of imaging repetitions:</p>
<p>For particularly noisy datasets, 14 repetitions is indeed quite few. I reckon this was not the choice of the authors, but rather limited by the inherent experimental conditions. Despite minimisation of required average laser power during the development of s-TeFo imaging, the authors still required almost 200 mW (which is still quite a lot of exposure). Although 14 repetitions for 13 azimuthal locations every 5 s is at face value a relatively short imaging session (~15 min.), at 191 mW, with the desire to image mice multiple times, I could imagine that this is a practical limitation the authors faced (to avoid excessive tissue heating or photodamage, which was assessed in the original Nature Methods article, but not here). Nevertheless, this logic (or whatever logic they had) should be explained for non-imaging experts in the readership.</p>
</disp-quote>
<p>This is now addressed in the answers to the public reviews.</p>
<disp-quote content-type="editor-comment">
<p>(3) Redundancy:</p>
<p>It is honestly unclear to me what the authors mean by this. I don't speculate that they mean there are &quot;redundant&quot; (small) populations of neurons that sufficiently encode azimuth, but I'm actually not certain. If that were the case, I believe this would need further clarification, since redundant representations would be both inconsistent with the general (perhaps surprising) finding that large populations are not required in the DCIC, which is thought to be the case at earlier processing stages.</p>
</disp-quote>
<p>In the text we are referring to the azimuth information being redundantly distributed across DCIC top ranked units. We do not mention redundant “populations of neurons”.</p>
<disp-quote content-type="editor-comment">
<p>(4) Correspondence of decoding accuracy with psychometric functions in mice: While this is an interesting coincidental observation, it should not be interpreted that the neuronal detection threshold in the DCIC somehow is somehow responsible its psychometric counterpart (which is an interesting yet exceedingly complex question). Although I do not believe the authors intended to suggest this, I would personally be cautious in the way I describe this correspondence. I mention this because the authors point it out multiple times in the manuscript (whereas I would have just mentioned it once in passing).</p>
</disp-quote>
<p>This is now clarified in the revised manuscript.</p>
<disp-quote content-type="editor-comment">
<p>(5) Noisy vs. sparse:</p>
<p>I'm confident that the authors understand the differences between these terms, both in concept (stochastic vs. scattered) and in context (neuronal vs. experimental), but I personally would be cautious in the way I use them in the description of the study. Indeed, auditory neuronal signals are to my knowledge generally thought to be both sparse and noisy, which is in itself interesting, but the study also deals with substantial experimental (recording) noise, and I think it's important for the readership to understand when &quot;noise&quot; refers to the recordings (in particular the imaging data) and to neuronal activity. I mention this specifically because &quot;noisy&quot; appears in the title.</p>
</disp-quote>
<p>We have clarified this issue at the bottom of page 5 by adding the following sentences to the revised manuscript:</p>
<p>“In this section we used the word “noise” to refer to the sound stimuli used and recording setup background sound levels or recording noise in the acquired signals. To avoid confusion, from now on in the manuscript the word “noise” will be used in the context of neuronal noise, which is the trial-to-trial variation in neuronal responses unrelated to stimuli, unless otherwise noted.”</p>
<disp-quote content-type="editor-comment">
<p>(6)  More details in the Methods:</p>
<p>The Methods section is perhaps the least-well structured part of the present manuscript in my view, and I encourage the authors to carefully go through it and add the following information (in case I somehow missed it).</p>
<p>a. Please also indicate the number of animals used here.</p>
</disp-quote>
<p>Added.</p>
<disp-quote content-type="editor-comment">
<p>b. How many sessions were performed on each mouse?</p>
</disp-quote>
<p>This is already specified in the methods section in page 25:</p>
<p>“mice were imaged a total of 2-11 times (sessions), one to three times a week.”</p>
<p>We added for clarification:</p>
<p>“Datasets here analyzed and reported come from the imaging session in which we observed maximal calcium sensor signal (peak AAV expression) and maximum number of detected units.”</p>
<disp-quote content-type="editor-comment">
<p>c. For the imaging experiments, was it possible to image the same units from session tosession?</p>
</disp-quote>
<p>This is not possible for sTeFo 2P data due to low spatial resolution which makes precisely matching neuron ROIs across sessions challenging.</p>
<disp-quote content-type="editor-comment">
<p>d. Could the authors please add more detail to the analyses of the videos (to track facialmovements) or provide a reference?</p>
</disp-quote>
<p>Added citation.</p>
<disp-quote content-type="editor-comment">
<p>e. The same goes for the selection of subcellular regions of interest that were used as&quot;units.&quot;</p>
</disp-quote>
<p>Added to page 25:</p>
<p>“We used the CaImAn package (Giovannucci et al., 2019) for automatic ROI segmentation through constrained non negative matrix factorization and selected ROIs (Units) showing clear Ca transients consistent with neuronal activity, and IC neuron somatic shape and size (Schofield and Beebe, 2019).”</p>
<disp-quote content-type="editor-comment">
<p>Specific: In order to maximise the efficiency of my comments and suggestions (as there are no line numbers), my numerated points are organised in sequential order.</p>
<p>(1) Abstract: I wouldn't personally motivate the study with the central nucleus of the IC (i.e. Idon't think this is necessary). I think the authors can motivate it simply with the knowledge gaps in spatial coding throughout the auditory system, in which such large data sets such as the ones presented here are of general value.</p>
<p>(2) Page 4: 15-50 kHz &quot;white&quot; noise is incorrect. It should be &quot;band-passed&quot; noise.</p>
</disp-quote>
<p>Changed.</p>
<disp-quote content-type="editor-comment">
<p>(3) Supplemental figure 1, panel A: Since the authors could not identify cell bodiesunequivocally from their averaged volume timeseries data, it would be clearer to the readership if larger images are shown, so that they can evaluate (speculate) for themselves what subcellular structures were identified as units. Even better would be to include a planar image through a cross-section. As mentioned above, not everything determined for the cortex or hippocampus can be assumed to be true for the DCIC.</p>
</disp-quote>
<p>The raw images and segmentations are publicly available for detailed inspections.</p>
<disp-quote content-type="editor-comment">
<p>(4) Supplemental figure 2, panel A: This panel requires further explanation, in particular thepanel on the right. I assume that to be a simple subtraction of sequential frames, but I'm thrown off by the &quot;d(Grey)&quot; colour bar. Also, if &quot;grey&quot; refers to the neutral colour, it is conventionally spelled &quot;gray&quot; in US-American English.</p>
</disp-quote>
<p>Changed.</p>
<disp-quote content-type="editor-comment">
<p>(5) Supplemental figure 2, panel B: I'm personally curious why the animals exhibitedmovement just prior to a stimulus. Did they learn to anticipate the presentation of a sound after some habituation? Is that somehow a pre-emptive startle response? We observe that in our own experiments (but as we stochastically vary the inter-trial-intervals, the movement typically occurs directly after the stimulus). I don't suggest the authors dwell on this, but I find it an interesting observation.</p>
</disp-quote>
<p>It is indeed interesting, but we can’t conclude much about it without comparing it to random inter-trial-intervals.</p>
<disp-quote content-type="editor-comment">
<p>(6) Supplemental figure 3: I personally find these data (decoding of all electrophysiologicaldata) of central relevance to the study, since it mirrors the analyses presented for its imaging data counterpart and encourage the authors to move it to the main text.</p>
</disp-quote>
<p>Changed.</p>
<disp-quote content-type="editor-comment">
<p>(7) Page 12: Do the authors have any further analyses of spatial tuning functions? We allknow they can parametrically obscure (i.e., bi-lobed, non-monotonic, etc.), but having these parameters (even if just in a supplemental figure) would be informative for the spatial auditory community.</p>
</disp-quote>
<p>We dedicated significant effort to attempt to parametrize and classify the azimuth response dependency functions from the recorded DCIC cells in an unbiased way. Nevertheless, given the observed response noise and the “obscure” properties of spatial tuning functions mentioned by the reviewer, we could only reach the general qualitative observation of having a more frequent contralateral selectivity.</p>
<disp-quote content-type="editor-comment">
<p>(8) Page 14 (end): Here, psychometric correspondence is referenced. Please add theLauer et al., (2011) reference, or, as I would, remove the statement entirely and save it for the discussion (where it is also mentioned and referenced).</p>
</disp-quote>
<p>Changed.</p>
<disp-quote content-type="editor-comment">
<p>(9) Figure 5, Panels B and C: Why don't the authors report the Kruskal-Wallis tests (forincreasing number of units training the model), akin to e.g., Panel G of Figure 4? I think that would be interesting to see (e.g., if the number of required units to achieve statistical significance is the same).</p>
</disp-quote>
<p>Within class randomization produced a moderate effect on decoder performance, achieving statistical significance at similar numbers of units, as seen in figure 5 panels B and C. We did not include these plots for the sake of not cluttering the figure with dense distributions and fuzzing the visualization of the differences between the distributions shown.</p>
<disp-quote content-type="editor-comment">
<p>(10) Figure 5, Panels B and C (histograms): I see a bit of skewedness in the distributions(even after randomisation). Where does this come from? This is just a small talking point.</p>
</disp-quote>
<p>We believe this is potentially due to more than one distribution of pairwise correlations combined into one histogram (like in a Gaussian mixture model).</p>
<disp-quote content-type="editor-comment">
<p>(11) Page 21: Could the authors please specify that the Day and Delgutte (2013) study wasperformed on rabbits? Since rabbits have an entirely different spectral hearing range compared to mice, spatial coding principles could very well be different in those animals (and I'm fairly certain such a study has not yet been published for mice).</p>
</disp-quote>
<p>Specified.</p>
<disp-quote content-type="editor-comment">
<p>(12) Page 22: I'd encourage the authors to remove the reference to Rayleigh's duplextheory, since mice hardly (if at all) use interaural time differences for azimuthal sound localisation, given their generally high-frequency hearing range.</p>
</disp-quote>
<p>That sentence is meant to discuss beyond the mouse model an exciting outlook of our findings in light of previous reports, which is a hypothetical functional relationship between the tonotopy in DCIC and the spatial distribution of azimuth sensitive DCIC neurons. We have clarified this now in the text.</p>
<disp-quote content-type="editor-comment">
<p>(13) Page 23: I believe the conventional verb for gene delivery with viruses is still&quot;transduce&quot; (or &quot;infect&quot;, but not &quot;induce&quot;). What was the specific &quot;syringe&quot; used for stereotactic injections? Also, why were mice housed separately after surgery? This question pertains to animal welfare.</p>
</disp-quote>
<p>Changed. The syringe was a 10ml syringe to generate positive or negative pressure, coupled to the glass needle through a silicon tubing via a luer 3-way T valve. Single housing was chosen to avoid mice compromising each other’s implantations. Therefore this can be seen as a refinement of our method to maximize the chances of successful imaging per implanted mouse.</p>
<disp-quote content-type="editor-comment">
<p>(14) Page 25: Could the authors please indicate the refractory period violation time windowhere? I had to find it buried in the figure caption of Supplementary figure 1.</p>
</disp-quote>
<p>Added.</p>
<disp-quote content-type="editor-comment">
<p>(15) Page 27: What version of MATLAB was used? This could be important for reproductionof the analyses, since The Mathworks is infamously known to add (or even more deplorably, modify) functions in particular versions (and not update older ones accordingly).</p>
</disp-quote>
<p>Added.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #3 (Recommendations For The Authors):</bold></p>
<p>Overall I thought this was a nice manuscript and a very interesting dataset. Here are some suggestions and minor corrections:</p>
<p>You may find this work of interest - 'A monotonic code for sound azimuth in primate inferior colliculus' 2003, Groh, Kelly &amp; Underhill.</p>
</disp-quote>
<p>We thank the reviewer for pointing out this extremely relevant reference, which we regrettably failed to cite. It is now included in the revised version of the manuscript.</p>
<disp-quote content-type="editor-comment">
<p>In your introduction, you state &quot;our findings point to a functional role of DCIC in sound location coding&quot;. Though your results show that there is azimuthal information contained in a subset of DCIC units there's no evidence in the manuscript that shows a functional link between this representation and sound localization.</p>
</disp-quote>
<p>This is now addressed in the answers to the public reviews.</p>
<disp-quote content-type="editor-comment">
<p>I found the variability in your DCIC population quite striking - especially during the intersound intervals. The entrainment of the population in the imaging datatset suggests some type of input activating the populations - maybe these are avenues for further probing the variability here:</p>
<p>(1) I'm curious if you can extract eye movements from your video. Work from Jennifer Grohshows that some cells in the primate inferior colliculus are sensitive to different eye positions (Groh et. al., 2001). With recent work showing eye movements in rodents, it may explain some of the variance in the DCIC responses.</p>
</disp-quote>
<p>This is now addressed in the answers to the public reviews.</p>
<disp-quote content-type="editor-comment">
<p>(2) I was also curious if the motor that moves the speaker made noise It could be possiblesome of the 'on going' activity could be some sound-evoked response.</p>
</disp-quote>
<p>We were careful to set the stepper motor speed so that it produced low frequency noise, within a band mostly outside of the hearing range of mice (&lt;4kHz). Nevertheless, we cannot fully rule out that a very quiet but perhaps very salient component of the motor noise could influence the activity during the inter trial periods. The motor was stationary and quiet for a period of at least one stimulus duration before and during stimulus presentation.</p>
<disp-quote content-type="editor-comment">
<p>(3) Was the sound you present frozen or randomly generated on each trial? Could therebe some type of structure in the noise you presented that sometimes led cells to respond to a particular azimuth location but not others?</p>
</disp-quote>
<p>The sound presented was frozen noise. This is now clarified in the methods section.</p>
<disp-quote content-type="editor-comment">
<p>It may be useful to quantify the number of your units that had refractory period violations.</p>
</disp-quote>
<p>Our manual curation of sorted units was very stringent to avoid mixing differently tuned neurons. The single units analyzed had very infrequent refractory period violations, in less than ~5% of the spikes, considering a 2 ms refractory period.</p>
<disp-quote content-type="editor-comment">
<p>Was the video recording contralateral or ipsilateral to the recording?</p>
</disp-quote>
<p>The side of the face ipsilateral to the imaged IC was recorded. Added to methods.</p>
<disp-quote content-type="editor-comment">
<p>I was struck by the snout and ear movements - in the example shown in Supplementary Figure 2B it appears as they are almost predicting sound onset. Was there any difference in ear movements in the habituated and non-habituated animals? Also, does the placement of the cranial window disturb any of the muscles used in ear movement?</p>
</disp-quote>
<p>Mouse snout movements appear to be quite active perhaps reflecting arousal (Stringer et al., 2019). We cannot rule out that the cranial window implantation disturbed ear movement but while moving the mouse headfixed we observed what could be considered normal ear movements.</p>
<disp-quote content-type="editor-comment">
<p>Did you correlate time-point by time-point in the average population activity and movement or did you try different temporal labs/leads in case the effect of the movements was delayed in some way?</p>
</disp-quote>
<p>Point by point due to 250ms time resolution of imaging.</p>
<disp-quote content-type="editor-comment">
<p>Are the video recordings only available during the imaging? It would be nice to see the same type of correlations in the neuropixel-acquired data as well.</p>
</disp-quote>
<p>Only imaging. For neuropixels recordings, we were skeptical about face videography as we suspected that face movements were likely influenced by the acute nature of the preparation procedure. Our cranial window preparation in the other hand involved a recovery period of at least 4 weeks. Therefore we were inclined to perform videographical interrogation of face movements on these mice instead.</p>
<disp-quote content-type="editor-comment">
<p>If you left out more than 1 trial do you think this would help your overfitting issue (e.g. leaving out 20% of the data).</p>
</disp-quote>
<p>Due to the relatively small number of trial repetitions collected, fitting the model with an even smaller training dataset is unlikely to help overfitting and will likely decrease decoder performance.</p>
<disp-quote content-type="editor-comment">
<p>It would be nice to see a confusion matrix - even though azimuthal error and cumulative distribution of error are a fine way to present the data - a confusion matrix would tell us which actual sounds the decoder is confusing. Just looking at errors could result in some funky things where you reduce the error generally but never actually estimate the correct location.</p>
</disp-quote>
<p>We considered confusion matrices early on in our study but they were not easily interpretable or insightful, likely due to the relatively low discrimination ability of the mouse model with +/- 30º error after extensive training. Therefore, we reasoned that in passively listening mice (and likely trained mice too) with limited trial repetitions, an undersampled and diffuse confusion matrix is expected which is not an ideal means of visualizing and comparing decoding errors. Hence we relied on cumulative error distributions.</p>
<disp-quote content-type="editor-comment">
<p>Do your top-ranked units have stronger projections onto your 10-40 principal components?</p>
<p>It would be interesting to know if the components are mostly taking into account those 30ish percent of the population that is dependent upon azimuth.</p>
</disp-quote>
<p>Inspection of PC loadings across units ranked based on response dependency to stimulus azimuth does not show a consistent stronger projection of top ranked units onto the first 10-40 principal components (Author response image 3).</p>
<fig id="sa4fig3">
<label>Author response image 3.</label>
<caption>
<title>PC loading matrices for each recorded mouse.</title>
<p>The units recorded in each mouse are ranked in descending order of response dependency to stimulus azimuth based on  the p value of the chi square test. Units above the red dotted line display a chi square p value &lt; 0.05, units below this line have p values &gt;= 0.05.</p>
</caption>
<graphic mime-subtype="jpg" xlink:href="elife-97598-sa4-fig3.jpg" mimetype="image"/>
</fig>
<disp-quote content-type="editor-comment">
<p>How much overlap is there in the tuning of the top-ranked units?</p>
</disp-quote>
<p>This is quite varying from mouse to mouse and imaging vs electrophysiology, which makes it hard to make a generalization since this might depend on the unique DCIC population sampled in each mouse.</p>
<p>I'm not really sure I follow what the nS/N adds - it doesn't really measure tuning but it seems to be introduced to discuss/extract some measure of tuning.</p>
<disp-quote content-type="editor-comment">
<p>nS/N is used to quantify how noisy neurons are, independent of how sensitive their responses are to the stimulus azimuth.</p>
<p>Is the noise correlation - observed to become more positive - for more contralateral stimuli a product of higher firing rates due to a more preferred stimulus presentation or a real effect in the data? Was there any relationship between distance and strength of observed noise correlation in the DCIC?</p>
</disp-quote>
<p>We observed a consistent and homogeneous trend of pairwise noise correlation distributions either shifted or tailed towards more positive values across stimulus azimuths, for imaging and electrophysiology datasets (Author response image 3). The lower firing frequency observed in neuropixels recordings in response to ipsilateral azimuths could have affected the statistical power of the comparison between the pairwise noise correlation coefficient distribution to its randomized chance level, but the overall histogram shapes qualitatively support this consistent trend across azimuths (Author response image 4).</p>
<fig id="sa4fig4">
<label>Author response image 4.</label>
<caption>
<title>Distribution histograms for the pairwise correlation coefficients (Kendall tau) from pairs of simultaneously recorded top ranked units across mice (blue) compared to the chance level distribution obtained through randomization of the temporal structure of each unit’s activity to break correlations (purple).</title>
<p>Vertical lines show the medians of these distributions. Imaging data comes from n = 12 mice and neuropixels data comes from n = 4 mice.</p>
</caption>
<graphic mime-subtype="jpg" xlink:href="elife-97598-sa4-fig4.jpg" mimetype="image"/>
</fig>
<disp-quote content-type="editor-comment">
<p>Typos:</p>
<p>'a population code consisting on the simultaneous&quot; &gt; should on be of?</p>
<p>'half of the trails' &gt; trails should be trials?</p>
<p>'referncing the demuxed channels' &gt; should it be demixed?</p>
</disp-quote>
<p>Corrected.</p>
</body>
</sub-article>
</article>