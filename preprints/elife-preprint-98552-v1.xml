<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">98552</article-id>
<article-id pub-id-type="doi">10.7554/eLife.98552</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.98552.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Structural Biology and Molecular Biophysics</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Ais: streamlining segmentation of cryo-electron tomography datasets</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3739-8863</contrib-id>
<name>
<surname>Last</surname>
<given-names>Mart G.F.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7634-5353</contrib-id>
<name>
<surname>Abendstein</surname>
<given-names>Leoni</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9794-067X</contrib-id>
<name>
<surname>Voortman</surname>
<given-names>Lenard M.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1990-2333</contrib-id>
<name>
<surname>Sharp</surname>
<given-names>Thomas H.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Cell and Chemical Biology, Leiden University Medical Center</institution>, Leiden, 2333ZC, <country>The Netherlands</country></aff>
<aff id="a2"><label>2</label><institution>School of Biochemistry, University of Bristol</institution>, Bristol, BS8 1TD, <country>United Kingdom</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Scheres</surname>
<given-names>Sjors HW</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>MRC Laboratory of Molecular Biology</institution>
</institution-wrap>
<city>Cambridge</city>
<country>United Kingdom</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Campelo</surname>
<given-names>Felix</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Institute of Photonic Sciences</institution>
</institution-wrap>
<city>Barcelona</city>
<country>Spain</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>To whom correspondence should be addressed: <email>t.sharp@bristol.ac.uk</email>, <email>mgflast@gmail.com</email></corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-06-21">
<day>21</day>
<month>06</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP98552</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-04-20">
<day>20</day>
<month>04</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-04-04">
<day>04</day>
<month>04</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.04.04.586917"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Last et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Last et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-98552-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Segmentation is a critical data processing step in many applications of cryo-electron tomography. Downstream analyses, such as subtomogram averaging, are often based on segmentation results, and are thus critically dependent on the availability of open-source software for accurate as well as high-throughput tomogram segmentation. There is a need for more user-friendly, flexible and comprehensive segmentation software that offers an insightful overview of all steps involved in preparing automated segmentations. Here, we present Ais: a dedicated tomogram segmentation package that is geared towards both high performance and accessibility, available at <ext-link ext-link-type="uri" xlink:href="http://www.github.com/bionanopatterning/Ais">github.com/bionanopatterning/Ais</ext-link>. In this report, we demonstrate two common processing steps that can be greatly accelerated with Ais: particle picking for subtomogram averaging, and generating many-feature models of cellular architecture based on <italic>in situ</italic> tomography data. Featuring comprehensive annotation, segmentation, and rendering functionality, as well as an open repository for trained models at <ext-link ext-link-type="uri" xlink:href="http://aiscryoet.org">aiscryoet.org</ext-link>, we hope that Ais will help accelerate research and dissemination of data involving cryoET.</p>
</abstract>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="external-links">
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://aiscryoet.org">https://aiscryoet.org</ext-link>
</p></fn>
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://ais-cryoet.readthedocs.io">https://ais-cryoet.readthedocs.io</ext-link>
</p></fn>
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://github.com/bionanopatterning/Ais">https://github.com/bionanopatterning/Ais</ext-link>
</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Segmentation is a key step in processing cryo-electron tomography (cryoET) datasets that entails identifying specific structures of interest within the volumetric data and marking them as distinct features. This process forms the basis of many subsequent analysis steps, including particle picking for subtomogram averaging and the generation of 3D models that help visualize the ultrastructure of the sample.</p>
<p>Although it is a common task, the currently available software packages for tomogram segmentation often leave room for improvement in either scope, accessibility, or open availability of the source code. Some popular programs, such as Amira™ (Thermo Fisher Scientific), are not free to use, while other more general purpose EM data processing suites offer limited functionality in terms of visualization and user interaction. Specifically, we found that a deficit existed of software that is easy to use, competitively performing, freely available, and dedicated to segmentation of cryoET datasets for downstream processing.</p>
<p>In this report we present Ais, an open-source tool that is designed to enable any cryoET user – whether experienced with software and segmentation or a novice – to quickly and accurately segment their cryoET data in a largely automated fashion. Ais was designed to have an intuitive and straightforward user interface in order to make it accessible to a broad audience, while a library of various neural network architectures, a system of configurable interactions between different models, a streamlined workflow that facilitates rapid fine-tuning of neural network predictions, and built-in particle picking and volume rendering functionalities enable users to quickly prepare highly reusable models for specific segmentation tasks, as well as publication-quality figures.</p>
<p>To demonstrate the use of Ais, we outline its use in two such tasks: first, to automate the particle picking step of a subtomogram averaging workflow, and secondly for the generation of rich three-dimensional models of cellular architecture, with ten distinct cellular components, based on cryoET datasets acquired on cellular samples.</p>
</sec>
<sec id="s2">
<title>Results and discussion</title>
<p>The first step in image segmentation using convolutional neural networks (CNNs) is to manually annotate a subset of the data for use as a training dataset. Ais facilitates this step by providing a simple interface for browsing data, drawing overlays, and selecting boxes to use as training data (<bold><xref rid="fig1" ref-type="fig">Fig. 1a</xref>, also Fig. S1-S5</bold>). Multiple features, such as membranes, microtubules, ribosomes, and phosphate crystals, can be segmented and edited at the same time across multiple datasets (even hundreds). These annotations are then extracted and used as ground truth labels upon which to condition neural networks, with which one can automatically annotate the same or any other dataset (<bold><xref rid="fig1" ref-type="fig">Fig. 1b</xref></bold>). Segmentation in Ais is performed <italic>on-the-fly</italic> and can achieve interactive framerates, depending on the size of the datasets and models that are used. With a little experience, users can generate a training dataset and then train, apply, and asses the quality of a model within a few minutes (<bold><xref rid="fig1" ref-type="fig">Fig. 1c</xref></bold>), including on desktop or laptop Windows and Linux systems with fairly low-end GPUs (e.g., we often use an NVIDIA T1000).</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>An overview of the user interface and functionalities.</title>
<p><bold>a</bold>) The interface for annotation of datasets. In this example, a tomographic slice has been annotated with various features – a detailed explanation follows in <xref rid="fig5" ref-type="fig">Fig. 5</xref>. <bold>b</bold>) After annotation, multiple neural networks (or ‘models’) are set up and trained on the aforemention ed annotations. The models can then be used to segment the various distinct features. In this example, double membrane vesicles (DMVs), single membrane vesicles, ribosomes, intermediate filaments, mitochondrial granules, and molecular pores in the DMVs are segmented. <bold>c</bold>) After training or downloading the required models and exporting segmented volumes, the resulting segmentation are immediately available within the software for 3d rendering and inspection. <bold>d</bold>) The Ais model repository at <ext-link ext-link-type="uri" xlink:href="http://aiscryoet.org">aiscryoet.org</ext-link> facilitates sharing and reuse of trained models. After validation, submitted models can be freely downloaded by anyone. <bold>e</bold>) Additional information, such as the pixel size and the filtering applied to the training data, is displayed alongside all models in the repository, in order to help a user identify whether a model is suited to segment their datasets.</p></caption>
<graphic xlink:href="586917v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Many cryoET datasets look alike, especially for cellular samples. A model prepared by one user to segment, for example, ribosomes in a dataset with a pixel size of 10 Å, might also be adequate for another user’s ribosome segmentation at 12 Å per pixel. To facilitate this sort of reuse and sharing of models, we launched an open model repository at <ext-link ext-link-type="uri" xlink:href="http://aiscryoet.org">aiscryoet.org</ext-link> where users can freely upload and download successfully trained models (<bold><xref rid="fig1" ref-type="fig">Fig. 1d</xref></bold>). Models that pass screening become public, are labelled with relevant metadata (<bold><xref rid="fig1" ref-type="fig">Fig. 1e</xref></bold>), and can be downloaded in a format that allows for direct use in Ais. Thus, users can skip the annotation and training steps of the segmentation workflow. To kickstart the repository, all 27 models that are presented in this article have been uploaded to it.</p>
<p>Our software is not the first to address the challenge of segmenting cryoET datasets; established suites such as EMAN2<sup><xref ref-type="bibr" rid="c1">1</xref></sup>, MIB<sup><xref ref-type="bibr" rid="c2">2</xref></sup>, SuRVOS<sup><xref ref-type="bibr" rid="c3">3</xref></sup>, or QuPath<sup><xref ref-type="bibr" rid="c4">4</xref></sup> also provide some or most of the functionality that is available in Ais. Each comes equipped with one or various choices of classifier architectures to use, and many more designs for neural networks for semantic image segmentation can be found in the literature. Therefore, as well as creating a package geared specifically towards ease of use and fast results, we also wanted to include functionality that enables a user to quickly compare different models in order to facilitate determining which models are best suited for a particular segmentation task. The software thus includes a library of a number of well-performing models, including adaptations of single-model convolutional neural network architectures such as InceptionNet<sup><xref ref-type="bibr" rid="c5">5</xref></sup>, ResNet<sup><xref ref-type="bibr" rid="c6">6</xref></sup>, various UNets<sup><xref ref-type="bibr" rid="c7">7</xref></sup>, VGGNet<sup><xref ref-type="bibr" rid="c8">8</xref></sup>, and the default model available in EMAN2<sup><xref ref-type="bibr" rid="c1">1</xref></sup>, as well as the more complex generative-adversarial network Pix2pix<sup><xref ref-type="bibr" rid="c9">9</xref></sup>. This library can also be extended by copying any Python file that adheres to a minimal template into the corresponding directory of the project.</p>
<sec id="s2a">
<title>A library of neural network architectures supports varied applications</title>
<p>To illustrate how useful it can be to rapidly test various models before selecting one that is well suited for the segmentation of any particular feature, we used six different models for the segmentation of three distinct features within the same tomogram, and analyzed the results (<bold><xref rid="tbl1" ref-type="table">Table 1</xref>)</bold>. We used a cryoET dataset that we have previously acquired<sup><xref ref-type="bibr" rid="c10">10</xref></sup>, which contained liposomes with membrane bound Immunoglobulin G3 (IgG3) antibodies that form an elevated Fragment crystallizable (Fc) platform, prepared on a lacey carbon substrate. The features of interest for segmentation were the membranes, antibody platforms, and carbon support film (<bold><xref rid="fig2" ref-type="fig">Fig. 2a</xref></bold>).</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><title>Comparison of some of the default models available in Ais.</title>
<p><sup>a</sup> The computational cost is only roughly proportional to the number of model parameters, which is reported in the software. The specifics of the model architecture affect the processing speed more significantly. <sup>b</sup> Time required to process one 511×720 pixel sized tomographic slice. <sup>c</sup> The loss, calculated as the binary cross-entropy (bce) of predicted and original annotation, is a (rough) metric of how well a model performs (see Methods). From left to right, the columns list the losses of the membrane, carbon, and antibody platform models, respectively. <sup>d</sup> Unlike the other models, Pix2 pix is not trained to minimize the bce loss but uses a different loss function instead. The bce loss values shown here were computed after training and may not be entirely comparable.</p></caption>
<graphic xlink:href="586917v1_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>A comparison of different neural networks for tomogram segmentation.</title>
<p><bold>a</bold>) A representative example of the manual segmentation used to prepare training datasets. Membranes are annotated in cyan, carbon film in yellow, and antibody platforms in magenta. For the antibody training set, we used annotations prepared in multiple slices of the same tomogram, but for the carbon and membrane training set the slice shown here comprised all the training data. <bold>b</bold>) A tomographic slice from a different tomogram that contains the same features of interest, also showing membrane bound antibodies with elevated Fc platforms that are adjacent to carbon (magenta arrowheads). <bold>c</bold>) Results of segmentation of membranes (top; cyan), carbon (middle; yellow), and antibody platforms (bottom; magenta), with the six different neural networks.</p></caption>
<graphic xlink:href="586917v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>After training, we applied the models to a different tomogram than that used to generate the training data (<bold><xref rid="fig2" ref-type="fig">Fig. 2b</xref></bold>), so that there was no overlap between the training and testing datasets. Next, we compared the training times, relative loss values, and quality of the segmentations.</p>
<p>Based on the model losses (the loss is a metric of how well the model predictions match the ground truth labels), VGGNet was best suited for the segmentation of membranes, while UNet performed best on the carbon support film and antibody platforms. However, the loss values do not capture model performance in the same way as human judgement (<bold><xref rid="fig2" ref-type="fig">Fig. 2c</xref></bold>). For the antibody platform models, the model that would be expected to be one of the worst based on the loss values, Pix2pix, actually generates segmentations that are well-suited for the downstream processing tasks. Pix2pix appears to predict both fewer false negatives and fewer false positives than the lowest-loss model, UNet, which occasionally labels sections of membrane and support film as antibody platform. Moreover, since Pix2pix is a relatively large model, it might also be improved further by increasing the number of training epochs.</p>
<p>When taking the training and processing speeds in to account as well as the segmentation results, there is no overall best model. We therefore included multiple well-performing model architectures in the final library, in order to allow users to select from these models to find one that works well for their specific datasets. Although it is not necessary to screen different models and users may simply opt to use the default model architecture (VGGNet), these results thus show that it can be useful to test different models in order to identify one that is best.</p>
</sec>
<sec id="s2b">
<title>Fine-tuning segmentation results with <bold><italic>model interactions</italic></bold></title>
<p>Although the above results go some way towards distinguishing the three different structures, they also show demonstrate a common limitation encountered in automated tomogram segmentation: some features are assigned a high segmentation value by multiple of the networks, leading to ambiguity in the results. For example, the InceptionNet and ResNet antibody platform models falsely label edges of the carbon film.</p>
<p>To further improve the segmentation results, we decided to implement a system of proximity-based ‘model interactions’ of two types, colocalization and avoidance (<bold><xref rid="fig3" ref-type="fig">Fig. 3a</xref></bold>), using which the output of one model can be adjusted based on the output of other models. In a colocalization interaction, the predictions of one model (the <italic>child</italic>) are suppressed wherever the prediction value of another model (the <italic>parent)</italic> is below some threshold. In an avoidance interaction, suppression occurs wherever the parent model’s prediction value is above a threshold.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Model interactions can significantly increase segmentation accuracy.</title>
<p><bold>a</bold>) An overview of the settings available in the ‘Models’ menu in Ais. Three models: 1) ‘membrane’ (red), 2) ‘carbon’ (white), and 3) ‘antibody platforms’ (green) are active, with each showing a different section of the model settings: the training menu (1), prediction parameters (2), and the interactions menu (3). <bold>b</bold>) A section of a tomographic slice is segmented by two models, carbon (white; <italic>parent</italic> model) and membrane (red; <italic>child</italic> model), with the membrane model showing a clear false positive prediction on an edge of the carbon film (panel ‘without interactions’). By configuring an avoidance interaction between the membrane model that is conditional upon the carbon model’ s prediction, this false positive is avoided (panel ‘with interactions’). <bold>c</bold>) By setting up multiple model interactions, inaccurate predictions by the ‘antibody platforms’ model are suppressed. In this example, the membrane model avoids carbon while the antibody model is set to colocalize with the membrane model. <bold>d</bold>) 3D renders (see Methods) of the same dataset as used in <xref rid="fig2" ref-type="fig">Fig. 2</xref> processed three ways: without any interactions (left), using model competition only (middle), or by using model competition as well as multiple model interactions (right).</p></caption>
<graphic xlink:href="586917v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>These interactions are implemented as follows: first, a binary mask is generated by thresholding the <italic>parent</italic> model’s predictions. Next, the mask is then dilated using a circular kernel with a radius <italic>R</italic>, a parameter that we call the interaction radius. Finally, the <italic>child</italic> model’s prediction values are multiplied with this mask.</p>
<p>Besides these specific interactions between two models, the software also enables pitching multiple models against one another in what we call ‘model competition’. Models can be set to ‘emit’ and/or ‘absorb’ competition from other models. On a pixel-by-pixel basis, all models that absorb competition are suppressed whenever their prediction value for that pixel is lower than that of any of the emitting models.</p>
<p>With the help of these model interactions it is possible to suppress common erroneous segmentation results. For example, an interaction like ‘absorbing <bold>membrane model</bold> <underline>avoids</underline> emitting <bold>carbon model</bold> with R = 10 nm’ is effective at suppressing the prediction of edges of the carbon film as being membranes (<bold><xref rid="fig3" ref-type="fig">Fig. 3b</xref></bold>). Another straightforward example of the utility of membrane interactions is the segmentation of membrane-bound particles. By defining the following two interactions: <bold>‘antibody platform model</bold> <underline>avoids</underline> <bold>membrane model</bold> with R = 10 nm’ followed by <bold>‘antibody platform model</bold> <underline>colocalizes</underline> with <bold>membrane model</bold> with R = 30 nm’, the Fc-platforms formed by IgG3 at a distance of ∼22 nm from the membrane are retained, while false positive labelling of features such as the membrane or carbon is suppressed (<bold><xref rid="fig3" ref-type="fig">Fig. 3c</xref></bold>).</p>
<p>By conditionally combining and editing the prediction results of multiple neural networks, model interactions can thus be helpful in fine-tuning segmentations to be better suited for downstream applications. To illustrate this, we generated a comparison of segmentation results using i) no interactions, ii) model competition only, and iii) model competition as well as model interactions (<bold><xref rid="fig3" ref-type="fig">Fig. 3d</xref></bold>), which demonstrates the degree to which false positives can be reduced by the use of model interactions (although at times at the expense of increasing the rate of false negatives).</p>
</sec>
<sec id="s2c">
<title>Automating particle picking for subtomogram averaging</title>
<p>Protein structure determination by cryoET requires the careful selection of many subtomograms (i.e., sub-volumes of a tomogram that all contain the same structure of interest), and aligning and averaging these to generate a 3D reprojection of the structure of interest with a significantly increased signal to noise ratio. The process of selecting these sub-volumes is called ‘particle picking’, and can be done either manually or in an automated fashion. Much time can be saved by automating particle picking based on segmentations. In many cases, though, segmentation results are not readily usable for particle picking, as they can often introduce numerous false positives. This is particularly the case with complex, feature-rich datasets such as those obtained within cells, where the structures of interest can visually appear highly similar to other structures that are also found in the data, or when the structures of interest are located close to other features and are therefore hard to isolate. An example of this latter case is the challenge of picking membrane-bound particles.</p>
<p>Recently, we have used cryoET and subtomogram averaging to determine the structures of membrane bound IgG3 platforms and of IgG3 interacting with the human complement system component 1 (C1) on the surface of lipid vesicles<sup><xref ref-type="bibr" rid="c10">10</xref></sup>. The reconstructions of the antibody platforms alone and of the antibody-C1 complex were prepared using 1193 and 2561 manually selected subtomograms, extracted from 55 and 101 tomograms, respectively. Manual picking of structures of interest, although very precise, is very time consuming and in this particular case took approximately 20 hours of work.</p>
<p>To demonstrate the utility of our software for particle picking, we re-analyzed these same datasets, this time using Ais to automate the picking of the two structures: antibody platforms and antibody-C1 complexes. For the antibody platforms, we used the same models and model interactions as described above, while we trained an additional neural network to identify C1 complexes for the segmentation of the antibody-C1 complexes. To prepare a training dataset for this latter model, we opened all 101 tomograms in Ais, and browsed the data to select and annotate slices where one or multiple antibody-C1 complexes were clearly visible (<bold><xref rid="fig4" ref-type="fig">Fig. 4a</xref></bold>). The training dataset thus consisted of samples taken from multiple different tomograms; the annotation and data selection in this case took around 1 hour of work.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Automated particle picking for sub-tomogram averaging of antibody complexes.</title>
<p><bold>a</bold>) Manually prepared annotations used to train a neural network to recognize antibody platforms (top) or antibody-C1 complexes (bottom). <bold>b</bold>) Segmentation results as visualized within the software. Membranes (red) and carbon support film (white) were used to condition the antibody (green) and antibody-C1 complex (yellow) predictions using model interactions. <bold>c</bold>) 3 D representations of the segmented volumes rendered in Ais. <bold>d</bold>) Tomographic slices showing particles picked automatically based on the segmented volume shown in panel c. <bold>e)</bold> Subtomogram averaging result of the 2499 automatically picked antibody platforms. <bold>f)</bold> Subtomogram averaging result obtained with the 602 automatically picked antibody-C1 complexes. The quadrants in panels e and f show orthogonal slices of the reconstructed density maps and a 3D isosurface model (the latter rendered in ChimeraX).</p></caption>
<graphic xlink:href="586917v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The antibody platform and antibody-C1 complex models were then applied to the respective datasets, in combination with the membrane and carbon models and the model interactions described above (<bold><xref rid="fig4" ref-type="fig">Fig. 4b</xref></bold>). We then launched a relatively large batch segmentation process (3 models × 156 tomograms) and left it to complete overnight.</p>
<p>Once complete, we used Ais to inspect the segmented volumes and original datasets in 3D, and adjusted the threshold value and so that, in as far as possible, only the particles of interest remained visible and the number of false positive particles was minimized (<bold><xref rid="fig4" ref-type="fig">Fig. 4c</xref></bold>). After selecting these values, we then launched a batch particle picking process to determine lists of particle coordinates based on the segmented volumes. Next, we used EMAN2<sup><xref ref-type="bibr" rid="c1">1</xref></sup> (spt_boxer.py) to extract volumes using these coordinates as an input (<bold><xref rid="fig4" ref-type="fig">Fig. 4d</xref></bold>), which resulted in 2499 volumes for the antibody platform reconstruction and 602 for the antibody-C1 complex (<italic>n</italic>.<italic>b</italic>. these numbers can be highly dependent on the threshold value). These volumes, or subtomograms, were used as the input for subtomogram averaging using EMAN2<sup><xref ref-type="bibr" rid="c1">1</xref></sup> and Dynamo<sup><xref ref-type="bibr" rid="c11">11</xref></sup> (see Methods), without further curation – i.e., we did not manually discard any of the extracted volumes.</p>
<p>After applying the same approach to subtomogram averaging as used previously<sup><xref ref-type="bibr" rid="c10">10</xref></sup>, the resulting averages were indeed highly similar to the original reconstructions (<bold><xref rid="fig4" ref-type="fig">Figs. 4e,f</xref>, Fig. S6</bold>). These results demonstrate that Ais can be succesfully used to automate particle picking, and thus to significantly reduce the amount of time spent on what is often a laborious processing step.</p>
</sec>
<sec id="s2d">
<title>Many-feature segmentations of complex <bold><italic>in situ</italic></bold> datasets</title>
<p>Aside from particle picking, segmentation is also often used to visualize and study the complex internal structure of a sample, as for example encountered when applying tomography to whole cells. Here too, the accuracy of a segmentation can be a critical factor in the success of downstream analyses such as performing measurements on the basis of 3D models generated <italic>via</italic> segmentation.</p>
<p>A challenging aspect of segmentation of cellular samples is that these datasets typically contain many features that are biologically distinct, but visually and computationally difficult to distinguish. For example, one challenge that is often encountered is that of distinguishing between various linearly shaped components: lipid membranes, actin filaments, microtubules, and intermediate filaments, which all appear as linear features with a relatively high density. To show the utility of Ais for the accurate segmentation of complex cellular tomograms, we next demonstrate a number of examples of such feature-rich segmentations.</p>
<p>The first example is a segmentation of seven distinct features observed in the base of <italic>Chlamydomonas reinhardtii</italic> cilia (<bold><xref rid="fig5" ref-type="fig">Fig. 5a</xref></bold>), using the data by van den Hoek et al.<sup><xref ref-type="bibr" rid="c12">12</xref></sup> that was deposited in the Electron Microscopy Public Image Archive (EMPIAR)<sup><xref ref-type="bibr" rid="c13">13</xref></sup> with accession number 11078. The features are: membranes, ribosomes, microtubule doublets, axial microtubules, non-microtubular filaments, interflagellar transport trains (IFTs), and glycocalyx. This dataset was particularly intricate (the supplementary information to the original publication lists more than 20 features that can be identified across the dataset) and some rare features, such as the IFTs, required careful annotation across all tomograms before we could compile a sufficiently large training dataset. The final segmentation correctly annotates most of the selected characteristics present in the sample: the ribosome exclusion zone that surrounds the ciliary base<sup><xref ref-type="bibr" rid="c12">12</xref></sup> is clearly recognizable, and the structures of the glycocalyx, membranes, and microtubule doublets within the cilia are well defined. Some fractions of the meshwork of stellate fiber and Y-link proteins are also detected within the cilium.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Segmentations of complex <italic>in situ</italic> tomograms.</title>
<p><bold>a</bold>) A segmentation of seven distinct features observed in the base of <italic>C. reinhardtii</italic> cilia<sup><xref ref-type="bibr" rid="c12">12</xref></sup> (EMPIAR-11078, tomogram 12): membranes (gray), ribosomes (magenta), microtubule doublets (green) and axial microtubules (green), non-microtubular fi laments within the cilium (blue), interflagellar transport trains (yellow), and glycocalyx (orange). Inset: a perpendicular view of the axis of the cilium. The arrows in the adjacent panel indicate these structures in a tomographic slice. <bold>b</bold>) A segmentation of six features observed in and around mitochondria in a mouse neuron with Huntington disease phenotype <sup><xref ref-type="bibr" rid="c14">14</xref></sup> (EMD-29207): membranes (gray), mitochondrial granules (yellow), membranes of the mitochondrial cristae (red), microtubules (green), actin (turquoise), and ribosomes (magenta). <bold>c</bold>) Left: a segmentation of ten different cellular components found in tomograms of coronavirus infected mammalian cells <sup><xref ref-type="bibr" rid="c16">16</xref></sup> : double membrane vesicles (DMVs, light red), single membranes (gray), viral nucleocapsid proteins (red), viral pores in the DMVs (blue), nucleic acids in the DMVs (pink), microtubules (green), actin (cyan), intermediate fi laments (orange), ribosomes (magenta), and mitochondrial granules (yellow). Right: a representative slice, with examples of each of the features (except the mitochondrial granules) indicated by arrows of the corresponding colour.</p></caption>
<graphic xlink:href="586917v1_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>In the second example, we show a segmentation of six features found in and around a mitochondrion in a mouse neuron (<bold><xref rid="fig5" ref-type="fig">Fig. 5b</xref></bold>), using the data by Wu et al.<sup><xref ref-type="bibr" rid="c14">14</xref></sup> as available in the EMDataBank (EMDB)<sup><xref ref-type="bibr" rid="c15">15</xref></sup> with accession number 29207. In the original publication, the authors developed a segmentation method to detect and perform measurements on the granules found within mitochondria. Using Ais, we were able to prepare models to segment these granules, as well as microtubules, actin filaments, ribosomes, and to distinguish between the highly similar vesicular membranes on the one hand, and the membranes of the mitochondrial cristae on the other.</p>
<p>Lastly, we used Ais to generate a 3D model of ten distinct cellular features observed in coronavirus infected mammalian cells (<bold><xref rid="fig5" ref-type="fig">Fig. 5c</xref>, Fig. S7</bold>), using data by Wolff et al.<sup><xref ref-type="bibr" rid="c16">16</xref></sup>: single membranes, double membrane vesicles (DMVs), actin filaments, intermediate filaments, microtubules, mitochondrial granules, ribosomes, coronaviral nucleocapsid proteins, coronaviral pores in the DMVs, and the nucleic acids within the DMV replication organelles. The software was able to accurately distinguish between single membranes and double membranes, as well as to discriminate between the various filaments of the cytoskeleton. Moreover, we could identify the molecular pores within the DMV, and upon manually thresholding the segmented volumes found no immediately apparent false positive predictions of these pores (<bold>Fig. S8</bold>). We could also segment the nucleocapsid proteins, thus distinguishing viral particles from other, similarly sized, single membrane vesicles, as well as detect the nucleic acids found within the DMVs. Although the manual annotation took some hours in this case, the processing of the full volume took approximately 3 minutes per feature once the models were trained, and models can of course be applied to other volumes without requiring additional training.</p>
<p>To conclude, our aim with the development of Ais was to simplify and improve the accuracy of automated tomogram segmentation in order to make this processing step more accessible to many cryoET users. Here, we have attempted to create an intuitive and organized user interface that streamlines the whole workflow from annotation, to model preparation, to volume processing and particle picking and inspecting the results. Additionally, the model repository at <ext-link ext-link-type="uri" xlink:href="http://aiscryoet.org">aiscryoet.org</ext-link> is designed to aid users in achieving results even faster, by removing the need to generate custom models for common segmentation tasks. To help users become familiar with the software, documentation and tutorials are available at <ext-link ext-link-type="uri" xlink:href="http://ais-cryoet.readthedocs.org">ais-cryoet.readthedocs.org</ext-link> and video tutorials can be accessed via <email>youtube.com/@scNodes</email>. By demonstrating the use of Ais in automating segmentation and particle picking for subtomogram averaging, and making the software available as an open-source project, we thus hope to help accelerate research and dissemination of data involving cryoET.</p>
</sec>
</sec>
<sec id="s3">
<title>Methods</title>
<sec id="s3a">
<title>Model comparisons</title>
<p>The comparison presented in <xref rid="tbl1" ref-type="table">Table 1</xref> was prepared with the use of the same training datasets for all models, consisting of 53/52/58 positive images showing membranes/carbon/antibody platforms and corresponding annotations alongside 159/51/172 negative images that did not contain the feature of interest, but rather the other two features, reconstruction artefacts, isolated protein, or background noise. Images were 64 × 64 pixels in size and the dataset was resampled, in random orientations, such that every positive image was copied 10 times and that the ratio of negatives to positives was 1.3:1. Models were trained for 50 epochs with 32 images per batch, with the exception of the ResNet and Pix2pix antibody platform models, which were trained for 30 epochs to avoid a divergence that occurred during training after a larger number of epochs, due to the large number of model parameters and relatively low number of unique input images.</p>
<p>The reported loss is that calculated on the training dataset itself, i.e., no validation split was applied. During regular use of the software a validation split is also not applied in order to make full use of an input set of ground truth annotations. The software also reports the overall loss during training, rather than the validation loss.</p>
</sec>
<sec id="s3b">
<title>Data visualization</title>
<p>Images shown in the figures were either captured within the software (<xref rid="fig1" ref-type="fig">Fig. 1</xref>, <xref rid="fig3" ref-type="fig">Fig. 3bc</xref> ‘original image’, <xref rid="fig4" ref-type="fig">Fig. 4abc</xref>), output from the software that was colourized in Inkscape (<xref rid="fig2" ref-type="fig">Fig. 2c</xref>, <xref rid="fig3" ref-type="fig">Fig. 3bc</xref>), or output from the software that was rendered using ChimeraX<sup><xref ref-type="bibr" rid="c17">17</xref></sup> (<xref rid="fig3" ref-type="fig">Fig. 3d</xref>, <xref rid="fig4" ref-type="fig">Fig. 4ef</xref>, <xref rid="fig5" ref-type="fig">Fig. 5</xref>). For the panels in <xref rid="fig3" ref-type="fig">Fig. 3d</xref>, segmented volumes were rendered as isosurfaces at a manually chosen suitable isosurface level and with the use of the ‘hide dust’ function (the same settings were used for each panel, different settings used for each model).</p>
</sec>
<sec id="s3c">
<title>Hardware</title>
<p>The software does not require a GPU, but works optimally when a CUDA capable GPU is available. For the measurements shown in <xref rid="tbl1" ref-type="table">Table 1</xref> we used an NVIDIA Quadro P2200 GPU on a PC with an Intel i9-10900K CPU. We’ve also extensively used the software on a less powerful system equipped with an NVIDIA T1000 and an Intel i3-10100 CPU, as well as on various systems with intermediate specifications, and found that the software reaches interactive segmentation rates in most cases. For batch processing of many volumes, a more powerful GPU is useful.</p>
</sec>
<sec id="s3d">
<title>Tomogram reconstruction and subtomogram averaging</title>
<p>Data collection and subtomogram averaging (<xref rid="fig3" ref-type="fig">Figs. 3</xref> and <xref rid="fig4" ref-type="fig">4</xref>) was performed as described in a previously published article<sup><xref ref-type="bibr" rid="c10">10</xref></sup>. Briefly, tilt series were collected on a Talos Arctica 200 kV system equipped with a Gatan K3 detector with energy filter at a pixel size of 1.74 Å per pixel using a dose-symmetric tilt scheme with range ±57° and tilt increments of 3° with a total dose of 60 e/Å<sup><xref ref-type="bibr" rid="c2">2</xref></sup>. Tomograms were reconstructed using IMOD<sup><xref ref-type="bibr" rid="c18">18</xref></sup>. Particle picking was done in Ais (and is explained in more detail in the online documentation). Subtomogram averaging was done using a combination of EMAN<sup><xref ref-type="bibr" rid="c1">1</xref></sup> and Dynamo<sup><xref ref-type="bibr" rid="c11">11</xref></sup>. For a detailed description of the subtomogram averaging procedure, see Abendstein et al. (2023)<sup><xref ref-type="bibr" rid="c10">10</xref></sup>.</p>
</sec>
<sec id="s3e">
<title>Open-source software</title>
<p>This project depends critically on a number of open-source software components, including: Python, Tensorflow<sup><xref ref-type="bibr" rid="c19">19</xref></sup>, numpy<sup><xref ref-type="bibr" rid="c20">20</xref></sup>, scipy<sup><xref ref-type="bibr" rid="c21">21</xref></sup>, scikit-image<sup><xref ref-type="bibr" rid="c22">22</xref></sup>, mrcfile<sup><xref ref-type="bibr" rid="c23">23</xref></sup>, and imgui<sup><xref ref-type="bibr" rid="c24">24</xref></sup>.</p>
</sec>
</sec>
<sec id="s4">
<title>Software availability</title>
<p>A standalone version of the software is available as ‘Ais-cryoET’ on the Python package index and at <ext-link ext-link-type="uri" xlink:href="http://github.com/bionanopatterning/Ais">github.com/bionanopatterning/Ais</ext-link>. We have also integrated the functionality into scNodes<sup><xref ref-type="bibr" rid="c25">25</xref></sup>, our dedicated processing suite for correlated light and electron microscopy. In the combined package, the segmentation editor contains additional features for visualization of fluorescence data and the scNodes correlation editor can be used to prepare correlated datasets for segmentation. Documentation for both versions of Ais can be found at <ext-link ext-link-type="uri" xlink:href="http://ais-cryoet.readthedocs.org">ais-cryoet.readthedocs.org</ext-link>. Video tutorials are available via <email>youtube.com/@scNodes</email>.</p>
</sec>
<sec id="d1e914" sec-type="supplementary-material">
<title>Supporting information</title>
<supplementary-material id="d1e1002">
<label>Supplementary Information</label>
<media xlink:href="supplements/586917_file03.pdf"/>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>We thank A. Koster and M. Barcena for helpful discussions and providing us with access to the coronaviral replication organelle datasets. We are also grateful to van den Hoek et al.<sup><xref ref-type="bibr" rid="c12">12</xref></sup>and Wu et al.<sup><xref ref-type="bibr" rid="c14">14</xref></sup>, for uploading the data that we used for <xref rid="fig5" ref-type="fig">Fig. 5</xref> onto EMPIAR and EMDB, as well as to the authors of various other datasets uploaded to these databases that are not discussed in this manuscript but that were very helpful for testing the software. This research was supported by the following grants to THS: European Research Council H202 Grant 759517; European Union’s Horizon Europe Program IMAGINE grant 101094250, and the Netherlands Organization for Scientific Research Grant VI.Vidi.193.014.</p>
</ack>
<sec id="s5">
<title>Author Contributions</title>
<p>MGFL and LA collected and processed the data. MGFL wrote the software with input from all other authors. THS and LMV supervised the project.</p>
</sec>
<sec id="s6">
<title>Competing Interests Statement</title>
<p>The authors declare no competing interests.</p>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1</label><mixed-citation publication-type="journal"><string-name><surname>Galaz-Montoya</surname>, <given-names>J. G.</given-names></string-name>, <string-name><surname>Flanagan</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Schmid</surname>, <given-names>M. F.</given-names></string-name> &amp; <string-name><surname>Ludtke</surname>, <given-names>S. J.</given-names></string-name> <article-title>Single particle tomography in EMAN2</article-title>. <source>J Struct Biol</source> <volume>190</volume>, <fpage>279</fpage>–<lpage>290</lpage> (<year>2015</year>). <pub-id pub-id-type="doi">10.1016/j.jsb.2015.04.016</pub-id></mixed-citation></ref>
<ref id="c2"><label>2</label><mixed-citation publication-type="journal"><string-name><surname>Belevich</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Joensuu</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Kumar</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Vihinen</surname>, <given-names>H.</given-names></string-name> &amp; <string-name><surname>Jokitalo</surname>, <given-names>E.</given-names></string-name> <article-title>Microscopy image browser: a platform for segmentation and analysis of multidimensional datasets</article-title>. <source>PLoS biology</source> <volume>14</volume>, <fpage>e1002340</fpage> (<year>2016</year>). <pub-id pub-id-type="doi">10.1371/journal.pbio.1002340</pub-id></mixed-citation></ref>
<ref id="c3"><label>3</label><mixed-citation publication-type="journal"><string-name><surname>Luengo</surname>, <given-names>I.</given-names></string-name> <etal>et al.</etal> <article-title>SuRVoS: Super-Region Volume Segmentation workbench</article-title>. <source>J Struct Biol</source> <volume>198</volume>, <fpage>43</fpage>–<lpage>53</lpage> (<year>2017</year>). <pub-id pub-id-type="doi">10.1016/j.jsb.2017.02.007</pub-id></mixed-citation></ref>
<ref id="c4"><label>4</label><mixed-citation publication-type="journal"><string-name><surname>Bankhead</surname>, <given-names>P.</given-names></string-name> <etal>et al.</etal> <article-title>QuPath: Open source software for digital pathology image analysis</article-title>. <source>Sci Rep</source> <volume>7</volume>, <fpage>16878</fpage> (<year>2017</year>). <pub-id pub-id-type="doi">10.1038/s41598-017-17204-5</pub-id></mixed-citation></ref>
<ref id="c5"><label>5</label><mixed-citation publication-type="preprint"><string-name><surname>Szegedy</surname>, <given-names>C.</given-names></string-name> <etal>et al.</etal> <article-title>Going deeper with convolutions</article-title>. <source>arXiv</source> (<year>2014</year>). <pub-id pub-id-type="doi">10.48550/arXiv.1409.4842</pub-id></mixed-citation></ref>
<ref id="c6"><label>6</label><mixed-citation publication-type="preprint"><string-name><surname>Szegedy</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Ioffe</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Vanhoucke</surname>, <given-names>V.</given-names></string-name> &amp; <string-name><surname>Alemi</surname>, <given-names>A.</given-names></string-name> <article-title>Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning</article-title>. <source>arXiv</source> (<year>2016</year>). <pub-id pub-id-type="doi">10.48550/arXiv.1602.07261</pub-id></mixed-citation></ref>
<ref id="c7"><label>7</label><mixed-citation publication-type="preprint"><string-name><surname>Ronneberger</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Fisher</surname>, <given-names>P.</given-names></string-name> &amp; <string-name><surname>Brox</surname>, <given-names>T.</given-names></string-name> <article-title>U-Net: Convolutional Networks for Biomedical Image Segmentation</article-title>. <source>arXiv</source> (<year>2015</year>). <pub-id pub-id-type="doi">10.48550/arXiv.1505.04597</pub-id></mixed-citation></ref>
<ref id="c8"><label>8</label><mixed-citation publication-type="preprint"><string-name><surname>Simonyan</surname>, <given-names>K.</given-names></string-name> &amp; <string-name><surname>Zisserman</surname>, <given-names>A.</given-names></string-name> <article-title>Very Deep Convolutional Networks for Large-scale Image Regognition</article-title>. <source>arXiv</source> (<year>2015</year>). <pub-id pub-id-type="doi">10.48550/arXiv.1409.1556</pub-id></mixed-citation></ref>
<ref id="c9"><label>9</label><mixed-citation publication-type="confproc"><string-name><surname>Isola</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Zhu</surname>, <given-names>J.-Y.</given-names></string-name>, <string-name><surname>Zhou</surname>, <given-names>T.</given-names></string-name> &amp; <string-name><surname>Efros</surname>, <given-names>A. A.</given-names></string-name> <article-title>Image-to-Image Translation with Conditional Adversarial Networks</article-title>. <source>2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</source>, <fpage>5967</fpage>–<lpage>5976</lpage> (<year>2017</year>). <pub-id pub-id-type="doi">10.1109/CVPR.2017.632</pub-id></mixed-citation></ref>
<ref id="c10"><label>10</label><mixed-citation publication-type="journal"><string-name><surname>Abendstein</surname>, <given-names>L.</given-names></string-name> <etal>et al.</etal> <article-title>Complement is activated by elevated IgG3 hexameric platforms and deposits C4b onto distinct antibody domains</article-title>. <source>Nat Commun</source> <volume>14</volume>, <fpage>4027</fpage> (<year>2023</year>). <pub-id pub-id-type="doi">10.1038/s41467-023-39788-5</pub-id></mixed-citation></ref>
<ref id="c11"><label>11</label><mixed-citation publication-type="journal"><string-name><surname>Castano-Diez</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Kudryashev</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Arheit</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Stahlberg</surname>, <given-names>H.</given-names></string-name> <article-title>Dynamo: a flexible, user-friendly development tool for subtomogram averaging of cryo-EM data in high-performance computing environments</article-title>. <source>J Struct Biol</source> <volume>178</volume>, <fpage>139</fpage>–<lpage>151</lpage> (<year>2012</year>). <pub-id pub-id-type="doi">10.1016/j.jsb.2011.12.017</pub-id></mixed-citation></ref>
<ref id="c12"><label>12</label><mixed-citation publication-type="journal"><string-name><surname>van den Hoek</surname>, <given-names>H.</given-names></string-name> <etal>et al.</etal> <article-title>In situ architecture of the ciliary base reveals thestepwise assembly of intraflagellar transport trains</article-title>. <source>Science</source> <volume>377</volume>, <fpage>543</fpage>–<lpage>548</lpage> (<year>2022</year>). <pub-id pub-id-type="doi">10.1126/science.abm6704</pub-id></mixed-citation></ref>
<ref id="c13"><label>13</label><mixed-citation publication-type="journal"><string-name><surname>Iudin</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal> <article-title>EMPIAR: the electron microscopy public image archive</article-title>. <source>Nucleic Acids Research</source> <volume>51</volume>, <fpage>D1503</fpage>–<lpage>D1511</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c14"><label>14</label><mixed-citation publication-type="journal"><string-name><surname>Wu</surname>, <given-names>G. H.</given-names></string-name> <etal>et al.</etal> <article-title>CryoET reveals organelle phenotypes in huntington disease patient iPSC-derived and mouse primary neurons</article-title>. <source>Nat Commun</source> <volume>14</volume>, <fpage>692</fpage> (<year>2023</year>). <pub-id pub-id-type="doi">10.1038/s41467-023-36096-w</pub-id></mixed-citation></ref>
<ref id="c15"><label>15</label><mixed-citation publication-type="journal"><string-name><surname>Lawson</surname>, <given-names>C. L.</given-names></string-name> <etal>et al.</etal> <article-title>EMDataBank unified data resource for 3DEM</article-title>. <source>Nucleic Acids Research</source> <volume>44</volume>, <fpage>D396</fpage>–<lpage>D403</lpage> (<year>2015</year>). <pub-id pub-id-type="doi">10.1093/nar/gkv1126</pub-id></mixed-citation></ref>
<ref id="c16"><label>16</label><mixed-citation publication-type="journal"><string-name><surname>Wolff</surname>, <given-names>G.</given-names></string-name> <etal>et al.</etal> <article-title>A molecular pore spans the double membrane of the coronavirus replication organelle</article-title>. <source>Science</source> <volume>369</volume>, <fpage>1395</fpage>–<lpage>1398</lpage> (<year>2020</year>). <pub-id pub-id-type="doi">10.1126/science.abd3629</pub-id></mixed-citation></ref>
<ref id="c17"><label>17</label><mixed-citation publication-type="journal"><string-name><surname>Goddard</surname>, <given-names>T. D.</given-names></string-name> <etal>et al.</etal> <article-title>UCSF ChimeraX: Meeting modern challenges in visualization and analysis</article-title>. <source>Protein Sci</source> <volume>27</volume>, <fpage>14</fpage>–<lpage>25</lpage> (<year>2018</year>). <pub-id pub-id-type="doi">10.1002/pro.3235</pub-id></mixed-citation></ref>
<ref id="c18"><label>18</label><mixed-citation publication-type="journal"><string-name><surname>Mastronarde</surname>, <given-names>D. N.</given-names></string-name> &amp; <string-name><surname>Held</surname>, <given-names>S. R.</given-names></string-name> <article-title>Automated tilt series alignment and tomographic reconstruction in IMOD</article-title>. <source>J Struct Biol</source> <volume>197</volume>, <fpage>102</fpage>–<lpage>113</lpage> (<year>2017</year>). <pub-id pub-id-type="doi">10.1016/j.jsb.2016.07.011</pub-id></mixed-citation></ref>
<ref id="c19"><label>19</label><mixed-citation publication-type="preprint"><string-name><surname>Abadi</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal> <article-title>Large-Scale Machine Learning on Heterogeneous Distributed Systems</article-title>. <source>arXiv</source> (<year>2015</year>). <pub-id pub-id-type="doi">10.48550/arXiv.1603.04467</pub-id></mixed-citation></ref>
<ref id="c20"><label>20</label><mixed-citation publication-type="journal"><string-name><surname>Harris</surname>, <given-names>C. R.</given-names></string-name> <etal>et al.</etal> <article-title>Array programming with NumPy</article-title>. <source>Nature</source> <volume>585</volume>, <fpage>357</fpage>–<lpage>362</lpage> (<year>2020</year>). <pub-id pub-id-type="doi">10.1038/s41586-020-2649-2</pub-id></mixed-citation></ref>
<ref id="c21"><label>21</label><mixed-citation publication-type="journal"><string-name><surname>Virtanen</surname>, <given-names>P.</given-names></string-name> <etal>et al.</etal> <article-title>SciPy 1.0: fundamental algorithms for scientific computing in Python</article-title>. <source>Nat Methods</source> <volume>17</volume>, <fpage>261</fpage>–<lpage>272</lpage> (<year>2020</year>). <pub-id pub-id-type="doi">10.1038/s41592-019-0686-2</pub-id></mixed-citation></ref>
<ref id="c22"><label>22</label><mixed-citation publication-type="journal"><string-name><surname>van der Walt</surname>, <given-names>S.</given-names></string-name> <etal>et al.</etal> <article-title>scikit-image: image processing in Python</article-title>. <source>PeerJ</source> <volume>2</volume>, <fpage>e453</fpage> (<year>2014</year>). <pub-id pub-id-type="doi">10.7717/peerj.453</pub-id></mixed-citation></ref>
<ref id="c23"><label>23</label><mixed-citation publication-type="journal"><string-name><surname>Burnley</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Palmer</surname>, <given-names>C. M.</given-names></string-name> &amp; <string-name><surname>Winn</surname>, <given-names>M.</given-names></string-name> <article-title>Recent developments in the CCP-EM software suite</article-title>. <source>Acta Crystallographica Section D</source> <volume>73</volume>, <fpage>469</fpage>–<lpage>477</lpage> (<year>2017</year>). doi:<pub-id pub-id-type="doi">10.1107/S2059798317007859</pub-id></mixed-citation></ref>
<ref id="c24"><label>24</label><mixed-citation publication-type="web"><string-name><surname>Cornut</surname>, <given-names>O. Dear Imgui</given-names></string-name>. (<year>2023</year>), <source>GitHub repository</source>, <ext-link ext-link-type="uri" xlink:href="https://github.com/ocornut/imgui">https://github.com/ocornut/imgui</ext-link></mixed-citation></ref>
<ref id="c25"><label>25</label><mixed-citation publication-type="journal"><string-name><surname>Last</surname>, <given-names>M. G. F.</given-names></string-name>, <string-name><surname>Voortman</surname>, <given-names>L. M.</given-names></string-name> &amp; <string-name><surname>Sharp</surname>, <given-names>T. H.</given-names></string-name> <article-title>scNodes: a correlation and processing toolkit for super-resolution fluorescence and electron microscopy</article-title>. <source>Nat Methods</source> <volume>20</volume>, <fpage>1445</fpage>–<lpage>1446</lpage> (<year>2023</year>). <pub-id pub-id-type="doi">10.1038/s41592-023-01991-z</pub-id></mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.98552.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Scheres</surname>
<given-names>Sjors HW</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>MRC Laboratory of Molecular Biology</institution>
</institution-wrap>
<city>Cambridge</city>
<country>United Kingdom</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This work describes a new software platform for machine-learning-based segmentation of and particle-picking in cryo-electron tomograms. The program and its corresponding online database of trained models will allow experimentalists to conveniently test different models and share their results with others. The paper provides <bold>solid</bold> evidence that the software will be <bold>valuable</bold> to the community.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.98552.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This paper describes &quot;Ais&quot;, a new software tool for machine-learning-based segmentation and particle picking of electron tomograms. The software can visualise tomograms as slices and allows manual annotation for the training of a provided set of various types of neural networks. New networks can be added, provided they adhere to a Python file with an (undescribed) format. Once networks have been trained on manually annotated tomograms, they can be used to segment new tomograms within the same software. The authors also set up an online repository to which users can upload their models, so they might be re-used by others with similar needs. By logically combining the results from different types of segmentations, they further improve the detection of distinct features. The authors demonstrate the usefulness of their software on various data sets. Thus, the software appears to be a valuable tool for the cryo-ET community that will lower the boundaries of using a variety of machine-learning methods to help interpret tomograms.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.98552.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Last et al. present Ais, a new deep learning-based software package for the segmentation of cryo-electron tomography data sets. The distinguishing factor of this package is its orientation to the joint use of different models, rather than the implementation of a given approach. Notably, the software is supported by an online repository of segmentation models, open to contributions from the community.</p>
<p>The usefulness of handling different models in one single environment is showcased with a comparative study on how different models perform on a given data set; then with an explanation of how the results of several models can be manually merged by the interactive tools inside Ais.</p>
<p>The manuscripts present two applications of Ais on real data sets; one is oriented to showcase its particle-picking capacities on a study previously completed by the authors; the second one refers to a complex segmentation problem on two different data sets (representing different geometries as bacterial cilia and mitochondria in a mouse neuron), both from public databases.</p>
<p>The software described in the paper is compactly documented on its website, additionally providing links to some YouTube videos (less than an hour in total) where the authors videocapture and comment on major workflows.</p>
<p>In short, the manuscript describes a valuable resource for the community of tomography practitioners.</p>
<p>Strengths:</p>
<p>A public repository of segmentation models; easiness of working with several models and comparing/merging the results.</p>
<p>Weaknesses:</p>
<p>A certain lack of concretion when describing the overall features of the software that differentiate it from others.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.98552.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>In this manuscript, Last and colleagues describe Ais, an open-source software package for the semi-automated segmentation of cryo-electron tomography (cryo-ET) maps. Specifically, Ais provides a graphical user interface (GUI) for the manual segmentation and annotation of specific features of interest. These manual annotations are then used as input ground-truth data for training a convolutional neural network (CNN) model, which can then be used for automatic segmentation. Ais provides the option of several CNNs so that users can compare their performance on their structures of interest in order to determine the CNN that best suits their needs. Additionally, pre-trained models can be uploaded and shared to an online database.</p>
<p>Algorithms are also provided to characterize &quot;model interactions&quot; which allows users to define heuristic rules on how the different segmentations interact. For instance, a membrane-adjacent protein can have rules where it must colocalize a certain distance away from a membrane segmentation. Such rules can help reduce false positives; as in the case above, false negatives predicted away from membranes are eliminated.</p>
<p>The authors then show how Ais can be used for particle picking and subsequent subtomogram averaging and for the segmentation of cellular tomograms for visual analysis. For subtomogram averaging, they used a previously published dataset and compared the averages of their automated picking with the published manual picking. Analysis of cellular tomogram segmentation was primarily visual.</p>
<p>Strengths:</p>
<p>CNN-based segmentation of cryo-ET data is a rapidly developing area of research, as it promises substantially faster results than manual segmentation as well as the possibility for higher accuracy. However, this field is still very much in the development and the overall performance of these approaches, even across different algorithms, still leaves much to be desired. In this context, I think Ais is an interesting package, as it aims to provide both new and experienced users with streamlined approaches for manual annotation, access to a number of CNNs, and methods to refine the outputs of CNN models against each other. I think this can be quite useful for users, particularly as these methods develop.</p>
<p>Weaknesses:</p>
<p>Whilst overall I am enthusiastic about this manuscript, I still have a number of comments:</p>
<p>On page 5, paragraph 1, there is a discussion on human judgement of these results. I think a more detailed discussion is required here, as from looking at the figures, I don't know that I agree with the authors' statement that Pix2pix is better. I acknowledge that this is extremely subjective, which is the problem. I think that a manual segmentation should also be shown in a figure so that the reader has a better way to gauge the performance of the automated segmentation.</p>
<p>On page 7, the authors mention terms such as &quot;emit&quot; and &quot;absorb&quot; but never properly define them, such that I feel like I'm guessing at their meaning. Precise definitions of these terms should be provided.</p>
<p>For Figure 3, it's unclear if the parent models shown (particularly the carbon model) are binary or not. The figure looks to be grey values, which would imply that it's the visualization of some prediction score. If so, how is this thresholded? This can also be made clearer in the text.</p>
<p>Figure 3D was produced in ChimeraX using the hide dust function. I think some discussion on the nature of this &quot;dust&quot; is in order, e.g. how much is there and how large does it need to be to be considered dust? Given that these segmentations can be used for particle picking, this seems like it may be a major contributor to false positives.</p>
<p>Page 9 contains the following sentence: &quot;After selecting these values, we then launched a batch particle picking process to determine lists of particle coordinates based on the segmented volumes.&quot; Given how important this is, I feel like this requires significant description, e.g. how are densities thresholded, how are centers determined, and what if there are overlapping segmentations?</p>
<p>The FSC shown in Figure S6 for the auto-picked maps is concerning. First, a horizontal line at FSC = 0 should be added. It seems that starting at a frequency of ~0.045, the FSC of the autopicked map increases above zero and stays there. Since this is not present in the FSC of the manually picked averages, this suggests the automatic approach is also finding some sort of consistent features. This needs to be discussed.</p>
<p>Page 11 contains the statement &quot;the segmented volumes found no immediately apparent false positive predictions of these pores&quot;. This is quite subjective and I don't know that I agree with this assessment. Unless the authors decide to quantify this through subtomogram classification, I don't think this statement is appropriate.</p>
<p>In the methods, the authors note that particle picking is explained in detail in the online documentation. Given that this is a key feature of this software, such an explanation should be in the manuscript.</p>
</body>
</sub-article>
<sub-article id="sa4" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.98552.1.sa4</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Last</surname>
<given-names>Mart G.F.</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3739-8863</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Abendstein</surname>
<given-names>Leoni</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7634-5353</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Voortman</surname>
<given-names>Lenard M.</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9794-067X</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Sharp</surname>
<given-names>Thomas H.</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1990-2333</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>Thank you for organising the review and providing us with the reviewer's feedback. These comments are very useful, and we would like to express our gratitude to the reviewers for their efforts.</p>
<p>The reviewers all point out a number of related improvements, relating to: 1) describing various processing steps more clearly, in the online documentation but also in the manuscript itself (e.g. for particle picking), 2) describing more clearly what features Ais offers, how these compare to those of other programmes, and how they might be interfaced with in third-party programmes (e.g. the expected format of models), and 3) a degree of subjectivity in discussion of the results presented in the manuscript (e.g. our statement that Pix2pix performed better in some cases than did other architectures).</p>
<p>We will address these points, as well as the various other suggestions, in the upcoming revised manuscript and updates to Ais.</p>
</body>
</sub-article>
</article>