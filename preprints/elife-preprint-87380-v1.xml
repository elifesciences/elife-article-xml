<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">87380</article-id>
<article-id pub-id-type="doi">10.7554/eLife.87380</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.87380.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Brain mechanisms of reversible symbolic reference: a potential singularity of the human brain</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1935-8216</contrib-id>
<name>
<surname>van Kerkoerle</surname>
<given-names>Timo</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Pape</surname>
<given-names>Louise</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4031-3055</contrib-id>
<name>
<surname>Ekramnia</surname>
<given-names>Milad</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Feng</surname>
<given-names>Xiaoxia</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9626-7823</contrib-id>
<name>
<surname>Tasserie</surname>
<given-names>Jordy</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Dupont</surname>
<given-names>Morgan</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Li</surname>
<given-names>Xiaolian</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Jarraya</surname>
<given-names>Bechir</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9399-343X</contrib-id>
<name>
<surname>Vanduffel</surname>
<given-names>Wim</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="aff" rid="a6">6</xref>
<xref ref-type="aff" rid="a7">7</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7418-8275</contrib-id>
<name>
<surname>Dehaene</surname>
<given-names>Stanislas</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a8">8</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2221-9081</contrib-id>
<name>
<surname>Dehaene-Lambertz</surname>
<given-names>Ghislaine</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Cognitive Neuroimaging Unit, CEA, INSERM, Université Paris-Saclay</institution>, NeuroSpin center, 91191 Gif/Yvette, <country>France</country></aff>
<aff id="a2"><label>2</label><institution>Center for Brain Circuit Therapeutics Department of Neurology Brigham &amp; Women’s Hospital, Harvard Medical School</institution>, Boston, MA, <country>USA</country></aff>
<aff id="a3"><label>3</label><institution>Department of Neurosciences, Laboratory of Neuro- and Psychophysiology, KU Leuven Medical School</institution>, Leuven 3000, <country>Belgium</country></aff>
<aff id="a4"><label>4</label><institution>Leuven Brain Institute</institution>, KU Leuven, Leuven 3000, <country>Belgium</country></aff>
<aff id="a5"><label>5</label><institution>Université Paris-Saclay (UVSQ)</institution>, Hôpital Foch, 92150, Suresnes, <country>France</country></aff>
<aff id="a6"><label>6</label><institution>Athinoula A. Martinos Center for Biomedical Imaging, Massachusetts General Hospital</institution>, Charlestown, MA 02129, <country>USA</country></aff>
<aff id="a7"><label>7</label><institution>Department of Radiology, Harvard Medical School</institution>, Boston, MA 02144, <country>USA</country></aff>
<aff id="a8"><label>8</label><institution>Collège de France, Université Paris-Sciences-Lettres (PSL)</institution>, 11 Place Marcelin Berthelot, 75005 Paris, <country>France</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Martin</surname>
<given-names>Andrea E</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Max Planck Institute for Psycholinguistics</institution>
</institution-wrap>
<city>Nijmegen</city>
<country>Netherlands</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Behrens</surname>
<given-names>Timothy E</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Oxford</institution>
</institution-wrap>
<city>Oxford</city>
<country>United Kingdom</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label><bold>Email:</bold> <email>ghislaine.dehaene@cea.fr</email> or <email>timo@neuroscience.visio</email>n</corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2023-07-21">
<day>21</day>
<month>07</month>
<year>2023</year>
</pub-date>
<volume>12</volume>
<elocation-id>RP87380</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-03-16">
<day>16</day>
<month>03</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-03-04">
<day>04</day>
<month>03</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.03.04.531109"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2023, van Kerkoerle et al</copyright-statement>
<copyright-year>2023</copyright-year>
<copyright-holder>van Kerkoerle et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-87380-v1.pdf"/>
<abstract>
<title>Abstract</title><p>The emergence of symbolic thinking has been proposed as a dominant cognitive criterion to distinguish humans from other primates during hominization. Although the proper definition of a symbol has been the subject of much debate, one of its simplest features is bidirectional attachment: the content is accessible from the symbol, and vice versa. Behavioral observations scattered over the past four decades suggest that this criterion might not be met in non-human primates, as they fail to generalize an association learned in one temporal order (A to B) to the reverse order (B to A). Here, we designed an implicit fMRI test to investigate the neural mechanisms of arbitrary audio-visual and visual-visual pairing in monkeys and humans and probe their spontaneous reversibility. After learning a unidirectional association, humans showed surprise signals when this learned association was violated. Crucially, this effect occurred spontaneously in both learned and reversed directions, within an extended network of high-level brain areas, including, but also going beyond the language network. In monkeys, by contrast, violations of association effects occurred solely in the learned direction and were largely confined to sensory areas. We propose that a human-specific brain network may have evolved the capacity for reversible symbolic reference.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>fMRI</kwd>
<kwd>primate</kwd>
<kwd>human</kwd>
<kwd>symbol</kwd>
<kwd>mathematic</kwd>
<kwd>language</kwd>
<kwd>learning</kwd>
</kwd-group>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>It is a longstanding question whether there is something unique about the cognitive abilities of humans relative to other animals (<xref ref-type="bibr" rid="c39">Hauser et al., 2002</xref>; <xref ref-type="bibr" rid="c30">Fitch et al., 2005</xref>; <xref ref-type="bibr" rid="c48">Iriki, 2006</xref>; <xref ref-type="bibr" rid="c45">Hopkins et al., 2012</xref>; <xref ref-type="bibr" rid="c53">Kietzmann, 2019</xref>; <xref ref-type="bibr" rid="c84">Penn et al., 2008</xref>; <xref ref-type="bibr" rid="c4">Berwick and Chomsky, 2016</xref>). Symbols are ubiquitous in many domains of human cognition, underlying not only language but mathematical, musical and social representations among many others domains (<xref ref-type="bibr" rid="c11">Deacon, 1998</xref>; <xref ref-type="bibr" rid="c12">Dehaene et al., 2022</xref>; <xref ref-type="bibr" rid="c49">Kabdebon and Dehaene-Lambertz, 2019</xref>; <xref ref-type="bibr" rid="c78">Nieder, 2009</xref>; <xref ref-type="bibr" rid="c98">Sablé-Meyer et al., 2021</xref>). The appearance of symbolic representations, which would develop in parallel with the expansion of prefrontal and parietal associative areas, has therefore been suggested as a crucial marker signaling hominization (<xref ref-type="bibr" rid="c11">Deacon, 1998</xref>; <xref ref-type="bibr" rid="c12">Dehaene et al., 2022</xref>; <xref ref-type="bibr" rid="c41">Henshilwood et al., 2002</xref>; <xref ref-type="bibr" rid="c74">Neubauer et al., 2018</xref>).</p>
<p>This proposal, however, hinges on the definition of what a symbol is. The term symbol is often used as a synonym for a sign, which is classically defined by Ferdinand de Saussure as an arbitrary binding between a “signifier” (for instance a word, a digit, but also a traffic sign, logo, etc.) and a “signified” (the meaning or content to which the signifier refers) . In that respect, however, many non-human animals, including chimpanzees, macaques, but also dogs, are able to learn hundreds of such relationships, even with arbitrary signs (<xref ref-type="bibr" rid="c50">Kaminski et al., 2004</xref>; <xref ref-type="bibr" rid="c60">Livingstone et al., 2010</xref>; <xref ref-type="bibr" rid="c67">Matsuzawa, 1985</xref>; <xref ref-type="bibr" rid="c92">Premack, 1971</xref>). Even bees can learn to associate arbitrary visual shapes to abstract representations such as visual quantities (2 or 3 elements) independently of the density, size or color of the elements in the visual display (<xref ref-type="bibr" rid="c46">Howard et al., 2019</xref>). More recently, it has been proposed to reserve the term “symbol” for a collection of such signs that can be syntactically manipulated according to precise compositional rules (<xref ref-type="bibr" rid="c11">Deacon, 1998</xref>; <xref ref-type="bibr" rid="c12">Dehaene et al., 2022</xref>; <xref ref-type="bibr" rid="c78">Nieder, 2009</xref>). The symbols then entertain relationships between each other that are parallel to the relationships between the objects, or concepts, they represent. For example, numerical symbols allow manipulations such “2+3=5” irrespective of whether it applies to apples, oranges or money. Performing the “sum” operation internally allows expectations about a specific outcome in the external world. Non-human animals may be conditioned to acquire iconic or indexical associations (i.e. signs which bear, respectively, a non-arbitrary or arbitrary relationships between the signifier and the signified) and even perhaps perform operations on the learned signs, such as addition (<xref ref-type="bibr" rid="c59">Livingstone et al., 2014</xref>), but their capacities for novel symbolic composition, especially of a recursive syntactic nature, appear limited, or absent (<xref ref-type="bibr" rid="c4">Berwick and Chomsky, 2016</xref>; <xref ref-type="bibr" rid="c12">Dehaene et al., 2022</xref>, <xref ref-type="bibr" rid="c13">2015</xref>; <xref ref-type="bibr" rid="c84">Penn et al., 2008</xref>; <xref ref-type="bibr" rid="c98">Sablé-Meyer et al., 2021</xref>; <xref ref-type="bibr" rid="c125">Yang, 2013</xref>; <xref ref-type="bibr" rid="c126">Zhang et al., 2022</xref>).</p>
<p>The difference between humans and animals in terms of symbolic access remains controversial, in part because learning complex tasks require considerable training in animals, and a variety of factors such as motivation, learning rate and working memory capacity, may therefore explain an animal’s failure. This difficulty could be circumvented by testing a basic element of symbolic representations, i.e., the temporal reversibility of a learned arbitrary association. While the associations between indices and objects (typically acquired during classical conditioning) are unidirectional, as in the famous example of the whistle indicating the food, symbolic associations are bidirectional or symmetric (<xref ref-type="bibr" rid="c11">Deacon, 1998</xref>; <xref ref-type="bibr" rid="c78">Nieder, 2009</xref>). When hearing the word ‘dog’ for example, you can think of a dog, but when seeing a dog, you can also come up with the word ‘dog’. Such reversibility is crucial for communication (the language learner must acquire both comprehension and production skills), but also for symbolic computations, which require going back-and-forth between the real world (e.g., seeing three sets of four objects), the internal symbols (e.g. to allow the internal computation “3x4=12”) and back (to expect a total quantity of twelve). In the current work, we test the “reversibility hypothesis”, which proposes that because of a powerful symbolic system, humans are biased to spontaneously form bidirectional associations between an object and an arbitrary sign. It implies that the referential function of the sign immediately operates in both directions (i.e., comprehension and production), allowing to retrieve the signified (meaning) from the signifier (symbol) and vice-versa.</p>
<p>A small number of behavioral studies, spread over four decades, report that non-human animals such as bees and pigeons, but also macaques, baboons and chimpanzees, struggle to reverse the associations that they learned in one direction (<xref ref-type="bibr" rid="c47">Imai et al., 2021</xref>; <xref ref-type="bibr" rid="c55">Kojima, 1984</xref>; <xref ref-type="bibr" rid="c57">Lipkens et al., 1988</xref>; <xref ref-type="bibr" rid="c68">Medam et al., 2016</xref>; <xref ref-type="bibr" rid="c105">Sidman et al., 1982</xref>; <xref ref-type="bibr" rid="c46">Howard et al., 2019</xref>; see <xref ref-type="bibr" rid="c8">Chartier and Fagot, 2022</xref>, for a review and discussion). In a recent experiment, <xref ref-type="bibr" rid="c8">Chartier and Fagot (2022)</xref> explored this question in 20 free-behaving baboons. After having learned to pair visual shapes (two pairs A-B) above 80% success, their performance dropped considerably when the order of presentation was subsequently reversed (B-A; 54% correct, chance = 50%), although their relearning performance was only slightly but significantly better when the reversed pairs were congruent (B1-A1; B2-A2) rather than incongruent (B1-A2; B2-A1). Even for the famous case of chimpanzee <italic>AI</italic>, who learned Arabic numerals and other arbitrary tokens for colors and objects (<xref ref-type="bibr" rid="c66">Matsuzawa, 2009</xref>, <xref ref-type="bibr" rid="c67">1985</xref>), it turns out that her capacity to associate signs and their meanings was based on an explicit and sequential training in both directions, at least initially (<xref ref-type="bibr" rid="c55">Kojima, 1984</xref>). In sharp contrast, humans as young as 8 months, even when tested under the same conditions as monkeys or baboons (<xref ref-type="bibr" rid="c105">Sidman et al., 1982</xref>), show behavioral evidence of immediate spontaneous reversal of learned associations (<xref ref-type="bibr" rid="c47">Imai et al., 2021</xref>; <xref ref-type="bibr" rid="c80">Ogawa et al., 2010</xref>; <xref ref-type="bibr" rid="c105">Sidman et al., 1982</xref>).</p>
<p>Still, behavioral tests depend on an explicit report which could hide an implicit understanding of symbolic representations. This confound can be alleviated by directly recording the brain responses, providing a more direct comparison between species. Here, we propose a simple brain-imaging test of reversible associations. First, the participant receives evidence of several stimulus pairings between an object (O) and an arbitrary sign or label (L) in a fixed ‘canonical order’, e.g., from O<sub>1</sub> to L<sub>1</sub> and from O<sub>2</sub> to L<sub>2</sub>. Knowledge of these learned (i.e., congruent) associations is then tested using a classic violation-of-expectation paradigm, by evaluating the brain’s surprise response or “prediction error” when, say, O<sub>1</sub> is followed by L<sub>2</sub>. This response can then also be evaluated in the converse direction, by switching the order of presentation of the two items within a pair. The crucial question is whether the brain shows a surprise response to an incongruent pairing presented in reversed order (e.g., L<sub>1</sub> followed by O<sub>2</sub>), relative to the corresponding congruent pairing (L<sub>1</sub> followed by O<sub>1</sub>). The reversibility hypothesis predicts that if symbolic associations are formed, pairs presented in canonical and reversed order should be similarly processed, and so a similar surprise response to incongruent pairings should be found in both cases.</p>
<p>A recent study from our lab used EEG to apply this approach to 4-5 month-old human infants (<xref ref-type="bibr" rid="c49">Kabdebon and Dehaene-Lambertz, 2019</xref>). The infants were habituated to pairs of stimuli in which a specific picture (a lion or a fish) was associated with tri-syllabic none words, depending on a rule concerning syllable- repetition in the word (e.g. xxY words such as <italic>babagu</italic>, <italic>didito</italic>, etc.. were followed by the fish picture whereas xYx words such as <italic>lotilo</italic>, <italic>fudafu</italic>, etc.. were followed by the lion picture). Violation-of-expectations responses were recorded in both canonical and reverse order, suggesting that preverbal human infants, already have the ability to reversibly attach a symbol to an abstract rule. In human adults, an fMRI study with a more complex design using explicit reports on associations between abstract patterns also showed brain signatures suggestive of spontaneous reversal of learned associations (<xref ref-type="bibr" rid="c80">Ogawa et al., 2010</xref>). The network of brain areas overlapped with the multiple-demand system that is ubiquitously observed in high- level cognitive tasks (<xref ref-type="bibr" rid="c18">Duncan, 2010</xref>; <xref ref-type="bibr" rid="c24">Fedorenko et al., 2013</xref>), including bilateral inferior and middle frontal gyrus (IFG and MFG), anterior insula (AI), intraparietal sulcus (IPS), and dorsal anterior cingulate cortex (dACC). In contrast, a human fMRI study investigating association learning between two natural visual objects found that violation effects in the learned direction were restricted to low level visual areas (<xref ref-type="bibr" rid="c93">Richter et al., 2018</xref>). Similarly, in macaque monkeys violation effects in the learned direction have been found selectively in visual areas, using fMRI as well as single-neuron recordings (<xref ref-type="bibr" rid="c51">Kaposvari et al., 2018</xref>; <xref ref-type="bibr" rid="c71">Meyer et al., 2014</xref>; <xref ref-type="bibr" rid="c70">Meyer and Olson, 2011</xref>; <xref ref-type="bibr" rid="c116">Vergnieux and Vogels, 2020</xref>). One of these studies (<xref ref-type="bibr" rid="c70">Meyer and Olson, 2011</xref>) also tested, in a small subset of 17 neurons, whether the learned associations spontaneously reversed, and showed no such reversal. From these studies, it is difficult to draw a conclusion about a potential difference between species, due to important differences in recording techniques and task design.</p>
<p>Here, we directly compared the ability to spontaneously reverse learned associations in humans and macaque monkeys using identical training, stimuli and whole-brain fMRI measures. Our goals were to (1) probe the reversibility hypothesis in an elementary passive paradigm in both species; (2) to shed light on the brain mechanisms of symbolic associations in humans. Indeed, two alternative hypotheses may be formulated. First, given that symbolic learning is a defining feature of language, reversible violation-of- expectation effects might be restricted to the left-hemispheric temporal and inferior frontal language areas. Alternatively, since symbolic learning is manifest in many domains outside of language, for instance in mathematics or music, each attached to a dissociable fronto-posterior brain network (<xref ref-type="bibr" rid="c2">Amalric and Dehaene, 2016</xref>; <xref ref-type="bibr" rid="c9">Chen et al., 2021</xref>; <xref ref-type="bibr" rid="c12">Dehaene et al., 2022</xref>; <xref ref-type="bibr" rid="c23">Fedorenko et al., 2011</xref>; <xref ref-type="bibr" rid="c77">Nieder, 2019</xref>; <xref ref-type="bibr" rid="c79">Norman-Haignere et al., 2015</xref>), reversibility could be expected to arise from a broad and bilateral network of human brain areas, including dorsal intraparietal and middle frontal nodes. We thus tested audio-visual and visual-visual symbolic pairing in two successive experiments.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Summary of the experimental design</title>
<p>In the first experiment, we examined the learning and reversibility of auditory-visual pairs, i.e., between a visual object and an auditory label. Over the course of three days, we habituated humans (n=31) and macaque monkeys (n=2) with 4 pairs of visual objects and speech sounds (<bold><xref rid="fig1" ref-type="fig">Figure 1A</xref>; <xref rid="figS1" ref-type="fig">Supplementary Figure 1</xref></bold>). Two of the pairs were presented in the auditory-to-visual direction and two in the visual-to-auditory direction, ensuring that all subjects had experience with both orders and would not be surprised by their temporal reversal <italic>per se</italic> (see discussion of the utility of this point in <xref ref-type="bibr" rid="c68">Medam et al, 2016</xref>). After three consecutive days of habituation with 100% of congruent canonical trials (24 training trials in total per pair, presented outside the scanner), subjects were tested for learning using 3T fMRI, during which they were passively exposed to pairs that respected or violated the learned pairings (<bold><xref rid="fig1" ref-type="fig">Figure 1B</xref></bold>). To sustain the memory for learned pairs, the design still included 70% of congruent canonical trials (identical to the trials presented during habituation). In addition, there were 10% of incongruent canonical trials, in which the temporal order was maintained but the pairings between auditory and visual stimuli were violated. Enhanced brain responses to such incongruent pairs would indicate surprise and therefore prove that the associations had been learned. Note that all auditory and visual stimuli themselves were familiar: only their pairing was unusual. The design also included 10% of reversed congruent and 10% of reversed incongruent trials, in which the habitual (i.e. canonical) order of presentation of the pairs was reversed (<bold><xref rid="fig1" ref-type="fig">Figure 1A</xref></bold>). Observing an incongruity effect on such reversed trials would indicate that subjects spontaneously reversed the pairings and were surprised when they were violated. Note that the frequency of the two types of reversed trials was equal, and thus did not afford any additional learning of the reversed pairs (unlike <xref ref-type="bibr" rid="c8">Chartier and Fagot, 2022</xref>).</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Experimental paradigm for auditory-visual label learning.</title>
<p><bold>A</bold>) Subjects were exposed to four different visual-auditory pairs during three days (6 repetitions of each pair, 3 minute video). Two pairs were always presented in the ‘visual-then-auditory’ order (object to label), and two in the ‘auditory-then-visual’ (label to object) order. During the test phase, this canonical order was kept on 80% of trials, including 10% of incongruent pairs to test memory of the learned pairs, and was reversed on 20% of the trials. On reversed trials, half the pairs were congruent and half were incongruent (each 10% of total trials), thus testing reversibility of the pairings without affording additional learning. <bold>B</bold>,<bold>C</bold>) Activation in sensory cortices. Although each trial comprises auditory and visual stimuli, these could be separated by the temporal offsets. Images show significantly activated regions in the contrasts image &gt; sound (red-yellow) and sound &gt; image (blue-light blue), averaged across all subjects and runs for humans (B) and monkeys (C). <bold>D</bold>,<bold>E</bold>) Average finite-impulse-response (FIR) estimate of the deconvolved hemodynamic responses for humans (D) and monkeys (E) within clusters shown in B and C respectively, separately for visual-audio (VA) and audio- visual (AV) trials. Sign flipped on y-axis for monkey responses.</p></caption>
<graphic xlink:href="531109v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2b">
<title>Experiment 1| audio-visual stimulus pairs</title>
<p>We first mapped the cortical regions that were activated by visual and auditory stimuli, modelling the two stimuli within each pair with separate regressors (<bold><xref rid="fig1" ref-type="fig">Figure 1B, C</xref></bold>). Visually evoked activations propagated all the way to the prefrontal cortex (PFC) in monkeys while they remained restricted to lower cortical areas in humans, in line with previous studies (<xref ref-type="bibr" rid="c15">Denys et al., 2004b</xref>; <xref ref-type="bibr" rid="c61">Mantini et al., 2013</xref>). In contrast, the response was relatively weak in the auditory cortex of monkeys, also in line with previous studies (<xref ref-type="bibr" rid="c22">Erb et al., 2019</xref>; <xref ref-type="bibr" rid="c88">Petkov et al., 2009</xref>; <xref ref-type="bibr" rid="c113">Uhrig et al., 2014</xref>). This is expected as the size of the auditory cortex in monkeys is small, relative to their visual cortex (<xref ref-type="bibr" rid="c26">Felleman and Van Essen, 1991</xref>), as well as relative to the size of the auditory cortex in humans (<xref ref-type="bibr" rid="c123">Woods et al., 2010</xref>). Even though the onset of the two stimuli within a pair were just 800ms apart, the fast acquisition allowed us to separate the timing of the activation of the visual and auditory pathways in both humans and monkeys (<bold><xref rid="fig1" ref-type="fig">Figure 1 D, E</xref></bold>). In visual cortex, the response evoked by the pair arose earlier when the first stimulus of the pair was visual compared to when it was auditory, and the other way around for the auditory cortex.</p>
<p>We next investigated whether the subjects had learned the associations, whether the brain responses showed signatures of generalization to the reversed direction, and which brain areas were involved. If participants had learned the associations, incongruent trials should evoke a surprise response relative to congruent trials, when presented in the same order as the training pairs (canonical trials). Crucially, if they spontaneously reversed the associations, a similar incongruity effect should also be seen on reversed trials. According to the reversibility hypothesis, humans should show a spontaneous reversal, while monkeys should not. Only for monkey, we should therefore find an interaction effect between incongruity and canonicity, indicating a significant difference between the congruity effect in the learned direction compared to the congruity effect in the reserved direction.</p>
<p>Indeed, in humans, a vast network was activated by incongruity on both canonical and reversed trials (voxel p&lt;0.001, cluster p&lt;0.05 corrected, n=31 participants) (<bold><xref rid="fig2" ref-type="fig">Figure 2A</xref>, <xref rid="tbl1" ref-type="table">Table 1</xref></bold>). This network included a set of high-level brain regions previously described as the multiple demand system (<xref ref-type="bibr" rid="c18">Duncan, 2010</xref>; <xref ref-type="bibr" rid="c24">Fedorenko et al., 2013</xref>), including bilateral IFG, MFG, AI, IPS, and dACC. It also included the language network (<xref ref-type="bibr" rid="c81">Pallier et al., 2011</xref>), with the left superior temporal sulcus (STS), and the left IFG. However, in our case the activation was bilateral, thereby supporting the model that the language network is part of a larger symbolic network (<xref ref-type="bibr" rid="c12">Dehaene et al., 2022</xref>). Furthermore, we also found activations in the precuneus, similar to the network that has been found for top-down attention to memorized visual stimuli (<xref ref-type="bibr" rid="c102">Sestieri et al., 2010</xref>), which also included bilateral STS and IPS. Notably, we did not find any congruity effects in visually activated regions (compare to <bold><xref rid="fig1" ref-type="fig">Figure 1B</xref></bold>), in contrast to a previous human fMRI study (<xref ref-type="bibr" rid="c93">Richter et al., 2018</xref>). <bold><xref rid="fig2" ref-type="fig">Figure 2B</xref></bold> shows the hemodynamic response within the different clusters and the different conditions. In all analyses, since there were a majority of canonical congruent trials, sensitivity was higher in the canonical direction, and thus the size of the significant clusters was larger on canonical than on reversed trials. However, no significant cluster exhibited any interaction between congruity and canonicity, indicating that there was no statistical difference between the effect of congruity for the habituated and the reversed direction. Thus, the human brain fully and spontaneously reverses the auditory-visual associations that it learns.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Congruity effects in the auditory-visual task in humans (experiment 1).</title>
<p><bold>A</bold>) areas activated by incongruent trials more than by congruent trial in canonical trials (red), reversed trials (blue), and their overlap (green). Brain maps are thresholded at p<sub>voxel</sub> &lt; 0.001&amp; p<sub>cluster</sub> &lt; 0.05 corrected for multiple comparisons across the brain volume. No interaction effect was observed between congruity and canonicity. <bold>B</bold>) Average FIR estimate of the deconvolved hemodynamic responses within significant clusters in the left hemisphere, separately for VA and AV trials.</p></caption>
<graphic xlink:href="531109v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><p>Congruity effect in Experiment 1 in humans (n=31).</p></caption>
<graphic xlink:href="531109v1_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>We next asked whether monkeys (n=3) also learned the associations and did so in both directions. The canonical congruity effect, indexing learning, was not significant when analyzing only the first imaging session after the 3 days of training. Thus, monkeys were further trained during two weeks (with in total ∼960 training trials per pair) and tested during 4 consecutive days. The same training and testing pattern was used for 5 stimuli sets (<bold><xref rid="figS1" ref-type="fig">Supplementary Figure 1</xref></bold>). After this extended training, we found consistent effects in both monkeys, with clusters in early visual areas (V1, V2, V4), and auditory association areas in the left temporo-parieto-occipital cortex (TPO) (AV and VA trials combined, p&gt;0.001, cluster p&lt;0.05, n=2) (<bold><xref rid="fig3" ref-type="fig">Figure 3</xref>, <xref rid="tbl2" ref-type="table">Table 2</xref></bold>). Crucially, however, this effect was confined to the canonical direction, with no significant clusters in the reversed direction at the whole-brain level, in accordance with the reversibility hypothesis. We specifically tested the difference between the congruity effect in the learned and the reversed direction by calculating the interaction effect between congruity and canonicity, which showed an activation pattern that was similar to the canonical congruity effect, which reached significance in areas V2 and V4. <bold><xref rid="fig3" ref-type="fig">Figure 3C</xref></bold> shows the corresponding hemodynamic signals, with an enhanced response to incongruent pairs in the canonical direction (continuous red curve) but not in the reversed direction (dashed red curve). The results thus indicated that monkey cortex could acquire audio-visual pairings, as also shown by prior visual-visual experiments (<xref ref-type="bibr" rid="c70">Meyer and Olson, 2011</xref>; <xref ref-type="bibr" rid="c116">Vergnieux and Vogels, 2020</xref>), but with two major differences with humans: the congruity effects did not involve a broad network of high-level cortical areas but remained restricted to early sensory areas, and the learned associations did not reverse.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Congruity effects in the auditory-visual task in monkeys (experiment 1).</title>
<p><bold>A</bold>) significant clusters from the incongruent-congruent canonical contrast. No significant clusters were found for the reversed direction. <bold>B</bold>) significant clusters from the interaction between congruity and canonicity. (p<sub>voxel</sub>&lt;0.001 &amp; p<sub>cluster</sub>&lt;0.05 for both maps) <bold>C</bold>,<bold>D</bold>) Average FIR estimate of the deconvolved MION responses within the clusters from the incongruent-congruent canonical contrast, averaged over VA and AV trials. All clusters in early visual areas were taken together to create figure C. Average of 2 animals.</p></caption>
<graphic xlink:href="531109v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2:</label>
<caption><p>Congruity effect in Experiment 1 in monkeys (n=2)</p></caption>
<graphic xlink:href="531109v1_tbl2.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s2c">
<title>Experiment 2 | visual-visual stimulus pairs</title>
<p>The non-reversal in monkeys in the above audio-visual experiment could be due to a number of methodological choices. First, although the visual stimuli were optimized for monkeys, as 3 out of 5 stimulus sets were pictures of familiar toys, the auditory stimuli (pseudowords) might have been suboptimal for them (although note that monkeys in our lab have extensive experience with human speech). It might be argued that this choice made their discrimination difficult (although note that the canonical congruity effect is evidence of discrimination). Indeed, the auditory cortex is relatively small in monkeys compared to humans (<xref ref-type="bibr" rid="c123">Woods et al., 2010</xref>), and there is evidence that auditory memory capacity is reduced in monkeys compared to humans (<xref ref-type="bibr" rid="c101">Scott and Mishkin, 2016</xref>). Second, the instructions differed: while we asked human subjects to fixate a dot at the center of the screen and to pay attention to the stimuli, monkeys were simply rewarded for fixation.</p>
<p>To address those concerns, we replicated the experiment with reward-dependent visual-visual associations in 3 macaque monkeys (<bold><xref rid="fig4" ref-type="fig">Figure 4</xref>; <xref rid="figS2" ref-type="fig">Supplementary Figure 2A</xref></bold>). First, we replaced the spoken auditory stimuli with abstract black-and-white shapes similar to the lexigrams used to train chimpanzees to communicate with humans (<xref ref-type="bibr" rid="c67">Matsuzawa, 1985</xref>) (<bold><xref rid="figS2" ref-type="fig">Supplementary Figure 2B</xref></bold>). Second, to enhance attention for the monkeys, we introduced a reward association paradigm that made the stimuli behaviorally relevant for them (<xref ref-type="bibr" rid="c120">Wikman et al., 2019</xref>). Within each presentation direction, one of the two pictures of objects was associated with a high reward, and one with a low reward (<bold><xref rid="figS2" ref-type="fig">Supplementary Figure 2A</xref></bold>). Monkeys were still rewarded for fixation, but object identity predicted the size of the reward during the delay period following the presentation of the stimuli (two objects predicted a high reward, and two predicted a low reward). To calculate congruity effects, the two pairs within each direction were always averaged, making the reward association an orthogonal element in the design.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Visual-visual label learning in humans and monkeys (experiment 2).</title>
<p><bold>A, Experiment paradigm.</bold> Subjects were habituated to 4 different visual-visual pairs during three days. Two pairs were in the ‘object-then-label’ order and two pairs in the ‘label-then-object’ order. For the monkeys, one object in each direction was associated with a high reward while the other one was associated with a low reward, making reward size orthogonal to congruity and canonicity (See <xref rid="figS2" ref-type="fig">Supplementary Figure 2</xref> for details). <bold>B, monkey fMRI results.</bold> Significant clusters (p<sub>voxel</sub>&lt;0.001 &amp; cluster volume &gt;50) from the incongruent- congruent canonical contrast (left) and the interaction between congruity and canonicity (right). <bold>C, human fMRI results.</bold> Areas more activated by incongruent trials more than by congruent trial in canonical trials (red), reversed trials (blue), and their overlap (green) (right) (p<sub>voxel</sub>&lt;0.005 &amp; cluster volume &gt;50). No red voxels are visible because all of them figure in the overlap (green). <bold>D, Human behavioral results</bold>. After learning, human adults rated the familiarity of different types of pairs (including a fifth category of novel, never seen pairings). Each dot represents the mean response of one subject in each condition. Although the reversed congruent trials constituted only 10% of the trials, they were considered almost as familiar as the canonical congruent pairs.</p></caption>
<graphic xlink:href="531109v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Using this design, we obtained significant canonical congruity effects in monkeys on the first imaging day after the initial training (24 trials per pair), indicating that the animals had learned the associations (<bold><xref rid="fig4" ref-type="fig">Figure 4B</xref>, <xref rid="tbl3" ref-type="table">Table 3</xref></bold>). The effect was again found in visual areas (V1, V2 &amp; V4), also spreading to the prefrontal cortex (45B, 46v), very similar to the visually activated areas (compare to <bold><xref rid="fig1" ref-type="fig">Figure 1C</xref></bold>). In addition, small clusters were also found in area 6 and in STS. . Crucially, the congruity effect remained restricted to the learned direction, as no area showed a significant reversed congruity effect, again in accordance with the reversibility hypothesis. The interaction between congruity and canonicity indicated that there was a significant difference between the canonical and the reversed direction in a similar set of regions (V1, V2, area 45A, 46v and 6). The greater involvement of frontal cortex in the congruity effect in this paradigm fits with previous reports on the impact of reward association on long-term memory for visual stimuli in macaque monkeys (<xref ref-type="bibr" rid="c36">Ghazizadeh et al., 2018</xref>) . To further investigate this, we split high versus low rewarded pairs and found that congruity effect was present only for high-reward conditions, with a significant interaction of congruity and reward in area 45 and caudate nucleus (<bold><xref rid="figS3" ref-type="fig">Supplementary Figure 3</xref></bold>). Overall, these results indicate that, even when stimuli were optimized and made relevant for monkeys, leading to enhanced activations and an activation of prefrontal cortex to violations of expectations, the learned associations did not reverse in monkeys.</p>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3:</label>
<caption><p>Congruity effect in Experiment 2 in monkeys (n=3)</p></caption>
<graphic xlink:href="531109v1_tbl3.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>We also ran this visual-visual paradigm in human participants (n=24) with the goal to clarify the role of language in the reversibility process. Humans again gave evidence of reversed association, although weaker than with spoken words (<bold><xref rid="fig4" ref-type="fig">Figure 4C</xref>, <xref rid="tbl4" ref-type="table">Table 4</xref></bold>). At the normal threshold (voxel p&lt;0.001, cluster p&lt;0.05 corrected), the main effect of congruity was significant in a network very similar to experiment 1, including bilateral middle frontal gyrus (MFG), left intraparietal sulcus (IPS), bilateral anterior insula, dorsal anterior cingulate cortex (dACC), with an additional focus in left inferior temporal gyrus (<bold><xref rid="fig4" ref-type="fig">Figure 4C</xref>, <xref rid="tbl4" ref-type="table">Table 4</xref></bold>). The involvement of the language network was limited. In particular a main effect of congruity in the STS was absent, in agreement with the shift to visual symbols. Still, bilateral middle frontal gyri, STS and the precuneus were again activated by the incongruent minus congruent contrast on reversed trials (voxel p&lt;0.001, cluster p&lt;0.05 corrected), thereby extending beyond the multiple-demand system (<xref ref-type="bibr" rid="c18">Duncan, 2010</xref>; <xref ref-type="bibr" rid="c24">Fedorenko et al., 2013</xref>). While sensory activated regions were again absent, in contrast to a previous study on congruity effects in humans when using associations between two visual objects (<xref ref-type="bibr" rid="c93">Richter et al., 2018</xref>). And crucially, no interaction effect was again found between congruity and canonicity, neither at the classical threshold (p&lt;0.001) nor at a lower threshold (p&lt;0.01). Those results indicate that humans can also encode pairs of visual stimuli in a symmetrical, reversible fashion, involving a network of high-level cortical areas, unlike monkeys.</p>
<table-wrap id="tbl4" orientation="portrait" position="float">
<label>Table 4:</label>
<caption><p>Congruity effect in Experiment 2 in humans (n=23)</p></caption>
<graphic xlink:href="531109v1_tbl4.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>Further evidence was obtained from a behavioral test, performed after imaging, where we collected familiarity ratings for each stimulus pair (see Methods, <bold><xref rid="fig4" ref-type="fig">Figure 4</xref></bold>). Although participants reported a higher familiarity with congruent canonical pairs (which were presented on 70% of trials) than with congruent reversed pairs (which were presented on 10% of trials, t(20)=2.8, p=0.01), both pairs were rated as much more familiar than their corresponding incongruent pairs (although they were also presented 10% of time), and than never-seen pairs (all t(20) &gt;7, p&lt;0.0001, bilateral paired t-test). This familiarity task thus confirms that humans spontaneously reverse associations and experience a memory illusion of seeing the reversed pairs.</p>
</sec>
<sec id="s2d">
<title>Joint analysis of audio-visual and visual-visual stimulus pairs</title>
<p>In order to better characterize the human reversible symbol learning network and its dependence on modality, we reanalyzed both human experiments together (n=55) (<bold><xref rid="figS4" ref-type="fig">Supplementary Figure 4</xref></bold>). There was, unsurprisingly, a main effect of experiment with greater activation in a bilateral auditory and linguistic network in the AV experiment, and in the occipital, occipito-temporal and occipito-parietal visual pathways in the VV experiment. A main effect of congruity was observed and was again significant in both directions, canonical and reversed, in bilateral regions: insula, MFG, precentral, IPS, precuneus, ACC and STS. Crucially, there was still no region sensitive to the congruity X canonicity interaction, indicating that the learned associations were fully reversible. Finally, a single region, the left posterior STS, showed a significantly different congruity effect in the two experiments, as it was slightly larger in the AV relative to VV paradigm ([-60 -40 8], z=4.51; 183 vox, pcor=0.049), compatible with a specific role in learning of new spoken lexical items. The results therefore suggest that a broad and bilateral network, encompassing language areas but extending beyond them into dorsal parietal and prefrontal cortices, responded to violations of reversible symbolic association regardless of modality.</p>
<p>To interrogate more finely the role of language-related and non-related areas, we turned to a sensitive subject-specific region-of-interest (ROI) analysis. We selected ROIs which are considered as the main hubs of language (<xref ref-type="bibr" rid="c81">Pallier et al., 2011</xref>), mathematics (<xref ref-type="bibr" rid="c2">Amalric &amp; Dehaene, 2016</xref>) and reading networks. Within these ROIs, we used a separate localizer (<xref ref-type="bibr" rid="c91">Pinel et al., 2007</xref>) to recover the subject-specific coordinates of the 10% best voxels involved in amodal sentence processing (within language ROIs), in mental arithmetic (within mathematical ROIs), and in sentence reading relative to listening (within the visual word form area, VWFA). We added this region as it is activated by written words, visual symbols <italic>par excellence</italic>. We then performed ANOVAs on the betas of the main experiment averaged over these voxels.</p>
<p>A main congruity effect was observed in all ROIs (<bold><xref rid="tbl5" ref-type="table">Table 5</xref></bold>). There was also a main effect of experiment in all language ROIs, VWFA and right IT, due on the one hand to larger activations in the AV than VV experiment in frontal and superior temporal ROIs, and on the other hand to the converse trend in the VWFA and IT ROIs. A significant congruity x experiment interaction was seen only in the pSTS and IFG triangularis, because these ROIs showed a large congruity effect in the AV experiment, but no effect in the VV experiment – thus further confirming that these areas contribute specifically to the acquisition of linguistic symbols, while all other areas were engaged regardless of modality. Importantly, in all these analyses, no significant interaction canonicity X congruity nor experiment x canonicity X congruity were observed, confirming the whole brain analyses (<bold><xref rid="figS4" ref-type="fig">Supplementary Figure 4</xref></bold> and <bold><xref rid="tbl5" ref-type="table">Table 5</xref></bold>).</p>
<table-wrap id="tbl5" orientation="portrait" position="float">
<label>Table 5:</label>
<caption><p>ROIs analyses: F-values of ANOVAs performed on the averaged betas of the main task across the 10% best voxels selected in an independent localizer in ROIs commonly activated in language and mathematical tasks. The language ROIs are presented as red areas on the sagittal (x=-50) and coronal (y=- 58) brain slices and the mathematical ROIs as yellow areas. The left white area corresponds to the VWFA; n=52; df=50; p<sub>FDRcor</sub>: *** &lt;0.001, ** &lt; 0.01, *&lt; 0.05, ° &lt; 0.1.</p></caption>
<graphic xlink:href="531109v1_tbl5.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>Finally, in experiment 2 in which participants rated the familiarity of the pairs, we computed a within- subject behavioral index of reversibility as the difference in familiarity rating between incongruent and congruent reversed pairs. Across subjects, this index was correlated with the fMRI congruity effect (difference between incongruent and congruent trials in the ROI) on canonical trials (r=0.49, p=0.028) and especially on reversed trials (r=0.64, p=0.002) in the left dorsal part of area 44. In the right cerebellum, a similar correlation was observed but only for the reversed trials (r=0.57, p=0.008). No significant correlation was observed in other ROIs.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Using fMRI in human and non-human primates, we studied the learning of a sequential association between either a spoken label and an object (Exp. 1), or a visual label and an object (Exp. 2). In humans, we observed no difference in brain activation between the learned and the temporally reversed associations: in both directions, violations of the learned association activated a large set of bilateral regions (insula, prefrontal, intraparietal, cingulate cortex,) that extended beyond the language processing network. Thus, humans generalized the learned pairings across a reversal of temporal order (<bold><xref rid="fig5" ref-type="fig">Figure 5</xref></bold>). In contrast, non-human primates showed evidence of remembering the pairs only in the learned direction and did not show any signature of spontaneous reversal. Monkey responses to incongruent pairings were entirely confined to the learned canonical order and occurred primarily within sensory areas, with propagation to frontal cortex only for rewarded stimuli, yet still only in the forward direction (<bold><xref rid="fig5" ref-type="fig">Figure 5</xref></bold>).</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Summary of the two experiments in humans and monkeys.</title>
<p>(In experiment 1, p<sub>voxel</sub> &lt; 0.001 &amp; p<sub>cluster</sub> &lt; 0.05 for humans and monkeys. In experiment 2, p<sub>voxel</sub>&lt;0.005 &amp; cluster volume &gt;50 in humans and p<sub>voxel</sub>&lt;0.001 &amp; cluster volume &gt;50 in monkeys.)</p></caption>
<graphic xlink:href="531109v1_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Several studies previously found behavioral evidence for a uniquely human ability to spontaneously reverse a learned association (<xref ref-type="bibr" rid="c47">Imai et al., 2021</xref>; <xref ref-type="bibr" rid="c55">Kojima, 1984</xref>; <xref ref-type="bibr" rid="c57">Lipkens et al., 1988</xref>; <xref ref-type="bibr" rid="c68">Medam et al., 2016</xref>; <xref ref-type="bibr" rid="c105">Sidman et al., 1982</xref>), and such reversibility was therefore proposed as a defining feature of symbol representation reference (<xref ref-type="bibr" rid="c11">Deacon, 1998</xref>; <xref ref-type="bibr" rid="c49">Kabdebon and Dehaene-Lambertz, 2019</xref>; <xref ref-type="bibr" rid="c78">Nieder, 2009</xref>). Here, we went one step further by testing this hypothesis at the brain level. Indeed, a limit of previous behavioral studies is that animals could have understood the reversibility of a symbolic relationship, but failed to express it behaviorally because of extraneous procedural or attentional factors, or because of a conflict between different brain processes (e.g., for maintaining the specific and rewarded learned pairing vs. generalizing to the reverse order). Here, we used fMRI and a passive paradigm to directly probe whether any area of the monkey brain would exhibit surprise at a violation of the reversal of a learned association. Our results show that this is not the case.</p>
<p>Interpretation must remain cautious, as there are also some occasional behavioral reports of spontaneous reversal of learned associations, for instance in one well-trained California sea lion and a Beluga whale (<xref ref-type="bibr" rid="c52">Kastak et al., 2001</xref>; <xref ref-type="bibr" rid="c73">Murayama et al., 2017</xref>; <xref ref-type="bibr" rid="c100">Schusterman and Kastak, 1998</xref>) and possibly in 1 out of 20 baboons in <xref ref-type="bibr" rid="c68">Medam et al. (2016)</xref>. These studies may indicate that, with sufficient training, symbolic representation might eventually emerge in some animals, as also suggested by the small reversal trend in a recent behavior study in baboons (<xref ref-type="bibr" rid="c8">Chartier and Fagot, 2022</xref>). However, they may also merely show that animals may begin to spontaneously reverse new associations once they have received extensive training with bidirectional ones (<xref ref-type="bibr" rid="c55">Kojima, 1984</xref>). The bulk of the literature strongly suggests that while animals easily learn indexical associations, especially monkeys and chimpanzees (<xref ref-type="bibr" rid="c16">Diester and Nieder, 2007</xref>; <xref ref-type="bibr" rid="c60">Livingstone et al., 2010</xref>; <xref ref-type="bibr" rid="c67">Matsuzawa, 1985</xref>; <xref ref-type="bibr" rid="c92">Premack, 1971</xref>), but also dogs (<xref ref-type="bibr" rid="c34">Fugazza et al., 2021</xref>; <xref ref-type="bibr" rid="c50">Kaminski et al., 2004</xref>), vocal birds (e.g. <xref ref-type="bibr" rid="c85">Pepperberg, 2009</xref>) and even bees (<xref ref-type="bibr" rid="c46">Howard et al, 2019</xref>), they exhibit little or no evidence for genuine symbolic processing. Discriminating symbolic from indexical representations can be achieved by testing for spontaneous reversibility between the labels and the objects, as in the current study, or by testing for the presence of relationships among the labels (<xref ref-type="bibr" rid="c78">Nieder, 2009</xref>).</p>
<p>One previous study showed preliminary evidence for a lack of reversibility in macaque monkey inferotemporal cortex (<xref ref-type="bibr" rid="c70">Meyer &amp; Olson, 2011</xref>), but only recorded on a subset of neurons, and after extensive training on pairs of visual images (816 exposures per pair). Interestingly, a similar set of arbitrary stimuli and extensive training protocol (258 trials per pair) was used in an fMRI study on stimulus association in humans, where congruity effects were also found to be restricted to early visual areas (<xref ref-type="bibr" rid="c93">Richter et al., 2018</xref>). It might have been that the extensive training lead to more low-level and rigid encoding in the trained direction. It is therefore instructive that, here, we found irreversibility after a very short training. Indeed, in experiment 2, just 24 exposures per pair were sufficient to observe a surprise effect in the canonical direction without generalization in the reverse direction -even after longer exposures. In addition, we strived to make the objects concrete and recognizable to the monkeys (by using pictures of toys that were familiar to them, taken from various angles), while the labels were as abstract as possible to promote a symbol- referent asymmetry in the pairs. We considered using macaque vocalizations for the sounds, but these already have a defined meaning, often emotional, that could have disrupted the experiments. Furthermore, the present animals had extensive experience with human speech. Finally, while the present lab setting could be judged artificial and not easily conducive to language acquisition, previous evidence indicates that human preverbal infants easily learn labels in such a setting (<xref ref-type="bibr" rid="c69">Mersad et al., 2021</xref>) and spontaneously reverse associations after only a short training period (<xref ref-type="bibr" rid="c20">Ekramnia and Dehaene-Lambertz, 2019</xref>; <xref ref-type="bibr" rid="c49">Kabdebon and Dehaene-Lambertz, 2019</xref>).</p>
<p>Non-human primates are often considered the animal model of choice to understand the neural correlates of high-level cognitive functions in humans (<xref ref-type="bibr" rid="c27">Feng et al., 2020</xref>; <xref ref-type="bibr" rid="c76">Newsome and Stein-Aviles, 1999</xref>; <xref ref-type="bibr" rid="c97">Roelfsema and Treue, 2014</xref>). Accordingly, many studies have emphasized the similarity between human and non-human primates in terms of brain anatomy, physiology and behavior (<xref ref-type="bibr" rid="c6">Caspari et al., 2018</xref>; <xref ref-type="bibr" rid="c10">De Valois et al., 1974</xref>; <xref ref-type="bibr" rid="c22">Erb et al., 2019</xref>; <xref ref-type="bibr" rid="c37">Hackett et al., 2001</xref>; <xref ref-type="bibr" rid="c38">Harwerth and Smith, 1985</xref>; Dante <xref ref-type="bibr" rid="c62">Mantini et al., 2012</xref>; <xref ref-type="bibr" rid="c64">D. Mantini et al., 2012</xref>; <xref ref-type="bibr" rid="c63">Mantini et al., 2011</xref>; <xref ref-type="bibr" rid="c65">Margulies et al., 2016</xref>; <xref ref-type="bibr" rid="c89">Petrides et al., 2012</xref>; <xref ref-type="bibr" rid="c113">Uhrig et al., 2014</xref>; <xref ref-type="bibr" rid="c119">Warren, 1974</xref>; <xref ref-type="bibr" rid="c121">Wilson et al., 2017</xref>; <xref ref-type="bibr" rid="c122">Wise, 2008</xref>). At the same time, important differences between human and monkey brains have been reported as well. Using a direct comparison with fMRI, some specific functional differences have been found (<xref ref-type="bibr" rid="c14">Denys et al., 2004a</xref>, <xref ref-type="bibr" rid="c15">2004b</xref>; <xref ref-type="bibr" rid="c61">Mantini et al., 2013</xref>; <xref ref-type="bibr" rid="c115">Vanduffel et al., 2002</xref>). Particularly relevant is that in contrast to humans, monkeys show clear feature tuning in the prefrontal cortex, which is in line with the sensory activation we found in monkey PFC (<bold><xref rid="fig1" ref-type="fig">Figure 1C</xref></bold>) and the involvement of monkey PFC in the congruity effect in experiment 2 (<bold><xref rid="fig4" ref-type="fig">Figure 4B</xref></bold>). Many anatomical differences have been reported between humans and monkeys using MRI as well as histological methods. In particular, the human brain is exceptionally large (<xref ref-type="bibr" rid="c42">Herculano-Houzel, 2012</xref>), and contains a number of structural differences compared to the brains of other primates (<xref ref-type="bibr" rid="c7">Chaplin et al., 2013</xref>; <xref ref-type="bibr" rid="c56">Leroy et al., 2015</xref>;</p>
<p><xref ref-type="bibr" rid="c75">Neubert et al., 2014</xref>; <xref ref-type="bibr" rid="c82">Palomero-Gallagher and Zilles, 2019</xref>; <xref ref-type="bibr" rid="c94">Rilling, 2014</xref>; <xref ref-type="bibr" rid="c99">Schenker et al., 2010</xref>; <xref ref-type="bibr" rid="c110">Takemura et al., 2017</xref>). Notably, while the human arcuate fasciculus provides a strong direct connection between inferior prefrontal and temporal areas involved in language processing, this bundle is reduced and does not extend as anteriorly and as ventrally in other primates, including chimpanzees (<xref ref-type="bibr" rid="c3">Balezeau et al., 2020</xref>; <xref ref-type="bibr" rid="c19">Eichert et al., 2020</xref>; <xref ref-type="bibr" rid="c95">Rilling et al., 2012</xref>, <xref ref-type="bibr" rid="c96">2008</xref>; <xref ref-type="bibr" rid="c112">Thiebaut de Schotten et al., 2012</xref>). Also, the PFC is selectively increased in terms of tissue volume (<xref ref-type="bibr" rid="c7">Chaplin et al., 2013</xref>; <xref ref-type="bibr" rid="c17">Donahue et al., 2018</xref>; <xref ref-type="bibr" rid="c44">Hill et al., 2010</xref>; <xref ref-type="bibr" rid="c106">Smaers et al., 2017</xref>). While this may not translate to a selective increase in terms of the number of PFC neurons (<xref ref-type="bibr" rid="c35">Gabi et al., 2016</xref>), dendritic arborizations and synaptic density are larger in human PFC (<xref ref-type="bibr" rid="c21">Elston, 2007</xref>; <xref ref-type="bibr" rid="c43">Hilgetag and Goulas, 2020</xref>; <xref ref-type="bibr" rid="c103">Shibata et al., 2021</xref>). These anatomical differences may underlie the fundamental differences in language learning abilities between these species, but this is still controversial (<xref ref-type="bibr" rid="c45">Hopkins et al., 2012</xref>; <xref ref-type="bibr" rid="c48">Iriki, 2006</xref>). Here, we show that reversibility of associations, a crucial element in the ability to attach symbols to objects and concepts, sharply differs between human and non-human primates and offers a more tractable way to investigate potential differences between species.</p>
<p>The areas that specifically activated in humans when the reversed association was violated were not limited to the classical language network in the left hemisphere. They extended bilaterally to homolog areas of the right hemisphere, which are involved for instance in the acquisition of musical languages (<xref ref-type="bibr" rid="c83">Patel, 2010</xref>). They also extend dorsally to the middle frontal gyrus and intraparietal sulcus which are involved in the acquisition of the language of numbers, geometry and higher mathematics (<xref ref-type="bibr" rid="c2">Amalric and Dehaene, 2016</xref>; <xref ref-type="bibr" rid="c90">Piazza, 2010</xref>; <xref ref-type="bibr" rid="c117">Wang et al., 2019</xref>). Finally, an ROI analysis shows that they also include the VWFA and vicinity. The VWFA is known to be sensitive to letters, but also to other visual symbols such as a new learned face-like script (<xref ref-type="bibr" rid="c72">Moore et al., 2014</xref>) or emblematic pictures of famous cities (e.g. the Eiffel tower for Paris; <xref ref-type="bibr" rid="c107">Song et al., 2012</xref>), and the nearby lateral inferotemporal cortex responds to Arabic numerals and other mathematical symbols (<xref ref-type="bibr" rid="c2">Amalric and Dehaene, 2016</xref>; <xref ref-type="bibr" rid="c104">Shum et al., 2013</xref>). Strikingly, these extended areas, shown in <bold><xref rid="fig2" ref-type="fig">Figure 2</xref></bold>, correspond to regions whose cortical expansion and connectivity patterns are maximally different in humans compared to other primates (<xref ref-type="bibr" rid="c7">Chaplin et al., 2013</xref>; <xref ref-type="bibr" rid="c17">Donahue et al., 2018</xref>; <xref ref-type="bibr" rid="c44">Hill et al., 2010</xref>; <xref ref-type="bibr" rid="c106">Smaers et al., 2017</xref>). They also fit with a previous fMRI comparison of humans and macaque monkeys, where humans were shown to exhibit uniquely abstract and integrative representations of numerical and sequence patterns in these regions (<xref ref-type="bibr" rid="c118">Wang et al., 2015</xref>).</p>
<p>In all of these studies, the observed changes are bilateral, extended, and go beyond the language network per se. Such an extended network does not fit with the hypothesis that a single localized system, such as natural language or a universal generative faculty, is the primary engine of all human-specific abstract symbolic abilities (<xref ref-type="bibr" rid="c40">Hauser and Watumull, 2017</xref>; <xref ref-type="bibr" rid="c108">Spelke, 2003</xref>). Rather, our results suggest that multiple parallel and partially dissociable human brain networks possess symbolic abilities and deploy them in different domains such as natural language, music and mathematics (<xref ref-type="bibr" rid="c1">Amalric and Dehaene, 2017</xref>; <xref ref-type="bibr" rid="c9">Chen et al., 2021</xref>; <xref ref-type="bibr" rid="c12">Dehaene et al., 2022</xref>; <xref ref-type="bibr" rid="c23">Fedorenko et al., 2011</xref>; <xref ref-type="bibr" rid="c25">Fedorenko and Varley, 2016</xref>).</p>
<p>The neurobiological mechanism that enables reversible symbol learning in humans remain to be discovered. Interestingly, most learning rules, such as spike-time-dependent plasticity, are sensitive to temporal order and timing, a feature of fundamental importance for predictive coding. In contrast, as indicated by the behavioral results of experiment 2, humans seem to forget the temporal order in which pairs of stimuli are presented when they store them at a symbolic level. This has been interpreted as improper causal reasoning (<xref ref-type="bibr" rid="c80">Ogawa et al., 2010</xref>). Indeed, if A repeatedly precedes B, then perceiving A predict the appearance of B; but if B is observed, concluding to the likely presence of A is a logical fallacy. Still, brain mechanisms for temporal reversal do exist in the literature. The most prominent candidate, in both humans and non-human animals, is hippocampal-dependent neuronal replay of sequences of events, which can occur in both forward and reverse temporal order (<xref ref-type="bibr" rid="c31">Foster, 2017</xref>; <xref ref-type="bibr" rid="c58">Liu et al., 2019</xref>). Sequence reversal may be important during learning, in order to trace back to a memorized event that led to a reward. In line with this, a retroactive gradient has been shown in memory storage in humans, where memory is strongest for stimuli that were presented close to the reward but preceding it (<xref ref-type="bibr" rid="c5">Braun et al., 2018</xref>). This memory trace may explain the slight facilitation observed in baboons when they learn reversed congruent pairs relative to reversed incongruent pairs (Chartier et al, 2022). Although neuronal replay in both forward and reverse directions exists in non-human animals, it might be that this mechanism has selectively expanded to symbol-related areas of the human brain – a clear hypothesis for future work.</p>
<p>Obviously, even humans do not always disregard temporal order for all associations between stimulus pairs – for instance, they remember letters of the alphabet in a fixed temporal order (<xref ref-type="bibr" rid="c54">Klahr et al., 1983</xref>). Thus, future work should also clarify which conditions promote reversible symbolic learning. Here, the pairs comprised one fixed and abstract element (either linguistic or graphical), which served as a label, paired with several different views of a concrete object. In human infants, the association of a label with the presentation of objects helps them construct the object category, as revealed by several experiments in which infants discriminate between categories (<xref ref-type="bibr" rid="c29">Ferry et al., 2013</xref>), or correctly process the number of objects (<xref ref-type="bibr" rid="c124">Xu et al., 2005</xref>) when the categories and objects are named, but not in the absence of a label. Interestingly, preverbal infants are flexible and accept pictures as labels for a rule (Kabdebon et al, 2019), as well as monkey vocalizations and tones as labels for an animal category (<xref ref-type="bibr" rid="c28">Ferguson and Waxman, 2016</xref>; <xref ref-type="bibr" rid="c29">Ferry et al., 2013</xref>), whereas older infants who have been exposed to many social situations in which language is the primary symbolic medium to transfer information, expect symbolic labels to be in the native language (<xref ref-type="bibr" rid="c87">Perszyk and Waxman, 2019</xref>). Later, they recover flexibility suggesting that this transient limitation might be a contextual strategy due to the pivotal role of language in naming at this time of life.</p>
<p>While our results suggest a dramatic difference in the way human and non-human primates encode associations between sensory stimuli, several limitations of the present work should be kept in mind. First, due to ethical and financial reasons we only tested 4 monkeys, while we tested 55 humans in total. While it is common in primate physiological studies to report the results for 2 animals, this makes it challenging to extrapolate the results to a species of animals (<xref ref-type="bibr" rid="c33">Fries and Maris, 2022</xref>). To address this point, we combined the results from two different labs, collecting data from 2 animals in each lab. A second limitation is that we only tested macaque monkeys; non-human primates closer to humans, such as chimpanzees, might yield different conclusions, and chimpanzee Ai’s failure of reversibility (<xref ref-type="bibr" rid="c55">Kojima, 1984</xref>), although striking, may not be representative. Similarly, reversible symbolic learning should be evaluated in vocal learners such as songbirds and parrots, as some demonstrate sophisticated flexible label learning (see e.g. <xref ref-type="bibr" rid="c86">Pepperberg and Carey, 2012</xref>). Furthermore, in dogs, social interactions between the dog and the experimenter during learning facilitate associations (<xref ref-type="bibr" rid="c34">Fugazza et al., 2021</xref>), as it is also the case in infants. Social cues were absent in our design, and whether they would favor a switch to a symbolic system might be interesting to explore. Finally, we only tested adult monkeys, yet there might be a critical period during which reversible symbolic representation might be possible with appropriate training procedures; indeed, juvenile macaques learn better and faster to associate an arbitrary label with visual quantities than adults (<xref ref-type="bibr" rid="c109">Srihasam et al., 2012</xref>). The present work provides a simple experimental paradigm that can easily be extended to all these cases, thus offering a unique opportunity to test whether humans are unique in their ability to acquire symbols.</p>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Participants</title>
<p>We tested four adult rhesus macaques (male, 6-8 kg, 5-19 years of age). YS and JD participated in experiment 1 and JD, JC and DN in experiment 2. All procedures were conducted in accordance with the European convention for animal care (86-406) and the NIH’s guide for the care and use of laboratory animals. They were approved by the Institutional Ethical Committee (CETEA protocol # 16-043) and by the ethical committee for animal research of the KU Leuven. Animal housing and handling were according to the recommendations of the Weatherall report, allowing extensive locomotor behavior, social interactions, and foraging. All animals were group-housed (cage size at least 16-32 m3) with diverse cage enrichment (auditory and visual stimuli, toys, foraging devices etc.).</p>
<p>We also tested 55 healthy human subjects with no known neurological or psychiatric pathology (Exp. 1, n=31; Exp2., n=24; in experiment 2, an additional 3 subjects were not included because they showed no evidence of learning the canonical pairs). Human subjects gave written informed consent to participate in this study, which was approved by the French national Ethics Committee.</p>
</sec>
<sec id="s4b">
<title>Stimuli</title>
<p>Five sets of images were used (<bold><xref rid="figS1" ref-type="fig">Supplementary Figure 1</xref></bold>). The two first sets were 3D renderings of objects differing in their visual properties and semantic categories. As they might be considered as more familiar to humans, the other three sets of objects were photographs of monkey toys which the monkeys were exposed to in their home cages for at least 2 weeks prior to the training blocks. They were mostly geometrical 3D objects with no evident and consistent name for naive human participants. The rendering and photos were taken from 8 different viewpoints. These stimuli were used in both experiments and are called “object” thereafter.</p>
<p>A label was associated to each object in each set. For experiment 1, the labels were auditory French pseudo- words with large differences in the number and identity of their syllables within each set (e.g. “tøj<sup>ɑ°</sup>”, “ɡliʃu”,”byɲyɲy”, “kʁɛfila”). Note that monkeys were daily exposed to French radio and television as well as to French-speaking animal caretakers. or experiment 2, the labels were abstract black-and-white shapes, difficult to name and similar to the lexigrams used to train chimpanzees to communicate with humans (<xref ref-type="bibr" rid="c67">Matsuzawa, 1985</xref>) .</p>
</sec>
<sec id="s4c">
<title>Experimental paradigm</title>
<sec id="s4c1">
<title>Stimulus presentation</title>
<p>Each set to be learned comprised 4 pairs. Two pairs were presented in the label- object direction (L1-O1 &amp; L3-O3), and two in the object-label direction (O2-L2 &amp; O4-L4). Labels were speech sounds in experiment 1, and black-and-white shapes in experiment 2. In each trial, the first stimulus (label or object) was presented during 700ms, followed by an inter-stimulus-interval of 100ms then the second stimulus during 700ms. The pairs were separated by a variable inter-trial-interval of 3-5 seconds. The visual stimuli were ∼8 degrees in diameter, centered on the screen, with an average luminance set equal to the background. At each trial, the orientation of the object was randomly chosen among the 8 possibilities. A cross was present at the center of the screen when no visual stimulus was present. Auditory stimuli were presented to both ears at 80dB.</p>
</sec>
<sec id="s4c2">
<title>Training</title>
<p>The experiment was designed to be also tested in 3-month-old human infants (Ekramnia et al, in preparation), which explains our choice of short training sessions over 3 consecutive days because of the short attention span in infants and the reported benefit of sleep for encoding word meaning after a learning session (<xref ref-type="bibr" rid="c32">Friedrich et al., 2017</xref>). Therefore, training consisted of three short videos presenting 24 trials as described above (one video for each of the 3 training days). Two pairs (one in each direction) were introduced on the first day of training (e.g., L1-O1 and O2-L2). First, one pair was shown for 6 trials, then the other pair for 6 trials, then the two pairs were randomly presented for 6 trials each. On the second day of training, the two other pairs (L3-O3 and O4-L4) were presented using the same procedure than on day 1. On the third day, all pairs were randomly presented (6 presentations each). The object-label pairing was constant but the direction of presentation (O-L or L-O) and the introduction of the pair on the first or second day was counterbalanced across participants.</p>
</sec>
<sec id="s4c3">
<title>Human protocol</title>
<p>n experiment 1, the participants came to the lab to watch the first video, and on the next two consecutive days they received a web link on which the two videos were uploaded for each day. For experiment 2, all 3 videos were sent via a web link. The participants were only instructed to look attentively at each movie (24 trials, ∼3 min long) one time on a given day. The participants came for the fMRI session on the fourth day. Each participant saw only one set of objects-labels, either stimulus set 2 or stimulus set 3, distributed equally across participants.</p>
<p>In experiment 2, we added a behavioral test at the end of the MRI session to check their learning. They were shown all 16 possible trial pairs (incongruent and congruent in canonical and non-canonical order), plus 16 never seen, one by one. For each of them, they were asked to rate how frequently they had seen them (on a 5-level scale ranging from never to rarely, sometimes, often and always). The results were analyzed using a 5-level ANOVA which included the canonicity X congruity 2x2 design. A computer crash erased responses from two participants and one subject did not participate leaving 21 subjects for this analysis.</p>
</sec>
<sec id="s4c4">
<title>Monkey protocol</title>
<p>Monkeys were implanted with an MR-compatible headpost under general anesthesia. The animals were first habituated to remain calm in a chair inside a mock MRI setup, and trained to fixate a small dot (0.25 degrees) within a virtual window of 1.25-2 degrees diameter (<xref ref-type="bibr" rid="c113">Uhrig et al., 2014</xref>). Then similar to the human participants, they received 1 training block per day for 3 consecutive days (24 trials per block) for each stimulus set. Rewards were given at regular intervals, asynchronous with the visual and auditory stimulus presentation. On the fourth day, they were scanned while being presented with the test blocks for the corresponding stimulus set. All monkeys were trained and tested with all of the stimulus sets.</p>
<p>For experiment 1, after the first imaging session at day 4 which did not show learning (no difference between congruent and incongruent pairs in the canonical direction), monkeys were further trained for an additional 2 weeks (∼80 blocks), and then scanned each day during 4 days. Then a new set of four object- label pairs was presented with the same training and testing design. So, training and testing took 3 consecutive weeks for each of the five stimulus sets.</p>
<p>In experiment 2, a reward was introduced to promote monkeys’ engagement in the task. The amount of reward that the monkeys received after successfully fixating throughout the pair presentation was either increased or decreased for a duration of 1450ms (starting 100ms after the offset of the second stimulus), depending on the identity of the visual object. The amount of reward remained the same, but the time in between consecutive rewards was set either twice as short (for high rewards) or twice as long (for low rewards). For each direction, one visual object was associated with a high reward while the other one was associated with a low reward (see <bold><xref rid="figS2" ref-type="fig">Supplementary Figure 2</xref></bold>). By design, the two pairs that were averaged for each of the critical tested dimension (direction, congruity and canonicity of the pair) had opposite reward size, making reward size an orthogonal design element. The first stimulus set was used for procedural training on this reward association paradigm for 2 weeks. Stimulus sets 2-5 were used for training as in experiment 1 (with 1 block per day for 3 consecutive days) and an fMRI test session on the fourth day.</p>
</sec>
<sec id="s4c5">
<title>Test in MRI</title>
<p>The MRI session comprised 4 test blocks in humans and between 12 and 32 blocks in monkeys. In both humans and monkeys, each block started with 4 trials in the learned direction (congruent canonical trials), one trial for each of the 4 pairs (2 O-L and 2 L-O pairs). The rest of the block consisted of 40 trials in which 70% of trials were identical to the training; 10% were incongruent pairs but the direction (O-L or L-O) was correct (incongruent canonical trials), thus testing whether the association was learned; 10% were congruent pairs but the direction within the pairs was reversed relative to the learned pairs (congruent reversed trials) and 10% were incongruent pairs in reverse (incongruent reversed trials). As the percentage of congruent and incongruent pairs was the same in the reversed direction, a difference can only be due to a generalization from the canonical direction. For incongruent trials, the incongruent stimulus always came from the pair presented in the same direction (see <xref rid="fig1" ref-type="fig">figure 1</xref>), in order to avoid that a change of position within the pair itself (1st or 2nd stimulus) induced the perception of an incongruity.</p>
<p>Human participants were only instructed to keep their eyes fixed on the fixation point and pay attention to the stimuli. The monkeys were rewarded for keeping their eyes fixed on the fixation point, as in the training. In Experiment 1, the reward was constant, whereas in Experiment 2, they received the differential reward that was implemented during training.</p>
</sec>
</sec>
<sec id="s4d">
<title>Data acquisition</title>
<p>For experiment 1, both humans and monkeys were scanned with the 3T Siemens Prisma at NeuroSpin using a T2*-weighted gradient echo-planar imaging (EPI) sequence, using a 64-channel head coil for humans and a customized eight-channel phased-array surface coil (KU Leuven, Belgium) for monkeys. The imaging parameters were the following: in humans, resolution: 1.75mm isotropic, TR: 1.81s, TE: 30.4ms, PF: 7/8, MB3, slices: 69; in monkeys, resolution: 1.5mm isotropic, TR: 1.08s, TE: 13.8ms, PF: 6/8, iPAT2, slices: 34.</p>
<p>Monkeys were trained to sit in a sphinx position in a primate chair with their head fixed. MION (monocrystalline iron oxide nanoparticle, Molday Ion, BioPAL, Worchester MA) contrast agent (10 mg/kg, i.v.) was injected to monkeys before scanning (<xref ref-type="bibr" rid="c114">Vanduffel et al., 2001</xref>). Eye movements were monitored and recorded by an eye tracking system (EyeLink 1000, SR Research, Ottawa, Canada). In total, we recorded 583 valid runs, 278 for YS and 305 for JD.</p>
<p>For Experiment 2, the settings remained the same for the humans and for one of the monkeys (JD). Two new monkeys (JC and DN) were included at the Laboratory of Neuro- and Psychophysiology of KU Leuven and scanned with a 3T Siemens Prisma using a T2*-weighted gradient echo-planar imaging (EPI) sequence. For JC, an external 8-channel coil was used and the imaging parameters were the following: resolution: 1.25mm isotropic, TR: 0.9s, T7: 15ms, PF: 6/8, iPAT3, multi-band 2, slices: 52. For DN, an implanted 8- channel coil was used and the imaging parameters were the following: resolution: 1.25mm isotropic, TR: 0.9s, TE: 15ms, PF: 6/8, iPAT3, multi-band 2, slices: 40. Monkeys were trained to sit in a sphinx position in a primate chair with their head fixed, and MION was again injected to before scanning (11 mg/kg, i.v.). Eye movements were monitored and recorded by an eye tracking system (ETL200, ISCAN inc., Woburn, MA, USA). The animals were also required to keep their hands in a box in front of the chair (as verified with optical sensors), which limited body motion. In total, we recorded 279 valid runs, 81 for JD, 106 for JC and 92 for DN.</p>
</sec>
<sec id="s4e">
<title>Preprocessing of monkey fMRI data</title>
<p>Functional images were reoriented, realigned, resampled (1.00 mm isotropic) and coregistered to the anatomical template of the monkey Montreal Neurologic Institute (Montreal, Canada) space using Pypreclin, a custom-made scripts of Python programming language (<xref ref-type="bibr" rid="c111">Tasserie et al., 2020</xref>).</p>
<p>Eye-data was inspected for each run for quality. Only runs with more than 85% fixation (virtual window of 2-2.5 degrees diameter) were included for further analyses (n=16 excluded in experiment 1 and n=14 excluded in experiment 2). Moreover, a trial was excluded if the eyes were closed for more than 650ms (out of 700) while an image was present on the screen. In experiment 1, the top 5% of runs were motion was strongest across monkeys were excluded (n=30) because there remained significant residual motion. In total, for experiment 1, 395 runs remained to be analyzed, 184 for YS and 211 for JD. For experiment 2, 268 runs remained, 77 for JD, 107 for JC and 84 for DN.</p>
</sec>
<sec id="s4f">
<title>Preprocessing of human fMRI data</title>
<p>SPM12 (<ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm">http://www.fil.ion.ucl.ac.uk/spm</ext-link>) was used for preprocessing of human data as well as first and second level models. Preprocessing consisted of standard preprocessing pipeline, including slice-time correction, realign, top-up correction, segmentation, normalization to standard MNI space and smoothing with a 4-mm isotropic Gaussian.</p>
</sec>
<sec id="s4g">
<title>First and second-level analyses</title>
<p>After imaging preprocessing, active brain regions were identified by performing voxel-wise GLM analyses implemented in SPM12 in both monkeys and humans. For the first experiment, in a first-level SPM model, the twelve predictors included: (1-4) the onsets of the first stimulus of the pair (4 regressors consisting in the combinations of audio/visual and canonical/non-canonical factors), and (5-12) the onsets of the second stimulus (8 regressors consisting in the combinations of audio/visual, canonical/non-canonical and congruent/incongruent factors). These twelve events were modeled as delta functions convolved with the canonical hemodynamic response function (for MION in case of monkeys). Parameters of head motion derived from realignment were also included in the model as covariates of no interest. Contrast images for the effect of congruity (incongruent-congruent canonical and incongruent - congruent non-canonical) as well as the interaction (congruity x canonicity) were computed. For the second experiment, the analysis was the same, except that given the two elements of the pair were in the same visual modality, only a single predictor was used for each stimulus pair, giving 4 predictors: the onsets of the second stimulus of the pair, with congruent/incongruent and canonical/non-canonical as the two factors. For the monkeys, an additional factor was whether the pair was associated with a high or a low reward, giving 8 predictors. In this case, the temporal derivative of the hemodynamic response function was added to the model as well. Before entering the second-level analysis, the data was smoothed again, using a 5mm smoothing kernel in humans and 2 mm in monkeys.</p>
<p>For the second-level group analysis, subjects were taken as the statistical unit for the humans and runs were taken as statistical units for the monkeys. One-sample t-tests were performed on the contrast images to test for the effect of the condition. Results are reported at an uncorrected voxelwise threshold of p&lt;0.001 and a cluster p&lt;0.05 corrected for multiple comparisons (FDR).</p>
</sec>
<sec id="s4h">
<title>ROI analyses</title>
<p>In a separate localizer, human participants listened and read short sentences. In some of the sentences, the participants were asked to compute easy mathematical operations (math sentences). Subtracting activations to math and non-math sentences allowed to separate the regions more involved in mathematical cognition than in general sentence comprehension and reciprocally. We selected seven left-hemispheric regions previously reported as showing a language-related activation (<xref ref-type="bibr" rid="c81">Pallier et al., 2011</xref>), 6 bilateral ROIs showing mathematically-related activations (<xref ref-type="bibr" rid="c2">Amalric &amp; Dehaene, 2016</xref>) and finally a 10-radius sphere around the VWFA [-45 -57 -12]. In these ROIs, we recovered the coordinates of each participant’s 10% best voxels in the comparisons: sentences vs rest for the 6 language Rois plus reading vs listening for the VWFA, and numerical vs non-numerical sentences for the 8 mathematical ROIs. We extracted the beta of these voxels and performed ANOVAs with Congruity and Canonicity as within-subject factors and experiment as between-subjects factor. “ Two participants in experiment 1 and one in experiment 2 had no localizer, leaving 52 participants (n=29 and n= 23) for these analyses. P-values were FDR corrected considering all 15 ROIs in each comparison.</p>
</sec>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Amalric</surname> <given-names>M</given-names></string-name>, <string-name><surname>Dehaene</surname> <given-names>S</given-names></string-name>. <year>2017</year>. <article-title>Cortical circuits for mathematical knowledge: evidence for a major subdivision within the brain’s semantic networks</article-title>. <source>Philos Trans R Soc Lond, B, Biol Sci</source> <volume>373</volume>. doi:<pub-id pub-id-type="doi">10.1098/rstb.2016.0515</pub-id></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Amalric</surname> <given-names>M</given-names></string-name>, <string-name><surname>Dehaene</surname> <given-names>S</given-names></string-name>. <year>2016</year>. <article-title>Origins of the brain networks for advanced mathematics in expert mathematicians</article-title>. <source>ProcNatlAcadSciUSA</source> <volume>113</volume>:<fpage>4909</fpage>–<lpage>4917</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Balezeau</surname> <given-names>F</given-names></string-name>, <string-name><surname>Wilson</surname> <given-names>B</given-names></string-name>, <string-name><surname>Gallardo</surname> <given-names>G</given-names></string-name>, <string-name><surname>Dick</surname> <given-names>F</given-names></string-name>, <string-name><surname>Hopkins</surname> <given-names>W</given-names></string-name>, <string-name><surname>Anwander</surname> <given-names>A</given-names></string-name>, <string-name><surname>Friederici</surname> <given-names>AD</given-names></string-name>, <string-name><surname>Griffiths</surname> <given-names>TD</given-names></string-name>, <string-name><surname>Petkov</surname> <given-names>CI</given-names></string-name>. <year>2020</year>. <article-title>Primate auditory prototype in the evolution of the arcuate fasciculus</article-title>. <source>Nat Neurosci</source> <volume>23</volume>:<fpage>611</fpage>–<lpage>614</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41593-020-0623-9</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="book"><string-name><surname>Berwick</surname> <given-names>RC</given-names></string-name>, <string-name><surname>Chomsky</surname> <given-names>N</given-names></string-name>. <year>2016</year>. <source>Why Only Us: Language and Evolution</source>. <publisher-name>The MIT Press</publisher-name>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Braun</surname> <given-names>EK</given-names></string-name>, <string-name><surname>Wimmer</surname> <given-names>GE</given-names></string-name>, <string-name><surname>Shohamy</surname> <given-names>D</given-names></string-name>. <year>2018</year>. <article-title>Retroactive and graded prioritization of memory by reward</article-title>. <source>Nat Commun</source> <volume>9</volume>:<fpage>4886</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41467-018-07280-0</pub-id></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Caspari</surname> <given-names>N</given-names></string-name>, <string-name><surname>Arsenault</surname> <given-names>JT</given-names></string-name>, <string-name><surname>Vandenberghe</surname> <given-names>R</given-names></string-name>, <string-name><surname>Vanduffel</surname> <given-names>W</given-names></string-name>. <year>2018</year>. <article-title>Functional Similarity of Medial Superior Parietal Areas for Shift-Selective Attention Signals in Humans and Monkeys</article-title>. <source>Cerebral Cortex</source> <volume>28</volume>:<fpage>2085</fpage>–<lpage>2099</lpage>. doi:<pub-id pub-id-type="doi">10.1093/cercor/bhx114</pub-id></mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Chaplin</surname> <given-names>TA</given-names></string-name>, <string-name><surname>Yu</surname> <given-names>H-H</given-names></string-name>, <string-name><surname>Soares</surname> <given-names>JGM</given-names></string-name>, <string-name><surname>Gattass</surname> <given-names>R</given-names></string-name>, <string-name><surname>Rosa</surname> <given-names>MGP</given-names></string-name>. <year>2013</year>. <article-title>A Conserved Pattern of Differential Expansion of Cortical Areas in Simian Primates</article-title>. <source>Journal of Neuroscience</source> <volume>33</volume>:<fpage>15120</fpage>–<lpage>15125</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2909-13.2013</pub-id></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Chartier</surname> <given-names>TF</given-names></string-name>, <string-name><surname>Fagot</surname> <given-names>J</given-names></string-name>. <year>2022</year>. <article-title>Simultaneous learning of directional and non-directional stimulus relations in baboons (Papio papio)</article-title>. <source>Learn Behav</source>. doi:<pub-id pub-id-type="doi">10.3758/s13420-022-00522-8</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="other"><string-name><surname>Chen</surname> <given-names>X</given-names></string-name>, <string-name><surname>Affourtit</surname> <given-names>J</given-names></string-name>, <string-name><surname>Ryskin</surname> <given-names>R</given-names></string-name>, <string-name><surname>Regev</surname> <given-names>TI</given-names></string-name>, <string-name><surname>Norman-Haignere</surname> <given-names>S</given-names></string-name>, <string-name><surname>Jouravlev</surname> <given-names>O</given-names></string-name>, <string-name><surname>Malik-Moraleda</surname> <given-names>S</given-names></string-name>, <string-name><surname>Kean</surname> <given-names>H</given-names></string-name>, <string-name><surname>Varley</surname> <given-names>R</given-names></string-name>, <string-name><surname>Fedorenko</surname> <given-names>E</given-names></string-name>. <year>2021</year>. <article-title>The human language system does not support music processing</article-title>. doi:<pub-id pub-id-type="doi">10.1101/2021.06.01.446439</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>De Valois</surname> <given-names>RL</given-names></string-name>, <string-name><surname>Morgan</surname> <given-names>H</given-names></string-name>, <string-name><surname>Snodderly</surname> <given-names>DM.</given-names></string-name> <year>1974</year>. <article-title>Psychophysical studies of monkey Vision-III. Spatial luminance contrast sensitivity tests of macaque and human observers</article-title>. <source>Vision Research</source> <volume>14</volume>:<fpage>75</fpage>–<lpage>81</lpage>. doi:<pub-id pub-id-type="doi">10.1016/0042-6989(74)90118-7</pub-id></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="book"><string-name><surname>Deacon</surname> <given-names>TW</given-names></string-name>. <year>1998</year>. <chapter-title>The Symbolic Species – The Co–evolution of Language &amp; the Brain</chapter-title>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>W. W. Norton &amp; Company</publisher-name>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Dehaene</surname> <given-names>S</given-names></string-name>, <string-name><surname>Al Roumi</surname> <given-names>F</given-names></string-name>, <string-name><surname>Lakretz</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Planton</surname> <given-names>S</given-names></string-name>, <string-name><surname>Sablé-Meyer</surname> <given-names>M.</given-names></string-name> <year>2022</year>. <article-title>Symbols and mental programs: a hypothesis about human singularity</article-title>. <source>Trends in Cognitive Sciences</source> <volume>26</volume>:<fpage>751</fpage>–<lpage>766</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.tics.2022.06.010</pub-id></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>Dehaene</surname> <given-names>S</given-names></string-name>, <string-name><surname>Meyniel</surname> <given-names>F</given-names></string-name>, <string-name><surname>Wacongne</surname> <given-names>C</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>L</given-names></string-name>, <string-name><surname>Pallier</surname> <given-names>C</given-names></string-name>. <year>2015</year>. <article-title>The Neural Representation of Sequences: From Transition Probabilities to Algebraic Patterns and Linguistic Trees</article-title>. <source>Neuron</source> <volume>88</volume>:<fpage>2</fpage>–<lpage>19</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.019</pub-id></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Denys</surname> <given-names>K</given-names></string-name>, <string-name><surname>Vanduffel</surname> <given-names>W</given-names></string-name>, <string-name><surname>Fize</surname> <given-names>D</given-names></string-name>, <string-name><surname>Nelissen</surname> <given-names>K</given-names></string-name>, <string-name><surname>Peuskens</surname> <given-names>H</given-names></string-name>, <string-name><surname>van</surname> <given-names>ED</given-names></string-name>, <string-name><surname>Orban</surname> <given-names>GA</given-names></string-name>. <year>2004a</year>. <article-title>The processing of visual shape in the cerebral cortex of human and nonhuman primates: a functional magnetic resonance imaging study</article-title>. <source>JNeurosci</source> <volume>24</volume>:<fpage>2551</fpage>–<lpage>2565</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Denys</surname> <given-names>K</given-names></string-name>, <string-name><surname>Vanduffel</surname> <given-names>W</given-names></string-name>, <string-name><surname>Fize</surname> <given-names>D</given-names></string-name>, <string-name><surname>Nelissen</surname> <given-names>K</given-names></string-name>, <string-name><surname>Sawamura</surname> <given-names>H</given-names></string-name>, <string-name><surname>Georgieva</surname> <given-names>S</given-names></string-name>, <string-name><surname>Vogels</surname> <given-names>R</given-names></string-name>, <string-name><surname>van</surname> <given-names>ED</given-names></string-name>, <string-name><surname>Orban</surname> <given-names>GA</given-names></string-name>. <year>2004b</year>. <article-title>Visual activation in prefrontal cortex is stronger in monkeys than in humans</article-title>. <source>JCogn Neurosci</source> <volume>16</volume>:<fpage>1505</fpage>–<lpage>1516</lpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Diester</surname> <given-names>I</given-names></string-name>, <string-name><surname>Nieder</surname> <given-names>A</given-names></string-name>. <year>2007</year>. <article-title>Semantic associations between signs and numerical categories in the prefrontal cortex</article-title>. <source>PLoS Biol</source> <volume>5</volume>:<fpage>e294</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pbio.0050294</pub-id></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Donahue</surname> <given-names>CJ</given-names></string-name>, <string-name><surname>Glasser</surname> <given-names>MF</given-names></string-name>, <string-name><surname>Preuss</surname> <given-names>TM</given-names></string-name>, <string-name><surname>Rilling</surname> <given-names>JK</given-names></string-name>, <string-name><surname>Essen</surname> <given-names>DCV</given-names></string-name>. <year>2018</year>. <article-title>Quantitative assessment of prefrontal cortex in humans relative to nonhuman primates</article-title>. <source>PNAS</source> <volume>115</volume>:<fpage>E5183</fpage>–<lpage>E5192</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1721653115</pub-id></mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Duncan</surname> <given-names>J</given-names></string-name>. <year>2010</year>. <article-title>The multiple-demand (MD) system of the primate brain: mental programs for intelligent behaviour</article-title>. <source>Trends in Cognitive Sciences</source> <volume>14</volume>:<fpage>172</fpage>–<lpage>179</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.tics.2010.01.004</pub-id></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Eichert</surname> <given-names>N</given-names></string-name>, <string-name><surname>Robinson</surname> <given-names>EC</given-names></string-name>, <string-name><surname>Bryant</surname> <given-names>KL</given-names></string-name>, <string-name><surname>Jbabdi</surname> <given-names>S</given-names></string-name>, <string-name><surname>Jenkinson</surname> <given-names>M</given-names></string-name>, <string-name><surname>Li</surname> <given-names>L</given-names></string-name>, <string-name><surname>Krug</surname> <given-names>K</given-names></string-name>, <string-name><surname>Watkins</surname> <given-names>KE</given-names></string-name>, <string-name><surname>Mars</surname> <given-names>RB</given-names></string-name>. <year>2020</year>. <article-title>Cross-species cortical alignment identifies different types of anatomical reorganization in the primate temporal lobe</article-title>. <source>eLife</source> <volume>9</volume>:<fpage>e53232</fpage>. doi:<pub-id pub-id-type="doi">10.7554/eLife.53232</pub-id></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="other"><string-name><surname>Ekramnia</surname> <given-names>M</given-names></string-name>, <string-name><surname>Dehaene-Lambertz</surname> <given-names>G.</given-names></string-name> <year>2019</year>. <article-title>Investigating bidirectionality of associations in young infants as an approach to the symbolic system</article-title>. <source>Presented at the CogSci.</source> p. <fpage>3449</fpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="book"><string-name><surname>Elston</surname> <given-names>GN</given-names></string-name>. <year>2007</year>. <chapter-title>4.13 - Specialization of the Neocortical Pyramidal Cell during Primate Evolution</chapter-title> In: <person-group person-group-type="editor"><string-name><surname>Kaas</surname> <given-names>JH</given-names></string-name></person-group>, editor. <source>Evolution of Nervous Systems</source>. <publisher-loc>Oxford</publisher-loc>: <publisher-name>Academic Press</publisher-name>. pp. <fpage>191</fpage>–<lpage>242</lpage>. doi:<pub-id pub-id-type="doi">10.1016/B0-12-370878-8/00164-6</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Erb</surname> <given-names>J</given-names></string-name>, <string-name><surname>Armendariz</surname> <given-names>M</given-names></string-name>, <string-name><surname>De Martino</surname> <given-names>F</given-names></string-name>, <string-name><surname>Goebel</surname> <given-names>R</given-names></string-name>, <string-name><surname>Vanduffel</surname> <given-names>W</given-names></string-name>, <string-name><surname>Formisano</surname> <given-names>E.</given-names></string-name> <year>2019</year>. <article-title>Homology and Specificity of Natural Sound-Encoding in Human and Monkey Auditory Cortex</article-title>. <source>Cerebral Cortex</source> <volume>29</volume>:<fpage>3636</fpage>–<lpage>3650</lpage>. doi:<pub-id pub-id-type="doi">10.1093/cercor/bhy243</pub-id></mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Fedorenko</surname> <given-names>E</given-names></string-name>, <string-name><surname>Behr</surname> <given-names>MK</given-names></string-name>, <string-name><surname>Kanwisher</surname> <given-names>N</given-names></string-name>. <year>2011</year>. <article-title>Functional specificity for high-level linguistic processing in the human brain</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>108</volume>:<fpage>16428</fpage>–<lpage>33</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1112937108</pub-id></mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Fedorenko</surname> <given-names>E</given-names></string-name>, <string-name><surname>Duncan</surname> <given-names>J</given-names></string-name>, <string-name><surname>Kanwisher</surname> <given-names>N</given-names></string-name>. <year>2013</year>. <article-title>Broad domain generality in focal regions of frontal and parietal cortex</article-title>. <source>Proc Natl Acad Sci USA</source> <volume>110</volume>:<fpage>16616</fpage>–<lpage>16621</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1315235110</pub-id></mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Fedorenko</surname> <given-names>E</given-names></string-name>, <string-name><surname>Varley</surname> <given-names>R</given-names></string-name>. <year>2016</year>. <article-title>Language and thought are not the same thing: evidence from neuroimaging and neurological patients</article-title>. <source>Ann N Y Acad Sci</source> <volume>1369</volume>:<fpage>132</fpage>–<lpage>153</lpage>. doi:<pub-id pub-id-type="doi">10.1111/nyas.13046</pub-id></mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>Felleman</surname> <given-names>DJ</given-names></string-name>, <string-name><surname>Van Essen</surname> <given-names>DC.</given-names></string-name> <year>1991</year>. <article-title>Distributed hierarchical processing in the primate cerebral cortex</article-title>. <source>CerebCortex</source> <volume>1</volume>:<fpage>1</fpage>–<lpage>47</lpage>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>Feng</surname> <given-names>G</given-names></string-name>, <string-name><surname>Jensen</surname> <given-names>FE</given-names></string-name>, <string-name><surname>Greely</surname> <given-names>HT</given-names></string-name>, <string-name><surname>Okano</surname> <given-names>H</given-names></string-name>, <string-name><surname>Treue</surname> <given-names>S</given-names></string-name>, <string-name><surname>Roberts</surname> <given-names>AC</given-names></string-name>, <string-name><surname>Fox</surname> <given-names>JG</given-names></string-name>, <string-name><surname>Caddick</surname> <given-names>S</given-names></string-name>, <string-name><surname>Poo</surname> <given-names>M</given-names></string-name>, <string-name><surname>Newsome</surname> <given-names>WT</given-names></string-name>, <string-name><surname>Morrison</surname> <given-names>JH</given-names></string-name>. <year>2020</year>. <article-title>Opportunities and limitations of genetically modified nonhuman primate models for neuroscience research</article-title>. <source>PNAS</source> <volume>117</volume>:<fpage>24022</fpage>–<lpage>24031</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.2006515117</pub-id></mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><string-name><surname>Ferguson</surname> <given-names>B</given-names></string-name>, <string-name><surname>Waxman</surname> <given-names>SR</given-names></string-name>. <year>2016</year>. <article-title>What the [beep]? Six-month-olds link novel communicative signals to meaning</article-title>. <source>Cognition</source> <volume>146</volume>:<fpage>185</fpage>–<lpage>9</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cognition.2015.09.020</pub-id></mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><string-name><surname>Ferry</surname> <given-names>AL</given-names></string-name>, <string-name><surname>Hespos</surname> <given-names>SJ</given-names></string-name>, <string-name><surname>Waxman</surname> <given-names>SR</given-names></string-name>. <year>2013</year>. <article-title>Nonhuman primate vocalizations support categorization in very young human infants</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>110</volume>:<fpage>15231</fpage>–<lpage>5</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1221166110</pub-id></mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>Fitch</surname> <given-names>WT</given-names></string-name>, <string-name><surname>Hauser</surname> <given-names>MD</given-names></string-name>, <string-name><surname>Chomsky</surname> <given-names>N</given-names></string-name>. <year>2005</year>. <article-title>The evolution of the language faculty: clarifications and implications</article-title>. <source>Cognition</source> <volume>97</volume>:<fpage>179</fpage>–<lpage>210</lpage>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>Foster</surname> <given-names>DJ</given-names></string-name>. <year>2017</year>. <article-title>Replay Comes of Age</article-title>. <source>Annual Review of Neuroscience</source> <volume>40</volume>:<fpage>581</fpage>–<lpage>602</lpage>. doi:<pub-id pub-id-type="doi">10.1146/annurev-neuro-072116-031538</pub-id></mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><string-name><surname>Friedrich</surname> <given-names>M</given-names></string-name>, <string-name><surname>Wilhelm</surname> <given-names>I</given-names></string-name>, <string-name><surname>Molle</surname> <given-names>M</given-names></string-name>, <string-name><surname>Born</surname> <given-names>J</given-names></string-name>, <string-name><surname>Friederici</surname> <given-names>AD</given-names></string-name>. <year>2017</year>. <article-title>The Sleeping Infant Brain Anticipates Development</article-title>. <source>Curr Biol</source> <volume>27</volume>:<fpage>2374</fpage>–<lpage>2380</lpage> e3. doi:<pub-id pub-id-type="doi">10.1016/j.cub.2017.06.070</pub-id></mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><string-name><surname>Fries</surname> <given-names>P</given-names></string-name>, <string-name><surname>Maris</surname> <given-names>E</given-names></string-name>. <year>2022</year>. <article-title>What to Do If N Is Two?</article-title> <source>Journal of Cognitive Neuroscience</source> <volume>34</volume>:<fpage>1114</fpage>–<lpage>1118</lpage>. doi:<pub-id pub-id-type="doi">10.1162/jocn_a_01857</pub-id></mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Fugazza</surname> <given-names>C</given-names></string-name>, <string-name><surname>Andics</surname> <given-names>A</given-names></string-name>, <string-name><surname>Magyari</surname> <given-names>L</given-names></string-name>, <string-name><surname>Dror</surname> <given-names>S</given-names></string-name>, <string-name><surname>Zempléni</surname> <given-names>A</given-names></string-name>, <string-name><surname>Miklósi</surname> <given-names>Á</given-names></string-name>. <year>2021</year>. <article-title>Rapid learning of object names in dogs</article-title>. <source>Sci Rep</source> <volume>11</volume>:<fpage>2222</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41598-021-81699-2</pub-id></mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>Gabi</surname> <given-names>M</given-names></string-name>, <string-name><surname>Neves</surname> <given-names>K</given-names></string-name>, <string-name><surname>Masseron</surname> <given-names>C</given-names></string-name>, <string-name><surname>Ribeiro</surname> <given-names>PFM</given-names></string-name>, <string-name><surname>Ventura-Antunes</surname> <given-names>L</given-names></string-name>, <string-name><surname>Torres</surname> <given-names>L</given-names></string-name>, <string-name><surname>Mota</surname> <given-names>B</given-names></string-name>, <string-name><surname>Kaas</surname> <given-names>JH</given-names></string-name>, <string-name><surname>Herculano- Houzel</surname> <given-names>S</given-names></string-name>. <year>2016</year>. <article-title>No relative expansion of the number of prefrontal neurons in primate and human evolution</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>113</volume>:<fpage>9617</fpage>–<lpage>9622</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1610178113</pub-id></mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><string-name><surname>Ghazizadeh</surname> <given-names>A</given-names></string-name>, <string-name><surname>Griggs</surname> <given-names>W</given-names></string-name>, <string-name><surname>Leopold</surname> <given-names>DA</given-names></string-name>, <string-name><surname>Hikosaka</surname> <given-names>O</given-names></string-name>. <year>2018</year>. <article-title>Temporal–prefrontal cortical network for discrimination of valuable objects in long-term memory</article-title>. <source>PNAS</source> <volume>115</volume>:<fpage>E2135</fpage>–<lpage>E2144</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1707695115</pub-id></mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><string-name><surname>Hackett</surname> <given-names>TA</given-names></string-name>, <string-name><surname>Preuss</surname> <given-names>TM</given-names></string-name>, <string-name><surname>Kaas</surname> <given-names>JH</given-names></string-name>. <year>2001</year>. <article-title>Architectonic identification of the core region in auditory cortex of macaques, chimpanzees, and humans</article-title>. <source>J Comp Neurol</source> <volume>441</volume>:<fpage>197</fpage>–<lpage>222</lpage>. doi:<pub-id pub-id-type="doi">10.1002/cne.1407</pub-id></mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><string-name><surname>Harwerth</surname> <given-names>RS</given-names></string-name>, <string-name><surname>Smith</surname> <given-names>EL</given-names></string-name>. <year>1985</year>. <article-title>Rhesus monkey as a model for normal vision of humans</article-title>. <source>Am J Optom Physiol Opt</source> <volume>62</volume>:<fpage>633</fpage>–<lpage>641</lpage>. doi:<pub-id pub-id-type="doi">10.1097/00006324-198509000-00009</pub-id></mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><string-name><surname>Hauser</surname> <given-names>MD</given-names></string-name>, <string-name><surname>Chomsky</surname> <given-names>N</given-names></string-name>, <string-name><surname>Fitch</surname> <given-names>WT</given-names></string-name>. <year>2002</year>. <article-title>The faculty of language: what is it, who has it, and how did it evolve?</article-title> <source>Science</source> <volume>298</volume>:<fpage>1569</fpage>–<lpage>1579</lpage>.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><string-name><surname>Hauser</surname> <given-names>MD</given-names></string-name>, <string-name><surname>Watumull</surname> <given-names>J</given-names></string-name>. <year>2017</year>. <article-title>The Universal Generative Faculty: The source of our expressive power in language, mathematics, morality, and music</article-title>. <source>Journal of Neurolinguistics</source>. doi:<pub-id pub-id-type="doi">10.1016/j.jneuroling.2016.10.005</pub-id></mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><string-name><surname>Henshilwood</surname> <given-names>CS</given-names></string-name>, <string-name><surname>d’Errico</surname> <given-names>F</given-names></string-name>, <string-name><surname>Yates</surname> <given-names>R</given-names></string-name>, <string-name><surname>Jacobs</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Tribolo</surname> <given-names>C</given-names></string-name>, <string-name><surname>Duller</surname> <given-names>GAT</given-names></string-name>, <string-name><surname>Mercier</surname> <given-names>N</given-names></string-name>, <string-name><surname>Sealy</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Valladas</surname> <given-names>H</given-names></string-name>, <string-name><surname>Watts</surname> <given-names>I</given-names></string-name>, <string-name><surname>Wintle</surname> <given-names>AG.</given-names></string-name> <year>2002</year>. <article-title>Emergence of Modern Human Behavior: Middle Stone Age Engravings from South Africa</article-title>. <source>Science</source> <volume>295</volume>:<fpage>1278</fpage>–<lpage>1280</lpage>. doi:<pub-id pub-id-type="doi">10.1126/science.1067575</pub-id></mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><string-name><surname>Herculano-Houzel</surname> <given-names>S</given-names></string-name>. <year>2012</year>. <article-title>The remarkable, yet not extraordinary, human brain as a scaled-up primate brain and its associated cost</article-title>. <source>PNAS</source> <volume>109</volume>:<fpage>10661</fpage>–<lpage>10668</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1201895109</pub-id></mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><string-name><surname>Hilgetag</surname> <given-names>CC</given-names></string-name>, <string-name><surname>Goulas</surname> <given-names>A</given-names></string-name>. <year>2020</year>. <article-title>‘Hierarchy’ in the organization of brain networks</article-title>. <source>Philosophical Transactions of the Royal Society B: Biological Sciences</source> <volume>375</volume>:<fpage>20190319</fpage>. doi:<pub-id pub-id-type="doi">10.1098/rstb.2019.0319</pub-id></mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><string-name><surname>Hill</surname> <given-names>J</given-names></string-name>, <string-name><surname>Inder</surname> <given-names>T</given-names></string-name>, <string-name><surname>Neil</surname> <given-names>J</given-names></string-name>, <string-name><surname>Dierker</surname> <given-names>D</given-names></string-name>, <string-name><surname>Harwell</surname> <given-names>J</given-names></string-name>, <string-name><surname>Van Essen</surname> <given-names>D.</given-names></string-name> <year>2010</year>. <article-title>Similar patterns of cortical expansion during human development and evolution</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>107</volume>:<fpage>13135</fpage>–<lpage>13140</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1001229107</pub-id></mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><string-name><surname>Hopkins</surname> <given-names>WD</given-names></string-name>, <string-name><surname>Russell</surname> <given-names>JL</given-names></string-name>, <string-name><surname>Schaeffer</surname> <given-names>JA</given-names></string-name>. <year>2012</year>. <article-title>The neural and cognitive correlates of aimed throwing in chimpanzees: a magnetic resonance image and behavioural study on a unique form of social tool use</article-title>. <source>Philos Trans R Soc Lond B Biol Sci</source> <volume>367</volume>:<fpage>37</fpage>–<lpage>47</lpage>. doi:<pub-id pub-id-type="doi">10.1098/rstb.2011.0195</pub-id></mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><string-name><surname>Howard</surname> <given-names>SR</given-names></string-name>, <string-name><surname>Avarguès-Weber</surname> <given-names>A</given-names></string-name>, <string-name><surname>Garcia</surname> <given-names>JE</given-names></string-name>, <string-name><surname>Greentree</surname> <given-names>AD</given-names></string-name>, <string-name><surname>Dyer</surname> <given-names>AG</given-names></string-name>. <year>2019</year>. <article-title>Symbolic representation of numerosity by honeybees (Apis mellifera): matching characters to small quantities</article-title>. <source>Proceedings of the Royal Society B: Biological Sciences</source> <volume>286</volume>:<fpage>20190238</fpage>. doi:<pub-id pub-id-type="doi">10.1098/rspb.2019.0238</pub-id></mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><string-name><surname>Imai</surname> <given-names>M</given-names></string-name>, <string-name><surname>Murai</surname> <given-names>C</given-names></string-name>, <string-name><surname>Miyazaki</surname> <given-names>M</given-names></string-name>, <string-name><surname>Okada</surname> <given-names>H</given-names></string-name>, <string-name><surname>Tomonaga</surname> <given-names>M</given-names></string-name>. <year>2021</year>. <article-title>The contingency symmetry bias (affirming the consequent fallacy) as a prerequisite for word learning: A comparative study of pre-linguistic human infants and chimpanzees</article-title>. <source>Cognition</source> <volume>214</volume>:<fpage>104755</fpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cognition.2021.104755</pub-id></mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><string-name><surname>Iriki</surname> <given-names>A</given-names></string-name>. <year>2006</year>. <article-title>The neural origins and implications of imitation, mirror neurons and tool use. <italic>Current Opinion in Neurobiology</italic></article-title>, <source>Motor systems / Neurobiology of behaviour</source> <volume>16</volume>:<fpage>660</fpage>–<lpage>667</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.conb.2006.10.008</pub-id></mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><string-name><surname>Kabdebon</surname> <given-names>C</given-names></string-name>, <string-name><surname>Dehaene-Lambertz</surname> <given-names>G</given-names></string-name>. <year>2019</year>. <article-title>Symbolic labeling in 5-month-old human infants</article-title>. <source>PNAS</source> <volume>116</volume>:<fpage>5805</fpage>–<lpage>5810</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1809144116</pub-id></mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><string-name><surname>Kaminski</surname> <given-names>J</given-names></string-name>, <string-name><surname>Call</surname> <given-names>J</given-names></string-name>, <string-name><surname>Fischer</surname> <given-names>J</given-names></string-name>. <year>2004</year>. <article-title>Word learning in a domestic dog: evidence for “fast mapping.”</article-title> <source>Science</source> <volume>304</volume>:<fpage>1682</fpage>–<lpage>3</lpage>. doi:<pub-id pub-id-type="doi">10.1126/science.1097859</pub-id></mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><string-name><surname>Kaposvari</surname> <given-names>P</given-names></string-name>, <string-name><surname>Kumar</surname> <given-names>S</given-names></string-name>, <string-name><surname>Vogels</surname> <given-names>R</given-names></string-name>. <year>2018</year>. <article-title>Statistical Learning Signals in Macaque Inferior Temporal Cortex</article-title>. <source>Cereb Cortex</source> <volume>28</volume>:<fpage>250</fpage>–<lpage>266</lpage>. doi:<pub-id pub-id-type="doi">10.1093/cercor/bhw374</pub-id></mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><string-name><surname>Kastak</surname> <given-names>CR</given-names></string-name>, <string-name><surname>Schusterman</surname> <given-names>RJ</given-names></string-name>, <string-name><surname>Kastak</surname> <given-names>D</given-names></string-name>. <year>2001</year>. <article-title>Equivalence classification by California sea lions using class- specific reinforcers</article-title>. <source>J Exp Anal Behav</source> <volume>76</volume>:<fpage>131</fpage>–<lpage>158</lpage>. doi:<pub-id pub-id-type="doi">10.1901/jeab.2001.76-131</pub-id></mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="book"><string-name><surname>Kietzmann</surname> <given-names>C</given-names></string-name>. <year>2019</year>. <chapter-title>Aristotle on the Definition of What It Is to Be Human</chapter-title> In: <person-group person-group-type="editor"><string-name><surname>Keil</surname> <given-names>G</given-names></string-name>, <string-name><surname>Kreft</surname> <given-names>N</given-names></string-name></person-group>, editors. <source>Aristotle’s Anthropology</source>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>. pp. <fpage>25</fpage>–<lpage>43</lpage>. doi:<pub-id pub-id-type="doi">10.1017/9781108131643.002</pub-id></mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><string-name><surname>Klahr</surname> <given-names>D</given-names></string-name>, <string-name><surname>Chase</surname> <given-names>WG</given-names></string-name>, <string-name><surname>Lovelace</surname> <given-names>EA</given-names></string-name>. <year>1983</year>. <article-title>Structure and process in alphabetic retrieval</article-title>. <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source> <volume>9</volume>:<fpage>462</fpage>–<lpage>477</lpage>. doi:<pub-id pub-id-type="doi">10.1037/0278-7393.9.3.462</pub-id></mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><string-name><surname>Kojima</surname> <given-names>T</given-names></string-name>. <year>1984</year>. <article-title>Generalization between productive use and receptive discrimination of names in an artificial visual language by a chimpanzee</article-title>. <source>Int J Primatol</source> <volume>5</volume>:<fpage>161</fpage>–<lpage>182</lpage>. doi:<pub-id pub-id-type="doi">10.1007/BF02735739</pub-id></mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><string-name><surname>Leroy</surname> <given-names>F</given-names></string-name>, <string-name><surname>Cai</surname> <given-names>Q</given-names></string-name>, <string-name><surname>Bogart</surname> <given-names>SL</given-names></string-name>, <string-name><surname>Dubois</surname> <given-names>J</given-names></string-name>, <string-name><surname>Coulon</surname> <given-names>O</given-names></string-name>, <string-name><surname>Monzalvo</surname> <given-names>K</given-names></string-name>, <string-name><surname>Fischer</surname> <given-names>C</given-names></string-name>, <string-name><surname>Glasel</surname> <given-names>H</given-names></string-name>, <string-name><surname>Van der Haegen</surname> <given-names>L</given-names></string-name>, <string-name><surname>Bénézit</surname> <given-names>A</given-names></string-name>, <string-name><surname>Lin</surname> <given-names>C-P</given-names></string-name>, <string-name><surname>Kennedy</surname> <given-names>DN</given-names></string-name>, <string-name><surname>Ihara</surname> <given-names>AS</given-names></string-name>, <string-name><surname>Hertz-Pannier</surname> <given-names>L</given-names></string-name>, <string-name><surname>Moutard</surname> <given-names>M-L</given-names></string-name>, <string-name><surname>Poupon</surname> <given-names>C</given-names></string-name>, <string-name><surname>Brysbaert</surname> <given-names>M</given-names></string-name>, <string-name><surname>Roberts</surname> <given-names>N</given-names></string-name>, <string-name><surname>Hopkins</surname> <given-names>WD</given-names></string-name>, <string-name><surname>Mangin</surname> <given-names>J-F</given-names></string-name>, <string-name><surname>Dehaene-Lambertz</surname> <given-names>G.</given-names></string-name> <year>2015</year>. <article-title>New human-specific brain landmark: The depth asymmetry of superior temporal sulcus</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>112</volume>:<fpage>1208</fpage>–<lpage>1213</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1412389112</pub-id></mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><string-name><surname>Lipkens</surname> <given-names>R</given-names></string-name>, <string-name><surname>Kop</surname> <given-names>PFM</given-names></string-name>, <string-name><surname>Matthijs</surname> <given-names>W</given-names></string-name>. <year>1988</year>. <article-title>A test of symmetry and transitivity in the conditional discrimination performances of pigeons</article-title>. <source>J Exp Anal Behav</source> <volume>49</volume>:<fpage>395</fpage>–<lpage>409</lpage>. doi:<pub-id pub-id-type="doi">10.1901/jeab.1988.49-395</pub-id></mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><string-name><surname>Liu</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Dolan</surname> <given-names>RJ</given-names></string-name>, <string-name><surname>Kurth-Nelson</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Behrens</surname> <given-names>TEJ</given-names></string-name>. <year>2019</year>. <article-title>Human Replay Spontaneously Reorganizes Experience</article-title>. <source>Cell</source> <volume>178</volume>:<fpage>640</fpage>–<lpage>652</lpage>.e14. doi:<pub-id pub-id-type="doi">10.1016/j.cell.2019.06.012</pub-id></mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><string-name><surname>Livingstone</surname> <given-names>MS</given-names></string-name>, <string-name><surname>Pettine</surname> <given-names>WW</given-names></string-name>, <string-name><surname>Srihasam</surname> <given-names>K</given-names></string-name>, <string-name><surname>Moore</surname> <given-names>B</given-names></string-name>, <string-name><surname>Morocz</surname> <given-names>IA</given-names></string-name>, <string-name><surname>Lee</surname> <given-names>D</given-names></string-name>. <year>2014</year>. <article-title>Symbol addition by monkeys provides evidence for normalized quantity coding</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>111</volume>:<fpage>6822</fpage>– <lpage>7</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1404208111</pub-id></mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><string-name><surname>Livingstone</surname> <given-names>MS</given-names></string-name>, <string-name><surname>Srihasam</surname> <given-names>K</given-names></string-name>, <string-name><surname>Morocz</surname> <given-names>IA</given-names></string-name>. <year>2010</year>. <article-title>The benefit of symbols: monkeys show linear, human- like, accuracy when using symbols to represent scalar value</article-title>. <source>Anim Cogn</source> <volume>13</volume>:<fpage>711</fpage>–<lpage>9</lpage>. doi:<pub-id pub-id-type="doi">10.1007/s10071-010-0321-1</pub-id></mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><string-name><surname>Mantini</surname> <given-names>D</given-names></string-name>, <string-name><surname>Corbetta</surname> <given-names>M</given-names></string-name>, <string-name><surname>Romani</surname> <given-names>GL</given-names></string-name>, <string-name><surname>Orban</surname> <given-names>GA</given-names></string-name>, <string-name><surname>Vanduffel</surname> <given-names>W</given-names></string-name>. <year>2013</year>. <article-title>Evolutionarily novel functional networks in the human brain?</article-title> <source>JNeurosci</source> <volume>33</volume>:<fpage>3259</fpage>–<lpage>3275</lpage>.</mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><string-name><surname>Mantini</surname> <given-names>D</given-names></string-name>, <string-name><surname>Corbetta</surname> <given-names>M</given-names></string-name>, <string-name><surname>Romani</surname> <given-names>GL</given-names></string-name>, <string-name><surname>Orban</surname> <given-names>GA</given-names></string-name>, <string-name><surname>Vanduffel</surname> <given-names>W</given-names></string-name>. <year>2012</year>. <article-title>Data-driven analysis of analogous brain networks in monkeys and humans during natural vision</article-title>. <source>NeuroImage</source> <volume>63</volume>:<fpage>1107</fpage>–<lpage>1118</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.08.042</pub-id></mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><string-name><surname>Mantini</surname> <given-names>D</given-names></string-name>, <string-name><surname>Gerits</surname> <given-names>A</given-names></string-name>, <string-name><surname>Nelissen</surname> <given-names>K</given-names></string-name>, <string-name><surname>Durand</surname> <given-names>J-B</given-names></string-name>, <string-name><surname>Joly</surname> <given-names>O</given-names></string-name>, <string-name><surname>Simone</surname> <given-names>L</given-names></string-name>, <string-name><surname>Sawamura</surname> <given-names>H</given-names></string-name>, <string-name><surname>Wardak</surname> <given-names>C</given-names></string-name>, <string-name><surname>Orban</surname> <given-names>GA</given-names></string-name>, <string-name><surname>Buckner</surname> <given-names>RL</given-names></string-name>, <string-name><surname>Vanduffel</surname> <given-names>W</given-names></string-name>. <year>2011</year>. <article-title>Default mode of brain function in monkeys</article-title>. <source>J Neurosci</source> <volume>31</volume>:<fpage>12954</fpage>–<lpage>12962</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.2318-11.2011</pub-id></mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><string-name><surname>Mantini</surname> <given-names>D.</given-names></string-name>, <string-name><surname>Hasson</surname> <given-names>U</given-names></string-name>, <string-name><surname>Betti</surname> <given-names>V</given-names></string-name>, <string-name><surname>Perrucci</surname> <given-names>MG</given-names></string-name>, <string-name><surname>Romani</surname> <given-names>GL</given-names></string-name>, <string-name><surname>Corbetta</surname> <given-names>M</given-names></string-name>, <string-name><surname>Orban</surname> <given-names>GA</given-names></string-name>, <string-name><surname>Vanduffel</surname> <given-names>W</given-names></string-name>. <year>2012</year>. <article-title>Interspecies activity correlations reveal functional correspondence between monkey and human brain areas</article-title>. <source>NatMethods</source> <volume>9</volume>:<fpage>277</fpage>–<lpage>282</lpage>.</mixed-citation></ref>
<ref id="c65"><mixed-citation publication-type="journal"><string-name><surname>Margulies</surname> <given-names>DS</given-names></string-name>, <string-name><surname>Ghosh</surname> <given-names>SS</given-names></string-name>, <string-name><surname>Goulas</surname> <given-names>A</given-names></string-name>, <string-name><surname>Falkiewicz</surname> <given-names>M</given-names></string-name>, <string-name><surname>Huntenburg</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Langs</surname> <given-names>G</given-names></string-name>, <string-name><surname>Bezgin</surname> <given-names>G</given-names></string-name>, <string-name><surname>Eickhoff</surname> <given-names>SB</given-names></string-name>, <string-name><surname>Castellanos</surname> <given-names>FX</given-names></string-name>, <string-name><surname>Petrides</surname> <given-names>M</given-names></string-name>, <string-name><surname>Jefferies</surname> <given-names>E</given-names></string-name>, <string-name><surname>Smallwood</surname> <given-names>J</given-names></string-name>. <year>2016</year>. <article-title>Situating the default-mode network along a principal gradient of macroscale cortical organization</article-title>. <source>PNAS</source> <volume>113</volume>:<fpage>12574</fpage>–<lpage>12579</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1608282113</pub-id></mixed-citation></ref>
<ref id="c66"><mixed-citation publication-type="journal"><string-name><surname>Matsuzawa</surname> <given-names>T</given-names></string-name>. <year>2009</year>. <article-title>Symbolic representation of number in chimpanzees</article-title>. <source>Curr Opin Neurobiol</source> <volume>19</volume>:<fpage>92</fpage>–<lpage>8</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.conb.2009.04.007</pub-id></mixed-citation></ref>
<ref id="c67"><mixed-citation publication-type="journal"><string-name><surname>Matsuzawa</surname> <given-names>T</given-names></string-name>. <year>1985</year>. <article-title>Use of numbers by a chimpanzee</article-title>. <source>Nature</source> <volume>315</volume>:<fpage>57</fpage>–<lpage>59</lpage>. doi:<pub-id pub-id-type="doi">10.1038/315057a0</pub-id></mixed-citation></ref>
<ref id="c68"><mixed-citation publication-type="journal"><string-name><surname>Medam</surname> <given-names>T</given-names></string-name>, <string-name><surname>Marzouki</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Montant</surname> <given-names>M</given-names></string-name>, <string-name><surname>Fagot</surname> <given-names>J</given-names></string-name>. <year>2016</year>. <article-title>Categorization does not promote symmetry in Guinea baboons (Papio papio)</article-title>. <source>Anim Cogn</source> <volume>19</volume>:<fpage>987</fpage>–<lpage>998</lpage>. doi:<pub-id pub-id-type="doi">10.1007/s10071-016-1003-4</pub-id></mixed-citation></ref>
<ref id="c69"><mixed-citation publication-type="journal"><string-name><surname>Mersad</surname> <given-names>K</given-names></string-name>, <string-name><surname>Kabdebon</surname> <given-names>C</given-names></string-name>, <string-name><surname>Dehaene-Lambertz</surname> <given-names>G</given-names></string-name>. <year>2021</year>. <article-title>Explicit access to phonetic representations in 3- month-old infants. <italic>Cognition</italic>, Special Issue in Honour of Jacques Mehler</article-title>, <source>Cognition’s founding editor</source> <volume>213</volume>:<fpage>104613</fpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cognition.2021.104613</pub-id></mixed-citation></ref>
<ref id="c70"><mixed-citation publication-type="journal"><string-name><surname>Meyer</surname> <given-names>T</given-names></string-name>, <string-name><surname>Olson</surname> <given-names>CR</given-names></string-name>. <year>2011</year>. <article-title>Statistical learning of visual transitions in monkey inferotemporal cortex</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>108</volume>:<fpage>19401</fpage>–<lpage>19406</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1112895108</pub-id></mixed-citation></ref>
<ref id="c71"><mixed-citation publication-type="journal"><string-name><surname>Meyer</surname> <given-names>T</given-names></string-name>, <string-name><surname>Ramachandran</surname> <given-names>S</given-names></string-name>, <string-name><surname>Olson</surname> <given-names>CR</given-names></string-name>. <year>2014</year>. <article-title>Statistical Learning of Serial Visual Transitions by Neurons in Monkey Inferotemporal Cortex</article-title>. <source>J Neurosci</source> <volume>34</volume>:<fpage>9332</fpage>–<lpage>9337</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.1215-14.2014</pub-id></mixed-citation></ref>
<ref id="c72"><mixed-citation publication-type="journal"><string-name><surname>Moore</surname> <given-names>MW</given-names></string-name>, <string-name><surname>Durisko</surname> <given-names>C</given-names></string-name>, <string-name><surname>Perfetti</surname> <given-names>CA</given-names></string-name>, <string-name><surname>Fiez</surname> <given-names>JA</given-names></string-name>. <year>2014</year>. <article-title>Learning to Read an Alphabet of Human Faces Produces Left-lateralized Training Effects in the Fusiform Gyrus</article-title>. <source>J Cogn Neurosci</source> <volume>26</volume>:<fpage>896</fpage>–<lpage>913</lpage>. doi:<pub-id pub-id-type="doi">10.1162/jocn_a_00506</pub-id></mixed-citation></ref>
<ref id="c73"><mixed-citation publication-type="journal"><string-name><surname>Murayama</surname> <given-names>T</given-names></string-name>, <string-name><surname>Suzuki</surname> <given-names>R</given-names></string-name>, <string-name><surname>Kondo</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Koshikawa</surname> <given-names>M</given-names></string-name>, <string-name><surname>Katsumata</surname> <given-names>H</given-names></string-name>, <string-name><surname>Arai</surname> <given-names>K</given-names></string-name>. <year>2017</year>. <article-title>Spontaneous establishing of cross-modal stimulus equivalence in a beluga whale</article-title>. <source>Sci Rep</source> <volume>7</volume>:<fpage>9914</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41598-017-09925-4</pub-id></mixed-citation></ref>
<ref id="c74"><mixed-citation publication-type="journal"><string-name><surname>Neubauer</surname> <given-names>S</given-names></string-name>, <string-name><surname>Hublin</surname> <given-names>JJ</given-names></string-name>, <string-name><surname>Gunz</surname> <given-names>P</given-names></string-name>. <year>2018</year>. <article-title>The evolution of modern human brain shape</article-title>. <source>Sci Adv</source> <volume>4</volume>:<fpage>eaao5961</fpage>. doi:<pub-id pub-id-type="doi">10.1126/sciadv.aao5961</pub-id></mixed-citation></ref>
<ref id="c75"><mixed-citation publication-type="journal"><string-name><surname>Neubert</surname> <given-names>F-X</given-names></string-name>, <string-name><surname>Mars</surname> <given-names>RB</given-names></string-name>, <string-name><surname>Thomas</surname> <given-names>AG</given-names></string-name>, <string-name><surname>Sallet</surname> <given-names>J</given-names></string-name>, <string-name><surname>Rushworth</surname> <given-names>MFS</given-names></string-name>. <year>2014</year>. <article-title>Comparison of human ventral frontal cortex areas for cognitive control and language with areas in monkey frontal cortex</article-title>. <source>Neuron</source> <volume>81</volume>:<fpage>700</fpage>–<lpage>713</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2013.11.012</pub-id></mixed-citation></ref>
<ref id="c76"><mixed-citation publication-type="journal"><string-name><surname>Newsome</surname> <given-names>WT</given-names></string-name>, <string-name><surname>Stein-Aviles</surname> <given-names>JA</given-names></string-name>. <year>1999</year>. <article-title>Nonhuman Primate Models of Visually Based Cognition</article-title>. <source>ILAR Journal</source> <volume>40</volume>:<fpage>78</fpage>–<lpage>91</lpage>. doi:<pub-id pub-id-type="doi">10.1093/ilar.40.2.78</pub-id></mixed-citation></ref>
<ref id="c77"><mixed-citation publication-type="book"><string-name><surname>Nieder</surname> <given-names>A</given-names></string-name>. <year>2019</year>. <chapter-title>A Brain for Numbers: The Biology of the Number Instinct</chapter-title>. <publisher-name>The MIT Press</publisher-name>.</mixed-citation></ref>
<ref id="c78"><mixed-citation publication-type="journal"><string-name><surname>Nieder</surname> <given-names>A</given-names></string-name>. <year>2009</year>. <article-title>Prefrontal cortex and the evolution of symbolic reference</article-title>. <source>CurrOpinNeurobiol</source> <volume>19</volume>:<fpage>99</fpage>–<lpage>108</lpage>.</mixed-citation></ref>
<ref id="c79"><mixed-citation publication-type="journal"><string-name><surname>Norman-Haignere</surname> <given-names>S</given-names></string-name>, <string-name><surname>Kanwisher</surname> <given-names>NG</given-names></string-name>, <string-name><surname>McDermott</surname> <given-names>JH</given-names></string-name>. <year>2015</year>. <article-title>Distinct Cortical Pathways for Music and Speech Revealed by Hypothesis-Free Voxel Decomposition</article-title>. <source>Neuron</source> <volume>88</volume>:<fpage>1281</fpage>–<lpage>1296</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.035</pub-id></mixed-citation></ref>
<ref id="c80"><mixed-citation publication-type="journal"><string-name><surname>Ogawa</surname> <given-names>A</given-names></string-name>, <string-name><surname>Yamazaki</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Ueno</surname> <given-names>K</given-names></string-name>, <string-name><surname>Cheng</surname> <given-names>K</given-names></string-name>, <string-name><surname>Iriki</surname> <given-names>A</given-names></string-name>. <year>2010</year>. <article-title>Neural correlates of species-typical illogical cognitive bias in human inference</article-title>. <source>J Cogn Neurosci</source> <volume>22</volume>:<fpage>2120</fpage>–<lpage>2130</lpage>. doi:<pub-id pub-id-type="doi">10.1162/jocn.2009.21330</pub-id></mixed-citation></ref>
<ref id="c81"><mixed-citation publication-type="journal"><string-name><surname>Pallier</surname> <given-names>C</given-names></string-name>, <string-name><surname>Devauchelle</surname> <given-names>A-D</given-names></string-name>, <string-name><surname>Dehaene</surname> <given-names>S</given-names></string-name>. <year>2011</year>. <article-title>Cortical representation of the constituent structure of sentences</article-title>. <source>PNAS</source> <volume>108</volume>:<fpage>2522</fpage>–<lpage>2527</lpage>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1018711108</pub-id></mixed-citation></ref>
<ref id="c82"><mixed-citation publication-type="journal"><string-name><surname>Palomero-Gallagher</surname> <given-names>N</given-names></string-name>, <string-name><surname>Zilles</surname> <given-names>K</given-names></string-name>. <year>2019</year>. <article-title>Differences in cytoarchitecture of Broca’s region between human, ape and macaque brains. <italic>Cortex</italic></article-title>, <source>The Evolution of the Mind and the Brain</source> <volume>118</volume>:<fpage>132</fpage>–<lpage>153</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cortex.2018.09.008</pub-id></mixed-citation></ref>
<ref id="c83"><mixed-citation publication-type="book"><string-name><surname>Patel</surname> <given-names>AD</given-names></string-name>. <year>2010</year>. <source>Music, Language, and the Brain</source>. <publisher-name>Oxford University Press</publisher-name>, <publisher-loc>USA</publisher-loc>.</mixed-citation></ref>
<ref id="c84"><mixed-citation publication-type="journal"><string-name><surname>Penn</surname> <given-names>DC</given-names></string-name>, <string-name><surname>Holyoak</surname> <given-names>KJ</given-names></string-name>, <string-name><surname>Povinelli</surname> <given-names>DJ</given-names></string-name>. <year>2008</year>. <article-title>Darwin’s mistake: explaining the discontinuity between human and nonhuman minds</article-title>. <source>Behav Brain Sci</source> <volume>31</volume>:<fpage>109</fpage>–<lpage>30</lpage>; discussion 130-178. doi:<pub-id pub-id-type="doi">10.1017/S0140525X08003543</pub-id></mixed-citation></ref>
<ref id="c85"><mixed-citation publication-type="book"><string-name><surname>Pepperberg</surname> <given-names>IM</given-names></string-name>. <year>2009</year>. <chapter-title>The Alex studies: cognitive and communicative abilities of grey parrots</chapter-title>. <publisher-name>Harvard University Press</publisher-name>.</mixed-citation></ref>
<ref id="c86"><mixed-citation publication-type="journal"><string-name><surname>Pepperberg</surname> <given-names>IM</given-names></string-name>, <string-name><surname>Carey</surname> <given-names>S</given-names></string-name>. <year>2012</year>. <article-title>Grey parrot number acquisition: the inference of cardinal value from ordinal position on the numeral list</article-title>. <source>Cognition</source> <volume>125</volume>:<fpage>219</fpage>–<lpage>232</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cognition.2012.07.003</pub-id></mixed-citation></ref>
<ref id="c87"><mixed-citation publication-type="journal"><string-name><surname>Perszyk</surname> <given-names>DR</given-names></string-name>, <string-name><surname>Waxman</surname> <given-names>SR</given-names></string-name>. <year>2019</year>. <article-title>Infants’ advances in speech perception shape their earliest links between language and cognition</article-title>. <source>Sci Rep</source> <volume>9</volume>:<fpage>3293</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41598-019-39511-9</pub-id></mixed-citation></ref>
<ref id="c88"><mixed-citation publication-type="journal"><string-name><surname>Petkov</surname> <given-names>CI</given-names></string-name>, <string-name><surname>Kayser</surname> <given-names>C</given-names></string-name>, <string-name><surname>Augath</surname> <given-names>M</given-names></string-name>, <string-name><surname>Logothetis</surname> <given-names>NK</given-names></string-name>. <year>2009</year>. <article-title>Optimizing the imaging of the monkey auditory cortex: sparse vs. continuous fMRI</article-title>. <source>Magn ResonImaging</source> <volume>27</volume>:<fpage>1065</fpage>–<lpage>1073</lpage>.</mixed-citation></ref>
<ref id="c89"><mixed-citation publication-type="journal"><string-name><surname>Petrides</surname> <given-names>M</given-names></string-name>, <string-name><surname>Tomaiuolo</surname> <given-names>F</given-names></string-name>, <string-name><surname>Yeterian</surname> <given-names>EH</given-names></string-name>, <string-name><surname>Pandya</surname> <given-names>DN</given-names></string-name>. <year>2012</year>. <article-title>The prefrontal cortex: comparative architectonic organization in the human and the macaque monkey brains</article-title>. <source>Cortex</source> <volume>48</volume>:<fpage>46</fpage>–<lpage>57</lpage>.</mixed-citation></ref>
<ref id="c90"><mixed-citation publication-type="journal"><string-name><surname>Piazza</surname> <given-names>M</given-names></string-name>. <year>2010</year>. <article-title>Neurocognitive start-up tools for symbolic number representations. <italic>Trends in Cognitive Sciences</italic>, Special Issue: Space</article-title>, <source>Time and Number</source> <volume>14</volume>:<fpage>542</fpage>–<lpage>551</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.tics.2010.09.008</pub-id></mixed-citation></ref>
<ref id="c91"><mixed-citation publication-type="journal"><string-name><surname>Pinel</surname> <given-names>P</given-names></string-name>, <string-name><surname>Thirion</surname> <given-names>B</given-names></string-name>, <string-name><surname>Meriaux</surname> <given-names>S</given-names></string-name>, <string-name><surname>Jobert</surname> <given-names>A</given-names></string-name>, <string-name><surname>Serres</surname> <given-names>J</given-names></string-name>, <string-name><surname>Le Bihan</surname> <given-names>D</given-names></string-name>, <string-name><surname>Poline</surname> <given-names>JB</given-names></string-name>, <string-name><surname>Dehaene</surname> <given-names>S.</given-names></string-name> <year>2007</year>. <article-title>Fast reproducible identification and large-scale databasing of individual functional cognitive networks</article-title>. <source>BMC neuroscience</source> <volume>8</volume>:<fpage>91</fpage>.</mixed-citation></ref>
<ref id="c92"><mixed-citation publication-type="journal"><string-name><surname>Premack</surname> <given-names>D</given-names></string-name>. <year>1971</year>. <article-title>Language in chimpanzee</article-title>. <source>Science</source> <volume>172</volume>:<fpage>808</fpage>–<lpage>822</lpage>.</mixed-citation></ref>
<ref id="c93"><mixed-citation publication-type="journal"><string-name><surname>Richter</surname> <given-names>D</given-names></string-name>, <string-name><surname>Ekman</surname> <given-names>M</given-names></string-name>, <string-name><surname>Lange</surname> <given-names>FP de</given-names></string-name>. <year>2018</year>. <article-title>Suppressed Sensory Response to Predictable Object Stimuli throughout the Ventral Visual Stream</article-title>. <source>J Neurosci</source> <volume>38</volume>:<fpage>7452</fpage>–<lpage>7461</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.3421-17.2018</pub-id></mixed-citation></ref>
<ref id="c94"><mixed-citation publication-type="journal"><string-name><surname>Rilling</surname> <given-names>JK</given-names></string-name>. <year>2014</year>. <article-title>Comparative primate neuroimaging: insights into human brain evolution</article-title>. <source>Trends in Cognitive Sciences</source> <volume>18</volume>:<fpage>46</fpage>–<lpage>55</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.tics.2013.09.013</pub-id></mixed-citation></ref>
<ref id="c95"><mixed-citation publication-type="journal"><string-name><surname>Rilling</surname> <given-names>JK</given-names></string-name>, <string-name><surname>Glasser</surname> <given-names>MF</given-names></string-name>, <string-name><surname>Jbabdi</surname> <given-names>S</given-names></string-name>, <string-name><surname>Andersson</surname> <given-names>J</given-names></string-name>, <string-name><surname>Preuss</surname> <given-names>TM</given-names></string-name>. <year>2012</year>. <article-title>Continuity, Divergence, and the Evolution of Brain Language Pathways</article-title>. <source>Front Evol Neurosci</source> <volume>3</volume>:<fpage>11</fpage>. doi:<pub-id pub-id-type="doi">10.3389/fnevo.2011.00011</pub-id></mixed-citation></ref>
<ref id="c96"><mixed-citation publication-type="journal"><string-name><surname>Rilling</surname> <given-names>JK</given-names></string-name>, <string-name><surname>Glasser</surname> <given-names>MF</given-names></string-name>, <string-name><surname>Preuss</surname> <given-names>TM</given-names></string-name>, <string-name><surname>Ma</surname> <given-names>X</given-names></string-name>, <string-name><surname>Zhao</surname> <given-names>T</given-names></string-name>, <string-name><surname>Hu</surname> <given-names>X</given-names></string-name>, <string-name><surname>Behrens</surname> <given-names>TEJ</given-names></string-name>. <year>2008</year>. <article-title>The evolution of the arcuate fasciculus revealed with comparative DTI</article-title>. <source>Nat Neurosci</source> <volume>11</volume>:<fpage>426</fpage>–<lpage>428</lpage>. doi:<pub-id pub-id-type="doi">10.1038/nn2072</pub-id></mixed-citation></ref>
<ref id="c97"><mixed-citation publication-type="journal"><string-name><surname>Roelfsema</surname> <given-names>PR</given-names></string-name>, <string-name><surname>Treue</surname> <given-names>S</given-names></string-name>. <year>2014</year>. <article-title>Basic neuroscience research with nonhuman primates: a small but indispensable component of biomedical research</article-title>. <source>Neuron</source> <volume>82</volume>:<fpage>1200</fpage>–<lpage>1204</lpage>.</mixed-citation></ref>
<ref id="c98"><mixed-citation publication-type="journal"><string-name><surname>Sablé-Meyer</surname> <given-names>M</given-names></string-name>, <string-name><surname>Fagot</surname> <given-names>J</given-names></string-name>, <string-name><surname>Caparos</surname> <given-names>S</given-names></string-name>, <string-name><surname>van Kerkoerle</surname> <given-names>T</given-names></string-name>, <string-name><surname>Amalric</surname> <given-names>M</given-names></string-name>, <string-name><surname>Dehaene</surname> <given-names>S.</given-names></string-name> <year>2021</year>. <article-title>Sensitivity to geometric shape regularity in humans and baboons: A putative signature of human singularity</article-title>. <source>ProcNatlAcadSciUSA</source> <volume>118</volume>.</mixed-citation></ref>
<ref id="c99"><mixed-citation publication-type="journal"><string-name><surname>Schenker</surname> <given-names>NM</given-names></string-name>, <string-name><surname>Hopkins</surname> <given-names>WD</given-names></string-name>, <string-name><surname>Spocter</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Garrison</surname> <given-names>AR</given-names></string-name>, <string-name><surname>Stimpson</surname> <given-names>CD</given-names></string-name>, <string-name><surname>Erwin</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Hof</surname> <given-names>PR</given-names></string-name>, <string-name><surname>Sherwood</surname> <given-names>CC</given-names></string-name>. <year>2010</year>. <article-title>Broca’s area homologue in chimpanzees (Pan troglodytes): probabilistic mapping, asymmetry, and comparison to humans</article-title>. <source>Cereb Cortex</source> <volume>20</volume>:<fpage>730</fpage>–<lpage>742</lpage>. doi:<pub-id pub-id-type="doi">10.1093/cercor/bhp138</pub-id></mixed-citation></ref>
<ref id="c100"><mixed-citation publication-type="journal"><string-name><surname>Schusterman</surname> <given-names>R</given-names></string-name>, <string-name><surname>Kastak</surname> <given-names>D</given-names></string-name>. <year>1998</year>. <article-title>Functional equivalence in a California sea lion: relevance to animal social and communicative interactions</article-title>. <source>Anim Behav</source> <volume>55</volume>:<fpage>1087</fpage>–<lpage>1095</lpage>. doi:<pub-id pub-id-type="doi">10.1006/anbe.1997.0654</pub-id></mixed-citation></ref>
<ref id="c101"><mixed-citation publication-type="journal"><string-name><surname>Scott</surname> <given-names>BH</given-names></string-name>, <string-name><surname>Mishkin</surname> <given-names>M</given-names></string-name>. <year>2016</year>. <article-title>Auditory short-term memory in the primate auditory cortex</article-title>. <source>Brain Res</source> <volume>1640</volume>:<fpage>264</fpage>–<lpage>277</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.brainres.2015.10.048</pub-id></mixed-citation></ref>
<ref id="c102"><mixed-citation publication-type="journal"><string-name><surname>Sestieri</surname> <given-names>C</given-names></string-name>, <string-name><surname>Shulman</surname> <given-names>GL</given-names></string-name>, <string-name><surname>Corbetta</surname> <given-names>M</given-names></string-name>. <year>2010</year>. <article-title>Attention to Memory and the Environment: Functional Specialization and Dynamic Competition in Human Posterior Parietal Cortex</article-title>. <source>J Neurosci</source> <volume>30</volume>:<fpage>8445</fpage>– <lpage>8456</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.4719-09.2010</pub-id></mixed-citation></ref>
<ref id="c103"><mixed-citation publication-type="journal"><string-name><surname>Shibata</surname> <given-names>M</given-names></string-name>, <string-name><surname>Pattabiraman</surname> <given-names>K</given-names></string-name>, <string-name><surname>Lorente-Galdos</surname> <given-names>B</given-names></string-name>, <string-name><surname>Andrijevic</surname> <given-names>D</given-names></string-name>, <string-name><surname>Kim</surname> <given-names>S-K</given-names></string-name>, <string-name><surname>Kaur</surname> <given-names>N</given-names></string-name>, <string-name><surname>Muchnik</surname> <given-names>SK</given-names></string-name>, <string-name><surname>Xing</surname> <given-names>X</given-names></string-name>, <string-name><surname>Santpere</surname> <given-names>G</given-names></string-name>, <string-name><surname>Sousa</surname> <given-names>AMM</given-names></string-name>, <string-name><surname>Sestan</surname> <given-names>N</given-names></string-name>. <year>2021</year>. <article-title>Regulation of prefrontal patterning and connectivity by retinoic acid</article-title>. <source>Nature</source> <volume>598</volume>:<fpage>483</fpage>–<lpage>488</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41586-021-03953-x</pub-id></mixed-citation></ref>
<ref id="c104"><mixed-citation publication-type="journal"><string-name><surname>Shum</surname> <given-names>J</given-names></string-name>, <string-name><surname>Hermes</surname> <given-names>D</given-names></string-name>, <string-name><surname>Foster</surname> <given-names>BL</given-names></string-name>, <string-name><surname>Dastjerdi</surname> <given-names>M</given-names></string-name>, <string-name><surname>Rangarajan</surname> <given-names>V</given-names></string-name>, <string-name><surname>Winawer</surname> <given-names>J</given-names></string-name>, <string-name><surname>Miller</surname> <given-names>KJ</given-names></string-name>, <string-name><surname>Parvizi</surname> <given-names>J</given-names></string-name>. <year>2013</year>. <article-title>A brain area for visual numerals</article-title>. <source>J Neurosci</source> <volume>33</volume>:<fpage>6709</fpage>–<lpage>15</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.4558-12.2013</pub-id></mixed-citation></ref>
<ref id="c105"><mixed-citation publication-type="journal"><string-name><surname>Sidman</surname> <given-names>M</given-names></string-name>, <string-name><surname>Rauzin</surname> <given-names>R</given-names></string-name>, <string-name><surname>Lazar</surname> <given-names>R</given-names></string-name>, <string-name><surname>Cunningham</surname> <given-names>S</given-names></string-name>, <string-name><surname>Tailby</surname> <given-names>W</given-names></string-name>, <string-name><surname>Carrigan</surname> <given-names>P</given-names></string-name>. <year>1982</year>. <article-title>A search for symmetry in the conditional discriminations of rhesus monkeys, baboons, and children</article-title>. <source>J Exp Anal Behav</source> <volume>37</volume>:<fpage>23</fpage>– <lpage>44</lpage>. doi:<pub-id pub-id-type="doi">10.1901/jeab.1982.37-23</pub-id></mixed-citation></ref>
<ref id="c106"><mixed-citation publication-type="journal"><string-name><surname>Smaers</surname> <given-names>JB</given-names></string-name>, <string-name><surname>Gómez-Robles</surname> <given-names>A</given-names></string-name>, <string-name><surname>Parks</surname> <given-names>AN</given-names></string-name>, <string-name><surname>Sherwood</surname> <given-names>CC</given-names></string-name>. <year>2017</year>. <article-title>Exceptional Evolutionary Expansion of Prefrontal Cortex in Great Apes and Humans</article-title>. <source>Current Biology</source> <volume>27</volume>:<fpage>714</fpage>–<lpage>720</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cub.2017.01.020</pub-id></mixed-citation></ref>
<ref id="c107"><mixed-citation publication-type="journal"><string-name><surname>Song</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Tian</surname> <given-names>M</given-names></string-name>, <string-name><surname>Liu</surname> <given-names>J</given-names></string-name>. <year>2012</year>. <article-title>Top-down processing of symbolic meanings modulates the visual word form area</article-title>. <source>J Neurosci</source> <volume>32</volume>:<fpage>12277</fpage>–<lpage>83</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.1874-12.2012</pub-id></mixed-citation></ref>
<ref id="c108"><mixed-citation publication-type="book"><string-name><surname>Spelke</surname> <given-names>E</given-names></string-name>. <year>2003</year>. <chapter-title>What makes us smart? Core knowledge and natural language</chapter-title> In: <person-group person-group-type="editor"><string-name><surname>Gentner</surname> <given-names>D</given-names></string-name>, <string-name><surname>Goldin- Meadow</surname> <given-names>S</given-names></string-name></person-group>, editors. <source>Language in Mind</source>. <publisher-loc>Cambridge</publisher-loc>, <publisher-name>Mass.: MIT Press</publisher-name>.</mixed-citation></ref>
<ref id="c109"><mixed-citation publication-type="journal"><string-name><surname>Srihasam</surname> <given-names>K</given-names></string-name>, <string-name><surname>Mandeville</surname> <given-names>JB</given-names></string-name>, <string-name><surname>Morocz</surname> <given-names>IA</given-names></string-name>, <string-name><surname>Sullivan</surname> <given-names>KJ</given-names></string-name>, <string-name><surname>Livingstone</surname> <given-names>MS</given-names></string-name>. <year>2012</year>. <article-title>Behavioral and Anatomical Consequences of Early versus Late Symbol Training in Macaques</article-title>. <source>Neuron</source> <volume>73</volume>:<fpage>608</fpage>–<lpage>619</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuron.2011.12.022</pub-id></mixed-citation></ref>
<ref id="c110"><mixed-citation publication-type="journal"><string-name><surname>Takemura</surname> <given-names>H</given-names></string-name>, <string-name><surname>Pestilli</surname> <given-names>F</given-names></string-name>, <string-name><surname>Weiner</surname> <given-names>KS</given-names></string-name>, <string-name><surname>Keliris</surname> <given-names>GA</given-names></string-name>, <string-name><surname>Landi</surname> <given-names>SM</given-names></string-name>, <string-name><surname>Sliwa</surname> <given-names>J</given-names></string-name>, <string-name><surname>Ye</surname> <given-names>FQ</given-names></string-name>, <string-name><surname>Barnett</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Leopold</surname> <given-names>DA</given-names></string-name>, <string-name><surname>Freiwald</surname> <given-names>WA</given-names></string-name>, <string-name><surname>Logothetis</surname> <given-names>NK</given-names></string-name>, <string-name><surname>Wandell</surname> <given-names>BA</given-names></string-name>. <year>2017</year>. <article-title>Occipital White Matter Tracts in Human and Macaque</article-title>. <source>Cereb Cortex</source> <volume>27</volume>:<fpage>3346</fpage>–<lpage>3359</lpage>. doi:<pub-id pub-id-type="doi">10.1093/cercor/bhx070</pub-id></mixed-citation></ref>
<ref id="c111"><mixed-citation publication-type="journal"><string-name><surname>Tasserie</surname> <given-names>J</given-names></string-name>, <string-name><surname>Grigis</surname> <given-names>A</given-names></string-name>, <string-name><surname>Uhrig</surname> <given-names>L</given-names></string-name>, <string-name><surname>Dupont</surname> <given-names>M</given-names></string-name>, <string-name><surname>Amadon</surname> <given-names>A</given-names></string-name>, <string-name><surname>Jarraya</surname> <given-names>B</given-names></string-name>. <year>2020</year>. <article-title>Pypreclin: An automatic pipeline for macaque functional MRI preprocessing</article-title>. <source>NeuroImage</source> <volume>207</volume>:<fpage>116353</fpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.116353</pub-id></mixed-citation></ref>
<ref id="c112"><mixed-citation publication-type="journal"><string-name><surname>Thiebaut de Schotten</surname> <given-names>M</given-names></string-name>, <string-name><surname>Dell’Acqua</surname> <given-names>F</given-names></string-name>, <string-name><surname>Valabregue</surname> <given-names>R</given-names></string-name>, <string-name><surname>Catani</surname> <given-names>M</given-names></string-name>. <year>2012</year>. <article-title>Monkey to human comparative anatomy of the frontal lobe association tracts</article-title>. <source>Cortex</source> <volume>48</volume>:<fpage>82</fpage>–<lpage>96</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cortex.2011.10.001</pub-id></mixed-citation></ref>
<ref id="c113"><mixed-citation publication-type="journal"><string-name><surname>Uhrig</surname> <given-names>L</given-names></string-name>, <string-name><surname>Dehaene</surname> <given-names>S</given-names></string-name>, <string-name><surname>Jarraya</surname> <given-names>B.</given-names></string-name> <year>2014</year>. <article-title>A hierarchy of responses to auditory regularities in the macaque brain</article-title>. <source>JNeurosci</source> <volume>34</volume>:<fpage>1127</fpage>–<lpage>1132</lpage>.</mixed-citation></ref>
<ref id="c114"><mixed-citation publication-type="journal"><string-name><surname>Vanduffel</surname> <given-names>W</given-names></string-name>, <string-name><surname>Fize</surname> <given-names>D</given-names></string-name>, <string-name><surname>Mandeville</surname> <given-names>JB</given-names></string-name>, <string-name><surname>Nelissen</surname> <given-names>K</given-names></string-name>, <string-name><surname>Van Hecke</surname> <given-names>P</given-names></string-name>, <string-name><surname>Rosen</surname> <given-names>BR</given-names></string-name>, <string-name><surname>Tootell</surname> <given-names>RBH</given-names></string-name>, <string-name><surname>Orban</surname> <given-names>GA.</given-names></string-name> <year>2001</year>. <article-title>Visual motion processing investigated using contrast agent-enhanced fMRI in awake behaving monkeys</article-title>. <source>Neuron</source> <volume>32</volume>:<fpage>565</fpage>–<lpage>577</lpage>.</mixed-citation></ref>
<ref id="c115"><mixed-citation publication-type="journal"><string-name><surname>Vanduffel</surname> <given-names>W</given-names></string-name>, <string-name><surname>Fize</surname> <given-names>D</given-names></string-name>, <string-name><surname>Peuskens</surname> <given-names>H</given-names></string-name>, <string-name><surname>Denys</surname> <given-names>K</given-names></string-name>, <string-name><surname>Sunaert</surname> <given-names>S</given-names></string-name>, <string-name><surname>Todd</surname> <given-names>JT</given-names></string-name>, <string-name><surname>Orban</surname> <given-names>GA</given-names></string-name>. <year>2002</year>. <article-title>Extracting 3D from Motion: Differences in Human and Monkey Intraparietal Cortex</article-title>. <source>Science</source> <volume>298</volume>:<fpage>413</fpage>–<lpage>415</lpage>. doi:<pub-id pub-id-type="doi">10.1126/science.1073574</pub-id></mixed-citation></ref>
<ref id="c116"><mixed-citation publication-type="journal"><string-name><surname>Vergnieux</surname> <given-names>V</given-names></string-name>, <string-name><surname>Vogels</surname> <given-names>R</given-names></string-name>. <year>2020</year>. <article-title>Statistical Learning Signals for Complex Visual Images in Macaque Early Visual Cortex</article-title>. <source>Frontiers in Neuroscience</source> <volume>14</volume>.</mixed-citation></ref>
<ref id="c117"><mixed-citation publication-type="journal"><string-name><surname>Wang</surname> <given-names>L</given-names></string-name>, <string-name><surname>Amalric</surname> <given-names>M</given-names></string-name>, <string-name><surname>Fang</surname> <given-names>W</given-names></string-name>, <string-name><surname>Jiang</surname> <given-names>X</given-names></string-name>, <string-name><surname>Pallier</surname> <given-names>C</given-names></string-name>, <string-name><surname>Figueira</surname> <given-names>S</given-names></string-name>, <string-name><surname>Sigman</surname> <given-names>M</given-names></string-name>, <string-name><surname>Dehaene</surname> <given-names>S</given-names></string-name>. <year>2019</year>. <article-title>Representation of spatial sequences using nested rules in human prefrontal cortex</article-title>. <source>NeuroImage</source> <volume>186</volume>:<fpage>245</fpage>–<lpage>255</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.10.061</pub-id></mixed-citation></ref>
<ref id="c118"><mixed-citation publication-type="journal"><string-name><surname>Wang</surname> <given-names>L</given-names></string-name>, <string-name><surname>Uhrig</surname> <given-names>L</given-names></string-name>, <string-name><surname>Jarraya</surname> <given-names>B</given-names></string-name>, <string-name><surname>Dehaene</surname> <given-names>S</given-names></string-name>. <year>2015</year>. <article-title>Representation of Numerical and Sequential Patterns in Macaque and Human Brains</article-title>. <source>Curr Biol</source> <volume>25</volume>:<fpage>1966</fpage>–<lpage>1974</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.cub.2015.06.035</pub-id></mixed-citation></ref>
<ref id="c119"><mixed-citation publication-type="journal"><string-name><surname>Warren</surname> <given-names>JM</given-names></string-name>. <year>1974</year>. <article-title>Possibly unique characteristics of learning by Primates</article-title>. <source>Journal of Human Evolution</source> <volume>3</volume>:<fpage>445</fpage>–<lpage>454</lpage>. doi:<pub-id pub-id-type="doi">10.1016/0047-2484(74)90004-9</pub-id></mixed-citation></ref>
<ref id="c120"><mixed-citation publication-type="journal"><string-name><surname>Wikman</surname> <given-names>P</given-names></string-name>, <string-name><surname>Rinne</surname> <given-names>T</given-names></string-name>, <string-name><surname>Petkov</surname> <given-names>CI</given-names></string-name>. <year>2019</year>. <article-title>Reward cues readily direct monkeys’ auditory performance resulting in broad auditory cortex modulation and interaction with sites along cholinergic and dopaminergic pathways</article-title>. <source>Sci Rep</source> <volume>9</volume>:<fpage>3055</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41598-019-38833-y</pub-id></mixed-citation></ref>
<ref id="c121"><mixed-citation publication-type="journal"><string-name><surname>Wilson</surname> <given-names>B</given-names></string-name>, <string-name><surname>Marslen-Wilson</surname> <given-names>WD</given-names></string-name>, <string-name><surname>Petkov</surname> <given-names>CI</given-names></string-name>. <year>2017</year>. <article-title>Conserved Sequence Processing in Primate Frontal Cortex</article-title>. <source>Trends Neurosci</source> <volume>40</volume>:<fpage>72</fpage>–<lpage>82</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.tins.2016.11.004</pub-id></mixed-citation></ref>
<ref id="c122"><mixed-citation publication-type="journal"><string-name><surname>Wise</surname> <given-names>SP</given-names></string-name>. <year>2008</year>. <article-title>Forward frontal fields: phylogeny and fundamental function</article-title>. <source>Trends Neurosci</source> <volume>31</volume>:<fpage>599</fpage>–<lpage>608</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.tins.2008.08.008</pub-id></mixed-citation></ref>
<ref id="c123"><mixed-citation publication-type="journal"><string-name><surname>Woods</surname> <given-names>DL</given-names></string-name>, <string-name><surname>Herron</surname> <given-names>TJ</given-names></string-name>, <string-name><surname>Cate</surname> <given-names>AD</given-names></string-name>, <string-name><surname>Yund</surname> <given-names>EW</given-names></string-name>, <string-name><surname>Stecker</surname> <given-names>GC</given-names></string-name>, <string-name><surname>Rinne</surname> <given-names>T</given-names></string-name>, <string-name><surname>Kang</surname> <given-names>X</given-names></string-name>. <year>2010</year>. <article-title>Functional properties of human auditory cortical fields</article-title>. <source>Front Syst Neurosci</source> <volume>4</volume>:<fpage>155</fpage>. doi:<pub-id pub-id-type="doi">10.3389/fnsys.2010.00155</pub-id></mixed-citation></ref>
<ref id="c124"><mixed-citation publication-type="journal"><string-name><surname>Xu</surname> <given-names>F</given-names></string-name>, <string-name><surname>Cote</surname> <given-names>M</given-names></string-name>, <string-name><surname>Baker</surname> <given-names>A</given-names></string-name>. <year>2005</year>. <article-title>Labeling guides object individuation in 12-month-old infants</article-title>. <source>Psychol Sci</source> <volume>16</volume>:<fpage>372</fpage>–<lpage>7</lpage>. doi:<pub-id pub-id-type="doi">10.1111/j.0956-7976.2005.01543.x</pub-id></mixed-citation></ref>
<ref id="c125"><mixed-citation publication-type="journal"><string-name><surname>Yang</surname> <given-names>C.</given-names></string-name> <year>2013</year>. <article-title>Ontogeny and phylogeny of language</article-title>. <source>PNAS</source> <volume>201216803</volume>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1216803110</pub-id></mixed-citation></ref>
<ref id="c126"><mixed-citation publication-type="journal"><string-name><surname>Zhang</surname> <given-names>H</given-names></string-name>, <string-name><surname>Zhen</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Yu</surname> <given-names>S</given-names></string-name>, <string-name><surname>Long</surname> <given-names>T</given-names></string-name>, <string-name><surname>Zhang</surname> <given-names>B</given-names></string-name>, <string-name><surname>Jiang</surname> <given-names>X</given-names></string-name>, <string-name><surname>Li</surname> <given-names>J</given-names></string-name>, <string-name><surname>Fang</surname> <given-names>W</given-names></string-name>, <string-name><surname>Sigman</surname> <given-names>M</given-names></string-name>, <string-name><surname>Dehaene</surname> <given-names>S</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>L</given-names></string-name>. <year>2022</year>. <article-title>Working Memory for Spatial Sequences: Developmental and Evolutionary Factors in Encoding Ordinal and Relational Structures</article-title>. <source>J Neurosci</source> <volume>42</volume>:<fpage>850</fpage>–<lpage>864</lpage>. doi:<pub-id pub-id-type="doi">10.1523/JNEUROSCI.0603-21.2021</pub-id></mixed-citation></ref>
</ref-list>
<sec>
<fig id="figS1" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary figure 1:</label>
<caption><title>Stimulus sets for experiment 1.</title></caption>
<graphic xlink:href="531109v1_figS1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS2" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 2.</label>
<caption><p><bold>A) Complete description of the task paradigm for visual-visual label learning.</bold> Subjects were habituated to 4 different visual-visual pairs during three days. Two pairs were in the ‘object-label’ order and two pairs in the ‘label-object’ order. During the test phase, the same canonical order was kept in 80% of the trials, including 10% of incongruent pairs. In reversed trials (20% of trials), the pairs were either congruent (10%) or incongruent (10%) with the learning. For the monkeys, one pair in each direction was associated with a high reward while the other one was associated with a low reward, making the reward size orthogonal to congruity and canonicity. <bold>B)</bold> Stimulus sets for experiment 2 in monkeys. Humans were tested with stimulus set 2.</p></caption>
<graphic xlink:href="531109v1_figS2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS3" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 3</label>
<caption><title>Effect of reward for the visual-visual task in non-human primates.</title>
<p><bold>A</bold>) Significant clusters from the incongruent-congruent canonical contrast in low reward trials. <bold>B</bold>) Significant from the incongruent-congruent canonical contrast in high reward trials. <bold>C</bold>) Significant clusters from the interaction between congruity and reward. p<sub>voxel</sub>&lt;0.001 &amp; p<sub>cluster</sub> &lt;0.05 in all panels.</p></caption>
<graphic xlink:href="531109v1_figS3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS4" position="float" orientation="portrait" fig-type="figure">
<label>Supplementary Figure 4.</label>
<caption><title>Analyses of all human participants in experiments 1 and 2 merged.</title>
<p><bold>A)</bold> Main effect of experiment. <bold>B)</bold> Main effect of congruity, <bold>C)</bold> Effect of congruity in the canonical trials and D) in the reversed trials. <bold>E)</bold> No significant cluster was observed for the interaction canonicity X congruity. <bold>F)</bold> slices in the 3 planes showing the only significant cluster in the Experiment X Congruity interaction. p<sub>voxel</sub>&lt;0.001 &amp; p<sub>cluster</sub> &lt;0.05 in all panels</p></caption>
<graphic xlink:href="531109v1_figS4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.87380.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Martin</surname>
<given-names>Andrea E</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Max Planck Institute for Psycholinguistics</institution>
</institution-wrap>
<city>Nijmegen</city>
<country>Netherlands</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
<kwd>Solid</kwd>
</kwd-group>
</front-stub>
<body>
<p>fMRI was used to address an <bold>important</bold> aspect of human cognition - the capacity for structured representations and symbolic processing - in a cross-species comparison with non-human primates (macaques); the experimental design probed implicit symbolic processing through reversal of learned stimulus pairs. The authors present <bold>solid</bold> evidence in humans that helps elucidate the role of brain networks in symbolic processing, however the evidence from macaques was <bold>incomplete</bold> (e.g., sample size constraints, potential and hard-to-quantify differences in attention allocation, motivation, and lived experience between species).</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.87380.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Kerkoerle and colleagues present a very interesting comparative fMRI study in humans and monkeys, assessing neural responses to surprise reactions at the reversal of a previously learned association. The implicit nature of this task, assessing how this information is represented without requiring explicit decision-making, is an elegant design. The paper reports that both humans and monkeys show neural responses across a range of areas when presented with incongruous stimulus pairs. Monkeys also show a surprise response when the stimuli are presented in a reversed direction. However, humans show no such surprise response based on this reversal, suggesting that they encode the relationship reversibly and bidirectionally, unlike the monkeys. This has been suggested as a hallmark of symbolic representation, that might be absent in nonhuman animals.</p>
<p>I find this experiment and the results quite compelling, and the data do support the hypothesis that humans are somewhat unique in their tendency to form reversible, symbolic associations. I think that an important strength of the results is that the critical finding is the presence of an interaction between congruity and canonicity in macaques, which does not appear in humans. These results go a long way to allay concerns I have about the comparison of many human participants to a very small number of macaques.</p>
<p>I understand the impossibility of testing 30+ macaques in an fMRI experiment. However, I think it is important to note that differences necessarily arise in the analysis of such datasets. The authors report that they use '...identical training, stimuli, and whole-brain fMRI measures'. However, the monkeys (in experiment 1) actually required 10 times more training. More importantly, while the fMRI measures are the same, group analysis over 30+ individuals is inherently different from comparing only 2 macaques (including smoothing and averaging away individual differences that might be more present in the monkeys, due to the much smaller sample size).</p>
<p>Despite this, the results do appear to show that macaques show the predicted interaction effect (even despite the sample size), while humans do not. I think this is quite convincing, although had the results turned out differently (for example an effect in humans that was absent in macaques), I think this difference in sample size would be considerably more concerning.</p>
<p>I would also note that while I agree with the authors' conclusions, it is notable to me that the congruity effect observed in humans (red vs blue lines in Fig. 2B) appears to be far more pronounced than any effect observed in the macaques (Fig. 3C-3). Again, this does not challenge the core finding of this paper but does suggest methodological or possibly motivational/attentional differences between the humans and the monkeys (or, for example, that the monkeys had learned the associations less strongly and clearly than the humans).</p>
<p>This is a strong paper with elegant methods and makes a worthwhile contribution to our understanding of the neural systems supporting symbolic representations in humans, as opposed to other animals.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.87380.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>In their article titled &quot;Brain mechanisms of reversible symbolic reference: a potential singularity of the human brain&quot;, van Kerkoerle et al address the timely question of whether non-human primates (rhesus macaques) possess the ability for reverse symbolic inference as observed in humans. Through an fMRI experiment in both humans and monkeys, they analyzed the bold signal in both species while observing audio-visual and visual-visual stimuli pairs that had been previously learned in a particular direction. Remarkably, the findings pertaining to humans revealed that a broad brain network exhibited increased activity in response to surprises occurring in both the learned and reverse directions. Conversely, in monkeys, the study uncovered that the brain activity within sensory areas only responded to the learned direction but failed to exhibit any discernible response to the reverse direction. These compelling results indicate that the capacity for reversible symbolic inference may be unique to humans.</p>
<p>In general, the manuscript is skillfully crafted and highly accessible to readers. The experimental design exhibits originality, and the analyses are tailored to effectively address the central question at hand. Although the first experiment raised a number of methodological inquiries, the subsequent second experiment thoroughly addresses these concerns and effectively replicates the initial findings, thereby significantly strengthening the overall study. Overall, this article is already of high quality and brings new insight into human cognition.</p>
<p>I identified three weaknesses in the manuscript:</p>
<p>
- One major issue in the study is the absence of significant results in monkeys. Indeed, authors draw conclusions regarding the lack of significant difference in activity related to surprise in the multi-demand network (MDN) in the reverse congruent versus reverse incongruent conditions. Although the results are convincing (especially with the significant interaction between congruency and canonicity), the article could be improved by including additional analyses in a priori ROI for the MDN in monkeys (as well as in humans, for comparison).</p>
<p>
- While the authors acknowledge in the discussion that the number of monkeys included in the study is considerably lower compared to humans, it would be informative to know the variability of the results among human participants.</p>
<p>
- Some details are missing in the methods.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.87380.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This study investigates the hypothesis that humans (but not non-human primates) spontaneously learn reversible temporal associations (i.e., learning a B-A association after only being exposed to A-B sequences), which the authors consider to be a foundational property of symbolic cognition. To do so, they expose humans and macaques to 2-item sequences (in a visual-auditory experiment, pairs of images and spoken nonwords, and in a visual-visual experiment, pairs of images and abstract geometric shapes) in a fixed temporal order, then measure the brain response during a test phase to congruent vs. incongruent pairs (relative to the trained associations) in canonical vs. reversed order (relative to the presentation order used in training). The advantage of neuroimaging for this question is that it removes the need for a behavioral test, which non-human primates can fail for reasons unrelated to the cognitive construct being investigated. In humans, the researchers find statistically indistinguishable incongruity effects in both directions (supporting a spontaneous reversible association), whereas in monkeys they only find incongruity effects in the canonical direction (supporting an association but a lack of spontaneous reversal). Although the precise pattern of activation varies by experiment type (visual-auditory vs. visual-visual) in both species, the authors point out that some of the regions involved are also those that are most anatomically different between humans and other primates. The authors interpret their finding to support the hypothesis that reversible associations, and by extension symbolic cognition, is uniquely human.</p>
<p>This study is a valuable complement to prior behavioral work on this question. However, I have some concerns about methods and framing.</p>
<p>Methods - Design issues:</p>
<p>1. The authors originally planned to use the same training/testing protocol for both species but the monkeys did not learn anything, so they dramatically increased the amount of training and evaluation. By my calculation from the methods section, humans were trained on 96 trials and tested on 176, whereas the monkeys got an additional 3,840 training trials and 1,408 testing trials. The authors are explicit that they continued training the monkeys until they got a congruity effect. On the one hand, it is commendable that they are honest about this in their write-up, given that this detail could easily be framed as deliberate after the fact. On the other hand, it is still a form of p-hacking, given that it's critical for their result that the monkeys learn the canonical association (otherwise, the critical comparison to the non-canonical association is meaningless).</p>
<p>2. Between-species comparisons are challenging. In addition to having differences in their DNA, human participants have spent many years living in a very different culture than that of NHPs, including years of formal education. As a result, attributing the observed differences to biology is challenging. One approach that has been adopted in some past studies is to examine either young children or adults from cultures that don't have formal educational structures. This is not the approach the authors take. This major confound needs to minimally be explicitly acknowledged up front.</p>
<p>3. Humans have big advantages in processing and discriminating spoken stimuli and associating them with visual stimuli (after all, this is what words are in spoken human languages). Experiment 2 ameliorates these concerns to some degree, but still, it is difficult to attribute the failure of NHPs to show reversible associations in Experiment 1 to cognitive differences rather than the relative importance of sound string to meaning associations in the human vs. NHP experiences.</p>
<p>4. More minor: The localizer task (math sentences vs. other sentences) makes sense for math but seems to make less sense for language: why would a language region respond more to sentences that don't describe math vs. ones that do?</p>
<p>Methods - Analysis issues:</p>
<p>5. The analyses appear to &quot;double dip&quot; by using the same data to define the clusters and to statistically test the average cluster activation (Kriegeskorte et al., 2009). The resulting effect sizes are therefore likely inflated, and the p-values are anticonservative.</p>
<p>Framing:</p>
<p>6. The framing (&quot;Brain mechanisms of reversible symbolic reference: A potential singularity of the human brain&quot;) is bigger than the finding (monkeys don't spontaneously reverse a temporal association but humans do). The title and discussion are full of buzzy terms (&quot;brain mechanisms&quot;, &quot;symbolic&quot;, and &quot;singularity&quot;) that are only connected to the experiments by a debatable chain of assumptions.</p>
<p>First, this study shows relatively little about brain &quot;mechanisms&quot; of reversible symbolic associations, which implies insights into how these associations are learned, recognized, and represented. But we're only given standard fMRI analyses that are quite inconsistent across similar experimental paradigms, with purely suggestive connections between these spatial patterns and prior work on comparative brain anatomy.</p>
<p>Second, it's not clear what the relationship is between symbolic cognition and a propensity to spontaneously reverse a temporal association. Certainly, if there are inter-species differences in learning preferences this is important to know about, but why is this construed as a difference in the presence or absence of symbols? Because the associations aren't used in any downstream computation, there is not even any way for participants to know which is the sign and which is the signified: these are merely labels imposed by the researchers on a sequential task.</p>
<p>Third, the word &quot;singularity&quot; is both problematically ambiguous and not well supported by the results. &quot;Singularity&quot; is a highly loaded word that the authors are simply using to mean &quot;that which is uniquely human&quot;. Rather than picking a term with diverse technical meanings across fields and then trying to restrict the definition, it would be better to use a different term. Furthermore, even under the stated definition, this study performed a single pairwise comparison between humans and one other species (macaques), so it is a stretch to then conclude (or insinuate) that the &quot;singularity&quot; has been found (see also pt. 2 above).</p>
<p>7. Related to pt. 6, there is circularity in the framing whereby the authors say they are setting out to find out what is uniquely human, hypothesizing that the uniquely human thing is symbols, and then selecting a defining trait of symbols (spontaneous reversible association) *because* it seems to be uniquely human (see e.g., &quot;Several studies previously found behavioral evidence for a uniquely human ability to spontaneously reverse a learned association (Imai et al., 2021; Kojima, 1984; Lipkens et al., 1988; Medam et al., 2016; Sidman et al., 1982), and such reversibility was therefore proposed as a defining feature of symbol representation reference (Deacon, 1998; Kabdebon and Dehaene-Lambertz, 2019; Nieder, 2009).&quot;, line 335). They can't have it both ways. Either &quot;symbol&quot; is an independently motivated construct whose presence can be independently tested in humans and other species, or it is by fiat synonymous with the &quot;singularity&quot;. This circularity can be broken by a more modest framing that focuses on the core research question (e.g., &quot;What is uniquely human? One possibility is spontaneous reversal of temporal associations.&quot;) and then connects (speculatively) to the bigger conceptual landscape in the discussion (&quot;Spontaneous reversal of temporal associations may be a core ability underlying the acquisition of mental symbols&quot;).</p>
</body>
</sub-article>
</article>