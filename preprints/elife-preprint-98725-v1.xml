<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">98725</article-id>
<article-id pub-id-type="doi">10.7554/eLife.98725</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.98725.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.3</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Connectome-Based Attractor Dynamics Underlie Brain Activity in Rest, Task, and Disease</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Englert</surname>
<given-names>Robert</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Kincses</surname>
<given-names>Balint</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Kotikalapudi</surname>
<given-names>Raviteja</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Gallitto</surname>
<given-names>Giuseppe</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Li</surname>
<given-names>Jialin</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Hoffschlag</surname>
<given-names>Kevin</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7423-5422</contrib-id>
<name>
<surname>Woo</surname>
<given-names>Choong-Wan</given-names>
</name>
<xref ref-type="aff" rid="a5">5</xref>
<xref ref-type="aff" rid="a6">6</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Wager</surname>
<given-names>Tor D</given-names>
</name>
<xref ref-type="aff" rid="a7">7</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Timmann</surname>
<given-names>Dagmar</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Bingel</surname>
<given-names>Ulrike</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2942-0821</contrib-id>
<name>
<surname>Spisak</surname>
<given-names>Tamas</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Center for Translational Neuro- and Behavioral Sciences (C-TNBS), University Medicine Essen</institution>, <country>Germany</country></aff>
<aff id="a2"><label>2</label><institution>Department of Diagnostic and Interventional Radiology and Neuroradiology, University Medicine Essen</institution>, <country>Germany</country></aff>
<aff id="a3"><label>3</label><institution>Department of Neurology, University Medicine Essen</institution>, <country>Germany</country></aff>
<aff id="a4"><label>4</label><institution>Max Planck School of Cognition</institution>, Leipzig, <country>Germany</country></aff>
<aff id="a5"><label>5</label><institution>Center for Neuroscience Imaging Research, Institute for Basic Science</institution>, Suwon, South Korea</aff>
<aff id="a6"><label>6</label><institution>Department of Biomedical Engineering, Sungkyunkwan University</institution>, Suwon, South Korea</aff>
<aff id="a7"><label>7</label><institution>Department of Psychological and Brain Sciences, Dartmouth College</institution>, Hanover, NH, <country>USA</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Marquand</surname>
<given-names>Andre F</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Radboud University Nijmegen</institution>
</institution-wrap>
<city>Nijmegen</city>
<country>Netherlands</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Marquand</surname>
<given-names>Andre F</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Radboud University Nijmegen</institution>
</institution-wrap>
<city>Nijmegen</city>
<country>Netherlands</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label><italic>corresponding author:</italic> <email>tamas.spisak@uk-essen.de</email></corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-09-05">
<day>05</day>
<month>09</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP98725</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-05-28">
<day>28</day>
<month>05</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-04-11">
<day>11</day>
<month>04</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.11.03.565516"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Englert et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Englert et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-98725-v1.pdf"/>
<abstract>
<p>Understanding large-scale brain dynamics is a grand challenge in neuroscience. We propose functional connectome-based Hopfield Neural Networks (fcHNNs) as a model of macro-scale brain dynamics, arising from recurrent activity flow among brain regions. An fcHNN is neither optimized to mimic certain brain characteristics, nor trained to solve specific tasks; its weights are simply initialized with empirical functional connectivity values. In the fcHNN framework, brain dynamics are understood in relation to so-called attractor states, i.e. neurobiologically meaningful low-energy activity configurations. Analyses of 7 distinct datasets demonstrate that fcHNNs can accurately reconstruct and predict brain dynamics under a wide range of conditions, including resting and task states and brain disorders. By establishing a mechanistic link between connectivity and activity, fcHNNs offer a simple and interpretable computational alternative to conventional descriptive analyses of brain function. Being a generative framework, fcHNNs can yield mechanistic insights and hold potential to uncover novel treatment targets.</p>
</abstract>
<abstract>
<title>Key Points</title>
<list list-type="bullet">
<list-item><p>We present a simple yet powerful phenomenological model for large-scale brain dynamics</p></list-item>
<list-item><p>The model uses a functional connectome-based Hopfield artificial neural network (fcHNN) architecture to compute recurrent “activity flow” through the network of brain regions</p></list-item>
<list-item><p>fcHNN attractor dynamics accurately reconstruct several characteristics of resting state brain dynamics</p></list-item>
<list-item><p>fcHNNs conceptualize both task-induced and pathological changes in brain activity as a non-linear alteration of these dynamics</p></list-item>
<list-item><p>Our approach is validated using large-scale neuroimaging data from seven studies</p></list-item>
<list-item><p>fcHNNs offers a simple and interpretable computational alternative to conventional descriptive analyses of brain function</p></list-item>
</list>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>- improved introduction
- improved presentation of the dependence of results on the temperature and noise parameter
- better discussion of related literature (structural connectivity based attractor network approaches)
- some typos fixed</p></fn>
</fn-group>
<fn-group content-type="external-links">
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://pni-lab.github.io/connattractor">https://pni-lab.github.io/connattractor</ext-link>
</p></fn>
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://github.com/pni-lab/connattractor">https://github.com/pni-lab/connattractor</ext-link>
</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Brain function is characterized by the continuous activation and deactivation of anatomically distributed neuronal populations (<xref ref-type="bibr" rid="c4">Buzsaki, 2006</xref>). Irrespective of the presence or absence of explicit stimuli, brain regions appear to work in concert, giving rise to a rich and spatiotemporally complex fluctuation (<xref ref-type="bibr" rid="c2">Bassett &amp; Sporns, 2017</xref>). This fluctuation is neither random nor stationary over time (<xref ref-type="bibr" rid="c38">Liu &amp; Duyn, 2013</xref>; <xref ref-type="bibr" rid="c62">Zalesky <italic>et al</italic>., 2014</xref>). It is organized around large-scale gradients (<xref ref-type="bibr" rid="c40">Margulies <italic>et al</italic>., 2016</xref>; <xref ref-type="bibr" rid="c30">Huntenburg <italic>et al</italic>., 2018</xref>) and exhibits quasi-periodic properties, with a limited number of recurring patterns known as “brain states” (<xref ref-type="bibr" rid="c21">Greene <italic>et al</italic>., 2023</xref>; <xref ref-type="bibr" rid="c59">Vidaurre <italic>et al</italic>., 2017</xref>; <xref ref-type="bibr" rid="c38">Liu &amp; Duyn, 2013</xref>). A wide variety of descriptive techniques have been previously employed to characterize whole-brain dynamics (<xref ref-type="bibr" rid="c57">Smith <italic>et al</italic>., 2012</xref>; <xref ref-type="bibr" rid="c59">Vidaurre <italic>et al</italic>., 2017</xref>; <xref ref-type="bibr" rid="c38">Liu &amp; Duyn, 2013</xref>; <xref ref-type="bibr" rid="c7">Chen <italic>et al</italic>., 2018</xref>). These efforts have provided accumulating evidence not only for the existence of dynamic brain states, but also for their clinical significance (<xref ref-type="bibr" rid="c31">Hutchison <italic>et al</italic>., 2013</xref>; <xref ref-type="bibr" rid="c1">Barttfeld <italic>et al</italic>., 2015</xref>; <xref ref-type="bibr" rid="c42">Meer <italic>et al</italic>., 2020</xref>). The underlying driving forces, however, remain elusive due to the descriptive nature of such studies.</p>
<p>Conventional computational approaches attempt to solve this puzzle, by going all the way down to the biophysical properties of single neurons and aim to construct a model of larger neural populations, or even the entire brain (<xref ref-type="bibr" rid="c3">Breakspear, 2017</xref>). These approaches have shown numerous successful applications (<xref ref-type="bibr" rid="c44">Murray <italic>et al</italic>., 2018</xref>; <xref ref-type="bibr" rid="c35">Kriegeskorte &amp; Douglas, 2018</xref>; <xref ref-type="bibr" rid="c26">Heinz <italic>et al</italic>., 2019</xref>). However, such models need to estimate a vast number of neurobiologically motivated free parameters to fit the data. This hampers their ability to effectively bridge the gap between explanations at the level of single neurons and the complexity of behavior (<xref ref-type="bibr" rid="c3">Breakspear, 2017</xref>). Recent efforts using coarse-grained brain network models (<xref ref-type="bibr" rid="c54">Schirner <italic>et al</italic>., 2022</xref>; <xref ref-type="bibr" rid="c53">Schiff <italic>et al</italic>., 1994</xref>; <xref ref-type="bibr" rid="c47">Papadopoulos <italic>et al</italic>., 2017</xref>; <xref ref-type="bibr" rid="c55">Seguin <italic>et al</italic>., 2023</xref>) and linear network control theory (<xref ref-type="bibr" rid="c8">Chiêm <italic>et al</italic>., 2021</xref>; <xref ref-type="bibr" rid="c52">Scheid <italic>et al</italic>., 2021</xref>; <xref ref-type="bibr" rid="c22">Gu <italic>et al</italic>., 2015</xref>) opted to trade biophysical fidelity to phenomenological validity. Such models have provided insights into some of the inherent key characteristics of the brain as a dynamic system; for instance, the importance of stable patterns, so-called <italic>“attractor states”</italic>, in governing brain dynamics (<xref ref-type="bibr" rid="c13">Deco <italic>et al</italic>., 2012</xref>; <xref ref-type="bibr" rid="c20">Golos <italic>et al</italic>., 2015</xref>; <xref ref-type="bibr" rid="c24">Hansen <italic>et al</italic>., 2015</xref>). While attractor networks have become established models of micro-scale canonical brain circuits in the last four decades (<xref ref-type="bibr" rid="c33">Khona &amp; Fiete, 2022</xref>), these studies highlighted that attractor dynamics are essential characteristics of macro-scale brain dynamics as well. However, the standard practice among these studies is the use of models that capitalize on information about the structural wiring of the brain, leading to the grand challenge of modeling the relationship between structural pathways and polysynaptic functional connectivity. The “neuroconnectionist” approach (<xref ref-type="bibr" rid="c15">Doerig <italic>et al</italic>., 2023</xref>) makes another step towards trading biophysical detail for “cognitive/behavioral fidelity” (<xref ref-type="bibr" rid="c35">Kriegeskorte &amp; Douglas, 2018</xref>), by using artificial neural networks (ANNs) that are trained to perform various tasks, as brain models. However, the need to train ANNs for specific tasks inherently limits their ability to explain task-independent, spontaneous neural dynamics (<xref ref-type="bibr" rid="c50">Richards <italic>et al</italic>., 2019</xref>).</p>
<p>Here we propose a minimal phenomenological model for large-scale brain dynamics, that combines the advantages of large-scale attractor network models (<xref ref-type="bibr" rid="c20">Golos <italic>et al</italic>., 2015</xref>), neuroconnectionism (<xref ref-type="bibr" rid="c15">Doerig <italic>et al</italic>., 2023</xref>), and recent advances in undersanding the flow of brain activity across regions (<xref ref-type="bibr" rid="c10">Cole <italic>et al</italic>., 2016</xref>), to investigate brain dynamics. We utilize an ANN as an abstract, high-level computational model of the brain, similarly to the neuroconnectionist approach. However, our model is not explicitly trained for a specific task, instead we set its weights empirically. Specifically, we employ a continuous-space Hopfield Neural Network (HNN) (<xref ref-type="bibr" rid="c29">Hopfield, 1982</xref>; <xref ref-type="bibr" rid="c36">Krotov, 2023</xref>), similar to the spin-glass and Hopfield-style attractor network models applied e.g. by <xref ref-type="bibr" rid="c13">Deco <italic>et al</italic>. (2012)</xref> or <xref ref-type="bibr" rid="c20">Golos <italic>et al</italic>. (2015)</xref>, where the nodes of the network model represent large-scale brain areas. However, in contrast to these previous efforts that start from the structural wiring of the brain, we initialize the edge weights of the network based on direct estimates of node-to-node information transfer, as measured with fMRI. Our decision to capitalize on a direct proxy of interregional communication, rather than structural pathways, is motivated by the “activity flow” principle (<xref ref-type="bibr" rid="c10">Cole <italic>et al</italic>., 2016</xref>; <xref ref-type="bibr" rid="c32">Ito <italic>et al</italic>., 2017</xref>), a thoroughly validated phenomenological model for the association between brain activity and functional connectivity. This allows us to circumvent the necessity of comprehensively understanding and accurately modeling structural-functional coupling in the brain. Instead, we can concentrate on the overarching dynamical properties of the system.</p>
<p>Based on the topology of the functional connectome, our model establishes an energy level for any arbitrary activation patterns and determines a “trajectory of least action” towards one of the finite number of <italic>attractor states</italic>, that minimize this energy. In the proposed framework, macro-scale brain dynamics can be conceptualized as an intricate, high-dimensional path on the energy landscape (<xref rid="fig1" ref-type="fig">Figure 1C</xref>), arising from the activity flow (<xref ref-type="bibr" rid="c10">Cole <italic>et al</italic>., 2016</xref>) within the functional connectome and constrained by the “gravitational pull” of the attractor states of the system. The generative nature of the proposed framework offers testable predictions for the effect of various perturbations and alterations of these dynamics, from task-induced activity to changes related to brain disorders.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Connectome-based Hopfield networks as models of macro-scale brain dynamics.</title>
<p><bold>(A)</bold> Hopfield artificial neural networks (HNNs) are a form of recurrent artificial neural networks that serve as content-addressable (“associative”) memory systems. Hopfield networks can be trained to store a finite number of patterns (e.g. via Hebbian learning a.k.a. “fire together - wire together”). During the training procedure, the weights of the HNN are trained so that the stored patterns become stable attractor states of the network. Thus, when the trained network is presented partial, noisy or corrupted variations of the stored patterns, it can effectively reconstruct the original pattern via an iterative relaxation procedure that converges to the attractor states. <bold>(B)</bold> We consider regions of the brain as nodes of a Hopfield network. Instead of initializing the network with the structural wiring of the brain or training it to solve specific tasks, we set its weights empirically, using information about the interregional activity flow across regions, as estimated via functional brain connectivity. Capitalizing on strong analogies between the relaxation rule of Hopfield networks and the activity flow principle that links activity to connectivity in brain networks, we propose the resulting functional connectome-based Hopfield neural network (fcHNN) as a phenomenological model for macro-scale brain dynamics. <bold>(C)</bold> The proposed computational framework assigns an energy level, an attractor state and a position in a low-dimensional embedding to brain activation patterns. Additionally, it models how the entire state-space of viable activation patterns is restricted by the dynamics of the system and how alterations in activity and/or connectivity modify these dynamics.</p></caption>
<graphic xlink:href="565516v3_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>In the present work, we investigate how well the functional connectome is suited to be an attractor network, map the corresponding attractor states and model itinerant stochastic dynamics traversing the different basins of attraction of the system. We use a diverse set of experimental, clinical and meta-analytic studies to evaluate our model’s ability to reconstruct various characteristics of resting state brain dynamics, as well as its capacity to detect and explain changes induced by experimental conditions or alterations in brain disorders.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Connectome-based Hopfield network as a model of brain dynamics</title>
<p>First, we investigated the functional connectome as an attractor network in a sample of n=41 healthy young participants (study 1, see <xref rid="tbls1" ref-type="table">Methods Table 1</xref> for details). We estimated interregional activity flow (<xref ref-type="bibr" rid="c10">Cole <italic>et al</italic>., 2016</xref>; <xref ref-type="bibr" rid="c32">Ito <italic>et al</italic>., 2017</xref>) as the study-level average of regularized partial correlations among the resting state fMRI timeseries of m = 122 functional parcels of the BASC brain atlas (see Methods for details). We then used the standardized functional connectome as the <italic>w<sub>i,j</sub></italic> weights of a fully connected recurrent ANN, specifically a continuous-state Hopfield network (<xref ref-type="bibr" rid="c29">Hopfield, 1982</xref>; <xref ref-type="bibr" rid="c34">Koiran, 1994</xref>), consisting of <italic>m</italic> neural units, each having an activity <italic>α<sub>i</sub></italic> ∈ [−1,1] ⊂ R. Hopfield networks can be initialized by an arbitrary activation pattern (consisting of <italic>m</italic> activation values) and iteratively updated (i.e. “relaxed”) until their energy converges a local minimum, that is, to one of the finite number of attractor states (see Methods). The relaxation procedure is based on a simple rule; in each iteration, the activity of a region is constructed as the weighted average of the activities of all other regions, with weights defined by the connectivity between them. The average is then transformed by a sigmoidal activation function, to keep it in the desired [-1,1] interval. This can be expressed by the following equation:
<disp-formula id="eqn1">
<graphic xlink:href="565516v3_eqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>where <italic>α<sub>i</sub></italic>’ is the activity of neural unit <italic>i</italic> in the next iteration and (S/<italic>α<sub>j</sub></italic>) is the sigmoidal activation function (<italic>S</italic>(<italic>α</italic>) = <italic>tanh</italic>(<italic>α</italic>)) in our implementation) and <italic>b<sub>i</sub></italic> is the bias of unit <italic>i</italic> and β is the so-called temperature parameter. For the sake of simplicity, we set <italic>b<sub>i</sub></italic> = 0 in all our experiments. We refer to this architecture as a functional connectivity-based Hopfield Neural Network (fcHNN). The relaxation of a fcHNN model can be conceptualized as the repeated application of the activity flow principle (<xref ref-type="bibr" rid="c10">Cole <italic>et al</italic>., 2016</xref>; <xref ref-type="bibr" rid="c32">Ito <italic>et al</italic>., 2017</xref>), simultaneously for all regions: <inline-formula><inline-graphic xlink:href="565516v3_inline1.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. The update rule also exhibits analogies with network control theory (<xref ref-type="bibr" rid="c22">Gu <italic>et al</italic>., 2015</xref>) and the inner workings of neural mass models, as applied e.g. in dynamic causal modeling (<xref ref-type="bibr" rid="c11">Daunizeau <italic>et al</italic>., 2012</xref>). Hopfield networks assign an energy value to each possible activity configuration (<xref ref-type="bibr" rid="c29">Hopfield, 1982</xref>; <xref ref-type="bibr" rid="c34">Koiran, 1994</xref>), which decreases during the relaxation procedure until reaching an equilibrium state with minimal energy (<xref rid="fig2" ref-type="fig">Figure 2A</xref>, top panel). We used a sufficiently large number of random initializations (n=100000) to obtain all possible attractor states of the connectome-based Hopfield network in study 1 (<xref rid="fig2" ref-type="fig">Figure 2A</xref>, bottom panel). Consistent with theoretical expectations, we observed that increasing the temperature parameter β led to an increasing number of attractor states (<xref rid="fig2" ref-type="fig">Figure 2E</xref>, left, Supplementary Figure 3), appearing in symmetric pairs (i.e. <inline-formula><inline-graphic xlink:href="565516v3_inline2.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, see <xref rid="fig2" ref-type="fig">Figure 2G</xref>).</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Attractor states and state-space dynamics of connectome-based Hopfield networks</title>
<p><bold>(A)</bold> Top: During so-called relaxation procedure, activities in the nodes of an fcHNN model are iteratively updated based on the activity of all other regions and the connectivity between them. The energy of a connectome-based Hopfield network decreases during the relaxation procedure until reaching an equilibrium state with minimal energy, i.e. an attractor state. Bottom: Four attractor states of the fcHNN derived from the group-level functional connectivity matrix from study 1 (n=44). <bold>(B)</bold> Top: In presence of weak noise (stochastic update), the system does not converge to equilibrium anymore. Instead, activity traverses on the state landscape in a way restricted by the topology of the connectome and the “gravitational pull” of the attractor states. Bottom: We sample the “state landscape” by running the stochastic relaxation procedure for an extended amount of time (e.g. 100.000 consecutive stochastic updates), each point representing an activation configuration or state. To construct a low-dimensional representation of the state space, we take the first two principal components of the simulated activity patterns. The first two principal components explain approximately 58-85% of the variance of state energy (depending on the noise parameter σ, see Supplementary Figure 1). <bold>(C)</bold> We map all states of the state space sample to their corresponding attractor state, with the conventional Hopfield relaxation procedure (A). The four attractor states are also visualized in their corresponding position on the PCA-based projection. The first two principal components yield a clear separation of the attractive state basins (cross-validated classification accuracy: 95.5%, Supplementary Figure 2). We refer to the resulting visualization as the fcHNN projection and use it to visualize fcHNN-derived and empirical brain dynamics throughout the rest of the manuscript. <bold>(D)</bold> The fcHNN of study 1 seeded with real activation maps (gray dots) of an example participant. All activation maps converge to one of the four attractor states during the relaxation procedure (without noise) and the system reaches equilibrium. Trajectories are colored by attractor state. <bold>(E)</bold> Illustration of the stochastic relaxation procedure in the same fcHNN model, seeded from a single starting point (activation pattern). The system does not converge to an attractor state but instead traverses the state space in a way restricted by the topology of the connectome and the “gravitational pull” of the attractor states. The shade of the trajectory changes with increasing number of iterations. The trajectory is smoothed with a moving average over 10 iterations for visualization purposes. <bold>(F)</bold> Real resting state fMRI data of an example participant from study 1, plotted on the fcHNN projection. The shade of the trajectory changes with an increasing number of iterations. The trajectory is smoothed with a moving average over 10 iterations for visualization purposes. <bold>(G)</bold> Consistent with theoretical expectations, we observed that increasing the temperature parameter β led to an increasing number of attractor states, emerging in a nested fashion (i.e. the basin of a new attractor state is fully contained within the basin of a previous one). When contrasting the functional connectome-based HNN with a null model based on symmetry-retaining permuted variations of the connectome, we found that the topology of the original (unpermuted) functional brain connectome makes it significantly better suited to function as an attractor network; than the permuted null model. Table contains the median number of iterations until convergence for the original and permuted connectomes for different temperature parameters β and the corresponding p-value. <bold>(H)</bold> We optimized the noise parameter σ of the stochastic relaxation procedure for 8 different σ values over a logarithmic range between σ = 0.1 and 1 so that the similarity (the timeframes distribution over the attractor basins) is maximized between the empirical data and the fcHNN-generated data. We used two null models to assess the significance of similarity: one based on multivariate normal data, with the covariance matrix set to the functional connectome’s covariance matrix, and one based on spatial phase-randomization. P-values are given in the table at the bottom of the panel. The fcHNN only reached multistability with σ &gt; 0.19, and it provided the most accurate reconstruction of the real data with σ = 0.37 (p=0.007, and p&lt;0.001 for the two null models).</p></caption>
<graphic xlink:href="565516v3_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>FcHNNs, without any modifications, always converge to an equilibrium state. To incorporate stochastic fluctuations in neuronal activity (<xref ref-type="bibr" rid="c51">Robinson <italic>et al</italic>., 2005</xref>), we introduced weak Gaussian noise to the fcHNN relaxation procedure. This procedure, referred to as stochastic relaxation, prevents the system from reaching equilibrium and, somewhat similarly to stochastic DCM (<xref ref-type="bibr" rid="c11">Daunizeau <italic>et al</italic>., 2012</xref>), induces complex, heteroclinic system dynamics (<xref rid="fig2" ref-type="fig">Figure 2B</xref>). In order to enhance interpretability, we obtained the first two principal components (PCs) of the states sampled from the stochastic relaxation procedure. On the low-dimensional embedding, which we refer to as the <italic>fcHNN</italic> projection, we observed a clear separation of the attractor states (<xref rid="fig2" ref-type="fig">Figure 2C</xref>), with the two symmetric pairs of attractor states located at the extremes of the first and second PC. To map the attractors’ basins on the space spanned by the first two PCs (<xref rid="fig2" ref-type="fig">Figure 2C</xref>), we obtained the attractor state of each point visited during the stochastic relaxation and fit a multinomial logistic regression model to predict the attractor state from the first two PCs. The resulting model accurately predicted attractor states of arbitrary brain activity patterns, achieving a cross-validated accuracy of 96.5% (permutation-based p&lt;0.001). The attractor basins were visualized by using the decision boundaries obtained from this model. (<xref rid="fig2" ref-type="fig">Figure 2C</xref>). We propose the 2-dimensional fcHNN projection depicted on (<xref rid="fig2" ref-type="fig">Figure 2C</xref>) as a simplified representation of brain dynamics and use it as a basis for all subsequent analyses in this work.</p>
<p>Panel D on <xref rid="fig2" ref-type="fig">Figure 2</xref> uses the fcHNN projection to visualize the conventional Hopfield relaxation procedure. It depicts the trajectory of individual activation maps (sampled randomly from the timeseries data in Study 1) until converging to one of the four attractor states. Panel E shows that the system will no longer converge to an attractor state if weak noise is introduced to the system (stochastic relaxation). The resulting path is still influenced by the attractor states’ gravity, producing heteroclinic dynamics that resemble the empirical timeseries data (example data on panel F).</p>
<p>In study 1, we have investigated the convergence process of the functional connectivity-based HNN and contrasted it with a null model based on permuted variations of the connectome (while retaining the symmetry of the matrix). This null model preserves the sparseness and the degree distribution of the connectome, but destroys its topological structure (e.g. clusteredness). We found that the topology of the original (unpermuted) functional brain connectome makes it significantly better suited to function as an attractor network compared to the permuted null model. While the original connectome based HNN converged to an attractor state in less than 150 iterations in more than 50% of the cases, the null model did not reach convergence in more than 98% of the cases, even after 10000 iterations (<xref rid="fig2" ref-type="fig">Figure 2G</xref>, Supplementary Figure 4). This result was robustly observed, independent of the temperature parameter beta. We set the temperature parameter for the rest of the paper to a value providing the fastest convergence (β = 0.4, median iterations: 107), resulting in 4 distinct attractor states. The primary motivation for selecting β = 0.4 was to reduce computational burden for further analyses. However, as with increasing temperature, attractor states emerge in a nested fashion (i.e. the basin of a new attractor state is fully contained within the basin of a previous one), we expect that the results of the following analyses would be, although more detailed, but qualitatively similar with higher β values.</p>
<p>We optimized the noise parameter σ of the stochastic relaxation procedure for 8 different σ values over a logarithmic range between σ = 0.1 and 1 so that the similarity (the timeframes distribution over the attractor basins) is maximized between the empirical data and the fcHNN-generated data. We contrasted this similarity with two null-models (<xref rid="fig2" ref-type="fig">Figure 2H</xref>). First, we generated null-data as random draws from a multivariate normal distribution with co-variance matrix set to the functional connectome’s covariance matrix (partial correlation-based connectivity estimates). This serves as a baseline for generating data that optimally matches the empirical data in terms of distribution and spatial autocorrelation, as based on information on the underlying co-variance structure (and given Gaussian assumptions), but without any mechanistic model of the generative process, e.g. without modelling any non-linear and non-Gaussian effects and temporal autocorrelations stemming from recurrent activity flow. We found that the fcHNN only reached multistability with σ &gt; 0.19, and it provided more accurate reconstruction of the real data than the null model for σ = 0.37 and σ = 0.52 (p=0.007 and 0.015, χ<sup>)</sup> dissimilarity: 11.16 and 21.57, respectively). With our second null model, we investigated whether the fcHNN-reconstructed data is more similar to the empirical data than synthetic data with identical spatial autocorrelation structure (generated by spatial phase randomization of the original volumes, see Methods). We found that the fcHNNs significantly outperform this null model with all investigated σ values if σ ≥ 0.37 (p&lt;0.001 for all). Based on this coarse optimization procedure, we set σ = 0.37 for all subsequent analyses.</p>
</sec>
<sec id="s2b">
<title>Reconstruction of resting state brain dynamics</title>
<p>The spatial patterns of the obtained attractor states exhibit high neuroscientific relevance and closely resemble previously described large-scale brain systems (<xref rid="fig3" ref-type="fig">Figure 3A</xref>). The first pair of attractors (mapped on PC1, horizontal axis) represent two complementary brain systems, that have been previously found in anatomical, functional, developmental, and evolutionary hierarchies, as well as gene expression, metabolism, and blood flow, (see <xref ref-type="bibr" rid="c58">Sydnor <italic>et al</italic>., 2021</xref> for a review), an reported under various names, like intrinsic and extrinsic systems (<xref ref-type="bibr" rid="c19">Golland <italic>et al</italic>., 2008</xref>), Visual-Sensorimotor-Auditory and Parieto-Temporo-Frontal “rings” (<xref ref-type="bibr" rid="c9">Cioli <italic>et al</italic>., 2014</xref>), “primary” brain states (<xref ref-type="bibr" rid="c7">Chen <italic>et al</italic>., 2018</xref>), unimodal-to-transmodal principal gradient (<xref ref-type="bibr" rid="c40">Margulies <italic>et al</italic>., 2016</xref>; <xref ref-type="bibr" rid="c30">Huntenburg <italic>et al</italic>., 2018</xref>) or sensorimotor-association axis (<xref ref-type="bibr" rid="c58">Sydnor <italic>et al</italic>., 2021</xref>). A common interpretation of these two patterns is that they represent (i) an “extrinsic” system linked to the immediate sensory environment and (ii) an “intrinsic” system for higher-level internal context, commonly referred to as the default mode network (<xref ref-type="bibr" rid="c48">Raichle <italic>et al</italic>., 2001</xref>). The other pair of attractors span an orthogonal axis and resemble to patterns commonly associated with perception–action cycles (<xref ref-type="bibr" rid="c18">Fuster, 2004</xref>), and described as a gradient across sensory-motor modalities (<xref ref-type="bibr" rid="c30">Huntenburg <italic>et al</italic>., 2018</xref>), recruiting regions associated with active (e.g. motor cortices) and perceptual inference (e.g. visual areas).</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3:</label>
<caption><title>fcHNNs reconstruct characteristics of real resting state brain activity.</title>
<p><bold>(A)</bold> The four attractor states of the fcHNN model from study 1 reflect brain activation patterns with high neuroscientific relevance, representing sub-systems previously associated with “internal context” (blue), “external context” (yellow), “action” (red) and “perception” (green) (<xref ref-type="bibr" rid="c19">Golland <italic>et al</italic>., 2008</xref>; <xref ref-type="bibr" rid="c9">Cioli <italic>et al</italic>., 2014</xref>; <xref ref-type="bibr" rid="c7">Chen <italic>et al</italic>., 2018</xref>; <xref ref-type="bibr" rid="c18">Fuster, 2004</xref>; <xref ref-type="bibr" rid="c40">Margulies <italic>et al</italic>., 2016</xref>). <bold>(B)</bold> The attractor states show excellent replicability in two external datasets (study 2 and 3, mean correlation 0.93). <bold>(C)</bold> The fcHNN projection (first two PCs of the fcHNN state space) explains significantly more variance (p&lt;0.0001) in the real resting state fMRI data than principal components derived from the real resting state data itself and generalizes better (p&lt;0.0001) to out-of-sample data (study 2). Error bars denote 99% bootstrapped confidence intervals. <bold>(D)</bold> The fcHNN analysis reliably predicts various characteristics of real resting state fMRI data, such as the fraction of time spent in the basins of the four attractors (first column, p=0.007, contrasted to the multivariate normal null model), the distribution of the data on the fcHNN-projection (second column, p&lt;0.001, contrasted to the multivariate normal null model) and the temporal autocorrelation structure of the real data (third column, p&lt;0.001, contrasted to a null model based on temporally permuted data). This analysis was based on flow maps of the mean trajectories (i.e. the characteristic timeframe-to-timeframe transition direction) in fcHNN-generated data, as compared to a shuffled null model representing zero temporal autocorrelation. For more details, see Methods. Furthermore, (rightmost column), stochastic fcHNNs are capable of self-reconstruction: the timeseries resulting from the stochastic relaxation procedure mirror the co-variance structure of the functional connectome the fcHNN model was initialized with. While the self-reconstruction property in itself does not strengthen the face validity of the approach (no unknown information is reconstructed), it is a strong indicator of the model’s construct validity; i.e. that systems that behave like the proposed model inevitably “leak” their weights into the activity time series.</p></caption>
<graphic xlink:href="565516v3_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>The discovered attractor states demonstrate high replicability (mean Pearson’s correlation 0.93) across the discovery dataset (study 1) and two independent replication datasets (study 2 and 3, <xref rid="fig3" ref-type="fig">Figure 3C</xref>). Moreover, the attractor states were found to be significantly more robust to noisy weights, as compared to nodal strength scores (used as a reference, see Supplementary Figure 8 for details).</p>
<p>Further analysis in study 1 showed that connectome-based Hopfield models accurately reconstructed multiple characteristics of true resting-state data. First, the two axes (first two PCs) of the fcHNN projection accounted for a substantial amount of variance in the real resting-state fMRI data in study 1 (mean <italic>R</italic><sup>2</sup> = 0.399) and generalized well to out-of-sample data (study 2, mean <italic>R</italic><sup>2</sup> = 0.396) (<xref rid="fig3" ref-type="fig">Figure 3E</xref>). The explained variance of the fcHNN projection significantly exceeded that of the first two PCs derived directly from the real resting-state fMRI data itself (<italic>R</italic><sup>2</sup> = 0.37 and 0.364 for in- and out-of-sample analyses). Second, during stochastic relaxation, the fcHNN model was found to spend approximately three-quarters of the time in the basins of the first two attractor states and one-quarter on the basis of the second pair of attractor states (approximately equally distributed between pairs). We observed similar temporal occupancies in the real data <xref rid="fig3" ref-type="fig">Figure 3D</xref> left column), statistically significant with two different null models (Supplementary Figure 5). Fine-grained details of the bimodal distribution observed in the real resting-state fMRI data were also convincingly reproduced by the fcHNN model (<xref rid="fig3" ref-type="fig">Figure 3F</xref> and <xref rid="fig2" ref-type="fig">Figure 2D</xref>, second column). Third, not only spatial activity patterns, but also timeseries generated by the fcHNN are similar to empirical timeseries data. Next to the visual similarity shown on <xref rid="fig2" ref-type="fig">Figure 2E and F</xref>, we observed a statistically significant similarity between the average trajectories of fcHNN-generated and real timeseries “flow” (i.e. the characteristic timeframe-to-timeframe transition direction), as compared to null-models of zero temporal autocorrelation (randomized timeframe order, <xref rid="fig3" ref-type="fig">Figure 3D</xref>, third column Methods for analysis details). Finally, fcHNNs were found to generate signal that preserves the covariance structure of the real functional connectome, indicating that dynamic systems of this type (including the brain) inevitably “leak” their underlying structure into the activity time series, strengthening the construct validity of our approach (<xref rid="fig3" ref-type="fig">Figure 3D</xref>).</p>
</sec>
<sec id="s2c">
<title>An explanatory framework for task-based brain activity</title>
<p>Next to reproducing various characteristics of spontaneous brain dynamics, fcHNNs can also be used to model responses to various perturbations. We obtained task-based fMRI data from a study by <xref ref-type="bibr" rid="c61">Woo <italic>et al</italic>. (2015)</xref> (study 4, n=33, see <xref rid="fig3" ref-type="fig">Figure 3</xref>), investigating the neural correlates of pain and its self-regulation. We found that activity changes due to pain (taking into account hemodynamics, see Methods) were characterized on the fcHNN projection by a shift towards the attractor state of action/execution (permutation test for mean projection difference by randomly swapping conditions, p&lt;0.001, <xref rid="fig4" ref-type="fig">Figure 4A</xref>, left). Energies, as defined by the fcHNN, were also significantly different between the two conditions (p&lt;0.001), with higher energies during pain stimulation. When participants were instructed to up- or downregulate their pain sensation (resulting in increased and decreased pain reports and differential brain activity in the nucleus accumbens, NAc (see <xref ref-type="bibr" rid="c61">Woo <italic>et al</italic>., 2015</xref> for details), we observed further changes of the location of momentary brain activity patterns on the fcHNN projection (p&lt;0.001, <xref rid="fig4" ref-type="fig">Figure 4A</xref>, right), with downregulation pulling brain dynamics towards the attractor state of internal context and perception. Interestingly, self-regulation did not trigger significant energy changes (p=0.36).</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4:</label>
<caption><title>Empirical Hopfield-networks reconstruct real task-based brain activity.</title>
<p><bold>A</bold> Functional MRI time-frames during pain stimulation from study 4 (second fcHNN projection plot) and self-regulation (third and fourth) are distributed differently on the fcHNN projection than brain states during rest (first projection, permutation test, p&lt;0.001 for all). Energies, as defined by the Hopfield model, are also significantly different between rest and the pain conditions (permutation test, p&lt;0.001), with higher energies during pain stimulation. Triangles denote participant-level mean activations in the various blocks (corrected for hemodynamics). Small circle plots show the directions of the change for each individual (points) as well as the mean direction across participants (arrow), as compared to the reference state (downregulation for the last circle plot, rest for all other circle plots). <bold>B</bold> Flow-analysis (difference in the average timeframe-to-timeframe transition direction) reveals a non-linear difference in brain dynamics during pain and rest (left). When introducing weak pain-related signal in the fcHNN model during stochastic relaxation, it accurately reproduces these non-linear flow differences (right). <bold>C</bold> Simulating activity in the Nucleus Accumbens (NAc) (the region showing significant activity differences in <xref ref-type="bibr" rid="c61">Woo <italic>et al</italic>., 2015</xref>) reconstructs the observed non-linear flow difference between up- and downregulation (left). <bold>D</bold> Schematic representation of brain dynamics during pain and its up- and downregulation, visualized on the fcHNN projection. In the proposed framework, pain does not simply elicit a direct response in certain regions, but instead, shifts spontaneous brain dynamics towards the “action” attractor, converging to a characteristic “ghost attractor” of pain. Down-regulation by NAc activation exerts force towards the attractor of internal context, leading to the brain less frequent “visiting” pain-associated states. <bold>E</bold> Visualizing meta-analytic activation maps (see Supplementary Table 1 for details) on the fcHNN projection captures intimate relations between the corresponding tasks and <bold>F</bold> serves as a basis for a fcHNN-based theoretical interpretative framework for spontaneous and task-based brain dynamics. In the proposed framework, task-based activity is not a mere response to external stimuli in certain brain locations but a perturbation of the brain’s characteristic dynamic trajectories, constrained by the underlying functional connectivity. From this perspective, “activity maps” from conventional task-based fMRI analyses capture time-averaged differences in these whole brain dynamics.</p></caption>
<graphic xlink:href="565516v3_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Next, we conducted a “flow analysis” on the fcHNN projection, quantifying how the average timeframe-to-timeframe transition direction differs on the fcHNN projection between conditions (see Methods). This analysis unveiled that during pain (<xref rid="fig4" ref-type="fig">Figure 4B</xref>, left side), brain activity tends to gravitate towards a distinct point on the projection on the boundary the basins of the internal and action attractors, which we term the “ghost attractor” of pain (similar to <xref ref-type="bibr" rid="c60">Vohryzek <italic>et al</italic>., 2020</xref>). In case of downregulation (as compared to upregulation), brain activity is pulled away from the pain-related “ghost attractor” (<xref rid="fig4" ref-type="fig">Figure 4C</xref>, left side), towards the attractor of internal context. Our fcHNN was able to accurately reconstruct these non-linear dynamics by adding a small amount of realistic “control signal” (similarly to network control theory, see e.g. <xref ref-type="bibr" rid="c39">Liu <italic>et al</italic>., 2011</xref> and <xref ref-type="bibr" rid="c22">Gu <italic>et al</italic>., 2015</xref>). To simulate the alterations in brain dynamics during pain stimulation, we acquired a meta-analytic pain activation map (<xref ref-type="bibr" rid="c63">Zunhammer <italic>et al</italic>., 2021</xref>) (n=603) and incorporated it as a control signal added to each iteration of the stochastic relaxation procedure. The ghost attractor found in the empirical data was present across a relatively wide range of signal-to-noise (SNR) values (Supplementary Figure 6). Results with SNR=0.005 are presented on <xref rid="fig4" ref-type="fig">Figure 4B</xref>, right side (Pearson’s r = 0.46, p=0.005 based on randomizing conditions on a per-participant basis). The same model was also able to reconstruct the observed non-linear differences in brain dynamics between the up- and downregulation conditions (Pearson’s r = 0.62, p=0.023) without any further optimization (SNR=0.005, <xref rid="fig4" ref-type="fig">Figure 4C</xref>, right side). The only change we made to the model was the addition (downregulation) or subtraction (upregulation) of control signal in the NAc (the region in which (<xref ref-type="bibr" rid="c61">Woo <italic>et al</italic>., 2015</xref>) observed significant changes between up- and downregulation), introducing a signal difference of ΔSNR=0.005 (the same value we found optimal in the pain-analysis). Results were reproducible with lower NAc SNRs, too (Supplementary Figure 7).</p>
<p>To provide a comprehensive picture on how tasks and stimuli other than pain map onto the fcHNN projection, we obtained various task-based meta-analytic activation maps from Neurosynth (see Methods) and plotted them on the fcHNN projection (<xref rid="fig4" ref-type="fig">Figure 4E</xref>). This analysis reinforced and extended our interpretation of the four investigated attractor states and shed more light on how various functions are mapped on the axes of internal vs. external context and perception vs. action. In the coordinate system of the fcHNN projection, visual processing is labeled “external-perception”, sensory-motor processes fall into the “external-active” domain, language, verbal cognition and working memory belongs to the “internal-active” region and long-term memory as well as social and autobiographic schemata fall into the “internal-perception” regime (<xref rid="fig4" ref-type="fig">Figure 4F</xref>).</p>
</sec>
<sec id="s2d">
<title>Clinical relevance</title>
<p>We obtained data from n=172 autism spectrum disorder (ASD) and typically developing control (TDC) individuals, acquired at the New York University Langone Medical Center, New York, NY, USA (NYU) and generously shared in the Autism Brain Imaging Data Exchange dataset (study 7: ABIDE, (<xref ref-type="bibr" rid="c14">Di Martino <italic>et al</italic>., 2014</xref>). After excluding high-motion cases (with the same approach as in study 1-4, see Methods), we visualized the distribution of time-frames on the fcHNN-projection separately for the ASD and TDC groups (<xref rid="fig5" ref-type="fig">Figure 5A</xref>). First, we assigned all timeframes to one of the 4 attractor states with the fcHNN from study 1 and found several significant differences in the mean activity on the attractor basins (see Methods) of the ASD group as compared to the respective controls (<xref rid="fig5" ref-type="fig">Figure 5B</xref>). Strongest differences were found on the “action-perception” axis (<xref rid="tbl1" ref-type="table">Table 1</xref>), with increased activity of the sensory-motor and middle cingular cortices during “action-execution” related states and increased visual and decreased sensory and auditory activity during “perception” states, likely reflecting the widely acknowledged, yet poorly understood, perceptual atypicalities in ASD (<xref ref-type="bibr" rid="c23">Hadad &amp; Schwartz, 2019</xref>). ASD related changes in the internal-external axis were characterized by more involvement of the posterior cingulate, the precuneus, the nucleus accumbens, the dorsolateral prefrontal cortex (dlPFC), the cerebellum (Crus II, lobule VII) and inferior temporal regions during activity of the internalizing subsystem (<xref rid="tbl1" ref-type="table">Table 1</xref>). While similar, default mode network (DMN)-related changes have often been attributed to an atypical integration of information about the “self” and the “other” (<xref ref-type="bibr" rid="c46">Padmanabhan <italic>et al</italic>., 2017</xref>), a more detailed fcHNN-analysis may help to further disentangle the specific nature of these changes.</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5:</label>
<caption><title>Connectome-based Hopfield analysis of autism spectrum disorder.</title>
<p><bold>(A)</bold> The distribution of time-frames on the fcHNN-projection separately for ASD patients and typically developing control (TDC) participants. <bold>(B)</bold> We quantified attractor state activations in the Autism Brain Imaging Data Exchange datasets (study 7) as the individual-level mean activation of all time-frames belonging to the same attractor state. This analysis captured alterations similar to those previously associated to ASD-related perceptual atypicalities (visual, auditory and somatosensory cortices) as well as atypical integration of information about the “self” and the “other” (default mode network regions). All results are corrected for multiple comparisons across brain regions and attractor states (122*4 comparisons) with Bonferroni-correction. See <xref rid="tbl1" ref-type="table">Table 1</xref> and Supplementary Figure 9 for detailed results. <bold>(C)</bold> The comparison of data generated by fcHNNs initialized with ASD and TDC connectomes, respectively, revealed a characteristic pattern of differences in the system’s dynamics, with increased pull towards (and potentially a higher separation between) the action and perception attractors and a lower tendency of trajectories going towards the internal and external attractors. <bold><italic>Abbreviations</italic></bold>: MCC: middle cingulate cortex, ACC: anterior cingulate cortex, pg: perigenual, PFC: prefrontal cortex, dm: dorsomedial, dl: dorsolateral, STG: superior temporal gyrus, ITG: inferior temporal gyrus, Caud/Acc: caudate-accumbens, SM: sensorimotor, V1: primary visual, A1: primary auditory, SMA: supplementary motor cortex, ASD: autism spectrum disorder, TDC: typically developing control.</p></caption>
<graphic xlink:href="565516v3_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><title>The top ten largest changes in average attractor-state activity between autistic and control individuals.</title><p>Mean attractor-state activity changes are presented in the order of their absolute effect size. All p-values are based on permutation tests (shuffling the group assignment) and corrected for multiple comparisons (via Bonferroni’s correction). For a comprehensive list of significant findings, see Supplementary Figure 9.</p></caption>
<graphic xlink:href="565516v3_tbl1.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<p>Thus, we contrasted the characteristic trajectories derived from the fcHNN models of the two groups (initialized with the group-level functional connectomes). Our fcHNN-based flow analysis predicted that in ASD, there is an increased likelihood of states returning towards the middle (more noisy states) from the internal-external axis and an increased likelihood of states transitioning towards the extremes of the action-perception axis (<xref rid="fig5" ref-type="fig">Figure 5C</xref>). We observed a highly similar pattern in the real data (Pearson’s correlation: 0.66), statistically significant after permutation testing (shuffling the group assignment, p=0.009).</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>In this study, we have introduced and validated a simple and robust network-level generative computational framework that elucidates how activity propagation within the functional connectome orchestrates large-scale brain dynamics, leading to the spontaneous emergence of brain states, smooth gradients among them, and characteristic dynamic responses to perturbations.</p>
<p>The construct validity of our model is rooted in the activity flow principle, first introduced by <xref ref-type="bibr" rid="c10">Cole <italic>et al</italic>. (2016)</xref>. The activity flow principle states that activity in a brain region can be predicted by a weighted combination of the activity of all other regions, where the weights are set to the functional connectivity of those regions to the held-out region. This principle has been shown to hold across a wide range of experimental and clinical conditions (<xref ref-type="bibr" rid="c10">Cole <italic>et al</italic>., 2016</xref>; <xref ref-type="bibr" rid="c32">Ito <italic>et al</italic>., 2017</xref>; <xref ref-type="bibr" rid="c43">Mill <italic>et al</italic>., 2022</xref>; <xref ref-type="bibr" rid="c25">Hearne <italic>et al</italic>., 2021</xref>; <xref ref-type="bibr" rid="c7">Chen <italic>et al</italic>., 2018</xref>). The proposed approach is based on the intuition that the repeated, iterative application of the activity flow equation exhibits close analogies with a type of recurrent artificial neural networks, known as Hopfield networks (<xref ref-type="bibr" rid="c29">Hopfield, 1982</xref>). Hopfield networks have been widely acknowledged for their relevance for brain function, including the ability to store and recall memories (<xref ref-type="bibr" rid="c29">Hopfield, 1982</xref>), self-repair (<xref ref-type="bibr" rid="c45">Murre <italic>et al</italic>., 2003</xref>), a staggering robustness to noisy or corrupted inputs (<xref ref-type="bibr" rid="c27">Hertz <italic>et al</italic>., 1991</xref>) (see also Supplementary Figure 8) and the ability to produce multistable dynamics organized by the “gravitational pull” of a finite number of attractor states (<xref ref-type="bibr" rid="c33">Khona &amp; Fiete, 2022</xref>). While many of such properties of Hopfield networks have previously been proposed as a model for micro-scale neural systems (see <xref ref-type="bibr" rid="c33">Khona &amp; Fiete, 2022</xref> for a review), the proposed link between macro-scale activity propagation and Hopfield networks allows transferring the vast body of knowledge on Hopfield networks to the study of large-scale brain dynamics.</p>
<p>Integrating Cole’s activity flow principle with the HNN architecture mandates the initiation of network weights with functional connectivity values, specifically partial correlations as suggested by <xref ref-type="bibr" rid="c10">Cole <italic>et al</italic>. (2016)</xref>. Considering the functional connectome as weights of a neural network distinguishes our methodology from conventional biophysical and phenomenological computational modeling strategies, which usually rely on the structural connectome to model polysynaptic connectivity (<xref ref-type="bibr" rid="c5">Cabral <italic>et al</italic>., 2017</xref>; <xref ref-type="bibr" rid="c13">Deco <italic>et al</italic>., 2012</xref>; <xref ref-type="bibr" rid="c20">Golos <italic>et al</italic>., 2015</xref>; <xref ref-type="bibr" rid="c24">Hansen <italic>et al</italic>., 2015</xref>). Given the challenges of accurately modelling the structure-function coupling in the brain (<xref ref-type="bibr" rid="c55">Seguin <italic>et al</italic>., 2023</xref>), such models are currently limited in terms of reconstruction accuracy, hindering translational applications. By working with direct, functional MRI-based activity flow estimates, fcHNNs bypass the challenge of modelling the structural-functional coupling and are able to provide a more accurate representation of the brain’s dynamic activity propagation (although at the cost of losing the ability to provide biophysical details on the underlying mechanisms). Another advantage of the proposed model is its simplicity. While many conventional computational models rely on the optimization of a high number of free parameters, the basic form of the fcHNN approach comprises solely two, easily interpretable “hyperparameters” (temperature and noise) and yields notably consistent outcomes across an extensive range of these parameters (Supplementary Figure 1, 3, 5, 6, 7). To underscore the potency of this simplicity and stability, in the present work, we avoided any unnecessary parameter optimization, leaving a negligible chance of overfitting. It is likely, however, that extensive parameter optimization could further improve the accuracy of the model.</p>
<p>Further, the fcHNN approach allows us to leverage on knowledge about the underlying ANN architecture. Specifically, Hopfield attractor dynamics provide a mechanistic account for the emergence of large-scale canonical brain networks (<xref ref-type="bibr" rid="c62">Zalesky et al., 2014</xref>), and shed light to the origin of characteristic task-responses that are accounted by “ghost attractors” in the system (<xref ref-type="bibr" rid="c12">Deco &amp; Jirsa, 2012</xref>; <xref ref-type="bibr" rid="c60">Vohryzek <italic>et al</italic>., 2020</xref>). As fcHNNs do not need to be trained to solve any explicit tasks, they are well suited to examine spontaneous brain dynamics. However, it is worth mentioning that fcHNNs are compatible with the neuroconnectionist approach (Doerig et al., 2021), as well. Like any other ANNs, fcHNNs can also be further trained via established ANN training techniques (e.g. via the Hebbian learning rule) to “solve” various tasks or to match developmental dynamics or pathological alterations. In this promising future direction, the training procedure itself becomes part of the model, providing testable hypotheses about the formation, and various malformations, of brain dynamics.</p>
<p>Given its simplicity, it is noteworthy, how well the fcHNN model is able to reconstruct and predict brain dynamics under a wide range of conditions. First and foremost, we have found that the topology of the functional connectome seems to be well suited to function as an attractor network, as it converges much faster than permuted null models. Second, we found that the two-dimensional fcHNN projection can explain more variance in real resting state fMRI data than the first two principal components derived from the data itself. This may indicate that through the known noise tolerance of the underlying ANN architecture, fcHNNs are able to capture essential principles of the underlying dynamic processes even if our empirical measurements are corrupted by noise and low sampling rate. Indeed, fcHNN attractor states were found to be robust to noisy weights (Supplementary Figure 8) and highly replicable across datasets acquired at different sites, with different scanners and imaging sequences (study 2 and 3). The observed high level of replicability allowed us to re-use the fcHNN model constructed with the connectome of study 1 for all subsequent analyses, without any further fine-tuning or study-specific parameter optimization.</p>
<p>Conceptually, the notion of a global attractor model of the brain network is not new (<xref ref-type="bibr" rid="c16">Freeman, 1987</xref>; <xref ref-type="bibr" rid="c12">Deco &amp; Jirsa, 2012</xref>; <xref ref-type="bibr" rid="c60">Vohryzek <italic>et al</italic>., 2020</xref>; <xref ref-type="bibr" rid="c13">Deco <italic>et al</italic>., 2012</xref>; <xref ref-type="bibr" rid="c20">Golos <italic>et al</italic>., 2015</xref>; <xref ref-type="bibr" rid="c24">Hansen <italic>et al</italic>., 2015</xref>). The present work shows, however, that the brain as an attractor network necessarily ‘leaks its internal weights’ in form of the partial correlation across the regional timeseries. This indicates that, partial correlations across neural timeseries data from different regions (i.e. functional connectivity) may be a more straightforward entry point to investigating the brain’s attractor dynamics, than estimates of structural connectedness. Thereby, the fcHNN approach provides a simple and interpretable way to infer and investigate the attractor states of the brain, without the need for additional assumptions about the underlying biophysical details. This is a significant advantage, as the functional connectome can be easily and non-invasively acquired in humans, while biophysical details required by other models are hard to measure or estimate accurately. Furthermore, here we complement previous work on large-scale brain attractor dynamics, by demonstrating that the reconstructed attractor states are not solely local minima in the state-space but act as a driving force for the dynamic trajectories of brain activity. We argue that attractor dynamics may be the main driving factor for the spatial and temporal autocorrelation structure of the brain, recently described to be predictive of network topology in relation to age, subclinical symptoms of dementia, and pharmacological manipulations with serotonergic drugs (<xref ref-type="bibr" rid="c56">Shinn <italic>et al</italic>., 2023</xref>). Nevertheless, attractor states should not be confused with the conventional notion of brain states (<xref ref-type="bibr" rid="c6">Chen <italic>et al</italic>., 2015</xref>) and large-scale functional gradients (<xref ref-type="bibr" rid="c40">Margulies <italic>et al</italic>., 2016</xref>). In the fcHNN framework, attractor states can rather be conceptualized as “Platonic idealizations” of brain activity, that are continuously approximated - but never reached - by the brain, resulting in re-occurring patterns (brain states) and smooth gradual transitions (large-scale gradients).</p>
<p>Relying on previous work, we can establish a relatively straightforward (although somewhat speculative) correspondence between attractor states and brain function, mapping brain activation on the axes of internal vs. external context (<xref ref-type="bibr" rid="c19">Golland <italic>et al</italic>., 2008</xref>; <xref ref-type="bibr" rid="c9">Cioli <italic>et al</italic>., 2014</xref>), as well as perception vs. action (<xref ref-type="bibr" rid="c18">Fuster, 2004</xref>). This four-attractor architecture exhibits an appealing analogy with Friston’s free energy principle (<xref ref-type="bibr" rid="c17">Friston <italic>et al</italic>., 2006</xref>) that postulates the necessary existence of brain subsystems for active and perceptual inference and proposes that the dynamical dependencies that drive the flow of information in the brain can be represented with a hierarchically nested structure (e.g. external and internal subsystem) that may be an essential ingredient of conscious (<xref ref-type="bibr" rid="c49">Ramstead <italic>et al</italic>., 2023</xref>) and autonomous (<xref ref-type="bibr" rid="c37">Lee <italic>et al</italic>., 2023</xref>) agents. Resting and task states are often treated as separate phenomena, both conceptually and in terms of analysis practices. However, in the fcHNN framework, the differentiation between task and resting states is considered an artificial dichotomy. Task-based brain activity in the fcHNN framework is not a mere response to external stimuli in certain brain locations but a perturbation of the brain’s characteristic dynamic trajectories, with increased preference for certain locations on the energy landscape (“ghost attractors”). In our analyses, the fcHNN approach captured and predicted participant-level activity changes induced by pain and its self-regulation and gave a mechanistic account for how relatively small activity changes in a single region (NAcc) may result in a significantly altered pain experience. Our control-signal analysis is different from, but compatible with, linear network control theory-based approaches (<xref ref-type="bibr" rid="c39">Liu <italic>et al</italic>., 2011</xref>; <xref ref-type="bibr" rid="c22">Gu <italic>et al</italic>., 2015</xref>). Combining network control theory with the fcHNN approach could provide a powerful framework for understanding the effects of various tasks, conditions and interventions (e.g. brain stimulation) on brain dynamics.</p>
<p>Brain dynamics can not only be perturbed by task or other types of experimental or naturalistic interventions, but also by pathological alterations. Here we provide an initial demonstration (study 7) of how fcHNN-based analyses can characterize and predict altered brain dynamics in autism spectrum disorder (ASD). The observed ASD-associated changes in brain dynamics are indicative of a reduced ability to flexibly switch between perception and internal representations, corroborating previous findings that in ASD, sensory-driven connectivity transitions do not converge to transmodal areas (<xref ref-type="bibr" rid="c28">Hong <italic>et al</italic>., 2019</xref>). Such findings are in line with previous reports of a reduced influence of context on the interpretation of incoming sensory information in ASD (e.g. the violation of Weber’s law) (<xref ref-type="bibr" rid="c23">Hadad &amp; Schwartz, 2019</xref>).</p>
<p>Our findings open up a series of exciting opportunities for the better understanding of brain function in health and disease. First, the 2-dimensional fcHNN projection offers a simple framework not only for the visualization, but also for the <italic>interpretation</italic>, of brain activity patterns, as it conceptualizes changes related to various behavioral or clinical states or traits as a shift in brain dynamics in relation to brain attractor states. Second, fcHNN analyses may provide insights into the causes of changes in brain dynamics, by for instance, identifying the regions or connections that act as an “Achilles heel” in generating such changes. Such control analyses could, for instance, aid the differentiation of primary causes and secondary effects of activity or connectivity changes in various clinical conditions. Third, the fcHNN approach can provide testable predictions about the effects of pharmacological interventions as well as non-invasive brain stimulation (e.g. transcranial magnetic or direct current stimulation, focused ultrasound, etc.) and neurofeedback. Obtaining the optimal stimulation or treatment target within the fcHNN framework (e.g. by means of network control theory (<xref ref-type="bibr" rid="c39">Liu <italic>et al</italic>., 2011</xref>)) is one of the most promising future directions with the potential to significantly advance the development of novel, personalized treatment approaches.</p>
<p>The proposed approach is not without limitations. First, the fcHNN model is obviously a simplification of the brain’s dynamics, and it does not aim to explain (i) the brain’s ability to perform certain computations, (ii) brain regions’ ability to perform certain functions or (iii) biophysical details underlying (altered) polysynaptic connections. Nevertheless, our approach showcases that many characteristics of brain dynamics, like multistability, temporal autocorrelations, states and gradients, can be explained, and predicted, by a very simple nonlinear phenomenological model. Second, our model assumes a stationary connectome, which seems to contradict notions of dynamic connectivity. However, with realistically changing control signals, our model can easily reconstruct dynamic connectivity changes, which still stem from an underlying, stationary functional connectivity architecture. This is in line with the notion of “latent functional connectivity”; an intrinsic brain network architecture built up from connectivity properties that are persistent across brain states (<xref ref-type="bibr" rid="c41">McCormick <italic>et al</italic>., 2022</xref>).</p>
<p>In this initial work, we presented the simplest possible implementation of the fcHNN concept. It is clear that the presented analyses exploit only a small proportion of the richness of the full state-space dynamics reconstructed by the fcHNN model. There are many potential ways to further improve the utility of the fcHNN approach. Increasing the number of reconstructed attractor states (by increasing the temperature parameter), investigating higher-dimensional dynamics, fine-tuning the hyperparameters, testing the effect of different initializations and perturbations are all important direction for future work, with the potential to further improve the model’s accuracy and usefulness.</p>
</sec>
<sec id="s4">
<title>Conclusion</title>
<p>We have proposed a lightweight, high-level computational framework that accurately captures and predicts brain dynamics under a wide range of conditions, including resting states, task-induced activity changes and brain disorders. The framework models large-scale activity flow in the brain with a recurrent artificial neural network architecture that, instead of being trained to solve specific tasks or mimic certain dynamics, is simply initialized with the empirical functional connectome. The framework identifies neurobiologically meaningful attractor states and provides a model for how these restrict brain dynamics. The proposed model establishes a conceptual link between connectivity and activity, provides a mechanistic account for the emergence of brain states, gradients and temporal autocorrelation structure and offers a simple, robust, and highly interpretable computational alternative to conventional descriptive approaches to investigating brain function. The generative nature of our proposed model opens up a wealth of opportunities for future research, including predicting the effect, and understanding the mechanistic bases, of various interventions; thereby paving the way for designing novel treatment approaches.</p>
</sec>
<sec id="d1e1417" sec-type="supplementary-material">
<title>Supporting information</title>
<supplementary-material id="d1e1531">
<label>Supplementary Material</label>
<media xlink:href="supplements/565516_file02.pdf"/>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>The work was supported by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation; projects ‘TRR289 - Treatment Expectation’, ID 422744262 and ‘SFB1280 - Extinction Learning’, ID 316803389) and by IBS-R015-D1 (Institute for Basic Science; C.W.-W.).</p>
</ack>
<sec id="s6">
<title>Additional information</title>
<sec id="s6a">
<title>Analysis source code</title>
<p><ext-link ext-link-type="uri" xlink:href="https://github.com/pni-lab/connattractor">https://github.com/pni-lab/connattractor</ext-link></p>
</sec>
<sec id="s7">
<title>Project website</title>
<p><ext-link ext-link-type="uri" xlink:href="https://pni-lab.github.io/connattractor/">https://pni-lab.github.io/connattractor/</ext-link></p>
</sec>
<sec id="s8">
<title>Data availability</title>
<p>Study 1, 2 and 4 is available at <ext-link ext-link-type="uri" xlink:href="http://openneuro.org">openneuro.org</ext-link> (ds002608, ds002608, ds000140). Data for study 3 is available upon request. Data for study 5-6 is available at the github page of the project: <ext-link ext-link-type="uri" xlink:href="https://github.com/pni-lab/connattractor">https://github.com/pni-lab/connattractor</ext-link>. Study 7 is available at <ext-link ext-link-type="uri" xlink:href="https://fcon_1000.projects.nitrc.org/indi/abide/">https://fcon_1000.projects.nitrc.org/indi/abide/</ext-link>, preprocessed data is available at <ext-link ext-link-type="uri" xlink:href="http://preprocessed-connectomes-project.org">http://preprocessed-connectomes-project.org</ext-link><underline>/</underline>.</p>
</sec>
<sec id="s9">
<title>Declaration of interests</title>
<p>The authors declare no competing interests.</p>
</sec>
<sec id="s10">
<title>Declaration of generative AI and AI-assisted technologies in the writing process</title>
<p>During the preparation of this work the authors used ChatGPT 3.5 in order to improve language and readability of the manuscript. After using this tool/service, the authors reviewed and edited the content as needed and take full responsibility for the content of the publication.</p>
</sec>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Barttfeld</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Uhrig</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Sitt</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Sigman</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Jarraya</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Dehaene</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Signature of consciousness in the dynamics of resting-state brain activity</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>112</volume>(<issue>3</issue>), <fpage>887</fpage>–<lpage>892</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bassett</surname>, <given-names>D. S.</given-names></string-name>, &amp; <string-name><surname>Sporns</surname>, <given-names>O.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Network neuroscience</article-title>. <source>Nature Neuroscience</source>, <volume>20</volume>(<issue>3</issue>), <fpage>353</fpage>–<lpage>364</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Breakspear</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Dynamic models of large-scale brain activity</article-title>. <source>Nature Neuroscience</source>, <volume>20</volume>(<issue>3</issue>), <fpage>340</fpage>–<lpage>352</lpage>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Buzsaki</surname>, <given-names>G.</given-names></string-name></person-group> (<year>2006</year>). <source>Rhythms of the Brain</source>. <publisher-name>Oxford university press</publisher-name>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cabral</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Kringelbach</surname>, <given-names>M. L.</given-names></string-name>, &amp; <string-name><surname>Deco</surname>, <given-names>G</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Functional connectivity dynamically evolves on multiple time-scales over a static structural connectome: Models and mechanisms</article-title>. <source>NeuroImage</source>, <volume>160</volume>, <fpage>84</fpage>–<lpage>96</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname>, <given-names>J. E.</given-names></string-name>, <string-name><surname>Chang</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Greicius</surname>, <given-names>M. D.</given-names></string-name>, &amp; <string-name><surname>Glover</surname>, <given-names>G. H</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Introducing co-activation pattern metrics to quantify spontaneous brain network dynamics</article-title>. <source>Neuroimage</source>, <volume>111</volume>, <fpage>476</fpage>–<lpage>488</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname>, <given-names>R. H.</given-names></string-name>, <string-name><surname>Ito</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Kulkarni</surname>, <given-names>K. R.</given-names></string-name>, &amp; <string-name><surname>Cole</surname>, <given-names>M. W</given-names></string-name></person-group>. (<year>2018</year>). <article-title>The human brain traverses a common activation-pattern state space across task and rest</article-title>. <source>Brain Connectivity</source>, <volume>8</volume>(<issue>7</issue>), <fpage>429</fpage>–<lpage>443</lpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chiêm</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Crevecoeur</surname>, <given-names>F.</given-names></string-name>, &amp; <string-name><surname>Delvenne</surname>, <given-names>J.-C</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Structure-informed functional connectivity driven by identifiable and state-specific control regions</article-title>. <source>Network Neuroscience</source>, <volume>5</volume>(<issue>2</issue>), <fpage>591</fpage>–<lpage>613</lpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cioli</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Abdi</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Beaton</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Burnod</surname>, <given-names>Y.</given-names></string-name>, &amp; <string-name><surname>Mesmoudi</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2014</year>). <article-title>Differences in human cortical gene expression match the temporal properties of large-scale functional networks</article-title>. <source>PloS One</source>, <volume>9</volume>(<issue>12</issue>), <fpage>e115913</fpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cole</surname>, <given-names>M. W.</given-names></string-name>, <string-name><surname>Ito</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Bassett</surname>, <given-names>D. S.</given-names></string-name>, &amp; <string-name><surname>Schultz</surname>, <given-names>D. H</given-names></string-name></person-group>. (<year>2016</year>). <article-title>Activity flow over resting-state networks shapes cognitive task activations</article-title>. <source>Nature Neuroscience</source>, <volume>19</volume>(<issue>12</issue>), <fpage>1718</fpage>–<lpage>1726</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Daunizeau</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Stephan</surname>, <given-names>K. E.</given-names></string-name>, &amp; <string-name><surname>Friston</surname>, <given-names>K. J</given-names></string-name></person-group>. (<year>2012</year>). <article-title>Stochastic dynamic causal modelling of fMRI data: should we care about neural noise?</article-title> <source>Neuroimage</source>, <volume>62</volume>(<issue>1</issue>), <fpage>464</fpage>–<lpage>481</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Deco</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Jirsa</surname>, <given-names>V. K</given-names></string-name></person-group>. (<year>2012</year>). <article-title>Ongoing cortical activity at rest: criticality, multistability, and ghost attractors</article-title>. <source>Journal of Neuroscience</source>, <volume>32</volume>(<issue>10</issue>), <fpage>3366</fpage>–<lpage>3375</lpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Deco</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Senden</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Jirsa</surname>, <given-names>V</given-names></string-name></person-group>. (<year>2012</year>). <article-title>How anatomy shapes dynamics: a semi-analytical study of the brain at rest by a simple spin model</article-title>. <source>Frontiers in Computational Neuroscience</source>, <volume>6</volume>, <fpage>68</fpage>.</mixed-citation></ref>
    <ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Di Martino</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Yan</surname>, <given-names>C.-G.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Denio</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Castellanos</surname>, <given-names>F. X.</given-names></string-name>, <string-name><surname>Alaerts</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Anderson</surname>, <given-names>J. S.</given-names></string-name>, <string-name><surname>Assaf</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Bookheimer</surname>, <given-names>S. Y.</given-names></string-name>, <string-name><surname>Dapretto</surname>, <given-names>M.</given-names></string-name>, <etal>et al</etal></person-group>. (<year>2014</year>). <article-title>The autism brain imaging data exchange: towards a large-scale evaluation of the intrinsic brain architecture in autism</article-title>. <source>Molecular Psychiatry</source>, <volume>19</volume>(<issue>6</issue>), <fpage>659</fpage>–<lpage>667</lpage>.</mixed-citation></ref>
    <ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Doerig</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Sommers</surname>, <given-names>R. P.</given-names></string-name>, <string-name><surname>Seeliger</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Richards</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Ismael</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Lindsay</surname>, <given-names>G. W.</given-names></string-name>, <string-name><surname>Kording</surname>, <given-names>K. P.</given-names></string-name>, <string-name><surname>Konkle</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Van Gerven</surname>, <given-names>M. A.</given-names></string-name>, <string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name>, <etal>et al</etal></person-group>. (<year>2023</year>). <article-title>The neuroconnectionist research programme</article-title>. <source>Nature Reviews Neuroscience</source>, <fpage>1</fpage>–<lpage>20</lpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Freeman</surname>, <given-names>W. J</given-names></string-name></person-group>. (<year>1987</year>). <article-title>Simulation of chaotic EEG patterns with a dynamic model of the olfactory system</article-title>. <source>Biological Cybernetics</source>, <volume>56</volume>(<issue>2–3</issue>), <fpage>139</fpage>–<lpage>150</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Friston</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Kilner</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Harrison</surname>, <given-names>L</given-names></string-name></person-group>. (<year>2006</year>). <article-title>A free energy principle for the brain</article-title>. <source>Journal of Physiology-Paris</source>, <volume>100</volume>(<issue>1–3</issue>), <fpage>70</fpage>–<lpage>87</lpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fuster</surname>, <given-names>J. M</given-names></string-name></person-group>. (<year>2004</year>). <article-title>Upper processing stages of the perception–action cycle</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>8</volume>(<issue>4</issue>), <fpage>143</fpage>–<lpage>145</lpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Golland</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Golland</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Bentin</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Malach</surname>, <given-names>R</given-names></string-name></person-group>. (<year>2008</year>). <article-title>Data-driven clustering reveals a fundamental subdivision of the human cortex into two global systems</article-title>. <source>Neuropsychologia</source>, <volume>46</volume>(<issue>2</issue>), <fpage>540</fpage>–<lpage>553</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Golos</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Jirsa</surname>, <given-names>V.</given-names></string-name>, &amp; <string-name><surname>Daucé</surname>, <given-names>E</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Multistability in large scale models of brain activity</article-title>. <source>PLoS Computational Biology</source>, <volume>11</volume>(<issue>12</issue>), <fpage>e1004644</fpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Greene</surname>, <given-names>A. S.</given-names></string-name>, <string-name><surname>Horien</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Barson</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Scheinost</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Constable</surname>, <given-names>R. T</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Why is everyone talking about brain state?</article-title> <source>Trends in Neurosciences</source>.</mixed-citation></ref>
    <ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gu</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Pasqualetti</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Cieslak</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Telesford</surname>, <given-names>Q. K.</given-names></string-name>, <string-name><surname>Yu</surname>, <given-names>A. B.</given-names></string-name>, <string-name><surname>Kahn</surname>, <given-names>A. E.</given-names></string-name>, <string-name><surname>Medaglia</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Vettel</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>M. B.</given-names></string-name>, <string-name><surname>Grafton</surname>, <given-names>S. T.</given-names></string-name>, <etal>et al</etal></person-group>. (<year>2015</year>). <article-title>Controllability of structural brain networks</article-title>. <source>Nature Communications</source>, <volume>6</volume>(<issue>1</issue>), <fpage>8414</fpage>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hadad</surname>, <given-names>B.-S.</given-names></string-name>, &amp; <string-name><surname>Schwartz</surname>, <given-names>S</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Perception in autism does not adhere to Weber’s law</article-title>. <source>Elife</source>, <volume>8</volume>, <fpage>e42223</fpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hansen</surname>, <given-names>E. C.</given-names></string-name>, <string-name><surname>Battaglia</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Spiegler</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Deco</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Jirsa</surname>, <given-names>V. K.</given-names></string-name></person-group> (<year>2015</year>). <article-title>Functional connectivity dynamics: modeling the switching behavior of the resting state</article-title>. <source>Neuroimage</source>, <volume>105</volume>, <fpage>525</fpage>–<lpage>535</lpage>.</mixed-citation></ref>
    <ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hearne</surname>, <given-names>L. J.</given-names></string-name>, <string-name><surname>Mill</surname>, <given-names>R. D.</given-names></string-name>, <string-name><surname>Keane</surname>, <given-names>B. P.</given-names></string-name>, <string-name><surname>Repovš</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Anticevic</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Cole</surname>, <given-names>M. W</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Activity flow underlying abnormalities in brain activations and cognition in schizophrenia</article-title>. <source>Science Advances</source>, <volume>7</volume>(<issue>29</issue>), <elocation-id>eabf2513</elocation-id>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Heinz</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Murray</surname>, <given-names>G. K.</given-names></string-name>, <string-name><surname>Schlagenhauf</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Sterzer</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Grace</surname>, <given-names>A. A.</given-names></string-name>, &amp; <string-name><surname>Waltz</surname>, <given-names>J. A</given-names></string-name></person-group>. (<year>2019</year>). <article-title>Towards a unifying cognitive, neurophysiological, and computational neuroscience account of schizophrenia</article-title>. <source>Schizophrenia Bulletin</source>, <volume>45</volume>(<issue>5</issue>), <fpage>1092</fpage>–<lpage>1100</lpage>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hertz</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Krogh</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Palmer</surname>, <given-names>R. G</given-names></string-name></person-group>. (<year>1991</year>). <article-title>Introduction to the Theory of Neural Computation, chapter 7</article-title>. <source>Lecture Notes</source>, <volume>1</volume>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hong</surname>, <given-names>S.-J.</given-names></string-name>, <string-name><given-names>Vos</given-names> <surname>de Wael</surname></string-name>, <string-name><given-names>R.</given-names>, <surname>Bethlehem</surname></string-name>, <string-name><given-names>R. A.</given-names>, <surname>Lariviere</surname></string-name>, <string-name><given-names>S.</given-names>, <surname>Paquola</surname></string-name>, <string-name><given-names>C.</given-names>, <surname>Valk</surname></string-name>, <string-name><given-names>S. L.</given-names>, <surname>Milham</surname></string-name>, <string-name><given-names>M. P.</given-names>, <surname>Di Martino</surname></string-name>, <string-name><given-names>A.</given-names>, <surname>Margulies</surname></string-name>, <string-name><given-names>D. S.</given-names>, <surname>Smallwood</surname></string-name>, <string-name><given-names>J.</given-names>, &amp; <surname>others</surname></string-name></person-group>. (<year>2019</year>). <article-title>Atypical functional connectome hierarchy in autism</article-title>. <source>Nature Communications</source>, <volume>10</volume>(<issue>1</issue>), <fpage>1022</fpage>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hopfield</surname>, <given-names>J. J</given-names></string-name></person-group>. (<year>1982</year>). <article-title>Neural networks and physical systems with emergent collective computational abilities</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>79</volume>(<issue>8</issue>), <fpage>2554</fpage>–<lpage>2558</lpage>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huntenburg</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Bazin</surname>, <given-names>P.-L.</given-names></string-name>, &amp; <string-name><surname>Margulies</surname>, <given-names>D. S</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Large-scale gradients in human cortical organization</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>22</volume>(<issue>1</issue>), <fpage>21</fpage>–<lpage>31</lpage>.</mixed-citation></ref>
    <ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hutchison</surname>, <given-names>R. M.</given-names></string-name>, <string-name><surname>Womelsdorf</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Allen</surname>, <given-names>E. A.</given-names></string-name>, <string-name><surname>Bandettini</surname>, <given-names>P. A.</given-names></string-name>, <string-name><surname>Calhoun</surname>, <given-names>V. D.</given-names></string-name>, <string-name><surname>Corbetta</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Della Penna</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Duyn</surname>, <given-names>J. H.</given-names></string-name>, <string-name><surname>Glover</surname>, <given-names>G. H.</given-names></string-name>, <string-name><surname>Gonzalez-Castillo</surname>, <given-names>J.</given-names></string-name>, <etal>et al</etal></person-group>. (<year>2013</year>). <article-title>Dynamic functional connectivity: promise, issues, and interpretations</article-title>. <source>Neuroimage</source>, <volume>80</volume>, <fpage>360</fpage>–<lpage>378</lpage>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ito</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Kulkarni</surname>, <given-names>K. R.</given-names></string-name>, <string-name><surname>Schultz</surname>, <given-names>D. H.</given-names></string-name>, <string-name><surname>Mill</surname>, <given-names>R. D.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>R. H.</given-names></string-name>, <string-name><surname>Solomyak</surname>, <given-names>L. I.</given-names></string-name>, &amp; <string-name><surname>Cole</surname>, <given-names>M. W</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Cognitive task information is transferred between brain regions via resting-state network topology</article-title>. <source>Nature Communications</source>, <volume>8</volume>(<issue>1</issue>), <fpage>1027</fpage>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Khona</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Fiete</surname>, <given-names>I. R</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Attractor and integrator networks in the brain</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>23</volume>(<issue>12</issue>), <fpage>744</fpage>–<lpage>766</lpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Koiran</surname>, <given-names>P</given-names></string-name></person-group>. (<year>1994</year>). <article-title>Dynamics of discrete time, continuous state Hopfield networks</article-title>. <source>Neural Computation</source>, <volume>6</volume>(<issue>3</issue>), <fpage>459</fpage>–<lpage>468</lpage>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kriegeskorte</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Douglas</surname>, <given-names>P. K</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Cognitive computational neuroscience</article-title>. <source>Nature Neuroscience</source>, <volume>21</volume>(<issue>9</issue>), <fpage>1148</fpage>–<lpage>1160</lpage>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krotov</surname>, <given-names>D</given-names></string-name></person-group>. (<year>2023</year>). <article-title>A new frontier for Hopfield networks</article-title>. <source>Nature Reviews Physics</source>, <fpage>1</fpage>–<lpage>2</lpage>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lee</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Oh</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>An</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Yoon</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Friston</surname>, <given-names>K. J.</given-names></string-name>, <string-name><surname>Hong</surname>, <given-names>S. J.</given-names></string-name>, &amp; <string-name><surname>Woo</surname>, <given-names>C.-W</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Life-inspired Interoceptive Artificial Intelligence for Autonomous and Adaptive Agents</article-title>. <source>arXiv</source> Preprint arXiv:2309.05999.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname>, <given-names>X.</given-names></string-name>, &amp; <string-name><surname>Duyn</surname>, <given-names>J. H</given-names></string-name></person-group>. (<year>2013</year>). <article-title>Time-varying functional network information extracted from brief instances of spontaneous brain activity</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>110</volume>(<issue>11</issue>), <fpage>4392</fpage>–<lpage>4397</lpage>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname>, <given-names>Y.-Y.</given-names></string-name>, <string-name><surname>Slotine</surname>, <given-names>J.-J.</given-names></string-name>, &amp; <string-name><surname>Barabási</surname>, <given-names>A.-L</given-names></string-name></person-group>. (<year>2011</year>). <article-title>Controllability of complex networks</article-title>. <source>Nature</source>, <volume>473</volume>(<issue>7346</issue>), <fpage>167</fpage>– <lpage>173</lpage>.</mixed-citation></ref>
    <ref id="c40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Margulies</surname>, <given-names>D. S.</given-names></string-name>, <string-name><surname>Ghosh</surname>, <given-names>S. S.</given-names></string-name>, <string-name><surname>Goulas</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Falkiewicz</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Huntenburg</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Langs</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Bezgin</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Eickhoff</surname>, <given-names>S. B.</given-names></string-name>, <string-name><surname>Castellanos</surname>, <given-names>F. X.</given-names></string-name>, <string-name><surname>Petrides</surname>, <given-names>M.</given-names></string-name>, <etal>et al</etal></person-group>. (<year>2016</year>). <article-title>Situating the default-mode network along a principal gradient of macroscale cortical organization</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>113</volume>(<issue>44</issue>), <fpage>12574</fpage>– <lpage>12579</lpage>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McCormick</surname>, <given-names>E. M.</given-names></string-name>, <string-name><surname>Arnemann</surname>, <given-names>K. L.</given-names></string-name>, <string-name><surname>Ito</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Hanson</surname>, <given-names>S. J.</given-names></string-name>, &amp; <string-name><surname>Cole</surname>, <given-names>M. W</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Latent functional connectivity underlying multiple brain states</article-title>. <source>Network Neuroscience</source>, <volume>6</volume>(<issue>2</issue>), <fpage>570</fpage>–<lpage>590</lpage>. <pub-id pub-id-type="doi">10.1162/netn_a_00234</pub-id></mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Meer</surname>, <given-names>J. N. van der</given-names></string-name>, <string-name><surname>Breakspear</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Chang</surname>, <given-names>L. J.</given-names></string-name>, <string-name><surname>Sonkusare</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Cocchi</surname>, <given-names>L</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Movie viewing elicits rich and reliable brain state dynamics</article-title>. <source>Nature Communications</source>, <volume>11</volume>(<issue>1</issue>), <fpage>5004</fpage>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mill</surname>, <given-names>R. D.</given-names></string-name>, <string-name><surname>Hamilton</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Winfield</surname>, <given-names>E. C.</given-names></string-name>, <string-name><surname>Lalta</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>R. H.</given-names></string-name>, &amp; <string-name><surname>Cole</surname>, <given-names>M. W</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Network modeling of dynamic brain interactions predicts emergence of neural information that supports human cognitive behavior</article-title>. <source>PLoS Biology</source>, <volume>20</volume>(<issue>8</issue>), <fpage>e3001686</fpage>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Murray</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Demirtaş</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Anticevic</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2018</year>). <article-title>Biophysical modeling of large-scale brain dynamics and applications for computational psychiatry</article-title>. <source>Biological Psychiatry: Cognitive Neuroscience and Neuroimaging</source>, <volume>3</volume>(<issue>9</issue>), <fpage>777</fpage>–<lpage>787</lpage>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Murre</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Griffioen</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Robertson</surname>, <given-names>I</given-names></string-name></person-group>. (<year>2003</year>). <article-title>Selfreparing neural networks: a model for recovery from brain damage</article-title>. <source>Knowledge-Based Intelligent Information and Engineering Systems: 7th International Conference, KES 2003, Oxford, UK, September 2003. Proceedings</source><italic>, Part II 7</italic>, <fpage>1164</fpage>–<lpage>1171</lpage>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Padmanabhan</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Lynch</surname>, <given-names>C. J.</given-names></string-name>, <string-name><surname>Schaer</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Menon</surname>, <given-names>V</given-names></string-name></person-group>. (<year>2017</year>). <article-title>The default mode network in autism</article-title>. <source>Biological Psychiatry: Cognitive Neuroscience and Neuroimaging</source>, <volume>2</volume>(<issue>6</issue>), <fpage>476</fpage>–<lpage>486</lpage>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Papadopoulos</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Kim</surname>, <given-names>J. Z.</given-names></string-name>, <string-name><surname>Kurths</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Bassett</surname>, <given-names>D. S</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Development of structural correlations and synchronization from adaptive rewiring in networks of Kuramoto oscillators</article-title>. <source>Chaos: An Interdisciplinary Journal of Nonlinear Science</source>, <volume>27</volume>(<fpage>7</fpage>).</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Raichle</surname>, <given-names>M. E.</given-names></string-name>, <string-name><surname>MacLeod</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Snyder</surname>, <given-names>A. Z.</given-names></string-name>, <string-name><surname>Powers</surname>, <given-names>W. J.</given-names></string-name>, <string-name><surname>Gusnard</surname>, <given-names>D. A.</given-names></string-name>, &amp; <string-name><surname>Shulman</surname>, <given-names>G. L</given-names></string-name></person-group>. (<year>2001</year>). <article-title>A default mode of brain function</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>98</volume>(<issue>2</issue>), <fpage>676</fpage>–<lpage>682</lpage>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ramstead</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Albarracin</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Kiefer</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Klein</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Fields</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Friston</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Safron</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2023</year>). <article-title>The inner screen model of consciousness: applying the free energy principle directly to the study of conscious experience</article-title>. <source>arXiv</source> Preprint arXiv:2305.02205.</mixed-citation></ref>
    <ref id="c50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Richards</surname>, <given-names>B. A.</given-names></string-name>, <string-name><surname>Lillicrap</surname>, <given-names>T. P.</given-names></string-name>, <string-name><surname>Beaudoin</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Bengio</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Bogacz</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>ChristenMISSINGREFsen</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Clopath</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Costa</surname>, <given-names>R. P.</given-names></string-name>, <string-name><surname>de Berker</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Ganguli</surname>, <given-names>S.</given-names></string-name>, <etal>et al</etal></person-group>. (<year>2019</year>). <article-title>A deep learning framework for neuroscience</article-title>. <source>Nature Neuroscience</source>, <volume>22</volume>(<issue>11</issue>), <fpage>1761</fpage>–<lpage>1770</lpage>.</mixed-citation></ref>
    <ref id="c51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Robinson</surname>, <given-names>P. A.</given-names></string-name>, <string-name><surname>Rennie</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Rowe</surname>, <given-names>D. L.</given-names></string-name>, <string-name><surname>O’Connor</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Gordon</surname>, <given-names>E.</given-names></string-name></person-group>. (<year>2005</year>). <article-title>Multiscale brain modelling</article-title>. <source>Philosophical Transactions of the Royal Society B: Biological Sciences</source>, <volume>360</volume>(<issue>1457</issue>), <fpage>1043</fpage>–<lpage>1050</lpage>.</mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Scheid</surname>, <given-names>B. H.</given-names></string-name>, <string-name><surname>Ashourvan</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Stiso</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Davis</surname>, <given-names>K. A.</given-names></string-name>, <string-name><surname>Mikhail</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Pasqualetti</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Litt</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Bassett</surname>, <given-names>D. S</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Time-evolving controllability of effective connectivity networks during seizure progression</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>118</volume>(<issue>5</issue>), <fpage>e2006436118</fpage>.</mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schiff</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>Jerger</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Duong</surname>, <given-names>D. H.</given-names></string-name>, <string-name><surname>Chang</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Spano</surname>, <given-names>M. L.</given-names></string-name>, &amp; <string-name><surname>Ditto</surname>, <given-names>W. L</given-names></string-name></person-group>. (<year>1994</year>). <article-title>Controlling chaos in the brain</article-title>. <source>Nature</source>, <volume>370</volume>(<issue>6491</issue>), <fpage>615</fpage>–<lpage>620</lpage>.</mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schirner</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Kong</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Yeo</surname>, <given-names>B. T.</given-names></string-name>, <string-name><surname>Deco</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Ritter</surname>, <given-names>P</given-names></string-name></person-group>. (<year>2022</year>). <article-title>Dynamic primitives of brain network interaction</article-title>. <source>NeuroImage</source>, <volume>250</volume>, <fpage>118928</fpage>.</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Seguin</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Sporns</surname>, <given-names>O.</given-names></string-name>, &amp; <string-name><surname>Zalesky</surname>, <given-names>A</given-names></string-name></person-group>. (<year>2023</year>). <article-title>Brain network communication: concepts, models and applications</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>24</volume>(<issue>9</issue>), <fpage>557</fpage>–<lpage>574</lpage>.</mixed-citation></ref>
    <ref id="c56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Shinn</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Hu</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Turner</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Noble</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Preller</surname>, <given-names>K. H.</given-names></string-name>, <string-name><surname>Ji</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Moujaes</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Achard</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Scheinost</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Constable</surname>, <given-names>R. T.</given-names></string-name>, <etal>et al</etal></person-group>. (<year>2023</year>). <article-title>Functional brain networks reflect spatial and temporal autocorrelation</article-title>. <source>Nature Neuroscience</source>, <fpage>1</fpage>–<lpage>12</lpage>.</mixed-citation></ref>
    <ref id="c57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Smith</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>K. L.</given-names></string-name>, <string-name><surname>Moeller</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Xu</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Auerbach</surname>, <given-names>E. J.</given-names></string-name>, <string-name><surname>Woolrich</surname>, <given-names>M. W.</given-names></string-name>, <string-name><surname>Beckmann</surname>, <given-names>C. F.</given-names></string-name>, <string-name><surname>Jenkinson</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Andersson</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Glasser</surname>, <given-names>M. F.</given-names></string-name>, <etal>et al</etal></person-group>. (<year>2012</year>). <article-title>Temporally-independent functional modes of spontaneous brain activity</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>109</volume>(<issue>8</issue>), <fpage>3131</fpage>–<lpage>3136</lpage>.</mixed-citation></ref>
    <ref id="c58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sydnor</surname>, <given-names>V. J.</given-names></string-name>, <string-name><surname>Larsen</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Bassett</surname>, <given-names>D. S.</given-names></string-name>, <string-name><surname>Alexander-Bloch</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Fair</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Liston</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Mackey</surname>, <given-names>A. P.</given-names></string-name>, <string-name><surname>Milham</surname>, <given-names>M. P.</given-names></string-name>, <string-name><surname>Pines</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Roalf</surname>, <given-names>D. R.</given-names></string-name>, <etal>et al</etal></person-group>. (<year>2021</year>). <article-title>Neurodevelopment of the association cortices: Patterns, mechanisms, and implications for psychopathology</article-title>. <source>Neuron</source>, <volume>109</volume>(<issue>18</issue>), <fpage>2820</fpage>–<lpage>2846</lpage>.</mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vidaurre</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>S. M.</given-names></string-name>, &amp; <string-name><surname>Woolrich</surname>, <given-names>M. W</given-names></string-name></person-group>. (<year>2017</year>). <article-title>Brain network dynamics are hierarchically organized in time</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>114</volume>(<issue>48</issue>), <fpage>12827</fpage>–<lpage>12832</lpage>.</mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vohryzek</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Deco</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Cessac</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Kringelbach</surname>, <given-names>M. L.</given-names></string-name>, &amp; <string-name><surname>Cabral</surname>, <given-names>J</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Ghost attractors in spontaneous brain activity: Recurrent excursions into functionally-relevant BOLD phase-locking states</article-title>. <source>Frontiers in Systems Neuroscience</source>, <volume>14</volume>, <fpage>20</fpage>.</mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Woo</surname>, <given-names>C.-W.</given-names></string-name>, <string-name><surname>Roy</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Buhle</surname>, <given-names>J. T.</given-names></string-name>, &amp; <string-name><surname>Wager</surname>, <given-names>T. D</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Distinct brain systems mediate the effects of nociceptive input and self-regulation on pain</article-title>. <source>PLoS Biology</source>, <volume>13</volume>(<issue>1</issue>), <fpage>e1002036</fpage>.</mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zalesky</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Fornito</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Cocchi</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Gollo</surname>, <given-names>L. L.</given-names></string-name>, &amp; <string-name><surname>Breakspear</surname>, <given-names>M</given-names></string-name></person-group>. (<year>2014</year>). <article-title>Time-resolved resting-state brain networks</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>111</volume>(<issue>28</issue>), <fpage>10341</fpage>–<lpage>10346</lpage>.</mixed-citation></ref>
    <ref id="c63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zunhammer</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Spisák</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Wager</surname>, <given-names>T. D.</given-names></string-name>, &amp; <string-name><surname>Bingel</surname>, <given-names>U</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Meta-analysis of neural systems underlying placebo</article-title>. <source>Nature Communications</source>, <volume>12</volume>, <elocation-id>1391</elocation-id>.</mixed-citation></ref>
</ref-list>
<sec id="s5">
<title>Methods</title>
<sec id="s5a">
<title>Data</title>
<p>We obtained functional MRI data from 7 different sources (<xref rid="tbls1" ref-type="table">Table 1</xref>). We included three resting state studies with healthy volunteers (study 1, study 2, study 3, n<sub>*+*,-</sub> = 118), one task-based study (study 4, <italic>n<sub>total</sub></italic> = 33 participants, 9 runs each), an individual participant meta-analytic activation map of pain (study 5, <italic>n<sub>total</sub></italic> = 603 from 20 different studies), 8 task-based activation patterns obtained from coordinate-based meta-analyses via Neurosynth (study 6, 14371 studies in total, see Supplementary Table 1) and a resting state dataset focusing on Autism Spectrum Disorder (ASD) from the ABIDE (Autism Brain Imaging Data Exchange, study 6, <italic>n<sub>total</sub></italic> = 1112, <xref ref-type="bibr" rid="c14">Di Martino <italic>et al</italic>. 2014</xref>).</p>
<table-wrap id="tbls1" orientation="portrait" position="float">
<label>Table 1:</label><caption><title>Datasets and studies.</title>
<p>The table includes details about the study modality, analysis aims, sample size used for analyses, mean age, gender ratio, and references.</p></caption>
<graphic xlink:href="565516v3_tbls1.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<p>Study 1 was used to evaluate the potential of the resting state functional brain connectome to be considered as an attractor network, to optimize the temperature (β) and noise (σ) parameters of the fcHNN model, and to evaluate the proposed approach to reconstruct resting state brain dynamics. Study 2 and 3 served as replications studies for these analyses. Study 1, 2 and 3 is well suited to examine replicability and generalizability; data in these three studies were acquired in 3 different centers from 2 different countries, by different research staff, with different scanners (Philips, Siemens, GE) and different imaging sequences. Further details on study 1-3 are described in <xref ref-type="bibr" rid="c80">Spisak <italic>et al</italic>., 2020</xref>. The ability of the proposed approach to model task-based perturbation of brain dynamics was evaluated in Study 4, which consisted of nine task-based fMRI runs for each of the 33 healthy volunteers. In all runs, participants received heat pain stimulation. Each stimulus lasted 12.5 seconds, with 3-second ramp-up and 2-second ramp-down periods and 7.5 seconds at target temperature. Six levels of temperature were administered to the participants (level 1: 44.3°C; level 2: 45.3°C; level 3: 46.3°C; level 4: 47.3°C; level 5: 48.3°C; level 6: 49.3°C). We used run 1 (passive experience), run 3 (down-regulation) and run 7 (up-regulation) from this study. In runs 3 and 7, participants were asked to cognitively “increase” (regulate-up) or “decrease” (regulate-down) pain intensity. No self-regulation instructions were provided in run 1. See <xref ref-type="bibr" rid="c61">Woo <italic>et al</italic>. (2015)</xref> for details. Pain control signal for our task-based trajectory analyses on data from study 4 was derived from our individual participant meta-analysis of 20 pain fMRI studies (study 5, n=603). For details, see <xref ref-type="bibr" rid="c63">Zunhammer <italic>et al</italic>. (2021)</xref>. To obtain fMRI activation maps for other tasks, we used Neurosynth (Wager TD., 2011), a web-based platform for large-scale, automated synthesis of functional magnetic resonance imaging (fMRI) data. We performed 8 different coordinate-based meta-analyses with the terms “motor”, “auditory”, “visual”, “face”, “autobiographical”, “theory mind”, “language” and “pain” (Supplementary Table 1) and obtained the Z-score maps from a two-way ANOVA, comparing the coordinates reported for studies with and without the term of interest, and testing for the presence of a non-zero association between term use and voxel activation. In study 7 (ABIDE), we obtained preprocessed regional timeseries data from the Preprocessed Connectome Project (<xref ref-type="bibr" rid="c70">Craddock <italic>et al</italic>., 2013</xref>), as shared (<ext-link ext-link-type="uri" xlink:href="https://osf.io/hc4md">https://osf.io/hc4md</ext-link>) by <xref ref-type="bibr" rid="c71">Dadi <italic>et al</italic>. (2019)</xref>. Preprocessed timeseries data were obtained with the 122-region version of the BASC (Bootstrap Analysis of Stable Clusters) brain atlas (<xref ref-type="bibr" rid="c68">Bellec <italic>et al</italic>., 2010</xref>).</p>
</sec>
<sec id="s5b">
<title>Preprocessing and timeseries extraction</title>
<p>Functional MRI data from studies 1-4 was preprocessed with our in-house analysis pipeline, called the RPN-pipeline (<ext-link ext-link-type="uri" xlink:href="https://github.com/spisakt/RPN-signature">https://github.com/spisakt/RPN-signature</ext-link>). The RPN-pipeline is based on PUMI (Neuroimaging Pipelines Using Modular workflow Integration, <ext-link ext-link-type="uri" xlink:href="https://github.com/pni-lab/PUMI">https://github.com/pni-lab/PUMI</ext-link>), a nipype-based (<xref ref-type="bibr" rid="c75">Gorgolewski <italic>et al</italic>., 2011</xref>) workflow management system. It capitalizes on tools from FSL (<xref ref-type="bibr" rid="c77">Jenkinson <italic>et al</italic>., 2012</xref>), ANTS (<xref ref-type="bibr" rid="c66">Avants <italic>et al</italic>., 2011</xref>) and AFNI (<xref ref-type="bibr" rid="c69">Cox, 1996</xref>), with code partially adapted from the software tools C-PAC (<xref ref-type="bibr" rid="c70">Craddock <italic>et al</italic>., 2013</xref>) and niworkflows (<xref ref-type="bibr" rid="c73">Esteban <italic>et al</italic>., 2019</xref>), as well as in-house python routines.</p>
<p>Brain extraction from both the anatomical and the structural images, as well as tissue-segmentation from the anatomical images was performed with FSL bet and fast. Anatomical images were linearly and non-linearly co-registered to the 1mm-resolution MNI152 standard brain template brain with ANTs (see <ext-link ext-link-type="uri" xlink:href="https://gist.github.com/spisakt/0caa7ec4bc18d3ed736d3a4e49da7415">https://gist.github.com/spisakt/0caa7ec4bc18d3ed736d3a4e49da7415</ext-link> for parameters). Functional images were co-registered to the anatomical images with the boundary-based registration technique of FSL flirt. All resulting transformations were saved for further use. The preprocessing of functional images happened in the native image space, without resampling. Realignment-based motion-correction was performed with FSL mcflirt. The resulting six head motion estimates (3 rotations, 3 translations), their squared versions, their derivatives and the squared derivatives (known as the Friston-24-expansion, <xref ref-type="bibr" rid="c74">Friston <italic>et al</italic>., 1996</xref>) were calculated to be used as nuisance signals. Additionally, head motion was summarized as framewise displacement (FD) timeseries, according to Power’s method (<xref ref-type="bibr" rid="c78">Power <italic>et al</italic>., 2012</xref>), to be used in data censoring and exclusion. After motion-correction, outliers (e.g. motion spikes) in timeseries data were attenuated using AFNI despike. The union of the eroded white-matter maps and ventricle masks were transformed to the native functional space and used for extracting noise-signal for anatomical CompCor correction (<xref ref-type="bibr" rid="c67">Behzadi <italic>et al</italic>., 2007</xref>). In a nuisance regression step, 6 CompCor parameters (the 6 first principal components of the noise-region timeseries), the Friston-24 motion parameters and the linear trend were removed from the timeseries data with a general linear model. On the residual data, temporal bandpass filtering was performed with AFNI’s 3DBandpass to retain the 0.008–0.08Hz frequency band. To further attenuate the impact of motion artifacts, potentially motion-contaminated time-frames, defined by a conservative FD&gt;0.15mm threshold, were dropped from the data (known as scrubbing, <xref ref-type="bibr" rid="c79">Satterthwaite <italic>et al</italic>., 2013</xref>). Participants were excluded from further analysis if more than 50% of frames were scrubbed. The 122-parcel version of the BASC (Multi-level bootstrap analysis of stable clusters) multi-resolution functional brain atlas (<xref ref-type="bibr" rid="c68">Bellec <italic>et al</italic>., 2010</xref>) was individualized; it was transformed to the native functional space of each participant (interpolation: nearest neighbour) and masked by the grey-matter mask obtained from the anatomical image, to retain individual grey-matter voxels only. Voxel-timeseries were averaged over these individualized BASC regions.</p>
<p>All these preprocessing steps are part of the containerized version of the RPN-pipeline (<ext-link ext-link-type="uri" xlink:href="https://spisakt.github.io/RPN-signature">https://spisakt.github.io/RPN-signature</ext-link>), which we run with default parameters for all studies, as in <xref ref-type="bibr" rid="c80">Spisak <italic>et al</italic>., 2020</xref>.</p>
</sec>
<sec id="s5c">
<title>Functional connectome</title>
<p>Regional timeseries were ordered into large-scale functional modules (defined by the 7-parcel level of the BASC atlas) for visualization purposes. Next, in all datasets, we estimated study-level mean connectivity matrices by regularized partial correlation, via the Graphical Lasso algorithm that estimates a sparse precision matrix by solving a Lasso problem and an L1 penalty for sparsity (<xref ref-type="bibr" rid="c82">Varoquaux <italic>et al</italic>., 2010</xref>), as implemented in nilearn (<xref ref-type="bibr" rid="c65">Abraham <italic>et al</italic>., 2014</xref>). Diagonal elements of the matrices were set to zero.</p>
</sec>
<sec id="s5d">
<title>Connectome-based Hopfield networks</title>
<p>Hopfield networks, a type of artificial neural network, consist of a single layer of <italic>m</italic> fully connected nodes (<xref ref-type="bibr" rid="c29">Hopfield, 1982</xref>), with activations <italic><bold>α</bold></italic> = (<italic>α</italic><sub>1</sub>, … , <italic>α<sub>m</sub></italic>). Hopfield networks assign an energy to any arbitrary activity configurations:
<disp-formula id="eqns1">
<graphic xlink:href="565516v3_eqns1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>W</italic> is the weight matrix with element <italic>w<sub>i,j</sub></italic> denoting the weight between nodes i and j and <bold><italic>b</italic></bold> is the bias, which is set to <bold><italic>b</italic></bold> = 0 for all experiments.</p>
<p>During the so-called relaxation process, the activities of the nodes are iteratively updated until the network converges to a stable state, known as an attractor state. The dynamics of the network are governed by the equation referenced as <xref rid="eqn1" ref-type="disp-formula">eq. (1)</xref> of the main text, or in matrix form:
<disp-formula id="eqns2">
<graphic xlink:href="565516v3_eqns2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <inline-formula><inline-graphic xlink:href="565516v3_inline3.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is the activity in the next iteration and <italic>S</italic>(.) is the sigmoidal activation function (<italic>S</italic>(<italic>α</italic>) = <italic>tanh</italic>(<italic>α</italic>) in our implementation) and β is the temperature parameter. During the stochastic relaxation procedure, we add weak Gaussian noise to each node’s activity at every iteration:
<disp-formula id="eqns3">
<graphic xlink:href="565516v3_eqns3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where ɛ ∼ 𝒩(µ, σ), with σ regulating the amount of noise added and µ set to 0, by default.</p>
<p>In this work we propose functional connectome-based Hopfield neural networks (fcHNNs) as a model for large-scale brain dynamics. FcHNNs are continuous-state Hopfield neural networks with each node representing a brain region and weights initialized with a group-level functional connectivity matrix. The weights are scaled to zero mean and unit standard deviation.</p>
</sec>
<sec id="s5e">
<title>fcHNN convergence and attractors</title>
<p>We investigated the convergence properties of functional connectome-based HNNs in study 1 by contrasting the median number of iterations until reaching convergence to a permutation based null model. In more detail, the null model was constructed by randomly permuting the upper triangle of the original connectome and filling up the lower triangle to get a symmetric network (symmetry of the weight matrix is a general requirement for convergence). This procedure was repeated 1000 times. In each repetition, we initialized both the original and the permuted fcHNN with random input and counted the number of iterations until convergence. The whole procedure was repeated with β = 0.3, 0.35, 0.4, 0.45, 0.5, 0.55 and 0.6 (providing 2-8 attractor states). In studies 1-3, we obtained the finite number of attractor states with the same values of β by repeatedly (10<sup>1</sup> times) initializing the fcHNNs with random activations and relaxing them until convergence.</p>
</sec>
<sec id="s5f">
<title>fcHNN projection</title>
<p>We mapped out the fcHNN state-space by initializing our fcHNN model with a random input, and applying the stochastic update step for 10<sup>1</sup> iterations and storing all visited activity configurations. We performed a principal component analysis (PCA) on the state samples, and proposed the first two principal component (PCs) as the coordinate system for the fcHNN projection. Using a Multinomial Logistic Regression, we predicted to which attractor state each of the state samples converges to, using the first two PCs as features. The model’s performance was evaluated with 10-fold cross-validation. We visualized the attractor states position in the projection as well as the decision boundaries between the attractor states, based on this regression model.</p>
</sec>
<sec id="s5g">
<title>Parameter optimization</title>
<p>Based on the convergence analysis, we selected the β value that provided the fastest median convergence (β = 0.04) for all subsequent analyses, to minimize computational costs. We optimized the noise parameter σ by comparing the distribution of the state-space of the fcHNN with the distribution of the real fMRI data in the fcHNN projection. Specifically, we evaluated eight different σ values, spaced logarithmically between 0.1 and 1, obtained the fcHNN projection for each model, transformed the real data into this projection and compared the distribution of the data, as well as the state occupancies. The similarity of the distribution of of the real and fcHNN-generated data was quantified as the Pearson’s correlation coefficient between the 2-dimensional histograms over a 2-dimensional grid of 100×100 uniformly distributed bins in the [-6,6] range (arbitrary units on the fcHNN projection axes) after applying a Gaussian smoothing with a σ of 5 bins.</p>
<p>State occupancies for each attractor state were calculated as the ratio of time spent on the basis of the attractor (both for the fcHNN-generated and the empirical data). Similarity of fcHNN-generated state occupancies to those observed in the real data was evaluated with a χ<sup>)</sup>-test statistic. Both test statistics were contrasted to two types of null models. The first null model was constructed to investigate whether fcHNNs can extract information from the functional connectome over and beyond what is already present in the co-variance structure of the data, next to normality assumptions. This was implemented by drawing random samples from a multivariate normal distribution with the functional connectome as the covariance matrix. The second null model was constructed to investigate whether the fcHNN model’s performance can be explained solely with the spatial autocorrelation properties of the data. This null model was implemented by spatially autocorrelation-preserving randomization of the real data. Timeframes were first Fourier-transformed into the frequency domain, the phases were randomized simultaneously and the data was transformed back with the inverse-Fourier transformation. More details on the null models can be found in Supplementary Figure 5. Both null models were used to generate 1000 surrogates of the empirical data, which were projected into the fcHNN projection space and compared to the fcHNN-generated data with the above described test statistics. P-values were calculated by contrasting the real test statistics to the null-distributions. As a result of this procedure, we selected σ = 0.37 for all subsequent analyses.</p>
</sec>
<sec id="s5h">
<title>Replicability</title>
<p>We obtained the four attractor states in study 1, as described above. We then constructed two other fcHNNs, based on the study-mean functional connectome obtained in studies 2 and 3 and obtained all attractor states of these models, with the same parameter settings (β = 0.04 and σ = 0.37) as in study 1. In both replication studies we found four attractor states. The spatial similarity of attractor states across studies was evaluated by Pearson’s correlation coefficient.</p>
</sec>
<sec id="s5i">
<title>Evaluation: resting state dynamics</title>
<p>To evaluate the explanatory power of the fcHNN projection, we performed PCA on the preprocessed fMRI time-frames from study 1 (analogously to the methodology of the fcHNN projection, but on the empirical timeseries data). Next, we fitted linear regression models which used the first two fcHNN or real data-based PCs as regressors to reconstruct the real fMRI time-frames. In-sample explained variances and the corresponding confidence intervals were calculated for both models with bootstrapping (100 samples). To evaluate the out-of-sample generalization of the PCs (fcHNN- and real data-based) from study 1, we calculated how much variance they can explain in study 2. Similarity between state occupancy and distribution was calculated during the parameter optimization. More detail on the associated null-models can be found in Supplementary figure 5.</p>
<p>To confirm that the real and fcHNN temporal sequences (from the stochastic relaxation) display similar temporal autocorrelation properties, we compared both to their randomly shuffled variant with a “flow analysis”. First we calculated the direction on the fcHNN projection plane between each successive TR (a vector on the fcHNN projection plane for each TR transition), both for the empirical and the shuffled data. Next, we obtained a two-dimensional binned means for both the x and y coordinates of these transition vectors (pooled across all participants), calculated over a 2-dimensional grid of 100×100 uniformly distributed bins in the [-6,6] range (arbitrary units) and applied a Gaussian smoothing with a σ of 5 bins (same approach as in described in the Parameter optimization section). Finally, we visualized the difference between the binned-mean trajectories of the empirical and the shuffled data as a “streamplot”, with the Python package matplotlib. The same approach was repeated with the fcHNN-generated data. The similarity of the real and fcHNN-generated flow analysis was quantified with Pearson’s correlation coefficient, p-values were obtained with permutation testing.</p>
</sec>
<sec id="s5j">
<title>Evaluation: task-based dynamics</title>
<p>We used study 4 to evaluate the ability of the fcHNN approach to capture and predict task-induced alterations in large-scale brain dynamics. First, runs 1, 3 and 7, investigating the passive experience and the down- and up-regulation of pain, respectively, were preprocessed with the same workflow used to preprocess studies 1-3 (Preprocessing and timeseries extraction). Regional timeseries data was grouped to “pain” and “rest” blocks, with a 6-second delay to adjust for the hemodynamic response time. All activation timeframes were transformed to the fcHNN projection plane obtained from study 1. Within-participant differences of the average location on the fcHNN projection was calculated and visualized with radial plots, showing the participant-level mean trajectory on the projection plane from rest to pain, denoted with circles, as well as the group level trajectory (arrow). The significance of the position difference and energy difference of the participant-level mean activations in the projection plane was tested with a permutation test. We used the L2 norm of the two-dimensional position difference and the absolute energy difference, respectively, as test statistics. The permutation tests were run with 1000 permutations, randomly swapping the conditions within each participant.</p>
<p>To further highlight the difference between the task and rest conditions, a “flow analysis” was performed to investigate the dynamic trajectory differences between the conditions rest and pain. The analysis method was identical to the flow analysis of the resting sate data (Evaluation: resting state dynamics). First we calculated the direction in the projection plane between each successive TR during the rest conditions (a vector on the fcHNN projection plane for each TR transition). Next, we obtained a two-dimensional binned means for both the x and y coordinates of these transition vectors (pooled across all participants), calculated over a 2-dimensional grid of 100×100 uniformly distributed bins in the [-6,6] range (arbitrary units) and applied Gaussian smoothing with a σ 5 bins. The same procedure was repeated for the pain condition and the difference in the mean directions between the two conditions was visualized as “streamplots” (using Python’s matplotlib). We used the same approach to quantify the difference in characteristic state transition trajectories between the up- and downregulation conditions. The empirically estimated trajectory differences (from real fMRI data) were contrasted to the trajectory differences predicted by the fcHNN model from study 1.</p>
<p>To obtain fcHNN-simulated state transitions in resting conditions, we used the stochastic relaxation procedure (3), with µ set zero. To simulate the effect of pain-related activation on large-scale brain dynamics, we set µ<sub>!</sub> during the stochastic relaxation procedure to a value representing pain-elicited activity in region i. The region-wise activations were obtained calculating the parcel-level mean activations from the meta-analytic pain activation map from (<xref ref-type="bibr" rid="c63">Zunhammer <italic>et al</italic>., 2021</xref>), which contained Hedges’ g effect sizes from an individual participant-level meta-analysis of 20 pain studies, encompassing a total of n=603 participants. The whole activation map was scaled with five different values ranging from 10<sup>23</sup> to 10<sup>2&amp;</sup>, spaced logarithmically, to investigate various signal-to-noise scenarios. We obtained the activity patterns of 10<sup>1</sup>iterations from this stochastic relaxation procedure and calculated the state transition trajectories with the same approach used with the empirical data. Next we calculated the fcHNN-generated difference between the rest and pain conditions and compared it to the actual difference through a permutation test with 1000 permutations, randomly swapping the conditions within each participant in the real data and using Pearson’s correlation coefficient between the real (permuted) and fcHNN-generated flow-maps as test statistic. From the five investigated signal-to-noise values, we chose the one that provided the highest similarity to the real pain vs. rest trajectory difference.</p>
<p>When comparing the simulated and real trajectory differences between pain up- and downregulation, we used the same procedure, with two differences. First, when calculating the simulated state transition vectors for the self-regulation conditions, we used the same procedure as for the pain condition, but introduced and additional signal in the nucleus accumbens, with a negative and positive sign, for up- and downregulation, respectively. We did not optimize the signal-to-noise ratio for the nucleus accumbens signal but, instead, simply used the value optimized for the pain vs. rest contrast (For a robustness analysis, see Supplementary figure 7).</p>
</sec>
<sec id="s5k">
<title>Clinical data</title>
<p>To demonstrate the sensitivity of the fcHNN approach to clinically relevant alterations of large-scale brain dynamics in Autism Spectrum Disorder (ASD), we obtained data from n=172 individuals, acquired at the New York University Langone Medical Center, New York, NY, USA (NYU) as shared in the Autism Brain Imaging Data Exchange dataset (study 7: ABIDE, (<xref ref-type="bibr" rid="c14">Di Martino <italic>et al</italic>., 2014</xref>). We focused on the largest ABIDE imaging center to ensure that our results are not biased by center effects. We excluded high motion cases similarly to our approach in studies 1-4, i.e. by ignoring (“scrubbing”) volumes with FD&gt;0.15 and excluding participants with more than 50% of data scrubbed. Timeseries data was pooled and visualized on the fcHNN projection of study 1, separately for ASD and control participants. Next, for each participant, we grouped the timeframes from the regional timeseries data according to the corresponding attractor states (obtained with the fcHNN model from study 1) and averaged timeframes corresponding to the same attractor state to calculated participant-level mean attractor activations. We assessed mean attractor activity differences between the patient groups with a permutation test, randomly re-assigning the group labels 50000 times. We adjusted the significance threshold with a Bonferroni-correction, accounting for tests across 4 states and 122 regions, resulting in α = 0.0001. Finally, we have calculated the trajectory differences between the two groups, as predicted by the group-specific fcHNNs (initialized with the ASD and TCD connectomes), and - similarly to the approach used in study 4 - we contrasted the fcHNN predictions to the trajectory differences observed in the real rsfMRI data. As in the previous flow analyses, we tested the significance of the similarity between the predicted and observed trajectory differences with a permutation test (1000 permutations), by shuffling group labels.</p>
</sec>
<ref-list>
<title>Methods References</title>
<ref id="c65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Abraham</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Pedregosa</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Eickenberg</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Gervais</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Mueller</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kossaifi</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Gramfort</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Thirion</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Varoquaux</surname>, <given-names>G</given-names></string-name></person-group>. (<year>2014</year>). <article-title>Machine learning for neuroimaging with scikit-learn</article-title>. <source>Frontiers in Neuroinformatics</source>, <volume>8</volume>, <fpage>14</fpage>.</mixed-citation></ref>
<ref id="c66"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Avants</surname>, <given-names>B. B.</given-names></string-name>, <string-name><surname>Tustison</surname>, <given-names>N. J.</given-names></string-name>, <string-name><surname>Song</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Cook</surname>, <given-names>P. A.</given-names></string-name>, <string-name><surname>Klein</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Gee</surname>, <given-names>J. C</given-names></string-name></person-group>. (<year>2011</year>). <article-title>A reproducible evaluation of ANTs similarity metric performance in brain image registration</article-title>. <source>Neuroimage</source>, <volume>54</volume>(<issue>3</issue>), <fpage>2033</fpage>–<lpage>2044</lpage>.</mixed-citation></ref>
<ref id="c67"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Behzadi</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Restom</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Liau</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Liu</surname>, <given-names>T. T</given-names></string-name></person-group>. (<year>2007</year>). <article-title>A component based noise correction method (CompCor) for BOLD and perfusion based fMRI</article-title>. <source>Neuroimage</source>, <volume>37</volume>(<issue>1</issue>), <fpage>90</fpage>–<lpage>101</lpage>.</mixed-citation></ref>
<ref id="c68"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bellec</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Rosa-Neto</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Lyttelton</surname>, <given-names>O. C.</given-names></string-name>, <string-name><surname>Benali</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Evans</surname>, <given-names>A. C</given-names></string-name></person-group>. (<year>2010</year>). <article-title>Multi-level bootstrap analysis of stable clusters in resting-state fMRI</article-title>. <source>Neuroimage</source>, <volume>51</volume>(<issue>3</issue>), <fpage>1126</fpage>–<lpage>1139</lpage>.</mixed-citation></ref>
<ref id="c69"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cox</surname>, <given-names>R. W</given-names></string-name></person-group>. (<year>1996</year>). <article-title>AFNI: software for analysis and visualization of functional magnetic resonance neuroimages</article-title>. <source>Computers and Biomedical Research</source>, <volume>29</volume>(<issue>3</issue>), <fpage>162</fpage>–<lpage>173</lpage>.</mixed-citation></ref>
    <ref id="c70"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Craddock</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Sikka</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Cheung</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Khanuja</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Ghosh</surname>, <given-names>S. S.</given-names></string-name>, <string-name><surname>Yan</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Lurie</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Vogelstein</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Burns</surname>, <given-names>R.</given-names></string-name>, <etal>et al</etal></person-group>. (<year>2013</year>). <article-title>Towards automated analysis of connectomes: The configurable pipeline for the analysis of connectomes (c-pac)</article-title>. <source>Front Neuroinform</source>, <italic>42</italic>(10.3389).</mixed-citation></ref>
    <ref id="c71"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dadi</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Rahim</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Abraham</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Chyzhyk</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Milham</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Thirion</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Varoquaux</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Initiative</surname>, <given-names>A. D. N.</given-names></string-name>, <etal>et al</etal></person-group>. (<year>2019</year>). <article-title>Benchmarking functional connectome-based predictive models for resting-state fMRI</article-title>. <source>NeuroImage</source>, <volume>192</volume>, <fpage>115</fpage>–<lpage>134</lpage>.</mixed-citation></ref>
    <ref id="c72"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Di Martino</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Yan</surname>, <given-names>C.-G.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Denio</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Castellanos</surname>, <given-names>F. X.</given-names></string-name>, <string-name><surname>Alaerts</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Anderson</surname>, <given-names>J. S.</given-names></string-name>, <string-name><surname>Assaf</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Bookheimer</surname>, <given-names>S. Y.</given-names></string-name>, <string-name><surname>Dapretto</surname>, <given-names>M.</given-names></string-name>, <etal>et al</etal></person-group>. (<year>2014</year>). <article-title>The autism brain imaging data exchange: towards a large-scale evaluation of the intrinsic brain architecture in autism</article-title>. <source>Molecular Psychiatry</source>, <volume>19</volume>(<issue>6</issue>), <fpage>659</fpage>–<lpage>667</lpage>.</mixed-citation></ref>
    <ref id="c73"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Esteban</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Markiewicz</surname>, <given-names>C. J.</given-names></string-name>, <string-name><surname>Blair</surname>, <given-names>R. W.</given-names></string-name>, <string-name><surname>Moodie</surname>, <given-names>C. A.</given-names></string-name>, <string-name><surname>Isik</surname>, <given-names>A. I.</given-names></string-name>, <string-name><surname>Erramuzpe</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kent</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Goncalves</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>DuPre</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Snyder</surname>, <given-names>M.</given-names></string-name>, <etal>et al</etal></person-group>. (<year>2019</year>). <article-title>fMRIPrep: a robust preprocessing pipeline for functional MRI</article-title>. <source>Nature Methods</source>, <volume>16</volume>(<issue>1</issue>), <fpage>111</fpage>–<lpage>116</lpage>.</mixed-citation></ref>
<ref id="c74"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Friston</surname>, <given-names>K. J.</given-names></string-name>, <string-name><surname>Williams</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Howard</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Frackowiak</surname>, <given-names>R. S.</given-names></string-name>, &amp; <string-name><surname>Turner</surname>, <given-names>R</given-names></string-name></person-group>. (<year>1996</year>). <article-title>Movement-related effects in fMRI time-series</article-title>. <source>Magnetic Resonance in Medicine</source>, <volume>35</volume>(<issue>3</issue>), <fpage>346</fpage>–<lpage>355</lpage>.</mixed-citation></ref>
<ref id="c75"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gorgolewski</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Burns</surname>, <given-names>C. D.</given-names></string-name>, <string-name><surname>Madison</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Clark</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Halchenko</surname>, <given-names>Y. O.</given-names></string-name>, <string-name><surname>Waskom</surname>, <given-names>M. L.</given-names></string-name>, &amp; <string-name><surname>Ghosh</surname>, <given-names>S. S</given-names></string-name></person-group>. (<year>2011</year>). <article-title>Nipype: a flexible, lightweight and extensible neuroimaging data processing framework in python</article-title>. <source>Frontiers in Neuroinformatics</source>, <volume>5</volume>, <fpage>13</fpage>.</mixed-citation></ref>
<ref id="c76"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hopfield</surname>, <given-names>J. J</given-names></string-name></person-group>. (<year>1982</year>). <article-title>Neural networks and physical systems with emergent collective computational abilities</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>79</volume>(<issue>8</issue>), <fpage>2554</fpage>–<lpage>2558</lpage>.</mixed-citation></ref>
<ref id="c77"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jenkinson</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Beckmann</surname>, <given-names>C. F.</given-names></string-name>, <string-name><surname>Behrens</surname>, <given-names>T. E.</given-names></string-name>, <string-name><surname>Woolrich</surname>, <given-names>M. W.</given-names></string-name>, &amp; <string-name><surname>Smith</surname>, <given-names>S. M</given-names></string-name></person-group>. (<year>2012</year>). <article-title>Fsl</article-title>. <source>Neuroimage</source>, <volume>62</volume>(<issue>2</issue>), <fpage>782</fpage>–<lpage>790</lpage>.</mixed-citation></ref>
<ref id="c78"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Power</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Barnes</surname>, <given-names>K. A.</given-names></string-name>, <string-name><surname>Snyder</surname>, <given-names>A. Z.</given-names></string-name>, <string-name><surname>Schlaggar</surname>, <given-names>B. L.</given-names></string-name>, &amp; <string-name><surname>Petersen</surname>, <given-names>S. E</given-names></string-name></person-group>. (<year>2012</year>). <article-title>Spurious but systematic correlations in functional connectivity MRI networks arise from subject motion</article-title>. <source>Neuroimage</source>, <volume>59</volume>(<issue>3</issue>), <fpage>2142</fpage>–<lpage>2154</lpage>.</mixed-citation></ref>
    <ref id="c79"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Satterthwaite</surname>, <given-names>T. D.</given-names></string-name>, <string-name><surname>Elliott</surname>, <given-names>M. A.</given-names></string-name>, <string-name><surname>Gerraty</surname>, <given-names>R. T.</given-names></string-name>, <string-name><surname>Ruparel</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Loughead</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Calkins</surname>, <given-names>M. E.</given-names></string-name>, <string-name><surname>Eickhoff</surname>, <given-names>S. B.</given-names></string-name>, <string-name><surname>Hakonarson</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Gur</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>Gur</surname>, <given-names>R. E.</given-names></string-name>, <etal>et al</etal></person-group>. (<year>2013</year>). <article-title>An improved framework for confound regression and filtering for control of motion artifact in the preprocessing of resting-state functional connectivity data</article-title>. <source>Neuroimage</source>, <volume>64</volume>, <fpage>240</fpage>–<lpage>256</lpage>.</mixed-citation></ref>
<ref id="c80"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Spisak</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Kincses</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Schlitt</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Zunhammer</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Schmidt-Wilcke</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Kincses</surname>, <given-names>Z. T.</given-names></string-name>, &amp; <string-name><surname>Bingel</surname>, <given-names>U</given-names></string-name></person-group>. (<year>2020</year>). <article-title>Pain-free resting-state functional brain connectivity predicts individual pain sensitivity</article-title>. <source>Nature Communications</source>, <volume>11</volume>(<issue>1</issue>). <pub-id pub-id-type="doi">10.1038/s41467-019-13785-z</pub-id></mixed-citation></ref>
<ref id="c81"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wager</surname> <given-names>TD</given-names></string-name></person-group>. (<year>2011</year>). <article-title>NeuroSynth: a new platform for large-scale automated synthesis of human functional neuroimaging data</article-title>. <source>Frontiers in Neuroinformatics</source>, <volume>5</volume>. <pub-id pub-id-type="doi">10.3389/conf.fninf.2011.08.00058</pub-id></mixed-citation></ref>
<ref id="c82"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Varoquaux</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Baronnet</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Kleinschmidt</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Fillard</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Thirion</surname>, <given-names>B</given-names></string-name></person-group>. (<year>2010</year>). <article-title>Detection of brain functional-connectivity difference in post-stroke patients using group-level covariance modeling</article-title>. <source>Medical Image Computing and Computer-Assisted Intervention–MICCAI 2010: 13th International Conference, Beijing, China, September 20-24, 2010, Proceedings, Part I 13</source>, <fpage>200</fpage>–<lpage>208</lpage>.</mixed-citation></ref>
<ref id="c83"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Woo</surname>, <given-names>C.-W.</given-names></string-name>, <string-name><surname>Roy</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Buhle</surname>, <given-names>J. T.</given-names></string-name>, &amp; <string-name><surname>Wager</surname>, <given-names>T. D</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Distinct brain systems mediate the effects of nociceptive input and self-regulation on pain</article-title>. <source>PLoS Biology</source>, <volume>13</volume>(<issue>1</issue>), <fpage>e1002036</fpage>.</mixed-citation></ref>
<ref id="c84"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Woo</surname>, <given-names>C.-W.</given-names></string-name>, <string-name><surname>Roy</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Buhle</surname>, <given-names>J. T.</given-names></string-name>, &amp; <string-name><surname>Wager</surname>, <given-names>T. D</given-names></string-name></person-group>. (<year>2015</year>). <article-title>Distinct Brain Systems Mediate the Effects of Nociceptive Input and Self-Regulation on Pain</article-title>. <source>PLoS Biology</source>, <volume>13</volume>(<issue>1</issue>), <fpage>e1002036</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pbio.1002036</pub-id></mixed-citation></ref>
<ref id="c85"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yarkoni</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Poldrack</surname>, <given-names>R. A.</given-names></string-name>, <string-name><surname>Nichols</surname>, <given-names>T. E.</given-names></string-name>, <string-name><surname>Van Essen</surname>, <given-names>D. C.</given-names></string-name>, &amp; <string-name><surname>Wager</surname>, <given-names>T. D</given-names></string-name></person-group>. (<year>2011</year>). <article-title>Large-scale automated synthesis of human functional neuroimaging data</article-title>. <source>Nature Methods</source>, <volume>8</volume>(<issue>8</issue>), <fpage>665</fpage>–<lpage>670</lpage>. <pub-id pub-id-type="doi">10.1038/nmeth.1635</pub-id></mixed-citation></ref>
<ref id="c86"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zunhammer</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Spisák</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Wager</surname>, <given-names>T. D.</given-names></string-name>, &amp; <string-name><surname>Bingel</surname>, <given-names>U</given-names></string-name></person-group>. (<year>2021</year>). <article-title>Meta-analysis of neural systems underlying placebo analgesia from individual participant fMRI data</article-title>. <source>Nature Communications</source>, <volume>12</volume>(<issue>1</issue>), <fpage>1391</fpage>.</mixed-citation></ref>
</ref-list>
</sec>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.98725.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Marquand</surname>
<given-names>Andre F</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Radboud University Nijmegen</institution>
</institution-wrap>
<city>Nijmegen</city>
<country>Netherlands</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Useful</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study presents a <bold>useful</bold> approach for revealing large-scale brain attractor dynamics during resting states, task processing, and disease conditions using insights from Hopfield neural networks. The evidence supporting the findings is <bold>solid</bold> across the many datasets analysed. The work will be of broad interest to neuroscientists using neuroimaging data with interest in computational modelling of brain activity.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.98725.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Englert et al. proposed a functional connectome-based Hopfield artificial neural network (fcHNN) architecture to reveal attractor states and activity flows across various conditions, including resting state, task-evoked, and pathological conditions. The fcHNN can reconstruct characteristics of resting-state and task-evoked brain activities. Additionally, the fcHNN demonstrates differences in attractor states between individuals with autism and typically developing individuals.</p>
<p>Strengths:</p>
<p>(1) The study used seven datasets, which somewhat ensures robust replication and validation of generalization across various conditions.</p>
<p>(2) The proposed fcHNN improves upon existing activity flow models by mimicking artificial neural networks, thereby enhancing the representational ability of the model. This advancement enables the model to more accurately reconstruct the dynamic characteristics of brain activity.</p>
<p>(3) The fcHNN projection offers an interesting visualization, allowing researchers to observe attractor states and activity flow patterns directly.</p>
<p>Weaknesses:</p>
<p>(1) The fcHNN projection can offer low-dimensional dynamic visualizations, but its interpretability is limited, making it difficult to make strong claims based on these projections. The interpretability should be enhanced in the results and discussion.</p>
<p>(2) The presentation of results is not clear enough, including figures, wording, and statistical analysis, which contributes to the overall difficulty in understanding the manuscript. This lack of clarity in presenting key findings can obscure the insights that the study aims to convey, making it challenging for readers to fully grasp the implications and significance of the research.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.98725.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Englert et al. use a novel modelling approach called functional connectome-based Hopfield Neural Networks (fcHNN) to describe spontaneous and task-evoked brain activity and the alterations in brain disorders. Given its novelty, the authors first validate the model parameters (the temperature and noise) with empirical resting-state function data and against null models. Through the optimisation of the temperature parameter, they first show that the optimal number of attractor states is four before fixing the optimal noise that best reflects the empirical data, through stochastic relaxation. Then, they demonstrate how these fcHNN-generated dynamics predict task-based functional activity relating to pain and self-regulation. To do so, they characterise the different brain states (here as different conditions of the experimental pain paradigm) in terms of the distribution of the data on the fcHNN projections and flow analysis. Lastly, a similar analysis was performed on a population with autism condition. Through Hopfield modeling, this work proposes a comprehensive framework that links various types of functional activity under a unified interpretation with high predictive validity.</p>
<p>Strengths:</p>
<p>The phenomenological nature of the Hopfield model and its validation across multiple datasets presents a comprehensive and intuitive framework for the analysis of functional activity. The results presented in this work further motivate the study of phenomenological models as an adequate mechanistic characterisation of large-scale brain activity.</p>
<p>Following up on Cole et al. 2016, the authors put forward a hypothesis that many of the changes to the brain activity, here, in terms of task-evoked and clinical data, can be inferred from the resting-state brain data alone. This brings together neatly the idea of different facets of brain activity emerging from a common space of functional (ghost) attractors.</p>
<p>The use of the null models motivates the benefit of non-linear dynamics in the context of phenomenological models when assessing the similarity to the real empirical data.</p>
<p>Weaknesses:</p>
<p>While the use of the Hopfield model is neat and very well presented, it still begs the question of why to use the functional connectome (as derived by activity flow analysis from Cole et al. 2016). Deriving the functional connectome on the resting-state data that are then used for the analysis reads as circular. If the fcHNN derives the basins of four attractors that reflect the first two principal components of functional connectivity, it perhaps suffices to use the empirically derived components alone and project the task and clinical data on it without the need for the fcHNN framework.</p>
<p>As presented here, the Hopfield model is excellent in its simplicity and power, and it seems suited to tackle the structure-function relationship with the power of going further to explain task-evoked and clinical data. The work could be strengthened if that was taken into consideration. As such the model would not suffer from circularity problems and it would be possible to claim its mechanistic properties. Furthermore, as mentioned above, in the current setup, the connectivity matrix is based on statistical properties of functional activity amongst regions, and as such it is difficult to talk about a certain mechanism. This contention has for example been addressed in the Cole et al. 2016 paper with the use of a biophysical model linking structure and function, thus strengthening the mechanistic claim of the work.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.98725.1.sa3</article-id>
<title-group>
<article-title>Author Response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Englert</surname>
<given-names>Robert</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Kincses</surname>
<given-names>Balint</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Kotikalapudi</surname>
<given-names>Raviteja</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Gallitto</surname>
<given-names>Giuseppe</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Li</surname>
<given-names>Jialin</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Hoffschlag</surname>
<given-names>Kevin</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Woo</surname>
<given-names>Choong-Wan</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-7423-5422</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Wager</surname>
<given-names>Tor D</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Timmann</surname>
<given-names>Dagmar</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Bingel</surname>
<given-names>Ulrike</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Spisak</surname>
<given-names>Tamas</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2942-0821</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>We would like to thank the reviewers for their constructive feedback and for acknowledging that our approach offers a simple yet powerful framework with the potential to serve as a comprehensive and intuitive tool for analyzing functional activity and connectivity.</p>
<p>In response to the reviewers’ recommendations, we will aim to improve and clarify the following aspects of our work in an upcoming revision:</p>
<p><bold>Scope and limitations of the “fcHNN projection” (R#1 and R#2):</bold></p>
<p>Both reviewers have correctly noted that the interpretability and explanatory power of the simplistic, two-dimensional fcHNN-based projection is limited. In the revised manuscript, we will clarify that, indeed, attractors are in a close mathematical relationship with the principal components of the raw data (i.e., the eigenvectors of the connectome) within our framework. The fcHNN-projection was introduced solely to establish a link between the proposed framework and concepts with which the reader may be more familiar.</p>
<p>We will enhance the presentation and discussion of our results to emphasize that – as the reviewers also kindly pointed out - the value of our approach lies in modelling how different facets of brain activity dynamically emerge from a common space of functional (ghost) attractors, rather than studying in the static attractor patterns themselves.</p>
<p><bold>Motivations and Rationale for Using the Functional Connectome (R#2):</bold></p>
<p>We agree with Reviewer #2 that a deeper mechanistic explanatory power could be achieved by modeling structure-function coupling, and that our framework is well-suited for this challenge. In our revision, we will highlight this as one of the promising future applications of our framework. We will, furthermore, clarify that the scope of the present work was deliberately restricted to functional connectivity to demonstrate that our framework also allows us to “bypass” the significant challenge of structure-function coupling. This enables us to focus on understanding the origins of canonical resting-state networks, the dynamic responses of the system to perturbations and the complex relationship between task-induced activity and resting-state connectivity, without first solving the structure-function coupling problem.</p>
<p>Additionally, we will mathematically justify the use of linear measures of the functional connectome to reconstruct the underlying non-linear dynamic system, thereby clearly delineating which results can and cannot be considered circular when starting from the functional connectome.</p>
<p><bold>Improvements in Overall Clarity of Presentation (R#1):</bold></p>
<p>In line with the above points and in general, we will strive to enhance the overall clarity of the presentation of our results, including figures, wording, and statistical analysis.</p>
</body>
</sub-article>
</article>