<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">94835</article-id>
<article-id pub-id-type="doi">10.7554/eLife.94835</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.94835.2</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.3</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories><title-group>
<article-title>Neural coding of multiple motion speeds in visual cortical area MT</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Huang</surname>
<given-names>Xin</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>Xin.Huang@wisc.edu</email>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Ghimire</surname>
<given-names>Bikalpa</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Chakrala</surname>
<given-names>Anjani Sreeprada</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Wiesner</surname>
<given-names>Steven</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01y2jtd41</institution-id><institution>Department of Neuroscience, University of Wisconsin-Madison</institution></institution-wrap>, <city>Madison</city>, <country country="US">United States</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Groh</surname>
<given-names>Jennifer M</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Duke University</institution>
</institution-wrap>
<city>Durham</city>
<country country="US">United States</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Gold</surname>
<given-names>Joshua I</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Pennsylvania</institution>
</institution-wrap>
<city>Philadelphia</city>
<country country="US">United States</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-03-28">
<day>28</day>
<month>03</month>
<year>2024</year>
</pub-date>
<pub-date date-type="update" iso-8601-date="2025-07-17">
<day>17</day>
<month>07</month>
<year>2025</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP94835</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-01-03">
<day>03</day>
<month>01</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-11-22">
<day>22</day>
<month>11</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.04.08.532456"/>
</event>
<event>
<event-desc>Reviewed preprint v1</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2024-03-28">
<day>28</day>
<month>03</month>
<year>2024</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.94835.1"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.94835.1.sa3">eLife assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.94835.1.sa2">Reviewer #1 (Public Review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.94835.1.sa1">Reviewer #2 (Public Review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.94835.1.sa0">Reviewer #3 (Public Review):</self-uri>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Huang et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Huang et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-94835-v2.pdf"/>
<abstract>
<title>Abstract</title>
<p>Segmenting objects from each other and their background is critical for vision. Motion speed provides a salient cue for segmentation, yet how the visual system represents and differentiates multiple speeds remains poorly understood. We investigated the neural coding of multiple motion speeds in the primate visual cortex. First, we characterized the perceptual capacity of human and macaque subjects to segment overlapping random-dot stimuli moving at different speeds. We then recorded from neurons in the middle temporal (MT) cortex of macaque monkeys to determine how multiple speeds are represented. We made a novel finding that the responses of MT neurons to two speeds showed a robust bias toward the faster speed component when both speeds were slow (≤ 20<sup>°</sup>/s). This faster-speed bias emerged early in the neuronal response. It occurred regardless of whether the two speed components moved in the same or different directions, and even when attention was directed away from the receptive field. As stimulus speed increased, the faster-speed bias diminished and eventually disappeared at high speeds. Our finding can be explained by a modified divisive normalization model, in which the weights for the speed components are proportional to the responses of a population of neurons elicited by the individual speeds. We suggest that the neuron population, referred to as the weighting pool, includes neurons with a broad range of speed preferences. We also showed that a classifier can differentiate the responses of MT neurons to two speeds versus a single log-mean speed. We further showed that it was possible to decode two speeds from MT population response, supporting the theoretical framework of coding multiplicity of visual features in neuronal populations. The decoded speeds from MT population can account for the perceptual performance of segmenting two speeds with a large (×4) difference but not a small (×2) difference, raising questions for future investigations. Our findings help to define the neural coding rule of multiple speeds. The faster-speed bias in MT at slow stimulus speeds could benefit important behavioral tasks such as figure-ground segregation, as figural objects tend to move faster than the background in the natural environment.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>neural encoding</kwd>
<kwd>decoding</kwd>
<kwd>segmentation</kwd>
<kwd>discrimination</kwd>
<kwd>speed tuning</kwd>
<kwd>velocity</kwd>
<kwd>transparent motion</kwd>
<kwd>divisive normalization</kwd>
<kwd>figure-ground segregation</kwd>
<kwd>natural scenes</kwd>
<kwd>efficient coding</kwd>
</kwd-group>
<funding-group>
<award-group id="funding-1">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/03wkg3b53</institution-id>
<institution>National Eye Institute</institution>
</institution-wrap>
</funding-source>
<award-id>R01 EY022443</award-id>
</award-group>
</funding-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>1). We included a comprehensive decoding analysis that extracts either a single speed or two distinct speeds from MT population responses. Using the decoded speeds, we conducted a speed discrimination task analogous to the psychophysical experiments. We updated the title to emphasize both encoding and decoding aspects, changing neural encoding to neural coding of multiple motion speeds. 2). To address concerns that subtracting a common term (Rs) might introduce correlations between (R - Rs) and (Rf - Rs), we performed an additional analysis demonstrating that such confounding effects cannot account for our main findings. 3). We applied a modified normalization model to a better-constrained dataset comprising full direction-tuning curves of stimuli moving in two different directions at two speeds.
We have also expanded our discussion to address the implications and limitations of our results, and revised the text to state our hypotheses, methods, and interpretations more clearly throughout the manuscript.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Neuroscientists have been investigating how neurons in the brain represent sensory information for decades. Previous studies were often concerned with the neural coding of a single visual stimulus. However, natural environments are abundant with multiple entities that often co-occupy visual neurons’ receptive fields (RFs). Segmenting visual objects from each other and their background is a fundamental function of vision (<xref ref-type="bibr" rid="c12">Braddick, 1993</xref>), yet the neural mechanisms underlying the representation of multiple stimuli remain poorly understood. As the field moves toward understanding visual processing under more naturalistic conditions, it becomes increasingly important to uncover the principles by which the brain encodes multiple visual stimuli. Visual motion is a particularly salient cue for scene segmentation. Elements that share common motion are typically grouped into a single perceptual object, while entities moving at different velocities can often be segregated from each other. For instance, an object moving at a speed distinct from its background is more readily segmented. In this study, we investigated how the primate visual system represents multiple motion speeds.</p>
<p>The extrastriate middle-temporal cortex (area MT) is important for motion processing and motion-based segmentation (<xref ref-type="bibr" rid="c1">Allman et al., 1985</xref>; <xref ref-type="bibr" rid="c15">Britten, 2003</xref>; <xref ref-type="bibr" rid="c10">Born and Bradley, 2005</xref>; <xref ref-type="bibr" rid="c55">Pasternak et al., 2020</xref>; <xref ref-type="bibr" rid="c11">Born et al., 2000</xref>; <xref ref-type="bibr" rid="c30">Huang et al., 2007</xref>, <xref ref-type="bibr" rid="c31">2008</xref>). Segmentation of overlapping stimuli moving at different directions and speeds gives rise to the perception of transparent motion (<xref ref-type="bibr" rid="c13">Braddick, 1997</xref>; <xref ref-type="bibr" rid="c14">Braddick et al., 2002</xref>; <xref ref-type="bibr" rid="c46">Mestre et al., 2001</xref>; <xref ref-type="bibr" rid="c43">Masson et al., 1999</xref>). Previous studies have investigated how neurons in area MT represent two motion directions of transparently moving stimuli (<xref ref-type="bibr" rid="c71">Snowden et al., 1991</xref>; <xref ref-type="bibr" rid="c62">Qian and Andersen, 1994</xref>; <xref ref-type="bibr" rid="c45">McDonald et al., 2014</xref>; <xref ref-type="bibr" rid="c81">Xiao et al., 2014</xref>; <xref ref-type="bibr" rid="c80">Xiao and Huang, 2015</xref>; <xref ref-type="bibr" rid="c79">Wiesner et al., 2020</xref>; <xref ref-type="bibr" rid="c73">Stoner and Albright, 1992</xref>; <xref ref-type="bibr" rid="c35">Krekelberg and van Wezel, 2013</xref>). Although how cortical neurons represent the speed of a single stimulus has been well-studied (<xref ref-type="bibr" rid="c44">Maunsell and van Essen, 1983</xref>; <xref ref-type="bibr" rid="c39">Lisberger and Movshon, 1999</xref>; <xref ref-type="bibr" rid="c51">Nover et al., 2005</xref>; <xref ref-type="bibr" rid="c54">Pack et al., 2005</xref>; <xref ref-type="bibr" rid="c36">Krekelberg et al., 2006a</xref>; <xref ref-type="bibr" rid="c56">Perrone and Thiele, 2001</xref>; <xref ref-type="bibr" rid="c60">Priebe et al., 2003</xref>, <xref ref-type="bibr" rid="c61">2006</xref>; <xref ref-type="bibr" rid="c40">Liu and Newsome 2003</xref>), how neurons represent multiple speeds of transparently moving stimuli is largely unknown.</p>
<p>In characterizing how MT neurons represent multiple directions of transparently moving stimuli, we have previously shown that many neurons do not pool two directions equally, but weigh one direction more than the other (<xref ref-type="bibr" rid="c80">Xiao and Huang, 2015</xref>). We have also found that some MT neurons show response nonlinearity in pooling two motion directions in a way that better represents the individual direction components. The heterogeneous response weights and response nonlinearity in representing multiple directions can benefit the neural coding of multiple stimuli (<xref ref-type="bibr" rid="c53">Orhan and Ma, 2015</xref>; <xref ref-type="bibr" rid="c80">Xiao and Huang, 2015</xref>), and may constitute an optimal population representation of visual motion with multiple directions (<xref ref-type="bibr" rid="c28">Huang et al., 2017</xref>). Unlike two motion directions for which the individual directions appear to be balanced in perceptual quality and salience, visual stimuli moving at two speeds appear to be asymmetrical – one slower and one faster. The goal of this study is to determine the neural coding principle for multiple speeds of overlapping stimuli.</p>
<p>Visual information is encoded in the brain by populations of neurons, and Bayesian inference provides a robust framework for understanding the population neural code (<xref ref-type="bibr" rid="c57">Pouget et al., 2000</xref>; <xref ref-type="bibr" rid="c6">Averbeck et al., 2006</xref>; <xref ref-type="bibr" rid="c41">Ma et al., 2006</xref>; Fisher et al., 2010). Additionally, the visual system may be optimized to represent information in natural environments and to enhance performance in key behavioral tasks (<xref ref-type="bibr" rid="c8">Barlow, 1961</xref>; <xref ref-type="bibr" rid="c4">Atick and Redlich, 1992</xref>; <xref ref-type="bibr" rid="c70">Simoncelli and Olshausen, 2001</xref>; <xref ref-type="bibr" rid="c25">Ganguli and Simoncelli, 2014</xref>; <xref ref-type="bibr" rid="c42">Manning et al., 2024</xref>). Within this framework, we consider several scenarios for how MT neurons might encode two motion speeds within their RFs. 1) <italic>Response averaging</italic>: MT neurons may average the responses elicited by individual speed components, a phenomenon often observed in neural responses to multiple stimuli (e.g., <xref ref-type="bibr" rid="c63">Recanzone et al., 1997</xref>; <xref ref-type="bibr" rid="c85">Zoccolan et al., 2005</xref>). When the separation between the two speeds is smaller than the neuron’s tuning width, the population response to two speeds would appear unimodal, peaking at an intermediate speed. While decoding two stimuli from a unimodal response is theoretically possible (<xref ref-type="bibr" rid="c83">Zemel et al., 1998</xref>; <xref ref-type="bibr" rid="c74">Treue et al., 2000</xref>), response averaging may result in poorer segmentation compared to encoding schemes that emphasize individual components, as demonstrated in neural coding of overlapping motion directions (<xref ref-type="bibr" rid="c80">Xiao and Huang, 2015</xref>). 2) <italic>Bias toward the stronger component response</italic>: A neuron may favor the speed component that elicits a stronger response, following a soft-max operation (<xref ref-type="bibr" rid="c64">Riesenhuber and Poggio, 1999</xref>). This scheme allows neurons to preferentially encode stimuli closer to their preferred speed and maintain a population code representing both components. 3) <italic>Bias toward the slower speed component</italic>: Given that slower speeds are more prevalent in natural environments (<xref ref-type="bibr" rid="c78">Weiss et al., 2002</xref>; <xref ref-type="bibr" rid="c72">Stocker and Simoncelli, 2006</xref>; <xref ref-type="bibr" rid="c84">Zhang and Stocker, 2022</xref>), MT neurons may favor slower components. Such encoding would align with the prior probability of natural speed distributions, optimizing for more frequent stimuli. 4) <italic>Bias toward the faster speed component</italic>: Neurons may prioritize faster-moving components. This scheme would allow better segmentation of a faster-moving stimulus from a slower background and facilitate the critical perceptual task of figure-ground segregation. Finally, we explored whether these encoding rules depend on the stimulus speeds and the speed preferences of individual neurons.</p>
<p>Regarding neural decoding, previous studies successfully extracted single stimulus speeds from neuronal populations in area MT using decoders such as vector-averaging and maximum likelihood estimators (<xref ref-type="bibr" rid="c39">Lisberger and Movshon, 1999</xref>; <xref ref-type="bibr" rid="c23">Churchland and Lisberger, 2001</xref>; <xref ref-type="bibr" rid="c59">Priebe and Lisberger, 2004</xref>; <xref ref-type="bibr" rid="c29">Huang and Lisberger, 2009</xref>; <xref ref-type="bibr" rid="c82">Yang and Lisberger, 2009</xref>; <xref ref-type="bibr" rid="c36">Krekelberg et al., 2006a</xref>, b; <xref ref-type="bibr" rid="c35">Krekelberg and van Wezel, 2013</xref>). However, it is unclear whether simultaneously presented multiple speeds can be extracted from population neural responses, which would be difficult for decoders that only read out a single value. Zemel and colleagues developed a decoding framework that recovers the probabilistic distribution of a stimulus feature (<xref ref-type="bibr" rid="c83">Zemel et al., 1998</xref>; <xref ref-type="bibr" rid="c58">Pouget et al., 2003</xref>). Decoders of this type remain to be tested with neurophysiological and perceptual data.</p>
<p>We first characterized the perception of overlapping stimuli that moved simultaneously at two speeds. Our results showed that human and monkey subjects can segment overlapping stimuli based only on speed cues. The performance was better when the separation between two stimulus speeds was larger, and the ability of speed segmentation was reduced when stimulus speeds were fast. Next, we recorded neuronal responses from area MT of male macaque monkeys. We made a novel finding that MT neurons showed a strong faster-speed bias when stimulus speeds were slow, and as stimulus speeds increased, the faster-speed bias gradually shifted to response averaging. We also showed that a classifier could differentiate a two-speed stimulus from a single-speed stimulus based on MT responses in a way generally consistent with perception. We proposed a model in which each speed component was weighted by the responses of a population of neurons with a broad range of speed preferences elicited by that speed component. We also found that information about multiple speeds was carried in the population neural response in MT, and it was possible to extract either a single speed or multiple speeds from area MT in a way largely consistent with perception, with limitations when two stimulus speeds were less separated from each other. This study helps to fill a gap in understanding the neural coding principle of multiple motion speeds and provides new insight into the mechanism underlying the neural representation of multiple visual stimuli.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Perception of overlapping stimuli moving at different speeds</title>
<sec id="s2a1">
<title>Human psychophysics</title>
<p>To establish the perceptual basis for our study, we first characterized how human subjects perceived overlapping stimuli moving at different speeds. We used similar visual stimuli in our psychophysics experiments as in our neurophysiology experiments. We asked how perceptual segmentation was impacted by the separation between two stimulus speeds, and as the mean stimulus speed changed from slow to fast.</p>
<p>The visual stimuli were two overlapping random-dot patches presented within a stationary square aperture 10° wide and centered at 11° eccentricity. The random dots translated within the aperture in the same direction at two different speeds. It has been suggested that the neural representation of speed in the visual cortex is encoded on a logarithmic scale (<xref ref-type="bibr" rid="c44">Maunsell and van Essen, 1983</xref>; <xref ref-type="bibr" rid="c39">Lisberger and Movshon, 1999</xref>; <xref ref-type="bibr" rid="c51">Nover et al., 2005</xref>), so we used a fixed ratio between two speeds, which gave rise to a fixed speed difference in the logarithmic scale. One set of stimuli had a “large speed separation”, and the speed of the faster component was four times (x4) that of the slower component. The five speed pairs used were 1.25 and 5°/s, 2.5 and 10°/s, 5 and 20°/s, 10 and 40°/s, and 20 and 80°/s (<xref rid="fig1" ref-type="fig">Fig. 1B1</xref>). Another set of stimuli had a “small speed separation”, and the speed ratio was two (x2). The five speed pairs were 1.25 and 2.5°/s, 2.5 and 5°/s, 5 and 10°/s, 10 and 20°/s, and 20 and 40°/s (<xref rid="fig1" ref-type="fig">Fig. 1B2</xref>). Experimental trials of bi-speed stimuli that had large and small speed separations were randomly interleaved.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Psychophysical tasks and performance of human subjects.</title>
<p><bold>A</bold>. Illustration of the 2AFC and 3AFC tasks. <bold>B</bold>. Motion speeds of visual stimuli. The speeds of two stimulus components were plotted versus the log mean speed of each bi-speed stimulus. <bold>C</bold>. Discriminability of four human subjects performing a standard 2AFC task. Letters are coded symbols for individul subjects. <bold>D</bold>. In the 3AFC task, the percentage of trials that human subjects reported “no two-speeds”. <bold>E</bold>. Discriminability of the same subjects performing the 3AFC task. <bold>B1-E1</bold>. X4 speed separation. <bold>B2-E2</bold>. X2 speed separation. Each color represents data from one subject. The solid line shows the subject-averaged result. Error bars and error bands represent ±STE.</p></caption>
<graphic xlink:href="532456v3_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Human subjects first performed a standard two-alternative-forced-choice (2AFC) task to discriminate a bi-speed stimulus from the corresponding single-speed stimulus that moved at the log mean speed of the two component speeds. In each trial, the bi-speed and single-speed stimuli were presented in two consecutive time intervals in a random and balanced order (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>). At large (x4) speed separation, all four subjects could perform the task well when the component speeds were less than 20 and 80°/s (<xref rid="fig1" ref-type="fig">Fig. 1C1</xref>). At 20 and 80°/s, the discrimination performance was poor (mean <italic>d’</italic> = 0.74, standard error STE = 0.5), indicating that subjects could not segment the speed components. At the small (x2) speed separation, the discriminability was worse than at the x4 separation. When the component speeds were less than 20 and 40°/s, subjects on average could differentiate the bi-speed stimulus from the single-speed stimulus (<italic>d’</italic> &gt; 1.5), but not when speeds were at 20 and 40°/s (mean <italic>d’</italic> = 0.17, STE = 0.1) (<xref rid="fig1" ref-type="fig">Fig. 1C2</xref>).</p>
<p>In the standard 2AFC task, it is possible that subjects could not segment the bi-speed stimulus into two separate speeds, but were still able to differentiate the bi-speed from single-speed stimuli based on their appearances (e.g., the distribution of the random dots of the bi-speed stimulus may appear less uniform). Because our goal was to measure discriminability based on perceptual segmentation, we designed a novel 3AFC task to address this concern. In the modified task, subjects still discriminated the bi-speed stimulus from the corresponding single-speed stimulus but had the option to make a third choice on trials when they thought neither stimulus interval appeared to contain two speeds (“no two-speeds” choice) (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>). Panels D1 and D2 show the percentage of trials in which subjects made the no two-speeds choice (NTC). At x4 speed separation, the percentage of NTC was low at most speed pairs. Except at the highest speeds of 20 and 80°/s, subjects reported they could not see two speeds in most trials (<xref rid="fig1" ref-type="fig">Fig. 1D1</xref>). At x2 speed separation, the percentage of NTC showed a U-shape as a function of the stimulus speed, and was near 100% at 20 and 40°/s (<xref rid="fig1" ref-type="fig">Fig. 1D2</xref>). These results confirmed that human subjects had difficulty segmenting two speeds when stimulus speeds were high. In addition, at low stimulus speeds with a small (x2) speed separation, subjects tended to perceive only one speed (<xref rid="fig1" ref-type="fig">Fig. 1D2</xref>). We incorporated the NTC into the <italic>d’</italic> calculation by evenly splitting the NTC trials into “hit” trials and “false alarm” trials (see Methods). In this way, the NTC trials were accounted for by <italic>d’</italic>, in the sense that they did not contribute to successful discrimination.</p>
<p>The <italic>d’</italic> from the 3AFC task were similar to those of the 2AFC task, with a slight reduction of <italic>d’</italic> across conditions as the NTC trials reduced discrimination performance (<xref rid="fig1" ref-type="fig">Fig. 1E1</xref> vs. <xref rid="fig1" ref-type="fig">1C1, 1E2</xref> vs. <xref rid="fig1" ref-type="fig">1C2</xref>). The small performance difference between the 2AFC and 3AFC tasks suggests that human subjects generally relied on speed segmentation to perform the 2AFC task. Based on the results from the 3AFC task, we performed a two-way ANOVA, in which the two factors were the mean speed of the stimulus components and the speed separation (x4 or x2). We found that both factors had significant effects. <italic>d’</italic> changed significantly with the mean stimulus speed (F(4,30) = 26.8, p = 1.60×10<sup>−9</sup>) and the <italic>d’</italic> at x4 separation differed significantly from that at x2 separation (F(1,30) = 84.1, p = 3.29×10<sup>−10</sup>). <italic>d’</italic> was higher at x4 than at x2 speed separation except at the fastest speeds of 20 and 80°/s vs. 20 and 40°/s (<xref rid="fig1" ref-type="fig">Fig. 1E1</xref> vs. <xref rid="fig1" ref-type="fig">1E2</xref>). Our results also showed that segmentation was significantly worse at fast speeds – <italic>d’</italic> dropped significantly as the stimulus speeds increased from 10 and 40°/s to 20 and 80°/s for x4 separation (one-way ANOVA, F(1,6) = 38.6, p = 8.1×10<sup>−4</sup>) (<xref rid="fig1" ref-type="fig">Fig. 1E1</xref>), and from 10 and 20°/s to 20 and 40°/s for x2 separation (one-way ANOVA, F(1,6) = 32.7, p = 1.24×10<sup>−3</sup>) (<xref rid="fig1" ref-type="fig">Fig. 1E2</xref>).</p>
</sec>
<sec id="s2a2">
<title>Monkey psychophysics</title>
<p>We next measured the monkey’s ability to segment overlapping stimuli moving at two speeds. We trained one male macaque monkey to perform a 2AFC task to report whether a stimulus contained one or two speeds (<xref rid="fig2" ref-type="fig">Fig. 2A</xref>, see Methods). The monkey’s performance at x2 speed separation (<xref rid="fig2" ref-type="fig">Fig. 2B2</xref>) was very similar in shape to that of humans (<xref rid="fig1" ref-type="fig">Fig. 1C2</xref> of the 2AFC task). In addition, the monkey’s performance was generally better at x4 separation than at x2 separation (<xref rid="fig2" ref-type="fig">Fig. 2B1</xref> vs <xref rid="fig2" ref-type="fig">2B2</xref>).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Monkey psychophysics.</title>
<p><bold>A</bold>. Behavioral task and visual stimuli. <bold>B</bold>. Discriminability of a monkey subject performing a 2AFC task. <bold>B1</bold>. X4 speed separation. <bold>B2</bold>. X2 speed separation. Error bars and error bands represent ±STE.</p></caption>
<graphic xlink:href="532456v3_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>At x4 separation, the performance improved as the stimulus speeds increased from 1.25 and 5°/s to 5 and 20°/s. As the stimulus speeds increased from 5 and 20°/s to 20 and 80°/s, the performance declined (<xref rid="fig2" ref-type="fig">Fig. 2B1</xref>), similar to the human results (<xref rid="fig1" ref-type="fig">Fig. 1C1</xref>). However, the monkey was still able to differentiate the bi-speed and single-speed stimuli at the fastest speeds of 20 and 80°/s (<xref rid="fig2" ref-type="fig">Fig. 2B1</xref>), whereas the average human performance was poor (<xref rid="fig1" ref-type="fig">Fig. 1C1</xref>). Note that one human subject (NP) performed better than other subjects at 20 and 80°/s (mean <italic>d’</italic> = 2.12, STE = 0.12) (<xref rid="fig1" ref-type="fig">Fig. 1C1</xref>). The difference between the monkey and human results may be due to species differences or individual variability. The differences in behavioral tasks may also play a role – the monkey received feedback on the correctness of the choice, whereas human subjects did not.</p>
<p>Another notable difference between the monkey and human results was that, at low stimulus speeds of 1.25 and 5°/s, human subjects could differentiate the bi-speed stimulus from the corresponding single-speed (2.5°/s) stimulus nearly perfectly. In comparison, the ability of the monkey subject to segment 1.25 and 5 °/s was lower (<italic>d’</italic> = 2.8, STE = 0.51), although still good (<xref rid="fig2" ref-type="fig">Fig 2B1</xref> vs <xref rid="fig1" ref-type="fig">1C1</xref>). This may be explained by how the monkey performed the task. For human subjects, while the motion of the faster component (5°/s) of the bi-speed stimulus appeared to be salient, it required effort to notice the very slow component (1.25°/s) to be moving rather than stationary. In some trials, the monkey may be able to segment the 5°/s component from the bi-speed stimulus but consider the slower component of 1.25°/s as stationary and, therefore, reported that the stimulus contained only one speed. Despite some differences between the human and monkey results, the two general trends – better segmentation performance at larger than smaller speed separation and reduced segmentation ability at very fast speeds were consistent across species.</p>
</sec>
</sec>
<sec id="s2b">
<title>Neuronal responses in MT elicited by bi-speed stimuli and single-speed components</title>
<p>To characterize how neurons in the visual cortex encode two overlapping stimuli moving at different speeds, we recorded extracellularly from 100 isolated neurons in area MT of two male macaque monkeys (60 neurons from IM and 40 neurons from MO) while the monkeys performed a fixation task. <xref rid="fig3" ref-type="fig">Figure 3</xref> shows the responses from four example neurons. To visualize the relationship between the responses to the bi-speed stimulus (red) and the constituent speed components, the plots of the response tuning curves to the slower (green) and faster (blue) components are shifted horizontally so that the responses elicited by the bi-speed stimulus and its constituent single-speed components are aligned along a vertical line as illustrated in <xref rid="fig3" ref-type="fig">Figure 3A1</xref>.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Speed tuning curves of four example neurons to bi-speed stimuli and constituent single-speed components.</title>
<p><bold>A</bold>. Illustration of the visual stimuli and the response tuning curves of an example neuron. Green and blue dots in the diagram indicate two overlapping achromatic random-dot patterns moving in the same direction at different speeds. Colors are used for illustration purposes only. The abscissas in green and blue show the speeds of the slower and faster components, respectively. The abscissa in black shows the log mean speed of the two speed components. <bold>A-D</bold>. Four example neurons are sorted by their preferred speeds (PS) from slow to fast. Error bars represent ±STE. For some data points, error bars were comparable to the symbol size. <bold>A1-D1</bold>. X4 speed separation. <bold>A2-D2</bold>. X2 speed separation.</p></caption>
<graphic xlink:href="532456v3_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We found that the relationship between the responses elicited by the bi-speed stimulus and the constituent components depended on the stimulus speeds. <xref rid="fig3" ref-type="fig">Figure 3A1-D1</xref> shows the responses of four MT neurons when the speed separation was large (×4). The component speeds were the same as the bi-speed stimuli used in the psychophysics experiments. When the two component speeds were slow (1.25 and 5°/s), the response to the bi-speed stimulus nearly followed the response elicited by the faster-speed component (the leftmost data points in <xref rid="fig3" ref-type="fig">Fig. 3A1-D1</xref>). Importantly, the response elicited by the bi-speed stimuli did not simply follow the stronger component response. When the preferred speed of a neuron was sufficiently low such that the response elicited by the faster component was weaker than that elicited by the slower component, the response to the bi-speed stimulus still followed the weaker response elicited by the faster component (<xref rid="fig3" ref-type="fig">Fig. 3A1</xref>). When the speeds of the two stimulus components were at 2.5 and 10°/s, the response elicited by the bi-speed stimulus was also biased toward the faster component, albeit to a lesser degree. As the mean speed of the two stimulus components increased, the bi-speed response became closer to the average of the two component responses (<xref rid="fig3" ref-type="fig">Fig. 3A1-D1</xref>). We found similar results when the speed separation between the two stimulus components was small (×2) (<xref rid="fig3" ref-type="fig">Fig. 3A2-D2</xref>).</p>
<p>We found the same trend in the neural responses averaged across 100 neurons (<xref rid="fig4" ref-type="fig">Fig. 4A</xref>). At ×4 speed separation, the population-averaged response showed a strong bias toward the faster component when the stimulus speeds were low and shifted toward the average of the component responses as the speeds increased (<xref rid="fig4" ref-type="fig">Fig. 4A1</xref>). To determine whether this trend held for neurons with different preferred speeds, we divided the neuron population into three groups with “low” (&lt;2.5°/s), “intermediate” (between 2.5 and 25°/s), and “high” (&gt;25°/s) preferred speeds. For 10 neurons that preferred low speeds, the response to the faster component was weaker than that to the slower component. However, the response to the bi-speed stimuli was strongly biased toward the faster component when the stimulus speeds were low (<xref rid="fig4" ref-type="fig">Fig. 4B1</xref>). This finding suggests that the bi-speed response is not biased toward the stimulus component that the neuron prefers when presented alone but biased toward the faster speed component.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Population-averaged speed tuning curves to bi-speed stimuli and constituent single-speed components.</title>
<p>Speed tuning curves averaged across <bold>A</bold>. 100 neurons in our dataset. <bold>B</bold>. 10 neurons that had PS lower than 2.5<sup>°</sup>/s. <bold>C</bold>. 61 neurons that had PS between 2.5 and 25<sup>°</sup>/s. <bold>D</bold>. 29 neurons that had PS greater than 25<sup>°</sup>/s. Error bars represent ±STE. For some data points, error bars were comparable to the symbol size. <bold>A1-D1</bold>. X4 speed separation. <bold>A2-D2</bold>. X2 speed separation.</p></caption>
<graphic xlink:href="532456v3_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>For 61 neurons that preferred intermediate speeds (<xref rid="fig4" ref-type="fig">Fig. 4C1</xref>) and 29 neurons that preferred high speeds (<xref rid="fig4" ref-type="fig">Fig. 4D1</xref>), we also found a strong bias toward the faster speed component when the stimulus speeds were low, and a gradual change toward the average of the component responses as the stimulus speeds increased. At the lowest stimulus speeds of 1.25 and 5°/s, the bi-speed response was nearly identical to that elicited by the faster component, showing “faster-component-take-all”. For neurons that preferred high speeds, faster-component-take-all was also found for the stimulus speeds of 2.5 and 10°/s (<xref rid="fig4" ref-type="fig">Fig. 4D1</xref>). At the fastest speeds of 20 and 80°/s, the response to the bi-speed stimuli showed a slight bias toward the slower component. We found similar results at x2 speed separation (<xref rid="fig4" ref-type="fig">Fig. 4A2-D2</xref>), although the effect is not as pronounced as x4 speed separation.</p>
</sec>
<sec id="s2c">
<title>Relationship between the responses to bi-speed stimuli and constituent stimulus components</title>
<p>We aimed to quantify the relationship between the response elicited by the bi-speed stimuli and the corresponding component responses. We first made an assumption that the response <italic>R</italic> of a neuron elicited by two component speeds can be described as a weighted sum of the component responses <italic>R</italic><sub><italic>s</italic></sub> and <italic>R</italic><sub><italic>f</italic></sub> elicited by the slower (<italic>v</italic><sub><italic>s</italic></sub>) and faster (<italic>v</italic><sub><italic>f</italic></sub>) component speed, respectively (<xref ref-type="disp-formula" rid="eqn5">Eq. 5</xref>).
<disp-formula id="eqn5">
<graphic xlink:href="532456v3_eqn5.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
in which, <italic>w</italic><sub><italic>s</italic></sub> and <italic>w</italic><sub><italic>f</italic></sub> are the response weights for the slower and faster speed component <italic>v</italic><sub><italic>s</italic></sub> and <italic>v</italic><sub><italic>f</italic></sub>, respectively.</p>
<p>Our goal was to estimate the weights for each speed pair and determine whether the weights change with the stimulus speeds. In our main data set, the two speed components moved in the same direction. To determine the weights of <italic>w</italic><sub><italic>s</italic></sub> and <italic>w</italic><sub><italic>f</italic></sub> for each neuron at each speed pair, we have three data points <italic>R, R</italic><sub><italic>s</italic></sub>, and <italic>R</italic><sub><italic>f</italic></sub>, which are trial-averaged responses. Since it is not possible to solve for both variables, <italic>w</italic><sub><italic>s</italic></sub> and <italic>w</italic><sub><italic>f</italic></sub>, from a single equation (<xref ref-type="disp-formula" rid="eqn5">Eq. 5</xref>) with three data values, we introduced an additional constraint: <italic>w</italic><sub><italic>s</italic></sub> + <italic>w</italic><sub><italic>f</italic></sub> =1. While this constraint may not yield the exact weights that would be obtained with a fully determined system, it nevertheless allows us to characterize how the relative weights vary with stimulus speed. With this constraint, as long as <italic>R</italic><sub><italic>f</italic></sub> ≠ <italic>R</italic><sub><italic>s</italic></sub>, <italic>R</italic> can be expressed as:
<disp-formula id="eqn6">
<graphic xlink:href="532456v3_eqn6.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula></p>
<p>The response weights are <inline-formula><inline-graphic xlink:href="532456v3_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. Intuitively, if <italic>R</italic> were closer to one component response, that stimulus component would have a higher weight. Note that <xref ref-type="disp-formula" rid="eqn6">Equation 6</xref> is not intended for fitting the response <italic>R</italic> using <italic>R</italic><sub><italic>s</italic></sub> and <italic>R</italic><sub><italic>f</italic></sub>, but rather to use the relationship among <italic>R, R</italic><sub><italic>s</italic></sub>, and <italic>R</italic><sub><italic>f</italic></sub> to determine the weights for the faster and slower components.</p>
<p>Using this approach to estimate response weights for individual neurons can be unreliable, particularly when <italic>R</italic><sub><italic>f</italic></sub> and <italic>Rs</italic> are similar. This situation often arises when the two speeds fall on opposite sides of the neuron’s preferred speed, resulting in a small denominator (<italic>R</italic><sub><italic>f</italic></sub> – <italic>Rs</italic>) and consequently an artificially inflated weight estimate. We, therefore, used the neuronal responses across the population to determine the response weights (<xref rid="fig5" ref-type="fig">Fig. 5</xref>). For each pair of stimulus speeds, we plotted (<italic>R - R</italic><sub><italic>s</italic></sub>) in the ordinate versus (<italic>R</italic><sub><italic>f</italic></sub> - <italic>R</italic><sub><italic>s</italic></sub>) in the abscissa. <xref rid="fig5" ref-type="fig">Figure 5A1-E1</xref> shows the results obtained at ×4 speed separation. Across the neuronal population, the relationship between (<italic>R - R</italic><sub><italic>s</italic></sub>) and (<italic>R</italic><sub><italic>f</italic></sub> - <italic>R</italic><sub><italic>s</italic></sub>) is well described by a linear equation (<xref ref-type="disp-formula" rid="eqn7">Eq. 7</xref>) (<italic>R</italic><sup><italic>2</italic></sup> ranged from 0.94 to 0.76, see <xref rid="tbl1" ref-type="table">Table 1</xref>). This linearity suggests that the response weights for each speed pair are consistent across the neuronal population.
<disp-formula id="eqn7">
<graphic xlink:href="532456v3_eqn7.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula></p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><title>Response weight for faster component based on linear regression (N = 100)</title></caption>
<graphic xlink:href="532456v3_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Relationship between the responses to the bi-speed stimuli and the constituent stimulus components.</title>
<p><bold>A-E</bold>. Each panel shows the responses from 100 neurons. Each dot represents the response from one neuron. The ordinate shows the difference between the responses to a bi-speed stimulus and the slower component (<italic>R - R</italic><sub><italic>s</italic></sub>). The abscissa shows the difference between the responses to the faster and slower components (<italic>R</italic><sub><italic>f</italic></sub> <italic>- R</italic><sub><italic>s</italic></sub>). The regression line is shown in red. <bold>F</bold>. Response weights for the faster stimulus component obtained from the slope of the linear regression based on the recorded responses of 100 neurons (black symbols), and based on simulated responses to the bi-speed stimuli (gray symbols). Error bars represent 95% confidence intervals. <bold>A1-F1</bold>. X4 speed separation. <bold>A2-F2</bold>. X2 speed separation.</p></caption>
<graphic xlink:href="532456v3_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Because all the regression lines in <xref rid="fig5" ref-type="fig">Figure 5</xref> nearly go through the origin (i.e. intercept <italic>b</italic> ≈ 0, <xref rid="tbl1" ref-type="table">Table 1</xref>), the slope <italic>k</italic> obtained from the linear regression approximates <inline-formula><inline-graphic xlink:href="532456v3_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, which is the response weight <italic>w</italic><sub><italic>f</italic></sub> for the faster component (<xref ref-type="disp-formula" rid="eqn6">Eq. 6</xref>). Hence, for each pair of stimulus speeds, we can estimate the response weight for the faster component using the slope of the linear regression of the responses from the neuronal population.</p>
<p>Our results showed that the bi-speed response showed a strong bias toward the faster component when the speeds were slow and changed progressively from a scheme of “faster-component-take-all” to “response-averaging” as the speeds of the two stimulus components increased (<xref rid="fig5" ref-type="fig">Fig. 5F1</xref>). We found similar results when the speed separation between the stimulus components was small (×2), although the bias toward the faster component at low stimulus speeds was not as strong as x4 speed separation (<xref rid="fig5" ref-type="fig">Fig. 5A2-F2</xref> and <xref rid="tbl1" ref-type="table">Table 1</xref>).</p>
<p>In the regression between (<italic>R</italic> − <italic>R</italic><sub><italic>s</italic></sub>) and (<italic>R</italic><sub><italic>f</italic></sub> – <italic>R</italic><sub><italic>s</italic></sub>), <italic>R</italic><sub><italic>s</italic></sub>was a common term and therefore could artificially introduce correlations. We wanted to determine whether our estimates of the regression slope (<italic>w</italic><sub><italic>f</italic></sub>) and the coefficient of determination (<italic>R</italic><sup><italic>2</italic></sup>) can be explained by this confounding factor. At each speed pair and for each neuron from the data sample of the 100 neurons shown in <xref rid="fig5" ref-type="fig">Figure 5</xref>, we simulated the response to the bi-speed stimuli (<italic>R</italic><sub><italic>e</italic></sub>) as a randomly weighted sum of <italic>R</italic><sub><italic>f</italic></sub> and <italic>R</italic><sub><italic>s</italic></sub> of the same neuron.
<disp-formula id="ueqn1">
<graphic xlink:href="532456v3_ueqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
in which <italic>a</italic> was a randomly generated weight (between 0 and 1) for <italic>R</italic><sub><italic>f</italic></sub>, and the weights for <italic>R</italic><sub><italic>f</italic></sub> and <italic>R</italic><sub><italic>s</italic></sub> summed to one. We then calculated the regression slope and the correlation coefficient between the simulated <italic>R</italic><sub><italic>e</italic></sub>-<italic>R</italic><sub><italic>s</italic></sub> and <italic>R</italic><sub><italic>f</italic></sub>-<italic>R</italic><sub><italic>s</italic></sub> across the 100 neurons. We repeated the process 1000 times and obtained the mean and 95% confidence interval (CI) of the regression slope and the <italic>R</italic><sup><italic>2</italic></sup>. The mean slope based on the simulated responses was 0.5 across all speed pairs. The estimated slope (<italic>w</italic><sub><italic>f</italic></sub>) based on the data was significantly greater than the simulated slope at slow speeds of 1.25/5, 2.5/10 (<xref rid="fig5" ref-type="fig">Fig. 5F1</xref>), and 1.25/2.5, 2.5/5, and 5/10 degrees/s (<xref rid="fig5" ref-type="fig">Fig. 5F2</xref>) (bootstrap test, see p values in <xref rid="tbl1" ref-type="table">Table 1</xref>). The estimated <italic>R</italic><sup><italic>2</italic></sup> based on the data was also significantly higher than the simulated <italic>R</italic><sup><italic>2</italic></sup> for most of the speed pairs (<xref rid="tbl1" ref-type="table">Table 1</xref>). These results suggest that the faster-speed bias at the slow stimulus speeds and the consistent response weights across the neuron population at each speed pair are not analysis artifacts.</p>
</sec>
<sec id="s2d">
<title>Timecourse of MT responses to bi-speed stimuli</title>
<p>The temporal dynamics of the response bias toward the faster component may provide a useful constraint on the neural model that accounts for this phenomenon. We therefore examined the timecourse of MT response to the bi-speed stimuli. We asked whether the faster-speed bias occurred early in the neuronal response or developed gradually.</p>
<p><xref rid="fig6" ref-type="fig">Figure 6</xref> shows the timecourse of the normalized responses averaged across 100 neurons in the population. The bias toward the faster speed component occurred at the very beginning of the neuronal response when the stimulus speeds were less than 20º/s (<xref rid="fig6" ref-type="fig">Fig. 6A-C</xref>). The first 20-30 ms of the neuronal response elicited by the bi-speed stimulus was nearly identical to the response elicited by the faster component alone, as if the slower component were not present. The early dominance of the faster component on the bi-speed response cannot be explained by the difference in the response latencies of the faster and slower components. Faster stimuli elicit a shorter response latency (<xref ref-type="bibr" rid="c39">Lisberger and Movshon, 1999</xref>), which can be seen in <xref rid="fig6" ref-type="fig">Figure 6A-C</xref>. However, the bi-speed response still closely followed the faster component for a period of time after the response to the slower component started to rise. The effect of the slower component on the bi-speed response was delayed for about 25 ms, as indicated by the arrows in <xref rid="fig6" ref-type="fig">Figure 6A-C</xref>. During the rest of the response period, the bias toward the faster component was persistent. As the stimulus speeds increased, the bi-speed response gradually changed to follow the average of the component responses (<xref rid="fig6" ref-type="fig">Fig. 6E</xref>). We found similar results when the speed separation between the two stimulus components was x4 (<xref rid="fig6" ref-type="fig">Fig. 6A1-E1</xref>) and x2 (<xref rid="fig6" ref-type="fig">Fig. 6A2-E2</xref>). At slow speeds, the very early faster-speed bias suggests a likely role of feedforward inputs to MT on the faster-speed bias. The slightly delayed reduction (normalization) in the bi-speed response relative to the stronger component response also helps constrain the circuit model for divisive normalization.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Timecourse of MT responses averaged across neurons to bi-speed stimuli.</title>
<p>Peristimulus time histograms (PSTHs) were averaged across 100 neurons. The bin width of PSTH was 10 ms. <bold>A1-E1</bold>. X4 speed separation. <bold>A2-E2</bold>. X2 speed separation. In A-C, the left dash line indicates the latency of the response to a bi-speed stimulus, and the right dash line and the arrow indicate when the response to a bi-speed stimulus started to diverge from the response to the faster component.</p></caption>
<graphic xlink:href="532456v3_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2e">
<title>Faster-speed bias still present when attention was directed away from the RFs</title>
<p>One possible explanation for the faster-speed bias is that bottom-up attention is drawn toward the faster stimulus component, enhancing the response to the faster component. To address this question, we asked whether the faster-speed bias was still present if attention was directed away from the RFs. We trained one monkey (RG) to perform a demanding fine direction-discrimination task in the visual hemifield opposite to the RFs. The perifoveal/peripheral viewing of the attended stimulus and using a fine direction-discrimination task made the task attention-demanding (see Methods). The monkey performed the task well with an average correct rate of 86.7 ± 7.3% (mean ± std) (see Methods and Supplementary Material 1).</p>
<p>We recorded the responses from 48 MT neurons in 23 experimental sessions while the monkey performed the task. Among the 48 neurons, 32 were recorded using both the attention-away paradigm and a fixation paradigm. We found a similar faster-speed bias at low speeds. The results obtained using the attention-away paradigm and the fixation paradigm were similar (<xref rid="figS1" ref-type="fig">Supplementary Fig. 1</xref>). The faster-speed bias was more evident at x4 speed separation than at x2 speed separation. Based on the neuronal responses across the population, we calculated the weight for the faster stimulus component at each of the five speed pairs using linear regression (<xref ref-type="disp-formula" rid="eqn6">Eqs. 6</xref>, <xref ref-type="disp-formula" rid="eqn7">7</xref>), as we did in <xref rid="fig5" ref-type="fig">Figure 5</xref>. When attention was directed away from the RFs, the response weight for the faster component decreased from a strong faster-speed bias to response averaging as the stimulus speeds increased, similar to the results from the fixation paradigm (<xref rid="fig7" ref-type="fig">Fig. 7</xref>). These results suggest that the faster-speed bias at low speeds cannot be explained by attention drawn to the faster-speed component.</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7.</label>
<caption><title>Comparison of response weights between attention-away and fixation paradigms.</title>
<p>The red and blue curves indicate the response weights for the faster speed component in an attention-away paradigm and a fixation paradigm, respectively, obtained from the same population of 32 neurons. The black curves are the replot of the data in <xref rid="fig5" ref-type="fig">Figure 5F</xref>, obtained from 100 neurons in a fixation paradigm. <bold>A</bold>. X4 speed separation. <bold>B</bold>. X2 speed separation.</p></caption>
<graphic xlink:href="532456v3_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2f">
<title>Faster speed bias also occurs when stimulus components move in different directions</title>
<p>We showed that at low speeds, MT response to the bi-speed stimulus was biased toward the faster stimulus component when two overlapping components moved in the same direction (at the preferred direction of the neuron). We asked whether this faster-speed bias also occurred when visual stimuli moved in different directions. We presented overlapping random-dot stimuli moving in two directions separated by 90° in the RF. The two stimulus components moved at speeds of 2.5 and 10°/s. The faster speed component moved on the clockwise side of the two directions. We varied the vector-average (VA) direction of the two component directions across 360° to characterize the direction tuning curves. Each neuron’s direction tuning curve was fitted with a spline and circularly shifted such that the VA direction 0° was aligned with the neuron’s preferred direction before averaging across neurons.</p>
<p><xref rid="fig8" ref-type="fig">Figure 8A</xref> shows the results averaged across 21 neurons (13 from monkey RG, 8 from monkey GE). The peak response to the faster component (<xref rid="fig8" ref-type="fig">Fig. 8A</xref>, blue curve) was stronger than that to the slower component (green curve), consistent with the overall speed preference of a large MT neuron population (<xref ref-type="bibr" rid="c51">Nover et al., 2005</xref>). MT responses elicited by the bi-directional stimuli (red curve) showed a strong bias toward the faster component, more than expected by the average of the two component responses (gray curve). The bi-speed response was biased toward the faster component regardless of whether the response to the faster component was stronger (in positive VA directions) or weaker (in negative VA directions) than that to slower component (<xref rid="fig8" ref-type="fig">Fig. 8A</xref>). The result from an example neuron further demonstrated that, even when the peak firing rates of the faster and slower component responses were similar, the response elicited by the bi-speed stimuli was still biased toward the faster component (<xref rid="fig8" ref-type="fig">Fig. 8B</xref>). These results suggest that the bias was not toward the strong component response of the individual neuron, but to the faster component.</p>
<fig id="fig8" position="float" fig-type="figure">
<label>Figure 8.</label>
<caption><title>MT responses to bi-speed stimuli moving in different directions and the linear weighted sum (LWS) and normalization model fits.</title>
<p><bold>A</bold>. Population-averaged direction tuning curves of 21 neurons in response to stimuli moving at two speeds and in two directions separated by 90<sup>°</sup> (red). The component direction Dir. 1 (blue) moved at 10<sup>°</sup>/s, and the component direction Dir. 2 (green) moved at 2.5<sup>°</sup>/s. The faster component Dir. 1 was always on the clockwise side of Dir. 2. The abscissas in blue and green show the directions of stimulus components Dir. 1 and Dir. 2, respectively. The blue and green axes are shifted by 90<sup>°</sup> relative to each other. The abscissa in black shows the corresponding VA direction of the two direction components. Error bands represent ±STE. The gray curve represents the average of the component responses. The orange and black curves are the LWS and normalization model fits, respectively, of the population-averaged direction-tuning curve to the bi-speed stimuli. <bold>B</bold>. The direction-tuning curves of an example neuron showing similar peak responses to the slower and faster components. The orange and black curves are nearly identical and are the LWS and normalization model fits of the bi-speed responses. The weights of <italic>w</italic><sub><italic>f</italic></sub>, <italic>w</italic><sub><italic>s</italic></sub> are from the normalization model fit. <bold>C</bold>. Response weights for the stimulus components obtained using the LWS model fit. Each circle represents one neuron. <bold>D</bold>. Response weights obtained using the normalization model fit. The dashed lines in C, D indicate where <italic>w</italic><sub><italic>s</italic></sub> and <italic>w</italic><sub><italic>f</italic></sub> sum to one. Although <italic>w</italic><sub><italic>s</italic></sub> and <italic>w</italic><sub><italic>f</italic></sub> are not constrained to sum to one in the model fits, the fitted weights are roughly aligned with the dashed lines. <bold>E</bold>. Population-averaged speed tuning curves of MT neurons recorded in our data sample in response to single speeds. The red circles indicate responses to 2.5 and 10º/s. Error bars represent ±STE.</p></caption>
<graphic xlink:href="532456v3_fig8.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To quantify the response weights, for each neuron we fitted the MT raw firing rates of the direction tuning curve to bi-speed/bi-directional stimuli as a linear weighted sum (LWS) of the direction tuning curves to the individual stimulus components moving at different speeds:
<disp-formula id="eqn8">
<graphic xlink:href="532456v3_eqn8.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<italic>R</italic><sub><italic>bi</italic></sub> is the model-fitted direction-tuning curves to the bi-speed and bi-direction stimuli. <italic>R</italic><sub><italic>s</italic></sub> and <italic>R</italic><sub><italic>f</italic></sub> are the measured direction tuning curves to the slower and faster stimulus components, respectively. <italic>θ</italic><sub>1</sub> and <italic>θ</italic><sub>2</sub> are the motion directions of the two components; <italic>w</italic><sub><italic>s</italic></sub>, <italic>w</italic><sub><italic>f</italic></sub>, and <italic>c</italic> are model parameters, which represent the response weights for the slower and faster components and an offset constant, respectively. <italic>c</italic> was constrained to be between 0 and 100 spikes/s. Because the model can be well constrained by the measured direction-tuning curves, it is not necessary to require <italic>w</italic><sub><italic>s</italic></sub> and <italic>w</italic><sub><italic>f</italic></sub> to sum to one, which is more general. An implicit assumption of the model is that, at a given pair of stimulus speeds, the response weights for the slower and faster components are fixed across motion directions. The model fitted MT responses very well, accounting for an average of 91.8% of the response variance (std = 7.2%, N = 21) (see Methods). The success of the model supports the assumption that the response weights are fixed across motion directions. The median response weights for the faster and slower components were 0.74 and 0.26, respectively, and were significantly different (Wilcoxon signed-rank test, p = 8.0 x10<sup>−5</sup>). For most neurons (20 out of 21), the response weight for the faster component was larger than that for the slower component (<xref rid="fig8" ref-type="fig">Fig. 8C</xref>). This result suggests that at low speeds, the faster-speed bias is a general phenomenon that applies to overlapping stimuli moving either in the same direction or different directions.</p>
</sec>
<sec id="s2g">
<title>Normalization model fit of the direction-tuning curves to bi-speed stimuli</title>
<p>We showed that the neuronal response in MT to a bi-speed stimulus can be described by a weighted sum of the neuron’s responses to the individual speed components. However, what determines the response weights? The divisive normalization model (<xref ref-type="bibr" rid="c19">Carandini and Heeger, 2012</xref>) has been used to explain a wide array of phenomena, including neuronal responses elicited by multiple visual stimuli (e.g. <xref ref-type="bibr" rid="c16">Britten and Heuer 1999</xref>; <xref ref-type="bibr" rid="c27">Heuer and Britten 2002</xref>; <xref ref-type="bibr" rid="c18">Busse et al. 2009</xref>; <xref ref-type="bibr" rid="c81">Xiao et al. 2014</xref>; <xref ref-type="bibr" rid="c80">Xiao and Huang 2015</xref>; <xref ref-type="bibr" rid="c7">Bao and Tsao 2018</xref>). In the normalization model, while the division by the activity of a population of neurons in the denominator (the normalization pool) is well accepted, the nature of the numerator is less understood. We have previously proposed that the weight of a stimulus component is proportional to the activity of a population of neurons elicited by the stimulus component (<xref ref-type="bibr" rid="c81">Xiao et al., 2014</xref>; <xref ref-type="bibr" rid="c79">Wiesner et al., 2020</xref>). We refer to this neuronal population as the “weighting pool”. Here, we assumed that the weighting pool was composed of neurons with a broad range of speed preferences in response to multiple speed components. So, the summed response of the weighting pool reflects the speed preference of the neuronal population rather than the speed preference of individual neurons. We used the following equation (<xref ref-type="disp-formula" rid="eqn9">Eq. 9</xref>) to fit the direction-tuning curves of each neuron in response to two speed components moving in different directions:
<disp-formula id="eqn9">
<graphic xlink:href="532456v3_eqn9.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<italic>R</italic><sub><italic>bi</italic></sub>, <italic>R</italic><sub><italic>s</italic></sub>, <italic>R</italic><sub><italic>f</italic></sub>, <italic>θ</italic><sub>1</sub>, and <italic>θ</italic><sub>2</sub> are the same as in <xref ref-type="disp-formula" rid="eqn8">Equation 8</xref>. <italic>S</italic><sub><italic>s</italic></sub> and <italic>S</italic><sub><italic>f</italic></sub> are the population neural responses of the weighting pools to the slower and faster component speeds, respectively. <italic>n, σ</italic>, α, and <italic>c</italic> are model parameters and have the following constraints: 0.01 ≤ n ≤ 100, 0 ≤ σ ≤ 500, 0.01 ≤ α ≤ 100, 0 ≤ c ≤ 100. α is a parameter that controls for the tuned normalization (<xref ref-type="bibr" rid="c50">Ni et al., 2012</xref>; <xref ref-type="bibr" rid="c67">Rust et al., 2006</xref>; <xref ref-type="bibr" rid="c20">Carandini et al., 1997</xref>). We approximated <italic>S</italic><sub><italic>s</italic></sub> and <italic>S</italic><sub><italic>f</italic></sub> based on the population-averaged responses of our recorded MT neurons (N = 100) in response to single speeds moving in the preferred direction of each neuron (<xref rid="fig8" ref-type="fig">Fig. 8E</xref>). For the speeds of 2.5 and 10°/s, <italic>S</italic><sub><italic>s</italic></sub> = 36.7 and <italic>S</italic><sub><italic>f</italic></sub> = 62.5 spikes/s (red circles in <xref rid="fig8" ref-type="fig">Fig. 8E</xref>). The normalization model fit the data well, accounting for an average of 90.5% of the response variance (std = 7.1%, N = 21), slightly smaller but comparable to the fit by the LWS model. The median response weights obtained from the normalization model for the faster and slower components were 0.78 and 0.15, respectively, and were significantly different (Wilcoxon signed-rank test, p = 6.0 x10<sup>−5</sup>) (<xref rid="fig8" ref-type="fig">Fig. 8D</xref>). The median values of the fitted parameters across 21 neurons are n = 4.13, σ = 123, α = 1.57, c = 0.03.</p>
<p>So far, we have described the neural encoding of multiple speeds in area MT. We will next examine the decoding of speed(s) from population neural responses in MT and compare the performance of decoding with perceptual performance.</p>
</sec>
<sec id="s2h">
<title>Discriminate bi-speed and single-speed stimuli based on neuronal responses in area MT</title>
<p>We asked whether the responses of MT neurons contained information about bi-speed and single-speed stimuli that were suitable to support the perceptual discrimination of these stimuli. To address this question, we first examined the responses elicited by the bi-speed and single-speed stimuli from a population of MT neurons with different preferred speeds (PS). Next, we used a classifier to discriminate the bi-speed stimuli from the single, log-mean speed stimuli based on MT responses.</p>
<p>In different experimental sessions, we centered visual stimuli on neurons’ RFs. The visual stimuli were identical across experimental sessions except for the spatial location of the RF. This allowed us to pool the trial-averaged responses recorded from different neurons to form a pseudo-population (see Methods). One can interpret the responses as from a population of neurons elicited by the same visual stimulus. <xref rid="fig9" ref-type="fig">Figure 9</xref> shows the pseudo-population neural response (referred to in brief as the population response) plotted as a function of neurons’ PS, constructed from 100 neurons that we recorded using a fixation paradigm (see Methods). To capture the population response evenly across a full range of PS, we spline-fitted the recorded response elicited by the bi-speed stimulus (the red curves) and by the single, log-mean speed (the black curves) (<xref rid="fig9" ref-type="fig">Fig. 9A-E</xref>). At x4 and x2 speed separations, the population responses elicited by two speeds did not show two separate peaks. Instead, they had a single hump that shifted from low PS to high PS as the stimulus speeds increased. At x4 speed separation across all five speed pairs, the population response elicited by two speeds was broader and flatter than that elicited by the single log-mean speed (<xref rid="fig9" ref-type="fig">Fig. 9A1-E1</xref>).</p>
<fig id="fig9" position="float" fig-type="figure">
<label>Figure 9.</label>
<caption><title>Population neural responses elicited by the bi-speed and single-speed stimuli and the performance of a linear classifier.</title>
<p>A population response of 100 recorded neurons was reconstructed by pooling across recordings in different experimental sessions. Each neuron’s response was averaged across experimental trials and normalized by the maximum response of the spline-fitted speed tuning curve to single speeds. Each dot represents the response from one neuron plotted as the neuron’s PS in the natural logarithm scale. The curves represent the spline-fitted population neural responses. Red: response to the bi-speed stimulus; Black: the response to the corresponding single, log-mean speed. <bold>A1-F1</bold>. X4 speed separation. The speeds of the bi-speed stimuli are 1.25 and 5<sup>°</sup>/s (A1), 2.5 and 10<sup>°</sup>/s (B1), 5 and 20<sup>°</sup>/s (C1), 10 and 40<sup>°</sup>/s (D1), 20 and 80<sup>°</sup>/s (E1). <bold>A2-F2</bold>. X2 speed separation. The speeds of the bi-speed stimuli are 1.25 and 2.5<sup>°</sup>/s (A2), 2.5 and 5<sup>°</sup>/s (B2), 5 and 10<sup>°</sup>/s (C2), 10 and 20<sup>°</sup>/s (D2), 20 and 40<sup>°</sup>/s (E2). Two red dots on the X-axis indicate two component speeds; the black dot indicates the log-mean speed. <bold>F1, F2</bold>. Performance of a linear classifier to discriminate the population neural responses to the bi-speed stimulus and the corresponding single log-mean speed. Error bars represent STE.</p></caption>
<graphic xlink:href="532456v3_fig9.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>In our experiments, we directly measured the neuronal responses elicited by the log-mean speed of x4 but not x2 speed separation. Because we had characterized each neuron’s tuning curve to single speeds, we could infer the responses elicited by the log-mean speed of x2 separation by interpolating the speed tuning curve using a spline fit. At x2 speed separation, the population response elicited by two speeds was similar to that elicited by the single log-mean speed, with the two-speed population response slightly broader (<xref rid="fig9" ref-type="fig">Fig. 9A2-E2</xref>).</p>
<p>We used a linear classifier to perform a discrimination task to evaluate the discriminability between MT population responses elicited by the bi-speed stimulus and the corresponding log-mean speed. Trial-by-trial population responses were generated randomly according to a Poisson process, and the mean response of each neuron was set to the trial-averaged neuronal response. The classifier was trained and tested using k-fold cross-validation. The classifier determined whether a population response from the recorded 100 neurons in our data set was elicited by two speeds or a single speed (see Methods). Discriminability of the classifier was measured in <italic>d’</italic> as in our psychophysics study.</p>
<p>Consistent with perceptual discrimination (<xref rid="fig1" ref-type="fig">Figs. 1F</xref>, <xref rid="fig2" ref-type="fig">2B</xref>), the classifier’s performance at x4 speed separation (<xref rid="fig9" ref-type="fig">Fig. 9F1</xref>) was better than that at x2 speed separation (<xref rid="fig9" ref-type="fig">Fig. 9F2</xref>). This provides a neural correlate with better perceptual speed segmentation at larger speed separation. At x4 speed separation, the discriminability of the classifier was slightly decreased as the stimulus speed increased (<xref rid="fig9" ref-type="fig">Fig. 9F1</xref>), which was generally consistent with the human psychophysics results (<xref rid="fig1" ref-type="fig">Fig. 1E1</xref>). However, one difference was that at 20 and 80°/s, the classifier’s performance did not drop to a low level as human performance (compare <xref rid="fig9" ref-type="fig">Fig. 9F1</xref> with <xref rid="fig1" ref-type="fig">Fig. 1E1</xref>), but was more comparable to that of the monkey subject (<xref rid="fig2" ref-type="fig">Fig. 2B1</xref>). At x2 speed separation, the classifier’s performance (<xref rid="fig9" ref-type="fig">Fig. 9F2</xref>) had a similar shape as that of the human (<xref rid="fig1" ref-type="fig">Fig. 1E2</xref>) and monkey (<xref rid="fig2" ref-type="fig">Fig. 2B2</xref>) subjects, but the performance was not as good as the perceptual performance at intermediate speeds.</p>
<p>When the stimulus speeds were 20 and 80°/s, the population responses elicited by the bi-speed stimulus and the single log-mean speed stimulus were noticeably different (<xref rid="fig9" ref-type="fig">Fig. 9E1</xref>), which explains the good performance of the classifier in differentiating the two stimuli. However, the difference in the population neural responses may contribute to perceptual differences in quality other than motion speeds, and the monkey subject might be able to pick up these perceptual cues at these high speeds to aid the task performance. To directly evaluate whether the population neural responses elicited by the bi-speed stimulus carry information about two speeds, it is important to conduct a decoding analysis to extract speed(s) from MT population responses.</p>
</sec>
<sec id="s2i">
<title>Decoding either a single speed or two speeds from trial-averaged population neural response</title>
<p>Since the population responses elicited by the x4 and x2 speed separations only had a single peak centered between the two component speeds (<xref rid="fig9" ref-type="fig">Fig. 9A-E</xref>), this raised the question of how neuronal populations represent multiple speeds of the motion components. To address this question, we used a decoding approach motivated by the theoretical framework of coding multiplicity and probability distribution of visual features in neuronal populations proposed by Zemel et al. (<xref ref-type="bibr" rid="c83">Zemel et al., 1998</xref>; <xref ref-type="bibr" rid="c58">Pouget et al., 2003</xref>; also see <xref ref-type="bibr" rid="c74">Treue et al., 2000</xref>). Our decoder extracted speeds that minimized the difference (sum squared error) between the estimated population response elicited by the extracted speeds, and the reconstructed population neural response based on the neural recording (<xref ref-type="disp-formula" rid="eqn10">Eqs. 10</xref>-<xref ref-type="disp-formula" rid="eqn13">13</xref>, see Methods). Rather than searching for a probability distribution of speed, we constrained the search to either a single speed or two speeds. We also constrained the weights for the extracted speeds to sum to one, consistent with a probability distribution.</p>
<p>Our approach is akin to the forward encoding model for decoding that is often used in brain imaging studies (e.g., <xref ref-type="bibr" rid="c34">Kay et al., 2008</xref>; <xref ref-type="bibr" rid="c17">Brouwer and Heeger, 2009</xref>; <xref ref-type="bibr" rid="c49">Naselaris et al., 2011</xref>; <xref ref-type="bibr" rid="c77">Vintch and Gardner, 2014</xref>; van <xref ref-type="bibr" rid="c9">Bergen et al., 2015</xref>). We applied an encoding rule and found the visual stimuli that generated a population response best matched the recorded neural response. Our assumed encoding rule in the decoder is that a neuron’s response to multiple speeds is the linear sum of the neuron’s responses to individual speed components presented alone based on the neuron’s speed tuning curve, and weighted by the strength (or probability) of each speed component. The decision to use this encoding model for decoding, rather than the encoding rule characterized in this study, was made primarily for practical reasons. Our experimental data only covered two speed separations (x4 and x2) and 5 log mean speeds. We do not yet know a general encoding rule for two speeds across all different speed separations and log mean speeds. However, if the linear encoding of the two speeds, as characterized in this study, generalizes across a broader range of speed combinations – such that only the weights of the speed components vary within the general encoding rule – then our choice of encoding model for decoding would not alter the decoded speeds themselves, but would merely affect the estimated weights associated with those speeds (<xref ref-type="disp-formula" rid="eqn10">Eq. 10</xref>).</p>
<p><xref rid="fig10" ref-type="fig">Figure 10</xref> shows the decoding procedure and the results of extracting speed(s) from the population neural responses reconstructed based on the trial-averaged responses of 100 recorded neurons to the bi-speed stimuli. To capture the population neural response across a full range of the PS, we spline-fitted the recorded (red dots) and estimated (blue dots) population responses. The estimated population responses (<xref rid="fig10" ref-type="fig">Fig. 10</xref>, blue curves) matched the recorded neural responses well (<xref rid="fig10" ref-type="fig">Fig. 10</xref>, red curves) (for five speed pairs, R<sup>2</sup> &gt; 0.96 at x4 speed separation; R<sup>2</sup> &gt; 0.99 at x2 speed separation). At x4 speed separation, the decoder extracted two speeds for all speed combinations (<xref rid="fig10" ref-type="fig">Fig. 10A-E</xref>). The readout speeds were generally close to the veridical stimulus speeds. At low stimulus speeds of 1.25 and 5<sup>°</sup>/s (<xref rid="fig10" ref-type="fig">Fig. 10A</xref>) and 2.5 and 10<sup>°</sup>/s (<xref rid="fig10" ref-type="fig">Fig. 10B</xref>), the decoded faster speed component had a higher weight than the slower component. At the highest speeds of 20 and 80<sup>°</sup>/s, the decoder extracted two speeds (<xref rid="fig10" ref-type="fig">Fig. 10E</xref>), whereas human subjects could not perceive two speeds (<xref rid="fig1" ref-type="fig">Fig. 1E1</xref>) (see <xref rid="figS3" ref-type="fig">Supplementary Figure 3</xref>). At x2 speed separation, the decoder extracted two speeds only at low stimulus speeds of 1.25 and 2.5<sup>°</sup>/s (<xref rid="fig10" ref-type="fig">Fig. 10F</xref>). At higher stimulus speeds, the decoder extracted a dominant speed that was between the two component speeds, with or without a second nearby speed that had a very low weight (<xref rid="fig10" ref-type="fig">Fig. 10G-J</xref>). In contrast, human subjects could perceive two speeds when stimulus speeds were below 20 and 40<sup>°</sup>/s (<xref rid="fig1" ref-type="fig">Fig. 1E2</xref>) (see below and Discussion).</p>
<fig id="fig10" position="float" fig-type="figure">
<label>Figure 10.</label>
<caption><title>Illustration of the decoding procedure and extraction of speed(s) from population responses reconstructed based on the trial-averaged neuronal responses to the bi-speed stimuli. A-E. X4 speed separation. F-J. X2 speed separation.</title>
<p>The neural population contains 100 recorded neurons, as shown in <xref rid="fig9" ref-type="fig">Figure 9</xref>. Each red dot represents the trial-averaged response from one neuron plotted versus the PS of the neuron in the natural logarithm scale. The red curve represents the spline-fitted population neural response. The decoder found either one speed or two speeds with different weights (vertical green bars on the X-axis), giving rise to the estimated and spline-fitted population response (blue curve) that best fitted the recorded and spline-fitted population neural response (red curve). Each blue dot represents the estimated response from one neuron, and the blue curve represents the spline-fitted estimated population response. Two red dots on the X-axis indicate the stimulus speeds. The Y-axis on the right side shows the weight of the readout speed (A, F).</p></caption>
<graphic xlink:href="532456v3_fig10.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2j">
<title>Decoding speeds from trial-by-trial population neural responses</title>
<p>To determine the distribution of the readout speed across trials, we randomly generated 200 trials based on the trial-averaged responses of 100 recorded neurons in our data sample. In each simulated trial, a given neuron’s response was determined by a Poisson process, with the mean set to the spike count averaged across the recorded trials. The trial-by-trial response of each neuron was normalized to construct the population response and then spline-fitted for decoding. The speeds extracted from the recorded neural responses to single stimulus speeds (<xref rid="figS2" ref-type="fig">Suppl. Fig. 2A-G</xref>) and from the inferred responses to the log-mean speed of x2 speed separation (<xref rid="figS2" ref-type="fig">Suppl. Fig. 2H-L</xref>) matched the single stimulus speed well (<xref rid="figS2" ref-type="fig">Suppl. Fig. 2M</xref>).</p>
<p><xref rid="fig11" ref-type="fig">Figure 11</xref> shows the speeds extracted from the neural response to the bi-speed stimuli. The decoder often extracted two speeds across trials. In some trials, the readout of one speed component had a minimal weight. We considered a trial having a “single” readout speed if the weight difference between the two readout speeds was greater than 0.7 (i.e., the weaker weight &lt; 0.15). This usually happened when the readout speed having a minimal weight was either at one of the boundaries of the speed range (i.e., 1.25<sup>°</sup>/s or 80<sup>°</sup>/s) or separated from the other readout speed by a large speed separation (x27.86, which was the largest speed separation searched by the algorithm) (see Methods). These small weights were likely artifacts due to the boundaries of the stimulus speeds used in our experiments or the range of speed separation searched by the decoder.</p>
<fig id="fig11" position="float" fig-type="figure">
<label>Figure 11.</label>
<caption><title>Trial-by-trial readout speeds decoded from population neural responses to the bi-speed stimuli.</title>
<p>The neural population contains 100 recorded neurons and the trial-by-trial responses are randomly generated based on a Poisson process. The convention is the same as in <xref rid="fig10" ref-type="fig">Figure 10</xref>. <bold>A-E. Speeds decoded from population responses to x4 speed separation</bold>. The vertical red lines indicate two component speeds, which are 1.25 and 5<sup>°</sup>/s (A), 2.5 and 10<sup>°</sup>/s (B), 5 and 20<sup>°</sup>/s (C), 10 and 40<sup>°</sup>/s (D), 20 and 80<sup>°</sup>/s (E). <bold>F-J. Speeds decoded from population responses to x2 speed separation</bold>. The red vertical line indicates two component speeds, and the black vertical line indicates the log mean speed. The component speeds are 1.25 and 2.5<sup>°</sup>/s (F), 2.5 and 5<sup>°</sup>/s (G), 5 and 10<sup>°</sup>/s (H), 10 and 20<sup>°</sup>/s (I), 20 and 40<sup>°</sup>/s (J).</p></caption>
<graphic xlink:href="532456v3_fig11.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>At x4 speed separation, the decoder was able to extract the speeds of the stimulus components (<xref rid="fig11" ref-type="fig">Fig. 11A-D</xref>), except at the fastest speeds of 20 and 80<sup>°</sup>/s. At low stimulus speeds of 1.25 and 5<sup>°</sup>/s, and 2.5 and 10<sup>°</sup>/s, the readout speed around the faster stimulus component had a higher weight than that around the slower stimulus component (<xref rid="fig11" ref-type="fig">Fig. 11A, B</xref>). At stimulus speeds of 1.25 and 5<sup>°</sup>/s, in trials with two readout speeds (<xref rid="fig11" ref-type="fig">Fig. 11A</xref>, on the white background), the faster readout speeds were close to the faster stimulus speed of 5<sup>°</sup>/s. The slower readout speeds were closely aligned with the slower stimulus speed of 1.25<sup>°</sup>/s, which was also the lower boundary of the speed range. In trials considered to have a single readout speed, the readout was very close to the faster stimulus speed of 5<sup>°</sup>/s (<xref rid="fig11" ref-type="fig">Fig. 11A</xref>, on the grey background). For some of these trials (at the top of <xref rid="fig11" ref-type="fig">Fig. 11A</xref>), the faster readout speed was near the upper-speed boundary of 80<sup>°</sup>/s and had a minimal weight (&lt; 0.15). Those faster readout speeds were boundary artifacts.</p>
<p>At stimulus speeds of 2.5 and 10<sup>°</sup>/s, the decoder extracted two speeds that had a separation close to the veridical separation (<xref rid="fig11" ref-type="fig">Figs. 11B, 12B</xref>). In trials considered to have a single-speed readout, the readout speed was close to the faster stimulus speed of 10<sup>°</sup>/s. In some single- and two-readout speed trials, the slower readout speeds aligned with the 1.25<sup>°</sup>/s boundary and had a small weight, suggesting they were boundary artifacts.</p>
<p>At stimulus speeds of 5 and 20<sup>°</sup>/s, nearly all trials had two readout speeds with a separation well aligned with the veridical speed separation (<xref rid="fig11" ref-type="fig">Figs. 11C, 12C</xref>). At stimulus speeds of 10 and 40<sup>°</sup>/s, the decoder was able to extract two speeds for most of the trials (<xref rid="fig11" ref-type="fig">Fig. 11D</xref>). A small percentage of the trials (about 10%) were considered to have a single readout speed, which was close to the log mean speed of the two stimulus speeds (20<sup>°</sup>/s) (at the top of <xref rid="fig11" ref-type="fig">Fig. 11D</xref> on the grey background).</p>
<p>At the fastest stimulus speeds of 20 and 80<sup>°</sup>/s, about 40% of the total trials were considered to have only a single readout speed, which was near the log mean speed of the stimulus components (40<sup>°</sup>/s) (<xref rid="fig11" ref-type="fig">Fig. 11E</xref>). In other trials, the decoder extracted two speeds – the slower readout speeds were generally higher than the slower stimulus speed (20<sup>°</sup>/s), and the faster readout speeds aligned with the faster stimulus speed (80<sup>°</sup>/s), which was also the upper boundary speed. However, an examination of the objective function as the decoder searched for the best-fit population response across speed separations revealed that the trial-averaged objective function was flat within a big range of speed separations (<xref rid="figS3" ref-type="fig">Suppl. Fig. 3A</xref>). Further analysis showed that the decoder was uncertain about how many speeds were in the visual stimuli and therefore had difficulty segmenting the visual stimuli at these fast stimulus speeds of 20 and 80<sup>°</sup>/s (<xref rid="figS3" ref-type="fig">Suppl. Fig. 3</xref>).</p>
<p>At x2 speed separation, the decoder was not able to extract two speeds of the stimulus components, except at the slowest speeds of 1.25 and 2.5<sup>°</sup>/s (<xref rid="fig11" ref-type="fig">Fig. 11F-J</xref>). At stimulus speeds of 1.25 and 2.5<sup>°</sup>/s (<xref rid="fig11" ref-type="fig">Fig. 11F</xref>), in 38% of total trials considered to have a single readout speed, the readout speed was close to the faster stimulus speed of 2.5<sup>°</sup>/s (mean = 1.97<sup>°</sup>/s, STD = 1.08). In trials that had two readout speeds, the slower readout speeds roughly followed the slower stimulus speed (1.25<sup>°</sup>/s), which was also the lower boundary of the speed range (<xref rid="fig11" ref-type="fig">Fig. 11F</xref>). At stimulus speeds higher than 1.25 and 2.5<sup>°</sup>/s, most trials were considered to have a single readout speed (<xref rid="fig11" ref-type="fig">Fig. 11G-J</xref>). The mean speeds of the single readout-speed trials were 3.9<sup>°</sup>/s (STD = 1.07), 7.3<sup>°</sup>/s (STD = 1.99), 13.5<sup>°</sup>/s (STD = 1.06), and 31<sup>°</sup>/s (STD = 1.07), respectively, for stimulus speeds of 2.5 and 5<sup>°</sup>/s, 5 and 10<sup>°</sup>/s, 10 and 20<sup>°</sup>/s, and 20 and 40<sup>°</sup>/s. These mean readout speeds were close to the log mean speeds of the two stimulus speeds (3.54<sup>°</sup>/s, 7.07<sup>°</sup>/s, 14.14<sup>°</sup>/s, and 28.28<sup>°</sup>/s, respectively).</p>
</sec>
<sec id="s2k">
<title>Discrimination between single- and bi-speed stimuli based on decoded speeds</title>
<p>To compare the perceptual discrimination between bi-speed stimuli and the log-mean speed, we used the decoding results to perform a discrimination task similar to that used in our psychophysical experiments. <xref rid="fig12" ref-type="fig">Figure 12</xref> shows the distributions of the speed separation between two readout speeds extracted from the reconstructed population neural responses to the bi-speed stimuli and the correspondingly single log-mean speed. As stated above, when the difference between the weights of two readout speeds in a trial was greater than 0.7, the trial was considered to have a single readout speed, and the speed separation was set to zero. At x4 speed separation, the separations between the readout speeds extracted from the response to the bi-speed stimuli generally matched the veridical speed separation. They were larger than those extracted from the response to single log-mean speed (<xref rid="fig12" ref-type="fig">Fig. 12A-E</xref>). Based on the distributions of the decoded speeds, we used a speed separation threshold of x1.3 (i.e., 0.26 on the log scale, marked by a black triangle in <xref rid="fig12" ref-type="fig">Fig. 12</xref>) to distinguish single- and bi-peed stimuli and to evaluate the hit rate and false alarm rate. The exact choice of the threshold within a range from x1.1 to x1.7 did not change the results qualitatively. We calculated <italic>d’</italic> to measure the ability to discriminate the bi-speed stimuli from the corresponding single log-mean speed. At x4 speed separation, the <italic>d’</italic> (<xref rid="fig12" ref-type="fig">Fig. 12K</xref>) was similar to the psychophysical performance of the monkey subject (<xref rid="fig2" ref-type="fig">Fig. 2B1</xref>), reaching its peak at 5 and 20<sup>°</sup>/s. Although <italic>d’s</italic> at stimulus speeds of 1.25 and 5<sup>°</sup>/s and 2.5 and 10<sup>°</sup>/s were smaller than those of human subjects (<xref rid="fig1" ref-type="fig">Fig. 1C1, E1</xref>), the fact that in many trials, the readout speeds matched the faster stimulus speeds (<xref rid="fig12" ref-type="fig">Fig. 12A, B</xref>) indicated that the decoder was able to segment the visual stimuli when stimulus speeds were low.</p>
<fig id="fig12" position="float" fig-type="figure">
<label>Figure 12.</label>
<caption><title>Discrimination between single- and bi-speed stimuli based on decoded speeds.</title>
<p><bold>A-J</bold>. The distributions of the speed separation between two readout speeds in each trial for the bi-speed stimuli (yellow) and the single, log-mean speed (blue). The bin width is 0.05. The abscissa is shown in the natural logarithm scale. The red dotted line indicates veridical speed separation. <bold>A-E. X4 speed separation</bold>. The speeds of the bi-speed stimuli are 1.25 and 5<sup>°</sup>/s (A), 2.5 and 10<sup>°</sup>/s (B), 5 and 20<sup>°</sup>/s (C), 10 and 40<sup>°</sup>/s (D), 20 and 80<sup>°</sup>/s (E). <bold>F-J. X2 speed separation</bold>. The speeds of the bi-speed stimuli are 1.25 and 2.5<sup>°</sup>/s (F), 2.5 and 5<sup>°</sup>/s (G), 5 and 10<sup>°</sup>/s (H), 10 and 20<sup>°</sup>/s (I), 20 and 40<sup>°</sup>/s (J). <bold>K-L</bold>. The performance of discriminating a bi-speed stimulus from the corresponding log-mean speed is based on the speed separation of the decoded speeds. <bold>K</bold>. X4 speed separation; <bold>L</bold>. X2 speed separation. The black triangles in A-J indicate the speed separation threshold of x1.3 (0.26 on the log scale) used for discriminating bi-speed and single-speed stimuli.</p></caption>
<graphic xlink:href="532456v3_fig12.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>At x2 speed separation, except at 1.25 and 2.5<sup>°</sup>/s, the distribution of the speed separation extracted from the response to the bi-speed stimuli was similar to that extracted from the inferred response to single log-mean speed (see Methods) (i.e., orange and blue bars overlapping) (<xref rid="fig12" ref-type="fig">Fig. 12F-J</xref>). The <italic>d’</italic> calculated based on the decoded speed separation (<xref rid="fig12" ref-type="fig">Fig. 12L</xref>) was smaller than the psychophysical performance of human and monkey subjects (<xref rid="fig1" ref-type="fig">Fig. 1C2, E2</xref>; Fig. B2), suggesting that the decoder was not able to segment the visual stimuli at x2 speed separation, except at the lowest speeds of 1.5 and 2.5<sup>°</sup>/s.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<sec id="s3a">
<title>Perceptual segmentation of multiple motion speeds</title>
<p>Our human psychophysical study employed a novel 3AFC task. The task combined an identification task (to report whether a stimulus had one or two speeds) with a discrimination task (to compare a two-speed stimulus with a single-speed stimulus) (<xref rid="fig1" ref-type="fig">Fig. 1A, E1, E2</xref>). This approach allowed us to characterize discriminability based on perceptual segmentation, rather than other perceptual appearances of the stimuli. We made two findings. First and intuitively, the performance of speed segmentation was better when the separation between two stimulus speeds was larger. Second, at a fixed speed separation, speed segmentation became harder at fast speeds. Our results are consistent with previous studies. <xref ref-type="bibr" rid="c43">Masson et al. (1999)</xref> showed that the speed segmentation threshold increased sharply when the mean stimulus speed increased from 8<sup>°</sup>/s to 16<sup>°</sup>/s. By varying the width of a speed notch, <xref ref-type="bibr" rid="c65">Rocchi et al. (2018)</xref> showed that transparent motion perception was stronger with a wider notch width, and that transparent motion was well perceived at slow speeds (mean speed = 4.6<sup>°</sup>/s) but not at faster speeds (mean speed = 20.6<sup>°</sup>/s) at a range of notch width from 1 to 6<sup>°</sup>/s. Our study tested a larger range of speeds and showed that the segmentation performance dropped sharply at speeds of 20 and 80<sup>°</sup>/s (x4), and 20 and 40<sup>°</sup>/s (x2), faster than those shown in the previous studies. This discrepancy is likely due to the larger speed separations used in our study and the difference in stimuli. The visual stimuli used in our study had either one or two speeds, whereas those used by <xref ref-type="bibr" rid="c65">Rocchi et al. (2018)</xref> were sampled from a distribution of motion speeds and had multiple elements.</p>
</sec>
<sec id="s3b">
<title>Neural encoding of multiple speeds and implication for efficient coding</title>
<p>We found that, at low stimulus speeds, MT neurons showed a faster-speed bias in representing two speeds of overlapping stimuli. We also showed that faster-speed bias in MT is a robust phenomenon regardless of whether the stimulus components move in the same or different directions. A faster-speed bias in representing two motion speeds is a novel finding. It adds to a growing body of studies demonstrating that visual neurons do not necessarily average the responses elicited by individual stimulus components in response to multiple stimuli (e.g., <xref ref-type="bibr" rid="c50">Ni et al., 2012</xref>; <xref ref-type="bibr" rid="c7">Bao and Tsao, 2018</xref>). Our laboratory has previously reported that the responses of MT neurons to multiple moving stimuli can show a bias toward the stimulus component with a higher signal strength such as motion coherence or luminance contrast (<xref ref-type="bibr" rid="c81">Xiao et al., 2014</xref>; <xref ref-type="bibr" rid="c79">Wiesner et al., 2020</xref>), a directional side bias toward one of two motion directions, even when the stimulus components have the same signal strength (<xref ref-type="bibr" rid="c80">Xiao and Huang, 2015</xref>), and a disparity bias toward one of two surfaces moving at different stereoscopic depths (<xref ref-type="bibr" rid="c22">Chakrala et al., 2024</xref>). These different response biases enhance the representation of individual stimulus components and can help to facilitate the segmentation of multiple moving stimuli.</p>
<p>While the faster-speed bias reported in this study may facilitate the segregation of faster-moving stimuli, it may come at the cost of reduced ability to segregate slower speeds. Why does the primate visual system encode multiple speeds in this way? An efficient way to represent sensory information is to devote limited resources to better represent signals that occur more frequently in the natural environment (<xref ref-type="bibr" rid="c5">Attneave 1954</xref>; <xref ref-type="bibr" rid="c8">Barlow 1961</xref>; <xref ref-type="bibr" rid="c70">Simoncelli and Olshausen 2001</xref>). Previous studies have suggested that slow speeds are more likely to occur than fast speeds in natural scenes (<xref ref-type="bibr" rid="c78">Weiss et al., 2002</xref>; <xref ref-type="bibr" rid="c72">Stocker and Simoncelli, 2006</xref>; <xref ref-type="bibr" rid="c84">Zhang and Stocker, 2022</xref>). If neurons in the primate visual cortex are optimized to efficiently represent speeds that are more likely to occur in natural scenes, one may expect to find neurons showing a slower-speed bias rather than a faster-speed bias. However, besides maximizing information about the environment, neural representation in the sensory cortices may be optimized for other goals, such as maximizing the performance of certain behavioral tasks (<xref ref-type="bibr" rid="c70">Simoncelli and Olshausen, 2001</xref>; <xref ref-type="bibr" rid="c42">Manning et al., 2024</xref>). Since a figural object tends to move faster than its background in natural scenes (<xref ref-type="bibr" rid="c32">Huang et al., 2019</xref>), a neural representation of multiple motions with a faster-speed bias would help to identify the figure and, therefore, benefit the performance of an essential behavioral task – figure/ground segregation. Our finding of a faster-speed bias at slow stimulus speeds underscores the possibility that, when choosing between efficiently representing the most commonly occurring features in natural scenes (e.g., slow speeds) and enhancing behavioral performance in critical tasks (e.g., figure-ground segregation), some brain areas in the visual system may prioritize representing the stimulus features that enhances the behavioral performance.</p>
</sec>
<sec id="s3c">
<title>Potential mechanisms underlying the neural encoding of multiple speeds</title>
<p>We found that the faster-speed bias was still present when attention was directed away from the RFs, suggesting that the faster-speed bias cannot be explained by an attentional modulation. The faster-speed bias cannot be explained by the apparent contrast of the stimulus component either – the random dots of the faster-speed component had shorter dwell time on the video display and appeared dimmer than the slower component. We suggest a modified normalization model that may explain why the faster-speed bias in MT occurs at low stimulus speeds and diminishes at high speeds.</p>
<p>Previous studies that characterize the neural representation of multiple stimuli have used stimulus strength to weigh the component responses in the divisive normalization model (e.g., <xref ref-type="bibr" rid="c18">Busse et al., 2009</xref>; <xref ref-type="bibr" rid="c50">Ni et al, 2012</xref>; <xref ref-type="bibr" rid="c81">Xiao et al., 2014</xref>; <xref ref-type="bibr" rid="c27">Heuer and Britten, 2002</xref>). In comparison to the standard normalization model, we suggest that the response of a population of neurons (i.e., the weighting pool) defines the numerator of the normalization equation (<xref ref-type="disp-formula" rid="eqn9">Eq. 9</xref>). The weighting pool may or may not be the same as the normalization pool that defines the response in the denominator. We suggest that the weighting pool contains a population of neurons with a broad range of speed preferences. In this way, the summed (or averaged) response of the weighting pool depends mainly on the stimulus speed, and therefore the weighting is less sensitive to the individual neuron’s speed preference. In this study, we used MT population-averaged responses to single speeds to approximate the responses of the weighting pool. MT population-averaged speed tuning in our data peaked around 20<sup>°</sup>/s (<xref rid="fig8" ref-type="fig">Fig. 8E</xref>), consistent with previous studies (<xref ref-type="bibr" rid="c44">Maunsell and Van Essen 1983</xref>; <xref ref-type="bibr" rid="c39">Lisberger and Movshon, 1999</xref>; <xref ref-type="bibr" rid="c51">Nover et al., 2005</xref>; <xref ref-type="bibr" rid="c29">Huang and Lisberger, 2009</xref>). At stimulus speeds less than 20<sup>°</sup>/s, the population speed tuning has a positive slope, and a faster component would elicit a stronger population response than a slower component. This insight explains the faster-speed bias at low stimulus speeds and why the faster-speed bias tends to be stronger at x4 than x2 speed separation. Conceptually, this model can also explain why faster-speed bias diminishes at higher speeds because, when two stimulus speeds are at opposite sides of the population’s preferred speed, they elicit similar population responses in the weighting pool. This model also predicts that when both stimulus speeds are higher than the preferred speed of the weighting pool, the response weight for the slower component should be higher than the faster component.</p>
<p>This modified normalization model well described our data on MT responses to two stimuli moving in different directions at 2.5 and 10<sup>°</sup>/s (<xref rid="fig8" ref-type="fig">Fig. 8</xref>). However, our current data set has limitations to validate this model fully. This normalization model (<xref ref-type="disp-formula" rid="eqn9">Eq. 9</xref>) can describe our data on MT responses to the bi-speed stimuli moving in the same direction across five speed pairs reasonably (<xref rid="fig5" ref-type="fig">Fig. 5</xref>) (results not shown). However, since the responses of each neuron to the bi-speed stimuli only have five data points (see <xref rid="fig3" ref-type="fig">Fig. 3</xref>) and our model has four free parameters (<xref ref-type="disp-formula" rid="eqn9">Eq. 9</xref>), the model is underconstrained. In future work, it will be important to extend the experiment to include pairs of stimuli moving in different directions at varying combinations of speeds across a broader range. By incorporating full direction tuning curves (as shown in <xref rid="fig8" ref-type="fig">Fig. 8</xref>) to better constrain the model, and systematically varying speed combinations, such a study could test the model’s prediction that the response bias shifts from a faster-speed bias to response averaging and eventually to a slower-speed bias, as overall stimulus speeds increase.</p>
<p>Although in our model, we used the responses of a population of MT neurons to estimate the responses of the weighting pool, it is possible that the weighting pool may be composed of neurons that feed signals into MT and have similar population-averaged speed tuning as MT neurons. MT neurons receive feedforward motion-selective input mainly from V1, and also from V2 and V3 (<xref ref-type="bibr" rid="c75">Ungerleider and Desimone, 1986</xref>; Movshson and Newsome, 1996; <xref ref-type="bibr" rid="c3">Anderson et al., 1998</xref>; <xref ref-type="bibr" rid="c2">Anderson and Martin, 2002</xref>; <xref ref-type="bibr" rid="c66">Rockland, 2002</xref>). Speed-selective complex cells in V1 have preferred speeds in a range similar to that of MT neurons, but the mean preferred speed is slower than MT (<xref ref-type="bibr" rid="c47">Mikami et al., 1986</xref>; <xref ref-type="bibr" rid="c52">Orban et al., 1986</xref>; <xref ref-type="bibr" rid="c61">Priebe et al., 2006</xref>). In future work, examination of the transition speeds at which faster-speed bias changes to response averaging and slower-speed bias may help to differentiate whether the weighting pool consists of neurons in MT or early visual areas such as V1.</p>
</sec>
<sec id="s3d">
<title>Decoding multiple speeds from population neural responses</title>
<p>Theoretical studies have proposed neural coding of probability distribution and multiplicity of a visual attribute (<xref ref-type="bibr" rid="c57">Pouget et al., 2000</xref>). The key idea of this framework is that neurons are not coding a single stimulus value but instead coding the distribution of the stimulus (<xref ref-type="bibr" rid="c83">Zemel et al., 1998</xref>; <xref ref-type="bibr" rid="c58">Pouget et al., 2003</xref>). However, neurophysiological evidence supporting this framework on coding multiplicity is limited. Previous studies have not demonstrated the ability to extract multiple speeds from population neural responses. Our results provide experimental support for this framework of coding multiplicity. Our decoding analysis reveals that the population neural response in MT carries information about multiple speeds of overlapping stimuli, and it is possible to extract multiple speeds and their weights even when the population neural response has a unimodal distribution.</p>
<p>At large (x4) speed separation, our decoding results captured several key features of human and monkey’s perception of multiple speeds – the decoded speeds support perceptual segmentation at low to intermediate speeds (<xref rid="fig11" ref-type="fig">Figs. 11A-E</xref>, <xref rid="fig12" ref-type="fig">12A-K</xref>). At 20 and 80<sup>°</sup>/s, the decoder was uncertain about whether a single speed or two speeds were present in the visual stimuli and, therefore, had difficulty segmenting the visual stimuli at these fast speeds (<xref rid="figS3" ref-type="fig">Suppl. Fig. 3</xref>). However, at small (x2) speed separation, the decoding results showed very little segmentation (<xref rid="fig11" ref-type="fig">Figs. 11G-J</xref>, <xref rid="fig12" ref-type="fig">12L</xref>), except at very low speeds. This result differs from the perception at stimulus speeds less than 20 and 40<sup>°</sup>/s (<xref rid="fig1" ref-type="fig">Figs. 1C2, E</xref>, <xref rid="fig2" ref-type="fig">2B2</xref>). What are the potential reasons for the decoder’s inadequacy in segmenting small speed separations? The best-fit population response predicted by the encoding rule of the decoder matched the neural responses remarkably well (<italic>R</italic><sup><italic>2</italic></sup> &gt; 0.99 for all five speed pairs of x2 separation, <xref rid="fig10" ref-type="fig">Fig. 10F-J</xref>). So, the encoding model for decoding well described the population neural responses to the bi-speed stimuli. Because we found the same results when performing decoding based on neural responses averaged across experimental trials (<xref rid="fig10" ref-type="fig">Fig. 10G-J</xref>), this inadequacy was unlikely due to our assumption of the trial-by-trial response variability following a Poisson process, nor due to the lack of consideration of noise correlations (<xref ref-type="bibr" rid="c86">Zohary et al., 1994</xref>; <xref ref-type="bibr" rid="c29">Huang and Lisberger, 2009</xref>). We consider several factors that may contribute to this discrepancy.</p>
<p>First, this may be attributed to the limited sample size of our dataset. If we had a much larger MT neuron population, potential differences in neuronal responses to bi-speed stimuli and the single log mean speed might be captured by the data, which may lead to better decoding. Second, it may be due to the choice of the “objective function”. Our decoder minimized the sum squared error between the predicted population response and the recorded neural response. In contrast, <xref ref-type="bibr" rid="c83">Zemel et al. (1998)</xref> found motion directions that maximized the posterior probability <italic>P(</italic><bold><italic>s</italic></bold>|<bold><italic>r</italic></bold><italic>)</italic> using a maximum a posteriori (MAP) estimate. It remains to be determined whether maximizing the posterior probability can improve the resolution of segmenting multiple speeds. Third, neuronal response in different sensory areas, including MT, to two stimuli can fluctuate from trial to trial between representing one stimulus component from the other (<xref ref-type="bibr" rid="c38">Li et al., 2016</xref>; <xref ref-type="bibr" rid="c21">Caruso et al., 2018</xref>; <xref ref-type="bibr" rid="c33">Jun et al., 2022</xref>; <xref ref-type="bibr" rid="c68">Schmehl et al., 2024</xref>; <xref ref-type="bibr" rid="c26">Groh et al., 2024</xref>). If this trial-varying stimulus multiplexing also occurred for representing two speeds with a small separation, information about individual speed components would be lost in the trial-averaged responses (with added variability based on a Poisson process), as in our decoding procedure. Future studies with a large number of repeated experimental trials would be needed to test this possibility. Finally, while area MT is clearly important for motion-based segmentation, other motion-sensitive brain areas may be important for segmenting speeds with a small separation.</p>
</sec>
</sec>
<sec id="s4">
<title>Materials and methods</title>
<p>We conducted psychophysical experiments using human subjects, and psychophysical and neurophysiological experiments using macaque monkeys.</p>
<sec id="s4a">
<title>Human psychophysics</title>
<sec id="s4a1">
<title>Subjects</title>
<p>Four adult human subjects (<italic>CN, CO, IN, NP</italic>), two men and two women, with normal or corrected-to-normal visual acuity participated in the psychophysics experiments. Subject <italic>CN</italic> was naive about the purposes of the experiments. Subjects CO and IN had a general idea about this study but did not know the specific design of the experiments. Informed consent was obtained from the subjects. All aspects of the study were in accordance with the principles of the Declaration of Helsinki and were approved by the Institutional Review Board at the University of Wisconsin-Madison.</p>
</sec>
<sec id="s4a2">
<title>Apparatus</title>
<p>Visual stimuli were generated by a Linux workstation using an OpenGL application and displayed on a 19-inch CRT monitor. The monitor had a resolution of 1,024 × 768 pixels and a refresh rate of 100 Hz. The output of the video monitor was measured with a photometer (LS-110, Minolta) and was gamma-corrected. Stimulus presentation was controlled by a real-time data acquisition and stimulus control program “Maestro” (<ext-link ext-link-type="uri" xlink:href="https://sites.google.com/a/srscicomp.com/maestro/">https://sites.google.com/a/srscicomp.com/maestro/</ext-link>) as in the animal behavior and neurophysiology experiments. Subjects viewed the visual stimuli in a dark room with dim background illumination. The viewing distance was 58 cm. A chin rest and forehead support were used to restrict the head movements of the observers. During experimental trials, human subjects maintained fixation on a small spot within a 2 × 2° window. Eye positions were monitored using a video-based eye tracker (EyeLink, SR Research) at a rate of 1kHz.</p>
</sec>
<sec id="s4a3">
<title>Visual stimuli</title>
<p>Visual stimuli were two spatially overlapping random-dot patches presented within a square aperture 10° wide. Each square stimulus was centered 11° to the right of the fixation spot, therefore covering 6° to 16° eccentricity. This range roughly matched the RF eccentricity of the recorded MT neurons in our neurophysiological experiments. The random dots were achromatic. Each random dot was 3 pixels and had a luminance of 15.0 cd/m<sup>2</sup>. The background luminance was 0.03 cd/m<sup>2</sup>. The dot density of each random dot patch was 2 dots/degree<sup>2</sup>. The two random-dot patches translated horizontally in the same direction. To reduce adaptation, the motion direction was either leftward or rightward in half of the trials, and stimulus trials were randomly interleaved. In one set of trials, two overlapping random-dot patches had a “large speed separation” and the speed of the faster component was always four times (x4) that of the slower component. In another set of trials, visual stimuli had a “small speed separation” and the speed of the faster component was always twice (x2) that of the slower component (see <xref rid="fig1" ref-type="fig">Fig. 1B1, B2</xref>). For each bi-speed stimulus, there was a corresponding single-speed stimulus composed of two overlapping random-dot patches moving in the same direction at the same speed. The single speed was the natural logarithmic (log) mean speed of the bi-speed stimulus: <inline-formula><inline-graphic xlink:href="532456v3_inline1a.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, in which <italic>Spd</italic><sub><italic>1</italic></sub> and <italic>Spd</italic><sub><italic>2</italic></sub> were the two component speeds. The motion coherence of each random-dot patch was always 100%.</p>
</sec>
<sec id="s4a4">
<title>Procedure</title>
<p>In a standard two-alternative-forced-choice (2AFC) task, subjects discriminated a bi-speed stimulus from the corresponding single log-mean speed stimulus. The bi-speed and single-speed stimuli were presented in two consecutive time intervals with a 500 ms gap in between, in random, balanced order. In each time interval, the visual stimulus appeared, remained stationary for 250 ms, and then moved for 500 ms. At the end of each trial, subjects reported which time interval contained a bi-speed stimulus by pressing one of two buttons (left or right) within a 1500-ms window. After the button press, the inter-trial interval was 1300 ms. Each block of trials contained 40 trials, i.e. 5 speed pairs × 2 speed separations × 2 temporal orders (the bi-speed stimulus appeared in the first or second time-interval) × 2 motion directions (visual stimuli moved either to the left or right). Each experimental session typically contained 5 blocks, i.e. 200 trials.</p>
<p>Subjects also performed a 3AFC task. As in the 2AFC task, subjects discriminated a bi-speed stimuli from the corresponding single log-mean speed stimulus but had the option to make a third choice by pressing the middle button on trials when they thought neither stimulus interval appeared to contain two speeds (“no two-speeds” choice). When subjects thought one of the two stimulus intervals contained two speeds, subjects then pressed either the left or the right button to indicate which interval had two speeds.</p>
</sec>
<sec id="s4a5">
<title>Data analysis</title>
<p>The hit rate was calculated as the percentage of trials in which a subject correctly picked the bi-speed stimulus as having two speeds. The false alarm rate was calculated as the percentage of trials that a subject incorrectly picked the singe-speed stimulus as having two speeds. As a measure of discriminability between the bi-speed and the corresponding single-speed stimuli, we calculated the discriminability index <italic>d′</italic> = <italic>norminv</italic>(hit rate) – <italic>norminv(</italic>false alarm rate). <italic>norminv</italic> is a MATLAB function that calculates the inverse of the normal cumulative distribution function, with the mean and standard deviation set to 0 and 1, respectively. When the hit or false alarm rate was occasionally close to 1, to avoid infinite d’ values, d’ was calculated using a modified formula: <italic>d’</italic> = norminv{[(100 x hit rate)+1]/102} - norminv{[(100 x false alarm rate) +1]/102}. In analyzing the results of the 3AFC task, we incorporated the NTC trials into the <italic>d’</italic> calculation by evenly splitting the NTC trials into “hit” trials and “false alarm” trials. In this way, the NTC trials were still accounted for by the hit rate and false alarm rate, in the sense that they did not contribute to the discrimination. We also examined the percentage of trials in which subjects made the NTC choice at different stimulus speeds.</p>
</sec>
</sec>
<sec id="s4b">
<title>Neurophysiological and psychophysical experiments</title>
<sec id="s4b1">
<title>Subjects</title>
<p>Five male adult rhesus monkeys (<italic>Macaca mulatta</italic>) were used in the experiments. Four monkeys were used in the neurophysiological experiments, and one was used in the psychophysical experiment. Experimental protocols were approved by the local Institutional Animal Care and Use Committee and were in strict compliance with U.S. Department of Agriculture regulations and the National Institutes of Health <italic>Guide for the Care and Use of Laboratory Animals</italic>.</p>
</sec>
<sec id="s4b2">
<title>Apparatus and electrophysiological recording</title>
<p>Procedures for surgical preparation and electrophysiological recording were routine and similar to those described previously (<xref ref-type="bibr" rid="c29">Huang and Lisberger, 2009</xref>; <xref ref-type="bibr" rid="c81">Xiao et al., 2014</xref>). For subjects IM and MO, horizontal and vertical eye positions were monitored using the search coil method at a sampling rate of 1kHz on each channel. For subjects RG, GE, and BJ, eye positions were monitored using a video-based eye tracker (EyeLink, SR Research) at a rate of 1kHz. For electrophysiological recordings, we lowered single-contact tungsten microelectrodes (Thomas Recording or FHC) either using the MiniMatrix microdrive (Thomas Recording) or the NAN drive (NAN Instruments) into the posterior bank of the superior temporal sulcus. The impedances of the electrodes were 1∼3 MΩ. We identified area MT by its characteristically large proportion of directionally selective neurons, small classical RFs relative to those in the neighboring medial superior temporal area, and location on the posterior bank of the superior temporal sulcus. Electrical signals were filtered, amplified, and digitized conventionally. Single units were identified with a real-time template-matching system (Plexon). Spikes were carefully sorted using Plexon offline sorter.</p>
<p>Stimulus presentation and the behavioral paradigm were controlled by a real-time data acquisition program Maestro as described in the human psychophysics experiment. For neurophysiological recordings from IM and MO, visual stimuli were presented on a 20-inch CRT monitor at a viewing distance of 38 cm. Monitor resolution was 1,280 × 1,024 pixels and the refresh rate was 85 Hz. For RG, GE, and BJ, visual stimuli were presented on a 25-inch CRT monitor at a viewing distance of 63 cm. Monitor resolution was 1,024 × 768 pixels and the refresh rate was 100 Hz. Visual stimuli were generated by a Linux workstation using an OpenGL application that communicated with the main experimental-control computer over a dedicated Ethernet link. The output of the video monitor was gamma-corrected.</p>
</sec>
<sec id="s4b3">
<title>Visual stimuli and experimental procedure of the main experiment</title>
<p>All visual stimuli were presented in individual trials while monkeys maintained fixation. Monkeys were required to maintain fixation within a 1.5 × 1.5° window centered around a fixation spot during each trial to receive juice rewards, although actual fixation was typically more accurate. In a trial, visual stimuli were illuminated after the animal had acquired fixation for 200 ms. To assist the isolation of directional-selective neurons in area MT, we used circular translation of a large random-dot patch (30 × 30°) as a search stimulus (<xref ref-type="bibr" rid="c69">Schoppmann and Hoffmann, 1976</xref>). After an MT neuron was isolated, we characterized the direction tuning by randomly interleaved trials of 30 × 30° random-dot patches moving at 10°/s in eight different directions from 0 to 315° at 45° steps. Next, we mapped the RF by recording responses to a series of 5 × 5° patches of random dots that moved in the preferred direction of the neuron at 10°/s. The location of the patch was varied randomly to tile the screen in 5° steps without overlap and to cover an area of either 40 × 30° or 35 × 25°. The raw map of the RF was interpolated using the Matlab function <italic>interp2</italic> at an interval of 0.5° and the location giving rise to the highest firing rate was taken as the center of the RF. In the following experiments, testing stimuli were centered on the RF.</p>
<p>Monkeys IM and MO were tested with the main visual stimuli used in our experiments, which were two spatially overlapping random-dot patches presented within a square aperture 10° wide. The random dots were achromatic. The dot density of each random-dot patch was 2 dots/deg<sup>2</sup>. Each random dot was 3 pixels at a side and had a luminance of 15.0 cd/m<sup>2</sup>. The background luminance was &lt; 0.2 cd/m<sup>2</sup>. In each trial, the random dots moved within the aperture. The two random-dot patches translated at two different speeds at 100% motion coherence and in the same direction (the preferred direction of the recorded neuron). The ratio between the two component speeds was fixed either at 4 (i.e. the large speed separation) or 2 (i.e. the small speed separation) (see Methods for human psychophysics above). At x4 speed separation, the five speed pairs used were 1.25 and 5°/s, 2.5 and 10°/s, 5 and 20°/s, 10 and 40°/s, and 20 and 80°/s (<xref rid="fig1" ref-type="fig">Fig. 1B1</xref>). At x2 speed separation, the speed pairs used were 1.25 and 2.5°/s, 2.5 and 5°/s, 5 and 10°/s, 10 and 20°/s, and 20 and 40°/s (<xref rid="fig1" ref-type="fig">Fig. 1B2</xref>). Experimental trials of bi-speed stimuli that had x4 or x2 speed separations were randomly interleaved. Also randomly interleaved were trials that showed only a single random-dot patch moving at a speed of 1.25, 2.5, 5, 10, 20, 40, or 80°/s, which were the individual stimulus components of the bi-speed stimuli.</p>
<p>Monkeys RG and GE were tested with a variation of the main visual stimuli, in which two overlapping random-dot stimulus components moved at two fixed speeds of 2.5 and 10°/s, respectively, and in two different directions separated by 90°. The diameter of the stimulus aperture was 3°. The faster component moved at the clockwise side of the two component directions (illustrated in <xref rid="fig8" ref-type="fig">Fig. 8</xref>). We varied the vector average direction of the two stimulus components across 360° in a step of 15° to characterize the direction-tuning curves of MT neurons. We also measured the direction-tuning curves to a single stimulus moving at the individual component speeds.</p>
</sec>
<sec id="s4b4">
<title>Behavioral paradigm and visual stimuli of attention control</title>
<p>Monkey RG was also tested in a control experiment in which the attention of the animal was directed away from the RFs of MT neurons. The attended stimulus was a random-dot patch moving in a single direction at 100% motion coherence within a stationary circular aperture that had a diameter of 5<sup>°</sup>. The stimulus patch was centered 10<sup>°</sup> to the left of the fixation spot, in the visual hemifield contralateral to the hemifield of the recorded MT neurons’ RFs. The monkey performed a fine direction-discrimination task to report whether the motion direction of the attended stimulus moved at the clockwise or counter-clockwise side of the vertical direction. While the animal fixated on a point at the center of the monitor, both the attended stimulus and the RF stimulus were turned on and remained stationary for 250 ms before they moved for 500 ms. The attended stimulus translated at a speed of 10°/s and in a direction either clockwise or counter-clockwise from an invisible vertical (upward) direction by an offset of 10°, 15°, or 20°. The RF stimuli were the same as our main visual stimuli, with either a single-speed or bi-speed stimulus moving in the same direction. All trials were randomly interleaved. After the motion period, all the visual stimuli were turned off, and two reporting targets appeared 10° eccentric on the left and right sides of the fixation point. To receive a juice reward, the animal was required to make a saccadic eye movement within 400 ms after the fixation spot was turned off, either to the left or right target when the motion direction of the attended stimulus was counter-clockwise or clockwise to the vertical direction, respectively.</p>
</sec>
<sec id="s4b5">
<title>Monkey psychophysics</title>
<p>Monkey BJ was trained to perform a 2AFC discrimination task. The visual stimuli were the same as our main visual stimuli in the neurophysiological experiments except that the stimulus moving at a single speed was also composed of two overlapping random-dot patches moving in the same direction at the same speed, the same as in the human psychophysics experiments. In this way, the single-speed stimulus and the bi-speed stimuli had the same dot density. Visual stimuli were random-dot patches moving within a square aperture of 10°x10°, centered 10° to the right of the fixation spot. The motion direction of the visual stimuli was always rightward. Experimental trials of bi-speed stimuli that had x4 or x2 speed separations, as well as the single-speed stimulus that moved at the log mean speed of the bi-speed stimuli were randomly interleaved. Visual stimuli were turned on and remained stationary for 250 ms before they moved for 500 ms. Following the stimulus offset, two reporting targets (dots) were presented 5.7° away from the fixation spot, at upper right (4°, 4°) and lower left (−4°, -4°) positions relative to the fixation spot. To receive a juice reward, the animal was required to make a saccadic eye movement to one of the two targets within 300 ms after the fixation spot was turned off. In a majority of the experiment trials, the animal received juice rewards if selecting the upper-right target when visual stimuli moved at two different speeds and selecting the lower-left target when visual stimuli moved at a single speed. Guided by our human psychophysics results, we made an exception to always reward the animal when the bi-speed stimuli moved at 20 and 80°/s or at 20 and 40°/s, regardless of which target was selected to avoid biasing the monkey’s choice by veridically rewarding the animal. This was because, at these fast speeds, human subjects could not segment the bi-speed stimuli. During training, the animal was never presented with the bi-speed stimuli of 20 and 80°/s, and 20 and 40°/s. During testing, the trials of 20 and 80°/s, and 20 and 40°/s were randomly interleaved with bi-speed and single-speed trials that were rewarded veridically to anchor the task rule. Among all testing trials, only 10% of the trials were rewarded with a 100% rate. We collected 50 trials of data for x4 speed separation across 5 experimental sessions, and 90 trials for x2 speed separation across 9 sessions during the testing phase. The hit rate, false alarm rate, and the <italic>d’</italic> were calculated in the same way as in the human psychophysics experiments.</p>
</sec>
<sec id="s4b6">
<title>Model fit of the tuning curves to bi-speed stimuli</title>
<p>We used a linear weighted summation model (<xref ref-type="disp-formula" rid="eqn8">Eq. 8</xref>) to fit the direction-tuning curves to overlapping stimuli moving in different directions and at different speeds. We also fitted the direction-tuning curves to the bi-speed/bi-directional stimuli using a modified divisive normalization model (<xref ref-type="disp-formula" rid="eqn9">Eq. 9</xref>). These model fits were obtained using the constrained minimization tool “fmincon” (MATLAB) to minimize the sum of squared error. To evaluate the goodness of fit of models for the response tuning curves, we calculated the percentage of variance (PV) accounted for by the model as follows: <inline-formula><inline-graphic xlink:href="532456v3_inline3.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, where SSE is the sum of squared errors between the model fit and the neuronal data, and SST is the sum of squared differences between the data and the mean of the data (Morgan et al., 2008).</p>
</sec>
<sec id="s4b7">
<title>Construction of population neural response</title>
<p>For each recorded MT neuron, we plotted the trial-averaged speed tuning curve in response to the single speed and spline-fitted the tuning curve using the Matlab function <italic>csaps</italic> with the smoothing parameter <italic>p</italic> set to 0.93. We found <italic>p</italic> = 0.93 best captured the trend of the speed tuning, without obvious overfitting. We then found the preferred speed (PS) of the neuron, which is the speed when the maximum firing rate was reached in the spline-fitted tuning curve. The neuron’s responses to all single-speed and bi-speed stimuli were normalized by the maximum firing rate at the PS. To construct the population neural response to a given stimulus, we took the normalized firing rate of each neuron elicited by that stimulus and plotted it against the PS of the neuron. Because the PSs of the neurons in our data sample did not cover the full speed range evenly, we spline-fitted (with a smoothing parameter of 0.93) the population neural response to capture the population neural response evenly across the full range of PS.</p>
</sec>
<sec id="s4b8">
<title>Discrimination of population neural responses using a classifier</title>
<p>We trained a linear classifier to discriminate constructed population neural response to a bi-speed stimulus and the corresponding single-speed stimulus moving at the log mean speed. Constructed trial-by-trial population responses were generated randomly according to a Poisson process with the mean set to the recorded neuronal response averaged across experimental trials.</p>
<p>For each speed combination, we generated 200 trials of responses to the bi-speed stimuli and the corresponding single-speed stimulus, respectively. Constructed population responses were partitioned into training and testing sets using k-fold cross-validation (k = 40). The 200 generated trials were randomly divided into 40 folds. The classifier was trained on 39 data folds and tested on the remaining fold, and the process was repeated 40 times to ensure that each fold was used for testing exactly once. The Matlab <italic>fitclinear</italic> function was used to fit a linear classifier to the training data. The logistic learner and lasso regularization techniques were specified during the model training. The Stochastic Gradient Descent solver was used to optimize the objective function during the training of the classifier. The performance of the classifier was evaluated by <italic>d’</italic>, calculated using the hit rate and false alarm rate as described in human psychophysics.</p>
</sec>
<sec id="s4b9">
<title>Population Decoding</title>
<p>We define a given probability distribution of stimulus speed as: ∅<sub><italic>m</italic></sub> = {<italic>P</italic><sub><italic>m,j</italic></sub>}, in which <italic>P</italic><sub><italic>m,j</italic></sub> is the probability of speed <italic>S</italic><sub><italic>j</italic></sub>, <italic>j</italic> = 1, 2, 3, …, 121, and <italic>j</italic> evenly samples speeds from 1.25<sup>°</sup>/s to 80<sup>°</sup>/s (referred to as the “full speed range”) in a natural logarithm scale and at a “<italic>speed interval</italic>” of 0.0347. Because ∅<sub><italic>m</italic></sub> is a probability distribution, ∑<sub><italic>j</italic></sub> <italic>P</italic><sub><italic>m,j</italic></sub> = 1. <italic>m</italic> is an index for different distributions.</p>
<p>The estimated response (<italic>ES</italic>) of neuron <italic>i</italic> to the stimulus speeds with a probability distribution ∅<sub><italic>m</italic></sub> is a linear sum of the responses of neuron <italic>i</italic> to each single speed <italic>S</italic><sub><italic>j</italic></sub> within the full speed range, weighed by the probability of each speed in ∅<sub><italic>m</italic></sub>. The probability can also be considered as the weight (signal strength) of the speed.
<disp-formula id="eqn10">
<graphic xlink:href="532456v3_eqn10.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>f</italic><sub><italic>i</italic></sub> is the spline-fitted speed tuning curve of neuron <italic>i</italic> in response to single speeds. The estimated population response (<italic>EP</italic>) of <italic>N</italic> neurons to ∅<sub><italic>m</italic></sub> is:
<disp-formula id="eqn11">
<graphic xlink:href="532456v3_eqn11.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>PS</italic><sub><italic>i</italic></sub> is the preferred speed of neuron <italic>i, i</italic> = 1, 2, 3, …, N. N = 100 in our neural data.</p>
<p>We then spline-fitted the estimated population response <italic>EP</italic><sub><italic>m</italic></sub>(ln (<italic>PS</italic><sub><italic>i</italic></sub>)) using a smoothing parameter of 0.93, interpolating the PS within the full speed range from 1.25<sup>°</sup>/s to 80<sup>°</sup>/s in natural logarithm with 121 evenly spaced values. The spline-fitted estimated population response is represented as <italic>spEP</italic><sub><italic>m</italic></sub>(ln (<italic>PS</italic><sub><italic>j</italic></sub>)), <italic>j</italic> = 1, 2, 3, …, 121.</p>
<p>Similarly, we spline-fitted the recorded and normalized population neural response <italic>RP</italic><sub><italic>m</italic></sub>(ln (<italic>PS</italic><sub><italic>i</italic></sub>)), <italic>i</italic> = 1, 2, 3, …, 100, and interpolated the PS to the same 121-speed values in a logarithm scale within the full speed range as above. The spline-fitted, recorded population neural response is represented as <italic>spRP</italic><sub><italic>m</italic></sub>(ln (<italic>PS</italic><sub><italic>j</italic></sub>)), <italic>j</italic> = 1, 2, 3, …, 121.</p>
<p>The decoded probability distribution of the stimulus speed ∅<sub><italic>e</italic></sub> is the ∅<sub><italic>m</italic></sub> that maximizes the objective function (OF), which is defined as the negative value of the SSE (sum squared error) between the spline-fitted estimated population response and the recorded neural response:
<disp-formula id="eqn12">
<graphic xlink:href="532456v3_eqn12.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn13">
<graphic xlink:href="532456v3_eqn13.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Rather than finding an arbitrary distribution, we constrained ∅<sub><italic>e</italic></sub> to contain either a single speed with a probability (referred to as the “weight”) of 1 or two speeds with the same or different weights that sum to 1.</p>
</sec>
<sec id="s4b10">
<title>Algorithm to search for the probability distribution of stimulus speed</title>
<p>We first searched for the best-fit distribution ∅<sub><italic>e</italic>1</sub> that contained a single speed <italic>SP</italic> with non-zero probability (P=1) that gave rise to the maximum OF across the full speed range (<italic>OF</italic><sub><italic>max1</italic></sub>). We next searched for the best-fit distribution ∅<sub><italic>e</italic>2</sub> that contained two speeds <italic>SP</italic><sub>1</sub> and <italic>SP</italic><sub>2</sub> with non-zero probability and gave rise to the maximum OF for two speeds (<italic>OF</italic><sub><italic>max2</italic></sub>). We varied the speed separation, the center position, and the probabilities of the two speeds. For each speed separation and center position, the probabilities of <italic>SP</italic><sub>1</sub> and <italic>SP</italic><sub>2</sub> were varied from 0 to 1 at a step of 0.01, with the constraint that they summed to 1. We searched the speed separation, ln(<italic>SP</italic><sub>2</sub>)- ln(<italic>SP</italic><sub>1</sub>), from 0.0693 (i.e. 2 <italic>speed intervals</italic>) to 3.3271 (i.e. 96 <italic>speed intervals</italic>), in a step of 0.0693. The search range covered the speed ratio <italic>SP</italic><sub>2</sub>/<italic>SP</italic><sub>1</sub> from x1.07 to x27.86, sufficiently broader than x2 and x4 used in our visual stimuli. For each speed separation, we started the search where the center position of the two speeds [ln(<italic>SP</italic><sub>1</sub>)+ln(<italic>SP</italic><sub>2</sub>)]/2 was in the middle of the 121 possible speed values, referred to as the “speed axis”. We then moved the center position toward the left border of ln(1.25) at a step of 0.0347 to find the maximum OF value (<italic>OF</italic><sub><italic>leftmax</italic></sub>) along the left half of the speed axis. If the OF value at the center position next to the current position was higher, the search moved to the next position. Otherwise, the current position was considered a local maximum. After we found a local maximum, the search continued in the same direction for up to another 30 <italic>speed intervals</italic> until one of the component speeds hit a border, or 30 intervals were reached, or an OF value greater than the previous local maximum was found. If a larger OF was found, the local maximum was updated and the search jumped to that position, and the procedure repeated until <italic>OF</italic><sub><italic>leftmax</italic></sub> was found. We then returned to the middle of the speed axis and searched speed pair toward the right border ln(80) to find the maximum <italic>OF</italic><sub><italic>rightmax</italic></sub>. The larger one of <italic>OF</italic><sub><italic>leftmax</italic></sub> and <italic>OF</italic><sub><italic>rightmax</italic></sub> was the maximum OF for two speeds (<italic>OF</italic><sub><italic>max2</italic></sub>). The ∅<sub><italic>e</italic></sub> was either ∅<sub><italic>e</italic>1</sub> or ∅<sub><italic>e</italic>2</sub>, whichever gave rise to the larger value of <italic>OF</italic><sub><italic>max</italic>1</sub> and <italic>OF</italic><sub><italic>max2</italic></sub>.</p>
</sec>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>We thank Dr. Steven Lisberger for his support in the early phase of this project, Emily Ausloos and Jianbo Xiao for data collection in early human psychophysics experiments, Bryce Arseneau for animal training, Ying Cao for collecting additional neural data, Drs. Jennifer Coonen and Kevin Brunner at the Wisconsin National Primate Research Center for excellent veterinary care and surgical assistance, Dr. Kechen Zhang for helpful suggestions on the study, Drs. Emily Cooper and Greg DeAngelis for their valuable comments on the manuscript.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Allman</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Miezin</surname>, <given-names>F.</given-names></string-name>, &amp; <string-name><surname>McGuinness</surname>, <given-names>E.</given-names></string-name></person-group> (<year>1985</year>). <article-title>Direction- and velocity-specific responses from beyond the classical receptive field in the middle temporal visual area (MT)</article-title>. <source>Perception</source>, <volume>14</volume>(<issue>2</issue>), <fpage>105</fpage>–<lpage>126</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Anderson</surname>, <given-names>J. C.</given-names></string-name>, &amp; <string-name><surname>Martin</surname>, <given-names>K. A.</given-names></string-name></person-group> (<year>2002</year>). <article-title>Connection from cortical area V2 to MT in macaque monkey</article-title>. <source>J Comp Neurol</source>, <volume>443</volume>(<issue>1</issue>), <fpage>56</fpage>–<lpage>70</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Anderson</surname>, <given-names>J. C.</given-names></string-name>, <string-name><surname>Binzegger</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Martin</surname>, <given-names>K. A.</given-names></string-name>, &amp; <string-name><surname>Rockland</surname>, <given-names>K. S.</given-names></string-name></person-group> (<year>1998</year>). <article-title>The connection from cortical area V1 to V5: a light and electron microscopic study</article-title>. <source>J Neurosci</source>, <volume>18</volume>(<issue>24</issue>), <fpage>10525</fpage>–<lpage>10540</lpage>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Atick</surname>, <given-names>J. J.</given-names></string-name> &amp; <string-name><surname>Redlich</surname>, <given-names>A. N.</given-names></string-name></person-group> (<year>1992</year>). <article-title>What Does the Retina Know about Natural Scenes?</article-title> <source>Neural Computation</source>, <volume>4</volume>(<issue>2</issue>), <fpage>196</fpage>–<lpage>210</lpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Attneave</surname>, <given-names>F.</given-names></string-name></person-group> (<year>1954</year>). <article-title>Some informational aspects of visual perception</article-title>. <source>Psychol Rev</source>, <volume>61</volume>(<issue>3</issue>), <fpage>183</fpage>–<lpage>193</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Averbeck</surname>, <given-names>B. B.</given-names></string-name>, <string-name><surname>Latham</surname>, <given-names>P. E.</given-names></string-name> &amp; <string-name><surname>Pouget</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2006</year>). <article-title>Neural correlations, population coding and computation</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>7</volume>(<issue>5</issue>), <fpage>358</fpage>–<lpage>366</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bao</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Tsao</surname>, <given-names>D. Y.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Representation of multiple objects in macaque category-selective areas</article-title>. <source>Nat Commun</source>, <volume>9</volume>(<issue>1</issue>), <fpage>1774</fpage>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Barlow</surname> <given-names>H. B.</given-names></string-name></person-group> (<year>1961</year>). <chapter-title>Possible principles underlying the transformations of sensory messages. Chapter 13</chapter-title>. In: <person-group person-group-type="editor"><string-name><given-names>W.</given-names> <surname>Rosenblith</surname></string-name></person-group> (Ed.), <source>Sensory communication</source> (pp. <fpage>217</fpage>–<lpage>234</lpage>). <publisher-name>M.I.T. Press</publisher-name>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bergen</surname>, <given-names>R. S. van</given-names></string-name>, <string-name><surname>Ma</surname>, <given-names>W. J.</given-names></string-name>, <string-name><surname>Pratte</surname>, <given-names>M. S.</given-names></string-name> &amp; <string-name><surname>Jehee</surname>, <given-names>J. F. M.</given-names></string-name></person-group> (<year>2015</year>). <article-title>Sensory uncertainty decoded from visual cortex predicts behavior</article-title>. <source>Nature Neuroscience</source>, <volume>18</volume>(<issue>12</issue>), <fpage>1728</fpage>–<lpage>1730</lpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Born</surname>, <given-names>R. T.</given-names></string-name>, &amp; <string-name><surname>Bradley</surname>, <given-names>D. C.</given-names></string-name></person-group> (<year>2005</year>). <article-title>Structure and function of visual area MT</article-title>. <source>Annu Rev Neurosci</source>, <volume>28</volume>, <fpage>157</fpage>–<lpage>189</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Born</surname>, <given-names>R. T.</given-names></string-name>, <string-name><surname>Groh</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Zhao</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Lukasewycz</surname>, <given-names>S. J.</given-names></string-name></person-group> (<year>2000</year>). <article-title>Segregation segregation of object and background motion in visual area MT: effects of microstimulation on eye movements</article-title>. <source>Neuron</source>, <volume>26</volume>(<issue>3</issue>), <fpage>725</fpage>–<lpage>734</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Braddick</surname>, <given-names>O.</given-names></string-name></person-group> (<year>1993</year>). <article-title>Segmentation versus integration in visual motion processing</article-title>. <source>Trends Neurosci</source>, <volume>16</volume>(<issue>7</issue>), <fpage>263</fpage>–<lpage>268</lpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Braddick</surname>, <given-names>O.</given-names></string-name></person-group> (<year>1997</year>). <article-title>Local and global representations of velocity: transparency, opponency, and global direction perception</article-title>. <source>Perception</source>, <volume>26</volume>(<issue>8</issue>), <fpage>995</fpage>–<lpage>1010</lpage>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Braddick</surname>, <given-names>O. J.</given-names></string-name>, <string-name><surname>Wishart</surname>, <given-names>K. A.</given-names></string-name>, &amp; <string-name><surname>Curran</surname>, <given-names>W.</given-names></string-name></person-group> (<year>2002</year>). <article-title>Directional performance in motion transparency</article-title>. <source>Vision Res</source>, <volume>42</volume>(<issue>10</issue>), <fpage>1237</fpage>–<lpage>1248</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Britten</surname>, <given-names>K. H.</given-names></string-name></person-group> (<year>2003</year>). <chapter-title>The middle temporal area: motion processing and the link to perception</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>J. W. LM</given-names> <surname>Chalupa</surname></string-name></person-group> (Ed.), <source>The visual neurosciences</source> (pp. <fpage>1203</fpage>–<lpage>1216</lpage>). <publisher-name>The MIT Press</publisher-name>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Britten</surname>, <given-names>K. H.</given-names></string-name>, &amp; <string-name><surname>Heuer</surname>, <given-names>H. W.</given-names></string-name></person-group> (<year>1999</year>). <article-title>Spatial summation in the receptive fields of MT neurons</article-title>. <source>J Neurosci</source>. <volume>19</volume>, <fpage>5074</fpage>–<lpage>5084</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brouwer</surname>, <given-names>G. J.</given-names></string-name> &amp; <string-name><surname>Heeger</surname>, <given-names>D. J.</given-names></string-name></person-group> (<year>2009</year>). <article-title>Decoding and Reconstructing Color from Responses in Human Visual Cortex</article-title>. <source>The Journal of Neuroscience</source>, <volume>29</volume>(<issue>44</issue>), <fpage>13992</fpage>–<lpage>14003</lpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Busse</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Wade</surname>, <given-names>A. R.</given-names></string-name>, &amp; <string-name><surname>Carandini</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2009</year>). <article-title>Representation of concurrent stimuli by population activity in visual cortex</article-title>. <source>Neuron</source>, <volume>64</volume>(<issue>6</issue>), <fpage>931</fpage>–<lpage>942</lpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carandini</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Heeger</surname>, <given-names>D. J.</given-names></string-name></person-group> (<year>2012</year>). <article-title>Normalization as a canonical neural computation</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>13</volume>(<issue>1</issue>), <fpage>51</fpage>–<lpage>62</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carandini</surname>. <given-names>M.</given-names></string-name>, <string-name><surname>Heeger</surname>, <given-names>D. J.</given-names></string-name>, &amp; <string-name><surname>Movshon</surname>, <given-names>J. A.</given-names></string-name></person-group> (<year>1997</year>). <article-title>Linearity and normalization in simple cells of the macaque primary visual cortex</article-title>. <source>J Neurosci</source>. <volume>17</volume>, <fpage>8621</fpage>–<lpage>8644</lpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Caruso</surname>, <given-names>V. C.</given-names></string-name>, <string-name><surname>Mohl</surname>, <given-names>J. T.</given-names></string-name>, <string-name><surname>Glynn</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Willett</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Zaman</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Ebihara</surname>, <given-names>A. F.</given-names></string-name>, <string-name><surname>Estrada</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Freiwald</surname>, <given-names>W. A.</given-names></string-name>, <string-name><surname>Tokdar</surname>, <given-names>S. T.</given-names></string-name> &amp; <string-name><surname>Groh</surname>, <given-names>J. M.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Single neurons may encode simultaneous stimuli by switching between activity patterns</article-title>. <source>Nature Communications</source>, <volume>9</volume>(<issue>1</issue>), <fpage>2715</fpage>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Chakrala</surname>, <given-names>A. S.</given-names></string-name>, <string-name><surname>Xiao</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Huang</surname>, <given-names>X.</given-names></string-name></person-group> (<year>2024</year>). <article-title>The role of binocular disparity and attention in the neural representation of multiple moving stimuli in the visual cortex</article-title>. <source>BioRxiv</source>, 2023.06.25.546480.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Churchland</surname>, <given-names>M. M.</given-names></string-name>, &amp; <string-name><surname>Lisberger</surname>, <given-names>S. G.</given-names></string-name></person-group> (<year>2001</year>). <article-title>Shifts in the population response in the middle temporal visual area parallel perceptual and motor illusions produced by apparent motion</article-title>. <source>J Neurosci</source>, <volume>21</volume>(<issue>23</issue>), <fpage>9387</fpage>–<lpage>9402</lpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fiser</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Berkes</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Orbán</surname>, <given-names>G.</given-names></string-name> &amp; <string-name><surname>Lengyel</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2010</year>). <article-title>Statistically optimal perception and learning: from behavior to neural representations</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>14</volume>(<issue>3</issue>), <fpage>119</fpage>–<lpage>130</lpage>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ganguli</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>Simoncelli</surname>, <given-names>E. P.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Efficient Sensory Encoding and Bayesian Inference with Heterogeneous Neural Populations</article-title>. <source>Neural Computation</source>, <volume>26</volume>(<issue>10</issue>), <fpage>2103</fpage>–<lpage>2134</lpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Groh</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Schmehl</surname>, <given-names>M. N.</given-names></string-name>, <string-name><surname>Caruso</surname>, <given-names>V. C.</given-names></string-name> &amp; <string-name><surname>Tokdar</surname>, <given-names>S. T.</given-names></string-name></person-group> (<year>2024</year>). <article-title>Signal switching may enhance processing power of the brain</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>28</volume>(<issue>7</issue>), <fpage>600</fpage>–<lpage>613</lpage>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Heuer</surname>, <given-names>H. W.</given-names></string-name>, &amp; <string-name><surname>Britten</surname>, <given-names>K. H.</given-names></string-name></person-group> (<year>2002</year>). <article-title>Contrast dependence of response normalization in area MT of the rhesus macaque</article-title>. <source>J Neurophysiol</source>, <volume>88</volume>(<issue>6</issue>), <fpage>3398</fpage>–<lpage>3408</lpage>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Huang</surname> <given-names>W.</given-names></string-name>, <string-name><surname>Huang</surname> <given-names>X.</given-names></string-name>, &amp; <string-name><surname>Zhang</surname> <given-names>K.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Information-theoretic interpretation of tuning curves for multiple motion directions</article-title>. <conf-name>51st Annual Conference on Information Sciences and Systems (CISS)</conf-name>, <conf-loc>Baltimore, MD, USA</conf-loc>, pp. <fpage>1</fpage>–<lpage>4</lpage>, doi: <pub-id pub-id-type="doi">10.1109/CISS.2017.7926142</pub-id>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname>, <given-names>X.</given-names></string-name>, &amp; <string-name><surname>Lisberger</surname>, <given-names>S. G.</given-names></string-name></person-group> (<year>2009</year>). <article-title>Noise correlations in cortical area MT and their potential impact on trial-by-trial variation in the direction and speed of smooth-pursuit eye movements</article-title>. <source>J Neurophysiol</source>, <volume>101</volume>(<issue>6</issue>), <fpage>3012</fpage>–<lpage>3030</lpage>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Albright</surname>, <given-names>T. D.</given-names></string-name>, &amp; <string-name><surname>Stoner</surname>, <given-names>G. R.</given-names></string-name></person-group> (<year>2007</year>). <article-title>Adaptive surround modulation in cortical area MT</article-title>. <source>Neuron</source>, <volume>53</volume>(<issue>5</issue>), <fpage>761</fpage>–<lpage>770</lpage>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Albright</surname>, <given-names>T. D.</given-names></string-name>, &amp; <string-name><surname>Stoner</surname>, <given-names>G. R.</given-names></string-name></person-group> (<year>2008</year>). <article-title>Stimulus dependency and mechanisms of surround modulation in cortical area MT</article-title>. <source>J Neurosci</source>, <volume>28</volume>(<issue>51</issue>), <fpage>13889</fpage>–<lpage>13906</lpage>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><surname>Huang</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Arseneau</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Yerxa</surname>, <given-names>T. E.</given-names></string-name>, <string-name><surname>Cooper</surname>, <given-names>E. A.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Natural scene statistics of depth and motion pertinent to figure-ground segregation</article-title>. <source>Society for Neuroscience (SfN) Abstract</source>. 2019-S-7048-SfN.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Jun</surname>, <given-names>N. Y.</given-names></string-name>, <string-name><surname>Ruff</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Kramer</surname>, <given-names>L. E.</given-names></string-name>, <string-name><surname>Bowes</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Tokdar</surname>, <given-names>S. T.</given-names></string-name>, <string-name><surname>Cohen</surname>, <given-names>M. R.</given-names></string-name> &amp; <string-name><surname>Groh</surname>, <given-names>J. M.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Coordinated multiplexing of information about separate objects in visual cortex</article-title>. <source>eLife</source>, <volume>11</volume>, <elocation-id>e76452</elocation-id>. <pub-id pub-id-type="doi">10.7554/eLife.76452</pub-id></mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kay</surname>, <given-names>K. N.</given-names></string-name>, <string-name><surname>Naselaris</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Prenger</surname>, <given-names>R. J.</given-names></string-name> &amp; <string-name><surname>Gallant</surname>, <given-names>J. L.</given-names></string-name></person-group> (<year>2008</year>). <article-title>Identifying natural images from human brain activity</article-title>. <source>Nature</source>, <volume>452</volume>(<issue>7185</issue>), <fpage>352</fpage>–<lpage>355</lpage>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krekelberg</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>van Wezel</surname>, <given-names>R. J.</given-names></string-name></person-group> (<year>2013</year>). <article-title>Neural mechanisms of speed perception: transparent motion</article-title>. <source>J Neurophysiol</source>, <volume>110</volume>(<issue>9</issue>), <fpage>2007</fpage>–<lpage>2018</lpage>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krekelberg</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>van Wezel</surname>, <given-names>R. J.</given-names></string-name>, &amp; <string-name><surname>Albright</surname>, <given-names>T. D.</given-names></string-name></person-group> (<year>2006a</year>). <article-title>Adaptation in macaque MT reduces perceived speed and improves speed discrimination</article-title>. <source>J Neurophysiol</source>, <volume>95</volume>(<issue>1</issue>), <fpage>255</fpage>–<lpage>270</lpage>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krekelberg</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>van Wezel</surname>, <given-names>R. J.</given-names></string-name>, &amp; <string-name><surname>Albright</surname>, <given-names>T. D.</given-names></string-name></person-group> (<year>2006b</year>). <article-title>Interactions between speed and contrast tuning in the middle temporal area: implications for the neural code for speed</article-title>. <source>J Neurosci</source>, <volume>26</volume>(<issue>35</issue>), <fpage>8988</fpage>–<lpage>8998</lpage>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Kozyrev</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Kyllingsbæk</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Treue</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Ditlevsen</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Bundesen</surname>, <given-names>C.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Neurons in Primate Visual Cortex Alternate between Responses to Multiple Stimuli in Their Receptive Field</article-title>. <source>Frontiers in Computational Neuroscience</source>, <volume>10</volume>, <fpage>141</fpage>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lisberger</surname>, <given-names>S. G.</given-names></string-name>, &amp; <string-name><surname>Movshon</surname>, <given-names>J. A.</given-names></string-name></person-group> (<year>1999</year>). <article-title>Visual motion analysis for pursuit eye movements in area MT of macaque monkeys</article-title>. <source>J Neurosci</source>, <volume>19</volume>(<issue>6</issue>), <fpage>2224</fpage>–<lpage>2246</lpage>.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Newsome</surname>, <given-names>W. T.</given-names></string-name></person-group> (<year>2003</year>). <article-title>Functional organization of speed tuned neurons in visual area MT</article-title>. <source>J Neurophysiol</source>, <volume>89</volume>(<issue>1</issue>), <fpage>246</fpage>–<lpage>256</lpage>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ma</surname>, <given-names>W. J.</given-names></string-name>, <string-name><surname>Beck</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Latham</surname>, <given-names>P. E.</given-names></string-name> &amp; <string-name><surname>Pouget</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2006</year>). <article-title>Bayesian inference with probabilistic population codes</article-title>. <source>Nature Neuroscience</source>, <volume>9</volume>(<issue>11</issue>), <fpage>1432</fpage>–<lpage>1438</lpage>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Manning</surname>, <given-names>T. S.</given-names></string-name>, <string-name><surname>Alexander</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Cumming</surname>, <given-names>B. G.</given-names></string-name>, <string-name><surname>DeAngelis</surname>, <given-names>G. C.</given-names></string-name>, <string-name><surname>Huang</surname>, <given-names>X.</given-names></string-name> &amp; <string-name><surname>Cooper</surname>, <given-names>E. A.</given-names></string-name></person-group> (<year>2024</year>). <article-title>Transformations of sensory information in the brain suggest changing criteria for optimality</article-title>. <source>PLOS Computational Biology</source>, <volume>20</volume>(<issue>1</issue>), <fpage>e1011783</fpage>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Masson</surname>, <given-names>G. S.</given-names></string-name>, <string-name><surname>Mestre</surname>, <given-names>D. R.</given-names></string-name>, &amp; <string-name><surname>Stone</surname>, <given-names>L. S.</given-names></string-name></person-group> (<year>1999</year>). <article-title>Speed tuning of motion segmentation and discrimination</article-title>. <source>Vision Res</source>, <volume>39</volume>(<issue>26</issue>), <fpage>4297</fpage>–<lpage>4308</lpage>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Maunsell</surname>, <given-names>J. H.</given-names></string-name>, &amp; <string-name><surname>Van Essen</surname>, <given-names>D. C.</given-names></string-name></person-group> (<year>1983</year>). <article-title>Functional properties of neurons in middle temporal visual area of the macaque monkey. I. Selectivity for stimulus direction, speed, and orientation</article-title>. <source>J Neurophysiol</source>, <volume>49</volume>(<issue>5</issue>), <fpage>1127</fpage>–<lpage>1147</lpage>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McDonald</surname>, <given-names>J. S.</given-names></string-name>, <string-name><surname>Clifford</surname>, <given-names>C. W.</given-names></string-name>, <string-name><surname>Solomon</surname>, <given-names>S. S.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>S. C.</given-names></string-name>, &amp; <string-name><surname>Solomon</surname>, <given-names>S. G.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Integration and segregation of multiple motion signals by neurons in area MT of primate</article-title>. <source>J Neurophysiol</source>, <volume>111</volume>(<issue>2</issue>), <fpage>369</fpage>–<lpage>378</lpage>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mestre</surname>, <given-names>D. R.</given-names></string-name>, <string-name><surname>Masson</surname>, <given-names>G. S.</given-names></string-name>, &amp; <string-name><surname>Stone</surname>, <given-names>L. S.</given-names></string-name></person-group> (<year>2001</year>). <article-title>Spatial scale of motion segmentation from speed cues</article-title>. <source>Vision Res</source>, <volume>41</volume>(<issue>21</issue>), <fpage>2697</fpage>–<lpage>2713</lpage>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mikami</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Newsome</surname>, <given-names>W. T.</given-names></string-name>, &amp; <string-name><surname>Wurtz</surname>, <given-names>R. H.</given-names></string-name></person-group> (<year>1986</year>). <article-title>Motion selectivity in macaque visual cortex. I. Mechanisms of direction and speed selectivity in extrastriate area MT</article-title>. <source>J Neurophysiol</source>, <volume>55</volume>(<issue>6</issue>), <fpage>1308</fpage>–<lpage>1327</lpage>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Movshon</surname>, <given-names>J. A.</given-names></string-name>, &amp; <string-name><surname>Newsome</surname>, <given-names>W. T.</given-names></string-name></person-group> (<year>1996</year>). <article-title>Visual response properties of striate cortical neurons projecting to area MT in macaque monkeys</article-title>. <source>J Neurosci</source>, <volume>16</volume>(<issue>23</issue>), <fpage>7733</fpage>–<lpage>7741</lpage>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Naselaris</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Kay</surname>, <given-names>K. N.</given-names></string-name>, <string-name><surname>Nishimoto</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Gallant</surname>, <given-names>J. L.</given-names></string-name></person-group> (<year>2011</year>). <article-title>Encoding and decoding in fMRI</article-title>. <source>NeuroImage</source>, <volume>56</volume>(<issue>2</issue>), <fpage>400</fpage>–<lpage>410</lpage>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ni</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Ray</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Maunsell</surname>, <given-names>J. H.</given-names></string-name></person-group> (<year>2012</year>). <article-title>Tuned normalization explains the size of attention modulations</article-title>. <source>Neuron</source>, <volume>73</volume>(<issue>4</issue>), <fpage>803</fpage>–<lpage>813</lpage>.</mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nover</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Anderson</surname>, <given-names>C. H.</given-names></string-name>, &amp; <string-name><surname>DeAngelis</surname>, <given-names>G. C.</given-names></string-name></person-group> (<year>2005</year>). <article-title>A logarithmic, scale-invariant representation of speed in macaque middle temporal area accounts for speed discrimination performance</article-title>. <source>J Neurosci</source>, <volume>25</volume>(<issue>43</issue>), <fpage>10049</fpage>–<lpage>10060</lpage>.</mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Orban</surname>, <given-names>G. A.</given-names></string-name>, <string-name><surname>Kennedy</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Bullier</surname>, <given-names>J.</given-names></string-name></person-group> (<year>1986</year>). <article-title>Velocity sensitivity and direction selectivity of neurons in areas V1 and V2 of the monkey: influence of eccentricity</article-title>. <source>J Neurophysiol</source>, <volume>56</volume>(<issue>2</issue>), <fpage>462</fpage>–<lpage>480</lpage>.</mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Orhan</surname>, <given-names>A. E.</given-names></string-name>, &amp; <string-name><surname>Ma</surname>, <given-names>W. J.</given-names></string-name></person-group> (<year>2015</year>). <article-title>Neural population coding of multiple stimuli</article-title>. <source>J Neurosci.</source> <volume>35</volume>, <fpage>3825</fpage>–<lpage>3841</lpage>.</mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pack</surname>, <given-names>C. C.</given-names></string-name>, <string-name><surname>Hunter</surname>, <given-names>J. N.</given-names></string-name>, &amp; <string-name><surname>Born</surname>, <given-names>R. T.</given-names></string-name></person-group> (<year>2005</year>). <article-title>Contrast dependence of suppressive influences in cortical area MT of alert macaque</article-title>. <source>J Neurophysiol</source>, <volume>93</volume>(<issue>3</issue>), <fpage>1809</fpage>–<lpage>1815</lpage>.</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pasternak</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Tadin</surname>, <given-names>D.</given-names></string-name></person-group> (<year>2020</year>). <article-title>Linking Neuronal Direction Selectivity to Perceptual Decisions About Visual Motion</article-title>. <source>Annu Rev Vis Sci</source>, <volume>6</volume>, <fpage>335</fpage>–<lpage>362</lpage>.</mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Perrone</surname>, <given-names>J. A.</given-names></string-name>, &amp; <string-name><surname>Thiele</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2001</year>). <article-title>Speed skills: measuring the visual speed analyzing properties of primate MT neurons</article-title>. <source>Nat Neurosci</source>, <volume>4</volume>(<issue>5</issue>), <fpage>526</fpage>–<lpage>532</lpage>.</mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pouget</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Snyder</surname>, <given-names>L. H.</given-names></string-name></person-group> (<year>2000</year>). <article-title>Computational approaches to sensorimotor transformations</article-title>. <source>Nat Neurosci</source>, <volume>3</volume> <issue>Suppl</issue>, <fpage>1192</fpage>–<lpage>1198</lpage>.</mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pouget</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Zemel</surname>, <given-names>R. S.</given-names></string-name></person-group> (<year>2003</year>). <article-title>Inference and computation with population codes</article-title>. <source>Annu Rev Neurosci</source>, <volume>26</volume>, <fpage>381</fpage>–<lpage>410</lpage>.</mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Priebe</surname>, <given-names>N. J.</given-names></string-name>, &amp; <string-name><surname>Lisberger</surname>, <given-names>S. G.</given-names></string-name></person-group> (<year>2004</year>). <article-title>Estimating target speed from the population response in visual area MT</article-title>. <source>J Neurosci</source>, <volume>24</volume>(<issue>8</issue>), <fpage>1907</fpage>–<lpage>1916</lpage>.</mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Priebe</surname>, <given-names>N. J.</given-names></string-name>, <string-name><surname>Cassanello</surname>, <given-names>C. R.</given-names></string-name>, &amp; <string-name><surname>Lisberger</surname>, <given-names>S. G.</given-names></string-name></person-group> (<year>2003</year>). <article-title>The neural representation of speed in macaque area MT/V5</article-title>. <source>J Neurosci</source>, <volume>23</volume>(<issue>13</issue>), <fpage>5650</fpage>–<lpage>5661</lpage>.</mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Priebe</surname>, <given-names>N. J.</given-names></string-name>, <string-name><surname>Lisberger</surname>, <given-names>S. G.</given-names></string-name>, &amp; <string-name><surname>Movshon</surname>, <given-names>J. A.</given-names></string-name></person-group> (<year>2006</year>). <article-title>Tuning for spatiotemporal frequency and speed in directionally selective neurons of macaque striate cortex</article-title>. <source>J Neurosci</source>, <volume>26</volume>(<issue>11</issue>), <fpage>2941</fpage>–<lpage>2950</lpage>.</mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Qian</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Andersen</surname>, <given-names>R. A.</given-names></string-name></person-group> (<year>1994</year>). <article-title>Transparent motion perception as detection of unbalanced motion signals. II. Physiology</article-title>. <source>J Neurosci</source>, <volume>14</volume>(<issue>12</issue>), <fpage>7367</fpage>–<lpage>7380</lpage>.</mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Recanzone</surname>, <given-names>G. H.</given-names></string-name>, <string-name><surname>Wurtz</surname>, <given-names>R. H.</given-names></string-name> &amp; <string-name><surname>Schwarz</surname>, <given-names>U.</given-names></string-name></person-group> (<year>1997</year>). <article-title>Responses of MT and MST Neurons to One and Two Moving Objects in the Receptive Field</article-title>. <source>Journal of Neurophysiology</source>, <volume>78</volume>(<issue>6</issue>), <fpage>2904</fpage>–<lpage>2915</lpage>.</mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Riesenhuber</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Poggio</surname>, <given-names>T.</given-names></string-name></person-group> (<year>1999</year>). <article-title>Hierarchical models of object recognition in cortex</article-title>. <source>Nat Neurosci</source>, <volume>2</volume>(<issue>11</issue>), <fpage>1019</fpage>–<lpage>1025</lpage>.</mixed-citation></ref>
<ref id="c65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rocchi</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Ledgeway</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Webb</surname>, <given-names>B.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Criterion-free measurement of motion transparency perception at different speeds</article-title>. <source>Journal of Vision</source>, <volume>18</volume>(<issue>4</issue>).</mixed-citation></ref>
<ref id="c66"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rockland</surname>, <given-names>K. S.</given-names></string-name></person-group> (<year>2002</year>). <article-title>Visual cortical organization at the single axon level: a beginning</article-title>. <source>Neurosci Res</source>, <volume>42</volume>(<issue>3</issue>), <fpage>155</fpage>–<lpage>166</lpage>.</mixed-citation></ref>
<ref id="c67"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rust</surname>, <given-names>N. C.</given-names></string-name>, <string-name><surname>Mante</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Simoncelli</surname>, <given-names>E. P.</given-names></string-name>, &amp; <string-name><surname>Movshon</surname>, <given-names>J. A.</given-names></string-name></person-group> (<year>2006</year>). <article-title>How MT cells analyze the motion of visual patterns</article-title>. <source>Nature Neuroscience</source>, <volume>9</volume>(<issue>11</issue>), <fpage>1421</fpage>–<lpage>1431</lpage>.</mixed-citation></ref>
<ref id="c68"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schmehl</surname>, <given-names>M. N.</given-names></string-name>, <string-name><surname>Caruso</surname>, <given-names>V. C.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Jun</surname>, <given-names>N. Y.</given-names></string-name>, <string-name><surname>Willett</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Mohl</surname>, <given-names>J. T.</given-names></string-name>, <string-name><surname>Ruff</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Cohen</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Ebihara</surname>, <given-names>A. F.</given-names></string-name>, <string-name><surname>Freiwald</surname>, <given-names>W. A.</given-names></string-name>, <string-name><surname>Tokdar</surname>, <given-names>S. T.</given-names></string-name> &amp; <string-name><surname>Groh</surname>, <given-names>J. M.</given-names></string-name></person-group> (<year>2024</year>). <article-title>Multiple objects evoke fluctuating responses in several regions of the visual pathway</article-title>. <source>eLife</source>, <volume>13</volume>, <elocation-id>e91129</elocation-id>. <pub-id pub-id-type="doi">10.7554/eLife.91129</pub-id></mixed-citation></ref>
<ref id="c69"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schoppmann</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Hoffmann</surname>, <given-names>K. P.</given-names></string-name></person-group> (<year>1976</year>). <article-title>Continuous mapping of direction selectivity in the cat’s visual cortex</article-title>. <source>Neurosci Lett</source>, <volume>2</volume>(<issue>4</issue>), <fpage>177</fpage>–<lpage>181</lpage>.</mixed-citation></ref>
<ref id="c70"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Simoncelli</surname>, <given-names>E. P.</given-names></string-name>, &amp; <string-name><surname>Olshausen</surname>, <given-names>B. A.</given-names></string-name></person-group> (<year>2001</year>). <article-title>Natural image statistics and neural representation</article-title>. <source>Annu Rev Neurosci</source>, <volume>24</volume>, <fpage>1193</fpage>–<lpage>1216</lpage>.</mixed-citation></ref>
<ref id="c71"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Snowden</surname>, <given-names>R. J.</given-names></string-name>, <string-name><surname>Treue</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Erickson</surname>, <given-names>R. G.</given-names></string-name>, &amp; <string-name><surname>Andersen</surname>, <given-names>R. A.</given-names></string-name></person-group> (<year>1991</year>). <article-title>The response of area MT and V1 neurons to transparent motion</article-title>. <source>J Neurosci</source>, <volume>11</volume>(<issue>9</issue>), <fpage>2768</fpage>–<lpage>2785</lpage>.</mixed-citation></ref>
<ref id="c72"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stocker</surname>, <given-names>A. A.</given-names></string-name>, &amp; <string-name><surname>Simoncelli</surname>, <given-names>E. P.</given-names></string-name></person-group> (<year>2006</year>). <article-title>Noise characteristics and prior expectations in human visual speed perception</article-title>. <source>Nat Neurosci</source>, <volume>9</volume>(<issue>4</issue>), <fpage>578</fpage>–<lpage>585</lpage>.</mixed-citation></ref>
<ref id="c73"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stoner</surname>, <given-names>G. R.</given-names></string-name>, &amp; <string-name><surname>Albright</surname>, <given-names>T. D.</given-names></string-name></person-group> (<year>1992</year>). <article-title>Neural correlates of perceptual motion coherence</article-title>. <source>Nature</source>, <volume>358</volume>(<issue>6385</issue>), <fpage>412</fpage>–<lpage>414</lpage>.</mixed-citation></ref>
<ref id="c74"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Treue</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Hol</surname>, <given-names>K.</given-names></string-name> &amp; <string-name><surname>Rauber</surname>, <given-names>H.-J.</given-names></string-name></person-group> (<year>2000</year>). <article-title>Seeing multiple directions of motion—physiology and psychophysics</article-title>. <source>Nature Neuroscience</source>, <volume>3</volume>(<issue>3</issue>), <fpage>270</fpage>–<lpage>276</lpage>.</mixed-citation></ref>
<ref id="c75"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ungerleider</surname>, <given-names>L. G.</given-names></string-name>, &amp; <string-name><surname>Desimone</surname>, <given-names>R.</given-names></string-name></person-group> (<year>1986</year>). <article-title>Cortical connections of visual area MT in the macaque</article-title>. <source>J Comp Neurol</source>, <volume>248</volume>(<issue>2</issue>), <fpage>190</fpage>–<lpage>222</lpage>.</mixed-citation></ref>
<ref id="c76"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ungerleider</surname>, <given-names>L. G.</given-names></string-name>, &amp; <string-name><surname>Desimone</surname>, <given-names>R.</given-names></string-name></person-group> (<year>1986</year>). <article-title>Cortical connections of visual area MT in the macaque</article-title>. <source>J Comp Neurol</source>, <volume>248</volume>(<issue>2</issue>), <fpage>190</fpage>–<lpage>222</lpage>.</mixed-citation></ref>
<ref id="c77"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vintch</surname>, <given-names>B.</given-names></string-name> &amp; <string-name><surname>Gardner</surname>, <given-names>J. L.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Cortical Correlates of Human Motion Perception Biases</article-title>. <source>The Journal of Neuroscience</source>, <volume>34</volume>(<issue>7</issue>), <fpage>2592</fpage>–<lpage>2604</lpage>.</mixed-citation></ref>
<ref id="c78"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Weiss</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Simoncelli</surname>, <given-names>E. P.</given-names></string-name>, &amp; <string-name><surname>Adelson</surname>, <given-names>E. H.</given-names></string-name></person-group> (<year>2002</year>). <article-title>Motion illusions as optimal percepts</article-title>. <source>Nat Neurosci</source>, <volume>5</volume>(<issue>6</issue>), <fpage>598</fpage>–<lpage>604</lpage>.</mixed-citation></ref>
<ref id="c79"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wiesner</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Baumgart</surname>, <given-names>I. W.</given-names></string-name>, &amp; <string-name><surname>Huang</surname>, <given-names>X.</given-names></string-name></person-group> (<year>2020</year>). <article-title>Spatial Arrangement Drastically Changes the Neural Representation of Multiple Visual Stimuli That Compete in More Than One Feature Domain</article-title>. <source>J Neurosci</source>, <volume>40</volume>(<issue>9</issue>), <fpage>1834</fpage>–<lpage>1848</lpage>.</mixed-citation></ref>
<ref id="c80"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xiao</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Huang</surname>, <given-names>X.</given-names></string-name></person-group> (<year>2015</year>). <article-title>Distributed and Dynamic Neural Encoding of Multiple Motion Directions of Transparently Moving Stimuli in Cortical Area MT</article-title>. <source>J Neurosci</source>, <volume>35</volume>(<issue>49</issue>), <fpage>16180</fpage>–<lpage>16198</lpage>.</mixed-citation></ref>
<ref id="c81"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xiao</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Niu</surname>, <given-names>Y. Q.</given-names></string-name>, <string-name><surname>Wiesner</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Huang</surname>, <given-names>X.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Normalization of neuronal responses in cortical area MT across signal strengths and motion directions</article-title>. <source>J Neurophysiol</source>, <volume>112</volume>(<issue>6</issue>), <fpage>1291</fpage>–<lpage>1306</lpage>.</mixed-citation></ref>
<ref id="c82"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yang</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Lisberger</surname>, <given-names>S. G.</given-names></string-name></person-group> (<year>2009</year>). <article-title>Relationship between adapted neural population responses in MT and motion adaptation in speed and direction of smooth-pursuit eye movements</article-title>. <source>J Neurophysiol</source>, <volume>101</volume>(<issue>5</issue>), <fpage>2693</fpage>–<lpage>2707</lpage>.</mixed-citation></ref>
<ref id="c83"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zemel</surname>, <given-names>R. S.</given-names></string-name>, <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Pouget</surname>, <given-names>A.</given-names></string-name></person-group> (<year>1998</year>). <article-title>Probabilistic interpretation of population codes</article-title>. <source>Neural Comput</source>, <volume>10</volume>(<issue>2</issue>), <fpage>403</fpage>–<lpage>430</lpage>.</mixed-citation></ref>
<ref id="c84"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname>, <given-names>L. Q.</given-names></string-name>, &amp; <string-name><surname>Stocker</surname>, <given-names>A. A.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Prior Expectations in Visual Speed Perception Predict Encoding Characteristics of Neurons in Area MT</article-title>. <source>J Neurosci</source>, <volume>42</volume>(<issue>14</issue>), <fpage>2951</fpage>–<lpage>2962</lpage>.</mixed-citation></ref>
<ref id="c85"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zoccolan</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Cox</surname>, <given-names>D. D.</given-names></string-name> &amp; <string-name><surname>DiCarlo</surname>, <given-names>J. J.</given-names></string-name></person-group> (<year>2005</year>). <article-title>Multiple Object Response Normalization in Monkey Inferotemporal Cortex</article-title>. <source>The Journal of Neuroscience</source>, <volume>25</volume>(<issue>36</issue>), <fpage>8150</fpage>–<lpage>8164</lpage>.</mixed-citation></ref>
<ref id="c86"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zohary</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Shadlen</surname>, <given-names>M. N.</given-names></string-name>, &amp; <string-name><surname>Newsome</surname>, <given-names>W. T.</given-names></string-name></person-group> (<year>1994</year>). <article-title>Correlated neuronal discharge rate and its implications for psychophysical performance</article-title>. <source>Nature</source>, <volume>370</volume>(<issue>6485</issue>), <fpage>140</fpage>–<lpage>143</lpage>.</mixed-citation></ref>
</ref-list>
<app-group>
<app id="s5">
<title>Supplementary Materials and Figures</title>
<sec id="s5a">
<label>1.</label><title>Behavioral performance of the fine-direction discrimination task and MT response properties when attention was directed away from MT neurons’ RFs</title>
<p>The monkey RG performed a fine-direction discrimination task with an average correct rate of 86.7 ± 7.3% (mean ± std) across 23 sessions and over 5000 trials. The correct rates for 10°, 15°, and 20° direction offsets of the fine direction-discrimination task were 78.8 ± 9.7%, 87.5 ± 8.3%, and 93.9 ± 5.8%, respectively (see Methods).</p>
<fig id="figS1" position="float" fig-type="figure">
<label>Supplementary Figure 1.</label>
<caption><title>Population-averaged speed tuning curves to bi-speed stimuli and constituent single-speed components recorded in an attention-away and a fixation paradigm.</title>
<p>Speed tuning curves from one monkey (RG) averaged across <bold>A1-D1</bold>. 5 neurons that had PS ≤ 2.5<sup>°</sup>/s, <bold>A2-D2</bold>. 6 neurons that had PS between 2.5 and 25<sup>°</sup>/s, <bold>A3-D3</bold>. 21 neurons that had PS &gt; 25<sup>°</sup>/s. Error bars represent ±STE. <bold>A1-A3</bold> and <bold>B1-B3</bold>. X4 speed separation; <bold>C1-C3</bold> and <bold>D1-D3</bold>. X2 speed separation. <bold>A1-A3</bold> and <bold>C1-C3</bold>. Attention directed away from the RF; <bold>B1-B3</bold> and <bold>D1-D3</bold>. Fixation paradigm.</p></caption>
<graphic xlink:href="532456v3_figS1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s5b">
<label>2.</label><title>Trial-by-trial readouts from population neural responses to single speeds</title>
<fig id="figS2" position="float" fig-type="figure">
<label>Supplementary Figure 2.</label>
<caption><title>Trial-by-trial readout speeds decoded from population neural responses to single speeds.</title>
<p>The neural population contained 100 recorded neurons, as shown in <xref rid="fig9" ref-type="fig">Figure 9</xref>. The trial-by-trial responses were randomly generated based on a Poisson process, with the mean set to the spike count averaged across the recorded trials. Each row shows the readout speed(s) from one trial, and each dot’s size is proportional to the weight of the readout speed. If only one speed is decoded in a trial, that readout speed is shown in red. In trials with two readout speeds, the slower and faster readout speeds are shown in green and blue, respectively. The white background indicates trials with a weight difference between two readout speeds less than 0.7 and are considered to have two readout speeds. The gray background indicates trials with a weight difference greater than 0.7 and are considered to have only one readout speed. The vertical black line and the speed marked in each panel indicate the stimulus speed. <bold>A-G</bold>. Speeds decoded from recorded population neural responses to single speeds from 1.25 to 80<sup>°</sup>/s. Note that, at the stimulus speed of 80<sup>°</sup>/s (G), in addition to picking up the veridical speed of 80<sup>°</sup>/s (log speed of 4.382), the decoder often picked up a slower speed at 2.872<sup>°</sup>/s (log speed of 1.055), which was at the largest speed separation from 80<sup>°</sup>/s used in our searching algorithm (x27.86, log value 3.327). This border effect can also be seen at the stimulus speed of 1.25<sup>°</sup>/s (A) as well, in which a weaker and faster speed was sometimes picked up around 34.8<sup>°</sup>/s (log speed of 3.55). <bold>H-L</bold>. Speeds decoded from inferred population neural response to single speeds, which are the log-mean speeds of the bi-speed stimuli with x2 speed separation. The responses of these log mean speeds of x2 speed separation were obtained from the splined-fitted, trial-averaged speed-tuning curve of each neuron. <bold>M</bold>. Comparison of the readout speeds and the stimulus speeds. The diagonal line is the unity line. The ordinate represents the speed at the peak of the readout speed distribution pooled across simulated trials (not shown). At the stimulus speed of 1.77<sup>°</sup>/s (H), the distribution of the readout speed has two peaks, indicated by a solid circle (at 1.77<sup>°</sup>/s) and an open circle (at 1.25<sup>°</sup>/s). At the stimulus speed of 80<sup>°</sup>/s (G), the distribution of the readout speed also has two peaks; only the readout speed for the higher peak is shown in M.</p></caption>
<graphic xlink:href="532456v3_figS2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s5c">
<label>3.</label><title>Analysis of decoded speeds of the bi-speed stimulus with the fastest speeds of 20 and 80<sup>°</sup>/s</title>
<p>At the fastest stimulus speeds of 20 and 80<sup>°</sup>/s, across all trials, the mean objective function value peaked at speed separation of x3.25 (mean OF = -0.17, std = 0.14) (purple vertical line in <xref rid="figS3" ref-type="fig">Suppl. Fig. 3A</xref>). However, the peak value is not significantly different from the mean objective function value at the largest speed separation (x27.86, 3.3 on the log scale) searched (mean OF = -0.19, std = 0.14) (paired t-test, p=0.31) (orange vertical line in <xref rid="figS3" ref-type="fig">Suppl. Fig. 3A</xref>). The flat objective function suggests high uncertainty of the extracted speed separation at this speed pair.</p>
<p>We divided the trials into two subgroups, considering that they had either one or two readout speeds, and calculated the objective function for each subgroup. For trials considered to have one readout speed, the mean objective function showed a peak at the speed separation of x27.86 (3.3 on the log scale), which was the largest speed separation searched (orange vertical line in <xref rid="figS3" ref-type="fig">Suppl. Fig. 3E</xref>). As shown in <xref rid="figS3" ref-type="fig">Supplementary Figure 3F</xref>, as the searched speed separation increased, the dominate faster readout speed approached the log mean speed (40<sup>°</sup>/s, 3.7 on log scale) (thick navy blue curve) and the mean weight increased to 0.94 (cyan curve), whereas the slower readout speed approached the lower boundary speed (1.25<sup>°</sup>/s) (thick green curve) with the weight diminishing to negligible 0.06 (thin green curve) as a likely artifact. For trials considered to have two readout speeds, the objective function peaked at the speed separation of x3.25 (1.18 on the log scale) (purple vertical line in <xref rid="figS3" ref-type="fig">Suppl. Fig. 3B</xref>), corresponding to two readout speeds of 17.8 and 58.0<sup>°</sup>/s (the interaction points between the purple vertical line with the thick navy blue and thick green curves) (<xref rid="figS3" ref-type="fig">Suppl. Fig. 3C</xref>).</p>
<p>Furthermore, we compared the population neural responses averaged across the one-readout-speed trials and the two-readout-speed trials. The spline-fitted population responses of the two subgroups were highly correlated (R<sup>2</sup>=0.99) and statistically indistinguishable (paired t-test, p=0.30) (<xref rid="figS3" ref-type="fig">Suppl. Fig. 3D</xref>). This indicates that a tiny change in the population response (e.g., a slightly higher peak near log preferred speed of 3.7) would lead the decoder to exact one speed rather than two speeds (<xref rid="figS3" ref-type="fig">Suppl. Fig. 3D</xref>). In other words, the decoder was uncertain about how many speeds were in the visual stimuli and therefore had difficulty segmenting the visual stimuli at these fast stimulus speeds of 20 and 80<sup>°</sup>/s.</p>
<fig id="figS3" position="float" fig-type="figure">
<label>Supplementary Figure 3.</label>
<caption><title>Analysis of decoding the speeds of the bi-speed stimulus with the fastest speeds of 20 and 80<sup>°</sup>/s.</title>
<p><bold>A</bold>. Evolution of the objective function averaged across all 200 trials as the decoder searched through different speed separations. The red dot on the X-axis indicates the speed separation of the stimulus speeds. <bold>B, E</bold>. Evolution of the objective functions averaged across trials considered to have two (B) and one (E) readout speed(s). In A, B, and E, the error bands indicate ±STE. The black arrow indicates the speed separation where the objective function reaches its peak. The horizontal dotted line indicates the peak value of the objective function. <bold>C, F</bold>. Evolution of the readout speeds (darker and thick lines) and their weights (lighter and thin lines) as the decoder searched through different speed separations in trials considered to have two (C) and one (F) readout speed(s). <bold>D</bold>. Population neural responses averaged across trials that are considered to have two readout speeds (purple) and one readout speed (orange). Each dot represents the trial-averaged response of one neuron. The curves represent the spline-fitted population neural responses. The two red dots on the X-axis indicate stimulus speeds of 20 and 80<sup>°</sup>/s.</p></caption>
<graphic xlink:href="532456v3_figS3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</app>
</app-group>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94835.2.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Groh</surname>
<given-names>Jennifer M</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Duke University</institution>
</institution-wrap>
<city>Durham</city>
<country country="US">United States</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Compelling</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study concerns how macaque visual cortical area MT represents stimuli composed of more than one speed of motion. The study is <bold>valuable</bold> because little is known about how the visual pathway segments and preserves information about multiple stimuli, and the study involves perceptual reports from both humans and one monkey regarding whether there are one or two speeds in the stimulus. The study presents <bold>compelling</bold> evidence that (on average) MT neurons shift from faster-speed-takes-all at low speeds to representing the average of the two speeds at higher speeds. Ultimately, this study raises intriguing questions about how exactly the response patterns in visual cortical area MT might preserve information about each speed, since such information could potentially be lost in an average response as described here, depending on assumptions about how MT activity is evaluated by other visual areas.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94835.2.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Most studies in sensory neuroscience investigate how individual sensory stimuli are represented in the brain (e.g., the motion or color of a single object). This study starts tackling the more difficult question of how the brain represents multiple stimuli simultaneously and how these representations help to segregate objects from cluttered scenes with overlapping objects.</p>
<p>Strengths</p>
<p>The authors first document the ability of humans to segregate two motion patterns based on differences in speed. Then they show that a monkey's performance is largely similar; thus establishing the monkey as a good model to study the underlying neural representations.</p>
<p>Careful quantification of the neural responses in the middle temporal area during the simultaneous presentation of fast and slow speeds leads to the surprising finding that, at low average speeds, many neurons respond as if the slowest speed is not present, while they show averaged responses at high speeds. This unexpected complexity of the integration of multiple stimuli is key to the model developed in this paper.</p>
<p>One experiment in which attention is drawn away from the receptive field supports the claim that this is not due to the involuntary capture of attention by fast speeds.</p>
<p>A classifier using the neuronal response and trained to distinguish single speed from bi-speed stimuli shows a similar overall performance and dependence on the mean speed as the monkey. This supports the claim that these neurons may indeed underlie the animal's decision process.</p>
<p>The authors expand the well-established divisive normalization model to capture the responses to bi-speed stimuli. The incremental modeling (eq 9 and 10) clarifies which aspects of the tuning curves are captured by the parameters.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94835.2.sa1</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This study concerns how macaque visual cortical area MT represents stimuli composed of more than one speed of motion.</p>
<p>Strengths:</p>
<p>The study is valuable because little is known about how the visual pathway segments and preserves information about multiple stimuli. The study presents compelling evidence that (on average) MT neurons shift from faster-speed-takes-all at low speeds to representing the average of the two speeds at higher speeds. An additional strength of the study is the inclusion of perceptual reports from both humans and one monkey participant performing a task in which they judged whether the stimuli involved one vs two different speeds. Ultimately, this study raises intriguing questions about how exactly the response patterns in visual cortical area MT might preserve information about each speed, since such information is potentially lost in an average response as described here.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94835.2.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Huang</surname>
<given-names>Xin</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Ghimire</surname>
<given-names>Bikalpa</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Chakrala</surname>
<given-names>Anjani Sreeprada</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Wiesner</surname>
<given-names>Steven</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>The following is the authors’ response to the original reviews</p>
<disp-quote content-type="editor-comment">
<p><bold>Public Reviews:</bold></p>
<p><bold>Reviewer #1 (Public Review):</bold></p>
<p>Summary:</p>
<p>Most studies in sensory neuroscience investigate how individual sensory stimuli are represented in the brain (e.g., the motion or color of a single object). This study starts tackling the more difficult question of how the brain represents multiple stimuli simultaneously and how these representations help to segregate objects from cluttered scenes with overlapping objects.</p>
<p>Strengths</p>
<p>The authors first document the ability of humans to segregate two motion patterns based on differences in speed. Then they show that a monkey's performance is largely similar; thus establishing the monkey as a good model to study the underlying neural representations.</p>
<p>Careful quantification of the neural responses in the middle temporal area during the simultaneous presentation of fast and slow speeds leads to the surprising finding that, at low average speeds, many neurons respond as if the slowest speed is not present, while they show averaged responses at high speeds. This unexpected complexity of the integration of multiple stimuli is key to the model developed in this paper.</p>
<p>One experiment in which attention is drawn away from the receptive field supports the claim that this is not due to the involuntary capture of attention by fast speeds.</p>
<p>A classifier using the neuronal response and trained to distinguish single-speed from bi-speed stimuli shows a similar overall performance and dependence on the mean speed as the monkey. This supports the claim that these neurons may indeed underlie the animal's decision process.</p>
<p>The authors expand the well-established divisive normalization model to capture the responses to bi-speed stimuli. The incremental modeling (eq 9 and 10) clarifies which aspects of the tuning curves are captured by the parameters.</p>
</disp-quote>
<p>We thank the Reviewer for the thorough summary of the findings and supportive comments.</p>
<disp-quote content-type="editor-comment">
<p>Weaknesses</p>
<p>While the comparison of the overall pattern of behavioral performance between monkeys and humans is important, some of the detailed comparisons are not well supported by the data. For instance, whether the monkey used the apparent coherence simply wasn't tested and a difference between 4 human subjects and a single monkey subject cannot be tested statistically in a meaningful manner. I recommend removing these observations from the manuscript and leaving it at &quot;The difference between the monkey and human results may be due to species differences or individual variability&quot; (and potentially add that there are differences in the task as well; the monkey received feedback on the correctness of their choice, while the humans did not.)</p>
</disp-quote>
<p>Thanks for the suggestion. We agree and have modified the text accordingly. We now state on page 8, lines 189-191, &quot;The difference between the monkey and human results may be due to species differences or individual variability. The differences in behavioral tasks may also play a role – the monkey received feedback on the correctness of the choice, whereas human subjects did not.&quot;</p>
<disp-quote content-type="editor-comment">
<p>A control experiment aims to show that the &quot;fastest speed takes all&quot; behavior is general by presenting two stimuli that move at fast/slow speeds in orthogonal directions. The claim that these responses also show the &quot;fastest speed takes all&quot; is not well supported by the data. In fact, for directions in which the slow speed leads to the largest response on its own, the population response to the bi-speed stimulus is the average of the response to the components (This is fine. One model can explain all direction tuning curve, which also explain averaging at the slower speed stronger directions). Only for the directions where the fast speed stimulus is the preferred direction is there a bias towards the faster speed (Figure 7A). The quantification of this effect in Figure 7B seems to suggest otherwise, but I suspect that this is driven by the larger amplitude of Rf in Figure 8, and the constraint that ws and wf are constant across directions. The interpretation of this experiment needs to be reconsidered.</p>
</disp-quote>
<p>The Reviewer raised a good question. Our model with fixed weights for faster and slower components across stimulus directions provided a parsimonious explanation for the whole tuning curve, regardless of whether the faster component elicited a stronger response than the slower component. Because the model can be well constrained by the measured direction-tuning curves, we did not restrain 𝑤 and 𝑤 to sum to one, which is more general. The linear weighted summation (LWS) model fits the neuronal responses to the bi-speed stimuli very well, accounting for an average of 91.8% (std = 7.2%) of the response variance across neurons. As suggested by the Reviewer, we now use the normalization model to fit the data with fixed weights across all motion directions. The normalization model also provides a good fit, accounting for an average of 90.5% (std = 7.1%) of the response variance across neurons.</p>
<p>Note that in the new Figure 8A, at the left side of the tuning curve (i.e., at negative vector average (VA) directions), where the slower component moving in a more preferred direction of the neurons than the faster component, the bi-speed response (red curve) is slightly lower than the average of the component response (gray curve), indicating a bias toward the weaker faster component. Therefore, the faster speed bias does not occur only when the faster component moves in the more preferred direction. This can also be seen in the direction-tuning curves of an example neuron that we added to the figure (new Fig. 8B). The peak responses to the slower and faster component were about the same, but the neuron still showed a faster-speed bias. At negative VA directions, the red curve is lower than the response average (gray curve) and is biased toward the weaker (faster) component.</p>
<p>The faster-speed bias also occurs when the peak response to the slower component is stronger than the faster component. As a demonstration, Author response image 1 1 shows an example MT neuron that has a slow preferred speed (PS = 1.9 deg/s) and was stimulated by two speeds of 1.2 and 4.8 deg/s. The peak response to the faster component (blue) was weaker than that to the slower component (green). However, this neuron showed a strong bias toward the faster component. A normalization model fit with fixed weights for the faster and slower components (black curve) described the neuronal response to both speeds (red) well. This neuron was not included in the neuron population shown in Figure 8 because it was not tested with stimulus speeds of 2.5 and 10 deg/s.</p>
<fig id="sa3fig1">
<label>Author response image 1.</label>
<caption>
<title>An example MT neuron was tested with stimulus speeds of 1.</title>
<p>2 and 4.8 deg/s. The preferred speed of this neuron was 1.9 deg/s. Fixed weights of 0.59 for the faster component and 0.12 for the slower component described the responses to the bispeed stimuli well using a normalization model. The neuron showed a faster-speed bias although its peak response to the slower component was higher than that of the faster component.</p>
</caption>
<graphic mime-subtype="jpg" xlink:href="elife-94835-sa3-fig1.jpg" mimetype="image"/>
</fig>
<p>We modified the text to clarify these points:</p>
<p>Page 19, lines 405 – 410, “The bi-speed response was biased toward the faster component regardless of whether the response to the faster component was stronger (in positive VA directions) or weaker (in negative VA directions) than that to slower component (Fig. 8A). The result from an example neuron further demonstrated that, even when the peak firing rates of the faster and slower component responses were similar, the response elicited by the bi-speed stimuli was still biased toward the faster component (Fig. 8B). ”</p>
<p>Page 19, lines 421 – 427, “Because the model can be well constrained by the measured direction-tuning curves, it is not necessary to require 𝑤 and 𝑤 to sum to one, which is more general. An implicit assumption of the model is that, at a given pair of stimulus speeds, the response weights for the slower and faster components are fixed across motion directions. The model fitted MT responses very well, accounting for an average of 91.8% of the response variance (std = 7.2%, N = 21) (see Methods). The success of the model supports the assumption that the response weights are fixed across motion directions.”</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public Review):</bold></p>
<p>Summary:</p>
<p>This is a paper about the segmentation of visual stimuli based on speed cues. The experimental stimuli are random dot fields in which each dot moves at one of two velocities. By varying the difference between the two speeds, as well as the mean of the two speeds, the authors estimate the capacity of observers (human and non-human primates) to segment overlapping motion stimuli. Consistent with previous work, perceptual segmentation ability depends on the mean of the two speeds. Recordings from area MT in monkeys show that the neuronal population to compound stimuli often shows a bias towards the faster-speed stimuli. This bias can be accounted for with a computational model that modulates single-neuron firing rates by the speed preferences of the population. The authors also test the capacity of a linear classifier to produce the psychophysical results from the MT data.</p>
<p>Strengths:</p>
<p>Overall, this is a thorough treatment of the question of visual segmentation with speed cues. Previous work has mostly focused on other kinds of cues (direction, disparity, color), so the neurophysiological results are novel. The connection between MT activity and perceptual segmentation is potentially interesting, particularly as it relates to existing hypotheses about population coding.</p>
</disp-quote>
<p>We thank the Reviewer for the summary and comments.</p>
<disp-quote content-type="editor-comment">
<p>Weaknesses:</p>
<p>Page 10: The relationship between (R-Rs) and (Rf-Rs) is described as &quot;remarkably linear&quot;. I don't actually find this surprising, as the same term (Rs) appears on both the x- and y-axes. The R^2 values are a bit misleading for this reason.</p>
</disp-quote>
<p>The Reviewer is correct that subtracting a common term Rs from R and Rf would introduce correlation between (R-Rs) and (Rf-Rs). To address this concern, we conducted an additional analysis. We showed that, at most speed pairs, the R^2 values between (R-Rs) and (Rf-Rs) based on the data are significantly higher than the R^2 values between (R’-Rs) and (RfRs), in which R’ was a random combination of Rs and Rf. Since the same Rs was commonly subtracted in calculating R^2 (data) and R^2 (simulation), the difference between R^2 (data) and R^2 (simulation) suggests that the response pattern of R contributes to the additional correlation.</p>
<p>We now acknowledge this confounding factor and describe the new analysis results on page 14, lines 309 – 326. Please also see the response to Reviewer 3 about a similar concern.</p>
<disp-quote content-type="editor-comment">
<p>Figure 9: I'm confused about the linear classifier section of the paper. The idea makes sense - the goal is to relate the neuronal recordings to the psychophysical data. However the results generally provide a poor quantitative match to the psychophysical data. There is mention of a &quot;different paper&quot; (page 26) involving a separate decoding study, as well as a preprint by Huang et al. (2023) that has better decoding results. But the Huang et al. preprint appears to be identical to the current manuscript, in that neither has a Figure 12, 13, or 14. The text also says (page 26) that the current paper is not really a decoding study, but the linear classifier (Figure 9F) is a decoder, as noted on page 10. It sounds like something got mixed up in the production of two or more papers from the same dataset.</p>
</disp-quote>
<p>We apologize for the confusion regarding the reference of Huang et al. (2023, bioRxiv). We referred to an earlier version of this bioRxiv manuscript (version 1), which included decoding analysis. In the bibliography, we provided two URLs for this pre-print. While the second link was correct, the first URL automatically links to the latest version (version 2), which did not have the abovementioned decoding analysis.</p>
<p>The analysis in Figure 9 is to apply a classifier to discriminate two-speed from singlespeed stimuli, which is a decoding analysis as the Reviewer pointed out. We revised the result section about the classifier to make it clear what the classifier can and cannot explain (pages 2223, lines 516-534). We also included a sentence at the end of this section that leads to additional decoding analysis to extract motion speed(s) from MT population responses (page 23, lines 541543), “To directly evaluate whether the population neural responses elicited by the bi-speed stimulus carry information about two speeds, it is important to conduct a decoding analysis to extract speed(s) from MT population responses.”</p>
<disp-quote content-type="editor-comment">
<p>In any case, I think that some kind of decoding analysis would really strengthen the current paper by linking the physiology to the psychophysics, but given the limitations of the linear classifier, a more sophisticated approach might be necessary -- see for example Zemel, Dayan, and Pouget, 1998. The authors might also want to check out closely related work by Treue et al. (Nature Neuroscience 2000) and Watamaniuk and Duchon (1992).</p>
</disp-quote>
<p>We thank the Reviewer for the suggestion and agree that it is useful to incorporate additional decoding analysis that can better link physiology results to psychophysics. The decoding analysis we conducted was motivated by the framework proposed by Zemel, Dayan, and Pouget (1998), and also similar to the idea briefly mentioned in the Discussion of Treue et al. (2000). We have added the decoding analysis to this paper on pages 25-32.</p>
<disp-quote content-type="editor-comment">
<p>What do we learn from the normalization model? Its formulation is mostly a restatement of the results - that the faster and slower speeds differentially affect the combined response. This hypothesis is stated quantitatively in equation 8, which seems to provide a perfectly adequate account of the data. The normalization model in equation 10 is effectively the same hypothesis, with the mean population response interposed - it's not clear how much the actual tuning curve in Figure 10A even matters, since the main effect of the model is to flatten it out by averaging the functions in Figure 10B. Although the fit to the data is reasonable, the model uses 4 parameters to fit 5 data points and is likely underconstrained; the parameters other than alpha should at least be reported, as it would seem that sigma is actually the most important one. And I think it would help to examine how robust the statistical results are to different assumptions about the normalization pool.</p>
</disp-quote>
<p>In the linear weighted summation model (LWS) model (Eq. 8), the weights Ws and Wf are free parameters. We think the value of the normalization model (Eq. 9) is that it provides an explanation of what determines the response weights. We agree with the Reviewer that using the normalization model (Eq. 9) with 4 parameters to fit 5 data points of the tuning curves to bispeed stimuli of individual neurons is under-constrained. We, therefore, removed the section using the normalization model to fit overlapping stimuli moving in the same direction at different speeds.</p>
<p>A better way to constrain the normalization model is to use the full direction-tuning curves of MT neurons in response to two stimulus components moving in different directions at different speeds, as shown in Figure 8. We now use the normalization model (Eq. 9) to fit this data set (also suggested by Reviewer 1), in addition to the LWS model. We now report the median values of the model parameters of the normalization model, including the exponent n, sigma, alpha, and the constant c. We also compared the normalization model fit with the linear summation (LWS) model. We discuss the limitations of our data set and what needs to be done in future studies. The revisions are on page 20, lines 434-467 in the Results, and pages 34-35, lines 818-829 in Discussion.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #3 (Public Review):</bold></p>
<p>Summary:</p>
<p>This study concerns how macaque visual cortical area MT represents stimuli composed of more than one speed of motion.</p>
<p>Strengths:</p>
<p>The study is valuable because little is known about how the visual pathway segments and preserves information about multiple stimuli. The study presents compelling evidence that (on average) MT neurons represent the average of the two speeds, with a bias that accentuates the faster of the two speeds. An additional strength of the study is the inclusion of perceptual reports from both humans and one monkey participant performing a task in which they judged whether the stimuli involved one vs two different speeds. Ultimately, this study raises intriguing questions about how exactly the response patterns in visual cortical area MT might preserve information about each speed, since such information could potentially be lost in an average response as described here, depending on assumptions about how MT activity is evaluated by other visual areas.</p>
<p>Weaknesses:</p>
<p>My main concern is that the authors are missing an opportunity to make clear that the divisive normalization, while commonly used to describe neural response patterns in visual areas (and which fits the data here), fails on the theoretical front as an explanation for how information about multiple stimuli can be preserved. Thus, there is a bit of a disconnect between the goal of the paper - how does MT represent multiple stimuli? - and the results: mostly averaging responses which, while consistent with divisive normalization, would seem to correspond to the perception of a single intermediate speed. This is in contrast to the psychophysical results which show that subjects can at least distinguish one from two speeds. The paper would be strengthened by grappling with this conundrum in a head-on manner.</p>
</disp-quote>
<p>We thank the Reviewer for the constructive comments. We agree with the Reviewer that it is important to connect the encoding of multiple speeds with the perception. The Reviewer also raised an important question regarding whether multiple speeds can be extracted from population neural responses, given the encoding rules characterized in this study.</p>
<p>It is a hard problem to extract multiple stimulus values from the population neural response. Inspired by the theoretical framework proposed by Zemel et al. (1998), we conducted a detailed decoding study to extract motion speed(s) from MT population responses. We used the decoded speed(s) to perform a discrimination task similar to our psychophysics task and compared the decoder's performance with perception. We found that, at X4 speed difference, we could decode two speeds based on MT response, and the decoder's performance was similar to that of perception. However, at X2 speed difference, except at the slowest speeds of 1.25 and 2.5 deg/s, the decoder cannot extract two speeds and cannot differentiate between a bi-speed stimulus and a single log-mean speed stimulus. We have added the decoding analysis to this paper on pages 25-32. We also discuss the implications and limitations of these results (pages 35-36, lines 852-884).</p>
<disp-quote content-type="editor-comment">
<p><bold>Recommendations for the authors:</bold></p>
<p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p>
<p>Classifier:</p>
<p>One question I have is how the classifier's performance scales with the number of neurons used in the analysis. Here that number is set to the number that was recorded, but it is a free parameter in this analysis. Why does the arbitrary choice of 100 neurons match the animals' performance?</p>
</disp-quote>
<p>We apologize for the unclearness of this point. The decoding using the classifier was based on the neural responses of 100 recorded MT neurons in our data set. The number of 100 neurons was not a free parameter. We need to reconstruct the population neural response based on the responses of the recorded neurons and their preferred speeds (red and black dots in Figure 9A-E).</p>
<p>We spline-fitted the reconstructed population neural responses (red and black curves in Figure 9-E). One way to change the number of neurons used for the decoding is to resample N points along the spline-fitted population responses, using N as a free parameter. However, we think it is better to conduct decoding based on the responses from the recorded neurons rather than based on interpolated responses. We now clarify on page 22, lines 520-522, that we based on the responses of the 100 recorded neurons in our dataset to do the classification (decoding).</p>
<disp-quote content-type="editor-comment">
<p>Normalization Model:</p>
<p>Although the model is phenomenological, a schematic circuit diagram could help the reader understand how this could work (I think this is worthwhile even though the data cannot distinguish among different implementations of divisive normalization).</p>
</disp-quote>
<p>Thanks for this suggestion. We agree that a circuit diagram would help the readers understand how the model works. However, as the Reviewer pointed out, our data cannot distinguish between different implementations of the model. For example, divisive normalization can occur on the inputs to MT neurons or on MT neurons themselves. The circuit mechanism of weighting the component responses is not clear either. A schematic circuit diagram then mainly serves to recapitulate the normalization model in Equation 9. We, therefore, choose not to add a schematic circuit diagram at this time. We are interested in developing a circuit model to account for how visual neurons represent multiple stimuli in future studies.</p>
<disp-quote content-type="editor-comment">
<p>Another suggestion is that the time courses could be used to constrain the model; the fact that it takes a while after the onset of the slow-speed response for averaging to reveal itself suggests the presence of inertia/hysteresis in the circuit).</p>
</disp-quote>
<p>We agree that the time course of MT responses could be used to constrain the model. This is also why we think it is important to document the time course in this paper. We now state in the Results, page 17, lines 354-357:</p>
<p>“At slow speeds, the very early faster-speed bias suggests a likely role of feedforward inputs to MT on the faster-speed bias. The slightly delayed reduction (normalization) in the bispeed response relative to the stronger component response also helps constrain the circuit model for divisive normalization.”</p>
<disp-quote content-type="editor-comment">
<p>Two-Direction Experiment:</p>
<p>Applying the normalization model to this dataset could help determine its generality.</p>
</disp-quote>
<p>This is a good point. We now apply the normalization model (Eq. 9) to fit this data set with the full direction tuning curves in response to two stimuli moving in different directions at different speeds. Please also see the response to Reviewer 2 about the normalization model fit.</p>
<p>The results of the normalization model fit are now described on page 20 and Figure 8A, B, D.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p>
<p>In terms of impact, I would say that the presentation is geared largely toward people who go to VSS. To broaden the appeal, the authors might consider a more general formulation of the four hypotheses stated at the bottom of page 3. These are prominent ideas in systems neuroscience - population encoding, Bayesian inference, etc.</p>
</disp-quote>
<p>We thank the Reviewer for the suggestion. We have revised the Introduction accordingly on pages 3-4, lines 43-69. Please also see the response to Reviewer 3 about the Introduction.</p>
<disp-quote content-type="editor-comment">
<p>Figure 5: It might be helpful to show the predictions for different hypotheses. If the response to the transparent stimulus is equal to that of the faster stimulus, you will have a line with slope 1. If it is equal to the response to the slow stimulus, all points will lie on the x-axis. In between you get lines with slopes less than 1.</p>
</disp-quote>
<p>In Figures 5F1 and 5F2, we show dotted lines indicating faster-all (i.e., faster-componenttake-all), response averaging, and slower-all (i.e., slower-component-take-all) on the X-axis. We show those labels in between Figs. 5F1 and F2.</p>
<disp-quote content-type="editor-comment">
<p>Figure 6: The analysis is not motivated by any particular question, and the results are presented without any quantitation. This section could be better motivated or else removed.</p>
</disp-quote>
<p>We now better motivate the section about the response time course on page 16, lines 336 – 339: “The temporal dynamics of the response bias toward the faster component may provide a useful constraint on the neural model that accounts for this phenomenon. We therefore examined the timecourse of MT response to the bi-speed stimuli. We asked whether the faster-speed bias occurred early in the neuronal response or developed gradually.”</p>
<p>On page 17, lines 354-357, we also state that “At slow speeds, the very early faster-speed bias suggests a likely role of feedforward inputs to MT on the faster-speed bias. The slightly delayed reduction (normalization) in the bi-speed response relative to the stronger component response also helps constrain the circuit model for divisive normalization.”</p>
<disp-quote content-type="editor-comment">
<p>Equation (9): There appears to be an &quot;S&quot; missing in the denominator.</p>
</disp-quote>
<p>We double-checked and did not see a missing &quot;S&quot; in Equation 9, on page 20.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #3 (Recommendations For The Authors):</bold></p>
<p>This is an impressive study, with the chief strengths being the computational/theoretical motivation and analyses and the inclusion of psychophysics together with primate neurophysiology. The manuscript is well-written and the figures are clear and convincing (with a couple of suggestions detailed below).</p>
</disp-quote>
<p>We thank the Reviewer for the comments.</p>
<disp-quote content-type="editor-comment">
<p>Specific suggestions:</p>
<p>(1) Intro para 3</p>
<p>&quot;It is conceivable that the responses of MT neurons elicited by two motion speeds may follow one of the following rules: (1) averaging the responses elicited by the individual speed components; (2) bias toward the speed component that elicits a stronger response, i.e. &quot;soft-max operation&quot; (Riesenhuber and Poggio, 1999); (3) bias toward the slower speed component, which may better represent the more probable slower speeds in nature scenes (Weiss et al., 2002); (4) bias toward the faster speed component, which may benefit the segmentation of a faster-moving stimulus from a slower background.&quot;</p>
<p>This would be a good place to point out which of these options is likely to preserve vs. lose information and how.</p>
<p>It seems to me that only #2 is clearly information-preserving, assuming that there are neurons with a variety of different speed preferences such that different neurons will exhibit different &quot;winners&quot;. #1 would predict subjects would perceive only an intermediate speed, whereas #3 would predict perceiving only/primarily the slower speed and #4 would predict only/primarily perceiving the faster speed.</p>
<p>The difference between &quot;only&quot; and &quot;primarily&quot; would depend on whether the biases are complete or only partial. I acknowledge that the behavioral task in the study is not a &quot;report all perceived speeds&quot; task, but rather a 1 vs 2 speeds task, so the behavioral assay is not a direct assessment of the question I'm raising here, but I think it should still be possible to write about the perceptual implications of these different possibilities for encoding in an informative way.</p>
</disp-quote>
<p>Thanks for the suggestions. We have revised this paragraph in the Introduction on pages 3 – 4, lines 43 – 69.</p>
<disp-quote content-type="editor-comment">
<p>(2) Analysis clarifications</p>
<p>The section &quot;Relationship between the responses to bi-speed stimuli and constituent stimulus components&quot; could use some clarification/rearrangement/polish. I had to read it several times. Possibly, rearrangement, simplification/explanation of nomenclature, and building up from a simpler to a more complex case would help. If I understand correctly, the outcome of the analysis is to obtain a weight value for every combination of slow and fast speeds used. The R's in equation 5 are measured responses, observed on the single stimulus and combined stimulus trials. It was not clear to me if the R's reflect average responses or individual trial responses; this should be clarified. Ws = 1- wf so in essence only 1 weight is computed for each combination. Then, in the subsequent sections of the manuscript, the authors explore whether the weight computed for each stimulus combination is the same or does it vary across conditions. If I have this right, then walking through these steps will aid the reader.</p>
</disp-quote>
<p>The Reviewer is correct. We now walk through these steps and better state the rationale for this approach. The R's in Equation 5 are trial-averaged responses, not trial-by-trial responses.</p>
<p>We have clarified these points on page 13.</p>
<disp-quote content-type="editor-comment">
<p>To take a particular example, the sentence &quot;Using this approach to estimate the response weights for individual neurons can be inaccurate because, at each speed pair, the weights are determined only by three data points&quot; struck me as a rather backdoor way to get at the question. Is the estimate noisy? Or does the weighting vary systematically across speeds? I think the authors are arguing the latter; if so, it would be valuable to say so.</p>
</disp-quote>
<p>We wanted to estimate the weighting for each speed pair and determine whether the weights change with the stimulus speeds. Indeed, we found that the weights change systematically across speed pairs. The issue was not because the estimate was noisy (see below in response to the second paragraph for point 3.</p>
<p>We have clarified this point in the text, on page 13, lines 273 – 280: “Our goal was to estimate the weights for each speed pair and determine whether the weights change with the stimulus speeds. In our main data set, the two speed components moved in the same direction. To determine the weights of 𝑤 and w<sub>f</sub> for each neuron at each speed pair, we have three data points R, R<sub>s</sub>, and R<sub>f</sub>, which are trial-averaged responses. Since it is not possible to solve for both variables, 𝑤 and w<sub>f</sub>, from a single equation (Eq. 5) with three data values, we introduced an additional constraint: 𝑤 + w<sub>f</sub> =1. While this constraint may not yield the exact weights that would be obtained with a fully determined system, it nevertheless allows us to characterize how the relative weights vary with stimulus speed.”</p>
<disp-quote content-type="editor-comment">
<p>(3) Figure 5</p>
<p>Related to the previous point, Figures 5A-E are subject to a possible confound. When plotting x vs y values, it is critical that the x and y not depend trivially on the same value. Here, the plots are R-Rs and Rf-Rs. Rs, therefore, is contained in both the x and y values. Assume, for the sake of argument, that R and Rf are constants, whereas Rs is drawn from a distribution of random noise. When Rs, by chance, has an extreme negative value, R-Rs and Rf-Rs will be large positive values. The solution to this artificial confound is to split the trials that generate Rs into two halves and subtract one half from R and the other half from Rf. Then, the same noisy draw will not be contributing to both x and y. The above is what is needed if the authors feel strongly about including this analysis.</p>
</disp-quote>
<p>The Reviewer is correct that subtracting a common term (Rs) would introduce a correlation between (R-Rs) and (Rf-Rs) (Reviewer 2 also raised this point). R's in Equations 5, 6, 7 (and Figure 5A-E) are trial-averaged responses. So, we cannot address the issue by dividing R’s into two halves. Our results showed that the regression slope (W<sub>f</sub>) changed from near 1 to about 0.5 as the stimulus speeds increased, and the correlation coefficient between (R – Rs) and (R<sub>f</sub> – Rs) was high at slow stimulus speeds. To determine whether these results can be explained by the confounding factor of subtracting a common term Rs, rather than by the pattern of R in representing two speeds, we did an additional analysis. We acknowledged the issue and described the new analysis on page 13, lines 303 – 326:</p>
<p>“Our results showed that the bi-speed response showed a strong bias toward the faster component when the speeds were slow and changed progressively from a scheme of ‘fastercomponent-take-all’ to ‘response-averaging’ as the speeds of the two stimulus components increased (Fig. 5F1). We found similar results when the speed separation between the stimulus components was small (×2), although the bias toward the faster component at low stimulus speeds was not as strong as x4 speed separation (Fig. 5A2-F2 and Table 1).</p>
<p>In the regression between (𝑅 – 𝑅<sub>s</sub>) and (𝑅<sub>f</sub> – 𝑅<sub>s</sub>), 𝑅<sub>s</sub> was a common term and therefore could artificially introduce correlations. We wanted to determine whether our estimates of the regression slope (𝑤<sub>f</sub>) and the coefficient of determination (𝑅<sup>2</sup>) can be explained by this confounding factor. At each speed pair and for each neuron from the data sample of the 100 neurons shown in Figure 5, we simulated the response to the bi-speed stimuli (𝑅 <sub>e</sub>) as a randomly weighted sum of 𝑅<sub>f</sub> and 𝑅<sub>s</sub> of the same neuron.</p>
<p>𝑅<sub>e</sub> = 𝑎𝑅<sub>f</sub> + (1 − 𝑎)𝑅<sub>s</sub>,</p>
<p>in which 𝑎 was a randomly generated weight (between 0 and 1) for 𝑅<sub>f</sub>, and the weights for 𝑅<sub>f</sub> and 𝑅<sub>s</sub> summed to one. We then calculated the regression slope and the correlation coefficient between the simulated 𝑅<sub>e</sub> - 𝑅<sub>s</sub> and 𝑅<sub>f</sub> - 𝑅<sub>s</sub> across the 100 neurons. We repeated the process 1000 times and obtained the mean and 95% confidence interval (CI) of the regression slope and the 𝑅<sup>2</sup>. The mean slope based on the simulated responses was 0.5 across all speed pairs. The estimated slope (𝑤<sub>f</sub>) based on the data was significantly greater than the simulated slope at slow speeds of 1.25/5, 2.5/10 (Fig. 5F1), and 1.25/2.5, 2.5/5, and 5/10 degrees/s (Fig. 5F2) (bootstrap test, see p values in Table 1). The estimated 𝑅<sup>2</sup> based on the data was also significantly higher than the simulated 𝑅<sup>2</sup> for most of the speed pairs (Table 1). These results suggest that the faster-speed bias at the slow stimulus speeds and the consistent response weights across the neuron population at each speed pair are not analysis artifacts.”</p>
<disp-quote content-type="editor-comment">
<p>However, I don't see why the analysis is needed at all. Can't Figure 5F be computed on its own? Rather than computing weights from the slopes in 5A-E, just compute the weights from each combination of stimulus conditions for each neuron, subject to the constraint ws=1-wf. I think this would be simpler to follow, not subject to the noise confound described in the previous point, and likely would make writing about the analysis easier.</p>
</disp-quote>
<p>We initially tried the suggested approach to determine the weights of the individual neurons. The weights from each speed combination for each neuron are calculated by:  𝑤<sub>s</sub> = <inline-formula id="sa3equ1"><inline-graphic xlink:href="elife-94835-sa3-equ1.jpg" mimetype="image" mime-subtype="jpeg"/></inline-formula>, 𝑤<sub>f</sub> <inline-formula id="sa3equ2"><inline-graphic xlink:href="elife-94835-sa3-equ2.jpg" mimetype="image" mime-subtype="jpeg"/></inline-formula>, and 𝑤<sub>s</sub> and 𝑤<sub>f</sub> sum to 1. 𝑅, 𝑅<sub>f</sub> and  𝑅<sub>s</sub> are the responses to the same motion direction. Using this approach to estimate response weights for individual neurons can be unreliable, particularly when 𝑅<sub>f</sub> and 𝑅<sub>s</sub> are similar. This situation often arises when the two speeds fall on opposite sides of the neuron's preferred speed, resulting in a small denominator (𝑅<sub>f</sub> - 𝑅<sub>s</sub>) and, consequently, an artificially inflated weight estimate. We therefore used an alternative approach. We estimated the response weights for the neuronal population at each speed pair (𝑅<sub>f</sub> - 𝑅<sub>s</sub>) using linear regression of (𝑅 - 𝑅<sub>s</sub>) against (𝑅<sub>f</sub> - 𝑅<sub>s</sub>). The slope <inline-formula id="sa3equ3"><inline-graphic xlink:href="elife-94835-sa3-equ3.jpg" mimetype="image" mime-subtype="jpeg"/></inline-formula> is the weight for the faster component for the population. This approach overcame the difficulty of determining the response weights for single neurons.</p>
<p>Nevertheless, if the data provide better constraints, it is possible to estimate the response weights for each speed pair for individual neurons. For example, we can calculate the weights for single neurons by using stimuli that move in different directions at two speeds. By characterizing the full direction tuning curves for R, R<sub>f</sub>, and Rs, we have sufficient data to constrain the response weights for single neurons, as we did for the speed pair of 2.5 and 10º/s in Figure 8. In future studies, we can use this approach to measure the response weights for single neurons at different speed pairs and average the weights across the neuron population.</p>
<p>We explain these considerations in the Results (pages 13–14, lines 265-326) and Discussion (pages 34-35, lines 818-829).</p>
<disp-quote content-type="editor-comment">
<p>(4) Figure 7</p>
<p>Bidirectional analysis. It would be helpful to have a bit more explanation for why this analysis is not subject to the ws=1-wf constraint. In Figure 7B, a line could be added to show what ws + wf =1 would look like (i.e. a line with slope -1 going from (0,1) to (1,0); it looks like these weights are a little outside that line but there is still a negative trend suggesting competition.</p>
</disp-quote>
<p>For the data set when visual stimuli move in the same direction at different speeds, we included a constraint that W<sub>s</sub> and W<sub>f</sub> sum to 1. This is because one cannot solve two independent variables (Ws and Wf) using one equation R = W<sub>s</sub> · R<sub>s</sub> + W<sub>f</sub> R<sub>f</sub>, with three data values (R, Rs, Rf).</p>
<p>In the dataset using bi-directional stimuli (now Fig. 8), we can use the full direction tuning curves to constrain the linear weighted (LWS) summation model and the normalization model. So, we did not need to impose the additional constraint that Ws and Wf sum to one, which is more general. We now clarify this in the text, on page 19, lines 421-423.</p>
<p>As suggested, we added a line showing Ws + Wf = 1 for the LWS model fit (Fig. 8C) and the normalization model fit (Fig. 8D) (also see page 21, lines 482-484). Although 𝑤 and 𝑤 are not constrained to sum to one in the model fits, the fitted weights are roughly aligned with the dashed lines of Ws + Wf = 1.</p>
<disp-quote content-type="editor-comment">
<p>(5) Attention task</p>
<p>General wording suggestions - a caution against using &quot;attention&quot; as a causal/mechanistic explanation as opposed to a hypothesized cognitive state. For example, &quot;We asked whether the faster-speed bias was due to bottom-attention being drawn toward the faster stimulus component&quot;. This could be worded more conservatively as whether the bias is &quot;still present if attention is directed elsewhere&quot; - i.e. a description of the experimental manipulation.</p>
</disp-quote>
<p>We intended to test the hypothesis of whether the faster-speed bias can be explained by attention automatically drawn to the faster component and therefore enhance the contribution of the faster component to the bi-speed response. We now state it as a possible explanation to be tested. We changed the subtitle of this section to be more conservative: “Faster-speed bias still present when attention was directed away from the RFs”, on page 18, line 363.</p>
<p>We also modified the text on page 18, lines 364-367: “One possible explanation for the faster-speed bias may be that bottom-up attention is drawn toward the faster stimulus component, enhancing the response to the faster component. To address this question, we asked whether the faster-speed bias was still present if attention was directed away from the RFs.”</p>
<disp-quote content-type="editor-comment">
<p>Relatedly, in the Discussion, the section on &quot;Neural mechanisms&quot;, the sentence &quot;The faster-speed bias was not due to an attentional modulation&quot; should be rephrased as something like 'the bias survived or was still present despite an attentional modulation requiring the monkey to attend elsewhere'.</p>
</disp-quote>
<p>Our motivation for doing the attention-away experiment was to determine whether a bottom-up attentional modulation can explain the faster-speed bias. We now describe the results as suggested by the Reviewer. But we’d also like to interpret the implications of the results. In Discussion, page 34, lines 789-790, we now state: “We found that the faster-speed bias was still present when attention was directed away from the RFs, suggesting that the faster-speed bias cannot be explained by an attentional modulation.”</p>
<disp-quote content-type="editor-comment">
<p>(6) &quot;A model that accounts for the neuronal responses to bi-speed stimuli&quot;. This section opens with: &quot;We showed that the neuronal response in MT to a bi-speed stimulus can be described by a weighted sum of the neuron's responses to the individual speed components&quot;. &quot;Weighted average&quot; would be more appropriate here, given that ws = 1-wf.</p>
</disp-quote>
<p>As mentioned above, the added constraint of Ws+Wf = 1 was only a practical solution for determining the weights for the data set using visual stimuli moving in the same direction. More generally, Ws and Wf do not need to sum to one. As such, we prefer the wording of weighted sum.</p>
<disp-quote content-type="editor-comment">
<p>(7) &quot;As we have shown previously using visual stimuli moving transparently in different directions, a classifier's performance of discriminating a bi-directional stimulus from a singledirection stimulus is worse when the encoding rule is response-averaging than biased toward one of the stimulus components&quot; - this is important! Can this be worked into the Introduction?</p>
</disp-quote>
<p>Yes, we now also mention this point in the Introduction regarding response averaging on page 4, lines 54-57: “While decoding two stimuli from a unimodal response is theoretically possible (Zemel et al., 1998; Treue et al., 2000), response averaging may result in poorer segmentation compared to encoding schemes that emphasize individual components, as demonstrated in neural coding of overlapping motion directions (Xiao and Huang, 2015).” Also, please see the response to point 1 above.</p>
<disp-quote content-type="editor-comment">
<p>(8) Minor, but worth catching now - is the use of initials for human participants consistent with best practices approved at your institution?</p>
</disp-quote>
<p>Thanks for checking. The letters are not the initials of the human subjects. They are coded characters. We have clarified it in the legend of Figure 1, on page 7, line 168.</p>
</body>
</sub-article>
</article>