<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">102823</article-id>
<article-id pub-id-type="doi">10.7554/eLife.102823</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.102823.2</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.3</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories><title-group>
<article-title>Increased listening effort and cochlear neural degeneration underlie behavioral deficits in speech perception in noise in normal hearing middle-aged adults</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Zink</surname>
<given-names>Maggie E</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n2">*</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Zhen</surname>
<given-names>Leslie</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n2">*</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1148-4018</contrib-id>
<name>
<surname>McHaney</surname>
<given-names>Jacie R</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n2">*</xref><xref ref-type="author-notes" rid="n1">+</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Klara</surname>
<given-names>Jennifer</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Yurasits</surname>
<given-names>Kimberly</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Cancel</surname>
<given-names>Victoria</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Flemm</surname>
<given-names>Olivia</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Mitchell</surname>
<given-names>Claire</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Datta</surname>
<given-names>Jyotishka</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Chandrasekaran</surname>
<given-names>Bharath</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">+</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4573-8004</contrib-id>
<name>
<surname>Parthasarathy</surname>
<given-names>Aravindakshan</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
<email>Aravind_Partha@pitt.edu</email>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01an3r305</institution-id><institution>Department of Communication Science and Disorders, School of Health and Rehabilitation Sciences, University of Pittsburgh</institution></institution-wrap>, <city>Pittsburgh</city>, <country country="US">United States</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02smfhw86</institution-id><institution>Department of Statistics, Virginia Polytechnic Institute and State University</institution></institution-wrap>, <city>Blacksburg</city>, <country country="US">United States</country></aff>
<aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01an3r305</institution-id><institution>Department of Bioengineering, Swanson School of Engineering, University of Pittsburgh</institution></institution-wrap>, <city>Pittsburgh</city>, <country country="US">United States</country></aff>
<aff id="a4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01an3r305</institution-id><institution>Department of Otolaryngology, School of Medicine, University of Pittsburgh</institution></institution-wrap>, <city>Pittsburgh</city>, <country country="US">United States</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Obleser</surname>
<given-names>Jonas</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Lübeck</institution>
</institution-wrap>
<city>Lübeck</city>
<country country="DE">Germany</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>King</surname>
<given-names>Andrew J</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Oxford</institution>
</institution-wrap>
<city>Oxford</city>
<country country="GB">United Kingdom</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
    <fn id="n1" fn-type="present-address"><label>+</label><p>Present address: Department of Communication Sciences and Disorders, Northwestern University, Evanston, United States</p></fn>
<fn id="n2" fn-type="equal"><label>*</label><p>Equal contributions</p></fn>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-11-14">
<day>14</day>
<month>11</month>
<year>2024</year>
</pub-date>
<pub-date date-type="update" iso-8601-date="2025-06-26">
<day>26</day>
<month>06</month>
<year>2025</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP102823</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-09-03">
<day>03</day>
<month>09</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-10-16">
<day>16</day>
<month>10</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.08.01.606213"/>
</event>
<event>
<event-desc>Reviewed preprint v1</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2024-11-14">
<day>14</day>
<month>11</month>
<year>2024</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.102823.1"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.102823.1.sa2">eLife Assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.102823.1.sa1">Reviewer #1 (Public review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.102823.1.sa0">Reviewer #2 (Public review):</self-uri>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Zink et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Zink et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-102823-v2.pdf"/>
<abstract>
<title>Abstract</title><p>Middle-age is a critical period of rapid changes in brain function that presents an opportunity for early diagnostics and intervention for neurodegenerative conditions later in life. Hearing loss is one such early indicator linked to many comorbidities experienced in older age. However, current clinical tests fail to capture hearing difficulties for ∼10% of middle-aged adults with normal hearing thresholds seeking help at hearing clinics. Cochlear neural degeneration (CND) could play a role in these hearing deficits, but our current understanding is limited by the lack of objective diagnostics and uncertainty regarding its perceptual consequences. Here, using a cross-species approach, we measured envelope following responses (EFRs) – neural ensemble responses to sound originating from the peripheral auditory pathway – in young and middle-aged adults with normal audiometric thresholds and compared these responses to young and middle-aged Mongolian gerbils, where CND was histologically confirmed. We observed near identical changes in EFRs across species that were associated with CND. Perceptual effects measured as behavioral readouts showed deficits in the most challenging listening conditions and were associated with CND. Additionally, pupil-indexed listening effort increased even at moderate task difficulties where behavioral outcomes were matched. Our results reveal perceptual deficits in middle-aged adults are associated with CND and increases in listening effort, which may result in increased listening fatigue and conversational disengagement.</p>
</abstract>
<funding-group>
<award-group id="funding-1">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/04mhx6838</institution-id>
<institution>National Institute on Deafness and Other Communication Disorders</institution>
</institution-wrap>
</funding-source>
<award-id>R21DC018882</award-id>
</award-group>
<award-group id="funding-1a">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/04mhx6838</institution-id>
<institution>National Institute on Deafness and Other Communication Disorders</institution>
</institution-wrap>
</funding-source>
<award-id>T32DC011499</award-id>
</award-group>
<award-group id="funding-1b">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/04mhx6838</institution-id>
<institution>National Institute on Deafness and Other Communication Disorders</institution>
</institution-wrap>
</funding-source>
<award-id>F31DC020085</award-id>
</award-group>
<award-group id="funding-2">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/01cwqze88</institution-id>
<institution>National Institutes of Health</institution>
</institution-wrap>
</funding-source>
<award-id>1S10RR028478</award-id>
</award-group>
<award-group id="funding-2a">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/01cwqze88</institution-id>
<institution>National Institutes of Health</institution>
</institution-wrap>
</funding-source>
<award-id>UL1TR001857</award-id>
</award-group>
</funding-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Additional analyses and language added to the discussion section. Some tables updated. Acknowledgements updated.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Age-related hearing loss, defined as declines in hearing sensitivity, is exceedingly common; according to some estimates, ∼45 million adults in the United States over 50 years of age have age-related hearing loss that is significant enough to interfere with communication (<xref ref-type="bibr" rid="c1">1</xref>). Untreated hearing loss decreases quality of life and is considered to be the single-largest modifiable risk factor in middle-age for other age-related comorbidities such as cognitive impairment and dementia (<xref ref-type="bibr" rid="c2">2</xref>). However, current measures of hearing sensitivity fail to capture critical aspects of real-world hearing difficulties in this population (<xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c4">4</xref>). Hearing difficulties experienced by up to 10% of adults seeking help in the hearing clinic are ‘hidden’ to current diagnostic procedures (<xref ref-type="bibr" rid="c3">3</xref>–<xref ref-type="bibr" rid="c6">6</xref>). Peripheral deafferentation caused by cochlear neural degeneration (CND) may underlie many of these perceptual difficulties (<xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c8">8</xref>). Anatomical evidence for progressive CND with aging is clear – postmortem studies using human temporal bones estimate a 40% deafferentation caused by CND by the fifth decade of life (<xref ref-type="bibr" rid="c9">9</xref>–<xref ref-type="bibr" rid="c11">11</xref>). CND causes neural coding deficits in the peripheral auditory pathway, affecting the faithful representation of spectrotemporally complex auditory stimuli (<xref ref-type="bibr" rid="c12">12</xref>–<xref ref-type="bibr" rid="c14">14</xref>). But the evidence linking CND with perceptual deficits is mixed - current assessments of perceptual deficits associated with CND primarily focus on behavioral measures of speech in noise, with mixed evidence of deficits in individuals with putative CND (<xref ref-type="bibr" rid="c15">15</xref>–<xref ref-type="bibr" rid="c18">18</xref>).</p>
<p>Two challenges impede our understanding of the perceptual consequences of CND. First, while many non-invasive markers of CND have been proposed and validated in animal models (<xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c19">19</xref>, <xref ref-type="bibr" rid="c20">20</xref>), non-invasive estimates of putative CND in humans cannot be confirmed with histological assessment of synapses in the same participants. Cross-species comparative studies and computational modeling provide promising avenues for overcoming this gap (<xref ref-type="bibr" rid="c21">21</xref>, <xref ref-type="bibr" rid="c22">22</xref>). Secondly, behavioral readouts of perceptual difficulties in humans show mixed results, with putative CND depending on the specific test used and degree of spectrotemporal and contextual information provided in that test (<xref ref-type="bibr" rid="c17">17</xref>, <xref ref-type="bibr" rid="c23">23</xref>, <xref ref-type="bibr" rid="c24">24</xref>). The most promising tests for CND are ones with no linguistic context and short spectrotemporal processing windows (<xref ref-type="bibr" rid="c13">13</xref>, <xref ref-type="bibr" rid="c24">24</xref>). However, these behavioral readouts may minimize subliminal changes in perception that are reflected in listening effort but <italic>not</italic> in accuracies (<xref ref-type="bibr" rid="c25">25</xref>–<xref ref-type="bibr" rid="c27">27</xref>). Specifically, two individuals may show similar accuracies on a listening task, but one individual may need to exert substantially more listening effort to achieve the same accuracy as the other. Here, we used a cross-species approach, combined with simultaneous measurements of behavior and listening effort, to show that CND was associated with decreased neural coding fidelity and increased listening effort in middle-aged adults with normal audiometric thresholds. We measured putative CND using the envelope following response (EFR) to rapid (∼1000Hz) modulation frequencies – a suggested marker for CND (<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c14">14</xref>). Cross-species comparisons with identical recordings in a low-frequency hearing animal model, the Mongolian gerbil, confirmed that decreases in EFRs were selective only for responses with generators in the auditory nerve. These EFRs were also associated with histologically-confirmed CND in gerbils. In the human model, we simultaneously measured pupil-indexed listening effort in participants as they performed a speech-in-noise task and showed that increased listening effort was present despite matched behavioral accuracies. These results point to hitherto underexplored aspects of auditory perceptual difficulties associated with listening effort and CND.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>“Normal” hearing middle-aged adults show evidence of peripheral neural coding deficits that are associated with CND</title>
    <p>Middle-aged (40-55 years) and young adult (18-25 years) listeners were recruited to participate in this study (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>). All participants had clinically normal hearing thresholds and spoke fluent American English. Participants had normal otoscopy by visual examination and air conduction thresholds ≤ 25dB HL for octave frequencies between 250Hz to 8 kHz (<xref rid="fig1" ref-type="fig">Fig. 1B</xref>, <xref rid="tbl1" ref-type="table">Table 1</xref>), consistent with WHO guidelines for normal hearing (<xref ref-type="bibr" rid="c28">28</xref>). Threshold differences were exaggerated in MAs at extended high frequencies (&gt;8kHz), which are seldom clinically measured but may be a marker for accumulated lifetime noise damage ((<xref ref-type="bibr" rid="c17">17</xref>, <xref ref-type="bibr" rid="c29">29</xref>–<xref ref-type="bibr" rid="c31">31</xref>), <xref rid="fig1" ref-type="fig">Fig. 1B</xref>, <xref rid="tbl2" ref-type="table">Table 2</xref>). Outer hair cell function, assessed using distortion product otoacoustic emissions (DPOAEs), were comparable between young adult and middle-aged listeners up to 4 kHz, the frequency regions that contains most of the spectral information in speech (<xref rid="fig1" ref-type="fig">Fig. 1C</xref>, <xref rid="tbl3" ref-type="table">Table 3</xref>). Participants also had no severe symptoms of tinnitus (<xref rid="fig1" ref-type="fig">Fig. 1D</xref>) assessed using the Tinnitus Handicap Inventory (THI; (<xref ref-type="bibr" rid="c32">32</xref>)) and Loudness Discomfort Levels (LDLs; (<xref ref-type="bibr" rid="c32">32</xref>)) above 80 dB SPL for frequencies up to 3 kHz (<xref rid="fig1" ref-type="fig">Fig. 1E</xref>, <xref rid="tbl4" ref-type="table">Table 4</xref>). Self-reported noise exposure using the Noise Exposure Questionnaire (NEQ; (<xref ref-type="bibr" rid="c34">34</xref>)) was not significantly different between age groups (<xref rid="fig1" ref-type="fig">Fig. 1F</xref>, <xref rid="tbl4" ref-type="table">Table 4</xref>). Participants also had normal cognitive function indexed by the Montreal Cognitive Assessment (MoCA ≥ 25; (<xref ref-type="bibr" rid="c35">35</xref>)) and comparable working memory scores assessed using the operation span task (OSPAN) ((<xref ref-type="bibr" rid="c36">36</xref>), <xref rid="fig1" ref-type="fig">Fig. 1G</xref>, <xref rid="tbl4" ref-type="table">Table 4</xref>). Hence, the middle-aged adults recruited for this study were all “normal” by currently administered behavioral and audiological assessments in the hearing clinic, while exhibiting some sub-clinical outer hair cell dysfunction, especially at frequencies above 4kHz.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Age-related CND occurs prior to overt changes in hearing thresholds and can be assessed non-invasively by measuring phase-locked neural envelope following responses.</title>
<p><bold>(A)</bold> Thirty middle-aged (MA, 40-55 yrs, mean = 46.1<underline>+</underline>4.6 yrs) and 36 young adults (YA, 18-25 years, mean = 21.17<underline>+</underline> 1.8yrs) participated in this study. <bold>(B)</bold> All participants had clinically normal hearing thresholds with some evidence of threshold losses at extended high frequencies above 8 kHz typically not tested in the clinic. Hearing thresholds in dB HL are shown on the Y axis and frequency in kHz is plotted on the X axis. <bold>(C)</bold> Outer hair cell function assessed using DPOAEs is comparable between YA and MA up to 4kHz and showed age-related decreases at higher frequencies. Both cohorts show no evidence of self-reported tinnitus <bold>(D)</bold> or hyperacusis measured as LDLs <bold>(E)</bold>, have comparable self-reported noise exposure levels <bold>(F),</bold> and comparable working memory scores assessed using OSPAN <bold>(G). (H)</bold> EFRs to modulation frequencies of 1024Hz can be reliably recorded in young and middle-aged adults using ‘tiptrodes’. The panel shows grand-averaged FFT traces for YA and MA. <bold>(I)</bold> Middle-aged adults showed significant declines in EFR amplitudes at 1024Hz AM, with putative neural generators in the auditory nerve. <bold>(J)</bold> Signal-to-noise ratios were 8dB on average for YA and 4dB for MA. <bold>(K)</bold> Statistically significant decreases in EFR amplitudes were selective for 1024Hz AM, the modulation frequency with putative generators in the auditory nerve. All panels: Error bars and shading represent standard error of the mean (SEM). Asterisks represent p&lt;0.05, ANOVA.</p></caption>
<graphic xlink:href="606213v3_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1</label>
<caption><title>Comparison of air conduction thresholds using a 3-way ANOVA (MA = 37, YA = 35)</title></caption>
<graphic xlink:href="606213v3_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2</label>
<caption><title>Comparison of extended high frequencies using 3-way ANOVA (MA = 37, YA = 35)</title></caption>
<graphic xlink:href="606213v3_tbl2.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3</label>
<caption><title>Comparison of right ear distortion product otoacoustic emissions using a 2-way ANOVA (MA = 34, YA = 31)</title></caption>
<graphic xlink:href="606213v3_tbl3.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tbl4" orientation="portrait" position="float">
<label>Table 4</label>
<caption><title>Comparisons using 1-way ANOVAs</title></caption>
<graphic xlink:href="606213v3_tbl4.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>We then measured putative CND using neural ensemble responses from the auditory periphery phase-locked to the stimulus amplitude envelope via the EFR. EFRs can be used to emphasize neural generators in the auditory periphery by exploiting divergent phase-locking abilities along the ascending auditory pathway. EFRs at rapid amplitude modulation (AM) frequencies above 600Hz have been shown to relate to underlying CND in animal models (<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c14">14</xref>) and in humans (<xref ref-type="bibr" rid="c37">37</xref>). Here, we measured EFRs to AM frequencies that have putative neural generators in the central auditory pathway such as the cortex (40Hz AM) (<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c38">38</xref>), as well as faster modulation rates (110Hz, 512Hz, and 1024Hz AM) that emphasize progressively peripheral auditory regions (<xref ref-type="bibr" rid="c12">12</xref>). We were able to reliably record EFRs up to 1024Hz by using gold-foil tipped electrodes (‘tiptrodes’) placed in the ear canal, closer to the presumptive neural generators in the auditory nerve (<xref rid="fig1" ref-type="fig">Fig. 1H</xref>). EFR peaks analyzed in the spectral domain were above the noise floor, with average signal to noise ratios (SNRs) of 8dB in younger and 4dB in middle-aged adults (Fig. I, J). Statistically significant age-related decreases in EFR amplitudes were only present for EFRs to the 1024Hz AM rate, which has putative generators in the auditory nerve (<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c14">14</xref>) but were not present for slower AM rates with putative generators in the midbrain or cortex (<xref rid="fig1" ref-type="fig">Fig. 1K</xref>, <xref rid="tbl5" ref-type="table">Table 5</xref>).</p>
<table-wrap id="tbl5" orientation="portrait" position="float">
<label>Table 5</label>
<caption><title>Comparison of EFRs using 2-way ANOVAs (MA = 29, YA = 28)</title></caption>
<graphic xlink:href="606213v3_tbl5.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>To confirm that the EFR parameters used here were indeed sensitive to putative CND, we measured EFRs using identical stimuli, acquisition, and analysis parameters in young (22wk) and middle-aged (80wk) Mongolian gerbils (<xref rid="fig2" ref-type="fig">Fig. 2A</xref>). The hearing range of gerbils largely overlaps with that of humans at speech frequencies (<xref ref-type="bibr" rid="c39">39</xref>), making them an ideal animal model for direct comparison in cross-species studies. Middle-aged gerbils showed no loss of hearing thresholds, similar to middle-aged humans (<xref rid="fig2" ref-type="fig">Fig. 2B</xref>). Remarkably, gerbils also exhibited a selective decrease in EFR amplitudes for AM rates at 1024Hz, similar to middle-aged humans (<xref rid="fig2" ref-type="fig">Fig. 2C</xref>, <xref rid="tbl6" ref-type="table">Table 6</xref>). CND in gerbils was assessed using immunohistological analysis of cochlear whole mounts, where the cell bodies, presynaptic ribbon terminals and the post-synaptic glutamate receptor patches were immunostained, visualized using confocal microscopy, and quantified from 3D reconstructed images (<xref rid="fig2" ref-type="fig">Fig. 2D</xref>). Significant decreases in afferent synapse counts were present in middle-aged gerbils, reaching up to 20% losses compared to the young gerbils (<xref rid="fig2" ref-type="fig">Fig. 2E</xref>, <xref rid="tbl7" ref-type="table">Table 7</xref>). Further, EFR amplitudes were significantly correlated to the number of remaining cochlear synapses (<xref rid="fig2" ref-type="fig">Fig. 2F</xref>), thus confirming that our EFRs were a sensitive metric of CND.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Cross-species experiments in a rodent model show that EFRs are a sensitive biomarker for histologically confirmed CND.</title>
<p><bold>(A)</bold> Cross-species comparisons were made with young (22<underline>+</underline> 0.86 weeks, n = 14) and middle-aged (80<underline>+</underline> 0.76 weeks, n = 13) Mongolian gerbils, with identical stimuli, recording, and analysis parameters. <bold>(B)</bold> Middle- aged gerbils did not show any age-related decreases in hearing thresholds. <bold>(C)</bold> Age-related decreases in EFR amplitudes were isolated to the 1024Hz modulation frequency, similar to middle-aged humans in Fig1K. <bold>(D)</bold> CND was quantified for a subset of these gerbils (n = 10 young and 10 middle-aged) using immunostained organ of Corti whole mounts, where afferent excitatory synapses were quantified using 3D reconstructed images. <bold>(E)</bold> Cochlear synapse counts at the 3kHz cochlear region corresponding to the carrier frequency for the EFRs was significantly decreased in middle-aged gerbils, despite matched auditory thresholds. <bold>(F)</bold> EFR amplitudes at 1024Hz AM were significantly correlated with the number of remaining cochlear synapses, suggesting that these EFRs are a sensitive metric for CND with age. All panels: Error bars and shading represent standard error of the mean (SEM). Asterisks represent p&lt;0.05, ANOVA.</p></caption>
<graphic xlink:href="606213v3_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<table-wrap id="tbl6" orientation="portrait" position="float">
<label>Table 6</label>
<caption><title>Comparison of 22 week-old gerbil (n= 14) and 80 week-old gerbil (n = 12) EFRs using 2-way ANOVAs</title></caption>
<graphic xlink:href="606213v3_tbl6.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tbl7" orientation="portrait" position="float">
<label>Table 7</label>
<caption><title>Comparison of synapse counts at 3000 Hz in 22 and 80 week-old gerbils using 1-way ANOVA</title></caption>
<graphic xlink:href="606213v3_tbl7.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s2b">
<title>Perceptual deficits manifest as increased listening effort prior to behavioral deficits in middle-aged adults</title>
<p>Do middle-aged adults with putative CND experience challenges with hearing in noise despite having clinically normal hearing thresholds? We measured speech perception in noise abilities with the clinically-used Quick Speech-in-Noise (QuickSIN; (<xref ref-type="bibr" rid="c40">40</xref>)) task, to assess hearing in noise changes that were closer to real-world listening scenarios. QuickSIN tests suprathreshold hearing of medium context sentences presented in varying levels of four-talker background babble ranging from 25 to 0 dB SNR levels in 5 dB steps (<xref rid="fig3" ref-type="fig">Fig. 3A</xref>). Further, QuickSIN is a clinically relevant test that we recently identified as being sensitive to detect perceptual deficits in adult populations with normal audiograms (<xref ref-type="bibr" rid="c5">5</xref>). On each trial, participants were required to repeat a target sentence, which contained five key words for identification. Clinically, QuickSIN is scored as dB SNR loss, reflecting the SNR level required to correctly identify key words in noise correctly half the time. No significant age-related differences were observed in clinically scored QuickSIN dB SNR loss (<xref rid="fig3" ref-type="fig">Fig. 3B</xref>, <xref rid="tbl4" ref-type="table">Table 4</xref>). When analyzing performance at each SNR, accuracy was at near-ceiling from 25 dB SNR to 10 dB SNR, but dropped from 5dB SNR in both young and middle-aged adults. Statistically significant behavioral deficits with age were observed on QuickSIN only in the most challenging SNR of 0 dB (<xref rid="fig3" ref-type="fig">Fig. 3C</xref>, <xref rid="tbl8" ref-type="table">Table 8</xref>).</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Increased listening effort precedes behavioral deficits in speech in noise perception in middle-aged adults.</title>
<p><bold>(A)</bold> Speech perception in noise was assessed using the QuickSIN test, which presents moderate context sentences in varying levels of multi-talker babble. Pupillary measures were analyzed in two time-windows – 1. during stimulus presentation, and 2. after target sentence offset and prior to response initiation <bold>(B)</bold> No significant age- related differences were observed in clinical QuickSIN scores presented as dB SNR loss. <bold>(C)</bold> QuickSIN performance is matched between middle-aged (MA) and younger adults (YA) until the most difficult noise condition (SNR 0). The x- axis shows the SNR condition that the target sentences were presented in, with 25dB being the easiest noise condition, and 0dB being the most difficult noise condition. The y-axis shows participant accuracy in repeating key words from the target sentences as percent correct. <bold>(D)</bold> Grand-averaged pupillary responses measured during task listening as an index of effort exhibit modulation with task difficulty, with greater pupillary dilations observed in harder conditions for both groups. <bold>(E)</bold> Middle-aged adults show consistently higher pupillary responses during performance on the QuickSIN task and at SNR levels prior to when overt behavioral deficits are observed. <bold>(F)</bold> Grand- averaged pupillary responses measured after target sentence offset as an index of effort exhibit greater modulation with task difficulty, compared to changes in the listening window. <bold>(G)</bold> Trends seen in the listening window were amplified in this integration window, with middle-aged adults showing even greater effort, especially at moderate SNRs where behavior was matched.</p></caption>
<graphic xlink:href="606213v3_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<table-wrap id="tbl8" orientation="portrait" position="float">
<label>Table 8</label>
<caption><title>Comparison of QuickSIN performance using a 2-way ANOVA (MA = 34, YA = 31)</title></caption>
<graphic xlink:href="606213v3_tbl8.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>Are there perceptual deficits experienced by middle-aged adults that are not captured by traditional behavioral readouts? We addressed this question by measuring isoluminous task-related changes in pupil diameter as an index of listening effort (<xref ref-type="bibr" rid="c41">41</xref>–<xref ref-type="bibr" rid="c43">43</xref>) while participants performed the QuickSIN task (<xref rid="fig3" ref-type="fig">Fig. 3A</xref>). Pupillary changes were analyzed using growth curve analysis (GCA, (<xref ref-type="bibr" rid="c44">44</xref>)). GCAs provide a statistical approach to modeling changes over time in the timing and shape of the pupillary response and has several advantages to analyzing pupillary response over traditional approaches. First, GCA does not require time-binned samples, thus removing the trade-off between temporal resolution and statistical power, and secondly, GCA can account for individual variability. Two second-order GCAs were fit to different time-windows (<xref rid="tbl9" ref-type="table">Table 9</xref>-<xref rid="tbl10" ref-type="table">10</xref>, see methods). One time window encompassed the onset of the masker through the first 2.8s of the target sentence (listening window). The second window spanned from the end of the target sentence up to the verbal response prompt (integration window). These two time-windows were hypothesized to represent effort associated with differing sensory and cognitive processes. The listening window reflects linguistic and semantic processing of ongoing speech stimuli and is a physiological response to auditory processing (<xref ref-type="bibr" rid="c45">45</xref>), while the integration window reflects error correction, working memory and comparisons with predictive internal models (<xref ref-type="bibr" rid="c46">46</xref>, <xref ref-type="bibr" rid="c47">47</xref>). The linear term from the GCA was further analyzed as a marker for the slope of pupillary change over time.</p>
<table-wrap id="tbl9" orientation="portrait" position="float">
<label>Table 9</label>
<caption><title>Fixed-effect estimates for model of pupillary responses from 0 to 5.8 seconds time-locked to babble masker onset to examine the effect of SNR and age group (observations = 96,612, groups: participant x SNR = 332, participant = 63)</title></caption>
<graphic xlink:href="606213v3_tbl9.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tbl10" orientation="portrait" position="float">
<label>Table 10</label>
<caption><title>Fixed-effect estimates for model of pupillary responses from 0 to 3 seconds time-locked to QuickSIN target sentence offset to examine the effect of SNR and age group (observations = 63,184, groups: participant x SNR = 359, participant = 63)</title></caption>
<graphic xlink:href="606213v3_tbl10.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>Pupil-indexed listening effort measured during listening was modulated by task difficulty, with pupil diameters showing a larger increase at more challenging SNRs (<xref rid="fig3" ref-type="fig">Fig. 3D</xref>). Both younger and middle-aged adults showed increases in pupil-indexed effort prior to overt decreases in behavioral performance (<xref rid="fig3" ref-type="fig">Fig. 3E</xref>). While MAs exhibited larger increases in listening effort compared to YA, this change was not statistically significant (<xref rid="fig3" ref-type="fig">Fig. 3E</xref>, Supp. Table 9). Trends seen in the pupillary responses for the listening window were further amplified in the integration window (<xref rid="fig3" ref-type="fig">Fig. 3F</xref>). Pupillary slopes obtained from the GCA increased with task difficulty for both YA and MA. However, middle-aged adults showed a larger increase in listening effort than younger adults with decreasing SNRs, with significant age group listening effort differences at 10dB SNR, even though behavioral performance was matched (<xref rid="fig3" ref-type="fig">Figure 3G</xref>, Supp. Table 10). These results suggest that middle-aged adults may maintain comparable performance to younger listeners at moderate task difficulty but at the cost of greater listening effort.</p>
</sec>
<sec id="s2c">
<title>Pupil-indexed listening effort and CND provide synergistic contributions to speech in noise intelligibility</title>
<p>We sought to understand the relationships between CND, listening effort, and speech-in-noise intelligibility in normal-hearing middle-aged adults. Behavioral performance in QuickSIN at 0dB SNR, where there was a group effect of age, was significantly correlated with putative CND assessed using EFRs at 1024 Hz (<xref rid="fig4" ref-type="fig">Fig. 4A</xref>). This suggests that peripheral deafferentation may manifest as overt behavioral deficits under the most challenging listening conditions. Pupil-indexed listening effort was also greater in the integration window in middle-aged adults at 10dB SNR compared to younger adults (<xref rid="fig3" ref-type="fig">Fig. 3G</xref>), even though behavioral performance was near ceiling for both age groups. Pupillary slopes at 10dB SNR in the integration window were correlated with behavioral deficits at 0 dB SNR (<xref rid="fig4" ref-type="fig">Fig. 4B</xref>). These results add to the growing evidence suggesting that pupil-indexed listening effort to maintain behavioral performance at moderate task difficulties is predictive of behavioral performance at more challenging listening conditions (<xref ref-type="bibr" rid="c48">48</xref>). There were significant correlations between pupillary slopes in the listening window as well, even though there were no group level differences with age (<xref rid="fig4" ref-type="fig">Fig. 4C</xref>). These data suggest that CND and increased listening effort both associated with listening challenges in middle-aged adults.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Listening effort and CND provide complementary contributions to speech in noise intelligibility.</title>
<p><bold>(A)</bold> Behavioral performance at the most challenging SNR was significantly correlated with the EFR measures of CND, with lower EFR amplitudes being associated with poorer behavioral performance. <bold>(B)</bold> Pupillary responses at 10 dB SNR from the integration window were significantly correlated with behavioral performance at 0dB SNR, <bold>(B)</bold> These correlations between pupillary responses at 10 dB SNR and behavioral performance at 0dB SNR was also found in the listening window, even though there were no group differences in age, further strengthening the link between listening effort at moderate SNRs and behavioral performance at challenging SNRs. <bold>(D)</bold> an elastic net regression model with 10-fold cross validation (cv) was fit to the QuickSIN scores at 0dB SNR. The tuning parameter Lambda controls the extent to which coefficients contributing least to predictive accuracy are suppressed. <bold>(E)</bold> A lollipop plot displaying the coefficients (β) contributing to explaining variance on QuickSIN performance suggests that CND, listening effort and subclinical changes in hearing thresholds all contribute to QuickSIN performance. <bold>(F)</bold> QuickSIN scores predicted by the elastic net regression are corelated with actual participant QuickSIN scores.</p></caption>
<graphic xlink:href="606213v3_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Is increase in listening effort synergistic with CND? To understand the multifactorial contributions of sensory and top-down factors that may affect speech perception in noise, we performed a penalized regression with elastic net penalty (<xref ref-type="bibr" rid="c49">49</xref>). QuickSIN performance at 0dB SNR (scaled to 0-100) was used as the outcome variable and all other measured variables were inserted as input variables. The elastic net penalized regression framework is a robust method that blends Lasso’s ability to perform variable selection and Ridge’s ability to handle multicollinearity and grouped covariates. The fitted elastic net regression model showed an R<sup>2</sup> value of 0.5981, and five significant predictors – hearing thresholds averaged across 500Hz to 4kHz (PTA4k), EFR amplitudes at 1024Hz AM, pupillary slopes at 10dB SNR and 0 dB SNR in the listening window, and pupillary slopes at 10dB SNR in the integration window (<xref rid="fig4" ref-type="fig">Fig. 4D-E</xref>). This model was significantly related to QuickSIN performance and predicted the observed QuickSIN scores across younger and middle-aged adults (r = 0.64/(pseudo-)R<sup>2</sup> = 0.41, <xref rid="fig4" ref-type="fig">Fig. 4F</xref>). Hence, the output of the elastic net regression suggests that CND and pupil-indexed listening, in addition to subclinical changes in hearing thresholds, all provided complementary contributions to speech perception in noise.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Middle-age, typically defined as the fifth and sixth decade of life, has been historically understudied compared to older age ranges (<xref ref-type="bibr" rid="c50">50</xref>). Increasing evidence suggests that middle-age is a critical period of rapid changes in brain function (<xref ref-type="bibr" rid="c51">51</xref>, <xref ref-type="bibr" rid="c52">52</xref>). The resilience of the brain in keeping with degenerative processes that begin to occur in middle-age predicts further age-related degeneration in later life and presents a critical opportunity for early intervention (<xref ref-type="bibr" rid="c50">50</xref>, <xref ref-type="bibr" rid="c53">53</xref>–<xref ref-type="bibr" rid="c55">55</xref>). Hearing loss in middle-age has recently been identified as the largest modifiable risk factor for dementia and Alzheimer’s disease later in life (<xref ref-type="bibr" rid="c2">2</xref>). However, the number of middle-aged patients who seek help for hearing difficulties but show no abnormal clinical indicators suggests the need for the development of sensitive biomarkers for hearing challenges experienced by this population (<xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c6">6</xref>, <xref ref-type="bibr" rid="c56">56</xref>).</p>
<p>Anatomical evidence from human temporal bones suggests a 40% deafferentation of cochlear synapses in middle-aged adults, even without substantial noise exposure history (<xref ref-type="bibr" rid="c9">9</xref>–<xref ref-type="bibr" rid="c11">11</xref>). Peripheral deafferentation triggers compensatory mechanisms across sensory, language, and attentional systems (<xref ref-type="bibr" rid="c57">57</xref>–<xref ref-type="bibr" rid="c60">60</xref>). But our understanding of the perceptual consequences of cochlear deafferentation are limited by the lack of consensus on sensitive biomarkers for CND (<xref ref-type="bibr" rid="c61">61</xref>). Recent studies have identified multiple promising biomarkers for CND in animal models and human populations (<xref ref-type="bibr" rid="c21">21</xref>, <xref ref-type="bibr" rid="c37">37</xref>, <xref ref-type="bibr" rid="c62">62</xref>). Reduced wave I amplitudes in the auditory brainstem response are a reliable marker of CND in animal models (<xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c63">63</xref>) but can be challenging to obtain in humans (<xref ref-type="bibr" rid="c20">20</xref>, <xref ref-type="bibr" rid="c62">62</xref>). The middle-ear muscle reflex, an acoustic measurement of middle-ear immittance driven by efferent feedback to the middle-ear muscles, has also been identified as a promising marker for CND (<xref ref-type="bibr" rid="c19">19</xref>, <xref ref-type="bibr" rid="c21">21</xref>, <xref ref-type="bibr" rid="c64">64</xref>). Here, we used the EFR to identify CND in middle-aged adults with normal audiometric thresholds. As opposed to the middle-ear muscle reflex, EFRs measure peripheral neural coding and central auditory activity by exploiting the divergent phase-locking abilities of the ascending auditory pathway (<xref ref-type="bibr" rid="c65">65</xref>, <xref ref-type="bibr" rid="c66">66</xref>). EFRs with modulation rates greater than ∼1000 Hz have been associated with CND and are considered to reflect the integrity of the auditory nerve (<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c14">14</xref>), given that midbrain and cortical neurons cannot phase-lock to such high rates (<xref ref-type="bibr" rid="c65">65</xref>). We observed decreases in EFRs at modulation rates that were selective to the auditory periphery (i.e., 1024 Hz) in middle-aged adults, while EFRs at slower modulation rates, likely generated from the central auditory structures, were not different from those in younger adults (<xref rid="fig1" ref-type="fig">Fig. 1K</xref>). The use of a more rapid onset time in the stimulus modulation envelope, such as the rectangular amplitude modulated tones (RAM EFRs), may result in a larger separation of these groups even at slower modulation rates (<xref ref-type="bibr" rid="c67">67</xref>, <xref ref-type="bibr" rid="c68">68</xref>), as sharper onset times result in greater EFR amplitudes (<xref ref-type="bibr" rid="c37">37</xref>, <xref ref-type="bibr" rid="c69">69</xref>). However, a more intriguing possibility is that middle-aged adults exhibited an increase in relative central auditory activity, or ‘gain’, in the presence of decreased peripheral neural coding (<xref ref-type="bibr" rid="c57">57</xref>, <xref ref-type="bibr" rid="c59">59</xref>). The perceptual consequences of this gain are unclear, but our findings align with emerging evidence suggesting that gain is associated with selective deficits in speech-in-noise abilities (<xref ref-type="bibr" rid="c59">59</xref>, <xref ref-type="bibr" rid="c70">70</xref>, <xref ref-type="bibr" rid="c71">71</xref>). EFRs at suprathreshold levels presented here also have contributions from higher frequency regions due to a broader excitation at the cochlea (<xref ref-type="bibr" rid="c72">72</xref>, <xref ref-type="bibr" rid="c73">73</xref>). Since cochlear synapse loss is also believed to be flat across frequencies with age, EFRs used here likely index cochlear synapse loss equally across a broad range of frequencies (<xref ref-type="bibr" rid="c9">9</xref>, <xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c63">63</xref>). This notion is further supported by emerging evidence that suggests that phase-locking measured to lower frequency pure tones also indexes cochlear synaptopathy in ways that are similar to using a faster modulation rate on a higher frequency tone (<xref ref-type="bibr" rid="c74">74</xref>, <xref ref-type="bibr" rid="c75">75</xref>).</p>
<p>The Mongolian gerbil provides a robust model for cross-species comparisons with aging humans, due to overlapping hearing frequency ranges and experimentally tractable lifespans. Here, using young and middle-aged gerbils, we showed similar EFR decreases as seen in human listeners (<xref rid="fig2" ref-type="fig">Fig. 2C</xref>). Additionally, age-related changes in the EFR were associated with confirmed CND (<xref rid="fig2" ref-type="fig">Fig. 2F</xref>). CND in gerbils reached ∼20% in the middle-aged 80 week group tested here, which is less than what has been observed in middle-aged humans, where CND estimates typically reach 40-50% by the fifth decade of life (<xref ref-type="bibr" rid="c9">9</xref>). However, our EFRs were still sensitive to this degree of CND, reiterating that EFRs are a sensitive metric for measuring cochlear deafferentation. Additionally, we confirmed that the gerbils used in this study did not show any changes in hearing thresholds (<xref rid="fig2" ref-type="fig">Fig. 2B</xref>). Hence, they were unlikely to have strial degenerations that are known to occur in older gerbils that affect auditory thresholds (<xref ref-type="bibr" rid="c76">76</xref>). The synapse loss patterns and EFR amplitude changes seen here in gerbils were in agreement with earlier studies using alternate rodent models (<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c69">69</xref>), further confirming that age-related cochlear synapse loss is a pervasive mammalian phenomenon that can be captured using EFRs to rapid modulation frequencies (∼1000 Hz).</p>
<p>Strong evidence links CND with altered neural coding of sounds in multiple ascending auditory stations (<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c58">58</xref>, <xref ref-type="bibr" rid="c59">59</xref>). However, the perceptual consequences of CND on speech-in-noise abilities remain unclear (<xref ref-type="bibr" rid="c61">61</xref>). Evidence for overt behavioral deficits have been mixed and may depend on the specific type of task used for assessment (<xref ref-type="bibr" rid="c17">17</xref>, <xref ref-type="bibr" rid="c23">23</xref>). Here we used QuickSIN, a clinically relevant test that we recently identified as being sensitive to changes in adult normal hearing populations with perceived hearing deficits (<xref ref-type="bibr" rid="c5">5</xref>). However, tests that are further challenging in spectrotemporal complexity, such as the addition of time compression or reverberation, may further tease apart these differences (<xref ref-type="bibr" rid="c17">17</xref>, <xref ref-type="bibr" rid="c37">37</xref>). In the current study, behavioral deficits began to emerge only at the most challenging SNR levels (<xref rid="fig3" ref-type="fig">Fig. 3</xref>). However, perceptual deficits in terms of listening effort began to appear prior to behavioral changes.</p>
<p>Listening effort is an umbrella term that may assess multiple forms of executive function such as cognitive resource allocation, working memory, and attention, and can be assessed by measuring isoluminous task-related changes in pupil diameter (<xref ref-type="bibr" rid="c26">26</xref>, <xref ref-type="bibr" rid="c41">41</xref>–<xref ref-type="bibr" rid="c43">43</xref>, <xref ref-type="bibr" rid="c77">77</xref>). The mechanisms underlying these pupillary changes are still under study (<xref ref-type="bibr" rid="c78">78</xref>, <xref ref-type="bibr" rid="c79">79</xref>) but are hypothesized to involve the Locus Coeruleus – Norepinephrine (LC-NE) system (<xref ref-type="bibr" rid="c80">80</xref>, <xref ref-type="bibr" rid="c81">81</xref>). Here, we observed that pupil-indexed listening effort increased in middle-aged adults, even when behavioral performance was matched (<xref rid="fig3" ref-type="fig">Fig. 3E, F</xref>). This suggests that middle-aged adults expend more effort to maintain behavioral performance, which may lead to more listening fatigue or disengagement from conversations (<xref ref-type="bibr" rid="c25">25</xref>, <xref ref-type="bibr" rid="c82">82</xref>, <xref ref-type="bibr" rid="c83">83</xref>). Potentially confounding factors impacting pupil measurement such as the decrease of pupil dynamic range with aging (<xref ref-type="bibr" rid="c84">84</xref>, <xref ref-type="bibr" rid="c85">85</xref>), participant fatigue, or task habituation (<xref ref-type="bibr" rid="c45">45</xref>, <xref ref-type="bibr" rid="c77">77</xref>, <xref ref-type="bibr" rid="c86">86</xref>), can vary between individuals for a multitude of reasons (<xref ref-type="bibr" rid="c87">87</xref>). Here, the effects of these factors were minimized by applying trial-by-trial baseline corrections prior to analysis to match the magnitude of response between young and middle-aged adults.</p>
<p>Interestingly, pupil-indexed listening effort at a moderate SNR was a better predictor of behavioral performance at a more challenging SNR using two separate approaches – a Pearsons’s correlation and the elastic net regression model (<xref rid="fig4" ref-type="fig">Fig. 4B-D</xref>). We have previously demonstrated similar results in a different test group of young adult participants (<xref ref-type="bibr" rid="c48">48</xref>). These results suggest that the amount of effort required to maintain ceiling performance at moderate SNRs are predictive of behavioral performance at harder task difficulties. Pupillary indices at the harder task conditions may be rolling over into hyperexcitability (<xref ref-type="bibr" rid="c78">78</xref>, <xref ref-type="bibr" rid="c79">79</xref>) and thus being a poorer predictor of concomitant behavioral performance. Additionally, our elastic net regression model suggested that CND and listening effort provided complementary contributions to explaining variance on the QuickSIN task.</p>
<p>Even though both young and middle-aged adults had clinically normal hearing thresholds, subtle changes within this normal range affected speech-in-noise performance (<xref rid="fig4" ref-type="fig">Fig. 4D</xref>), lending support to studies suggesting that the definition of clinically ‘normal’ may need revision (<xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c88">88</xref>). Our findings demonstrate a need for next-generation diagnostic measures of auditory processing that incorporate both neurophysiological encoding of the temporal elements of sound and cognitive factors associated with listening effort to better capture one’s listening abilities. Future studies will directly test the link between cochlear and peripheral neural deficits and listening effort, and explore further contributions of other top-down mechanisms that may influence listening effort such as selective attention or semantic load (<xref ref-type="bibr" rid="c89">89</xref>, <xref ref-type="bibr" rid="c90">90</xref>).</p>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Humans</title>
<sec id="s4a1">
<title>Participants</title>
<sec id="s4a1a">
<title>Recruitment</title>
<p>Young (<italic>n</italic> = 38; 18-25 years old, male = 10) and middle-aged (<italic>n</italic> = 45; 40-55 years old, male = 16) adult participants were recruited from the University of Pittsburgh Pitt + Me research participant registry, the University of Pittsburgh Department of Communication Science and Disorders research participant pool, and the broader community under a protocol approved by the University of Pittsburgh Institutional Review Board (IRB#21040125). Participants were compensated for their time, travel, and given an additional monetary incentive for completing all study sessions.</p>
</sec>
<sec id="s4a1b">
<title>Eligibility</title>
    <p>Participant eligibility was determined during the first session of the study. Eligible participants had normal cognition determined by the Montreal Cognitive Assessment (MoCA ≥ 25; <xref ref-type="bibr" rid="c35">Nasreddine et al., 2005</xref>), normal hearing thresholds (≤ 25 dB HL 250-8000 Hz), no severe tinnitus as self-reported via the Tinnitus Handicap Inventory (THI; (<xref ref-type="bibr" rid="c32">32</xref>), and Loudness Discomfort Levels (LDLs) ≥ 80dB HL at .5, 1, and 3kHz (<xref ref-type="bibr" rid="c33">33</xref>). Participants were not required to have specific complaints of speech perception in noise difficulties. The Beck’s depression Inventory (BDI (<xref ref-type="bibr" rid="c91">91</xref>)) was administered and participants were excluded if they reported thoughts of self-harm, determined by any response to survey item nine greater than 0. Participants self-reported American English fluency. Thirty-five young (18-25 years old, male = 10) and 37 middle-aged participants (40-55 years old, male = 10) met all eligibility criteria and were tested further using the battery described below.</p>
</sec>
</sec>
<sec id="s4a2">
<title>Audiological assessment</title>
<sec id="s4a2a">
<title>Otoscopy</title>
<p>An otoscopic examination was conducted using a Welch Allyn otoscope to examine the patient’s external auditory canal, tympanic membrane, and middle ear space for excess cerumen, ear drainage, and other abnormalities. The presence of any such abnormality resulted in exclusion from the study, as these may lead to a conductive hearing loss.</p>
</sec>
<sec id="s4a2b">
<title>Audiogram</title>
<p>Hearing thresholds were collected inside a sound attenuating booth using a MADSEN Astera<sup>2</sup> audiometer, Otometrics transducers [Natus Medical, Inc. Middleton, WI], and foam insert eartips sized to the participants’ ear canal width. Tones were presented using a pulsed beat and participants were instructed to press a response plunger if they believed that they perceived a tone being played, even if they were unsure. Extended high frequency hearing thresholds (EHFs) were collected at frequencies 8, 12.5, and 16kHz using Sennheiser circumaural headphones and Sennheiser HDA 300 transducers using the same response instructions.</p>
</sec>
<sec id="s4a2c">
<title>Loudness Discomfort Levels (LDLs)</title>
<p>LDLs were collected binaurally using Otometrics transducer [Natus Medical, Inc., Middleton, WI] and foam tip ear inserts. Warble tones were presented, and participants were instructed to rate the loudness on a scale of one to seven, with seven being so loud that they would leave the room.</p>
</sec>
<sec id="s4a2d">
<title>Distortion Product Otoacoustic Emissions (DPOAEs)</title>
<p>Outer hair cell function was assessed using DPOAEs. DPOAEs were collected from both the right and left ear individually, with a starting frequency of 500Hz and an ending frequency of 16kHz. The stimulus had an L1 of 75dB SPL and an L2 of 65dB SPL and was presented in 8 blocks of 24 sweeps in alternating polarities. Responses were collected using rubber ear inserts sized to participants’ ear canal width and ER-10D DPOAE Probe transducer [Etymotic Research Inc., Elk Grove, IL].</p>
</sec>
<sec id="s4a2e">
<title>Noise Exposure History</title>
<p>Participants completed the Noise Exposure Questionnaire (NEQ; (<xref ref-type="bibr" rid="c34">34</xref>)) as a self-reported assay of annual noise exposure, accounting for both occupational and non-occupational sources. Annual noise exposure was expressed using L<sub>Aeq8760h</sub>, representing the annual hourly duration of noise exposure presented in sound pressure level in dB. Calculation of the L<sub>Aeq8760h</sub> followed the original article (<xref ref-type="bibr" rid="c34">34</xref>).</p>
</sec>
<sec id="s4a2f">
<title>OSPAN</title>
<p>Participants also completed the automated version of the OSPAN task(<xref ref-type="bibr" rid="c92">92</xref>), as a metric of working memory (<xref ref-type="bibr" rid="c36">36</xref>). Participants were shown simple arithmetic problems and asked to decide whether presented solutions to the problems were correct or incorrect. A letter was displayed on the screen after each problem. Following a series of arithmetic-letter presentations, participants were required to recall the letters that were displayed in the order that they appeared. The task consisted of 15 letter sequences that spanned three to seven letters (three repetitions of each span). If a participant correctly recalled all letters from a sequence, the span length was added to their score. The maximum possible score on the OSPAN task was 75.</p>
</sec>
</sec>
<sec id="s4a3">
<title>Speech perception in noise</title>
<sec id="s4a3a">
<title>Sentence-level speech perception in noise</title>
<p>Speech perception in noise was indexed using moderate-predictability sentences masked in multitalker babble at six different signal-to-noise ratios (SNR) from the Quick Speech in Noise test (QuickSIN;(<xref ref-type="bibr" rid="c40">40</xref>). QuickSIN is a standardized measure of speech perception in noise that is commonly used in audiology clinics and is representative of a naturalistic listening environment (<xref ref-type="bibr" rid="c93">93</xref>). Each QuickSIN test list consisted of six sentences masked in four-talker babble at the following SNR levels: 25, 20, 15, 10, 5, and 0dB. All participants completed four test lists. Participants listened to the sentences through Sennheiser circumaural headphones. The masker was presented at 60dB SPL, and the sound level of the target sentences were varied to obtain the required SNR level. Participants were instructed to repeat the target sentence to the best of their ability. Each target sentence contained five keywords for identification. The number of key words identified per sentence were recorded. Then, the proportion of keywords correctly identified for each SNR across all four test lists (20 total key words per SNR) was calculated for each participant (<xref ref-type="bibr" rid="c40">40</xref>, <xref ref-type="bibr" rid="c94">94</xref>). In addition, we calculated the standard clinical QuickSIN score of dB SNR loss, which reflects the lowest SNR level that an individual can accurately identify words 50% of the time. For each participant, the dB SNR loss score was calculated for each test list separately using the following equation: 25.5 − (𝑠𝑢𝑚 𝑜𝑓 𝑘𝑒𝑦𝑤𝑜𝑟𝑑𝑠 𝑖𝑑𝑒𝑛𝑡𝑖𝑓𝑖𝑒𝑑 𝑖𝑛 𝑙𝑖𝑠𝑡) (<xref ref-type="bibr" rid="c40">40</xref>). Then, the mean dB SNR loss across all four test lists was calculated and used for analysis.</p>
</sec>
</sec>
<sec id="s4a4">
<title>Pupillometry</title>
<sec id="s4a4a">
<title>Acquisition</title>
<p>Pupillary responses were recorded while participants completed the QuickSIN task. Participants were seated in a testing room with consistent, moderate ambient lighting facing a monitor. Monocular left-eye pupillary responses were recorded at a 1000 Hz sampling rate using an EyeLink 1000 Plus Desktop Mount camera and chin rest (SR Research). Nine-point eye-tracker calibration was performed prior to the start of the experiment. To start each trial, participants were required to fixate on a cross in the center of the screen for a minimum of 500 ms. This fixation criterion was applied to control for the effects of saccades, which can alter pupil diameter, and to minimize pupil foreshortening errors (<xref ref-type="bibr" rid="c95">95</xref>–<xref ref-type="bibr" rid="c97">97</xref>). After meeting the 500 ms fixation criteria, a 100 ms 1000 Hz beep was presented to alert the participant to the start of the trial. There was a two second delay after the beep before the QuickSIN stimulus was presented. The background masker began three seconds before the target sentence and continued for two seconds after the target sentence. After the end of the background masker, there was a two second delay followed by a 100 ms 1000 Hz beep to signal the start of the verbal response period. Manual drift correction was performed at the end of each trial by the experimenter to ensure high quality tracking of the pupil.</p>
</sec>
<sec id="s4a4b">
<title>Preprocessing</title>
<p>Pupillary data were processed in R (<xref ref-type="bibr" rid="c98">98</xref>) using the <italic>eyelinker</italic> package (<xref ref-type="bibr" rid="c99">99</xref>) and custom written scripts. Pupillary responses were analyzed in two windows of interest: 1) listening window, from multi-talker babble onset through 5800 ms, and 2) integration window, from target sentence offset to 1000 ms prior to behavioral response period. Separately for each window of interest, data were first processed to remove noise from blinks and saccades. Any trial with more than fifteen percent of the samples detected as saccades or blinks were removed. For the remaining trials, blinks were linearly interpolated from 60 ms before to 160ms after the detected blinks. Saccades were linearly interpolated from 60 ms before to 60 ms after any detected saccade. The de-blinked data were then down sampled to 50 Hz. Pupillary responses were baseline corrected and normalized on a trial-by-trial basis to account for a downward drift in baseline that can occur across a task and for individual differences in pupil dynamic range (<xref ref-type="bibr" rid="c96">96</xref>). Baseline pupil size was defined as the average pupil size in the 1000 ms period prior to the start of the window of interest <inline-formula><inline-graphic xlink:href="606213v3_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. The pupillary response was then averaged across all four test lists for each SNR per participant in each window of interest. The outcome reported is percent change in pupil size from baseline.</p>
<p>Growth curve analyses (GCA; Mirman, 2014) were used to obtain a measure of the slope of the pupillary response during QuickSIN. GCA uses orthogonal polynomial time terms to model distinct functional forms of the pupillary response over time. Two GCAs were fit using a second-order orthogonal polynomial to model the interaction of age group with SNR level, separately for the listening window and the integration window. This second-order model provides three parameters to explain the pupillary response. The first is the intercept, which refers to the overall change in the pupillary response over the time-window of interest. The second is the linear term (ot1), which represents the slope of the pupillary response over time, or the rate of dilation. The third is the quadratic term (ot2), representing curvature of the pupil response, or the change in rate of the pupillary response over time. GCA were conducted in R (R Core Team, 2022) using the <italic>lme4</italic> package (<xref ref-type="bibr" rid="c100">100</xref>) and <italic>p</italic>-values were estimated using the <italic>lmerTest</italic> package (<xref ref-type="bibr" rid="c101">101</xref>).</p>
<p>For the listening window, the best-fit GCA model included fixed effects of each time term (ot1, ot2), SNR (reference = 25), Group (reference = younger), and all 2- and 3-way interactions between SNR, Group, and time terms. The random effect structure consisted of a random slope of each time term per participant that removed the correlation between random effects, and a random slope of each time term per the interaction of participant and SNR level.
<disp-formula>
<graphic xlink:href="606213v3_ueqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
For the integration window, the best-fit GCA model included fixed effects of each time term (ot1, ot2), SNR (reference = 25), Group (reference = younger), and all 2- and 3-way interactions between SNR, Group, and time terms. The random effect structure consisted of a random slope of each time term per participant, and a random slope of each time term per the interaction of participant and SNR level.
<disp-formula>
<graphic xlink:href="606213v3_ueqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
</p>
</sec>
</sec>
<sec id="s4a5">
<title>Electrophysiology</title>
<sec id="s4a5a">
<title>Envelope Following Responses (EFRs)</title>
<p>EFRs were collected in a sound attenuating booth using a BioSemi ActiveTwo EEG system while participants were seated in a recliner. Stimuli were presented using ER-3C transducers [Etymotic Research Inc., Elk Grove, IL] with gold-foil tiptrodes placed in the ear canals to deliver sound stimuli and record additional channels of evoked potentials. EFRs were recorded to a 250 ms tone with a carrier frequency of 3000Hz, amplitude modulated (AM) at 40, 110, 512, and 1024Hz. Stimuli were presented in alternating polarity, with 500 repetitions each at 85dB SPL to the right ear. Each token was presented at 3.1 repetitions/second, for a period of 322ms.</p>
</sec>
<sec id="s4a5b">
<title>Preprocessing</title>
<p>EFRs from the Fz to the ipsilateral (right) tiptrode were processed and analyzed using custom written scripts in MATLAB v. 2022a (Mathworks Inc., Natick, Massachussetts). EFRs were processed using a fourth-order Butterworth filter with a lowpass filter of 3000Hz. The highpass filter cutoffs used were 5Hz, 80Hz, 200Hz, 300Hz for 40Hz, 110Hz, 512Hz, and 1024Hz AM stimuli, respectively. Fast Fourier transforms (FFTs) were performed on the averaged time domain waveforms for each participant at each AM rate starting 10ms after stimulus onset to exclude auditory brain stem responses (ABRs) and ending 10ms after stimulus offset. The maximum amplitude of the FFT peak at one of three adjacent bins (∼3Hz) around the modulation frequency of the AM rate was reported as the EFR amplitude.</p>
</sec>
</sec>
</sec>
<sec id="s4b">
<title>Animals</title>
<sec id="s4b1">
<title>Subjects</title>
<p>Fourteen young adult Mongolian gerbils aged 18-27 weeks (male = 9) and thirteen middle-aged Mongolian gerbils aged 75-82 weeks (male = 6) were used in this study. All animals are born and raised in our animal care facility from breeders obtained from Charles River. The acoustic environment within the holding facility was characterized by noise-level data logging and was periodically monitored. Data logging revealed an average noise level of 56 dB, with transients not exceeding 74 dB during regular housing conditions and 88dB once a week during cage changes. All animal procedures were approved by the Institutional Animal Care and Use Committee of the University of Pittsburgh (Protocol #21046600).</p>
</sec>
<sec id="s4b2">
<title>Experimental Setup</title>
<p>Experiments were performed in a double walled acoustic chamber. Animals were placed on a water circulated warming blanket set to 37 °C with the pump placed outside the recording chamber to eliminate audio and electrical interferences. Gerbils were initially anesthetized with isoflurane gas anesthesia (4%) in an induction chamber. The animals were transferred post induction to a manifold and maintained at 1%–1.5% isoflurane. Subdermal electrodes (Ambu) were then placed on the animals’ scalps for the recordings. A positive electrode was placed along the vertex. The negative electrode was placed under the ipsilateral ear, along the mastoid, while the ground electrode was placed in the base of the tail. Impedances from the electrodes were always less than 1 kHz as tested using the head-stage (RA4LI, Tucker Davis Technologies (TDT)). The average duration of isoflurane anesthesia during the electrode setup process was approximately 10 min. After placing electrodes, animals were injected with dexmedetomidine (Dexdomitor, 0.3 mg/kg subdermal) and taken off the isoflurane. Dexmedetomidine is an alpha-adrenergic agonist that acts as a sedative and an analgesic and is known to decrease motivation but preserve behavioral and neural responses in rodents (<xref ref-type="bibr" rid="c102">102</xref>, <xref ref-type="bibr" rid="c103">103</xref>). This helps to maintain animals in an un-anesthetized state, where they still respond to pain stimuli, such as a foot pinch, but are otherwise compliant to recordings for a period of about 3 hours. The time window for the effects of isoflurane to wear off was determined empirically as 9 minutes, based on ABRs waveforms and latencies, as well as the response to foot pinch stimuli. Recordings then commenced 15 minutes after cessation of isoflurane.</p>
</sec>
<sec id="s4b3">
<title>Stimulus presentation, acquisition, and analysis</title>
<p>Stimuli were presented to the right ear of the animal using insert earphones (ER3C, Etymotic), which matched the stimulus presentation in humans. Stimuli presentation and acquisition were done by a custom program for gerbils in LabView. The output from the insert earphones was calibrated using a Bruel Kjaer microphone and was found to be within ±6 dB for the frequency range tested. Digitized waveforms were recorded with a multichannel recording and stimulation system (RZ-6, TDT) and analyzed with custom written programs in MATLAB (Mathworks).</p>
<p>Hearing thresholds were obtained using ABRs presented to tone stimuli that were 5 ms long, with a 2.5 ms on and off ramp, at 27.1 repetitions per second. ABRs were filtered from 300Hz to 30000Hz, and thresholds were determined as the minimum sound level that produced a response as assessed using visual inspection by two blinded, trained observers.</p>
<p>EFRs were elicited to sinusoidally AM tones (5ms rise/fall, 250ms duration, 3.1 repetitions/s, alternating polarity) at a 3KHz carrier frequency presented 30dB above auditory thresholds obtained using ABRs at 3kHz. The modulation frequency was systematically varied from 16Hz to 1024Hz AM. Responses were amplified (×10,000; TDT Medusa 4z amplifier) and filtered (0.1–3 kHz). Trials in which the response amplitude exceeded 200μV were rejected. 250 artifact-free trials of each polarity were averaged to compute the EFR waveform. FFTs were performed on the averaged time–domain waveforms starting 10ms after stimulus onset to exclude ABRs and ending at stimulus offset using custom-written programs in MATLAB (MathWorks). The maximum amplitude of the FFT peak at 1 of 3 frequency bins (∼3 Hz each) around the modulation frequency was recorded as the peak FFT amplitude. The FFT amplitude at the AM frequency was reported as the EFR amplitude. The noise floor of the EFR was calculated as the average of 5 frequency bins (∼3 Hz each) above and below the central three bins. A response was deemed as significantly above the noise floor if the FFT amplitude was at least 6 dB greater than the noise floor.</p>
</sec>
<sec id="s4b4">
<title>Immunohistology</title>
<p>Animals were transcardially perfused using a 4% paraformaldehyde solution (Sigma-Aldrich, 441244) for approximately five minutes before decapitation and isolation of the right and left cochlea. Following intra-labyrinthine perfusion with 4% paraformaldehyde, cochleas were stored in paraformaldehyde for one hour. Cochleae were decalcified in EDTA (Fisher Scientific, BP120500) for 3 to 5 days, followed by cryoprotection with sucrose (Fisher Scientific, D16500) and flash freezing. All chemicals were of reagent grade. Cochlea were thawed prior to dissection, then dissected in PBS solution. Immunostaining was accomplished by incubation with the following primary antibodies: 1) mouse anti-CtBP2 (BD Biosciences) at 1:200, 2) mouse anti-GluA2 (Millipore) at 1:2000, 3) rabbit anti-myosin VIIa (Proteus Biosciences) at 1:200; followed by incubation with secondary antibodies coupled to AlexaFluors in the red, green, and blue channels. Piece lengths were measured and converted to cochlear frequency using established cochlear maps (<xref ref-type="bibr" rid="c104">104</xref>) and custom plugins in ImageJ. Cochlear stacks were obtained at the target frequency (3kHz) spanning the cuticular plate to the synaptic pole of ∼10 hair cells (in 0.25 μm z-steps). Images were collected in a 1024 × 1024 raster using a high-resolution, oil-immersion objective (x60) and 1.59x digital zoom using a Nikon A1 confocal microscope. Images were denoised in NIS elements and loaded into an image-processing software platform (Imaris; Oxford Instruments), where inner hair cells were quantified based on their Myosin VIIa-stained cell bodies and CtBP2-stained nuclei. Presynaptic ribbons and postsynaptic glutamate receptor patches were counted using 3D representations of each confocal z-stack. Juxtaposed ribbons and receptor puncta constitute a synapse, and these synaptic associations were determined using IMARIS workflows that calculated and displayed the x–y projection of the voxel space (<xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c105">105</xref>).</p>
</sec>
</sec>
<sec id="s4c">
<title>Statistical analysis</title>
<sec id="s4c1">
<title>Analysis of Variance (ANOVA)</title>
<p>Normality of all variables was first checked visually using Q-Q plots and statistically using Shapiro-Wilks test with alpha = 0.05. Homogeneity of variance was assessed using Levene’s test. N-way ANOVAs were completed using R 2022.07.1 for each measure to determine statistically significant differences between groups (<xref ref-type="bibr" rid="c106">106</xref>). The function employed, <italic>aov</italic>, uses treatment contrasts in which the first baseline level is compared to each of the following levels. The number of factors was determined based on the conditions tested in each measure. Bonferroni corrections were used to control familywise error rate due to multiple comparisons.</p>
</sec>
<sec id="s4c2">
<title>Correlations</title>
<p>Outliers were detected using Tukey’s Fence with a boundary distance of k = 1.5 and removed. Correlations were computed using Pearson’s correlations. Degrees of freedom, <italic>r</italic>, and <italic>p-</italic>values were reported.</p>
</sec>
<sec id="s4c3">
<title>Elastic Net Regression</title>
<p>We used an linear model with an elastic net penalization/regularization (<xref ref-type="bibr" rid="c49">49</xref>) to simultaneously estimate the underlying contributions of the various predictor variables measured in our studies, and perform model selection. This approach has been previously validated for model selection using multidimensional data related to hearing pathologies like tinnitus and hyperacusis (<xref ref-type="bibr" rid="c107">107</xref>). The relative strength of selection and shrinkage is controlled by the hyper-parameters 𝜆 and 𝛼: a higher 𝜆 implies more stringent penalization pushing towards the null model, and 0 ≤ 𝛼 ≤ 1 controls the degree of convexity and hence the amount of sparsity, with 𝛼 = 0 implying a Ridge regression with no variable selection. Elastic net is a regularized regression method that minimizes the negative log-likelihood with a penalty on the parameters that combines the l<sub>1</sub> (LASSO) and l<sub>2</sub> (Ridge) penalty, i.e. the elastic net penalty on the regression parameters β can be written as 𝑃𝑒𝑛(β) = λ(α‖β‖<sub>1</sub> + (1 − α)/2‖β‖<sup>2</sup>). An elastic net regularization has several advantages over both of LASSO or Ridge as well as a simple linear model. The l<sub>1</sub> part of the elastic net (‖β‖<sub>1</sub>) leads to a sparse model where some of the coefficients are shrunk to exact zeroes, thereby performing an automatic model selection without the combinatorial computational complexities of a best-subset selection approach. Further, the quadratic l<sub>2</sub> part (‖β‖<sup>2</sup>) encourages grouped variable selection and removes the limitation of number of selected variables unlike LASSO while stablizing the selection path. To choose the tuning parameters 𝜆 and 𝛼, we used a 10-fold cross-validation that minimizes the out-of-sample root mean-squared error (RMSE). We used the R packages <italic>glmnet</italic> (<xref ref-type="bibr" rid="c108">108</xref>) and <italic>caret</italic> (<xref ref-type="bibr" rid="c109">109</xref>) for training the elastic net regularizer.</p>
</sec>
<sec id="s4c4" sec-type="data-availability">
<title>Data Availability</title>
<p>All data reported and analyzed in this study can be found on the Open Science Framework at <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.17605/OSF.IO/4BGDA">http://doi.org/10.17605/OSF.IO/4BGDA</ext-link></p>
</sec>
</sec>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>This work was supported by the National Institute on Deafness and Other Communication Disorders-National Institutes of Health Grants R21DC018882 to A.P, T32DC011499 to K. Kandler and B. yates (Trainee: M.E.Z) and F31DC020085 to J.R.M., and the PNC-Trees Charitable Trust (PNC to B.C. and A.P.). We thank Dr. Carl Snyderman for collaboration on the PNC-Trees grant, and Megan Hallihan, Kathryn Bergstrom, Sarah Anthony, and Shaina Wasileski for their assistance with participant recruitment and data collection. Thanks also to Dr. Simon Warkins, Katherine Helfrich and Mike Calderon at the Center for Biological Imaging at the University of Pittsburgh, supported by NIH grant 1S10RR028478-01 for collaboration on confocal imaging, and the Clinical and Translational Science Institute at the University of Pittsburgh, supported by the NIH Clinical and Translational Science Award (CTSA) program, grant UL1 TR001857 for assistance with participant recruitment.</p>
</ack>
<sec id="d1e1834" sec-type="additional-information">
<title>Additional information</title>
<sec id="s6">
<title>Author Contributions</title>
<p>Conceptualization: AP; Methodology: AP, BC, JM, JD; Data collection: MEZ, JK, KY, VC, OF, CM; Data analysis: MEZ, LZ, JRM, KY, VC, OF, CM; Statistical analysis: JRM, MEZ, LZ, JD; Writing: MEZ, JRM; Editing: AP, JD, BC; Supervision, Project administration: AP, BC; Funding acquisition: AP, BC, JRM</p>
</sec>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>F. R.</given-names> <surname>Lin</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Thorpe</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Gordon-Salant</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Ferrucci</surname></string-name></person-group>, <article-title>Hearing Loss Prevalence and Risk Factors Among Older Adults in the United States</article-title>. <source>J. Gerontol. Ser. -Biol. Sci. Med. Sci</source>. <volume>66</volume>, <fpage>582</fpage>–<lpage>590</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G.</given-names> <surname>Livingston</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Dementia prevention, intervention, and care</article-title>. <source>The Lancet</source> <volume>390</volume>, <fpage>2673</fpage>–<lpage>2734</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S. E.</given-names> <surname>Hind</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Prevalence of clinical referrals having hearing thresholds within normal limits</article-title>. <source>Int. J. Audiol</source>. <volume>50</volume>, <fpage>708</fpage>–<lpage>716</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K. L.</given-names> <surname>Tremblay</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Self-Reported Hearing Difficulties Among Adults With Normal Audiograms: The Beaver Dam Offspring Study</article-title>. <source>Ear Hear.</source> <volume>36</volume>, <fpage>E290</fpage>–<lpage>E299</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>V. E.</given-names> <surname>Cancel</surname></string-name>, <string-name><given-names>J. R.</given-names> <surname>McHaney</surname></string-name>, <string-name><given-names>V.</given-names> <surname>Milne</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Palmer</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Parthasarathy</surname></string-name></person-group>, <article-title>A data-driven approach to identify a rapid screener for auditory processing disorder testing referrals in adults</article-title>. <source>Sci. Rep</source>. <volume>13</volume>, <fpage>13636</fpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Parthasarathy</surname></string-name>, <string-name><given-names>K. E.</given-names> <surname>Hancock</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Bennett</surname></string-name>, <string-name><given-names>V.</given-names> <surname>DeGruttola</surname></string-name>, <string-name><given-names>D. B.</given-names> <surname>Polley</surname></string-name></person-group>, <article-title>Bottom-up and top-down neural signatures of disordered multi-talker speech perception in adults with normal hearing</article-title>. <source>eLife</source> <volume>9</volume>, <elocation-id>e51419</elocation-id> (<year>2020</year>). <pub-id pub-id-type="doi">10.7554/eLife.51419</pub-id></mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S. G.</given-names> <surname>Kujawa</surname></string-name>, <string-name><given-names>M. C.</given-names> <surname>Liberman</surname></string-name></person-group>, <article-title>Adding Insult to Injury: Cochlear Nerve Degeneration after “Temporary” Noise-Induced Hearing Loss</article-title>. <source>J. Neurosci</source>. <volume>29</volume>, <fpage>14077</fpage>–<lpage>14085</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R.</given-names> <surname>Schaette</surname></string-name>, <string-name><given-names>D.</given-names> <surname>McAlpine</surname></string-name></person-group>, <article-title>Tinnitus with a Normal Audiogram: Physiological Evidence for Hidden Hearing Loss and Computational Model</article-title>. <source>J. Neurosci</source>. <volume>31</volume>, <fpage>13452</fpage>–<lpage>13457</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>P. Z.</given-names> <surname>Wu</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Primary Neural Degeneration in the Human Cochlea: Evidence for Hidden Hearing Loss in the Aging Ear</article-title>. <source>Neuroscience</source> (<year>2018</year>). <pub-id pub-id-type="doi">10.1016/j.neuroscience.2018.07.053</pub-id>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>P.</given-names> <surname>Wu</surname></string-name>, <string-name><given-names>J. T.</given-names> <surname>O’Malley</surname></string-name>, <string-name><given-names>M. C.</given-names> <surname>Liberman</surname></string-name></person-group>, <article-title>Neural Degeneration in Normal-Aging Human Cochleas: Machine-Learning Counts and 3D Mapping in Archival Sections</article-title>. <source>J. Assoc. Res. Otolaryngol</source>. (<year>2023</year>). <pub-id pub-id-type="doi">10.1007/s10162-023-00909-y</pub-id>.</mixed-citation></ref>
    <ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>P.-Z.</given-names> <surname>Wu</surname></string-name>, <string-name><given-names>J. T.</given-names> <surname>O’Malley</surname></string-name>, <string-name><given-names>V.</given-names> <surname>de Gruttola</surname></string-name>, <string-name><given-names>M. C.</given-names> <surname>Liberman</surname></string-name></person-group>, <article-title>Age-Related Hearing Loss Is Dominated by Damage to Inner Ear Sensory Cells, Not the Cellular Battery That Powers Them</article-title>, <source>J. Neurosci. Off. J. Soc. Neurosci</source>. <volume>40</volume>, <fpage>6357</fpage>–<lpage>6366</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Parthasarathy</surname></string-name>, <string-name><given-names>S. G.</given-names> <surname>Kujawa</surname></string-name></person-group>, <article-title>Synaptopathy in the Aging Cochlea: Characterizing Early-Neural Deficits in Auditory Temporal Envelope Processing</article-title>. <source>J. Neurosci. Off. J. Soc. Neurosci</source>. <volume>38</volume>, <fpage>7108</fpage>– <lpage>7119</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. M.</given-names> <surname>Mepani</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Envelope following responses predict speech-in-noise performance in normal-hearing listeners</article-title>. <source>J. Neurophysiol</source>. <volume>125</volume>, <fpage>1213</fpage>–<lpage>1222</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>L. A.</given-names> <surname>Shaheen</surname></string-name>, <string-name><given-names>M. D.</given-names> <surname>Valero</surname></string-name>, <string-name><given-names>M. C.</given-names> <surname>Liberman</surname></string-name></person-group>, <article-title>Towards a Diagnosis of Cochlear Neuropathy with Envelope Following Responses</article-title>. <source>J Assoc Res Otolaryngol</source> (<year>2015</year>). <pub-id pub-id-type="doi">10.1007/s10162-015-0539-3</pub-id>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G.</given-names> <surname>Prendergast</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Effects of noise exposure on young adults with normal audiograms I: Electrophysiology</article-title>. <source>Hear. Res</source>. <volume>344</volume>, <fpage>68</fpage>–<lpage>81</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H.</given-names> <surname>Guest</surname></string-name>, <string-name><given-names>K. J.</given-names> <surname>Munro</surname></string-name>, <string-name><given-names>C. J.</given-names> <surname>Plack</surname></string-name></person-group>, <article-title>Tinnitus with a normal audiogram: Role of high-frequency sensitivity and reanalysis of brainstem-response measures to avoid audiometric over-matching</article-title>. <source>Hear. Res</source>. <volume>356</volume>, <fpage>116</fpage>–<lpage>117</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K. J.</given-names> <surname>Grant</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Electrophysiological markers of cochlear function correlate with hearing-in-noise performance among audiometrically normal subjects</article-title>. <source>J. Neurophysiol</source>. <volume>124</volume>, <fpage>418</fpage>–<lpage>431</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K. J.</given-names> <surname>Grant</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Predicting neural deficits in sensorineural hearing loss from word recognition scores</article-title>. <source>Sci. Rep</source>. <volume>12</volume>, <fpage>8929</fpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. D.</given-names> <surname>Valero</surname></string-name>, <string-name><given-names>K. E.</given-names> <surname>Hancock</surname></string-name>, <string-name><given-names>S. F.</given-names> <surname>Maison</surname></string-name>, <string-name><given-names>M. C.</given-names> <surname>Liberman</surname></string-name></person-group>, <article-title>Effects of cochlear synaptopathy on middle-ear muscle reflexes in unanesthetized mice</article-title>. <source>Hear. Res</source>. <volume>363</volume>, <fpage>109</fpage>–<lpage>118</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G.</given-names> <surname>Mehraei</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Auditory Brainstem Response Latency in Noise as a Marker of Cochlear Synaptopathy</article-title>. <source>J. Neurosci</source>. <volume>36</volume>, <fpage>3755</fpage>–<lpage>3764</lpage> (<year>2016</year>).</mixed-citation></ref>
    <ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H. M.</given-names> <surname>Bharadwaj</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Cross-species experiments reveal widespread cochlear neural damage in normal hearing</article-title>. <source>Commun Biol</source>. <volume>5</volume>, <fpage>1</fpage>–<lpage>10</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B. N.</given-names> <surname>Buran</surname></string-name>, <string-name><given-names>G. P.</given-names> <surname>McMillan</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Keshishzadeh</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Verhulst</surname></string-name>, <string-name><given-names>N. F.</given-names> <surname>Bramhall</surname></string-name></person-group>, <article-title>Predicting synapse counts in living humans by combining computational models with auditory physiology</article-title>. <source>J. Acoust. Soc. Am</source>. <volume>151</volume>, <issue>561</issue> (<year>2022</year>).</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G.</given-names> <surname>Prendergast</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Effects of noise exposure on young adults with normal audiograms II: Behavioral measures</article-title>. <source>Hear. Res</source>. <volume>356</volume>, <fpage>74</fpage>–<lpage>86</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. M.</given-names> <surname>Mepani</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Middle Ear Muscle Reflex and Word Recognition in “Normal-Hearing” Adults: Evidence for Cochlear Synaptopathy?</article-title> <source>Ear Hear</source>. (<year>2019</year>). <pub-id pub-id-type="doi">10.1097/AUD.0000000000000804</pub-id>.</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. K.</given-names> <surname>Pichora-Fuller</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Hearing Impairment and Cognitive Energy: The Framework for Understanding Effortful Listening (FUEL)</article-title>. <source>Ear Hear</source>. <volume>37</volume>, <fpage>5S</fpage>–<lpage>27S</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. E.</given-names> <surname>Peelle</surname></string-name></person-group>, <article-title>Listening Effort: How the Cognitive Consequences of Acoustic Challenge Are Reflected in Brain and Behavior</article-title>. <source>Ear Hear</source>. <volume>39</volume>, <fpage>204</fpage>–<lpage>214</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. A.</given-names> <surname>Zekveld</surname></string-name>, <string-name><given-names>S. E.</given-names> <surname>Kramer</surname></string-name>, <string-name><given-names>J. M.</given-names> <surname>Festen</surname></string-name></person-group>, <article-title>Cognitive Load During Speech Perception in Noise: The Influence of Age, Hearing Loss, and Cognition on the Pupil Response</article-title>. <source>Ear Hear</source>. <volume>32</volume>, <fpage>498</fpage>–<lpage>510</lpage> (<year>2011</year>).</mixed-citation></ref>
    <ref id="c28"><label>28.</label><mixed-citation publication-type="web"><person-group person-group-type="author"><collab>WHO</collab></person-group><article-title>International Classification of Functioning, Disability and Health (ICF)</article-title>. Available at: <ext-link ext-link-type="uri" xlink:href="https://www.who.int/standards/classifications/international-classification-of-functioning-disability-and-health">https://www.who.int/standards/classifications/international-classification-of-functioning-disability-and-health</ext-link> [Accessed 4 April 2024]. <year>no date</year></mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Škerková</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Extended high-frequency audiometry: hearing thresholds in adults</article-title>. <source>Eur. Arch. Otorhinolaryngol</source>. <volume>280</volume>, <fpage>565</fpage>–<lpage>572</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S. K.</given-names> <surname>Mishra</surname></string-name>, <string-name><given-names>U.</given-names> <surname>Saxena</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Rodrigo</surname></string-name></person-group>, <article-title>Extended High-frequency Hearing Impairment Despite a Normal Audiogram: Relation to Early Aging, Speech-in-noise Perception, Cochlear Function, and Routine Earphone Use</article-title>. <source>Ear Hear</source>. <volume>43</volume>, <fpage>822</fpage>–<lpage>835</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Lough</surname></string-name>, <string-name><given-names>C. J.</given-names> <surname>Plack</surname></string-name></person-group>, <article-title>Extended high-frequency audiometry in research and clinical practice</article-title>. <source>J. Acoust. Soc. Am</source>. <volume>151</volume>, <fpage>1944</fpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>C. W.</given-names> <surname>Newman</surname></string-name>, <string-name><given-names>G. P.</given-names> <surname>Jacobson</surname></string-name>, <string-name><given-names>J. B.</given-names> <surname>Spitzer</surname></string-name></person-group>, <article-title>Development of the Tinnitus Handicap Inventory</article-title>. <source>Arch. Otolaryngol. Head Neck Surg</source>. <volume>122</volume>, <fpage>143</fpage>–<lpage>148</lpage> (<year>1996</year>).</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>L. P.</given-names> <surname>Sherlock</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Formby</surname></string-name></person-group>, <article-title>Estimates of loudness, loudness discomfort, and the auditory dynamic range: normative estimates, comparison of procedures, and test-retest reliability</article-title>. <source>J. Am. Acad. Audiol</source>. <volume>16</volume>, <fpage>85</fpage>–<lpage>100</lpage> (<year>2005</year>).</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>T. A.</given-names> <surname>Johnson</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Cooper</surname></string-name>, <string-name><given-names>G. C.</given-names> <surname>Stamper</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Chertoff</surname></string-name></person-group>, <article-title>Noise Exposure Questionnaire (NEQ): A Tool for Quantifying Annual Noise Exposure</article-title>. <source>J. Am. Acad. Audiol</source>. <volume>28</volume>, <fpage>14</fpage>–<lpage>35</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Z. S.</given-names> <surname>Nasreddine</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>The Montreal Cognitive Assessment, MoCA: a brief screening tool for mild cognitive impairment</article-title>. <source>J. Am. Geriatr. Soc.</source> <volume>53</volume>, <fpage>695</fpage>–<lpage>699</lpage> (<year>2005</year>).</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. L.</given-names> <surname>Turner</surname></string-name>, <string-name><given-names>R. W.</given-names> <surname>Engle</surname></string-name></person-group>, <article-title>Is working memory capacity task dependent?</article-title> <source>J. Mem. Lang</source>. <volume>28</volume>, <fpage>127</fpage>– <lpage>154</lpage> (<year>1989</year>).</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. M.</given-names> <surname>Mepani</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Envelope following responses predict speech-in-noise performance in normal-hearing listeners</article-title>. <source>J. Neurophysiol</source>. <volume>125</volume>, <fpage>1213</fpage>–<lpage>1222</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Parthasarathy</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Bartlett</surname></string-name></person-group>, <article-title>Two-channel recording of auditory-evoked potentials to detect age-related deficits in temporal processing</article-title>. <source>Hear. Res</source>. <volume>289</volume>, <fpage>52</fpage>–<lpage>62</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Ryan</surname></string-name></person-group>, <article-title>Hearing sensitivity of the mongolian gerbil, Meriones unguiculatis</article-title>. <source>J. Acoust. Soc. Am</source>. <volume>59</volume>, <fpage>1222</fpage>–<lpage>1226</lpage> (<year>1976</year>).</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. C.</given-names> <surname>Killion</surname></string-name>, <string-name><given-names>P. A.</given-names> <surname>Niquette</surname></string-name>, <string-name><given-names>G. I.</given-names> <surname>Gudmundsen</surname></string-name>, <string-name><given-names>L. J.</given-names> <surname>Revit</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Banerjee</surname></string-name></person-group>, <article-title>Development of a quick speech-in-noise test for measuring signal-to-noise ratio loss in normal-hearing and hearing-impaired listeners</article-title>. <source>J. Acoust. Soc. Am</source>. <volume>116</volume>, <fpage>2395</fpage>–<lpage>2405</lpage> (<year>2004</year>).</mixed-citation></ref>
    <ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names> <surname>Beatty</surname></string-name></person-group>, <article-title>Phasic not tonic pupillary responses vary with auditory vigilance performance</article-title>. <source>Psychophysiology</source> <volume>19</volume>, <fpage>167</fpage>–<lpage>172</lpage> (<year>1982</year>).</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. B.</given-names> <surname>Winn</surname></string-name>, <string-name><given-names>J. R.</given-names> <surname>Edwards</surname></string-name>, <string-name><given-names>R. Y.</given-names> <surname>Litovsky</surname></string-name></person-group>, <article-title>The Impact of Auditory Spectral Resolution on Listening Effort Revealed by Pupil Dilation</article-title>. <source>Ear Hear</source>. <volume>36</volume>, <fpage>e153</fpage>–<lpage>e165</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S. E.</given-names> <surname>Kuchinsky</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Pupil size varies with word listening and response selection difficulty in older adults with hearing loss</article-title>. <source>Psychophysiology</source> <volume>50</volume>, <fpage>23</fpage>–<lpage>34</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>D.</given-names> <surname>Mirman</surname></string-name></person-group>, <source>Growth Curve Analysis and Visualization Using R</source> (<publisher-name>Chapman and Hall/CRC</publisher-name>, <year>2014</year>).</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. R.</given-names> <surname>McHaney</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Tessmer</surname></string-name>, <string-name><given-names>C. L.</given-names> <surname>Roark</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Chandrasekaran</surname></string-name></person-group>, <article-title>Working memory relates to individual differences in speech category learning: Insights from computational modeling and pupillometry</article-title>. <source>Brain Lang</source>. <volume>222</volume>, <fpage>105010</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S. E.</given-names> <surname>Kuchinsky</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Speech-perception training for older adults with hearing loss impacts word recognition and effort</article-title>. <source>Psychophysiology</source> <volume>51</volume>, <fpage>1046</fpage>–<lpage>1057</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. B.</given-names> <surname>Winn</surname></string-name></person-group>, <article-title>Time Scales and Moments of Listening Effort Revealed in Pupillometry</article-title>. <source>Semin. Hear</source>. <volume>44</volume>, <fpage>106</fpage>–<lpage>123</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. R.</given-names> <surname>McHaney</surname></string-name>, <string-name><given-names>K. E.</given-names> <surname>Hancock</surname></string-name>, <string-name><given-names>D. B.</given-names> <surname>Polley</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Parthasarathy</surname></string-name></person-group>, <article-title>Sensory representations and pupil-indexed listening effort provide complementary contributions to multi-talker speech intelligibility</article-title>. <source>Sci. Rep</source>. <volume>14</volume>, <fpage>30882</fpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H.</given-names> <surname>Zou</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Hastie</surname></string-name></person-group>, <article-title>Regularization and Variable Selection Via the Elastic Net</article-title>. <source>J. R. Stat. Soc. Ser. B Stat. Methodol</source>. <volume>67</volume>, <fpage>301</fpage>–<lpage>320</lpage> (<year>2005</year>).</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names> <surname>Dohm-Hansen</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>The “middle-aging” brain</article-title>. <source>Trends Neurosci</source>. <volume>0</volume> (<year>2024</year>).</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>N.</given-names> <surname>Schaum</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Ageing hallmarks exhibit organ-specific temporal signatures</article-title>. <source>Nature</source> <volume>583</volume>, <fpage>596</fpage>– <lpage>602</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>T. A.</given-names> <surname>Salthouse</surname></string-name></person-group>, <article-title>Trajectories of normal cognitive aging</article-title>. <source>Psychol. Aging</source> <volume>34</volume>, <fpage>17</fpage>–<lpage>24</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. L.</given-names> <surname>Elliott</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Brain-age in midlife is associated with accelerated biological aging and cognitive decline in a longitudinal birth cohort</article-title>. <source>Mol. Psychiatry</source> <volume>26</volume>, <fpage>3829</fpage>–<lpage>3838</lpage> (<year>2021</year>).</mixed-citation></ref>
    <ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. L.</given-names> <surname>Elliott</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Disparities in the pace of biological aging among midlife adults of the same chronological age have implications for future frailty risk and policy</article-title>. <source>Nat Aging</source> <volume>1</volume>, <fpage>295</fpage>–<lpage>308</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. L.</given-names> <surname>Hughes</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Agrigoroaei</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Jeon</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Bruzzese</surname></string-name>, <string-name><given-names>M. E.</given-names> <surname>Lachman</surname></string-name></person-group>, <article-title>Change in Cognitive Performance From Midlife Into Old Age: Findings from the Midlife in the United States (MIDUS) Study</article-title>. <source>J. Int. Neuropsychol. Soc</source>. <volume>24</volume>, <fpage>805</fpage>–<lpage>820</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B. P.</given-names> <surname>Spehar</surname></string-name>, <string-name><given-names>J. T.</given-names> <surname>Lichtenhan</surname></string-name></person-group>, <article-title>Patients With Normal Hearing Thresholds but Difficulty Hearing in Noisy Environments: A Study on the Willingness to Try Auditory Training</article-title>. <source>Otol. Neurotol. Off. Publ. Am. Otol. Soc. Am. Neurotol. Soc. Eur. Acad. Otol. Neurotol</source>. <volume>39</volume>, <fpage>950</fpage>–<lpage>956</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B. D.</given-names> <surname>Auerbach</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Radziwon</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Salvi</surname></string-name></person-group>, <article-title>Testing the Central Gain Model: Loudness Growth Correlates with Central Auditory Gain Enhancement in a Rodent Model of Hyperacusis</article-title>. <source>Neuroscience</source> <volume>407</volume>, <fpage>93</fpage>–<lpage>107</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. R.</given-names> <surname>Chambers</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Central Gain Restores Auditory Processing following Near-Complete Cochlear Denervation</article-title>. <source>Neuron</source> <volume>89</volume>, <fpage>867</fpage>–<lpage>879</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names> <surname>Resnik</surname></string-name>, <string-name><given-names>D. B.</given-names> <surname>Polley</surname></string-name></person-group>, <article-title>Cochlear neural degeneration disrupts hearing in background noise by increasing auditory cortex internal noise</article-title>. <source>Neuron</source> <volume>109</volume>, <fpage>984</fpage>–<lpage>996.e4</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H. M.</given-names> <surname>Bharadwaj</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Masud</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Mehraei</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Verhulst</surname></string-name>, <string-name><given-names>B. G.</given-names> <surname>Shinn-Cunningham</surname></string-name></person-group>, <article-title>Individual Differences Reveal Correlates of Hidden Hearing Deficits</article-title>. <source>J. Neurosci</source>. <volume>35</volume>, <fpage>2161</fpage>–<lpage>2172</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>N.</given-names> <surname>Bramhall</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>The search for noise-induced cochlear synaptopathy in humans: Mission impossible?</article-title> <source>Hear. Res</source>. <volume>377</volume>, <fpage>88</fpage>–<lpage>103</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H.</given-names> <surname>Bharadwaj M</surname></string-name>., <etal>et al.</etal></person-group>, <article-title>Non-Invasive Assays of Cochlear Synaptopathy - Candidates and Considerations</article-title>. <source>Neuroscience</source> <volume>407</volume>, <fpage>53</fpage>–<lpage>66</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c63"><label>63.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Y.</given-names> <surname>Sergeyenko</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Lall</surname></string-name>, <string-name><given-names>M. C.</given-names> <surname>Liberman</surname></string-name>, <string-name><given-names>S. G.</given-names> <surname>Kujawa</surname></string-name></person-group>, <article-title>Age-Related Cochlear Synaptopathy: An Early-Onset Contributor to Auditory Functional Decline</article-title>. <source>J. Neurosci</source>. <volume>33</volume>, <fpage>13686</fpage>–<lpage>13694</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c64"><label>64.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. D.</given-names> <surname>Valero</surname></string-name>, <string-name><given-names>K. E.</given-names> <surname>Hancock</surname></string-name>, <string-name><given-names>M. C.</given-names> <surname>Liberman</surname></string-name></person-group>, <article-title>The middle ear muscle reflex in the diagnosis of cochlear neuropathy</article-title>. <source>Hear. Res</source>. <volume>332</volume>, <fpage>29</fpage>–<lpage>38</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c65"><label>65.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>P. X.</given-names> <surname>Joris</surname></string-name>, <string-name><given-names>C. E.</given-names> <surname>Schreiner</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Rees</surname></string-name></person-group>, <article-title>Neural processing of amplitude-modulated sounds</article-title>. <source>Physiol. Rev</source>. <volume>84</volume>, <fpage>541</fpage>–<lpage>577</lpage> (<year>2004</year>).</mixed-citation></ref>
    <ref id="c66"><label>66.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names> <surname>Parida</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Rapid and objective assessment of auditory temporal processing using dynamic amplitude-modulated stimuli</article-title>. <source>Commun Biol</source>. <volume>7</volume>, <fpage>1</fpage>–<lpage>10</lpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c67"><label>67.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>V.</given-names> <surname>Vasilkov</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Garrett</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Mauermann</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Verhulst</surname></string-name></person-group>, <article-title>Enhancing the sensitivity of the envelope-following response for cochlear synaptopathy screening in humans: The role of stimulus envelope</article-title>. <source>Hear. Res</source>. <volume>400</volume>, <fpage>108132</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c68"><label>68.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Garrett</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Deciphering Compromised Speech-in-Noise Intelligibility in Older Listeners: The Role of Cochlear Synaptopathy</article-title>. <source>eNeuro</source> <volume>12</volume> (<year>2025</year>).</mixed-citation></ref>
<ref id="c69"><label>69.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Parthasarathy</surname></string-name>, <string-name><given-names>E. L.</given-names> <surname>Bartlett</surname></string-name></person-group>, <article-title>Age-related Auditory Deficits in Temporal Processing in F-344 Rats</article-title>. <source>Neuroscience</source> <volume>192</volume>, <fpage>619</fpage>–<lpage>630</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c70"><label>70.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K.</given-names> <surname>Dougherty</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Hustedt-Mai</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Hagedorn</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Bharadwaj</surname></string-name></person-group>, <article-title>Central gain in aging, tinnitus, and temporary hearing loss</article-title>. <source>J. Acoust. Soc. Am</source>. <volume>150</volume>, <fpage>A341</fpage>–<lpage>A341</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c71"><label>71.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. A.</given-names> <surname>Rumschlag</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Age-Related Central Gain with Degraded Neural Synchrony in the Auditory Brainstem of Mice and Humans</article-title>. <source>Neurobiol. Aging</source> <volume>115</volume>, <fpage>50</fpage>–<lpage>59</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c72"><label>72.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Parthasarathy</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Lai</surname></string-name>, <string-name><given-names>E. L.</given-names> <surname>Bartlett</surname></string-name></person-group>, <article-title>Age-Related Changes in Processing Simultaneous Amplitude Modulated Sounds Assessed Using Envelope Following Responses</article-title>. <source>Jaro-J. Assoc. Res. Otolaryngol</source>. <volume>17</volume>, <fpage>119</fpage>–<lpage>132</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c73"><label>73.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names> <surname>Lai</surname></string-name>, <string-name><given-names>E. L.</given-names> <surname>Bartlett</surname></string-name></person-group>, <article-title>Masking Differentially Affects Envelope-following Responses in Young and Aged Animals</article-title>. <source>Neuroscience</source> <volume>386</volume>, <fpage>150</fpage>–<lpage>165</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c74"><label>74.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names> <surname>Märcher-Rørsted</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Age-related reduction in frequency-following responses as a potential marker of cochlear neural degeneration</article-title>. <source>Hear. Res</source>. <volume>414</volume>, <issue>108411</issue> (<year>2022</year>).</mixed-citation></ref>
    <ref id="c75"><label>75.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>E.</given-names> <surname>Ponsot</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Devolder</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Dhooge</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Verhulst</surname></string-name></person-group>, <article-title>Age-related decline in neural phase-locking to envelope and temporal fine structure revealed by frequency following responses: A potential signature of cochlear synaptopathy impairing speech intelligibility</article-title>. <source>bioRxiv</source> (<year>2024</year>). <pub-id pub-id-type="doi">10.1101/2024.12.11.628010</pub-id>.</mixed-citation></ref>
    <ref id="c76"><label>76.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. A.</given-names> <surname>Gratton</surname></string-name>, <string-name><given-names>B. A.</given-names> <surname>Schulte</surname></string-name></person-group>, <article-title>Alterations in microvasculature are associated with atrophy of the stria vascularis in quiet-aged gerbils</article-title>. <source>Hear. Res</source>. <volume>82</volume>, <fpage>44</fpage>–<lpage>52</lpage> (<year>1995</year>).</mixed-citation></ref>
<ref id="c77"><label>77.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>V. A.</given-names> <surname>Brown</surname></string-name>, <string-name><given-names>D. J.</given-names> <surname>McLaughlin</surname></string-name>, <string-name><given-names>J. F.</given-names> <surname>Strand</surname></string-name>, <string-name><given-names>K. J.</given-names> <surname>Van Engen</surname></string-name></person-group>, <article-title>Rapid adaptation to fully intelligible nonnative-accented speech reduces listening effort</article-title>. <source>Q. J. Exp. Psychol. 2006</source> <volume>73</volume>, <fpage>1431</fpage>–<lpage>1443</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c78"><label>78.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. J.</given-names> <surname>McGinley</surname></string-name>, <string-name><given-names>S. V.</given-names> <surname>David</surname></string-name>, <string-name><given-names>D. A.</given-names> <surname>McCormick</surname></string-name></person-group>, <article-title>Cortical Membrane Potential Signature of Optimal States for Sensory Signal Detection</article-title>. <source>Neuron</source> <volume>87</volume>, <fpage>179</fpage>–<lpage>192</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c79"><label>79.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J. W.</given-names> <surname>de Gee</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Pupil-linked phasic arousal predicts a reduction of choice bias across species and decision domains</article-title>. <source>eLife</source> <volume>9</volume>, <elocation-id>e54014</elocation-id> (<year>2020</year>). <pub-id pub-id-type="doi">10.7554/eLife.54014</pub-id></mixed-citation></ref>
<ref id="c80"><label>80.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names> <surname>Joshi</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Li</surname></string-name>, <string-name><given-names>R. M.</given-names> <surname>Kalwani</surname></string-name>, <string-name><given-names>J. I.</given-names> <surname>Gold</surname></string-name></person-group>, <article-title>Relationships between Pupil Diameter and Neuronal Activity in the Locus Coeruleus, Colliculi, and Cingulate Cortex</article-title>. <source>Neuron</source> <volume>89</volume>, <fpage>221</fpage>–<lpage>234</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c81"><label>81.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names> <surname>Reimer</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Pupil fluctuations track rapid changes in adrenergic and cholinergic activity in cortex</article-title>. <source>Nat. Commun</source>. <volume>7</volume>, <issue>13289</issue> (<year>2016</year>).</mixed-citation></ref>
<ref id="c82"><label>82.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B. W. Y.</given-names> <surname>Hornsby</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Naylor</surname></string-name>, <string-name><given-names>F. H.</given-names> <surname>Bess</surname></string-name></person-group>, <article-title>A Taxonomy of Fatigue Concepts and Their Relation to Hearing Loss</article-title>. <source>Ear Hear</source>. <volume>37</volume>, <fpage>136S</fpage>–<lpage>144S</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c83"><label>83.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B. W. Y.</given-names> <surname>Hornsby</surname></string-name></person-group>, <article-title>The effects of hearing aid use on listening effort and mental fatigue associated with sustained speech processing demands</article-title>. <source>Ear Hear</source>. <volume>34</volume>, <fpage>523</fpage>–<lpage>534</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c84"><label>84.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>H. H.</given-names> <surname>Telek</surname></string-name></person-group>, <article-title>The Effects of Age Pupil Diameters at Different Light Amplitudes</article-title>. <source>Beyoglu Eye J</source>. (<year>2018</year>). <pub-id pub-id-type="doi">10.14744/bej.2018.43534</pub-id>.</mixed-citation></ref>
<ref id="c85"><label>85.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>T.</given-names> <surname>Piquado</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Isaacowitz</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Wingfield</surname></string-name></person-group>, <article-title>Pupillometry as a measure of cognitive effort in younger and older adults</article-title>. <source>Psychophysiology</source> <volume>47</volume>, <fpage>560</fpage>–<lpage>569</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c86"><label>86.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>W. W.</given-names> <surname>Tryon</surname></string-name></person-group>, <article-title>Pupillometry: A Survey of Sources of Variation</article-title>. <source>Psychophysiology</source> <volume>12</volume>, <fpage>90</fpage>–<lpage>93</lpage> (<year>1975</year>).</mixed-citation></ref>
<ref id="c87"><label>87.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. S.</given-names> <surname>Ansari</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Vehof</surname></string-name>, <string-name><given-names>C. J.</given-names> <surname>Hammond</surname></string-name>, <string-name><given-names>F. D.</given-names> <surname>Bremner</surname></string-name>, <string-name><given-names>K. M.</given-names> <surname>Williams</surname></string-name></person-group>, <article-title>Evidence That Pupil Size and Reactivity Are Determined More by Your Parents Than by Your Environment</article-title>. <source>Front. Neurol</source>. <volume>12</volume> (<year>2021</year>).</mixed-citation></ref>
<ref id="c88"><label>88.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>L. L.</given-names> <surname>Hunter</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Extended high frequency hearing and speech perception implications in adults and children</article-title>. <source>Hear. Res</source>. <volume>397</volume>, <fpage>107922</fpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c89"><label>89.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B. G.</given-names> <surname>Shinn-Cunningham</surname></string-name>, <string-name><given-names>V.</given-names> <surname>Best</surname></string-name></person-group>, <article-title>Selective attention in normal and impaired hearing</article-title>. <source>Trends Amplif</source>. <volume>12</volume>, <fpage>283</fpage>–<lpage>299</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c90"><label>90.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D. J.</given-names> <surname>McLaughlin</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Pupillometry reveals cognitive demands of lexical competition during spoken word recognition in young and older adults</article-title>. <source>Psychon. Bull. Rev</source>. <volume>29</volume>, <fpage>268</fpage>–<lpage>280</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c91"><label>91.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. T.</given-names> <surname>Beck</surname></string-name>, <string-name><given-names>R. A.</given-names> <surname>Steer</surname></string-name>, <string-name><given-names>M. G.</given-names> <surname>Carbin</surname></string-name></person-group>, <article-title>Psychometric properties of the Beck Depression Inventory: Twenty-five years of evaluation</article-title>. <source>Clin. Psychol. Rev</source>. <volume>8</volume>, <fpage>77</fpage>–<lpage>100</lpage> (<year>1988</year>).</mixed-citation></ref>
<ref id="c92"><label>92.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>N.</given-names> <surname>Unsworth</surname></string-name>, <string-name><given-names>R. P.</given-names> <surname>Heitz</surname></string-name>, <string-name><given-names>J. C.</given-names> <surname>Schrock</surname></string-name>, <string-name><given-names>R. W.</given-names> <surname>Engle</surname></string-name></person-group>, <article-title>An automated version of the operation span task</article-title>. <source>Behav. Res. Methods</source> <volume>37</volume>, <fpage>498</fpage>–<lpage>505</lpage> (<year>2005</year>).</mixed-citation></ref>
<ref id="c93"><label>93.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names> <surname>Meyer</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Dentel</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Meunier</surname></string-name></person-group>, <article-title>Speech recognition in natural background noise</article-title>. <source>PloS One</source> <volume>8</volume>, <fpage>e79279</fpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c94"><label>94.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R. H.</given-names> <surname>Wilson</surname></string-name>, <string-name><given-names>H. B.</given-names> <surname>Abrams</surname></string-name>, <string-name><given-names>A. L.</given-names> <surname>Pillion</surname></string-name></person-group>, <article-title>A word-recognition task in multitalker babble using a descending presentation mode from 24 dB to 0 dB signal to babble</article-title>. <source>J. Rehabil. Res. Dev</source>. <volume>40</volume>, <fpage>321</fpage> (<year>2003</year>).</mixed-citation></ref>
<ref id="c95"><label>95.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A. A.</given-names> <surname>Zekveld</surname></string-name>, <string-name><given-names>J. M.</given-names> <surname>Festen</surname></string-name>, <string-name><given-names>S. E.</given-names> <surname>Kramer</surname></string-name></person-group>, <article-title>Task Difficulty Differentially Affects Two Measures of Processing Load: The Pupil Response During Sentence Processing and Delayed Cued Recall of the Sentences</article-title>. <source>J. Speech Lang. Hear. Res</source>. <volume>56</volume>, <fpage>1156</fpage>–<lpage>1165</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c96"><label>96.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M. B.</given-names> <surname>Winn</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Wendt</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Koelewijn</surname></string-name>, <string-name><given-names>S. E.</given-names> <surname>Kuchinsky</surname></string-name></person-group>, <article-title>Best Practices and Advice for Using Pupillometry to Measure Listening Effort: An Introduction for Those Who Want to Get Started</article-title>. <source>Trends Hear</source>. <volume>22</volume>, <issue>2331216518800869</issue> (<year>2018</year>).</mixed-citation></ref>
<ref id="c97"><label>97.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>T.</given-names> <surname>Koelewijn</surname></string-name>, <string-name><given-names>A. A.</given-names> <surname>Zekveld</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Lunner</surname></string-name>, <string-name><given-names>S. E.</given-names> <surname>Kramer</surname></string-name></person-group>, <article-title>The effect of reward on listening effort as reflected by the pupil dilation response</article-title>. <source>Hear. Res</source>. <volume>367</volume>, <fpage>106</fpage>–<lpage>112</lpage> (<year>2018</year>).</mixed-citation></ref>
    <ref id="c98"><label>98.</label><mixed-citation publication-type="software"><person-group person-group-type="author"><collab>R Core Team</collab></person-group> <article-title>R: a language and environment for statistical computing</article-title> (<year>2022</year>). <publisher-name>R Foundation for Statistical Computing</publisher-name> <publisher-loc>Vienna, Austria</publisher-loc> Available at: <ext-link ext-link-type="uri" xlink:href="https://www.r-project.org/">https://www.r-project.org/</ext-link> [Accessed 11 December 2022].</mixed-citation></ref>
<ref id="c99"><label>99.</label><mixed-citation publication-type="software"><person-group person-group-type="author"><string-name><given-names>S.</given-names> <surname>Barthelme</surname></string-name></person-group>, <article-title>eyelinker: An R package for importing data from EyeLink ASC files</article-title>. <source>GitHub</source>  Available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/a-hurst/eyelinker">https://github.com/a-hurst/eyelinker</ext-link> [Accessed 22 July 2024]. <year>2021</year></mixed-citation></ref>
<ref id="c100"><label>100.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D.</given-names> <surname>Bates</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Mächler</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Bolker</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Walker</surname></string-name></person-group>, <article-title>Fitting Linear Mixed-Effects Models Using lme4</article-title>. <source>J. Stat. Softw</source>. <volume>67</volume>, <fpage>1</fpage>–<lpage>48</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c101"><label>101.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A.</given-names> <surname>Kuznetsova</surname></string-name>, <string-name><given-names>P. B.</given-names> <surname>Brockhoff</surname></string-name>, <string-name><given-names>R. H. B.</given-names> <surname>Christensen</surname></string-name></person-group>, <article-title>lmerTest Package: Tests in Linear Mixed Effects Models</article-title>. <source>J. Stat. Softw</source>. <volume>82</volume>, <fpage>1</fpage>–<lpage>26</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c102"><label>102.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S.</given-names> <surname>Ruotsalainen</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Haapalinna</surname></string-name>, <string-name><given-names>P. J.</given-names> <surname>Riekkinen</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Sirviö</surname></string-name></person-group>, <article-title>Dexmedetomidine Reduces Response Tendency, but Not Accuracy of Rats in Attention and Short-Term Memory Tasks</article-title>. <source>Pharmacol. Biochem. Behav</source>. <volume>56</volume>, <fpage>31</fpage>–<lpage>40</lpage> (<year>1997</year>).</mixed-citation></ref>
<ref id="c103"><label>103.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Ter-Mikaelian</surname></string-name>, <string-name><given-names>M. N.</given-names> <surname>Semple</surname></string-name>, <string-name><given-names>D. H.</given-names> <surname>Sanes</surname></string-name></person-group>, <article-title>Effects of spectral and temporal disruption on cortical encoding of gerbil vocalizations</article-title>. <source>J. Neurophysiol</source>. <volume>110</volume>, <fpage>1190</fpage>–<lpage>1204</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c104"><label>104.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D. D.</given-names> <surname>Greenwood</surname></string-name></person-group>, <article-title>A Cochlear Frequency-Position function for several species −29 Years Later</article-title>. <source>J. Acoust. Soc. Am</source>. <volume>87</volume>, <fpage>2592</fpage>–<lpage>2605</lpage> (<year>1990</year>).</mixed-citation></ref>
<ref id="c105"><label>105.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>L. D.</given-names> <surname>Liberman</surname></string-name>, <string-name><given-names>H. B.</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>M. C.</given-names> <surname>Liberman</surname></string-name></person-group>, <article-title>Opposing Gradients of Ribbon Size and AMPA Receptor Expression Underlie Sensitivity Differences among Cochlear-Nerve/Hair-Cell Synapses</article-title>. <source>J. Neurosci.</source> <volume>31</volume>, <fpage>801</fpage>–<lpage>808</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c106"><label>106.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>E. R.</given-names> <surname>Girden</surname></string-name></person-group>, <source>ANOVA: Repeated measures</source> (<publisher-name>Sage Publications, Inc</publisher-name>, <year>1992</year>).</mixed-citation></ref>
    <ref id="c107"><label>107.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>S. S.</given-names> <surname>Smith</surname></string-name>, <string-name><given-names>K. N.</given-names> <surname>Jahn</surname></string-name>, <string-name><given-names>J. A.</given-names> <surname>Sugai</surname></string-name>, <string-name><given-names>K. E.</given-names> <surname>Hancock</surname></string-name>, <string-name><given-names>D. B.</given-names> <surname>Polley</surname></string-name></person-group>, <article-title>The human pupil and face encode sound affect and provide objective signatures of tinnitus and auditory hypersensitivity disorders</article-title>. <source>bioRxiv</source> (<year>2024</year>). <pub-id pub-id-type="doi">10.1101/2023.12.22.571929</pub-id>.</mixed-citation></ref>
<ref id="c108"><label>108.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J.</given-names> <surname>Friedman</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Hastie</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Tibshirani</surname></string-name></person-group>, <article-title>Regularization Paths for Generalized Linear Models via Coordinate Descent</article-title>. <source>J. Stat. Softw</source>. <volume>33</volume>, <fpage>1</fpage>–<lpage>22</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c109"><label>109.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>M.</given-names> <surname>Kuhn</surname></string-name></person-group>, <article-title>Building Predictive Models in R Using the caret Package</article-title>. <source>J. Stat. Softw</source>. <volume>28</volume>, <fpage>1</fpage>–<lpage>26</lpage> (<year>2008</year>).</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.102823.2.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Obleser</surname>
<given-names>Jonas</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Lübeck</institution>
</institution-wrap>
<city>Lübeck</city>
<country>Germany</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Compelling</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study aims to clarify the effects of cochlear neural degeneration on auditory processing in listeners with normal audiograms (sometimes referred to as 'hidden hearing loss'). The authors provide <bold>important</bold> new data demonstrating associations between cochlear neural degeneration, non-invasive assays of auditory processing, and speech perception. Based on a cross-species comparison, the findings pose <bold>compelling</bold> evidence that cochlear synaptopathy is associated with a significant part of hearing difficulties in complex environments.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.102823.2.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This study is part of an ongoing effort to clarify the effects of cochlear neural degeneration (CND) on auditory processing in listeners with normal audiograms. This effort is important because ~10% of people who seek help for hearing difficulties have normal audiograms and current hearing healthcare has nothing to offer them.</p>
<p>The authors identify two shortcomings in previous work that they intend to fix. The first is a lack of cross-species studies that make direct comparisons between animal models in which CND can be confirmed and humans for which CND must be inferred indirectly. The second is the low sensitivity of purely perceptual measures to subtle changes in auditory processing. To fix these shortcomings, the authors measure envelope following responses (EFRs) in gerbils and humans using the same sounds, while also performing histological analysis of the gerbil cochleae, and testing speech perception while measuring pupil size in the humans.</p>
<p>The study begins with a comprehensive assessment of the hearing status of the human listeners. The only differences found between the young adult (YA) and middle aged (MA) groups are in thresholds at frequencies &gt; 10 kHz and DPOAE amplitudes at frequencies &gt; 5 kHz. The authors then present the EFR results, first for the humans and then for the gerbils, showing that amplitudes decrease more rapidly with increasing envelope frequency for MA than for YA in both species. The histological analysis of the gerbil cochleae shows that there were, on average, 20% fewer IHC-AN synapses at the 3 kHz place in MA relative to YA, and the number of synapses per IHC was correlated with the EFR amplitude at 1024 Hz.</p>
<p>The study then returns to the humans to report the results of the speech perception tests and pupillometry. The correct understanding of keywords decreased more rapidly with decreasing SNR in MA than in YA, with a noticeable difference at 0 dB, while pupillary slope (a proxy for listening effort) increased more rapidly with decreasing SNR for MA than for YA, with the largest differences at SNRs between 5 and 15 dB. Finally, the authors report that a linear combination of audiometric threshold, EFR amplitude at 1024 Hz, and a few measures of pupillary slope is predictive of speech perception at 0 dB SNR.</p>
<p>I only have two questions/concerns about the specific methodologies used:</p>
<p>(1) Synapse counts were made only at the 3 kHz place on the cochlea. But the EFR sounds were presented at 85 dB SPL, which means that a rather large section of the cochlea will actually be excited. Do we know how much of the EFR actually reflects AN fibers coming from the 3 kHz place? And are we sure that this is the same for gerbils and humans given the differences in cochlear geometry, head size, etc.?</p>
<p>[Note added after revision: the authors have added new data, references, and discussion that have answered my initial questions].</p>
<p>(2) Unless I misunderstood, the predictive power of the final model was not tested on held out data. The standard way to fit and test such model would be to split the data into two segments, one for training and hyperparameter optimization, and one for testing. But it seems that the only spilt was for training and hyperparameter optimization.</p>
<p>[Note added after revision: the authors now make it clear in their response that the modeling tells us how much of the current data can be explained but not necessary about generalization to other datasets.]</p>
<p>While I find the study to be generally well executed, I am left wondering what to make of it all. The purpose of the study with respect to fixing previous methodological shortcomings was clear, but exactly how fixings these shortcomings has allowed us to advance is not. I think we can be more confident than before that EFR amplitude is sensitive to CND, and we now know that measures of listening effort may also be sensitive to CND. But where is this leading us?</p>
<p>I think what this line of work is eventually aiming for is to develop a clinical tool that can be used to infer someone's CND profile. That seems like a worthwhile goal but getting there will require going beyond exploratory association studies. I think we're ready to start being explicit about what properties a CND inference tool would need to be practically useful. I have no idea whether the associations reported in this study are encouraging or not because I have no idea what level of inferential power is ultimately required.</p>
<p>[Note added after revision: the authors have added to the Discussion to put their work into a broader perspective.]</p>
<p>That brings me to my final comment: there is an inappropriate emphasis on statistical significance. The sample size was chosen arbitrarily. What if the sample had been half the size? Then few, if any, of the observed effects would have been significant. What if the sample had been twice the size? Then many more of the observed effects would have been significant (particularly for the pupillometry). I hope that future studies will follow a more principled approach in which relevant effect sizes are pre-specified (ideally as the strength of association that would be practically useful) and sample sizes are determined accordingly.</p>
<p>[Note added after revision: my intention with this comment was not to make a philosophical or nitty-gritty point about statistics. It was more of a follow on to the previous point. Because I don't know what sort of effect size is big enough to matter (for whatever purpose), I don't find the statistical significance (or lack thereof) of the effect size observed to be informative. But I don't think there is anything more that the authors can or should do in this regard.]</p>
<p>So, in summary, I think this study is a valuable but limited advance. The results increase my confidence that non-invasive measures can be used to infer underlying CND, but I am unsure how much closer we are to anything that is practically useful.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.102823.2.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This paper addresses the bottom-up and top-down causes of hearing difficulties in middle-aged adults with clinically-normal audiograms using a cross-species approach (humans vs. gerbils, each with two age groups) mixing behavioral tests and electrophysiology.. The study is not only a follow-up of Parthasarathy et al (eLife 2020), since there are several important differences. Parthasarathy et al. (2020) only considered a group of young normal-hearing individuals with normal audiograms yet with high complaints for hearing in noisy situations. Here, this issue is considered specifically regarding aging, using a between-subject design comparing young NH and older NH individuals recruited from the general population, without additional criterion (i.e. no specifically high problems of hearing in noise). In addition, this is a cross-species approach, with the same physiological EFR measurements with the same stimuli deployed on gerbils.</p>
<p>This article is of very high quality. It is extremely clear, and the results show clearly a decrease of neural phase-locking to high modulation frequencies in both middle-aged humans and gerbils, compared to younger groups/cohorts. In addition, pupillometry measurements conducted during the QuickSIN task suggest increased listening efforts in middle-aged participants, and a statistical model including both EFRs and pupillometry features suggest that both factors contribute to reduced speech-in-noise intelligibility evidenced in middle-aged individuals, beyond their slight differences in audiometric thresholds (although they were clinically normal in both groups).</p>
<p>These provide strong support to the view that normal aging in humans leads to auditory nerve synaptic loss (cochlear neural degeneration - CND- or, put differently, cochlear synaptopathy) as well as increased listening effort, before any clearly visible audiometric deficits as defined in current clinical standards. This result is very important for the community, since we are still missing direct evidence that cochlear synaptopathy might likely underly a significant part of hearing difficulties in complex environments for listeners with normal thresholds, such as middle-aged and senior listeners. This paper shows that these difficulties can be reasonably well accounted for by this sensory disorder (CND), but also that listening effort, i.e. a top-down factor, further contributes to this problem. The methods are sound, well described and I would like to emphasize that they are presented concisely yet in a very precise manner, so that they can be understood very easily - even for a reader that is not familiar with the employed techniques. I believe this study will be of interest to a broad readership.
I have some comments and questions which I think would make the paper even stronger once addressed.</p>
<p>Main comments:</p>
<p>(1) Presentation of EFR analyses / Interpretation of EFR differences found in both gerbils and humans</p>
<p>a) Could you comment further on why you think you found a significant difference only at the highest mod. frequency of 1024 Hz in your study?
Indeed, previous studies employing SAM or RAM tones very similar to the ones employed here were able to show age effects already at lower modulation freqs. of ~100H; e.g. there are clear age effects reported in human studies of Vasilikov et al. (2021) or Mepani et al. (2021), and also in animals ( see Garrett et al. bioRxiv : <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/biorxiv/early/2024/04/30/2020.06.09.142950.full.pdf">https://www.biorxiv.org/content/biorxiv/early/2024/04/30/2020.06.09.142950.full.pdf</ext-link>)</p>
<p>Furthermore, some previous EEG experiments in humans that SAM tones with modulation freqs. of ~100Hz showed that EFRs do not exhibit a single peak, i.e. there are peaks not only at fm but also for the first harmonics (e.g. 2<italic>fm or 3</italic>fm) see e.g. Garrett et al. bioXiv <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/biorxiv/early/2024/04/30/2020.06.09.142950.full.pdf">https://www.biorxiv.org/content/biorxiv/early/2024/04/30/2020.06.09.142950.full.pdf</ext-link></p>
<p>Did you try to extract EFR strength by looking at the summed amplitude of multiple peaks (Vasilikov Hear Res. 2021), in particular for the lower modulation frequencies? (Indeed, there will be no harmonics for the higher mod. freqs).</p>
<p>b) How the present EFR results relate to FFR results, where effects of age are already at low carrier freqs? (e.g. Märcher-Rørsted et al., Hear. Res., 2022 for pure tones with freq &lt; 500 Hz)
Do you think it could be explained by the fact that this is not the same cochlear region, and that synapses die earlier in higher compared to lower CFs. This should be discussed.
Beyond the main group effect of age, there were no negative correlations of EFRs with age in your data?</p>
<p>(2) Size of the effects / comparing age effects between two species:
Although the size of the age effect on EFRs cannot be directly compared between humans and gerbils - the comparison remains qualitative - could you a least provide references regarding the rate of synaptic loss with aging in both humans and gerbils, so that we understand that the yNH/MA difference can be compared between the two age groups used for gerbils; it would have been critical in case of a non-significant age effect in one species.</p>
<p>Equalization / control of stimuli differences across the two species: For measuring EFRs, SAM stimuli were presented at 85 dB SPL for humans vs. 30 dB above detection threshold (inferred from ABRs) for gerbils - I do not think the results strongly depend on this choice, but it would be good to comment on why you did not choose also to present stimuli 30 dB above thresholds in humans.</p>
<p>Simulations of EFRs using functional models could have been used to understand (at least in humans) how the differences in EFRs obtained between the two groups are <italic>quantitatively</italic> compatible with the differences in % of remaining synaptic connections known from histopathological studies for their age range (see the approach in Märcher-Rørsted et al., Hear. Res., 2022)</p>
<p>(3) Synergetic effects of CND and listening effort
Could you test whether there is an interaction between CNR and listening effort? (e.g. one could hypothesize that MA subjects with largest CND have also the higher listening effort)</p>
<p>Comments on revised version:</p>
<p>The authors did well to address all the points raised in my review. This paper will make an important contribution to our assessment of the sources of age-related auditory processing deficits beyond the cochlea that impair speech intelligibility.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.102823.2.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Zink</surname>
<given-names>Maggie E</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Zhen</surname>
<given-names>Leslie</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>McHaney</surname>
<given-names>Jacie R</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1148-4018</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Klara</surname>
<given-names>Jennifer</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Yurasits</surname>
<given-names>Kimberly</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Cancel</surname>
<given-names>Victoria</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Flemm</surname>
<given-names>Olivia</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Mitchell</surname>
<given-names>Claire</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Datta</surname>
<given-names>Jyotishka</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Chandrasekaran</surname>
<given-names>Bharath</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Parthasarathy</surname>
<given-names>Aravindakshan</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4573-8004</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>The following is the authors’ response to the original reviews.</p>
<disp-quote content-type="editor-comment">
<p><bold>Public Reviews:</bold></p>
<p><bold>Reviewer #1 (Public review):</bold></p>
<p>This study is part of an ongoing effort to clarify the effects of cochlear neural degeneration (CND) on auditory processing in listeners with normal audiograms. This effort is important because ~10% of people who seek help for hearing difficulties have normal audiograms and current hearing healthcare has nothing to offer them.</p>
<p>The authors identify two shortcomings in previous work that they intend to fix. The first is a lack of cross-species studies that make direct comparisons between animal models in which CND can be confirmed and humans for which CND must be inferred indirectly. The second is the low sensitivity of purely perceptual measures to subtle changes in auditory processing. To fix these shortcomings, the authors measure envelope following responses (EFRs) in gerbils and humans using the same sounds, while also performing histological analysis of the gerbil cochleae, and testing speech perception while measuring pupil size in the humans.</p>
<p>The study begins with a comprehensive assessment of the hearing status of the human listeners. The only differences found between the young adult (YA) and middle-aged (MA) groups are in thresholds at frequencies &gt; 10 kHz and DPOAE amplitudes at frequencies &gt; 5 kHz. The authors then present the EFR results, first for the humans and then for the gerbils, showing that amplitudes decrease more rapidly with increasing envelope frequency for MA than for YA in both species. The histological analysis of the gerbil cochleae shows that there were, on average, 20% fewer IHC-AN synapses at the 3 kHz place in MA relative to YA, and the number of synapses per IHC was correlated with the EFR amplitude at 1024 Hz.</p>
<p>The study then returns to the humans to report the results of the speech perception tests and pupillometry. The correct understanding of keywords decreased more rapidly with decreasing SNR in MA than in YA, with a noticeable difference at 0 dB, while pupillary slope (a proxy for listening effort) increased more rapidly with decreasing SNR for MA than for YA, with the largest differences at SNRs between 5 and 15 dB. Finally, the authors report that a linear combination of audiometric threshold, EFR amplitude at 1024 Hz, and a few measures of pupillary slope is predictive of speech perception at 0 dB SNR.</p>
<p>I only have two questions/concerns about the specific methodologies used:</p>
<p>(1) Synapse counts were made only at the 3 kHz place on the cochlea. However, the EFR sounds were presented at 85 dB SPL, which means that a rather large section of the cochlea will actually be excited. Do we know how much of the EFR actually reflects AN fibers coming from the 3 kHz place? And are we sure that this is the same for gerbils and humans given the differences in cochlear geometry, head size, etc.?</p>
</disp-quote>
<p>Thank you for raising this important point. The frequency regions that contribute to the generation of EFRs, especially at the suprathreshold sound levels presented here are expected to be broad, with a greater leaning towards higher frequencies and reaching up to one octave above the center frequency. We have investigated this phenomenon in earlier published articles using both low/high pass masking noise and computational models using data from rodent models and humans (Encina-Llamas et al. 2017; Parthasarathy, Lai, and Bartlett 2016). So, the expectation here is that the EFRs reflect a wider frequency region centered at 3 kHz. The difference in cochlear activation regions between humans and gerbils for EFRs have not been systematically studied to our knowledge but given the general agreement between humans and other rodent models stated above, we expect this to be similar to gerbils as well. Additionally, all current evidence points to cochlear synapse loss with age being flat across frequencies, in contrast to cochlear synapse loss with noise which is dependent on the bandwidth of the noise exposure.</p>
<p>Histological evidence for this flat loss across frequencies is found in mice and human temporal bones (Parthasarathy and Kujawa 2018; Sergeyenko et al. 2013; Wu et al. 2018). We find this to be true in our gerbils as well. Author response image 1 shows the patterns of synapse loss as a function of cochlear place. We focused on synapse loss at 3 kHz to keep the analysis focused on the center frequency of the stimulus and minimize compounding errors due to averaging synapse counts across multiple frequency regions. We have now added some explanatory language in the discussion.</p>
<fig id="sa3fig1">
<label>Author response image 1.</label>
<caption>
<title>Cochlear synapse counts per inner hair cell (IHC) in young and middle-aged gerbils as a function of cochlear frequency.</title>
</caption>
<graphic mime-subtype="jpg" xlink:href="elife-102823-sa3-fig1.jpg" mimetype="image"/>
</fig>
<disp-quote content-type="editor-comment">
<p>(2) Unless I misunderstood, the predictive power of the final model was not tested on heldout data. The standard way to fit and test such a model would be to split the data into two segments, one for training and hyperparameter optimization, and one for testing. But it seems that the only split was for training and hyperparameter optimization.</p>
</disp-quote>
<p>The goal of the analysis in this current manuscript was inference, rather than prediction, i.e., to find the important/significant variables that contribute to speech intelligibility in noise, rather than predicting the behavioral deficit of speech performance in a yet-unforeseen sample of adults.</p>
<p>Additionally, we used a repeated 10-fold cross-validation approach for our model building exercise as detailed in the Elastic Net Regression section of the methods.  This repeated-cross validation calculated the mean square error on a held-out fold and average it repeatedly to reduce the inherent variability of randomly choosing a validation set. The repeated 10-fold CV approach is both more stable and efficient compared to a validation set approach, or splitting the data into two segments: training and test, and provides a better estimate of the test error by utilizing more observations for training (vide Chapter 5,(James et al. 2021). These predictive MSEs along with the R-squared for the final model give us a good idea of the predictive performance, as, for the linear model the R-squared is the correlation between the observed and the predicted response. Future studies with a larger sample size can facilitate having a designated test set and still have enough statistical power to perform predictive analyses.</p>
<disp-quote content-type="editor-comment">
<p>While I find the study to be generally well executed, I am left wondering what to make of it all. The purpose of the study with respect to fixing previous methodological shortcomings was clear, but exactly how fixing these shortcomings has allowed us to advance is not. I think we can be more confident than before that EFR amplitude is sensitive to CND, and we now know that measures of listening effort may also be sensitive to CND. But where is this leading us? I think what this line of work is eventually aiming for is to develop a clinical tool that can be used to infer someone's CND profile. That seems like a worthwhile goal but getting there will require going beyond exploratory association studies. I think we're ready to start being explicit about what properties a CND inference tool would need to be practically useful. I have no idea whether the associations reported in this study are encouraging or not because I have no idea what level of inferential power is ultimately required.</p>
</disp-quote>
<p>Studies with CND have so far been largely inferential in humans, since currently we cannot confirm CND in vivo. Hence any measures of putative CND in humans can only be interpreted based on evidence from other animal studies. Our translational approach is partly meant to address this deficit, as mentioned in the Introduction section. By using identical stimuli, recording, acquisition and analysis parameters we hope to reduce some of the variability that may be associated with this inference between human and other animal models. Until direct measurements of CND in humans are possible, the intended goal is to provide diagnostic biomarkers that have face validity – i.e., that explain variance related to speech intelligibility deficits in this population.</p>
<p>We’ve added more to the discussion to state that our work demonstrates the need for next generation diagnostic measures of auditory processing that incorporate cognitive factors associated with listening effort to better capture speech in noise perceptual abilities.</p>
<disp-quote content-type="editor-comment">
<p>That brings me to my final comment: there is an inappropriate emphasis on statistical significance. The sample size was chosen arbitrarily. What if the sample had been half the size? Then few, if any, of the observed effects would have been significant. What if the sample had been twice the size? Then many more of the observed effects would have been significant (particularly for the pupillometry). I hope that future studies will follow a more principled approach in which relevant effect sizes are pre-specified (ideally as the strength of association that would be practically useful) and sample sizes are determined accordingly.</p>
</disp-quote>
<p>We agree that pre-determining sample sizes is the optimal approach towards designing a study. The sample sizes here were chosen a priori based on previously published data in young adults with normal hearing thresholds (McHaney et al. 2024; Parthasarathy et al. 2020). With the lack of published literature especially for the EFRs at 1024Hz AM in middle aged adults, there are practical challenges in pre-determining the sample size (given a prefixed power and an effect size) with limited precursors to supply good estimates of the parameters (e.g., mean, s.d. for each age group for a two-sample test). We hope that this data set now shared will enable us and other researchers to conduct power analyses for successive studies that use similar metrics on this population.</p>
<p>Several authors, including Heinsburg and Weeks (2022) argue that post-hoc power could be “misleading and simply not informative” and encourage using other indicators of poorly powered studies such as the width of the confidence interval. Since the elastic net estimate is a non-linear and non-differentiable function of the response values—even for fixed tuning parameters—it is difficult to obtain an accurate estimate of its standard error (Tibshirani and Taylor 2012).  While acknowledging the limitations of post-hoc power analyses, we performed a retrospective power calculation for our linear model with the predictors that we selected (EFR @ 1024Hz, Pupil slope for QuickSIN at selected SNRs and analyses windows, and PTA). The calculated Cohen’s effect size was 0.56, which is considered large (Cohen 2013). With this effect size, a power analysis with our sample size revealed a very high retrospective power of 0.99 with a significance level of 0.05. The minimum number of subjects needed to get 80% power with this effect size was N = 21. Hence for the final model, we are confident that our results hold true with adequate statistical power.</p>
<disp-quote content-type="editor-comment">
<p>So, in summary, I think this study is a valuable but limited advance. The results increase my confidence that non-invasive measures can be used to infer underlying CND, but I am unsure how much closer we are to anything that is practically useful.</p>
</disp-quote>
<p>Thank you for your comments. We hope that this study establishes a framework for the eventual development of the next generation of objective diagnostics tests in the hearing clinic that provide insights into the underlying neurophysiology of the auditory pathway and take into effect top-down contributors such as listening effort.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public review):</bold></p>
<p>Summary:</p>
<p>This paper addresses the bottom-up and top-down causes of hearing difficulties in middleaged adults with clinically-normal audiograms using a cross-species approach (humans vs. gerbils, each with two age groups) mixing behavioral tests and electrophysiology. The study is not only a follow-up of Parthasarathy et al (eLife 2020), since there are several important differences.</p>
<p>Parthasarathy et al. (2020) only considered a group of young normal-hearing individuals with normal audiograms yet with high complaints of hearing in noisy situations. Here, this issue is considered specifically regarding aging, using a between-subject design comparing young NH and older NH individuals recruited from the general population, without additional criterion (i.e. no specifically high problems of hearing in noise). In addition, this is a cross-species approach, with the same physiological EFR measurements with the same stimuli deployed on gerbils.</p>
<p>This article is of very high quality. It is extremely clear, and the results show clearly a decrease of neural phase-locking to high modulation frequencies in both middle-aged humans and gerbils, compared to younger groups/cohorts. In addition, pupillometry measurements conducted during the QuickSIN task suggest increased listening efforts in middle-aged participants, and a statistical model including both EFRs and pupillometry features suggests that both factors contribute to reduced speech-in-noise intelligibility evidenced in middle-aged individuals, beyond their slight differences in audiometric thresholds (although they were clinically normal in both groups).</p>
<p>These provide strong support to the view that normal aging in humans leads to auditory nerve synaptic loss (cochlear neural degeneration - CNR- or, put differently, cochlear synaptopathy) as well as increased listening effort, before any clearly visible audiometric deficits as defined in current clinical standards. This result is very important for the community since we are still missing direct evidence that cochlear synaptopathy might likely underlie a significant part of hearing difficulties in complex environments for listeners with normal thresholds, such as middle-aged and senior listeners. This paper shows that these difficulties can be reasonably well accounted for by this sensory disorder (CND), but also that listening effort, i.e. a top-down factor, further contributes to this problem. The methods are sound and well described and I would like to emphasize that they are presented concisely yet in a very precise manner so that they can be understood very easily - even for a reader who is not familiar with the employed techniques. I believe this study will be of interest to a broad readership.</p>
<p>I have some comments and questions which I think would make the paper even stronger once addressed.</p>
<p>Main comments:</p>
<p>(1) Presentation of EFR analyses / Interpretation of EFR differences found in both gerbils and humans:</p>
<p>a) Could the authors comment further on why they think they found a significant difference only at the highest mod. frequency of 1024 Hz in their study? Indeed, previous studies employing SAM or RAM tones very similar to the ones employed here were able to show age effects already at lower modulation freqs. of ~100H; e.g. there are clear age effects reported in human studies of Vasilikov et al. (2021) or Mepani et al. (2021), and also in animals (see Garrett et al. bioXiv: <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/biorxiv/early/2024/04/30/2020.06.09.142950.full.p">https://www.biorxiv.org/content/biorxiv/early/2024/04/30/2020.06.09.142950.full.p</ext-link> df).</p>
</disp-quote>
<p>Previously published studies in animal models by us and others suggests that EFRs elicited to AM rates &gt; 700Hz are most sensitive to confirmed CND (Parthasarathy and Kujawa 2018; Shaheen, Valero, and Liberman 2015). This is likely because these AM rates fall well outside of phase-locking limits in the auditory midbrain and cortex (Joris, Schreiner, and Rees 2004), and hence represent a ‘cleaner’ signal from the auditory periphery that may not be modulated by complex excitatory/inhibitory feedback circuits present more centrally (Caspary et al. 2008). We have also demonstrated that we are able to acquire high quality EFRs at 1024Hz AM rates both in a previously published study in young normal hearing adults (McHaney et al. 2024), and in middle aged adults in the present study as seen in Fig. 1 H-J. We posit that the lack of age-related differences at the lower AM rates may be indicative of compensatory plasticity with age (central ‘gain’) that occurs with age in more central regions of the auditory pathway (Auerbach, Radziwon, and Salvi 2019; Parthasarathy and Kujawa 2018). We now expand on this in the discussion. A secondary reason for the lack of change in slower modulation rates may be the difference in stimulus between sinusoidally amplitude modulated tones used here, and the rectangular amplitude modulated tones in other studies, as discussed in response to the comment below.</p>
<disp-quote content-type="editor-comment">
<p>Furthermore, some previous EEG experiments in humans that SAM tones with modulation freqs. of ~100Hz showed that EFRs do not exhibit a single peak, i.e. there are peaks not only at fm but also for the first harmonics (e.g. 2<italic>fm or 3</italic>fm) see e.g.Garrett et al. bioXiv <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/biorxiv/early/2024/04/30/2020.06.09.142950.full.pd">https://www.biorxiv.org/content/biorxiv/early/2024/04/30/2020.06.09.142950.full.pd</ext-link> f. Did the authors try to extract EFR strength by looking at the summed amplitude of multiple peaks (Vasilikov Hear Res. 2021), in particular for the lower modulation frequencies? (indeed, there will be no harmonics for the higher mod. freqs).</p>
</disp-quote>
<p>We examined peak amplitudes for the AM rate and harmonics for the 110 Hz AM condition as shown in Author response image 2. The quantified amplitudes of the first four harmonics did not differ with age (ps &gt; .08).</p>
<p>Additionally, the harmonic structures obtained were also not as robust as would be expected with rectangular amplitude modulated stimuli. The choice of sinusoidal modulation may explain why. We have previously published studies systematically modulating the rise time of the envelope per cycle in amplitude modulated tones, where the individual period of the envelope is described by Env (t) = t<sup>x</sup> (1-t),  where t goes from 0 to 1 in one period, and where x = 0.05 represents a highly damped envelope akin to the rising envelope  f a rectangular modulation, and x = 1 representing a symmetric, near-sinusoidal envelope (Parthasarathy and Bartlett 2011). The harmonic structure was much more developed in the damped envelopes compared to the symmetric envelopes and response amplitudes were also higher for the damped envelopes overall, a result also observed in Mepani et. al., 2021. Hence, we believe the rapid rise time may contribute to the harmonic structures evidenced in studies using RAM stimuli, and the absence of this rapid onset may result in reduced harmonic structures in our EFRs. Some language regarding this issue is now added to the discussion.</p>
<fig id="sa3fig2">
<label>Author response image 2.</label>
<caption>
<title>Harmonics analysis for the first four harmonics of envelope following responses elicited to the 110Hz AM stimulus.</title>
</caption>
<graphic mime-subtype="jpg" xlink:href="elife-102823-sa3-fig2.jpg" mimetype="image"/>
</fig>
<disp-quote content-type="editor-comment">
<p>b) How do the present EFR results relate to FFR results, where effects of age are already at low carrier freqs? (e.g. Märcher-Rørsted et al., Hear. Res., 2022 for pure tones with freq &lt; 500 Hz). Do the authors think it could be explained by the fact that this is not the same cochlear region, and that synapses die earlier in higher compared to lower CFs? This should be discussed. Beyond the main group effect of age, there were no negative correlations of EFRs with age in the data?</p>
</disp-quote>
<p>We believe the current results are in close agreement with these studies showing deficits in pure tone phase locking with age. These tones are typically at ~300-500Hz or above, and phase locking to these tones likely involves the same or similar peripheral neural generators in the auditory nerve and brainstem. Emerging evidence also seems to suggest that TFS coding measured using pure tone phase locking is closely related to sound with amplitude modulation in the same range (Ponsot et al. 2024). Unpublished observations from our lab support this view as well. In this data set, we begin to see EFR responses at 512 Hz diverge with age, but this difference does not reach statistical significance. This may be due to specific AM frequencies selected or a lack of statistical power. Using more continuous AM frequency sweeps such as with our recently published dynamic amplitude modulated tones (Parida et al. 2024) may help resolve these AM frequency specific challenges and help us investigate changes over a broader range of AM frequencies. Ongoing studies are currently exploring this hypothesis. Some explanatory language is now presented in the discussion.</p>
<disp-quote content-type="editor-comment">
<p>(2) Size of the effects / comparing age effects between two species:</p>
<p>Although the size of the age effect on EFRs cannot be directly compared between humans and gerbils - the comparison remains qualitative - could the authors at least provide references regarding the rate of synaptic loss with aging in both humans and gerbils, so that we understand that the yNH/MA difference can be compared between the two age groups used for gerbils; it would have been critical in case of a non-significant age effect in one species.</p>
</disp-quote>
<p>Current evidence seems to suggest that humans have more synaptic loss than gerbils, though exact comparison of lifespan between the two species is challenging due to differences in slopes of growth trajectories between species. Post-mortem temporal bone studies demonstrate a ~40-50% loss of synapses in humans by the fifth decade of life. On the other hand, our gerbils in the current study showed approximately 15-20% loss. Based on our findings and previous studies, it is reasonable to assume that our gerbil data underestimate the temporal processing deficits that would be seen in humans due to CND.</p>
<p>We have added this information and citations to the discussion section.</p>
<disp-quote content-type="editor-comment">
<p>Equalization/control of stimuli differences across the two species: For measuring EFRs, SAM stimuli were presented at 85 dB SPL for humans vs. 30 dB above the detection threshold (inferred from ABRs) for gerbils - I do not think the results strongly depend on this choice, but it would be good to comment on why you did not choose also to present stimuli 30 dB above thresholds in humans.</p>
</disp-quote>
<p>We chose to record EFRs to stimuli presented at 85 dB SPL in humans, as opposed to 30 dB SL, because 30 dB SL in humans would have corresponded to an intensity that makes EEG recordings unfeasible. The average PTA across younger and middle-aged adults was 7.51 dB HL (~19.51 dB SPL), which would have resulted in an average stimulus intensity of ~50 dB SPL at 30 dB SL. This intensity level would have been far too low to reliably record EFRs without presenting many thousands of trials. In a pilot study, we recorded EFRs at 75 dB SL, which equated to an average of 83.9 dB SPL. Thus, we chose the suprathreshold level of 85 dB SPL for the current study to obtain reliable responses with just 1000 trials.</p>
<disp-quote content-type="editor-comment">
<p>Simulations of EFRs using functional models could have been used to understand (at least in humans) how the differences in EFRs obtained between the two groups are <italic>quantitatively</italic> compatible with the differences in % of remaining synaptic connections known from histopathological studies for their age range (see the approach in Märcher-Rørsted et al., Hear. Res., 2022)</p>
</disp-quote>
<p>We agree with the reviewer that phenomenological models would be a useful approach to examining differences between age groups and species. We have previously used the Zilany/Carney model to examine differences in EFRs with age in rats (Parthasarathy, Lai, and Bartlett 2016). It is unclear if such models will directly translate to responses form gerbils. However, this is a subject of ongoing study in our lab.</p>
<disp-quote content-type="editor-comment">
<p>(3) Synergetic effects of CND and listening effort:</p>
<p>Could you test whether there is an interaction between CND and listening effort? (e.g. one could hypothesize that MA subjects with the largest CND have also higher listening effort).</p>
</disp-quote>
<p>We have previously reported that EFRs and listening effort are not linearly related (McHaney et al. 2024). We found the same to be largely true in the current study as well. We ran correlations between EFR amplitudes at 1024 Hz and listening effort at each SNR level in the listening and integrations windows. We did not observe any significant relationships between EFRs at 1024 Hz and listening effort in the listening window (all <italic>ps</italic> &gt; .05). In the integration window, we did see a significant correlation between listening effort at SNR 5 and EFRs at 1024 Hz, which was significant after correcting for multiple comparisons (<italic>r</italic> = -.42, <italic>p</italic>-adj = .021). However, we chose to not report these multiple oneto-one correlations in the current study and instead opted for the elastic net regression analysis to better understand the multifactorial contributions to speech-in-noise abilities. These results also do not preclude non-linear relationships between listening effort and EFRs which may be present based on emerging results (Bramhall, Buran, and McMillan 2025), and will be explored in future studies.</p>
<disp-quote content-type="editor-comment">
<p><bold>Recommendations for the authors:</bold></p>
<p><bold>Reviewer #1 (Recommendations for the authors):</bold></p>
<p>A few more minor comments/questions:</p>
<p>(1) How old were the YA gerbils on average? 18 weeks, or 19 weeks, or 22 weeks?</p>
</disp-quote>
<p>Young gerbils were on average 22 weeks. We have updated the manuscript accordingly.</p>
<disp-quote content-type="editor-comment">
<p>(2) &quot;Gerbils share the same hearing frequency range as humans&quot; is misleading; the gerbil hearing range extends to much higher frequencies.</p>
</disp-quote>
<p>We have revised the statement to say: “The hearing range of gerbils largely overlaps with that of humans, making them an ideal animal model for direct comparison in crossspecies studies.”</p>
<disp-quote content-type="editor-comment">
<p>(3) The writing contains more than a few typos and grammatical errors.</p>
</disp-quote>
<p>We have completed a thorough revision to correct for grammatical and typographical errors.</p>
<disp-quote content-type="editor-comment">
<p>(4) Suggesting that correlation and linear modelling are &quot;independent&quot; methods is misleading since they are both measuring linear associations. A better word would be &quot;different&quot;.</p>
</disp-quote>
<p>Thank you for this suggestion. We have rephrased the sentence as “two separate approaches”</p>
<disp-quote content-type="editor-comment">
<p>(5) The phrase &quot;Our results reveal perceptual deficits ... driven by CND&quot; in the abstract is too strong. Correlation is not causation.</p>
</disp-quote>
<p>We have revised this phrase to say they “are associated with CND.”</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Recommendations for the authors):</bold></p>
<p>More general comments:</p>
<p>(1) Recruitment criterion related to hearing-in-noise difficulties:</p>
<p>If I understood correctly, the middle-aged participants recruited for this study do not have specific hearing in noise difficulties, some could, as with 10% in the general population, but they were not recruited using this criterion. If this is correct, this should be stated explicitly, as it constitutes an important methodological choice and a difference with your eLife 2020 study. If you were to use this specific recruitment criterion for both groups here, what differences would you expect?</p>
</disp-quote>
<p>Our participants were not required to have specific complaints of speech perception in noise challenges to be eligible for this study. We included middle-aged adults here, as opposed to only younger adults as in Parthasarathy et al. (2020), with the assumption that middle-aged adults were likely to have some cochlear synapse loss and individual variability in the degree of synapse loss based on post-mortem data from human temporal bones. We have recently published studies identifying the specific clinical populations of patients with self-perceived hearing loss, including those adults who have received assessments for auditory processing disorders (Cancel et al. 2023). Ongoing studies in the lab are aimed at recruiting from this population.</p>
<disp-quote content-type="editor-comment">
<p>It is striking here that the QuickSIN test does not exhibit the same variability at low SNRS here as with the digits-in-noise used in your eLife 2020 study. Why would QuickSIN more appropriate than the Digits-in-noise test? Would you expect the same results with the Digits-in-noise test?</p>
</disp-quote>
<p>Our 2020 eLife study investigated the effects of TFS coding in multi-talker speech intelligibility. TFS coding is specifically hypothesized to be related to multi-talker speech, compared to broadband maskers. The digits test was appropriate in that context as the ‘masker’ there was two competing speakers also speaking digits.  In this study, we wanted to test the effects of CND on speech in noise perception using clinically relevant speech in noise tests. The Digits test is devoid of linguistic context and is essentially closed set (participants know that only a digit will be presented). However, QuickSIN consists of open set sentences of moderate context, making it closer to real world listening situations. Additionally, we recently published pupillometry recorded in response to QuickSIN in young adults ((McHaney et al. 2024) and identified QuickSIN as a promising screening tool for self-perceived hearing difficulties (Cancel et al. 2023). These factors informed our choice of using QuickSIN in the current study.</p>
<disp-quote content-type="editor-comment">
<p>(2) Why is the increase in listening effort interpreted as an increase in gain? please clarify (p10, 1st paragraph; [these data suggest a decrease in peripheral neural coding, with a concomitant increase in central auditory activity or 'gain'])</p>
</disp-quote>
<p>In the above referenced paragraph, we were discussing the increase in 40 Hz AM rate EFRs in middle-aged adults as an increase in central gain. We have revised parts of this paragraph to better communicate that we were discussing the EFRs and not listening effort: “We observed decreases in EFRs at modulation rates that were selective to the auditory periphery (i.e., 1024 Hz) in middle-aged adults, while EFRs primarily generated from the central auditory structures were not different from those in younger adults (Fig. 1K). These data suggest that middle-aged adults exhibited an increase in central auditory activity, or ‘gain’, in the presence of decreased peripheral neural coding. The perceptual consequences of this gain are unclear, but our findings align with emerging evidence suggesting that gain is associated with selective deficits in speech-in-noise abilities”</p>
<disp-quote content-type="editor-comment">
<p>(3) Further discussion on the relationship/differences between markers EFR marker of CND (this study) and MEMR marker of CND(Bharadwaj et al., 2022) is needed.</p>
</disp-quote>
<p>We now make mention of other candidate markers of CND (ABR wave I and MEMRs) in the discussion and expand on why we chose the EFR.</p>
<disp-quote content-type="editor-comment">
<p>(4) Further analyses and discussion would be needed to be related to extended high-freq thresholds:</p>
<p>Did you test for a potential correlation of your EFR marker of CND with extended high-freq. thresholds ? (could be paralleling the amount of CND in these individuals) Why won't you also consider measuring extended HF in Gerbils?</p>
</disp-quote>
<p>We acknowledge that there is increasing evidence to suggest extended high frequency thresholds may be an early marker for hidden hearing loss/CND. We have examined an additional correlation for extended high frequency pure tone averages (8k-16k Hz) with EFR amplitudes at 1024 Hz AM rate, which revealed a significant relationship (<italic>r</italic> = -.43, <italic>p</italic> &lt; .001). However, we opted to exclude this analysis from our current study as we wanted to reduce reporting on several one-to-one correlations. Therefore, we chose the elastic net regression model to examine individual contributions to speech in noise abilities. EHF thresholds were included in the elastic net regression models, but were not found to be significant upon accounting for individual differences in PTA.</p>
<p>Additionally, our electrophysiological experimental paradigm was not designed with the consideration of extended high frequencies—we used ER3C transducers which are not optimal for frequencies above ~6kHz. Future studies could use transducers such as the ER2 or free field speakers to examine the influence of extended high frequencies on the EFRs and measure high frequency thresholds in gerbils.</p>
<disp-quote content-type="editor-comment">
<p>Minor Comments:</p>
<p>(1) Abstract: repetition of 'later in life' in the first two sentences - please reformulate.</p>
</disp-quote>
<p>We have revised the first two sentences to state: “Middle-age is a critical period of rapid changes in brain function that presents an opportunity for early diagnostics and intervention for neurodegenerative conditions later in life. Hearing loss is one such early indicator linked to many comorbidities in older age.”</p>
<disp-quote content-type="editor-comment">
<p>(2) Sentence on page 3 [However, these behavioral readouts may minimize subliminal changes in perception that are reflected in listening effort but not in accuracies (26-28)] is not clear.</p>
</disp-quote>
<p>We’ve added a sentence just after that states: “Specifically, two individuals may show similar accuracies on a listening task, but one individual may need to exert substantially more listening effort to achieve the same accuracy as the other.”</p>
<disp-quote content-type="editor-comment">
<p>(3) The second paragraph of page 11 should go to a methods (model) section, not to the discussion.</p>
</disp-quote>
<p>We have now moved a portion of this paragraph to the Elastic Net Regression subsection of the Statistical Analysis in the Methods.</p>
<disp-quote content-type="editor-comment">
<p>(4) Please checks references: references 13 and 25 are identical.</p>
</disp-quote>
<p>Fixed</p>
<p>References</p>
<p>Auerbach, Benjamin D., Kelly Radziwon, and Richard Salvi. 2019. “Testing the Central Gain Model: Loudness Growth Correlates with Central Auditory Gain Enhancement in a Rodent Model of Hyperacusis.” Neuroscience 407:93–107. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroscience.2018.09.036">https://doi.org/10.1016/j.neuroscience.2018.09.036</ext-link>.</p>
<p>Bramhall, Naomi F., Brad N. Buran, and Garnett P. McMillan. 2025. “Associations Between Physiological Indicators of Cochlear Deafferentation and Listening Effort in Military Veterans with Normal Audiograms.” Hearing Research, April, 109263. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.heares.2025.109263">https://doi.org/10.1016/j.heares.2025.109263</ext-link>.</p>
<p>Cancel, Victoria E., Jacie R. McHaney, Virginia Milne, Catherine Palmer, and Aravindakshan Parthasarathy. 2023. “A Data-Driven Approach to Identify a Rapid Screener for Auditory Processing Disorder Testing Referrals in Adults.” Scientific Reports 13 (1): 13636. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/s41598-023-40645-0">https://doi.org/10.1038/s41598-023-40645-0</ext-link>.</p>
<p>Caspary, D. M., L. Ling, J. G. Turner, and L. F. Hughes. 2008. “Inhibitory Neurotransmission, Plasticity and Aging in the Mammalian Central Auditory System.” Journal of Experimental Biology 211 (11): 1781–91. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1242/jeb.013581">https://doi.org/10.1242/jeb.013581</ext-link>.</p>
<p>Cohen, Jacob. 2013. Statistical Power Analysis for the Behavioral Sciences. 2nd ed. New York: Routledge. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.4324/9780203771587">https://doi.org/10.4324/9780203771587</ext-link>.</p>
<p>Encina-Llamas, Gerard, Aravindakshan Parthasarathy, James Michael Harte, Torsten Dau, Sharon G. Kujawa, Barbara Shinn-Cunningham, and Bastian Epp. 2017. “Hidden Hearing Loss with Envelope Following Responses (EFRs): The off-Frequency Problem: 40th MidWinter Meeting of the Association for Research in Otolaryngology.” In .</p>
<p>James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2021. An Introduction to Statistical Learning: With Applications in R. Springer Texts in Statistics. New York, NY: Springer US. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/978-1-0716-1418-1">https://doi.org/10.1007/978-1-0716-1418-1</ext-link>.</p>
<p>Joris, P. X., C. E. Schreiner, and A. Rees. 2004. “Neural Processing of Amplitude-Modulated Sounds.” Physiological Reviews 84 (2): 541–77. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/physrev.00029.2003">https://doi.org/10.1152/physrev.00029.2003</ext-link>.</p>
<p>McHaney, Jacie R., Kenneth E. Hancock, Daniel B. Polley, and Aravindakshan Parthasarathy. 2024. “Sensory Representations and Pupil-Indexed Listening Effort Provide Complementary Contributions to Multi-Talker Speech Intelligibility.” Scientific Reports 14 (1): 30882. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/s41598-024-81673-8">https://doi.org/10.1038/s41598-024-81673-8</ext-link>.</p>
<p>Parida, Satyabrata, Kimberly Yurasits, Victoria E. Cancel, Maggie E. Zink, Claire Mitchell, Meredith C. Ziliak, Audrey V. Harrison, Edward L. Bartlett, and Aravindakshan Parthasarathy. 2024. “Rapid and Objective Assessment of Auditory Temporal Processing Using Dynamic Amplitude-Modulated Stimuli.” Communications Biology 7 (1): 1–10. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/s42003-024-07187-1">https://doi.org/10.1038/s42003-024-07187-1</ext-link>.</p>
<p>Parthasarathy, A., and E. L. Bartlett. 2011. “Age-Related Auditory Deficits in Temporal Processing in F-344 Rats.” Neuroscience 192:619–30. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroscience.2011.06.042">https://doi.org/10.1016/j.neuroscience.2011.06.042</ext-link>.</p>
<p>Parthasarathy, A., J. Lai, and E. L. Bartlett. 2016. “Age-Related Changes in Processing Simultaneous Amplitude Modulated Sounds Assessed Using Envelope Following Responses.” Jaro-Journal of the Association for Research in Otolaryngology 17 (2): 119–32. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s10162-016-0554-z">https://doi.org/10.1007/s10162-016-0554-z</ext-link>.</p>
<p>Parthasarathy, A., Kenneth E Hancock, Kara Bennett, Victor DeGruttola, and Daniel B Polley. 2020. “Bottom-up and Top-down Neural Signatures of Disordered Multi-Talker Speech Perception in Adults with Normal Hearing.” Edited by Barbara G Shinn-Cunningham, Huan Luo, Fan-Gang Zeng, and Christian Lorenzi. eLife 9 (January):e51419. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7554/eLife.51419">https://doi.org/10.7554/eLife.51419</ext-link>.</p>
<p>Parthasarathy, Aravindakshan, and Sharon G. Kujawa. 2018. “Synaptopathy in the Aging Cochlea: Characterizing Early-Neural Deficits in Auditory Temporal Envelope Processing.” The Journal of Neuroscience. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/jneurosci.324017.2018">https://doi.org/10.1523/jneurosci.324017.2018</ext-link>.</p>
<p>Ponsot, Emmanuel, Pauline Devolder, Ingeborg Dhooge, and Sarah Verhulst. 2024. “AgeRelated Decline in Neural Phase-Locking to Envelope and Temporal Fine Structure Revealed by Frequency Following Responses: A Potential Signature of Cochlear Synaptopathy Impairing Speech Intelligibility.” bioRxiv. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1101/2024.12.11.628010">https://doi.org/10.1101/2024.12.11.628010</ext-link>.</p>
<p>Sergeyenko, Yevgeniya, Kumud Lall, M. Charles Liberman, and Sharon G. Kujawa. 2013. “Age-Related Cochlear Synaptopathy: An Early-Onset Contributor to Auditory Functional Decline.” Journal of Neuroscience 33 (34): 13686–94. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/jneurosci.1783-13.2013">https://doi.org/10.1523/jneurosci.1783-13.2013</ext-link>.</p>
<p>Shaheen, L. A., M. D. Valero, and M. C. Liberman. 2015. “Towards a Diagnosis of Cochlear Neuropathy with Envelope Following Responses.” J Assoc Res Otolaryngol. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s10162-015-0539-3">https://doi.org/10.1007/s10162-015-0539-3</ext-link>.</p>
<p>Tibshirani, Ryan J., and Jonathan Taylor. 2012. “Degrees of Freedom in Lasso Problems.” The Annals of Statistics 40 (2): 1198–1232. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1214/12-AOS1003">https://doi.org/10.1214/12-AOS1003</ext-link>.</p>
<p>Wu, P. Z., L. D. Liberman, K. Bennett, V. de Gruttola, J. T. O’Malley, and M. C. Liberman. 2018. “Primary Neural Degeneration in the Human Cochlea: Evidence for Hidden Hearing Loss in the Aging Ear.” Neuroscience. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroscience.2018.07.053">https://doi.org/10.1016/j.neuroscience.2018.07.053</ext-link>.</p>
</body>
</sub-article>
</article>