<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">93934</article-id>
<article-id pub-id-type="doi">10.7554/eLife.93934</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.93934.2</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Immunology and Inflammation</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>Computational and Systems Biology</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>NetTCR 2.2 - Improved TCR specificity predictions by combining pan- and peptide-specific training strategies, loss-scaling and integration of sequence similarity</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0004-6664-448X</contrib-id>
<name>
<surname>Jensen</surname>
<given-names>Mathias Fynbo</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Nielsen</surname>
<given-names>Morten</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Health Technology, Section for Bioinformatics, Technical University of Denmark, DTU</institution>, 2800 Kgs. Lyngby, <country>Denmark</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Sohn</surname>
<given-names>Jungsan</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Johns Hopkins University School of Medicine</institution>
</institution-wrap>
<city>Baltimore</city>
<country>United States of America</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Rath</surname>
<given-names>Satyajit</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Indian Institute of Science Education and Research (IISER)</institution>
</institution-wrap>
<city>Pune</city>
<country>India</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>Corresponding author: Morten Nielsen, <email>morni@dtu.dk</email></corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2023-12-20">
<day>20</day>
<month>12</month>
<year>2023</year>
</pub-date>
<pub-date date-type="update" iso-8601-date="2024-02-02">
<day>02</day>
<month>02</month>
<year>2024</year>
</pub-date>
<volume>12</volume>
<elocation-id>RP93934</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-11-07">
<day>07</day>
<month>11</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-10-16">
<day>16</day>
<month>10</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.10.12.562001"/>
</event>
<event>
<event-desc>Reviewed preprint v1</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2023-12-20">
<day>20</day>
<month>12</month>
<year>2023</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.93934.1"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.93934.1.sa2">eLife assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.93934.1.sa1">Reviewer #1 (Public Review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.93934.1.sa0">Reviewer #2 (Public Review):</self-uri>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2023, Jensen &amp; Nielsen</copyright-statement>
<copyright-year>2023</copyright-year>
<copyright-holder>Jensen &amp; Nielsen</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-93934-v2.pdf"/>
<abstract>
<title>Abstract</title>
<p>The ability to predict binding between peptides presented by the Major Histocompatibility Complex (MHC) class I molecules and T-cell receptors (TCR) is of great interest in areas of vaccine development, cancer treatment and treatment of autoimmune diseases. However, the scarcity of paired-chain data, combined with the bias towards a few well-studied epitopes, has challenged the development of pan-specific machine-learning (ML) models with accurate predictive power towards peptides characterized by little or no TCR data. To deal with this, we here benefit from a larger paired-chain peptide-TCR dataset and explore different ML model architectures and training strategies to better deal with imbalanced data. We show that while simple changes to the architecture and training strategies results in greatly improved performance, particularly for peptides with little available data, predictions on unseen peptides remain challenging, especially for peptides distant to the training peptides. We also demonstrate that ML models can be used to detect potential outliers, and that the removal of such outliers from training further improves the overall performance. Furthermore, we show that a model combining the properties of pan-specific and peptide-specific models achieves improved performance, and that performance can be further improved by integrating similarity-based predictions, especially when a low false positive rate is desirable. Moreover, in the context of the IMMREP 2022 benchmark, this updated modeling framework archived state-of-the-art performance. Finally, we show that combining all these approaches results in acceptable predictive accuracy for peptides characterized with as little as 15 positive TCRs. This observation thus places great promise on rapidly expanding the peptide covering of the current models for predicting TCR specificity. The final NetTCR 2.2 models are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/mnielLab/NetTCR-2.2">https://github.com/mnielLab/NetTCR-2.2</ext-link>, and as a web server at <ext-link ext-link-type="uri" xlink:href="https://services.healthtech.dtu.dk/services/NetTCR-2.2/">https://services.healthtech.dtu.dk/services/NetTCR-2.2/</ext-link>.</p>
</abstract>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>We detected a few minor factual errors in the method section, which we have corrected in this revision. The first error was that we wrongfully stated that our final dataset had 6358 unique TCRs, whereas it was in fact 6353 unique TCRs. The second error was that we stated that the maximum length of CDR1ꞵ was 5, where it was in fact 6. The last error was that we stated that we used a Levenshtein distance of at least 3 to discard similar peptides when swapping the TCRs to generate negatives. This should have been a Levenshtein greater than 3. We also added a brief mention of potential applications for our models to the introduction and discussion, and extended our conclusion to better cover all the findings. Finally, we changed Figure 3 and Supplementary Figure 1 to boxplots to better illustrate the differences in performance.</p></fn>
</fn-group>
<fn-group content-type="external-links">
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://github.com/mnielLab/NetTCR-2.2">https://github.com/mnielLab/NetTCR-2.2</ext-link>
</p></fn>
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://services.healthtech.dtu.dk/services/NetTCR-2.2/">https://services.healthtech.dtu.dk/services/NetTCR-2.2/</ext-link>
</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>T-cell mediated immune responses play a crucial role in safeguarding the body’s health by identification and elimination of pathogen infected and malfunctioning cells. One of the essential steps triggering the T-cell response is the recognition of peptides presented by MHC (Major Histocompatibility Complex) at the surface of cells by T cell receptors (TCR). The TCR is heterodimer (most often) formed by an α and β chain. To be able to recognize the extreme variety of peptides presented by the MHC, the repertoire of different TCRs expressed by T cells in a given host is immense. This variation is mostly limited to the interacting domains of the TCR, known as the complementary determining regions (CDRs) [<xref ref-type="bibr" rid="c1">1</xref>].</p>
<p>The possibility of accurately predicting TCR specificity holds immense immunotherapeutic and biotechnological potentials, for instance as a means to rapidly and cost-effectively identify the target of relevant T cell populations in the context of antigen discovery, vaccine design and/or T cell therapy.</p>
<p>However, while machine-learning (ML) approaches have allowed to accurately predicts which peptides can be presented by the MHC [<xref ref-type="bibr" rid="c2">2</xref>], the scarce data, combined with the extreme variability of the TCR, has made it difficult to produce models with broad peptide-HLA coverage with similar accuracies for predictions of TCR specificity. Several models ranging from neural network models to similarity-based approaches have, however, allowed for development of accurate prediction models covering the limited set of peptides, for which sufficient data is available [<xref ref-type="bibr" rid="c3">3</xref>].</p>
<p>Current ML-based methods for predicting TCR-specificity include convolutional neural network (CNN) models, such as ImRex [<xref ref-type="bibr" rid="c4">4</xref>], TCRAI [<xref ref-type="bibr" rid="c5">5</xref>] and NetTCR 2.1 [<xref ref-type="bibr" rid="c6">6</xref>], auto-encoder-based models such as DeepTCR [<xref ref-type="bibr" rid="c7">7</xref>] decision-tree models such as SETE [<xref ref-type="bibr" rid="c8">8</xref>], Gaussian process models such as TCRGP [<xref ref-type="bibr" rid="c9">9</xref>], as well as transformer-based models such as TULIP [<xref ref-type="bibr" rid="c9">9</xref>]. Furthermore, unsupervised similarity-based methods have been developed, such as TCRdist3 [<xref ref-type="bibr" rid="c11">11</xref>], GLIPH2 [<xref ref-type="bibr" rid="c12">12</xref>] and TCRbase [<xref ref-type="bibr" rid="c6">6</xref>][<xref ref-type="bibr" rid="c13">13</xref>]. However, many more models exist, and new models are constantly being proposed (refer to [<xref ref-type="bibr" rid="c14">14</xref>] and [<xref ref-type="bibr" rid="c15">15</xref>] for recent reviews).</p>
<p>Going back just a few years, the majority of models for TCR specificity predictions were based on single chain data, most often CDR3β, since this data was (and still is) much more abundant than paired chain data (e.g. comprising both the α- and β-chain). However, with the emergence of single cell sequencing techniques, the volume of paired data has started to increase. Recent benchmarks have shown that training models on both chains leads to vastly improved predictive performance, compared to training on single chain data alone [<xref ref-type="bibr" rid="c15">15</xref>]. This performance is improved even further when also including the CDR1 and CDR2 sequences of the chains, either as amino acid sequences or implicitly through annotated V- and J-genes (from which the CDR1 and CDR2 sequences are determined).</p>
<p>While similarity-based methods have been shown to perform almost on par with ML-based models in cases where high similarity exist between the training and evaluation data and where many positive TCR observations are present for a given peptide, these approaches tend to be surpassed by ML methods when this similarity is decreased [<xref ref-type="bibr" rid="c6">6</xref>][<xref ref-type="bibr" rid="c15">15</xref>].</p>
<p>Earlier work has been estimated that ∼150 unique TCRs are required to construct an accurate ML prediction model capturing the rules of TCR specificity towards a specific peptide [<xref ref-type="bibr" rid="c16">16</xref>], and that very limited if any predictive power can be maintained when predicting specificity towards peptides, for which no binding TCRs have been recorded [<xref ref-type="bibr" rid="c4">4</xref>][<xref ref-type="bibr" rid="c17">17</xref>]. This lack of extrapolative power is the single most current challenging factor within the field of TCR specificity prediction. In order to predict binding for unseen peptides, models are required to be trained in a pan-specific setup, where a model is trained on data covering many different peptides at once including the peptide sequence as input to the model. Such a setup has with high success been applied for the MHC system where pan-specific models have been developed on data spanning large sets of different MHC molecules resulting in high extrapolation power also for molecules not included in the training data [<xref ref-type="bibr" rid="c18">18</xref>][<xref ref-type="bibr" rid="c19">19</xref>].</p>
<p>While many of the current day models for TCR specificity predictions are trained in this way, no models have so far been able to obtain substantial performance when predicting binding for unseen peptides that are not highly similar to already seen peptides. The main problem limiting the power of extrapolation for these pan-specific models lies in the scarcity of data available for training, especially so for paired-chain data, combined with the problem that the current data is highly imbalanced towards only a few peptides. Moreover, while the availability of data has increased recently, another problem is the high proportion of noise contained within the data produced with the current single cell high-throughput sequencing methods [<xref ref-type="bibr" rid="c5">5</xref>][<xref ref-type="bibr" rid="c20">20</xref>]. Statistical denoising methods have been proposed to deal with this problem [<xref ref-type="bibr" rid="c5">5</xref>][<xref ref-type="bibr" rid="c21">21</xref>]. However, these methods are naturally challenged when dealing with small T cell populations, and due to their statistical nature likely share suboptimal sensitivity (i.e. remove true data) and specificity (i.e. allow false positives to slip through) [<xref ref-type="bibr" rid="c5">5</xref>][<xref ref-type="bibr" rid="c20">20</xref>].</p>
<p>In this manuscript, we seek to address these issues in the context of a large data set of paired TCRs with annotated pMHC specificity. We investigate impacts of refining the machine learning model architecture and training setup to achieve pan-specific models with improved generalization capabilities. Further, strategies such as data denoising in terms of outlier identification in the training data, and inclusion of redundant data during training, is explored. We also investigate a new model architecture which combines the properties of a pan- and peptide-specific model, and explore how a similarity based approach can be integrated into the framework to boost model performance.</p>
</sec>
<sec id="s2">
<title>Materials and Methods</title>
<sec id="s2a">
<title>Training Data</title>
<p>The initial data was acquired from IEDB [<xref ref-type="bibr" rid="c22">22</xref>] and VDJdb [<xref ref-type="bibr" rid="c23">23</xref>] on the 23<sup>th</sup> and 24<sup>th</sup> of August 2022, respectively, using a query to select only positive T-cell assays for MHC class I and Human cells. Additionally, only paired-chain (αβ) data was collected. This resulted in a dataset of 21,825 observations across 631 peptides for IEDB and 27,005 observations across 898 peptides for VDJdb.</p>
<p>This data was subsequently filtered to exclude data originating from 10X sequencing, which was done by manually investigating references with at least 100 observations. Furthermore, filtering was conducted to include only observations with annotated V and J genes and fully specified MHC alleles. In cases where the V and J genes did not have a fully specified allele, the most common allele (*01) was assigned. Furthermore, CDR3 sequences which did not follow the nomenclature of beginning with a cysteine and ending with a phenylalanine (F) or tryptophan (W) were modified to follow this nomenclature by adding a cysteine to the start of the sequence if missing, and adding phenylalanine to the end of the sequence if phenylalanine or tryptophan was not present at the end of the sequence. This filtering resulted in 4439 observations across 405 peptides after merging the two datasets together and dropping duplicate entries.</p>
<p>Next, a dataset from a 10x sequencing study [<xref ref-type="bibr" rid="c24">24</xref>] which was denoised with iTRAP [<xref ref-type="bibr" rid="c21">21</xref>] was included, resulting in a combined dataset of 10,239 observations across 435 peptides.</p>
<p>To retrieve the full TCR sequences required for annotating all CDRs, <italic>Stitchr</italic> [<xref ref-type="bibr" rid="c25">25</xref>] was used. In brief, <italic>Stitchr</italic> looks up the sequences for the V and J genes in IMGT/GENE-DB and attempts to align these sequences with the specified CDR3 amino acid sequence. In case of mismatches in the alignment, the CDR3-proximal residues of the V and J gene products, respectively, are progressively removed until a match can be found. As the alignment failed on either one chain or both for some of the sequences, 9,045 full TCR sequences were retrieved in this step.</p>
<p>In cases where <italic>Stitchr</italic> failed to reconstruct the TCR, a second run of <italic>Stitchr</italic> was performed where tryptophan was added instead of phenylalanine for the CDR3s with the wrong nomenclature. This resulted in the rescue of 20 additional TCR sequences, bringing the total number of full TCR sequences up to 9,065 (88.5% of the inputs given to <italic>Stitchr</italic>).</p>
<p>Finally, the CDR1, CDR2 and CDR3 amino acid sequences were annotated by submitting the full TCR sequences to the <italic>ANARCI</italic> software [<xref ref-type="bibr" rid="c26">26</xref>], which is a tool that is used for annotating the sequences according to the IMGT naming scheme [<xref ref-type="bibr" rid="c27">27</xref>]. Here, CDR1 was defined as position 27 to 38, CDR2 as position 56 to 65 and CDR3 as position 105 to 117.</p>
</sec>
<sec id="s2b">
<title>Redundancy reduction</title>
<p>The CDR-annotated data was redundancy reduced in two steps using the Hobohm 1 algorithm [<xref ref-type="bibr" rid="c28">28</xref>] based on a summed BLOSUM62 encoded kernel similarity [<xref ref-type="bibr" rid="c13">13</xref>] of CDR3α and CDR3β. In the first step, the dataset was split according to peptides, and a redundancy reduction was carried out separately for TCRs belonging to each unique peptide using a 0.95 kernel similarity threshold. Here, only peptides with at least 30 unique TCRs after the first redundancy reduction were kept. This redundancy reduction and filtering resulted in a dataset of 6,415 observations across 26 peptides.</p>
<p>A second redundancy reduction was subsequently carried out also at a 0.95 kernel similarity threshold across all remaining observations and peptides, where the data was sorted by peptide according to TCR count (least abundant to most abundant) in order to limit the risk of removing observations from peptides with few observations. This resulted in the further removal of 68 observations, resulting in a final dataset of 6,353 positive observations across 26 peptides. The amount of redundant data removed by the redundancy reductions is summarized in <bold>Supplementary Table 1</bold>, while information regarding source organism and MHC allele for each peptide is summarized in <bold>Supplementary Table 2</bold>. The number of observations originating from 10X sequence data is also summarized in <bold>Supplementary Table 3</bold>, where the vast majority of 10X data comes from the iTRAP filtered dataset, with a few observations originating from other 10X studies that managed to slip through the initial manual filtering.</p>
</sec>
<sec id="s2c">
<title>Data partitioning and generation of swapped negatives</title>
<p>To prepare the data for model training, this data was randomly split into five partitions, and negatives were generated by swapping the TCRs for a given peptide with TCRs binding to other peptides. Here, such TCRs were only samples from peptides which had a Levenshtein distance greater than 3, to reduce the risk of generating false negatives. For each positive observation, five negative observations were generated using this approach, except for the GILGFVFTL peptide, where all TCRs from the other peptides were used as negatives, since there was not enough data to allow for a 1:5 positive to negative ratio for this peptide (a 1:4.647 ratio was achieved here). The generation of swapped negatives was done separately within each partition, in order to reduce the risk of data leakage.</p>
</sec>
<sec id="s2d">
<title>Baseline model</title>
<p>TCRbase <bold>[<xref ref-type="bibr" rid="c6">6</xref>]</bold>, a distance-based model, was used as the baseline model. For a given peptide, TCRbase calculated the similarity between sets of CDRs found in the test partition to all positive CDR sets found in the remaining partitions. In short, the similarity is calculated per CDR as the mean kernel-similarity of BLOSUM62-encoded kmers ranging from size 1 to 30 between the two sets of CDRs that are compared [<xref ref-type="bibr" rid="c13">13</xref>]. The weighting for the CDRs was set to 1,1,3,1,1,3 for CDR1α-, CDR2α-, CDR3α-, CDR1β-, CDR2β- and CDR3β, respectively, in line with earlier recommendations [<xref ref-type="bibr" rid="c6">6</xref>].</p>
</sec>
<sec id="s2e">
<title>CNN architecture</title>
<p>The CNN architecture for NetTCR 2.1 [<xref ref-type="bibr" rid="c6">6</xref>] was reconstructed in Keras [<xref ref-type="bibr" rid="c29">29</xref>], in preparation for further updates to the architecture. In brief, the original architecture consists of a set of convolutional 1D layers for each input feature, where each layer has 16 filters of kernel size of 1, 3, 5, 7 and 9, respectively, which are activated by a sigmoid activation function. Each layer is then max-pooled, concatenated, and fed to a dense layer of size 32 followed by a linear output layer of size 1, representing the final prediction score. The outputs of both linear layers are activated by a sigmoid activation function.</p>
<p>Except for the first models referred to as NetTCR 2.1 (which ran in PyTorch [<xref ref-type="bibr" rid="c30">30</xref>]), the version 2.2 CNN models described in this paper used a slightly modified architecture compared to NetTCR 2.1. Here, the activation function for the max-pooling layer was replaced with a rectified linear unit (previously sigmoid), a dropout layer was introduced for the concatenated max-pooling output, and the size of the dense layer was doubled to 64 neurons. For the models utilizing dropout, a dropout rate of 0.6 was used. The models referred to here as NetTCR 2.1 uses the original pan-specific NetTCR 2.1 architecture [<xref ref-type="bibr" rid="c6">6</xref>], which also includes convolutional filters for the peptide-sequence.</p>
</sec>
<sec id="s2f">
<title>Embedding</title>
<p>The input features for the CNN models consisted of peptide-, CDR1α-, CDR2α-, CDR3α-, CDR1β-, CDR2β-, and CDR3β-amino acid sequence. These were each represented using a BLOSUM50-embedding (calculated using a normalization factor of 5) and right-padded to the maximum length observed for that feature in the dataset, by assigning a vector of 20 times -1 for each missing residue. For reference, the maximum length observed was 12, 7, 8, 22, 6, 7, and 23 residues for the peptide-, CDR1α-, CDR2α-, CDR3α-, CDR1β-, CDR2β-, and CDR3β-amino acid sequences, respectively.</p>
</sec>
<sec id="s2g">
<title>Training setup and Early Stopping</title>
<p>All CNN models were trained in a nested cross-validation setup with four folds in the inner loop and five folds in the outer loop. Here, three partitions were used for training, one was used for validation, while the remaining partition was used as a test partition to evaluate the performance of the model. For all CNN models, Binary Cross Entropy was used as the loss function, and the Adam optimizer [<xref ref-type="bibr" rid="c30">30</xref>] was used for updating the weights during training. A learning rate of 0.001 was used for training of all models.</p>
<p>A patience of 200 epochs was used for the early stopping for the peptide-specific CNNs, whereas for the pan-specific CNNs, a patience of 100 epochs was used. The increased patience for the peptide-specific models was introduced to allow the models to escape local minima imposed by small training set sizes. For the NetTCR 2.1 models (PyTorch), the validation loss was used as a stopping criterion for early stopping, and validation AUC 0.1 was used as the stopping criterion for the updated models in Keras.</p>
<p>For the pan-specific models, a batch size of 64 was used together with shuffling. For the peptide-specific models, an adaptive batch size was used, which ensured that no batch ended up having less than 32 observations. Here, it was first tested if it was possible to use a batch size of 64 while still having at least 32 observations for the final batch. If not, the default batch size of 64 was progressively increased by 1, until it was ensured that the final batch had at least 32 observations.</p>
</sec>
<sec id="s2h">
<title>Performance Evaluation</title>
<p>The cross-validation setup results in 4 models generated in the inner loop. The test set predictions were then calculated from the average over the 4 predictions for each entry. The performance was evaluated on the 5 concatenated test sets in terms of AUC and AUC 0.1 on a per-peptide basis, as well as the unweighted and weighted average performance across all peptides:
<disp-formula id="ueqn1">
<graphic xlink:href="562001v2_ueqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
Where <italic>M</italic><sub><italic>unweighted</italic></sub> and <italic>M</italic><sub><italic>weighted</italic></sub> is the unweighted and weighted average metric, respectively, <italic>M</italic><sub><italic>peptide</italic></sub> is the metric for a given peptide, <italic>N</italic><sub><italic>peptide</italic></sub> is the number of positive observations for a given peptide, <italic>N</italic><sub><italic>unique peptides</italic></sub> is the number of unique peptides, and <italic>N</italic><sub>total</sub> is the total number of positive observations across all peptides.</p>
<p>A summary of the per-peptide performance of all models is found in <bold>Supplementary File “nettcr_performance.xlsx”</bold>.</p>
</sec>
<sec id="s2i">
<title>Performance comparisons</title>
<p>To assess the difference in performance between models, bootstraps were performed by sampling with replacement from the model predictions 10,000 times and calculating the weighted and unweighted performance metrics for each subsample as described above. The same seed for subsampling and order of predictions was used for all bootstraps, to ensure that performance within a given subsample could be compared between models. The p-value for the null hypothesis that two models had equal performance was then calculated as the number of times that the first model had a higher performance than the second model within the same subsample, normalized by the total number of subsamples.</p>
</sec>
<sec id="s2j">
<title>Weighted loss</title>
<p>A weighted loss was implemented for the pan-specific CNN model to allow the model to focus more on the observations from the less abundant peptides in the training dataset. Here, the binary cross entropy loss for observations from each peptide was weighted according to the formula:
<disp-formula id="ueqn2">
<graphic xlink:href="562001v2_ueqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where N<sub>total</sub> is the total number of observations, N<sub>peptide</sub> is the number of observations for the given peptide, and c is a constant that is used to scale the loss, so the overall loss becomes close to that of the unweighted approach. The value of c was set to 3.8 to ensure that the overall weighted loss was comparable to the training done without sample weighting. For the peptide-specific models, a weight of 1 was used for all samples.</p>
</sec>
<sec id="s2k">
<title>Redundant training dataset</title>
<p>A dataset was constructed based on the primary training dataset, where redundant data from the first redundancy reduction (see <bold>Supplementary Table 1</bold>) was added back by assigning them to the partition of the data point that they were redundant to. Only positive data was added back in this way, and additional swapped negatives were not generated for this dataset to keep it as similar to the original as possible. Models trained on this dataset were evaluated on the original test datasets without redundant data.</p>
</sec>
<sec id="s2l">
<title>Limited training dataset</title>
<p>Using the prediction scores for the validation partitions of the updated peptide-specific CNN model, additional datasets were constructed by removing observations that consistently received a poor prediction score in relation to their designated label. That is, positive observations were removed if they received a validation prediction score of less than the n<sup>th</sup> percentile of the negative prediction scores for the given peptide for all four models that were not trained on that partition, while negative observations were removed if they received a validation prediction score of more than the (1 – n)<sup>th</sup> percentile of the positive validation prediction scores for all four models that were not trained on that partition. Thresholds of n=50, 60, 70, 80, 85, 90 and 95 were tested in this way.</p>
</sec>
<sec id="s2m">
<title>Pre-trained models</title>
<p>A modified version of the NetTCR 2.2 architecture was made to combine the properties of the pan- and peptide-specific models, as shown in <bold><xref rid="fig1" ref-type="fig">Figure 1</xref></bold>. This architecture consists of a pan-specific and a peptide-specific CNN block. The pan-specific CNN block consists of 32 1D convolutional filters of size 1,3,5,7 and 9, respectively for each of the peptide-, CDR1α-, CDR2α-, CDR3α-, CDR1β-, CDR2β-, and CDR3β embeddings. The peptide-specific CNN block consists of 16 1D convolutional filters, also of size 1,3,5,7 and 9, respectively, for the same feature embeddings, except the peptide embedding, as this information is redundant when trained on a single peptide. The outputs from each CNN block are max-pooled with a rectified linear unit activation function, concatenated, and fed to two dropout layers with a dropout rate of 0.6, one for each output of a CNN block.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><p>Architecture of the pre-trained model. The pan-specific CNN block consists of the layers shown in blue, whereas the peptide-specific CNN block consists of the layers shown in red. During the pan-specific training, the weights and biases for the peptide-specific CNN block are frozen, whereas the opposite is the case during the peptide-specific training. The layers shown in purple are kept unfrozen during both training steps.</p></caption>
<graphic xlink:href="562001v2_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Each of the two resulting tensors are fed separately to dense layers with 64 units and sigmoid activation, both of which are connected to a second dense layer with 32 units and a sigmoid activation. The output of the second dense layer is finally connected to an output layer of size 1, which is also activated by a sigmoid activation function, to give a prediction score between 0 and 1.</p>
<p>These models are trained in two rounds. During the first round of training, a pan-specific training is performed. Here the weights in the peptide-specific CNN block are kept frozen, as shown in <bold><xref rid="fig1" ref-type="fig">Figure 1</xref></bold>. This pre-trained model is then used as the starting point for a second round of training performed in a peptide-specific setup, where the weights in the pan-specific CNN block are frozen, while those in the peptide-specific CNN block are unfrozen. During both training rounds, a patience of 100 is used and the maximum number of epochs is set to 200.</p>
</sec>
<sec id="s2n">
<title>CNN – TCRbase ensemble</title>
<p>The pre-trained CNN model was combined with the sequence similarity based TCRbase model [<xref ref-type="bibr" rid="c6">6</xref>][<xref ref-type="bibr" rid="c13">13</xref>]. The predictions for this new ensemble were calculated using the following formula:
<disp-formula id="ueqn3">
<graphic xlink:href="562001v2_ueqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where P<sub>TCRbase_ensemble</sub> is the prediction of the combined ensemble, P<sub>CNN</sub> is the prediction of the CNN model, P<sub>TCRbase</sub> is the prediction from TCRbase, and α is a scaling factor used to give TCRs with low similarity to known binders a harsher penalty. This ensemble was tested on the validation partitions of the full dataset, where α was varied from 0 to 40.</p>
<p>The Pearson correlation coefficients between the α resulting in the best performance in terms of AUC and AUC 0.1, respectively, and the corresponding performance metric for the TCRbase and pre-trained model without scaling, was calculated using the <italic>pearsonr</italic> function from <italic>scipy</italic>.<italic>stats</italic> [<xref ref-type="bibr" rid="c32">32</xref>]. Five samples were used for each peptide, as there were five different validation partitions to consider, resulting in a total of 130 samples for calculating the Pearson correlation coefficients. P-values for the null hypothesis that there was no correlation was also reported using this function.</p>
</sec>
<sec id="s2o">
<title>Percentile-rank rescaling</title>
<p>Prediction scores were rescaled to a percentile rank by comparing the score to the score distribution obtained for 15,957 negative controls paired to the corresponding peptide. These negative controls were obtained from the IMMREP 2022 workshop dataset [<xref ref-type="bibr" rid="c15">15</xref>]. Here, the percentile rank score for a given TCRs was calculated as the percentage of negative controls which had a score above the score of that of the TCR.</p>
</sec>
<sec id="s2p">
<title>Peptide specificity test</title>
<p>To evaluate the models’ ability to correctly identify which peptide is most likely to bind a given TCR, all TCRs were paired with all peptides present within each partition, and predictions were performed by the models which had not seen the given partition during training. The specificity was then calculated per peptide as the number of times that the true peptide-TCR complex was given the highest prediction score, compared to the total number of positive observations in the original dataset for the given peptide. The test was performed on the limited dataset, where the peptides KLGGALQAK, AVFDRKSDAK, NLVPMVATV, CTELKLSDY, RLRAEAQVK, RLPGVLPRA, and SLFNTVATLY were discarded, due to low performance of the full model (AUC 0.1 &lt; 0.65).</p>
</sec>
<sec id="s2q">
<title>Leave most out</title>
<p>To test the models’ ability to learn from small data sets, models were re-trained on small subsets of the original data. For each of the peptides with at least 100 positive observations in the limited training dataset except for KLGGALQAK, AVFDRKSDAK and NLVPMVATV (e.g. GILGFVFTL, RAKFKQLL, ELAGIGILTV, IVTDFSVIK, LLWNGPMAV, CINGVCWTV, GLCTLVAML and SPRWYFYYL were included), new training datasets were constructed by subsampling 5, 10, 15, 20, 25, 50 and 100 positive peptides, respectively, per partition, as well as five negative observations per positive. KLGGALQAK, AVFDRKSDAK and NLVPMVATV were excluded from this analysis, due to low performance of the full model (AUC 0.1 &lt; 0.65). All models trained here were evaluated on the full dataset (not limited).</p>
<p>As a baseline, TCRbase was used to perform predictions on the test partitions, using the positives from the four remaining partitions as the positive database for similarity inference.</p>
<p>In addition, a set of peptide-specific models were also trained on these datasets, using the same hyperparameters as the best (non-pre-trained) peptide-specific model, when evaluated on the full dataset.</p>
<p>A set of pre-trained models were also re-trained on these datasets, where the first training round of the pan-specific CNN was conducted on the leave one out dataset. For each peptide and each number of positives, the pan-specific CNN block was fine-tuned by training for 30 epochs in a pan-specific setup, where observation for the leave-most-out peptide was assigned a sample weight of 1, while the observations for the remaining peptides were assigned a weight of 0.1. Swapped negatives assigned to other peptides than the one the models were trained for were removed for this training, if they originated from an observation belonging to the peptide in question. Following this, the pan-specific CNN block was frozen, and the peptide-specific CNN block was trained on the observations for the peptide of interest.</p>
<p>Finally, an ensemble consisting of the pre-trained models scaled by the TCRbase prediction (α = 10) were evaluated (see <bold>CNN - TCRbase ensemble)</bold>.</p>
<p>Due to the low number of positives for some of the leave-most-out datasets, the default batch size was set to 32 for the peptide-specific training, while the criteria for early stopping and model saving was changed from validation AUC 0.1 to a custom metric taking both validation AUC 0.1 and binary cross entropy loss into account. This custom metric was calculated as:
<disp-formula id="ueqn4">
<graphic xlink:href="562001v2_ueqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
and the model was saved when this value was maximized. A patience of 100 was used for early stopping during the peptide-specific training.</p>
</sec>
<sec id="s2r">
<title>IMMREP 2022 training and evaluation</title>
<p>The labeled training and test data for the IMMREP 2022 workshop [<xref ref-type="bibr" rid="c15">15</xref>] was collected from GitHub (<underline>GitHub - viragbioinfo/IMMREP_2022_TCRSpecificity</underline>) on the 5th of July 2023. The training data was randomly split into five partitions, and models were trained in the same cross-validation as described above, e.g. nested cross-validation for the neural network models and a five-fold cross validation for TCRbase. To make the data compatible with our models, the labels for the negative observations were changed from -1 to 0. The performance of each model was then evaluated on the separate test dataset, using the average in prediction score given by all models resulting from the cross-validation.</p>
<p>A separate redundancy reduced dataset was created based on the IMMREP dataset following the strategy described above. An overview of the number of observations removed by this redundancy reduction is shown in <bold>Supplementary Table 4</bold>.</p>
<p>Swapped negatives were generated within each partition, by randomly sampling TCRs binding to other peptides with a Levenshtein distance of at least three, until a 1:3 ratio of positives to negatives were achieved. Negative controls were first subjected to a redundancy reduction at a 95% similarity threshold, followed by random partitioning. Within each partition, negative controls were sampled in a 1:2 ratio of positive to negatives for each peptide, bringing the total positive to negative ratio up to 1:5.</p>
<p>Models were then trained on this training dataset using nested cross-validation (or five-fold cross-validation for TCRbase), while the performance was evaluated on the test-partitions, which were not seen during training. The average prediction score of the four cross-validation models per test partition was used as the final prediction score for this performance evaluation.</p>
<p>A summary of the per-peptide performance of all models trained and tested on the IMMREP 2022 dataset is found in <bold>Supplementary File “nettcr_IMMREP_performance.xlsx”</bold>.</p>
</sec>
</sec>
<sec id="s3">
<title>Results</title>
<p>Here, we seek to demonstrate step by step how improved low complexity models with state-of-the-art performance for the prediction of TCR specificity can be obtained by dealing with the essential issues related to data imbalance, low data accuracy and data volume. We do this on a large set of data obtained from the public domain covering paired full length TCR sequences with specificity annotated towards a set of 26 unique peptides (for details refer to materials and methods). The machine learning framework applied is a low complexity max-pooled CNN architecture inspired by the original NetTCR model [<xref ref-type="bibr" rid="c16">16</xref>]. This model makes use of 80 convolutional filters for the peptide and each of the 6 CDRs. Due to the limited number of peptides (and HLAs), HLA is not included in the model.</p>
<p>The NetTCR framework has so far performed best in a peptide-specific setup where separate models are trained for individual peptides [<xref ref-type="bibr" rid="c6">6</xref>]. Ideally, one would like to construct pan-specific models trained across multiple peptides at once, since this should allow the model to leverage shared information resulting in boosted predictive power, especially for peptides characterized with few or even no positive TCR observations. However, for NetTCR 2.1, the opposite tendency was observed. This work was however limited to only 6 peptides, and we therefore first investigated if this conclusion still held true in the context of our data set with increased peptide coverage. The result of this analysis can be seen in <bold><xref rid="fig2" ref-type="fig">Figure 2</xref></bold> and demonstrates that peptide-specific models also here are superior to the pan-specific model.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><p>Per peptide performance of the peptide-specific and pan-specific NetTCR 2.1 in terms of AUC, when trained and evaluated on the new dataset. The peptides are sorted based on the number of positive observations from most abundant to least abundant, with the number of positive observations listed next to the peptide sequence. The unweighted (direct) mean of AUC across all peptides is shown furthest to the left, while the weighted mean is shown second furthest to the left. The weighted mean is weighted by the number of positive observations per peptide and puts more emphasis on the peptides with the most observations.</p></caption>
<graphic xlink:href="562001v2_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<sec id="s3a">
<title>Improving the pan-specific model</title>
<sec id="s3a1">
<title>Updating the model architecture for pan-specific predictions</title>
<p>One potential source of the low performance for the pan-specific model is the high imbalance in the number of observations per peptide resulting in the model focusing/overfitting on the more abundant peptides. To investigate this, we first introduced a dropout-layer with a dropout rate of 0.6 to the architecture for the concatenated output of the max-pooling layer, while also doubling the number of neurons for the dense layer from 32 to 64 to allow for sufficient flow of information. Additionally, this model was rebuilt in Keras [<xref ref-type="bibr" rid="c29">29</xref>] and the stopping criterion was changed from validation loss to validation AUC 0.1. As shown in <bold><xref rid="fig3" ref-type="fig">Figure 3</xref></bold>, this resulted in a highly significant increase in performance (bootstrap test resulting in p&lt; 0.0001 for all tested metrics).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><p>Boxplot of AUC of the pan- and peptide-specific NetTCR 2.1 and 2.2 models, respectively. The NetTCR 2.2 models include the updates to the model architecture, with the primary change being the introduction of dropout for the concatenated max-pooling layer (dropout rate = 0.6). Both the introduction of dropout and sample weights are shown to result in considerably improved performance for the pan-specific model. Separate boxplots are shown for all peptides, as well as separately for peptides with at least 100 positive observations and peptides with less than 100 positive observations, to highlight the effect of introducing dropout and sample weight for the least abundant peptides.</p></caption>
<graphic xlink:href="562001v2_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>To further deal with the imbalance problem, we next introduced a peptide specific sample weight so that the loss was increased for peptides with a low number of positive observations (for details refer to methods). This is based on the notation that the model then would focus more on the less abundant peptides when updating the weights. As demonstrated in <bold><xref rid="fig3" ref-type="fig">Figure 3</xref></bold>, this approach resulted in a further increase in performance for the less abundant peptides, whereas the performance for the more abundant peptides was largely unaffected. Here, a significant increase in performance was observed for the unweighted mean AUC (p= 0.0026) and AUC 0.1 (p&lt;0.0001)). Moreover, when only considering the peptides with less than 100 positive observations, the improvement in performance was significant across all metrics (p=0.0101, p=0.0035, p&lt;0.0001 and p&lt;0.0001 for AUC, weighted AUC, AUC 0.1 and weighted AUC 0.1, respectively).</p>
<p>Next, the impacts of the updates to the model architecture and training strategy on the performance of peptide-specific models was investigated. As expected, these results (<bold><xref rid="fig3" ref-type="fig">Figure 3</xref></bold> and <bold>Supplementary Figure 1</bold>) demonstrated a limited gain in performance compared to NetTCR-2.1 - Peptide, which was however significant for all metrics (p=0.0337 for AUC, and p&lt;0.0001 for AUC 0.1 and weighted AUC/AUC 0.1). Interestingly, the updated pan-specific model significantly outperformed the updated peptide-specific models in terms of both unweighted (p&lt;0.0001) and weighted AUC (p=0.0004), and the performance gain was especially observed for the less abundant peptides. However, in terms of AUC 0.1, the updated peptide- specific model (NetTCR-2.2 - Peptide) maintained a superior performance (see <bold>Supplementary Figure 1</bold>) (p=0.0008 and p&lt;0.0001 for AUC 0.1 and weighted AUC 0.1, respectively). We will later address how to get the best of the two models later in the <bold>Pre-training</bold> section.</p>
</sec>
<sec id="s3a2">
<title>Reusing redundant data does not lead to better performance</title>
<p>The results until now have been generated based on redundancy reduced data. That is data where redundant data have been removed based on a Hobohm-1 like redundancy reduction algorithm (for details see methods). However, as data is very sparse, one could argue that a better approach would be to reuse redundant data, either by performing clustering when making the data partitions, or by adding back redundant data to the same partition as the data that it was redundant to. To test how such a strategy would affect the performance of the model, a new dataset was created using the latter approach. To keep the performance evaluation fair, redundant data were only re-introduced to the training dataset while the original dataset without redundant observations was used for testing and performance evaluation. The total number of redundant observations for each peptide from the first redundancy reduction is shown in <bold>Supplementary Table 1</bold> (note that those from the second reduction are not added back).</p>
<p>As shown in <bold>Supplementary Figure 2</bold>, neither the peptide-nor the pan-specific model benefitted from reusing the redundant data. In fact, the performance of the pan-specific model was significantly reduced in terms of unweighted AUC (p=0.0041) and weighted AUC 0.1 (p=0.0395). This is likely caused by the larger imbalance in observations per peptide introduced by the redundant data, as a large proportion of these observations came from the already abundant GILGFVFTL peptide.</p>
</sec>
<sec id="s3a3">
<title>Removing potential outliers from training leads to better performance</title>
<p>During the testing of our models, we observed that several peptides consistently had a performance much lower compared to other peptides characterized with similar amounts of data. One thing shared by these peptides is that 10X sequencing made up the vast majority of the experimental source of the recorded TCRs, as shown in <bold>Supplementary Table 3</bold>. For most of the peptides with poor performance (KLG, AVF, IVT, RLR, RLP, SLF), only 10X sequencing data was available. On the other hand, not all 10X data are bad, as illustrated by RAKFKQLL which is a high performing peptide only covered by 10X data (see for instance <bold>Supplementary File “nettcr_performance.xlsx”</bold>). Further, when comparing the predicted score distributions between positive and negative TCRs, we observe examples of outliers with low scoring positive TCRs and high scoring negative TCRs across all peptides (see <bold>Supplementary Figure 3</bold>). These observations strongly suggest that the data contain a certain degree of wrongly labeled entries, and that these could be a source to limit the performance of the models. Inspired by the plot in <bold>Supplementary Figure 3</bold>, outliers were identified by scoring TCRs using the NetTCR-2.2 peptide-specific model, and positive and negative TCR outliers assessed based percentile scores estimated from the contrary TCR pool (for details refer to <bold>Material and Methods</bold>). Using this approach, TCRs were removed from the training data based on percentile thresholds of 50%, 60%, 70%, 80%, 85%, 90% and 95% respectively. That is, for a threshold of 70%, a positive TCR was identified as an outlier if it had a predicted score below the lower 70% percentile score range of the negative TCRs for all models predicting on the validation data (four models per partition). Next, pan-specific models were trained using the “limited” data for training and validation, while evaluating the models based on the full dataset.</p>
<p>An overall increase in performance for the models trained on the limited datasets was observed up until the 70<sup>th</sup> percentile datasets, after which the performance gain stagnated (see <bold>Supplementary Figure 4)</bold>. Since the difference in performance between the 80<sup>th</sup> and 70<sup>th</sup> percentile model was statistically insignificant for any of the bootstrap metrics (p&gt;0.08 in all of weight and unweight performance metrics), the 70<sup>th</sup> percentile dataset for removing outliers from training was selected, since this filtering removed the least amount of data. As seen in <bold>Supplementary Figure 5</bold>, more observations were, as expected, removed for the peptides with poor performance, indicating a higher presence of outliers for these peptides. The average performance of the model trained on the 70<sup>th</sup> percentile dataset was significantly higher than the model trained on the full dataset (p=0.0001, p&lt;0.0001, p=0.0054 and p&lt;0.0001 for AUC, weighted AUC, AUC 0.1 and weighted AUC 0.1, respectively). As shown in <bold><xref rid="fig4" ref-type="fig">Figure 4</xref></bold>, a higher performance was also consistently observed for the peptides which originated from 10X sequencing, apart from the RLP peptide, which obtained a slightly lower AUC (-0.0066). While most peptides benefitted from the removal of potential outliers, some peptides did receive a substantially lower performance. It should however be noted that the performance evaluation was conducted on the full dataset, meaning that if a peptide has many actual outliers, the performance may be underestimated, since these outliers are included in the evaluation.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><p>Difference in AUC between pan-specific CNN trained on the limited dataset (70<sup>th</sup> percentile) and full dataset. Peptides with TCRs originating solely from 10x sequencing are highlighted in red. The performance was in both cases evaluated per peptide on the full dataset. A positive ΔAUC indicates that the model trained on the limited dataset performs better than the model trained on the full dataset.</p></caption>
<graphic xlink:href="562001v2_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</sec>
<sec id="s3b">
<title>Improving the peptide-specific models</title>
<sec id="s3b1">
<title>Pre-training</title>
<p>As described earlier, the pan-specific model was generally observed to excel in terms of AUC, whereas the peptide-specific model was better in terms of AUC 0.1.</p>
<p>To benefit from the strengths of both of these models, a new model architecture was investigated. In brief, this architecture consists of two blocks of CNNs; one which is used for training on a pan-specific dataset to learn a general representation of binding, while the other block is used to train on a peptide-specific dataset to better learn the pattern of binding specific to a certain peptide (for details refer to methods). The pan-specific CNN block was trained first, with frozen initial weights and biases in the peptide-specific CNN block. After pre-training the pan-specific CNN block, these pan-specific CNN layers were frozen, whereas the layers for the peptide-specific CNN were allowed to update during the peptide-specific training.</p>
<p>As shown in <bold><xref rid="fig5" ref-type="fig">Figure 5</xref></bold>, this pre-trained model outperformed both the pan- and peptide-specific models. This improvement was found to be highly significant (p&lt;0.0001) across all metrics, when compared to the bootstrap of the pan-specific model, which was also the case when comparing to the peptide-specific model (p&lt;0.0001, p&lt;0.0001, p=0.0008 and p=0.0021 for AUC, weighted AUC, AUC 0.1 and weighted AUC 0.1, respectively). Furthermore, this pre-trained model had higher performance across all metrics than a simple ensemble of the pan-specific and peptide-specific models (data not shown).</p>
</sec>
<sec id="s3b2">
<title>TCRbase ensemble</title>
<p>Earlier work has demonstrated a high performance of simple similarity-based models for prediction of TCR-specificity [<xref ref-type="bibr" rid="c15">15</xref>]. We therefore wanted to investigate if the predictive power could be further improved by integrating the sequence-similarity based predictions of TCRbase [<xref ref-type="bibr" rid="c6">6</xref>] into our modeling framework. In short, TCRbase makes predictions by calculating a similarity between a given TCR and the positive TCRs for a given peptide in terms of a sum over the paired similarities over the 6 CDR loops [<xref ref-type="bibr" rid="c6">6</xref>]. TCRbase was integrated in terms of a simple scaling factor so that the pre-trained CNN model predictions were multiplied by the TCRbase predictions lifted to a power of α&gt;0. The optimal value of α was here estimated based on the validation partitions, and the test partitions were removed from the positive database given to TCRbase, to avoid overfitting and performance overestimation.</p>
<p>As shown in <bold>Supplementary Figure 7A</bold>, the use of TCRbase predictions as a scaling factor resulted in a consistent increase in performance across both unweighted mean AUC and AUC 0.1. Whereas the mean AUC was only affected slightly by this scaling (maximum increase of 0.00212 at α=14), a greater increase in performance was observed in terms of AUC 0.1 (maximum increase of 0.00723 at α=8). Overall, the integration of TCRbase led to a significant improvement in performance for all metrics (p&lt;0.0001). It should however be noted that while the use of the TCRbase scaling generally improved performance, the optimal α factor varied between each validation partition and cross-validation model (see <bold>Supplementary Figure 7B</bold>). Nevertheless, the median of the optimal α across the cross-validation models was 10 in the case of AUC 0.1, which strengthened our confidence in using this α as the base scaling factor. Despite these variable observations, we for the sake of consistency stick to an α of 10 for the remaining analysis in this paper. The performance per peptide when using the α=10 scaling is shown in <bold><xref rid="fig5" ref-type="fig">Figure 5</xref></bold> (AUC), as well as <bold>Supplementary Figure 6</bold>.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><p>Per peptide performance of the updated peptide-specific, pan-specific, and pre-trained CNN in terms of AUC, when trained on the limited training dataset and evaluated on the full dataset. The peptides are sorted based on the number of positive observations from most abundant to least abundant, with the number of positive observations listed next to the peptide sequence. The unweighted (direct) mean of AUC across all peptides is shown furthest to the left, while the weighted mean is shown second furthest to the left. The weighted mean is weighted by the number of positive observations per peptide and puts more emphasis on the peptides with the most observations.</p></caption>
<graphic xlink:href="562001v2_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6.</label>
<caption><p>Percentage of correctly chosen true peptide-TCR pairs for each peptide, when evaluated using the direct prediction score (blue) and the percentile rank (orange) of the TCRbase ensemble on the limited dataset. KLGGALQAK, AVFDRKSDAK, NLVPMVATV, CTELKLSDY, RLRAEAQVK, RLPGVLPRA, and SLFNTVATLY were excluded from this analysis due to low predictive performance for these peptides (AUC 0.1 &lt; 0.65). The numbers next to the peptides indicate the number of positive TCRs in the filtered dataset, and the dashed line indicates the expected value for a random prediction.</p></caption>
<graphic xlink:href="562001v2_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We also observed that the optimal value for α varied between peptides, with a slight positive correlation to the performance of TCRbase for the given peptide (see <bold>Supplementary Table 5</bold>), suggesting the peptides with high TCRbase performance benefit more from the α rescaling.</p>
<p>To investigate further how the integration of TCRbase predictions benefitted the performance, we in <bold>Supplementary Figure 8</bold> plotted the difference in true positive rates at different false positives rates between the TCRbase ensemble and the pre-trained CNN alone. This figure demonstrates that the benefit from TCRbase mainly consist of increasing the discrimination between binders and non-binders at thresholds corresponding to low FPRs (0 &lt;= FPR &lt;= 0.15), whereas the predictions may become slightly worse than without scaling when the threshold for binders are set to that of an FPR higher than 0.3. This result thus suggests that scaling the predictions of neural network models based on similarity to known binders is mostly beneficial when a high specificity is desired.</p>
</sec>
<sec id="s3b3">
<title>Percentile rank rescaling</title>
<p>The prediction scores of the final CNN+TCRbase model ensemble fall between 0-1 but display substantial score distribution variations between peptides (see <bold>Supplementary Figure 9</bold>), which makes it hard to directly compare prediction scores between peptides. A common approach to resolve this is to apply percentile rank scores [<xref ref-type="bibr" rid="c6">6</xref>]. Here, we used the CNN+TCRbase model to predict scores for a set of 15,957 negative TCRs for each peptide, which was obtained from the dataset for the IMMREP 2022 workshop [<xref ref-type="bibr" rid="c15">15</xref>], and used these scores to calculate a percentile rank for each observation in our test data. Here, the percentile rank is defined as the proportion (in percentage) of negative controls, which scored higher than the given observation. As shown in <bold>Supplementary Figure 9</bold>, the percentile ranks for binders between peptides are more similar when compared to the direct prediction scores.</p>
</sec>
<sec id="s3b4">
<title>Peptide Specificity Test</title>
<p>The performance evaluations performed so far have focused on the ability to predict whether or not a TCR can bind to a given peptide. Another important aspect is the ability to predict the correct peptide target of a given TCR. To investigate the performance in this context, each positive TCR was scored against all peptides, and a performance metric was estimated in terms of how often the correct TCR-peptide pair was given the highest score (or lowest percentile rank). The result of this analysis is shown in <bold><xref rid="fig6" ref-type="fig">Figure 6</xref></bold>, which was conducted on the limited dataset, while excluding observations for low performing peptides with an AUC &lt; 0.8 and AUC 0.1 &lt; 0.65 for the TCRbase ensemble (see <bold><xref rid="fig5" ref-type="fig">Figure 5</xref></bold> and <bold>Supplementary Figure 6</bold>). This dataset thus consists of 21 peptides, and a random predictor is expected to obtain a performance of 1/19 ∼ 0.05. The results show that the model clearly outperforms this random baseline for all peptides. Also, a higher performance is observed for the three most abundant peptides in this analysis (GILGFVFTL, RAKFKQLL and ELAGIGILTV). Furthermore, it is seen that there is a slight tendency for a lower percentage of correctly chosen peptide-TCR pairs, as the number of positive TCRs for the training becomes lower. Interestingly, the percentage of correctly chosen pairs correlates very strongly with the AUC and the AUC 0.1 of the peptides. In the case of ranks when using direct prediction, the PCC of the percentage of correct predictions to AUC and AUC 0.1 were 0.740 and 0.830, respectively (sample size of 19 peptides). This high correlation was also observed for percentile ranks, with a PCC of 0.706 and 0.873 to AUC and AUC 0.1, respectively.</p>
<p>Furthermore, a tendency of lower average ranks for the pre-trained and TCRbase ensemble models compared to the other models was observed (see <bold>Supplementary Figure 10</bold>). However, while the application of percentile rank widened the range of average rank per peptide, it generally resulted in a decrease of the median rank for most peptides.</p>
<p>To better understand why the models sometimes failed to predict the correct peptide-TCR pair, we looked at the distribution in percentile rank of the top scoring pairs. As <bold><xref rid="fig7" ref-type="fig">Figure 7</xref></bold> shows, the binding TCRs for the peptides with a high proportion of correctly chosen pairs (GILGFVFTL and RAKFKQLL) is characterized by having a low percentile rank of around 0.1 (see “Top TP”).</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7.</label>
<caption><p>Boxplot of percentile ranks per peptide in the rank test, with KLGGALQAK, NLVPMVATV, CTELKLSDY, RLRAEAQVK, RLPGVLPRA, and SLFNTVATLY excluded. AVFDRKSDAK was included as an example of a peptide with a poor rank in the rank test. Top TP: Percentile rank of the correctly chosen pairs. Second TN: Percentile rank of the second-best pair, when the correct pair was chosen. Top FP: Percentile rank of the best scoring pair when the incorrect pair was chosen. FN: Percentile rank of the correct pair, when the incorrect pair was chosen.</p></caption>
<graphic xlink:href="562001v2_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Peptides which had poor predictive performance (mainly those excluded in <bold><xref rid="fig6" ref-type="fig">Figure 6</xref></bold>) generally had a poor specificity with less than 20% peptide-TCR pairs chosen correctly. These peptides are characterized by having a much higher percentile rank for the true peptide:TCR pair, as exemplified by AVFDRKSDAK in <bold><xref rid="fig7" ref-type="fig">Figure 7</xref></bold>, which again indicates the presence of potential outliers for these peptides.</p>
<p>Interestingly, the percentile ranks for the TCR pairs of two of the peptides FEDLRLLSF and FEDLRVLSF are characterized by having a very low percentile rank for the second highest scoring pair. This appears to be at least partially due to a high shared similarity between these two peptides, causing the model to mislabel the top scoring peptide. For example, for FEDLRLLSF, the best scoring peptide was FEDLRVLSF 22.2% and 25.9% of the time for predictions and percentile ranks, respectively. For FEDLRVLSF, the best scoring peptide was FEDLRLLSF 23.8% and 38.1% of the time for predictions and percentile ranks, respectively.</p>
<p>Generally, it should also be noted that in cases where the correct peptide-TCR is not given the lowest rank, the correct peptide-TCR pair is given a very high percentile rank, most often greater than 20 (refer to FN label in <bold><xref rid="fig7" ref-type="fig">Figure 7</xref></bold>). The same observation holds for the top scoring peptides in these cases (top FP in <bold><xref rid="fig7" ref-type="fig">Figure 7</xref></bold>). This once again indicates that there might be some potential wrongly labeled outliers in the positive data, even when the data is filtered with the use of the model predictions.</p>
</sec>
</sec>
<sec id="s3c">
<title>Performance when data is scarce or absent</title>
<p>Having demonstrated a robust and high performance of the CNN-pan-specific model in the context of TCR specificity towards known peptides, i.e. peptides included in the training data, we next turned to the uttermost challenging question namely prediction of TCR specificity towards novel peptides.</p>
<p>To investigate this, we trained models in a pan-specific leave-one-out setup, where for a given peptide, both positives and negatives generated from that peptide were removed from the training data, thus preventing data leakage. This was done both for the NetTCR 2.1 and the updated NetTCR 2.2 architecture. For this experiment, the limited training dataset with outliers removed was used. This resulted in 26 different models, each of which was evaluated on the peptide dataset for the left-out peptide. As shown in <bold><xref rid="fig8" ref-type="fig">Figure 8</xref></bold>, a performance in terms of AUC slightly better than random was observed for most of the peptides. Furthermore, a noticeable improvement in performance was seen for the updated NetTCR 2.2 model. However, the performance was almost completely random when evaluated in terms of AUC 0.1, as can be seen in <bold>Supplementary Figure 11</bold>. The only peptides with non-random AUC 0.1 performance were FEDLRLLSF and FEDLRVLSF, and this was only the case for the NetTCR-2.2 model architecture. These peptides differ by only a single amino acid, and the result thus indicates that the updated model in this case is able to transfer the knowledge gained from training on another similar peptide, which was not the case with the old architecture.</p>
<fig id="fig8" position="float" fig-type="figure">
<label>Figure 8.</label>
<caption><p>Per peptide performance of the old (NetTCR 2.1) and updated (NetTCR 2.2) pan-specific CNN models trained in a leave-one-out setup. The performance was evaluated in terms of AUC on the full dataset.</p></caption>
<graphic xlink:href="562001v2_fig8.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We next extended the analysis to a leave-most-out setting to investigate how little data is required in order to train models with non-random performance. Here, a number of training datasets were generated by subsampling the limited dataset in order to achieve 5, 10, 15, 20, 25, 50 and 100 positive observations, respectively, per peptide. Swapped negatives were also subsample in this way, keeping a ratio of 1:5 between binders and non-binders. This was only done for the peptides GILGFVFTL, RAKFKQLL, ELAGIGILTV, IVTDFSVIK, LLWNGPMAV, CINGVCWTV, GLCTLVAML and SPRWYFYYL, since they all had substantial performance (AUC 0.1 &gt;= 0.65) for the full model and more than 100 positive observations to begin with.</p>
<p>In the case of the pre-trained model, the leave-one-out model was used as the startpoint. Rather than having to re-train the full pan-specific CNN block (which may be impractical, if a user wants to re-train the model on a new peptide), we decided to instead fine-tune this CNN block by adding the subsampled data to the leave-one-out training data, while setting the sample weight to 1 for the new peptide observations, and 0.1 for the remaining observations. The pan-specific CNN block was then trained for 30 epochs in this way (for details refer to methods).</p>
<p>As shown in <bold><xref rid="fig9" ref-type="fig">Figure 9</xref></bold> and <bold>Supplementary Figure 12</bold>, all models demonstrated a non-random performance with as low as 5 positive observations. As expected, a general increase in performance was observed as more and more data was available for training. This was especially the case for the TCRbase ensemble model, which strongly outperformed all other models with an AUC close to 0.8, when the number of training points surpassed 15.</p>
<fig id="fig9" position="float" fig-type="figure">
<label>Figure 9.</label>
<caption><p>Performance in terms of AUC of various models trained on increasing amounts of data. These models were trained on the following peptides: GILGFVFTL, RAKFKQLL, ELAGIGILTV, IVTDFSVIK, LLWNGPMAV, CINGVCWTV, GLCTLVAML and SPRWYFYYL. The pre-trained models were based on the leave-one-out model, and afterwards fine-tuned and re-trained on the smaller training datasets.</p></caption>
<graphic xlink:href="562001v2_fig9.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Noticeably, the performance of the baseline TCRbase model did not improve nearly as much as the CNN-based models when the amount of training data was increased, suggesting that the CNN models are able to benefit much more from the increased amount of information present in larger datasets.</p>
</sec>
<sec id="s3d">
<title>External evaluation</title>
<sec id="s3d1">
<title>IMMREP 2022 Benchmark</title>
<p>Having defined a novel and improved architecture and framework for training models for prediction of TCR specificity, we next turned to an independent data set to confirm its robustness. Here, we applied the datasets from the IMMREP 2022 workshop [<xref ref-type="bibr" rid="c15">15</xref>], keeping all model hyperparameters unchanged compared to the different models described above. As shown in <bold><xref rid="fig10" ref-type="fig">Figure 10</xref></bold>, the updated peptide-specific models, NetTCR-2.2 - Peptide, significantly outperformed NetTCR 2.1 (p=0.0367, p=0.0263, p=0.0087 and p=0.0034 for AUC, weighted AUC, AUC 0.1 and weighted AUC 0.1, respectively). With an unweighted average AUC of 0.8476, this model performed on par with the best performing model in terms of AUC at the IMMREP workshop, TCRex αβ [<xref ref-type="bibr" rid="c33">33</xref>], with an average unweighted AUC of 0.8473. However, to our surprise, and contrary to our findings on the original dataset of this paper, the NetTCR-2.2 - Pre-trained model underperformed compared to the peptide-specific model, even though part of this performance loss was recovered when introducing the TCRbase scaling on the pre-trained model. Furthermore, the NetTCR-2.2 - Pan model was also found to perform much worse than expected.</p>
<fig id="fig10" position="float" fig-type="figure">
<label>Figure 10.</label>
<caption><p>Boxplot of reported unweighted AUC per peptide for the models in the IMMREP benchmark, as well as the updated NetTCR 2.2 models. Except for the updated NetTCR 2.2 models (NetTCR 2.2 - Pan, NetTCR 2.2 - Peptide, NetTCR 2.2 - Pre-trained and TCRbase ensemble) the performance of all models is equal to the reported performance in the IMMREP benchmark. The color of the bars indicates the type of input used by the model. Machine-learning models are labeled with black text, whereas distance-based models are labeled with blue text. Note that the TCRbase ensemble is a mixture between a machine-learning and distance-based model.</p></caption>
<graphic xlink:href="562001v2_fig10.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We further evaluated the peptide specificity of the models by calculating the average rank of each peptide in the benchmark specificity test dataset, and compared the ranks to those of the other methods included in the IMMREP benchmark. As is shown in <bold>Supplementary Figure 13</bold>, also here the average ranks of the updated models were found to be comparable to the best performing models in the IMMREP benchmark.</p>
<p>To understand the source of the relatively poor performance of the pan-specific models in this benchmark, we further investigated the IMMREP datasets. Even though the construction of IMMRep datasets was made to ensure that no positive TCR was shared between the training and test data sets, inspection of the data revealed that swapped negatives were present in the training data, which originated from positive peptides in the test data. When a pan-specific model is trained on such data, this results in certain TCRs being “seen” only as non-binders only during the model training. Given this, the model will likely assign such TCRs as negative when asked to predict the test data. This problem is limited to pan-specific models hence explaining the reduced performance compared to the peptide-specific model.</p>
<p>Further, as shown in <bold>Supplementary Table 6</bold>, the degree of redundancy between training and test data was relatively high for many of the peptides. This redundancy between the IMMREP test and training data may result in test performance overestimation since the models observe similar TCR-peptide combinations during training.</p>
<p>When comparing the per peptide AUC of all models to the per peptide redundancy between training- and test data, we observed a Pearson correlation of 0.428 (sample size of 370), which was a much stronger correlation than observed between the number of training observations and AUC (0.062).</p>
<p>To address these issues, we applied the redundancy reduction and swapped negative data generation (generating the swapped within each data partition) from our own data pipeline on the training data, while ensuring a positive to swapped negative ratio of 1:3 and positive to negative control ratio of 1:2, as was the case for the original IMMREP dataset. The performance of the different models was next assessed via nested cross-validation on this dataset, rather than the original left-out test data. As shown in <bold><xref rid="fig11" ref-type="fig">Figure 11</xref></bold>, this data setup once again resulted in the pre-trained models outperforming the peptide-specific models, and that the use of TCRbase scaling together with the pre-trained model resulted in the overall best performance, in line with our earlier findings. Moreover, the overall performance of the models was found to drop, especially for the peptides with a high degree of redundant data, confirming a degree of performance overestimation in the original benchmark (see <bold>Supplementary File “nettcr_IMMREP_performance.xlsx”</bold> for individual peptide performance).</p>
<fig id="fig11" position="float" fig-type="figure">
<label>Figure 11.</label>
<caption><p>Boxplot of unweighted AUC per peptide for the NetTCR 2.1 and 2.2 models, when trained and evaluated on the redundancy reduced dataset. The evaluation was performed using a nested cross-validation setup.</p></caption>
<graphic xlink:href="562001v2_fig11.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</sec>
</sec>
<sec id="s4">
<title>Discussion</title>
<p>Here, we have presented an improved NetTCR framework for prediction of TCR specificity including updates to the training data, modeling architecture and training setup, with the goal of increasing the overall performance and generalization power of the model. First and foremost, the update includes a substantial expansion of the training data to 26 peptides, up from the six peptides available for predictions in NetTCR 2.1. The model updates included dropout and peptide-specific sample weights to deal with data imbalance, forcing the model to focus more evenly on all peptides, and resulted in vastly improved performance in the pan-specific setup. This performance gain was particularly pronounced for peptides with few observed binding TCRs. The updated architecture in the form of more hidden units in the dense layer, the change from sigmoid to ReLu activation for the max-pooling, and the introduction of dropout further improved the NetTCR model. A variation of the updated architecture was also investigated, which combined the properties of the pan-specific and peptide-specific models, by having two separate CNN blocks where one block was pre-trained separately in pan-specific setup, followed by training the second block in a peptide-specific setup. This pre-training setup resulted in an additional increase in performance, mainly for the least abundant peptides.</p>
<sec id="s4a">
<title>How to best use available data for training</title>
<p>The scarness of paired TCR data means that it often could be tempting to include all available data to the fullest, and include all redundant data for training. However, as we show here, the addition of redundant data in the training does not lead to improved performance. In fact, we found that the addition of redundant data may cause pan-specific models to underperform if the peptide imbalance of data is not accounted for, since the inclusion of redundant data often results in a further increased peptide imbalance.</p>
<p>The observation that the predictive performance for some peptides was much lower than expected given the amount of available training data, led us to believe that outliers in the form of false positives might be a potential issue. Furthermore, many of these peptides had in common that the main source of data was 10X sequencing [<xref ref-type="bibr" rid="c24">24</xref>], a platform known to have a high proportion of false annotations [<xref ref-type="bibr" rid="c5">5</xref>][<xref ref-type="bibr" rid="c21">21</xref>]. To deal with this issue, we implemented a machine learning driven approach for outlier detection using the predictions of the peptide-specific NetTCR models to identify observations which repeatedly received very poor predictions. The removal of these potential outliers from the training led to significantly improved test performance. It should also be noted that the data applied in the study included denoising for most of the 10X data in the form of ITRAP [<xref ref-type="bibr" rid="c21">21</xref>], which together with ICON [<xref ref-type="bibr" rid="c5">5</xref>] have earlier been shown to properly remove outliers [<xref ref-type="bibr" rid="c20">20</xref>]. Nevertheless, our results suggest that some outliers had escaped these denoising steps, indicating that denoising methods should still be improved upon. While the use of our model predictions to remove outliers resulted in improved performance, we believe that this approach should only be considered a proof-of-concept, and that more elaborate ways to identify outliers merit further investigation.</p>
</sec>
<sec id="s4b">
<title>Integrating distance-based methods can improve performance of ML models</title>
<p>Inspired by the observation that sequence similarity distance-based models often achieve very high performance for the prediction of TCR specificity [<xref ref-type="bibr" rid="c15">15</xref>], we investigated if integrating TCRbase predictions could improve the performance of our models. We integrated TCRbase by scaling the CNN prediction with the TCRbase prediction to a power of α, and found that the performance of this ensemble (Pre-trained + TCRbase) achieved a significantly improved performance in terms of AUC and AUC 0.1. Interestingly, further inspections revealed that the increased performance mainly resulted from improved discrimination of binders and non-binders when the binding-threshold was set to result in a low FPR. Given how we are often interested in keeping the FPR very low for TCR specificity predictions, the simple integration of TCRbase can thus vastly benefit many real-world use-cases for TCR specificity predictions. While we decided to use a general α of 10 for the TCRbase scaling, it is possible that performance could be improved further, if α is allowed to be flexible depending on the peptide. For example, one could imagine that a peptide with a very high TCRbase predictive performance could benefit from a higher α, compared to another peptide with a lower TCRbase performance. Furthermore, the amount of positive data also influences which α is optimal. It would therefore be interesting to further investigate this, as this could potentially lead to further improved performance. Finally, investigating the relation between TPR and FPR at different values of α could also benefit many actual use-cases, considering that the optimal alpha value could be determined based on the desired maximum FPR rate.</p>
</sec>
<sec id="s4c">
<title>Predictions for unseen peptide</title>
<p>It has repeatedly been shown that predicting TCR specificity for “unseen” peptides is extremely hard, especially for peptides that are very dissimilar to the peptides included in the training data [<xref ref-type="bibr" rid="c4">4</xref>][<xref ref-type="bibr" rid="c17">17</xref>]. Investigating the performance of the pan-specific models in a leave-one-out setup revealed that the performance on unseen peptides overall remained very poor, also for the updated NetTCR-2.2 model. While the performance for NetTCR-2.2 in terms of AUC was generally better than random, the performance in terms of AUC 0.1 was very close to random, severely limiting its general potential use. Nevertheless, we observed that the performance of NetTCR 2.2 in the leave-one-out setup was improved when compared to NetTCR 2.1, especially for two peptides sharing a high mutual similarity. While the performance for these two peptides was still low compared to that observed in the full training setup, this result affirms that given a broad enough peptide coverage, pan-specific models have the potential to predict binding also for unseen peptides.</p>
</sec>
<sec id="s4d">
<title>Improved performance when data is scarce</title>
<p>While high performance for unseen peptides so far remains very challenging, another important issue is to boost performance for peptides with relatively few observations. Performing a leave-most-data-out, a substantial increase in performance was observed compared to the leave-out-out experiment with as little as five training observations, and already with 15 observations, a satisfactory performance was observed. This is in great contrast to earlier work, where a number of ∼150 was suggested to be required for modeling TCR specificity [<xref ref-type="bibr" rid="c16">16</xref>]. These results thus suggest that the pre-trained models can beneficially be used as seeds for the development of peptide-specific models allowing for rapid fine-tuning to new data.</p>
<p>We also observed that the TCRbase ensemble based on the pre-trained model consistently outperformed any of the other models, both when data was very scarce, but also as the amount of training data was increased, highlighting the benefits of integrating distance-based methods for predictions. As a final note, we would also expect that the discrepancy between the performance of the peptide-specific- and pre-trained model will become larger as the number of peptides to train on increases in the future, as a pan-specific CNN block trained on a more diverse dataset should allow for better generalization.</p>
</sec>
<sec id="s4e">
<title>Performance on IMMREP 2022 benchmark</title>
<p>To compare the updated models with other models for TCR specificity predictions, we applied the modeling framework to the dataset from the IMMREP 2022 benchmark [<xref ref-type="bibr" rid="c15">15</xref>]. Here, we observed that the updated peptide-specific model performed on par with the best models in the benchmark. We however also observed that the pre-trained model performed worse than expected. Careful inspection of the data revealed that swapped negatives had been generated across the test and training data, meaning that some TCRs were only seen as negatives in the training, whereas they could be positive in the test data, albeit for a different peptide. This problem strongly affected the pre-trained model, which had a pan-specific component. Furthermore, since redundancy was only dealt with by removing duplicate TCRs, redundancy in both training and test data was observed, resulting in a certain degree of performance overestimation. This was for instance reflected in an unusually high performance for the peptides which had higher degrees of redundancies between training and test data.</p>
<p>To deal with these problems, we performed redundancy reduction on the training data identical to what was done for our novel extended data set, and made sure to only generate swapped negatives from TCRs within a given partition. We then trained and evaluated our models using the nested cross-validation approach on this redundancy reduced data. Here, we recovered the earlier conclusion that the pre-trained models outperformed the peptide-specific models, and that the integration of TCRbase led to the highest overall performance. These results thus strongly underline a problematic issue with data redundancy and the leakage of swapped negative TCR between training and test datasets present in the IMMREP benchmark. This is of high concern, since these properties, as shown here, are in particular detrimental for pan-specific models. Considering this, we encourage the creation of a new benchmark which takes these issues into account, while ideally also expanding on the number of peptides present for predictions.</p>
</sec>
</sec>
<sec id="s5">
<title>Conclusion</title>
<p>In this work, we have demonstrated how prediction of TCR specificity can be greatly improved by introducing minor but critical updates to the NetTCR training and modeling framework. While also improving on the peptide-specific models, these updates in particular boost the performance of pan-specific models. In addition, we show that pre-training models on pan-specific data, followed by training in a peptide-specific setup, leads to substantially improved performance, especially when the amount of data is low. Scaling the predictions from NetTCR with similarity to known binders is also shown to boost performance. Further, we have for the first time demonstrated how machine learning models can be designed and applied for rational data denoising in the context of TCR specificity data. The performance for “unseen” peptides was found to be overall low. However, the results demonstrated an encouraging tendency of high predictive power in cases of “unseen” peptides with high similarity to the training data.</p>
</sec>
<sec id="s5a">
<title>Software and data availability</title>
<p>The final peptide-specific, pan-specific and pre-trained models, along with the main datasets, are available on GitHub at <ext-link ext-link-type="uri" xlink:href="https://github.com/mnielLab/NetTCR-2.2">https://github.com/mnielLab/NetTCR-2.2</ext-link>, and a web server for the pan- and pre-trained models is available at <ext-link ext-link-type="uri" xlink:href="https://services.healthtech.dtu.dk/services/NetTCR-2.2/">https://services.healthtech.dtu.dk/services/NetTCR-2.2/</ext-link>, where an easy-to-use interface is provided for predictions.</p>
</sec>
<sec id="d1e1266" sec-type="supplementary-material">
<title>Supporting information</title>
<supplementary-material id="d1e1376">
<label>Supplementary figures and tables</label>
<media xlink:href="supplements/562001_file03.docx"/>
</supplementary-material>
<supplementary-material id="d1e1383">
<label>Model performance on primary dataset</label>
<media xlink:href="supplements/562001_file04.xlsx"/>
</supplementary-material>
<supplementary-material id="d1e1390">
<label>Model performance on IMMREP 2022 benchmark</label>
<media xlink:href="supplements/562001_file05.xlsx"/>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>This project is in part funded from the Innovative Medicines Initiative 2 Joint Undertaking under grant agreement No 101007799 (Inno4Vac), and the National Institute of Allergy and Infectious Diseases (NIAID), under award number 75N93019C00001.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="journal"><string-name><surname>Davis</surname>, <given-names>M. M.</given-names></string-name>, &amp; <string-name><surname>Bjorkman</surname>, <given-names>P. J.</given-names></string-name> (<year>1988</year>). <article-title>T-cell antigen receptor genes and T-cell recognition</article-title>. <source>Nature</source>, <volume>334</volume>(<issue>6181</issue>), <fpage>395</fpage>–<lpage>402</lpage>. <pub-id pub-id-type="doi">10.1038/334395a0</pub-id></mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="journal"><string-name><surname>Nielsen</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Andreatta</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Peters</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Buus</surname>, <given-names>S.</given-names></string-name> (<year>2020</year>). <article-title>Immunoinformatics: Predicting Peptide-MHC Binding</article-title>. <source>Annual review of biomedical data science</source>, <volume>3</volume>, <fpage>191</fpage>–<lpage>215</lpage>. <pub-id pub-id-type="doi">10.1146/annurev-biodatasci-021920-100259</pub-id></mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><string-name><surname>Hudson</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Fernandes</surname>, <given-names>R. A.</given-names></string-name>, <string-name><surname>Basham</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Ogg</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Koohy</surname>, <given-names>H.</given-names></string-name> (<year>2023</year>). <article-title>Can we predict T cell specificity with digital biology and machine learning?</article-title> <source>Nature reviews. Immunology</source>, <volume>23</volume>(<issue>8</issue>), <fpage>511</fpage>–<lpage>521</lpage>. <pub-id pub-id-type="doi">10.1038/s41577-023-00835-3</pub-id></mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="journal"><string-name><surname>Moris</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>De Pauw</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Postovskaya</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Gielis</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>De Neuter</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Bittremieux</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Ogunjimi</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Laukens</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Meysman</surname>, <given-names>P.</given-names></string-name> (<year>2021</year>). <article-title>Current challenges for unseen-epitope TCR interaction prediction and a new perspective derived from image classification</article-title>. <source>Briefings in bioinformatics</source>, <volume>22</volume>(<issue>4</issue>), <fpage>bbaa318</fpage>. <pub-id pub-id-type="doi">10.1093/bib/bbaa318</pub-id></mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="journal"><string-name><surname>Zhang</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Hawkins</surname>, <given-names>P. G.</given-names></string-name>, <string-name><surname>He</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Gupta</surname>, <given-names>N. T.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Choonoo</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Jeong</surname>, <given-names>S. W.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>C. R.</given-names></string-name>, <string-name><surname>Dhanik</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Dillon</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Deering</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Macdonald</surname>, <given-names>L. E.</given-names></string-name>, <string-name><surname>Thurston</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Atwal</surname>, <given-names>G. S.</given-names></string-name> (<year>2021</year>). <article-title>A framework for highly multiplexed dextramer mapping and prediction of T cell receptor sequences to antigen specificity</article-title>. <source>Science advances</source>, <volume>7</volume>(<issue>20</issue>), <fpage>eabf5835</fpage>. <pub-id pub-id-type="doi">10.1126/sciadv.abf5835</pub-id></mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="journal"><string-name><surname>Montemurro</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Jessen</surname>, <given-names>L. E.</given-names></string-name>, &amp; <string-name><surname>Nielsen</surname>, <given-names>M.</given-names></string-name> (<year>2022</year>). <article-title>NetTCR-2.1: Lessons and guidance on how to develop models for TCR specificity predictions</article-title>. <source>Frontiers in immunology</source>, <volume>13</volume>, <fpage>1055151</fpage>. <pub-id pub-id-type="doi">10.3389/fimmu.2022.1055151</pub-id></mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="journal"><string-name><surname>Sidhom</surname>, <given-names>J. W.</given-names></string-name>, <string-name><surname>Larman</surname>, <given-names>H. B.</given-names></string-name>, <string-name><surname>Pardoll</surname>, <given-names>D. M.</given-names></string-name>, &amp; <string-name><surname>Baras</surname>, <given-names>A. S.</given-names></string-name> (<year>2021</year>). <article-title>DeepTCR is a deep learning framework for revealing sequence concepts within T-cell repertoires</article-title>. <source>Nature communications</source>, <volume>12</volume>(<issue>1</issue>), <fpage>1605</fpage>. <pub-id pub-id-type="doi">10.1038/s41467-021-21879-w</pub-id></mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="journal"><string-name><surname>Tong</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Zheng</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Xiao</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Zhu</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Lai</surname>, <given-names>X.</given-names></string-name>, &amp; <string-name><surname>Liu</surname>, <given-names>X.</given-names></string-name> (<year>2020</year>). <article-title>SETE: Sequence-based Ensemble learning approach for TCR Epitope binding prediction</article-title>. <source>Computational biology and chemistry</source>, <volume>87</volume>, <fpage>107281</fpage>. <collab>Advance online publication</collab>. <pub-id pub-id-type="doi">10.1016/j.compbiolchem.2020.107281</pub-id></mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="journal"><string-name><surname>Jokinen</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Huuhtanen</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Mustjoki</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Heinonen</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Lähdesmäki</surname>, <given-names>H.</given-names></string-name> (<year>2021</year>). <article-title>Predicting recognition between T cell receptors and epitopes with TCRGP</article-title>. <source>PLoS computational biology</source>, <volume>17</volume>(<issue>3</issue>), <fpage>e1008814</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1008814</pub-id></mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="other"><string-name><surname>Meynard-Piganeau</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Feinauer</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Weigt</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Walczak</surname>, <given-names>A. M.</given-names></string-name>, &amp; <string-name><surname>Mora</surname>, <given-names>T.</given-names></string-name> (<year>2023</year>). <article-title>TULIP — a Transformer based Unsupervised Language model for Interacting Peptides and T-cell receptors that generalizes to unseen epitopes</article-title>. <source>bioRxiv</source>. <pub-id pub-id-type="doi">10.1101/2023.07.19.549669</pub-id></mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="journal"><string-name><surname>Mayer-Blackwell</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Schattgen</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Cohen-Lavi</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Crawford</surname>, <given-names>J. C.</given-names></string-name>, <string-name><surname>Souquette</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Gaevert</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Hertz</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Thomas</surname>, <given-names>P. G.</given-names></string-name>, <string-name><surname>Bradley</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Fiore-Gartland</surname>, <given-names>A.</given-names></string-name> (<year>2021</year>). <article-title>TCR meta-clonotypes for biomarker discovery with tcrdist3 enabled identification of public, HLA-restricted clusters of SARS-CoV-2 TCRs</article-title>. <source>eLife</source>, <volume>10</volume>, <fpage>e68605</fpage>. <pub-id pub-id-type="doi">10.7554/eLife.68605</pub-id></mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="journal"><string-name><surname>Huang</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Rubelt</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Scriba</surname>, <given-names>T. J.</given-names></string-name>, &amp; <string-name><surname>Davis</surname>, <given-names>M. M.</given-names></string-name> (<year>2020</year>). <article-title>Analyzing the Mycobacterium tuberculosis immune response by T-cell receptor clustering with GLIPH2 and genome-wide antigen screening</article-title>. <source>Nature biotechnology</source>, <volume>38</volume>(<issue>10</issue>), <fpage>1194</fpage>–<lpage>1202</lpage>. <pub-id pub-id-type="doi">10.1038/s41587-020-0505-4</pub-id></mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="other"><string-name><surname>Shen</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Wong</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Xiao</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Guo</surname>, <given-names>X.</given-names></string-name>, &amp; <string-name><surname>Smale</surname>, <given-names>S.</given-names></string-name> (<year>2012</year>). <article-title>Towards a mathematical foundation of immunology and amino acid chains</article-title>. <source>arXiv</source>. <pub-id pub-id-type="doi">10.48550/arXiv.1205.6031</pub-id></mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="journal"><string-name><surname>Hudson</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Fernandes</surname>, <given-names>R. A.</given-names></string-name>, <string-name><surname>Basham</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Ogg</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Koohy</surname>, <given-names>H.</given-names></string-name> (<year>2023</year>). <article-title>Can we predict T cell specificity with digital biology and machine learning?</article-title> <source>Nature reviews. Immunology</source>, <volume>23</volume>(<issue>8</issue>), <fpage>511</fpage>–<lpage>521</lpage>. <pub-id pub-id-type="doi">10.1038/s41577-023-00835-3</pub-id></mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="other"><string-name><surname>Meysman</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Barton</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Bravi</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Cohen-Lavi</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Karnaukhov</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Lilleskov</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Montemurro</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Nielsen</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Mora</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Pereira</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Postovskaya</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Martínez</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Fernandez-de-Cossio-Diaz</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Vujkovic</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Walczak</surname>, <given-names>A.M</given-names></string-name>, <string-name><surname>Weber</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Yin</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Eugster</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Sharma</surname>, <given-names>V.</given-names></string-name> (<year>2023</year>). <article-title>Benchmarking solutions to the T-cell receptor epitope prediction problem: IMMREP22 workshop report</article-title>. <source>Immunoinformatics</source>, <fpage>100024</fpage>. <pub-id pub-id-type="doi">10.1016/j.immuno.2023.100024</pub-id></mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="journal"><string-name><surname>Montemurro</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Schuster</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Povlsen</surname>, <given-names>H. R.</given-names></string-name>, <string-name><surname>Bentzen</surname>, <given-names>A. K.</given-names></string-name>, <string-name><surname>Jurtz</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Chronister</surname>, <given-names>W. D.</given-names></string-name>, <string-name><surname>Crinklaw</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Hadrup</surname>, <given-names>S. R.</given-names></string-name>, <string-name><surname>Winther</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Peters</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Jessen</surname>, <given-names>L. E.</given-names></string-name>, &amp; <string-name><surname>Nielsen</surname>, <given-names>M.</given-names></string-name> (<year>2021</year>). <article-title>NetTCR-2.0 enables accurate prediction of TCR-peptide binding by using paired TCRα and β sequence data</article-title>. <source>Communications biology</source>, <volume>4</volume>(<issue>1</issue>), <fpage>1060</fpage>. <pub-id pub-id-type="doi">10.1038/s42003-021-02610-3</pub-id></mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="journal"><string-name><surname>Grazioli</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Mösch</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Machart</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Alqassem</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>O’Donnell</surname>, <given-names>T. J.</given-names></string-name>, &amp; <string-name><surname>Min</surname>, <given-names>M. R.</given-names></string-name> (<year>2022</year>). <article-title>On TCR binding predictors failing to generalize to unseen peptides</article-title>. <source>Frontiers in immunology</source>, <volume>13</volume>, <fpage>1014256</fpage>. <pub-id pub-id-type="doi">10.3389/fimmu.2022.1014256</pub-id></mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="journal"><string-name><surname>Reynisson</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Alvarez</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Paul</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Peters</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Nielsen</surname>, <given-names>M.</given-names></string-name> (<year>2020</year>). <article-title>NetMHCpan-4.1 and NetMHCIIpan-4.0: improved predictions of MHC antigen presentation by concurrent motif deconvolution and integration of MS MHC eluted ligand data</article-title>. <source>Nucleic acids research</source>, <volume>48</volume>(<issue>W1</issue>), <fpage>W449</fpage>–<lpage>W454</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gkaa379</pub-id></mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="journal"><string-name><surname>Nilsson</surname>, <given-names>J. B.</given-names></string-name>, <string-name><surname>Kaabinejadian</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Yari</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Peters</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Barra</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Gragert</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Hildebrand</surname>, <given-names>W.</given-names></string-name>, &amp; <string-name><surname>Nielsen</surname>, <given-names>M.</given-names></string-name> (<year>2023</year>). <article-title>Machine learning reveals limited contribution of trans-only encoded variants to the HLA-DQ immunopeptidome</article-title>. <source>Communications biology</source>, <volume>6</volume>(<issue>1</issue>), <fpage>442</fpage>. <pub-id pub-id-type="doi">10.1038/s42003-023-04749-7</pub-id></mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="journal"><string-name><surname>Montemurro</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Povlsen</surname>, <given-names>H. R.</given-names></string-name>, <string-name><surname>Jessen</surname>, <given-names>L. E.</given-names></string-name>, &amp; <string-name><surname>Nielsen</surname>, <given-names>M.</given-names></string-name> (<year>2023</year>). <article-title>Benchmarking data-driven filtering for denoising of TCRpMHC single-cell data</article-title>. <source>Scientific reports</source>, <volume>13</volume>(<issue>1</issue>), <fpage>16147</fpage>. <pub-id pub-id-type="doi">10.1038/s41598-023-43048-3</pub-id></mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="journal"><string-name><surname>Povlsen</surname>, <given-names>H. R.</given-names></string-name>, <string-name><surname>Bentzen</surname>, <given-names>A. K.</given-names></string-name>, <string-name><surname>Kadivar</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Jessen</surname>, <given-names>L. E.</given-names></string-name>, <string-name><surname>Hadrup</surname>, <given-names>S. R.</given-names></string-name>, &amp; <string-name><surname>Nielsen</surname>, <given-names>M.</given-names></string-name> (<year>2023</year>). <article-title>Improved T cell receptor antigen pairing through data-driven filtering of sequencing information from single cells</article-title>. <source>eLife</source>, <volume>12</volume>, <fpage>e81810</fpage>. <pub-id pub-id-type="doi">10.7554/eLife.81810</pub-id></mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="journal"><string-name><surname>Vita</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Mahajan</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Overton</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Dhanda</surname>, <given-names>S. K.</given-names></string-name>, <string-name><surname>Martini</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Cantrell</surname>, <given-names>J. R.</given-names></string-name>, <string-name><surname>Wheeler</surname>, <given-names>D. K.</given-names></string-name>, <string-name><surname>Sette</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Peters</surname>, <given-names>B.</given-names></string-name> (<year>2019</year>). <article-title>The Immune Epitope Database (IEDB): 2018 update</article-title>. <source>Nucleic acids research</source>, <volume>47</volume>(<issue>D1</issue>), <fpage>D339</fpage>–<lpage>D343</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gky1006</pub-id></mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="journal"><string-name><surname>Bagaev</surname>, <given-names>D. V.</given-names></string-name>, <string-name><surname>Vroomans</surname>, <given-names>R. M. A.</given-names></string-name>, <string-name><surname>Samir</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Stervbo</surname>, <given-names>U.</given-names></string-name>, <string-name><surname>Rius</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Dolton</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Greenshields-Watson</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Attaf</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Egorov</surname>, <given-names>E. S.</given-names></string-name>, <string-name><surname>Zvyagin</surname>, <given-names>I. V.</given-names></string-name>, <string-name><surname>Babel</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Cole</surname>, <given-names>D. K.</given-names></string-name>, <string-name><surname>Godkin</surname>, <given-names>A. J.</given-names></string-name>, <string-name><surname>Sewell</surname>, <given-names>A. K.</given-names></string-name>, <string-name><surname>Kesmir</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Chudakov</surname>, <given-names>D. M.</given-names></string-name>, <string-name><surname>Luciani</surname>, <given-names>F.</given-names></string-name>, &amp; <string-name><surname>Shugay</surname>, <given-names>M.</given-names></string-name> (<year>2020</year>). <article-title>VDJdb in 2019: database extension, new analysis infrastructure and a T-cell receptor motif compendium</article-title>. <source>Nucleic acids research</source>, <volume>48</volume>(<issue>D1</issue>), <fpage>D1057</fpage>–<lpage>D1062</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gkz874</pub-id></mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="web"><collab>10x Genomics</collab>. (<year>2020</year>, <month>March</month> 25). <source>A New Way of Exploring Immunity - Linking Highly Multiplexed Antigen Recognition to Immune Repertoire and Phenotype</source>. <ext-link ext-link-type="uri" xlink:href="https://www.technologynetworks.com/immunology/application-notes/a-new-way-of-exploring-immunity-linking-highly-multiplexed-antigen-recognition-to-immune-repertoire-332554">https://www.technologynetworks.com/immunology/application-notes/a-new-way-of-exploring-immunity-linking-highly-multiplexed-antigen-recognition-to-immune-repertoire-332554</ext-link></mixed-citation></ref>
<ref id="c25"><label>[25]</label><mixed-citation publication-type="journal"><string-name><surname>Heather</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Spindler</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Alonso</surname>, <given-names>M. H.</given-names></string-name>, <string-name><surname>Shui</surname>, <given-names>Y. I.</given-names></string-name>, <string-name><surname>Millar</surname>, <given-names>D. G.</given-names></string-name>, <string-name><surname>Johnson</surname>, <given-names>D. S.</given-names></string-name>, <string-name><surname>Cobbold</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Hata</surname>, <given-names>A. N.</given-names></string-name> (<year>2022</year>). <article-title>Stitchr: stitching coding TCR nucleotide sequences from V/J/CDR3 information</article-title>. <source>Nucleic acids research</source>, <volume>50</volume>(<issue>12</issue>), <fpage>e68</fpage>. <pub-id pub-id-type="doi">10.1093/nar/gkac190</pub-id></mixed-citation></ref>
<ref id="c26"><label>[26]</label><mixed-citation publication-type="journal"><string-name><surname>Dunbar</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Deane</surname>, <given-names>C. M.</given-names></string-name> (<year>2016</year>). <article-title>ANARCI: antigen receptor numbering and receptor classification</article-title>. <source>Bioinformatics (Oxford, England)</source>, <volume>32</volume>(<issue>2</issue>), <fpage>298</fpage>–<lpage>300</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btv552</pub-id></mixed-citation></ref>
<ref id="c27"><label>[27]</label><mixed-citation publication-type="journal"><string-name><surname>Lefranc</surname>, <given-names>M. P.</given-names></string-name>, <string-name><surname>Pommié</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Ruiz</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Giudicelli</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Foulquier</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Truong</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Thouvenin-Contet</surname>, <given-names>V.</given-names></string-name>, &amp; <string-name><surname>Lefranc</surname>, <given-names>G.</given-names></string-name> (<year>2003</year>). <article-title>IMGT unique numbering for immunoglobulin and T cell receptor variable domains and Ig superfamily V-like domains</article-title>. <source>Developmental and comparative immunology</source>, <volume>27</volume>(<issue>1</issue>), <fpage>55</fpage>–<lpage>77</lpage>. <pub-id pub-id-type="doi">10.1016/s0145-305x(02)00039-3</pub-id></mixed-citation></ref>
<ref id="c28"><label>[28]</label><mixed-citation publication-type="journal"><string-name><surname>Hobohm</surname>, <given-names>U.</given-names></string-name>, <string-name><surname>Scharf</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Schneider</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Sander</surname>, <given-names>C.</given-names></string-name> (<year>1992</year>). <article-title>Selection of representative protein data sets</article-title>. <source>Protein science : a publication of the Protein Society</source>, <volume>1</volume>(<issue>3</issue>), <fpage>409</fpage>–<lpage>417</lpage>. <pub-id pub-id-type="doi">10.1002/pro.5560010313</pub-id></mixed-citation></ref>
<ref id="c29"><label>[29]</label><mixed-citation publication-type="web"><string-name><surname>Chollet</surname>, <given-names>F.</given-names></string-name>, <etal>et al.</etal> (<year>2015</year>). <source>Keras</source>. <ext-link ext-link-type="uri" xlink:href="https://github.com/fchollet/keras">https://github.com/fchollet/keras</ext-link></mixed-citation></ref>
<ref id="c30"><label>[30]</label><mixed-citation publication-type="journal"><string-name><surname>Paszke</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Gross</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Massa</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Lerer</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Bradbury</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Chanan</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Killeen</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Lin</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Gimelshein</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Antiga</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Desmaison</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Köpf</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>DeVito</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Raison</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Tejani</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Chilamkurthy</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Steiner</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Fang</surname>, <given-names>Lu.</given-names></string-name>, <string-name><surname>Bai</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Chintala</surname>, <given-names>S.</given-names></string-name> (<year>2019</year>). <article-title>Pytorch: An imperative style, high-performance deep learning library</article-title>. <source>Advances in neural information processing systems</source>, <volume>32</volume>.</mixed-citation></ref>
<ref id="c31"><label>[31]</label><mixed-citation publication-type="other"><string-name><surname>Kingma</surname>, <given-names>D. P.</given-names></string-name>, &amp; <string-name><surname>Ba</surname>, <given-names>J.</given-names></string-name> (<year>2014</year>). <article-title>Adam: A method for stochastic optimization</article-title>. <source>arXiv</source>. <pub-id pub-id-type="doi">10.48550/arXiv.1412.6980</pub-id></mixed-citation></ref>
<ref id="c32"><label>[32]</label><mixed-citation publication-type="journal"><string-name><surname>Virtanen</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Gommers</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Oliphant</surname>, <given-names>T. E.</given-names></string-name>, <string-name><surname>Haberland</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Reddy</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Cournapeau</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Burovski</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Peterson</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Weckesser</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Bright</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>van der Walt</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>Brett</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Millman</surname>, <given-names>K. J.</given-names></string-name>, <string-name><surname>Mayorov</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Nelson</surname>, <given-names>A. R. J.</given-names></string-name>, <string-name><surname>Jones</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Kern</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Larson</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Carey</surname>, <given-names>C. J.</given-names></string-name>, <etal>et al.</etal> <collab>SciPy 1.0 Contributors</collab> (<year>2020</year>). <article-title>SciPy 1.0: fundamental algorithms for scientific computing in Python</article-title>. <source>Nature methods</source>, <volume>17</volume>(<issue>3</issue>), <fpage>261</fpage>–<lpage>272</lpage>. <pub-id pub-id-type="doi">10.1038/s41592-019-0686-2</pub-id></mixed-citation></ref>
<ref id="c33"><label>[33]</label><mixed-citation publication-type="other"><string-name><surname>Gielis</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Moris</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>De Neuter</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Bittremieux</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Ogunjimi</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Laukens</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Meysman</surname>, <given-names>P.</given-names></string-name> (<year>2018</year>). <article-title>TCRex: a webtool for the prediction of T-cell receptor sequence epitope specificity</article-title>. <source>bioRxiv</source>. <pub-id pub-id-type="doi">10.1101/373472</pub-id></mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.93934.2.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Sohn</surname>
<given-names>Jungsan</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Johns Hopkins University School of Medicine</institution>
</institution-wrap>
<city>Baltimore</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Compelling</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Useful</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study presents a <bold>useful</bold> tool for predicting TCR specificity with <bold>compelling</bold> evidence for improvements over prior art. This work/tool will be broadly relevant to computational biologists and immunologists.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.93934.2.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>In this article, different machine learning models (pan-specific, peptide-specific, pre-trained, and ensemble models) are tested to predict TCR-specificity from a paired-chain peptide-TCR dataset. The data consists of 6,358 positive observations across 26 peptides (as compared to six peptides in NetTCR version 2.1) after several pre-processing steps (filtering and redundancy reduction). For each positive sample, five negative samples were generated by swapping TCRs of a given peptide with TCRs binding to other peptides. The weighted loss function is used to deal with the imbalanced dataset in pan-specific models.</p>
<p>The results demonstrate that the redundant data introduced during training did not lead to performance gain; rather, a decrease in performance was observed for the pan-specific model. The removal of outliers leads to better performance.</p>
<p>To further improve the peptide-specific model performance, an architecture is created to combine pan-specific and peptide-specific models, where the pan-specific model is trained on pan-specfic data while keeping the peptide-specfic part of the model frozen, and the peptide-specific model is trained on a peptide-specific dataset while keeping the pan-specific part of the model frozen. This model surpassed the performance of individual pan-specific and peptide-specific models. Finally, sequence similarity-based predictions of TCRbase are integrated into the pre-trained CNN model, which further improved the model performance (mostly due to the better discrimination of binders and non-binders).</p>
<p>The prediction for unseen peptides is still low in a pan-specific model; however, an improvement in prediction is observed for peptides with high similarity to the ones in the training dataset. Furthermore, it is shown that 15 observations shows satisfactory performance as compared to the ~150 recommended in the literature.</p>
<p>Models are evaluated on the external dataset (IMMREP benchmark). Peptide-specific models performed competitively with the best models in the benchmark. The pre-trained model performed worst, which the authors suggested could be because of positive and negative sample swapping across training and testing sets. To resolve this issue, they applied the redundancy removal technique to the IMMER dataset. The results agreed with earlier conclusion that the pre-trained models surpassed peptide-specific models and the integration of similarity-based methods leads to performance boost. It highlights the need for the creation of a new benchmark without data redundancy or leakage problems.</p>
<p>The manuscript is well written, clear and easy to understand. The data is effectively presented. The results validate the drawn conclusions.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.93934.2.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>
The authors describe a novel ML approach to predict binding between MHC-bound peptides and T-Cell receptors. Such approaches are particularly useful for predicting the binding of peptide sequences with low similarity when compared to existing data sets. The authors focus on improving dataset quality and optimizing model architecture to achieve a pan-specific predictive model in hopes of achieving a high precision model for novel peptide sequences.</p>
<p>Strengths:</p>
<p>
Since assuring the quality of training datasets is the first major step in any ML training project, the extensive human curation and computational analysis and enhancements made in this manuscript represent a major contribution to the field. Moreover, the systematic approach to testing redundancy reduction and data augmentation is exemplary, and will significantly help future research in the field.</p>
<p>The authors also highlight how their model can identify outliers and how that can be used to improve the model around known sequences, which can help the creation and optimization of future datasets for peptide binding.</p>
<p>The new models presented here are novel and built using paired α/β TCR sequence data to predict peptide-specific TCR binding, and have been extensively and rigorously tested.</p>
<p>Weaknesses:</p>
<p>
Achieving an accurate pan-specific model is an ambitious goal, and the authors have significant difficulties when trying to achieve non-random performance for prediction of TCR binding to novel peptides. This is the most challenging task for this kind of model, but also the most desirable when applying such models to biotechnological and bioengineering projects.</p>
<p>The manuscript is a highly technical and extremely detailed computational work, which can make the achievements and impact of the work hard to parse for application-oriented researchers, and still hard to translate to real-world use-cases for TCR specificity predictions.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.93934.2.sa3</article-id>
<title-group>
<article-title>Author Response</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Jensen</surname>
<given-names>Mathias Fynbo</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0004-6664-448X</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Nielsen</surname>
<given-names>Morten</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>The following is the authors’ response to the original reviews.</p>
<p>We thank the editor and reviewers for their valuable feedback and comments. Below we have addressed all points carefully and have, when needed, revised the manuscript accordingly.</p>
<p>Note that we have taken the opportunity to correct minor typos and unclear text in the revised manuscript.</p>
<p>Of importance to the editors and reviewers, we detected a few minor factual errors in the method section, which we have now corrected. The first error was that we wrongfully stated that our final dataset had 6358 unique TCRs, whereas it was in fact 6353 unique TCRs. The second error was that we stated that the maximum length of CDR1ꞵ was 5, where it was in fact 6. The last error was that we stated that we used a Levenshtein distance of at least 3 to discard similar peptides when swapping the TCRs to generate negatives. This should have been a Levenshtein greater than 3, to match the script we used to generate negatives (though no peptides had a Levenshtein distance of exactly 3).</p>
<disp-quote content-type="editor-comment">
<p><bold>eLife assessment</bold></p>
<p>This important study reports on an improved deep-learning-based method for predicting TCR specificity. The evidence supporting the overall method is compelling, although the inclusion of real-world applications and clear comparisons with the previous version would have further strengthened the study. This work will be of broad interest to immunologists and computational biologists.</p>
</disp-quote>
<p>It is not fully clear to us what is meant by “clear comparisons with the previous version”. In the manuscript we consistently compare the performance of each novel approach introduced to that of the ancestor NetTCR-2.1. Further, we concluded the manuscript with a performance to a large set of current state-of-the-art methods by training and evaluating the novel modeling framework on the IMMREP22 benchmark data.</p>
<p>We agree that the manuscript can be improved by including a brief discussion of real-life applications of models for prediction of TCR specificity, and have included a brief text in the introduction.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p>
<p>It was a great pleasure to read this article. All the concepts and motivations are clearly defined. I have just a few questions.</p>
<p>What was the motivation behind employing a 1:5 positive-negative ratio? Could it be the cause of worse performance in the case of outliers?</p>
</disp-quote>
<p>The ratio 1:5 is based on results from earlier work [36561755]. In this work, negatives were constructed as a mix of swapped and true (i.e measured) negatives with a ratio 1:5 for each. This work demonstrated a slight gain when including both types of negatives compared to only using swapped. In a subsequent publication [<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.immuno.2023.100024">https://doi.org/10.1016/j.immuno.2023.100024</ext-link>], it demonstrated that optimal performance was obtained when only including swapped negatives (again in a ratio 1:5). Given this, we maintained this approach in the current work. It is clear that this choice is somewhat arbitrary, and that further work is needed to fully address this issue and the general issue of how to best generate negatives for ML of TCR specificity. Such work is in our view however beyond the scope of the current manuscript.</p>
<disp-quote content-type="editor-comment">
<p>Why is the patience of 200 epochs for peptide-specific models and 100 epochs for pan-specific and pre-trained models used in the context of the early stopping mechanism?</p>
</disp-quote>
<p>We observed that the loss curve was overall very stable in the case of pan-specific training, likely due to the large amount of data included in this training. Therefore, these models were less likely to become stuck in a local minimum during training, meaning that a lower patience for early stopping would not prevent the model from learning optimally. In contrast, we found for some peptides that the loss curve was very erratic, and would sometimes become stuck in a local minimum for an extended time. To resolve this, the patience was increased from 100 to 200, which resulted in a better chance to escape these minima, as well as a better overall performance.</p>
<disp-quote content-type="editor-comment">
<p>Why is weight 3.8 used in the weighted loss function in the pan-specific model?</p>
</disp-quote>
<p>The weighted loss was scaled with a division factor (c) of 3.8, in order to get an overall loss that was comparable to training without sample weights. This was primarily done to better compare the two approaches (scaling and no scaling) in terms of loss, and not so much to improve the training itself, as we already use a relatively conservative sample weight scaling based on log2. We have added a brief sentence to clarify this in the manuscript.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p>
<p>This work is the evolution of previous studies that developed the NetTCR platform, and in a previous paper cited in this study, the authors explore the paired dataset approach with &quot;paired α/β TCR sequence data&quot;. In this manuscript, the authors should make clear what advances were made when compared to the previous study. This is not clear, although extensive reference is made to NetTCR 2.0 and 2.1. Differences are scattered throughout the manuscript, so I would suggest a section or paragraph clearly delineating the advances in model architecture and training when compared to previous versions recently published.</p>
</disp-quote>
<p>It is not clear to us when the reviewer is referring to when stating “the authors should make clear what advances were made when compared to the previous study”. Throughout the manuscript we consistently compare the performance of each novel approach introduced to that of the ancestor NetTCR-2.1. In addition, we briefly discuss all of the changes to the architecture and training at the start of the discussion section. Further, we concluded the manuscript with a performance to a large set of current state-of-the-art methods by training and evaluating the novel modeling framework on the IMMREP22 benchmark data. It is correct that the advances are described progressively by introducing each novel approach one by one, i.e. refining the machine learning model architecture and training setup, data denoising in terms of outlier identification in the training data, new model architectures combining the properties of a pan- and peptide-specific model, and integration of similarity based approach to boost model performance). We believe this helps better justify the relevance of each of the novel approaches introduced.</p>
<disp-quote content-type="editor-comment">
<p>In Figure 3, the colors have labels, but they are not explained in the legend or in the text. This makes it very difficult to understand the data in the various columns. Also, since it represents the Mean AUC, the data would be best displayed with a boxplot or a mean and bars for variance.</p>
</disp-quote>
<p>We agree, and have changed Figure 3 and its corresponding AUC 0.1 figure (Supplementary Figure 1) into a boxplot. We also further clarified what the different models were in the figure text.</p>
<disp-quote content-type="editor-comment">
<p>Given the potential impact of this work on bioengineering and biotechnology, I would suggest adding a paragraph or section to the discussion where potential applications of the current model, or examples of applications of previous (or competing) models have been used to further biological research.</p>
</disp-quote>
<p>We agree and have added a brief sentence in the introduction to outline biotechnological applications of models for prediction of TCR specificity.</p>
</body>
</sub-article>
</article>