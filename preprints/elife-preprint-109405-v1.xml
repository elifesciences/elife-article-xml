<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">109405</article-id>
<article-id pub-id-type="doi">10.7554/eLife.109405</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.109405.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Improved inference of latent neural states from calcium imaging data</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-3920-4540</contrib-id>
<name>
<surname>Keeley</surname>
<given-names>Stephen</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">†</xref>
<email>skeeley1@Fordham.edu</email>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Zoltowski</surname>
<given-names>David</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n1">†</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-9045-3489</contrib-id>
<name>
<surname>Charles</surname>
<given-names>Adam</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0002-3638-8831</contrib-id>
<name>
<surname>Pillow</surname>
<given-names>Jonathan</given-names>
</name>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03qnxaf80</institution-id><institution>Department of Natural Sciences, Fordham University</institution></institution-wrap>, <city>New York</city>, <country country="US">United States</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00f54p054</institution-id><institution>Department of Statistics, Wu Tsai Neurosciences Institute, Stanford University</institution></institution-wrap>, <city>Stanford</city>, <country country="US">United States</country></aff>
<aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00za53h95</institution-id><institution>Department of Biomedical Engineering, Johns Hopkins University</institution></institution-wrap>, <city>Baltimore</city>, <country country="US">United States</country></aff>
<aff id="a4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hx57361</institution-id><institution>Princeton Neuroscience Institute, Princeton University</institution></institution-wrap>, <city>Princeton</city>, <country country="US">United States</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Petkoski</surname>
<given-names>Spase</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/019kqby73</institution-id><institution>Institut de Neurosciences des Systèmes</institution>
</institution-wrap>
<city>Marseille</city>
<country country="FR">France</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Marquand</surname>
<given-names>Andre F</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/016xsfp80</institution-id><institution>Radboud University Nijmegen</institution>
</institution-wrap>
<city>Nijmegen</city>
<country country="NL">Netherlands</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="equal"><label>†</label><p>These authors contributed equally to this work.</p></fn>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2026-01-22">
<day>22</day>
<month>01</month>
<year>2026</year>
</pub-date>
<volume>15</volume>
<elocation-id>RP109405</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-10-17">
<day>17</day>
<month>10</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-10-17">
<day>17</day>
<month>10</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.10.17.682993"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2026, Keeley et al</copyright-statement>
<copyright-year>2026</copyright-year>
<copyright-holder>Keeley et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-109405-v1.pdf"/>
<abstract>
<p>Calcium imaging (CI) is a standard method for recording neural population activity, as it enables simultaneous recording of hundreds-to-thousands of individual somatic signals. Accordingly, CI recordings are prime candidates for population-level latent variable analyses, for example using models such as Gaussian Process Factor Analysis (GPFA), hidden Markov models (HMMs), and latent dynamical systems. However, these models have been primarily developed and fine-tuned for electrophysiological measurements of spiking activity. To adapt these models for use with the calcium signals recorded with CI, per-neuron fluorescence time-traces are typically either de-convolved to approximate spiking events or analyzed directly under Gaussian observation assumptions. The former approach, while enabling the direct application of latent variable methods developed for spiking data, suffers from the imprecise nature of spike estimation from CI. Moreover, isolated spikes can be undetectable in the fluorescence signal, creating additional uncertainty. A more direct model linking observed fluorescence to latent variables would account for these sources of uncertainty. Here, we develop accurate and tractable models for characterizing the latent structure of neural population activity from CI data. We propose to augment HMM, GPFA, and dynamical systems models with a CI observation model that consists of latent Poisson spiking and autoregressive calcium dynamics. Importantly, this model is both more flexible and directly compatible with standard methods for fitting latent models of neural dynamics. We demonstrate that using this more accurate CI observation model improves latent variable inference and model fitting on both CI observatons generated using state-of-the-art biophysical simulations as well as imaging data recorded in an experimental setting. We expect the developed methods to be widely applicable to many different analysis of population CI data.</p>
</abstract>
<funding-group>
<award-group id="par-1">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/01cwqze88</institution-id>
<institution>NIH Brain Initiative</institution>
</institution-wrap>
</funding-source>
<award-id>F32MH115445-03</award-id>
<principal-award-recipient>
<name>
<surname>Keeley</surname>
<given-names>Stephen</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="par-2">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/021nxhr62</institution-id>
<institution>National Science Foundation</institution>
</institution-wrap>
</funding-source>
<award-id>2340338</award-id>
<principal-award-recipient>
<name>
<surname>Charles</surname>
<given-names>Adam</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="par-3">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100014373</institution-id>
<institution>SU | Wu Tsai Neurosciences Institute, Stanford University (Wu Tsai Neurosciences Institute)</institution>
</institution-wrap>
</funding-source>
<principal-award-recipient>
<name>
<surname>Zoltowski</surname>
<given-names>David M</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="par-4">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/01cmst727</institution-id>
<institution>Simons Foundation</institution>
</institution-wrap>
</funding-source>
<award-id>SCGB AWD543027</award-id>
<principal-award-recipient>
<name>
<surname>Pillow</surname>
<given-names>Jonathan W</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="par-5">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/01cwqze88</institution-id>
<institution>NIH Brain Initiative</institution>
</institution-wrap>
</funding-source>
<award-id>9R01DA056404</award-id>
<principal-award-recipient>
<name>
<surname>Pillow</surname>
<given-names>Jonathan W</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="par-6">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/01s5ya894</institution-id>
<institution>National Institute of Neurological Disorders and Stroke</institution>
</institution-wrap>
</funding-source>
<award-id>U19NS104648</award-id>
<principal-award-recipient>
<name>
<surname>Pillow</surname>
<given-names>Jonathan W</given-names>
</name>
</principal-award-recipient>
</award-group>
</funding-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Electrophysiological recordings have historically been the de-facto approach for observing the activity of single neurons. Consequently, many statistical models for neuronal data at the single-cell level are formulated for spike train observations. That is, they describe a mapping from stimuli or unobserved latent variables to a probability distribution over discrete spike events. This class of models includes (but is not limited to) Poisson regression models (<xref ref-type="bibr" rid="c62">Truccolo et al., 2005</xref>; <xref ref-type="bibr" rid="c48">Pillow et al., 2008</xref>; <xref ref-type="bibr" rid="c38">McFarland et al., 2013</xref>; <xref ref-type="bibr" rid="c44">Park et al., 2013</xref>; <xref ref-type="bibr" rid="c79">Zoltowski and Pillow, 2018</xref>), non-Poisson spike count regression models (<xref ref-type="bibr" rid="c47">Pillow and Scott, 2012</xref>; <xref ref-type="bibr" rid="c19">Goris et al., 2014</xref>; <xref ref-type="bibr" rid="c64">Williamson et al., 2015</xref>; <xref ref-type="bibr" rid="c16">Gao et al., 2015</xref>; <xref ref-type="bibr" rid="c34">Linderman et al., 2016a</xref>; <xref ref-type="bibr" rid="c60">Stevenson, 2016</xref>; <xref ref-type="bibr" rid="c4">Charles et al., 2018</xref>), linear dynamical system (LDS) (<xref ref-type="bibr" rid="c37">Macke et al., 2011</xref>), nonlinear dynamics models (<xref ref-type="bibr" rid="c35">Linderman et al., 2017</xref>; <xref ref-type="bibr" rid="c43">Pandarinath et al., 2018</xref>; <xref ref-type="bibr" rid="c12">Duncker et al., 2019</xref>; <xref ref-type="bibr" rid="c75">Zhao and Park, 2019</xref>), Gaussian process factor analysis (GPFA) models (<xref ref-type="bibr" rid="c68">Yu et al., 2009a</xref>; <xref ref-type="bibr" rid="c74">Zhao and Park, 2017</xref>; <xref ref-type="bibr" rid="c26">Keeley et al., 2019</xref>), and nonlinear tuning curve models (<xref ref-type="bibr" rid="c71">Zhang et al., 1998</xref>; <xref ref-type="bibr" rid="c70">Zemel et al., 1998</xref>; <xref ref-type="bibr" rid="c6">Cronin et al., 2010</xref>; <xref ref-type="bibr" rid="c52">Rad and Paninski, 2011</xref>; <xref ref-type="bibr" rid="c2">Calabrese et al., 2011</xref>; <xref ref-type="bibr" rid="c45">Park et al., 2014</xref>; <xref ref-type="bibr" rid="c54">Savin and Tkacik, 2016</xref>; <xref ref-type="bibr" rid="c51">Rad et al., 2017</xref>; <xref ref-type="bibr" rid="c65">Wu et al., 2017</xref>).</p>
<p>Calcium imaging (CI) is a popular approach for recording large neural populations due to its ability to image large areas (<italic>&gt;</italic>0.5<italic>μm</italic><sup>2</sup>) at micron level resolution, enabling simultaneously recording many neurons (100-1000 typical, 10<sup>9</sup> in the most advanced systems (<xref ref-type="bibr" rid="c8">Demas et al., 2021</xref>)) and tracking the same population of cells for days at a time. CI, however, measures neural spiking activity indirectly. Specifically, fluorescence changes in recorded CI time series represent fluctuations in intra-cellular calcium concentrations that result from the biophysics of action potentials; each spike results in a rapid rise in the calcium concentration. The fluorescence then jumps as the calcium is bound to the fluorescent proteins followed by a slower decay as the calcium unbinds (<xref ref-type="bibr" rid="c58">Song et al., 2021</xref>; <xref ref-type="bibr" rid="c20">Helmchen and Tank, 2015</xref>). While theoretically the relationship between neural spiking and calcium-based fluorescence is well characterized, practically variability in concentrations and noise considerations complicates the ability to discern single spikes (or even small bursts of 2-3 spikes) from calcium traces (<xref ref-type="bibr" rid="c58">Song et al., 2021</xref>; <xref ref-type="bibr" rid="c33">Ledochowitsch et al., 2019</xref>).</p>
<p>Due to the indirect relationship between neural firing and CI traces, point-process models are no longer directly applicable to CI data. Instead methods to statistically analyze CI datasets commonly take two approaches: (1) ignore spiking and resort to Gaussian noise models operating directly on the calcium traces; or (2) apply Poisson models to <italic>estimates</italic> of the spike train obtained from calcium inference methods (<xref ref-type="bibr" rid="c57">Smith and Häusser, 2010</xref>; <xref ref-type="bibr" rid="c30">Ko et al., 2013</xref>; <xref ref-type="bibr" rid="c49">Pnevmatikakis et al., 2016</xref>). The former approach is suboptimal because the statistics of CI data are asymmetric with high-skew and long tails, and thus widely deviate from the statistics of Gaussian distributions (<xref ref-type="bibr" rid="c63">Wei et al., 2020</xref>). Additionally, <italic>i</italic>.<italic>i</italic>.<italic>d</italic>. noise observations are not appropriate for the long time-scale autocorrelations observed in CI data. The latter approach, spike-time estimation, is suboptimal because it does not take into account the uncertainty of the unobserved spikes. Specifically, single spikes have been shown to only be visible in the CI traces a fraction of the time (<xref ref-type="bibr" rid="c21">Huang et al., 2021</xref>), and the nonlinearities in calcium buffering in bursting can make spike estimation highly unreliable in many settings. Our approach instead uses an observation model that is more faithful to the data-generating process, which we demonstrate provides more accurate inference and scientific insight in use.</p>
<p>Specifically, here we extend a calcium observation likelihood first presented in <xref ref-type="bibr" rid="c15">Ganmor et al. (2016)</xref> to latent variable models where the firing rate is a function of the latent variables. The three primary latent variable models we consider are hidden Markov models (HMMs) (<xref ref-type="bibr" rid="c56">Smith and Brown, 2003</xref>; <xref ref-type="bibr" rid="c14">Escola et al., 2011</xref>; <xref ref-type="bibr" rid="c32">Krause and Drugowitsch, 2022</xref>), Gaussian Process Factor Analysis (GPFA) (<xref ref-type="bibr" rid="c68">Yu et al., 2009a</xref>), and Latent Factor Analysis via Dynamical Systems (LFADS) (<xref ref-type="bibr" rid="c43">Pandarinath et al., 2018</xref>), though our approach also applies to switching dynamical systems (<xref ref-type="bibr" rid="c35">Linderman et al., 2017</xref>) and more general nonlinear dynamics models (<xref ref-type="bibr" rid="c39">Mudrik et al., 2024</xref>, <xref ref-type="bibr" rid="c40">2025</xref>; <xref ref-type="bibr" rid="c67">Yezerets et al., 2025</xref>; <xref ref-type="bibr" rid="c5">Chen et al., 2024</xref>). The models each are fit using different methods, including maximum likelihood (ML) for the HMM, and variational inference for GPFA and LFADS, which demonstrates the range of methods that can be adapted with our approach. We evaluate the models using simulated datasets, a state-of-the-art biophysical simulator NAOMi (<xref ref-type="bibr" rid="c58">Song et al., 2021</xref>), and in-vivo 2-photo calcium imaging recordings. In each of these cases, we show that the calcium likelihood can be used in conjunction with various LVMs is able to better capture the underlying latent structure in the simulated or experimental neural population traces than competing observation likelihoods.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Calcium LVM Framework</title>
<p>We propose the following framework for adapting LVMs developed for spiking data to the setting of calcium imaging recordings <bold>y</bold><sub><bold>t</bold></sub> ∈ ℝ<sup><bold>N</bold></sup> of <italic>N</italic> neurons for <italic>t</italic> ∈{1, …, <italic>T</italic>}. We consider models that prescribe a generative distribution over Poisson spike counts <bold>s</bold><sub><bold>t</bold></sub> ∈ ℕ<sub><bold>0</bold></sub><sup><bold>N</bold></sup> via latent variables <bold>x</bold>
<disp-formula id="eqn1">
<graphic xlink:href="682993v1_eqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn2">
<graphic xlink:href="682993v1_eqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the latent variables <bold>x</bold> may be continuous or discrete and the firing rate <italic>λ</italic><sub><italic>θ</italic></sub> depends on the value of the latent variables, potentially through a mapping parameterized by <italic>θ</italic>. This formulation includes many common LVMs used in neuroscience that we will describe in detail in the following sections. Previously, <xref ref-type="bibr" rid="c15">Ganmor et al. (2016)</xref> proposed a model for fitting firing rates from calcium traces via approximate marginalization over unobserved Poisson spike counts. Here we propose to augment the generative models over spike counts with this model such that for a given neuron <italic>n</italic>
<disp-formula id="eqn3">
<graphic xlink:href="682993v1_eqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where we have generalized the approach of <xref ref-type="bibr" rid="c15">Ganmor et al. (2016)</xref> to the setting of higher-order AR processes. This model has three sets of parameters per-neuron. The AR coefficients <italic>α</italic><sub><italic>i</italic></sub> account for autoregressive calcium dynamics. If the model is <italic>AR</italic>(1),then <italic>α</italic><sub>1</sub> determines the exponential decay of fluorescence. Next, <italic>c</italic> describes the fluorescence increase due to a single spike and <italic>σ</italic><sup>2</sup> is the variance of additive Gaussian noise.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Schematic for the calcium LVMs.</title>
<p>A low-dimensional latent variable maps to Poisson firing rates for time-series neural population activity. These Poisson spike probabilities are marginalized over and fed through an auto-regressive process to describe the evolution of the calcium traces.</p></caption>
<graphic xlink:href="682993v1_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Importantly, in this model the unobserved spike count variables can be approximately marginalcross-validation (60 trainingi zed out via numerical integration such that it is tractable to evaluate <inline-formula id="inline-eqn-1"><inline-graphic xlink:href="682993v1_inline1.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. Accordingly, with automatic differentiation approaches and current approximate inference methods this observation model can be generally applied across a variety of neural population models. In the following sections we will detail three specific applications of this framework.</p>
</sec>
<sec id="s2b">
<title>Calcium Hidden Markov Models</title>
<p>Hidden Markov Models (HMMs) are latent sequence models for identifying discrete structure over time. Here we describe the calcium HMM, an HMM with a more appropriate observation distribution for identifying discrete sequential structure in calcium imaging recordings. The generative model for a population of neurons is
<disp-formula id="eqn4">
<graphic xlink:href="682993v1_eqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn5">
<graphic xlink:href="682993v1_eqn5.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn6">
<graphic xlink:href="682993v1_eqn6.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn7">
<graphic xlink:href="682993v1_eqn7.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>z</italic> ∈{1, …, <italic>K</italic>} is a discrete variable taking on one of <italic>K</italic> values, ⊙ indicates element wise multiplication, and Ψ is a diagonal matrix of per-neuron noise variances. The parameters <italic>π</italic><sub>0</sub> and <italic>π</italic><sub><italic>k</italic></sub> correspond to the initial discrete state distribution and transition distribution conditioned on state <italic>k</italic>, respectively. Here, we have rewritten the per-neuron observation model in Equation (3) in a vectorized form for an AR(1) process. In the model, each discrete state prescribes a separate Poisson spike rate for every neuron. The spike counts generated from the model are then input to the AR observation process, whose parameters are shared across states.</p>
<p>The model is fit via the Expectation-Maximization (EM) algorithm <xref ref-type="bibr" rid="c9">Dempster et al. (1977)</xref>. The spike counts are numerically marginalized to get state-dependent likelihoods <italic>p</italic>(<bold><italic>y</italic></bold><sub><italic>t</italic></sub> ∣ <bold><italic>y</italic></bold><sub><italic>t</italic>−1</sub>,<italic>z</italic><sub><italic>t</italic></sub> = <italic>k</italic>) used in the E-step. In the M-step, the expected joint log likelihood is optimized with respect to the model parameters using automatic differentiation.</p>
</sec>
<sec id="s2c">
<title>Simulated Data</title>
<p>We demonstrate the potential benefits of the Calcium HMM in a simulated experiment where a population of neurons exhibits sequential firing activity (<xref rid="fig2" ref-type="fig">Fig. 2a-b</xref>). The data is simulated from an HMM with 5 states and a separate cluster of neurons has high firing rates in each state. The transition matrix enforces sequential transitions between clusters. We first simulated the spike counts and then simulated the calcium observations given the spike counts. The calcium observations were generated from Equation (21) with additional independent measurement noise per time point. Importantly, this additional noise is biophysically motivated, meaning that the data do not fully arise from any of the models we will consider and are more faithful to real data collected in neuroscience experiments.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Simulated calcium HMM.</title>
<p>(a) Schematic for the overall calcium-HMM model. (b) The simulated data and (c) the inferred and true discrete states of the underlying latent states using different calcium models. (d) the inferred test log-likeilhoods as we vary the number of discrete latent states for different models. (e) true neural rates for each state of the underlying data alongside the inferred AR parameter mean (middle) and expected calcium fluorescence value (right).</p></caption>
<graphic xlink:href="682993v1_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We fit four different models to the simulated data. First, we fit a Poisson HMM with five states to the underlying spike counts. This comparison point quantifies how informative the underlying spikes are for recovering the model parameters and latent states, providing a reasonable upper bound on performance. We next fit three HMMs with different observation models to the generated calcium imaging data. The three observation models are independent Gaussian, autoregressive (AR) Gaussian, and the calcium observation model from Equation (21). The AR Gaussian model can be thought of as a special case of the calcium model that ablates the spiking component to test the relative utility of including the discrete spiking.</p>
<p>We found that modeling the calcium imaging data as an autoregressive model with a latent discrete spiking component best explained the simulated data. The recovered latent states from the calcium HMM on test data (correlation between true discrete states and inferred discrete states <italic>ρ</italic> =0.89) more closely matched the true latent states than those inferred from the Gaussian HMM (<italic>ρ</italic> =0.53) or autoregressive HMM (<italic>ρ</italic> =0.73), and approached the performance of the Poisson HMM (<italic>ρ</italic> =0.91) fit to the spiking data (<xref rid="fig2" ref-type="fig">Figure 2c</xref>). The calcium HMM achieved the test highest log-likelihood out of the models fit to the simulated calcium data and correctly identified the number of latent discrete states (<xref rid="fig2" ref-type="fig">Fig. 2d</xref>). Finally, for each discrete state we compared the true neuron firing rates with the “calcium influx” <bold>c</bold> ⊙<italic>λ</italic><sub><bold>z</bold></sub>, which are the firing rates inferred from the Calcium HMM model scaled by the influx parameters. We find that the estimated calcium influx approximately matches the true simulated firing rates and correctly identifies the different clusters of neurons, which is in contrast to the AR model that learns a less clear clustering (<xref rid="fig2" ref-type="fig">Fig. 2e</xref>).</p>
<p>Modeling Piriform Cortex Recordings During Odor Presentation After validating calcium HMM in simulation, we next demonstrate fitting the model to calcium imaging responses recorded in mouse piriform cortex during passive odor presentation (<xref ref-type="bibr" rid="c7">Daste and Pierré, 2022</xref>; <xref ref-type="bibr" rid="c59">Srinivasan et al., 2023</xref>). In this dataset, ten different odors were presented eight times over the course of a session containing 80 trials. The duration of each trial was 30 seconds and the odor was passively presented for 1 second starting 10 s after the trial onset.</p>
<p>We fit HMMs with calcium or Gaussian observation models to the responses of 284 neurons in piriform cortex recorded via calcium imaging (<xref rid="fig3" ref-type="fig">Fig. 3a</xref>). We first selected the number of discrete states <italic>K</italic> for each model via cross-validation (60 training trials, 19 test trials; <italic>K</italic> =13 for calcium and <italic>K</italic> =12 for Gaussian). The test log likelihood for the calcium HMM is substantially higher than the Gaussian observation model due to the more expressive observation model (<xref rid="fig3" ref-type="fig">Fig. 3b</xref>).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>HMM comparison on odor response data.</title>
<p>The calcium HMM identifies an odor onset state that is more tightly coupled with the actual odor onset.<bold>(a)</bold> Example Δ<italic>F</italic> /<italic>F</italic> traces for the population of recorded neurons on one trial. <bold>(b)</bold> Test log likelihoods for calcium and Gaussian HMMs as a function of the number of discrete states. Arrows indicate the number of discrete states with the highest test log likelihood. <bold>(c)</bold> Inferred most likely states on both training and test trials for each model. Each model identifies a consistent “odor onset” state linked to the time of odor presentation at 10s. <bold>(d)</bold> The fraction of trials in the odor onset state at each time point for each model. The calcium HMM odor onset state peaks more closely to the odor presentation window and has a shorter width (black arrows denote calculation of width).</p></caption>
<graphic xlink:href="682993v1_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We next analyzed the resulting calcium and Gaussian HMMs given the optimal number of states for each model. In each model, we found a discrete state that appears locked to odor onset across most trials (<xref rid="fig3" ref-type="fig">Fig. 3c</xref>). This “odor onset” state appears to mark a transition in the population response that occurs across most odor presentations. Notably, we found that the temporal extent of the odor onset state for the calcium HMM was more closely locked to the odor delivery window than the odor onset state for the Gaussian HMM (<xref rid="fig3" ref-type="fig">Fig. 3d</xref>). For the calcium HMM, trials generally transitioned into the odor onset state shortly after the odor presentation started and transitioned out of the odor onset state after a couple of seconds (peak onset state occupancy at 10.63s and onset state occupancy width of 2.65s). However, for the Gaussian HMM the transition into the odor onset state was generally delayed relative to the odor presentation and had a longer duration (peak onset state occupancy at 12.85s and onset state occupancy width of 6.64s).</p>
<p>The differences in the inferred odor onset state highlight the potential utility of the calcium LVMs described in this paper. In this dataset, the calcium HMM identified a discrete state that was time-locked to a behavioral variable of interest (odor presentation) in terms of both onset and duration of the discrete state. The calcium HMM odor onset state is more consistent with a population state that is time locked to the odor delivery window than the Gaussian HMM odor onset state. These results match our intuitions from the simulated calcium HMM example, where the inferred discrete states using the calcium HMM closely match the true discrete states but the inferred discrete states using the Gaussian HMM are generally delayed relative to the true discrete states.</p>
</sec>
<sec id="s2d">
<title>Calcium Gaussian Process Factor Analysis</title>
<p>Gaussian Process Factor Analysis (GPFA) is a standard tool for identifying smooth continuous latent structure underlying neural population data (<xref ref-type="bibr" rid="c69">Yu et al., 2009b</xref>). Many modern variants of GPFA include count-observation likelihoods and are typically evaluated on spiking data <xref ref-type="bibr" rid="c73">Zhao and Park (2016)</xref>; <xref ref-type="bibr" rid="c13">Duncker and Sahani (2018)</xref>; <xref ref-type="bibr" rid="c25">Keeley et al. (2020b)</xref>; <xref ref-type="bibr" rid="c65">Wu et al. (2017)</xref>. Here, we apply the calcium observation model to GPFA. In GPFA the prior on each latent dimension over time is a Gaussian Process. For a discrete set of time points, the prior is a multivariate Gaussian
<disp-formula id="eqn8">
<graphic xlink:href="682993v1_eqn8.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the covariance <italic>K</italic><sub><italic>j</italic></sub> is a <italic>T</italic> × <italic>T</italic> matrix whose entries are defined by a covariance function <italic>k</italic>(<italic>t, t</italic> <sup>′</sup>). Here, we use the function <italic>k</italic>(<italic>t, t</italic> <sup>′</sup>) = exp(−(<italic>t</italic> − <italic>t</italic> <sup>′</sup>)<sup>2</sup>/(2<italic>ℓj</italic><sup>2</sup>)) with a length-scale parameter <italic>ℓj</italic>.However, the proposed approach applies to other covariance functions as well. The dimensions are concatenated at each time point to produce a vector <inline-formula id="inline-eqn-2"><inline-graphic xlink:href="682993v1_inline2.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. The neural rates are generated via a linear map from the latent space followed by a non-linearity <italic>f</italic> which generates provides the rate parameter of the Poisson distribution. The observations are then modeled with using the Calcium AR process as before, however, for this example we include an additional AR-2 comparison, where the CI dynamics evolve dependent on the previous two time-steps.
<disp-formula id="eqn9">
<graphic xlink:href="682993v1_eqn9.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn10">
<graphic xlink:href="682993v1_eqn10.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>p</italic> is set to either 1 or 2 for our GPFA comparisons. The linear transformation contains, weights or “loadings” <italic>C</italic> and offsets <italic>d</italic>. Here, Ψ is a diagonal covariance matrix (<xref rid="fig4" ref-type="fig">Fig. 4(b)</xref>). The model is fit using a variational inference scheme which samples over the expectation term in the objective function (a so-called ‘black-box’ approach, see <xref ref-type="bibr" rid="c24">Keeley et al. (2020a)</xref>).</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Calcium GPFA simulated experiment using biophysical calcium imaging simulator.</title>
<p>(a) Graphical depiction of the biophysical calcium imaging simulator. (b) The Calcium GPFA model. (c) The temporal evolution of the three true underlying latent variables and the inferred latents from the population data using different observation likelihoods (left) and the overall estimation error of the latent variables under each model (right).</p></caption>
<graphic xlink:href="682993v1_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>To evaluate the model, we used a biophysical calcium imaging simulator NAOMi (<xref ref-type="bibr" rid="c58">Song et al., 2021</xref>) to simulate a population of 30 neurons whose spiking activity was generated from a Poisson GPFA model with three continuous latent dimensions (<xref rid="fig4" ref-type="fig">Fig. 4(a)</xref>). The simulator was critical for obtaining a realistic recording of CI data with known <italic>population</italic> ground truth spiking. Specifically, NAOMi simulates data via the biological and optical processes underlying CI, including variability in expression, optical aberrations, and calcium dynamics, providing a fair comparison that is not simply data sampled from the same statistical model used to fit the data. We fit GPFA models with CI and Gaussian observation models to the data.</p>
<p>The model with CI observations more accurately recovers both the continuous latent states (<xref rid="fig4" ref-type="fig">Fig. 4c,d</xref>), though in this example with the NaOMI-simulated traces, we find that the order of the AR process in the likelihood plays an important role in identifying the true underlying latent structure, with the CI AR2 likelihood outperforming AR1 as well as GPFA run on the deconvolved traces.</p>
</sec>
<sec id="s2e">
<title>Modeling nonlinear dynamics with Calcium LFADS</title>
<p>Latent Factor Analysis via Dynamical Systems (LFADs <xref ref-type="bibr" rid="c61">Sussillo et al. 2016</xref>; <xref ref-type="bibr" rid="c43">Pandarinath et al. 2018</xref>) is a model of neural population spiking data with nonlinear, recurrent neural network (RNN) dynamics. The model is general and provides accurate fits to neural population activity in multiple real-world settings (<xref ref-type="bibr" rid="c43">Pandarinath et al. 2018</xref>; <xref ref-type="bibr" rid="c46">Pei et al. 2021</xref>; <xref ref-type="bibr" rid="c27">Keshtkaran et al. 2022</xref>). As in the previous models, the standard LFADS formulation prescribes a distribution over Poisson firing rates via a Poisson GLM readout from the RNN. For calcium imaging data, previous work has proposed to incorporate an additional set of continuous latent variables corresponding to approximate spiking (<xref ref-type="bibr" rid="c50">Prince et al., 2021</xref>) or to fit the model to deconvolved spiking events (<xref ref-type="bibr" rid="c77">Zhu et al., 2022</xref>). Here we proposed an alternative adaptation of LFADS to calcium imaging data by adding the calcium observation model on top of the firing rates. The schematic of the model extension can be seen in <xref rid="fig5" ref-type="fig">Figure 5a</xref>. Importantly, the standard amortized variational inference fitting procedure for LFADS (<xref ref-type="bibr" rid="c29">Kingma and Welling 2014</xref>; <xref ref-type="bibr" rid="c28">Kingma et al. 2015</xref>; <xref ref-type="bibr" rid="c61">Sussillo et al. (2016</xref>) does not need to be modified with this change since the latent Poisson spike counts are marginalized out, in contrast to the model in <xref ref-type="bibr" rid="c50">Prince et al. (2021)</xref>. Additionally, the model is fit directly to fluorescence measurements without deconvolution, in contrast to <xref ref-type="bibr" rid="c77">Zhu et al. (2022)</xref>.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><p>(a) Calcium LFADS model. (b) Generated latents variables as well as Poisson firing rates, spiking activity, and observed calcium traces. (c) inferred latent dynamics under an (AR1) calcium model and Gaussian likelihood. (c) latent state prediction peroformance as well as inferred and true calcium trace hyperparameters.</p></caption>
<graphic xlink:href="682993v1_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>To demonstrate the approach, we synthetically generated latent time series from a 3D Lorenz attractor. We mapped the latent time series to Poisson spiking rates via a Poisson GLM. Then, we simulated Poisson spiking followed by autoregressive calcium dynamics (<xref rid="fig5" ref-type="fig">Fig. 5b</xref>). We compare the model with LFADS fit using a Gaussian observation model. In <xref rid="fig5" ref-type="fig">Figure 5c,d</xref> we show that the model with calcium observations infers more accurate latent variables than the model with Gaussian observations (mean latent state reconstruction <italic>R</italic><sup>2</sup>=0.77 for calcium model compared to <italic>R</italic><sup>2</sup>=0.37 for the Gaussian model, with 78/80 trials better reconstructed by the calcium model). Additionally, the inferred parameters of the calcium autoregressive dynamics are qualitatively similar to the ground truth parameters across the simulated neurons (<xref rid="fig5" ref-type="fig">Fig. 5d</xref>).</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Here we have demonstrated that a tractable likelihood for calcium imaging data can be used to adapt a variety of latent variable models in neuroscience to the setting of calcium imaging recordings. The proposed models can be fit with similar computational and inference requirements to the equivalent spiking versions of the models and do not require deconvolution methods.</p>
<p>Importantly, our work complements a variety of recent efforts for improved estimation of neural activity from calcium imaging data. Many of these approaches work with the implicit goal of best inferring spikes from calcium traces (<xref ref-type="bibr" rid="c41">Pachitariu et al., 2018</xref>; <xref ref-type="bibr" rid="c63">Wei et al., 2020</xref>). Although such efforts are useful, they do not take into account the uncertainty underlying spiking in estimating neural rates.</p>
<p>Our work depends on extracting the calcium traces from fluorescence videos, which is itself an active area of research with a number of available methods (<xref ref-type="bibr" rid="c49">Pnevmatikakis et al., 2016</xref>; <xref ref-type="bibr" rid="c3">Charles et al., 2022</xref>; <xref ref-type="bibr" rid="c42">Pachitariu et al., 2016</xref>; <xref ref-type="bibr" rid="c11">Dinç et al., 2021</xref>). As such, errors in calcium imaging source extraction, e.g., due to false transients (<xref ref-type="bibr" rid="c17">Gauthier et al., 2022</xref>), can impact the outputs of our model in much the same way that multi-unit activity in electrophysiology. Care, therefore, should be taken to curate or validate the calcium traces, or use a robust estimation method (<xref ref-type="bibr" rid="c17">Gauthier et al., 2022</xref>; <xref ref-type="bibr" rid="c22">Inan et al., 2017</xref>).</p>
<p>In contrast to these spike-estimation approaches, there has been recent work that also uses generative models to describe calcium dynamics themselves, avoiding the two-step approach of first de-convolving, and then inferring latent structure from spike trains. In particular, <xref ref-type="bibr" rid="c50">Prince et al. (2021)</xref> uses a variational auto-encoder-style model to directly infer latent dynamics from raw calcium traces using latent Poisson rates and observed Gaussian likelihoods on the resultant calcium traces. Additionally, <xref ref-type="bibr" rid="c31">Koh et al. (2022)</xref> derives a generative autoregressive model of calcium dynamics from an underlying latent variables which evolve via linear dynamics. Here, there is no spiking explicitly modeled, and the underlying latent dynamics directly prescribe correlations in the observed calcium traces. Similarly, <xref ref-type="bibr" rid="c53">Rupasinghe et al. (2021)</xref> uses signal and noise correlations in the calcium population activity to extract latent time-series which generate latent (Bernoulli) spike rates, which, similar to our approach, leverage uncertainty in latent spike counts. This again avoids the two-step procedure and directly infers latent structure from population covariance.</p>
<p>Our work here as well as in <xref ref-type="bibr" rid="c15">Ganmor et al. (2016)</xref> complements these approaches, but in contrast to them, does not enforce a specific model of latent structure. Instead, we have shown how a versatile calcium likelihood can be used in conjunction with a wide variety of latent variable models used in neuroscience. We do not assume a specific latent variable structure and instead leave that choice to the practitioner. While we demonstrate the effectiveness of this approach for GPFA, LFADS, and HMMs, there are many other existing latent variable models that could be adapted for our approach including switching dynamical systems (<xref ref-type="bibr" rid="c36">Linderman et al., 2016b</xref>; <xref ref-type="bibr" rid="c78">Zoltowski et al., 2020</xref>; <xref ref-type="bibr" rid="c23">Karniol-Tambour et al., 2022</xref>), other nonstationary dynamical systems (<xref ref-type="bibr" rid="c39">Mudrik et al., 2024</xref>, <xref ref-type="bibr" rid="c40">2025</xref>), extensions to GPFA (<xref ref-type="bibr" rid="c24">Keeley et al., 2020a</xref>; <xref ref-type="bibr" rid="c18">Gokcen, 2023</xref>), or other auto-encoder style latent variable models (<xref ref-type="bibr" rid="c76">Zhou and Wei, 2020</xref>; <xref ref-type="bibr" rid="c55">Schneider et al., 2023</xref>).</p>
<p>Additionally, our proposed approach may also be relevant for large-scale models of neural recordings (<xref ref-type="bibr" rid="c1">Azabou et al., 2023</xref>; <xref ref-type="bibr" rid="c66">Ye et al., 2023</xref>; <xref ref-type="bibr" rid="c72">Zhang et al., 2024</xref>). Such models often incorporate Poisson spiking rates and neural reconstruction losses often uses Poisson or cross-entropy observation models. The CI observation model incorporated in this paper could be applied to directly adapt such models for CI data and even presents the opportunity to jointly train large-scale models on electrophyisological and CI recordings.</p>
<p>Overall, we demonstrate that models developed for direct use on neural spike-trains can be adapted to calcium imaging data using a simple plug-and-play approach. Our public repository (<ext-link ext-link-type="uri" xlink:href="https://github.com/skeeley/Calcium_likelihoods">https://github.com/skeeley/Calcium_likelihoods</ext-link>) is available in both JAX and PyTorch implementations, with tutorials to demonstrate how they can be integrated into existing models, and it is our hope that this method will accelerate the application of powerful latent variable models to calcium imaging data.</p>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Calcium observation model</title>
<p>A likelihood originally proposed in 2016 (<xref ref-type="bibr" rid="c15">Ganmor et al., 2016</xref>) defines a conditional probability of measured calcium fluorescence <italic>y</italic> (the so-called “dF over F”) given a Poisson firing rate <italic>λ</italic>.This model is an autoregressive (AR) model whose output depends linearly on its previous value one timestep in the past (so-called AR(1) model). This basic AR(1) version additionally has the calcium level depend on Poisson spiking with additive independent Gaussian noise on each time step:
<disp-formula id="eqn11">
<graphic xlink:href="682993v1_eqn11.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn12">
<graphic xlink:href="682993v1_eqn12.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn13">
<graphic xlink:href="682993v1_eqn13.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>This model has three parameters:</p>
<list list-type="bullet">
<list-item><p><italic>α</italic>, the AR coefficient, which determines exponential decay of fluorescence;</p></list-item>
<list-item><p><italic>c</italic>, the fluorescence increase due to a single spike;</p></list-item>
<list-item><p><italic>σ</italic><sup>2</sup>, the variance of the additive Gaussian noise.</p></list-item>
</list>
<p>Practically, this model can be interpreted as a process where an individual spike causes an instantaneous rise in calcium florescence, followed by an exponential decay due to the AR coefficient. Here, additive Gaussian noise is fed through the AR process. Importantly, the model allows us to marginalize over spike counts <italic>n</italic>, so we can consider the probability of the fluorescence given the <italic>rate, λ</italic>, and we need not consider individual spikes. We elaborate on the details of the model below.</p>
</sec>
<sec id="s4b">
<title>Likelihood Evaluation</title>
<p>For model fitting and inference, we must be able to efficiently evaluate the likelihood of observed calcium responses marginalized over the unobserved spike count vector <bold>n</bold>. The independence across time bins in (<bold>??</bold>) means that these marginals can be computed independently for each time bin. That is, we can compute likelihood by summing over spike count in each bin from 0 to some maximum possible spike count <italic>R</italic>.</p>
<p>Thus, numerical evaluation of the likelihood can be achieved practically as:
<disp-formula id="eqn14">
<graphic xlink:href="682993v1_eqn14.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn15">
<graphic xlink:href="682993v1_eqn15.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <inline-formula id="inline-eqn-3"><inline-graphic xlink:href="682993v1_inline3.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is the Poisson probability over spike counts in each time bin.</p>
<p>In practice we will of course compute the log-likelihood, given by:
<disp-formula id="eqn16">
<graphic xlink:href="682993v1_eqn16.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>Importantly, this marginalization is amenable to automatic differentiation packages, making this truly a ‘plug and play’ observation distribution for various models.</p>
</sec>
<sec id="s4c">
<title>Synthetic HMM Dataset and Experimental Details</title>
<p>The synthetic HMM dataset had <italic>K</italic> =5 states and <italic>D</italic> =25 observed neurons. We generated two sequences of length <italic>T</italic> = 2000; the first was observed for training and the second was held-out for testing. The state transition matrix was designed to generate a repeating chain structure in the latent states such that the transition matrix <italic>P</italic> was
<disp-formula id="eqn17">
<graphic xlink:href="682993v1_eqn17.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>The synthetic neurons were grouped into 5 groups of 5 neurons corresponding to each of the latent states. Each neuron’s firing rate was 0.2 spikes per bin. The calcium observation model parameters were selected as <italic>α ∼</italic> 𝒩 (0.8, 0.1), <italic>c</italic> =1.0,and <italic>σ</italic><sup>2</sup>=1<italic>e</italic>−2. The AR coefficients were clipped to be within the range <italic>α</italic> ∈[0.6, 0.95]. Importantly, we added simulated measurement noise to the simulated calcium traces via a Gaussian noise model with zero mean and standard deviation of 0.2. Therefore, the simulated dataset is generated from a model that is mismatched to all models considered.</p>
<p>We initialized the calcium AR parameters via the following procedure. The AR coefficients were initialized via a linear regression predicting the next calcium observation from the previous observation for each neuron. The initial variance was set to the squared residual error of this linear regression. The initial fluorescence increases <italic>c</italic> were set randomly from the distribution 𝒩 (1.0, 0.2).</p>
</sec>
<sec id="s4d">
<title>Piriform Cortex Recodings During Odor Presentation</title>
<p>We applied the Calcium HMM model to a publicly available dataset of piriform cortex calcium imaging recordings during passive odor presentation (<xref ref-type="bibr" rid="c7">Daste and Pierré, 2022</xref>). This dataset consists of 8 repeated presentations of 10 different odors, yielding 80 total trials. We used publicly available code to process the code into Δ<italic>F</italic> /<italic>F</italic> (<ext-link ext-link-type="uri" xlink:href="https://gitlab.com/fleischmann-lab/datasets/daste-odor-set2021-11">https://gitlab.com/fleischmann-lab/datasets/daste-odor-set2021-11</ext-link>). We additionally filtered out one anomalous trial and one anomalous neuron. After processing, the dataset consisted of recordings of 284 neurons across 79 trials. Each trial lasted 30 seconds and the imaging sampling frequency was 4.53 Hz (see (<xref ref-type="bibr" rid="c59">Srinivasan et al., 2023</xref>), ‘Two-photon microscopy’ methods for additional details).</p>
<p>We used the first 30 and last 30 trials as training trials and tested on the middle 19 trials. The observation model parameters were initialized with a two-step procedure. First, initial discrete state sequences were set using the known odor sequence or using K-means clustering. Then, we optimized the observation model parameters (both Poisson rates and calcium observation parameters) by maximizing the likelihood of the calcium observations with the discrete state sequence fixed. After this initialization, we then optimized all parameters with respective to the HMM marginal likelihood using SGD for 5000 iterations.</p>
<p>The calcium HMM was implemented in JAX using HMM tools from the Dynamax repository (<ext-link ext-link-type="uri" xlink:href="https://github.com/probml/dynamax">https://github.com/probml/dynamax</ext-link>). This was important for computationally efficiency, as the optimization step was automatically batched across trials and compiled for speed.</p>
</sec>
<sec id="s4e">
<title>GPFA Synthetic Dataset with NAOMi Simulator</title>
<p>To use the NAOMi simulator, we generated a neural volume using the anatomy module and simulated the light propagation using the optics module. Rather than use the built in Hawkes process to simulate arbitrary dynamics, we imposed the spike times from the GPFA spike generation using calcium dynamics module’s feature that enables user-defined spikes. The calcium module then generated the ground-truth fluorescence traces from the provided spikes and we generated the CI simulated videos using the scanning module.</p>
<p>To recover single fluorescence traces from the video we used profile-assisted least-squares (PALS) as in the original NAOMi paper (<xref ref-type="bibr" rid="c58">Song et al., 2021</xref>). In this process we scan the volume under no-noise conditions with only one neuron “on” at a time and no neuropil or other contamination. These scans provide the ground-truth spatial profiles that can be used to identify the temporal profiles by solving a per-frame least-squares optimization. To reduce noise, we regularize the time-traces with a sparsity-promoting <italic>ℓj</italic><sub>1</sub> norm, also as in (<xref ref-type="bibr" rid="c58">Song et al., 2021</xref>). ThePALStracesremove the confounding factor of cell detection, which can vary significantly between approaches and can result in bleed-through errors that can effect the inferred coding properties of the cells (<xref ref-type="bibr" rid="c17">Gauthier et al., 2022</xref>).</p>
<p>To generate the simulated data for Calcium GPFA inference, generate Poisson spiking activity from 30 neurons for 4000 timespoints derived from a 3 dimensional latent space, where each latent is governed by a Gaussian Process with a different temporal length scale <italic>ℓj</italic> = {250, 450, 500}. Spike-times from these 30 neurons were then used as the ground-truth spikes in the NAOMi simulator. However, after simulation only 22 calcium traces had nonzero calcium dynamics. Therefore, inference for calcium GPFA was used on 22 calcium traces. The competing models either used Gaussian observations or Poisson observations from spikes that were determined by deconvolution via SpikeML (<xref ref-type="bibr" rid="c10">Deneux et al. 2016</xref>). GP length scales were all initialized to 350, calcium AR1 and AR2 parameters were initialized to.51 and {1.81, −.81} for all neurons, respectively. The noise parameter per neuron was initialized by setting it to the variance of the calcium values determined across consecutive timepoints, and the amplitude of the calcium influx due to a spike was initialized to 1 for all neurons. The model was learned via black-box variational inference for 20000 iterations. All inferred latents were regressed to the true latent before calculating the mean squared error.</p>
</sec>
<sec id="s4f">
<title>Calcium LFADS Model and Experimental Details</title>
<p>To evaluate the Calcium LFADS model, we simulated synthetic calcium observations from the Lorenz dynamical system across 400 trials each of length 100 with Δ<sub><italic>t</italic></sub> = 0.025 using the Runge-Kutta method (RK4). We simulated observations from 30 neurons. The average number of spikes per bin was 0.42. The calcium observation model parameters for each neuron were randomly sampled with <italic>α ∼</italic> Unif(0.8, 0.95) and <italic>c ∼</italic> Unif(0.8, 1.2). The autoregressive dynamics noise was set to 1<italic>e</italic> −3. After simulating the calcium traces, we added zero-mean Gaussian measurement noise with a standard deviation of 0.2 independently to each time step. Importantly, this measurement noise is not present in the generative model, as in the HMM example.</p>
<p>The full generative model of the LFADS model with calcium observations is
<disp-formula id="eqn18">
<graphic xlink:href="682993v1_eqn18.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn19">
<graphic xlink:href="682993v1_eqn19.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn20">
<graphic xlink:href="682993v1_eqn20.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn21">
<graphic xlink:href="682993v1_eqn21.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>F</italic> is a recurrent neural network (GRU) and the random inputs <italic>u</italic><sub>1:<italic>T</italic></sub> are generated from an autoregressive process with <inline-formula id="inline-eqn-4"><inline-graphic xlink:href="682993v1_inline4.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. The model is fit as a sequential variational autoencoder as in (<xref ref-type="bibr" rid="c43">Pandarinath et al., 2018</xref>) with encoder networks inferring approximate posterior distributions over the initial state <italic>x</italic><sub>0</sub> and sequence of random inputs <italic>u</italic><sub>1:<italic>T</italic></sub>. Before fitting the model, we initialized the calcium observation model hyperameters <italic>α</italic> and <italic>c</italic>. For each neuron, the AR parameter <italic>α</italic> was estimated via a linear regression predicting <italic>y</italic><sub><italic>t</italic>−1</sub> from <italic>y</italic><sub><italic>t</italic></sub> for timepoints where <italic>y</italic><sub><italic>t</italic>−1</sub> <italic>&lt;y</italic><sub><italic>t</italic></sub>. The influx parameter <italic>c</italic> was estimated by sweeping over a range of possible values from 0.8 to 2.2 and identifying the value the best aligned the differences <italic>y</italic><sub><italic>t</italic>−1</sub> − <italic>y</italic><sub><italic>t</italic></sub> with quantized values 0,<italic>c</italic>, 2<italic>c</italic>, 3<italic>c</italic>.</p>
</sec>
</sec>
</body>
<back>
<sec id="das" sec-type="data-availability">
<title>Data availability</title>
<p>The current manuscript is a computational study, so no data have been generated for this manuscript. The code for analyses presented in this paper is openly accessible at <ext-link ext-link-type="uri" xlink:href="https://github.com/skeeley/Calcium_likelihoods">https://github.com/skeeley/Calcium_likelihoods</ext-link></p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>SK was supposed by the NIH BRAIN Initiative (F32MH115445-03). DMZ was funded by the Wu Tsai Interdisciplinary Postdoctoral Research Fellowship. ASC was supported by the NSF under Grant No. 2340338 (Faculty Early Career Development Program -CAREER). JWP was supported by the Simons Collaboration on the Global Brain (SCGB AWD543027), the NIH BRAIN Initiative (9R01DA056404), and a U19 NIH-NINDS BRAIN Initiative Award (U19NS104648).</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Azabou</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Arora</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Ganesh</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Mao</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Nachimuthu</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Mendelson</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Richards</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Perich</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Lajoie</surname>, <given-names>G.</given-names></string-name>, and <string-name><surname>Dyer</surname>, <given-names>E.</given-names></string-name></person-group> (<year>2023</year>). <article-title>A unified, scalable framework for neural population decoding</article-title>. <source>Advances in Neural Information Processing Systems</source>, <volume>36</volume>:<fpage>44937</fpage>–<lpage>44956</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Calabrese</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Schumacher</surname>, <given-names>J. W.</given-names></string-name>, <string-name><surname>Schneider</surname>, <given-names>D. M.</given-names></string-name>, <string-name><surname>Paninski</surname>, <given-names>L.</given-names></string-name>, and <string-name><surname>Woolley</surname>, <given-names>S. M. N.</given-names></string-name></person-group> (<year>2011</year>). <article-title>A generalized linear model for estimating spectrotemporal receptive fields from responses to natural sounds</article-title>. <source>PLoS One</source>, <volume>6</volume>(<issue>1</issue>):<fpage>e16104</fpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Charles</surname>, <given-names>A. S.</given-names></string-name>, <string-name><surname>Cermak</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Affan</surname>, <given-names>R. O.</given-names></string-name>, <string-name><surname>Scott</surname>, <given-names>B. B.</given-names></string-name>, <string-name><surname>Schiller</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Mishne</surname>, <given-names>G.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Graft: graph filtered temporal dictionary learning for functional neural imaging</article-title>. <source>IEEE Transactions on Image Processing</source>, <volume>31</volume>:<fpage>3509</fpage>–<lpage>3524</lpage>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Charles</surname>, <given-names>A. S.</given-names></string-name>, <string-name><surname>Park</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Weller</surname>, <given-names>J. P.</given-names></string-name>, <string-name><surname>Horwitz</surname>, <given-names>G. D.</given-names></string-name>, and <string-name><surname>Pillow</surname>, <given-names>J. W.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Dethroning the fano factor: A flexible, model-based approach to partitioning neural variability</article-title>. <source>Neural computation</source>, <volume>30</volume>(<issue>4</issue>):<fpage>1012</fpage>–<lpage>1045</lpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chen</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Mudrik</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Johnsen</surname>, <given-names>K. A.</given-names></string-name>, <string-name><surname>Alagapan</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Charles</surname>, <given-names>A. S.</given-names></string-name>, and <string-name><surname>Rozell</surname>, <given-names>C.</given-names></string-name></person-group> (<year>2024</year>). <article-title>Probabilistic decomposed linear dynamical systems for robust discovery of latent neural dynamics</article-title>. <source>Advances in Neural Information Processing Systems</source>, <volume>37</volume>:<fpage>104443</fpage>–<lpage>104470</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cronin</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Stevenson</surname>, <given-names>I. H.</given-names></string-name>, <string-name><surname>Sur</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Körding</surname>, <given-names>K. P.</given-names></string-name></person-group> (<year>2010</year>). <article-title>Hierarchical bayesian modeling and markov chain monte carlo sampling for tuning-curve analysis</article-title>. <source>J Neurophysiol</source>, <volume>103</volume>(<issue>1</issue>):<fpage>591</fpage>–<lpage>602</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="data" specific-use="generated"><person-group person-group-type="author"><string-name><surname>Daste</surname>, <given-names>S.</given-names></string-name> and <string-name><surname>Pierré</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Two photon calcium imaging of mice piriform cortex under passive odor presentation. (Version 0.220928.1306)</article-title>. <source>DANDI archive</source>. <pub-id pub-id-type="doi">10.48324/dandi.000167/0.220928.1306</pub-id>.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Demas</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Manley</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Tejera</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Barber</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Kim</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Traub</surname>, <given-names>F. M.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>B.</given-names></string-name>, and <string-name><surname>Vaziri</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2021</year>). <article-title>High-speed, cortex-wide volumetric recording of neuroactivity at cellular resolution using light beads microscopy</article-title>. <source>Nature Methods</source>, <volume>18</volume>(<issue>9</issue>):<fpage>1103</fpage>–<lpage>1111</lpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dempster</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Laird</surname>, <given-names>N.</given-names></string-name>, and <string-name><surname>Rubin</surname>, <given-names>R.</given-names></string-name></person-group> (<year>1977</year>). <article-title>Maximum likelihood from incomplete data via the EM algorithm</article-title>. <source>J. Royal Statistical Society, B</source>, <volume>39</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>38</lpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Deneux</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Kaszas</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Szalay</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Katona</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Lakner</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Grinvald</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Rózsa</surname>, <given-names>B.</given-names></string-name>, and <string-name><surname>Vanzetta</surname>, <given-names>I.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Accurate spike estimation from noisy calcium signals for ultrafast three-dimensional imaging of large neuronal populations in vivo</article-title>. <source>Nature communications</source>, <volume>7</volume>(<issue>1</issue>):<fpage>12190</fpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Dinç</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Inan</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Hernandez</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Schmuckermair</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Hazon</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Tasci</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Ahanonu</surname>, <given-names>B. O.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Lecoq</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Haziza</surname>, <given-names>S.</given-names></string-name>, <etal>et al.</etal></person-group> (<year>2021</year>). <article-title>Fast, scalable, and statistically robust cell extraction from large-scale neural calcium imaging datasets</article-title>. <source>BioRxiv</source>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Duncker</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Bohner</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Boussard</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Sahani</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Learning interpretable continuous-time models of latent stochastic dynamical systems</article-title>. <source>arXiv</source> <pub-id pub-id-type="arxiv">1902.04420</pub-id>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Duncker</surname>, <given-names>L.</given-names></string-name> and <string-name><surname>Sahani</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Temporal alignment and latent gaussian process factor inference in population spike trains</article-title>. In <conf-name>Advances in Neural Information Processing Systems</conf-name>, pages <fpage>10445</fpage>–<lpage>10455</lpage>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Escola</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Fontanini</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Katz</surname>, <given-names>D.</given-names></string-name>, and <string-name><surname>Paninski</surname>, <given-names>L.</given-names></string-name></person-group> (<year>2011</year>). <article-title>Hidden markov models for the stimulus-response relationships of multistate neural systems</article-title>. <source>Neural Computation</source>, <volume>23</volume>(<issue>5</issue>):<fpage>1071</fpage>–<lpage>1132</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Ganmor</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Krumin</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Rossi</surname>, <given-names>L. F.</given-names></string-name>, <string-name><surname>Carandini</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Simoncelli</surname>, <given-names>E. P.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Direct estimation of firing rates from calcium imaging data</article-title>. <source>arXiv</source> <pub-id pub-id-type="arxiv">1601.00364</pub-id>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Gao</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Busing</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Shenoy</surname>, <given-names>K. V.</given-names></string-name>, and <string-name><surname>Cunningham</surname>, <given-names>J. P.</given-names></string-name></person-group> (<year>2015</year>). <article-title>High-dimensional neural spike train analysis with generalized count linear dynamical systems</article-title>. In <conf-name>Advances in neural information processing systems</conf-name>, pages <fpage>2044</fpage>–<lpage>2052</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gauthier</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Koay</surname>, <given-names>S. A.</given-names></string-name>, <string-name><surname>Nieh</surname>, <given-names>E. H.</given-names></string-name>, <string-name><surname>Tank</surname>, <given-names>D. W.</given-names></string-name>, <string-name><surname>Pillow</surname>, <given-names>J. W.</given-names></string-name>, and <string-name><surname>Charles</surname>, <given-names>A. S.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Detecting and correcting false transients in calcium imaging</article-title>. <source>Nature Methods</source>, <volume>19</volume>(<issue>4</issue>):<fpage>470</fpage>–<lpage>478</lpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Gokcen</surname>, <given-names>E.</given-names></string-name></person-group> (<year>2023</year>). <source>Disentangling communication across populations of neurons</source>. <publisher-name>Carnegie Mellon University</publisher-name>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Goris</surname>, <given-names>R. L. T.</given-names></string-name>, <string-name><surname>Movshon</surname>, <given-names>J. A.</given-names></string-name>, and <string-name><surname>Simoncelli</surname>, <given-names>E. P.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Partitioning neuronal variability</article-title>. <source>Nat Neurosci</source>, <volume>17</volume>(<issue>6</issue>):<fpage>858</fpage>–<lpage>865</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Helmchen</surname>, <given-names>F.</given-names></string-name> and <string-name><surname>Tank</surname>, <given-names>D. W.</given-names></string-name></person-group> (<year>2015</year>). <article-title>A single-compartment model of calcium dynamics in nerve terminals and dendrites</article-title>. <source>Cold Spring Harbor Protocols</source>, <volume>2015</volume>(<issue>2</issue>):<fpage>pdb</fpage>–<lpage>top085910</lpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Huang</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Ledochowitsch</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Knoblich</surname>, <given-names>U.</given-names></string-name>, <string-name><surname>Lecoq</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Murphy</surname>, <given-names>G. J.</given-names></string-name>, <string-name><surname>Reid</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>de Vries</surname>, <given-names>S. E.</given-names></string-name>, <string-name><surname>Koch</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Zeng</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Buice</surname>, <given-names>M. A.</given-names></string-name>, <etal>et al.</etal></person-group> (<year>2021</year>). <article-title>Relationship between simultaneously recorded spiking activity and fluorescence signal in gcamp6 transgenic mice</article-title>. <source>eLife</source>, <volume>10</volume>:<elocation-id>e51675</elocation-id>. <pub-id pub-id-type="doi">10.7554/eLife.51675</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Inan</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Erdogdu</surname>, <given-names>M. A.</given-names></string-name>, and <string-name><surname>Schnitzer</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Robust estimation of neural signals in calcium imaging</article-title>. <source>Advances in neural information processing systems</source>, <volume>30</volume>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Karniol-Tambour</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Zoltowski</surname>, <given-names>D. M.</given-names></string-name>, <string-name><surname>Diamanti</surname>, <given-names>E. M.</given-names></string-name>, <string-name><surname>Pinto</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Tank</surname>, <given-names>D. W.</given-names></string-name>, <string-name><surname>Brody</surname>, <given-names>C. D.</given-names></string-name>, and <string-name><surname>Pillow</surname>, <given-names>J. W.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Modeling communication and switching nonlinear dynamics in multi-region neural activity</article-title>. <source>bioRxiv</source>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Keeley</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Aoi</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Yu</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>S.</given-names></string-name>, and <string-name><surname>Pillow</surname>, <given-names>J. W.</given-names></string-name></person-group> (<year>2020a</year>). <article-title>Identifying signal and noise structure in neural population activity with gaussian process factor models</article-title>. <source>Advances in Neural Information Processing Systems</source>, <volume>33</volume>:<fpage>13795</fpage>–<lpage>13805</lpage>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Keeley</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Zoltowski</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Yu</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>S.</given-names></string-name>, and <string-name><surname>Pillow</surname>, <given-names>J.</given-names></string-name></person-group> (<year>2020b</year>). <article-title>Efficient non-conjugate gaussian process factor models for spike count data using polynomial approximations</article-title>. In <conf-name>International Conference on Machine Learning</conf-name>, pages <fpage>5177</fpage>–<lpage>5186</lpage>. <publisher-name>PMLR</publisher-name>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Keeley</surname>, <given-names>S. L.</given-names></string-name>, <string-name><surname>Zoltowski</surname>, <given-names>D. M.</given-names></string-name>, <string-name><surname>Yu</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Yates</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Smith</surname>, <given-names>S. L.</given-names></string-name>, and <string-name><surname>Pillow</surname>, <given-names>J. W.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Efficient non-conjugate gaussian process factor models for spike count data using polynomial approximations</article-title>. <source>arXiv</source> <pub-id pub-id-type="arxiv">1906.03318</pub-id>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Keshtkaran</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Sedler</surname>, <given-names>A. R.</given-names></string-name>, <string-name><surname>Chowdhury</surname>, <given-names>R. H.</given-names></string-name>, <string-name><surname>Tandon</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Basrai</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Nguyen</surname>, <given-names>S. L.</given-names></string-name>, <string-name><surname>Sohn</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Jazayeri</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>L. E.</given-names></string-name>, and <string-name><surname>Pandarinath</surname>, <given-names>C.</given-names></string-name></person-group> (<year>2022</year>). <article-title>A large-scale neural network training framework for generalized estimation of single-trial population dynamics</article-title>. <source>Nature Methods</source>, <volume>19</volume>(<issue>12</issue>):<fpage>1572</fpage>–<lpage>1577</lpage>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Kingma</surname>, <given-names>D. P.</given-names></string-name>, <string-name><surname>Salimans</surname>, <given-names>T.</given-names></string-name>, and <string-name><surname>Welling</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2015</year>). <article-title>Variational dropout and the local reparameterization trick</article-title>. In <conf-name>Advances in Neural Information Processing Systems</conf-name>, pages <fpage>2575</fpage>–<lpage>2583</lpage>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Kingma</surname>, <given-names>D. P.</given-names></string-name> and <string-name><surname>Welling</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Auto-encoding variational bayes</article-title>. <source>arXiv</source>:<pub-id pub-id-type="arxiv">1312.6114</pub-id>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ko</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Cossell</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Baragli</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Antolik</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Clopath</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Hofer</surname>, <given-names>S. B.</given-names></string-name>, and <string-name><surname>Mrsic-Flogel</surname>, <given-names>T. D.</given-names></string-name></person-group> (<year>2013</year>). <article-title>The emergence of functional microcircuits in visual cortex</article-title>. <source>Nature</source>, <volume>496</volume>(<issue>7443</issue>):<fpage>96</fpage>–<lpage>100</lpage>.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Koh</surname>, <given-names>T. H.</given-names></string-name>, <string-name><surname>Bishop</surname>, <given-names>W. E.</given-names></string-name>, <string-name><surname>Kawashima</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Jeon</surname>, <given-names>B. B.</given-names></string-name>, <string-name><surname>Srinivasan</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Kuhlman</surname>, <given-names>S. J.</given-names></string-name>, <string-name><surname>Ahrens</surname>, <given-names>M. B.</given-names></string-name>, <string-name><surname>Chase</surname>, <given-names>S. M.</given-names></string-name>, and <string-name><surname>Byron</surname>, <given-names>M. Y.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Dimensionality reduction of calcium-imaged neuronal population activity</article-title>. <source>bioRxiv</source>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krause</surname>, <given-names>E. L.</given-names></string-name> and <string-name><surname>Drugowitsch</surname>, <given-names>J.</given-names></string-name></person-group> (<year>2022</year>). <article-title>A large majority of awake hippocampal sharp-wave ripples feature spatial trajectories with momentum</article-title>. <source>Neuron</source>, <volume>110</volume>(<issue>4</issue>):<fpage>722</fpage>–<lpage>733</lpage>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Ledochowitsch</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Huang</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Knoblich</surname>, <given-names>U.</given-names></string-name>, <string-name><surname>Oliver</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Lecoq</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Reid</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Zeng</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Koch</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Waters</surname>, <given-names>J.</given-names></string-name>, <etal>et al.</etal></person-group> (<year>2019</year>). <article-title>On the correspondence of electrical and optical physiology in in vivo population-scale two-photon calcium imaging</article-title>. <source>BioRxiv</source>, page <fpage>800102</fpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Linderman</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Adams</surname>, <given-names>R. P.</given-names></string-name>, and <string-name><surname>Pillow</surname>, <given-names>J. W.</given-names></string-name></person-group> (<year>2016a</year>). <article-title>Bayesian latent structure discovery from multi-neuron recordings</article-title>. In <conf-name>Advances in neural information processing systems</conf-name>, pages <fpage>2002</fpage>–<lpage>2010</lpage>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Linderman</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Johnson</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Adams</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Blei</surname>, <given-names>D.</given-names></string-name>, and <string-name><surname>Paninski</surname>, <given-names>L.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Bayesian Learning and Inference in Recurrent Switching Linear Dynamical Systems</article-title>. <conf-name>Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, volume 54 of Proceedings of Machine Learning Research</conf-name>, pages <fpage>914</fpage>–<lpage>922</lpage>, <publisher-loc>Fort Lauderdale, FL, USA</publisher-loc>. <publisher-name>PMLR</publisher-name>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Linderman</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Adams</surname>, <given-names>R. P.</given-names></string-name>, <string-name><surname>Blei</surname>, <given-names>D. M.</given-names></string-name>, <string-name><surname>Paninski</surname>, <given-names>L.</given-names></string-name>, and <string-name><surname>Johnson</surname>, <given-names>M. J.</given-names></string-name></person-group> (<year>2016b</year>). <article-title>Recurrent switching linear dynamical systems</article-title>. <source>arXiv</source>.</mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Macke</surname>, <given-names>J. H.</given-names></string-name>, <string-name><surname>Buesing</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Cunningham</surname>, <given-names>J. P.</given-names></string-name>, <string-name><surname>Byron</surname>, <given-names>M. Y.</given-names></string-name>, <string-name><surname>Shenoy</surname>, <given-names>K. V.</given-names></string-name>, and <string-name><surname>Sahani</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2011</year>). <article-title>Empirical models of spiking in neural populations</article-title>. In <source>Advances in neural information processing systems</source>, volume <volume>24</volume>, pages <fpage>1350</fpage>–<lpage>1358</lpage>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McFarland</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Cui</surname>, <given-names>Y.</given-names></string-name>, and <string-name><surname>Butts</surname>, <given-names>D. A.</given-names></string-name></person-group> (<year>2013</year>). <article-title>Inferring nonlinear neuronal computation based on physiologically plausible inputs</article-title>. <source>PLoS Comput Biol</source>, <volume>9</volume>(<issue>7</issue>):<fpage>e1003143.</fpage>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mudrik</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Yezerets</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Rozell</surname>, <given-names>C. J.</given-names></string-name>, and <string-name><surname>Charles</surname>, <given-names>A. S.</given-names></string-name></person-group> (<year>2024</year>). <article-title>Decomposed linear dynamical systems (dlds) for learning the latent components of neural dynamics</article-title>. <source>Journal of Machine Learning Research</source>, <volume>25</volume>(<issue>59</issue>):<fpage>1</fpage>–<lpage>44</lpage>.</mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Mudrik</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Ly</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Ruebel</surname>, <given-names>O.</given-names></string-name>, and <string-name><surname>Charles</surname>, <given-names>A. S.</given-names></string-name></person-group> (<year>2025</year>). <article-title>Creimbo: Cross-regional ensemble interactions in multi-view brain observations</article-title>. In <conf-name>The Thirteenth International Conference on Learning Representations</conf-name>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pachitariu</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Stringer</surname>, <given-names>C.</given-names></string-name>, and <string-name><surname>Harris</surname>, <given-names>K. D.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Robustness of spike deconvolution for neuronal calcium imaging</article-title>. <source>Journal of Neuroscience</source>, <volume>38</volume>(<issue>37</issue>):<fpage>7976</fpage>–<lpage>7985</lpage>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Pachitariu</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Stringer</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Schröder</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Dipoppa</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Rossi</surname>, <given-names>L. F.</given-names></string-name>, <string-name><surname>Carandini</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Harris</surname>, <given-names>K. D.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Suite2p: beyond 10,000 neurons with standard two-photon microscopy</article-title>. <source>BioRxiv</source>, page <fpage>061507</fpage>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pandarinath</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>O’Shea</surname>, <given-names>D. J.</given-names></string-name>, <string-name><surname>Collins</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Jozefowicz</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Stavisky</surname>, <given-names>S. D.</given-names></string-name>, <string-name><surname>Kao</surname>, <given-names>J. C.</given-names></string-name>, <string-name><surname>Trautmann</surname>, <given-names>E. M.</given-names></string-name>, <string-name><surname>Kaufman</surname>, <given-names>M. T.</given-names></string-name>, <string-name><surname>Ryu</surname>, <given-names>S. I.</given-names></string-name>, <string-name><surname>Hochberg</surname>, <given-names>L. R.</given-names></string-name>, <string-name><surname>Henderson</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Shenoy</surname>, <given-names>K. V.</given-names></string-name>, <string-name><surname>Abbott</surname>, <given-names>L. F.</given-names></string-name>, and <string-name><surname>Sussillo</surname>, <given-names>D.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Inferring single-trial neural population dynamics using sequential auto-encoders</article-title>. <source>Nature Methods</source>, <volume>15</volume>(<issue>10</issue>):<fpage>805</fpage>–<lpage>815</lpage>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Park</surname>, <given-names>I. M.</given-names></string-name>, <string-name><surname>Archer</surname>, <given-names>E. W.</given-names></string-name>, <string-name><surname>Priebe</surname>, <given-names>N.</given-names></string-name>, and <string-name><surname>Pillow</surname>, <given-names>J. W.</given-names></string-name></person-group> (<year>2013</year>). <chapter-title>Spectral methods for neural characterization using generalized quadratic models</chapter-title>. In <person-group person-group-type="editor"><string-name><surname>Burges</surname>, <given-names>C. J. C.</given-names></string-name>, <string-name><surname>Bottou</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Welling</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Ghahramani</surname>, <given-names>Z.</given-names></string-name>, and <string-name><surname>Weinberger</surname>, <given-names>K. Q.</given-names></string-name></person-group>, editors, <source>Advances in Neural Information Processing Systems</source> <volume>26</volume>, pages <fpage>2454</fpage>–<lpage>2462</lpage>. <publisher-name>Curran Associates, Inc</publisher-name>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Park</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Weller</surname>, <given-names>J. P.</given-names></string-name>, <string-name><surname>Horwitz</surname>, <given-names>G. D.</given-names></string-name>, and <string-name><surname>Pillow</surname>, <given-names>J. W.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Bayesian active learning of neural firing rate maps with transformed gaussian process priors</article-title>. <source>Neural Computation</source>, <volume>26</volume>(<issue>8</issue>):<fpage>1519</fpage>–<lpage>1541</lpage>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Pei</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Ye</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Zoltowski</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Wu</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Chowdhury</surname>, <given-names>R. H.</given-names></string-name>, <string-name><surname>Sohn</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>O’Doherty</surname>, <given-names>J. E.</given-names></string-name>, <string-name><surname>Shenoy</surname>, <given-names>K. V.</given-names></string-name>, <string-name><surname>Kaufman</surname>, <given-names>M. T.</given-names></string-name>, <string-name><surname>Churchland</surname>, <given-names>M.</given-names></string-name>, <etal>et al.</etal></person-group> (<year>2021</year>). <article-title>Neural latents benchmark’21: evaluating latent variable models of neural population activity</article-title>. <source>arXiv</source> <pub-id pub-id-type="arxiv">2109.04463</pub-id>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Pillow</surname>, <given-names>J.</given-names></string-name> and <string-name><surname>Scott</surname>, <given-names>J.</given-names></string-name></person-group> (<year>2012</year>). <article-title>Fully bayesian inference for neural models with negative-binomial spiking</article-title>. <conf-name>Advances in Neural Information Processing Systems</conf-name> <volume>25</volume>, pages <fpage>1907</fpage>–<lpage>1915</lpage>.</mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pillow</surname>, <given-names>J. W.</given-names></string-name>, <string-name><surname>Shlens</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Paninski</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Sher</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Litke</surname>, <given-names>A. M.</given-names></string-name>, and <string-name><surname>Chichilnisky</surname>, <given-names>E. J.</given-names></string-name> <string-name><surname>Simoncelli</surname>, <given-names>E. P.</given-names></string-name></person-group> (<year>2008</year>). <article-title>Spatiotemporal correlations and visual signaling in a complete neuronal population</article-title>. <source>Nature</source>, <volume>454</volume>:<fpage>995</fpage>–<lpage>999</lpage>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pnevmatikakis</surname>, <given-names>E. A.</given-names></string-name>, <string-name><surname>Soudry</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Gao</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Machado</surname>, <given-names>T. A.</given-names></string-name>, <string-name><surname>Merel</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Pfau</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Reardon</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Mu</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Lacefield</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>W.</given-names></string-name>, <etal>et al.</etal></person-group> (<year>2016</year>). <article-title>Simultaneous denoising, deconvolution, and demixing of calcium imaging data</article-title>. <source>Neuron</source>, <volume>89</volume>(<issue>2</issue>):<fpage>285</fpage>–<lpage>299</lpage>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Prince</surname>, <given-names>L. Y.</given-names></string-name>, <string-name><surname>Bakhtiari</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Gillon</surname>, <given-names>C. J.</given-names></string-name>, and <string-name><surname>Richards</surname>, <given-names>B. A.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Parallel inference of hierarchical latent dynamics in two-photon calcium imaging of neuronal populations</article-title>. <source>bioRxiv</source>.</mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rad</surname>, <given-names>K. R.</given-names></string-name>, <string-name><surname>Machado</surname>, <given-names>T. A.</given-names></string-name>, <string-name><surname>Paninski</surname>, <given-names>L.</given-names></string-name>, <etal>et al.</etal></person-group> (<year>2017</year>). <article-title>Robust and scalable bayesian analysis of spatial neural tuning function data</article-title>. <source>The Annals of Applied Statistics</source>, <volume>11</volume>(<issue>2</issue>):<fpage>598</fpage>–<lpage>637</lpage>.</mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Rad</surname>, <given-names>K. R.</given-names></string-name> and <string-name><surname>Paninski</surname>, <given-names>L.</given-names></string-name></person-group> (<year>2011</year>). <article-title>Information rates and optimal decoding in large neural populations</article-title>. <conf-name>Advances in Neural Information Processing Systems</conf-name> <volume>24</volume>, pages <fpage>846</fpage>–<lpage>854</lpage>.</mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rupasinghe</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Francis</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Bowen</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Kanold</surname>, <given-names>P. O.</given-names></string-name>, and <string-name><surname>Babadi</surname>, <given-names>B.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Direct extraction of signal and noise correlations from two-photon calcium imaging of ensemble neuronal activity</article-title>. <source>eLife</source>, <volume>10</volume>:<elocation-id>e68046</elocation-id>. <pub-id pub-id-type="doi">10.7554/eLife.68046</pub-id></mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Savin</surname>, <given-names>C.</given-names></string-name> and <string-name><surname>Tkacik</surname>, <given-names>G.</given-names></string-name></person-group> (<year>2016</year>). <chapter-title>Estimating nonlinear neural response functions using gp priors and kronecker methods</chapter-title>. In <person-group person-group-type="editor"><string-name><surname>Lee</surname>, <given-names>D. D.</given-names></string-name>, <string-name><surname>Sugiyama</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Luxburg</surname>, <given-names>U. V.</given-names></string-name>, <string-name><surname>Guyon</surname>, <given-names>I.</given-names></string-name>, and <string-name><surname>Garnett</surname>, <given-names>R.</given-names></string-name></person-group>, editors, <source>Advances in Neural Information Processing Systems</source> <volume>29</volume>, pages <fpage>3603</fpage>–<lpage>3611</lpage>. <publisher-name>Curran Associates, Inc</publisher-name>.</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schneider</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>J. H.</given-names></string-name>, and <string-name><surname>Mathis</surname>, <given-names>M. W.</given-names></string-name></person-group> (<year>2023</year>). <article-title>Learnable latent embeddings for joint behavioural and neural analysis</article-title>. <source>Nature</source>, <volume>617</volume>(<issue>7960</issue>):<fpage>360</fpage>–<lpage>368</lpage>.</mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Smith</surname>, <given-names>A. C.</given-names></string-name> and <string-name><surname>Brown</surname>, <given-names>E. N.</given-names></string-name></person-group> (<year>2003</year>). <article-title>Estimating a state-space model from point process observations</article-title>. <source>Neural computation</source>, <volume>15</volume>(<issue>5</issue>):<fpage>965</fpage>–<lpage>991</lpage>.</mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Smith</surname>, <given-names>S. L.</given-names></string-name> and <string-name><surname>Häusser</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2010</year>). <article-title>Parallel processing of visual space by neighboring neurons in mouse visual cortex</article-title>. <source>Nature neuroscience</source>, <volume>13</volume>(<issue>9</issue>):<fpage>1144</fpage>–<lpage>1149</lpage>.</mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Song</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Gauthier</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Pillow</surname>, <given-names>J. W.</given-names></string-name>, <string-name><surname>Tank</surname>, <given-names>D. W.</given-names></string-name>, and <string-name><surname>Charles</surname>, <given-names>A. S.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Neural anatomy and optical microscopy (naomi) simulation for evaluating calcium imaging methods</article-title>. <source>Journal of Neuroscience Methods</source>, <volume>358</volume>:<fpage>109173</fpage>.</mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Srinivasan</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Daste</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Modi</surname>, <given-names>M. N.</given-names></string-name>, <string-name><surname>Turner</surname>, <given-names>G. C.</given-names></string-name>, <string-name><surname>Fleischmann</surname>, <given-names>A.</given-names></string-name>, and <string-name><surname>Navlakha</surname>, <given-names>S.</given-names></string-name></person-group> (<year>2023</year>). <article-title>Effects of stochastic coding on olfactory discrimination in flies and mice</article-title>. <source>PLoS Biology</source>, <volume>21</volume>(<issue>10</issue>):<fpage>e3002206</fpage>.</mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stevenson</surname>, <given-names>I. H.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Flexible models for spike count data with both over-and under-dispersion</article-title>. <source>Journal of computational neuroscience</source>, <volume>41</volume>(<issue>1</issue>):<fpage>29</fpage>–<lpage>43</lpage>.</mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Sussillo</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Jozefowicz</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Abbott</surname>, <given-names>L.</given-names></string-name>, and <string-name><surname>Pandarinath</surname>, <given-names>C.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Lfads-latent factor analysis via dynamical systems</article-title>. <source>arXiv</source> <pub-id pub-id-type="arxiv">1608.06315</pub-id>.</mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Truccolo</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Eden</surname>, <given-names>U. T.</given-names></string-name>, <string-name><surname>Fellows</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Donoghue</surname>, <given-names>J. P.</given-names></string-name>, and <string-name><surname>Brown</surname>, <given-names>E. N.</given-names></string-name></person-group> (<year>2005</year>). <article-title>A point process framework for relating neural spiking activity to spiking history, neural ensemble and extrinsic covariate effects</article-title>. <source>J. Neurophysiol</source>, <volume>93</volume>(<issue>2</issue>):<fpage>1074</fpage>–<lpage>1089</lpage>.</mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Wei</surname>, <given-names>X.-X.</given-names></string-name>, <string-name><surname>Zhou</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Grosmark</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Ajabi</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Sparks</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Zhou</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Brandon</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Losonczy</surname>, <given-names>A.</given-names></string-name>, and <string-name><surname>Paninski</surname>, <given-names>L.</given-names></string-name></person-group> (<year>2020</year>). <article-title>A zero-inflated gamma model for deconvolved calcium imaging traces</article-title>. <source>arXiv</source> <pub-id pub-id-type="arxiv">2006.03737</pub-id>.</mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Williamson</surname>, <given-names>R. S.</given-names></string-name>, <string-name><surname>Sahani</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Pillow</surname>, <given-names>J. W.</given-names></string-name></person-group> (<year>2015</year>). <article-title>The equivalence of information-theoretic and likelihood-based methods for neural dimensionality reduction</article-title>. <source>PLoS Comput Biol</source>, <volume>11</volume>(<issue>4</issue>):<fpage>e1004141</fpage>.</mixed-citation></ref>
<ref id="c65"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Wu</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Roy</surname>, <given-names>N. G.</given-names></string-name>, <string-name><surname>Keeley</surname>, <given-names>S.</given-names></string-name>, and <string-name><surname>Pillow</surname>, <given-names>J. W.</given-names></string-name></person-group> (<year>2017</year>). <chapter-title>Gaussian process based nonlinear latent structure discovery in multivariate spike train data</chapter-title>. In <person-group person-group-type="editor"><string-name><surname>Guyon</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Luxburg</surname>, <given-names>U. V.</given-names></string-name>, <string-name><surname>Bengio</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Wallach</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Fergus</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Vishwanathan</surname>, <given-names>S.</given-names></string-name>, and <string-name><surname>Garnett</surname>, <given-names>R.</given-names></string-name></person-group>, editors, <source>Advances in Neural Information Processing Systems</source> <volume>30</volume>, pages <fpage>3496</fpage>–<lpage>3505</lpage>. <publisher-name>Curran Associates, Inc</publisher-name>.</mixed-citation></ref>
<ref id="c66"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ye</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Collinger</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Wehbe</surname>, <given-names>L.</given-names></string-name>, and <string-name><surname>Gaunt</surname>, <given-names>R.</given-names></string-name></person-group> (<year>2023</year>). <article-title>Neural data transformer 2: multi-context pretraining for neural spiking activity</article-title>. <source>Advances in Neural Information Processing Systems</source>, <volume>36</volume>:<fpage>80352</fpage>–<lpage>80374</lpage>.</mixed-citation></ref>
<ref id="c67"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yezerets</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Mudrik</surname>, <given-names>N.</given-names></string-name>, and <string-name><surname>Charles</surname>, <given-names>A. S.</given-names></string-name></person-group> (<year>2025</year>). <article-title>Decomposed linear dynamical systems (dlds) models reveal instantaneous, context-dependent dynamic connectivity in C. elegans</article-title>. <source>Communications Biology</source>, <volume>8</volume>(<issue>1</issue>):<fpage>1218</fpage>.</mixed-citation></ref>
<ref id="c68"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yu</surname>, <given-names>B. M.</given-names></string-name>, <string-name><surname>Cunningham</surname>, <given-names>J. P.</given-names></string-name>, <string-name><surname>Santhanam</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Ryu</surname>, <given-names>S. I.</given-names></string-name>, <string-name><surname>Shenoy</surname>, <given-names>K. V.</given-names></string-name>, and <string-name><surname>Sahani</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2009a</year>). <article-title>Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity</article-title>. <source>Journal of Neurophysiology</source>, <volume>102</volume>(<issue>1</issue>):<fpage>614</fpage>.</mixed-citation></ref>
<ref id="c69"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Yu</surname>, <given-names>B. M.</given-names></string-name>, <string-name><surname>Cunningham</surname>, <given-names>J. P.</given-names></string-name>, <string-name><surname>Santhanam</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Ryu</surname>, <given-names>S. I.</given-names></string-name>, <string-name><surname>Shenoy</surname>, <given-names>K. V.</given-names></string-name>, and <string-name><surname>Sahani</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2009b</year>). <article-title>Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity</article-title>. In <conf-name>Advances in Neural Information Processing Systems</conf-name>, pages <fpage>1881</fpage>–<lpage>1888</lpage>.</mixed-citation></ref>
<ref id="c70"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zemel</surname>, <given-names>R. S.</given-names></string-name>, <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name>, and <string-name><surname>Pouget</surname>, <given-names>A.</given-names></string-name></person-group> (<year>1998</year>). <article-title>Probabilistic interpretation of population codes</article-title>. <source>Neural Comput</source>, <volume>10</volume>(<issue>2</issue>):<fpage>403</fpage>–<lpage>430</lpage>.</mixed-citation></ref>
<ref id="c71"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Ginzburg</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>McNaughton</surname>, <given-names>B.</given-names></string-name>, and <string-name><surname>Sejnowski</surname>, <given-names>T.</given-names></string-name></person-group> (<year>1998</year>). <article-title>Interpreting neuronal population activity by reconstruction: Unified framework with application to hippocampal place cells</article-title>. <source>Journal of Neurophysiology</source>, <volume>79</volume>:<fpage>1017</fpage>–<lpage>1044</lpage>.</mixed-citation></ref>
<ref id="c72"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhang</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Jiménez-Benetó</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Azabou</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Richards</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Tung</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Winter</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Dyer</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Paninski</surname>, <given-names>L.</given-names></string-name>, <etal>et al.</etal></person-group> (<year>2024</year>). <article-title>Towards a” universal translator” for neural dynamics at single-cell, single-spike resolution</article-title>. <source>Advances in Neural Information Processing Systems</source>, <volume>37</volume>:<fpage>80495</fpage>–<lpage>80521</lpage>.</mixed-citation></ref>
<ref id="c73"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Zhao</surname>, <given-names>Y.</given-names></string-name> and <string-name><surname>Park</surname>, <given-names>I. M.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Variational latent gaussian process for recovering single-trial dynamics from population spike trains</article-title>. <source>arXiv</source> <pub-id pub-id-type="arxiv">1604.03053</pub-id>.</mixed-citation></ref>
<ref id="c74"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhao</surname>, <given-names>Y.</given-names></string-name> and <string-name><surname>Park</surname>, <given-names>I. M.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Variational latent gaussian process for recovering single-trial dynamics from population spike trains</article-title>. <source>Neural Computation</source>, <volume>29</volume>(<issue>5</issue>):<fpage>1293</fpage>–<lpage>1316</lpage>.</mixed-citation></ref>
<ref id="c75"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Zhao</surname>, <given-names>Y.</given-names></string-name> and <string-name><surname>Park</surname>, <given-names>I. M.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Variational joint filtering</article-title>. <source>arXiv</source> <pub-id pub-id-type="arxiv">1707.09049</pub-id>.</mixed-citation></ref>
<ref id="c76"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhou</surname>, <given-names>D.</given-names></string-name> and <string-name><surname>Wei</surname>, <given-names>X.-X.</given-names></string-name></person-group> (<year>2020</year>). <article-title>Learning identifiable and interpretable latent models of high-dimensional neural activity using pi-vae</article-title>. <source>Advances in Neural Information Processing Systems</source>, <volume>33</volume>:<fpage>7234</fpage>–<lpage>7247</lpage>.</mixed-citation></ref>
<ref id="c77"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zhu</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Grier</surname>, <given-names>H. A.</given-names></string-name>, <string-name><surname>Tandon</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Cai</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Agarwal</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Giovannucci</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Kaufman</surname>, <given-names>M. T.</given-names></string-name>, and <string-name><surname>Pandarinath</surname>, <given-names>C.</given-names></string-name></person-group> (<year>2022</year>). <article-title>A deep learning framework for inference of single-trial neural population dynamics from calcium imaging with subframe temporal resolution</article-title>. <source>Nature neuroscience</source>, <volume>25</volume>(<issue>12</issue>):<fpage>1724</fpage>–<lpage>1734</lpage>.</mixed-citation></ref>
<ref id="c78"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Zoltowski</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Pillow</surname>, <given-names>J.</given-names></string-name>, and <string-name><surname>Linderman</surname>, <given-names>S.</given-names></string-name></person-group> (<year>2020</year>). <article-title>A general recurrent state space framework for modeling neural dynamics during decision-making</article-title>. In <conf-name>International Conference on Machine Learning</conf-name>, pages <fpage>11680</fpage>–<lpage>11691</lpage>. <publisher-name>PMLR</publisher-name>.</mixed-citation></ref>
<ref id="c79"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Zoltowski</surname>, <given-names>D.</given-names></string-name> and <string-name><surname>Pillow</surname>, <given-names>J. W.</given-names></string-name></person-group> (<year>2018</year>). <chapter-title>Scaling the poisson glm to massive neural datasets through polynomial approximations</chapter-title>. In <person-group person-group-type="editor"><string-name><surname>Bengio</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Wallach</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Larochelle</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Grauman</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Cesa-Bianchi</surname>, <given-names>N.</given-names></string-name>, and <string-name><surname>Garnett</surname>, <given-names>R.</given-names></string-name></person-group>, editors, <source>Advances in Neural Information Processing Systems</source> <volume>31</volume>, pages <fpage>3521</fpage>–<lpage>3531</lpage>. <publisher-name>Curran Associates, Inc</publisher-name>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.109405.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Petkoski</surname>
<given-names>Spase</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/019kqby73</institution-id><institution>Institut de Neurosciences des Systèmes</institution>
</institution-wrap>
<city>Marseille</city>
<country>France</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>valuable</bold> study provides a practical computational framework for inferring latent neural states directly from calcium fluorescence recordings, bypassing the traditional need for a separate spike deconvolution step. The evidence supporting the method is <bold>solid</bold>, featuring rigorous validation across multiple latent variable model families (including HMM, GPFA, and LFADS) using both simulated and experimental data. However, the assessment of the method's generality would be further strengthened by application to a broader range of experimental datasets, such as recordings from different brain regions or using different calcium indicators.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.109405.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>In this study, the authors elegantly combined latent variable models (i.e., HMM, GPFA and dynamical system models) with a calcium imaging observation model (i.e., latent Poisson spiking and autoregressive calcium dynamics (AR)).</p>
<p>Strengths:</p>
<p>Integrating a calcium observation model into existing latent variable models improves significantly the inference of latent neural states compared to existing approaches such as spike deconvolution or Gaussian assumptions.</p>
<p>
The authors also provide an open-source access to their method for direct application to calcium imaging data analysis.</p>
<p>Weaknesses:</p>
<p>As acknowledged by the authors, their method is dependent on the quality of calcium trace extraction from fluorescence videos. It should be noted that this limitation applies to alternative strategies.</p>
<p>While the contribution of this study should prove useful for researchers using calcium imaging, the novelty is limited, as it consists of an integration of the calcium imaging model from Ganmor et al. 2016 with existing LVM frameworks.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.109405.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This compelling study proposes a framework to implement latent variable models using population level calcium imaging data. The study incorporates autoregressive dynamics and latent Poisson spiking to improve inference of latent states across different model classes including HMMs, Gaussian Process Factor Analysis and nonlinear dynamical systems models. This approach allows for a more seamless integration of existing methods typically used with spiking data to apply on calcium imaging data. The authors test the model on piriform cortex recordings as well as a biophysical simulator to validate their methods. This approach promises to have wide usability for neuroscientists using large population level calcium imaging.</p>
<p>Strengths:</p>
<p>The strengths of this study are the flexibility in the choice of models and relatively easy adaptation to user-specific use cases.</p>
<p>Weaknesses:</p>
<p>The weakness of the study lies in its limited validation of biological calcium imaging data. Calcium dynamics in a task-specific context in a sensory brain region might be very different from slower dynamics in a region of integration. The biophysical properties of the data would also be dependent on the SNR of the imaging platform and the generation of calcium indicator being used.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.109405.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>S. Keeley &amp; collaborators propose a computational approach to infer time-varying latent variables directly from calcium traces (for instance, obtained with 2p imaging) without the need for deconvolving the traces into spike trains in a preliminary, independent step. Their approach rests on 1 of 3 families of latent models: GPFA, HMM and dynamical systems - which they augment with an observation model that maps latent variables to fluorescence traces. They validate their approach on simulated and real data, showing that the approach improves latent variable inference and model fitting, compared to more traditional approaches (although not directly compared with the 2-step one; see below). They provide a GitHub repository with code to fit their models (which I have not tested).</p>
<p>Strengths:</p>
<p>The approach is sound and well-motivated. The authors are specialists in latent variable models. The manuscript is succinct, well-written, and the figures are clear. I particularly liked the diversity of latent models considered, in particular latent models with continuous (GPFA) vs. discrete (HMM) dynamics, which are useful for characterizing different types of neural computations. The validation on both simulated and real data is convincing.</p>
<p>Weaknesses:</p>
<p>The main weakness that I see is that the approach is tested only on a single real dataset (odor response dataset). The other model fits are obtained from simulated data. While the results are convincing, it would be useful to see the approach tested on other datasets, for instance, datasets with different brain areas, different behavioral conditions, or different calcium indicators. This would help assess the generality of the approach and its robustness to different experimental conditions.</p>
<p>The other points below mostly pertain to clarifications and possible extensions of the approach, and to simple model recovery experiments that would help quantify the advantage of the proposed approach over more traditional ones.</p>
<p>I have a question related to interpretability and diagnosis of model fits. One advantage of the two-step approach: (1) deconvolution =&gt; (2) latent variance inference, is that one can inspect the quality of the deconvolution step independently from the latent variable inference step. In the proposed approach, it seems more difficult to diagnose potential problems with model fitting. For instance, if the inferred latent variables are not interpretable, how can one determine whether this is due to a poor choice of latent model (e.g., HMM with too few states), or a poor fit of the observation model (e.g., wrong parameters for the calcium dynamics)? Are there any diagnostic tools that could help identify potential problems with model fitting?</p>
<p>Could the authors comment on whether their approach allows for instance to compare different forms of latent models (e.g., HMM vs. GPFA) in terms of model evidence, cross-validated log-likelihood or other model comparison metrics? This would be useful to quantitatively determine which type of latent dynamics is more appropriate for a given dataset.</p>
<p>The HMM part reveals a pretty large number of states, with one state being interpretable (evoked response). Shouldn't we expect a simpler scenario, with 2 states? I know this is a difficult question that is more general and common with HMM approaches, but it would be useful to discuss this point. For instance, would a hierarchical HMM (with a smaller number of &quot;super-states&quot;) be more appropriate here?</p>
<p>While it certainly makes sense that models accounting for the full transformation of latent =&gt; spikes =&gt; fluorescence data should outperform the two-step (1) deconvolution =&gt; (2) latent variance inference approach, the amount of improvement is not clear. A direct comparison (e.g., w/ parameter &amp; model recovery metrics) between the two approaches on simulated data would be useful to quantify the advantage of the proposed approach over more traditional ones.</p>
<p>It would be useful to discuss the possible extension of the approach to other types of data that are related to neural activity but have different observation models, e.g., voltage imaging, or neuromodulator sensors (e.g., GRAB-NE, dLight, etc). Do the authors see any specific challenges that would arise in these cases and that would need to be addressed in the future (other than changing the Poisson spiking part)?</p>
</body>
</sub-article>
</article>