<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">91769</article-id>
<article-id pub-id-type="doi">10.7554/eLife.91769</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.91769.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Auditory cortical error signals retune during songbird courtship</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5894-0239</contrib-id>
<name>
<surname>Jones</surname>
<given-names>Caleb</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0422-8902</contrib-id>
<name>
<surname>Goldberg</surname>
<given-names>Jesse H.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Neurobiology and Behavior, Cornell University</institution>, Ithaca, NY 14853, <country>USA</country></aff>
<aff id="a2"><label>2</label><institution>Department of Biomedical Engineering, Cornell University</institution>, Ithaca, NY 14853, <country>USA</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>King</surname>
<given-names>Andrew J</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Oxford</institution>
</institution-wrap>
<city>Oxford</city>
<country>United Kingdom</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>King</surname>
<given-names>Andrew J</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Oxford</institution>
</institution-wrap>
<city>Oxford</city>
<country>United Kingdom</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>Corresponding Author <email>jessehgoldberg@gmail.com</email></corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2023-11-01">
<day>01</day>
<month>11</month>
<year>2023</year>
</pub-date>
<volume>12</volume>
<elocation-id>RP91769</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-08-22">
<day>22</day>
<month>08</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-08-08">
<day>08</day>
<month>08</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.08.08.552485"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2023, Jones &amp; Goldberg</copyright-statement>
<copyright-year>2023</copyright-year>
<copyright-holder>Jones &amp; Goldberg</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-91769-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Auditory feedback is important for vocal learning and control, but it remains unclear how the presence of an audience affects neural representations of self-produced sounds. Here we recorded neural activity in a primary auditory cortical area, Field L, in zebra finches practicing singing alone and directing courtship songs to females. We first discovered that many Field L neurons changed their singing-related discharge patterns during courtship singing, even though the auditory feedback from the bird’s own song was similar. We next used syllable-targeted distorted auditory feedback (DAF) to test how auditory error signals depend on courtship context. Though past work showed that dopamine neurons uniformly reduce error signaling during courtship, Field L neurons exhibited heterogeneous error signal re-tuning in the presence of the female. Thus, single neurons in a primary sensory area process feedback from self-produced actions differently during practice and performance.</p>
</abstract>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Motivational drive affects attention and associated sensory responses to external events (<xref ref-type="bibr" rid="c3">Allen et al., 2019</xref>; <xref ref-type="bibr" rid="c6">Aton, 2013</xref>; <xref ref-type="bibr" rid="c26">Hindmarsh Sten et al., 2021</xref>)). Hungry or thirsty animals are more alert to food or water cues, which evoke larger brainwide neural responses (<xref ref-type="bibr" rid="c3">Allen et al., 2019</xref>; <xref ref-type="bibr" rid="c9">Burgess et al., 2018</xref>). Courtship also influences behavioral and neural responses to sensory events (<xref ref-type="bibr" rid="c48">Sakata and Brainard, 2009</xref>, <xref ref-type="bibr" rid="c49">2008</xref>; <xref ref-type="bibr" rid="c54">Skals et al., 2005</xref>; <xref ref-type="bibr" rid="c63">Zhang et al., 2018</xref>), but it remains unclear how representations of self-produced behaviors change with the presence of an audience during courtship. Here we recorded auditory cortical neurons in birds singing alone and to females to test how auditory feedback signals depend on courtship-associated changes in motivational state.</p>
<p>Adult male zebra finches practice undirected song alone and also direct courtship song to females (<xref ref-type="bibr" rid="c31">Kao et al., 2008</xref>; <xref ref-type="bibr" rid="c62">Zann, 1996</xref>). Both undirected and directed songs combine introductory notes, calls, and a stereotyped sequence of phonologically distinct syllables called motifs (<xref ref-type="bibr" rid="c30">Hyland Bruno and Tchernichovski, 2019</xref>; <xref ref-type="bibr" rid="c43">Rajan and Doupe, 2013</xref>). The acoustic structure of undirected and directed motifs is highly similar in adult finches, enabling singing-related neural activity to be precisely aligned and compared across contexts (<xref ref-type="bibr" rid="c31">Kao et al., 2008</xref>; <xref ref-type="bibr" rid="c58">Woolley et al., 2014</xref>; <xref ref-type="bibr" rid="c62">Zann, 1996</xref>). A first goal of this study was to examine motif-aligned discharge in auditory cortical neurons to test if neural representations depend on courtship state.</p>
<p>A second goal was to test how perceived song errors are represented across performance modes. In past work, perceived errors during undirected singing were experimentally controlled with syllable-targeted distorted auditory feedback (DAF) (<xref ref-type="bibr" rid="c4">Andalman and Fee, 2009</xref>; <xref ref-type="bibr" rid="c55">Tumer and Brainard, 2007</xref>). Though DAF does not capture all aspects of natural song learning, it brings song evaluation under experimental control (<xref ref-type="bibr" rid="c2">Ali et al., 2013</xref>; <xref ref-type="bibr" rid="c10">Canopoli et al., 2014</xref>; <xref ref-type="bibr" rid="c28">Hoffmann et al., 2016</xref>). Birds learn to change the way they sing a syllable to avoid DAF, and several studies support a reinforcement learning framework. First, a dopaminergic (DA) projection from the ventral tegmental area (VTA) to Area X, the striatal nucleus of the song system, is necessary for both natural and DAF-based learning (<xref ref-type="bibr" rid="c17">Duffy et al., 2022</xref>; <xref ref-type="bibr" rid="c21">Gadagkar et al., 2016</xref>; <xref ref-type="bibr" rid="c27">Hisey et al., 2018</xref>; <xref ref-type="bibr" rid="c28">Hoffmann et al., 2016</xref>; <xref ref-type="bibr" rid="c59">Xiao et al., 2018a</xref>; <xref ref-type="bibr" rid="c2">Ali et al., 2013</xref>; <xref ref-type="bibr" rid="c25">Harding, 2004</xref>; <xref ref-type="bibr" rid="c51">Scharff and Nottebohm, 1991</xref>). Second, Area X projecting DA neurons exhibit reward-prediction error (RPE)-like signals during singing: phasic activations following undistorted renditions and suppressions following distorted ones (<xref ref-type="bibr" rid="c21">Gadagkar et al., 2016</xref>). Third, photoactivation or suppression of DA release in Area X can reinforce or suppress syllable variations (<xref ref-type="bibr" rid="c27">Hisey et al., 2018</xref>; <xref ref-type="bibr" rid="c59">Xiao et al., 2018a</xref>). The role of RPE-like DA signals in evaluating both reward and song outcomes suggest common principles for birdsong learning and more classic reinforcement learning commonly studied in hungry or thirsty mammals (<xref ref-type="bibr" rid="c13">Chen and Goldberg, 2020</xref>).</p>
<p>Recently we discovered that DA signals retune during courtship. Specifically, DAF-associated DA signals known to evaluate undirected song are uniformly reduced during female-directed singing - as if a bird does not attend to his own mistakes (<xref ref-type="bibr" rid="c47">Roeser et al., 2023</xref>). This discovery raises two possibilities. First, DA error signals might be retuned at the level of VTA, for example by behavioral state-dependent modulation of intrinsic or synaptic excitability of VTA DA neurons (<xref ref-type="bibr" rid="c60">Xiao et al., 2018b</xref>). If this is the case, then error responses in upstream inputs to VTA could exhibit similar tuning to auditory feedback during directed and undirected song, but their influence on DA spiking is altered. Another possibility is that brainwide responses to auditory feedback differ when alone versus when courting a female, analogous to how motivational drives such as thirst or hunger retune widespread neural responses to water or food cues (<xref ref-type="bibr" rid="c3">Allen et al., 2019</xref>; <xref ref-type="bibr" rid="c9">Burgess et al., 2018</xref>), or how auditory cortical signaling is affected by attention (<xref ref-type="bibr" rid="c1">Ahissar et al., 1992</xref>; <xref ref-type="bibr" rid="c29">Hubel et al., 1959</xref>). This idea predicts that auditory representations even in a primary cortical area would change with possible attentional and motivational changes associated with a transition from singing alone to singing to a potential mate.</p>
<p>To test these possibilities we recorded single neuronal activity in Field L in birds singing alone and to females. Field L is a primary auditory cortical area situated at the bottom of a cortical hierarchy that projects into multiple higher auditory areas that, in turn, project to VTA (<xref ref-type="bibr" rid="c8">Bottjer et al., 2000</xref>; <xref ref-type="bibr" rid="c19">Foster and Bottjer, 1998</xref>; <xref ref-type="bibr" rid="c36">Mandelblat-Cerf et al., 2014</xref>; <xref ref-type="bibr" rid="c40">Moore and Woolley, 2019</xref>). Here we report that auditory responses to both bird’s own song and DAF-induced errors changed in heterogeneous ways at the transition from undirected to courtship directed singing. Thus a bird’s auditory representations of its own song vary across practice and courtship performance modes. Together with past work showing a re-tuning of premotor signals during courtship (<xref ref-type="bibr" rid="c31">Kao et al., 2008</xref>; <xref ref-type="bibr" rid="c53">Singh Alvarado et al., 2021</xref>; <xref ref-type="bibr" rid="c58">Woolley et al., 2014</xref>), our discovery that a sensory area retunes is consistent with brainwide changes in neural responsiveness during courtship.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Singing-related discharge in Field L is altered during courtship</title>
<p>Because we were interested in how Field L activity changed during female directed song, we recorded at least 20 song motifs during undirected singing and then presented females to elicit courtship song (n=161 neurons, n=11 birds, Methods). Consistent with past work (<xref ref-type="bibr" rid="c33">Keller and Hahnloser, 2009</xref>), we observed heterogeneous singing-related firing in Field L neurons, ranging from highly temporally precise to variable discharge across motif renditions (<xref rid="fig1" ref-type="fig">Figure 1A-C</xref>). To compare neural responses between undirected and directed singing, we focused on motif-aligned activity to compare acoustically similar vocalizations in the undirected and directed states (<xref rid="fig1" ref-type="fig">Figure 1A-F</xref>). For each neuron, we analyzed mean firing rates, burst fraction, and the temporal precision of motif-locked discharge depended on courtship state, using analyses previously described (Methods)(<xref ref-type="bibr" rid="c31">Kao et al., 2008</xref>; <xref ref-type="bibr" rid="c48">Sakata and Brainard, 2009</xref>; <xref ref-type="bibr" rid="c58">Woolley et al., 2014</xref>). Burst fraction was computed as the fraction of spikes occurring in burst events, defined as three (or more) spikes with two (or more) consecutive interspike intervals less than the 25th percentile of the ISI distribution (Methods). The temporal precision of neuronal song locked firing was computed as the intermotif correlation coefficient (IMCC, Methods) (<xref ref-type="bibr" rid="c23">Goldberg and Fee, 2010</xref>; <xref ref-type="bibr" rid="c41">Olveczky et al., 2005</xref>;<xref ref-type="bibr" rid="c31">Kao et al., 2008</xref>; <xref ref-type="bibr" rid="c48">Sakata and Brainard, 2009</xref>; <xref ref-type="bibr" rid="c58">Woolley et al., 2014</xref>).</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Singing related discharge can retune during courtship.</title>
<p>(A-C) Three example neurons with stable firing properties across alone and female-directed song conditions. Top to bottom: single trial example spectrograms, spike discharge, corresponding spike raster plots, and rate histograms (aligned to motif onset) from motif renditions singing alone (black) and to the female (green). Black vertical scale bar for spiking activity is 0.2 mV, y-axis limits of spectrograms are 0 to 8 kHz. (D-F) Data plotted as in A-C for three example neurons with significant context-dependent changes in firing. (H-J) Scatter plots of mean firing rates (H), IMCC values (I) and neuronal burst fraction (J) for 161 neurons when singing alone and to the female. Red: neurons with significant change across conditions (p&lt;0.01, Methods).</p></caption>
<graphic xlink:href="552485v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>At the population level, neither the temporal precision nor mean firing rate of neurons changed with courtship (<xref rid="fig1" ref-type="fig">Figure 1H-I</xref>). A small but significant increase in burst fraction was observed (paired t-test, p=1.16✕10<sup>−4</sup>, n=161 neurons, <xref rid="fig1" ref-type="fig">Figure 1J</xref>). Thus, Field L neurons did not uniformly change their singing-related firing patterns at the transition to courtship singing. But individual neurons could exhibit significant changes in discharge with changes in courtship state, including increases or decreases in their average motif-locked firing rate (n=24 increase; n=22 decrease, p&lt;0.01), burst fraction (n=21 increase; n=3 decrease, p&lt;0.01), or precision of timing within the motif (n=11 increase; n=6 decrease, p&lt;0.01) (<xref rid="fig1" ref-type="fig">Figure 1D-F</xref>, p values derived from Monte Carlo shuffles by condition, Methods).</p>
</sec>
<sec id="s2b">
<title>Singing-related performance error signals can retune during courtship</title>
<p>Past work showed that Field L neurons can exhibit responses to distorted auditory feedback (DAF) during undirected singing (<xref ref-type="bibr" rid="c33">Keller and Hahnloser, 2009</xref>). To test if error responses exist and/or retune during courtship, we recorded Field L neurons during lone and directed singing as we controlled perceived song quality with syllable-targeted DAF (<xref ref-type="bibr" rid="c4">Andalman and Fee, 2009</xref>; <xref ref-type="bibr" rid="c55">Tumer and Brainard, 2007</xref>). For each bird, a specific syllable was probabilistically targeted with a 50 ms song-like sound played through speakers surrounding the bird (Methods) (<xref ref-type="bibr" rid="c14">Chen et al., 2019</xref>; <xref ref-type="bibr" rid="c21">Gadagkar et al., 2016</xref>; <xref ref-type="bibr" rid="c24">Hamaguchi et al., 2014</xref>). To quantify error responses across the population of neurons and across conditions, we compared the activity between randomly interleaved renditions of distorted and undistorted songs. For each neuron and for each behavioral condition (alone or directed), we first performed the same analysis as in a previous Field L recording study during undirected singing (<xref ref-type="bibr" rid="c33">Keller and Hahnloser, 2009</xref>) (Methods). This analysis identified 58/161 neurons as error responsive in undirected song, and 55/161 during directed singing, and 33/161 exhibiting error responses during both conditions. Visual inspection of error responses in motif-aligned rasters revealed that while some of these neurons unambiguously exhibited robust DAF responses (<xref rid="fig2" ref-type="fig">Figure 2D</xref>), many exhibited extremely subtle ones (<xref rid="fig2S2" ref-type="fig">Figure 2–figure supplement 2A-B</xref>).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Error responses in Field L neurons can retune during courtship.</title>
<p>(A-C) Three example neurons with different error responses across courtship conditions. Top to bottom: single trial example spectrograms and spiking activity for undistorted and distorted trials, corresponding raster plots (blue vertical bar denotes feedback target time in undistorted renditions; red shading denotes actual feedback time on distorted renditions; pink vertical dotted line denotes onset and offset of song motif). Corresponding rate histograms for undistorted renditions (blue trace) and distorted renditions (red trace). Below are the same plots, but for songs directed to the female. Bottom: z-scored difference between undistorted and distorted rate histograms for singing alone (black trace) and singing to female (green trace). All data are time-aligned to the onset of the motif. (D-F) Data plotted as in A-C for three neurons with similar error responses across courtship conditions. Error scores for each neuron and condition are enumerated as insets in the histogram. Scale bar for spiking activity is 0.2 mV. Vertical axis limits for spectrograms are 0 to 8 kHz.</p></caption>
<graphic xlink:href="552485v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Statistical tests defining Field L neurons as error-responsive or not in a binary fashion may not be suitable if the underlying population of error responses exist on a continuum from error non-responsive to responsive. To score each neuron’s error response and identify the shape of the error response distributions across the population of neurons, we computed the z-scored difference between target onset–aligned distorted and undistorted rate histograms (target onset defined as the median DAF onset time relative to distorted syllable onset, n = 161 neurons in 12 birds), as previously described (<xref ref-type="bibr" rid="c21">Gadagkar et al., 2016</xref>). We defined the error response as the average z-scored difference in firing between undistorted and distorted renditions during the 100 ms interval following target onset (Methods). In past recordings from VTA, this analysis yielded a bimodal distribution of z-scored error responses which made classification of error-responsive neurons straightforward. Yet when we plotted the distribution of error responses across the 161 Field L neurons recorded during both undirected and directed singing, we observed unimodal distributions consistent with a continuum of Field L responses (<xref rid="fig2S1" ref-type="fig">Figure 2–figure supplement 1</xref>). This analysis suggests that no true threshold exists to unambiguously define a neuron as an error neuron. To visualize a distribution of error scores for parts of the song that were never targeted with DAF, we repeated the same analysis for a time window of the motif preceding the target time (i.e. when the auditory feedback was undistorted across all trials). As expected, we observed significantly lower error scores (<xref rid="fig2S1" ref-type="fig">Figure 2–figure supplement 1</xref>, p&lt;10<sup>−10</sup>, Wilcoxon signed-rank test, Methods). For the purposes of examining courtship-state dependent re-tuning of error signals we conservatively defined ‘error neurons’ as those with an absolute z-scored difference in firing rate between distorted and undistorted renditions greater than 2.5 in either the directed or undirected conditions (Methods).</p>
<p>To test if courtship state affected these most robust error responses in our dataset, for each error neuron we compared the z-scored error response across undirected and directed singing. Interestingly, though VTAx DA neurons uniformly decreased their error response during courtship singing (<xref ref-type="bibr" rid="c47">Roeser et al., 2023</xref>), Field L neurons exhibited heterogenous re-tuning: some neurons exhibited error responses only when singing to the female (n=22), others exhibited error signal attenuation during female-directed song (n=11), while others were not significantly affected by courtship state (n=10, <xref rid="fig2" ref-type="fig">Figure 2</xref>). Together, these data show that Field L responses to distorted auditory feedback during singing can retune during courtship.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>By recording from the primary auditory cortex in zebra finches singing alone and to females, we discovered, for the first time to our knowledge, that auditory representations of an animal’s own vocalizations change with an audience. These findings extend past work in finches showing that social context affects auditory responses to the calls of conspecifics (<xref ref-type="bibr" rid="c5">Angeloni and Geffen, 2018</xref>; <xref ref-type="bibr" rid="c38">Menardy et al., 2014</xref>, <xref ref-type="bibr" rid="c39">2012</xref>; <xref ref-type="bibr" rid="c44">Remage-Healey et al., 2010</xref>)). More broadly, these findings support the idea that auditory cortical activity is modulated not just by acoustic features (<xref ref-type="bibr" rid="c22">Gervain and Geffen, 2019</xref>; <xref ref-type="bibr" rid="c35">King et al., 2018</xref>) but also diverse phenomena such as attention (<xref ref-type="bibr" rid="c29">Hubel et al., 1959</xref>), primary rewards (<xref ref-type="bibr" rid="c15">David et al., 2012</xref>), task parameters (<xref ref-type="bibr" rid="c16">Downer et al., 2015</xref>; <xref ref-type="bibr" rid="c20">Fritz et al., 2003</xref>); (<xref ref-type="bibr" rid="c5">Angeloni and Geffen, 2018</xref>; <xref ref-type="bibr" rid="c38">Menardy et al., 2014</xref>, <xref ref-type="bibr" rid="c39">2012</xref>; <xref ref-type="bibr" rid="c44">Remage-Healey et al., 2010</xref>), and even hormone levels (<xref ref-type="bibr" rid="c5">Angeloni and Geffen, 2018</xref>; <xref ref-type="bibr" rid="c38">Menardy et al., 2014</xref>, <xref ref-type="bibr" rid="c39">2012</xref>; <xref ref-type="bibr" rid="c44">Remage-Healey et al., 2010</xref>).</p>
<p>Detecting differences between predicted and actual sensory feedback is a crucial aspect of motor learning (<xref ref-type="bibr" rid="c34">Keller and Mrsic-Flogel, 2018</xref>), and auditory cortical neurons in diverse species can signal mismatch errors (<xref ref-type="bibr" rid="c18">Eliades and Wang, 2008</xref>; <xref ref-type="bibr" rid="c33">Keller and Hahnloser, 2009</xref>; <xref ref-type="bibr" rid="c42">Parras et al., 2021</xref>; <xref ref-type="bibr" rid="c56">Ulanovsky et al., 2003</xref>). In past recordings from VTA we observed a bimodal distribution of error responses, and the error-responding neurons were the ones that projected to Area X (<xref ref-type="bibr" rid="c21">Gadagkar et al., 2016</xref>). Yet in cortex there is uncertainty about the suitability of classifying single neurons by response profile, as task-relevant parameters that can be decoded from neuronal populations may not be apparent when examining single neuronal representations (<xref ref-type="bibr" rid="c32">Kaufman et al., 2014</xref>; <xref ref-type="bibr" rid="c37">Mante et al., 2013</xref>; <xref ref-type="bibr" rid="c45">Rigotti et al., 2013</xref>; <xref ref-type="bibr" rid="c57">Williams et al., 2018</xref>). We observed a continuum of error responses during both directed and undirected singing which made it difficult to unambiguously define a neuron as being error responsive or not.</p>
<p>Because the main goal of this study was to test if courtship-associated reduction in error signaling, recently observed in VTA DA neurons (<xref ref-type="bibr" rid="c47">Roeser et al., 2023</xref>), resulted from a local process in VTA or reflected a brainwide re-tuning of auditory responsiveness, we imposed an arbitrary threshold of 2.5 in the z-scored error response to test if the most robust error signals in Field L depended on courtship state. Surprisingly, we discovered that Field L neurons could retune at the transition from lone to courtship singing in diverse ways, consistent with a brainwide process that does not fully explain the uniform error signal attenuation observed in VTA. Interestingly, Area X and LMAN neurons uniformly increase their temporal precision and reduce their burstiness during courtship singing (<xref ref-type="bibr" rid="c31">Kao et al., 2008</xref>; <xref ref-type="bibr" rid="c47">Roeser et al., 2023</xref>; <xref ref-type="bibr" rid="c49">Sakata and Brainard, 2008</xref>; <xref ref-type="bibr" rid="c53">Singh Alvarado et al., 2021</xref>; <xref ref-type="bibr" rid="c58">Woolley et al., 2014</xref>). In contrast, Field L neurons could exhibit increases or decreases in burstiness, temporal precision, or mean rate with courtship.</p>
<p>An open question is how Field L receives information about whether or not a female is present, and how this information influences neural activity. Several neuromodulatory systems with possible information about courtship state project to songbird auditory forebrain, including acetylcholine (<xref ref-type="bibr" rid="c52">Shea and Margoliash, 2010</xref>), serotonin (<xref ref-type="bibr" rid="c61">Yip et al., 2020</xref>), and norepinephrine (<xref ref-type="bibr" rid="c11">Cardin and Schmidt, 2004</xref>). Estrogens can also rapidly modulate auditory firing (<xref ref-type="bibr" rid="c44">Remage-Healey et al., 2010</xref>; <xref ref-type="bibr" rid="c50">Scarpa et al., 2022</xref>). Yet how the courtship state may be orchestrated across multiple brain regions remains unclear. One possibility is that hypothalamic nuclei such as the medial preoptic nucleus (MPOA) initiate the courtship state. The MPOA projects to multiple brainstem neuromodulatory areas which in turn project broadly throughout the forebrain, including the song system and auditory system (<xref ref-type="bibr" rid="c46">Riters and Alger, 2004</xref>)(<xref ref-type="bibr" rid="c7">Ben-Tov et al., 2023</xref>; <xref ref-type="bibr" rid="c12">Castelino and Ball, 2005</xref>; <xref ref-type="bibr" rid="c53">Singh Alvarado et al., 2021</xref>). It will be interesting in future studies to examine the neural signals propagating through these pathways at transitions into and out of the courtship state.</p>
</sec>
</body>
<back>
<sec id="s4">
<title>Materials and Methods</title>
<sec id="s4a">
<title>Subjects</title>
<p>Sixteen adult male zebra finches (&gt;90 days post hatch) were the subjects of this study. Animal care and experiments were carried out in accordance with NIH guidelines and were approved by the Cornell Institutional Animal Care and Use Committee.</p>
</sec>
<sec id="s4b">
<title>Surgery and awake-behaving electrophysiology</title>
<p>For chronic neural recordings, subjects were anesthetized with isoflurane inhalation and mounted on a stereotaxic instrument for probe implantation. All probes were 16-channel moveable electrode bundles (Innovative Neurophysiology). Probes were implanted 1.5-2.0 mm anterior and 1.5-2.0 mm lateral of the bifurcation of the mid-sagittal sinus to target Field L (<xref ref-type="bibr" rid="c33">Keller &amp; Hahnloser 2009</xref>) at a head angle of 80 degrees (measured as the angle from the tip of the beak to the center of the ear bars relative to the horizontal plane). The end of the cannula was implanted 1.5 mm ventral to the surface of the brain. Birds were then placed alone in a sound isolation chamber (12 hour light/dark cycle) with ad libitum food and water and allowed 1 day to recover post op before being subjected to the distorted auditory feedback (DAF) protocol. 2-3 days were allotted for habituation to DAF and to ensure the bird began to spontaneously sing a sufficient number of motifs in social isolation before neural recordings. DAF was implemented with a custom LabView acquisition program that analyzed song syllables in real-time and delivered syllable-targeted feedback. DAF (50 ms broadband noise bandpass filtered at 1.5-8 kHz to match frequency range of zebra finch song) was played over speakers in the recording chamber on top of a specific target syllable randomly on 50% of motif renditions. Experiments were carried out in the male’s home cage, which was inside a sound isolation chamber. When the homecage lights came on each day, recording began and the male was left alone to sing at least 40 undirected song motifs. Female directed motifs were then recorded by presenting a female in the chamber in ∼10 minute intervals throughout the day until at least 40 directed song motifs were elicited (ref andreas paper). Electrode placement was verified at the end of the experiment with small electrolytic lesions, histology, and dark field imaging. 11 of the 16 implanted birds yielded single unit recordings and sang sufficient motifs for the experiment. Many channels on the probes recorded multi-unit activity, which were taken note of but not analyzed in this study.</p>
</sec>
<sec id="s4c">
<title>Neural Recording and Analysis</title>
<p>Neural signals were acquired with the Intan RHD recording controller and 16-channel Intan headstages that directly interfaced with the moveable bundles. Sampling rate was set to 20kHz and recording was manually controlled with the Intan recording software, where a 60 Hz notch filter was applied and spiking activity of single units could be visualized in real time. Audio data and a real-time digital copy of the DAF signal were simultaneously recorded with neural data in the recording controller such that all data could be easily time aligned. A custom MATLAB GUI was used for visualizing song and neural data, and for spike sorting. Neural recordings were bandpass filtered between 0.4 kHz and 6-8 kHz and single unit spiking activity was manually sorted as previously described (<xref ref-type="bibr" rid="c23">Goldberg and Fee, 2010</xref>). Motif aligned spiking activity was time-warped to the median duration of undirected or directed motifs. Firing rate (FR) histograms were computed by binning spiking events in 10 ms windows and smoothing with a 3-bin moving average. To calculate the significance of the FR changes across behavioral contexts, we randomly assigned spike trains from each song motif trial as undirected or directed groups while conserving trial numbers, then calculated FR values for the randomized dataset, as previously described (<xref ref-type="bibr" rid="c23">Goldberg and Fee, 2010</xref>). This shuffling without replacement was repeated 10,000 times for each neuron, yielding 10,000 new changes in FR values. Measured changes in firing rate that were greater than the 99th percentile of the shuffled distribution were considered significant, as in previous studies (<xref ref-type="bibr" rid="c49">Sakata and Brainard, 2008</xref>). This procedure was repeated for IMCC and burst fraction. A p value less than 0.01 was considered significant to account for multiple comparisons. To quantify the degree to which neuronal firing was time-locked to song, the intermotif correlation coefficient (IMCC) was calculated as described previously (<xref ref-type="bibr" rid="c14">Chen et al., 2019</xref>; <xref ref-type="bibr" rid="c31">Kao et al., 2008</xref>; <xref ref-type="bibr" rid="c41">Olveczky et al., 2005</xref>). To compute IMCC, motif-aligned FR was mean-subtracted and smoothed with a Gaussian kernel of 20 ms SD, resulting in a rate vector, <italic><bold>r</bold></italic><sub><italic>i</italic></sub>, for each motif. IMCC was defined as the mean of all pairwise correlation coefficients between <italic><bold>r</bold></italic><sub><italic>i</italic></sub> as follows:
<disp-formula id="ueqn1">
<alternatives><graphic xlink:href="552485v1_ueqn1.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
We defined bursts as events containing three or more spikes with consecutive interspike intervals less than the 25th percentile of the 25th percentile of the interspike interval distributions during singing. Burst fraction was calculated as the fraction of spikes during song motifs that occurred during bursts.</p>
<p>We quantified the error responsiveness for each neuron in two ways, following approaches previously described (<xref ref-type="bibr" rid="c14">Chen et al., 2019</xref>; <xref ref-type="bibr" rid="c21">Gadagkar et al., 2016</xref>; <xref ref-type="bibr" rid="c33">Keller and Hahnloser, 2009</xref>). Spike counts in 30 ms time windows shifted in 5 ms steps up to 50 ms after DAF offset were generated for undistorted and distorted trials. A WRS test assessed the significance of each 30 ms window, and only neurons with 2 or more consecutively significant windows were considered a significant error response. Neurons with two or more subsequent windows with P&lt;0.05 were considered significant. (<xref ref-type="bibr" rid="c33">Keller and Hahnloser, 2009</xref>). We also calculated the z-scored difference between smoothed firing rates in undistorted and distorted trials for the time window 100 ms after feedback onset, and defined the error score as the average z-scored difference across the three bins centered around the absolute maximum difference during the response window. To test if error responses were attributable to DAF, we compared absolute error score distributions derived from the same analysis in the 100 ms window preceding target onset in the motif and therefore not associated with DAF. The pre-DAF error score distribution was significantly less in both conditions: a paired Wilcoxon signed-rank test indicated significantly lower error scores pre-DAF than post-DAF during undirected song (p&lt;0.001, median pre-DAF: 0.82, median post-DAF:1.39) and directed song (p&lt;0.001, median pre-DAF: 0.81, median post-DAF: 1.41). 3.4% of pre-DAF and 16.5% of post-DAF error scores were greater than 2.5. Given the continuum of post-DAF error scores in both directed and undirected conditions (<xref rid="fig2" ref-type="fig">Figure 2–figure supplement 1</xref>), we conservatively chose a threshold of 2.5 to define an error response. Neurons with error responses greater than 2.5 in only one condition (undirected versus directed) were considered to have retuned; neurons with error scores greater than 2.5 in both conditions were considered not to have retuned. Our results did not fundamentally change with an even more strict definition for an error response. With a more stringent threshold of 3, 12 neurons exhibit error response only when singing to the female, and 8 neurons exhibit error signal attenuation during female-directed song, and 6 neurons exhibit a stable error response across conditions.</p>
</sec>
</sec>
<sec id="s5">
<title>Figure Legends</title>
<fig id="fig2S1" position="float" fig-type="figure">
<label>Figure S1–figure supplement 1.</label>
<caption><title>Distributions of absolute error responses in Field L neurons</title>
<p>Scatter plot where each dot represents the absolute z-scored error response of a single neuron during the 100 ms interval after the onset of DAF (blue) and 100 ms before DAF onset (orange) (Methods). Corresponding histograms for each condition are projected along the x and y axes. Gray dotted lines indicate the 2.5 cutoff threshold used to define error neurons.</p></caption>
<graphic xlink:href="552485v1_fig2S1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="fig2S2" position="float" fig-type="figure">
<label>Figure S2–figure supplement 2.</label>
<caption><title>Neurons exemplifying a broad range of error responses in Field L.</title>
<p>(A-C) Top to bottom: example spectrograms, spike discharge, corresponding spike raster plots, and rate histograms for undistorted (blue) and distorted (red) trials aligned to motif onset (blue vertical bar denotes feedback target time in undistorted renditions; red shading denotes DAF; pink vertical dotted line denotes onset and offset of song motif). Error scores for each neuron and condition are enumerated as insets in the histogram. Scale bar for spiking activity is 0.2 mV. Vertical axis limits for spectrograms are 0 to 8 kHz.</p></caption>
<graphic xlink:href="552485v1_fig2S2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Ahissar</surname> <given-names>E</given-names></string-name>, <string-name><surname>Vaadia</surname> <given-names>E</given-names></string-name>, <string-name><surname>Ahissar</surname> <given-names>M</given-names></string-name>, <string-name><surname>Bergman</surname> <given-names>H</given-names></string-name>, <string-name><surname>Arieli</surname> <given-names>A</given-names></string-name>, <string-name><surname>Abeles</surname> <given-names>M.</given-names></string-name> <year>1992</year>. <article-title>Dependence of cortical plasticity on correlated activity of single neurons and on behavioral context</article-title>. <source>Science</source> <volume>257</volume>:<fpage>1412</fpage>–<lpage>1415</lpage>.</mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Ali</surname> <given-names>F</given-names></string-name>, <string-name><surname>Otchy</surname> <given-names>TM</given-names></string-name>, <string-name><surname>Pehlevan</surname> <given-names>C</given-names></string-name>, <string-name><surname>Fantana</surname> <given-names>AL</given-names></string-name>, <string-name><surname>Burak</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Olveczky</surname> <given-names>BP</given-names></string-name>. <year>2013</year>. <article-title>The basal ganglia is necessary for learning spectral, but not temporal, features of birdsong</article-title>. <source>Neuron</source> <volume>80</volume>:<fpage>494</fpage>–<lpage>506</lpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Allen</surname> <given-names>WE</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>MZ</given-names></string-name>, <string-name><surname>Pichamoorthy</surname> <given-names>N</given-names></string-name>, <string-name><surname>Tien</surname> <given-names>RH</given-names></string-name>, <string-name><surname>Pachitariu</surname> <given-names>M</given-names></string-name>, <string-name><surname>Luo</surname> <given-names>L</given-names></string-name>, <string-name><surname>Deisseroth</surname> <given-names>K.</given-names></string-name> <year>2019</year>. <article-title>Thirst regulates motivated behavior through modulation of brainwide neural population dynamics</article-title>. <source>Science</source> <volume>364</volume>.</mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Andalman</surname> <given-names>AS</given-names></string-name>, <string-name><surname>Fee</surname> <given-names>MS</given-names></string-name>. <year>2009</year>. <article-title>A basal ganglia-forebrain circuit in the songbird biases motor output to avoid vocal errors</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>106</volume>:<fpage>12518</fpage>–<lpage>12523</lpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Angeloni</surname> <given-names>C</given-names></string-name>, <string-name><surname>Geffen</surname> <given-names>MN</given-names></string-name>. <year>2018</year>. <article-title>Contextual modulation of sound processing in the auditory cortex</article-title>. <source>Curr Opin Neurobiol</source> <volume>49</volume>:<fpage>8</fpage>–<lpage>15</lpage>.</mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Aton</surname> <given-names>SJ</given-names></string-name>. <year>2013</year>. <article-title>Set and setting: how behavioral state regulates sensory function and plasticity</article-title>. <source>Neurobiol Learn Mem</source> <volume>106</volume>:<fpage>1</fpage>–<lpage>10</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Ben-Tov</surname> <given-names>M</given-names></string-name>, <string-name><surname>Duarte</surname> <given-names>F</given-names></string-name>, <string-name><surname>Mooney</surname> <given-names>R.</given-names></string-name> <year>2023</year>. <article-title>A neural hub for holistic courtship displays</article-title>. <source>Curr Biol</source> <volume>33</volume>:<fpage>1640</fpage>–<lpage>1653</lpage>.e5.</mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Bottjer</surname> <given-names>SW</given-names></string-name>, <string-name><surname>Brady</surname> <given-names>JD</given-names></string-name>, <string-name><surname>Cribbs</surname> <given-names>B.</given-names></string-name> <year>2000</year>. <article-title>Connections of a motor cortical region in zebra finches: relation to pathways for vocal learning</article-title>. <source>J Comp Neurol</source> <volume>420</volume>:<fpage>244</fpage>–<lpage>260</lpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Burgess</surname> <given-names>CR</given-names></string-name>, <string-name><surname>Livneh</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Ramesh</surname> <given-names>RN</given-names></string-name>, <string-name><surname>Andermann</surname> <given-names>ML</given-names></string-name>. <year>2018</year>. <article-title>Gating of visual processing by physiological need</article-title>. <source>Curr Opin Neurobiol</source> <volume>49</volume>:<fpage>16</fpage>–<lpage>23</lpage>.</mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Canopoli</surname> <given-names>A</given-names></string-name>, <string-name><surname>Herbst</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Hahnloser</surname> <given-names>RH</given-names></string-name>. <year>2014</year>. <article-title>A higher sensory brain region is involved in reversing reinforcement-induced vocal changes in a songbird</article-title>. <source>J Neurosci</source> <volume>34</volume>:<fpage>7018</fpage>–<lpage>7026</lpage>.</mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Cardin</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Schmidt</surname> <given-names>MF</given-names></string-name>. <year>2004</year>. <article-title>Noradrenergic inputs mediate state dependence of auditory responses in the avian song system</article-title>. <source>Journal of Neuroscience</source> <volume>24</volume>:<fpage>7745</fpage>–<lpage>7753</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Castelino</surname> <given-names>CB</given-names></string-name>, <string-name><surname>Ball</surname> <given-names>GF</given-names></string-name>. <year>2005</year>. <article-title>A role for norepinephrine in the regulation of context-dependent ZENK expression in male zebra finches (Taeniopygia guttata)</article-title>. <source>Eur J Neurosci</source> <volume>21</volume>:<fpage>1962</fpage>–<lpage>1972</lpage>.</mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>Chen</surname> <given-names>R</given-names></string-name>, <string-name><surname>Goldberg</surname> <given-names>JH</given-names></string-name>. <year>2020</year>. <article-title>Actor-critic reinforcement learning in the songbird</article-title>. <source>Curr Opin Neurobiol</source> <volume>65</volume>:<fpage>1</fpage>–<lpage>9</lpage>.</mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Chen</surname> <given-names>R</given-names></string-name>, <string-name><surname>Puzerey</surname> <given-names>PA</given-names></string-name>, <string-name><surname>Roeser</surname> <given-names>AC</given-names></string-name>, <string-name><surname>Riccelli</surname> <given-names>TE</given-names></string-name>, <string-name><surname>Podury</surname> <given-names>A</given-names></string-name>, <string-name><surname>Maher</surname> <given-names>K</given-names></string-name>, <string-name><surname>Farhang</surname> <given-names>AR</given-names></string-name>, <string-name><surname>Goldberg</surname> <given-names>JH</given-names></string-name>. <year>2019</year>. <article-title>Songbird Ventral Pallidum Sends Diverse Performance Error Signals to Dopaminergic Midbrain</article-title>. <source>Neuron</source> <volume>103</volume>:<fpage>266</fpage>–<lpage>276 e4</lpage>.</mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>David</surname> <given-names>SV</given-names></string-name>, <string-name><surname>Fritz</surname> <given-names>JB</given-names></string-name>, <string-name><surname>Shamma</surname> <given-names>SA</given-names></string-name>. <year>2012</year>. <source>Task reward structure shapes rapid receptive field plasticity in auditory cortex</source> <volume>109</volume>:<fpage>2144</fpage>–<lpage>2149</lpage>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Downer</surname> <given-names>JD</given-names></string-name>, <string-name><surname>Niwa</surname> <given-names>M</given-names></string-name>, <string-name><surname>Sutter</surname> <given-names>ML</given-names></string-name>. <year>2015</year>. <article-title>Task engagement selectively modulates neural correlations in primary auditory cortex</article-title>. <source>J Neurosci</source> <volume>35</volume>:<fpage>7565</fpage>–<lpage>7574</lpage>.</mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Duffy</surname> <given-names>A</given-names></string-name>, <string-name><surname>Latimer</surname> <given-names>KW</given-names></string-name>, <string-name><surname>Goldberg</surname> <given-names>JH</given-names></string-name>, <string-name><surname>Fairhall</surname> <given-names>AL</given-names></string-name>, <string-name><surname>Gadagkar</surname> <given-names>V.</given-names></string-name> <year>2022</year>. <article-title>Dopamine neurons evaluate natural fluctuations in performance quality</article-title>. <source>Cell Rep</source> <volume>38</volume>:<fpage>110574</fpage>.</mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Eliades</surname> <given-names>SJ</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>X.</given-names></string-name> <year>2008</year>. <article-title>Neural substrates of vocalization feedback monitoring in primate auditory cortex</article-title>. <source>Nature</source> <volume>453</volume>:<fpage>1102</fpage>–<lpage>1106</lpage>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Foster</surname> <given-names>EF</given-names></string-name>, <string-name><surname>Bottjer</surname> <given-names>SW</given-names></string-name>. <year>1998</year>. <article-title>Axonal connections of the high vocal center and surrounding cortical regions in juvenile and adult male zebra finches</article-title>. <source>J Comp Neurol</source> <volume>397</volume>:<fpage>118</fpage>–<lpage>138</lpage>.</mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Fritz</surname> <given-names>J</given-names></string-name>, <string-name><surname>Shamma</surname> <given-names>S</given-names></string-name>, <string-name><surname>Elhilali</surname> <given-names>M</given-names></string-name>, <string-name><surname>Klein</surname> <given-names>D.</given-names></string-name> <year>2003</year>. <article-title>Rapid task-related plasticity of spectrotemporal receptive fields in primary auditory cortex</article-title>. <source>Nat Neurosci</source> <volume>6</volume>:<fpage>1216</fpage>–<lpage>1223</lpage>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Gadagkar</surname> <given-names>V</given-names></string-name>, <string-name><surname>Puzerey</surname> <given-names>PA</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>R</given-names></string-name>, <string-name><surname>Baird-Daniel</surname> <given-names>E</given-names></string-name>, <string-name><surname>Farhang</surname> <given-names>AR</given-names></string-name>, <string-name><surname>Goldberg</surname> <given-names>JH</given-names></string-name>. <year>2016</year>. <article-title>Dopamine neurons encode performance error in singing birds</article-title>. <source>Science</source> <volume>354</volume>:<fpage>1278</fpage>–<lpage>1282</lpage>.</mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Gervain</surname> <given-names>J</given-names></string-name>, <string-name><surname>Geffen</surname> <given-names>MN</given-names></string-name>. <year>2019</year>. <article-title>Efficient Neural Coding in Auditory and Speech Perception</article-title>. <source>Trends Neurosci</source> <volume>42</volume>:<fpage>56</fpage>–<lpage>65</lpage>.</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Goldberg</surname> <given-names>JH</given-names></string-name>, <string-name><surname>Fee</surname> <given-names>MS</given-names></string-name>. <year>2010</year>. <article-title>Singing-related neural activity distinguishes four classes of putative striatal neurons in the songbird basal ganglia</article-title>. <source>J Neurophysiol</source> <volume>103</volume>:<fpage>2002</fpage>–<lpage>2014</lpage>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Hamaguchi</surname> <given-names>K</given-names></string-name>, <string-name><surname>Tschida</surname> <given-names>KA</given-names></string-name>, <string-name><surname>Yoon</surname> <given-names>I</given-names></string-name>, <string-name><surname>Donald</surname> <given-names>BR</given-names></string-name>, <string-name><surname>Mooney</surname> <given-names>R.</given-names></string-name> <year>2014</year>. <article-title>Auditory synapses to song premotor neurons are gated off during vocalization in zebra finches</article-title>. <source>Elife</source> <volume>3</volume>:<fpage>e01833</fpage>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Harding</surname> <given-names>CF</given-names></string-name>. <year>2004</year>. <article-title>Brief alteration in dopaminergic function during development causes deficits in adult reproductive behavior</article-title>. <source>J Neurobiol</source> <volume>61</volume>:<fpage>301</fpage>–<lpage>308</lpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>Hindmarsh Sten</surname> <given-names>T</given-names></string-name>, <string-name><surname>Li</surname> <given-names>R</given-names></string-name>, <string-name><surname>Otopalik</surname> <given-names>A</given-names></string-name>, <string-name><surname>Ruta</surname> <given-names>V.</given-names></string-name> <year>2021</year>. <article-title>Sexual arousal gates visual processing during Drosophila courtship</article-title>. <source>Nature</source> <volume>595</volume>:<fpage>549</fpage>–<lpage>553</lpage>.</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>Hisey</surname> <given-names>E</given-names></string-name>, <string-name><surname>Kearney</surname> <given-names>MG</given-names></string-name>, <string-name><surname>Mooney</surname> <given-names>R.</given-names></string-name> <year>2018</year>. <article-title>A common neural circuit mechanism for internally guided and externally reinforced forms of motor learning</article-title>. <source>Nat Neurosci</source> <volume>1</volume>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><string-name><surname>Hoffmann</surname> <given-names>LA</given-names></string-name>, <string-name><surname>Saravanan</surname> <given-names>V</given-names></string-name>, <string-name><surname>Wood</surname> <given-names>AN</given-names></string-name>, <string-name><surname>He</surname> <given-names>L</given-names></string-name>, <string-name><surname>Sober</surname> <given-names>SJ</given-names></string-name>. <year>2016</year>. <article-title>Dopaminergic Contributions to Vocal Learning</article-title>. <source>J Neurosci</source> <volume>36</volume>:<fpage>2176</fpage>–<lpage>2189</lpage>.</mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><string-name><surname>Hubel</surname> <given-names>DH</given-names></string-name>, <string-name><surname>Henson</surname> <given-names>CO</given-names></string-name>, <string-name><surname>Rupert</surname> <given-names>A</given-names></string-name>, <string-name><surname>Galambos</surname> <given-names>R.</given-names></string-name> <year>1959</year>. <article-title>“attention” units in the auditory cortex</article-title>. <source>Science</source> <volume>129</volume>:<fpage>1279</fpage>–<lpage>1280</lpage>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>Hyland Bruno</surname> <given-names>J</given-names></string-name>, <string-name><surname>Tchernichovski</surname> <given-names>O.</given-names></string-name> <year>2019</year>. <article-title>Regularities in zebra finch song beyond the repeated motif</article-title>. <source>Behav Proc</source> <volume>163</volume>: <fpage>53</fpage>--59.</mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>Kao</surname> <given-names>MH</given-names></string-name>, <string-name><surname>Wright</surname> <given-names>BD</given-names></string-name>, <string-name><surname>Doupe</surname> <given-names>AJ</given-names></string-name>. <year>2008</year>. <article-title>Neurons in a forebrain nucleus required for vocal plasticity rapidly switch between precise firing and variable bursting depending on social context</article-title>. <source>J Neurosci</source> <volume>28</volume>:<fpage>13232</fpage>–<lpage>13247</lpage>.</mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><string-name><surname>Kaufman</surname> <given-names>MT</given-names></string-name>, <string-name><surname>Churchland</surname> <given-names>MM</given-names></string-name>, <string-name><surname>Ryu</surname> <given-names>SI</given-names></string-name>, <string-name><surname>Shenoy</surname> <given-names>KV</given-names></string-name>. <year>2014</year>. <article-title>Cortical activity in the null space: permitting preparation without movement</article-title>. <source>Nat Neurosci</source> <volume>17</volume>:<fpage>440</fpage>–<lpage>448</lpage>.</mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><string-name><surname>Keller</surname> <given-names>GB</given-names></string-name>, <string-name><surname>Hahnloser</surname> <given-names>RHR</given-names></string-name>. <year>2009</year>. <article-title>Neural processing of auditory feedback during vocal practice in a songbird</article-title>. <source>Nature</source> <volume>457</volume>:<fpage>187</fpage>–<lpage>190</lpage>.</mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Keller</surname> <given-names>GB</given-names></string-name>, <string-name><surname>Mrsic-Flogel</surname> <given-names>TD</given-names></string-name>. <year>2018</year>. <article-title>Predictive Processing: A Canonical Cortical Computation</article-title>. <source>Neuron</source> <volume>100</volume>:<fpage>424</fpage>–<lpage>435</lpage>.</mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>King</surname> <given-names>AJ</given-names></string-name>, <string-name><surname>Teki</surname> <given-names>S</given-names></string-name>, <string-name><surname>Willmore</surname> <given-names>BDB</given-names></string-name>. <year>2018</year>. <article-title>Recent advances in understanding the auditory cortex [version 1; peer review: 2 approved]</article-title>. <source>F1000Res</source> <volume>7</volume>. doi:<pub-id pub-id-type="doi">10.12688/F1000RESEARCH.15580.1</pub-id></mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><string-name><surname>Mandelblat-Cerf</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Las</surname> <given-names>L</given-names></string-name>, <string-name><surname>Denisenko</surname> <given-names>N</given-names></string-name>, <string-name><surname>Fee</surname> <given-names>MS</given-names></string-name>. <year>2014</year>. <article-title>A role for descending auditory cortical projections in songbird vocal learning</article-title>. <source>Elife</source> <volume>3</volume>. doi:<pub-id pub-id-type="doi">10.7554/eLife.02152</pub-id></mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><string-name><surname>Mante</surname> <given-names>V</given-names></string-name>, <string-name><surname>Sussillo</surname> <given-names>D</given-names></string-name>, <string-name><surname>Shenoy</surname> <given-names>KV</given-names></string-name>, <string-name><surname>Newsome</surname> <given-names>WT</given-names></string-name>. <year>2013</year>. <article-title>Context-dependent computation by recurrent dynamics in prefrontal cortex</article-title>. <source>Nature</source> <volume>503</volume>:<fpage>78</fpage>–<lpage>84</lpage>.</mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><string-name><surname>Menardy</surname> <given-names>F</given-names></string-name>, <string-name><surname>Giret</surname> <given-names>N</given-names></string-name>, <string-name><surname>Del Negro</surname> <given-names>C.</given-names></string-name> <year>2014</year>. <article-title>The presence of an audience modulates responses to familiar call stimuli in the male zebra finch forebrain</article-title>. <source>Eur J Neurosci</source> <volume>40</volume>:<fpage>3338</fpage>–<lpage>3350</lpage>.</mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="other"><string-name><surname>Menardy</surname> <given-names>F</given-names></string-name>, <string-name><surname>Touiki</surname> <given-names>K</given-names></string-name>, <string-name><surname>Dutrieux</surname> <given-names>G</given-names></string-name>, <string-name><surname>Bozon</surname> <given-names>B</given-names></string-name>, <string-name><surname>Vignal</surname> <given-names>C</given-names></string-name>, <string-name><surname>Mathevon</surname> <given-names>N</given-names></string-name>, <string-name><surname>Del Negro</surname> <given-names>C.</given-names></string-name> <year>2012</year>. <article-title>Social experience affects neuronal responses to male calls in adult female zebra finches</article-title>. <source>European Journal of Neuroscience</source>. doi:<pub-id pub-id-type="doi">10.1111/j.1460-9568.2012.08047.x</pub-id></mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><string-name><surname>Moore</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Woolley</surname> <given-names>SMN</given-names></string-name>. <year>2019</year>. <article-title>Emergent tuning for learned vocalizations in auditory cortex</article-title>. <source>Nat Neurosci</source> <volume>22</volume>:<fpage>1469</fpage>–<lpage>1476</lpage>.</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><string-name><surname>Olveczky</surname> <given-names>BP</given-names></string-name>, <string-name><surname>Andalman</surname> <given-names>AS</given-names></string-name>, <string-name><surname>Fee</surname> <given-names>MS</given-names></string-name>. <year>2005</year>. <article-title>Vocal experimentation in the juvenile songbird requires a basal ganglia circuit</article-title>. <source>PLoS Biol</source> <volume>3</volume>:<fpage>e153</fpage>.</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><string-name><surname>Parras</surname> <given-names>GG</given-names></string-name>, <string-name><surname>Casado-Román</surname> <given-names>L</given-names></string-name>, <string-name><surname>Schröger</surname> <given-names>E</given-names></string-name>, <string-name><surname>Malmierca</surname> <given-names>MS</given-names></string-name>. <year>2021</year>. <article-title>The posterior auditory field is the chief generator of prediction error signals in the auditory cortex</article-title>. <source>Neuroimage</source> <volume>242</volume>:<fpage>118446</fpage>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><string-name><surname>Rajan</surname> <given-names>R</given-names></string-name>, <string-name><surname>Doupe</surname> <given-names>AJ</given-names></string-name>. <year>2013</year>. <article-title>Behavioral and neural signatures of readiness to initiate a learned motor sequence</article-title>. <source>Curr Biol</source> <volume>23</volume>:<fpage>87</fpage>–<lpage>93</lpage>.</mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><string-name><surname>Remage-Healey</surname> <given-names>L</given-names></string-name>, <string-name><surname>Coleman</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Oyama</surname> <given-names>RK</given-names></string-name>, <string-name><surname>Schlinger</surname> <given-names>BA</given-names></string-name>. <year>2010</year>. <article-title>Brain estrogens rapidly strengthen auditory encoding and guide song preference in a songbird</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>107</volume>:<fpage>3852</fpage>–<lpage>3857</lpage>.</mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><string-name><surname>Rigotti</surname> <given-names>M</given-names></string-name>, <string-name><surname>Barak</surname> <given-names>O</given-names></string-name>, <string-name><surname>Warden</surname> <given-names>MR</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>XJ</given-names></string-name>, <string-name><surname>Daw</surname> <given-names>ND</given-names></string-name>, <string-name><surname>Miller</surname> <given-names>EK</given-names></string-name>, <string-name><surname>Fusi</surname> <given-names>S.</given-names></string-name> <year>2013</year>. <article-title>The importance of mixed selectivity in complex cognitive tasks</article-title>. <source>Nature</source> <volume>497</volume>:<fpage>585</fpage>–<lpage>590</lpage>.</mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><string-name><surname>Riters</surname> <given-names>LV</given-names></string-name>, <string-name><surname>Alger</surname> <given-names>SJ</given-names></string-name>. <year>2004</year>. <article-title>Neuroanatomical evidence for indirect connections between the medial preoptic nucleus and the song control system: possible neural substrates for sexually motivated song</article-title>. <source>Cell Tissue Res</source> <volume>316</volume>:<fpage>35</fpage>–<lpage>44</lpage>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="web"><string-name><surname>Roeser</surname> <given-names>A</given-names></string-name>, <string-name><surname>Gadagkar</surname> <given-names>V</given-names></string-name>, <string-name><surname>Das</surname> <given-names>A</given-names></string-name>, <string-name><surname>Puzerey</surname> <given-names>PA</given-names></string-name>, <string-name><surname>Kardon</surname> <given-names>B</given-names></string-name>, <string-name><surname>Goldberg</surname> <given-names>JH</given-names></string-name>. <year>2023</year>. <article-title>Dopaminergic signals for reward, performance and social outcomes are dynamically gated during courtship</article-title>. <source>bioRxiv</source> <fpage>822817</fpage>; doi: <pub-id pub-id-type="doi">101101/822817</pub-id>. doi:<pub-id pub-id-type="doi">10.1101/822817</pub-id></mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><string-name><surname>Sakata</surname> <given-names>JT</given-names></string-name>, <string-name><surname>Brainard</surname> <given-names>MS</given-names></string-name>. <year>2009</year>. <article-title>Social context rapidly modulates the influence of auditory feedback on avian vocal motor control</article-title>. <source>J Neurophysiol</source> <volume>102</volume>:<fpage>2485</fpage>–<lpage>2497</lpage>.</mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><string-name><surname>Sakata</surname> <given-names>JT</given-names></string-name>, <string-name><surname>Brainard</surname> <given-names>MS</given-names></string-name>. <year>2008</year>. <article-title>Online contributions of auditory feedback to neural activity in avian song control circuitry</article-title>. <source>J Neurosci</source> <volume>28</volume>:<fpage>11378</fpage>–<lpage>11390</lpage>.</mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="other"><string-name><surname>Scarpa</surname> <given-names>GB</given-names></string-name>, <string-name><surname>Starrett</surname> <given-names>JR</given-names></string-name>, <string-name><surname>Li</surname> <given-names>G-L</given-names></string-name>, <string-name><surname>Brooks</surname> <given-names>C</given-names></string-name>, <string-name><surname>Morohashi</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Yazaki-Sugiyama</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Remage-Healey</surname> <given-names>L.</given-names></string-name> <year>2022</year>. <article-title>Estrogens rapidly shape synaptic and intrinsic properties to regulate the temporal precision of songbird auditory neurons</article-title>. <source>Cereb Cortex</source> <fpage>3401</fpage>–<lpage>3420</lpage>.</mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><string-name><surname>Scharff</surname> <given-names>C</given-names></string-name>, <string-name><surname>Nottebohm</surname> <given-names>F.</given-names></string-name> <year>1991</year>. <article-title>A comparative study of the behavioral deficits following lesions of various parts of the zebra finch song system: implications for vocal learning</article-title>. <source>J Neurosci</source> <volume>11</volume>:<fpage>2896</fpage>–<lpage>2913</lpage>.</mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><string-name><surname>Shea</surname> <given-names>SD</given-names></string-name>, <string-name><surname>Margoliash</surname> <given-names>D.</given-names></string-name> <year>2010</year>. <article-title>Behavioral state-dependent reconfiguration of song-related network activity and cholinergic systems</article-title>. <source>J Chem Neuroanat</source> <volume>39</volume>:<fpage>132</fpage>–<lpage>140</lpage>.</mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><string-name><surname>Singh Alvarado</surname> <given-names>J</given-names></string-name>, <string-name><surname>Goffinet</surname> <given-names>J</given-names></string-name>, <string-name><surname>Michael</surname> <given-names>V</given-names></string-name>, <string-name><surname>Liberti</surname> <given-names>W</given-names> <suffix>III</suffix></string-name>, <string-name><surname>Hatfield</surname> <given-names>J</given-names></string-name>, <string-name><surname>Gardner</surname> <given-names>T</given-names></string-name>, <string-name><surname>Pearson</surname> <given-names>J</given-names></string-name>, <string-name><surname>Mooney</surname> <given-names>R.</given-names></string-name> <year>2021</year>. <article-title>Neural dynamics underlying birdsong practice and performance</article-title>. <source>Nature</source> <volume>599</volume>:<fpage>635</fpage>–<lpage>639</lpage>.</mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><string-name><surname>Skals</surname> <given-names>N</given-names></string-name>, <string-name><surname>Anderson</surname> <given-names>P</given-names></string-name>, <string-name><surname>Kanneworff</surname> <given-names>M</given-names></string-name>, <string-name><surname>Löfstedt</surname> <given-names>C</given-names></string-name>, <string-name><surname>Surlykke</surname> <given-names>A.</given-names></string-name> <year>2005</year>. <article-title>Her odours make him deaf: crossmodal modulation of olfaction and hearing in a male moth</article-title>. <source>J Exp Biol</source> <volume>208</volume>:<fpage>595</fpage>–<lpage>601</lpage>.</mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><string-name><surname>Tumer</surname> <given-names>EC</given-names></string-name>, <string-name><surname>Brainard</surname> <given-names>MS</given-names></string-name>. <year>2007</year>. <article-title>Performance variability enables adaptive plasticity of “crystallized” adult birdsong</article-title>. <source>Nature</source> <volume>450</volume>:<fpage>1240</fpage>–<lpage>1244</lpage>.</mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><string-name><surname>Ulanovsky</surname> <given-names>N</given-names></string-name>, <string-name><surname>Las</surname> <given-names>L</given-names></string-name>, <string-name><surname>Nelken</surname> <given-names>I.</given-names></string-name> <year>2003</year>. <article-title>Processing of low-probability sounds by cortical neurons</article-title>. <source>Nat Neurosci</source> <volume>6</volume>:<fpage>391</fpage>–<lpage>398</lpage>.</mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><string-name><surname>Williams</surname> <given-names>AH</given-names></string-name>, <string-name><surname>Kim</surname> <given-names>TH</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>F</given-names></string-name>, <string-name><surname>Vyas</surname> <given-names>S</given-names></string-name>, <string-name><surname>Ryu</surname> <given-names>SI</given-names></string-name>, <string-name><surname>Shenoy</surname> <given-names>KV</given-names></string-name>, <string-name><surname>Schnitzer</surname> <given-names>M</given-names></string-name>, <string-name><surname>Kolda</surname> <given-names>TG</given-names></string-name>, <string-name><surname>Ganguli</surname> <given-names>S.</given-names></string-name> <year>2018</year>. <article-title>Unsupervised Discovery of Demixed, Low-Dimensional Neural Dynamics across Multiple Timescales through Tensor Component Analysis</article-title>. <source>Neuron</source> <volume>98</volume>:<fpage>1099</fpage>–<lpage>1115</lpage>.e8.</mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><string-name><surname>Woolley</surname> <given-names>SC</given-names></string-name>, <string-name><surname>Rajan</surname> <given-names>R</given-names></string-name>, <string-name><surname>Joshua</surname> <given-names>M</given-names></string-name>, <string-name><surname>Doupe</surname> <given-names>AJ</given-names></string-name>. <year>2014</year>. <article-title>Emergence of context-dependent variability across a basal ganglia network</article-title>. <source>Neuron</source> <volume>82</volume>:<fpage>208</fpage>–<lpage>223</lpage>.</mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><string-name><surname>Xiao</surname> <given-names>L</given-names></string-name>, <string-name><surname>Chattree</surname> <given-names>G</given-names></string-name>, <string-name><surname>Oscos</surname> <given-names>FG</given-names></string-name>, <string-name><surname>Cao</surname> <given-names>M</given-names></string-name>, <string-name><surname>Wanat</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Roberts</surname> <given-names>TF</given-names></string-name>. <year>2018a</year>. <article-title>A Basal Ganglia Circuit Sufficient to Guide Birdsong Learning</article-title>. <source>Neuron</source> <volume>98</volume>:<fpage>208</fpage>–<lpage>221 e5</lpage>.</mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><string-name><surname>Xiao</surname> <given-names>L</given-names></string-name>, <string-name><surname>Priest</surname> <given-names>MF</given-names></string-name>, <string-name><surname>Kozorovitskiy</surname> <given-names>Y.</given-names></string-name> <year>2018b</year>. <article-title>Oxytocin functions as a spatiotemporal filter for excitatory synaptic inputs to VTA dopamine neurons</article-title>. <source>Elife</source> <volume>7</volume>. doi:<pub-id pub-id-type="doi">10.7554/eLife.33892</pub-id></mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><string-name><surname>Yip</surname> <given-names>PK</given-names></string-name>, <string-name><surname>Schmitzberger</surname> <given-names>M</given-names></string-name>, <string-name><surname>Al-Hasan</surname> <given-names>M</given-names></string-name>, <string-name><surname>George</surname> <given-names>J</given-names></string-name>, <string-name><surname>Tripoliti</surname> <given-names>E</given-names></string-name>, <string-name><surname>Michael-Titus</surname> <given-names>AT</given-names></string-name>, <string-name><surname>Clayton</surname> <given-names>D</given-names></string-name>,<string-name><surname>Priestley</surname> <given-names>JV</given-names></string-name>. <year>2020</year>. <article-title>Serotonin Expression in the Song Circuitry of Adult Male Zebra Finches</article-title>. <source>Neuroscience</source> <volume>444</volume>:<fpage>170</fpage>–<lpage>182</lpage>.</mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="book"><string-name><surname>Zann</surname> <given-names>RA</given-names></string-name>. <year>1996</year>. <source>The zebra finch: a synthesis of field and laboratory studies</source>. <publisher-name>Oxford University Press</publisher-name>.</mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><string-name><surname>Zhang</surname> <given-names>SX</given-names></string-name>, <string-name><surname>Miner</surname> <given-names>LE</given-names></string-name>, <string-name><surname>Boutros</surname> <given-names>CL</given-names></string-name>, <string-name><surname>Rogulja</surname> <given-names>D</given-names></string-name>, <string-name><surname>Crickmore</surname> <given-names>MA</given-names></string-name>. <year>2018</year>. <article-title>Motivation, Perception, and Chance Converge to Make a Binary Decision</article-title>. <source>Neuron</source> <volume>99</volume>:<fpage>376</fpage>–<lpage>388</lpage>.e6.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.91769.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>King</surname>
<given-names>Andrew J</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Oxford</institution>
</institution-wrap>
<city>Oxford</city>
<country>United Kingdom</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study reports that neural activity in the auditory cortex (field L) of singing male songbirds can be modulated by social context. These potentially <bold>important</bold> findings indicate that the presence of a female conspecific alters the response of auditory cortical neurons to the male bird's own song and to perturbations of auditory feedback that the bird has been trained to expect. While they extend recent work showing that the activity of dopaminergic neurons in songbirds is also affected by an audience, the evidence presented is <bold>incomplete</bold> since it is unclear how much of the apparent modulation of cortical neurons may be due to other factors, such as changes in the recorded neurons or their properties over time, which will require additional analyses to work out.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.91769.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>
This study examines the context-dependent modulation of auditory cortical neurons in response to expected sensory input, either self-generated sounds or expected perturbations of self-generated sounds. Specifically, using songbirds, the authors ask whether social context (the presence of a female conspecific) affects 1) the response of auditory cortical neurons to the bird's own song when he is singing; and 2) the response of neurons to perturbations of auditory feedback that the bird has been trained to expect.</p>
<p>Strengths:</p>
<p>
First, the authors report that across the population, the responses of the neurons does not differ when a male bird sings alone or if he sings to a female. A fraction of auditory cortical neurons, however, do show significant differences in the firing rate, precision, and/or degree of burst firing when males sing alone vs. when they sing to females. This finding is broadly consistent with the literature showing that sensory neurons (visual, auditory, somatosensory, etc.) can be rapidly reconfigured into different &quot;information processing modes&quot; depending on behavioral state (e.g, quiescence vs vigilance).</p>
<p>For the perturbation experiments, the authors trained birds to expect distorted auditory feedback during a particular syllable. They found that some neurons showed greater responses during perturbation when a female was present (compared to when males were alone) while other neurons had smaller responses during perturbation when a female was present. In addition, the response of a small number of auditory cortical neurons were not affected by behavioral state. These results contrast with their prior report that the responses of midbrain dopaminergic neurons that project to the basal ganglia are &quot;uniformly reduced&quot; in the presence of a female, raising a question of how an evaluation signal is transformed in the circuit from the primary sensory region to the midbrain.</p>
<p>Weaknesses:</p>
<p>
While the experiments and analysis are solid, the finding that social context can alter responses of auditory cortical neurons in a multitude of ways (increase, decrease or no change) raises several questions that can be examined with additional analysis. For example, do context-dependent differences in auditory responses derive from context-dependent differences in the songs? Are context-dependent differences present in all classes of neurons and throughout the auditory system?</p>
<p>The observed heterogeneity in the firing properties of auditory cortical neurons, both in response to self-generated sounds and during perturbations of auditory feedback, raises the question of which neurons are sensitive to social context (which likely can be addressed by the authors in a revision). The authors should provide additional details about the recordings:</p>
<p>a) What are the locations of the recording sites?</p>
<p>
Prior work has shown that there is an organized map of spectrotemporal features of sounds in the auditory cortex of songbirds; spectral tuning widths change along the medial-lateral axis and temporal tuning widths differ between the input and output layers of Field L. Were the recordings primarily in Field L2 (thalamo-recipient region), L1 or L3? Were some recordings lateral to Field L in secondary auditory regions? Were the neurons that showed context-dependent changes in firing properties localized or distributed throughout Field L (i.e., were the context-dependent differences in neural responses truly brain-wide)? At a minimum, the authors should include a schematic showing the different regions of Field L and a summary of the location of the recording sites. Images of the processed tissue with electrolytic lesions would also be helpful.</p>
<p>b) Was the context-dependent modulation limited to a particular class of neurons (distinguished by spike waveform shape, spontaneous firing rate, or other feature)?</p>
<p>While the authors attribute differences in the responses of single auditory cortical neurons to the presence of a female, other potential explanations for the observed differences should be examined (and potentially ruled out):</p>
<p>a) Prior work has shown that songs of zebra finches differ slightly when males sing alone compared to when they sing to females: songs are faster; pitch is less variable; and the number of introductory elements is greater when males sing to females. Do some of the observed social context-dependent differences in the responses of auditory neurons reflect differences in the songs in the two conditions? This idea is supported in part by a prior study in juvenile zebra finches (Keller &amp; Hahnloser, 2009) showing that ~20% of the neurons they recorded in Field L and a secondary auditory region (CLM) showed anticipatory activity even before the onset of a song bout, suggesting a source of premotor (or at least non-auditory drive) to neurons in the auditory cortex. Did the authors of this study also find premotor activity in Field L, and if so, did it differ between the two social contexts? Might differences in Field L responses reflect motor/song differences?</p>
<p>b) For the perturbation experiments, the authors report heterogeneous responses to playback, with some neurons firing more and other firing less when a female is present compared to when the male is alone. Keller and Hahnloser (2009) found that in juvenile birds, responses of Field L to perturbations of auditory feedback were sensitive to sound amplitude; perturbation responses increased with relative perturbation amplitude. This raises a question of whether perturbation amplitude is different when a male is alone and when a female is present (i.e., the male may move towards the female when she is present and if the speaker is close to the female, the perturbation may be louder than when the male is alone; alternatively, the male be more active when he is alone so the loudness of the perturbation may be more variable across song bouts). It would be useful to know if (and how much) perturbation amplitude varied depending on the location inside the cage as well as whether the sound pressure level of the underlying song was higher (e.g., Lombard effect). Addition of details of the experimental setup/procedure would help to allay concerns that the amplitude of the white noise varied significantly depending on behavioral context.</p>
<p>Finally, I am still trying to make sense of the differences in the context-dependent modulation of responses of auditory cortical neurons vs. midbrain dopaminergic neurons. Given the heterogeneity of responses in Field L, both to self-generated sounds and to expected perturbations during singing, how are the signals decoded downstream of Field L? At the population level, neither the mean firing rate nor the timing of firing of Field L neurons changed with courtship. Similarly, across the population, the responses to perturbations of auditory feedback were not affected by courtship state (error signal attenuated in 11 neurons, increased in 22 neurons and not affected in 10 neurons). Yet, the courtship state &quot;uniformly&quot; reduces the response of midbrain dopaminergic neurons to auditory perturbation. It would be helpful if the authors could include a model and/or more discussion of how this change may arise.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.91769.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>In the manuscript 'Auditory cortical error signals retune during songbird courtship', Jones and Goldberg study auditory cortex in male zebra finches. They explore song-related responses in two different contexts, when the male is either alone or in the presence of a female. Social-context related responses are hypothesized based on previous results on downstream VTA neurons where such modulation is found. They play jamming stimuli through a loudspeaker to probe sensitivity of song-related neural responses to these external stimuli. They find a heterogeneity of responses, in line with auditory cortical neurons computing the social modulation of responses found in VTA.</p>
<p>Strengths:</p>
<p>In general, the work is interesting and sheds light onto auditory processing and self-perception mechanisms in songbirds.</p>
<p>Weaknesses:</p>
<p>Stability of responses has not been studied: some neurons seem to have responses that slowly drift in time, which could lead to observed differences between alone and with-female conditions. Also, possible motor confounds and sound-of-audience confounds should be addressed. The language is often imprecise.</p>
<p>Stability and Reversal: It is a bit unfortunate that stability of effects seemingly has not been studied by reversing experimental conditions. The work would be much stronger if authors could show that audience-dependent tuning is robust in individual cells. Did they record from some neurons during reversal back to the alone condition? Ideally, the responses should be identical before and after recording with an audience. This would control for possible non-stationarities in their neuron recordings/spike-sorting/circadian trends. If authors do not have such data, it would be worth wile to even just try to divide the dataset for each neuron and condition (either the audience or isolate condition) into two parts to verify that the response is the same in either part (provided sufficient song renditions are recorded). See also my comment below about Fig. 2A.</p>
<p>Motor responses: Does DAF playback change song? If so, especially if it applies only in one of the two conditions (audience/no audience), then the observed response differences could be motor-related rather than auditory responses. Analyses of song spectrograms right after DAF would presumably provide the answer.</p>
<p>Similarly, motif-aligned spiking activity was time warped to the median duration of undirected or directed motifs. Could the shorter motifs during directed song (as has been reported in other studies) lead to alignment differences that would account for the different error responses in alone/wfemale conditions? In other words, could increased error responses be due to the fixed 100 ms analysis window of the audience condition that extends into a song region beyond the 100 ms region of the no-audience condition where there is increased firing? And vice versa for observed decreases in error responses, i.e. is there a firing pause just after the offset of the 100 ms window in the no-audience condition that causes audience dependence of responses? A simple compensation of song tempo differences by shortening/stretching the analysis window in one of the two conditions would allow to test for this.</p>
<p>Audience versus sound of audience: In the first sentence of the discussion authors write: we discovered that auditory representations of an animal's own vocalizations change with an audience. Is it truly the audience that causes the difference in error responses or is it the sounds the audience makes? To control for that would be to play back stimuli that simulate a non-silent audience through a loudspeaker to see whether error responses depend on the soundscape created by a typical audience (either present or absent). Authors probably do not have such data and to record it would go beyond the scope of this study, but it would be important to discuss this possibility or perform some analysis in that vein.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.91769.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>In this study, Jones et al. examine how neural activity in a primary auditory area (field L) of singing male songbirds is modulated by the presence or absence of an audience (a female conspecific). Prior work has demonstrated that the presence of an audience attenuates the responses of dopaminergic neurons to distortions of auditory feedback (DAF). Here the authors report that even in a region that is primarily considered sensory, responses to DAF are also modulated by the audience, although in a heterogeneous manner that does not readily explain previously observed attenuation. These findings address an interesting question and will potentially be important in adding to an understanding of how non-sensory factors can alter response properties of neurons even in primary sensory regions in a context dependent fashion. However, to be fully persuasive, additional analyses will be required to address how much of the apparent modulation by audience may be explained by other factors such as changes in recorded neurons or their properties over time.</p>
<p>Full Public Review:</p>
<p>In this study, Jones et al. examine how neural activity in a primary auditory area (field L) of singing male songbirds is modulated by the presence or absence of an audience (a female conspecific). They test whether activity in Field L differs between conditions in which the male is singing to a female (directed song) or alone (undirected song) and whether response to distortions of auditory feedback (DAF) differ between these conditions. Previous work has shown that in other parts of the songbird brain, sensory-motor activity can differ between directed and undirected song, and that responses to DAF are attenuated when males sing directed song versus undirected song. These prior results raise the interesting question of the extent to which such modulations of activity by the presence of an audience are already present in primary sensory areas such as Field L. This possibility is also motivated by prior work that has shown that Field L activity is not exclusively explained by auditory input, but can also be modulated by the bird's state - whether it is singing or not.</p>
<p>Against this background, the questions asked here are of interest for two inter-related reasons:</p>
<p>1. the authors address whether the presence of an audience (a female conspecific) alters activity in a primary auditory area during singing. Primary auditory areas such as Field L, and analogous mammalian thalamo-recipient cortical regions such as A1, are often thought of as responding very specifically to the features of sensory stimuli, but are also understood to be modulated by a variety of factors including the attentional and behavioral state of the animal. For audition, such modulation includes whether or not animals are vocalizing and listening to themselves or listening to playback of their own vocalizations. Cited works from Keller (2009) as well as Eliades and Wang (2008) have indicated that the act of vocalizing can modulate auditory responses to self-generated feedback in primary auditory areas relative to those arising from playback of the same sounds. Here, the question is whether responses to self-generated feedback differ between conditions of singing alone versus singing to a female audience. A demonstration that the presence of an audience matters to responses in Field L would add to a general understanding of how it is that non-auditory factors can modulate sensory responses.</p>
<p>2. the authors address the possible source of an audience-dependent modulation of responses to feedback perturbation in the VTA previously reported by Goldberg and colleagues (2023). In the VTA, responses to perturbations during singing are consistently attenuated when males are singing to females versus when they are singing alone, but the underlying mechanisms of this modulation are unknown. Here, the authors test the possibility that such modulation by an audience is already present at the level of Field L. The previously reported attenuation in VTA is quite striking and reflects a nice example of how neural processing can differ with varying behavioral priorities. Understanding whether this modulation of responses to DAF arises already in primary auditory areas would further a mechanistic understanding of an intriguing example of state-dependent modulation of sensory processing and behavior, and lend broad insight into related phenomena.</p>
<p>The authors report 1) that activity in Field L differs between directed and undirected singing at many individual recording sites, but that these changes are heterogeneous, with both increases and decreases in activity, so that there is no consistent change across the population and 2) that the responses to DAF differ between directed and undirected song, but that there is no consistent attenuation of response (as observed in the VTA) and instead heterogeneous increases and decreases in response to DAF so that there is no net change at the population level.</p>
<p>These findings, if firmly established, are important and of general interest. While they do not readily explain the source of the audience-dependent attenuation of auditory responses to DAF in the VTA, the demonstration of audience-dependent modulation of self-generated feedback and its disruption in a primary auditory area is an exciting result that would provide an opportunity for further investigation of how changes in social context influence brain and behavior. The manuscript is generally well written, although the presentation is terse. My main reservations about the current manuscript relate to aspects of experimental design and analysis that need to be clarified and addressed before these conclusions will be fully persuasive. There are also some places where further discussion of the findings and their relationship to prior studies would be helpful.</p>
<p>1. A central concern relates to whether the main reported effects associated with differences in singing directed versus undirected song reflect only those changes in conditions, versus contributions from changes in unit isolation or response properties over time. The authors record undirected song in a block in the morning and only after collecting at least 40 renditions do they later record responses during directed song over a series of repeated exposures to a female. Therefore, differences between data collected during undirected song and directed song also reflect differences between data collected initially during the morning versus later. It is unclear from methods whether any of these recordings during undirected and directed conditions are interleaved, but if this is not the case, then it is crucial to ask how stable were neural recordings with respect to unit isolation, and potential changes to response properties, over the duration of the experiments. This would be less of a concern if the results mirrored those observed in the VTA, where attenuation of responses was observed across the entire population during directed versus undirected conditions - it is hard to explain a phenomenon that is consistently observed across the population as arising from a change in which neurons and spikes are contributing to responses, or other forms of non-stationarity. However, because there are no significant differences reported at the population level in the current study, it is important to address the possibility that observed differences between conditions reflect some form of noise or drift in recorded units, rather than being entirely due to directed versus undirected singing. I have elaborated in more detail below on this concern, including places where the data seems to suggest some non-stationarity of responses, and have some suggestions for ways in which this concern might be addressed.</p>
<p>2. A second concern, related to this first one, has to do with the categorical definition of 'error neurons'. The authors note in their text that it could be problematic to apply categorical definitions to continuous distributions, and yet that seems to be what they then do. The authors have a metric of error sensitivity that they apply to each neuron's response to DAF in both undirected and directed conditions (the error score). They show that there is a continuous distribution of error scores (Figure 2 - figure supplement 1) across the population, with no bimodality that would be suggestive of distinct error sensitive and error-insensitive neurons. One nice feature of their analysis is that they also show the distribution of error scores computed in an analogous fashion for a period of neural activity in the song prior to DAF. This control data set makes it persuasive that there is a significant response to DAF, but also shows that there can be a broad range of error scores even when no DAF has been played, and that this range of 'noise' responses to DAF overlaps substantially with the actual responses to DAF. Despite the continuum of error scores, the authors define a subset of neurons as error responsive only if their responses to DAF exceed a specific threshold (2.5 standard deviations). One of the main conclusions of the paper is based on finding a subset of 22 neurons that exhibited error responses (by this definition) only during singing to a female and 11 neurons that exhibited error responses only when singing alone. These neurons are described as 'retuned' because they have error responses in only one condition.</p>
<p>The problem here is that for some, if not many, of the neurons that are categorically defined as being responsive to DAF in only one condition (directed versus undirected) there is almost certainly not a significant difference in the actual responses to DAF between conditions. This is apparent in the relevant data figure (figure 2 - figure supplement 1) and is a consequence of using a threshold to split a continuous distribution into groups defined as error responsive or not. For example, several neurons in this plot that have almost identical scores in the directed and undirected condition are counted as examples of retuning because the error scores are just a bit over 2.5 in the directed condition and just a bit under 2.5 in the undirected condition.</p>
<p>That this kind of categorical approach may be problematic is apparent in the control data in the plot. Despite the absence of any perturbation, there are error responsive neurons present in these data that are considered selective for directed versus undirected singing - this is an expected consequence of using a threshold on dispersed or noisy biological data. Shifting to a more stringent threshold of three standard deviations, as the authors do, does not help with this problem, as that still treats as categorically different responses that fall on either side of a line, even if only by a tiny amount. I suggest that the authors devise a measure for each neuron to test whether the responses to DAF are significantly different under the two conditions (directed versus undirected). As noted above, this measure should take into account some assessment of the stationarity of responses, as well as the distribution of responses (which, in some of the examples does not seem to be Gaussian around a mean response level, but rather highly variable across trials).</p>
<p>3. There are several places where further discussion of the previous literature and how the current results relate to that literature would be helpful. This includes:</p>
<p>3a. Some discussion of what is already known about the auditory tuning of field L, and the extent to which responses associated with distortion of feedback may reflect the frequency tuning of field L neurons versus something that might be construed as more specifically as detecting an error in perceived feedback. For example, Field L neurons have previously been characterized as having relatively simple spectro-temporal receptive fields, often with a single frequency band that is excitatory and nearby frequency bands that are inhibitory. It would be beyond the scope of this paper to directly assess the extent to which both song responses and responses to DAF are well predicted by simple STRFs that might be measured for the recorded neurons, or computed from activity during a range of vocalizations, but perhaps worth discussing whether a neuron with such frequency tuning would potentially exhibit 'error responses' of the sort described here, simply because the DAF stimulus happens to fall into the excitatory or inhibitory regions of the neuron's receptive field. While it is OK to use the term 'error responsive' in the current study, it would be good to make clear that changes in firing associated with playing DAF should be expected even for neurons that have simple auditory receptive fields (i.e. with center surround tuning to specific frequencies in a tonotopic map, as has been described for Field L) without necessarily indicating that these neurons are specifically registering any deviation or 'error' between expected feedback and experienced feedback. In this respect, there are multiple subdivisions of Field L with different tuning properties. Please specify further what criteria were used to determine recording locations and how these correspond with previously defined subdivisions.</p>
<p>3b. It would also be useful to discuss further previous work on differences in auditory tuning or responses between conditions when subjects are vocalizing, versus when vocalizations are played back (as in Keller, Eliades) and whether the results in the current study are similar or different. For example, this prior work has indicated that efference copy or other signals that precede vocalizations can reach and influence activity in auditory areas - with the most compelling evidence for this being the modulation of activity prior to the onset of vocalizations. Was this also observed in the current study, and to what extent might this kind of mechanism contribute to the processing of feedback distortions? With respect to this kind of efference signal, or other possibilities, can the authors provide some discussion or speculation about possible mechanisms that might be differentially engaged between conditions of singing directed versus undirected song?</p>
<p>3c. The previous study on DAF responses in VTA indicates enhanced responses to female calls during directed song. To what extent did the current study control for any vocalizations or other sounds produced by females during the directed singing, and could this have contributed to differences in Field L activity between conditions? This question is motivated partly by the highly variable responses in raster plots even within one condition - might some of this reflect motifs during which transient noises are produced from female calling or other movements by the male or female?</p>
<p>More regarding stability of recordings:</p>
<p>The data presented in Figure 1D illustrate some of my concerns about the stationarity of recordings. In the directed condition there are no spikes at all following the first handful of motif renditions. Were the directed and undirected recordings interleaved here? If not, could the recorded neuron simply have been lost, changed in amplitude of recorded spikes so that it was no longer counted, or reduced its responsiveness over the course of the recordings? Because the recordings of undirected and directed singing are described as occurring sequentially, it seems likely that this type of change in recorded signal could contribute to changes in measured responses over time, independently of effects due to directed versus undirected singing.</p>
<p>A minor issue of this example is that the raw example trace with male alone does not seem to have a corresponding set of points in the roster plot. For panel E, I also cannot find rasters that correspond to the example recordings shown at top.</p>
<p>Figure 2A also shows a neuron that looks like it has non-stationarity; for the alone condition without altered feedback, the main peak has no spikes for the bottom half of the rasters. For the directed condition, much of the difference between control and distorted feedback conditions seems to come from a few trials towards the bottom of the raster plot that show more and earlier firing than most other rasters.</p>
<p>Other more subtle examples are suggested in the figures, such as Figure 1F where responses in the alone condition seem to increase over the course of recordings. A related issue apparent in some of the raster plots is that the firing rate distributions within a given condition sometimes appear to be very non-gaussian, with some motifs during which there is a lot of activity, or apparent bursting, and others in which there is little activity. In addition to the examples above, this includes</p>
<p>
responses in Fig 1E and Fig 2F. Does anything distinguish these cases or trails? Where differences between conditions are driven by firing differences that are present on only a subset of trials, such as in Fig 2A, there is some deviation from the normal criteria for use of T-tests/Z-scores. Please consider this point and discuss any caveats and/or apply other tests (Monte Carlo? Non-parametric?) as appropriate.</p>
<p>These potential issues of non-stationarily, and non-Gaussian firing rate distributions in each condition, make it complicated to think about what differences in activity reflect changes from undirected to directed conditions versus these other factors.</p>
<p>Approaches to addressing this issue could include more specifically indicating examples in which recordings from the alone condition and directed condition are interleaved and exhibit reversible (between conditions) changes in the pattern of responses (both without DAF in comparing alone versus directed, and with DAF demonstrating differences in DAF influences between conditions). Some good interleaved examples of this sort would be very helpful to illustrate the robustness of differences between conditions. More generally, the methods and or raster plots should include some further explanation of the time periods over which recordings were made in the alone versus directed conditions, and the extent to which they are interleaved or not.</p>
<p>Another approach that could be used if there are not many instances of inter-leaved recordings is to try to document the stationarily or stability of unit isolation and/or responses over time. It would be most helpful when applied to recordings from a given singing condition (i.e. alone or directed) that are interleaved, but even in cases where this is not possible perhaps one could assess the stability of waveforms and unit isolation across time. For example in Figure 2 - Supplementary figure 2, the left-hand and middle examples appear to have quite good unit isolation, and might be the sorts of cases where measures of unit isolation and waveform stability could be used to argue that a gain or loss of spikes due to drift in recordings or changes to SNR and spike detection are not contributing to changes in firing patterns over time (and across conditions).</p>
<p>It potentially would also be informative to present the prevalence of the main effects reported in the study as a function of some measures of unit isolation, SNR, and recording stability. It would be reassuring to see that significant differences between conditions are equally or more prevalent under the conditions of greatest unit isolation and recording stability than in cases with worse SNR or stability.</p>
<p>One other way that the authors might be able to address my main concern would be to look at the stability of firing patterns within conditions, where differences across trials most directly indicate the potential contributions of technical or biological changes in neural activity over time that are not related to the experimental conditions.</p>
<p>To further address some of these issues, it would be helpful to have additional explanations in this paper (rather than by reference to Goldberg and Fee, 2010) of the criteria that were used for counting spikes, and assessing stability of recordings. All I found about this in the Goldberg and Fee, 2010 reference was that &quot;Spikes were sorted off-line using custom Matlab software&quot; Does this require human inspection and judgment? Is there a simple threshold, or waveform measurement used for detecting spikes from single units? Are some sort of signal to noise measures, or ISI violations used to score how well units are isolated?</p>
<p>For the specific examples shown in figures, it would be useful to indicate by small tick marks or otherwise which spikes were counted as single units. For example in figure 2 column B, for the condition with female, did only the 1-3 largest spikes get counted, or also the spikes of medium height?</p>
<p>Page 11: &quot;Many channels on the probes recorded multi-unit activity, which were taken note of but not analyzed in this study.&quot;</p>
<p>What were the criteria for this? For several of the examples in the figures there are spikes of varying amplitudes and as mentioned above it would be helpful to clarify how the spikes were sorted into single units in such cases.</p>
<p>Categorical scores:</p>
<p>Page 13: &quot;Neurons with error responses greater than 2.5 in only one condition (undirected versus directed) were considered to have retuned; neurons with error scores greater than 2.5 in both conditions were considered not to have retuned.&quot;</p>
<p>This definition results in cases where responses of 2.45 vs 2.55 are described as 'retuned', even if these responses are not significantly different. The figure (Figure 2 - figure supplement 1) indicates that multiple neurons that were scored as retuning had responses that fall very near the threshold in this way.</p>
<p>Page 13, &quot;Our results did not fundamentally change with ... a more stringent threshold of 3...&quot;</p>
<p>The stringency is not issue here, rather the categorical threshold. Retuning would be more persuasively demonstrated if the authors could provide a test of whether or not the responses for individual neurons differ significantly between conditions appropriately taking into account multiple comparisons, stability of recordings, non-Gaussian firing rate distributions across motif renditions, etc. and use this metric to report effects, rather than setting a categorical threshold.</p>
</body>
</sub-article>
</article>