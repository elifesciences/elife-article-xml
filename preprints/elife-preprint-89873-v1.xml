<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">89873</article-id>
<article-id pub-id-type="doi">10.7554/eLife.89873</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.89873.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Multi-level processing of emotions in life motion signals revealed through pupil responses</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Yuan</surname>
<given-names>Tian</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Wang</surname>
<given-names>Li</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Jiang</surname>
<given-names>Yi</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<aff id="a1"><label>1</label><institution>State Key Laboratory of Brain and Cognitive Science, CAS Center for Excellence in Brain Science and Intelligence Technology, Institute of Psychology, Chinese Academy of Sciences</institution>, 16 Lincui Road, Beijing 100101, <country>China</country></aff>
<aff id="a2"><label>2</label><institution>Department of Psychology, University of Chinese Academy of Sciences</institution>, 19A Yuquan Road, Beijing 100049, <country>China</country></aff>
<aff id="a3"><label>3</label><institution>Chinese Institute for Brain Research</institution>, 26 Science Park Road, Beijing 102206, <country>China</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Zhang</surname>
<given-names>Xilin</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>South China Normal University</institution>
</institution-wrap>
<city>Guangzhou</city>
<country>China</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Bi</surname>
<given-names>Yanchao</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Beijing Normal University</institution>
</institution-wrap>
<city>Beijing</city>
<country>China</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>Corresponding authors: Li Wang (<email>wangli@psych.ac.cn</email>), Institute of Psychology, Chinese Academy of Sciences, 16 Lincui Road, Beijing 100101, China</corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2023-08-31">
<day>31</day>
<month>08</month>
<year>2023</year>
</pub-date>
<volume>12</volume>
<elocation-id>RP89873</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-06-16">
<day>16</day>
<month>06</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-07-19">
<day>19</day>
<month>07</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.07.18.549471"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2023, Yuan et al</copyright-statement>
<copyright-year>2023</copyright-year>
<copyright-holder>Yuan et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-89873-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Perceiving emotions from the movements of other biological entities is critical for human survival and interpersonal interactions. Here, we report that emotional information conveyed by point-light biological motion (BM) triggered automatic physiological responses as reflected in pupil size. Specifically, happy BM evoked larger pupil size than neutral and sad BM, while sad BM induced a smaller pupil response than neutral BM. Moreover, this happy over sad pupil dilation effect is negatively correlated with individual autistic traits. Notably, emotional BM with only local motion features retained could also exert modulations on pupils. Compared with intact BM, both happy and sad local BM evoked stronger pupil responses than neutral local BM starting from an earlier timepoint, with no difference between the happy and sad conditions. These results revealed a fine-grained pupil-related emotional modulation induced by intact BM and a coarse but rapid modulation by local BM, demonstrating multi-level processing of emotions in life motion signals. Taken together, our findings shed new light on the mechanisms underlying BM emotion processing, and highlight the potential of utilizing the emotion-modulated pupil response to facilitate the diagnosis of social cognitive disorders.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Key words</title>
<kwd>pupil size</kwd>
<kwd>biological motion</kwd>
<kwd>emotion processing</kwd>
<kwd>local</kwd>
</kwd-group>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="external-links">
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.57760/sciencedb.psych.00125">https://doi.org/10.57760/sciencedb.psych.00125</ext-link>
</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Perceiving and interpreting emotions from various social signals is critical for human social functioning, which enables us to infer the intentions of our conspecifics and further facilitates interpersonal interactions. Facial expressions present the most common non-verbal social communicative signals regarding others’ affective states and intentions (<xref ref-type="bibr" rid="c20">Frith, 2009</xref>). In addition to faces, the movements of biological organisms serve as another essential type of social signals carrying significant emotional information, and this information remained salient even from a far distance (<xref ref-type="bibr" rid="c14">de Gelder, 2006</xref>). The human visual system is highly sensitive to such signals that we can readily decipher emotions from biological motion (BM), even when it was portrayed by several point lights attached to the major joints (<xref ref-type="bibr" rid="c26">Johansson, 1973</xref>; <xref ref-type="bibr" rid="c48">Troje, 2008</xref>). Moreover, it has been found that happy point-light walkers were recognized faster and more accurately than sad, angry or neutral walkers, demonstrating a happiness superiority (<xref ref-type="bibr" rid="c34">Lee &amp; Kim, 2016</xref>; <xref ref-type="bibr" rid="c47">Spencer et al., 2016</xref>). While these studies provided some insights into the emotion processing mechanism of BM, they relied mainly on the explicit identification and active evaluation of BM emotions. Importantly, the encoding of emotional information also involved a rather automatic and implicit process that is independent of the participant’s explicit identifications (<xref ref-type="bibr" rid="c12">Critchley et al., 2000</xref>; <xref ref-type="bibr" rid="c33">Lange et al., 2003</xref>; <xref ref-type="bibr" rid="c39">Okon-Singer et al., 2013</xref>; <xref ref-type="bibr" rid="c46">Shafer et al., 2012</xref>). Notably, this implicit aspect of emotion processing could be even more effective in probing individual differences and social deficits (<xref ref-type="bibr" rid="c29">Kana et al., 2015</xref>; <xref ref-type="bibr" rid="c30">Keifer et al., 2020</xref>; <xref ref-type="bibr" rid="c32">Kovarski et al., 2018</xref>; <xref ref-type="bibr" rid="c54">Wong et al., 2008</xref>), as it requires the intuitive processing of emotions that could not be learned (U. <xref ref-type="bibr" rid="c21">Frith, 2004</xref>). For example, research has shown that individuals with autistic disorders showed altered neural activities during implicit but not explicit emotion processing of natural scenes (<xref ref-type="bibr" rid="c29">Kana et al., 2015</xref>). These observations highlighted the importance of using objective measurements to investigate the implicit and automatic aspect of BM emotion processing.</p>
<p>The pupil response hence serves as a promising approach for reliably unfolding the implicit emotion processing of BM as it adds no extra task requirements to the cognitive process (<xref ref-type="bibr" rid="c8">Burley et al., 2017</xref>). In particular, pupil size is related to the activity of the automatic nervous system mediated by the locus coeruleus norepinephrine (LC-NE), which not only responds to physical light, but also reflects the underlying cognitive state (<xref ref-type="bibr" rid="c28">Joshi &amp; Gold, 2019</xref>). Moreover, it could spontaneously capture the current subjective state and is thus useful for revealing the time course of the related cognitive processing (<xref ref-type="bibr" rid="c13">de Gee et al., 2014</xref>; <xref ref-type="bibr" rid="c23">Graves et al., 2021</xref>; <xref ref-type="bibr" rid="c31">Kloosterman et al., 2015</xref>; <xref ref-type="bibr" rid="c40">Oliva &amp; Anikin, 2018</xref>). Recently, this measurement has been introduced to the field of emotion perception, and emerging evidence has suggested that emotions conveyed by social signals (e.g., faces, voices) could modulate pupil responses. For instance, happy and angry dynamic faces elicited a pupil dilation effect as compared with sad and neutral faces (<xref ref-type="bibr" rid="c7">Burley &amp; Daughters, 2020</xref>; <xref ref-type="bibr" rid="c44">Prunty et al., 2021</xref>). Noticeably, the point-light BM, as another critical type of social signals, also conveyed salient affective information. Besides, its emotion processing mechanism is closely connected with that of faces (<xref ref-type="bibr" rid="c2">Alaerts et al., 2011</xref>; <xref ref-type="bibr" rid="c5">Becker et al., 2011</xref>; <xref ref-type="bibr" rid="c34">Lee &amp; Kim, 2016</xref>). However, it remains unequivocal whether the pupil also responds to the emotional information carried by the minimalistic point-light walker display. Such physiological observation can faithfully uncover the implicit emotion processing mechanism of BM, and it also expands the existing line of inquiry on the emotion processing of social cues.</p>
<p>To fill this gap, the current study implemented the pupil recording technique together with the passive viewing paradigm to explore the automatic and implicit emotion processing mechanism of BM. We first investigated the pupil responses to point-light walkers with different emotions (i.e., happy, sad and neutral). In addition to intact emotional BM sequences, we also tested scrambled emotional BM sequences, which lack the gestalt of a global figure but preserve the same local motion components as the intact walkers. Recent studies have shown that such local motion signals play an essential role in conveying biologically salient information such as animacy, walking direction (Chang &amp; <xref ref-type="bibr" rid="c48">Troje, 2008</xref>, 2009; <xref ref-type="bibr" rid="c49">Troje &amp; Westhoff, 2006</xref>). This study went further to investigate whether this local BM signal could convey emotional information and elicit corresponding pupil responses. Moreover, given that emotion perception from social signals is generally impaired in individuals with autism (<xref ref-type="bibr" rid="c24">Harms et al., 2010</xref>; <xref ref-type="bibr" rid="c25">Hubert et al., 2006</xref>), we also took the individual autistic traits into consideration by measuring the autistic tendencies in normal populations with the Autistic Quotient (AQ) questionnaire (<xref ref-type="bibr" rid="c4">Baron-Cohen et al., 2001</xref>).</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Experiment 1: Intact emotional BM</title>
<p>In Experiment 1, we investigated whether emotional BM could exert influences on pupil responses. A one-way repeated measures ANOVA was conducted on the mean pupil size for each emotional condition (happy, sad, neutral) obtained by collapsing the pupillometry across all time points. The results showed a significant main effect of emotional condition (<italic>F</italic>(1.4, 32.2) = 8.93, <italic>p</italic> = .002, <inline-formula><alternatives><inline-graphic xlink:href="549471v1_inline1a.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> = 0.28; Greenhouse-Geisser corrected, <xref rid="fig1" ref-type="fig">Fig.1A</xref>). On average, the happy BM induced a significantly larger pupil response than the neutral BM (<italic>t</italic>(23) = 2.73 <italic>p</italic> = .024, Cohen’s <italic>d</italic> = 0.56, 95% CI for the mean difference = [0.037, 0.266]; Holm-corrected, <xref rid="fig1" ref-type="fig">Fig.1A</xref>). In contrast, the sad BM evoked a significantly smaller pupil size than the neutral BM (sad vs. neutral: <italic>t</italic>(23) = - 2.43, <italic>p</italic> = .024, Cohen’s <italic>d</italic> = 0.50, 95% CI for the mean difference = [-0.35, -0.03]; Holm-corrected, <xref rid="fig1" ref-type="fig">Fig.1A</xref>). Moreover, the happy BM evoked a significantly larger pupil size than the sad BM (<italic>t</italic>(23) = 3.34, <italic>p</italic> = .009, Cohen’s <italic>d</italic> = 0.68, 95% confidence interval (CI) for the mean difference = [0.13, 0.55]; Holm-corrected, <xref rid="fig1" ref-type="fig">Fig.1A</xref>), which echoes with former studies showing a happiness advantage in BM processing (<xref ref-type="bibr" rid="c1">Actis-Grosso et al., 2015</xref>; <xref ref-type="bibr" rid="c34">Lee &amp; Kim, 2016</xref>; <xref ref-type="bibr" rid="c47">Spencer et al., 2016</xref>; <xref ref-type="bibr" rid="c56">Yuan et al., 2023</xref>). Importantly, the observed happy over sad dilation effect is negatively correlated with the individual autistic traits (<italic>r</italic>(23) = -0.47, <italic>p</italic> = .022, 95% CI for the mean difference = [-0.73, -0.08], <xref rid="fig1" ref-type="fig">Fig.1B</xref>), indicating a compromised ability to perceive emotions from BM among individuals with higher autism tendencies. The results of the cluster-based permutation analysis showed that the happy BM induced a significant pupil dilation effect than the neutral BM from 1750 ms to 3200 ms (see <xref rid="fig2" ref-type="fig">Fig. 2A</xref>). Conversely, the sad BM evoked a significantly smaller pupil response than the neutral BM, which starts from 1900 ms until the end of the stimulus presentation (see <xref rid="fig2" ref-type="fig">Fig. 2A</xref>). Notably, the happy BM evoked a significantly larger pupil response as compared to the sad BM in a longstanding time window, ranging from 1200 ms until the disappearance of the display (see <xref rid="fig2" ref-type="fig">Fig. 2A</xref>). These results together demonstrated a pupil dilation effect caused by happy information embedded in the minimized point-light walker, reflecting that emotional BM can modulate pupil responses. Moreover, the happy and sad BM exerted differential modulation on the pupil responses: the happy BM evoked a larger pupil response than the neutral BM, while the sad BM evoked smaller pupil size as compared to the neutral one.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Fig. 1.</label>
<caption><p>Normalized mean pupil responses using the neutral condition as baseline, plotted against happy and sad conditions, and the relevant correlation. (A) In Experiment 1, the group average pupil response to happy intact BM is significantly larger than that to sad and neutral BM, while the pupil size induced by sad BM is significantly smaller than that evoked by neutral BM. (B) Moreover, a significant negative correlation was found between the happy over sad pupil dilation effect and individual autistic quotient (AQ). (C) In Experiment 2, no significant differences in pupil responses were observed for inverted BM. (E) In Experiment 3, when the biological characteristic was deprived from the emotional BM, it failed to induce any modulations on pupil sizes. (D) In Experiment 4, both the happy and sad local BM induced a significantly larger pupil size than neutral local BM, with no significant difference between the happy and sad condition. Green dots in the scatter plot indicate the individual data and the shaded region indicate the 95% confidence interval. All the pupil data are in arbitrary units (a.u.). Error bars showed standard errors of the mean. * <italic>p</italic> &lt; .05, ** <italic>p</italic> &lt; .01.</p></caption>
<graphic xlink:href="549471v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="fig2" position="float" fig-type="figure">
<label>Fig. 2.</label>
<caption><p>Time course of pupil responses to happy, sad, and neutral BM in Experiments 1-4. Solid lines represent pupil diameter under each emotional condition as a function of time (happy: red; sad: blue; neutral: gray); shaded areas represent the SEM between participants; colored horizontal lines indicate periods during which there are statistically significant differences among conditions at <italic>p</italic> &lt;0.05; and black horizontal lines indicate significant differences after cluster-based permutation correction. All the pupil data are in arbitrary units (a.u.) (A) In Experiment 1, the happy BM evoked larger pupil response as compared to the sad and neutral BM, and the sad BM evoked smaller pupil size than the neutral BM. (B) In Experiment 2, the inverted BM failed to produce such emotional modulation effects. (C) In Experiment 3, the emotional BM that is deprived of the local motion feature exerted no emotional modulation on pupil responses. (D) In Experiment 4, both the happy and sad local BM induced a larger pupil response than the neutral local BM, and such dilation effect started from a relatively early time point.</p></caption>
<graphic xlink:href="549471v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2b">
<title>Experiment 2: Inverted emotional BM</title>
<p>To rule out the possibility that the difference in low-level visual features rather than the emotional information per se might account for the obtained emotional modulation effect, we presented observers with the inverted BM stimuli that shared the exact perceptual features with their upright counterparts in Experiment 2. An identical one-way repeated measures ANOVA was conducted, while no significant main effect of emotional condition on pupil responses was observed in inverted BM (<italic>F</italic>(2, 46) = 0.95, <italic>p</italic> = .396, <inline-formula><alternatives><inline-graphic xlink:href="549471v1_inline3.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> = 0.04, <xref rid="fig1" ref-type="fig">Fig. 1C</xref>, <xref rid="fig2" ref-type="fig">Fig. 2B</xref>). Besides, the cluster-based permutation analysis also observed no significantly different time points among different emotional conditions. Critically, the mixed 2 (orientation: upright, inverted) × 3 (emotional condition: happy, sad, neutral) ANOVA on the average pupil size obtained in Experiment 1 and Experiment 2 showed a significant interaction between orientation and emotional condition (<italic>F</italic>(2, 92) = 4.53, <italic>p</italic> = .013, <inline-formula><alternatives><inline-graphic xlink:href="549471v1_inline4.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> = 0.09). This further indicated that the observed emotional modulation on pupil responses did not arise from low-level visual differences.</p>
</sec>
<sec id="s2c">
<title>Experiment 3: Nonbiological Motion</title>
<p>Given the ample evidence showing that local motion feature is essential for the perception of biologically significant information from BM (Chang &amp; <xref ref-type="bibr" rid="c48">Troje, 2008</xref>, 2009; <xref ref-type="bibr" rid="c49">Troje &amp; Westhoff, 2006</xref>; <xref ref-type="bibr" rid="c51">Wang &amp; Jiang, 2012</xref>), we moved forward to explore the role of local motion feature in the emotion processing of BM. In Experiment 3, we presented observers with non-BM stimuli, which were derived from the fragments identical to emotional BM but with critical local characteristic removed (<xref ref-type="bibr" rid="c10">Chang &amp; Troje, 2009</xref>). Results of the one-way repeated ANOVA on average pupil size showed no significant main effect of emotional condition (<italic>F</italic>(1.6, 35.7) = 0.02, <italic>p</italic> = .964, <inline-formula><alternatives><inline-graphic xlink:href="549471v1_inline1.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>; Greenhouse-Geisser corrected). Besides, the permutation analysis also found no significantly different time points in pupil responses to the happy, sad, and neutral conditions (see <xref rid="fig1" ref-type="fig">Fig. 1D</xref>, <xref rid="fig2" ref-type="fig">Fig. 2C</xref>). Moreover, combining the results obtained from Experiment 1 and Experiment 3, we found a significant interaction between stimulus type (upright, non-biological) and emotional condition (happy, sad, neutral) (<italic>F</italic>(2, 92) = 7.38, <italic>p</italic> = .001, <inline-formula><alternatives><inline-graphic xlink:href="549471v1_inline2.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>). These findings together showed that the removal of local characteristic greatly disrupted the emotional modulations on observers’ pupil responses, providing conceivable evidence for the critical contribution of local motion feature in emotion perception from the BM signal.</p>
</sec>
<sec id="s2d">
<title>Experiment 4: Local emotional BM</title>
<p>In Experiment 4, we went further to examine whether local BM alone could carry emotional information and exert a similar modulation effect on pupil size. In particular, we adopted the well-established local BM stimuli, the scrambled BM, whose local motion feature was retained while the global configuration information was completely disrupted. Both the explicit and implicit emotion processing of the scrambled BM were investigated to provide a thorough view of emotion perception from local BM. Specifically, a group of observers viewed the scrambled BM and made explicit behavioral judgments on the emotional information contained in scrambled BM. The results showed that observers could successfully recognize the emotions contained in scrambled BMs with the average accuracy reaching significantly above 50% (M ± SD = 83% ± 2.8%, <italic>p</italic> &lt; .001). This indicated that scrambled BM conveyed recognizable emotional information.</p>
<p>Furthermore, we investigated the pupil responses to scrambled happy, sad, and neutral BMs to explore the automatic and implicit processing of local emotional BM. The one-way repeated measures ANOVA on the mean pupil size indicated a significant main effect of emotional condition (<italic>F</italic>(2, 46) = 6.52, <italic>p</italic> = .003, <inline-formula><alternatives><inline-graphic xlink:href="549471v1_inline5.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, <xref rid="fig1" ref-type="fig">Fig. 1E</xref>). Follow-up analysis showed that the scrambled happy BM induced a significantly larger pupil response than the scrambled neutral BM (<italic>t</italic>(23) = 3.26, <italic>p</italic> = .008, Cohen’s <italic>d</italic> = 0.68, 95% CI for the mean difference = [0.14, 0.59]; Holm-corrected, <xref rid="fig1" ref-type="fig">Fig. 1E</xref>), which is similar to that observed in Experiment 1. Notably, the scrambled sad BM also induced a larger pupil size than the neutral one (<italic>t</italic>(23) = 3.35, <italic>p</italic> = .008, Cohen’s <italic>d</italic> = 0.67, 95% CI for the mean difference = [0.14, 0.59]; Holm-corrected, <xref rid="fig1" ref-type="fig">Fig. 1E</xref>). Moreover, no difference in pupil size is observed between the happy and sad conditions (<italic>t</italic>(23) = -0.20, <italic>p</italic> = .842, Cohen’s <italic>d</italic> = 0.04, 95% CI for the mean difference = [-0.28, 0.23]; Holm-corrected, <xref rid="fig1" ref-type="fig">Fig. 1E</xref>). The consecutive cluster-based permutation analysis further showed that both the scrambled happy and sad BM evoked larger pupil size than the scrambled neutral BM. Importantly, such effect appeared in a rather early time window and could last for a quite long time (happy vs. neutral: 450 ms -3550 ms; sad vs. neutral: 350 ms-4000 ms, see <xref rid="fig2" ref-type="fig">Fig. 2D</xref>). The observed effect could not be accounted for by perceptual differences (e.g., speed), as the happy and sad scrambled BM differed the most in low-level features, whereas they induced similar dilation effects on pupil sizes. An additional mixed 2 (BM type: intact, scrambled) × 3 (emotional condition: happy, sad, neutral) ANOVA on average pupil size was conducted to examine whether or not this emotional modulation effect of local BM varied from that of intact BM reported in Experiment 1. Results revealed a significant interaction between BM type and emotional condition (<italic>F</italic>(2, 92) = 3.22, <italic>p</italic> = .045, <inline-formula><alternatives><inline-graphic xlink:href="549471v1_inline6.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> = 0.07), indicating that emotions in intact and local BM exerted differential modulations on pupil size. Overall, these findings showed that the local BM could convey significant emotional information, which could induce a pupil dilation effect regardless of its exact type. As compared to the intact BM, the emotional modulation observed in local BM is different because it occurred faster and is rather coarse.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Life motion signals convey salient emotional information that is crucial for human survival and social interactions (<xref ref-type="bibr" rid="c26">Johansson, 1973</xref>; <xref ref-type="bibr" rid="c48">Troje, 2008</xref>). Here, we reported that such emotional clues carried by the point-light BM walker could exert a modulation effect on pupil responses. Specifically, the happy BM significantly dilated pupils as compared to the neutral BM, and the sad BM evoked smaller pupil responses than the neutral BM, showing distinct emotional modulations on pupil responses which depend on the emotional contents. Moreover, this emotional modulation of pupil responses could not be explained by the low-level differences, as viewing inverted BMs failed to induce such effects. Importantly, when the emotional BM was deprived of the local motion feature through the removal of accelerations, it failed to induce any modulation on pupil responses. Furthermore, the scrambled emotional BM with only local motion feature retained could still produce a modulation effect on pupil size. Noticeably, this modulation is rapid but rather coarse: viewing the scrambled happy and sad BM would evoke greater pupil size than the scrambled neutral BM in a relatively early time window, while no significant difference was observed between the scrambled happy and sad BM. Taken together, these findings revealed multi-level processing of emotions in life motion signals: the global emotional BM modulated pupil size in a fine-grained manner that discriminates each type of emotion, and the local emotional BM exerted a coarse but rapid modulation on pupil size.</p>
<p>The emotion processing mechanisms of BM have been investigated in former studies using explicit behavioral detection and recognition paradigm. It has been reported that happy BM is more rapidly identified and detected as compared to sad and neutral BM (<xref ref-type="bibr" rid="c1">Actis-Grosso et al., 2015</xref>; <xref ref-type="bibr" rid="c34">Lee &amp; Kim, 2016</xref>; <xref ref-type="bibr" rid="c47">Spencer et al., 2016</xref>), while other research observed no such superiority (<xref ref-type="bibr" rid="c11">Chouchourelou et al., 2006</xref>). Here, the present study adopted the novel and objective pupillometry index to investigate the emotion processing mechanisms of BM from a physiological aspect. The pupil index, as a direct reflection of individual arousal level and cognitive state, served as a powerful tool for faithfully and automatically reflecting the implicit emotion processing mechanism of BM. Our results showed a significant pupil dilation effect for happy over sad and neutral BM, showing a happiness superiority that could occur during the implicit emotion processing of BM. This finding resonates well with the happiness superiority reported in the explicit emotion processing of BM (<xref ref-type="bibr" rid="c34">Lee &amp; Kim, 2016</xref>; <xref ref-type="bibr" rid="c47">Spencer et al., 2016</xref>; <xref ref-type="bibr" rid="c56">Yuan et al., 2023</xref>). More importantly, it provided a physiological account for the happiness superiority by demonstrating that happy BM evoked a more heightened state in the automatic nervous system than sad and neutral BM. The activity of this system has long been associated with the level of attention engagement into related cognitive processes (<xref ref-type="bibr" rid="c15">Eckstein et al., 2017</xref>; <xref ref-type="bibr" rid="c17">Eldar et al., 2013</xref>). Hence, our findings suggest that happy BM may be more effective in capturing attention as compared to neutral BM, while sad BM could be less efficient than neutral BM. This observation parallels with a previous study, which demonstrated that infants looked more at the happy BM walker when displayed in pair with the neutral walker, whereas they attended less to the sad walker as compared to the neutral one (<xref ref-type="bibr" rid="c38">Ogren et al., 2019</xref>). Notably, the happy over sad dilation effect was negatively correlated with autistic traits: individuals with greater autistic tendencies showed decreased sensitivities to emotions in BM. Given that pupil measurement does not require any explicit verbal reports, it is easily attainable in children and even infants. Thus, the pupil dilation effect obtained here may serve as a sensitive and reliable physiological marker for detecting early social cognitive disorders.</p>
<p>Remarkably, our findings highlighted the central role of local motion feature in modulating pupil responses towards emotional information contained in BM. Previous studies have shown that human visual system is highly sensitive to the local BM stimulus, whose global configural information is completely deprived through spatially scrambling (<xref ref-type="bibr" rid="c49">Troje &amp; Westhoff, 2006</xref>). For example, it has been demonstrated that scrambled BM could perform as intact BM in lengthening subjective temporal perception (<xref ref-type="bibr" rid="c51">Wang &amp; Jiang, 2012</xref>). Besides, such local motion feature also served as a basic pre-attentive feature in visual search (<xref ref-type="bibr" rid="c53">Wang et al., 2010</xref>) and could further induce a significant reflexive attentional effect (<xref ref-type="bibr" rid="c52">Wang et al., 2014</xref>; <xref ref-type="bibr" rid="c55">Yu et al., 2020</xref>). Moreover, the deprivation of the local BM feature would greatly disrupt the perception of the contained biologically salient information, such as animacy and walking direction (<xref rid="c9" ref-type="bibr">Chang &amp; Troje, 2008</xref>, 2009; <xref ref-type="bibr" rid="c55">Yu et al., 2020</xref>). Here, we extended this line of research to the emotional domain by demonstrating that the local BM component is also critical for the processing of emotional information: when the local BM feature is disrupted, the modulation of emotions on pupil size completely disappeared. Furthermore, the emotional BM that retained only local motion features could still exert a salient modulation effect on pupil size. In particular, the happy and sad local BM induced a significant pupil dilation effect as compared to the neutral local BM stimuli. Intriguingly, this dilation effect is independent of the specific emotion category but reflects a general activation caused by the affective salient information. In addition, this non-selective pupil dilation effect in local BM appeared in a relatively early time window, indicating that the extraction of emotions from local BM is rapid. Taken together, these findings identified a coarse but rapid emotion processing mechanism in local BM that could promptly detect the emotional information therein without the aid of the global shape.</p>
<p>Notably, our findings revealed the existence of distinct emotional modulations in intact and local BM, respectively, as evidenced by variations in pupil responses. In particular, the intact emotional point-light walker exerted a relatively late but fine-grained modulation on pupil responses, while the local BM induced a quick but non-selective emotional modulation on pupil sizes. The dissociated emotion processing mechanisms could be well understood regarding its analogous function to another important type of emotional signal (i.e., facial expression). Specifically, it has been argued that there exist two parallel pathways for facial expression processing: a slow route that conveys fine-grained facial features along cortical areas to the amygdala, and a rapid subcortical pathway that directly transfers emotional information to amygdala without detailed analysis, which is known as the “quick and dirty” route (<xref ref-type="bibr" rid="c22">Garrido et al., 2012</xref>; <xref ref-type="bibr" rid="c27">Johnson, 2005</xref>; <xref ref-type="bibr" rid="c35">Méndez-Bértolo et al., 2016</xref>; <xref ref-type="bibr" rid="c50">Vuilleumier et al., 2003</xref>). It is probable that the emotion processing of the local and intact point-light BM potentially functions in a manner similar to that of the faces, with the former serving as a rapid detection mechanism that automatically captures emotionally significant information conveyed by animate agents without detailed analysis and the latter aiding in more specific emotion identification based on fine-grained analyses of their motion pattern and global shape. Compatible with this view, recent studies have reported that the emotion processing of face and BM was very similar. For example, they both showed a happiness superiority in visual detection (<xref ref-type="bibr" rid="c5">Becker et al., 2011</xref>; <xref ref-type="bibr" rid="c34">Lee &amp; Kim, 2016</xref>; <xref ref-type="bibr" rid="c36">Nackaerts et al., 2012</xref>) and guiding social attention (<xref ref-type="bibr" rid="c56">Yuan et al., 2023</xref>). Moreover, their emotion processing involved potentially overlapping brain regions (e.g., amygdala, STS) (<xref ref-type="bibr" rid="c3">Alaerts et al., 2014</xref>; <xref ref-type="bibr" rid="c18">Engell &amp; Haxby, 2007</xref>; <xref ref-type="bibr" rid="c41">Peelen et al., 2007</xref>; <xref ref-type="bibr" rid="c43">Pessoa &amp; Adolphs, 2010</xref>). Overall, our findings, together with the former evidence, suggest dissociated emotion processing mechanisms for BM in the human brain akin to the dual-route model reported in faces, and further imply a general “emotional brain” that can be shared by different types of social signals. Still, future studies are needed to implement the neuroimaging techniques to directly identify the brain regions involved in the emotion processing of local and global BM signals.</p>
<p>To conclude, the current study clearly demonstrated that the emotional information conveyed by point-light BM modulated pupil responses. The intact BM exerted a fine-grained emotional modulation on pupil sizes, while disrupting the contained local motion characteristic would deteriorate the observed modulations. Moreover, BM with only local motion features retained could exert a fast but rather coarse modulation on pupillometry. These findings together highlight the critical role of local motion feature in BM emotion processing, and further reveal the multi-level mechanisms subserving emotion processing of BM. Notably, the observed emotional modulation in intact BM is associated with individual autistic traits, suggesting the potential of utilizing the emotion-modulated pupil responses to facilitate the diagnosis of social cognitive disorders.</p>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Participants</title>
<p>A total of 120 participants (44 males, 76 females) ranging from 18 to 29 years old (M ± SD = 23.1 ± 2.5) were recruited, with 24 in each experiment. All of the participants had normal or corrected-to-normal vision and gave written informed consent in accordance with the procedure and protocols approved by the institutional review board of the Institute of Psychology, Chinese Academy of Sciences. They were all naïve to the purpose of the experiments. Prior power analyses (<italic>F</italic> tests, repeated measures, within factors) using G*Power (Version 3.1.9.4; (<xref ref-type="bibr" rid="c19">Faul et al., 2007</xref>)) indicated that a sample size of 24 participants would afford 80% power with alpha at .05 to detect a moderate main effect (<italic>f</italic> = 0.27). This sample size was comparable to previous studies with similar designs (<xref ref-type="bibr" rid="c37">Nakakoga et al., 2020</xref>).</p>
</sec>
<sec id="s4b">
<title>Stimuli</title>
<p>Stimuli were displayed using MATLAB (Mathworks, Inc.) together with the Psychtoolbox extensions (<xref ref-type="bibr" rid="c6">Brainard, 1997</xref>; <xref ref-type="bibr" rid="c42">Pelli, 1997</xref>) on a 23-inch LED monitor (1920 × 1080 at 60 Hz) with gray background (RGB: 100, 100, 100). The biological motion (BM) stimuli were adopted from Troje (<xref ref-type="bibr" rid="c48">Troje, 2008</xref>). Each comprised 15 point-light dots depicting the motions of the head, pelvis, thorax and major joints (i.e., shoulders, elbows, wrists, hips, knees, and ankles). Its emotional state was indexed by a normalized Z score on an axis that reflects the differences between happy and sad walkers in terms of a linear classifier. The scores were computed within a 10-dimensional sub-space spanned by the first 10 principal components based on a Fourier-based representation of observers’ emotional ratings of 80 actual walkers (half male) (<xref ref-type="bibr" rid="c48">Troje, 2008</xref>). We adopted the neutral walker that scored 0 on the linear axis, together with the happy walker 6 SDs into the happy part of the axis and the sad walker 6 SDs into the sad part of the axis (see <ext-link ext-link-type="uri" xlink:href="https://www.biomotionlab.ca/html5-bml-walker/">https://www.biomotionlab.ca/html5-bml-walker/</ext-link> for an interactive animation). Besides, we turned the BM walkers 45 degrees leftwards or rightwards to maximize the visibility of expressive bodily cues (<xref ref-type="bibr" rid="c45">Roether et al., 2009</xref>). In Experiment 1, the upright emotional (happy, sad, or neutral) BM walkers with two walking directions (45°leftwards or rightwards) were used. In Experiment 2, the stimuli were replaced with their inverted counterparts created by mirror flipping the upright BM vertically. In Experiment 3, we presented observers with the non-biological motion stimuli whose local BM characteristic was disrupted through acceleration removal. More specifically, each individual dot moved along the original path with a constant speed equal to the average speed of the dot (<xref ref-type="bibr" rid="c10">Chang &amp; Troje, 2009</xref>). Such manipulation disrupted the local motion feature of the BM stimuli but kept the trajectories of individual point lights unchanged. In Experiment 4, observers viewed the scrambled BM stimuli, which were created by randomly relocating the point light dots within the region occupied by the original BM walker. In this manner, the local motion feature was preserved while the global configuration of the BM stimulus was entirely disrupted (<xref ref-type="bibr" rid="c49">Troje &amp; Westhoff, 2006</xref>). Please refer to Supplementary Materials for the demostrations displaying the motion stimuli used in Experiments 1-4.</p>
</sec>
<sec id="s4c">
<title>Procedure</title>
<p>Participants were seated at a viewing distance of 60 cm to the computer screen with their heads on a chinrest to minimize their head movements. Their pupil size and eye position of the left eye were recorded using a video-based iView X Hi-Speed system (SMI, Berlin, Germany) at 500 Hz. Each trial began with a central fixation cross (0.2° × 0.2°) with variable duration (800-1200 ms), followed by a happy/sad/neutral point-light walker (half leftwards and half rightwards) presented centrally for 4000 ms. Participants were required to passively view the BM stimulus and continued the procedure by pressing the space bar. After that, a blank screen was displayed for 3000 ms (<xref rid="fig3" ref-type="fig">Fig. 3</xref>). There were 4 blocks of 30 trials, and participants were given a short break after every block. Besides, we also administered a 9-point calibration of the eye-tracker followed by a validation stage before each experimental block to ensure the data quality. Participants were told to maintain fixation on the center of the screen and not to blink during the stimuli presentation. The experimental procedure of Experiment 2 is identical to Experiment 1, except that the BM stimuli were changed to their inverted counterparts. In Experiment 3, we instead presented participants with the non-biological motion displays whose local motion feature was deprived through acceleration removal. In Experiment 4, we adopted the scrambled emotional BM stimuli, and investigated both the explicit and the implicit emotion processing of scrambled BM. Specifically, a group of participants was recruited to make emotional judgements on the scrambled BM in order to investigate whether the emotional information carried by local BM signals could be explicitly identified. Another group of participants was enrolled for the pupil recording experiment, which followed the identical experimental procedure of Experiments 1-3. At the end of all experiments, participants were required to complete the 50-point Autism-spectrum Questionnaire (AQ), which measured the degree of autistic traits in the normal population (<xref ref-type="bibr" rid="c4">Baron-Cohen et al., 2001</xref>).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Fig. 3.</label>
<caption><p>Schematic representation of the experimental procedure and the stimuli in Experiment 1. A happy/sad/neutral BM walker turning 45 degrees leftwards or rightwards was presented at the center of the screen for 4000 ms. Participants were instructed to maintain their fixation on the BM stimuli during stimulus presentation and to continue the procedure through key pressing.</p></caption>
<graphic xlink:href="549471v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s4d">
<title>Data Analysis</title>
<p>The raw pupil data for each trial was first screened to remove eye blinks (either replaced by linear interpolation or with this trial discarded). Then, trials with pupil size deviating ±3 SDs from the mean were excluded from further analysis. Finally, the pupil size data were down-sampled to 20 Hz and baseline-corrected for each trial by subtracting the mean pupil size during the 200 ms pre-stimulus period. We computed the average pupil size for each emotional condition (happy, sad, or neutral) obtained by collapsing the pupillometry across all time points. Besides, to depict the time course of pupil responses towards emotional BM, we further conducted a consecutive paired-sample <italic>t</italic>-test across all time points comparing different emotional conditions. The cluster-based permutation analysis was applied to avoid potential problems brought about by multiple comparisons (<xref ref-type="bibr" rid="c16">Einhauser et al., 2008</xref>). In this analysis, the computed <italic>t</italic>-values neighboring in time that exceeded a threshold (<italic>p</italic> &lt; 0.05) were defined as clusters, and then summed to produce a cluster mass. The cluster mass was compared with a null distribution, which was generated by 2000 random permutations of the pupil data from different conditions. If the cluster mass fell beyond 95% of the null distribution (<italic>α</italic> = 0.05), it was deemed to be statistically significantly different (<xref ref-type="bibr" rid="c16">Einhauser et al., 2008</xref>). The pupil size was analyzed and reported in arbitrary unit (a.u.) without transforming into the actual unit (mm), as the relative change of the pupil size was of main interest.</p>
</sec>
</sec>
<sec id="d1e821" sec-type="supplementary-material">
<title>Supporting information</title>
<supplementary-material id="d1e901">
<label>Supplementary Materials</label>
<media xlink:href="supplements/549471_file05.docx"/>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<title>Acknowledgements</title>
<p>This research was supported by grants from the Ministry of Science and Technology of China (STI2030-Major Projects 2022ZD0205100 and 2021ZD0203800), the National Natural Science Foundation of China (No. 31830037), the Strategic Priority Research Program (No. XDB32010300), the Interdisciplinary Innovation Team (JCTD-2021-06), the Science Foundation of Institute of Psychology, Chinese Academy of Sciences, and the Fundamental Research Funds for the Central Universities. We thank Professor Nikolaus F. Troje for kindly providing us with the visual stimuli. We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. This study’s design and its analysis were not pre-registered. All data, materials, and analysis code used in the current study could be accessed at Science Data Bank (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.57760/sciencedb.psych.00125">https://doi.org/10.57760/sciencedb.psych.00125</ext-link>). The authors declared no conflicts of interest with respect to the authorship or the publication of this article.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Actis-Grosso</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Bossi</surname>, <given-names>F.</given-names></string-name>, &amp; <string-name><surname>Ricciardelli</surname>, <given-names>P.</given-names></string-name> (<year>2015</year>). <article-title>Emotion recognition through static faces and moving bodies: a comparison between typically developed adults and individuals with high level of autistic traits</article-title>. <source>Frontiers in Psychology</source>, <volume>6</volume>, <fpage>1570</fpage>. <pub-id pub-id-type="doi">10.3389/fpsyg.2015.01570</pub-id></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Alaerts</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Nackaerts</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Meyns</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Swinnen</surname>, <given-names>S. P.</given-names></string-name>, &amp; <string-name><surname>Wenderoth</surname>, <given-names>N.</given-names></string-name> (<year>2011</year>). <article-title>Action and emotion recognition from point light displays: an investigation of gender differences</article-title>. <source>PLoS ONE</source>, <volume>6</volume>(<issue>6</issue>), <fpage>e20989</fpage>.</mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Alaerts</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Woolley</surname>, <given-names>D. G.</given-names></string-name>, <string-name><surname>Steyaert</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Di Martino</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Swinnen</surname>, <given-names>S. P.</given-names></string-name>, &amp; <string-name><surname>Wenderoth</surname>, <given-names>N.</given-names></string-name> (<year>2014</year>). <article-title>Underconnectivity of the superior temporal sulcus predicts emotion recognition deficits in autism</article-title>. <source>Social Cognitive and Affective Neuroscience</source>, <volume>9</volume>(<issue>10</issue>), <fpage>1589</fpage>–<lpage>1600</lpage>. <pub-id pub-id-type="doi">10.1093/scan/nst156</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="web"><string-name><surname>Baron-Cohen</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Wheelwright</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Skinner</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Martin</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Clubley</surname>, <given-names>E.</given-names></string-name> (<year>2001</year>). <article-title>The autismspectrum quotient (aq): evidence from asperger syndrome/high-functioning autism, malesand females, scientists and mathematicians</article-title>. <source>Journal of Autism and Developmental Disorders</source>. <pub-id pub-id-type="doi">10.1023/a:1005653411471</pub-id></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Becker</surname>, <given-names>D. V.</given-names></string-name>, <string-name><surname>Anderson</surname>, <given-names>U. S.</given-names></string-name>, <string-name><surname>Mortensen</surname>, <given-names>C. R.</given-names></string-name>, <string-name><surname>Neufeld</surname>, <given-names>S. L.</given-names></string-name>, &amp; <string-name><surname>Neel</surname>, <given-names>R.</given-names></string-name> (<year>2011</year>). <article-title>The face in the crowd effect unconfounded: happy faces, not angry faces, are more efficiently detected in single- and multiple-target visual search tasks</article-title>. <source>Journal of Experimental Psychology: General</source>, <volume>140</volume>(<issue>4</issue>), <fpage>637</fpage>–<lpage>659</lpage>. <pub-id pub-id-type="doi">10.1037/a0024060</pub-id></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Brainard</surname>, <given-names>D.</given-names></string-name> (<year>1997</year>). <article-title>The psychophysics toolbox</article-title>. <source>Spatial Vision</source>, <volume>10</volume>(<issue>4</issue>), <fpage>433</fpage>–<lpage>436</lpage>.</mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Burley</surname>, <given-names>D. T.</given-names></string-name>, &amp; <string-name><surname>Daughters</surname>, <given-names>K.</given-names></string-name> (<year>2020</year>). <article-title>The effect of oxytocin on pupil response to naturalistic dynamic facial expressions</article-title>. <source>Hormones and Behavior</source>, <volume>125</volume>, <fpage>104837</fpage>. <pub-id pub-id-type="doi">10.1016/j.yhbeh.2020.104837</pub-id></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Burley</surname>, <given-names>D. T.</given-names></string-name>, <string-name><surname>Gray</surname>, <given-names>N. S.</given-names></string-name>, &amp; <string-name><surname>Snowden</surname>, <given-names>R. J.</given-names></string-name> (<year>2017</year>). <article-title>As far as the eye can see: relationship between psychopathic traits and pupil response to affective stimuli</article-title>. <source>PLOS ONE</source>, <volume>12</volume>(<issue>1</issue>), <fpage>e0167436</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0167436</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Chang</surname>, <given-names>D. H. F.</given-names></string-name>, &amp; <string-name><surname>Troje</surname>, <given-names>N. F.</given-names></string-name> (<year>2008</year>). <article-title>Perception of animacy and direction from local biological motion signals</article-title>. <source>Journal of Vision</source>, <volume>8</volume>(<issue>5</issue>), <fpage>3</fpage>. <pub-id pub-id-type="doi">10.1167/8.5.3</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Chang</surname>, <given-names>D. H. F.</given-names></string-name>, &amp; <string-name><surname>Troje</surname>, <given-names>N. F.</given-names></string-name> (<year>2009</year>). <article-title>Acceleration carries the local inversion effect in biological motion perception</article-title>. <source>Journal of Vision</source>, <volume>9</volume>(<issue>1</issue>), <fpage>19</fpage>–<lpage>19</lpage>. <pub-id pub-id-type="doi">10.1167/9.1.19</pub-id></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Chouchourelou</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Matsuka</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Harber</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Shiffrar</surname>, <given-names>M.</given-names></string-name> (<year>2006</year>). <article-title>The visual analysis of emotional actions</article-title>. <source>Social Neuroscience</source>, <volume>1</volume>(<issue>1</issue>), <fpage>63</fpage>–<lpage>74</lpage>. <pub-id pub-id-type="doi">10.1080/17470910600630599</pub-id></mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Critchley</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Daly</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Phillips</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Brammer</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Bullmore</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Williams</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Van Amelsvoort</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Robertson</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>David</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Murphy</surname>, <given-names>D.</given-names></string-name> (<year>2000</year>). <article-title>Explicit and implicit neural mechanisms for processing of social information from facial expressions: a functional magnetic resonance imaging study</article-title>. <source>Human Brain Mapping</source>, <volume>9</volume>(<issue>2</issue>), <fpage>93</fpage>–<lpage>105</lpage>. <pub-id pub-id-type="doi">10.1002/(sici)1097-0193(200002)9:2&lt;93::aid-hbm4&gt;3.0.co;2-z</pub-id></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>de Gee</surname>, <given-names>J. W.</given-names></string-name>, <string-name><surname>Knapen</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Donner</surname>, <given-names>T. H.</given-names></string-name> (<year>2014</year>). <article-title>Decision-related pupil dilation reflects upcoming choice and individual bias</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>111</volume>(<issue>5</issue>), <fpage>E618</fpage>–<lpage>E625</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1317557111</pub-id></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>de Gelder</surname>, <given-names>B.</given-names></string-name> (<year>2006</year>). <article-title>Towards the neurobiology of emotional body language</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>7</volume>(<issue>3</issue>), <fpage>242</fpage>–<lpage>249</lpage>. <pub-id pub-id-type="doi">10.1038/nrn1872</pub-id></mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Eckstein</surname>, <given-names>M. K.</given-names></string-name>, <string-name><surname>Guerra-Carrillo</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Miller Singley</surname>, <given-names>A. T.</given-names></string-name>, &amp; <string-name><surname>Bunge</surname>, <given-names>S. A.</given-names></string-name> (<year>2017</year>). <article-title>Beyond eye gaze: what else can eyetracking reveal about cognition and cognitive development?</article-title> <source>Developmental Cognitive Neuroscience</source>, <volume>25</volume>, <fpage>69</fpage>–<lpage>91</lpage>. <pub-id pub-id-type="doi">10.1016/j.dcn.2016.11.001</pub-id></mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Einhauser</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Stout</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Koch</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Carter</surname>, <given-names>O.</given-names></string-name> (<year>2008</year>). <article-title>Pupil dilation reflects perceptual selection and predicts subsequent stability in perceptual rivalry</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>105</volume>(<issue>5</issue>), <fpage>1704</fpage>–<lpage>1709</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.0707727105</pub-id></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Eldar</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Cohen</surname>, <given-names>J. D.</given-names></string-name>, &amp; <string-name><surname>Niv</surname>, <given-names>Y.</given-names></string-name> (<year>2013</year>). <article-title>The effects of neural gain on attention and learning</article-title>. <source>Nature Neuroscience</source>, <volume>16</volume>(<issue>8</issue>), <fpage>1146</fpage>–<lpage>1153</lpage>. <pub-id pub-id-type="doi">10.1038/nn.3428</pub-id></mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Engell</surname>, <given-names>A. D.</given-names></string-name>, &amp; <string-name><surname>Haxby</surname>, <given-names>J. V.</given-names></string-name> (<year>2007</year>). <article-title>Facial expression and gaze-direction in human superior temporal sulcus</article-title>. <source>Neuropsychologia</source>, <volume>45</volume>(<issue>14</issue>), <fpage>3234</fpage>–<lpage>3241</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2007.06.022</pub-id></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Faul</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Erdfelder</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Lang</surname>, <given-names>A.-G.</given-names></string-name>, &amp; <string-name><surname>Buchner</surname>, <given-names>A.</given-names></string-name> (<year>2007</year>). <article-title>G*Power 3: a flexible statistical power analysis program for the social, behavioral, and biomedical sciences</article-title>. <source>Behavior Research Methods</source>, <volume>39</volume>(<issue>2</issue>), <fpage>175</fpage>–<lpage>191</lpage>. <pub-id pub-id-type="doi">10.3758/bf03193146</pub-id></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Frith</surname>, <given-names>C.</given-names></string-name> (<year>2009</year>). <article-title>Role of facial expressions in social interactions</article-title>. <source>Philosophical Transactions of the Royal Society B: Biological Sciences</source>, <volume>364</volume>(<issue>1535</issue>), <fpage>3453</fpage>–<lpage>3458</lpage>. <pub-id pub-id-type="doi">10.1098/rstb.2009.0142</pub-id></mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Frith</surname>, <given-names>U.</given-names></string-name> (<year>2004</year>). <article-title>Emanuel miller lecture: confusions and controversies about asperger syndrome</article-title>. <source>Journal of Child Psychology and Psychiatry</source>, <volume>45</volume>(<issue>4</issue>), <fpage>672</fpage>–<lpage>686</lpage>. <pub-id pub-id-type="doi">10.1111/j.1469-7610.2004.00262.x</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Garrido</surname>, <given-names>M. I.</given-names></string-name>, <string-name><surname>Barnes</surname>, <given-names>G. R.</given-names></string-name>, <string-name><surname>Sahani</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Dolan</surname>, <given-names>R. J.</given-names></string-name> (<year>2012</year>). <article-title>Functional evidence for a dual route to amygdala</article-title>. <source>Current Biology</source>, <volume>22</volume>(<issue>2</issue>), <fpage>129</fpage>–<lpage>134</lpage>. <pub-id pub-id-type="doi">10.1016/j.cu</pub-id> b.2011.11.056</mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Graves</surname>, <given-names>J. E.</given-names></string-name>, <string-name><surname>Egré</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Pressnitzer</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>de Gardelle</surname>, <given-names>V.</given-names></string-name> (<year>2021</year>). <article-title>An implicit representation of stimulus ambiguity in pupil size</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>118</volume>(<issue>48</issue>), <fpage>e2107997118</fpage>.<pub-id pub-id-type="doi">10.1073/pnas.2107997118</pub-id></mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Harms</surname>, <given-names>M. B.</given-names></string-name>, <string-name><surname>Martin</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Wallace</surname>, <given-names>G. L.</given-names></string-name> (<year>2010</year>). <article-title>Facial emotion recognition in autism spectrum disorders: a review of behavioral and neuroimaging studies</article-title>. <source>Neuropsychology Review</source>, <volume>20</volume>(<issue>3</issue>), <fpage>290</fpage>–<lpage>322</lpage>. <pub-id pub-id-type="doi">10.1007/s11065-010-9138-6</pub-id></mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Hubert</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Wicker</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Moore</surname>, <given-names>D. G.</given-names></string-name>, <string-name><surname>Monfardini</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Duverger</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Fonséca</surname>, <given-names>D. D.</given-names></string-name>, &amp; <string-name><surname>Deruelle</surname>, <given-names>C.</given-names></string-name> (<year>2006</year>). <article-title>Brief report: recognition of emotional and non-emotional biological motion in individuals with autistic spectrum disorders</article-title>. <source>Journal of Autism and Developmental Disorders</source>, <volume>37</volume>(<issue>7</issue>), <fpage>1386</fpage>–<lpage>1392</lpage>. <pub-id pub-id-type="doi">10.1007/s10803-006-0275-y</pub-id></mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>Johansson</surname>, <given-names>G.</given-names></string-name> (<year>1973</year>). <article-title>Visual perception of biological motion and a model for its analysis</article-title>. <source>Perception &amp;amp; Psychophysics</source>, <volume>14</volume>(<issue>2</issue>), <fpage>201</fpage>–<lpage>211</lpage>. <pub-id pub-id-type="doi">10.3758/bf03212378</pub-id></mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>Johnson</surname>, <given-names>M. H.</given-names></string-name> (<year>2005</year>). <article-title>Subcortical face processing</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>6</volume>(<issue>10</issue>), <fpage>766</fpage>–<lpage>774</lpage>. <pub-id pub-id-type="doi">10.1038/nrn1766</pub-id></mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><string-name><surname>Joshi</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name> (<year>2019</year>). <article-title>Pupil size as a window on neural substrates of cognition</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>24</volume>(<issue>6</issue>), <fpage>466</fpage>–<lpage>480</lpage>. <pub-id pub-id-type="doi">10.31234/osf.io/dvsme</pub-id></mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><string-name><surname>Kana</surname>, <given-names>R. K.</given-names></string-name>, <string-name><surname>Patriquin</surname>, <given-names>M. A.</given-names></string-name>, <string-name><surname>Black</surname>, <given-names>B. S.</given-names></string-name>, <string-name><surname>Channell</surname>, <given-names>M. M.</given-names></string-name>, &amp; <string-name><surname>Wicker</surname>, <given-names>B.</given-names></string-name> (<year>2015</year>). <article-title>Altered medial frontal and superior temporal response to implicit processing of emotions in autism</article-title>. <source>Autism Research</source>, <volume>9</volume>(<issue>1</issue>), <fpage>55</fpage>–<lpage>66</lpage>. <pub-id pub-id-type="doi">10.1002/aur.1496</pub-id></mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>Keifer</surname>, <given-names>C. M.</given-names></string-name>, <string-name><surname>Mikami</surname>, <given-names>A. Y.</given-names></string-name>, <string-name><surname>Morris</surname>, <given-names>J. P.</given-names></string-name>, <string-name><surname>Libsack</surname>, <given-names>E. J.</given-names></string-name>, &amp; <string-name><surname>Lerner</surname>, <given-names>M. D.</given-names></string-name> (<year>2020</year>). <article-title>Prediction of social behavior in autism spectrum disorders: explicit versus implicit social cognition</article-title>. <source>Autism</source>, <volume>24</volume>(<issue>7</issue>), <fpage>1758</fpage>–<lpage>1772</lpage>. <pub-id pub-id-type="doi">10.1177/1362361320922058</pub-id></mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>Kloosterman</surname>, <given-names>N. A.</given-names></string-name>, <string-name><surname>Meindertsma</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>van Loon</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Lamme</surname>, <given-names>V. A. F.</given-names></string-name>, <string-name><surname>Bonneh</surname>, <given-names>Y. S.</given-names></string-name>, &amp; <string-name><surname>Donner</surname>, <given-names>T. H.</given-names></string-name> (<year>2015</year>). <article-title>Pupil size tracks perceptual content and surprise</article-title>. <source>European Journal of Neuroscience</source>, <volume>41</volume>(<issue>8</issue>), <fpage>1068</fpage>–<lpage>1078</lpage>. <pub-id pub-id-type="doi">10.1111/ejn.12859</pub-id></mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><string-name><surname>Kovarski</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Mennella</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Wong</surname>, <given-names>S. M.</given-names></string-name>, <string-name><surname>Dunkley</surname>, <given-names>B. T.</given-names></string-name>, <string-name><surname>Taylor</surname>, <given-names>M. J.</given-names></string-name>, &amp; <string-name><surname>Batty</surname>, <given-names>M.</given-names></string-name> (<year>2018</year>). <article-title>Enhanced early visual responses during implicit emotional faces processing in autism spectrum disorder</article-title>. <source>Journal of Autism and Developmental Disorders</source>, <volume>49</volume>(<issue>3</issue>), <fpage>871</fpage>–<lpage>886</lpage>. <pub-id pub-id-type="doi">10.1007/s10803-018-3787-3</pub-id></mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><string-name><surname>Lange</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Williams</surname>, <given-names>L. M.</given-names></string-name>, <string-name><surname>Young</surname>, <given-names>A. W.</given-names></string-name>, <string-name><surname>Bullmore</surname>, <given-names>E. T.</given-names></string-name>, <string-name><surname>Brammer</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Williams</surname>, <given-names>S. C. R.</given-names></string-name>, <string-name><surname>Gray</surname>, <given-names>J. A.</given-names></string-name>, &amp; <string-name><surname>Phillips</surname>, <given-names>M. L.</given-names></string-name> (<year>2003</year>). <article-title>Task instructions modulate neural responses to fearful facial expressions</article-title>. <source>Biological Psychiatry</source>, <volume>53</volume>(<issue>3</issue>), <fpage>226</fpage>–<lpage>232</lpage>. <pub-id pub-id-type="doi">10.1016/s0006-3223(02)01455-5</pub-id></mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Lee</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Kim</surname>, <given-names>J.</given-names></string-name> (<year>2016</year>). <article-title>Facilitating effects of emotion on the perception of biological motion: evidence for a happiness superiority effect</article-title>. <source>Perception</source>, <volume>46</volume>(<issue>6</issue>), <fpage>679</fpage>–<lpage>697</lpage>. <pub-id pub-id-type="doi">10.1177/0301006616681809</pub-id></mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>Méndez-Bértolo</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Moratti</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Toledano</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Lopez-Sosa</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Martínez-Alvarez</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Mah</surname>, <given-names>Y. H.</given-names></string-name>, <string-name><surname>Vuilleumier</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Gil-Nagel</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Strange</surname>, <given-names>B. A.</given-names></string-name> (<year>2016</year>). <article-title>A fast pathway for fear in human amygdala</article-title>. <source>Nature Neuroscience</source>, <volume>19</volume>(<issue>8</issue>), <fpage>1041</fpage>–<lpage>1049</lpage>. <pub-id pub-id-type="doi">10.1038/nn.4324</pub-id></mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><string-name><surname>Nackaerts</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Wagemans</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Helsen</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Swinnen</surname>, <given-names>S. P.</given-names></string-name>, <string-name><surname>Wenderoth</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Alaerts</surname>, <given-names>K.</given-names></string-name> (<year>2012</year>). <article-title>Recognizing biological motion and emotions from point-light displays in autism spectrum disorders</article-title>. <source>PLoS ONE</source>, <volume>7</volume>(<issue>9</issue>), <fpage>e44473</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0044473</pub-id></mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><string-name><surname>Nakakoga</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Higashi</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Muramatsu</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Nakauchi</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Minami</surname>, <given-names>T.</given-names></string-name> (<year>2020</year>). <article-title>Asymmetrical characteristics of emotional responses to pictures and sounds: evidence from pupillometry</article-title>. <source>PLOS ONE</source>, <volume>15</volume>(<issue>4</issue>), <fpage>e0230775</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0230775</pub-id></mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><string-name><surname>Ogren</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Kaplan</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Peng</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Johnson</surname>, <given-names>K. L.</given-names></string-name>, &amp; <string-name><surname>Johnson</surname>, <given-names>S. P.</given-names></string-name> (<year>2019</year>). <article-title>Motion or emotion: infants discriminate emotional biological motion based on low-level visual information</article-title>. <source>Infant Behavior and Development</source>, <volume>57</volume>, <fpage>101324</fpage>. <pub-id pub-id-type="doi">10.1016/j.infbeh.2019.04.006</pub-id></mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><string-name><surname>Okon-Singer</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Lichtenstein-Vidne</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>Cohen</surname>, <given-names>N.</given-names></string-name> (<year>2013</year>). <article-title>Dynamic modulation of emotional processing</article-title>. <source>Biological Psychology</source>, <volume>92</volume>(<issue>3</issue>), <fpage>480</fpage>–<lpage>491</lpage>. <pub-id pub-id-type="doi">10.1016/j.biopsycho.2012.05.010</pub-id></mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><string-name><surname>Oliva</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Anikin</surname>, <given-names>A.</given-names></string-name> (<year>2018</year>). <article-title>Pupil dilation reflects the time course of emotion recognition in human vocalizations</article-title>. <source>Scientific Reports</source>, <volume>8</volume>(<issue>1</issue>), <fpage>4871</fpage>. <pub-id pub-id-type="doi">10.1038/s41598-018-23265-x</pub-id></mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><string-name><surname>Peelen</surname>, <given-names>M. V.</given-names></string-name>, <string-name><surname>Atkinson</surname>, <given-names>A. P.</given-names></string-name>, <string-name><surname>Andersson</surname>, <given-names>F.</given-names></string-name>, &amp; <string-name><surname>Vuilleumier</surname>, <given-names>P.</given-names></string-name> (<year>2007</year>). <article-title>Emotional modulation of body-selective visual areas</article-title>. <source>Social Cognitive and Affective Neuroscience</source>, <volume>2</volume>(<issue>4</issue>), <fpage>274</fpage>–<lpage>283</lpage>. <pub-id pub-id-type="doi">10.1093/scan/nsm023</pub-id></mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="other"><string-name><surname>Pelli</surname>, <given-names>D.</given-names></string-name> (<year>1997</year>). <article-title>The videotoolbox software for visual psychophysics: transforming numbers into movies</article-title>. <source>Spatial Vision</source>.</mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><string-name><surname>Pessoa</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>Adolphs</surname>, <given-names>R.</given-names></string-name> (<year>2010</year>). <article-title>Emotion processing and the amygdala: from a “low road” to “many roads” of evaluating biological significance</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>11</volume>(<issue>11</issue>), <fpage>773</fpage>–<lpage>782</lpage>. <pub-id pub-id-type="doi">10.1038/nrn2920</pub-id></mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><string-name><surname>Prunty</surname>, <given-names>J. E.</given-names></string-name>, <string-name><surname>Keemink</surname>, <given-names>J. R.</given-names></string-name>, &amp; <string-name><surname>Kelly</surname>, <given-names>D. J.</given-names></string-name> (<year>2021</year>). <article-title>Infants show pupil dilatory responses to happy and angry facial expressions</article-title>. <source>Developmental Science</source>, <volume>25</volume>(<issue>2</issue>). <pub-id pub-id-type="doi">10.1111/desc.13182</pub-id></mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><string-name><surname>Roether</surname>, <given-names>C. L.</given-names></string-name>, <string-name><surname>Omlor</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Christensen</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Giese</surname>, <given-names>M. A.</given-names></string-name> (<year>2009</year>). <article-title>Critical features for the perception of emotion from gait</article-title>. <source>Journal of Vision</source>, <volume>9</volume>(<issue>6</issue>), <fpage>15</fpage>–<lpage>15</lpage>. <pub-id pub-id-type="doi">10.1167/9.6.15</pub-id></mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><string-name><surname>Shafer</surname>, <given-names>A. T.</given-names></string-name>, <string-name><surname>Matveychuk</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Penney</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>O’Hare</surname>, <given-names>A. J.</given-names></string-name>, <string-name><surname>Stokes</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Dolcos</surname>, <given-names>F.</given-names></string-name> (<year>2012</year>). <article-title>Processing of emotional distraction is both automatic and modulated by attention: evidence from an eventrelated fmri investigation</article-title>. <source>Journal of Cognitive Neuroscience</source>, <volume>24</volume>(<issue>5</issue>), <fpage>1233</fpage>–<lpage>1252</lpage>. <pub-id pub-id-type="doi">10.1162/jocn_a_00206</pub-id></mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><string-name><surname>Spencer</surname>, <given-names>J. M. Y.</given-names></string-name>, <string-name><surname>Sekuler</surname>, <given-names>A. B.</given-names></string-name>, <string-name><surname>Bennett</surname>, <given-names>P. J.</given-names></string-name>, <string-name><surname>Giese</surname>, <given-names>M. A.</given-names></string-name>, &amp; <string-name><surname>Pilz</surname>, <given-names>K. S.</given-names></string-name> (<year>2016</year>). <article-title>Effects of aging on identifying emotions conveyed by point-light walkers</article-title>. <source>Psychology and Aging</source>, <volume>31</volume>(<issue>1</issue>), <fpage>126</fpage>–<lpage>138</lpage>. <pub-id pub-id-type="doi">10.1037/a0040009</pub-id></mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="book"><string-name><surname>Troje</surname>, <given-names>N. F.</given-names></string-name> (<year>2008</year>). <source>Retrieving Information from Human Movement Patterns</source> (pp. <fpage>308</fpage>–<lpage>334</lpage>). <publisher-name>Oxford University PressNew York</publisher-name>. <pub-id pub-id-type="doi">10.1093/acprof:oso/9780195188370.003.0014</pub-id></mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><string-name><surname>Troje</surname>, <given-names>N. F.</given-names></string-name>, &amp; <string-name><surname>Westhoff</surname>, <given-names>C.</given-names></string-name> (<year>2006</year>). <article-title>The inversion effect in biological motion perception: evidence for a “life detector”?</article-title> <source>Current Biology</source>, <volume>16</volume>(<issue>8</issue>), <fpage>821</fpage>–<lpage>824</lpage>.<pub-id pub-id-type="doi">10.1016/j.cub.2011.11.056</pub-id></mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><string-name><surname>Vuilleumier</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Armony</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Driver</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Dolan</surname>, <given-names>R. J.</given-names></string-name> (<year>2003</year>). <article-title>Distinct spatial frequency sensitivities for processing faces and emotional expressions</article-title>. <source>Nature Neuroscience</source>, <volume>6</volume>(<issue>6</issue>), <fpage>624</fpage>–<lpage>631</lpage>. <pub-id pub-id-type="doi">10.1038/nn1057</pub-id></mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><string-name><surname>Wang</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>Jiang</surname>, <given-names>Y.</given-names></string-name> (<year>2012</year>). <article-title>Life motion signals lengthen perceived temporal duration</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>109</volume>(<issue>11</issue>), <fpage>E673</fpage>–<lpage>E677</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1115515109</pub-id></mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><string-name><surname>Wang</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Shi</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Jiang</surname>, <given-names>Y.</given-names></string-name> (<year>2014</year>). <article-title>The feet have it: local biological motion cues trigger reflexive attentional orienting in the brain</article-title>. <source>NeuroImage</source>, <volume>84</volume>, <fpage>217</fpage>–<lpage>224</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.08.041</pub-id></mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><string-name><surname>Wang</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>He</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Jiang</surname>, <given-names>Y.</given-names></string-name> (<year>2010</year>). <article-title>Searching for life motion signals</article-title>. <source>Psychological Science</source>, <volume>21</volume>(<issue>8</issue>), <fpage>1083</fpage>–<lpage>1089</lpage>. <pub-id pub-id-type="doi">10.1177/0956797610376072</pub-id></mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><string-name><surname>Wong</surname>, <given-names>T. K. W.</given-names></string-name>, <string-name><surname>Fung</surname>, <given-names>P. C. W.</given-names></string-name>, <string-name><surname>Chua</surname>, <given-names>S. E.</given-names></string-name>, &amp; <string-name><surname>McAlonan</surname>, <given-names>G. M.</given-names></string-name> (<year>2008</year>). <article-title>Abnormal spatiotemporal processing of emotional facial expressions in childhood autism: dipole source analysis of event-related potentials</article-title>. <source>European Journal of Neuroscience</source>, <volume>28</volume>(<issue>2</issue>), <fpage>407</fpage>–<lpage>416</lpage>. <pub-id pub-id-type="doi">10.1111/j.1460-9568.2008.06328.x</pub-id></mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><string-name><surname>Yu</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Ji</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>Jiang</surname>, <given-names>Y.</given-names></string-name> (<year>2020</year>). <article-title>Cross-modal social attention triggered by biological motion cues</article-title>. <source>Journal of Vision</source>, <volume>20</volume>(<issue>10</issue>), <fpage>21</fpage>. <pub-id pub-id-type="doi">10.1167/jov.20.10.21</pub-id></mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><string-name><surname>Yuan</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Ji</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>Jiang</surname>, <given-names>Y.</given-names></string-name> (<year>2023</year>). <article-title>Happy is stronger than sad: Emotional information modulates social attention</article-title>. <source>Emotion</source>, <volume>23</volume>(<issue>4</issue>), <fpage>1061</fpage>–<lpage>1074</lpage>. <pub-id pub-id-type="doi">10.1037/emo0001145</pub-id></mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.89873.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Zhang</surname>
<given-names>Xilin</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>South China Normal University</institution>
</institution-wrap>
<city>Guangzhou</city>
<country>China</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study presents an <bold>important</bold> finding on the implicit and automatic emotion perception from biological motion (BM). The evidence supporting the claims of the authors is <bold>solid</bold>, although inclusion of a larger number of samples and more evidence for the discrepancy between Intact and local emotional BMs would have strengthened the study. The work will be of broad interest to perceptual and cognitive neuroscience.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.89873.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>
Tian et al. investigated the effects of emotional signals in biological motion on pupil responses. In this study, subjects were presented with point-light biological motion stimuli with happy, neutral, and sad emotions. Their pupil responses were recorded with an eye tracker. Throughout the study, emotion type (i.e., happy/sad/neutral) and BM stimulus type (intact/inverted/non-BM/local) were systematically manipulated. For intact BM stimuli, happy BM induced a larger pupil diameter than neutral BM, and neutral BM also induced a larger pupil diameter than sad BM. Importantly, the diameter difference between happy and sad BM correlated with the autistic trait of individuals. These effects disappeared for the inverted BM and non-BM stimuli. Interestingly, both happy and sad emotions show superiority in pupil diameter.</p>
<p>Strengths:</p>
<p>
1. The experimental conditions and results are very easy to understand.</p>
<p>
2. The writing and data presentation are clear.</p>
<p>
3. The methods are sound. I have no problems with the experimental design and results.</p>
<p>Weaknesses:</p>
<p>
1. My main concern is the interpretation of the intact and local condition results. The processing advantage of happy emotion is not surprising given a number of existing studies. However, the only difference here seems to be the smaller (or larger) pupil diameter for sad compared to neutral in the intact (or local, respectively) condition. The current form only reports this effect but lacks in-depth discussions and explanations as to why this is the case.</p>
<p>2. I also found no systematic discussion and theoretical contributions regarding the correlation with the autistric trait. If the main point of this paper is to highlight an implicit and objective behavioral marker of the autistric trait, more interpretation and discussion of the links between the results and existing findings in ASD are needed.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.89873.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>
Through a series of four experiments, Yuan, Wang and Jiang examined pupil size responses to emotion signals in point-light motion stimuli. Experiment 1 examined upright happy, sad and neutral point-light biological motion (BM) walkers. The happy BM induced a significantly larger pupil response than the neutral, whereas the sad BM evoked a significantly smaller pupil size than the neutral BM. Experiment 2 examined inverted BM walkers. Experiment 3 examined BM stimuli with acceleration removed. No significant effects of emotion were found in neither Experiment 2 nor Experiment 3. Experiment 4 examined scrambled BM stimuli, in which local motion features were preserved while the global configuration was disrupted. Interestingly, the scrambled happy and sad BM led to significantly greater pupil size than the scrambled neutral BM at a relatively early time, while no significant difference between the scrambled happy and sad BM was found. Thus, the authors argue that these results suggest multi-level processing of emotions in life motion signals.</p>
<p>Strengths:</p>
<p>
The experiments were carefully designed and well-executed, with point-light stimuli that eliminate many potential confounding effects of low-level visual features such as luminance, contrast, and spatial frequency.</p>
<p>Weaknesses:</p>
<p>
Correlation results with limited sample size should be interpreted with extra caution.</p>
<p>It would be helpful to add discussions as a context to compare the current results with pupil size reactions to emotion signals in picture stimuli.</p>
<p>Overall, I think this is a well-written paper with solid experimental results that support the claim of the authors, i.e., the human visual system may process emotional information in biological motion at multiple levels. Given the key role of emotion processing in normal social cognition, the results will be of interest not only to basic scientists who study visual perception, but also to clinical researchers who work with patients of social cognitive disorders. In addition, this paper suggests that examining pupil size responses could be a very useful methodological tool to study brain mechanisms underlying emotion processing.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.89873.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>
The overarching goal of the authors was to understand whether emotional information conveyed through point-light biological motion can trigger automatic physiological responses, as reflected in pupil size.</p>
<p>Strengths:</p>
<p>
This manuscript has several noticeable strengths: it addresses an intriguing research question that fills that gap in existing literature, presents a clear and accurate presentation of the current literature, and conducts a series of experiments and control experiments with adequate sample size. Yet, it also entails several noticeable limitations - especially in the study design and statistical analyses.</p>
<p>Weaknesses:</p>
<p>
1. Study design:</p>
<p>
1.1 Dependent variable:</p>
<p>
Emotional attention is known to modulate both microsaccades and pupil size. Given the existing pupillometry data that the authors have collected, it would be both possible and valuable to determine whether the rate of microsaccades is also influenced by emotional biological motion.</p>
<p>1.2 Stimuli:</p>
<p>
It appears that the speed of the emotional biological motion stimuli mimics the natural pace of the emotional walker. What is the average velocity of the biological motion stimuli for each condition?</p>
<p>When the authors used inverted biological motion stimuli, they didn't observe any modulation in pupil size. Could there be a difference in microsaccades when comparing inverted emotional biological motion stimuli?</p>
<p>2. Statistical analyses</p>
<p>
2.1 Multiple comparisons:</p>
<p>
There are many posthoc comparisons throughout the manuscript. The authors should consider correction for multiple comparisons. Take Experiment 1 for example, it is important to note that the happy over neutral BM effect and the sad over neutral BM effect are no longer significant after Bonferroni correction, which is worth noting.</p>
<p>2.2 The authors present the correlation between happy over sad dilation effect and the autistic traits in Experiment 1, but do not report such correlations in Experiments 2-4. Did the authors collect the Autistic Quotient measure in Experiments 2-4? It would be informative if the authors could demonstrate the reproducibility (or lack thereof) of this happy-sad index in Experiments 2-4.</p>
<p>2.3 The observed correlation between happy over sad dilation effect and the autistic traits in Experiment 1 seems rather weak. It could be attributed to the poor reliability of the Autistic Quotient measure or the author-constructed happy-sad index. Did the authors examine the test-retest reliability of their tasks or the Autistic Quotient measure?</p>
<p>2.4 Relatedly, the happy over sad dilation effect is essentially a subtraction index. Without separately presenting the pipul size correlation with happy and sad BM in supplemental figures, it becomes challenging to understand what's primarily driving the observed correlation.</p>
<p>2.5 For the sake of transparency, it is important to report all findings, not just the positive results, throughout the paper.</p>
<p>3. Structure</p>
<p>
3.1 The Results section immediately proceeds to the one-way repeated measures ANOVA. This section could be more reader-friendly by including a brief overview of the task procedures and variables, e.g., shifting Fig. 3 to this section.</p>
</body>
</sub-article>
</article>