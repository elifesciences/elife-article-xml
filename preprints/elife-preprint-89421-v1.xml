<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">89421</article-id>
<article-id pub-id-type="doi">10.7554/eLife.89421</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.89421.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Simple decoding of behavior from a complicated neural manifold</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9456-4648</contrib-id>
<name>
<surname>Perkins</surname>
<given-names>Sean M.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Cunningham</surname>
<given-names>John P.</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="aff" rid="a5">5</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8656-1439</contrib-id>
<name>
<surname>Wang</surname>
<given-names>Qi</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9123-6526</contrib-id>
<name>
<surname>Churchland</surname>
<given-names>Mark M.</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a5">5</xref>
<xref ref-type="aff" rid="a6">6</xref>
<xref ref-type="aff" rid="a7">7</xref>
<xref ref-type="corresp" rid="cor1">✉</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Biomedical Engineering, Columbia University</institution>, New York, NY, <country>USA</country></aff>
<aff id="a2"><label>2</label><institution>Zuckerman Institute, Columbia University</institution>, New York, NY, <country>USA</country></aff>
<aff id="a3"><label>3</label><institution>Department of Statistics, Columbia University</institution>, New York, NY, <country>USA</country></aff>
<aff id="a4"><label>4</label><institution>Center for Theoretical Neuroscience, Columbia University Medical Center</institution>, New York, NY, <country>USA</country></aff>
<aff id="a5"><label>5</label><institution>Grossman Center for the Statistics of Mind, Columbia University</institution>, New York, NY, <country>USA</country></aff>
<aff id="a6"><label>6</label><institution>Department of Neuroscience, Columbia University Medical Center</institution>, New York, NY, <country>USA</country></aff>
<aff id="a7"><label>7</label><institution>Kavli Institute for Brain Science, Columbia University Medical Center</institution>, New York, NY, <country>USA</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Mathis</surname>
<given-names>Mackenzie W</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>École Polytechnique Fédérale de Lausanne</institution>
</institution-wrap>
<city>Genève</city>
<country>Switzerland</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Gold</surname>
<given-names>Joshua I</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Pennsylvania</institution>
</institution-wrap>
<city>Philadelphia</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>✉</label>Correspondence: <email>mc3502@columbia.edu</email></corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2023-10-10">
<day>10</day>
<month>10</month>
<year>2023</year>
</pub-date>
<volume>12</volume>
<elocation-id>RP89421</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-06-08">
<day>08</day>
<month>06</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-04-29">
<day>29</day>
<month>04</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.04.05.535396"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2023, Perkins et al</copyright-statement>
<copyright-year>2023</copyright-year>
<copyright-holder>Perkins et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-89421-v1.pdf"/>
<abstract>
<p>Decoders for brain-computer interfaces (BCIs) assume constraints on neural activity, chosen to reflect scientific beliefs while yielding tractable computations. We document how low tangling – a typical property of motor-cortex neural trajectories – yields unusual neural geometries. We designed a decoder, MINT, to embrace statistical constraints that are appropriate for these geometries. MINT takes a trajectory-centric approach: a library of neural trajectories (rather than a set of neural dimensions) provides a scaffold approximating the neural manifold. Each neural trajectory has a corresponding behavioral trajectory, allowing straightforward but highly nonlinear decoding. MINT consistently outperformed other interpretable methods, and outperformed expressive machine learning methods in 37 of 42 comparisons. Yet unlike these expressive methods, MINT’s constraints are known rather than the implicit result of optimizing decoder output. MINT performed well across tasks, suggesting its assumptions are generally well-matched to the statistics of neural data. Despite embracing highly nonlinear relationships between behavior and potentially complex neural trajectories, MINT’s computations are simple, scalable, and provide interpretable quantities such as data likelihoods. MINT’s performance and simplicity suggest it may be an excellent candidate for clinical BCI applications.</p>
</abstract>
<kwd-group kwd-group-type="author">
<kwd>brain-computer interfaces</kwd>
<kwd>population geometry</kwd>
<kwd>neural dynamics</kwd>
<kwd>motor cortex</kwd>
<kwd>motor control</kwd>
</kwd-group>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>SP, JC, and MC hold a patent pertaining to this work. The patent has been licensed to Blackrock Neurotech. The authors declare no additional competing interests.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Minor revisions to Abstract, Introduction, and Discussion.</p></fn>
</fn-group>
<fn-group content-type="external-links">
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://github.com/seanmperkins/mint">https://github.com/seanmperkins/mint</ext-link>
</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>A common goal in neural engineering and neuroscience is to estimate target variables, in real time, from observations of neural spiking activity. For brain-computer interfaces (BCIs), target variables may correspond to prosthetic motion [<xref ref-type="bibr" rid="c1">1</xref>–<xref ref-type="bibr" rid="c6">6</xref>], muscle activity [<xref ref-type="bibr" rid="c7">7</xref>–<xref ref-type="bibr" rid="c10">10</xref>], cursor control [<xref ref-type="bibr" rid="c11">11</xref>–<xref ref-type="bibr" rid="c17">17</xref>], navigation [<xref ref-type="bibr" rid="c18">18</xref>–<xref ref-type="bibr" rid="c20">20</xref>], speech [<xref ref-type="bibr" rid="c21">21</xref>–<xref ref-type="bibr" rid="c23">23</xref>], handwriting [<xref ref-type="bibr" rid="c24">24</xref>], or cognitive states [<xref ref-type="bibr" rid="c25">25</xref>–<xref ref-type="bibr" rid="c29">29</xref>]. In other applications, one may wish to estimate the state of the brain, a latent variable, for clinical monitoring [<xref ref-type="bibr" rid="c30">30</xref>], data visualization [<xref ref-type="bibr" rid="c31">31</xref>], or closed-loop neurally contingent experiments [<xref ref-type="bibr" rid="c32">32</xref>]. Spiking activity is high-dimensional (dimensionality matching the number of neurons) and can be variable across repeated trials of a nominally identical behavior. This complexity can be managed by utilizing statistical models that simplify the assumed relationship between spiking activity and variables of interest. For example, early BCI decoders estimated horizontal and vertical cursor velocity via weighted sums of neural activity, allowing velocity to be readily decoded even for spike patterns that were never observed during training. Ideally, estimation should leverage assumptions that are both accurate and strongly simplifying.</p>
<p>Perhaps the most common constraint assumed by models of spiking activity is the notion of ‘rate’. Rates are estimated in various ways by binning, filtering, and/or trial-averaging. Fundamentally, a neuron’s rate is a value determining its instantaneous probability of spiking. Statistically, this assumption has been powerful, especially in brain areas where spiking shows considerable variability. Furthermore, in artificial spiking networks, rate is a well-defined quantity whose properties justify those statistical models [<xref ref-type="bibr" rid="c33">33</xref>]. It is thus common practice to assume that neural activity, at each moment in time, can be summarized by a vector of continuously varying rates with one entry per neuron (the ‘neural state’). Spikes are then treated as noisy observations of the neural state.</p>
<p>A variety of methods for estimating the neural state and decoding behavior on single trials have been proposed [<xref ref-type="bibr" rid="c34">34</xref>–<xref ref-type="bibr" rid="c40">40</xref>]. Many of these leverage an additional assumption: that the neural state is low-dimensional, with the vector of rates exploring far fewer dimensions than the number of recorded neurons. Low-dimensional state estimation and decoding are often implicitly combined – e.g. linear decoders consider a neural state whose dimensionality matches the number of decoded variables [<xref ref-type="bibr" rid="c1">1</xref>–<xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c11">11</xref>, <xref ref-type="bibr" rid="c12">12</xref>].</p>
<p>Many studies have usefully assumed further constraints on the neural state, beyond those related to dimensionality. For example, studies have leveraged assumptions regarding linear [<xref ref-type="bibr" rid="c37">37</xref>] or nonlinear [<xref ref-type="bibr" rid="c38">38</xref>] neural dynamics that constrain how the neural state can evolve. Multiple studies have assumed constraints on neural activity related to structure in behavior [<xref ref-type="bibr" rid="c13">13</xref>, <xref ref-type="bibr" rid="c16">16</xref>, <xref ref-type="bibr" rid="c17">17</xref>, <xref ref-type="bibr" rid="c41">41</xref>–<xref ref-type="bibr" rid="c49">49</xref>]. Sani et al. [<xref ref-type="bibr" rid="c50">50</xref>] leveraged the assumption that only a subspace within the low-dimensional neural state is relevant to behavior. Schneider, Lee, and Mathis [<xref ref-type="bibr" rid="c51">51</xref>] and Zhou and Wei [<xref ref-type="bibr" rid="c52">52</xref>] assumed behaviorally-relevant structure in latent variables that relate nonlinearly to the full-dimensional neural state. Nonlinear decoders (including neural networks) can relax some constraints (e.g. linear relationships between behavior and neural state) while imposing or learning others [<xref ref-type="bibr" rid="c21">21</xref>, <xref ref-type="bibr" rid="c23">23</xref>, <xref ref-type="bibr" rid="c24">24</xref>, <xref ref-type="bibr" rid="c38">38</xref>, <xref ref-type="bibr" rid="c40">40</xref>, <xref ref-type="bibr" rid="c53">53</xref>–<xref ref-type="bibr" rid="c61">61</xref>].</p>
<p>Each of these prior approaches succeeded by imposing structure on the estimation problem via constraints (explicit or learned) on the neural state or its relationship to behavior. Here, we propose a novel algorithm, Mesh of Idealized Neural Trajectories (MINT), that leverages different constraints. These constraints derive from advances – some recent and some presented here – in our understanding of the geometry of population activity and its relationship to movement. MINT takes a trajectory-centric view of neural geometry, in which the manifold of observable neural states is best approximated using stereotyped trajectories and interpolations between them. MINT assumes that the relationship between neural activity and behavior, while highly nonlinear, can be approximated by creating a correspondence between neural and behavioral trajectories. MINT is well-suited to situations where neural activity is shaped by dynamics, yet makes no assumption regarding the form of those dynamics. Because MINT’s assumptions were chosen to respect scientific beliefs rather than tractability, they might be expected to complicate computation. Fortuitously the opposite is true: MINT’s assumptions make it easier to compute desired quantities such as data likelihoods.</p>
<p>Below we document and quantify properties of motor-cortex population geometry – and its relationship with behavior – that are relevant to any decoder (and more generally to many scientific analyses and hypotheses). We describe how MINT was designed to respect and leverage these properties. We compare MINT’s decode performance with multiple other decode methods. We do so across a variety of tasks and behavioral variables, to document MINT’s flexibility. We also evaluate MINT as a method for neural-state estimation. MINT’s overall high level of performance illustrates the value of a trajectory-centric view that respects the empirical structure of population geometry.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Neural trajectories are sparsely distributed, stereotyped, and can be high-dimensional</title>
<p>We analyzed 8 datasets consisting of simultaneous neural recordings and behavioral measurements from primates performing motor, sensory, or cognitive tasks. To begin, we focus on one dataset (MC_Cycle) recorded during a task where a primate grasps a hand-pedal and moves it cyclically forward or backward to navigate a virtual environment. We use this dataset to document some unusual properties of motor-cortex population geometry – properties that have implications for any BCI-decoding method. A variety of studies indicate that the dominant features of neural trajectories do not reflect encoded parameters or network outputs, but rather the computational needs of network solutions (e.g. [<xref ref-type="bibr" rid="c62">62</xref>, <xref ref-type="bibr" rid="c63">63</xref>]). For example, noise-robust solutions require low trajectory tangling [<xref ref-type="bibr" rid="c64">64</xref>], resulting in neural trajectories that look very different from the outputs they create [<xref ref-type="bibr" rid="c65">65</xref>].</p>
<p>By definition, low-tangled neural trajectories never come close to crossing while traveling in different directions. For example, forward-cycling trajectories and backward-cycling trajectories appear to overlap when viewed in two-dimensions (<xref rid="fig1" ref-type="fig">Fig. 1a</xref>, <italic>top</italic>). Yet the apparent crossings do not result in high trajectory tangling; there exist other dimensions where forward and backward trajectories are well separated (<xref rid="fig1" ref-type="fig">Fig. 1a</xref>, <italic>bottom</italic>, same scale used for both). Separation keeps trajectory tangling extremely low – far lower than for the corresponding muscle trajectories.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Properties of neural trajectories in motor cortex, illustrated for data recorded during the cycling task (MC_Cycle dataset).</title>
<p><bold>a)</bold> Low tangling implies separation between trajectories that might otherwise be close. <italic>Top</italic>. Neural trajectories for forward (<italic>purple</italic>) and backward (<italic>orange</italic>) cycling. Trajectories begin 600 ms before movement onset and end 600 ms after movement offset. Trajectories are based on trial-averaged firing rates, projected onto two dimensions. Dimensions were hand-selected to highlight apparent trajectory crossings while also capturing considerable variance (11.5%, comparable to the 11.6% captured by PCs 3 and 4). <italic>Gray region</italic> highlights one set of apparent crossings. <italic>Bottom</italic>. Trajectories during the restricted range of times in the gray region, but projected onto different dimensions: the top two principal components when PCA was applied to this subset of data. The same scale is used in top and bottom subpanels. <bold>b)</bold> Examples of similar behavioral states (<italic>inset</italic>) corresponding to well-separated neural states (<italic>main panel</italic>). Colored trajectory tails indicate the previous 150 ms of states. Data from 7-cycle forward condition. <bold>c)</bold> Joint distribution of pairwise distances for muscle and neural trajectories. Analysis considered all states across all conditions. For both muscle and neural trajectories, we computed all possible pairwise distances across all states. Each muscle state has a corresponding neural state, from the same time within the same condition. Thus, each pairwise muscle-state distance has a corresponding neural-state distance. The color of each pixel indicates how common it was to observe a particular combination of muscle-state distance and neural-state distance. Muscle trajectories are based on seven z-scored intramuscular EMG recordings. Correspondence between neural and muscle state pairs included a 50 ms lag to account for physiological latency. Results were not sensitive to the presence or size of this lag. Neural and muscle distances were normalized (separately) by average pairwise distance. <bold>d)</bold> Same analysis for neural and kinematic distances (based on phase and angular velocity). Correspondence between neural and kinematic state pairs included a 150 ms lag. Results were not sensitive to the presence or size of this lag. <bold>e)</bold> Control analysis to assess the impact of sampling error. If two sets of trajectories (e.g. neural and kinematic) are isometric and can be estimated perfectly, their joint distribution should fall along the diagonal. To estimate the impact of sampling error, we repeated the above analysis comparing neural distances across two data partitions, each containing 15-18 trials/condition.</p></caption>
<graphic xlink:href="535396v2_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Under the commonly assumed low-dimensional constraint, the manifold of observable neural states is equivalent to a subspace. This assumption is so standard that the terms ‘manifold’ and ‘subspace’ have often been used interchangeably. From that perspective, all states within that subspace are possible, with probabilities that may be described by a covariance matrix. For example, if two states are likely, the state between them is also likely. A family of low-tangled trajectories will often display the opposite property. Low-tangled trajectories typically require large voids that are never occupied. For example, circular trajectories are common [<xref ref-type="bibr" rid="c63">63</xref>, <xref ref-type="bibr" rid="c64">64</xref>, <xref ref-type="bibr" rid="c66">66</xref>]. Their intrinsically low tangling would increase if other trajectories (e.g. from other conditions) intruded into their center, but empirically this is avoided. Thus, the manifold of observable states may be far more sparsely distributed than is suggested by the simple constraint of a subspace or covariance matrix.</p>
<p>Maintaining low trajectory tangling can require adding ‘new’ dimensions to separate trajectories. Thus, neural-state dimensionality may be higher than the number of variables one wishes to decode [<xref ref-type="bibr" rid="c67">67</xref>, <xref ref-type="bibr" rid="c68">68</xref>]. Furthermore, low trajectory tangling requires that two similar neural states lead to similar future neural states, even over timescales longer than those governing temporal smoothness. Thus, sequences of neural states over time may be stereotyped. Recent work used this assumption to compare network and biological solutions [<xref ref-type="bibr" rid="c69">69</xref>]. Stereotyped trajectories would also be consistent with recent BCI-adaptation results. BCI adaptation involves reusing existing patterns of neural activity [<xref ref-type="bibr" rid="c70">70</xref>], and trajectories do not reverse even when that would be advantageous [<xref ref-type="bibr" rid="c71">71</xref>, <xref ref-type="bibr" rid="c72">72</xref>].</p>
<p>These observations argue that the appropriate constraints on the neural state have little to do with dimensionality per se – dimensionality may actually be quite high. Rather, constraints should reflect that neural states are sparsely distributed and belong to families of stereotyped trajectories. MINT makes assumptions that embrace these aspects of state-trajectory geometry. We briefly summarize these assumptions here, leaving a detailed description of MINT for a later section. First, MINT accommodates any dimensionality (high or low) by operating directly on the neural state rather than attempting to reduce its dimensionality. Second, MINT assumes the manifold of observable states is extremely sparsely distributed and therefore best approximated by leveraging the trajectories themselves rather than their covariance matrix or corresponding subspace. Third, MINT assumes that neural states are traversed in a stereotyped order (i.e. each neural state determines the subsequent state). MINT embodies these assumptions by approximating the manifold of observable neural states – and the transitions between them – with a ‘mesh’ of neural trajectories. A library of idealized trajectories samples the underlying manifold. Interpolations between neural states connect these trajectories into a mesh that spans the manifold more completely, allowing MINT to decode neural and behavioral states beyond those observed during training.</p>
</sec>
<sec id="s2b">
<title>Neural and behavioral trajectories are non-isometric</title>
<p>The geometry of neural trajectories also has implications regarding how the neural state, once it is estimated, should be decoded into a behavioral state. To explore, we compared distances in neural and behavioral space. Well-separated neural states frequently corresponded to the same behavioral state. For example, in <xref rid="fig1" ref-type="fig">Figure 1b</xref>, the two red circles correspond to moments when behavior is essentially identical: cycling at ∼1.7 Hz with the hand approaching the ‘bottom’ of the cycle. Nevertheless, the corresponding moments are distant in neural state space. Similarly, the two gray squares correspond to two moments when the hand is stopped at the bottom (immediately before and after bouts of cycling) and are also quite distant. The neural and kinematic dimensions in <xref rid="fig1" ref-type="fig">Figure 1b</xref> were selected and oriented to highlight some resemblance between neural and behavioral trajectories. Yet, there are geometric differences even in this view, and these would only become more pronounced if more conditions (e.g. backward cycling) were included. As a consequence, the neural-to-behavioral-state mapping is many-to-one.</p>
<p>To compare trajectory-geometries quantitatively, we leveraged the fact that each neural distance has a corresponding behavioral distance, taken for the same pair of conditions and times (allowing for a latency shift). If geometries are similar, behavioral and neural distances should be strongly correlated. To establish a baseline that takes into account the impact of sampling error, we compared neural distances across two partitions. As expected, nearly all data fell along the diagonal (<xref rid="fig1" ref-type="fig">Fig. 1e</xref>). The joint distribution was strikingly non-diagonal when comparing neural versus muscle-population trajectories (<xref rid="fig1" ref-type="fig">Fig. 1c</xref>) and neural versus kinematic trajectories (<xref rid="fig1" ref-type="fig">Fig. 1d</xref>).</p>
<p>Thus, neural trajectories are isometric to neither muscle nor kinematic trajectories. Similar behavioral states frequently corresponded to dissimilar neural states. Defining similar kinematic states to be those with normalized distance &lt;0.1, corresponding neural states were as close as 0.02 and as far as 1.46. Nevertheless, dissimilar behavioral states did not correspond to similar neural states. Defining dissimilar kinematic states to be those within 0.1 of distance 2, neural states were never closer than 0.53. These relationships facilitate decoding in some ways – different behavioral states imply different neural states – while also creating a challenge – decoding must map dissimilar neural states to similar behavioral states.</p>
<p>In principle, this many-to-one mapping could be accomplished linearly. Suppose neural trajectories mirrored behavioral trajectories, but with additional non-behavior-encoding dimensions. A linear decoder could simply ignore those additional dimensions. Yet this will be suboptimal if the ignored dimensions capture the majority of response variance. MINT leverages all dimensions by learning, directly from training data, which behavioral state is associated with each neural state in a library of idealized trajectories. This allows highly nonlinear mappings – including many-to-one mappings – without needing to choose a nonlinear function class and fit it to the data.</p>
</sec>
<sec id="s2c">
<title>Training and decoding procedure</title>
<p>For training, MINT requires a library of neural trajectories (Ω) and a corresponding library of behavioral trajectories (Φ). Libraries can be learned in a variety of ways, depending on the nature of the task and training data. Because trial-averaging is particularly easy to apply, we focus first on libraries of neural trajectories learned in this way.</p>
<p>Consider a center-out reaching task. Neural and behavioral trajectories (<xref rid="fig2" ref-type="fig">Fig. 2a</xref>) have different geometries: stacked loops versus radially arranged and relatively straight. Trajectories are learned from a training set containing repeated reaching trials to each target location. Each moment in the training data corresponds to a condition (<italic>c</italic>) and an index (<italic>k</italic>) indicating progress through the movement. For example, <italic>c</italic> = 3 corresponds to the purple reach condition and <italic>k</italic> = 240 indicates a moment 240 ms into that movement. There will typically be many such moments in the training data: one for each trial of that type. Averaging across trials yields a behavioral state <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline1.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. Similarly, temporally filtering spikes and averaging across trials yields a neural state <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline2.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, containing each neuron’s estimated rate. Rate estimation can be further improved by a variety of means, including additional smoothing across neurons and/or conditions (see Methods). For some tasks, training data may not be organized by discrete conditions. Rates would then be estimated using methods devised for that purpose (e.g. [<xref ref-type="bibr" rid="c38">38</xref>, <xref ref-type="bibr" rid="c40">40</xref>]).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Example training (top panel) and decoding (bottom panels) procedures for MINT, illustrated using four conditions from a reaching task.</title>
<p><bold>a)</bold> Libraries of neural and behavioral trajectories are learned such that each neural state <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline113.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> corresponds to a behavioral state <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline114.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. <bold>b)</bold> Spiking observations are binned spike counts (20 ms bins for all main analyses). <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline115.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> contains the spike count of each neuron for the present bin, <italic>t′</italic>, and <italic>τ ′</italic> bins in the past. <bold>c)</bold> At each time step during decoding, the log-likelihood of observing <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline116.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> is computed for each and every state in the library of neural trajectories. Log-likelihoods decompose across neurons and time bins into Poisson log-likelihoods that can be queried from a precomputed lookup table. A recursive procedure (not depicted) further improves computational efficiency. Despite utilizing binned spiking observations, log-likelihoods can be updated at millisecond resolution (Methods). <bold>d)</bold> Two candidate neural states (<italic>purple</italic> and <italic>blue</italic>) are identified. The first is the state within the library of trajectories that maximizes the log-likelihood of the observed spikes. The second state similarly maximizes that log-likelihood, with the restriction that the second state must not come from the same trajectory as the first (i.e. must be from a different condition). Interpolation identifies an intermediate state that maximizes log-likelihood. <bold>e)</bold> The optimal interpolation is applied to candidate neural states – yielding the final neural-state estimate – and their corresponding behavioral states – yielding decoded behavior.</p></caption>
<graphic xlink:href="535396v2_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The library of neural trajectories (Ω) and the corresponding library of behavioral trajectories (Φ) are the parameters of MINT. They specify which states can be occupied and the order in which they are traversed. Prior work has utilized stereotyped behavioral trajectories [<xref ref-type="bibr" rid="c41">41</xref>, <xref ref-type="bibr" rid="c46">46</xref>] or a mixture of condition-specific behavioral trajectory models that capture trial-by-trial movement variability [<xref ref-type="bibr" rid="c49">49</xref>]. For tractability, those methods assumed low-dimensional neural states that are roughly isometric to arm velocities. With MINT, neural trajectories can take any geometry, are learned empirically, and are related to behavioral trajectories via <italic>c</italic> and <italic>k</italic>, rather than by an assumed geometric isometry. The relationship between neural and behavioral states can be highly nonlinear and many-to-one. Although in <xref rid="fig2" ref-type="fig">Figure 2a</xref> there is one trajectory per target location, in practice there may be multiple trajectories per target (e.g. different speeds or curvatures) to enrich the library by allowing for movement variations. At the same time, it is not necessary for every potential target location and movement variation to be present in the training set. As will be discussed below, MINT can generalize in a handful of ways, including between any two conditions where neural activity and behavior both change smoothly. Furthermore, although the design of MINT is inspired by observations related to low tangling during movement, it is perfectly acceptable if there are moments of high tangling within Ω. Indeed this often occurs at transitions, e.g. from not-yet preparing to preparing a specific reach.</p>
<p>During decoding, incoming observations of spiking activity are binned (<xref rid="fig2" ref-type="fig">Fig. 2b</xref>, Δ = 20 ms for all analyses here). Suppose we are at time-bin <italic>t</italic>′ within a session where behavior is being decoded. Recent spiking observations are denoted by <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline3.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, where <italic>τ</italic> ′ specifies the number of previous time bins that are retained in memory. We compute the log-likelihood that we would have observed <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline4.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> given each possible neural state, under a Poisson spiking model (<xref rid="fig2" ref-type="fig">Fig. 2c</xref>). The set of possible neural states is initially restricted to the states within the library of neural trajectories. This is a strong, but important assumption. If one were to consider all possible neural states in a 100-dimensional space, with each rate discretized into 10 possible values, it would be necessary to compute log-likelihoods for 10<sup>100</sup> potential neural states. Yet computing log-likelihoods becomes tractable if trajectories are sparsely distributed. For example, even with 1000 samples per neural trajectory for the 4 neural trajectories in <xref rid="fig2" ref-type="fig">Figure 2</xref>, there would still be only 4000 possible neural states for which log-likelihoods must be computed (in practice it is fewer still, see Methods). Beyond reducing computational complexity, MINT’s assumptions regarding where the neural state can (and can’t) reside should aid decoding if those assumptions are well-aligned with the data.</p>
<p>MINT also leverages the order in which states are traversed, providing another massive reduction in complexity. MINT assumes that each neural state along each neural trajectory has a unique recent history that can be compared to the recent history of spike counts when computing log-likelihoods. Fortuitously, spike counts in non-overlapping bins are conditionally independent given rate in a Poisson spiking model. Thus, the log-likelihood associated with a particular neural state decomposes across time bins and neurons into Poisson log-likelihoods (which can be queried from a precomputed lookup table). Furthermore, many terms computed for decoding in one time bin can be reused at the next time bin. A recursive solution for exploiting this redundancy reduces the complexity of computing these log-likelihoods, leading to a lightweight procedure amenable to real-time applications. The assumption of stereotypy trajectory also enables neural states (and decoded behaviors) to be updated in between time bins. While waiting for the next set of spiking observations to arrive, MINT simply assumes that each neural state advances deterministically along the trajectory to which it is assigned.</p>
<p>Using the above procedure, one could simply take the maximum-likelihood neural state from the library, then render a behavioral decode based on the corresponding behavioral state. However, we wish the trajectory library to serve not as an exhaustive set of possible states, but as the basic structure defining a ‘mesh’ of possible states. Suppose the subject made a reach that split the difference between purple and blue reach conditions in <xref rid="fig2" ref-type="fig">Figure 2a</xref>. MINT would identify two candidate states with high likelihoods, along different neural trajectories, and interpolate (<xref rid="fig2" ref-type="fig">Fig. 2d</xref>). A line segment connecting those states is parameterized by <italic>α</italic>, ranging from 0 (purple state) to 1 (blue state). Because the log-likelihood of the observed spikes is a concave function of <italic>α</italic>, the optimal neural state can be rapidly identified online using Newton’s method. The same interpolation produces the final decode from the corresponding behavioral states (<xref rid="fig2" ref-type="fig">Fig. 2e</xref>).</p>
<p>The ‘mesh’ in MINT conveys that interpolation fills in the space between candidate states along different trajectories. The mesh is not fully defined during training because it is unknown which candidate states to consider until the spiking observations arrive. Rather, as spikes are observed during decoding, they will often be consistent with more than one trajectory. It is at that juncture that MINT utilizes interpolation to consider a space of intermediate trajectories that could have given rise to these observations. It is easiest to think of the mesh as connecting nearby trajectories, as in <xref rid="fig2" ref-type="fig">Figure 2d,e</xref>, and this is indeed what occurs in practice. While no assumption prevents MINT from interpolating between very different trajectories, this is empirically rare: the vast majority of decoded states are near an on-trajectory state. For on-trajectory states, direct decoding should be nearly perfect in determining the associated behavior. For states near trajectories, linear interpolation should provide good generalization because neural activity and behavior typically vary together smoothly.</p>
</sec>
<sec id="s2d">
<title>Behavioral decoding in a multi-task network</title>
<p>MINT can be used in the same way for different tasks – the libraries differ but all other operations remain the same. If training data include multiple tasks, MINT can readily and implicitly switch tasks ‘on the fly’ based only on neural observations. MINT can do so even when the nonlinear relationship between neural activity and behavior is very different across tasks. If desired, MINT can report which type of behavior is presently being produced and decode only those variables relevant to that behavior. This could be useful, for example, if a subject were controlling both a computer cursor and a wheelchair. It is presently rare for physiological data to be recorded across multiple tasks in the same session. We thus demonstrate this task-switching ability for an artificial spiking network that performs two tasks on interleaved trials. This evaluation is also useful because the ground-truth neural state is known.</p>
<p>We evaluated MINT’s performance on data produced by an artificial recurrent network built from leaky-integrate-and-fire spiking neurons [<xref ref-type="bibr" rid="c33">33</xref>]. Network neurons exhibit realistic firing rates and realistic levels of spiking variability (i.e. spiking statistics are roughly Poisson). The network was trained to generate posterior deltoid activity (<xref rid="fig3" ref-type="fig">Fig. 3a</xref>) for a reaching task (similar to that in <xref rid="fig2" ref-type="fig">Fig. 2</xref>) and a cycling task (similar to that in <xref rid="fig1" ref-type="fig">Fig. 1</xref>). The network uses different strategies to perform the two tasks, and neural activity occupies distinct subspaces for each (<xref rid="fig3" ref-type="fig">Fig. 3b</xref>). This provides a stringent challenge; correlations between neural activity and behavioral output are completely different across tasks.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Examples of behavioral decoding provided by MINT for one simulated dataset and four empirically recorded datasets.</title>
<p>All decoding is causal; only spikes from before the decoded moment are used. <bold>a)</bold> MINT was applied to spiking data from an artificial spiking network. That network was trained to generate posterior deltoid activity and to switch between reaching and cycling tasks. Based on spiking observations, MINT approximately decoded the true network output at each moment. ‘R3’, ‘R4’, and ‘R6’ indicate three different reach conditions. ‘C’ indicates a cycling bout. MINT used no explicit task-switching, but simply tracked neural trajectories across tasks as if they were conditions within a task. <bold>b)</bold> Illustration of the challenging nature, from a decoding perspective, of network trajectories. Trajectories are shown for two dimensions that are strongly occupied during cycling. Trajectories for the 8 reaching conditions (<italic>pink</italic>) are all nearly orthogonal to the trajectory for cycling (<italic>brown</italic>) and thus appear compressed in this projection. <bold>c)</bold> Decoded behavioral variables (<italic>green</italic>) compared to actual behavioral variables (<italic>black</italic>) across four empirical datasets. MC_Cycle and MC_RTT show 10 seconds of continuous decoding. MC_Maze and Area2_Bump show randomly selected trials, demarcated by <italic>vertical dashed lines</italic>.</p></caption>
<graphic xlink:href="535396v2_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Decoding performance was excellent: <italic>R</italic><sup>2</sup> = .968 over ∼7.1 minutes of test trials. Decoded deltoid activity (<italic>green</italic>) was virtually identical to network output (<italic>black</italic>). This was true during both reaching (R3, R4 and R6 correspond to three reach directions) and cycling (C), with smooth transitions between them. MINT’s decoding approach was not hindered by the very different relationship between neural trajectories and behavioral output during the two tasks, nor by the dramatically different neuron-neuron covariance. Rather, MINT simply identified the most likely neural state at each moment and decoded the associated behavioral output.</p>
<p>The fact that the ground truth is known in this network illuminates a challenge that may impact decoding in many real-world situations. Even when a neural population or brain area exists to generate a particular output, that output may be encoded in low-variance dimensions and it may therefore be difficult to decode unless other dimensions can also be leveraged. For the present network, the output is simply a weighted sum of spikes, across all 1200 neurons. Thus, a linear readout (learned via ridge regression) that leveraged all 1200 neurons decoded network output exceptionally well (<italic>R</italic><sup>2</sup> = .982). However, the output dimension in this network captures exceedingly little of the total variance of network responses (∼2%), and thus is unlikely to perform well if only a subset of neurons were recorded. Indeed, when only using 5% of neurons in the network, linear decoding performance dropped to <italic>R</italic><sup>2</sup> = .773. In contrast, MINT’s performance only dropped by .001 to <italic>R</italic><sup>2</sup> = .967. Thus, even when the ground-truth readout is known, MINT can provide improved performance by leveraging all neural dimensions, not only those that directly impact behavioral output. Furthermore, MINT can readily decode other variables (as will be shown below) that are unlikely to be directly controlled by linear sums of spiking activity.</p>
</sec>
<sec id="s2e">
<title>Behavioral decoding across multiple datasets</title>
<p>We investigated how MINT performed on four datasets in which primates performed a variety of motor tasks. All tasks involved simultaneously collected spiking activity and behavioral measurements. MC_Cycle is the same dataset from <xref rid="fig1" ref-type="fig">Figure 1</xref>. MC_Maze involves neural recordings from primary motor cortex (M1) and dorsal premotor cortex (PMd) during straight and curved reaches [<xref ref-type="bibr" rid="c73">73</xref>]. Area2_Bump involves neural recordings from area 2 of somatosensory cortex during active and passive center-out-reaches [<xref ref-type="bibr" rid="c74">74</xref>]. MC_RTT involves M1 recordings during point-to-point reaches without condition structure [<xref ref-type="bibr" rid="c59">59</xref>]. All decoding was offline, to allow evaluation across a variety of task types and comparison with other decode methods (below) across multiple decoded variables. All decoding was causal; i.e. based on spikes from before the decoded time. All decoding examples and performance quantifications utilized held-out test sets. Discussion of how MINT’s (few) hyperparameters were selected for the analyses in <xref rid="fig3" ref-type="fig">Figure 3</xref> will be provided in the next section.</p>
<p>Decoding closely tracked actual behavior (<xref rid="fig3" ref-type="fig">Fig. 3c</xref>). For the MC_Cycle dataset, MINT closely tracked pedal phase and angular velocity. Decoding was virtually lag-free (on average): phase was decoded with near-zero lag, and transitions between rest and cycling occurred with near-zero latency. This was true despite the fact that all decoding was causal. During periods of non-movement, decoded angular velocity remained flat with few false movements. To illustrate, consider a 70 second stretch of cycling (Supp. Video) that included ∼30 seconds of true non-movement (true angular speed &lt;.05 Hz). Small decode mistakes (decoded angular speed &gt;0.1 Hz) did occasionally occur (e.g. <xref rid="fig3" ref-type="fig">Fig. 3c</xref>, small ‘blip’ before the middle cycling bout). Yet such mistakes were rare: decoded angular speed was &lt;0.1 Hz for ∼99% of non-moving times.</p>
<p>A subtle point is that MINT assumes stereotyped trajectories when computing data likelihoods, but this does not cause the maximum-likelihood state to follow a stereotyped trajectory during decoding. For example, individual trials rarely have a cycling speed that perfectly matches the library trajectory. Yet this does not cause a growing discrepancy between decoded and actual phase. If cycling is slightly faster than the library trajectory, MINT advances along that trajectory at a faster-than-usual rate. This flexibility is essential to good performance, but also reveals itself during errors when behavioral trajectories exhibit features (e.g. the small blip noted above) not present in any library trajectory.</p>
<p>In the MC_Maze dataset, decoded velocity tracked actual reach velocity across a wide variety of straight and curved reaches (108 conditions). Decoded and actual velocities were highly correlated (<italic>R</italic><sub><italic>x</italic></sub> = .962, <italic>R</italic><sub><italic>y</italic></sub> = .950). We quantified error in absolute terms using the mean absolute error (MAE). Absolute errors were low (MAE<sub><italic>x</italic></sub> = 4.6 cm/s, MAE<sub><italic>y</italic></sub> = 4.8 cm/s) relative to the range of x- and y-velocities (224.8 and 205.7 cm/s, respectively).</p>
<p>Decoding performance was also high for Area2_Bump (<italic>R</italic><sub><italic>x</italic></sub> = .939, <italic>R</italic><sub><italic>y</italic></sub> = .895; MAE<sub><italic>x</italic></sub> = 4.1 cm/s, MAE<sub><italic>y</italic></sub> = 4.4 cm/s). Errors were slightly smaller than for the MC_Maze dataset in absolute terms, but were modestly larger in relative terms because the behavioral range of velocities was smaller. Errors are thus slightly clearer in the traces plotted in <xref rid="fig3" ref-type="fig">Fig. 3c</xref>. The overall high performance – and minimal lag – is notable given that the decode was based on spiking in a primary sensory area.</p>
<p>The task used in the MC_RTT dataset was not designed to include repeated trials of the same movement. Thus, when learning neural trajectories, we used a method that doesn’t rely on averaging: AutoLFADS [<xref ref-type="bibr" rid="c39">39</xref>]. This yielded one long neural trajectory during training (only broken by recording gaps). MINT’s interpolation procedure was modified to 1) occur across states &gt;1000 ms apart, and 2) perform multiple pairwise interpolations between candidate-state pairs and use that which yielded the highest log-likelihood. The first modification ensures interpolation must consider different movements, even without a condition structure. The second modification accommodates the fact that this less-constrained task has many degrees of behavioral freedom. There may thus be more than two high-probability candidate states that are worth considering.</p>
<p>This strategy yielded decoded velocities (<xref rid="fig3" ref-type="fig">Fig. 3c</xref>) that correlated well (<italic>R</italic><sub><italic>x</italic></sub> = .786, <italic>R</italic><sub><italic>y</italic></sub> = .843) with actual velocities, but less well than for the other three datasets. Absolute errors were lower than for the other reaching datasets (MAE<sub><italic>x</italic></sub> = 2.7 cm/s, MAE<sub><italic>y</italic></sub> = 2.1 cm/s). However, x- and y-velocity ranges were also lower (86.6 and 61.3 cm/s). As will be documented below, decode performance for the MC_RTT dataset was lower, relative to that for the other three datasets, not only for MINT but also for other decode algorithms. There are two likely reasons. First, MC_RTT contained by far the slowest reaches of the three datasets. When analyzing only movement periods (reach speed &gt;1 cm/s), the median speed across all movement times was 38.1, 16.8, and 5.9 cm/s for MC_Maze, Area2_Bump, and MC_RTT, respectively. Second, the ability of AutoLFADS to denoise trajectories based on inferred dynamics may have been limited by the relatively short (8.1 minutes) amount of training data. This issue aside, the MC_RTT task provides a useful demonstration that the neural trajectories needed to parameterize MINT can be obtained without a standard condition structure and without trial averaging.</p>
</sec>
<sec id="s2f">
<title>Comparison to other decoders</title>
<p>We compared MINT to four other decode algorithms: the Kalman filter, Wiener filter, feedforward neural network, and recurrent neural network (GRU). The Kalman filter and Wiener filter are historically popular BCI algorithms [<xref ref-type="bibr" rid="c1">1</xref>, <xref ref-type="bibr" rid="c43">43</xref>] that are computationally simple and make linear assumptions. The feedforward neural network and GRU are expressive nonlinear function approximators that have been proposed for neural decoding [<xref ref-type="bibr" rid="c54">54</xref>, <xref ref-type="bibr" rid="c75">75</xref>] and can be implemented causally. At each decoding time, both the feedforward neural network and the GRU leverage recent spiking history. The primary difference between the two is whether the networks process that history all at once (feedforward network) or sequentially (GRU).</p>
<p>Each method was evaluated on each of four datasets, generating predictions for behavioral variables on held-out test sets (<xref rid="fig4" ref-type="fig">Fig. 4</xref>). All decoders were provided with a trailing window of spiking observations (binned in 20 millisecond increments). The length of this trailing window was optimized separately for each decoder and dataset (and, like all hyperparameters, was chosen using validation data). For non-MINT decoders, hyperparameters were tuned, using Bayesian optimization, to maximize performance [<xref ref-type="bibr" rid="c76">76</xref>]. MINT’s few hyperparameters were less extensively optimized. For example, window length was optimized once per dataset, rather than separately for different sets of behavioral variables (as was done for the non-MINT decoders). This choice embraces an unusual and useful aspect of MINT: there is no need to retrain across behavioral variables. Once the neural state has been estimated, all behavioral variables are readily and equally decodable. Less-extensive optimization is unlikely to have put MINT at a meaningful disadvantage; MINT is robust across reasonable hyperparameters choices (<xref rid="figS1" ref-type="fig">Fig. S1</xref>).</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Comparison of decoding performance, for MINT and four additional algorithms, for four datasets and multiple decoded variables.</title>
<p>On a given trial, MINT decodes all behavioral variables in a unified way based on the same inferred neural state. For non-MINT algorithms, separate decoders were trained for each behavioral group. E.g. separate GRUs were trained to output ‘position’ and ‘velocity’ in MC_Maze. Parentheticals indicate the number of behavioral variables within a group. E.g. ‘position (2)’ has two components: x- and y-position. <italic>R</italic><sup>2</sup> is averaged across behavioral variables within a group. ‘Overall’ plots performance averaged across all behavioral groups. <italic>R</italic><sup>2</sup> for feedforward networks and GRUs are additionally averaged across runs for 10 random seeds. The Kalman filter is traditionally utilized for position- and velocity-based decoding and was therefore only used to predict these behavioral groups. Accordingly, the ‘overall’ category excludes the Kalman filter for datasets in which the Kalman filter did not contribute predictions for every behavioral group. Vertical offsets and vertical ticks are used to increase visibility of data.</p></caption>
<graphic xlink:href="535396v2_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>By necessity and desire, all comparisons were made offline, enabling benchmarked performance across a variety of tasks and decoded variables, where each decoder had access to the exact same data and recording conditions. There were 15 total ‘behavioral groups’ across the four datasets. For example, MC_Maze yielded two behavioral groups, position and velocity, each of which had horizontal and vertical components.</p>
<p>MINT yielded the best performance, of all decoders, for 11/15 behavioral groups. For 3 of the 4 behavioral groups where MINT’s performance was not the highest, the deficit relative to the best method was very small: Δ<italic>R</italic><sup>2</sup> &lt; .004. We first consider position and velocity, two variables commonly focused on in BCI decoding. For position, three decoders – MINT, the GRU, and the feedforward network – provided extremely similar and very accurate performance. For velocity, MINT provided a small but noticeable improvement over the GRU and the feedforward network for two datasets (MC_Maze and Area2_Bump), was modestly worse for one dataset (MC_RTT), and was involved in essentially a three-way tie for one dataset (MC_Cycle). MINT tended to display the largest improvements, relative to the next-best decoder, when decoding muscle-related variables (EMG, force, muscle velocity, and muscle length) and phase (circular variables can be challenging for some methods but are not for MINT). Relative to the other computationally ‘lightweight’ methods – the Wiener and Kalman filter – MINT’s performance was consistently better, often by a large margin.</p>
<p>For each dataset, we computed overall performance by simply averaging across behavioral groups. In three of the four datasets (all but MC_RTT, discussed further below), overall performance was highest for MINT. Thus, despite using simple and interpretable operations, MINT is extremely competitive with highly expressive machine learning methods. Within these three datasets (MC_Cycle, MC_Maze, Area2_Bump), MINT performed well for every individual behavioral group. This consistency reflects a feature noted above: once the neural state is estimated, it becomes possible to decode any behavioral variable that has a relationship with the neural state (though some, such as EMG, may of course be intrinsically ‘noisier’).</p>
<p>MINT’s lowest performance, relative to other decoders, occurred for the MC_RTT dataset. MINT outperformed the Kalman filter and Wiener filter. Yet improved decoding was achieved by the feedforward network and GRU. Thus, this was the only situation, across all datasets and behavioral groups, where MINT was ever at a meaningful performance disadvantage. A likely explanation is that the training data in the MC_RTT task are not ideally suited for estimating the library of trajectories, limiting subsequent performance on test data. Thus, if using MINT is a goal for tasks of this type, more structured training data (e.g. repeated trials of the same type) might be helpful. Alternatively, it may be sufficient simply to collect more training data. This dataset contains only 8.1 minutes of training data, which may limit the ability of AutoLFADS to estimate single-trial rates. If collecting more training data is impractical, there exist methods that improve estimation of single-trial rates (and thus trajectories) based on data from other sessions using the same task [<xref ref-type="bibr" rid="c38">38</xref>]. We do not pursue these avenues here, but simply stress that the principal limitation on MINT’s performance is likely to be the ability to estimate an accurate library of trajectories. When doing so is challenging, MINT may be at a disadvantage. Conversely, if a library can be accurately estimated, MINT is likely to perform well across a broad range of decoded variables. In this way, MINT can be seen as largely reducing the problem of decoding to a problem of estimating a library of trajectories.</p>
</sec>
<sec id="s2g">
<title>When is generalization possible across tasks?</title>
<p>A natural hope of BCI decoding is to find a mapping between neural and behavioral states that generalizes across tasks, eliminating the need for task-specific training data. Whether this is achievable is not known; a basic challenge is that neural activity can sometimes occupy different subspaces across tasks. To explore the implications of such geometry, we leveraged the MC_Cycle dataset. Neural activity during forward and backward cycling typically occurs in rather different subspaces [<xref ref-type="bibr" rid="c64">64</xref>]. In the dataset used here, those subspaces are quite close to orthogonal (principal angles of 88°and 73°between the top two principal components for forward steady-state cycling and the top two principal components for backward steady-state cycling). When asked to generalize across cycling directions, all decode methods (including MINT) generalized poorly. Across all behavioral groups and all decode methods, generalization <italic>R</italic><sup>2</sup> values were typically negative and the largest positive value was 0.042. This was true even though the marginal distributions of x- and y-position and x- and y-velocity were similar across cycling directions.</p>
<p>The failure of all methods makes sense given the near-orthogonality of forward and backward neural trajectories (<xref rid="figS2" ref-type="fig">Fig. S2</xref>). MINT has no decoding advantage in this regard, but its focus on the geometry of neural activity may make it easier to anticipate when generalization is and isn’t likely to be possible. When neural trajectories are nearly orthogonal to those learned during training, the existing ‘mesh’ will not support generalization. This knowledge allows such situations to be recognized and handled appropriately.</p>
</sec>
<sec id="s2h">
<title>Modeling &amp; preprocessing choices</title>
<p>MINT uses a direct mapping from neural states to behavioral states and uses interpolation to potentially improve decoding. To determine the impact of these choices, we ran a full factorial analysis comparing the direct mapping to a linear mapping (<xref rid="figS3" ref-type="fig">Fig. S3a</xref>), and assessing the impact of interpolation (<xref rid="figS3" ref-type="fig">Fig. S3b</xref>). Both choices did indeed improve performance. The analysis also assessed how acausal decoding performed relative to causal decoding (<xref rid="figS3" ref-type="fig">Fig. S3c</xref>). Causal decoding is a requirement for real-time BCIs, and thus is employed for all our main decoding analyses. However, future applications could potentially introduce a small lag into online decoding, effectively allowing some ‘acausal decoding’ at the expense of longer-latency responses. As expected, acausal decoding provided modest performance increases, raising the possibility of an interesting tradeoff. Decoding can be zero-lag (causal), positive-lag (acausal), or even negative-lag. The latter would result in a very ‘snappy’ decoder that anticipated actions at the expense of decoding accuracy. The lag hyperparameter wouldn’t need to be specified prior to training and could be freely adjusted at any time.</p>
<p>All datasets were curated to contain sorted spikes. Yet during online performance, decoding must typically rely on unsorted threshold crossings. Prior studies have found that moving from sorted spikes to threshold crossings produces a modest but tolerable drop in performance [<xref ref-type="bibr" rid="c77">77</xref>]. We similarly found that moving from sorted spikes to threshold crossings (selected to be from ‘good’ channels with reasonable signal-to-noise) produced only a small drop in performance (<xref rid="figS3" ref-type="fig">Fig. S3d</xref>). The operations of MINT highlight why robustness is expected. When spikes from two neurons are combined, the resulting ‘unit’ acts statistically as if it were a high firing-rate neuron. Spiking is still approximately Poisson, because the sum of Poisson processes is a Poisson process. Thus, MINT’s statistical assumptions remain appropriate.</p>
</sec>
<sec id="s2i">
<title>Neural state estimation</title>
<p>MINT’s success at behavioral decoding suggests underlying success in neural-state estimation. However, that would not necessarily have to be true. For example, the GRU also typically supported excellent behavioral decodes, but doesn’t provide neural state estimation. MINT does (by its very construction) but whether those estimates are accurate must be determined directly.</p>
<p>To evaluate neural-state estimates, we submitted firing-rate predictions to the Neural Latents Benchmark [<xref ref-type="bibr" rid="c78">78</xref>], an online benchmark for latent variable models that compares acausal neural-state estimates across methods and datasets. The four primary datasets for the benchmark are MC_Maze, Area2_Bump, MC_RTT, and an additional dataset, DMFC_RSG, that contains neural recordings from dorsomedial frontal cortex while a monkey performed a cognitive timing task [<xref ref-type="bibr" rid="c79">79</xref>]. Three secondary datasets (MC_Maze-L, MC_Maze-M, and MC_Maze-S) contain additional sessions of the maze task with progressively fewer training trials (500, 250, 100, respectively).</p>
<p>By submitting to the Neural Latents Benchmark, we can ask how MINT performs relative to a set of ‘baseline’ methods. One baseline method (smoothed spikes) is traditional and simple. Other baseline methods, Gaussian Process Factor Analysis (GPFA) and Switching Linear Dynamical System (SLDS), are modern yet well-established. Finally, two baseline methods are quite new and cutting-edge: Neural Data Transformers (NDT) [<xref ref-type="bibr" rid="c40">40</xref>] and AutoLFADS [<xref ref-type="bibr" rid="c39">39</xref>]. These are expected to provide a high bar by which to judge the performance of other approaches.</p>
<p>Although the neural state is a well-defined quantity in spiking models [<xref ref-type="bibr" rid="c33">33</xref>], experimental data does not typically provide a ground-truth neural state against which estimates can be compared (unlike for behavioral-state decoding). Yet one can define attributes the neural state should possess, then determine whether estimates display those attributes. One critical attribute is prediction of spiking activity. This attribute is assessed via bits per spike, which is closely related to the log-likelihood of spiking observations given a set of firing rates (assuming Poisson spiking). MINT performed similarly to AutoLFADS and was consistently slightly better than NDT on the four primary datasets (<xref rid="fig5" ref-type="fig">Fig. 5a</xref>, <italic>left</italic>). MINT performed slightly better than AutoLFADS and NDT on the largest of the secondary datasets, and that advantage grew as dataset-size became smaller (<xref rid="fig5" ref-type="fig">Fig. 5a</xref>, <italic>right</italic>). MINT outperformed the other three baseline methods by modest-to-sizeable margins for all seven datasets.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Evaluation of neural state estimates for seven datasets.</title>
<p><bold>a)</bold> Performance quantified using bits per spike. The benchmark’s baseline methods have colored markers. All other submissions have gray markers. Vertical offsets and vertical ticks are used to increase visibility of data. Results with negative values are designated by markers to the left of zero, but their locations don’t reflect the magnitude of the negative values. Data from Neural Latents Benchmark (<ext-link ext-link-type="uri" xlink:href="https://neurallatents.github.io/">https://neurallatents.github.io/</ext-link>). <bold>b)</bold> Performance quantified using PSTH <italic>R</italic><sup>2</sup>. <bold>c)</bold> Performance quantified using velocity <italic>R</italic><sup>2</sup>, after velocity was decoded linearly from the neural state estimate. A linear decode is used simply as a way of evaluating the quality of neural state estimates, especially in dimensions relevant to behavior.</p></caption>
<graphic xlink:href="535396v2_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>MINT was not designed to maximize bits per spike – good performance in this regard simply results from the primary goal of estimating a neural state that is expressed in terms of firing rates. This matters because there exist spiking features – e.g. synchrony beyond that due to correlated rates – that some methods may be able to leverage. Doing so is reasonable but separate from MINT’s goal of estimating a rate-based neural state. It is thus worth considering other attributes expected of good neural-state estimates. The Neural Latents Benchmark includes two such attributes.</p>
<p>First, good neural state estimates should be correct on average. Although ground-truth trial-averaged neural states are also unavailable, they can be approximated by PSTHs (trial-averaged smoothed spikes for each condition). Thus, trial-averaged neural state estimates should resemble PSTHs from the same condition, an attribute assessed by PSTH <italic>R</italic><sup>2</sup>. MINT achieved higher <italic>R</italic><sup>2</sup> values than every other method on every dataset (<xref rid="fig5" ref-type="fig">Fig. 5b</xref>). This result relates to the fact that MINT estimates neural states near idealized trajectories ‘built’ from trial-averaged rates. Yet strong performance is not a trivial consequence of MINT’s design; PSTH <italic>R</italic><sup>2</sup> will be high only if condition (<italic>c</italic>), index (<italic>k</italic>), and the interpolation parameter (<italic>α</italic>) are accurately estimated.</p>
<p>Second, in sensorimotor areas during motor tasks, behavior should be decodable from the neural state. The benchmark thus measured <italic>R</italic><sup>2</sup> for a linear decode of velocity from the neural state. MINT outperformed all baseline approaches (<xref rid="fig5" ref-type="fig">Fig. 5c</xref>) for all datasets. (MINT could of course have achieved even better decoding using its typical direct association, but that would have undermined the utility of this comparison).</p>
<p>In addition to the five baseline methods, the Neural Latents Benchmark solicited submissions from other methods and many were submitted. These submissions spanned a broad range in terms of performance (gray vertical lines in <xref rid="fig5" ref-type="fig">Fig. 5</xref>), highlighting the challenging nature of this problem. Some submissions involved ensemble approaches, some of which outperformed both MINT and the baseline methods in terms of bits per spike. For the primary datasets, the highest bits per spike overall was achieved by an ensemble of SpatioTemporal Neural Data Transformers [<xref ref-type="bibr" rid="c80">80</xref>], achieving .386 bits per spike on the MC_Maze dataset, compared to .330 for MINT. For the smaller secondary datasets, the very best submissions provided minimal-to-modest improvement over MINT in terms of bits per spike (<xref rid="fig5" ref-type="fig">Fig. 5a</xref>, <italic>right</italic>), and the majority performed less well.</p>
<p>The ability of some expressive neural networks (and some ensembles of these networks) to improve the bits per spike metric indicates there exists variability in the neural recordings that MINT does not capture. That variability could arise from behaviorally irrelevant fluctuations in the neural state, from synchrony based effects, or from instabilities in the neural recordings. These are ‘real’ things and it is thus valid for a method to leverage them to predict spiking when that is the goal. Yet as noted above, they may often be incidental to one’s goals in estimating the neural state, highlighting the need to consider additional attributes such as PSTH <italic>R</italic><sup>2</sup> and velocity <italic>R</italic><sup>2</sup>. For PSTH <italic>R</italic><sup>2</sup>, MINT outperformed all other methods for all six datasets. For velocity <italic>R</italic><sup>2</sup>, MINT had the best performance for three out of six datasets and was very close to the highest <italic>R</italic><sup>2</sup> values for the remaining three datasets (the largest deficit was Δ<italic>R</italic><sup>2</sup> = .012) (<xref rid="fig5" ref-type="fig">Fig. 5c</xref>).</p>
<p>In summary, MINT’s strong decode performance (<xref rid="fig4" ref-type="fig">Fig. 4</xref>) does indeed follow from good neural-state estimation. MINT provided estimates that were competitive with the best present methods. This includes existing well-documented methods, as well as a bevy of additional submissions. This implies that MINT could be used in situations where neural-state estimation is the goal, possibly including monitoring of the neural state for clinical purposes. MINT uses simple operations and is readily implemented causally – indeed this is typically how we would expect to see it used. Yet MINT’s performance is typically similar to – and often better than – that of complex methods that would likely have to be limited to offline situations.</p>
</sec>
<sec id="s2j">
<title>Practical considerations</title>
<sec id="s2j1">
<title>Training &amp; execution times</title>
<p>MINT is typically very fast to train (<xref rid="tbl1" ref-type="table">Table 1</xref>), on the order of seconds using generic hardware (no GPUs). Fast training is a consequence of the simple operations involved in constructing the library of neural-state trajectories: principally filtering of spikes and averaging across trials. Thus, MINT can be trained extremely quickly. At the same time we stress that MINT is a method for leveraging a trajectory library, not a method for constructing it. One may sometimes wish to use alternatives to trial-averaging, either of necessity or because they improve trajectory estimates. For example, for the MC_RTT task we used AutoLFADS to infer the library and training was consequently much slower (hours rather than seconds). Training time could be reduced back to seconds using a different approach – grouping into pseudo-conditions – but performance was then reduced by a modest but meaningful amount. Thus, training will typically be very fast, but one may choose time-consuming methods when appropriate.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><title>MINT training times and average execution times (average time it took to decode a 20 ms bin of spiking observations).</title>
<p>To be appropriate for real-time applications, execution times must be shorter than the bin width. Note that the 20 ms bin width does not prevent MINT from decoding every millisecond; MINT updates the inferred neural state and associated behavioral state between bins, using neural and behavioral trajectories that are sampled every millisecond. For all table entries (except MC_RTT training time), means and standard deviations were computed across 10 train/test runs for each dataset. Training times exclude loading datasets into memory and any hyperparameter optimization. Timing measurements taken on a Macbook Pro (on CPU) with 32GB RAM and a 2.3 GHz 8-Core Intel Core i9 processor. For MC_RTT, training involved running AutoLFADS twice (and averaging the resulting rates) to generate neural trajectories. This training procedure utilized 10 GPUs and took <italic>∼</italic>1.6 hours per run. For AutoLFADS, hyperparameter optimization and model fitting procedures are intertwined. Thus, the training time reported includes time spent optimizing hyperparameters.</p></caption>
<graphic xlink:href="535396v2_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>Execution times were well below the threshold needed for real-time applications (<xref rid="tbl1" ref-type="table">Table 1</xref>), even using a laptop computer. State estimation in MINT is 𝒪 (<italic>NC</italic>) when making the simplifying assumption that all conditions are of equal length. Thus, the computational burden grows only linearly with neurons or with conditions. Additionally, much of the estimation procedure in MINT is condition-specific and therefore parallelizable. This makes MINT a good candidate for decoding in BCI applications that involve large neuron counts and/or large behavioral repertoires.</p>
</sec>
<sec id="s2j2">
<title>Performance on small training sets</title>
<p>To investigate robustness to training with small trial-counts, we leveraged the fact that the four maze-reaching datasets – one primary (MC_Maze), and three secondary (MC_Maze-L, MC_Maze-M, and MC_Maze-S) – contained training sets of decreasing size. For comparison, we chose the GRU and the feedforward neural network because of their generally good position- and velocity-decoding performance (<xref rid="fig4" ref-type="fig">Fig. 4</xref>).</p>
<p>On the largest training set, MINT and the GRU achieved similar performance for position decoding (<xref rid="fig6" ref-type="fig">Fig. 6a</xref>, <italic>R</italic><sup>2</sup> = .963 and <italic>R</italic><sup>2</sup> = .962, respectively). The performance gap widened as training sets became smaller (<italic>R</italic><sup>2</sup> = .926 versus <italic>R</italic><sup>2</sup> = .880 for the smallest dataset). Similar results were found for velocity decoding: the performance gap between MINT and the GRU widened for smaller training sets. Thus, MINT was quite robust to small training sets: an approximately five-fold reduction in training data led to a decline in <italic>R</italic><sup>2</sup> of only .037 (position) and .050 (velocity). The feedforward network did not show as consistent a performance rolloff with number of training trials, but also underperformed overall.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Decoding robustness in the face of small training sets and neuron counts.</title>
<p><bold>a)</bold> <italic>R</italic><sup>2</sup> values for MINT and two neural network decoders (GRU and the feedforward network) when decoding position and velocity from four maze datasets with progressively fewer training trials per condition. <bold>b)</bold> <italic>R</italic><sup>2</sup> values for MINT and the Wiener filter when decoding position and velocity from MC_Maze-L with progressively fewer neurons. ‘Retrained’ results (<italic>solid lines</italic>) show mean performance (across 50 random drops at each neuron count) when the decoders are trained and tested on reduced neuron sets. ‘Zeroed’ results (<italic>dashed lines</italic>) show mean performance when the decoders are trained on all 162 neurons and, during testing, the ‘dropped’ neurons’ spike counts are set to zero without retraining the decoder. Shaded regions depict standard errors across repeated droppings with different neurons.</p></caption>
<graphic xlink:href="535396v2_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2j3">
<title>Recording instabilities</title>
<p>With respect to recording quality, one desires two types of robustness. First, allowing for retraining, decoding should be robust to the across-session loss of neurons. To simulate such loss, we performed a neuron dropping analysis on the MC_Maze-L dataset (<xref rid="fig6" ref-type="fig">Fig. 6b</xref>, <italic>solid lines</italic>). Training was repeated after neurons were dropped. Average <italic>R</italic><sup>2</sup> for position decoding remained above 95% of peak performance until fewer than 58 neurons (of 162) remained. Results were similar for velocity decoding: performance was &gt;95% of its peak until fewer than 62 neurons remained. We repeated this analysis for the Wiener filter. Despite its overall lower performance, the Wiener filter provides a useful comparison because (like MINT) it is easy to retrain quickly, with reliable results, across the many differently sized training sets examined here. The Wiener filter was also fairly robust, but less so than MINT. To remain above 95% of peak performance, the Wiener filter needed approximately twice as many remaining neurons: 118 (Wiener filter) versus 58 (MINT) for position and 126 (Wiener filter) versus 62 (MINT) for velocity.</p>
<p>Second, because there can be occasional within-session loss of isolations or individual channels, one desires robustness to modest neuron loss even without retraining. We simulated within-session neuron loss by eliminating all spikes from a subset of neurons (<xref rid="fig6" ref-type="fig">Fig. 6b</xref>, <italic>dashed lines</italic>) with no retraining. MINT’s performance was robust to modest neuron loss. Losing fewer than 20 neurons caused essentially no performance loss. Position and velocity decoding remained above 95% of peak performance until fewer than 113 and 109 neurons remained, respectively. In contrast, the Wiener filter had a more linear performance roll off.</p>
<p>Thus, MINT is robust to modest neuron-loss without retraining. At the same time, we stress that ‘retraining’ MINT to account for neuron loss is incredibly simple – it simply involves ignoring that neuron when computing spike likelihoods. Unlike nearly all other methods (including the Wiener filter) the loss of one neuron does not require changing parameters that apply to other neurons. Thus, if neuron loss is detected, retraining can occur on the fly with no need to pause decoding.</p>
</sec>
<sec id="s2j4">
<title>Interpretability</title>
<p>One form of interpretability relates to whether an algorithm uses ‘black box’ optimization to learn a solution. Neural networks can be highly expressive and learn constraints directly from data. This approach is useful when appropriate constraints are unclear. However, when constraints are known, one can rely more on model assumptions and less on expressivity, yielding robust methods that perform accurately with less training data. MINT is an interpretable algorithm that relies on strong assumptions.</p>
<p>The performance of interpretable methods can reflect the extent to which their assumptions match the statistics of the data. Consider the Kalman filter – an interpretable algorithm – and its performance on the MC_Maze reaching dataset. The Kalman filter produces a relatively poor decode (<italic>R</italic><sup>2</sup> = .609 for hand velocity). This doesn’t imply the Kalman filter is a poor algorithm, simply that its assumptions may not be well-aligned with the data. We confirmed this by generating synthetic data whose properties are closer to those assumed by the Kalman filter. The Kalman filter then performed quite competitively (<xref rid="figS4" ref-type="fig">Fig. S4</xref>). While expected, this result underscores an important point. MINT does not outperform the Kalman filter because it is intrinsically a better method. Instead, MINT performs well because its assumptions, guided by an understanding of neural geometry, are presumably a good match to the underlying properties of the data.</p>
<p>MINT is also interpretable regarding why each prediction is made. Suppose that, at a given moment during decoding, MINT selects neural state <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline5.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> as the most likely state, and thus renders its decode using the associated behavioral state <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline6.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. Selection of <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline7.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> comes with an associated likelihood that conveys information regarding how well the spiking data matched that neural state. Likelihoods are known not only for this ‘selected’ state, but for all non-selected states on all trajectories in the library. These likelihoods can be analyzed to understand why the selected state was chosen over the others, how close the algorithm was to selecting a different state, and which neurons contributed most strongly to state selection. Because of its probability-based approach, MINT is readily modifiable and extensible in a variety of ways (<xref rid="figS5" ref-type="fig">Fig. S5</xref>).</p>
</sec>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<sec id="s3a">
<title>Implications regarding neural geometry</title>
<p>All neural decode algorithms and state estimators make assumptions regarding the structure of neural activity and/or its relationship to behavior. Correctly specifying these assumptions can yield accurate, interpretable methods. MINT is the outcome of our endeavor to codify observations regarding motor-cortex population geometry into statistical assumptions for a decoder. Some observations are recent and some are documented here for the first time.</p>
<p>Low trajectory tangling [<xref ref-type="bibr" rid="c64">64</xref>] creates sparsely distributed trajectories whose geometry differs from behavioral trajectories, both muscle and kinematic. In particular, distance is poorly preserved between neural and behavioral trajectories. Neighboring states in behavioral space can be quite distant in neural space. These observations challenge two common assumptions regarding motor cortex activity. The first is that there exist strong isometries between neural activity and to-be-decoded parameters. Traditional tuning-centric hypotheses embody this assumption. Yet even as the field has moved towards factor-dynamics based hypotheses, it has remained reasonable to assume strong isometries in a subset of high-variance dimensions. Yet as the model spiking network in <xref rid="fig3" ref-type="fig">Figure 3b</xref> illustrates, it is also likely that motor-cortex outputs are encoded in low-variance dimensions. If so, isometry-based decoding becomes limited to low-variance dimensions, or to isometries that are incidental and task-specific [<xref ref-type="bibr" rid="c20">20</xref>]. MINT avoids the need to make assumptions regarding isometries by using a direct decode.</p>
<p>The second common assumption is that the range of observable neural states can be approximately described by a covariance matrix, and/or by the associated low-dimensional subspace obtained from a subset of its eigenvectors (the principal components). There has always been some tension associated with this assumption. Dimensionality reduction has been – and almost certainly will continue to be – a powerful analysis tool. Competing hypotheses often make contrasting predictions regarding what occurs in high-variance dimensions. Dimensionality reduction methods are ideally suited for testing those predictions. At the same time, it is unclear when and whether motor-cortex trajectories are themselves low-dimensional. Even in studies that explicitly consider an occupied subspace, that subspace is high-dimensional relative to traditional assumptions [<xref ref-type="bibr" rid="c81">81</xref>], and learning can ‘open up’ new dimensions [<xref ref-type="bibr" rid="c82">82</xref>]. Studies have also stressed the possibility of a nonlinear manifold embedded in a higher-dimensional subspace [<xref ref-type="bibr" rid="c83">83</xref>–<xref ref-type="bibr" rid="c86">86</xref>]. Nonlinear dimensionality reduction techniques can reveal a manifold’s topology or how the manifold relates to external behavioral variables (e.g. [<xref ref-type="bibr" rid="c51">51</xref>]). Multiple studies have stressed the remarkably high-dimensional nature of motor cortex activity [<xref ref-type="bibr" rid="c67">67</xref>, <xref ref-type="bibr" rid="c68">68</xref>, <xref ref-type="bibr" rid="c87">87</xref>, <xref ref-type="bibr" rid="c88">88</xref>]. Network models of motor cortex activity [<xref ref-type="bibr" rid="c89">89</xref>, <xref ref-type="bibr" rid="c90">90</xref>] have a high ratio of across-neuron dimensionality to across-condition dimensionality [<xref ref-type="bibr" rid="c87">87</xref>]. Networks that produce extended temporally structured outputs can leverage trajectories whose geometry resembles complex and well-separated ‘tubes’ embedded in a very high-dimensional space [<xref ref-type="bibr" rid="c91">91</xref>].</p>
<p>Present results – both analysis of data and the successful decode provided by MINT – support the idea that ‘subspace dimensionality’ may not be the best way to describe the constraints governing neural trajectories. Low trajectory tangling can, depending on the circumstances, be compatible with either low or high dimensionality. What is more likely to be consistent are properties of the not-easily-described nonlinear manifold, where large ‘voids’ (e.g. the middle of circular trajectories) remain unoccupied [<xref ref-type="bibr" rid="c64">64</xref>, <xref ref-type="bibr" rid="c65">65</xref>]. Precisely because this geometry is difficult to describe with a model, MINT approximates the manifold using the empirical trajectories as a ‘scaffolding’, with interpolation producing a mesh of states that are considered during decoding.</p>
<p>Embracing these aspects of trajectory geometry produced excellent performance: MINT accurately estimated the neural state and decoded a broad range of behavioral variables across a variety of tasks and brain areas. Good decode performance, on its own, is insufficient to validate the assumptions of a decode method and we stress caution in that regard. This is particularly true because many of the scientific findings that inspired MINT are not, strictly speaking, assumptions of the method itself. MINT is designed to work well when trajectories are sparsely distributed, with low tangling, and spread out in a high-dimensional space. Yet MINT can perform well in the absence of these features. For example, MINT performed well on simulated data that was instead well-matched to the assumptions of a Kalman filter (MINT and the Kalman filter performed comparably well in that case).</p>
<p>Thus, good decode performance does not necessarily imply MINT’s assumptions are uniquely correct. Nevertheless, comparisons can aid interpretation. For the empirical data, MINT consistently outperformed the Kalman filter, often by a wide margin. This indicates that the data contain properties that MINT, but not the Kalman filter, is poised to leverage. Given the analysis in <xref rid="fig1" ref-type="fig">Figure 1</xref>, some of the most likely properties are those that motivated MINT’s design: sparsely distributed low-tangled trajectories. MINT’s assumption of Poisson spiking statistics may also have contributed, yet MINT had a much smaller advantage for simulated data where spiking was Poisson but neural geometry matched the Kalman filter’s assumptions <xref rid="figS4" ref-type="fig">Fig. S4</xref>. Thus, it is likely that MINT gains much of its advantage via constraints on the neural-state geometry that are more accurate than those imposed by the Kalman filter. Comparison with expressive machine-learning approaches makes a similar point from the other direction. Highly expressive methods, through training, should be able to learn and leverage a range of neural constraints. Given that MINT was competitive with these methods, its assumptions are likely to be a good match to the statistics of the data.</p>
</sec>
<sec id="s3b">
<title>Generalization</title>
<p>MINT readily performs certain types of generalization. Interpolation allows MINT to generalize spatially, to neural states (and corresponding behavioral states) that are between trajectories observed during training. MINT can also generalize temporally, by selecting mostly-likely states that move faster (or slower) in neural state space than those present during training. MINT can also generalize compositionally: switching between trajectories or exiting them early. As a simple example, a library consisting of a single 4-cycle trajectory from the cycling task would allow MINT to decode a 2-cycle movement or a 200-cycle movement. Thus, MINT is not stuck on the library trajectories, nor is it stuck traversing trajectories at fixed speeds or for fixed durations.</p>
<p>Yet while MINT can follow trajectories through the mesh that are quite different from those in the library, all decoded states will be on the mesh. MINT is not capable of generalizing to trajectories that traverse regions of state space far from the mesh. This is relevant, because empirical evidence indicates that ‘new’ behaviors can sometimes be associated with neural trajectories that are very different from all previously observed trajectories – often occupying orthogonal subspaces [<xref ref-type="bibr" rid="c64">64</xref>, <xref ref-type="bibr" rid="c92">92</xref>–<xref ref-type="bibr" rid="c94">94</xref>]. MINT could be modified to allow extrapolation outside the library, but we suspect that this form of generalization will still not typically be available. As illustrated in <xref rid="figS2" ref-type="fig">Figure S2</xref>, it will be extremely difficult for any decoder to successfully decode neural trajectories that are orthogonal to those in the training set. For example, none of the methods we evaluated were able to generalize from forward to backward cycling, which were associated with nearly orthogonal neural trajectories. However, MINT’s computation of log-likelihoods does lend it a potential advantage in handling novel or unexpected behaviors. Using the training set, one can roughly estimate the distribution of log-likelihoods. If, during decoding, log-likelihoods become vastly lower than expected, that suggests decoding is struggling with a movement too far from the training set. This knowledge would give the technician options, including decoding zero movement (on the grounds that no movement is better than a large error) or pausing to retrain. The latter could leverage another advantage of MINT: adding a trajectory to the library – and thus expanding the mesh – is simple and no other retraining or modification of parameters is needed.</p>
</sec>
<sec id="s3c">
<title>Multi-task decoding</title>
<p>Across-task generalization may often be limited by the above considerations. Yet this does not imply that MINT cannot decode in a multi-task regime. On the contrary, MINT is ideally suited to decoding from a behavioral repertoire spanning two or more tasks – each task simply needs to be represented in the mesh with an appropriate set of trajectories. And as noted above, trajectories corresponding to a new task can be easily added to the library.</p>
<p>MINT’s facility with multi-task decoding is particularly relevant because, historically, decoding approaches have had to vary across tasks. For example, linear decoding of velocity works well during reaching but not cycling [<xref ref-type="bibr" rid="c20">20</xref>]. Nevertheless, Schroeder et al. [<xref ref-type="bibr" rid="c20">20</xref>] were able to achieve accurate closed-loop decoding of cycling by nonlinearly leveraging statistical regularities in a task-specific neural subspace. MINT embraces both task-specificity and unification. Each task contributes a unique set of trajectories to the mesh. A unified decoding strategy then applies both within and across tasks. This avoids the need to engineer bespoke decoders for each task individually and facilitates multi-task decoding that doesn’t rely on an additional meta-decoder to identify the appropriate task-specific decoder at each moment.</p>
</sec>
<sec id="s3d">
<title>Future avenues</title>
<p>MINT’s probability-based framework is amenable to principled extensions. Rather than simply decode the state with the highest data likelihood, one could incorporate priors. Priors could be fixed or guided by incoming information (e.g. an eye tracker). Decoding could focus on utility functions rather than probabilities; a patient may value avoiding certain types of errors more than others. For example, erroneous transitions from stationary to moving may be jarring or unsafe, and could be dissuaded via an appropriately designed utility function.</p>
<p>As noted above, MINT is amenable to a variety of methods – simple or sophisticated – for inferring the trajectory library. Possible future approaches include leveraging the typical neural geometry for a particular task to allow a patient-specific mesh to be learned using fewer trials. This might even be done in an unsupervised way (similar to Dyer et al. [<xref ref-type="bibr" rid="c95">95</xref>]): a trajectory library could be built without behavioral labels, then appropriately linked to a ‘reference’ behavioral library via prior knowledge of task-specific neural geometry. As a simple example, cycling across different speeds produces a tube-shaped manifold with different velocities at each end [<xref ref-type="bibr" rid="c65">65</xref>]. An empirically observed tube might be given behavioral labels based on this knowledge. These observations may be relevant to a primary goal of MINT: potential use as an online decoder for real-time closed-loop performance. In situations involving paralyzed patients, training may involve asking subjects to observe and/or attempt movements, both of which engage neurons in motor cortex [<xref ref-type="bibr" rid="c96">96</xref>], but may create uncertainty regarding the exact behavioral label for each moment. The above strategies may aid in this regard. The approach of Gilja et al. [<xref ref-type="bibr" rid="c13">13</xref>] would also likely be helpful. They found that re-fitting Kalman filter parameters online improved closed-loop performance. One could similarly use an initial mesh to allow decoding to gain traction, then ‘re-mesh’ MINT online to improve performance.</p>
</sec>
</sec>
<sec id="d1e1484" sec-type="supplementary-material">
<title>Supporting information</title>
<supplementary-material id="d1e1570">
<label>Supplementary Video</label>
<media xlink:href="supplements/535396_file02.mp4"/>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<title>Acknowledgments</title>
<p>We thank Felix Pei, Chethan Pandarinath, and the rest of the Neural Latents Benchmark team for curating many of the datasets used in this paper and releasing them publicly. We thank those who originally collected those datasets: Raeed Chowdhury (Area2_Bump), Hansem Sohn (DMFC_RSG), Matt Kaufman and Mark Churchland (MC_Maze, MC_Maze-L,M,S), and Joseph O’Doherty (MC_RTT). We additionally thank Felix and Chethan for providing AutoLFADS rates for the MC_RTT dataset. We thank Karen Schroeder for collecting and preprocessing the MC_Cycle dataset in collaboration with the first and last authors. We thank Yana Pavlova for expert animal care while collecting the MC_Cycle dataset. We thank Brian DePasquale for providing code for simulating the artificial multitask spiking network. We thank Andrew Zimnik, Elom Amematsro, and Eric Trautmann for helping to present this work at NCM 2022 when the first author had COVID. This work was supported by the Simons Foundation and the Grossman Center for the Statistics of Mind.</p>
</ack>
<sec id="s4">
<title>Author contributions</title>
<p>SP and MC designed the decoder. JC provided input on how to conceptualize and formalize the decoder. SP wrote the software. SP and MC designed data analyses. SP performed analyses. QW provided guidance regarding analyses. SP and MC wrote the paper. All authors contributed to editing.</p>
</sec>
<sec id="s5">
<title>Competing interests</title>
<p>SP, JC, and MC hold a patent pertaining to this work. The patent has been licensed to Blackrock Neurotech. The authors declare no additional competing interests.</p>
</sec>
<sec id="s6">
<title>Code availability</title>
<list list-type="bullet">
<list-item><p>MINT is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/seanmperkins/mint">https://github.com/seanmperkins/mint</ext-link> (MATLAB).</p></list-item>
<list-item><p>Other decoders are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/seanmperkins/bci-decoders">https://github.com/seanmperkins/bci-decoders</ext-link> (Python).</p></list-item>
<list-item><p>Multitask spiking network was simulated with code from DePasquale et al. [<xref ref-type="bibr" rid="c33">33</xref>] that is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/briandepasquale/factor-based-spiking-nets/">https://github.com/briandepasquale/factor-based-spiking-nets/</ext-link> (MATLAB).</p></list-item>
</list>
</sec>
<sec id="s7">
<title>Data availability</title>
<p>All empirical datasets (except MC_Cycle) were curated by the Neural Latents Benchmark team [<xref ref-type="bibr" rid="c78">78</xref>] and made publicly available on DANDI (linked below). The MC_Cycle dataset is available upon request. Useful functions for loading the DANDI datasets are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/neurallatents/nlb_tools">https://github.com/neurallatents/nlb_tools</ext-link>.</p>
<list list-type="bullet">
<list-item><p>Area2_Bump: <ext-link ext-link-type="uri" xlink:href="https://dandiarchive.org/dandiset/000127">https://dandiarchive.org/dandiset/000127</ext-link></p></list-item>
<list-item><p>DMFC_RSG: <ext-link ext-link-type="uri" xlink:href="https://dandiarchive.org/dandiset/000130">https://dandiarchive.org/dandiset/000130</ext-link></p></list-item>
<list-item><p>MC_Maze: <ext-link ext-link-type="uri" xlink:href="https://dandiarchive.org/dandiset/000128">https://dandiarchive.org/dandiset/000128</ext-link></p></list-item>
<list-item><p>MC_Maze-L: <ext-link ext-link-type="uri" xlink:href="https://dandiarchive.org/dandiset/000138">https://dandiarchive.org/dandiset/000138</ext-link></p></list-item>
<list-item><p>MC_Maze-M: <ext-link ext-link-type="uri" xlink:href="https://dandiarchive.org/dandiset/000139">https://dandiarchive.org/dandiset/000139</ext-link></p></list-item>
<list-item><p>MC_Maze-S: <ext-link ext-link-type="uri" xlink:href="https://dandiarchive.org/dandiset/000140">https://dandiarchive.org/dandiset/000140</ext-link></p></list-item>
<list-item><p>MC_RTT: <ext-link ext-link-type="uri" xlink:href="https://dandiarchive.org/dandiset/000129">https://dandiarchive.org/dandiset/000129</ext-link></p></list-item>
</list>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="journal"><string-name><given-names>Jose M.</given-names> <surname>Carmena</surname></string-name> <etal>et al.</etal> “<article-title>Learning to Control a Brain–Machine Interface for Reaching and Grasping by Primates</article-title>”. <source>In: PLoS Biology</source> <volume>1</volume>.<issue>2</issue> (<year>2003</year>), <fpage>e42</fpage>. ISSN: <issn>1544-9173</issn>. DOI: <pub-id pub-id-type="doi">10.1371/journal.pbio.0000042</pub-id>.</mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="journal"><string-name><given-names>Leigh R.</given-names> <surname>Hochberg</surname></string-name> <etal>et al.</etal> “<article-title>Neuronal ensemble control of prosthetic devices by a human with tetraplegia</article-title>”. <source>In: Nature</source> <volume>442</volume>.<issue>7099</issue> (<year>2006</year>), pp. <fpage>164</fpage>–<lpage>171</lpage>. ISSN: <issn>0028-0836</issn>. DOI: <pub-id pub-id-type="doi">10.1038/nature04970</pub-id>.</mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><string-name><given-names>Meel</given-names> <surname>Velliste</surname></string-name> <etal>et al.</etal> “<article-title>Cortical control of a prosthetic arm for self-feeding</article-title>”. <source>In: Nature</source> <volume>453</volume>.<issue>7198</issue> (<year>2008</year>), pp. <fpage>1098</fpage>–<lpage>1101</lpage>. ISSN: <issn>0028-0836</issn>. DOI: <pub-id pub-id-type="doi">10.1038/nature06996</pub-id>.</mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="journal"><string-name><given-names>Leigh R.</given-names> <surname>Hochberg</surname></string-name> <etal>et al.</etal> “<article-title>Reach and grasp by people with tetraplegia using a neurally controlled robotic arm</article-title>”. <source>In: Nature</source> <volume>485</volume>.<issue>7398</issue> (<year>2012</year>), pp. <fpage>372</fpage>–<lpage>375</lpage>. ISSN: <issn>0028-0836</issn>. DOI: <pub-id pub-id-type="doi">10.1038/nature11076</pub-id>.</mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="journal"><string-name><given-names>Jennifer L.</given-names> <surname>Collinger</surname></string-name> <etal>et al.</etal> “<article-title>High-performance neuroprosthetic control by an individual with tetraplegia</article-title>”. <source>In: The Lancet</source> <volume>381</volume>.<issue>9866</issue> (<year>2013</year>), pp. <fpage>557</fpage>–<lpage>564</lpage>. ISSN: <issn>0140-6736</issn>. DOI: <pub-id pub-id-type="doi">10.1016/s0140-6736(12)61816-9</pub-id>.</mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="journal"><string-name><given-names>B</given-names> <surname>Wodlinger</surname></string-name> <etal>et al.</etal> “<article-title>Ten-dimensional anthropomorphic arm control in a human brain-machine interface: difficulties, solutions, and limitations</article-title>”. <source>In: Journal of Neural Engineering</source> <volume>12</volume>.<issue>1</issue> (<year>2015</year>), p. <fpage>016011</fpage>. ISSN: <issn>1741-2552</issn>. DOI: <pub-id pub-id-type="doi">10.1088/1741-2560/12/1/016011</pub-id>.</mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="journal"><string-name><given-names>Chet T.</given-names> <surname>Moritz</surname></string-name>, <string-name><given-names>Steve I.</given-names> <surname>Perlmutter</surname></string-name>, and <string-name><given-names>Eberhard E.</given-names> <surname>Fetz</surname></string-name>. “<article-title>Direct control of paralysed muscles by cortical neurons</article-title>”. <source>In: Nature</source> <volume>456</volume>.<issue>7222</issue> (<year>2008</year>), pp. <fpage>639</fpage>–<lpage>642</lpage>. ISSN: <issn>0028-0836</issn>. DOI: <pub-id pub-id-type="doi">10.1038/nature07418</pub-id>.</mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="journal"><string-name><given-names>C.</given-names> <surname>Ethier</surname></string-name> <etal>et al.</etal> “<article-title>Restoration of grasp following paralysis through brain-controlled stimulation of muscles</article-title>”. <source>In: Nature</source> <volume>485</volume>.<issue>7398</issue> (<year>2012</year>), pp. <fpage>368</fpage>–<lpage>371</lpage>. ISSN: <issn>0028-0836</issn>. DOI: <pub-id pub-id-type="doi">10.1038/nature10987</pub-id>.</mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="journal"><string-name><given-names>Chad E.</given-names> <surname>Bouton</surname></string-name> <etal>et al.</etal> “<article-title>Restoring cortical control of functional movement in a human with quadriplegia</article-title>”. <source>In: Nature</source> <volume>533</volume>.<issue>7602</issue> (<year>2016</year>), pp. <fpage>247</fpage>–<lpage>250</lpage>. ISSN: <issn>0028-0836</issn>. DOI: <pub-id pub-id-type="doi">10.1038/nature17435</pub-id>.</mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="journal"><string-name><given-names>A. Bolu</given-names> <surname>Ajiboye</surname></string-name> <etal>et al.</etal> “<article-title>Restoration of reaching and grasping movements through brain-controlled muscle stimulation in a person with tetraplegia: a proof-of-concept demonstration</article-title>”. <source>In: The Lancet</source> <volume>389</volume>.<issue>10081</issue> (<year>2017</year>), pp. <fpage>1821</fpage>–<lpage>1830</lpage>. ISSN: <issn>0140-6736</issn>. DOI: <pub-id pub-id-type="doi">10.1016/s0140-6736(17)30601-3</pub-id>.</mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="other"><string-name><given-names>Dawn M.</given-names> <surname>Taylor</surname></string-name>, <string-name><given-names>Stephen I. Helms</given-names> <surname>Tillery</surname></string-name>, and <string-name><given-names>Andrew B.</given-names> <surname>Schwartz</surname></string-name>. “<article-title>Direct Cortical Control of 3D Neuroprosthetic Devices</article-title>”. <source>In: Science</source> (<year>2002</year>).</mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="journal"><string-name><given-names>Mijail D.</given-names> <surname>Serruya</surname></string-name> <etal>et al.</etal> “<article-title>Instant neural control of a movement signal</article-title>”. <source>In: Nature</source> <volume>416</volume>.<issue>6877</issue> (<year>2002</year>), pp. <fpage>141</fpage>–<lpage>142</lpage>. ISSN: <issn>0028-0836</issn>. DOI: <pub-id pub-id-type="doi">10.1038/416141a</pub-id>.</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="journal"><string-name><given-names>Vikash</given-names> <surname>Gilja</surname></string-name> <etal>et al.</etal> “<article-title>A high-performance neural prosthesis enabled by control algorithm design</article-title>”. <source>In: Nature Neuroscience</source> <volume>15</volume>.<issue>12</issue> (<year>2012</year>), pp. <fpage>1752</fpage>–<lpage>1757</lpage>. ISSN: <issn>1097-6256</issn>. DOI: <pub-id pub-id-type="doi">10.1038/nn.3265</pub-id>.</mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="journal"><string-name><given-names>Beata</given-names> <surname>Jarosiewicz</surname></string-name> <etal>et al.</etal> “<article-title>Virtual typing by people with tetraplegia using a self-calibrating intracortical brain-computer interface</article-title>”. <source>In: Science Translational Medicine</source> <volume>7</volume>.<issue>313</issue> (<year>2015</year>), <fpage>313ra179</fpage>. ISSN: <issn>1946-6234</issn>. DOI: <pub-id pub-id-type="doi">10.1126/scitranslmed.aac7328</pub-id>.</mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="journal"><string-name><given-names>Paul</given-names> <surname>Nuyujukian</surname></string-name> <etal>et al.</etal> “<article-title>A High-Performance Keyboard Neural Prosthesis Enabled by Task Optimization</article-title>”. <source>In: IEEE Transactions on Biomedical Engineering</source> <volume>62</volume>.<issue>1</issue> (<year>2015</year>), pp. <fpage>21</fpage>–<lpage>29</lpage>. ISSN: <issn>0018-9294</issn>. DOI: <pub-id pub-id-type="doi">10.1109/tbme.2014.2354697</pub-id>.</mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="journal"><string-name><given-names>Maryam M.</given-names> <surname>Shanechi</surname></string-name> <etal>et al.</etal> “<article-title>Rapid control and feedback rates enhance neuroprosthetic control</article-title>”. <source>In: Nature Communications</source> <volume>8</volume>.<issue>1</issue> (<year>2017</year>), p. <fpage>13825</fpage>. DOI: <pub-id pub-id-type="doi">10.1038/ncomms13825</pub-id>.</mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="journal"><string-name><given-names>Chethan</given-names> <surname>Pandarinath</surname></string-name> <etal>et al.</etal> “<article-title>High performance communication by people with paralysis using an intracortical brain-computer interface</article-title>”. <source>In: eLife</source> <volume>6</volume> (<year>2017</year>), <fpage>e18554</fpage>. DOI: <pub-id pub-id-type="doi">10.7554/elife.18554</pub-id>.</mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="journal"><string-name><given-names>Camilo</given-names> <surname>Libedinsky</surname></string-name> <etal>et al.</etal> “<article-title>Independent Mobility Achieved through a Wireless Brain-Machine Interface</article-title>”. <source>In: PLOS ONE</source> <volume>11</volume>.<issue>11</issue> (<year>2016</year>), <fpage>e0165773</fpage>. DOI: <pub-id pub-id-type="doi">10.1371/journal.pone.0165773</pub-id>.</mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="journal"><string-name><given-names>Sankaranarayani</given-names> <surname>Rajangam</surname></string-name> <etal>et al.</etal> “<article-title>Wireless Cortical Brain-Machine Interface for Whole-Body Navigation in Primates</article-title>”. <source>In: Scientific Reports</source> <volume>6</volume>.<issue>1</issue> (<year>2016</year>), p. <fpage>22170</fpage>. DOI: <pub-id pub-id-type="doi">10.1038/srep22170</pub-id>.</mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="journal"><string-name><given-names>Karen E</given-names> <surname>Schroeder</surname></string-name> <etal>et al.</etal> “<article-title>Cortical Control of Virtual Self-Motion Using Task-Specific Subspaces</article-title>”. <source>In: The Journal of Neuroscience</source> <volume>42</volume>.<issue>2</issue> (<year>2022</year>), pp. <fpage>220</fpage>–<lpage>239</lpage>. ISSN: <issn>0270-6474</issn>. DOI: <pub-id pub-id-type="doi">10.1523/jneurosci.2687-20.2021</pub-id>.</mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="journal"><string-name><given-names>Gopala K.</given-names> <surname>Anumanchipalli</surname></string-name>, <string-name><given-names>Josh</given-names> <surname>Chartier</surname></string-name>, and <string-name><given-names>Edward F.</given-names> <surname>Chang</surname></string-name>. “<article-title>Speech synthesis from neural decoding of spoken sentences</article-title>”. <source>In: Nature</source> <volume>568</volume>.<issue>7753</issue> (<year>2019</year>), pp. <fpage>493</fpage>–<lpage>498</lpage>. ISSN: <issn>0028-0836</issn>. DOI: <pub-id pub-id-type="doi">10.1038/s41586-019-1119-1</pub-id>.</mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="journal"><string-name><given-names>Guy H.</given-names> <surname>Wilson</surname></string-name> <etal>et al.</etal> “<article-title>Decoding spoken English from intracortical electrode arrays in dorsal precentral gyrus</article-title>”. <source>In: Journal of Neural Engineering</source> <volume>17</volume>.<issue>6</issue> (<year>2020</year>), p. <fpage>066007</fpage>. ISSN: <issn>1741-2560</issn>. DOI: <pub-id pub-id-type="doi">10.1088/1741-2552/abbfef</pub-id>.</mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="other"><string-name><given-names>Francis</given-names> <surname>Willett</surname></string-name> <etal>et al.</etal> “<article-title>A high-performance speech neuroprosthesis</article-title>”. <source>In: bioRxiv</source> (<year>2023</year>), p. 2023.01.21.524489. DOI: <pub-id pub-id-type="doi">10.1101/2023.01.21.524489</pub-id>.</mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="journal"><string-name><given-names>Francis R.</given-names> <surname>Willett</surname></string-name> <etal>et al.</etal> “<article-title>High-performance brain-to-text communication via handwriting</article-title>”. <source>In: Nature</source> <volume>593</volume>.<issue>7858</issue> (<year>2021</year>), pp. <fpage>249</fpage>–<lpage>254</lpage>. ISSN: <issn>0028-0836</issn>. DOI: <pub-id pub-id-type="doi">10.1038/s41586-021-03506-2</pub-id>.</mixed-citation></ref>
<ref id="c25"><label>[25]</label><mixed-citation publication-type="journal"><string-name><given-names>S.</given-names> <surname>Musallam</surname></string-name> <etal>et al.</etal> “<article-title>Cognitive Control Signals for Neural Prosthetics</article-title>”. <source>In: Science</source> <volume>305</volume>.<issue>5681</issue> (<year>2004</year>), pp. <fpage>258</fpage>–<lpage>262</lpage>. ISSN: <issn>0036-8075</issn>. DOI: <pub-id pub-id-type="doi">10.1126/science.1097938</pub-id>.</mixed-citation></ref>
<ref id="c26"><label>[26]</label><mixed-citation publication-type="journal"><string-name><given-names>Joni D.</given-names> <surname>Wallis</surname></string-name>. “<article-title>Decoding Cognitive Processes from Neural Ensembles</article-title>”. <source>In: Trends in Cognitive Sciences</source> <volume>22</volume>.<issue>12</issue> (<year>2018</year>), pp. <fpage>1091</fpage>–<lpage>1102</lpage>. ISSN: <issn>1364-6613</issn>. DOI: <pub-id pub-id-type="doi">10.1016/j.tics.2018.09.002</pub-id>.</mixed-citation></ref>
<ref id="c27"><label>[27]</label><mixed-citation publication-type="journal"><string-name><given-names>Omid G.</given-names> <surname>Sani</surname></string-name> <etal>et al.</etal> “<article-title>Mood variations decoded from multi-site intracranial human brain activity</article-title>”. <source>In: Nature Biotechnology</source> <volume>36</volume>.<issue>10</issue> (<year>2018</year>), pp. <fpage>954</fpage>–<lpage>961</lpage>. ISSN: <issn>1087-0156</issn>. DOI: <pub-id pub-id-type="doi">10.1038/nbt.4200</pub-id>.</mixed-citation></ref>
<ref id="c28"><label>[28]</label><mixed-citation publication-type="journal"><string-name><given-names>Ali</given-names> <surname>Yousefi</surname></string-name> <etal>et al.</etal> “<article-title>Decoding Hidden Cognitive States From Behavior and Physiology Using a Bayesian Approach</article-title>”. <source>In: Neural Computation</source> <volume>31</volume>.<issue>9</issue> (<year>2019</year>), pp. <fpage>1751</fpage>–<lpage>1788</lpage>. ISSN: <issn>0899-7667</issn>. DOI: <pub-id pub-id-type="doi">10.1162/neco\_a\_01196</pub-id>.</mixed-citation></ref>
<ref id="c29"><label>[29]</label><mixed-citation publication-type="journal"><string-name><given-names>Nicole R.</given-names> <surname>Provenza</surname></string-name> <etal>et al.</etal> “<article-title>Decoding task engagement from distributed network electrophysiology in humans</article-title>”. <source>In: Journal of Neural Engineering</source> <volume>16</volume>.<issue>5</issue> (<year>2019</year>), p. <fpage>056015</fpage>. ISSN: <issn>1741-2552</issn>. DOI: <pub-id pub-id-type="doi">10.1088/1741-2552/ab2c58</pub-id>.</mixed-citation></ref>
<ref id="c30"><label>[30]</label><mixed-citation publication-type="journal"><string-name><given-names>Aswin</given-names> <surname>Chari</surname></string-name> <etal>et al.</etal> “<article-title>Microelectrode recordings in human epilepsy: A case for clinical translation?</article-title>” <source>In: Brain Communications</source> <volume>2</volume>.<issue>2</issue> (<year>2020</year>), <fpage>fcaa082</fpage>. ISSN: <issn>2632-1297</issn>. DOI: <pub-id pub-id-type="doi">10.1093/braincomms/fcaa082</pub-id>.</mixed-citation></ref>
<ref id="c31"><label>[31]</label><mixed-citation publication-type="journal"><string-name><given-names>Benjamin R.</given-names> <surname>Cowley</surname></string-name> <etal>et al.</etal> “<article-title>DataHigh: graphical user interface for visualizing and interacting with high-dimensional neural activity</article-title>”. <source>In: Journal of Neural Engineering</source> <volume>10</volume>.<issue>6</issue> (<year>2013</year>), p. <fpage>066012</fpage>. ISSN: <issn>1741-2552</issn>. DOI: <pub-id pub-id-type="doi">10.1088/1741-2560/10/6/066012</pub-id>.</mixed-citation></ref>
<ref id="c32"><label>[32]</label><mixed-citation publication-type="journal"><string-name><given-names>Diogo</given-names> <surname>Peixoto</surname></string-name> <etal>et al.</etal> “<article-title>Decoding and perturbing decision states in real time</article-title>”. <source>In: Nature</source> <volume>591</volume>.<issue>7851</issue> (<year>2021</year>), pp. <fpage>604</fpage>–<lpage>609</lpage>. ISSN: <issn>0028-0836</issn>. DOI: <pub-id pub-id-type="doi">10.1038/s41586-020-03181-9</pub-id>.</mixed-citation></ref>
<ref id="c33"><label>[33]</label><mixed-citation publication-type="other"><string-name><given-names>Brian</given-names> <surname>DePasquale</surname></string-name> <etal>et al.</etal> “<article-title>The centrality of population-level factors to network computation is demonstrated by a versatile approach for training spiking networks</article-title>”. <source>In: Neuron</source> (<year>2023</year>). ISSN: <issn>0896-6273</issn>. DOI: <pub-id pub-id-type="doi">10.1016/j.neuron.2022.12.007</pub-id>.</mixed-citation></ref>
<ref id="c34"><label>[34]</label><mixed-citation publication-type="journal"><string-name><given-names>Byron M.</given-names> <surname>Yu</surname></string-name> <etal>et al.</etal> <source>“Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity”. In</source>: vol. <volume>21</volume>. <year>2009</year>.</mixed-citation></ref>
<ref id="c35"><label>[35]</label><mixed-citation publication-type="journal"><string-name><given-names>Jakob H.</given-names> <surname>Macke</surname></string-name> <etal>et al.</etal> <source>“Empirical models of spiking in neural populations”. In</source>: vol. <volume>24</volume>. <year>2012</year>.</mixed-citation></ref>
<ref id="c36"><label>[36]</label><mixed-citation publication-type="journal"><string-name><given-names>Yuanjun</given-names> <surname>Gao</surname></string-name> <etal>et al.</etal> <source>“High-dimensional neural spike train analysis with generalized count linear dynamical systems”. In</source>: vol. <volume>28</volume>. <year>2015</year>.</mixed-citation></ref>
<ref id="c37"><label>[37]</label><mixed-citation publication-type="journal"><string-name><given-names>Jonathan C.</given-names> <surname>Kao</surname></string-name> <etal>et al.</etal> “<article-title>Single-trial dynamics of motor cortex and their applications to brain-machine interfaces</article-title>”. <source>In: Nature Communications</source> <volume>6</volume>.<issue>1</issue> (<year>2015</year>), p. <fpage>7759</fpage>. DOI: <pub-id pub-id-type="doi">10.1038/ncomms8759</pub-id>.</mixed-citation></ref>
<ref id="c38"><label>[38]</label><mixed-citation publication-type="journal"><string-name><given-names>Chethan</given-names> <surname>Pandarinath</surname></string-name> <etal>et al.</etal> “<article-title>Inferring single-trial neural population dynamics using sequential auto-encoders</article-title>”. <source>In: Nature Methods</source> <volume>15</volume>.<issue>10</issue> (<year>2018</year>), pp. <fpage>805</fpage>–<lpage>815</lpage>. ISSN: <issn>1548-7091</issn>. DOI: <pub-id pub-id-type="doi">10.1038/s41592-018-0109-9</pub-id>.</mixed-citation></ref>
<ref id="c39"><label>[39]</label><mixed-citation publication-type="other"><string-name><given-names>Mohammad Reza</given-names> <surname>Keshtkaran</surname></string-name> <etal>et al.</etal> “<article-title>A large-scale neural network training framework for generalized estimation of single-trial population dynamics</article-title>”. <source>In: Nature Methods</source> (<year>2022</year>), pp. <fpage>1</fpage>–<lpage>6</lpage>. ISSN: <issn>1548-7091</issn>. DOI: <pub-id pub-id-type="doi">10.1038/s41592-022-01675-0</pub-id>.</mixed-citation></ref>
<ref id="c40"><label>[40]</label><mixed-citation publication-type="other"><string-name><given-names>Joel</given-names> <surname>Ye</surname></string-name> and <string-name><given-names>Chethan</given-names> <surname>Pandarinath</surname></string-name>. “<article-title>Representation learning for neural population activity with Neural Data Transformers</article-title>”. <source>In: Neurons, Behavior, Data Analysis, and Theory</source> (<year>2021</year>). DOI: <pub-id pub-id-type="doi">10.51628/001c.27358</pub-id>.</mixed-citation></ref>
<ref id="c41"><label>[41]</label><mixed-citation publication-type="other"><string-name><given-names>Caleb T.</given-names> <surname>Kemere</surname></string-name> <etal>et al.</etal> “<article-title>Decoding of Plan and Peri-Movement Neural Signals in Prosthetic Systems</article-title>”. <source>In: IEEE Workshop on Signal Processing Systems</source> (<year>2002</year>), pp. <fpage>276</fpage>–<lpage>283</lpage>. DOI: <pub-id pub-id-type="doi">10.1109/sips.2002.1049722</pub-id>.</mixed-citation></ref>
<ref id="c42"><label>[42]</label><mixed-citation publication-type="journal"><string-name><given-names>Jonathan C.</given-names> <surname>Kao</surname></string-name> <etal>et al.</etal> “<article-title>A High-Performance Neural Prosthesis Incorporating Discrete State Selection With Hidden Markov Models</article-title>”. <source>In: IEEE Transactions on Biomedical Engineering</source> <volume>64</volume>.<issue>4</issue> (<year>2017</year>), pp. <fpage>935</fpage>–<lpage>945</lpage>. ISSN: <issn>0018-9294</issn>. DOI: <pub-id pub-id-type="doi">10.1109/tbme.2016.2582691</pub-id>.</mixed-citation></ref>
<ref id="c43"><label>[43]</label><mixed-citation publication-type="journal"><string-name><given-names>W.</given-names> <surname>Wu</surname></string-name> <etal>et al.</etal> <source>“Neural Decoding of Cursor Motion Using a Kalman Filter”. In</source>: vol. <volume>15</volume>. <year>2003</year>.</mixed-citation></ref>
<ref id="c44"><label>[44]</label><mixed-citation publication-type="journal"><string-name><given-names>A. E.</given-names> <surname>Brockwell</surname></string-name>, <string-name><given-names>A. L.</given-names> <surname>Rojas</surname></string-name>, and <string-name><given-names>R. E.</given-names> <surname>Kass</surname></string-name>. “<article-title>Recursive Bayesian Decoding of Motor Cortical Signals by Particle Filtering</article-title>”. <source>In: Journal of Neurophysiology</source> <volume>91</volume>.<issue>4</issue> (<year>2004</year>), pp. <fpage>1899</fpage>–<lpage>1907</lpage>. ISSN: <issn>0022-3077</issn>. DOI: <pub-id pub-id-type="doi">10.1152/jn.00438.2003</pub-id>.</mixed-citation></ref>
<ref id="c45"><label>[45]</label><mixed-citation publication-type="journal"><string-name><given-names>Caleb</given-names> <surname>Kemere</surname></string-name>, <string-name><given-names>Maneesh</given-names> <surname>Sahanil</surname></string-name>, and <string-name><given-names>Teresa</given-names> <surname>Meng</surname></string-name>. “<article-title>Robust Neural Decoding of Reaching Movements for Prosthetic Systems</article-title>”. <source>In: Proceedings of the 25th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (IEEE Cat. No. 03CH37439)</source> <volume>3</volume> (<year>2003</year>), pp. <fpage>2079</fpage>–<lpage>2082</lpage>. DOI: <pub-id pub-id-type="doi">10.1109/iembs.2003.1280146</pub-id>.</mixed-citation></ref>
<ref id="c46"><label>[46]</label><mixed-citation publication-type="journal"><string-name><given-names>C.</given-names> <surname>Kemere</surname></string-name>, <string-name><given-names>K. V.</given-names> <surname>Shenoy</surname></string-name>, and <string-name><given-names>T. H.</given-names> <surname>Meng</surname></string-name>. “<article-title>Model-based neural decoding of reaching movements: a maximum likelihood approach</article-title>”. <source>In: IEEE Transactions on Biomedical Engineering</source> <volume>51</volume>.<issue>6</issue> (<year>2004</year>), pp. <fpage>925</fpage>–<lpage>932</lpage>. ISSN: <issn>0018-9294</issn>. DOI: <pub-id pub-id-type="doi">10.1109/tbme.2004.826675</pub-id>.</mixed-citation></ref>
<ref id="c47"><label>[47]</label><mixed-citation publication-type="journal"><string-name><given-names>Caleb</given-names> <surname>Kemere</surname></string-name> <etal>et al.</etal> “<article-title>Model-Based Decoding of Reaching Movements for Prosthetic Systems</article-title>”. <source>In: The 26th Annual International Conference of the IEEE Engineering in Medicine and Biology Society</source> <volume>2</volume> (<year>2004</year>), pp. <fpage>4524</fpage>–<lpage>4528</lpage>. ISSN: <issn>1557-170X</issn>. DOI: <pub-id pub-id-type="doi">10.1109/iembs.2004.1404256</pub-id>.</mixed-citation></ref>
<ref id="c48"><label>[48]</label><mixed-citation publication-type="journal"><string-name><given-names>Caleb</given-names> <surname>Kemere</surname></string-name> <etal>et al.</etal> “<article-title>Detecting Neural-State Transitions Using Hidden Markov Models for Motor Cortical Prostheses</article-title>”. <source>In: Journal of Neurophysiology</source> <volume>100</volume>.<issue>4</issue> (<year>2008</year>), pp. <fpage>2441</fpage>–<lpage>2452</lpage>. ISSN: <issn>0022-3077</issn>. DOI: <pub-id pub-id-type="doi">10.1152/jn.00924.2007</pub-id>.</mixed-citation></ref>
<ref id="c49"><label>[49]</label><mixed-citation publication-type="journal"><string-name><given-names>Byron M.</given-names> <surname>Yu</surname></string-name> <etal>et al.</etal> “<article-title>Mixture of Trajectory Models for Neural Decoding of Goal-Directed Movements</article-title>”. <source>In: Journal of Neurophysiology</source> <volume>97</volume>.<issue>5</issue> (<year>2007</year>), pp. <fpage>3763</fpage>–<lpage>3780</lpage>. ISSN: <issn>0022-3077</issn>. DOI: <pub-id pub-id-type="doi">10.1152/jn.00482.2006</pub-id>.</mixed-citation></ref>
<ref id="c50"><label>[50]</label><mixed-citation publication-type="journal"><string-name><given-names>Omid G.</given-names> <surname>Sani</surname></string-name> <etal>et al.</etal> “<article-title>Modeling behaviorally relevant neural dynamics enabled by preferential subspace identification</article-title>”. <source>In: Nature Neuroscience</source> <volume>24</volume>.<issue>1</issue> (<year>2021</year>), pp. <fpage>140</fpage>–<lpage>149</lpage>. ISSN: <issn>1097-6256</issn>. DOI: <pub-id pub-id-type="doi">10.1038/s41593-020-00733-0</pub-id>.</mixed-citation></ref>
<ref id="c51"><label>[51]</label><mixed-citation publication-type="other"><string-name><given-names>Steffen</given-names> <surname>Schneider</surname></string-name>, <string-name><given-names>Jin Hwa</given-names> <surname>Lee</surname></string-name>, and <string-name><given-names>Mackenzie Weygandt</given-names> <surname>Mathis</surname></string-name>. “<article-title>Learnable latent embeddings for joint behavioral and neural analysis</article-title>”. <source>In: arXiv</source> (<year>2022</year>). DOI: <pub-id pub-id-type="doi">10.48550/arxiv.2204.00673</pub-id>. eprint: 2204.00673.</mixed-citation></ref>
<ref id="c52"><label>[52]</label><mixed-citation publication-type="other"><string-name><given-names>Ding</given-names> <surname>Zhou</surname></string-name> and <string-name><given-names>Xue-Xin</given-names> <surname>Wei</surname></string-name>. “<article-title>Learning identifiable and interpretable latent models of high-dimensional neural activity using pi-VAE</article-title>”. <source>In: arXiv</source> (<year>2020</year>). DOI: <pub-id pub-id-type="doi">10.48550/arxiv.2011.04798</pub-id>. eprint: 2011.04798.</mixed-citation></ref>
<ref id="c53"><label>[53]</label><mixed-citation publication-type="journal"><string-name><given-names>Eric A.</given-names> <surname>Pohlmeyer</surname></string-name> <etal>et al.</etal> “<article-title>Prediction of upper limb muscle activity from motor cortical discharge during reaching</article-title>”. <source>In: Journal of Neural Engineering</source> <volume>4</volume>.<issue>4</issue> (<year>2007</year>), p. <fpage>369</fpage>. ISSN: <issn>1741-2552</issn>. DOI: <pub-id pub-id-type="doi">10.1088/1741-2560/4/4/003</pub-id>.</mixed-citation></ref>
<ref id="c54"><label>[54]</label><mixed-citation publication-type="journal"><string-name><given-names>Joshua I.</given-names> <surname>Glaser</surname></string-name> <etal>et al.</etal> “<article-title>Machine learning for neural decoding</article-title>”. <source>In: eNeuro</source> <volume>7</volume>.<issue>4</issue> (<year>2020</year>), ENEURO.0506–19.2020. ISSN: <issn>2373-2822</issn>. DOI: <pub-id pub-id-type="doi">10.1523/eneuro.0506-19.2020</pub-id>.</mixed-citation></ref>
<ref id="c55"><label>[55]</label><mixed-citation publication-type="journal"><string-name><given-names>Nur</given-names> <surname>Ahmadi</surname></string-name>, <string-name><given-names>Timothy G.</given-names> <surname>Constandinou</surname></string-name>, and <string-name><given-names>Christos-Savvas</given-names> <surname>Bouganis</surname></string-name>. “<article-title>Robust and accurate decoding of hand kinematics from entire spiking activity using deep learning</article-title>”. <source>In: Journal of Neural Engineering</source> <volume>18</volume>.<issue>2</issue> (<year>2021</year>), p. <fpage>026011</fpage>. ISSN: <issn>1741-2560</issn>. DOI: <pub-id pub-id-type="doi">10.1088/1741-2552/abde8a</pub-id>.</mixed-citation></ref>
<ref id="c56"><label>[56]</label><mixed-citation publication-type="journal"><string-name><given-names>Zheng</given-names> <surname>Li</surname></string-name> <etal>et al.</etal> “<article-title>Unscented Kalman Filter for Brain-Machine Interfaces</article-title>”. <source>In: PLoS ONE</source> <volume>4</volume>.<issue>7</issue> (<year>2009</year>), <fpage>e6243</fpage>. DOI: <pub-id pub-id-type="doi">10.1371/journal.pone.0006243</pub-id>.</mixed-citation></ref>
<ref id="c57"><label>[57]</label><mixed-citation publication-type="journal"><string-name><given-names>David</given-names> <surname>Sussillo</surname></string-name> <etal>et al.</etal> “<article-title>A recurrent neural network for closed-loop intracortical brain–machine interface decoders</article-title>”. <source>In: Journal of Neural Engineering</source> <volume>9</volume>.<issue>2</issue> (<year>2012</year>), p. <fpage>026027</fpage>. ISSN: <issn>1741-2552</issn>. DOI: <pub-id pub-id-type="doi">10.1088/1741-2560/9/2/026027</pub-id>.</mixed-citation></ref>
<ref id="c58"><label>[58]</label><mixed-citation publication-type="journal"><string-name><given-names>David</given-names> <surname>Sussillo</surname></string-name> <etal>et al.</etal> “<article-title>Making brain–machine interfaces robust to future neural variability</article-title>”. <source>In: Nature Communications</source> <volume>7</volume>.<issue>1</issue> (<year>2016</year>), p. <fpage>13749</fpage>. DOI: <pub-id pub-id-type="doi">10.1038/ncomms13749</pub-id>. eprint: 1610.05872.</mixed-citation></ref>
<ref id="c59"><label>[59]</label><mixed-citation publication-type="journal"><string-name><given-names>Joseph G.</given-names> <surname>Makin</surname></string-name> <etal>et al.</etal> “<article-title>Superior arm-movement decoding from cortex with a new, unsupervised-learning algorithm</article-title>”. <source>In: Journal of Neural Engineering</source> <volume>15</volume>.<issue>2</issue> (<year>2018</year>), p. <fpage>026010</fpage>. ISSN: <issn>1741-2552</issn>. DOI: <pub-id pub-id-type="doi">10.1088/1741-2552/aa9e95</pub-id>.</mixed-citation></ref>
<ref id="c60"><label>[60]</label><mixed-citation publication-type="journal"><string-name><given-names>Michael A.</given-names> <surname>Schwemmer</surname></string-name> <etal>et al.</etal> “<article-title>Meeting brain–computer interface user performance expectations using a deep neural network decoding framework</article-title>”. <source>In: Nature Medicine</source> <volume>24</volume>.<issue>11</issue> (<year>2018</year>), pp. <fpage>1669</fpage>–<lpage>1676</lpage>. ISSN: <issn>1078-8956</issn>. DOI: <pub-id pub-id-type="doi">10.1038/s41591-018-0171-y</pub-id>.</mixed-citation></ref>
<ref id="c61"><label>[61]</label><mixed-citation publication-type="journal"><string-name><given-names>Po-He</given-names> <surname>Tseng</surname></string-name> <etal>et al.</etal> “<article-title>Decoding Movements from Cortical Ensemble Activity Using a Long Short-Term Memory Recurrent Network</article-title>”. <source>In: Neural Computation</source> <volume>31</volume>.<issue>6</issue> (<year>2019</year>), pp. <fpage>1085</fpage>–<lpage>1113</lpage>. ISSN: <issn>0899-7667</issn>. DOI: <pub-id pub-id-type="doi">10.1162/neco\_a\_01189</pub-id>.</mixed-citation></ref>
<ref id="c62"><label>[62]</label><mixed-citation publication-type="journal"><string-name><given-names>Eberhard E.</given-names> <surname>Fetz</surname></string-name>. “<article-title>Are movement parameters recognizably coded in the activity of single neurons?</article-title>” <source>In: Behavioral and Brain Sciences</source> <volume>15</volume>.<issue>4</issue> (<year>1992</year>), pp. <fpage>679</fpage>–<lpage>690</lpage>.</mixed-citation></ref>
<ref id="c63"><label>[63]</label><mixed-citation publication-type="journal"><string-name><given-names>Mark M</given-names> <surname>Churchland</surname></string-name> <etal>et al.</etal> “<article-title>Neural population dynamics during reaching</article-title>”. <source>In: Nature</source> <volume>487</volume>.<issue>7405</issue> (<year>2012</year>), pp. <fpage>51</fpage>–<lpage>56</lpage>. ISSN: <issn>0028-0836</issn>. DOI: <pub-id pub-id-type="doi">10.1038/nature11129</pub-id>.</mixed-citation></ref>
<ref id="c64"><label>[64]</label><mixed-citation publication-type="journal"><string-name><given-names>Abigail A.</given-names> <surname>Russo</surname></string-name> <etal>et al.</etal> “<article-title>Motor Cortex Embeds Muscle-like Commands in an Untangled Population Response</article-title>”. <source>In: Neuron</source> <volume>97</volume>.<issue>4</issue> (<year>2018</year>), <fpage>953</fpage>–<lpage>966</lpage>.e8. ISSN: <issn>0896-6273</issn>. DOI: <pub-id pub-id-type="doi">10.1016/j.neuron.2018.01.004</pub-id>.</mixed-citation></ref>
<ref id="c65"><label>[65]</label><mixed-citation publication-type="journal"><string-name><given-names>Shreya</given-names> <surname>Saxena</surname></string-name> <etal>et al.</etal> “<article-title>Motor cortex activity across movement speeds is predicted by network-level strategies for generating muscle activity</article-title>”. <source>In: eLife</source> <volume>11</volume> (<year>2022</year>), <fpage>e67620</fpage>. DOI: <pub-id pub-id-type="doi">10.7554/elife.67620.sa0</pub-id>.</mixed-citation></ref>
<ref id="c66"><label>[66]</label><mixed-citation publication-type="journal"><string-name><given-names>Matthew T.</given-names> <surname>Kaufman</surname></string-name> <etal>et al.</etal> “<article-title>The Largest Response Component in the Motor Cortex Reflects Movement Timing but Not Movement Type</article-title>”. <source>In: eNeuro</source> <volume>3</volume>.<issue>4</issue> (<year>2016</year>), ENEURO.0085–16.2016. DOI: <pub-id pub-id-type="doi">10.1523/eneuro.0085-16.2016</pub-id>.</mixed-citation></ref>
<ref id="c67"><label>[67]</label><mixed-citation publication-type="journal"><string-name><given-names>Mark M.</given-names> <surname>Churchland</surname></string-name> and <string-name><given-names>Krishna V.</given-names> <surname>Shenoy</surname></string-name>. “<article-title>Temporal Complexity and Heterogeneity of Single-Neuron Activity in Premotor and Motor Cortex</article-title>”. <source>In: Journal of Neurophysiology</source> <volume>97</volume>.<issue>6</issue> (<year>2007</year>), pp. <fpage>4235</fpage>–<lpage>4257</lpage>. ISSN: <issn>0022-3077</issn>. DOI: <pub-id pub-id-type="doi">10.1152/jn.00095.2007</pub-id>.</mixed-citation></ref>
<ref id="c68"><label>[68]</label><mixed-citation publication-type="other"><string-name><given-names>Najja J.</given-names> <surname>Marshall</surname></string-name> <etal>et al.</etal> “<article-title>Flexible neural control of motor units</article-title>”. <source>In: Nature Neuroscience</source> (<year>2022</year>), pp. <fpage>1</fpage>–<lpage>13</lpage>. ISSN: <issn>1097-6256</issn>. DOI: <pub-id pub-id-type="doi">10.1038/s41593-022-01165-8</pub-id>.</mixed-citation></ref>
<ref id="c69"><label>[69]</label><mixed-citation publication-type="journal"><string-name><given-names>Connor</given-names> <surname>Brennan</surname></string-name> <etal>et al.</etal> “<article-title>One dimensional approximations of neuronal dynamics reveal computational strategy</article-title>”. <source>In: PLOS Computational Biology</source> <volume>19</volume>.<issue>1</issue> (<year>2023</year>), <fpage>e1010784</fpage>. ISSN: <issn>1553-734X</issn>. DOI: <pub-id pub-id-type="doi">10.1371/journal.pcbi.1010784</pub-id>.</mixed-citation></ref>
<ref id="c70"><label>[70]</label><mixed-citation publication-type="journal"><string-name><given-names>Matthew D.</given-names> <surname>Golub</surname></string-name> <etal>et al.</etal> “<article-title>Learning by neural reassociation</article-title>”. <source>In: Nature Neuroscience</source> <volume>21</volume>.<issue>4</issue> (<year>2018</year>), pp. <fpage>607</fpage>–<lpage>616</lpage>. ISSN: <issn>1097-6256</issn>. DOI: <pub-id pub-id-type="doi">10.1038/s41593-018-0095-3</pub-id>.</mixed-citation></ref>
<ref id="c71"><label>[71]</label><mixed-citation publication-type="other"><string-name><given-names>Alan</given-names> <surname>Degenhart</surname></string-name> <etal>et al.</etal> “<article-title>Constraints on the time course of neural population activity</article-title>”. <source>In: Cosyne Abstracts</source> <fpage>III</fpage>–<lpage>59</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c72"><label>[72]</label><mixed-citation publication-type="other"><string-name><given-names>Vivek R.</given-names> <surname>Athalye</surname></string-name> <etal>et al.</etal> “<article-title>The brain uses invariant dynamics to generalize outputs across movements</article-title>”. <source>In: bioRxiv</source> (<year>2021</year>), p. 2021.08.27.457931. DOI: <pub-id pub-id-type="doi">10.1101/2021.08.27.457931</pub-id>.</mixed-citation></ref>
<ref id="c73"><label>[73]</label><mixed-citation publication-type="journal"><string-name><given-names>Mark M.</given-names> <surname>Churchland</surname></string-name> <etal>et al.</etal> “<article-title>Cortical Preparatory Activity: Representation of Movement or First Cog in a Dynamical Machine?</article-title>” <source>In: Neuron</source> <volume>68</volume>.<issue>3</issue> (<year>2010</year>). ISSN: <issn>0896-6273</issn>. DOI: <pub-id pub-id-type="doi">10.1016/j.neuron.2010.09.015</pub-id>.</mixed-citation></ref>
<ref id="c74"><label>[74]</label><mixed-citation publication-type="journal"><string-name><given-names>Raeed H</given-names> <surname>Chowdhury</surname></string-name>, <string-name><given-names>Joshua I</given-names> <surname>Glaser</surname></string-name>, and <string-name><given-names>Lee E</given-names> <surname>Miller</surname></string-name>. “<article-title>Area 2 of primary somatosensory cortex encodes kinematics of the whole arm</article-title>”. <source>In: eLife</source> <volume>9</volume> (<year>2020</year>), <fpage>e48198</fpage>. DOI: <pub-id pub-id-type="doi">10.7554/elife.48198</pub-id>.</mixed-citation></ref>
<ref id="c75"><label>[75]</label><mixed-citation publication-type="journal"><string-name><given-names>Johan</given-names> <surname>Wessberg</surname></string-name> <etal>et al.</etal> “<article-title>Real-time prediction of hand trajectory by ensembles of cortical neurons in primates</article-title>”. <source>In: Nature</source> <volume>408</volume>.<issue>6810</issue> (<year>2000</year>), pp. <fpage>361</fpage>–<lpage>365</lpage>. ISSN: <issn>0028-0836</issn>. DOI: <pub-id pub-id-type="doi">10.1038/35042582</pub-id>.</mixed-citation></ref>
<ref id="c76"><label>[76]</label><mixed-citation publication-type="journal"><string-name><given-names>Jasper</given-names> <surname>Snoek</surname></string-name>, <string-name><given-names>Hugo</given-names> <surname>Larochelle</surname></string-name>, and <string-name><given-names>Ryan P.</given-names> <surname>Adams</surname></string-name>. <source>“Practical Bayesian Optimization of Machine Learning Algorithms”. In</source>: vol. <volume>25</volume>. <year>2012</year>.</mixed-citation></ref>
<ref id="c77"><label>[77]</label><mixed-citation publication-type="journal"><string-name><given-names>Breanne P</given-names> <surname>Christie</surname></string-name> <etal>et al.</etal> “<article-title>Comparison of spike sorting and thresholding of voltage waveforms for intracortical brain–machine interface performance</article-title>”. <source>In: Journal of Neural Engineering</source> <volume>12</volume>.<issue>1</issue> (<year>2015</year>), p. <fpage>016009</fpage>. ISSN: <issn>1741-2552</issn>. DOI: <pub-id pub-id-type="doi">10.1088/1741-2560/12/1/016009</pub-id>.</mixed-citation></ref>
<ref id="c78"><label>[78]</label><mixed-citation publication-type="other"><string-name><given-names>Felix</given-names> <surname>Pei</surname></string-name> <etal>et al.</etal> “<article-title>Neural Latents Benchmark ‘21: Evaluating latent variable models of neural population activity</article-title>”. <source>In: Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks</source>. <year>2021</year>. DOI: <pub-id pub-id-type="doi">10.48550/arxiv.2109.04463</pub-id>.</mixed-citation></ref>
<ref id="c79"><label>[79]</label><mixed-citation publication-type="journal"><string-name><given-names>Hansem</given-names> <surname>Sohn</surname></string-name> <etal>et al.</etal> “<article-title>Bayesian Computation through Cortical Latent Dynamics</article-title>”. <source>In: Neuron</source> <volume>103</volume>.<issue>5</issue> (<year>2019</year>), <fpage>934</fpage>–<lpage>947</lpage>.e5. ISSN: <issn>0896-6273</issn>. DOI: <pub-id pub-id-type="doi">10.1016/j.neuron.2019.06.012</pub-id>.</mixed-citation></ref>
<ref id="c80"><label>[80]</label><mixed-citation publication-type="other"><string-name><given-names>Trung Le and Eli</given-names> <surname>Shlizerman</surname></string-name>. “<article-title>STNDT: Modeling Neural Population Activity with a Spatiotemporal Transformer</article-title>”. <source>In: arXiv</source> (<year>2022</year>). DOI: <pub-id pub-id-type="doi">10.48550/arxiv.2206.04727</pub-id>. eprint: 2206.04727.</mixed-citation></ref>
<ref id="c81"><label>[81]</label><mixed-citation publication-type="journal"><string-name><given-names>Patrick T.</given-names> <surname>Sadtler</surname></string-name> <etal>et al.</etal> “<article-title>Neural constraints on learning</article-title>”. <source>In: Nature</source> <volume>512</volume>.<issue>7515</issue> (<year>2014</year>), pp. <fpage>423</fpage>–<lpage>426</lpage>. ISSN: <issn>0028-0836</issn>. DOI: <pub-id pub-id-type="doi">10.1038/nature13665</pub-id>.</mixed-citation></ref>
<ref id="c82"><label>[82]</label><mixed-citation publication-type="journal"><string-name><given-names>Emily R.</given-names> <surname>Oby</surname></string-name> <etal>et al.</etal> “<article-title>New neural activity patterns emerge with long-term learning</article-title>”. <source>In: Proceedings of the National Academy of Sciences</source> <volume>116</volume>.<issue>30</issue> (<year>2019</year>), pp. <fpage>15210</fpage>–<lpage>15215</lpage>. ISSN: <issn>0027-8424</issn>. DOI: <pub-id pub-id-type="doi">10.1073/pnas.1820296116</pub-id>.</mixed-citation></ref>
<ref id="c83"><label>[83]</label><mixed-citation publication-type="journal"><string-name><given-names>Gal</given-names> <surname>Mishne</surname></string-name> <etal>et al.</etal> “<article-title>Hierarchical Coupled-Geometry Analysis for Neuronal Structure and Activity Pattern Discovery</article-title>”. <source>In: IEEE Journal of Selected Topics in Signal Processing</source> <volume>10</volume>.<issue>7</issue> (<year>2016</year>), pp. <fpage>1238</fpage>–<lpage>1253</lpage>. ISSN: <issn>1932-4553</issn>. DOI: <pub-id pub-id-type="doi">10.1109/jstsp.2016.2602061</pub-id>. eprint: 1511.02086.</mixed-citation></ref>
<ref id="c84"><label>[84]</label><mixed-citation publication-type="journal"><string-name><given-names>Juan A.</given-names> <surname>Gallego</surname></string-name> <etal>et al.</etal> “<article-title>Neural Manifolds for the Control of Movement</article-title>”. <source>In: Neuron</source> <volume>94</volume>.<issue>5</issue> (<year>2017</year>), pp. <fpage>978</fpage>–<lpage>984</lpage>. ISSN: <issn>0896-6273</issn>. DOI: <pub-id pub-id-type="doi">10.1016/j.neuron.2017.05.025</pub-id>.</mixed-citation></ref>
<ref id="c85"><label>[85]</label><mixed-citation publication-type="journal"><string-name><given-names>Rishidev</given-names> <surname>Chaudhuri</surname></string-name> <etal>et al.</etal> “<article-title>The intrinsic attractor manifold and population dynamics of a canonical cognitive circuit across waking and sleep</article-title>”. <source>In: Nature Neuroscience</source> <volume>22</volume>.<issue>9</issue> (<year>2019</year>), pp. <fpage>1512</fpage>–<lpage>1520</lpage>. ISSN: <issn>1097-6256</issn>. DOI: <pub-id pub-id-type="doi">10.1038/s41593-019-0460-x</pub-id>.</mixed-citation></ref>
<ref id="c86"><label>[86]</label><mixed-citation publication-type="journal"><string-name><given-names>Ege</given-names> <surname>Altan</surname></string-name> <etal>et al.</etal> “<article-title>Estimating the dimensionality of the manifold underlying multi-electrode neural recordings</article-title>”. <source>In: PLoS Computational Biology</source> <volume>17</volume>.<issue>11</issue> (<year>2021</year>), <fpage>e1008591</fpage>. ISSN: <issn>1553-734X</issn>. DOI: <pub-id pub-id-type="doi">10.1371/journal.pcbi.1008591</pub-id>.</mixed-citation></ref>
<ref id="c87"><label>[87]</label><mixed-citation publication-type="journal"><string-name><given-names>Jeffrey S.</given-names> <surname>Seely</surname></string-name> <etal>et al.</etal> “<article-title>Tensor Analysis Reveals Distinct Population Structure that Parallels the Different Computational Roles of Areas M1 and V1</article-title>”. <source>In: PLoS Computational Biology</source> <volume>12</volume>.<issue>11</issue> (<year>2016</year>), <fpage>e1005164</fpage>. ISSN: <issn>1553-734X</issn>. DOI: <pub-id pub-id-type="doi">10.1371/journal.pcbi.1005164</pub-id>.</mixed-citation></ref>
<ref id="c88"><label>[88]</label><mixed-citation publication-type="other"><string-name><given-names>Peiran</given-names> <surname>Gao</surname></string-name> <etal>et al.</etal> “<article-title>A theory of multineuronal dimensionality, dynamics and measurement</article-title>”. <source>In: bioRxiv</source> (<year>2017</year>), p. <fpage>214262</fpage>. DOI: <pub-id pub-id-type="doi">10.1101/214262</pub-id>.</mixed-citation></ref>
<ref id="c89"><label>[89]</label><mixed-citation publication-type="journal"><string-name><given-names>Guillaume</given-names> <surname>Hennequin</surname></string-name>, <string-name><given-names>Tim P.</given-names> <surname>Vogels</surname></string-name>, and <string-name><given-names>Wulfram</given-names> <surname>Gerstner</surname></string-name>. “<article-title>Optimal Control of Transient Dynamics in Balanced Networks Supports Generation of Complex Movements</article-title>”. <source>In: Neuron</source> <volume>82</volume>.<issue>6</issue> (<year>2014</year>), pp. <fpage>1394</fpage>–<lpage>1406</lpage>. ISSN: <issn>0896-6273</issn>. DOI: <pub-id pub-id-type="doi">10.1016/j.neuron.2014.04.045</pub-id>.</mixed-citation></ref>
<ref id="c90"><label>[90]</label><mixed-citation publication-type="journal"><string-name><given-names>David</given-names> <surname>Sussillo</surname></string-name> <etal>et al.</etal> “<article-title>A neural network that finds a naturalistic solution for the production of muscle activity</article-title>”. <source>In: Nature Neuroscience</source> <volume>18</volume>.<issue>7</issue> (<year>2015</year>), pp. <fpage>1025</fpage>–<lpage>1033</lpage>. ISSN: <issn>1097-6256</issn>. DOI: <pub-id pub-id-type="doi">10.1038/nn.4042</pub-id>.</mixed-citation></ref>
<ref id="c91"><label>[91]</label><mixed-citation publication-type="journal"><string-name><given-names>Vishwa</given-names> <surname>Goudar</surname></string-name> and <string-name><given-names>Dean V</given-names> <surname>Buonomano</surname></string-name>. “<article-title>Encoding sensory and motor patterns as time-invariant trajectories in recurrent neural networks</article-title>”. <source>In: eLife</source> <volume>7</volume> (<year>2018</year>), <fpage>e31134</fpage>. DOI: <pub-id pub-id-type="doi">10.7554/elife.31134</pub-id>.</mixed-citation></ref>
<ref id="c92"><label>[92]</label><mixed-citation publication-type="journal"><string-name><given-names>Andrew</given-names> <surname>Miri</surname></string-name> <etal>et al.</etal> “<article-title>Behaviorally Selective Engagement of Short-Latency Effector Pathways by Motor Cortex</article-title>”. <source>In: Neuron</source> <volume>95</volume>.<issue>3</issue> (<year>2017</year>), <fpage>683</fpage>–<lpage>696</lpage>.e11. ISSN: <issn>0896-6273</issn>. DOI: <pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.042</pub-id>.</mixed-citation></ref>
<ref id="c93"><label>[93]</label><mixed-citation publication-type="other"><string-name><given-names>Eric</given-names> <surname>Trautmann</surname></string-name> <etal>et al.</etal> “<article-title>Motor Cortex Isolates Skill-Specific Dynamics in a Context Switching Task</article-title>”. <source>In: Computational and Systems Neuroscience (COSYNE) Abstracts. Lisbon, Portugal</source>, <year>2022</year>.</mixed-citation></ref>
<ref id="c94"><label>[94]</label><mixed-citation publication-type="journal"><string-name><given-names>Claire L.</given-names> <surname>Warriner</surname></string-name> <etal>et al.</etal> “<article-title>Motor cortical influence relies on task-specific activity covariation</article-title>”. <source>In: Cell Reports</source> <volume>40</volume>.<issue>13</issue> (<year>2022</year>), p. <fpage>111427</fpage>. ISSN: <issn>2211-1247</issn>. DOI: <pub-id pub-id-type="doi">10.1016/j.celrep.2022.111427</pub-id>.</mixed-citation></ref>
<ref id="c95"><label>[95]</label><mixed-citation publication-type="journal"><string-name><given-names>Eva L.</given-names> <surname>Dyer</surname></string-name> <etal>et al.</etal> “<article-title>A cryptography-based approach for movement decoding</article-title>”. <source>In: Nature Biomedical Engineering</source> <volume>1</volume>.<issue>12</issue> (<year>2017</year>), pp. <fpage>967</fpage>–<lpage>976</lpage>. DOI: <pub-id pub-id-type="doi">10.1038/s41551-017-0169-7</pub-id>.</mixed-citation></ref>
<ref id="c96"><label>[96]</label><mixed-citation publication-type="journal"><string-name><given-names>Carlos E.</given-names> <surname>Vargas-Irwin</surname></string-name> <etal>et al.</etal> “<article-title>Watch, Imagine, Attempt: Motor Cortex Single-Unit Activity Reveals Context-Dependent Movement Encoding in Humans With Tetraplegia</article-title>”. <source>In: Frontiers in Human Neuroscience</source> <volume>12</volume> (<year>2018</year>), p. <fpage>450</fpage>. ISSN: <issn>1662-5161</issn>. DOI: <pub-id pub-id-type="doi">10.3389/fnhum.2018.00450</pub-id>.</mixed-citation></ref>
<ref id="c97"><label>[97]</label><mixed-citation publication-type="other"><string-name><given-names>Marius</given-names> <surname>Pachitariu</surname></string-name>, <string-name><given-names>Shashwat</given-names> <surname>Sridhar</surname></string-name>, and <string-name><given-names>Carsen</given-names> <surname>Stringer</surname></string-name>. “<article-title>Solving the spike sorting problem with Kilosort</article-title>”. <source>In: bioRxiv</source> (<year>2023</year>), p. 2023.01.07.523036. DOI: <pub-id pub-id-type="doi">10.1101/2023.01.07.523036</pub-id>.</mixed-citation></ref>
<ref id="c98"><label>[98]</label><mixed-citation publication-type="journal"><string-name><given-names>Alex H.</given-names> <surname>Williams</surname></string-name> <etal>et al.</etal> “<article-title>Discovering Precise Temporal Patterns in Large-Scale Neural Recordings through Robust and Interpretable Time Warping</article-title>”. <source>In: Neuron</source> <volume>105</volume>.<issue>2</issue> (<year>2020</year>), <fpage>246</fpage>–<lpage>259</lpage>.e8. ISSN: <issn>0896-6273</issn>. DOI: <pub-id pub-id-type="doi">10.1016/j.neuron.2019.10.020</pub-id>.</mixed-citation></ref>
<ref id="c99"><label>[99]</label><mixed-citation publication-type="journal"><string-name><given-names>R. E.</given-names> <surname>Kalman</surname></string-name>. “<article-title>A New Approach to Linear Filtering and Prediction Problems</article-title>”. <source>In: Journal of Basic Engineering</source> <volume>82</volume>.<issue>1</issue> (<year>1960</year>), pp. <fpage>35</fpage>–<lpage>45</lpage>. ISSN: <issn>0021-9223</issn>. DOI: <pub-id pub-id-type="doi">10.1115/1.3662552</pub-id>.</mixed-citation></ref>
<ref id="c100"><label>[100]</label><mixed-citation publication-type="book"><string-name><given-names>Frank</given-names> <surname>Rosenblatt</surname></string-name>. <source>Principles of neurodynamics. Perceptrons and the theory of brain mechanisms. Tech. rep</source>. <publisher-loc>Buffalo, NY</publisher-loc>: <publisher-name>Cornell Aeronautical Laboratory</publisher-name>, <year>1961</year>.</mixed-citation></ref>
<ref id="c101"><label>[101]</label><mixed-citation publication-type="other"><string-name><given-names>Diederik P</given-names> <surname>Kingma</surname></string-name> and <string-name><given-names>Jimmy</given-names> <surname>Ba</surname></string-name>. “<article-title>Adam: A Method for Stochastic Optimization</article-title>”. <source>In: arXiv</source> (<year>2014</year>). DOI: <pub-id pub-id-type="doi">10.48550/arxiv.1412.6980</pub-id>. eprint: 1412.6980.</mixed-citation></ref>
<ref id="c102"><label>[102]</label><mixed-citation publication-type="other"><string-name><given-names>Kyunghyun</given-names> <surname>Cho</surname></string-name> <etal>et al.</etal> “<article-title>Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation</article-title>”. <source>In: arXiv</source> (<year>2014</year>). DOI: <pub-id pub-id-type="doi">10.48550/arxiv.1406.1078</pub-id>. eprint: 1406.1078.</mixed-citation></ref>
<ref id="c103"><label>[103]</label><mixed-citation publication-type="other"><string-name><given-names>Tijmen</given-names> <surname>Tieleman</surname></string-name> and <string-name><given-names>Geoffrey</given-names> <surname>Hinton</surname></string-name>. “<article-title>Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude</article-title>”. <source>In: COURSERA: Neural networks for machine learning</source> (<year>2012</year>).</mixed-citation></ref>
</ref-list>
<sec id="s8">
<title>Methods</title>
<sec id="s8a">
<title>MINT (Part I): Estimating candidate states</title>
<sec id="s8a1">
<title>Model of idealized trajectories</title>
<p>Let <bold>s</bold><sub><italic>t</italic></sub> ∈𝒮<sup><italic>N</italic></sup> where 𝒮 = 0, 1, …, <italic>S</italic> be the measured spiking activity from <italic>N</italic> neurons at time sample <italic>t</italic>. Spikes are associated with some underlying neural state <bold>x</bold><sub><italic>t</italic></sub> ∈ <italic>ℝ</italic><sup><italic>N</italic></sup> and a corresponding behavioral state <bold>z</bold><sub><italic>t</italic></sub> ∈ <italic>ℝ</italic><sup><italic>M</italic></sup> where <italic>M</italic> is the number of behavioral variables (e.g. <italic>x</italic>- and <italic>y</italic>-velocity of the hand). We bin spiking activity in time such that <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline8.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. Given recent spiking history <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline9.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> (spike counts from the most recently completed bin <italic>t</italic>′ = ⌊<italic>t/</italic>Δ⌋ and <italic>τ</italic> ′ previous bins), we are interested in inferring posterior distributions over neural states <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline10.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> and over behavioral state <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline11.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. We can then perform <italic>maximum a posteriori</italic> estimation to generate candidate estimates for both the neural state and behavior. We introduce a model of the form:
<disp-formula id="eqn1">
<alternatives><graphic xlink:href="535396v2_eqn1.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn2">
<alternatives><graphic xlink:href="535396v2_eqn2.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn3">
<alternatives><graphic xlink:href="535396v2_eqn3.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn4">
<alternatives><graphic xlink:href="535396v2_eqn4.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <italic>g</italic> : Ω<sup>+</sup> →Ω<sup>+</sup> is a state-transition lookup table, <italic>f</italic> : Ω →Φ is a lookup table that associates neural states with behavioral states, <italic>δ</italic> = <italic>t</italic> −Δ<italic>t</italic>′ is the number of samples elapsed since the last time bin completed, and <italic>τ</italic> = <italic>δ</italic> +Δ(<italic>τ</italic> ′ + 1) −1 indicates the extent of the deterministic history for <bold>x</bold><sub><italic>t</italic></sub> (matching the extent of recent spiking history). This model has parameters Ω<sup>+</sup> and Φ. These parameters are described below, along with definitions for <italic>g</italic> and <italic>f</italic>.</p>
<p>Ω<sup>+</sup> is a set (library) of <italic>C</italic> neural trajectories, with each trajectory consisting of an ordered set of neural states. Each neural state in the library is notated as <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline12.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, where <italic>c</italic> indexes trajectories and <italic>k</italic> indexes locations along each trajectory (e.g. <italic>c</italic> = 2 and <italic>k</italic> = 100 indicates the 100th neural state along the second trajectory in the library). Each trajectory is presumed to contain the sequence of neural states that are traversed for a particular behavior. Thus, <italic>k</italic> increasing along a neural trajectory corresponds to the passage of time during the execution of a behavior. <xref ref-type="disp-formula" rid="eqn2">Eq. (2)</xref> and <xref ref-type="disp-formula" rid="eqn3">Eq. (3)</xref> indicate that each <bold>x</bold><sub><italic>t</italic></sub> has a history of <italic>τ</italic> states that are responsible for generating recent spike count observations. However, the first <italic>τ</italic> states along each neural trajectory lack a complete state history. Thus, we learn the full Ω<sup>+</sup>, but in <xref ref-type="disp-formula" rid="eqn1">Eq. (1)</xref> we only consider a reduced set of neural states, <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline13.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, because only these states have the necessary state histories. The state-transition lookup table is defined as follows,
<disp-formula id="eqn5">
<alternatives><graphic xlink:href="535396v2_eqn5.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
simply indicating that each neural state in the library has a recent history determined by the stereotyped ordering of neural states within each neural trajectory.</p>
<p>Φ is a set (library) of <italic>C</italic> behavioral trajectories, where each trajectory consists of an ordered set of behavioral states. Each <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline14.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> is associated with a behavioral state, <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline15.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, via
<disp-formula id="eqn6">
<alternatives><graphic xlink:href="535396v2_eqn6.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
In other words, each neural state in the library is paired with a behavioral state for the same <italic>c</italic> and <italic>k</italic>. Once the libraries of neural and behavioral trajectories have been learned, MINT’s parameters are fully learned. <italic>g</italic> will be determined by the ordering of states within each trajectory and <italic>f</italic> will be determined by each state’s <italic>c</italic> and <italic>k</italic> indices. There are a variety of methods one can employ for learning these trajectories. The methods used in this paper are described in Learning idealized trajectories. These trajectories can often be learned by averaging neural and behavioral data across many repeated trials of the same movement, yielding <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline16.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline17.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> that are highly representative of the neural and behavioral states expected for a particular movement.</p>
<p>We assume <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline18.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> if and only if <italic>c</italic><sub>1</sub> = <italic>c</italic><sub>2</sub> and <italic>k</italic><sub>1</sub> = <italic>k</italic><sub>2</sub>. (We similarly assume <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline19.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> if and only if <italic>c</italic><sub>1</sub> = <italic>c</italic><sub>2</sub> and <italic>k</italic><sub>1</sub> = <italic>k</italic><sub>2</sub>.) This can be made trivially true by letting <italic>c</italic> and <italic>k</italic> be the first two behavioral variables. Thus, <italic>f</italic> is invertible. This trick is mathematically convenient for subsequent derivations—it does not change that multiple neural states can be associated with the same behavior as in <xref rid="fig1" ref-type="fig">Figure 1</xref>.</p>
</sec>
<sec id="s8a2">
<title>Estimating candidate states</title>
<p>The prior in <xref ref-type="disp-formula" rid="eqn1">Eq. (1)</xref> ensures that <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline20.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. Every element of Ω can be written as <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline21.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> for some <italic>c</italic> and <italic>k</italic>, and the prior in <xref ref-type="disp-formula" rid="eqn1">Eq. (1)</xref> is uniform over the states in Ω. <xref ref-type="disp-formula" rid="eqn2">Eq. (2)</xref> and <xref ref-type="disp-formula" rid="eqn5">Eq. (5)</xref> indicate that each <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline22.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> has only one possible recent history, a history that is specified by the stereotyped ordering of neural states in the <italic>c</italic>-th trajectory. Thus, the posterior probabilities over neural states in Ω do not need to marginalize over multiple potential state histories. Rather, the probability associated with each <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline23.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> is proportional to the likelihood of recently observed spikes, <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline24.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, given the unique history of neural states associated with <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline25.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. Thus, the posterior probabilities over neural states in Ω can be written
<disp-formula id="eqn7">
<alternatives><graphic xlink:href="535396v2_eqn7.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn8">
<alternatives><graphic xlink:href="535396v2_eqn8.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline26.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> (i.e. Poisson likelihoods, as dictated by <xref ref-type="disp-formula" rid="eqn3">Eq. (3)</xref>), and <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline27.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline28.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> are the <italic>n</italic>-th components of <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline29.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline30.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, respectively. Recall that <italic>d</italic> is the number of time samples elapsed since the completion of the most recent time bin. A normalizing constant can convert <xref ref-type="disp-formula" rid="eqn7">Eq. (7)</xref> into full posterior probabilities. Computing this constant is straightforward because Ω is finite.</p>
<p><xref ref-type="disp-formula" rid="eqn4">Eq. (4)</xref> and <xref ref-type="disp-formula" rid="eqn6">Eq. (6)</xref> allow the posterior over behavioral states to be written in terms of the posterior over neural states. <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline31.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> if <bold>z</bold> ∉ F, but for behaviors in F the posterior probabilities are
<disp-formula id="eqn9">
<alternatives><graphic xlink:href="535396v2_eqn9.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
We can perform <italic>maximum a posteriori</italic> estimation on the log-transformed neural state posterior and read out the behavioral estimate directly.
<disp-formula id="eqn10">
<alternatives><graphic xlink:href="535396v2_eqn10.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn11">
<alternatives><graphic xlink:href="535396v2_eqn11.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
</p>
</sec>
<sec id="s8a3">
<title>Lookup table of log-likelihoods</title>
<p>One could proceed with querying <xref ref-type="disp-formula" rid="eqn10">Eq. (10)</xref> for all <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline32.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, selecting the most probable neural state, then reading out the associated behavioral state with <xref ref-type="disp-formula" rid="eqn11">Eq. (11)</xref>. However, one may often wish to speed up this process, e.g. to deploy in a real-time application. In this section (and the following two sections), we describe a procedure for approximating <xref ref-type="disp-formula" rid="eqn10">Eq. (10)</xref> with considerably reduced computational burden.</p>
<p>Notice that the log-likelihood term in <xref ref-type="disp-formula" rid="eqn10">Eq. (10)</xref> only varies as a function of spike count and rate. Spike counts are finite and firing rates have limited dynamic ranges, which can be discretized, so it is possible to precompute and store these log-likelihoods in a lookup table in memory. Suppose the dynamic range of rates is given by [<italic>λ</italic><sub><italic>min</italic></sub>, <italic>λ</italic><sub><italic>max</italic></sub>] and we sample this range with <italic>V</italic> + 1 values such that <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline33.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> for <italic>v</italic> ∈ 𝒱 where 𝒱 = {0, 1, …, <italic>V</italic> }. Every rate <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline33a.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> can now be approximated by <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline34.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> for some <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline35.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> that minimizes the approximation error. If we define a lookup table with entries <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline36.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, then <xref ref-type="disp-formula" rid="eqn10">Eq. (10)</xref> can be rewritten
<disp-formula id="eqn12">
<alternatives><graphic xlink:href="535396v2_eqn12.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
Thus, during training we can compute <italic>L</italic> for all <italic>s</italic> and <italic>v</italic>. Similarly, we can compute <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline37.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> for all <italic>c, n</italic>, and <italic>j</italic>. This formulation ensures the costly process of computing log-likelihoods only needs to be performed once, during training.</p>
</sec>
<sec id="s8a4">
<title>Recursive solution</title>
<p>The estimation procedure in <xref ref-type="disp-formula" rid="eqn12">Eq. (12)</xref> can be made faster still by exploiting recursive structure. Consider the following definitions.
<disp-formula id="eqn13">
<alternatives><graphic xlink:href="535396v2_eqn13.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn14">
<alternatives><graphic xlink:href="535396v2_eqn14.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
This expression can be generated recursively,
<disp-formula id="eqn15">
<alternatives><graphic xlink:href="535396v2_eqn15.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
with initial conditions <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline38.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. Given that <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline39.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> is simply shifted by one index relative to the previous time step when <italic>δ &gt;</italic> 0, the state estimate can be written
<disp-formula id="eqn16">
<alternatives><graphic xlink:href="535396v2_eqn16.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <italic>ĉ</italic> and <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline40.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> are the indices such that <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline41.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. Note that <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline42.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> cannot be computed until <italic>t &gt; τ</italic> (when sufficient spiking history has been collected).</p>
</sec>
<sec id="s8a5">
<title>Querying fewer states</title>
<p>The approach described in <xref ref-type="disp-formula" rid="eqn16">Eq. (16)</xref> is efficient insofar as it renders a new estimate at each time <italic>t</italic> while only requiring substantial computations every Δ time samples. Nevertheless, when <italic>δ</italic> = 0, the recursion requires computing new <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline43.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline44.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> for every element in Ω<sup>+</sup> to ensure that <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline44a.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> is defined for every <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline45.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. However, we typically assume some smoothness in neural trajectories over time. Thus, for reasonably small Δ, we can approximate the most likely neural state when <italic>δ</italic> = 0 by only considering a subset of neural states defined by
<disp-formula id="eqn17">
<alternatives><graphic xlink:href="535396v2_eqn17.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
which is equivalent to downsampling the neural trajectories in Ω with Δ spacing between samples. Letting <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline46.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, this choice yields a new expression for the neural state estimate,
<disp-formula id="eqn18">
<alternatives><graphic xlink:href="535396v2_eqn18.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline47.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. The recursion can now be performed over fewer states.
<disp-formula id="eqn19">
<alternatives><graphic xlink:href="535396v2_eqn19.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
This simplification reduces memory and execution time. Furthermore, by using interpolation (described in the next section) we can still estimate neural states outside of <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline48.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>.</p>
</sec>
<sec id="s8a6">
<title>Generating estimates at higher-than-bin-width resolution</title>
<p><xref ref-type="disp-formula" rid="eqn18">Eq. (18)</xref> describes a procedure for generating new neural state estimates at every time sample. When <italic>δ</italic> = 0, the estimate is updated using new spiking observations. When <italic>δ &gt;</italic> 0, the estimate is updated using the model of stereotyped trajectories, which specifies which neural state is likely to come next even in the absence of new spiking observations. However, to implement these equations in real time requires that the most time-consuming computations (those performed when <italic>δ</italic> = 0) be performed within one time sample (e.g. 1 ms). MINT is very fast and in many cases will be capable of generating estimates in under a millisecond (<xref rid="tbl1" ref-type="table">Table 1</xref>). When this isn’t possible, a small decoding lag can be introduced (e.g. 5 ms) such that the computations required when <italic>δ</italic> = 0 can begin prior to needing the result.</p>
</sec>
</sec>
<sec id="s8b">
<title>MINT (Part II): Interpolation</title>
<p>The algorithm described above leverages a library of neural trajectories composed of discrete sequences of neural states typically observed for a discrete set of conditions. These trajectories are presumed to sample an underlying neural manifold that is fundamentally continuous. The library of neural trajectories will more finely sample that manifold if one uses a large <italic>C</italic> such that small variations on a behavior each get their own neural and behavioral trajectories. Additionally, recall from Querying fewer states that, while decoding, only a subset of neural states (spaced apart by Δ) are considered. The larger Δ is, the more likely it is that the neural state estimate will make a small error in time (estimating a neural state that is slightly ahead or slightly behind the true state along a trajectory). Thus, neural state estimation can be more accurate in time and reflect more behavioral variability if one uses a small Δ and a large <italic>C</italic>. However, the computational burden of the algorithm grows as Δ shrinks or <italic>C</italic> grows. (The training data requirement also increases with <italic>C</italic>). This creates a potential trade-off between performance and computational burden. However, MINT side-steps this trade-off by using linear interpolation between states.</p>
<p>When the neural manifold is presumed to smoothly vary between neural states (across time or conditions) and there is also smooth variation between the corresponding behavioral states, it is unnecessary to use an overly small Δ and/or large <italic>C</italic>. Instead, one can identify candidate states along a small set of neural trajectories that coarsely sample the manifold, and then interpolate between those candidate states to find an intermediate state that is more consistent with the observed spikes. This two-step procedure (identify candidate states and then interpolate) allows the neural state estimate (and corresponding behavioral state estimate) to be accurate in time and capture variability between conditions (effectively as though a smaller Δ and larger <italic>C</italic> had been used) while preserving the computational benefits of a reasonable Δ (e.g. 20 ms) and small <italic>C</italic>.</p>
<sec id="s8b1">
<title>Model of interpolated states</title>
<p>Suppose we identify two neural states, <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline49.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline50.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, and we’d like to consider the possibility that the actual neural state is somewhere between them. We can use a model of the following form:
<disp-formula id="eqn20">
<alternatives><graphic xlink:href="535396v2_eqn20.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn21">
<alternatives><graphic xlink:href="535396v2_eqn21.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn22">
<alternatives><graphic xlink:href="535396v2_eqn22.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn23">
<alternatives><graphic xlink:href="535396v2_eqn23.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
This model assumes that as the neural state smoothly varies from <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline51.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> to <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline52.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, the corresponding behavior smoothly varies from <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline53.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> to <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline54.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>.</p>
</sec>
<sec id="s8b2">
<title>Interpolating between states</title>
<p>Explicitly evaluating the probabilities associated with all <bold>x</bold><sub><italic>t</italic></sub> in this model would be computationally inefficient. Given that the prior on <italic>α</italic> is uniform over the range [0, 1], we can simply select the <italic>α</italic> that maximizes the log-likelihood of the observed spikes. The log-likelihood of the observed spikes is given by the equation:
<disp-formula id="eqn24">
<alternatives><graphic xlink:href="535396v2_eqn24.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
Differentiating <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline55.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> twice with respect to <italic>α</italic> yields
<disp-formula id="eqn25">
<alternatives><graphic xlink:href="535396v2_eqn25.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
Notice that <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline56.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>always, i.e. <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline57.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> is a concave function of <italic>α</italic>. Thus, we can rapidly compute <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline58.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> using Newton’s method and then estimate <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline59.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline60.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> via <xref ref-type="disp-formula" rid="eqn21">Eq. (21)</xref> and <xref ref-type="disp-formula" rid="eqn23">Eq. (23)</xref>. This procedure will yield the same <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline61.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> for all <italic>t</italic> associated with the same <italic>t</italic>′. Thus, the interpolation only needs to be performed once per time bin, when <italic>δ</italic> = 0. In this paper, we used the following stopping criteria for Newton’s method: 1) the estimate of <italic>α</italic> is within .01 of the estimate at the previous iteration, 2) the estimate of <italic>α</italic> saturates at 0 or 1, or 3) optimization runs for 10 iterations.</p>
</sec>
<sec id="s8b3">
<title>Interpolating across indices</title>
<p><xref ref-type="disp-formula" rid="eqn17">Eq. (17)</xref> restricts the neural states under consideration to be spaced apart by Δ indices. Thus, a straightforward use of the interpolation scheme described above is to interpolate between nearby neural states along the same trajectory to restore the precision in the estimate that was lost by this restriction. First, a candidate neural state, which we’ll denote <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline62.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, is identified using <xref ref-type="disp-formula" rid="eqn18">Eq. (18)</xref>. Then, a second candidate neural state is identified, which we’ll denote <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline63.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. This second state is whichever of the two adjacent states (either <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline64.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> or <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline65.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>) has a larger log-likelihood of the observed spikes. Then, interpolation between <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline66.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline67.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> is performed as in Interpolating between states to yield neural and behavioral state estimates <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline68.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline69.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. This form of interpolation is less about generalization and more about enabling <xref ref-type="disp-formula" rid="eqn17">Eq. (17)</xref> to improve computational efficiency without loss of precision in the neural state estimates along each trajectory.</p>
</sec>
<sec id="s8b4">
<title>Interpolating across conditions</title>
<p>To interpolate across conditions, we also identify candidate neural states. The first candidate neural state, <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline70.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, is again identified using <xref ref-type="disp-formula" rid="eqn18">Eq. (18)</xref>. The second candidate neural state, <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline71.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, is identified as the neural state that maximizes the log-likelihood of the observed spikes but is not a state along the same trajectory as <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline72.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> (i.e. <italic>c</italic><sub>2</sub> ≠<italic>c</italic><sub>1</sub>). Next, both <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline73.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline74.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> are each interpolated across indices with their adjacent states to yield improved candidate neural and behavioral state estimates. Then, an additional interpolation is performed between the improved candidate state estimates to yield the condition-interpolated neural and behavioral state estimates <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline75.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline76.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. This allows for generalization between similar behaviors.</p>
</sec>
<sec id="s8b5">
<title>Other forms of interpolation</title>
<p>The exact manner in which interpolation is applied during MINT may vary by task or dataset. Often, interpolation across indices and conditions will be sufficient. However, in this section we’ll review some alternative interpolation implementations that were used for various analyses throughout this paper.</p>
<p>First, a dataset like MC_RTT that lacks explicit condition structure will not necessarily have one trajectory per behavior. We used AutoLFADS to learn neural trajectories for MC_RTT, which would have yielded a single neural trajectory for the entire training set were it not for recording gaps that broke up that trajectory. Thus, different portions of the same trajectory frequently corresponded to similar movements that it made sense to consider interpolations between. We therefore modified interpolation such that the second candidate state could be on the same trajectory as the first candidate state, but it had to be at least 1000 milliseconds away from that first state. Additionally, in a task with many degrees of behavioral freedom, there may be many trajectory fragments near a candidate neural state that could be worthwhile to interpolate to. Thus, for the MC_RTT dataset we expanded to multiple candidate neural states (6 for decoding analyses, 5 for the neural state estimation analysis; these values were optimized as hyperparameters). Interpolation occurred between all pairs of candidate neural states. Then, we proceeded to only use the interpolation that yielded the highest spike count log-likelihoods. These modifications ensured that utilizing long trajectories spanning multiple behaviors in a reaching task with many degrees of behavioral freedom would not limit the ability of interpolation to generalize between similar behaviors.</p>
<p>Second, in DMFC_RSG we computed multiple libraries of neural trajectories, each library corresponding to a different section of the training data in which the overall firing rate statistics differed due to recording instabilities throughout the session. For this dataset, we wished to expand interpolation to occur across indices, conditions, <italic>and</italic> libraries. We simply extended the approach for interpolating across conditions one step further. The first candidate neural state was selected as the most likely neural state across all libraries. The second candidate neural state was selected as the most likely neural state in any library except the one in which the first candidate state resided. For each of these two candidate states, within-library interpolation across indices and conditions proceeded to improve the estimates. Then, a final interpolation occurred between the best estimate in the first library with the best estimate in the second library. This approach enabled MINT to robustly estimate the neural state even when fed test data from various sections of the dataset in which different recording instabilities were present.</p>
<p>Third, in MC_Cycle we decoded a circular variable: phase. To accommodate this circularity, phase interpolations were modified such that they always occurred across the acute angle between the two phases. For example, if two candidate states corresponding to phases of 10 degrees and 350 degrees were identified, interpolation occurred across the 20 degree difference rather than the 340 degree difference.</p>
</sec>
</sec>
<sec id="s8c">
<title>Datasets</title>
<p>We analyzed 8 empirical datasets (Area2_Bump, DMFC_RSG, MC_Cycle, MC_Maze, MC_Maze-L, MC_Maze-M, MC_Maze-S, MC_RTT), several simulated maze datasets, and an artificial multitask spiking network. All empirical datasets contained spike times from offline or online sorted units. Detailed descriptions of all empirical datasets (except MC_Cycle) can be found in Pei et al. [<xref ref-type="bibr" rid="c78">78</xref>]. Here, we briefly describe each of the datasets.</p>
<sec id="s8c1">
<title>Area2_Bump</title>
<p>This dataset contains neural recordings (96-electrode Utah array) from Brodmann’s area 2 of S1 (a proprioceptive area) while a monkey used a manipulandum to make center-out-reaches to one of eight targets. On some trials, the monkey volitionally reached to the targets (‘active’ trials). On other trials, the manipulandum perturbed the monkey’s arm out toward one of the targets (‘passive’ trials). Thus, right after movement onset the ‘active’ trials involved predictable sensory feedback (the monkey planned the movement) and the ‘passive’ trials involved unexpected sensory feedback (the monkey was not planning to move). Between the eight targets and two trial types (‘active’ and ‘passive’), there were a total of 16 conditions. The behavioral data for this dataset includes: hand position (x- and y-components), hand velocity (x- and y-components), forces and torques applied to the manipulandum (x-y- and z-forces; x-y- and z-torques), 7 joint angles, 7 joint velocities, 39 muscle lengths, and 39 muscle velocities. Position data was zeroed at movement onset for each trial to ensure position data was relative to a pre-movement baseline. More information on the task and data can be found in Chowdhury, Glaser, and Miller [<xref ref-type="bibr" rid="c74">74</xref>].</p>
</sec>
<sec id="s8c2">
<title>DMFC_RSG</title>
<p>This dataset contains neural recordings (three Plexon probes) from dorsomedial frontal cortex while a monkey performed a time-interval reproduction task (aka Ready-Set-Go). In this task, the monkey received two visual cues, ‘Ready’ and ‘Set’, separated in time by a sample interval. The monkey was required to estimate the sample interval and report this estimate by performing an action (‘Go’) that followed the ‘Set’ cue by a production interval. The monkey was rewarded depending on how close the production interval was to the sample interval on a given trial. The sampling interval was selected on each trial from one of two prior distributions. The short prior distribution contained sampling intervals of 480, 560, 640, 720, and 800 ms. The long prior distribution contained sampling intervals of 800, 900, 1000, 1100, and 1200 ms. Trials were selected from prior distributions in blocks (i.e. many consecutive trials were drawn from the same prior distribution). Depending on the trial, the action could be reported in one of four ways: a joystick movement or an eye saccade to either the left or right. Between the two prior distributions, five sampling intervals per prior distribution, and four actions, there were a total of 40 conditions. More information on the task can be found in Sohn et al. [<xref ref-type="bibr" rid="c79">79</xref>].</p>
</sec>
<sec id="s8c3">
<title>MC_Cycle</title>
<p>This dataset contains neural recordings (two 96-electrode Utah arrays) from motor cortex (M1 and PMd) while a monkey performed a cycling task to navigate a virtual environment. Offline sorting of spike waveforms (using Kilosort [<xref ref-type="bibr" rid="c97">97</xref>]) yielded single-neuron and high-quality multi-neuron isolations. The dataset also includes threshold crossings that were detected online. On each trial, the monkey grasped a hand-pedal and moved it cyclically forward or backward to navigate the virtual environment. The color of the virtual landscape cued the monkey as to whether forward or backward pedaling would advance the avatar in the virtual environment (‘green’ landscape: forward pedaling advanced the avatar; ‘tan’ landscape: backward pedaling advanced the avatar). Pedaling distance was cued by a virtual target that appeared a fixed distance away in the virtual environment. The number of complete cycles of pedaling required to reach the target was either 1, 2, 4, or 7 cycles. Between the two pedaling directions and four pedaling distances, there were a total of 8 conditions. The behavioral data for this dataset includes: pedal phase, angular velocity of the pedal, x- and y-pedal position, x- and y-pedal velocity, and 7 intramuscular EMG recordings. The dataset includes both sorted spikes and threshold crossings. More information on the task can be found in Schroeder et al. [<xref ref-type="bibr" rid="c20">20</xref>].</p>
</sec>
<sec id="s8c4">
<title>MC_Maze</title>
<p>This dataset contains neural recordings (two 96-electrode Utah arrays) from motor cortex (M1 and PMd) while a monkey performed straight and curved reaches. The monkey was presented with a maze on a vertical screen with a cursor that tracked the motion of the monkey’s hand. Targets appeared on the screen and the monkey had to make reaches that would move the cursor onto the target. Virtual barriers were presented that the cursor could not pass through, requiring curved reaches that avoided the barriers. Each maze configuration had three variants. The first variant had a single target with no barriers (straight reach). The second variant had a single target with a barrier (curved reach). The third variant had a target with a barrier (curved reach) as well as two unreachable distractor targets elsewhere in the maze. There were 36 maze configurations for a total of 108 conditions. The behavioral data for this dataset includes x- and y-components of hand position and velocity. Position data was zeroed at movement onset for each trial to ensure position data was relative to a pre-movement baseline. More information on the task can be found in Churchland et al. [<xref ref-type="bibr" rid="c73">73</xref>].</p>
</sec>
<sec id="s8c5">
<title>MC_Maze-(L,M,S)</title>
<p>These three datasets were collected from the same monkey as in MC_Maze performing the same task, but on different days with different conditions. The same arrays were used to collect neural recordings (though different numbers of sorted units were identified in each session) and the same behavioral data was collected. These datasets differ from MC_Maze primarily in that they have fewer conditions (nine maze configurations with three variants, for a total of 27 conditions) and fewer trials.</p>
</sec>
<sec id="s8c6">
<title>MC_RTT</title>
<p>This dataset contains neural recordings (96-electrode Utah array) from motor cortex while a monkey made reaches in a horizontal plane to targets in an 8 × 8 grid. The task had no explicit trial structure nor did it require that individual movements be repeated throughout the session. Rather, a target would appear in one of the 64 grid locations and the monkey would reach to that target. Then, a new target would appear at a different random grid location and the monkey would reach there. This process continued throughout the session, leading to a collection of reaches that varied in terms of reach direction, reach distance, and reach speed. Despite lacking meaningful trial structure, the session was nevertheless broken up into 600 ms ‘trial’ segments (hence the trial count listed in <xref rid="tbl2" ref-type="table">Table 2</xref>). The behavioral data for this dataset includes x- and y-components of finger position and velocity. Due to the structure of the training data, neural trajectories were learned in long stretches spanning multiple movements. Thus, the zeroing of position data at movement onset that was employed for other datasets would have led to discontinuities in the behavioral trajectories for this task. We could have decoded position with no zeroing – however, similar movements (with similar corresponding neural activity) could have very different starting and ending positions in this dataset. Thus, we decided to focus decoding analyses on velocity only. More information on the task can be found in Makin et al. [<xref ref-type="bibr" rid="c59">59</xref>].</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2.</label>
<caption><p>Neuron, condition, and trial counts for each dataset. For some datasets, there are additional trials that are excluded from these counts. These trials are excluded because they were only usable for Neural Latents Benchmark submissions due to hidden behavioral data and partially hidden spiking data (see Neural Latents Benchmark).</p></caption>
<graphic xlink:href="535396v2_tbl2.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s8c7">
<title>Maze task simulations</title>
<p>Several synthetic datasets were generated based on the maze task. These simulations were based on the MC_Maze dataset and matched the neuron, condition, and trial counts from MC_Maze. In all cases, the actual behavior from MC_Maze was used — spiking activity was the only component that was simulated.</p>
<p>To simulate firing rates, we first z-scored hand position, velocity, and acceleration (x- and y-components). Then, we simulated rates for each neuron as a random weighted sum of these z-scored kinematics with a constant offset. The weights and offsets were scaled such that the means and standard deviations of firing rates for the simulated neurons matched the means and standard deviations of the empirical trial-averaged rates in MC_Maze. In some simulations, we increased simulated firing rates by a factor of 5 or 10.</p>
<p>Simulated spiking activity was generated from simulated rates in one of two ways. In one simulation, spiking activity was simulated as a Poisson process, which corresponds to exponential-interval spiking. In other simulations, spiking activity was simulated with gamma-interval spiking. More specifically, we let the interval between spikes be drawn from a gamma distribution with a shape parameter <italic>α</italic> = 2 and a rate parameter <italic>β</italic> = 2<italic>λ</italic>, where <italic>λ</italic> is the simulated firing rate. For reference, exponential-interval spiking corresponds to a gamma distribution with <italic>α</italic> = 1 and <italic>β</italic> = <italic>λ</italic>. The overall rate of spiking was matched regardless of whether exponential-interval or gamma-interval spiking was simulated, but spiking occurred more regularly given the same rate for the gamma-interval simulations.</p>
</sec>
<sec id="s8c8">
<title>Multitask spiking network</title>
<p>A simulated multitask dataset was generated using the method described in DePasquale et al. [<xref ref-type="bibr" rid="c33">33</xref>]. A spiking network was trained to generate posterior deltoid activity during reaching (eight reach conditions) and cycling (one cycling condition). In the network, there were 39 latent factors related to reaching and 12 latent factors related to cycling. The factors, and therefore the neural trajectories, for reaching and cycling were roughly orthogonal to one another. The network simulated 500 consecutive trials. A 135-trial stretch of this simulated dataset was designated as the test set (∼ 7.1 minutes of data). The training set was constructed by randomly selecting 15 trials per condition (135 training trials total) from the remaining trials.</p>
</sec>
</sec>
<sec id="s8d">
<title>Learning idealized trajectories</title>
<p>When training data includes repeated trials of the same behavior, neural and behavioral trajectories can be learned via standard trial-averaging. This procedure begins with filtering spikes temporally (e.g. with a Gaussian a filter) to yield single-trial rates. Then, rates and behavioral variables are extracted on each trial relative to behaviorally relevant trial events (e.g. movement onset). Depending on the structure of the task, time may need to be warped to ensure that task epochs unfold on the same timescale across different trials of the same condition. Finally, the single-trial rates are averaged across trials of the same condition to yield firing rates. The vector of firing rates at each time within each condition defines a neural state and the collection of neural states within each condition defines a neural trajectory. Single-trial behavioral variables are similarly averaged across trials to yield behavioral states and trajectories.</p>
<p>In the sections below, we describe how this standard trial-averaging procedure was applied to the datasets in this paper. We describe an additional trial-smoothing step that can be applied prior to averaging that often yields a small performance boost for MINT. We also describe a procedure for smoothing across conditions and neurons after averaging that can improve performance. All trajectories were learned at millisecond resolution.</p>
<p>There are two datasets for which non-standard trajectory-learning procedures were utilized. First, the training set for MC_RTT does not contain repeated trials of the same behavior and therefore was not amenable to the trial-averaging procedure. Trajectories were instead learned using AutoLFADS, as described in its own section below. Second, DMFC_RSG contained substantial recording instabilities. Thus, although this dataset still used trial-averaging, an additional procedure was developed for learning multiple libraries of neural trajectories corresponding to the same behaviors at different portions of the session in which different recording instabilities were present. This procedure is also described in its own section below.</p>
<sec id="s8d1">
<title>Filtering, extracting, and warping data on each trial</title>
<p>First, spiking activity for each neuron on each trial was temporally filtered with a Gaussian to yield single-trial rates. <xref rid="tbl3" ref-type="table">Table 3</xref> reports the Gaussian standard deviations <italic>σ</italic> (in milliseconds) used for each dataset. In general, datasets with fewer trials and/or noiser neural recordings tended to benefit from larger values.</p>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3.</label>
<caption><p>Hyperparameters for learning neural trajectories via standard trial-averaging. <italic>σ</italic> is the standard deviation of the Gaussian kernel used to temporally filter spikes. Trial-averaging Type I and Type II procedures are described in Averaging across trials. <italic>D</italic><sub><italic>neural</italic></sub> and <italic>D</italic><sub><italic>condition</italic></sub> are the neural- and condition-dimensionalities described in Smoothing across neurons and/or conditions. ‘Full’ means that no dimensionality reduction was performed. Condition smoothing could not be performed for MC_Cycle or the multitask network because different conditions in these datasets are of different lengths (i.e. <italic>K</italic><sub><italic>c</italic></sub> is not the same for all <italic>c</italic>). (C) and (R) refer to the cycling and reaching trajectories, respectively, in the multitask network. <italic>t</italic><sub><italic>move</italic></sub>, <italic>t</italic><sub><italic>stop</italic></sub>, and <italic>t</italic><sub><italic>go</italic></sub> correspond to movement onset, movement offset, and the ‘go’ time in the ready-set-go task, respectively.</p></caption>
<graphic xlink:href="535396v2_tbl3.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>Next, single-trial rates and behavioral data were extracted on each trial relative to key trial events. For example, in the maze datasets, data was extracted beginning 500 ms prior to movement onset and ending 700 ms after movement onset. These extraction boundaries (listed in <xref rid="tbl3" ref-type="table">Table 3</xref>) determine when the neural trajectories begin and end. These boundaries should be set to ensure that the behaviors one is interested in decoding are represented in the library of trajectories. It is also important to have extra data at the beginning of each trajectory because the first <italic>τ</italic> indices on each trajectory cannot be selected as candidate states (due to lack of sufficient state history).</p>
<p>In the maze datasets and in Area2_Bump, there was no need to warp time – all movements of the same condition unfolded over similar timescales relative to movement onset. However, in the cycling dataset this was not the case. The duration between movement onset and offset was variable across trials of the same condition. Thus, data in MC_Cycle was time-warped (separately for each condition) using the procedure described in Russo et al. [<xref ref-type="bibr" rid="c64">64</xref>]. In the DMFC_RSG dataset, the duration between the ‘set’ cue and ‘go’ action was variable across trials. Thus, uniform time-warping to match the average duration for each condition was used. More generally, one may find the time-warping technique in Williams et al. [<xref ref-type="bibr" rid="c98">98</xref>] to be a useful tool. It is important that warping take place <italic>after</italic> filtering spikes, because warping raw spiking activity would change the neurons’ rates.</p>
<p>The result of filtering, extracting, and warping is that, for each condition <italic>c</italic>, single-trial rates can be formatted into a tensor <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline77.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> where <italic>N</italic> is the number of neurons, <italic>K</italic><sub><italic>c</italic></sub> is the number of extracted time points on each trial, and <italic>R</italic> is the number of trials. Similarly, behavioral data can be formatted into tensors <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline78.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> where <italic>M</italic> is the number of behavioral variables.</p>
</sec>
<sec id="s8d2">
<title>Averaging across trials</title>
<p>It is straightforward to average each <bold>X</bold><sup><italic>c</italic></sup> across trials yielding matrices <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline79.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. We refer to this as Type I averaging. However, we found that a modified trial-averaging procedure (Type II) led to slightly improved neural state estimation and decoding in most cases. First, all rates (<bold>X</bold><sup><italic>c</italic></sup> for all <italic>c</italic>) are mean-centered and soft-normalized as described in Russo et al. [<xref ref-type="bibr" rid="c64">64</xref>]. The offset and scaling factor for this step are computed based on Type I averaged rates. Then, the mean-centered and soft-normalized rates are formatted into matrices <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline80.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. PCA is used to reduce the trial-dimensionality of the rates to 1 for each <italic>c</italic> via
<disp-formula id="eqn26">
<alternatives><graphic xlink:href="535396v2_eqn26.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <italic>W</italic><sub><italic>c</italic></sub> ∈ ℝ<sup><italic>R</italic></sup> is a column-vector corresponding to the first principal component of <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline81.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. Then, we reverse the soft-normalization and mean-centering operations on <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline82.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> and average across trials to get <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline83.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> indicates for each dataset which trial-averaging procedure was used.</p>
<p>We average each <bold>Z</bold><sup><italic>c</italic></sup> across trials yielding matrices <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline84.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. Typically, no modified trial-averaging procedure is required for behavioral data. However, there are cases where a behavioral variable should not be averaged without some pre- and/or post-processing. For example, in MC_Cycle, phase is a circular variable and therefore can’t be linearly averaged. To accommodate this, we unwrapped phase, averaged across trials, then re-wrapped it.</p>
</sec>
<sec id="s8d3">
<title>Smoothing across neurons and/or conditions</title>
<p>To additionally improve trial-averaged rate estimates we can use dimensionality reduction to smooth across neurons and/or conditions. First, trial-averaged rates are mean-centered and soft-normalized. Then, they are concatenated across conditions into a matrix <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline85.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> where <italic>K</italic> = Σ<sub><italic>c</italic></sub> <italic>K</italic><sub><italic>c</italic></sub>. PCA is used to reduce the neural-dimensionality of the rates via
<disp-formula id="eqn27">
<alternatives><graphic xlink:href="535396v2_eqn27.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline86.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> is the top <italic>D</italic><sub><italic>neural</italic></sub> principal components of <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline87.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. Then, <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline88.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> is reformatted into a new <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline89.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> where <italic>K</italic><sub><italic>c</italic></sub> is the same for all <italic>c</italic> (this form of smoothing cannot be applied when this is not the case). PCA is used to reduce the condition-dimensionality of the rates via
<disp-formula id="eqn28">
<alternatives><graphic xlink:href="535396v2_eqn28.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline90.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> is the top <italic>D</italic><sub><italic>condition</italic></sub> principal components of <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline91.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. Then, we reverse the soft-normalization and mean-centering operations on <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline92.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, rectify to ensure non-negative rates, and reformat the smoothed rates back into matrices <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline93.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. Not all datasets benefited from neuron smoothing and/or condition smoothing. The smoothing dimensionalities used for each dataset are reported in <xref rid="tbl3" ref-type="table">Table 3</xref>.</p>
<p>After completing the previous steps (some combination of smoothing rates over time, trials, neurons, and/or conditions), there will be matrices of firing rates <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline94.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> and behavioral data <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline95.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> for each <italic>c</italic>. The neural and behavioral states comprising the idealized neural and behavioral trajectories are then directly defined by these matrices.
<disp-formula id="eqn29">
<alternatives><graphic xlink:href="535396v2_eqn29.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn30">
<alternatives><graphic xlink:href="535396v2_eqn30.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
</p>
</sec>
<sec id="s8d4">
<title>Learning trajectories for MC_RTT</title>
<p>Neural trajectories were learned for MC_RTT using AutoLFADS [<xref ref-type="bibr" rid="c39">39</xref>]. Following the procedure described in Keshtkaran et al. [<xref ref-type="bibr" rid="c39">39</xref>], spiking activity in the training data was formatted into 600 ms segments with spike counts binned every 5 ms. Each segment overlapped with the previous segment by 200 ms and with the subsequent segment by 200 ms. AutoLFADS was then run twice on this formatted data (using 80/20 training and validation splits), yielding two sets of rate estimates that we then averaged across. Each AutoLFADS run yields slightly different results. Thus, we reasoned that averaging across runs would improve performance by reducing the impact of idiosyncratic rate variability that doesn’t show up consistently across runs. We chose not to average more than two runs due to the computational burden this would accrue for training.</p>
<p>After averaging across runs, the rates from each segment were stitched back together (via the weighted average described in Keshtkaran et al. [<xref ref-type="bibr" rid="c39">39</xref>]) into long neural trajectories spanning many movements. The trajectories were then upsampled to 1 kHz via linear interpolation. If there had been no recording gaps, this procedure would have yielded a single neural trajectory. For the decoding analyses, there were 2 recording gaps and therefore 3 neural trajectories. For the neural state estimation analysis (which utilized a larger training set), there were 3 recording gaps and therefore 4 neural trajectories. In all cases, each trajectory contained ∼ 2.7 minutes of data.</p>
<p>When running AutoLFADS for the neural state estimation analysis, one of the runs returned a highly oscillatory set of rates (∼ 25-40 Hz oscillations) that did not by eye resemble the output of the other AutoLFADS runs. Although we confirmed this set of rates performed similarly for neural state estimation (.200 bits/spike using the oscillatory rates alone, compared to .201 bits/spike when averaging across two non-oscillatory runs), we nevertheless chose to discard this run and average across two non-oscillatory AutoLFADS runs because the oscillatory solution was not one that AutoLFADS consistently returns for this particular training set.</p>
<p>See Other forms of interpolation for details on how these long neural trajectories are used during interpolation to improve neural state estimation and decoding.</p>
</sec>
<sec id="s8d5">
<title>Learning trajectories for DMFC_RSG</title>
<p>Learning neural trajectories for the DMFC_RSG dataset involved two main challenges. First, we needed to accommodate that each trial contained multiple trial events to align to. Second, we desired a procedure for creating multiple libraries of neural trajectories corresponding to different portions of the session in which different recording instabilities were present. The solutions we developed for each of these challenges are described below.</p>
<p>Each trial contained five main trial events: the ‘fixation’ time when the monkey began looking at the center of the screen, the ‘target onset’ time when a white target appeared in one of two locations on the screen, the ‘ready’ cue, the ‘set’ cue, and the ‘go’ time at which the monkey initiated a joystick movement or saccade (depending on the condition). Thus, when learning neural trajectories, we needed to compute rates for five trial epochs: fixation to target onset, target onset to ready cue, ready cue to set cue, set cue to go time, and go time to the end of the trial. The first three epochs could not be averaged across trials in the standard way (because the durations varied from one trial to the next), but it was also not appropriate to warp them. Warping should be performed when the monkey is executing a computation or behavior at a variable speed. In this case, the monkey was simply waiting for the next trial event without knowledge of when it would arrive. Thus, we chose to align to the initial event in each epoch, average across trials (ignoring missing data associated with the variable epoch durations), and then trim the averaged rates to the median epoch duration. In this task, certain conditions are not disambiguated for the monkey until the set cue arrives (e.g. the monkey doesn’t know if they are in an 800 ms or 900 ms interval trial until the set cue arrives). Thus, averages for a given condition in these first three epochs included all trials from the given condition plus all trials from other conditions that could not be distinguished from the given condition at this stage of the trial. In the set cue to go time epoch, rates were uniformly warped to match the average duration within each condition and then averaged across trials. All data after the go time were aligned to the go time and averaged. After computing these epoch-specific rate averages, the rates were concatenated across epochs to yield neural trajectories for each condition. They were then trimmed according to the trajectory start and end times listed in <xref rid="tbl3" ref-type="table">Table 3</xref>.</p>
<p>With access to a very large dataset, computing multiple libraries of neural trajectories for different recording conditions is straightforward: simply break the training data up in time into different sections and separately compute a library of trajectories for each. However, given limited training data, we sought to implement a similar strategy while not limiting the trajectories in each section to be based only on the small amount of spiking data available in that section. Thus, we first learned a library of neural trajectories based on the entire session (following the procedure described above) and smoothed across neurons and conditions to improve this estimate (yielding <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline96.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> for each condition <italic>c</italic>). Then, we broke up the session into 6 consecutive sections and proceeded to learn a complete set of neural trajectories for each section with no smoothing across neurons or conditions (yielding <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline97.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>for each condition <italic>c</italic> and section <italic>d</italic>). Finally, we learned a linear transformation of <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline98.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> for each section <italic>d</italic> that would better match the transformed firing rates for each section to those in <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline99.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> while preserving some of the neural geometry learned at the level of the session. This occurred via the equation
<disp-formula id="eqn31">
<alternatives><graphic xlink:href="535396v2_eqn31.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <italic>W</italic> <sup>(<italic>d</italic>)</sup> ∈ ℝ<sup><italic>N ×N</italic></sup>, <italic>b</italic><sup>(<italic>d</italic>)</sup> ∈ ℝ<sup><italic>N</italic></sup>, and Λ ∈ ℝ<sup><italic>N ×N</italic></sup>. Here, Λ is simply a diagonal matrix whose action on <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline100.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> is to soft-normalize. The values in Λ are learned from <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline101.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> via the same soft-normalization procedure described in Russo et al. [<xref ref-type="bibr" rid="c64">64</xref>] and used previously in this paper. The linear transformation was formulated in <xref ref-type="disp-formula" rid="eqn31">Eq. (31)</xref> to ensure that all regularization when learning the weights only applied to the deviation between the session-wide rates and the section-specific transformed rates. <italic>W</italic> <sup>(<italic>d</italic>)</sup> and <italic>b</italic><sup>(<italic>d</italic>)</sup> were learned via an L2-regularized weighted least squares regression,
<disp-formula id="eqn32">
<alternatives><graphic xlink:href="535396v2_eqn32.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn33">
<alternatives><graphic xlink:href="535396v2_eqn33.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn34">
<alternatives><graphic xlink:href="535396v2_eqn34.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn35">
<alternatives><graphic xlink:href="535396v2_eqn35.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn36">
<alternatives><graphic xlink:href="535396v2_eqn36.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn37">
<alternatives><graphic xlink:href="535396v2_eqn37.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <italic>S</italic> is a diagonal matrix of observation weights, <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline102.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> is the mean of <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline103.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> across columns, and <bold><italic>μ</italic></bold><sub>2</sub> is the mean of <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline104.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> across columns. In <xref ref-type="disp-formula" rid="eqn34">Eq. (34)</xref> and <xref ref-type="disp-formula" rid="eqn35">Eq. (35)</xref>, the subtractions of <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline105.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> and <bold><italic>μ</italic></bold><sub>2</sub> are applied to each column of the matrices they subtract from. The diagonal entries of <italic>S</italic> weight how much each observation should matter when learning <italic>W</italic> <sup>(<italic>d</italic>)</sup>. Given that the epoch between the set cue and the go time is when the monkey is performing an internal computation (keeping track of elapsed time internally) and this epoch is a large fraction of the evaluated trial period in the Neural Latents Benchmark, we decided <italic>W</italic> <sup>(<italic>b</italic>)</sup> should prioritize fitting this epoch well. Thus, diagonal entries of <italic>S</italic> corresponding to samples in the set-go epoch were given a weight <italic>s</italic><sub><italic>set</italic> − <italic>go</italic></sub> whereas all other diagonal entries of <italic>S</italic> were set to 1. Both the set-go epoch weight and the L2 regularization term were treated as hyperparameters and optimized on a validation set, yielding <italic>s</italic><sub><italic>set</italic>−<italic>go</italic></sub> = 4 and <italic>λ</italic> = 100. To summarize, <italic>W</italic> <sup>(<italic>d</italic>)</sup> transforms the mean-centered, soft-normalized session-wide rates into a set of rate residuals that can be added to the session-wide rates to better match the firing rate statistics in each section of the data. The result of this procedure is a complete library of neural trajectories for each section of the training data <italic>d</italic>.
<disp-formula id="eqn38">
<alternatives><graphic xlink:href="535396v2_eqn38.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
See Other forms of interpolation for details on how these multiple libraries are used during interpolation to improve the neural state estimate. There are no behavioral trajectories for this dataset (it was only used for neural state estimation analyses).</p>
</sec>
</sec>
<sec id="s8e">
<title>Visualizing neural trajectories</title>
<p>Neural trajectories have dimensionality matching the number of recorded neurons (or multi-units), but it is often useful to visualize them in a 2D state space. Throughout this paper, PCA is used to project neural trajectories into a low-dimensional subspace. When this done, firing rates are preprocessed with mean-centering and soft-normalization (as in Russo et al. [<xref ref-type="bibr" rid="c64">64</xref>]). In some cases, it is useful to rotate the data within the top PCs to find a perspective that highlights certain properties of the trajectories. When this is done, we report the neural variance captured by the plotted dimensions (along with the neural variance captured by the top PCs) to contextualize the scale of the neural dimensions. Percent neural variance captured was computed in the standard way, as described in Schroeder et al. [<xref ref-type="bibr" rid="c20">20</xref>].</p>
</sec>
<sec id="s8f">
<title>Distance analyses</title>
<p>In <xref rid="fig1" ref-type="fig">Figure 1c-e</xref>, several distance metrics were used to analyze the MC_Cycle dataset. Neural distance is defined as the Euclidean distance between two neural states in the full-dimensional space. Muscle distance is defined by z-scoring the ‘muscle state’ (portion of behavioral state corresponding to muscle activity), then computing the Euclidean distance between two normalized muscle states. The muscle state consisted of seven intramuscular EMG recordings (long head of the biceps, anterior deltoid, lateral deltoid, posterior deltoid, trapezius, lateral tricep, and long head of the triceps). Kinematic distance is defined using the phases and angular velocities associated with two behavioral states. Both phase and angular velocity are z-scored (for phase, this utilizes the circular standard deviation). Then, the phase distance (<italic>d</italic><sub><italic>ph</italic></sub>) is computed as the circular distance between the two normalized phases. The angular velocity distance (<italic>d</italic><sub><italic>av</italic></sub>) is computed as the absolute difference between the two normalized angular velocities. Then, the kinematic distance is computed as <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline106.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>. All trajectories (neural and behavioral) were binned at 10 ms resolution prior to computing pairwise distances to keep the analysis computationally manageable. In <xref rid="fig1" ref-type="fig">Figure 1e</xref>, data was partitioned into two trial sets (‘Partition A’ and ‘Partition B’) for a control analysis. To keep the number of trials used to compute trajectories matched across all analyses in <xref rid="fig1" ref-type="fig">Figure 1c-e</xref>, only trials from ‘Partition A’ were utilized in the neural distance vs. muscle distance and neural distance vs. kinematic distance analyses. When plotting pairwise distances, all distances were normalized (separately for each plotting axis) such that 1 corresponded to the average pairwise distance.</p>
</sec>
<sec id="s8g">
<title>Decoding analyses</title>
<p>All decoding analyses utilized the train-test trial splits listed in <xref rid="tbl4" ref-type="table">Table 4</xref>. Neural and behavioral trajectories were learned from the training set as described in Learning idealized trajectories. Then, MINT was provided with spiking activity on test trials with which to decode behavior. The trial epochs over which performance was evaluated were set to match the evaluation epochs from the Neural Latents Benchmark (for datasets that were used in the benchmark) and are listed in <xref rid="tbl4" ref-type="table">Table 4</xref>.</p>
<table-wrap id="tbl4" orientation="portrait" position="float">
<label>Table 4.</label>
<caption><p>Details for decoding analyses. The number of training and testing trials for each dataset are provided along with the evaluation period over which performance was computed. The window lengths refer to the amount of spiking history MINT used for decoding (e.g. when <italic>τ</italic>′ = 14 and Δ = 20, the window length is (<italic>τ</italic>′+ 1)Δ = 300 ms). <italic>t</italic><sub><italic>move</italic></sub> corresponds to movement onset, <italic>t</italic><sub><italic>stop</italic></sub> corresponds to movement offset, <italic>t</italic><sub><italic>start</italic></sub> refers to the beginning of a trial, and <italic>t</italic><sub><italic>end</italic></sub> refers to the end of a trial. There is no defined condition structure for MC_RTT to use for defining trial boundaries. Thus, each trial is simply a 600 ms segment of data, with no alignment to movement. Although 270 of these segments were available for testing, the first 2 segments lacked sufficient spiking history for all decoders to be evaluated and were therefore excluded, leaving 268 test trials. For the multitask network, performance was evaluated on a continuous stretch of 135 trials spanning <italic>∼</italic>7.1 minutes.</p></caption>
<graphic xlink:href="535396v2_tbl4.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>MINT used a bin size of Δ = 20 ms. The amount of spiking history provided to MINT at each decoding time step varied by dataset and is listed in <xref rid="tbl4" ref-type="table">Table 4</xref>. Decoding was always causal (i.e. only utilizing spiking history prior to the decoded moment), with one exception described below in MINT variants. MINT utilized interpolation for all datasets. The lookup table of log-likelihoods utilized a minimum rate, <italic>λ</italic><sub><italic>min</italic></sub>, corresponding to 1 spike/second. Log-likelihoods in the table were also clipped so as not to drop below log(10<sup>−6</sup>). These two choices regularize decoding such that a spurious spike from a neuron whose rate is close to 0 cannot dominate the decision of which neural state is most probable.</p>
<sec id="s8g1">
<title><italic>Decoding R</italic><sup>2</sup></title>
<p>Decoded behavioral variables were compared to ground truth behavioral variables over the evaluation epoch of all test trials. Performance was reported as the coefficient of determination (<italic>R</italic><sup>2</sup>) for the decoded behavioral variables, averaged across behavioral variables within a behavioral group. For example, <italic>R</italic><sup>2</sup> for x-velocity and y-velocity was averaged and reported as ‘velocity <italic>R</italic><sup>2</sup>’. When computing <italic>R</italic><sup>2</sup> for phase, circular distances and circular means were substituted for traditional distances and means in the <italic>R</italic><sup>2</sup> definition. For the neural networks, the training/testing procedure was repeated 10 times with different random seeds. Reported performance for each behavioral group is the average performance across these 10 runs. Decoding <italic>R</italic><sup>2</sup> was always computed at 5 ms resolution (set to match the resolution used by the Neural Latents Benchmark).</p>
</sec>
<sec id="s8g2">
<title>Decoder comparison</title>
<p>MINT was compared to four other decode algorithms: Kalman filter, Wiener filter, feedforward neural network, and a recurrent neural network (GRU). All decoders were provided with the same training/testing data and used the same evaluation epochs. Complete details on their implementations are provided in the Appendix.</p>
</sec>
<sec id="s8g3">
<title>Neuron dropping</title>
<p>The neuron dropping analyses in <xref rid="fig6" ref-type="fig">Figure 6</xref> were performed on the MC_Maze-L dataset, which has 162 neurons. The ‘retrained’ neuron dropping analysis consisted of training and testing the decoder with reduced sets of neurons. The ‘zeroed’ neuron dropping analysis consisted of training and testing the decoder with all 162 neurons, but in the test set a subset of those neurons were artificially set to never spike. The analyses were performed for the following neuron counts: [<xref ref-type="bibr" rid="c1">1</xref>, <xref ref-type="bibr" rid="c2">2</xref>, <xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c4">4</xref>, <xref ref-type="bibr" rid="c5">5</xref>, <xref ref-type="bibr" rid="c10">10</xref>, <xref ref-type="bibr" rid="c15">15</xref>,…, 150, 155, 160, 162]. At each neuron count, the ‘retrained’ and ‘zeroed’ analyses were each repeated 50 times (with different neurons randomly dropped at each repetition). Linear interpolation between these neuron counts was then applied to generate <italic>R</italic><sup>2</sup> values for every neuron count between 1 and 162.</p>
</sec>
<sec id="s8g4">
<title>MINT variants</title>
<p>The analysis in <xref rid="figS3" ref-type="fig">Figure S3a-c</xref> required training and testing several variations on MINT for Area2_Bump, MC_Cycle, MC_Maze, and MC_RTT. These variations are described here.</p>
<p>The first variation determines how behavior is decoded from the neural state estimate. The ‘Direct MINT Readout’ utilizes the direct association between neural and behavioral states that is standard for MINT. The ‘Linear MINT Readout’ begins by estimating the neural state using MINT, but behavior is then decoded as a weighted sum of the rates comprising the neural state estimate. The weights are learned from training data using ridge regression, with the L2 regularization term in the regression optimized via a grid search with 5-fold cross validation. To improve the quality of the fit, a lag between neural and behavioral states was included (lags set to match the values used in Pei et al. [<xref ref-type="bibr" rid="c78">78</xref>]; MC_Cycle set to 100 ms).</p>
<p>The second variation determined whether interpolation was used. When interpolation was used, the same methodology used for <xref rid="fig4" ref-type="fig">Figure 4</xref> analyses was followed (6 candidate states for MC_RTT; 2 candidate states for other datasets). When interpolation was not used, the neural state was selected from the library of neural trajectories as the state that maximized the log-likelihood of the observed spikes.</p>
<p>The third variation determined whether decoding occurred causally or acausally. When decoding causally, the spiking observations all came prior to the decoded moment. When decoding acausally, the spiking observations were centered on the decoding moment. For the analysis in <xref rid="figS3" ref-type="fig">Figure S3a-c</xref>, the extent of spiking observations (window length) was optimized separately for causal vs. acausal decoding to give each variant the opportunity to perform as well as possible. The causal window lengths are reported in <xref rid="tbl4" ref-type="table">Table 4</xref>. The acausal window lengths were 560 ms for Area2_Bump, 400 ms for MC_Cycle, 580 ms for MC_Maze, and 660 ms for MC_RTT.</p>
</sec>
<sec id="s8g5">
<title>SNR criteria for threshold crossings</title>
<p>When decoding based on threshold crossings in <xref rid="figS3" ref-type="fig">Figure S3d</xref>, a signal-to-noise ratio (SNR) was computed for each electrode channel. Then, only electrode channels with SNR &gt; 2 were utilized for decoding. The SNR was computed as the ratio of the range of firing rates (determined from trial-averaged rates) and the standard deviation of the firing rate residuals. The firing rate residuals on each trial were computed as the difference between the filtered spikes and the corresponding trial-averaged rates. If the standard deviation was less than 5 spikes/second, it was set to 5 spikes/second in the SNR computation. This ensured that channels with low variability in the residuals due to saturation at small or large firing rates were rejected. For example, an electrode channel that almost never spikes will have very low variability in the residuals simply because the firing rate is typically 0.</p>
</sec>
</sec>
<sec id="s8h">
<title>Neural Latents Benchmark</title>
<p>All neural state estimation results in <xref rid="fig5" ref-type="fig">Figure 5</xref> came from the Neural Latents Benchmark (<ext-link ext-link-type="uri" xlink:href="https://neurallatents.github.io/">https://neurallatents.github.io/</ext-link>), a neural latent variable modeling competition released through the 2021 NeurIPS Datasets &amp; Benchmarks Track [<xref ref-type="bibr" rid="c78">78</xref>]. For each of 7 datasets, the benchmark provided training data containing simultaneous spiking activity and behavioral measurements. The neurons in the training data were divided into two sets: held-in neurons and held-out neurons. For the test data, the spiking activity of the held-in neurons was provided, but the spiking activity of the held-out neurons and the behavioral data was kept private by the benchmark curators. These splits are provided in <xref rid="tbl5" ref-type="table">Table 5</xref>. The evaluation epochs used are the same as those used in <xref rid="tbl4" ref-type="table">Table 4</xref>. (For DMFC_RSG, the evaluation epoch was the 1500 ms leading up to the ‘go’ time.) In the test data, the held-in spiking activity was only provided for time points within the evaluation epochs. For each dataset, submissions consisted of rate estimates for every trial in the training and test sets (held-in rates and held-out rates). The benchmark was fundamentally acausal: rate estimates at a given moment could leverage spiking activity from the entire trial. The data in <xref rid="fig5" ref-type="fig">Figure 5</xref> reflect all benchmark submissions up through Feb. 24th, 2023.</p>
<table-wrap id="tbl5" orientation="portrait" position="float">
<label>Table 5.</label>
<caption><p>Details for neural state estimation results. Note that the training trial counts match the total number of trials reported in Table 2. This reflects that the Neural Latents Benchmark utilized an additional set of test trials not reflected in the Table 2 trial counts. The test trials used for this analysis have ground truth behavior hidden by the benchmark creators and are therefore only suitable for this analysis.</p></caption>
<graphic xlink:href="535396v2_tbl5.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<sec id="s8h1">
<title>MINT submissions</title>
<p>MINT first learned idealized neural trajectories during training as described in Learning idealized trajectories. Then, the neural trajectories were partitioned by neurons into two libraries: a held-in library of trajectories and a held-out library of trajectories. The held-in library contained neural states for the held-in neurons only. The held-out library similarly contained neural states for the held-out neurons only. MINT was run using the held-in library of trajectories to estimate a neural state in the held-in neural state space. A direct association between held-in neural states and held-out neural states (the same direct association typically used to map neural states to behavioral states) was then used generate rate estimates for the held-out neurons. Rate estimates were saturated such that they could not be lower than 0.1 spikes/second. Interpolation was utilized across indices and conditions (with modifications for DMFC_RSG and MC_RTT as described in Other forms of interpolation).</p>
<p>The window length used for acausal neural state estimation on each dataset is provided in <xref rid="tbl5" ref-type="table">Table 5</xref>. Note that test set data was not provided outside of the evaluation epochs. Thus, despite estimating rates acausally, the spiking observations often could not be centered on the estimated time. For example, when estimating the neural state for Area2_Bump, the window length was 500 ms, but the held-in spiking activity only spanned a 600 ms period. Thus, only neural states in the 250-350 ms portion of this 600 ms period could be estimated based on 500 ms of centered spiking activity. The neural states outside of this 250-350 ms zone were estimated by either propagating the earliest estimate backward or the latest estimate forward. This propagation is possible because each neural state estimate either occurs on a trajectory with a unique past and future or is an interpolation between trajectories that each have a unique past and future (i.e. the interpolation parameters are frozen and the states being interpolated are propagated backward or forward along their trajectories).</p>
<p>In addition to requiring test set rate estimates, the benchmark required training set rate estimates (these were needed for the velocity <italic>R</italic><sup>2</sup> metric, see Evaluation metrics). Each moment in each trial of the training data corresponded to a particular condition <italic>c</italic> and a time within the execution of that condition <italic>k</italic> (with the exception of MC_RTT, which will be discussed in a moment). Thus, training rate estimates were simply constructed by assigning each moment within each training trial a vector of rates <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline107.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> for the corresponding <italic>c</italic> and <italic>k</italic>. For MC_RTT, the training rate estimates were simply the single-trial rates learned via AutoLFADS.</p>
</sec>
<sec id="s8h2">
<title>Evaluation metrics</title>
<p>The evaluation metrics used in this paper are briefly described below. Detailed explanations can be found in Pei et al. [<xref ref-type="bibr" rid="c78">78</xref>].</p>
<p>Bits per spike was used to assess how well the rate estimates for the held-out neurons on the test data matched the actual held-out spiking activity. The metric is computed by first computing the log-likelihood of the observed spikes, given rate estimates, across all neurons. Then, the log-likelihood that would have been obtained by letting the rate estimates be the neurons’ mean rates is subtracted off. Finally, the metric is normalized. Positive values indicate that the held-out rate estimates are more predictive of held-out spiking activity than the mean rates.</p>
<p>PSTH <italic>R</italic><sup>2</sup> was computed by collecting all rate estimates on the test set, sorting them by condition, and averaging rate estimates across trials of the same condition. Then the <italic>R</italic><sup>2</sup> was computed between these rate-estimate-derived PSTHs and the empirical PSTHs (computed by smoothing spikes and averaging across trials within conditions). Empirical PSTHs were computed using trials from both the training and test sets. A separate <italic>R</italic><sup>2</sup> value was generated for each neuron — the reported values are the average <italic>R</italic><sup>2</sup> across all neurons. This metric could not be computed for MC_RTT due to lack of condition structure.</p>
<p>Velocity <italic>R</italic><sup>2</sup> was computed by regressing lagged x- and y-velocity of the hand against estimated rates in the training data (ridge regression). Then, the linear mapping learned via regression is applied to estimated rates in the test data to generate estimated x- and y-velocity of the hand. <italic>R</italic><sup>2</sup> is computed between estimated velocities and actual velocities on the test data and averaged across the x- and y-components. This metric was not computed for DMFC_RSG because the evaluated portion of the trials did not involve motion of the monkey’s arm.</p>
</sec>
</sec>
<sec id="s8i">
<title>Hyperparameter optimization</title>
<p>MINT has very few hyperparameters, all of which can be readily set by hand. These hyperparameters typically relate straightforwardly to properties of the task or data, and performance is robust to their exact values (<xref rid="figS1" ref-type="fig">Fig. S1</xref>). For example, we did not optimize bin size (Δ). Rather, we let Δ = 20 ms for all analyses, reasoning that this value would reduce computation time while remaining considerably shorter than the timescale over which rates change. MINT’s only other relevant hyperparameters are window length (duration of spiking history considered at each moment) and the number of candidate states to use for interpolation. The number of candidate states was simply set to two for all datasets except MC_RTT. For MC_RTT, the nature of the training data argued for considering more candidate states during the interpolation stage. Thus, the number of states was optimized using a grid search with 10-fold cross validation on the training set (using velocity decoding <italic>R</italic><sup>2</sup> as an objective function to maximize). Window length was also optimized via this grid search procedure, separately for each dataset. In some cases (e.g. the maze datasets), we still chose to standardize window length across datasets because optimization yielded similar values. Because neural state estimation was acausal and decoding analyses were causal, window length was also optimized separately across these analyses. For the simulated datasets, we chose not to optimize window length at all – the maze simulations and multitask spiking network were simply set to use the same window length as MC_Maze.</p>
<p>This approach to hyperparameter selection contrasts with our approach for the non-MINT decoders. As described in the Appendix, the non-MINT decoders utilized a more sophisticated technique to select hyperparameters: Bayesian optimization [<xref ref-type="bibr" rid="c76">76</xref>]. Additionally, the non-MINT decoders were allowed the flexibility of using a different window length for each behavioral group. The choice not to provide MINT with the same flexibility was not arbitrary. Rather, this choice emphasizes a particularly useful aspect of MINT: any relevant behavioral variable can be read out from the same neural state estimate. There is no need to use separate training or decoding procedures for different behavioral variables.</p>
<p>The methods we used for learning neural trajectories to use with MINT also contained hyperparameters (e.g. <xref rid="tbl3" ref-type="table">Table 3</xref>). For all datasets involved in the Neural Latents Benchmark (except MC_RTT), these hyperparameters were optimized using the grid search procedure (using bits per spike as an objective function to maximize). These hyperparameters were then re-used for decoding analyses with no additional optimization. For MC_RTT, we utilized AutoLFADS to learn neural trajectories, which contains a built-in procedure for optimizing hyperparameters. MC_Cycle, the maze simulations, and the multitask network were not part of the Neural Latents Benchmark and therefore needed their trajectory-learning hyperparameters set in a different way. For MC_Cycle, these hyperparameters were optimized using the grid search procedure with velocity decoding <italic>R</italic><sup>2</sup> as the objective function. The maze simulations simply used the same hyperparameters as MC_Maze. For the multitask network, the trajectory learning hyperparameters were set very conservatively by hand to only perform very light temporal smoothing on spikes along with standard trial-averaging.</p>
<p>The example decoding results in <xref rid="fig3" ref-type="fig">Fig. 3</xref> and the Supp. Video used the same hyperparameters that were used in generating the quantitative decoding results in <xref rid="fig4" ref-type="fig">Fig. 4</xref>.</p>
</sec>
</sec>
<sec id="s9">
<title>Supplementary Figures</title>
<fig id="figS1" position="float" fig-type="figure">
<label>Figure S1.</label>
<caption><title>MINT’s decoding performance is robust to the choice of hyperparameters.</title>
<p>MINT was run on the MC_Maze dataset with systematic perturbations to two of MINT’s hyperparameters: bin width (ms) and window length (ms). Bin width is the size of the bin in which spikes are counted: 20 ms for all analyses in the main figures. Window length is the length, in milliseconds, of spiking history that is considered. For all main analyses of the MC_Maze dataset, this was 300 ms, i.e. MINT considered the spike count in the present bin and in 14 previous bins. Perturbations were also made to two hyperparameters related to learning neural trajectories: temporal smoothing width (standard deviation of Gaussian filter applied to spikes) and condition-smoothing dimensionality (see Methods). These two hyperparameters describe how aggressively the trial-averaged data are smoothed (across time and conditions, respectively) when learning rates. Baseline decoding performance (<italic>black circles</italic>) was computed using the same hyperparameters that were used with the MC_Maze dataset in the analyses from <xref rid="fig3" ref-type="fig">Figure 3</xref> and <xref rid="fig4" ref-type="fig">Figure 4</xref>. Then, decoding performance was computed by perturbing each of the four hyperparameters twice (<italic>colored circles</italic>): once to <italic>∼</italic>50% of the hyperparameter’s baseline value and once to <italic>∼</italic>150%. Trials were bootstrapped (1000 resamples) to generate 95% confidence intervals (<italic>error bars</italic>). Perturbations of hyperparameters had little impact on performance. Altering bin width had essentially no impact, nor did altering temporal smoothing. Shortening window length had a negative impact, presumably because MINT had to estimate the neural state using fewer observations. However, the drop in performance was minimal: <italic>R</italic><sup>2</sup> dropped by .011 for position decoding only. Reducing the number of dimensions used for across-condition smoothing, and consequently over-smoothing the data, had a negative impact on both position and velocity decoding. Yet again this was small: e.g. velocity <italic>R</italic><sup>2</sup> dropped by .010. These results demonstrate that MINT can achieve high performance using hyperparameter values that span a large range. Thus, they do not need to be meticulously optimized to ensure good performance. In general, optimization may not be needed at all, as MINT’s hyperparameters can often be set based on first principles. For example, in this study, bin width was never optimized either for specific datasets or in general. We chose to always count spikes in 20 ms bins (except in the perturbations shown here) because this duration is long enough to reduce computation time yet short relative to the timescales over which rates change. Additionally, window length can be optimized (as we did for decoding analyses), but it could also simply be chosen to roughly match the timescale over which past behavior tends to predict future behavior. Temporal smoothing of trajectories when building the library can simply use the same values commonly used when analyzing such data. For example, in prior studies, we have used smoothing kernels of width 20 to 30 ms when computing trial-averaged rates, and these values also support excellent decoding. Condition smoothing is optional and need not be applied at all, but may be useful if one wishes to record fewer trials for more conditions. For example, rather than record 15 trials for 8 reach directions, one might wish to record 5 trials for 24 conditions, then use condition smoothing to reduce sampling error.</p></caption>
<graphic xlink:href="535396v2_figS1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS2" position="float" fig-type="figure">
<label>Figure S2.</label>
<caption><title>Illustration of why decoding will typically fail to generalize across tasks when neural trajectories occupy orthogonal subspaces.</title>
<p>In theory, learning the output-potent dimensions in motor cortex would be an effective strategy for biomimetic decoding that generalizes to novel tasks. In practice, it is difficult (and often impossible) to statistically infer these dimensions without observing the subject’s full behavioral repertoire (at which point generalization is no longer needed because all the relevant behaviors were directly observed). <bold>a)</bold> In this toy example, two neural trajectories occupy fully orthogonal subspaces. In the ‘blue task’, the neural trajectory occupies dimensions 1 and 2. In the ‘red task’, the neural trajectory occupies dimensions 3 and 4. Trajectories in both subspaces have a non-zero projection onto <bold>w</bold><sub><italic>out</italic></sub>, enabling neural activity from each task to drive the appropriate output. The output at right is simply the projection of the blue-task and red-task trajectories onto <bold>w</bold><sub><italic>out</italic></sub>. <bold>b)</bold> Illustration of the difficulty of inferring <bold>w</bold><sub><italic>out</italic></sub> from only one task. In this example, <bold>w</bold><sub><italic>out</italic></sub> is learned using data from the blue task, by linearly regressing the observed output against the neural trajectory for the blue task. The resulting estimate of <bold>ŵ</bold> <sub>1</sub> correctly translates neural activity in the blue task into the appropriate time-varying output, but fails to generalize to the red task. This failure to generalize is a straightforward consequence of the fact that <bold>ŵ</bold> <sub>1</sub> was learned from data that didn’t explore dimensions 3 and 4. Note that this same phenomenon would occur if <bold>ŵ</bold><sub>1</sub> were estimated by regressing intended output versus neural activity (as might occur in a paralyzed patient) <bold>c)</bold> Estimating the output-potent dimension based only on the red task yields an estimate <bold>ŵ</bold> <sub>2</sub> that fails to generalize to the blue task. This phenomenon is illustrated here for a linear readout, but would apply to most nonlinear methods as well, unless some other form of knowledge can allow interpretation of neural trajectories in previously unseen dimensions.</p></caption>
<graphic xlink:href="535396v2_figS2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS3" position="float" fig-type="figure">
<label>Figure S3.</label>
<caption><title>Impact of different modeling and preprocessing choices on performance of MINT.</title>
<p>For most applications we anticipate MINT will employ direct decoding that leverages the correspondence between neural and behavioral trajectories, but one could also choose to linearly decode behavior from the estimated neural state. For most applications, we anticipate MINT will use interpolation amongst candidate neural states on neighboring trajectories, but one could also restrict decoding to states within the trajectory library. For real-time applications we anticipate MINT will be run causally, but acausal decoding (using both past and future spiking observations) could be used offline or even online by introducing a lag. We anticipate MINT may be used both in situations where spike events have been sorted based on neuron identity, and situations where decoding simply uses channel-specific unsorted threshold crossings. Panels <bold>a-c</bold> explore the first three choices. Performance was quantified for all 8 combinations of: direct MINT readout vs. linear MINT readout, interpolation vs. no interpolation, causal decoding vs. acausal decoding. This was done for 121 behavioral variables across 4 datasets for a total of 964 <italic>R</italic><sup>2</sup> values. The ‘phase’ behavioral variable in MC_Cycle was excluded from ‘linear MINT readout’ variants because its circularity makes it a trivially poor target for linear decoding. <bold>a)</bold> MINT’s direct neural-to-behavioral-state association outperforms a linear readout based on MINT’s estimated neural state. Performance was significantly higher using the direct readout (Δ<italic>R</italic><sup>2</sup> = .061 ± .002 SE; p&lt;.001, paired t-test). Note that the linear readout still benefits from the ability of MINT to estimate the neural state using all neural dimensions, not just those that correlate with kinematics. <bold>b)</bold> Decoding with interpolation significantly outperformed decoding without interpolation (Δ<italic>R</italic><sup>2</sup> = .018 ± .001 SE; p&lt;.001, paired t-test). <bold>c)</bold> Running acausally significantly improved performance relative to causal decoding (Δ<italic>R</italic><sup>2</sup> = .051 ± .002 SE; p&lt;.001, paired t-test). Although causal decoding is required for real-time applications, this result suggests that (when tolerable) introducing a small decoding lag could improve performance. For example, a decoder using 200 ms of spiking activity could introduce a 50 ms lag such that the decode at time <italic>t</italic> is rendered by generating the best estimate of the behavioral state at time <italic>t</italic> − 50 using spiking data from <italic>t</italic> − 200 through <italic>t</italic>. <bold>d)</bold> Decoding performance for 13 behavioral variables in the MC_Cycle dataset when sorted spikes were used (112 neurons, <italic>pink</italic>) versus ‘good’ threshold crossings from electrodes for which the signal-to-noise ratio of the firing rates exceeded a threshold (93 electrodes, SNR &gt; 2, <italic>cyan</italic>). The loss in performance when using threshold crossings was small (Δ<italic>R</italic><sup>2</sup> = -.014 ± .002 SE). SE refers to standard error of the mean.</p></caption>
<graphic xlink:href="535396v2_figS3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS4" position="float" fig-type="figure">
<label>Figure S4.</label>
<caption><title>The Kalman filter’s relative performance would improve if neural data had different statistical properties.</title>
<p>We compared MINT to the Kalman filter across one empirical dataset (MC_Maze) and four simulated datasets (same behavior as MC_Maze, but simulated spikes). Simulated firing rates were linear functions of hand position, velocity, and acceleration (as is assumed by the Kalman filter). The means and standard deviations (across time and conditions) of the simulated firing rates were matched to actual neural data (with additional rate scaling in two cases). The Kalman filter assumes that observation noise is stationary and Gaussian. Although spiking variability cannot be Gaussian (spike counts must be positive integers), spiking variability can be made more stationary by letting that variability depend less on rate. Thus, although the first simulation generated spikes via a Poisson process, subsequent simulations utilized gamma-interval spiking (gamma distribution with <italic>α</italic> = 2 and <italic>β</italic> = 2<italic>λ</italic>, where <italic>λ</italic> is firing rate). Gamma-interval spiking variability of this form is closer to stationary at higher rates. Thus, the third and fourth simulations scaled up firing rates to further push spiking variability into a more stationary regime at the expense of highly unrealistic rates (in the fourth simulation, a firing rate briefly exceeded 1800 Hz). Overall, as the simulated neural data better accorded with the assumptions of the Kalman filter, decoding performance for the Kalman filter improved. Interestingly, MINT continued to perform well even on the simulated data, likely because MINT can exploit a linear relationship between neural and behavioral states when the data argue for it and higher rates benefit both algorithms. These results demonstrate that algorithms like MINT and the Kalman filter are not intrinsically good or bad. Rather, they are best suited to data that match their assumptions. When simulated data approximate the assumptions of the Kalman filter, both methods perform similarly. However, MINT shows much higher performance for the empirical data, suggesting that its assumptions are a better match for the statistical properties of the data. decoded behavior</p></caption>
<graphic xlink:href="535396v2_figS4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS5" position="float" fig-type="figure">
<label>Figure S5.</label>
<caption><title>MINT is a modular algorithm for which a variety of modifications and extensions exist.</title>
<p>The flowchart illustrates the standard MINT algorithm in <italic>black</italic> and lists potential changes to the algorithm in <italic>red</italic>. For example, the library of neural trajectories is typically learned via standard trial-averaging or a single-trial rate estimation technique like AutoLFADS. However, transfer learning could be utilized to learn the library of trajectories based on trajectories from a different subject or session. The trajectories could also be modified online while MINT is running to reflect changes in spiking activity that relate to recording instabilities. A potential modification to the method also occurs when likelihoods are converted into posterior probabilities. Typically, we assume a uniform prior over states in the library. However, that prior could be set to reflect the relative frequency of different behaviors and could even incorporate time-varying information from external sensors (e.g. state of a prosthetic limb, eye tracking, etc.) that include information about how probable each behavior is at a given moment. Another potential extension of MINT occurs at the stage where candidate neural states are selected. Typically, these states are selected based solely on spike count likelihoods. However, one could use a utility function that reflects a user’s values (e.g. the user may dislike some decoding mistakes more than others) in conjunction with the likelihoods to maximize expected utility. Lastly, the behavioral estimate that MINT returns could be post-processed (e.g. temporally smoothed). MINT’s modularity largely derives from the fact that the library of neural trajectories is finite. This assumption enables posterior probabilities to be directly computed for each state, rather than analytically derived. Thus, choices like how to learn the library of trajectories, which observation model to use (e.g. Poisson vs. generalized Poisson), and which (if any) state priors to use, can be made independently from one another. These choices all interact to impact performance. Yet they will not interact to impact tractability, as would have been the case if one analytically derived a continuous posterior probability distribution.</p></caption>
<graphic xlink:href="535396v2_figS5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s10">
<title>Supplementary Videos</title>
<fig id="figSV1" position="float" fig-type="figure">
<label>Figure SV1.</label>
<caption><title>Video demonstrating causal neural state estimation and behavioral decoding from MINT on the MC_Cycle dataset (see supplementary file).</title>
<p>In this dataset, a monkey moved a hand pedal cyclically forward or backward in response to visual cues. The raster plot of spiking activity (112 neurons, <italic>bottom right subpanel</italic>) and the actual and decoded angular velocities of the pedal (<italic>top right subpanel</italic>) are animated with 10 seconds of trailing history. Decoding was causal; the decode of the present angular velocity (right hand edge of scrolling traces) was based only on present and past spiking. Cycling speed was <italic>∼</italic>2 Hz. The underlying neural state estimate (<italic>green sphere in left subpanel</italic>) is plotted in a 3D neural subspace, with a 2D projection below. The present neural state is superimposed on top of the library of 8 neural trajectories used by MINT. The state estimate always remained on or near (via state interpolation) the neural trajectories. <italic>Purple</italic> and <italic>orange</italic> trajectories correspond to forward and backward pedaling conditions, respectively. The lighter-to-darker color gradients differentiate between trajectories corresponding to 1-, 2-, 4-, and 7-cycle conditions for each pedaling direction. Neural state estimate corresponds in time to the right edge of the scrolling raster/velocity plot. The three-dimensional neural subspace was hand-selected to capture a large amount of neural variance (59.6%; close to the 62.9% captured by the top 3 PCs) while highlighting the dominant translational and rotational structure in the trajectories.</p></caption>
<graphic xlink:href="535396v2_figSV1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<app-group>
<app id="app1">
<label>Appendix</label>
<title>Decoder implementations</title>
<p>All decoders described in this section were provided with the same training and testing data as MINT. When decoding, spiking activity was binned every 20 ms for each neuron. Each decoder was given access to recent binned spike counts to use for decoding. The following sections will: 1) provide an overview of the notation and definitions needed to understand the subsequent equations (notation <italic>will not</italic> in general match the notation used for MINT), 2) describe the hyperparameter optimization technique used for all decoders in this appendix, and 3) describe each decoder’s implementation in detail.</p>
<sec id="s11">
<title>Definitions</title>
<sec id="s11a">
<title>Time Bins</title>
<p>Each decoder received binned spiking activity and decoded behavior at time-bin resolution. These time bins are indexed by <italic>k</italic>. When higher-resolution estimates were required (e.g. for evaluating decoding performance), the decoded variables were simply upsampled with a zero-order-hold.</p>
</sec>
<sec id="s11b">
<title>Observations</title>
<p>The vector of spike counts at time bin <italic>k</italic> is denoted by the column vector <bold>x</bold><sub><italic>k</italic></sub> ∈ ℝ<sup><italic>N</italic></sup> where <italic>N</italic> is the number of neurons. When decoding, each decoder was given access to the current time bin of spike counts and <italic>κ</italic> previous time bins of spike counts. <italic>κ</italic> was not a fixed value and varied depending on the method, dataset, and behavioral group being decoded.</p>
</sec>
<sec id="s11c">
<title>Target Variables</title>
<p>The vector of behavioral variables at time bin <italic>k</italic> is denoted by the column vector <bold>y</bold><sub><italic>k</italic></sub> ∈ℝ<sup><italic>M</italic></sup> where <italic>M</italic> is the number of behavioral variables. This corresponds to the values of the behavioral variables at the end of the time bin.</p>
</sec>
<sec id="s11d">
<title>Decoded Variables</title>
<p>The vector of decoded behavioral variables at time bin <italic>k</italic> is denoted <bold>ŷ</bold><sub><italic>k</italic></sub>.</p>
</sec>
<sec id="s11e">
<title>Training Data</title>
<p>Observations and target variables at time bin <italic>i</italic> of trial <italic>j</italic> in the training data are denoted <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline108.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> and <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline109.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>.</p>
</sec>
</sec>
<sec id="s12">
<title>Hyperparameter Optimization</title>
<p>The hyperparameters for each decoder were set using Bayesian optimization [<xref ref-type="bibr" rid="c76">76</xref>]. The training set was split into a reduced training set (80% of the trials from the full training set) and a validation set (the remaining 20% of trials). The method is provided with a range of hyperparameter values to search. The method then seeks to learn a set of hyperparameters that, when trained on the reduced training set, will lead to maximal decoding <italic>R</italic><sup>2</sup> on the validation set. The optimization occurs via an iterative process that involves exploring the space of hyperparameters and exploiting knowledge of how certain hyperparameter sets performed in previous iterations. In all cases, we set the method to initially perform 10 iterations of random exploration of hyperparameter space, followed by 10 iterations of Bayesian optimization. The optimization was performed separately for each behavioral group (e.g. position vs. velocity) within each dataset. In the decoder-specific sections below, the exact hyperparameter values learned for each dataset and behavioral group are reported along with the hyperparameter ranges that were searched.</p>
</sec>
<sec id="s13">
<title>Wiener Filter</title>
<p>The Wiener filter [<xref ref-type="bibr" rid="c1">1</xref>] uses a model
<disp-formula id="eqnS1">
<alternatives><graphic xlink:href="535396v2_eqnS1.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <italic>b</italic> ∈ ℝ<sup><italic>M</italic></sup>, <italic>W</italic><sub><italic>i</italic></sub> ∈ ℝ<sup><italic>M ×N</italic></sup>, and the residuals are <bold><italic>ϵ</italic></bold><sub><italic>k</italic></sub> ∈ ℝ<sup><italic>M</italic></sup>. Decoding occurs via the equation
<disp-formula id="eqnS2">
<alternatives><graphic xlink:href="535396v2_eqnS2.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
for some matrix <italic>W</italic> that minimizes the squared error of the residuals in the training data.</p>
<sec id="s13a">
<title>Parameter fitting</title>
<p>For each trial <italic>j</italic> in the training data, we construct matrices
<disp-formula id="eqnS3">
<alternatives><graphic xlink:href="535396v2_eqnS3.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqnS4">
<alternatives><graphic xlink:href="535396v2_eqnS4.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <italic>T</italic><sub><italic>j</italic></sub> is the number of time bins in trial <italic>j</italic>. Then, we concatenate across <italic>J</italic> trials to get
<disp-formula id="eqnS5">
<alternatives><graphic xlink:href="535396v2_eqnS5.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqnS6">
<alternatives><graphic xlink:href="535396v2_eqnS6.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<italic>W</italic> can then be fit via a regularized regression,
<disp-formula id="eqnS7">
<alternatives><graphic xlink:href="535396v2_eqnS7.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
</p>
<table-wrap id="tbl6" orientation="portrait" position="float">
<label>Table 6.</label>
<caption><p>Hyperparameters used for the Wiener filter. The L2 regularization term <italic>λ</italic> was optimized in the range [0, 2000], with the optimized values rounded to the closest multiple of 10. Window lengths were optimized (in 20 ms increments) in the range [200, 600] for Area2_Bump, [200, 1000] for MC_Cycle, [200, 1200] for MC_RTT, and [200, 700] for MC_Maze, MC_Maze-L, MC_Maze-M, and MC_Maze-S. These ranges were determined by the structure of each dataset (e.g. Area2_Bump couldn’t look back more than 600 ms from the beginning of the evaluation epoch without entering the previous trial). Window lengths are directly related to <italic>κ</italic> via Δ (e.g. <italic>κ</italic> = 14 would correspond to a window length of Δ(<italic>κ</italic> + 1) = 20(14 + 1) = 300 ms.)</p></caption>
<graphic xlink:href="535396v2_tbl6.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<table-wrap id="tbl7" orientation="portrait" position="float">
<label>Table 7.</label>
<caption><p>Hyperparameters used for the Kalman filter. The lag (in increments of 20 ms time bins) between neural activity and behavior was optimized in the range [<xref ref-type="bibr" rid="c2">2</xref>, <xref ref-type="bibr" rid="c8">8</xref>], corresponding to 40-160 ms, for all datasets except Area2_Bump. For Area2_Bump the lag was not optimized and was simply set to 0 due to the fact that, in a sensory area, movement precedes sensory feedback. Given that <bold>x</bold><sub><italic>k</italic></sub> aggregates spikes across the whole time bin, but <bold>y</bold><sub><italic>k</italic></sub> corresponds to the behavioral variables at the end of the time bin, the effective lag is actually half a bin (10 ms) longer — i.e. the effective range of lags considered for the non-sensory datasets was 50-170 ms.</p></caption>
<graphic xlink:href="535396v2_tbl7.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
</sec>
<sec id="s14">
<title>Kalman filter</title>
<p>The Kalman filter [<xref ref-type="bibr" rid="c99">99</xref>] uses a model
<disp-formula id="eqnS8">
<alternatives><graphic xlink:href="535396v2_eqnS8.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqnS9">
<alternatives><graphic xlink:href="535396v2_eqnS9.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <bold>q</bold><sub><italic>k</italic></sub> ∈ 𝒩 (0, <italic>Q</italic>) and <bold>r</bold><sub><italic>k</italic></sub> ∈ 𝒩 (0, <italic>R</italic>). Decoding occurs via the standard update equations:
<disp-formula id="eqnS10">
<alternatives><graphic xlink:href="535396v2_eqnS10.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqnS11">
<alternatives><graphic xlink:href="535396v2_eqnS11.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where
<disp-formula id="eqnS12">
<alternatives><graphic xlink:href="535396v2_eqnS12.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqnS13">
<alternatives><graphic xlink:href="535396v2_eqnS13.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqnS14">
<alternatives><graphic xlink:href="535396v2_eqnS14.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
The state vector <bold>y</bold><sub><italic>k</italic></sub> includes 7 elements: position, velocity, and acceleration (x- and y-components of each) as well as a constant 1. The 1 was included to allow firing rates to have a constant offset. Acceleration was included as in [<xref ref-type="bibr" rid="c43">43</xref>] to improve the position and velocity estimates.</p>
<sec id="s14a">
<title>Parameter fitting</title>
<p>For each trial <italic>j</italic> in the training set, we construct matrices
<disp-formula id="eqnS15">
<alternatives><graphic xlink:href="535396v2_eqnS15.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqnS16">
<alternatives><graphic xlink:href="535396v2_eqnS16.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqnS17">
<alternatives><graphic xlink:href="535396v2_eqnS17.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqnS18">
<alternatives><graphic xlink:href="535396v2_eqnS18.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <italic>T</italic><sub><italic>j</italic></sub> is the number of time bins in trial <italic>j</italic>. Then, we concatenate across <italic>J</italic> trials to get
<disp-formula id="eqnS19">
<alternatives><graphic xlink:href="535396v2_eqnS19.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqnS20">
<alternatives><graphic xlink:href="535396v2_eqnS20.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqnS21">
<alternatives><graphic xlink:href="535396v2_eqnS21.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqnS22">
<alternatives><graphic xlink:href="535396v2_eqnS22.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
The parameters can then be fit as follows:
<disp-formula id="eqnS23">
<alternatives><graphic xlink:href="535396v2_eqnS23.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqnS24">
<alternatives><graphic xlink:href="535396v2_eqnS24.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqnS25">
<alternatives><graphic xlink:href="535396v2_eqnS25.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqnS26">
<alternatives><graphic xlink:href="535396v2_eqnS26.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqnS27">
<alternatives><graphic xlink:href="535396v2_eqnS27.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqnS28">
<alternatives><graphic xlink:href="535396v2_eqnS28.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <italic>T</italic><sub>1</sub> and <italic>T</italic> are the number of columns in <bold>Y</bold><sub>1</sub> and <bold>Y</bold>, respectively.</p>
</sec>
</sec>
<sec id="s15">
<title>Feedforward Neural Network</title>
<p>The feedforward neural network [<xref ref-type="bibr" rid="c100">100</xref>] we use takes spike count observations (current and previous time bins) and flattens them into a long vector,
<disp-formula id="eqnS29">
<alternatives><graphic xlink:href="535396v2_eqnS29.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
centers and normalizes that vector,
<disp-formula id="eqnS30">
<alternatives><graphic xlink:href="535396v2_eqnS30.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
and then feeds it through multiple hidden network layers,
<disp-formula id="eqnS31">
<alternatives><graphic xlink:href="535396v2_eqnS31.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqnS32">
<alternatives><graphic xlink:href="535396v2_eqnS32.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
before finally reading out behavior,
<disp-formula id="eqnS33">
<alternatives><graphic xlink:href="535396v2_eqnS33.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline110.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, <italic>D</italic> is the number of units per hidden layer, and <italic>L</italic> is the number of hidden layers.</p>
<sec id="s15a">
<title>Parameter fitting</title>
<p>For each trial <italic>j</italic> in the training set, we create flattened observations
<disp-formula id="eqnS34">
<alternatives><graphic xlink:href="535396v2_eqnS34.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
for all <italic>i &gt; κ</italic> (sufficient spike count history doesn’t exist for <italic>i</italic> ≤<italic>κ</italic>). We then let <italic>μ</italic> and <italic>σ</italic> be the element-wise mean and standard deviation of <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline111.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula> across all observations in the training set (i.e. across all time bins in all <italic>J</italic> trials for which <italic>i &gt; κ</italic>). The parameters <italic>W</italic><sub><italic>out</italic></sub>, <italic>b</italic><sub><italic>out</italic></sub>, <italic>W</italic><sub><italic>l</italic></sub>, and <italic>b</italic><sub><italic>l</italic></sub> for <italic>l</italic> ∈{1, …, <italic>L</italic>} are then learned by training the network with the Adam optimization routine [<xref ref-type="bibr" rid="c101">101</xref>] and a mean-squared error loss function. Training utilized dropout on the outputs of each hidden layer.</p>
<table-wrap id="tbl8" orientation="portrait" position="float">
<label>Table 8.</label>
<caption><p>Hyperparameters used for the feedforward neural network. The number of hidden layers (<italic>L</italic>) was optimized in the range [1, 15]. The number of units per hidden layer (D) was optimized in the range [50, 1000], with the optimized values rounded to the closest multiple of 10. The dropout rate was optimized in the range [0, 0.5] and the number of training epochs was optimized in the range [2, 100]. Window lengths were optimized (in 20 ms increments) in the range [200, 600] for Area2_Bump, [200, 1000] for MC_Cycle, [200, 1200] for MC_RTT, and [200, 700] for MC_Maze, MC_Maze-L, MC_Maze-M, and MC_Maze-S.</p></caption>
<graphic xlink:href="535396v2_tbl8.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
</sec>
<sec id="s16">
<title>GRU</title>
<p>The GRU neural network [<xref ref-type="bibr" rid="c102">102</xref>] we use takes spike count observations (current and previous time bins), centers and normalizes those observations,
<disp-formula id="eqnS35">
<alternatives><graphic xlink:href="535396v2_eqnS35.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
and then feeds the observations sequentially into the network (initializing with <bold>h</bold><sub><italic>k−κ−</italic>1</sub> = <bold>0</bold>),
<disp-formula id="eqnS36">
<alternatives><graphic xlink:href="535396v2_eqnS36.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqnS37">
<alternatives><graphic xlink:href="535396v2_eqnS37.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqnS38">
<alternatives><graphic xlink:href="535396v2_eqnS38.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
<disp-formula id="eqnS39">
<alternatives><graphic xlink:href="535396v2_eqnS39.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
ultimately reading out behavior from the final state,
<disp-formula id="eqnS40">
<alternatives><graphic xlink:href="535396v2_eqnS40.gif" mimetype="image" mime-subtype="gif"/></alternatives>
</disp-formula>
where <bold>z</bold><sub><italic>i</italic></sub>∈ ℝ<sup><italic>D</italic></sup>, <bold>r</bold><sub><italic>i</italic></sub>∈ ℝ<sup><italic>D</italic></sup>, <inline-formula><alternatives><inline-graphic xlink:href="535396v2_inline112.gif" mimetype="image" mime-subtype="gif"/></alternatives></inline-formula>, <bold>h</bold><sub><italic>i</italic></sub>∈ ℝ<sup><italic>D</italic></sup>, and <italic>D</italic> is the number of GRU units. The GRU hidden states do not persist from one decoding time bin to the next. Rather, at each decoding time bin, the GRU is re-initialized with <bold>h</bold><sub><italic>k−κ−</italic>1</sub> = <bold>0</bold> and run sequentially over recent history to generate an estimate of the behavior at the current time bin.</p>
<sec id="s16a">
<title>Parameter fitting</title>
<p><italic>μ</italic> and <italic>σ</italic> (both column vectors of length <italic>N</italic>) are computed as the mean and standard deviation, respectively, of the observed spike counts for each neuron in the training set. The parameters <italic>W</italic><sub><italic>z</italic></sub>, <italic>U</italic><sub><italic>z</italic></sub>, <italic>b</italic><sub><italic>z</italic></sub>, <italic>W</italic><sub><italic>r</italic></sub>, <italic>U</italic><sub><italic>r</italic></sub>, <italic>b</italic><sub><italic>r</italic></sub>, <italic>W</italic><sub><italic>h</italic></sub>, <italic>U</italic><sub><italic>h</italic></sub>, <italic>b</italic><sub><italic>h</italic></sub>, <italic>W</italic><sub><italic>out</italic></sub>, and <italic>b</italic><sub><italic>out</italic></sub> are then learned by training the network with the RMSProp optimization routine [<xref ref-type="bibr" rid="c103">103</xref>] and a mean-squared error loss function. Training utilized dropout both on the linear transformation of inputs and on the linear transformation of the recurrent state.</p>
<table-wrap id="tbl9" orientation="portrait" position="float">
<label>Table 9.</label>
<caption><p>Hyperparameters used for the GRU network. The number of units (<italic>D</italic>) was optimized in the range [50, 1000], with the optimized values rounded to the closest multiple of 10. The dropout rate was optimized in the range [0, 0.5] and the number of training epochs was optimized in the range [2, 50]. Window lengths were optimized (in 20 ms increments) in the range [200, 600] for Area2_Bump, [200, 1000] for MC_Cycle, [200, 1200] for MC_RTT, and [200, 700] for MC_Maze, MC_Maze-L, MC_Maze-M, and MC_Maze-S.</p></caption>
<graphic xlink:href="535396v2_tbl9.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
</sec></app></app-group>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.89421.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Mathis</surname>
<given-names>Mackenzie W</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>École Polytechnique Fédérale de Lausanne</institution>
</institution-wrap>
<city>Genève</city>
<country>Switzerland</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This paper presents a new method called MINT that is simple yet effective at BCI-style decoding tasks in stereotyped settings. While the reviewers raise caveats, overall they believe the work is a <bold>valuable</bold> study for the field of motor control, and the evidence to support their claims is <bold>solid</bold>.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.89421.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>
This paper presents an innovative decoding approach for brain-computer interfaces (BCIs), introducing a new method named MINT. The authors develop a trajectory-centric approach to decode behaviors across several different datasets, including eight empirical datasets from the Neural Latents Benchmark. Overall, the paper is well written and their method shows impressive performance compared to more traditional decoding approaches that use a simpler approach. While there are some concerns (see below), the paper's strengths, particularly its emphasis on a trajectory-centric approach and the simplicity of MINT, provide a compelling contribution to the field.</p>
<p>Strengths:</p>
<p>
The adoption of a trajectory-centric approach that utilizes statistical constraints presents a substantial shift in methodology, potentially revolutionizing the way BCIs interpret and predict neural behaviour. This is one of the strongest aspects of the paper.</p>
<p>The thorough evaluation of the method across various datasets serves as an assurance that the superior performance of MINT is not a result of overfitting. The comparative simplicity of the method in contrast to many neural network approaches is refreshing and should facilitate broader applicability.</p>
<p>Weaknesses:</p>
<p>
Scope: Despite the impressive performance of MINT across multiple datasets, it seems predominantly applicable to M1/S1 data. Only one of the eight empirical datasets comes from an area outside the motor/somatosensory cortex. It would be beneficial if the authors could expand further on how the method might perform with other brain regions that do not exhibit low tangling or do not have a clear trial structure (e.g. decoding of position or head direction from hippocampus)</p>
<p>When comparing methods, the neural trajectories of MINT are based on averaged trials, while the comparison methods are trained on single trials. An additional analysis might help in disentangling the effect of the trial averaging. For this, the authors could average the input across trials for all decoders, establishing a baseline for averaged trials. Note that inference should still be done on single trials. Performance can then be visualized across different values of N, which denotes the number of averaged trials used for training.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.89421.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>
The goal of this paper is to present a new method, termed MINT, for decoding behavioral states from neural spiking data. MINT is a statistical method which, in addition to outputting a decoded behavioral state, also provides soft information regarding the likelihood of that behavioral state based on the neural data. The innovation in this approach is neural states are assumed to come from sparsely distributed neural trajectories with low tangling, meaning that neural trajectories (time sequences of neural states) are sparse in the high-dimensional space of neural spiking activity and that two dissimilar neural trajectories tend to correspond to dissimilar behavioral trajectories. The authors support these assumptions through analysis of previously collected data, and then validate the performance of their method by comparing it to a suite of alternative approaches. The authors attribute the typically improved decoding performance by MINT to its assumptions being more faithfully aligned to the properties of neural spiking data relative to assumptions made by the alternatives.</p>
<p>Strengths:</p>
<p>
The paper did an excellent job critically evaluating common assumptions made by neural analytical methods, such as neural state being low-dimensional relative to the number of recorded neurons. The authors made strong arguments, supported by evidence and literature, for potentially high-dimensional neural states and thus the need for approaches that do not rely on an assumption of low dimensionality.</p>
<p>The paper was thorough in considering multiple datasets across a variety of behaviors, as well as existing decoding methods, to benchmark the MINT approach. This provided a valuable comparison to validate the method. The authors also provided nice intuition regarding why MINT may offer performance improvement in some cases and in which instances MINT may not perform as well.</p>
<p>In addition to providing a philosophical discussion as to the advantages of MINT and benchmarking against alternatives, the authors also provided a detailed description of practical considerations. This included training time, amount of training data, robustness to data loss or changes in the data, and interpretability. These considerations not only provided objective evaluation of practical aspects but also provided insights to the flexibility and robustness of the method as they relate back to the underlying assumptions and construction of the approach.</p>
<p>Weaknesses:</p>
<p>
The authors posit that neural and behavioral trajectories are non-isometric. To support this point, they look at distances between neural states and distances between the corresponding behavioral states, in order to demonstrate that there are differences in these distances in each respective space. This supports the idea that neural states and behavioral states are non-isometric but does not directly address their point. In order to say the trajectories are non-isometric, it would be better to look at pairs of distances between corresponding trajectories in each space.</p>
<p>With regards to the idea of neural and behavioral trajectories having different geometries, this is dependent on what behavioral variables are selected. In the example for Fig 2a, the behavior is reach position. The geometry of the behavioral trajectory of interest would look different if instead the behavior of interest was reach velocity. The paper would be strengthened by acknowledgement that geometries of trajectories are shaped by extrinsic choices rather than (or as much as they are) intrinsic properties of the data.</p>
<p>The approach is built up on the idea of creating a &quot;mesh&quot; structure of possible states. In the body of the paper the definition of the mesh was not entirely clear and I could not find in the methods a more rigorous explicit definition. Since the mesh is integral to the approach, the paper would be improved with more description of this component.</p>
<p>Impact:</p>
<p>
This work is motivated by brain-computer interfaces applications, which it will surely impact in terms of neural decoder design. However, this work is also broadly impactful for neuroscientific analysis to relate neural spiking activity to observable behavioral features. Thus, MINT will likely impact neuroscience research generally. The methods are made publicly available, and the datasets used are all in public repositories, which facilitates adoption and validation of this method within the greater scientific community.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.89421.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This manuscript develops a new method termed MINT for decoding of behavior. The method is essentially a table-lookup rather than a model. Within a given stereotyped task, MINT tabulates averaged firing rate trajectories of neurons (neural states) and corresponding averaged behavioral trajectories as stereotypes to construct a library. For a test trial with a realized neural trajectory, it then finds the closest neural trajectory to it in the table and declares the associated behavior trajectory in the table as the decoded behavior. The method can also interpolate between these tabulated trajectories. The authors mention that the method is based on three key assumptions: (1) Neural states may not be embedded in a low-dimensional subspace, but rather in a high-dimensional space. (2) Neural trajectories are sparsely distributed under different behavioral conditions. (3) These neural states traverse trajectories in a stereotyped order.</p>
<p>The authors conducted multiple analyses to validate MINT, demonstrating its decoding of behavioral trajectories in simulations and datasets (Figures 3, 4). The main behavior decoding comparison is shown in Figure 4. In stereotyped tasks, decoding performance is comparable (M_Cycle, MC_Maze) or better (Area 2_Bump) than other linear/nonlinear algorithms (Figure 4). However, MINT underperforms for the MC_RTT task, which is less stereotyped (Figure 4).</p>
<p>This paper is well-structured and its main idea is clear. The fact that performance on stereotyped tasks is high is interesting and informative, showing that these stereotyped tasks create stereotyped neural trajectories. The task-specific comparisons include various measures and a variety of common decoding approaches, which is a strength. However, I have several major concerns. I believe several of the conclusions in the paper, which are also emphasized in the abstract, are not accurate or supported, especially about generalization, computational scalability, and utility for BCIs. MINT is essentially a table-lookup algorithm based on stereotyped task-dependent trajectories and involves the tabulation of extensive data to build a vast library without modeling. These aspects will limit MINT's utility for real-world BCIs and tasks. These properties will also limit MINT's generalizability from task to task, which is important for BCIs and thus is commonly demonstrated in BCI experiments with other decoders without any retraining. Furthermore, MINT's computational and memory requirements can be prohibitive it seems. Finally, as MINT is based on tabulating data without learning models of data, I am unclear how it will be useful in basic investigations of neural computations. I expand on these concerns below.</p>
<p>Main comments:</p>
<p>1. MINT does not generalize to different tasks, which is a main limitation for BCI utility compared with prior BCI decoders that have shown this generalizability as I review below. Specifically, given that MINT tabulates task-specific trajectories, it will not generalize to tasks that are not seen in the training data even when these tasks cover the exact same space (e.g., the same 2D computer screen and associated neural space).</p>
<p>First, the authors provide a section on generalization, which is inaccurate because it mixes up two fundamentally different concepts: 1) collecting informative training data and 2) generalizing from task to task. The former is critical for any algorithm, but it does not imply the latter. For example, removing one direction of cycling from the training set as the authors do here is an example of generating poor training data because the two behavioral (and neural) directions are non-overlapping and/or orthogonal while being in the same space. As such, it is fully expected that all methods will fail. For proper training, the training data should explore the whole movement space and the associated neural space, but this does not mean all kinds of tasks performed in that space must be included in the training set (something MINT likely needs while modeling-based approaches do not). Many BCI studies have indeed shown this generalization ability using a model. For example, in Weiss et al. 2019, center-out reaching tasks are used for training and then the same trained decoder is used for typing on a keyboard or drawing on the 2D screen. In Gilja et al. 2012, training is on a center-out task but the same trained decoder generalizes to a completely different pinball task (hit four consecutive targets) and tasks requiring the avoidance of obstacles and curved movements. There are many more BCI studies, such as Jarosiewicz et al. 2015 that also show generalization to complex real-world tasks not included in the training set. Unlike MINT, these works can achieve generalization because they model the neural subspace and its association to movement. On the contrary, MINT models task-dependent neural trajectories, so the trained decoder is very task-dependent and cannot generalize to other tasks. So, unlike these prior BCIs methods, MINT will likely actually need to include every task in its library, which is not practical.</p>
<p>I suggest the authors remove claims of generalization and modify their arguments throughout the text and abstract. The generalization section needs to be substantially edited to clarify the above points. Please also provide the BCI citations and discuss the above limitation of MINT for BCIs.</p>
<p>2. MINT is shown to achieve competitive/high performance in highly stereotyped datasets with structured trials, but worse performance on MC_RTT, which is not based on repeated trials and is less stereotyped. This shows that MINT is valuable for decoding in repetitive stereotyped use-cases. However, it also highlights a limitation of MINT for BCIs, which is that MINT may not work well for real-world and/or less-constrained setups such as typing, moving a robotic arm in 3D space, etc. This is again due to MINT being a lookup table with a library of stereotyped trajectories rather than a model. Indeed, the authors acknowledge that the lower performance on MC_RTT (Figure 4) may be caused by the lack of repeated trials of the same type. However, real-world BCI decoding scenarios will also not have such stereotyped trial structure and will be less/un-constrained, in which MINT underperforms. Thus, the claim in the abstract or lines 480-481 that MINT is an &quot;excellent&quot; candidate for clinical BCI applications is not accurate and needs to be qualified. The authors should revise their statements according and discuss this issue. They should also make the use-case of MINT on BCI decoding clearer and more convincing.</p>
<p>3. Related to 2, it may also be that MINT achieves competitive performance in offline and trial-based stereotyped decoding by overfitting to the trial structure in a given task, and thus may not generalize well to online performance due to overfitting. For example, a recent work showed that offline decoding performance may be overfitted to the task structure and may not represent online performance (Deo et al. 2023). Please discuss.</p>
<p>4. Related to 2, since MINT requires firing rates to generate the library and simple averaging does not work for this purpose in the MC_RTT dataset (that does not have repeated trials), the authors needed to use AutoLFADS to infer the underlying firing rates. The fact that MINT requires the usage of another model to be constructed first and that this model can be computationally complex, will also be a limiting factor and should be clarified.</p>
<p>5. I also find the statement in the abstract and paper that &quot;computations are simple, scalable&quot; to be inaccurate. The authors state that MINT's computational cost is O(NC) only, but it seems this is achieved at a high memory cost as well as computational cost in training. The process is described in section &quot;Lookup table of log-likelihoods&quot; on line [978-990]. The idea is to precompute the log-likelihoods for any combination of all neurons with discretization x all delay/history segments x all conditions and to build a large lookup table for decoding. Basically, the computational cost of precomputing this table is O(V^{Nτ} x TC) and the table requires a memory of O(V^{Nτ}), where V is the number of discretization points for the neural firing rates, N is the number of neurons, τ is the history length, T is the trial length, and C is the number of conditions. This is a very large burden, especially the V^{Nτ} term. This cost is currently not mentioned in the manuscript and should be clarified in the main text. Accordingly, computation claims should be modified including in the abstract.</p>
<p>6. In addition to the above technical concerns, I also believe the authors should clarify the logic behind developing MINT better. From a scientific standpoint, we seek to gain insights into neural computations by making various assumptions and building models that parsimoniously describe the vast amount of neural data rather than simply tabulating the data. For instance, low-dimensional assumptions have led to the development of numerous dimensionality reduction algorithms and these models have led to important interpretations about the underlying dynamics (e.g., fixed points/limit cycles). While it is of course valid and even insightful to propose different assumptions from existing models as the authors do here, they do not actually translate these assumptions into a new model. Without a model and by just tabulating the data, I don't believe we can provide interpretation or advance the understanding of the fundamentals behind neural computations. As such, I am not clear as to how this library building approach can advance neuroscience or how these assumptions are useful. I think the authors should clarify and discuss this point.</p>
<p>7. Related to 6, there seems to be a logical inconsistency between the operations of MINT and one of its three assumptions, namely, sparsity. The authors state that neural states are sparsely distributed in some neural dimensions (Figure 1a, bottom). If this is the case, then why does MINT extend its decoding scope by interpolating known neural states (and behavior) in the training library? This interpolation suggests that the neural states are dense on the manifold rather than sparse, thus being contradictory to the assumption made. If interpolation-based dense meshes/manifolds underlie the data, then why not model the neural states through the subspace or manifold representations? I think the authors should address this logical inconsistency in MINT, especially since this sparsity assumption also questions the low-dimensional subspace/manifold assumption that is commonly made.</p>
<p>References</p>
<p>Weiss, Jeffrey M., Robert A. Gaunt, Robert Franklin, Michael L. Boninger, and Jennifer L. Collinger. 2019. &quot;Demonstration of a Portable Intracortical Brain-Computer Interface.&quot; Brain-Computer Interfaces 6 (4): 106-17. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/2326263X.2019.1709260">https://doi.org/10.1080/2326263X.2019.1709260</ext-link>.</p>
<p>Gilja, Vikash, Paul Nuyujukian, Cindy A. Chestek, John P. Cunningham, Byron M. Yu, Joline M. Fan, Mark M. Churchland, et al. 2012. &quot;A High-Performance Neural Prosthesis Enabled by Control Algorithm Design.&quot; Nature Neuroscience 15 (12): 1752-1757. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.3265">https://doi.org/10.1038/nn.3265</ext-link>.</p>
<p>Jarosiewicz, Beata, Anish A. Sarma, Daniel Bacher, Nicolas Y. Masse, John D. Simeral, Brittany Sorice, Erin M. Oakley, et al. 2015. &quot;Virtual Typing by People with Tetraplegia Using a Self-Calibrating Intracortical Brain-Computer Interface.&quot; Science Translational Medicine 7 (313): 313ra179-313ra179. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/scitranslmed.aac7328">https://doi.org/10.1126/scitranslmed.aac7328</ext-link>.</p>
<p>Darrel R. Deo, Francis R. Willett, Donald T. Avansino, Leigh R. Hochberg, Jaimie M. Henderson, and Krishna V. Shenoy. 2023. &quot;Translating Deep Learning to Neuroprosthetic Control.&quot; BioRxiv, 2023.04.21.537581. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1101/2023.04.21.537581">https://doi.org/10.1101/2023.04.21.537581</ext-link>.</p>
</body>
</sub-article>
</article>