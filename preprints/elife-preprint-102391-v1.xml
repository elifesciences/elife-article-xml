<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">102391</article-id>
<article-id pub-id-type="doi">10.7554/eLife.102391</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.102391.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Hierarchical Bayesian modeling of multi-region brain cell count data</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Dimmock</surname>
<given-names>Sydney</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
<email>sd14814bristol.ac.uk</email>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Exley</surname>
<given-names>Benjamin MS</given-names>
</name>
<xref ref-type="aff" rid="a2">b</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1613-8971</contrib-id>
<name>
<surname>Moore</surname>
<given-names>Gerald</given-names>
</name>
<xref ref-type="aff" rid="a3">c</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Menage</surname>
<given-names>Lucy</given-names>
</name>
<xref ref-type="aff" rid="a4">d</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4414-4714</contrib-id>
<name>
<surname>Delogu</surname>
<given-names>Alessio</given-names>
</name>
<xref ref-type="aff" rid="a4">d</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6794-5813</contrib-id>
<name>
<surname>Schultz</surname>
<given-names>Simon R</given-names>
</name>
<xref ref-type="aff" rid="a3">c</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2129-2060</contrib-id>
<name>
<surname>Warburton</surname>
<given-names>E Clea</given-names>
</name>
<xref ref-type="aff" rid="a2">b</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5017-9473</contrib-id>
<name>
<surname>Houghton</surname>
<given-names>Conor</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2031-9177</contrib-id>
<name>
<surname>O’Donnell</surname>
<given-names>Cian</given-names>
</name>
<xref ref-type="aff" rid="a1">a</xref>
<xref ref-type="aff" rid="a5">e</xref>
<email>c.odonnell2@ulster.ac.uk</email>
</contrib>
<aff id="a1"><label>a</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0524sp257</institution-id><institution>School of Engineering Mathematics and Technology, University of Bristol</institution></institution-wrap>, <city>Bristol</city>, <country>United Kingdom</country></aff>
<aff id="a2"><label>b</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0524sp257</institution-id><institution>School of Physiology, Pharmacology and Neuroscience, University of Bristol</institution></institution-wrap>, <city>Bristol</city>, <country>United Kingdom</country></aff>
<aff id="a3"><label>c</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/041kmwe10</institution-id><institution>Centre for Neurotechnology and Dept of Bioengineering, Imperial College London</institution></institution-wrap>, <city>London</city>, <country>United Kingdom</country></aff>
<aff id="a4"><label>d</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0220mzb33</institution-id><institution>Department of Basic and Clinical Neuroscience, Institute of Psychiatry, Psychology and Neuroscience, King’s College London</institution></institution-wrap>, <city>London</city>, <country>United Kingdom</country></aff>
<aff id="a5"><label>e</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01yp9g959</institution-id><institution>School of Computing, Engineering &amp; Intelligent Systems, Ulster University</institution></institution-wrap>, <city>Derry/Londonderry</city>, <country>United Kingdom</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Berman</surname>
<given-names>Gordon J</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Emory University</institution>
</institution-wrap>
<city>Atlanta</city>
<country>United States of America</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Poirazi</surname>
<given-names>Panayiota</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>FORTH Institute of Molecular Biology and Biotechnology</institution>
</institution-wrap>
<city>Heraklion</city>
<country>Greece</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn fn-type="coi-statement"><p>No competing interests.</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-11-25">
<day>25</day>
<month>11</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP102391</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-08-20">
<day>20</day>
<month>08</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-07-21">
<day>21</day>
<month>07</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.07.20.603979"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Dimmock et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Dimmock et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-102391-v1.pdf"/>
<abstract>
<p>We can now collect cell-count data across whole animal brains quantifying recent neuronal activity, gene expression, or anatomical connectivity. This is a powerful approach since it is a multi-region measurement, but because the imaging is done post-mortem, each animal only provides one set of counts. Experiments are expensive and since cells are counted by imaging and aligning a large number of brain sections, they are time-intensive. The resulting datasets tend to be under-sampled with fewer animals than brain regions. As a consequence, these data are a challenge for traditional statistical approaches. We demonstrate that hierarchical Bayesian methods are well suited to these data by presenting a ‘standard’ partially-pooled Bayesian model for multi-region cell-count data and applying it to two example datasets. For both datasets the Bayesian model outperformed standard parallel t-tests. Overall, the Bayesian approach’s ability to capture nested data and its rigorous handling of uncertainty in under-sampled data can substantially improve inference for cell-count data.</p></abstract>
<abstract abstract-type="summary">
<title>Significance Statement</title>
<p>Cell-count data is important for studying neuronal activation and gene expression relating to the complex processes in the brain. However, the difficulty and expense of data collection means that such datasets often have small sample sizes. Many routine analyses are not well-suited, especially if there is high variability among animals and surprising outliers in the data. Here we describe a multilevel, mixed effects Bayesian model for these data and show that the Bayesian approach improves inferences compared to the usual approach for two different cell-count datasets with different data characteristics.</p></abstract>
<kwd-group kwd-group-type="author">
<kwd>Bayesian analysis</kwd>
<kwd>Cell-counts</kwd>
<kwd>Hierarchical modeling</kwd>
<kwd>Neuroscience data</kwd>
</kwd-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="external-links">
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://github.com/SydneyJake/Hierarchical_Bayesian_Cell_Counts">https://github.com/SydneyJake/Hierarchical_Bayesian_Cell_Counts</ext-link>
</p></fn>
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.12787211">https://doi.org/10.5281/zenodo.12787211</ext-link>
</p></fn>
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.12787287">https://doi.org/10.5281/zenodo.12787287</ext-link>
</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s0">
<title>Introduction</title>
<p>In studying the brain we are often confronted with phenomena that involve specific subsets of neurons distributed across many brain regions. Computations, for example, are performed by neuronal networks connecting cells in different parts of the brain and, in development, neurons in different anatomical regions of the brain share the same lineage. An example of each of these types will be considered here, but the challenge is very general: how to measure and analyze multi-region neuronal data with cellular resolution.</p>
<p>In a typical cell-count experiment, gene expression is used to tag the specific cells of interest with a targeted indicator (<xref ref-type="bibr" rid="c1">1</xref>). The brain is sliced, an entire stack of brain sections from a single animal is imaged, aligning and registering the images to a standardised brain atlas such as the Allen mouse atlas (<xref ref-type="bibr" rid="c2">2</xref>–<xref ref-type="bibr" rid="c5">5</xref>), segmenting the images into anatomical regions and counting the labeled cells in each region. The resulting dataset consists of labeled cell counts across each of ∼10–100 brain regions. This technology is being deployed to address questions in a broad range of neuroscience subfields, for example: memory (<xref ref-type="bibr" rid="c6">6</xref>–<xref ref-type="bibr" rid="c8">8</xref>), neurodegenerative disorders (<xref ref-type="bibr" rid="c9">9</xref>), social behavior (<xref ref-type="bibr" rid="c10">10</xref>), and stress (<xref ref-type="bibr" rid="c11">11</xref>).</p>
<p>Cell-counts are often compared across groups of animals which differ by an experimental condition such as drug treatment, genotype or behavioural manipulation. However, the expense and difficulty of the experiment means that the number of animals in each group is often small, ten is a typical number but fewer than ten is not uncommon. This means that these data are undersampled: the dimensionality of the data, which corresponds to the number of brain regions, is much larger than the number of samples, which usually corresponds to the number of animals (<xref rid="fig1" ref-type="fig">Figure 1<bold>A</bold></xref>). Current statistical methods are not well-suited to these nested wide-but-shallow datasets. Furthermore, due to the complicated preparation and imaging procedure, there is often missing data and there is variability derived from experimental artifacts.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Fig. 1.</label>
<caption><title>Introduction.</title><p><bold>A</bold>: Each of <italic>N</italic> animals produce a cell-count from a total of <italic>R</italic> brain regions of interest. Cell-count data is typically undersampled with <italic>N</italic> ≪ <italic>R</italic>. Scientists analyse the brain sections from experiment for positive signals. Here an example section is shown where teal points mark cells expressing the immediate early gene <italic>c-Fos</italic>. The final cell-count is equal to the sum of these individual items (sagittal brain map taken from the Allen mouse brain atlas: <ext-link ext-link-type="uri" xlink:href="https://mouse.brain-map.org">https://mouse.brain-map.org</ext-link>. <bold>B</bold>: Partial pooling is a hierarchical structure that jointly models observations from some shared population distribution. It is a spectrum that depends on the value of the population variance <italic>τ</italic>. When <italic>τ</italic> = 0 there is no variation in the population and each individual observation is modeled as a conditionally independent estimate of some fixed population mean <italic>θ</italic> (complete pooling). As <italic>τ</italic> tends to infinity observations do not combine inferential strength but inform an independent estimate <italic>γ</italic><sub><italic>i</italic></sub> (no pooling). In between the two extremes combine. Each observation can contribute to the population estimate while simultaneously supporting a local one to effectively model the variance in the data. Observed quantities have been highlighted with a thicker stroke in the graphical model. <bold>C</bold>: An example of partial pooling on simulated count data. As the population standard deviation increases on the <italic>x</italic>-axis the individual estimates exp(<italic>γ</italic><sub><italic>i</italic></sub>) trace a path from a completely pooled estimate to an unpooled estimate. Circular points give the raw data values. Parameters are exponentiated because the outcomes are Poisson and so parameters are fit on the log scale.</p></caption>
<graphic xlink:href="603979v1_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>In cell count data there are two obvious sources of noise. The first of these is easy to describe, if a region has an rate that determines how likely a cell is to be marked for counting, then the actual number of marked cells is sampled from a Poisson distribution. The second source of noise is the animal to animal variability of the rate itself and this depends on diverse features of the individual animal and the experiment that are often unrelated to the phenomenon of interest. The challenge is to control for outliers and ‘poor’ data points whose rate is noisy, while extracting as much information as possible about the underlying process. Dealing with outliers is often an opaque and <italic>ad hoc</italic> procedure, it is also a binary decision, a point is either excluded so it does not contribute, or included, noise and all. This is where partial pooling helps. Partial pooling allows for the simultaneous estimation of individual parameters with the population distribution that describes them. This helps the data to self-regularise and elegantly balances the contribution of informative and weak observations to parameter values.</p>
<p>In recent years Bayesian approaches to data analysis have become powerful alternatives to classical frequentist approaches (<xref ref-type="bibr" rid="c12">12</xref>–<xref ref-type="bibr" rid="c14">14</xref>), including for some types of neuroscience data: such as neurolinguistics (<xref ref-type="bibr" rid="c15">15</xref>), neural coding (<xref ref-type="bibr" rid="c16">16</xref>, <xref ref-type="bibr" rid="c17">17</xref>), synaptic parameters (<xref ref-type="bibr" rid="c18">18</xref>–<xref ref-type="bibr" rid="c21">21</xref>) and neuronal-circuit connectivity (<xref ref-type="bibr" rid="c22">22</xref>, <xref ref-type="bibr" rid="c23">23</xref>). A Bayesian approach is particularly well suited to cell-count data but has not previously been applied to this problem.</p>
<p>A Bayesian approach formalizes the process of scientific inference, it distinguishes the data and a probabilistic mathematical model of the data. This model has a likelihood which gives the probability of the observed data for a given set of model parameters. The model often has a hierarchical structure which we compose to reflect the structure of the experiment and the investigators hypothesis of how the data depends on experimental condition. This hierarchy determines a set of <italic>a priori</italic> probabilities for the parameter values. The result of Bayesian inference is a probability distribution for these model parameters given the data, termed the posterior.</p>
<p>There are three advantages of a Bayesian approach that we want to emphasis, (<xref ref-type="bibr" rid="c1">1</xref>) while traditional multi-level models also allow a hierarchy (<xref ref-type="bibr" rid="c24">24</xref>), Bayesian models are more flexible and the role of the model is clearer, (<xref ref-type="bibr" rid="c2">2</xref>) since the result of Bayesian inference is a probability distribution over model parameters, it indicates not just the fitted value of a parameter but the uncertainty of the parameter value. Finally (<xref ref-type="bibr" rid="c3">3</xref>) Bayesian models tend to make more efficient use of data and therefore improving statistical power.</p>
<p>Here, our aim is to introduce a ‘standard’ Bayesian model for cell count data. We illustrate the application of this model to two datasets, one related to neural activation and the other to developmental lineage. In both cases the Bayesian model produces clearer results than the classical frequentist approach.</p>
</sec>
<sec id="s1">
<title>Materials and Methods</title>
<sec id="s1a">
<title>Data</title>
<p>To illustrate our approach we consider two example applications, one which counts cells active in regions of the recognition memory circuit of rat during a familiarity discrimination task, and the other which examines the distribution of a specific interneuron type in the mouse thalamus.</p>
</sec>
<sec id="s1b">
<title>Case study one – transient neural activity in the recognition memory circuit</title>
<p>The recognition memory network, <xref rid="fig3" ref-type="fig">Figure 3</xref>, is a distributed network which has been well studied using a variety of behavioural tasks. It includes the hippocampus (HPC) and perirhinal cortex (PRH), shown to deal with object spatial recognition and familiarity discrimination respectively (<xref ref-type="bibr" rid="c25">25</xref>–<xref ref-type="bibr" rid="c27">27</xref>); medial prefrontal cortex (MPFC), concerned with executive functions such as decision making but also with working memory, and the temporal association cortex (TE2) used for acquisition and retrieval of long-term object-recognition memories (<xref ref-type="bibr" rid="c28">28</xref>). The nucleus reuniens (NRe) is also believed to be an important component of the circuit (<xref ref-type="bibr" rid="c25">25</xref>, <xref ref-type="bibr" rid="c29">29</xref>), owing to its reciprocal connectivity with both MPFC and HPC (<xref ref-type="bibr" rid="c30">30</xref>). In previous studies, lesions of the NRe have been shown to significantly impair long-term but not short-term object-in-place recognition memory (<xref ref-type="bibr" rid="c29">29</xref>). The data analysed in this case study were collected to investigate the role of the NRe in the recognition memory circuit through contrasting the neural activation for animals with a lesion in the NRe with neural activation for animals with a sham surgery. The immediate early gene <italic>c-Fos</italic> is rapidly expressed following strong neural activation and is useful as a marker of transient neural activity. Animals in the experiment performed a familiarity discrimination task (single-item recognition memory), discriminating novel or familiar objects with or without an NRe lesion and the number of cells that expressed <italic>c-Fos</italic> was counted in regions across the recognition memory circuit. The two-by-two experimental design allocated ten animals to each of the four experiment groups {sham, lesion} × {novel, familiar} and cell counts were recorded from a total of 23 brain regions. The visual cortex V2C and the motor cortex M2C were taken as control regions as they were not expected to show differential <italic>c-Fos</italic> expression in response to novel or familiar objects (<xref ref-type="bibr" rid="c31">31</xref>).</p>
</sec>
<sec id="s1c">
<title>Case study two – Ontogeny of inhibitory neurons in mouse thalamus and hypothalamus</title>
<p>The second dataset comes from a study, (<xref ref-type="bibr" rid="c32">32</xref>), that, in part, counted the number of inhibitory interneurons in the thalamocortical regions of mouse. <italic>Sox14</italic> is a gene associated with inhibitory neurons in subcortical areas. It is required for the development and migration of local inhibitory interneurons in the dorsal lateral geniculate nucleus (LGd) of the thalamus (<xref ref-type="bibr" rid="c32">32</xref>, <xref ref-type="bibr" rid="c33">33</xref>). Consequently, <italic>Sox14</italic> is useful for identifying discrete neuronal populations in the thalamus and hypothalamus (or in the diencephalon) (<xref ref-type="bibr" rid="c32">32</xref>–<xref ref-type="bibr" rid="c34">34</xref>). A heterozygous (HET) knock-in mouse line <italic>Sox14</italic><sup><italic>GFP/+</italic></sup> to mark <italic>Sox14</italic> expressing neurons with green fluorescent protein (GFP), was compared to a homozygous knock-out (KO) mouse line <italic>Sox14</italic><sup><italic>GFP/GFP</italic></sup> engineered to block expression of the endogenous <italic>Sox14</italic> coding sequence (<xref ref-type="bibr" rid="c35">35</xref>). Each animal produced two samples, one for each hemisphere giving a total of ten data points, six belonging to HET (three animals), and four to KO (two animals). Each observation is 50 dimensional, corresponding to fifty individual brain regions in each hemisphere.</p>
</sec>
<sec id="s1d">
<title>Hierarchical modeling</title>
<p>Our goal in both cases is to quantify group differences in the data. We start with a ‘standard’ hierarchical model; this model can be further refined or changed to improve the analysis and to more clearly match the structure of a particular experiment, we will give an example of this for our second dataset. At the bottom of the model are the data themselves, the cell counts <italic>y</italic><sub><italic>i</italic></sub>. The index <italic>i</italic> runs over the full set of samples, in this case 23 × 10 × 4 datapoints in the first study, and 50 × 6 + 50 × 4 in the second. The basic assumption the model makes is that this count is derived from an underlying propensity, <italic>λ</italic><sub><italic>i</italic></sub> &gt; 0, which depends on brain region and, potentially, group:
<disp-formula id="eqn1">
<graphic xlink:href="603979v1_eqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>Hence, in this case, the propensity <italic>λ</italic><sub><italic>i</italic></sub> is the mean of the Poisson distribution, and the statistical model describes the dependence of this parameter on brain region and animal. Since <italic>λ</italic><sub><italic>i</italic></sub> is strictly positive a log-link function is used:
<disp-formula id="eqn2">
<graphic xlink:href="603979v1_eqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where
<disp-formula id="eqn3">
<graphic xlink:href="603979v1_eqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and we have used ‘array notation’ (<xref ref-type="bibr" rid="c36">36</xref>), mapping the sample index <italic>i</italic> to properties of the sample, so <italic>r</italic>[<italic>i</italic>] returns the region index of observation <italic>i</italic>, and similar for <italic>g</italic>[<italic>i</italic>] but for groups and animals.</p>
<p>We use partial pooling. Thus, ignoring <italic>E</italic><sub><italic>i</italic></sub> for now, the rate has been split between two terms, <italic>θ</italic><sub><italic>r</italic>[<italic>i</italic>],<italic>g</italic>[<italic>i</italic>]</sub> is the <italic>fixed effect</italic> which is constant across animals and <italic>γ</italic><sub><italic>r</italic>[<italic>i</italic>],<italic>a</italic>[<italic>i</italic>]</sub> is the <italic>random effect</italic> which captures the animal to animal variability. While <italic>θ</italic><sub><italic>rg</italic></sub> models the mean for log-cell-count for each region, given the condition; <italic>γ</italic><sub><italic>i</italic></sub> models variation around this mean. For this reason, <italic>γ</italic><sub><italic>i</italic></sub> is assumed to follow a normal distribution with zero mean. The regression term may appear over-parameterized, without <italic>θ</italic><sub><italic>rg</italic></sub> the <italic>γ</italic><sub><italic>i</italic></sub> could ‘do the work’ of matching the data. However, the model is regularized by a prior; observations with a weak likelihood will have their random effect <italic>γ</italic><sub><italic>i</italic></sub> shrunk towards the population location. The amount of regularization depends on the variation in the population, a quantity that is estimated from each likelihood. This is how partial pooling works as an adaptive prior for ‘similar’ parameters (<xref rid="fig1" ref-type="fig">Figure 1</xref><bold>B</bold>). The data ‘pools’ some evidence while still allowing for individual differences in sample.</p>
<p>The final term is the exposure <italic>E</italic><sub><italic>i</italic></sub>. Cell counts may be recorded from sections with different areas. The exposure term scales the parameters in the linear model as the recording area increases (<xref ref-type="bibr" rid="c13">13</xref>). In our model, the exposure is equal to the logarithm of the recording area; this value is available as part of the experimental data.</p>
<p>The set of parameters <italic>τ</italic><sub><italic>r,g</italic></sub> models the population standard deviations of the noise for each region <italic>r</italic> and animal group <italic>g</italic>.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><title>Parameter table for the hierarchical model.</title></caption>
<graphic xlink:href="603979v1_tbl1.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<p>When working on the log scale, priors for these parameters are typically derived in terms of multiplicative increases. Since the parameters are positive they are assigned a half-normal distribution
<disp-formula id="eqn4">
<graphic xlink:href="603979v1_eqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>with an appropriately chosen scale <italic>s</italic> &gt; 1. For our analyses we used <italic>s</italic> = 1.05 because this gives a HalfNormal distribution with 95% of its density in the interval [0, log(1.1)]. This translates into an approximate 10% variation around exp(<italic>θ</italic>) at the upper end, which is a moderately informative prior, reflecting our belief that within-group animal variability is small relative to between-group variability. This regularization also helps model inference when the datasets are undersampled.</p>
</sec>
<sec id="s1e">
<title>Horseshoe prior</title>
<p>Cell count data often has outliers, for example due to experimental artifacts. Since by default the likelihood does not account for these outliers, they may cause substantial changes in fitted parameter values. This is demonstrated in <xref rid="fig2" ref-type="fig">Figure 2</xref>, where a careless application of the Poisson distribution on data with several zero counts has a large influence on the posterior distribution. There are two general options for dealing with outliers: either modeling them in the likelihood or in the prior. Although the likelihood option is preferred as it is more direct, see our zero-inflation model below, it can be hard to design because it requires knowledge of the outlier generation process. The alternative is via a flexible prior such as the horseshoe (<xref ref-type="bibr" rid="c37">37</xref>, <xref ref-type="bibr" rid="c38">38</xref>). This more generic option may be suitable as a default approach if the outliers are poorly understood.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Fig. 2.</label>
<caption><title>Methods.</title><p>A table of partial pooling behaviour for different likelihood and prior combinations. Rows are the two prior choices for the population distribution, and columns the two distributions for the data. Within each cell the expectation of the marginal posterior <italic>p</italic>(exp(<italic>γ</italic><sub><italic>i</italic></sub>)|<italic>θ, τ, y</italic>) is plotted as a function of <italic>τ</italic>. The solid black line is the expectation of the marginal posterior <italic>p</italic>(<italic>θ</italic>|<italic>τ, y</italic>) with one standard deviation highlighted in grey. <bold>Top left</bold>: Combining a normal prior for the population with a Poisson likelihood is unsatisfactory in the presence of a zero observation. The zero observations influence the population mean in an extreme way owing to their high importance under the Poisson likelihood. <bold>Bottom left</bold>: By changing to a horseshoe prior the problematic zero observations can escape the regularisation machinery. However, regularisation of the estimates with positive observations is much less impactful. <bold>Top right</bold>: A zero-inflated Poisson likelihood accounts for the zero observations with an added process, reducing the burden on the population estimate to compromise between extreme values. <bold>Bottom right</bold>: No model.</p></caption>
<graphic xlink:href="603979v1_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig3" position="float" fig-type="figure">
<label>Fig. 3.</label>
<caption><title>Recognition memory circuit.</title><p>Schematic of the recognition memory network adapted from (<xref ref-type="bibr" rid="c31">31</xref>). Bold arrows show the assumed two-way connection between the medial prefrontal cortex and the hippocampus facilitated by the NRe. Colours highlight the HPC (red), MPC (blue) and specific areas of the rhinal cortex (yellow). The NRe was lesioned in the experiment.</p></caption>
<graphic xlink:href="603979v1_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>The horseshoe prior is a hierarchical prior for sparsity. It introduces an auxiliary parameter <italic>κ</italic><sub><italic>i</italic></sub> that multiplies the population scale <italic>τ</italic>. This construction allows surprising observations far from the bulk of the population density to escape regularisation.
<disp-formula id="eqn5">
<graphic xlink:href="603979v1_eqn5.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn6">
<graphic xlink:href="603979v1_eqn6.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>An example of this is given in <xref rid="fig2" ref-type="fig">Figure 2</xref> as the bottom left cell of the 2 × 2 table of models. The horseshoe prior often uses a Cauchy distribution but in our case the heavy tail causes problems for the sampling algorithm, see SI section 8.</p>
</sec>
<sec id="s1f">
<title>Zero inflation</title>
<p>A particular trait of the second dataset is that there are a large number of zero data points (∼6%). Although a zero observation is always possible for a Poisson distribution, for plausible values of the propensity, zeros should be rare. It is likely that for some regions the experiment has not worked as expected and the zeros show that something has ‘gone wrong’ and that the readings are not well described by a Poisson distribution. Here we extend the model to include this possibility. This is a useful elaboration of the ‘standard model’, in the standard model the horseshoe prior ensures that these anomalous readings only have a small effect on the result but it is more informative to extend the model to include them. While this particular extension is specific to these data, it also serves as an example of how a standard Bayesian model can serve as a starting for point for an investigation of the data.</p>
<p>The zero-inflated Poisson model is intended to model a situation were there are zeros unrelated to the Poisson distribution, in this case this might, for example, be the result of an error in the automated registration process that identifies regions and counts their cells. It is a mixture model, if
<disp-formula id="eqn7">
<graphic xlink:href="603979v1_eqn7.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
there is a probability <italic>π</italic> that <italic>y</italic><sub><italic>i</italic></sub> = 0 and a 1−<italic>π</italic> probability that <italic>y</italic><sub><italic>i</italic></sub> follows a Poisson distribution with rate <italic>λ</italic><sub><italic>i</italic></sub>. Importantly this means there are two ways in which <italic>y</italic><sub><italic>i</italic></sub> can be zero, through the Bernoulli process parameterized by <italic>π</italic>, or through the Poisson distribution. This has the effect of ‘inflating’ the probability mass at zero with the additional parameter <italic>π</italic> giving the proportion of extra zeros in the data that could not be explained by the standard Poisson distribution. This distribution can be visualized in <xref rid="fig2" ref-type="fig">Figure 2</xref> and further mathematical details are described in SI 2C.</p>
</sec>
<sec id="s1g">
<title>Model inference</title>
<p>Posterior inference was performed with the probabilistic programming language Stan (<xref ref-type="bibr" rid="c39">39</xref>), using its custom implementation of the No-U-Turn (NUTS) sampler (<xref ref-type="bibr" rid="c40">40</xref>, <xref ref-type="bibr" rid="c41">41</xref>). For each model, the posterior was sampled using four chains for 8000 iterations, with half of these being attributed to the warm-up phase; giving a total of 16000 samples from the posterior distribution.</p>
</sec>
</sec>
<sec id="s2">
<title>Results</title>
<p>We describe differences in estimated counts between groups in terms of log<sub>2</sub>-fold changes. Fold changes are useful because they prevent differences that are small in absolute magnitude from being masked by regions with high overall expression. Our results compare Bayesian highest density intervals (HDI) with the confidence interval (CI) from an uncorrected Welch’s <italic>t</italic>-test. The Bayesian HDI is calculated from the posterior distribution and is the smallest width interval that includes a chosen probability, here 0.95 (to correspond to <italic>α</italic> = 0.05), and summarizes the meaningful uncertainty over a parameter of interest.</p>
<sec id="s2a">
<title>Case study one – transient neural activity in the recognition memory circuit</title>
<p>Results for the first dataset are presented in <xref rid="fig4" ref-type="fig">Figure 4</xref> with <xref rid="fig4" ref-type="fig">Figure 4<bold>A</bold></xref> plotting cell-count differences between the novel and familiar conditions without lesion and <xref rid="fig4" ref-type="fig">Figure 4<bold>B</bold></xref> with lesion. These data were collected to investigate the role of different hippocampal and adjacent cortical regions in memory. However, some regions of interest, such as the intermediate dendate gyrus (IDG), and the dorsal subiculum (DSUB) look under-powered: in the sham animals, for both regions there is a markedly non-zero difference in expression between the novel and familiar conditions but a wide confidence interval overlapping zero makes the evidence unreliable (orange bars <xref rid="fig4" ref-type="fig">Figure 4<bold>A</bold></xref>).</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Fig. 4.</label>
<caption><title>Results—Case study 1.</title><p>log<sub>2</sub>-fold differences for each surgery type. The 95% Bayesian HDI is given in green, and the 95% confidence interval calculated from a Welch’s <italic>t</italic>-test in orange. Horizontal lines within the intervals mark the posterior mean of the Bayesian results, and the raw data means in the <italic>t</italic>-test case. The <italic>x</italic>-axis is ordered in terms of decreasing <italic>p</italic>-value from the significance test and ticks have been color-paired with the nodes in the recognition memory circuit diagram <xref rid="fig3" ref-type="fig">Figure 3</xref>. Black ticks are not present in the circuit because they are the control regions in the experiment. <bold>A</bold>: log<sub>2</sub>-fold differences between sham-familiar (SF) and sham-novel (SN) groups. <bold>B</bold>: log<sub>2</sub>-fold differences between lesion-familiar (LF) and lesion-novel (LN) groups.</p></caption>
<graphic xlink:href="603979v1_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>In contrast, the Bayesian estimates (green bars <xref rid="fig4" ref-type="fig">Figure 4</xref>) produce a clear result. For a number of brain regions in <xref rid="fig4" ref-type="fig">Figure 4<bold>A</bold></xref>, sham-novel animals have higher expression than sham-familiar ones. These differences disappear in <xref rid="fig4" ref-type="fig">Figure 4<bold>B</bold></xref> with lesion-novel and lesion-familiar animals showing roughly equal cell counts. This indicates that the difference is only present when the NRe is intact.</p>
</sec>
<sec id="s2b">
<title>Case study two – Ontogeny of inhibitory interneurons of the mouse thalamus</title>
<p>The estimated log<sub>2</sub>-fold difference in GFP expressing cells between the two genotypes, for each of the fifty brain regions, are plotted in <xref rid="fig5" ref-type="fig">Figure 5</xref>. This include the purple and pink 95% HDI from the horseshoe and zero-inflated Poisson models along with the 95% confidence interval arising from a <italic>t</italic>-test in orange.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Fig. 5.</label>
<caption><title>Results—Case study 2.</title><p>log<sub>2</sub> fold differences in GFP positive cells between mouse genotypes, heterozygous (HET) and knockout (KO), for each of the fifty recorded brain regions spread across two rows. The 95% Bayesian HDI is given in purple and pink for the Bayesian horseshoe and zero-inflated model. The 95% confidence interval calculated from a Welch’s <italic>t</italic>-test in orange. Horizontal lines within the intervals mark the posterior mean of the Bayesian results and the data estimate for the <italic>t</italic>-test. The <italic>x</italic>-axis is ordered in terms of decreasing <italic>p</italic>-value from the significance test.</p></caption>
<graphic xlink:href="603979v1_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig6" position="float" fig-type="figure">
<label>Fig. 6.</label>
<caption><title>Zero count observations.</title><p>On the left under data: boxplots with medians and interquartile ranges for the raw data for two example brain regions. The shape of each point pairs left and right hemisphere readings in each of the five animals. For both example regions there is a heterozygous animal with zero readings in both hemispheres. On the right under inference: HDIs and confidence intervals are plotted. The Bayesian estimates are not strongly influenced by the zero-valued observations and have means close to the data median. This explains the advantage of the Bayesian results over the confidence interval.</p></caption>
<graphic xlink:href="603979v1_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig7" position="float" fig-type="figure">
<label>Fig. 7.</label>
<caption><title>Diagnostics – Poisson.</title><p>Standard Poisson model, case study – 1.</p></caption>
<graphic xlink:href="603979v1_fig7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig8" position="float" fig-type="figure">
<label>Fig. 8.</label>
<caption><title>Diagnostics – Horseshoe.</title><p>Horseshoe model, case study – 2.</p></caption>
<graphic xlink:href="603979v1_fig8.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig9" position="float" fig-type="figure">
<label>Fig. 9.</label>
<caption><title>Diagnostics – ZIPoisson.</title><p>Zero-inflated Poisson, case study – 2.</p></caption>
<graphic xlink:href="603979v1_fig9.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig10" position="float" fig-type="figure">
<label>Fig. 10.</label>
<caption><title>PPC – Poisson.</title><p>Posterior predictive check for the standard Poisson model in case study – 1. <bold>A</bold>: The proportion of zeroes in the data matches the proportion of zeroes in posterior predictive samples. This proportion is zero. <bold>B</bold>: The distribution of standard deviations computed over a number of posterior predictive datasets (histogram), aligns with the standard deviation of the data.</p></caption>
<graphic xlink:href="603979v1_fig10.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig11" position="float" fig-type="figure">
<label>Fig. 11.</label>
<caption><title>PPC – Horseshoe.</title><p>Horseshoe model, case study – 2. Posterior predictive check for the standard horseshoe model in case study – 2. <bold>A</bold>: The proportion of zeroes in the data is larger than those found in posterior predictive datasets. This makes sense, because the likelihood is still a Poisson distribution. <bold>B</bold>: The distribution of standard deviations computed over a number of posterior predictive datasets (histogram), aligns with the standard deviation of the data.</p></caption>
<graphic xlink:href="603979v1_fig11.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig12" position="float" fig-type="figure">
<label>Fig. 12.</label>
<caption><title>PPC – ZIPoisson.</title><p>Zero-inflated Poisson, case study – 2. <bold>A</bold>: The proportion of zeroes in the data matches the proportion of zeroes in posterior predictive samples. <bold>B</bold>: The distribution of standard deviations computed over a number of posterior predictive datasets (histogram), aligns with the standard deviation of the data.</p></caption>
<graphic xlink:href="603979v1_fig12.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>The use of the zero-inflated Poisson distribution uncovers some interesting differences when compared to the <italic>t</italic>-test confidence intervals. One example of this is the result for tuberomammillary nucleus, dorsal part (TMd). For this region the HET animals have high GFP expression across both hemispheres, yet animal three has a reading of zero for both hemispheres. This injects variability into the standard deviation of the HET group. Consequently, the pooled standard deviation used in the <italic>t</italic>-test is large and almost certainly guarantees a non-significant result. Furthermore, the sample mean of this region looks nothing like zero, but also nothing like the other two animals with positive counts. In addition to the wide interval, the sign of the difference does not agree with the data. Similarly, the medial preoptic nucleus (MPN) also suffers from poor estimation. Once again, this region contains a single HET animal for which the reading from both hemispheres is zero. The zero-inflated Poisson produces a posterior distribution of the appropriate sign with small uncertainty.</p>
<p>Despite the large difference in interval estimation between the HDI and CI for many brain regions, as the data becomes stronger from the perspective of the frequentist <italic>p</italic>-value towards the right-hand side of the second row in <xref rid="fig5" ref-type="fig">Figure 5</xref>, they become much more compatible. The variation within groups is very small for these regions; further regularization is not necessary and so the impact of partial pooling has been reduced. The sample estimate of the <italic>t</italic>-test has ‘caught up’ to the regularized estimate because the signal is strong.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>We have presented a standard workflow for Bayesian analysis of multi-region cell-count data. We propose a likelihood and appropriate priors with a nested hierarchical structure reflecting the structure of the experiment. We applied this to two distinct example datasets and demonstrate that they capture more fruitfully the characteristics of the data when compared to field-standard frequentist analyses.</p>
<p>For both case studies, the Bayesian uncertainty intervals are more precise than the confidence intervals. These confidence intervals tend to be quite wide on these data because of the small sample size and because of violations to their parametric model assumptions. Our workflow uses a horseshoe prior, along with the partial pooling, this allows our model to deal effectively with outliers. Furthermore, for the data sizes presented here, a full Bayesian inference using Stan does not require long computation time, or even particularly high performance hardware. Modern multi-core laptop processors are quite sufficient for this task. Fitting a model typically takes less than an hour.</p>
<p>The workflow we have exhibited here is intended as a standard approach. We believe that, without extension, it will provide a robust model for cell-count data. However, we also suggest that the standard workflow can be a useful first step for a more comprehensive, extended, model when one is required. We have given an example of this for the second dataset where the anomalous zeros prompted us to change the likelihood to a zero-inflated Poisson. There are other possibilities, for example, zero inflation is not the only way to handle an anomaly in the number of zeros: the hurdle model is an alternative, (<xref ref-type="bibr" rid="c42">42</xref>). This is not a mixture model, instead it restricts the probability of zeros to some value <italic>π</italic> with the probabilities for the positive counts coming from a truncated Poisson distribution. The hurdle mode can deflate as well as inflate the probability mass at zero. This did not match the situation in the data we considered but might for other datasets. Another extension might involve tighter priors based on previous experiments. This is likely to be very relevant for cell-count data since these experiments are rarely performed in isolation and so prior information can be leveraged from a history of empirical results.</p>
<p>One obvious elaboration of our model would replace normal distributions with multivariate normal distributions. This would have two advantages. Firstly, correlations are difficult to estimate for under-sampled data. Including correlation matrix priors provides extra information, for example, based on anatomical connectivity, that can aid the statistical estimation of other parameters. Secondly, it would more closely match our understanding of the experiment: we know that activity is likely to be correlated across regions and so it is apposite to include that directly in the model. Unfortunately the problem of finding a suitable prior for the correlation proved insurmountable: the standard Lewandowski-Kurowicka-Joe distribution (<xref ref-type="bibr" rid="c43">43</xref>) which has been useful in lower-dimensional situations is too regularising here. This is an area where further work needs to be done.</p>
<p>It is important to highlight that a mixed effects model is not a uniquely Bayesian construction. Indeed, any model that tries to include more sophistication through hierarchical structures, Bayesian or otherwise is useful. However, non-Bayesian models can be complicated and opaque, they are also often more restrictive, for example they often assume normal distributions, and circumventing these restrictions can make the models even less transparent. A Bayesian approach is, at first, unfamiliar; this can make it seem more obscure than better established methods, but, in the long run, Bayesian models are typically clearer and do not involve so many different assumptions and so many fine adjustments.</p>
</sec>
</body>
<back>
<sec id="s4" sec-type="data-availability">
<title>Code and data availability</title>
<p>The code necessary to run the models presented in this manuscript can be found at our Github respository: <ext-link ext-link-type="uri" xlink:href="https://github.com/SydneyJake/Hierarchical">https://github.com/SydneyJake/Hierarchical</ext-link> Bayesian Cell Counts. The data for case study one on nucleus reunion lesion are available from <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.12787211">https://doi.org/10.5281/zenodo.12787211</ext-link> (<xref ref-type="bibr" rid="c44">44</xref>). The data from case study two on <italic>Sox14</italic> expressing neurons are available from <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.12787287">https://doi.org/10.5281/zenodo.12787287</ext-link> (<xref ref-type="bibr" rid="c45">45</xref>).</p>
</sec>
<ack>
<title>Acknowledgments</title>
<p>We are grateful to Andrew Dowsey and Matthew Nolan for useful discussion and helpful suggestions. We would like to acknowledge funding from the EPSRC (EP/R513179/1 Doctoral Training Partnership PhD studentship to SD and EP/W024020/1 to SS), BBSRC (BB/L02134X/1 to ECW and BB/R007020/1 to AD), Wellcome Trust (206401/Z/17/Z to ECW), Leverhulme Trust (RF-2021-533 to CJH), and MRC (MR/S026630/1 to COD)</p>
</ack>
<ref-list>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>T</given-names> <surname>Kawashima</surname></string-name>, <string-name><given-names>H</given-names> <surname>Okuno</surname></string-name>, <string-name><given-names>H</given-names> <surname>Bito</surname></string-name></person-group>, <article-title>A new era for functional labeling of neurons: activity-dependent promoters have come of age</article-title>. <source>Front. Neural Circuits</source> <volume>8</volume>, <fpage>37</fpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>ES</given-names> <surname>Lein</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Genome-wide atlas of gene expression in the adult mouse brain</article-title>. <source>Nature</source> <volume>445</volume>, <fpage>168</fpage>–<lpage>176</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>SW</given-names> <surname>Oh</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>A mesoscale connectome of the mouse brain</article-title>. <source>Nature</source> <volume>508</volume>, <fpage>207</fpage>–<lpage>214</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>TL</given-names> <surname>Daigle</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>A suite of transgenic driver and reporter mouse lines with enhanced brain-cell-type targeting and functionality</article-title>. <source>Cell</source> <volume>174</volume>, <fpage>465</fpage>–<lpage>480</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>JA</given-names> <surname>Harris</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Hierarchical organization of cortical and thalamic connectivity</article-title>. <source>Nature</source> <volume>575</volume>, <fpage>195</fpage>–<lpage>202</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>WB</given-names> <surname>Kim</surname></string-name>, <string-name><given-names>JH</given-names> <surname>Cho</surname></string-name></person-group>, <article-title>Encoding of discriminative fear memory by input-specific ltp in the amygdala</article-title>. <source>Neuron</source> <volume>95</volume>, <fpage>1129</fpage>–<lpage>1146</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J</given-names> <surname>Haubrich</surname></string-name>, <string-name><given-names>K</given-names> <surname>Nader</surname></string-name></person-group>, <article-title>Network-level changes in the brain underlie fear memory strength</article-title>. <source>eLife</source> <volume>12</volume>, <elocation-id>RP88172</elocation-id> (<year>2023</year>).</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>KE</given-names> <surname>Dorst</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Hippocampal engrams generate variable behavioral responses and brain-wide network states</article-title>. <source>J. Neurosci</source>. <volume>44</volume> (<year>2024</year>).</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>T</given-names> <surname>Liebmann</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Three-dimensional study of alzheimer’s disease hallmarks using the idisco clearing method</article-title>. <source>Cell Reports</source> <volume>16</volume>, <fpage>1138</fpage>–<lpage>1152</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Y</given-names> <surname>Kim</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Mapping social behavior-induced brain activation at cellular resolution in the mouse</article-title>. <source>Cell Reports</source> <volume>10</volume>, <fpage>292</fpage>–<lpage>305</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>V</given-names> <surname>Bonapersona</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>The mouse brain after foot shock in four dimensions: Temporal dynamics at a single-cell resolution</article-title>. <source>Proc. Natl. Acad. Sci</source>. <volume>119</volume>, <fpage>e2114002119</fpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>A</given-names> <surname>Gelman</surname></string-name>, <etal>et al.</etal></person-group>, <source>Bayesian data analysis</source>. (<publisher-name>CRC press</publisher-name>), (<year>2013</year>).</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>R</given-names> <surname>McElreath</surname></string-name></person-group>, <source>Statistical rethinking: A Bayesian course with examples in R and Stan</source>. (<publisher-name>Chapman and Hall/CRC</publisher-name>), (<year>2018</year>).</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>R</given-names> <surname>van de Schoot</surname></string-name>, <etal>et al.</etal></person-group> <article-title>Bayesian statistics and modelling</article-title> <source>Nat. Rev. Methods Primers</source> <volume>1</volume>, <fpage>1</fpage>–<lpage>26</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>S</given-names> <surname>Dimmock</surname></string-name>, <string-name><given-names>C</given-names> <surname>O’Donnell</surname></string-name>, <string-name><given-names>CJ</given-names> <surname>Houghton</surname></string-name></person-group>, <article-title>Bayesian analysis of phase data in EEG and MEG</article-title>. <source>eLife</source> <volume>12</volume>, <elocation-id>e84602</elocation-id> (<year>2023</year>).</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>EN</given-names> <surname>Brown</surname></string-name>, <string-name><given-names>LM</given-names> <surname>Frank</surname></string-name>, <string-name><given-names>D</given-names> <surname>Tang</surname></string-name>, <string-name><given-names>MC</given-names> <surname>Quirk</surname></string-name>, <string-name><given-names>MA</given-names> <surname>Wilson</surname></string-name></person-group>, <article-title>A statistical paradigm for neural spike train decoding applied to position prediction from ensemble firing patterns of rat hippocampal place cells</article-title>. <source>J. Neurosci</source>. <volume>18</volume>, <fpage>7411</fpage>–<lpage>7425</lpage> (<year>1998</year>).</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>K</given-names> <surname>Zhang</surname></string-name>, <string-name><given-names>I</given-names> <surname>Ginzburg</surname></string-name>, <string-name><given-names>BL</given-names> <surname>McNaughton</surname></string-name>, <string-name><given-names>TJ</given-names> <surname>Sejnowski</surname></string-name></person-group>, <article-title>Interpreting neuronal population activity by reconstruction: unified framework with application to hippocampal place cells</article-title>. <source>J. Neurophysiol</source>. <volume>79</volume>, <fpage>1017</fpage>–<lpage>1044</lpage> (<year>1998</year>).</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>RJ</given-names> <surname>Moran</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Bayesian estimation of synaptic physiology from the spectral responses of neural masses</article-title>. <source>Neuroimage</source> <volume>42</volume>, <fpage>272</fpage>–<lpage>284</lpage> (<year>2008</year>).</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>RP</given-names> <surname>Costa</surname></string-name>, <string-name><given-names>PJ</given-names> <surname>Sj”ostr”om</surname></string-name>, <string-name><given-names>MC Van</given-names> <surname>Rossum</surname></string-name></person-group>, <article-title>Probabilistic inference of short-term synaptic plasticity in neocortical microcircuits</article-title>. <source>Front. Comput. Neurosci</source>. <volume>7</volume>, <fpage>75</fpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>AD</given-names> <surname>Bird</surname></string-name>, <string-name><given-names>MJ</given-names> <surname>Wall</surname></string-name>, <string-name><given-names>MJ</given-names> <surname>Richardson</surname></string-name></person-group>, <article-title>Bayesian inference of synaptic quantal parameters from correlated vesicle release</article-title>. <source>Front. Comput. Neurosci</source>. <volume>10</volume>, <fpage>116</fpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>O</given-names> <surname>Bykowska</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Model-based inference of synaptic transmission</article-title>. <source>Front. Synaptic Neurosci</source>. <volume>11</volume>, <fpage>21</fpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>Y</given-names> <surname>Mishchencko</surname></string-name>, <string-name><given-names>JT</given-names> <surname>Vogelstein</surname></string-name>, <string-name><given-names>L</given-names> <surname>Paninski</surname></string-name></person-group>, <article-title>A Bayesian approach for inferring neuronal connectivity from calcium fluorescent imaging data</article-title>. <source>The Annals Appl. Stat</source>. pp. <fpage>1229</fpage>–<lpage>1261</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>F</given-names> <surname>Cinotti</surname></string-name>, <string-name><given-names>MD</given-names> <surname>Humphries</surname></string-name></person-group>, <article-title>Bayesian mapping of the striatal microcircuit reveals robust asymmetries in the probabilities and distances of connections</article-title>. <source>J. Neurosci</source>. <volume>42</volume>, <fpage>1417</fpage>–<lpage>1435</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>E</given-names> <surname>Aarts</surname></string-name>, <string-name><given-names>M</given-names> <surname>Verhage</surname></string-name>, <string-name><given-names>JV</given-names> <surname>Veenvliet</surname></string-name>, <string-name><given-names>CV</given-names> <surname>Dolan</surname></string-name>, <string-name><given-names>S Van Der</given-names> <surname>Sluis</surname></string-name></person-group>, <article-title>A solution to dependency: using multilevel analysis to accommodate nested data</article-title>. <source>Nat. Neurosci</source>. <volume>17</volume>, <fpage>491</fpage>–<lpage>496</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>GR</given-names> <surname>Barker</surname></string-name>, <string-name><given-names>EC</given-names> <surname>Warburton</surname></string-name></person-group>, <article-title>When is the hippocampus involved in recognition memory</article-title>? <source>J. Neurosci</source>. <volume>31</volume>, <fpage>10721</fpage>–<lpage>10731</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A</given-names> <surname>Ennaceur</surname></string-name>, <string-name><given-names>N</given-names> <surname>Neave</surname></string-name>, <string-name><given-names>JP</given-names> <surname>Aggleton</surname></string-name></person-group>, <article-title>Neurotoxic lesions of the perirhinal cortex do not mimic the behavioural effects of fornix transection in the rat</article-title>. <source>Behav. Brain Res</source>. <volume>80</volume>, <fpage>9</fpage>–<lpage>25</lpage> (<year>1996</year>).</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>G</given-names> <surname>Norman</surname></string-name>, <string-name><given-names>M</given-names> <surname>Eacott</surname></string-name></person-group>, <article-title>Impaired object recognition with increasing levels of feature ambiguity in rats with perirhinal cortex lesions</article-title>. <source>Behav. Brain Res</source>. <volume>148</volume>, <fpage>79</fpage>–<lpage>91</lpage> (<year>2004</year>).</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>JWT</given-names> <surname>Ho</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Contributions of area te2 to rat recognition memory</article-title>. <source>Learn. &amp; Mem</source>. <volume>18</volume>, <fpage>493</fpage>–<lpage>501</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>GR</given-names> <surname>Barker</surname></string-name>, <string-name><given-names>EC</given-names> <surname>Warburton</surname></string-name></person-group>, <article-title>A critical role for the nucleus reuniens in long-term, but not short-term associative recognition memory formation</article-title>. <source>J. Neurosci</source>. <volume>38</volume>, <fpage>3208</fpage>–<lpage>3217</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>WB</given-names> <surname>Hoover</surname></string-name>, <string-name><given-names>RP</given-names> <surname>Vertes</surname></string-name></person-group>, <article-title>Collateral projections from nucleus reuniens of thalamus to hippocampus and medial prefrontal cortex in the rat: a single and double retrograde fluorescent labeling study</article-title>. <source>Brain Struct. Funct</source>. <volume>217</volume>, <fpage>191</fpage>–<lpage>209</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>BMS</given-names> <surname>Exley</surname></string-name></person-group>, “<chapter-title>The role of the nucleus reuniens of the thalamus in the recognition memory network</chapter-title>,” <source>Master’s thesis, School of Physiology, Pharmacology &amp; Neuroscience</source>, <publisher-name>University of Bristol</publisher-name> (<year>2019</year>).</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>P</given-names> <surname>Jager</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Dual midbrain and forebrain origins of thalamic inhibitory interneurons</article-title>. <source>eLife</source> <volume>10</volume>, <elocation-id>e59272</elocation-id> (<year>2021</year>).</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>P</given-names> <surname>Jager</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Tectal-derived interneurons contribute to phasic and tonic inhibition in the visual thalamus</article-title>. <source>Nat. Commun</source>. <volume>7</volume>, <fpage>13579</fpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B</given-names> <surname>Golding</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Retinal input directs the recruitment of inhibitory interneurons into thalamic visual circuits</article-title>. <source>Neuron</source> <volume>81</volume>, <fpage>1057</fpage>–<lpage>1069</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A</given-names> <surname>Delogu</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Subcortical visual shell nuclei targeted by iprgcs develop from a sox14+-gabaergic progenitor and require sox14 to regulate daily activity rhythms</article-title>. <source>Neuron</source> <volume>75</volume>, <fpage>648</fpage>–<lpage>662</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><given-names>A</given-names> <surname>Gelman</surname></string-name>, <string-name><given-names>J</given-names> <surname>Hill</surname></string-name></person-group>, <source>Data analysis using regression and multilevel/hierarchical models</source>. (<publisher-name>Cambridge University Press</publisher-name>), (<year>2006</year>).</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>CM</given-names> <surname>Carvalho</surname></string-name>, <string-name><given-names>NG</given-names> <surname>Polson</surname></string-name>, <string-name><given-names>JG</given-names> <surname>Scott</surname></string-name></person-group>, <article-title>The horseshoe estimator for sparse signals</article-title>. <source>Biometrika</source> <volume>97</volume>, <fpage>465</fpage>–<lpage>480</lpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>J</given-names> <surname>Piironen</surname></string-name>, <string-name><given-names>A</given-names> <surname>Vehtari</surname></string-name></person-group>, <article-title>Sparsity information and regularization in the horseshoe and other shrinkage priors</article-title>. <source>Electron. J. Stat</source>. <volume>11</volume> (<year>2017</year>).</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>B</given-names> <surname>Carpenter</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>Stan: A probabilistic programming language</article-title>. <source>J. Stat. Softw</source>. <volume>76</volume> (<year>2017</year>).</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><given-names>M</given-names> <surname>Betancourt</surname></string-name></person-group>, <article-title>Identifying the optimal integration time in Hamiltonian Monte Carlo</article-title>. <source>arXiv</source>:<pub-id pub-id-type="arxiv">1601.00225</pub-id> (<year>2016</year>).</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>MD</given-names> <surname>Hoffman</surname></string-name>, <string-name><given-names>A</given-names> <surname>Gelman</surname></string-name>, <etal>et al.</etal></person-group>, <article-title>The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo</article-title>. <source>J. Mach. Learn. Res</source>. <volume>15</volume>, <fpage>1593</fpage>–<lpage>1623</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>JG</given-names> <surname>Cragg</surname></string-name></person-group>, <article-title>Some statistical models for limited dependent variables with application to the demand for durable goods</article-title>. <source>Econom. J. Econom. Soc</source>. pp. <fpage>829</fpage>–<lpage>844</lpage> (<year>1971</year>).</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>D</given-names> <surname>Lewandowski</surname></string-name>, <string-name><given-names>D</given-names> <surname>Kurowicka</surname></string-name>, <string-name><given-names>H</given-names> <surname>Joe</surname></string-name></person-group>, <article-title>Generating random correlation matrices based on vines and extended onion method</article-title>. <source>J. Multivar. Analysis</source> <volume>100</volume>, <fpage>1989</fpage>–<lpage>2001</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>B</given-names> <surname>Exley</surname></string-name>, <string-name><given-names>S</given-names> <surname>Dimmock</surname></string-name>, <string-name><given-names>C</given-names> <surname>Warburton</surname></string-name></person-group>, <source>Exley warburton nre lesion cell count data</source> (<year>2024</year>).</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name><given-names>M</given-names> <surname>Gerald</surname></string-name>, <string-name><given-names>D</given-names> <surname>Sydney</surname></string-name>, <string-name><given-names>L</given-names> <surname>Menage</surname></string-name>, <string-name><given-names>A</given-names> <surname>Delogu</surname></string-name>, <string-name><given-names>S</given-names> <surname>Schultz</surname></string-name></person-group>, <source>Moore schultz sox14 expressing neurons</source> (<year>2024</year>).</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A</given-names> <surname>Gelman</surname></string-name>, <string-name><given-names>DB</given-names> <surname>Rubin</surname></string-name></person-group>, <article-title>Inference from iterative simulation using multiple sequences</article-title>. <source>Stat. Sci</source>. pp. <fpage>457</fpage>–<lpage>472</lpage> (<year>1992</year>).</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><given-names>A</given-names> <surname>Vehtari</surname></string-name>, <string-name><given-names>A</given-names> <surname>Gelman</surname></string-name>, <string-name><given-names>D</given-names> <surname>Simpson</surname></string-name>, <string-name><given-names>B</given-names> <surname>Carpenter</surname></string-name>, <string-name><given-names>P.</given-names> <surname>B”urkner</surname></string-name></person-group>, <article-title>Rank-normalization, folding, and localization: an improved r for assessing convergence of mcmc (with discussion)</article-title>. <source>Bayesian Analysis</source> <volume>16</volume>, <fpage>667</fpage>–<lpage>718</lpage> (<year>2021</year>).</mixed-citation></ref>
</ref-list>
<app-group>
<app id="app0">
<title>Appendix</title>
<sec id="s5">
<label>1.</label>
<title>Full model</title>
<p>Here we present the complete mathematical model for each of of the three models applied in the main text. In all cases, the exposure term is only necessary for the first case study. Area was not available for the second so the exposure term was left out.</p>
<sec id="s5a">
<label>A.</label>
<title>Poisson model</title>
<disp-formula id="eqn8">
<graphic xlink:href="603979v1_eqn8.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn9">
<graphic xlink:href="603979v1_eqn9.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn10">
<graphic xlink:href="603979v1_eqn10.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn11">
<graphic xlink:href="603979v1_eqn11.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn12">
<graphic xlink:href="603979v1_eqn12.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</sec>
<sec id="s5b">
<label>B.</label>
<title>Horseshoe model</title>
<disp-formula id="eqn13">
<graphic xlink:href="603979v1_eqn13.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn14">
<graphic xlink:href="603979v1_eqn14.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn15">
<graphic xlink:href="603979v1_eqn15.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn16">
<graphic xlink:href="603979v1_eqn16.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn17">
<graphic xlink:href="603979v1_eqn17.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn18">
<graphic xlink:href="603979v1_eqn18.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</sec>
<sec id="s5c">
<label>C.</label>
<title>Zero-inflated model</title>
<disp-formula id="eqn19">
<graphic xlink:href="603979v1_eqn19.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn20">
<graphic xlink:href="603979v1_eqn20.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn21">
<graphic xlink:href="603979v1_eqn21.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn22">
<graphic xlink:href="603979v1_eqn22.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn23">
<graphic xlink:href="603979v1_eqn23.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn24">
<graphic xlink:href="603979v1_eqn24.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</sec>
</sec>
<sec id="s6">
<label>2.</label>
<title>Distributions</title>
<sec id="s6a">
<label>A.</label>
<title>Zero inflated Poisson distribution</title>
<p>The zero inflated Poisson distribution is a mixture distribution with mixing parameter <italic>π</italic>. The distribution is formally defined below. If,
<disp-formula id="eqn25">
<graphic xlink:href="603979v1_eqn25.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>then
<disp-formula id="eqn26">
<graphic xlink:href="603979v1_eqn26.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>where
<disp-formula id="eqn27">
<graphic xlink:href="603979v1_eqn27.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>Equivalently, the mixture can be specified with an indicator function.
<disp-formula id="eqn28">
<graphic xlink:href="603979v1_eqn28.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
</sec>
<sec id="s6b">
<label>B.</label>
<title>Half Normal distribution</title>
<p>The HalfNormal distribution coincides with a zero-mean normal distribution truncated at zero. It has a single scale parameter <italic>σ</italic>. If,
<disp-formula id="eqn29">
<graphic xlink:href="603979v1_eqn29.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
then
<disp-formula id="eqn30">
<graphic xlink:href="603979v1_eqn30.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
is the probability density function.</p>
</sec>
</sec>
<sec id="s7">
<label>3.</label>
<title>Additional methods</title>
<sec id="s7a">
<label>A.</label>
<title>Fold differences</title>
<p>In our results we present differences between experimental groups in terms of log<sub>2</sub>-fold differences. We calculate this as follows. The parameter of interest <italic>θ</italic><sub><italic>r,g</italic>=<italic>i</italic></sub> is modeled on the natural log scale owing to the log-link function necessary for the Poisson regression. At the average animal the difference,
<disp-formula id="eqn31">
<graphic xlink:href="603979v1_eqn31.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqn32">
<graphic xlink:href="603979v1_eqn32.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
is the natural log of the ratio of the expected counts. To obtain log<sub>2</sub>-fold differences we simply change the base by multiplying log Δ<sub><italic>ij</italic></sub> by log<sub>2</sub>(<italic>e</italic>).</p>
</sec>
<sec id="s7b">
<label>B.</label>
<title>Data transformations</title>
<p>To facilitate a comparison with the Bayesian intervals in terms of log<sub>2</sub>-fold differences, it was necessary to add one to any zero counts before applying the <italic>t</italic>-test.</p>
</sec>
<sec id="s7c">
<label>C.</label>
<title>Non-centered parameterization</title>
<p>Hierarchical models can produce geometry that is difficult for the sampler to explore. Fortunately, there exists a simple reparameterisation known as non-centering that can remedy this problem. In our model, instead of sampling <italic>γ</italic><sub><italic>i</italic></sub> directly, we sample the parameter <inline-formula><inline-graphic xlink:href="603979v1_inline1.gif" mime-subtype="gif" mimetype="image"/></inline-formula> instead, and use it to reconstruct <italic>γ</italic><sub><italic>i</italic></sub>. That is, sample <inline-formula><inline-graphic xlink:href="603979v1_inline2.gif" mime-subtype="gif" mimetype="image"/></inline-formula> from a standard normal distribution,
<disp-formula id="eqn33">
<graphic xlink:href="603979v1_eqn33.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and reconstruct <italic>γ</italic><sub><italic>i</italic></sub> as a deterministic function of sampled values of <inline-formula><inline-graphic xlink:href="603979v1_inline3.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <italic>τ</italic><sub><italic>r</italic>[<italic>i</italic>],<italic>g</italic>[<italic>i</italic>]</sub>.
<disp-formula id="eqn34">
<graphic xlink:href="603979v1_eqn34.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<p>This removes the frustrating joint behaviour between of (<italic>γ</italic><sub><italic>i</italic></sub>, <italic>τ</italic><sub><italic>r</italic>[<italic>i</italic>],<italic>g</italic>[<italic>i</italic>]</sub>), and promotes efficient sampling.</p>
</sec>
<sec id="s7d">
<label>D.</label>
<title>Preprocessing – case study 1</title>
<p>In these data some animals produced more than on reading per brain region. Before fitting our model these were summed together to produce a single count; the exposure term was also properly adjusted to correctly reflect the area of the recording site.</p>
</sec>
</sec>
<sec id="s8">
<label>4.</label>
<title>Software, packages and libraries</title>
<table-wrap id="utbl1" orientation="portrait" position="float">
<graphic xlink:href="603979v1_utbl1.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<list list-type="bullet">
<list-item><p>R version 4.2.1–“Funny-looking-kid”.</p></list-item>
<list-item><p>Computation was performed locally on a Dell XPS 13 7390 laptop (Intel i7-10510U @ 1.80 GHz, 16 GB of RAM; Ubuntu 20.04.4 LTS)</p></list-item>
<list-item><p>Panels composed using <monospace>inkscape</monospace> version 1.2.2.</p></list-item>
</list>
</sec>
<sec id="s9">
<label>5.</label>
<title>Glossary</title>
<p>Here we include a glossary of terms for the brain regions in each case study.</p>
<table-wrap id="utbl2" orientation="portrait" position="float">
<graphic xlink:href="603979v1_utbl2.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<table-wrap id="utbl3" orientation="portrait" position="float">
<graphic xlink:href="603979v1_utbl3.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
</sec>
<sec id="s10">
<label>6.</label>
<title>Sampler diagnostics</title>
<p>The basic Poisson model (<xref ref-type="disp-formula" rid="eqn1">Equation 1</xref>) was sampled excellently. Measures of sampling performance such as <inline-formula><inline-graphic xlink:href="603979v1_inline4.gif" mime-subtype="gif" mimetype="image"/></inline-formula> (<xref ref-type="bibr" rid="c46">46</xref>, <xref ref-type="bibr" rid="c47">47</xref>), and effective sample size, were all satisfactory (SI figure 1). Similarly, for the zero-inflated model (<xref ref-type="disp-formula" rid="eqn7">Equation 7</xref>), no problems were observed for any of the diagnostics (SI figure 2). Contrasting with this, the horseshoe model (<xref ref-type="disp-formula" rid="eqn6">Equation 6</xref>), exhibited some signs of fitting problems (SI figure 3). Divergences were not observed, and given the longer chain length this is reassuring evidence against biased computation. However for many parameters the effective sample size is much lower than we would like to see. This is reflected in the trace plots: the sampler is not making large jumps across the parameter space implying high auto-correlation and low effective sample size. Unfortunately, the horseshoe is notoriously hard to fit and we resort to brute-force methods such as increasing the number of iteration and reducing the step size of the sampler to improve the inference. In the following three plots diagnostics have been summarised with the following three items:</p>
<list list-type="bullet">
<list-item><p><bold>A</bold>: The performance of the sampler is illustrated by plotting <inline-formula><inline-graphic xlink:href="603979v1_inline5.gif" mime-subtype="gif" mimetype="image"/></inline-formula> (R-hat, <inline-formula><inline-graphic xlink:href="603979v1_inline6.gif" mime-subtype="gif" mimetype="image"/></inline-formula> ideal) against the ratio of the effective number of samples (larger is better) for each parameter in the model. Points represent individual parameters in the model, and have further been colour coded by their type. For example, all <italic>θ</italic><sub><italic>r,g</italic></sub> are coloured in green. Points have also been scaled based on how numerous the parameters are so the more numerous parameters have smaller dots, the less numerous, larger.</p></list-item>
<list-item><p><bold>B</bold>: A histogram comparing the marginal energy distribution <italic>π</italic><sub><italic>E</italic></sub>, and the transitional energy distribution <italic>π</italic><sub>Δ<italic>E</italic></sub> of the Hamiltonian. Ideally, these distributions should match each other closely if the posterior distribution has been properly explored by the sampler.</p></list-item>
<list-item><p><bold>C</bold>: For each parameter type the parameter with the ‘poorest’ mixing (largest <inline-formula><inline-graphic xlink:href="603979v1_inline7.gif" mime-subtype="gif" mimetype="image"/></inline-formula>) are presented with a post-warmup trace plot that overlays the ordered sequence of samples from each of the four chains. Corresponding points in <bold>A</bold> are marked with a black border and zero transparency.</p></list-item>
</list>
</sec>
<sec id="s11">
<label>7.</label>
<title>Posterior predictive checking</title>
<p>Posterior predictive checks use the posterior predictive distribution,
<disp-formula id="eqn35">
<graphic xlink:href="603979v1_eqn35.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>p</italic>(<italic>θ</italic>|<italic>y</italic>) is the posterior distribution, and <italic>p</italic>(<italic>y</italic><sup>rep</sup> |<italic>θ</italic>) is the data distribution for <italic>y</italic><sup>rep</sup> that follows the same form as the likelihood for <italic>y</italic>. If we can verify that the posterior predictive distribution can generate replicate datasets with similar statistics to the observed data, then we might conclude that our model is consistent with the observed data and useful for answering questions about it. In practice a Monte-carlo approach is used to approximate statistics of the posterior predictive distribution. For example, if <italic>T</italic> is the test statistic of interest such as the sample mean, then</p>
<list list-type="order">
<list-item><p>For 1, …, <italic>S</italic>.</p>
<list list-type="alpha-lower">
<list-item><p>sample <italic>θ</italic><sub><italic>s</italic></sub> ∼ <italic>p</italic>(<italic>θ</italic>|<italic>y</italic>)</p></list-item>
<list-item><p>sample <inline-formula><inline-graphic xlink:href="603979v1_inline8.gif" mime-subtype="gif" mimetype="image"/></inline-formula></p></list-item>
<list-item><p>calculate <inline-formula><inline-graphic xlink:href="603979v1_inline9.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, where <italic>T</italic> is the statistic of interest</p></list-item>
</list>
</list-item>
<list-item><p>return <inline-formula><inline-graphic xlink:href="603979v1_inline10.gif" mime-subtype="gif" mimetype="image"/></inline-formula></p>
</list-item>
</list>
<p>The posterior predictive checks that follow examine two important statistics of count data. 1) The standard deviation of the data (dispersion), as figure <bold>a</bold>. 2) The proportion of zeroes in the data (zero-inflation), as figure <bold>B</bold>. The value of the test statistic applied to the observed data <italic>T</italic> (<italic>y</italic>) is plotted as a solid purple line, and the distribution of test statistics <inline-formula><inline-graphic xlink:href="603979v1_inline11.gif" mime-subtype="gif" mimetype="image"/></inline-formula> as a purple histogram.</p>
</sec>
<sec id="s12">
<label>8.</label>
<title>Horseshoe densities</title>
<p>In our model a horseshoe prior was used to allow some <italic>γ</italic><sub><italic>i</italic></sub>, typically those informed by <italic>y</italic><sub><italic>i</italic></sub> = 0, to escape regularisation by partial pooling. However, we encountered many problems with the default parameterisation that assigns a HalfCauchy density to the individual inflation parameters <italic>κ</italic><sub><italic>i</italic></sub>. In <xref rid="fig13" ref-type="fig">Figure 13<bold>A</bold></xref>, the proportional conditional posterior density
<disp-formula id="eqn36">
<graphic xlink:href="603979v1_eqn36.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>θ</italic> and <italic>τ</italic> have been fixed, is plotted when <italic>y</italic><sub><italic>i</italic></sub> lies close to the population mean (left), or when it equals zero (right). Note that the <italic>x</italic>-axis is <inline-formula><inline-graphic xlink:href="603979v1_inline12.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and not <italic>γ</italic><sub><italic>i</italic></sub> because the model samples a non-centered parameterisation. That is,
<disp-formula id="eqn37">
<graphic xlink:href="603979v1_eqn37.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
captures the deviations of <italic>γ</italic><sub><italic>i</italic></sub> around the population mean <italic>θ</italic>.</p>
<fig id="fig13" position="float" fig-type="figure">
<label>Fig. 13.</label>
<caption><title>Horseshoe densities.</title><p><bold>A</bold>: Conditional posterior. <bold>B</bold>: MCMC pair plots. Divergent samples are coloured in pink, non-divergent in blue.</p></caption>
<graphic xlink:href="603979v1_fig13.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig14" position="float" fig-type="figure">
<label>Fig. 14.</label>
<caption><title>Modified horseshoe densities.</title><p><bold>A</bold>: The conditional posterior <inline-formula><inline-graphic xlink:href="603979v1_inline15.gif" mime-subtype="gif" mimetype="image"/></inline-formula> when <italic>y</italic> = 0 (left) and <italic>y</italic> ≠ 0 (right). <bold>B</bold>: MCMC pair plots of samples from the marginal posterior density <inline-formula><inline-graphic xlink:href="603979v1_inline16.gif" mime-subtype="gif" mimetype="image"/></inline-formula>.</p></caption>
<graphic xlink:href="603979v1_fig14.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p><xref rid="fig13" ref-type="fig">Figure 13</xref><bold>B</bold> plots samples from the marginal posterior <inline-formula><inline-graphic xlink:href="603979v1_inline13.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, when fitting to the data <bold>y</bold> = {770, 820, 713, 541, 0, 0}. Each data point corresponds to one of the six plots in <xref rid="fig13" ref-type="fig">Figure 13<bold>B</bold></xref>. This small example dataset is in fact the cell-counts for region TMd recorded from the heterozygote group in case study 2. The similarities in geometry can be readily seen with <xref rid="fig13" ref-type="fig">Figure 13<bold>A</bold></xref>. A large number of divergences were produced by the sampler as demonstrated by the number of pink points compared to the non-divergent transitions in blue. For fixed <italic>τ</italic> the values <inline-formula><inline-graphic xlink:href="603979v1_inline14.gif" mime-subtype="gif" mimetype="image"/></inline-formula> can take increase or decrease with smaller or larger <italic>κ</italic> respectively. The HalfCauchy places an extremely long right tail over <italic>κ</italic> that frustrates this relationship resulting in a posterior density that is difficult to sample from.</p>
<sec id="s12a">
<title>Modified horseshoe</title>
<p>For a Poisson model with parameters modeled on the log scale we consider the Cauchy parameterisation to be too extreme. In light of this we opted for a pragmatic approach, a modification to the original horseshoe by replacing the HalfCauchy distribution with a HalfNormal distribution. The modified horseshoe cuts off the top of the funnels by restricting <italic>κ</italic> to produce pleasant posterior geometry <xref rid="fig13" ref-type="fig">Figure 13<bold>A, B</bold></xref>. The modified horseshoe is much easier to sample from, but with the cost of a much more constraining prior over <italic>γ</italic><sub><italic>i</italic></sub>.</p>
</sec>
</sec>
</app>
</app-group>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.102391.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Berman</surname>
<given-names>Gordon J</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Emory University</institution>
</institution-wrap>
<city>Atlanta</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study proposes an <bold>important</bold> new approach to analyzing cell-count data that are often undersampled and cannot be correctly assessed with traditional statistical analyses. The presented case studies provide <bold>convincing</bold> evidence of the superiority of the proposed methodology to existing approaches, which could promote the use of Bayesian statistics among neuroscientists. However, the generalizability of the methodology to other data types is not fully evidenced.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.102391.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This work proposes a new approach to analyse cell-count data from multiple brain regions. Collecting such data can be expensive and time-intensive, so, more often than not, the dimensionality of the data is larger than the number of samples. The authors argue that Bayesian methods are much better suited to correctly analyse such data compared to classical (frequentist) statistical methods. They define a hierarchical structure, partial pooling, in which each observation contributes to the population estimate to more accurately explain the variance in the data. They present two case studies in which their method proves more sensitive in identifying regions where there are significant differences between conditions, which otherwise would be hidden.</p>
<p>Strengths:</p>
<p>The model is presented clearly, and the advantages of the hierarchical structure are strongly justified. Two alternative ways are presented to account for the presence of zero counts. The first involves the use of a horseshoe prior, which is the more flexible option, while the second involves a modified Poisson likelihood, which is better suited to datasets with a large number of zero counts, perhaps due to experimental artifacts. The results show a clear advantage of the Bayesian method for both case studies.</p>
<p>The code is freely available, and it does not require a high-performance cluster to execute for smaller datasets. As Bayesian statistical methods become more accessible in various scientific fields, the whole scientific community will benefit from the transition away from p-values. Hierarchical Bayesian models are an especially useful tool that can be applied to many different experimental designs. However, while conceptually intuitive, their implementation can be difficult. The authors provide a good framework with room for improvement.</p>
<p>Weaknesses:</p>
<p>Alternative possibilities are discussed regarding the prior and likelihood of the model. Given that the second case study inspired the introduction of the zero-inflation likelihood, it is not clear how applicable the general methodology is to various datasets. If every unique dataset requires a tailored prior or likelihood to produce the best results, the methodology will not easily replace more traditional statistical analyses that can be applied in a straightforward manner. Furthermore, the differences between the results produced by the two Bayesian models in case study 2 are not discussed. In specific regions, the models provide conflicting results (e.g., regions MH, VPMpc, RCH, SCH, etc.), which are not addressed by the authors. A third case study would have provided further evidence for the generalizability of the methodology.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.102391.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This is a well-written methodology paper applying a Bayesian framework to the statistics of cell counts in brain slices. A sharpening of the bounds on measured quantities is demonstrated over existing frequentist methods and therefore the work is a contribution to the field.</p>
<p>Strengths:</p>
<p>As well as a mathematical description of the approach, the code used is provided in a linked repository.</p>
<p>Weaknesses:</p>
<p>A clearer link between the experimental data and model-structure terminology would be a benefit to the non-expert reader.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.102391.1.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Dimmock</surname>
<given-names>Sydney</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Exley</surname>
<given-names>Benjamin MS</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Moore</surname>
<given-names>Gerald</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1613-8971</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Menage</surname>
<given-names>Lucy</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Delogu</surname>
<given-names>Alessio</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-4414-4714</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Schultz</surname>
<given-names>Simon R</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6794-5813</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Warburton</surname>
<given-names>E Clea</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-2129-2060</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Houghton</surname>
<given-names>Conor</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-5017-9473</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>O’Donnell</surname>
<given-names>Cian</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-2031-9177</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>We thank both reviewers for their considerate reviews. In this provisional response we would like to make a few key points.</p>
<p>Given that we introduced a bespoke likelihood model for the second dataset, Reviewer 1 asks whether &quot;every unique dataset requires a tailored prior or likelihood to produce the best results&quot;. Our intention is to advocate for the horseshoe prior model as a 'standard' first analysis for any cell count dataset. If extra knowledge about the data is available, or if any data artefacts are detected, more elaborate likelihoods could be introduced as needed in a follow-up analysis. Our introduction of the zero-inflated Poisson likelihood for the second dataset was one such example, but many alternatives could exist. This iterative approach to model building, sometimes referred to as a `Bayesian workflow' is seen as good practise in Bayesian data analysis literature. In the revised version of the paper, we will try to explain the recommendations and modelling philosophy behind this method while emphasising that tailoring or bespoke modelling is not required for our `standard analysis', what we would regard as the Bayesian replacement for a t-test on counts.</p>
<p>Reviewer 1 notes that &quot;the differences between the results produced by the two Bayesian models in case study 2 are not discussed&quot;. We agree that this discrepancy, arising from the specific assumptions of each model is an interesting issue which we should better explore in the paper. In Figure 6 we plotted the actual data values alongside posterior and confidence intervals to explain how the results from the ZIP likelihood and Horseshoe prior compare with those from a t-test. However, our example regions did not highlight cases where differences could be noted between the the two Bayesian models. In the revised version of the paper, we will extend Figure 6 to include further brain regions, such as those mentioned by the referee, and will use that as an opportunity to discuss the broader issue of what to do when the Bayesian models give conflicting results.</p>
<p>We agree with reviewer 2's point that the model description terminology could be made clearer for the target eLife audience. We tried to strike a balance between introducing the reader to the conventional technical terminology used in the Bayesian data analysis necessary for understanding the model while avoiding exhaustive statistical terminology. We erred too much on the side of the latter instead of providing clear links between the model construction and experimental data. In the revised version of the paper, we will augment any technical terms with more biological language and provide a Glossary for reader reference.</p>
</body>
</sub-article>
</article>