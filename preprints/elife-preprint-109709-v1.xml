<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">109709</article-id>
<article-id pub-id-type="doi">10.7554/eLife.109709</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.109709.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Computational and Systems Biology</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Benchmarking of signaling networks generated by large language models</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Tewari</surname>
<given-names>Jeevan</given-names>
</name>
<xref ref-type="author-notes" rid="n1">*</xref>
<xref ref-type="aff" rid="a1">2</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Dahl</surname>
<given-names>Benjamin W</given-names>
</name>
<xref ref-type="author-notes" rid="n1">*</xref>
<xref ref-type="aff" rid="a1">2</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0001-9464-8374</contrib-id>
<name>
<surname>Saucerman</surname>
<given-names>Jeffrey J</given-names>
</name>
<xref ref-type="aff" rid="a1">2</xref>
<email>jsaucerman@virginia.edu</email>
</contrib>
<aff id="a1"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0153tk833</institution-id><institution>Department of Biomedical Engineering, University of Virginia</institution></institution-wrap>, <city>Charlottesville</city>, <country country="US">United States</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Graña</surname>
<given-names>Martin</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Institut Pasteur de Montevideo</institution>
</institution-wrap>
<city>Montevideo</city>
<country country="UY">Uruguay</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Walczak</surname>
<given-names>Aleksandra M</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>CNRS</institution>
</institution-wrap>
<city>Paris</city>
<country country="FR">France</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="equal"><label>*</label><p>co-equal contributors</p></fn>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2026-01-22">
<day>22</day>
<month>01</month>
<year>2026</year>
</pub-date>
<volume>15</volume>
<elocation-id>RP109709</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-10-24">
<day>24</day>
<month>10</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-07-29">
<day>29</day>
<month>07</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.07.28.667217"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2026, Tewari et al</copyright-statement>
<copyright-year>2026</copyright-year>
<copyright-holder>Tewari et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-109709-v1.pdf"/>
<abstract>
<p>Computational models of signaling networks provide frameworks for predicting how molecular cues guide cell decisions. But they are typically limited by manual curation from incomplete literature. Here, we test whether general-purpose large language models (LLMs) generate accurate models of signaling networks. We find that general purpose LLMs generate 24-58% of the reactions of literature-curated networks for cardiomyocyte hypertrophy, myofibroblast activation, and mechano-signaling, and predicting network responses to perturbations with accuracies of 5-26%. While current general-purpose LLMs generate signaling networks with limited accuracy, this study provides a pipeline and benchmarks to guide future improvements.</p>
</abstract>
<funding-group>
<award-group id="par-1">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/01cwqze88</institution-id>
<institution>National Institutes of Health</institution>
</institution-wrap>
</funding-source>
<award-id>R01HL162925</award-id>
<principal-award-recipient>
<name>
<surname>Saucerman</surname>
<given-names>Jeffrey J</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="par-2">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/01cwqze88</institution-id>
<institution>National Institutes of Health</institution>
</institution-wrap>
</funding-source>
<award-id>R01HL160665</award-id>
<principal-award-recipient>
<name>
<surname>Saucerman</surname>
<given-names>Jeffrey J</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="par-3">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/01cwqze88</institution-id>
<institution>National Institutes of Health</institution>
</institution-wrap>
</funding-source>
<award-id>R01HL172417</award-id>
<principal-award-recipient>
<name>
<surname>Saucerman</surname>
<given-names>Jeffrey J</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="par-4">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/01cwqze88</institution-id>
<institution>National Institutes of Health</institution>
</institution-wrap>
</funding-source>
<award-id>T32GM156694</award-id>
<principal-award-recipient>
<name>
<surname>Tewari</surname>
<given-names>Jeevan</given-names>
</name>
</principal-award-recipient>
</award-group>
</funding-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>

</front>
<body>
<sec id="s1">
<title>Main</title>
<p>The response of cells to external stimuli is a fundamental characteristic of life, mediated by complex molecular networks of signal transduction and gene regulation. Computational models of signaling networks have been widely used to understand their systems properties and new guide experiments<sup><xref ref-type="bibr" rid="c1">1</xref>,<xref ref-type="bibr" rid="c2">2</xref></sup>. However, a central hurdle is that computational models of signaling networks typically require substantial manual literature curation of network reactions and rate constants, which is time intensive and requires extensive experimental knowledge<sup><xref ref-type="bibr" rid="c3">3</xref></sup>. Further, existing data is often incomplete.</p>
<p>AI, and large language models (LLMs) in particular, have the potential to outperform human labor-intensive processes of knowledge curation. For example, general purpose LLMs have scored highly on the U.S. Medical Licensing Exam<sup><xref ref-type="bibr" rid="c4">4</xref></sup>, law exams<sup><xref ref-type="bibr" rid="c5">5</xref></sup>, and Advanced Placement exams for many subjects<sup><xref ref-type="bibr" rid="c5">5</xref></sup>. AI has also made substantial contributions in biology, including predicting protein structure<sup><xref ref-type="bibr" rid="c6">6</xref>,<xref ref-type="bibr" rid="c7">7</xref></sup>, cell types<sup><xref ref-type="bibr" rid="c8">8</xref>,<xref ref-type="bibr" rid="c9">9</xref></sup>, and is expected to play a central role in the development of comprehensive virtual cells<sup><xref ref-type="bibr" rid="c10">10</xref>–<xref ref-type="bibr" rid="c12">12</xref></sup>. However, to our knowledge, LLM-generated predictive models of signaling networks have not been reported or benchmarked. Here, we develop a pipeline for LLM-generated models of signaling networks, and we test whether general purpose LLMs generate networks with accurate structure and predictions of perturbation responses, as benchmarked against three manually-curated and validated models<sup><xref ref-type="bibr" rid="c13">13</xref>–<xref ref-type="bibr" rid="c15">15</xref></sup>.</p>
<p>We first established a computational pipeline to generate network models from LLMs using a given gene set (<xref rid="fig1" ref-type="fig">Figure 1A</xref>). For benchmarking purposes, here the gene set is based on annotations of manually curated network models that have been extensively validated. However, future studies could derive gene sets from other sources such as proteomics or transcriptomics. We optimized a programmatic LLM prompt that iteratively queried for directed (activation or inhibition) interactions among the gene products in the context of a particular phenotype (here “hypertrophy”, “fibroblast”, or “mechanosignaling”). With text processing, we extracted the returned directed interactions to examine network structure and then converted the network into the format needed to simulate network responses to perturbations, here with logic- based differential equations in Netflux<sup><xref ref-type="bibr" rid="c16">16</xref></sup>. LLM-based models were generated 10 times per network to examine reproducibility.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Signaling networks generated by general-purpose large language models.</title>
<p>A) Schematic of pipeline for LLM-generated models of signaling networks. B) Network reactions recalled by three large language models (Gemini2.0, orange; ChatGPT4, blue; Claude3.7, green) compared with a “Ground Truth” literature-curated and validated cardiomyocyte hypertrophy signaling network<sup><xref ref-type="bibr" rid="c13">13</xref></sup> (gray reactions). LLM networks were generated using iterative prompts based on the gene set list of the Ground Truth hypertrophy network. Summary of reaction recall accuracy for three literature-curated signaling networks (C, hypertrophy<sup><xref ref-type="bibr" rid="c13">13</xref></sup>; D, fibroblast<sup><xref ref-type="bibr" rid="c14">14</xref></sup>; and E, mechanosignaling<sup><xref ref-type="bibr" rid="c15">15</xref></sup>) by Gemini, GPT, and Claude. * Indicates p &lt; 10<sup>−9</sup> in one-sample T test between LLM-generated replicates (n = 10) and the ground truth network.</p></caption>
<graphic xlink:href="667217v1_fig1-new.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We first tested the extent to which three general purpose LLMs (GPT 4.1, Open AI; Gemini 2.0, Google; and Claude 3.7, Anthropic) could reconstruct the structure of the manually-curated cardiomyocyte hypertrophy signaling network<sup><xref ref-type="bibr" rid="c13">13</xref></sup>, based on its gene annotations alone. Overall, all three LLMs capture aspects of this manually-curated network, but with varying coverage depending on the region of the network and the particular LLM. In particular, GPT 4.1, Gemini 2.0, and Claude 3.7 all performed fairly well at reconstructing upstream aspects of ligand-receptor interactions (e.g. EGF to EGFR) and well- established second messenger cascades like β-adrenergic receptor to cAMP to CREB pathway or phospholipase C to diacylglycerol to PKC. They also accurately predicted the structure of highly conserved signaling axes such as PI3K-Akt-mTor and calcium- calmodulin-calcineurin-NFAT. In contrast, the three LLMs were less able to reconstruct regulation of downstream transcription factors (e.g. cFOS, NFAT, cJUN, MEF2) and gene expression (SERCA, αMHC, βMHC, natriuretic peptides ANP/BNP) or cell area / hypertrophy. The lower reconstruction accuracy of downstream signaling may arise because these contain more cardiomyocyte-specific reactions, but such gaps could also represent a general challenge of LLMs in reconstructing gene regulation from literature. Overall, the three LLMs exhibited 26.70-58.12% reconstruction of network reactions in the cardiomyocyte hypertrophy network. The top-performing LLM was Claude 3.7, which was reproducible with repeated queries.</p>
<p>To what extent is the limited recall of LLM-generated networks specific to cardiomyocyte hypertrophy? To address this question, we used GPT 4.1, Gemini 2.0, and Claude 4.7 to also reconstruct network models of fibroblast activation<sup><xref ref-type="bibr" rid="c14">14</xref></sup> (91 nodes, 134 reactions) (<xref rid="figS1" ref-type="fig">Supplementary Figure 1</xref>) and mechanosignaling<sup><xref ref-type="bibr" rid="c15">15</xref></sup> (94 nodes, 125 reactions) (<xref ref-type="fig" rid="figS1">Supplementary Figure S2</xref>). Like the hypertrophy model, these networks were previously manually reconstructed from the literature, translated into predictive logic-based models, and had their predictions validated against substantial experiments from the literature that were not used to develop the model. Consistent with the hypertrophy network, LLM-generated models of fibroblast activation and mechanosignaling successfully reconstructed 25.93-50.00% and 24.42-48.26% of their manually curated counterparts. Across all three networks, Claude 4.7 and GPT 4.1 outperformed Gemini 2.0, but with limited recall of the overall network.</p>
<p>We then asked whether the regional coverage of LLM-generated networks of fibroblasts and mechanosignaling mirrors that of cardiomyocytes. Indeed, the LLM- generated fibroblast network was most effective at reconstructing ligand-receptor interactions and highly conserved pathways such as cAMP and Ras/Raf/ERK, but could not recall AT1R signaling, PDGFR-abl signaling, and especially downstream regulation of transcription factors, genes, and extracellular matrix (e.g. MMP-collagen subnetwork) (<xref rid="figS1" ref-type="fig">Supplementary Figure 1</xref>). Unlike hypertrophy and fibroblast networks, mechanosignaling is mediated by stretch-dependent proteins that are relatively less characterized. Indeed, the LLM-generated networks for mechanosignaling did not adequately reconstruct direct mechano-sensation and had limited coverage of gene regulation consistent with the other networks (<xref rid="figS2" ref-type="fig">Supplementary Figure 2</xref>). Still, core conserved pathways for Na/Ca regulation, regulation of protein synthesis, and MAPK signaling were reconstructed well.</p>
<p>Models of signaling networks are useful not just for their description of structure, but especially for their ability to simulate the response to new perturbations. Making such predictions requires a specific mathematical formalism. For the three networks used for benchmarking, we had previously automatically translated them into logic- based differential equation models<sup><xref ref-type="bibr" rid="c17">17</xref></sup> using the software Netflux<sup><xref ref-type="bibr" rid="c16">16</xref></sup>. This allows network- wide prediction of dynamics in response to any desired perturbations and does not require prior knowledge of rate constants or concentrations<sup><xref ref-type="bibr" rid="c17">17</xref></sup>. The predictions of these three logic-based models have also been highly validated against experiments not used to develop the model<sup><xref ref-type="bibr" rid="c13">13</xref>–<xref ref-type="bibr" rid="c15">15</xref>,<xref ref-type="bibr" rid="c18">18</xref></sup>. Therefore, we generated logic-based models based on all of the LLM-generated network structures described above.</p>
<p>Returning our focus to the hypertrophy network, we examined the ability of LLM- generated networks to predict classic the “fetal gene program” gene expression signature in cardiomyocytes. The manually curated model accurately predicts that AngII and/or ISO increase the expression of ANP, BNP, GATA4, βMHC, sACT, and increases cell area/size, while decreasing expression of SERCA and αMHC. In contrast, the LLM- generated network models produce limited aspects of this signature, with the best performance in predicting ISO-dependent ANP in the GPT version (<xref rid="fig2" ref-type="fig">Figure 2A</xref>). We then tested whether this validation accuracy scales across all available manually curated experiments that cover a wider array of perturbations and measured outputs. Overall, for 114 validations where the manually curated network has an functional accuracy of 94.74%, LLM-generated networks have an accuracy of 6.14-26.32% (<xref rid="fig2" ref-type="fig">Figure 2B</xref>).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Experimental validation of perturbation responses predicted by LLM-generated signaling network models.</title>
<p>A) Representative validations of network models generated by manual curation or by LLMs (Gemini, GPT, Claude), in comparison to experiments in conditions of Angiotensin II (AngII) or isoproterenol (ISO) from the literature<sup><xref ref-type="bibr" rid="c13">13</xref></sup>. B) Summary of systematic validations of manually curated (Ground Truth) and LLM-generated network models of hypertrophy, fibroblast, and mechano-signaling network models against perturbation experiments from the literature (n = 114, 83, and 171 experiments, respectively). * Indicates p &lt; 10<sup>−11</sup> in one-sample T test between LLM-generated model validation scores (n = 10 replicates) and ground truth model validation accuracy.</p></caption>
<graphic xlink:href="667217v1_fig2-new.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Repeating this systematic experimental validation for LLM-generated models of the fibroblast (<xref rid="fig2" ref-type="fig">Figure 2C</xref>) and mechano-signaling (<xref rid="fig2" ref-type="fig">Figure 2D</xref>), we observed similar validation accuracies of 16.87-21.69% and 5.81%, respectively. Together, these results indicate that validation accuracy of LLM-generated models for perturbation responses is even lower than their accuracy for reconstructing network structure. Because the validation tests are testing larger-range functional interactions, this difference may be caused by gaps in reconstructed pathways.</p>
<p>In conclusion, we developed a pipeline for generating predictive, logic-based models of signaling networks using general purpose large language models (LLMs). To test the reconstruction and simulation accuracy of LLM-generated network models, we benchmarked this pipeline using three LLMs (GPT 4.1, Claude 4.7, and Gemini 2.0) against three large-scale, manually curated and validated models of signaling networks. Across cardiac hypertrophy, fibroblast, and mechano-signaling networks, LLM- generated models exhibit 24.42-58.12% reconstruction of reactions from the manually curated models. Reconstruction accuracy is high for ligand-receptor interactions and well-conserved pathways, but lower for cell-specific gene regulation or biophysical regulation. Likely due to gaps in reconstructed pathways, LLM-generated models had a low ability to accurately simulate the responses of networks to perturbations. Overall, we provide a pipeline for LLM-generated models of signaling networks and benchmark their performance against three manually curated networks. Improving the performance of LLM-generated network models may require hybrid manual-LLM approaches or advances in more special-purpose AI models.</p>
</sec>
<sec id="s2">
<title>Methods</title>
<sec id="s2a">
<title>Prior knowledge models of signaling networks</title>
<p>To benchmark LLM-generated network models, we selected three large-scale curated network models based on manual curation of the directed interactions using the literature<sup><xref ref-type="bibr" rid="c13">13</xref>–<xref ref-type="bibr" rid="c15">15</xref></sup>. These models were recently used to benchmark protein interaction databases<sup><xref ref-type="bibr" rid="c19">19</xref></sup>, creating a comparison’ for the current analysis. These models contain a range of biological processes including ligand-receptor interactions, phosphorylation, gene regulation, and cellular phenotypes. Associated with the network structure is an annotated list of genes associated with the nodes in the model. These models were mathematically formulated as systems of logic-based differential equations<sup><xref ref-type="bibr" rid="c17">17</xref></sup>, which enable dynamic network-wide predictions of how those cells respond to new perturbations. The predictive accuracy of these models has previously been rigorously tested with manual curation of literature not used to develop the models, with accuracies of 94.74% (hypertrophy), 81.93% (fibroblast), and 77.33% (mechanosignaling)<sup><xref ref-type="bibr" rid="c13">13</xref>–<xref ref-type="bibr" rid="c15">15</xref></sup>.</p>
</sec>
<sec id="s2b">
<title>Querying large language models</title>
<p>We focused on widely used, general-purpose large language models (LLMs) that are most relevant to wider use in the field. Specifically, we selected current versions of GPT (4.1, OpenAI), Gemini (2.0, Google), and Claude (3.7, Anthromorphic). The prompt consisted of three steps:</p>
<list list-type="order">
<list-item><p>The list of gene symbols, along with the description: “List of genes and other signaling nodes:”.</p></list-item>
<list-item><p>Description of the desired outputs: “For the first {batch_size} entries in this list of genes, proteins, and other signaling nodes from a {phenotype} network, please provide more than 0 but fewer than {max_connections} direct interactions with other nodes from the list supported by available literature. Simply list the input node, affected node, and if the affected node is stimulated / inhibited.” Batch size was set at 20 genes, max connections set to the maximum number of connections exhibited in that parent network, and phenotype set at “cardiac hypertrophy”, “fibroblast”, or “mechanosignaling” corresponding to the three networks used for benchmarking.</p></list-item>
<list-item><p>Instructions to repeat the process until reaching the end of the gene list: “That looks great! Please do the same operation for the next {len(chunk)} nodes! Thank you”</p></list-item>
<list-item><p>The responses were stored as .txt files and then programmatically extracted using regular expressions.</p></list-item></list>
</sec>
<sec id="s2c">
<title>Extracting reactions from LLM outputs, logic-based model generation</title>
<p>Each of the LLMs returned network reactions in slightly different format. But for example, Claude 3.7 returned reactions in the form: “ADRB2 stimulates RAC1” or “RAC1 stimulates MAP3K1”. Relationships based on directional signed relationships were kept, such as terms “stimulates”, down-regulates”, or “generates”. Returned reactions referring to non-relevant proteins or processes were discarded, as were non- directional relationships. We attempted also querying PubMed IDs, but these were rarely accurate.</p>
<p>Reactions successfully extracted from the LLM outputs were formatted for uniform comparison to the reaction list from the corresponding manually curated network. Finally, this reaction list was translated into the Netflux format for automated conversion to a logic-based differential equation model<sup><xref ref-type="bibr" rid="c16">16</xref>,<xref ref-type="bibr" rid="c17">17</xref></sup>. This final logic-based model was used to perform validation simulations.</p>
</sec>
</sec>
</body>
<back>
<sec id="s4" sec-type="supplementary">
<title>Supplementary Information</title>
<fig id="figS1" position="float" fig-type="figure">
<label>Supplementary Figure 1.</label>
<caption><title>Visualization of LLM-generated fibroblast signaling networks, as recalled by three general-purpose large language models.</title>
<p>Network reactions recalled by three large language models (Gemini2.0, orange; ChatGPT4, blue; Claude3.7, green) compared with a “Ground Truth” literature-curated and validated fibroblast signaling network (gray reactions). LLM-generated networks used prompts based on the gene set list of the Ground Truth fibroblast network. This visualization corresponds to the analyses in <xref rid="fig1" ref-type="fig">Figure 1D</xref>.</p></caption>
<graphic xlink:href="667217v1_figS1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS2" position="float" fig-type="figure">
<label>Supplementary Figure 2.</label>
<caption><title>Visualization of LLM-generated mechanosignaling networks, as recalled by three general-purpose large language models.</title>
<p>Network reactions recalled by three large language models (Gemini2.0, orange; ChatGPT4, blue; Claude3.7, green) compared with a “Ground Truth” literature-curated and validated mechanosignaling network (gray reactions). LLM-generated networks used prompts based on the gene set list of the Ground Truth mechanosignaling network. This visualization corresponds to the analyses in <xref rid="fig1" ref-type="fig">Figure 1E</xref>.</p></caption>
<graphic xlink:href="667217v1_figS2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="das" sec-type="data-availability">
<title>Data availability</title>
<p>The code used in this project is freely available on GitHub at: <ext-link ext-link-type="uri" xlink:href="https://github.com/saucermanlab/LLM-network-generation">https://github.com/saucermanlab/LLM-network-generation</ext-link></p>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Karr</surname>, <given-names>J. R.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>A Whole-Cell Computational Model Predicts Phenotype from Genotype</article-title>. <source>Cell</source> <volume>150</volume>, <fpage>389</fpage>–<lpage>401</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Steinway</surname>, <given-names>S. N.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Network Modeling of TGFβ Signaling in Hepatocellular Carcinoma Epithelial-to-Mesenchymal Transition Reveals Joint Sonic Hedgehog and Wnt Pathway Activation</article-title>. <source>Cancer Research</source> <volume>74</volume>, <fpage>5963</fpage>–<lpage>5977</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Qiao</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Khalilimeybodi</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Linden-Santangeli</surname>, <given-names>N. J.</given-names></string-name> &amp; <string-name><surname>Rangamani</surname>, <given-names>P.</given-names></string-name></person-group> <article-title>The Evolution of Systems Biology and Systems Medicine: From Mechanistic Models to Uncertainty Quantification</article-title>. <source>Annu Rev Biomed Eng</source> <volume>27</volume>, <fpage>425</fpage>–<lpage>447</lpage> (<year>2025</year>).</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Singhal</surname>, <given-names>K.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Toward expert-level medical question answering with large language models</article-title>. <source>Nat Med</source> <volume>31</volume>, <fpage>943</fpage>–<lpage>950</lpage> (<year>2025</year>).</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="preprint"><person-group person-group-type="author"><collab>OpenAI</collab>, <etal>et al</etal></person-group>. <article-title>GPT-4 Technical Report</article-title>. <source>arXiv</source> <pub-id pub-id-type="doi">10.48550/arXiv.2303.08774</pub-id> (<year>2024</year>).</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Abramson</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Accurate structure prediction of biomolecular interactions with AlphaFold 3</article-title>. <source>Nature</source> <volume>630</volume>, <fpage>493</fpage>–<lpage>500</lpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dauparas</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Robust deep learning-based protein sequence design using ProteinMPNN</article-title>. <source>Science</source> <volume>378</volume>, <fpage>49</fpage>–<lpage>56</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Theodoris</surname>, <given-names>C. V.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Transfer learning enables predictions in network biology</article-title>. <source>Nature</source> <volume>618</volume>, <fpage>616</fpage>–<lpage>624</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Cui</surname>, <given-names>H.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>scGPT: toward building a foundation model for single-cell multi-omics using generative AI</article-title>. <source>Nat Methods</source> <volume>21</volume>, <fpage>1470</fpage>–<lpage>1480</lpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bunne</surname>, <given-names>C.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>How to build the virtual cell with artificial intelligence: Priorities and opportunities</article-title>. <source>Cell</source> <volume>187</volume>, <fpage>7045</fpage>–<lpage>7063</lpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Roohani</surname>, <given-names>Y. H.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Virtual Cell Challenge: Toward a Turing test for the virtual cell</article-title>. <source>Cell</source> <volume>188</volume>, <fpage>3370</fpage>–<lpage>3374</lpage> (<year>2025</year>).</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rood</surname>, <given-names>J. E.</given-names></string-name>, <string-name><surname>Hupalowska</surname>, <given-names>A.</given-names></string-name> &amp; <string-name><surname>Regev</surname>, <given-names>A.</given-names></string-name></person-group> <article-title>Toward a foundation model of causal cell and tissue biology with a Perturbation Cell and Tissue Atlas</article-title>. <source>Cell</source> <volume>187</volume>, <fpage>4520</fpage>–<lpage>4545</lpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ryall</surname>, <given-names>K.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Network reconstruction and systems analysis of cardiac myocyte hypertrophy signaling</article-title>. <source>The Journal of biological chemistry</source> <volume>287</volume>, <fpage>42259</fpage>–<lpage>42268</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Zeigler</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Richardson</surname>, <given-names>W. J.</given-names></string-name>, <string-name><surname>Holmes</surname>, <given-names>J. W.</given-names></string-name> &amp; <string-name><surname>Saucerman</surname>, <given-names>J. J.</given-names></string-name></person-group> <article-title>A computational model of cardiac fibroblast signaling predicts context-dependent drivers of myofibroblast differentiation</article-title>. <source>J Mol Cell Cardiol</source> <volume>94</volume>, <fpage>72</fpage>–<lpage>81</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tan</surname>, <given-names>P. M.</given-names></string-name>, <string-name><surname>Buchholz</surname>, <given-names>K. S.</given-names></string-name>, <string-name><surname>Omens</surname>, <given-names>J. H.</given-names></string-name>, <string-name><surname>McCulloch</surname>, <given-names>A. D.</given-names></string-name> &amp; <string-name><surname>Saucerman</surname>, <given-names>J. J.</given-names></string-name></person-group> <article-title>Predictive model identifies key network regulators of cardiomyocyte mechano-signaling</article-title>. <source>PLoS Comput Biol</source> <volume>13</volume>, <fpage>e1005854</fpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Clark</surname>, <given-names>A. P.</given-names></string-name>, <string-name><surname>Chowkwale</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Paap</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Dang</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Saucerman</surname>, <given-names>J. J.</given-names></string-name></person-group> <article-title>Logic-based modeling of biological networks with Netflux</article-title>. <source>PLoS Comput Biol</source> <volume>21</volume>, <fpage>e1012864</fpage> (<year>2025</year>).</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kraeutler</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Soltis</surname>, <given-names>A. R.</given-names></string-name> &amp; <string-name><surname>Saucerman</surname>, <given-names>J. J.</given-names></string-name></person-group> <article-title>Modeling cardiac β-adrenergic signaling with normalized-Hill differential equations: comparison with a biochemical model</article-title>. <source>BMC Syst Biol</source> <volume>4</volume>, <fpage>157</fpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Khalilimeybodi</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Paap</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Christiansen</surname>, <given-names>S. L. M.</given-names></string-name> &amp; <string-name><surname>Saucerman</surname>, <given-names>J. J.</given-names></string-name></person-group> <article-title>Context-specific network modeling identifies new crosstalk in β-adrenergic cardiac hypertrophy</article-title>. <source>PLoS Comput Biol</source> <volume>16</volume>, <fpage>e1008490</fpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Van de Graaf</surname>, <given-names>M. W.</given-names></string-name>, <string-name><surname>Eggertsen</surname>, <given-names>T. G.</given-names></string-name>, <string-name><surname>Zeigler</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Tan</surname>, <given-names>P. M.</given-names></string-name> &amp; <string-name><surname>Saucerman</surname>, <given-names>J. J.</given-names></string-name></person-group> <article-title>Benchmarking of protein interaction databases for integration with manually reconstructed signalling network models</article-title>. <source>J Physiol</source> (<year>2023</year>) doi:<pub-id pub-id-type="doi">10.1113/JP284616</pub-id>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.109709.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Graña</surname>
<given-names>Martin</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Institut Pasteur de Montevideo</institution>
</institution-wrap>
<city>Montevideo</city>
<country>Uruguay</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>The authors address a hard question and propose a pipeline for using Large Language Models to reconstruct signalling networks as well as to benchmark future models. The findings are <bold>valuable</bold> for a defined subfield, as the proposed framework allows for assessing such approaches systematically. The overall support is <bold>solid</bold>, although the present evaluation remains limited in scope and would benefit from a wider range of networks and performance metrics.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.109709.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Large language models (LLMs) have been developed rapidly in recent years and are already contributing to progress across scientific fields. The manuscript tries to address a specific question: whether LLMs can accurately infer signaling networks from gene lists. However, the evaluation is inadequate due to four major weaknesses described below. Despite these limitations, the authors conclude that current general-purpose LLMs lack adequate accuracy, which is already widely recognized. Its key contribution should instead be to provide concrete recommendations for the development of specialized LLMs for this task, which is completely absent. Developing such specific LLMs would be highly valuable, as they could substantially reduce the time required by researchers to analyze signaling networks.</p>
<p>Strengths:</p>
<p>The manuscript raises a good question: whether current LLMs can accurately generate signaling networks from gene lists.</p>
<p>Weaknesses:</p>
<p>(1) The authors evaluate LLM performance using only three signaling networks: &quot;hypertrophy&quot;, &quot;fibroblast&quot;, and &quot;mechanosignaling&quot;. Given the large number of well-established signaling pathways available, this is not a comprehensive assessment. Moreover, the analysis need not be restricted to signaling networks. Other network types, including metabolic and transcriptional regulatory networks, are already accessible in well-known databases such as KEGG, Reactome, BioCyc, WikiPathways, and Pathway Commons. Including these additional networks would substantially strengthen the evaluation.</p>
<p>(2) In LLM evaluation, the authors use the gene lists that exactly match those in their &quot;ground truth&quot; networks, thereby fixing the set of nodes and evaluating only the predicted edges. However, in practical research, the relevant genes or nodes are not fully known. A more realistic assessment would therefore include gene lists with both genes present in the ground-truth network and additional genes absent from it, to evaluate the ability of the LLM to exclude irrelevant genes.</p>
<p>(3) The authors report only the recall/sensitivity of the LLM, without assessing specificity. In practical applications, if an LLM generates a large number of incorrect interactions that greatly exceed the correct ones, researchers may be misled or may lose confidence in the LLM output. Therefore, a comprehensive evaluation must include both sensitivity and specificity. Furthermore, it would be informative to check whether some of the &quot;false positives&quot; might in fact represent biologically plausible interactions that are absent from the manually curated &quot;ground truth&quot;. Manually generated &quot;ground truth&quot; can overlook genuine interactions, and the ability of LLMs to recover such missing edges could be particularly valuable. This may even represent one of the most important potential contributions of LLMs.</p>
<p>(4) It is widely known that applying differential equation models to highly complex biological networks, such as the three networks in the manuscript, is meaningless, because these systems involve a large number of parameters whose values can drastically alter the results. As Richard Feynman once said: &quot;with four parameters I can fit an elephant, and with five I can make him wiggle his trunk.&quot; Thus, the evaluation of LLMs on &quot;logic-based differential equation models&quot; does not make much sense.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.109709.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The authors evaluate whether commonly used LLMs (ChatGPT, Claude and Gemini) can reconstruct signalling networks and predict effects of network perturbations, and propose a pipeline for benchmarking future models. Across three phenotypes (hypertrophy, fibroblast signalling, and mechanosignalling), LLMs capture upstream ligand-receptor interactions and conserved crosstalk but fail to recover downstream transcriptional programmes. Logic-based simulations show that LLM-derived networks underperform compared to manually curated models. The authors also propose that their pipeline can be used for benchmarking future models aimed at reconstructing signalling networks.</p>
<p>Strength:</p>
<p>The authors compare the outcomes from three LLMs with three manually curated and validated models. Additionally, they have investigated gene network reconstruction in the context of three distinct phenotypes. Using logic-based modelling, the authors assessed how LLM-derived networks predict perturbation effects, providing functional validation beyond network overlap.</p>
<p>Weaknesses:</p>
<p>The authors have used legacy models for all three LLMs, and the study would benefit from testing the current versions of the LLMs (ChatGPT 5.2, Claude 4.5 and Gemini 2.5). Additional metrics such as node coverage, node invention, direction accuracy and sign accuracy would be useful to make robust comparisons across models.</p>
</body>
</sub-article>
</article>