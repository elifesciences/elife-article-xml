<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">88463</article-id>
<article-id pub-id-type="doi">10.7554/eLife.88463</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.88463.2</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.3</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Microbiology and Infectious Disease</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Tools and methods for high-throughput single-cell imaging with the mother machine</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0348-4181</contrib-id>
<name>
<surname>Thiermann</surname>
<given-names>Ryan</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">*</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Sandler</surname>
<given-names>Michael</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">*</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Ahir</surname>
<given-names>Gursharan</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">*</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Sauls</surname>
<given-names>John T.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">*</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Schroeder</surname>
<given-names>Jeremy W.</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n1">*</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Brown</surname>
<given-names>Steven D.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Le Treut</surname>
<given-names>Guillaume</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Si</surname>
<given-names>Fangwei</given-names>
</name>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Li</surname>
<given-names>Dongyang</given-names>
</name>
<xref ref-type="aff" rid="a5">5</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1503-170X</contrib-id>
<name>
<surname>Wang</surname>
<given-names>Jue D.</given-names>
</name>
<xref ref-type="aff" rid="a6">6</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0139-4297</contrib-id>
<name>
<surname>Jun</surname>
<given-names>Suckjoon</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">**</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Physics, University of California San Diego</institution>, La Jolla CA</aff>
<aff id="a2"><label>2</label><institution>Department of Biological Chemistry, University of Michigan Medical School</institution>, Ann Arbor, MI</aff>
<aff id="a3"><label>3</label><institution>Chan Zuckerberg Biohub</institution>, San Francisco, CA</aff>
<aff id="a4"><label>4</label><institution>Department of Physics, Carnegie Mellon University</institution>, Pittsburgh, PA</aff>
<aff id="a5"><label>5</label><institution>Division of Biology and Biological Engineering, California Institute of Technology</institution>, Pasadena, CA</aff>
<aff id="a6"><label>6</label><institution>Department of Bacteriology, University of Wisconsin-Madison</institution>, Madison, WI</aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Salman</surname>
<given-names>Hanna</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Pittsburgh</institution>
</institution-wrap>
<city>Pittsburgh</city>
<country>United States of America</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Walczak</surname>
<given-names>Aleksandra M</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>CNRS</institution>
</institution-wrap>
<city>Paris</city>
<country>France</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>**</label>Corresponding author: <email>suckjoon.jun@gmail.com</email></corresp>
<fn id="n1" fn-type="equal"><label>*</label><p>These authors contributed equally to this work</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2023-07-26">
<day>26</day>
<month>07</month>
<year>2023</year>
</pub-date>
<pub-date date-type="update" iso-8601-date="2024-02-06">
<day>06</day>
<month>02</month>
<year>2024</year>
</pub-date>
<volume>12</volume>
<elocation-id>RP88463</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2023-05-11">
<day>11</day>
<month>05</month>
<year>2023</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-04-07">
<day>07</day>
<month>04</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.03.27.534286"/>
</event>
<event>
<event-desc>Reviewed preprint v1</event-desc>
<date date-type="reviewed-preprint" iso-8601-date="2023-07-26">
<day>26</day>
<month>07</month>
<year>2023</year>
</date>
<self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.88463.1"/>
<self-uri content-type="editor-report" xlink:href="https://doi.org/10.7554/eLife.88463.1.sa2">eLife assessment</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.88463.1.sa1">Reviewer #1 (Public Review):</self-uri>
<self-uri content-type="referee-report" xlink:href="https://doi.org/10.7554/eLife.88463.1.sa0">Reviewer #2 (Public Review):</self-uri>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2023, Thiermann et al</copyright-statement>
<copyright-year>2023</copyright-year>
<copyright-holder>Thiermann et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-88463-v2.pdf"/>
<abstract>
<title>Abstract</title>
<p>Despite much progress, image processing remains a significant bottleneck for high-throughput analysis of microscopy data. One popular platform for single-cell time-lapse imaging is the mother machine, which enables long-term tracking of microbial cells under precisely controlled growth conditions. While several mother machine image analysis pipelines have been developed in the past several years, adoption by a non-expert audience remains a challenge. To fill this gap, we implemented our own software, MM3, as a plugin for the multidimensional image viewer napari. napari-MM3 is a complete and modular image analysis pipeline for mother machine data, which takes advantage of the high-level interactivity of napari. Here, we give an overview of napari-MM3 and test it against several well-designed and widely-used image analysis pipelines, including BACMMAN and DeLTA. Researchers often analyze mother machine data with custom scripts using varied image analysis methods, but a quantitative comparison of the output of different pipelines has been lacking. To this end, we show that key single-cell physiological parameter correlations and distributions are robust to the choice of analysis method. However, we also find that small changes in thresholding parameters can systematically alter parameters extracted from single-cell imaging experiments. Moreover, we explicitly show that in deep learning based segmentation, “what you put is what you get” (WYPIWYG) - i.e., pixel-level variation in training data for cell segmentation can propagate to the model output and bias spatial and temporal measurements. Finally, while the primary purpose of this work is to introduce the image analysis software that we have developed over the last decade in our lab, we also provide information for those who want to implement mother-machine-based high-throughput imaging and analysis methods in their research.</p>
</abstract>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Software comparison and testing section expanded. Supplement updated.</p></fn>
</fn-group>
<fn-group content-type="external-links">
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://github.com/junlabucsd/napari-mm3">https://github.com/junlabucsd/napari-mm3</ext-link>
</p></fn>
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://github.com/junlabucsd/mother-machine-data">https://github.com/junlabucsd/mother-machine-data</ext-link>
</p></fn>
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://github.com/junlabucsd/mother-machine-protocols">https://github.com/junlabucsd/mother-machine-protocols</ext-link>
</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>The mother machine [<xref ref-type="bibr" rid="c1">1</xref>] is a popular microfluidic platform for long-term, high-throughput imaging of single cells. It has been widely adopted as a standard for long-term imaging of bacteria such as <italic>Escherichia coli</italic> and <italic>Bacillus subtilis</italic> [<xref ref-type="bibr" rid="c2">2</xref>], as well as the eukaryote <italic>Schizosaccharomyces pombe</italic> [<xref ref-type="bibr" rid="c3">3</xref>,<xref ref-type="bibr" rid="c4">4</xref>]. In the mother machine, thousands of single cells are trapped in one-ended growth channels that open into a central trench (<xref rid="fig1" ref-type="fig">Figure 1.1</xref>). The cells at the end of the growth channels (“mother cells”) grow and divide over hundreds of generations, while their progeny are successively flushed out of the device (<xref rid="fig1" ref-type="fig">Figure 1.2-1.3</xref>). Data gathered from the mother machine has brought critical insight into diverse domains such as aging [<xref ref-type="bibr" rid="c1">1</xref>], single-cell physiology [<xref ref-type="bibr" rid="c5">5</xref>], starvation adaptation [<xref ref-type="bibr" rid="c6">6</xref>], antibiotic persistence [<xref ref-type="bibr" rid="c7">7</xref>], cell differentiation [<xref ref-type="bibr" rid="c8">8</xref>], and the mechanics of cell wall growth [<xref ref-type="bibr" rid="c9">9</xref>] (<xref rid="fig1" ref-type="fig">Figure 1.4</xref>).</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Mother machine workflow, schematic, and applications.</title>
<p>(1.1) Mother machine schematic. Growth channels flank a central flow cell that supplies fresh media and whisks away daughter cells. In a typical experiment, numerous fields of view (FOVs) are imaged for several hours. (1.2) Fluorescence images of <italic>E. coli</italic> strains expressing cytoplasmic YFP [<xref ref-type="bibr" rid="c1">1</xref>] (left) and markers for the replisome protein DnaN and division protein FtsZ (right) [<xref ref-type="bibr" rid="c10">10</xref>]. (1.3) The mother machine setup allows long-term monitoring of the old-pole mother cell lineage [<xref ref-type="bibr" rid="c1">1</xref>] and has other versatile applications, including (1.4) the study of the mechanical properties of bacterial cells by applying controlled Stokes forces [<xref ref-type="bibr" rid="c9">9</xref>].</p></caption>
<graphic xlink:href="534286v3_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2:</label>
<caption><title>MM3 workflow and example images.</title>
<p>(2.1) The MM3 image analysis pipeline takes raw mother machine images and produces cell objects. Processes (rounded rectangles) are modular; multiple methods are provided for each. (2.2) Example images from the processing of one growth channel in a single FOV. The growth channel is first identified, cropped, and compiled in time. All cells are segmented (colored regions). Lineages are tracked by linking segments in time to determine growth and division (solid and dashed lines, respectively), creating cell objects.</p></caption>
<graphic xlink:href="534286v3_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3:</label>
<caption><title>napari-MM3 interface.</title>
<p>The napari viewer enables interactive analysis of mother machine data with real-time feedback and fast debugging. Raw data shown is from MG1655 background <italic>E coli</italic> expressing the fluorescence protein YPet fused to the replisome protein DnaN [<xref ref-type="bibr" rid="c10">10</xref>].</p></caption>
<graphic xlink:href="534286v3_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4:</label>
<caption><title>Comparison of various image analysis approaches.</title>
<p>(4.1) A time series of a typical cell growing in a nutrient-rich medium. The birth size, division size, and added size are indicated. (4.2) The adder principle ensures cell size homeostasis via passive convergence of cell size to the population mean. (4.3) We analyzed multiple datasets from our lab using MM3, DeLTA, and BACMMAN, and obtained robust correlations between birth length, doubling time, elongation rate, and added length. Representative results from one dataset [<xref ref-type="bibr" rid="c10">10</xref>] for MG1655 background <italic>E. coli</italic> grown in MOPS glycerol + 11 amino acids are shown, with 9,000 - 13,000 cells analyzed depending on the method. (4.4) Distributions of key physiological parameters are independent of the analysis methods. The data and code used to generate this figure are available at [<xref ref-type="bibr" rid="c44">44</xref>]</p></caption>
<graphic xlink:href="534286v3_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Despite the progress in imaging techniques and microfluidics, image processing remains a major bottleneck in the analysis pipelines. The unique structure of the mother machine device enables precise control of growth conditions and long-term tracking of cells, to the degree that cannot be achieved by traditional tracking of cells in microcolonies [<xref ref-type="bibr" rid="c11">11</xref>]. However, automated image processing is essential to process the large amounts of data generated by these high-throughput experiments. In addition, the unique structure of the mother machine device requires a specialized workflow to select and track individual growth channels. As experimentalists often need to extract precise statistics over multiple generations or observe rare events, the analysis workflow must be modular to allow inspection and curation of intermediate results. To meet these needs, numerous mother machine-specific image analysis packages have been introduced in the last few years [<xref ref-type="bibr" rid="c12">12</xref>–<xref ref-type="bibr" rid="c15">15</xref>], in addition to general image analysis packages adaptable to the mother machine workflow [<xref ref-type="bibr" rid="c16">16</xref>–<xref ref-type="bibr" rid="c20">20</xref>]. Much recent work has been catalyzed by advances in biomedical image analysis with deep convolutional neural networks, particularly the U-Net architecture [<xref ref-type="bibr" rid="c21">21</xref>]. Many of these tools [<xref ref-type="bibr" rid="c15">15</xref>,<xref ref-type="bibr" rid="c22">22</xref>] have been designed with ease-of-use and accessibility in mind. However, they can still present a steep learning curve for first-time users. In addition, as the outputs of these pipelines are often used by researchers to derive biological principles based on correlations, it is important to understand the limitations of and differences between different image analysis methods.</p>
<boxed-text id="bx1" position="float">
<label>Box 1:</label>
<p>Mother machine experimental workflow</p>
<p>Despite the well-appreciated power of single-cell time-lapse imaging approaches, the potential user base remains much greater than the number of researchers directly benefiting from the technology. A primary reason for this discrepancy between demand and actual adoption is the perceived cost in time and resources of investment in the required core technology: microfluidics and high-throughput image analysis. Until a few years ago, setting up a typical microfluidic system for the first time took several years of training and trial-and-error, along with significant resources, for most individual labs.</p>
<p>Running a mother machine experiment requires the following steps: (1) fabricating a mold for the device, (2) assembling the device, (3) performing time-lapse microscopy, and (4) analyzing the images to extract time traces and statistics. To our knowledge, steps (1) and (4) have been the primary bottlenecks for most groups. Here we give a brief overview of the experimental workflow. We refer interested readers to our previous review article on single-cell physiology [<xref ref-type="bibr" rid="c23">23</xref>], along with other recent reviews [<xref ref-type="bibr" rid="c24">24</xref>,<xref ref-type="bibr" rid="c25">25</xref>] and published protocols [<xref ref-type="bibr" rid="c26">26</xref>], for a more extensive guide to single-cell imaging techniques.</p>
<sec id="s1a">
<title>Device design and fabrication</title>
<p>In the original mother machine design [<xref ref-type="bibr" rid="c1">1</xref>], narrow channels trap bacterial cells perpendicular to a larger main trench through which fresh medium flows (<xref rid="fig1" ref-type="fig">Figure 1.4</xref>). Several constraints apply to the design of the device. The height and width of the channels should match the dimensions of the organism under study. The channels must be large enough to facilitate the loading of the cells and allow for fast diffusion of nutrients to mother cells at the channel ends. If the channels are too deep, cells may move out of focus and potentially overlap in the z-direction, both of which impede accurate segmentation. Similarly, if channels are too wide, cells may not grow in a single file, complicating segmentation and tracking. Longer trenches will retain cells longer and allow more cells to be tracked per channel.</p>
<p>The prohibitive cost of mold fabrication in clean room facilities has been a bottleneck to distributing microfluidic devices. We resolved this problem using an epoxy-based fabrication technique [<xref ref-type="bibr" rid="c27">27</xref>], allowing us to easily and cheaply create replicative molds. Once the first microfluidic device is fabricated in the clean room, the epoxy duplication method allows us to reliably create and distribute high-fidelity device molds at a fraction of the cost of the initial fabrication. Undergraduate students in our lab routinely perform this procedure. To assist new users of the mother machine, we include a detailed procedure for the duplication method at [<xref ref-type="bibr" rid="c28">28</xref>].</p>
<fig id="ufig1" position="float" fig-type="figure">
<graphic xlink:href="534286v3_ufig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s1b">
<title>Experiment setup</title>
<p>The first step of making the mother machine device is to pour PDMS (polydimethylsiloxane) onto a master mold, cure it, and remove it from the mold. Holes are punched in the cut devices at the inlet and outlet of the central channel to connect tubing for fresh medium (inlet) and waste removal (outlet) before plasma treatment (<xref rid="fig1" ref-type="fig">Figure 1.1</xref>). Plasma treatment covalently bonds the PDMS device to a glass cover slide or dish to be mounted on the microscope. BSA (bovine serum albumin) passed through the device passivates the surface. In our setup, we load cells to the growth channels in the device via a custom centrifuge [<xref ref-type="bibr" rid="c28">28</xref>] (<xref rid="figS1" ref-type="fig">Figure S1</xref>). Growth medium is passed through the device using a syringe pump. The medium flow should be fast enough to clear dead cells or biofilms in the device, but slow enough that the device does not delaminate. Mounting the device on an inverted microscope requires a custom stage insert for long-term imaging. The microscope temperature must be controlled tightly.</p>
</sec>
<sec id="s1c">
<title>Data analysis</title>
<p>Most mother machine image analysis workflows share the following steps: pre-processing the acquired images, including identification and cropping of cell traps, cell segmentation, and cell tracking. Cell segmentation is the most difficult and crucial step, as adjacent cells must be separated from each other and from device features. After accurate segmentation, the one-dimensional structure of the mother machine - which constrains the cells to move only in one direction along the length of the trap without bypassing each other - makes cell tracking relatively simple.</p>
<p>This article consists of three parts. First, for first-time users, we provide a brief walkthrough on implementing the mother machine in research (Box 1), including how to duplicate microfluidic devices at no cost using epoxy replicas and troubleshoot common image analysis problems. Next, we introduce MM3 [<xref ref-type="bibr" rid="c29">29</xref>], a fast and interactive image analysis pipeline for mother machine experiments that we have developed and used internally for over a decade. Our latest version is a Python plugin for the multidimensional image viewer napari [<xref ref-type="bibr" rid="c30">30</xref>]. Finally, we compare the accessibility, performance, and robustness of various current image analysis platforms. In order to trust analysis results, researchers should understand the limitations of their chosen method. With this in mind, we show that “what you put is what you get”: both classical and deep learning-based segmentation methods are highly sensitive to user-determined threshold values. As exact cell boundaries may be difficult to distinguish by eye, these values are difficult to set definitively, and can systematically alter the output of the analysis. Fortunately, we find that key single-cell physiological parameter correlations and distributions are robust to the choice of analysis method. However, interpreting and comparing the results of different analyses requires care.</p>
</sec>
</boxed-text>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Mother machine image analysis with napari-MM3</title>
<p>Analysis of time-lapse imaging experiments requires dedicated software due to the sheer volume of data produced. For instance, an experiment tracking aging might require imaging 50 fields of view (<xref rid="fig1" ref-type="fig">Figure 1.1</xref>) every two minutes for a week, producing a quarter of a million images comprising hundreds of gigabytes of data. While the experimental methods for mother machine experiments have become increasingly accessible, image analysis tools have lagged behind. Typically, labs using the mother machine have developed their own customized analysis pipelines. Many available tools require programming experience, familiarity with command line tools, and extensive knowledge of image analysis methods. They are also often fine-tuned for specific experimental setups and difficult for the average user to adapt. Finally, existing workflows frequently require users to move between multiple interfaces such as ImageJ, MATLAB, the command line, Python scripting, and Jupyter notebooks. Newer deep learning approaches are more versatile than traditional computer vision methods. Still, they bring new issues for novices: users may need to construct their own training data and train a model, requiring a new set of tools and technical expertise, and manual annotation of training data is susceptible to human error and bias.</p>
<p>These considerations guided us in the development of our in-house analysis tool. In building MM3, we sought to provide modularity and extensive interactivity while minimizing unnecessary user intervention. MM3 aims to be a complete and flexible solution for mother machine image analysis, taking raw images and producing readily graphable cell data, while accommodating both machine learning-based and traditional computer vision techniques. It supports phase contrast and fluorescence images, and has been tested with different species (bacteria <italic>E. coli</italic> and <italic>B. subtilis</italic>, yeast <italic>S. pombe</italic>), mother machine designs, and optical configurations. The modular pipeline architecture allows flexible use of mid-stream outputs and straightforward troubleshooting (for instance, while <italic>M. mycoides</italic> is too small to segment with traditional microscopy methods [<xref ref-type="bibr" rid="c31">31</xref>], we were able to obtain growth rate measurements by running the first half of the pipeline).</p>
<p>MM3 reflects the culmination of several iterations of our in-house mother machine analysis software developed over the past decade. Before MM3, we developed our image analysis pipeline in C++ [<xref ref-type="bibr" rid="c1">1</xref>] and MATLAB [<xref ref-type="bibr" rid="c32">32</xref>]. Eventually, Python became enormously popular, and we began MM3 as a set of Python scripts run from the command line [<xref ref-type="bibr" rid="c33">33</xref>]. However, the command-line-based interface had several drawbacks. The interface was more difficult for users unfamiliar with the command line or programming. It also had limited interactivity. As a result, troubleshooting was difficult and required modifying the source code to display image output at intermediate steps or manually inspecting output files in ImageJ. This made the user repeatedly move back and forth between different windows and applications, slowing the analysis.</p>
<p>These drawbacks motivated us to convert MM3 into a plug-in for the Python-based interactive image viewer napari [<xref ref-type="bibr" rid="c30">30</xref>]. napari provides an N-dimensional display ideal for visualizing multichannel time-lapse data. It offers built-in annotation tools and label layers to compare and annotate segmentation masks and tracking labels. It also provides a Python interpreter, allowing users to move easily between the viewer interface and the underlying data objects. For the best usability, we designed the napari-MM3 plug-in to allow the user to run the entire pipeline without leaving the napari interface.</p>
<p>Image analysis via napari-MM3 consists of four steps (<xref rid="fig3" ref-type="fig">Figure 3</xref>).</p>
<p>1. Crop raw images and compile them into stacks corresponding to individual growth channels.</p>
<p>2. Choose channel stacks to be (a) analyzed, (b) used as templates for background subtraction, or (c) ignored.</p>
<p>3. Segment cells.</p>
<p>4. Construct cell lineages. napari-MM3 treats individual cells in the lineages as objects that can be plotted directly or converted to another data format.</p>
<p>We elaborate on these steps as follows.</p>
</sec>
<sec id="s2b">
<label>1.</label>
<title>Channel detection and curation</title>
<p>The first section of the napari-MM3 pipeline takes in raw micrographs and returns image stacks corresponding to one growth channel through time. napari-MM3 detects channels using a wavelet transform and then aligns them over time to correct for stage drift and vibration. The aligned growth channels are saved as unique image stacks with all time points for a given growth channel and color channel. As not all growth channels contain cells, and napari-MM3 auto-detects channels as full or empty based on the time correlation of the y-profile of the growth channel. The auto-detected growth channels and their classifications are then displayed in the napari viewer for the user to inspect and modify as needed.</p>
</sec>
<sec id="s2c">
<label>2.</label>
<title>Cell segmentation</title>
<p>napari-MM3 offers two methods for cell segmentation, one using traditional computer vision techniques and the other using deep learning. The non-learning method utilizes Otsu’s method to apply a binary threshold to separate cell objects from the background. It then labels the isolated cells and uses a random walker algorithm [<xref ref-type="bibr" rid="c34">34</xref>] to fill out the cell boundaries. This method is fast but optimized for specific mother machine designs and phase contrast imaging of bacteria. It also requires accurate background subtraction of phase contrast images (Box 2), to ensure that the presence of the channel border does not interfere with cell detection. The supervised learning method uses a convolutional neural net (CNN) with the U-Net architecture [<xref ref-type="bibr" rid="c21">21</xref>,<xref ref-type="bibr" rid="c22">22</xref>,<xref ref-type="bibr" rid="c35">35</xref>]. The napari viewer can be used to construct training data, with the option to import existing Otsu or U-Net segmentation output as a template. The neural net can then be trained directly from napari, with the option to check the performance of the model in the napari viewer after successive rounds of training.</p>
<boxed-text id="bx2" position="float">
<label>Box 2:</label>
<p>Segmentation via Otsu’s method</p>
<p>The Otsu segmentation method first aligns the growth channel of interest with an empty background channel by computing the orientation that maximizes the pixel-wise cross-correlation. The empty channel is then subtracted from the full channel, and the image is inverted. This background subtraction step is essential, as it removes the dark image of the PDMS device, which will otherwise interfere with segmenting the (dark) cells. Otsu’s method [<xref ref-type="bibr" rid="c36">36</xref>] is applied to find the binary threshold value, which maximizes the inter-region variance. We then apply a Euclidean distance transform, wherein each pixel is labeled with its distance to the dark region. The image is thresholded again, and a morphological opening is applied to erode links between regions. Small objects and objects touching the image border are removed. Each region is labeled, and the labels are used to seed a random walker algorithm [<xref ref-type="bibr" rid="c34">34</xref>] on the original image.</p>
<fig id="ufig2" position="float" fig-type="figure">
<graphic xlink:href="534286v3_ufig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</boxed-text>
</sec>
<sec id="s2e">
<label>3.</label>
<title>Cell tracking and lineage reconstruction</title>
<p>Finally, napari-MM3 links segmented cells in time to define a lineage of cell objects, using a simple decision tree based on a priori knowledge of binary fission and the mother machine. Tracking produces a dictionary of cell objects containing relevant information derived from the cell segments, including the cell lengths and volumes over time, cell elongation rate, and generation time. Plotting and additional analysis can then be done with the user’s tool of choice. Statistics can be directly extracted from the cell objects, or the cell objects can be converted into a .csv file, a pandas DataFrame, or a MATLAB structure. We provide a Jupyter notebook demonstrating this analysis at [<xref ref-type="bibr" rid="c37">37</xref>].</p>
<sec id="s2e1">
<title>Additional features and future extensions</title>
<p>napari-MM3 offers several additional modules supplemental to the main processing pipeline, including methods for fluorescence image analysis and U-Net training data construction and model training. Integrated fluorescence signal and fluorescence per cell area and volume for each timepoint can be extracted using the “Colors” module. napari-MM3 also includes a module for the detection and tracking of fluorescent spots or “foci.” For example, we have used it to track fluorescently labeled replisome machinery in bacteria in order to measure the timing and synchrony of DNA replication initiation [<xref ref-type="bibr" rid="c2">2</xref>,<xref ref-type="bibr" rid="c10">10</xref>]. Lastly, U-Net segmentation training data can be constructed by manual annotation of raw images in the napari viewer. napari-MM3 offers the option to construct training data with existing Otsu or U-Net segmentation data as a template. This allows the user to iteratively train a model, correct mistakes in its output, and use the modified output as input for the next round of training. We also provide a Jupyter notebook covering training data construction and model training at [<xref ref-type="bibr" rid="c37">37</xref>].</p>
<p>Going forward, we plan to add support for additional segmentation and tracking modalities [<xref ref-type="bibr" rid="c18">18</xref>,<xref ref-type="bibr" rid="c38">38</xref>]. We will also incorporate support for additional organisms such as the budding yeast <italic>S. cerevisiae</italic>. Finally, we plan to take advantage of napari’s interactive display to add interactive data visualization and plotting.</p>
</sec>
<sec id="s2e2">
<title>Performance test of napari-MM3</title>
<p>To evaluate the speed of napari-MM3, we timed the processing of a typical dataset (<xref rid="tbl1" ref-type="table">Table 1</xref>). Using consumer-grade hardware, a single-channel stack consisting of several hundred time frames can be processed in less than five seconds, and a typical experiment consisting of 25 GB of imaging data can be processed in under an hour. These metrics are on par with those reported by other recently published mother machine software [<xref ref-type="bibr" rid="c15">15</xref>,<xref ref-type="bibr" rid="c22">22</xref>,<xref ref-type="bibr" rid="c40">40</xref>].</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><title>Performance metrics for napari-MM3.</title>
<p>Processing times were measured on an iMac with a 3.6 GHz 10-Core Intel Core i9 processor with 64 GB of RAM and an AMD Radeon Pro 5500 XT 8 GB GPU. Tensorflow was configured to use the AMD GPU according to [<xref ref-type="bibr" rid="c39">39</xref>]. The GPU was used in U-Net training and segmentation steps. The dataset analyzed is from [<xref ref-type="bibr" rid="c10">10</xref>] and consists of 26 GB of raw image data (12 hours, 262 time frames, 2 imaging planes, 34 FOVs, and ∼35 growth channels per FOV). Note that while the Otsu segmentation method is slightly faster than the U-Net, it also requires a background subtraction step, such that the total runtimes of the two methods are comparable.</p></caption>
<graphic xlink:href="534286v3_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s2e3">
<title>Testing napari-MM3 on other published datasets</title>
<p>We tested napari-MM3 on several publicly available mother machine datasets: three from experiments with <italic>E. coli</italic> [<xref ref-type="bibr" rid="c15">15</xref>,<xref ref-type="bibr" rid="c22">22</xref>,<xref ref-type="bibr" rid="c41">41</xref>] and one from <italic>C. glutamicum</italic> [<xref ref-type="bibr" rid="c13">13</xref>]. We were able to process all 4 datasets with minimal adjustments to the default parameter values (Methods). We quantified the performance of MM3 on each dataset by comparing the output of the Otsu segmentation method to manually determined ground truth masks from a subset of each dataset (<xref rid="tbl2" ref-type="table">Table 2</xref>). We computed the segmentation accuracy as the Jaccard Index at an IoU threshold of 0.6 (Methods). The software performed well on BACMMAN, molyso and MoMa datasets, with segmentation accuracies of 97.9%, 98.4% and 100.0% respectively. Segmentation was notably worse on the DeLTA dataset, with an accuracy of 91.5%. However, we observed that the majority of segmentation errors arose from misclassification of cells near the channel opening, where determining cell boundaries is often more difficult.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2:</label>
<caption><title>Testing napari-MM3 on external datasets.</title>
<p>Segmentation accuracy of napari-MM3 on published datasets from other groups [<xref ref-type="bibr" rid="c13">13</xref>,<xref ref-type="bibr" rid="c15">15</xref>,<xref ref-type="bibr" rid="c22">22</xref>,<xref ref-type="bibr" rid="c41">41</xref>]. As exact boundaries are difficult to determine by eye, a cell was considered to be correctly segmented if the Intersection over Union of the predicted mask and ground truth mask was greater than 0.6 (Methods). The accuracy is the Jaccard Index i.e. the ratio of true positives (correctly identified cells) to the sum of true positives, false positives (identified cells which were not present in the ground truth data) and false negatives (ground truth cells which were not identified by the segmentation).</p></caption>
<graphic xlink:href="534286v3_tbl2.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s2e4">
<title>Comparison with other image analysis software</title>
<p>We also tested napari-MM3’s usability and performance against other popular software. We began by surveying a range of existing mother machine image analysis tools (<xref rid="tbl3" ref-type="table">Table 3</xref>). Some early analysis pipelines used one-dimensional segmentation methods [<xref ref-type="bibr" rid="c13">13</xref>,<xref ref-type="bibr" rid="c41">41</xref>], which perform adequately when cells are tightly confined in the growth channels. In recent years, many excellent general-purpose CNN-based cell segmentation tools have also been developed [<xref ref-type="bibr" rid="c16">16</xref>–<xref ref-type="bibr" rid="c19">19</xref>,<xref ref-type="bibr" rid="c42">42</xref>], which may be extended to process mother machine data.</p>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3:</label>
<caption><title>Overview of mother-machine image analysis tools.</title>
<p>A comparison of several published imaging methods. ‘2D’ or ‘1D’ segmentation indicates whether the cells are labeled in an image and analyzed in two dimensions, or projected onto a vertical axis and analyzed in one dimension. Several tools support the use of deep learning (in place of or in addition to classical computer vision techniques).</p></caption>
<graphic xlink:href="534286v3_tbl3.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
<p>In this work, we only tested mother-machine-specific pipelines. In particular, we constrained our analysis to DeLTA and BACMMAN, two excellent open-source mother machine-specific pipelines offering 2D segmentation and cell tracking, which are also well-documented and actively maintained. BACMMAN [<xref ref-type="bibr" rid="c15">15</xref>] performs 2D segmentation via traditional computer vision methods similar to those implemented in napari-MM3 and has recently added support for CNN-based segmentation as well [<xref ref-type="bibr" rid="c43">43</xref>]. DeLTA [<xref ref-type="bibr" rid="c12">12</xref>,<xref ref-type="bibr" rid="c22">22</xref>] uses the U-Net architecture for channel detection, cell segmentation, and cell tracking, with a mother machine-specific and general agar pad mode. We used BACMMAN, DeLTA, and napari-MM3 to analyze the same published dataset [<xref ref-type="bibr" rid="c10">10</xref>] consisting of <italic>E. coli</italic> MG1655 grown in minimal growth medium (MOPS 0.4% glycerol + 11 amino acids with ∼60 minute doubling time) [<xref ref-type="bibr" rid="c10">10</xref>]. Data processed in napari-MM3 was separately segmented with U-Net and traditional computer vision methods. We found that the pre-trained mother machine model provided with DeLTA did not generalize well to our data. However, after training a new model with representative data, we achieved accurate segmentation.</p>
<p>We compared the distributions and correlations of key physiological parameters generated by each analysis tool, motivated by our standard approach to single-cell physiology [<xref ref-type="bibr" rid="c5">5</xref>,<xref ref-type="bibr" rid="c10">10</xref>,<xref ref-type="bibr" rid="c32">32</xref>,<xref ref-type="bibr" rid="c45">45</xref>]. First, we confirmed that all four analysis methods yield essentially identical correlations between cell length at birth (S<sub>B</sub>) vs. (a) generation time (τ), (b) elongation rate (λ), and (c) the length added between birth and division (Δ) (<xref rid="fig4" ref-type="fig">Figure 4.3</xref>). Next, we compared the distributions of various physiological parameters. The CV (coefficient of variation) of a physiological parameter distribution is often taken to reflect the tightness of the underlying biological control. We have previously found [<xref ref-type="bibr" rid="c2">2</xref>,<xref ref-type="bibr" rid="c32">32</xref>] that the CVs of a set of physiological parameters (birth length, division length, length added between divisions, growth rate, generation time, and septum position) are invariant across growth conditions in <italic>E. coli</italic> and <italic>B. subtilis</italic>, and that the hierarchy of CVs is preserved across the two evolutionarily divergent species [<xref ref-type="bibr" rid="c2">2</xref>,<xref ref-type="bibr" rid="c32">32</xref>]. Here, we confirmed that the distributions of these physiological parameters are independent of the analysis methods (<xref rid="fig4" ref-type="fig">Figure 4.4</xref>). In particular, the hierarchy of CVs is preserved by all three methods tested. Last, while in this dataset the old-pole “mother” cells showed signs of aging (in particular, a reduced elongation rate), this aging phenotype is strain- and condition-dependent (<xref rid="figS3" ref-type="fig">Figure S3</xref>).</p>
</sec>
<sec id="s2e5">
<title>Systematic discrepancies in cell segmentation outputs</title>
<p>While we found that the correlations between physiological parameters were preserved across the different analysis methods (<xref rid="fig4" ref-type="fig">Figure 4.3</xref>), we also observed systematic discrepancies in the results obtained by different methods, including cell length at birth (S<sub>b</sub>), length at division (S<sub>d</sub>), and length added between birth and division (Δ) (<xref rid="fig4" ref-type="fig">Figure 4.4</xref>). In particular, napari-MM3’s classical segmentation method systematically generated larger cell masks than napari-MM3 U-Net, DeLTA, and BACMMAN (<xref rid="fig4" ref-type="fig">Figure 4.4</xref>). We focused on the discrepancies between the two MM3 outputs. Although the deviation between the two masks may not appear significant when individual masks are inspected by eye (<xref rid="fig5" ref-type="fig">Figure 5.1</xref>, <xref rid="figS2" ref-type="fig">Figure S2</xref>), the classical method yields cells that are 5%-10% larger at each time point than those returned by the U-Net method when averaging over an entire experiment with tens of thousands of cells tracked (<xref rid="fig5" ref-type="fig">Figure 5.2</xref>). Cell birth and division times are also systematically shifted in the classical method, as the expanded cell boundaries lead the algorithm to split cells 1-2 time frames later on average.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5:</label>
<caption><title>Effect of systematic deviation in segmentation output from different methods.</title>
<p>5.1. Otsu / random walker and U-Net segmentation masks. The classical method systematically yields masks that are 5%-10% larger than the other methods. 5.2. We confirmed that this discrepancy occurs consistently across the cell cycle. 5.3 We trained the Omnipose model on masks generated by either napari-MM3-Otsu or napari-MM3-U-Net separately. 5.4. The systematic discrepancy in the training data masks propagated to the output of the trained models.</p></caption>
<graphic xlink:href="534286v3_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The root of this discrepancy is as follows. Exact cell boundaries are difficult to distinguish by eye, and the classical methods tested here require the user to set threshold values that can systematically alter the measured cell size. Indeed, both MM3 and BACMMAN’s non-learning method (which also uses Otsu thresholding and a watershed / diffusion algorithm) - output different cell masks with their ‘default’ parameter settings. On the other hand, binary U-Net segmentation methods, such as those implemented in napari-MM3 and DeLTA, tend to output smaller cell sizes because the model must leave a gap between cells so that they are not stitched together (note this is not a fundamental limitation of U-Net, but a consequence of our implementation: see, e.g. [<xref ref-type="bibr" rid="c17">17</xref>] or [<xref ref-type="bibr" rid="c38">38</xref>] for more complex approaches which avoid this issue).</p>
</sec>
<sec id="s2e6">
<title>WYPIWYG (“What You Put Is What You Get”) in deep-learning-based image analysis</title>
<p>Given that classical methods are clearly sensitive to this threshold tuning, we predicted that deep-learning approaches would also be impacted [<xref ref-type="bibr" rid="c46">46</xref>,<xref ref-type="bibr" rid="c47">47</xref>]. We chose the recent cutting-edge segmentation model Omnipose and separately trained it on masks derived from the aforementioned Otsu segmentation output and masks from the napari-MM3 U-Net segmentation output. We chose Omnipose as it assigns different labels to different cells, and can thus segment cells with contiguous boundaries, in contrast to MM3 or DeLTA’s U-Net implementations. Indeed, we found that the systematic discrepancy in the training masks propagated to the output of the trained models: the Omnipose model trained on larger Otsu masks generated larger masks upon evaluation with the same data, while the Omnipose model trained on smaller U-Net masks output smaller masks (<xref rid="fig5" ref-type="fig">Figure 5.3</xref>). In computer science, the phrase “Garbage in, garbage out” denotes the concept that undesirable attributes in the input to a program will propagate to the output [<xref ref-type="bibr" rid="c48">48</xref>,<xref ref-type="bibr" rid="c49">49</xref>]. Here we propose a related notion WYPIWYG, or “what you put is what you get”. That is, at least for our setup, systematic differences in training data masks lead the model to learn different threshold intensity values and thus to systematically output larger or smaller masks. We emphasize this result does not reflect a flaw in Omnipose - whose performance we found impressive - but rather a well-studied feature of machine learning methods in general [<xref ref-type="bibr" rid="c46">46</xref>].</p>
</sec>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>In this study, we introduced a modular and interactive image analysis pipeline for mother machine experiments, and compared its effectiveness to other existing tools. Unlike its predecessors, napari-MM3 is equipped with an intuitive and modular interface, making it highly accessible to new users. Our main goal is to lower the barrier to entry in image analysis, which has been a primary obstacle in adopting the mother machine, and ultimately increase its user base.</p>
<p>Finally, we discuss common challenges faced by users new to high-throughput image analysis and give our prescriptions for overcoming them.</p>
<sec id="s3a">
<title>Validating results</title>
<p>We showed that distributions and correlations in key cell cycle parameters are invariant to the choice of analysis pipeline, provided that care is taken in parameter adjustment and postprocessing. However, this parallel processing of data is not feasible for every experiment. Instead, we suggest users can validate their results in the following ways:</p>
<p>1. A qualitative “eye test” is an important first step: one should always visually inspect one’s data. Often, this may be sufficient to establish whether the analysis is operating as expected.</p>
<p>2. When a more quantitative and systematic approach is needed, the user can compare the output of their analysis to a subset of manually annotated ‘ground truth’ images. Quantitative measures such as the Jaccard index [<xref ref-type="bibr" rid="c47">47</xref>] or dice index may be used. These metrics are particularly useful for comparing the results of different parameter choices in a given method, allowing the user to determine the combination that yields the most accurate segmentation or tracking results.</p>
<p>3. Verify that the averages calculated from single-cell measurements match the results of population-level control experiments.</p>
<p>4. When possible, filter for subsets of the data that are likely to reflect accurate segmentation and continuous tracking, such as cell lineages that are continuously tracked for the duration of the experiment.</p>
</sec>
<sec id="s3b">
<title>Choosing an image analysis tool</title>
<p>For many years, published and well-documented pipelines for mother machine image analysis were scarce, and existing software required extensive parameter reconfiguration, knowledge of image processing techniques, and programming experience to use effectively. In recent years, advances in deep learning have contributed to a rapidly growing set of image analysis tools that perform cell segmentation and tracking.</p>
<p>Inspired by previous reviews [<xref ref-type="bibr" rid="c47">47</xref>,<xref ref-type="bibr" rid="c50">50</xref>], we make the following suggestions for new users selecting a tool:</p>
<p>1. Tools that are actively maintained, with an easy way to contact the developer, will be more likely to work well and will be easier to troubleshoot than others.</p>
<p>2. Detailed documentation and tutorials are valuable, and will allow the user to troubleshoot the software without direct guidance from the developers.</p>
<p>3. Depending on the user’s level of comfort with coding, it may be beneficial to choose a tool that is implemented through a graphical user interface and does not require additional programming. Moreover, even for programmers, we found within our lab that introducing interactivity when necessary dramatically expedited the data analysis process.</p>
<p>4. Full stack (vertically integrated) tools that cover the entire analysis pipeline may save time and work, relative to those which only perform a portion of the needed analysis.</p>
<p>5. It is worthwhile to engage with the online community around the tool, if one exists. We have found the image.sc forum [<xref ref-type="bibr" rid="c51">51</xref>] valuable in the past, in particular for help with napari.</p>
<p>6. Consider whether the tool is open source or requires a license. With regard to this point, we encourage tool developers to avoid proprietary software such as MATLAB, which may not be accessible to all users. The open-source Java-based image-processing program ImageJ [<xref ref-type="bibr" rid="c52">52</xref>] has been a dominant tool in biological image analysis for many years. The recent growth of image analysis and machine learning tools in Python makes napari [<xref ref-type="bibr" rid="c30">30</xref>] an attractive alternative to ImageJ.</p>
</sec>
<sec id="s3c">
<title>Traditional computer vision vs. deep learning methods</title>
<p>A key choice many users will face is whether to use deep learning-based or traditional methods for image analysis. The field has increasingly shifted toward deep learning methods, and this shift will likely accelerate. While traditional computer vision methods remain useful, deep learning-based methods have a clear advantage in their ability to generalize quickly to new datasets.</p>
<p>In our lab, we have found that traditional computer vision techniques perform excellently on cell segmentation and tracking in the mother machine, subject to constraints on the experimental setup. However, such methods often require extensive reconfiguration or fail entirely when applied to data obtained under new biological conditions (different organisms, different cell morphology) and imaging conditions (varied illumination, microscope setup). Our own non-learning segmentation method performs well, provided that cells are tightly confined in the mother machine channels and do not move substantially. Prior to the adoption of deep learning methods, this requirement necessitated the design of different devices for cells grown in different growth conditions, as the cell width in some <italic>E. coli</italic> strain backgrounds varies with the population growth rate.</p>
<p>By contrast, the key strength of deep learning approaches is their ability to generalize to new conditions - whether to different illumination conditions, different types of input images (phase contrast, brightfield, fluorescence) or different organisms and cell types entirely. The main barrier to adoption of learning-based methods remains the construction of training data, which can be tedious and time-consuming. A training data set of 50 - 100 images comprising several hundred cells can be constructed in a few hours and will achieve passable segmentation on representative data. However, larger training sets on the order of thousands of images are preferable, and will yield improved model accuracy and generalizability. The time needed for annotation can be reduced by seeding the data with masks generated by classical methods - or iteratively seeding with U-Net output - and then refining the masks further by hand. Model performance and generalizability can often be significantly improved by augmenting training data via manipulations such as rotating or shearing, distorting the intensity profile, and adding noise. Nonetheless, we have found that even with extensive data augmentation, applying the U-Net segmentation to new experimental configurations or imaging conditions often requires retraining the model on an expanded dataset with more representative data. Ultimately, deep learning methods are only as good as the data they are trained on, and are most likely to fail when training data is insufficient, mislabeled, or not representative. Going forward, sharing of training sets and models [<xref ref-type="bibr" rid="c53">53</xref>] between different groups can facilitate progress and aid reproducibility.</p>
<p>In addition to deep learning-based segmentation, learning-based cell tracking in the mother machine has been implemented recently by multiple groups [<xref ref-type="bibr" rid="c12">12</xref>,<xref ref-type="bibr" rid="c38">38</xref>]. For cells growing unconstrained on 2D surfaces such as agar pads, U-Net tracking dramatically outperforms traditional methods [<xref ref-type="bibr" rid="c12">12</xref>]. However, for steady-state growth in the mother machine where cells are confined and constrained to move in one dimension, we have not found a significant difference between the performance of deep learning-based tracking and the non-learning tracking method implemented in MM3. In both cases, errors in tracking nearly always arise from errors in segmentation. However, deep learning-based tracking may offer an advantage in cases where cells may move substantially along the length of the channel, or undergo dramatic morphological changes such as filamentation.</p>
<p>Ultimately, for groups with existing analysis pipelines fine-tuned for specific organisms under specific imaging conditions to perform simple tasks such as segmentation and 1D tracking, there may be little incentive to switch to deep learning methods. However, for users looking to develop a new pipeline or analyze more complex data, the power and generality of deep learning tools will make them the method of choice.</p>
</sec>
<sec id="s3d">
<title>Should users worry about the systematic discrepancy in segmentation results between different methods?</title>
<p>Given the 5%-10% variance in the segmented bacterial cell size is comparable to the CVs of several physiological parameters (<xref rid="fig4" ref-type="fig">Figure 4</xref>), should researchers be concerned about the robustness of their results? The answer depends on the purpose of the image analysis.</p>
<p>If the research critically relies on the absolute cell size, such as cell-size control [<xref ref-type="bibr" rid="c10">10</xref>,<xref ref-type="bibr" rid="c32">32</xref>], the researcher must be aware of inherent limitations to the accuracy of spatial measurements from cell segmentation. These arise in part from the difficulty of consistently distinguishing cell boundaries by eye. Once a threshold is chosen, the choice will affect all analyzed cells systematically. This limitation applies to both deep learning (through the construction of training data) and traditional computer vision methods (through the manual input of a threshold value). For cell segmentation, the uncertainties are typically comparable to the pixel size of the images, rather than optical resolutions. For example, the pixel size in the images in <xref rid="fig5" ref-type="fig">Figure 5</xref> is 0.065 μm (for the camera pixel size 6.5 μm and 100X magnification), which is non-negligible for many commonly cultured bacterial cells with submicron cell widths - e.g., <italic>Enterobacterales, Pseudomonas, Bacillus subtilis</italic>, and <italic>Caulobacter crescentus</italic>. For most commercially available cameras and objective lenses used in quantitative bacterial cell biology, 10% should be taken as a conservative lower bound for uncertainty when comparing absolute spatial measurements of bacterial cell size.</p>
<p>Indeed, researchers should be particularly careful when comparing absolute measurements of cell size, e.g., at division or initiation of chromosome replication obtained by different groups using different image analysis methods. While absolute temporal measurements are more robust than spatial measurements (<xref rid="fig4" ref-type="fig">Figure 4.4</xref>), the differences in spatial measurements can propagate to the measured timing of, e.g., cell division. For instance, we observed that the classical method stitched cells together for slightly longer than the U-Net method did (<xref rid="fig5" ref-type="fig">Figure 5.2</xref>), but as this shift applied equally to birth and division, it did not affect the average cell generation time (<xref rid="fig4" ref-type="fig">Figure 4.4</xref>).</p>
<p>Fortunately, the examples mentioned above are extreme cases. For instance, the pixel-size uncertainties will reflect a smaller proportion of the cell size when imaging larger cells such as yeast or mammalian cells. Even in our research on single-cell bacterial physiology [<xref ref-type="bibr" rid="c2">2</xref>,<xref ref-type="bibr" rid="c10">10</xref>,<xref ref-type="bibr" rid="c32">32</xref>], we find that correlations and relative changes are more likely to be robust than absolute spatial measurements to the choice of analysis method (<xref rid="fig4" ref-type="fig">Figure 4</xref>). Furthermore, different applications of deep-learning based image analysis, such as high-throughput phenotypic classification [<xref ref-type="bibr" rid="c54">54</xref>] will be much more robust to the pixel-size uncertainties in image segmentation results.</p>
</sec>
<sec id="s3e">
<title>Generating robust and unbiased segmentation results</title>
<p>We have shown that both traditional computer vision and deep learning methods are susceptible to biases introduced by imprecise thresholding and human error. How, then, can more precise cell boundaries be determined? For non-learning methods, thresholds could be calibrated against data from alternate imaging methods such as fluorescence or brightfield. For learning methods, one promising technique is the generation of synthetic training data [<xref ref-type="bibr" rid="c55">55</xref>]. This method also has the advantage that new training datasets can be instantaneously for different imaging conditions or cell types, once the appropriate parameters have been determined. For deep learning methods, metrics which lead the model to recognize cell interiors or centers [<xref ref-type="bibr" rid="c18">18</xref>,<xref ref-type="bibr" rid="c38">38</xref>,<xref ref-type="bibr" rid="c56">56</xref>] may yield more robust results than binary pixel-level classification. Once cell centers are known, boundaries can be determined relatively easily via classical watershed or random walker diffusion algorithms.</p>
</sec>
<sec id="s3f">
<title>Conclusion and recommendations</title>
<p>Here, we presented a guide to first-time users of the mother machine, introduced our updated image analysis software, and validated it against existing tools. napari-MM3 provides a simple and modular user-friendly interface, which we believe makes it uniquely accessible and valuable to novice users. By lowering the barrier to entry in image analysis - the key bottleneck in mother machine adoption - we aim to increase the user base of this powerful tool dramatically.</p>
<p>After testing two other well-constructed mother machine image analysis pipelines, we concluded that all four methods (BACMMAN, DeLTA, MM3 Otsu &amp; MM3 U-Net) yielded consistent and reproducible results, up to previously discussed limitations of segmentation algorithms. Thus, for users already comfortable with a given pipeline, there is no strong incentive to switch to a new one. However, the different pipelines do have markedly different user interfaces. DeLTA is set up to provide a simple “one-shot” analysis, in which image preprocessing, channel detection, segmentation, and tracking are performed in sequence with minimal user input. This arrangement simplifies the analysis process, especially for first-time users. In particular, it can be helpful for users who want to quickly verify that the software will serve their purpose, before investing more time in setting up and running the analysis. On the other hand, the intermediate steps in the pipeline are less accessible, which may make debugging and troubleshooting more involved. BACMMAN, like napari-MM3, is more modular than DeLTA. This modularity can aid troubleshooting and improves versatility, but configuration can be time consuming. With napari-MM3, we attempted to strike a balance between these two well-designed and well-performing tools, while taking advantage of the fast-growing next-generation image analysis platform napari. napari-MM3 attempts to infer or pre-set as many parameters as possible, while the napari interface makes midstream output easily accessible. We have been using MM3, and more recently napari-MM3, for over a decade since our introduction of the mother machine in 2010, and we will continue to actively maintain and improve it in the coming years.</p>
<p>The mother machine setup has become increasingly accessible to researchers in recent years, through the distribution of molds and the publication of in-depth protocols and open-source image analysis software. At the same time, new variations of the device have found diverse applications, including bacterial starvation [<xref ref-type="bibr" rid="c6">6</xref>], and genetic screening [<xref ref-type="bibr" rid="c57">57</xref>,<xref ref-type="bibr" rid="c58">58</xref>]. Clearly, the combination of microfluidics with high-resolution time-lapse imaging remains powerful among single-cell techniques. We hope that this article will prove useful to mother machine veterans and first-time users alike.</p>
</sec>
</sec>
</body>
<back>
<sec id="s4">
<title>Acknowledgements</title>
<p>This work has been made possible in part by CZI grant DAF2021-239849 and grant DOI [<xref ref-type="bibr" rid="c59">59</xref>] from the Chan Zuckerberg Initiative DAF, an advised fund of Silicon Valley Community Foundation (funder DOI 10.13039/100014989) . The work was also supported by NIH grant R35GM139622 and NSF grant MCB-2016090.</p>
<p>We thank Mara Casebeer, Thias Boesen, and the members of the Jun Lab for testing and debugging napari-MM3. We also thank Kevin Cutler for helping us to install Omnipose and run it on our data.</p>
</sec>
<sec id="s5">
<title>Methods</title>
<sec id="s5a">
<title>Resources</title>
<list list-type="bullet">
<list-item><p>napari-MM3 Github repository [<xref ref-type="bibr" rid="c60">60</xref>].</p>
<list list-type="bullet">
<list-item><p>Contains installation instructions and video tutorial.</p></list-item></list></list-item>
<list-item><p>Jupyter notebook demonstrating analysis of MM3 output data. [<xref ref-type="bibr" rid="c37">37</xref>]</p>
<list list-type="bullet">
<list-item><p>A notebook providing functions for postprocessing and plotting of the napari-MM3 output</p></list-item></list></list-item>
<list-item><p>Protocols for device fabrication and loading [<xref ref-type="bibr" rid="c28">28</xref>]</p></list-item>
<list-item><p>Raw and processed data analyzed in this manuscript [<xref ref-type="bibr" rid="c44">44</xref>]</p></list-item>
</list>
</sec>
<sec id="s5b">
<title>Getting started with napari-MM3</title>
<p>napari-MM3 is implemented entirely in Python and can be accessed on Github [<xref ref-type="bibr" rid="c60">60</xref>], along with documentation covering installation and usage. It will run on a standard Mac, PC, or Linux machine. We recommend using the Anaconda Python distribution to simplify installation.</p>
</sec>
<sec id="s5c">
<title>Imaging conditions</title>
<p>The data analyzed in <xref rid="fig4" ref-type="fig">Figures 4</xref> and <xref rid="fig5" ref-type="fig">5</xref> (originally published in [<xref ref-type="bibr" rid="c10">10</xref>]) was obtained on an inverted microscope (Nikon Ti-E) with Perfect Focus 3 (PFS3), 100x oil immersion objective (PH3, numerical aperture = 1.45), and Obis laser 488LX (Coherent Inc., CA) as a fluorescence light source, and an Andor NEO sCMOS (Andor Technology) camera. The laser power was 18 mW. The exposure time was 200 ms for phase contrast imaging and 50 ms for fluorescence.</p>
</sec>
<sec id="s5d">
<title>Image analysis for software comparison</title>
<p>For the software comparison in <xref rid="fig4" ref-type="fig">Figure 4</xref>, we analyzed a dataset from [<xref ref-type="bibr" rid="c10">10</xref>] consisting of <italic>E. coli</italic> MG1655 expressing a fluorescent protein YPet fused to the replisome protein DnaN. The cells were grown in MOPS minimal medium + glycerol and 11 amino acids. The dataset was analyzed end-to-end starting from the raw .nd2 file with BACMMAN, DeLTA, and MM3. For analysis with DeLTA, we used the provided channel detection and tracking models but trained a new model on our own data for segmentation. For segmentation with BACMMAN, we used the standard non-learning phase contrast segmentation method ‘MicrochannelPhase2D’. Postprocessing of the output of each pipeline was done in Python. For each pipeline, we filtered for cells whose mothers and daughters were also tracked.</p>
<p>The code and data to reproduce the plots in <xref rid="fig4" ref-type="fig">Figure 4</xref> are available at [<xref ref-type="bibr" rid="c37">37</xref>] and [<xref ref-type="bibr" rid="c44">44</xref>], respectively.</p>
<p>For the comparison of Otsu and U-Net outputs from Omnipose in <xref rid="fig5" ref-type="fig">Figure 5</xref>, we trained Omnipose with a learning rate of .01 without a pre-trained model. We used the same set of 1000 randomly selected images for both Otsu and U-Net, the only difference coming from the labeled masks themselves. Both models were trained until the loss dipped below 0.9 (390 epochs for U-Net, 210 epochs for Otsu). In some cases, the model “hallucinated” cells along the channel features. We excluded these images from the final analysis.</p>
</sec>
<sec id="s5e">
<title>Analysis of external datasets</title>
<p>The external datasets were preprocessed as follows: BACMMAN, MoMa and molyso datasets were rotated 1-2 degrees to align the channels vertically. BACMMAN, molyso and DeLTA datasets were cropped to remove imaging artifacts from the main trench.</p>
<p>The segmentation accuracy of napari-MM3 was quantified as follows: we computed the Jaccard Index as the ratio of true positives (correctly identified cells) to the sum of true positives, false positives (identified cells which were not present in the ground truth data) and false negatives (ground truth cells which were not identified by the segmentation). The segmentation and ground truth masks were determined to be matching if their Intersection over Union value was at least 0.6 (note that two masks become indistinguishable to the human eye at IoU 0.8 and higher [<xref ref-type="bibr" rid="c18">18</xref>,<xref ref-type="bibr" rid="c47">47</xref>]).</p>
<p>The output JSON file and kymographs showing reconstructed cell lineages from each sample datasets are available at [<xref ref-type="bibr" rid="c44">44</xref>], along with JSON files containing the parameter values used for each step of the analyses.</p>
</sec>
<sec id="s5f">
<title>U-Net model training</title>
<p>Training data was augmented as described below to aid the generalizability of the model. We trained the U-Net model using a pixel-wise weighted binary cross-entropy loss function, as implemented in DeLTA [<xref ref-type="bibr" rid="c22">22</xref>]. The model was trained using the Adam optimizer with a learning rate of 10<sup>-4</sup>, a dropout rate of 50%, a batch size of 8 samples, a patience (early stopping value) of 50 epochs and a train-test split of 90-10.</p>
</sec>
<sec id="s5g">
<title>Overview of the MM3 pipeline</title>
<sec id="s5h">
<title>Channel compilation and designation</title>
<p>The first section of the MM3 pipeline takes in raw micrographs and returns image stacks corresponding to one growth channel over time. Further pipeline operations are then applied to these stacks.</p>
<p>A standard mother machine experiment consists of thousands of images across multiple fields of view (FOVs) and many time points. Images are first collated based on the available metadata. MM3 expects TIFF files and looks for metadata in the TIFF header and from the file name.</p>
<p>All images from a particular FOV are analyzed for the location of channels using the phase contrast plane. Channel detection is performed using a wavelet transform, in which a mask is made which is applied across all time points. Channels are cropped through time using the masks and saved as unique image stacks that include all time points for a given channel and imaging plane. MM3 saves channel stacks in TIFF format.</p>
<p>MM3 attempts to compile all channels. However, not all channels contain cells, and some channels may have undesirable artifacts from the device preparation. It is, therefore, desirable to only process certain channels for analysis. Consequently, MM3 auto-detects empty and full channels based on the time correlation of the y-profile of the channel (empty channels are highly correlated in time, while channels containing cells are not). The autodetected channels and their classifications are then displayed in the napari viewer for the user to inspect and modify as needed. The user may also manually select empty channels free of artifacts to be used as templates for phase or fluorescence background subtraction.</p>
</sec>
</sec>
<sec id="s5i">
<title>Background subtraction</title>
<p>MM3’s Otsu segmentation method requires background subtraction of phase contrast images. The subtraction ensures that the presence of the channel border does not interfere with detection of cells. To this end, we overlay the previously-identified empty channels on the full channels to be subtracted. The two channels are aligned such that the cross-correlation of overlaid pixels is maximized. After the inversion of the image, this leaves the cells as the only bright objects on a dark background. Good alignment of the device features in the empty and full channel is essential here. Imperfect alignment will leave artifacts in the subtracted image, which interfere with later steps, and is a common failure point for this method. Note that the subtraction step necessitates the presence of some empty channels in each experiment. The U-Net segmentation does not require background subtraction.</p>
</sec>
<sec id="s5j">
<title>Cell segmentation</title>
<p>Cell segmentation is the first of the two major tasks in the image analysis pipeline. Segmentation receives channel stacks and produces 8-bit segmented image stacks. Typically, segmentation is done using the phase contrast time-collated stack.</p>
<p>MM3 has two methods for segmentation: a “standard” method and a supervised learning method. The standard method uses traditional image analysis techniques, specifically background subtraction, Otsu thresholding, morphological operations, and watershed algorithms. As the standard method may require fine-tuning of parameters, the napari plugin allows the user to quickly preview the effect of tuning morphological parameters and threshold value on the segmentation output, without having to process the entire dataset. The Otsu segmentation method first aligns the channel of interest with an empty background channel by computing the orientation, which maximizes the pixel-wise cross-correlation. The empty channel is then subtracted from the full channel, and the image is inverted. Otsu’s method is then applied to find the binary threshold value which maximizes the inter-region variance (or equivalently, minimizes the intra-region variance). We then apply a Euclidean distance transform, in which each pixel is labeled with its distance to the dark region. The image is thresholded again, and a morphological opening is applied to erode links between regions. Small objects and objects touching the image border are removed. Each region is labeled, and the labels are used to seed a random walker algorithm [<xref ref-type="bibr" rid="c34">34</xref>] on the original image. As implemented in MM3, this “standard” method has three adjustable parameters: the first opening pixel size, second opening pixel size, distance threshold (i.e. threshold which is applied to the distance transformed image, in pixels) and a dimensionless parameter to rescale the Otsu-determined threshold, if needed.</p>
<p>The supervised learning method uses a standard U-Net architecture with five levels [<xref ref-type="bibr" rid="c21">21</xref>]. The model outputs a cell class probability between 0 and 1 for each pixel, which is thresholded at 0.5 to obtain a binary segmentation. The napari viewer can be used to construct training data, with the option to import existing Otsu or U-Net segmentation output as a template. The neural net can then be trained using a separate widget, with the option to check the performance of the model in the napari viewer after successive rounds of training. We found that applying a weighted loss depending on pixel location - as suggested in the original U-Net paper [<xref ref-type="bibr" rid="c21">21</xref>] and implemented for instance in DeLTA [<xref ref-type="bibr" rid="c22">22</xref>] - sped up model training and improved segmentation and tracking. Since the accurate separation of adjacent cells is vital for cell tracking, the cost of misidentifying pixels between bordering cells is high. We initially implemented a simple binary weight map where pixels between cells were weighted highly and all others pixels relatively lower. We later added a more complex mapping, drawing directly from the one implemented in DeLTA [<xref ref-type="bibr" rid="c12">12</xref>], where weights are maximized on the skeletons [<xref ref-type="bibr" rid="c61">61</xref>] of the cells and borders. Intuitively, this weighting tells the model that pixels in the center of the cell, in regions far from cells, and on the borders between cells are most important to predict accurately.</p>
<p>Illumination conditions can vary across laboratories, microbial species, and with device design. To aid the generalizability of the U-Net model, on specific conditions, we augmented the training data with various morphological techniques, including changing magnification, zooming and rotating, and Gaussian noise and blur. We also adapted several non-standard operations from DeLTA, one which performs elastic deformation and two others that distort image contrast to simulate changes in illumination within the field of view and between experiments.</p>
</sec>
<sec id="s5k">
<title>Cell tracking</title>
<p>Tracking segmented cells is the second major task in the pipeline. Tracking involves linking cell segments in time in order to define a lineage of cell objects. The default tracking method is a simple decision tree based on <italic>a priori</italic> knowledge of binary fission and the mother machine. For example, cells normally grow by a small amount between time intervals, divide into two similarly sized daughter cells, and cannot pass each other in the channel. The tracking method accounts for the absolute positions and relative ordering of cells in each channel over time. Specifically, at each time point we iterate over all detected regions (potential cells). Based on their relative y positions in the channel and sizes, each is linked to a set of potential descendants / ancestors. When two cells are best matched to the same region, the event is classified as a division, subject to constraints on the size of the regions. This tracking implementation is similar to that employed by BACMMAN [<xref ref-type="bibr" rid="c15">15</xref>] although it does not explicitly take into account relative ordering of cells in the channel. It contrasts with more complex optimization-based methods used by other mother machine software[<xref ref-type="bibr" rid="c13">13</xref>][<xref ref-type="bibr" rid="c13">13</xref>,<xref ref-type="bibr" rid="c41">41</xref>].</p>
<p>The lineage tree obtained by tracking is displayed in the napari viewer in the form of a kymograph, in which the x-axis represents time, and cell linkages and divisions are indicated by forking lines.</p>
</sec>
<sec id="s5l">
<title>Data output and analysis</title>
<p>Tracking produces a dictionary of cell objects which contains relevant information derived from the cell segments. This includes, but is not limited to, birth and division size, growth rate, and generation time. Each object is identified by a key that represents the FOV and channel of the cell, the time point of its birth, and its position in the channel. Since each cell object has the requisite information to find its corresponding position in the channel stacks, the objects can be modified and extended by additional analysis. For example, the corresponding location of a cell in a fluorescent image stack can be retrieved, focus detection performed, and that information can be added to the cell object. This minimizes the burden of rerunning previous sections of the pipeline for new sub-analyses.</p>
<p>Plotting can be done from this cell object dictionary directly, or it can first be converted to a .csv, a pandas DataFrame, or a MATLAB structure. We provide a Jupyter notebook [<xref ref-type="bibr" rid="c37">37</xref>] to illustrate how the data can be extracted and plotted.</p>
</sec>
<sec id="s5m">
<title>Fluorescence analysis</title>
<p>Integrated fluorescence signal and fluorescence per cell area and volume for each timepoint can be extracted using the Colors module.</p>
</sec>
<sec id="s5n">
<title>Focus tracking</title>
<p>The focus tracking module enables the identification and tracking of fluorescent spots or ‘foci.’ This module has been used in our lab for tracking fluorescently labeled replisome machinery in bacteria in order to measure the timing and synchrony of DNA replication initiation. However, it may be applied to any use case requiring localization and tracking of intracellular spots. The module uses a Laplacian convolution to identify fluorescent spots. Foci are linked to the cell objects in which they appear.</p>
</sec>
<sec id="s5o">
<title>U-Net training data annotation</title>
<p>Training data can be constructed by manual annotation of raw images in the napari viewer. MM3 offers the option to construct training data with existing (Otsu or U-Net) segmentation data as a template. This allows the user to iteratively train a model, correct mistakes in its output, and use the modified output as input for the next round of training.</p>
<fig id="figS1" position="float" fig-type="figure">
<label>Figure S1.</label>
<caption><title>Inexpensive fabrication of cell loader with 3D printing.</title>
<p>An inexpensive device for loading cells into the mother machine. The construction involves 3D printing a custom holder/ rotor for a 50mm WillCo dish, on which a mother machine is attached. The holder is printed in three parts (2 blades and a central base) to account for 3D printers with small printing areas. This piece is then assembled and secured to a Honeywell fan from which the original blade has been removed. CAD files and details of the fan centrifuge construction are available at [<xref ref-type="bibr" rid="c28">28</xref>].</p></caption>
<graphic xlink:href="534286v3_figS1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS2" position="float" fig-type="figure">
<label>Figure S2:</label>
<caption><title>Segmentation accuracy of napari-MM3 Otsu and U-Net methods</title>
<p>To quantify the accuracy of the segmentation masks generated by MM3’s Otsu and U-Net segmentation methods, we computed the Jaccard Index [<xref ref-type="bibr" rid="c47">47</xref>,<xref ref-type="bibr" rid="c50">50</xref>] as a function of the intersection-over-union (IoU) threshold.</p></caption>
<graphic xlink:href="534286v3_figS2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="figS3" position="float" fig-type="figure">
<label>Figure S3:</label>
<caption><title>Old-pole aging phenotype is strain specific.</title>
<p>Cells imaged with fluorescence often show signs of aging in the old-pole “mother” cell. For instance, in the dataset analyzed in <xref rid="fig4" ref-type="fig">Figure 4</xref> (<italic>E. coli</italic> MG1655 with the fluorescent protein YPet fused to DnaN), we observed systematic differences in cell elongation rate and size between the old-pole cell at the end of the growth channel and its sisters, which inherit the new pole (top center). However, this asymmetry is not universal. Using napari-MM3’s Otsu segmentation method, we re-analyzed previously published data obtained without fluorescence illumination [<xref ref-type="bibr" rid="c32">32</xref>], and found that the old-pole and new-pole cell elongation rates varied only on the order of 1% (lower center), while in the dataset obtained under fluorescence imaging, the old-pole mother cells grow 7-10% slower than the new pole cells. These results are consistent with a previous survey [<xref ref-type="bibr" rid="c62">62</xref>], which found that most evidence for aging in <italic>E. coli</italic> comes from studies utilizing fluorescent proteins for visualization.</p></caption>
<graphic xlink:href="534286v3_figS3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>Wang</surname> <given-names>P</given-names></string-name>, <string-name><surname>Robert</surname> <given-names>L</given-names></string-name>, <string-name><surname>Pelletier</surname> <given-names>J</given-names></string-name>, <string-name><surname>Dang</surname> <given-names>WL</given-names></string-name>, <string-name><surname>Taddei</surname> <given-names>F</given-names></string-name>, <string-name><surname>Wright</surname> <given-names>A</given-names></string-name>, <etal>et al.</etal> <article-title>Robust growth of Escherichia coli</article-title>. <source>Curr Biol</source>. <year>2010</year>;<volume>20</volume>: <fpage>1099</fpage>–<lpage>1103</lpage>.</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Sauls</surname> <given-names>JT</given-names></string-name>, <string-name><surname>Cox</surname> <given-names>SE</given-names></string-name>, <string-name><surname>Do</surname> <given-names>Q</given-names></string-name>, <string-name><surname>Castillo</surname> <given-names>V</given-names></string-name>, <string-name><surname>Ghulam-Jelani</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Jun</surname> <given-names>S.</given-names></string-name> <article-title>Control of Bacillus subtilis Replication Initiation during Physiological Transitions and Perturbations</article-title>. <source>MBio</source>. <year>2019</year>;<volume>10</volume>. doi:<pub-id pub-id-type="doi">10.1128/mBio.02205-19</pub-id></mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>Nakaoka</surname> <given-names>H</given-names></string-name>, <string-name><surname>Wakamoto</surname> <given-names>Y.</given-names></string-name> <article-title>Aging, mortality, and the fast growth trade-off of Schizosaccharomyces pombe</article-title>. <source>PLoS Biol</source>. <year>2017</year>;<volume>15</volume>: <fpage>1</fpage>–<lpage>29</lpage>.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Spivey</surname> <given-names>EC</given-names></string-name>, <string-name><surname>Jones</surname> <given-names>SK</given-names></string-name>, <string-name><surname>Rybarski</surname> <given-names>JR</given-names></string-name>, <string-name><surname>Saifuddin</surname> <given-names>FA</given-names></string-name>, <string-name><surname>Finkelstein</surname> <given-names>IJ</given-names></string-name>. <article-title>An aging-independent replicative lifespan in a symmetrically dividing eukaryote</article-title>. <source>Elife</source>. <year>2017</year>;<volume>6</volume>: <fpage>1</fpage>–<lpage>25</lpage>.</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Jun</surname> <given-names>S</given-names></string-name>, <string-name><surname>Si</surname> <given-names>F</given-names></string-name>, <string-name><surname>Pugatch</surname> <given-names>R</given-names></string-name>, <string-name><surname>Scott</surname> <given-names>M.</given-names></string-name> <article-title>Fundamental principles in bacterial physiology—history, recent progress, and the future with focus on cell size control: a review</article-title>. <source>Rep Prog Phys</source>. <year>2018</year>;<volume>81</volume>: <fpage>056601</fpage>.</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Bakshi</surname> <given-names>S</given-names></string-name>, <string-name><surname>Leoncini</surname> <given-names>E</given-names></string-name>, <string-name><surname>Baker</surname> <given-names>C</given-names></string-name>, <string-name><surname>Cañas-Duarte</surname> <given-names>SJ</given-names></string-name>, <string-name><surname>Okumus</surname> <given-names>B</given-names></string-name>, <string-name><surname>Paulsson</surname> <given-names>J.</given-names></string-name> <article-title>Tracking bacterial lineages in complex and dynamic environments with applications for growth control and persistence</article-title>. <source>Nat Microbiol</source>. <year>2021</year>;<volume>6</volume>: <fpage>783</fpage>–<lpage>791</lpage>.</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Kaplan</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Reich</surname> <given-names>S</given-names></string-name>, <string-name><surname>Oster</surname> <given-names>E</given-names></string-name>, <string-name><surname>Maoz</surname> <given-names>S</given-names></string-name>, <string-name><surname>Levin-Reisman</surname> <given-names>I</given-names></string-name>, <string-name><surname>Ronin</surname> <given-names>I</given-names></string-name>, <etal>et al.</etal> <article-title>Observation of universal ageing dynamics in antibiotic persistence</article-title>. <source>Nature</source>. <year>2021</year>;<volume>600</volume>: <fpage>290</fpage>–<lpage>294</lpage>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Russell</surname> <given-names>JR</given-names></string-name>, <string-name><surname>Cabeen</surname> <given-names>MT</given-names></string-name>, <string-name><surname>Wiggins</surname> <given-names>PA</given-names></string-name>, <string-name><surname>Paulsson</surname> <given-names>J</given-names></string-name>, <string-name><surname>Losick</surname> <given-names>R.</given-names></string-name> <article-title>Noise in a phosphorelay drives stochastic entry into sporulation in Bacillus subtilis</article-title>. <source>EMBO J</source>. <year>2017</year>;<volume>36</volume>: <fpage>2856</fpage>–<lpage>2869</lpage>.</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Amir</surname> <given-names>A</given-names></string-name>, <string-name><surname>Babaeipour</surname> <given-names>F</given-names></string-name>, <string-name><surname>McIntosh</surname> <given-names>DB</given-names></string-name>, <string-name><surname>Nelson</surname> <given-names>DR</given-names></string-name>, <string-name><surname>Jun</surname> <given-names>S.</given-names></string-name> <article-title>Bending forces plastically deform growing bacterial cell walls</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2014</year>;<volume>111</volume>: <fpage>5778</fpage>–<lpage>5783</lpage>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Si</surname> <given-names>F</given-names></string-name>, <string-name><surname>Le Treut</surname> <given-names>G</given-names></string-name>, <string-name><surname>Sauls</surname> <given-names>JT</given-names></string-name>, <string-name><surname>Vadia</surname> <given-names>S</given-names></string-name>, <string-name><surname>Levin</surname> <given-names>PA</given-names></string-name>, <string-name><surname>Jun</surname> <given-names>S.</given-names></string-name> <article-title>Mechanistic Origin of Cell-Size Control and Homeostasis in Bacteria</article-title>. <source>Curr Biol</source>. <year>2019</year>;<volume>29</volume>: <fpage>1760</fpage>–<lpage>1770</lpage>.e7.</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>Stewart</surname> <given-names>EJ</given-names></string-name>, <string-name><surname>Madden</surname> <given-names>R</given-names></string-name>, <string-name><surname>Paul</surname> <given-names>G</given-names></string-name>, <string-name><surname>Taddei</surname> <given-names>F.</given-names></string-name> <article-title>Aging and death in an organism that reproduces by morphologically symmetric division</article-title>. <source>PLoS Biol</source>. <year>2005</year>;<volume>3</volume>: <fpage>e45</fpage>.</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>O’Connor</surname> <given-names>OM</given-names></string-name>, <string-name><surname>Alnahhas</surname> <given-names>RN</given-names></string-name>, <string-name><surname>Lugagne</surname> <given-names>J-B</given-names></string-name>, <string-name><surname>Dunlop</surname> <given-names>MJ</given-names></string-name>. <article-title>DeLTA 2.0: A deep learning pipeline for quantifying single-cell spatial and temporal dynamics</article-title>. <source>PLoS Comput Biol</source>. <year>2022</year>;<volume>18</volume>: <fpage>e1009797</fpage>.</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Sachs</surname> <given-names>CC</given-names></string-name>, <string-name><surname>Grünberger</surname> <given-names>A</given-names></string-name>, <string-name><surname>Helfrich</surname> <given-names>S</given-names></string-name>, <string-name><surname>Probst</surname> <given-names>C</given-names></string-name>, <string-name><surname>Wiechert</surname> <given-names>W</given-names></string-name>, <string-name><surname>Kohlheyer</surname> <given-names>D</given-names></string-name>, <etal>et al.</etal> <article-title>Image-Based Single Cell Profiling: High-Throughput Processing of Mother Machine Experiments</article-title>. <source>PLoS One</source>. <year>2016</year>;<volume>11</volume>: <fpage>e0163453</fpage>.</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><string-name><surname>Smith</surname> <given-names>A</given-names></string-name>, <string-name><surname>Metz</surname> <given-names>J</given-names></string-name>, <string-name><surname>Pagliara</surname> <given-names>S.</given-names></string-name> <article-title>MMHelper: An automated framework for the analysis of microscopy images acquired with the mother machine</article-title>. <source>Sci Rep</source>. <year>2019</year>;<volume>9</volume>: <fpage>10123</fpage>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Ollion</surname> <given-names>J</given-names></string-name>, <string-name><surname>Elez</surname> <given-names>M</given-names></string-name>, <string-name><surname>Robert</surname> <given-names>L.</given-names></string-name> <article-title>High-throughput detection and tracking of cells and intracellular spots in mother machine experiments</article-title>. <source>Nat Protoc</source>. <year>2019</year>;<volume>14</volume>: <fpage>3144</fpage>–<lpage>3161</lpage>.</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>Stylianidou</surname> <given-names>S</given-names></string-name>, <string-name><surname>Brennan</surname> <given-names>C</given-names></string-name>, <string-name><surname>Nissen</surname> <given-names>SB</given-names></string-name>, <string-name><surname>Kuwada</surname> <given-names>NJ</given-names></string-name>, <string-name><surname>Wiggins</surname> <given-names>PA</given-names></string-name>. <article-title>SuperSegger: robust image segmentation, analysis and lineage tracking of bacterial cells</article-title>. <source>Mol Microbiol</source>. <year>2016</year>;<volume>102</volume>: <fpage>690</fpage>–<lpage>700</lpage>.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><surname>Panigrahi</surname> <given-names>S</given-names></string-name>, <string-name><surname>Murat</surname> <given-names>D</given-names></string-name>, <string-name><surname>Le Gall</surname> <given-names>A</given-names></string-name>, <string-name><surname>Martineau</surname> <given-names>E</given-names></string-name>, <string-name><surname>Goldlust</surname> <given-names>K</given-names></string-name>, <string-name><surname>Fiche</surname> <given-names>J-B</given-names></string-name>, <etal>et al.</etal> <article-title>Misic, a general deep learning-based method for the high-throughput cell segmentation of complex bacterial communities</article-title>. <source>Elife</source>. <year>2021</year>;<volume>10</volume>. doi:<pub-id pub-id-type="doi">10.7554/eLife.65151</pub-id></mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="other"><string-name><surname>Cutler</surname> <given-names>KJ</given-names></string-name>, <string-name><surname>Stringer</surname> <given-names>C</given-names></string-name>, <string-name><surname>Wiggins</surname> <given-names>PA</given-names></string-name>, <string-name><surname>Mougous</surname> <given-names>JD</given-names></string-name>. <article-title>Omnipose: a high-precision morphology-independent solution for bacterial cell segmentation</article-title>. <source>Nat Methods</source>. <year>2022</year>; 2021.11.03.467199.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><surname>Spahn</surname> <given-names>C</given-names></string-name>, <string-name><surname>Gómez-de-Mariscal</surname> <given-names>E</given-names></string-name>, <string-name><surname>Laine</surname> <given-names>RF</given-names></string-name>, <string-name><surname>Pereira</surname> <given-names>PM</given-names></string-name>, <string-name><surname>von Chamier</surname> <given-names>L</given-names></string-name>, <string-name><surname>Conduit</surname> <given-names>M</given-names></string-name>, <etal>et al.</etal> <article-title>DeepBacs for multi-task bacterial image analysis using open-source deep learning approaches</article-title>. <source>Commun Biol</source>. <year>2022</year>;<volume>5</volume>: <fpage>688</fpage>.</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="other"><string-name><surname>Moen</surname> <given-names>E</given-names></string-name>, <string-name><surname>Borba</surname> <given-names>E</given-names></string-name>, <string-name><surname>Miller</surname> <given-names>G</given-names></string-name>, <string-name><surname>Schwartz</surname> <given-names>M</given-names></string-name>, <string-name><surname>Bannon</surname> <given-names>D</given-names></string-name>, <string-name><surname>Koe</surname> <given-names>N</given-names></string-name>, <etal>et al.</etal> <article-title>Accurate cell tracking and lineage construction in live-cell imaging experiments with deep learning</article-title>. <source>bioRxiv</source>. <year>2019</year>. p. <fpage>803205</fpage>. doi:<pub-id pub-id-type="doi">10.1101/803205</pub-id></mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Ronneberger</surname> <given-names>O</given-names></string-name>, <string-name><surname>Fischer</surname> <given-names>P</given-names></string-name>, <string-name><surname>Brox</surname> <given-names>T.</given-names></string-name> <article-title>U-net: Convolutional networks for biomedical image segmentation</article-title>. <source>Lect Notes Comput Sci</source>. <year>2015</year>;<volume>9351</volume>: <fpage>234</fpage>–<lpage>241</lpage>.</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>Lugagne</surname> <given-names>JB</given-names></string-name>, <string-name><surname>Lin</surname> <given-names>H</given-names></string-name>, <string-name><surname>Dunlop</surname> <given-names>MJ</given-names></string-name>. <article-title>Delta: Automated cell segmentation, tracking, and lineage reconstruction using deep learning</article-title>. <source>PLoS Comput Biol</source>. <year>2020</year>;<volume>16</volume>: <fpage>1</fpage>–<lpage>18</lpage>.</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Taheri-Araghi</surname> <given-names>S</given-names></string-name>, <string-name><surname>Brown</surname> <given-names>SD</given-names></string-name>, <string-name><surname>Sauls</surname> <given-names>JT</given-names></string-name>, <string-name><surname>McIntosh</surname> <given-names>DB</given-names></string-name>, <string-name><surname>Jun</surname> <given-names>S.</given-names></string-name> <article-title>Single-Cell Physiology</article-title>. <source>Annu Rev Biophys</source>. <year>2015</year>;<volume>44</volume>: <fpage>123</fpage>–<lpage>142</lpage>.</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><surname>Allard</surname> <given-names>P</given-names></string-name>, <string-name><surname>Papazotos</surname> <given-names>F</given-names></string-name>, <string-name><surname>Potvin-Trottier</surname> <given-names>L.</given-names></string-name> <article-title>Microfluidics for long-term single-cell time-lapse microscopy: Advances and applications</article-title>. <source>Front Bioeng Biotechnol</source>. <year>2022</year>;<volume>10</volume>: <fpage>968342</fpage>.</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Potvin-Trottier</surname> <given-names>L</given-names></string-name>, <string-name><surname>Luro</surname> <given-names>S</given-names></string-name>, <string-name><surname>Paulsson</surname> <given-names>J.</given-names></string-name> <article-title>Microfluidics and single-cell microscopy to study stochastic processes in bacteria</article-title>. <source>Curr Opin Microbiol</source>. <year>2018</year>;<volume>43</volume>: <fpage>186</fpage>–<lpage>192</lpage>.</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="other"><string-name><surname>Cabeen</surname> <given-names>MT</given-names></string-name>, <string-name><surname>Losick</surname> <given-names>R.</given-names></string-name> <article-title>Single-cell Microfluidic Analysis of Bacillus subtilis</article-title>. <source>J Vis Exp</source>. <year>2018</year>. doi:<pub-id pub-id-type="doi">10.3791/56901</pub-id></mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><string-name><surname>Kamande</surname> <given-names>JW</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Taylor</surname> <given-names>AM</given-names></string-name>. <article-title>Cloning SU8 silicon masters using epoxy resins to increase feature replicability and production for cell culture devices</article-title>. <source>Biomicrofluidics</source>. <year>2015</year>;<volume>9</volume>: <fpage>036502</fpage>.</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="web"><collab>mother-machine-protocols: Procedures for duplicating, constructing and using the microfluidic mother machine device</collab>. <source>Github</source>; Available: <ext-link ext-link-type="uri" xlink:href="https://github.com/junlabucsd/mother-machine-protocols">https://github.com/junlabucsd/mother-machine-protocols</ext-link></mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="web"><collab>Napari hub</collab>. [cited <date-in-citation content-type="access-date">17 Jan 2023</date-in-citation>]. Available: <ext-link ext-link-type="uri" xlink:href="https://www.napari-hub.org/plugins/napari-mm3">https://www.napari-hub.org/plugins/napari-mm3</ext-link></mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="web"><collab>napari — napari</collab>. [cited <date-in-citation content-type="access-date">23 Jan 2023</date-in-citation>]. Available: <ext-link ext-link-type="uri" xlink:href="https://napari.org/stable/">https://napari.org/stable/</ext-link></mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><string-name><surname>Rideau</surname> <given-names>F</given-names></string-name>, <string-name><surname>Villa</surname> <given-names>A</given-names></string-name>, <string-name><surname>Belzanne</surname> <given-names>P</given-names></string-name>, <string-name><surname>Verdier</surname> <given-names>E</given-names></string-name>, <string-name><surname>Hosy</surname> <given-names>E</given-names></string-name>, <string-name><surname>Arfi</surname> <given-names>Y.</given-names></string-name> <article-title>Imaging Minimal Bacteria at the Nanoscale: a Reliable and Versatile Process to Perform Single-Molecule Localization Microscopy in Mycoplasmas</article-title>. <source>Microbiol Spectr</source>. <year>2022</year>;<volume>10</volume>: <fpage>e0064522</fpage>.</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><string-name><surname>Taheri-Araghi</surname> <given-names>S</given-names></string-name>, <string-name><surname>Bradde</surname> <given-names>S</given-names></string-name>, <string-name><surname>Sauls</surname> <given-names>JT</given-names></string-name>, <string-name><surname>Hill</surname> <given-names>NS</given-names></string-name>, <string-name><surname>Levin</surname> <given-names>PA</given-names></string-name>, <string-name><surname>Paulsson</surname> <given-names>J</given-names></string-name>, <etal>et al.</etal> <article-title>Cell-size control and homeostasis in bacteria</article-title>. <source>Curr Biol</source>. <year>2015</year>;<volume>25</volume>: <fpage>385</fpage>–<lpage>391</lpage>.</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="other"><string-name><surname>Sauls</surname> <given-names>JT</given-names></string-name>, <string-name><surname>Schroeder</surname> <given-names>JW</given-names></string-name>, <string-name><surname>Si</surname> <given-names>F</given-names></string-name>, <string-name><surname>Brown</surname> <given-names>SD</given-names></string-name>, <string-name><surname>Le Treut</surname> <given-names>G</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>JD</given-names></string-name>. <article-title>Mother machine image analysis with MM3</article-title>. <source>bioRxiv</source>. <year>2019</year>; <fpage>4</fpage>–<lpage>7</lpage>.</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><string-name><surname>Grady</surname> <given-names>L.</given-names></string-name> <article-title>Random walks for image segmentation</article-title>. <source>IEEE Trans Pattern Anal Mach Intell</source>. <year>2006</year>;<volume>28</volume>: <fpage>1768</fpage>–<lpage>1783</lpage>.</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><string-name><surname>Falk</surname> <given-names>T</given-names></string-name>, <string-name><surname>Mai</surname> <given-names>D</given-names></string-name>, <string-name><surname>Bensch</surname> <given-names>R</given-names></string-name>, <string-name><given-names>Çiçek</given-names> <surname>Ö</surname></string-name>, <string-name><surname>Abdulkadir</surname> <given-names>A</given-names></string-name>, <string-name><surname>Marrakchi</surname> <given-names>Y</given-names></string-name>, <etal>et al.</etal> <article-title>U-Net: deep learning for cell counting, detection, and morphometry</article-title>. <source>Nat Methods</source>. <year>2019</year>;<volume>16</volume>: <fpage>67</fpage>–<lpage>70</lpage>.</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><string-name><surname>Otsu</surname> <given-names>N.</given-names></string-name> <article-title>A Threshold Selection Method from Gray-Level Histograms</article-title>. <source>IEEE Trans Syst Man Cybern</source>. <year>1979</year>;<volume>9</volume>: <fpage>62</fpage>–<lpage>66</lpage>.</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="web"><collab>notebooks at main · junlabucsd/napari-mm3. Github</collab>; Available: <ext-link ext-link-type="uri" xlink:href="https://github.com/junlabucsd/napari-mm3">https://github.com/junlabucsd/napari-mm3</ext-link></mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="book"><string-name><surname>Ollion</surname> <given-names>J</given-names></string-name>, <string-name><surname>Ollion</surname> <given-names>C.</given-names></string-name> <chapter-title>DistNet: Deep Tracking by Displacement Regression: Application to Bacteria Growing in the Mother Machine</chapter-title>. <source>Medical Image Computing and Computer Assisted Intervention – MICCAI 2020</source>. <publisher-name>Springer International Publishing</publisher-name>; <year>2020</year>. pp. <fpage>215</fpage>–<lpage>225</lpage>.</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="web"><collab>Apple Inc</collab>. <article-title>Tensorflow plugin - metal</article-title>. <source>In: Apple Developer [Internet]</source>. [cited <date-in-citation content-type="access-date">14 Jul 2023</date-in-citation>]. Available: <ext-link ext-link-type="uri" xlink:href="https://developer.apple.com/metal/tensorflow-plugin/">https://developer.apple.com/metal/tensorflow-plugin/</ext-link></mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="other"><string-name><surname>Banerjee</surname> <given-names>DS</given-names></string-name>, <string-name><surname>Stephenson</surname> <given-names>G</given-names></string-name>, <string-name><surname>Das</surname> <given-names>SG</given-names></string-name>. <article-title>Segmentation and analysis of mother machine data: SAM</article-title>. <source>bioRxiv</source>. <year>2020</year>. p. 2020.10.01.322685. doi:<pub-id pub-id-type="doi">10.1101/2020.10.01.322685</pub-id></mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><string-name><surname>Kaiser</surname> <given-names>M</given-names></string-name>, <string-name><surname>Jug</surname> <given-names>F</given-names></string-name>, <string-name><surname>Julou</surname> <given-names>T</given-names></string-name>, <string-name><surname>Deshpande</surname> <given-names>S</given-names></string-name>, <string-name><surname>Pfohl</surname> <given-names>T</given-names></string-name>, <string-name><surname>Silander</surname> <given-names>OK</given-names></string-name>, <etal>et al.</etal> <article-title>Monitoring single-cell gene regulation under dynamically controllable conditions with integrated microfluidics and software</article-title>. <source>Nat Commun</source>. <year>2018</year>;<volume>9</volume>. doi:<pub-id pub-id-type="doi">10.1038/s41467-017-02505-0</pub-id></mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><string-name><surname>Stringer</surname> <given-names>C</given-names></string-name>, <string-name><surname>Wang</surname> <given-names>T</given-names></string-name>, <string-name><surname>Michaelos</surname> <given-names>M</given-names></string-name>, <string-name><surname>Pachitariu</surname> <given-names>M.</given-names></string-name> <article-title>Cellpose: a generalist algorithm for cellular segmentation</article-title>. <source>Nat Methods</source>. <year>2021</year>;<volume>18</volume>: <fpage>100</fpage>–<lpage>106</lpage>.</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="web"><string-name><surname>Ollion</surname> <given-names>J.</given-names></string-name> <article-title>bacmman</article-title>. <source>Github</source>; Available: <ext-link ext-link-type="uri" xlink:href="https://github.com/jeanollion/bacmman">https://github.com/jeanollion/bacmman</ext-link></mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="web"><collab>mother-machine-data: A repository for processed mother machine data from the Jun Lab</collab>. <source>Github</source>; Available: <ext-link ext-link-type="uri" xlink:href="https://github.com/junlabucsd/mother-machine-data">https://github.com/junlabucsd/mother-machine-data</ext-link></mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><string-name><surname>Le Treut</surname> <given-names>G</given-names></string-name>, <string-name><surname>Si</surname> <given-names>F</given-names></string-name>, <string-name><surname>Li</surname> <given-names>D</given-names></string-name>, <string-name><surname>Jun</surname> <given-names>S.</given-names></string-name> <article-title>Quantitative Examination of Five Stochastic Cell-Cycle and Cell-Size Control Models for Escherichia coli and Bacillus subtilis</article-title>. <source>Front Microbiol</source>. <year>2021</year>;<volume>12</volume>: <fpage>721899</fpage>.</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><string-name><surname>Geiger</surname> <given-names>RS</given-names></string-name>, <string-name><surname>Cope</surname> <given-names>D</given-names></string-name>, <string-name><surname>Ip</surname> <given-names>J</given-names></string-name>, <string-name><surname>Lotosh</surname> <given-names>M</given-names></string-name>, <string-name><surname>Shah</surname> <given-names>A</given-names></string-name>, <string-name><surname>Weng</surname> <given-names>J</given-names></string-name>, <etal>et al.</etal> <article-title>“Garbage in, garbage out” revisited: What do machine learning application papers report about human-labeled training data?</article-title> <source>Quant Sci Stud</source>. <year>2021</year>;<volume>2</volume>: <fpage>795</fpage>–<lpage>827</lpage>.</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><string-name><surname>Laine</surname> <given-names>RF</given-names></string-name>, <string-name><surname>Arganda-Carreras</surname> <given-names>I</given-names></string-name>, <string-name><surname>Henriques</surname> <given-names>R</given-names></string-name>, <string-name><surname>Jacquemet</surname> <given-names>G.</given-names></string-name> <article-title>Avoiding a replication crisis in deep-learning-based bioimage analysis</article-title>. <source>Nat Methods</source>. <year>2021</year>;<volume>18</volume>: <fpage>1136</fpage>–<lpage>1144</lpage>.</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="other"><string-name><surname>Babbage</surname> <given-names>C.</given-names></string-name> <article-title>Passages from the life of a philosopher</article-title>. <source>Theclassics</source>; <year>2013</year>.</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="other"><string-name><surname>Mellin</surname> <given-names>WD</given-names></string-name>. <article-title>Work with new electronic “brains” opens field for army math experts</article-title>. <source>Hammond Times</source>.</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><string-name><surname>Jeckel</surname> <given-names>H</given-names></string-name>, <string-name><surname>Drescher</surname> <given-names>K.</given-names></string-name> <article-title>Advances and opportunities in image analysis of bacterial cells and communities</article-title>. <source>FEMS Microbiol Rev</source>. <year>2021</year>;<volume>45</volume>. doi:<pub-id pub-id-type="doi">10.1093/femsre/fuaa062</pub-id></mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="web"><collab>Image.Sc forum</collab>. <source>In: Image.sc Forum [Internet]</source>. [cited <date-in-citation content-type="access-date">24 Jan 2023</date-in-citation>]. Available: <ext-link ext-link-type="uri" xlink:href="https://forum.image.sc/">https://forum.image.sc/</ext-link></mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="book"><string-name><surname>Bourne</surname> <given-names>R.</given-names></string-name> <string-name><surname>Image</surname> <given-names>J.</given-names></string-name> In: <person-group person-group-type="editor"><string-name><surname>Bourne</surname> <given-names>R</given-names></string-name></person-group>, editor. <source>Fundamentals of Digital Imaging in Medicine</source>. <publisher-loc>London</publisher-loc>: <publisher-name>Springer London</publisher-name>; <year>2010</year>. pp. <fpage>185</fpage>–<lpage>188</lpage>.</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="web"><collab>Assets — DeLTA 2.0-gamma documentation</collab>. [cited <date-in-citation content-type="access-date">23 Feb 2023</date-in-citation>]. Available: <ext-link ext-link-type="uri" xlink:href="https://delta.readthedocs.io/en/latest/usage/assets_desc.html">https://delta.readthedocs.io/en/latest/usage/assets_desc.html</ext-link></mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><string-name><surname>Shiaelis</surname> <given-names>N</given-names></string-name>, <string-name><surname>Tometzki</surname> <given-names>A</given-names></string-name>, <string-name><surname>Peto</surname> <given-names>L</given-names></string-name>, <string-name><surname>McMahon</surname> <given-names>A</given-names></string-name>, <string-name><surname>Hepp</surname> <given-names>C</given-names></string-name>, <string-name><surname>Bickerton</surname> <given-names>E</given-names></string-name>, <etal>et al.</etal> <article-title>Virus detection and identification in minutes using single-particle imaging and deep learning</article-title>. <source>ACS Nano</source>. <year>2023</year>;<volume>17</volume>: <fpage>697</fpage>–<lpage>710</lpage>.</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><string-name><surname>Hardo</surname> <given-names>G</given-names></string-name>, <string-name><surname>Noka</surname> <given-names>M</given-names></string-name>, <string-name><surname>Bakshi</surname> <given-names>S.</given-names></string-name> <article-title>Synthetic Micrographs of Bacteria (SyMBac) allows accurate segmentation of bacterial cells using deep neural networks</article-title>. <source>BMC Biol</source>. <year>2022</year>;<volume>20</volume>: <fpage>263</fpage>.</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><string-name><surname>Naylor</surname> <given-names>P</given-names></string-name>, <string-name><surname>Lae</surname> <given-names>M</given-names></string-name>, <string-name><surname>Reyal</surname> <given-names>F</given-names></string-name>, <string-name><surname>Walter</surname> <given-names>T.</given-names></string-name> <article-title>Segmentation of Nuclei in Histopathology Images by Deep Regression of the Distance Map</article-title>. <source>IEEE Trans Med Imaging</source>. <year>2019</year>;<volume>38</volume>: <fpage>448</fpage>–<lpage>459</lpage>.</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><string-name><surname>Lawson</surname> <given-names>MJ</given-names></string-name>, <string-name><surname>Camsund</surname> <given-names>D</given-names></string-name>, <string-name><surname>Larsson</surname> <given-names>J</given-names></string-name>, <string-name><surname>Baltekin</surname> <given-names>Ö</given-names></string-name>, <string-name><surname>Fange</surname> <given-names>D</given-names></string-name>, <string-name><surname>Elf</surname> <given-names>J.</given-names></string-name> <article-title>In situ genotyping of a pooled strain library after characterizing complex phenotypes</article-title>. <source>Mol Syst Biol</source>. <year>2017</year>;<volume>13</volume>: <fpage>947</fpage>.</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="other"><string-name><surname>Luro</surname> <given-names>S</given-names></string-name>, <string-name><surname>Potvin-Trottier</surname> <given-names>L</given-names></string-name>, <string-name><surname>Okumus</surname> <given-names>B</given-names></string-name>, <string-name><surname>Paulsson</surname> <given-names>J.</given-names></string-name> <article-title>Isolating live cells after high-throughput, long-term, time-lapse microscopy</article-title>. <source>Nature Methods</source>. <year>2020</year>. pp. <fpage>93</fpage>–<lpage>100</lpage>. doi:<pub-id pub-id-type="doi">10.1038/s41592-019-0620-7</pub-id></mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="web"><collab>Microfluidic Device Analyzer napari Plugin. In: Chan Zuckerberg Initiative [Internet]</collab>. 11 <month>Nov</month> <year>2021</year> [cited <date-in-citation content-type="access-date">26 Jul 2023</date-in-citation>]. Available: <ext-link ext-link-type="uri" xlink:href="https://chanzuckerberg.com/science/programs-resources/imaging/napari/microfluidic-device-analyzer-napari-plugin/">https://chanzuckerberg.com/science/programs-resources/imaging/napari/microfluidic-device-analyzer-napari-plugin/</ext-link></mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="web"><collab>napari-mm3: Mother machine image analysis through napari</collab>. <source>Github</source>; Available: <ext-link ext-link-type="uri" xlink:href="https://github.com/junlabucsd/napari-mm3">https://github.com/junlabucsd/napari-mm3</ext-link></mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="journal"><string-name><surname>Lee</surname> <given-names>TC</given-names></string-name>, <string-name><surname>Kashyap</surname> <given-names>RL</given-names></string-name>, <string-name><surname>Chu</surname> <given-names>CN</given-names></string-name>. <article-title>Building Skeleton Models via 3-D Medial Surface Axis Thinning Algorithms</article-title>. <source>CVGIP: Graphical Models and Image Processing</source>. <year>1994</year>;<volume>56</volume>: <fpage>462</fpage>–<lpage>478</lpage>.</mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="journal"><string-name><surname>Rang</surname> <given-names>CU</given-names></string-name>, <string-name><surname>Peng</surname> <given-names>AY</given-names></string-name>, <string-name><surname>Poon</surname> <given-names>AF</given-names></string-name>, <string-name><surname>Chao</surname> <given-names>L.</given-names></string-name> <article-title>Ageing in Escherichia coli requires damage by an extrinsic agent</article-title>. <source>Microbiology</source>. <year>2012</year>;<volume>158</volume>: <fpage>1553</fpage>–<lpage>1559</lpage>.</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.88463.2.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Salman</surname>
<given-names>Hanna</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Pittsburgh</institution>
</institution-wrap>
<city>Pittsburgh</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This article provides a review and test of image-analysis methods for bacteria growing in the 'mother-machine' microfluidic device, introduceing also a new graphical user interface for the computational analysis of mother-machine movies based on the 'Napari' environment. The tool allows users to segment cells based on two previously published methods (classical image transformation and thresholding as well as UNet-based analysis), with <bold>solid</bold> evidence for their robust performance based on comparison with other methods and use of datasets from other labs. While it was difficult to assess the user-friendliness of the new GUI, it appears to be <bold>valuable</bold> and promising for the field.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.88463.2.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>The authors aim to develop an easy-to-use image analysis tool for the mother machine that is used for single-cell time-lapse imaging. Compared with related software, they tried to make this software more user-friendly for non-experts with a design of &quot;What You Put Is What You Get&quot;. This software is implemented as a plugin of Napari, which is an emerging microscopy image analysis platform. The users can interactively adjust the parameters in the pipeline with good visualization and interaction interface.</p>
<p>Strengths:</p>
<p>
- Updated platform with great 2D/3D visualization and annotation support.</p>
<p>
- Integrated one-stop pipeline for mather machine image processing.</p>
<p>
- Interactive user-friendly interface.</p>
<p>
- The users can have a visualization of intermediate results and adjust the parameters.</p>
<p>Weaknesses:</p>
<p>
- Based on the presentation of the manuscript, it is not clear that the goals are fully achieved.</p>
<p>
- Although there is great potential, there is little evidence that this tool has been adopted by other labs.</p>
<p>
- the diversity of datasets used in this study is limited.</p>
<p>
- Some paragraphs in the Discussion section are like blogs with general recommendations. Although the suggestions look pretty useful, it is not the focus of this manuscript. It might be more appropriate to put it in the GitHub repo or a documentation page. The discussion should still focus on the software, such as features, software maintenance, software development roadmap, and community adoption.</p>
<p>A discussion of the likely impact of the work on the field, and the utility of the methods and data to the community.</p>
<p>
- The impact of this work depends on the adoption of the software MM3. Napari is a promising platform with an expanding community. With good software user experience and long-term support, there is a good chance that this tool could be widely adopted in the mother machine image analysis community.</p>
<p>
- The data analysis in this manuscript is used as a demo of MM3 features, rather than scientific research.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.88463.2.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>The authors present an image-analysis pipeline for mother-machine data, i.e., for time-lapses of single bacterial cells growing for many generations in one-dimensional microfluidic channels. The pipeline is available as a plugin of the python-based image-analysis platform Napari. The tool comes with two different previously published methods to segment cells (classical image transformation and thresholding as well as UNet-based analysis), which compare qualitatively and quantitatively well with the results of widely accessible tools developed by others (BACNET, DelTA, Omnipose). The tool comes with a graphical user interface and example scripts, which should make it valuable for other mother-machine users, even if this has not been demonstrated yet.</p>
<p>The authors also add a practical overview of how to prepare and conduct mother-machine experiments, citing their previous work, referring to detailed instructions on their github page, and giving more advice on how to load cells using centrifugation.</p>
<p>Finally, the authors emphasize that machine-learning methods for image segmentation reproduce average quantities of training datasets, such as the length at birth or division. Therefore, differences in training can propagate to differences in measured average quantities. This result is not surprising but good to remember before interpreting absolute measurements of cell shape.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.88463.2.sa3</article-id>
<title-group>
<article-title>Author Response</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Thiermann</surname>
<given-names>Ryan</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0348-4181</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Sandler</surname>
<given-names>Michael</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Ahir</surname>
<given-names>Gursharan</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Sauls</surname>
<given-names>John T.</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Schroeder</surname>
<given-names>Jeremy W.</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Brown</surname>
<given-names>Steven D.</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Le Treut</surname>
<given-names>Guillaume</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Si</surname>
<given-names>Fangwei</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Li</surname>
<given-names>Dongyang</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Wang</surname>
<given-names>Jue D.</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1503-170X</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Jun</surname>
<given-names>Suckjoon</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0139-4297</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>The following is the authors’ response to the original reviews.</p>
<disp-quote content-type="editor-comment">
<p><bold>eLife assessment</bold></p>
<p>This article describes a useful python-based image-analysis tool for bacteria growing in the 'mother-machine' microfluidic device. This new method for image segmentation and tracking offers a user-friendly graphical interface based on the previously developed, promising environment for image analysis 'Napari'. The authors demonstrate the usefulness of their software and its robust performance by comparing it to other methods used for the same purpose. The comparison provides solid support for the new method, although it would have been even stronger if tested using data sets from other groups. This article will be of interest for scientists who utilize the 'mother machine', not least because it also provides a short overview of how to set up this widely used device.</p>
<p><bold>Public Reviews:</bold></p>
<p><bold>Reviewer #1 (Public Review):</bold></p>
<p>The authors aim to develop an easy-to-use image analysis tool for the mother machine that is used for single-cell time-lapse imaging. Compared with related software, they tried to make this software more user-friendly for non-experts with a design of &quot;What You Put Is What You Get&quot;. This software is implemented as a plugin of Napari, which is an emerging microscopy image analysis platform. The users can interactively adjust the parameters in the pipeline with good visualization and interaction interface.</p>
<p>Strengths:</p>
<list list-type="bullet">
<list-item><p>Updated platform with great 2D/3D visualization and annotation support.</p>
</list-item></list>
<list list-type="bullet">
<list-item><p>Integrated one-stop pipeline for mather machine image processing.</p>
</list-item></list>
<list list-type="bullet">
<list-item><p>Interactive user-friendly interface.</p>
</list-item></list>
<list list-type="bullet">
<list-item><p>The users can have a visualization of intermediate results and adjust the parameters.</p>
</list-item></list>
</disp-quote>
<p>We thank the reviewer for their positive comments.</p>
<disp-quote content-type="editor-comment">
<p>Weaknesses:</p>
<list list-type="bullet">
<list-item><p>Based on the presentation of the manuscript, it is not clear that the goals are fully achieved.</p>
</list-item></list>
<list list-type="bullet">
<list-item><p>Although there is great potential, there is little evidence that this tool has been adopted by other labs.</p>
</list-item></list>
<list list-type="bullet">
<list-item><p>The comparison of Otsu and U-Net results does not make much sense to me. The systematic bias could be adjusted by threshold change. The U-Net output is a probability map with floating point numbers. This output is probably thresholded to get a binary mask, which is not mentioned in the manuscript. This threshold could also be adjusted. Actually, Otsu is a segmentation method and U-Net is an image transformation method and they should not be compared together. U-Net output could also be segmented using Otsu.</p>
</list-item></list>
</disp-quote>
<p>We agree that the comparison of the classical and U-Net results may be misleading. As the reviewer points out, the issue ultimately comes down to thresholding. Indeed, the threshold of both the Otsu and U-Net outputs could be adjusted to bring them into line with each other. The comparison between the Otsu pipeline and U-Net pipeline is meant to illustrate that any pipeline (making use of a variety of methods) may be highly susceptible to the value of a user-input (or hard-coded threshold).</p>
<p>We have clarified the discussion to emphasize that the comparison is not specifically between U-Net and Otsu but between the two pipelines (lines 238 - 257).</p>
<p>We have also clarified that the U-Net probability map output was binarized with a threshold of 0.5 (lines 538-541). We note the same activation function and threshold are used in DeLTA. As the reviewer points out, Otsu’s method could indeed be applied to threshold the U-Net output as well. What we referred to as the “Otsu” MM3 method itself uses Otsu thresholding coupled with a Euclidean distance transform and a Random Walker algorithm. For clarity we now refer to it as a classical or non-learning method in the text.</p>
<disp-quote content-type="editor-comment">
<list list-type="bullet">
<list-item><p>The diversity of datasets used in this study is limited.</p>
</list-item></list>
</disp-quote>
<p>We have added a section “Testing napari-MM3 on other datasets” (lines 187-196) evaluating the performance of MM3 on 4 datasets (3 E. coli, 1 Corynebacterium glutamicum) from outside our lab, demonstrating its versatility.</p>
<disp-quote content-type="editor-comment">
<list list-type="bullet">
<list-item><p>There is some ambiguity in the main point of this manuscript, the title and figures illustrate a complete pipeline, including imaging, image segmentation, and analysis. While the abstract focus only on the software MM3. If only MM3 is the focus and contribution of this manuscript, more presentations should focus on this software tool. It is also not clear whether the analysis features are also integrated with MM3 or not.</p>
</list-item></list>
</disp-quote>
<p>We have added a line (lines 160-162) clarifying that final analysis and plotting must be done outside of napari. MM3 itself processes raw microscopy images, segments cells and reconstructs cell lineages (Figure 2).</p>
<disp-quote content-type="editor-comment">
<list list-type="bullet">
<list-item><p>The impact of this work depends on the adoption of the software MM3. Napari is a promising platform with expanding community. With good software user experience and long-term support, there is a good chance that this tool could be widely adopted in the mother machine image analysis community.</p>
</list-item></list>
</disp-quote>
<p>We thank the reviewer for their endorsement of MM3’s potential.</p>
<disp-quote content-type="editor-comment">
<list list-type="bullet">
<list-item><p>The data analysis in this manuscript is used as a demo of MM3 features, rather than scientific research.</p>
</list-item></list>
<p><bold>Reviewer #2 (Public Review):</bold></p>
<p>The authors present an image-analysis pipeline for mother-machine data, i.e., for time-lapses of single bacterial cells growing for many generations in one-dimensional microfluidic channels. The pipeline is available as a plugin of the python-based image-analysis platform Napari. The tool comes with two different previously published methods to segment cells (classical image transformation and thresholding as well as UNet-based analysis), which compare qualitatively and quantitatively well with the results of widely accessible tools developed by others (BACNET, DelTA, Omnipose). The tool comes with a graphical user interface and example scripts, which should make it valuable for other mother-machine users, even if this has not been demonstrated yet.</p>
</disp-quote>
<p>We thank the reviewer for their positive comments.</p>
<disp-quote content-type="editor-comment">
<p>The authors also add a practical overview of how to prepare and conduct mother-machine experiments, citing their previous work and giving more advice on how to load cells using centrifugation. However, the latter part lacks detailed instructions.</p>
</disp-quote>
<p>We have added a more detailed experimental protocol, including the procedure we use for cell loading, to the lab github page <ext-link ext-link-type="uri" xlink:href="https://github.com/junlabucsd/mother-machine-protocols">https://github.com/junlabucsd/mother-machine-protocols</ext-link> (linked in the main text).</p>
<disp-quote content-type="editor-comment">
<p>Finally, the authors emphasize that machine-learning methods for image segmentation reproduce average quantities of training datasets, such as the length at birth or division. Therefore, differences in training can propagate to difference in measured average quantities. This result is not surprising and is normally considered a desired property of any machine-learning algorithm as also commented on below.</p>
<p>Points for improvement:</p>
<p>Different datasets: The authors demonstrate the use of their method for bacteria growing in different growth conditions in their own microscope. However, they don't provide details on whether they had to adjust image-analysis parameters for each dataset. Similarly, they say that their method also works for other organisms including yeast and C. elegans (as part of the Results section) but they don't show evidence nor do they write whether the method needs to be tuned/trained for those datasets. Finally, they don't demonstrate that their method works on data from other labs, which might be different due to differences in setup or imaging conditions.</p>
</disp-quote>
<p>We have added a section “Testing napari-MM3 on other datasets” (lines 187-196) evaluating the performance of MM3 on 4 datasets (3 E. coli, 1 Corynebacterium glutamicum) from outside our lab, demonstrating its versatility. We provide details of the procedure and parameters used in the Methods section. (“Analysis of external datasets” lines 476-486).</p>
<disp-quote content-type="editor-comment">
<p>Bias due to training sets:</p>
<p>The bias in ML-methods based on training datasets is not surprising but arguably a desired property of those methods. Similarly, threshold-based classical segmentation methods are biased by the choice of threshold values and other segmentation parameters. A point that would have profited from discussion in this regard: How to make image segmentation unbiased, that is, how to deliver physical cell boundaries? This can be done by image simulations and/or by comparison with alternative methods such as fluorescence microscopy.</p>
</disp-quote>
<p>We agree this is an important point. We have revised the relevant sections (lines 238 - 270) to add context to the discussion of bias in both classical and deep learning methods. We have added a subsection (lines 401 - 410) discussing methods to this end, such as synthetic training data generation or calibrating the segmentation to fluorescence images.</p>
<disp-quote content-type="editor-comment">
<p>The authors stress the user-friendliness of their method in comparison to others. For example, they write: 'Unfortunately, many of these tools present a steep learning curve for most biologists, as they require familiarity with command line tools, programming, and image analysis methods.' I suggest to instead emphasize that many of the tools published in recent years are designed to be very use friendly. And as will all methods, MM3 also comes at a prize, which is to install Napari followed by the installation of MM3, which, according to their own instructions, is not easy either.</p>
</disp-quote>
<p>We have modified our language to acknowledge that indeed recent software such as DeLTA and BACMMAN make a point to be user-friendly and accessible (lines 52-53).</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p>
<p>-The resources, including documentation and code, are referenced and are not easy to find. It should be easier for readers to curate them in a separate Resources section.</p>
</disp-quote>
<p>We have created a Resources section in the Methods (top of first page) with the documentation, code and protocols hyperlinked.</p>
<disp-quote content-type="editor-comment">
<list list-type="bullet">
<list-item><p>It would be easier to understand the usage of MM3 with a screen recording video. I found a video from the GitHub paper, but the resolution is a bit low. Attaching a high-resolution screenshot video would be helpful.</p>
</list-item></list>
</disp-quote>
<p>A high resolution tutorial video has been made more visible on the github page.</p>
<disp-quote content-type="editor-comment">
<list list-type="bullet">
<list-item><p>In Table 1, AMD GPU is used which is not easy to use for Deep Learning. It is not clear whether the GPU is used for Deep Learning training and inference.</p>
</list-item></list>
</disp-quote>
<p>We have clarified this point in the Table 1 caption, and linked to a reference on how to use AMD GPUs with Tensorflow on Macs.</p>
<disp-quote content-type="editor-comment">
<list list-type="bullet">
<list-item><p>Some paragraphs in the Discussion section are like blogs with general recommendations. Although the suggestions look pretty useful, it is not the focus of this manuscript. It might be more appropriate to put it in the GitHub repo or a documentation page. The discussion should still focus on the software, such as features, software maintenance, software development roadmap, and community adoption.</p>
</list-item></list>
<list list-type="bullet">
<list-item><p>It would be easier for reviewers to add line numbers in the manuscript.</p>
</list-item></list>
<p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p>
<p>Software Installation: This might be something for the GitHub forum, but briefly trying to install the plugin myself, I already failed at the first line of the GitHub instructions, which is to use mamba for installation. This relates to my point above: Any program that is not stand-alone requires some user-savviness and trial-and-error, which is just hard to avoid for any method. I suggest being less critical of 'other methods' and instead focus on the advantage of the mother-machine-specific aspects of napari-mm3.</p>
<p>The authors write 'Still, most labs do not have the time and resources to evaluate other tools they do not use critically, [...]'. The sentence is not very clear. Evaluating tools not used is obviously difficult/impossible.</p>
</disp-quote>
<p>We have reworded this sentence to be more clear (lines 54-55).</p>
<disp-quote content-type="editor-comment">
<p>The authors write: 'The supervised learning method uses a convolutional neural net (CNN) with the U-Net architecture [20].' Can the authors cite previous work that has taken advantage of this approach before (e.g., DelTA)?</p>
</disp-quote>
<p>We have added citations to DeLTA and other previous software (line 151).</p>
<disp-quote content-type="editor-comment">
<p>Cell tracking and lineage reconstruction should be described in more detail and/or with reference to previous work.</p>
</disp-quote>
<p>We have added more details to the SI (lines 554 - 567) discussing the method in the context of existing mother machine analysis software.</p>
<disp-quote content-type="editor-comment">
<p>The authors provide a figure for a '3D printed cell loader', but as far they don't give instructions including a CAD file and the model of the fan used for spinning. The same holds for the stage inset (which, as far as I see, is not referred to in the manuscript text nor described in a figure caption).</p>
</disp-quote>
<p>Thank you for pointing out this omission. The centrifuge is referenced in Box 1. We have updated the manuscript with a link to a Github repository containing CAD files &amp; details of the centrifuge construction. We decided to remove the stage insert from the figure.</p>
<disp-quote content-type="editor-comment">
<p>Figure S3: Is the asymmetry in growth rate due to the expression of a fluorescent protein, due to strain differences, or due to imaging artifacts? Maybe this is impossible to tell based on the available datasets, but this could be discussed.</p>
</disp-quote>
<p>Based on previous work (DOI 10.1099/mic.0.057240-0) it is likely due to the expression of the fluorescent protein and fluorescence imaging. We have added a brief discussion in the Figure S3 caption.</p>
</body>
</sub-article>
</article>