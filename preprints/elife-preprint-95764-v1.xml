<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">95764</article-id>
<article-id pub-id-type="doi">10.7554/eLife.95764</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.95764.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.4</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Shortcutting from self-motion signals: quantifying trajectories and active sensing in an open maze</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Xu</surname>
<given-names>Jiayun</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n2">†</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9111-4905</contrib-id>
<name>
<surname>Girardi-Schappo</surname>
<given-names>Mauricio</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n1">5‡</xref>
<xref ref-type="author-notes" rid="n2">†</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7278-4906</contrib-id>
<name>
<surname>Béïque</surname>
<given-names>Jean-Claude</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0678-9893</contrib-id>
<name>
<surname>Longtin</surname>
<given-names>André</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7666-2754</contrib-id>
<name>
<surname>Maler</surname>
<given-names>Leonard</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Cellular and Molecular Medicine, University of Ottawa</institution>, Ottawa, Ontario, <country>Canada</country>, K1H 8M5</aff>
<aff id="a2"><label>2</label><institution>Department of Physics, University of Ottawa</institution>, Ottawa, Ontario, <country>Canada</country>, K1N 6N5</aff>
<aff id="a3"><label>3</label><institution>Brain and Mind Institute, University of Ottawa</institution>, Ottawa, Ontario, <country>Canada</country>, K1H 8M5</aff>
<aff id="a4"><label>4</label><institution>Center for Neural Dynamics and Artificial Intelligence, University of Ottawa</institution>, Ottawa, Ontario, <country>Canada</country>, K1H 8M5</aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Cowan</surname>
<given-names>Noah J</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Johns Hopkins University</institution>
</institution-wrap>
<city>Baltimore</city>
<country>United States of America</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Wassum</surname>
<given-names>Kate M</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of California, Los Angeles</institution>
</institution-wrap>
<city>Los Angeles</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>Author for correspondence: <email>lmaler@uottawa.ca</email></corresp>
<fn id="n1" fn-type="present-address"><label>5‡</label><p>Departamento de Física, Universidade Federal de Santa Catarina, 88040-900, Florianópolis, Santa Catarina, Brazil</p></fn>
<fn id="n2" fn-type="equal"><label>†</label><p>Contributed equally to this work</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-05-09">
<day>09</day>
<month>05</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP95764</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-01-12">
<day>12</day>
<month>01</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2023-12-28">
<day>28</day>
<month>12</month>
<year>2023</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.02.24.529984"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Xu et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Xu et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-95764-v1.pdf"/>
<abstract>
<title>Abstract</title>
<p>Animals navigate by learning the spatial layout of their environment. We investigated spatial learning of mice in an open maze where food was hidden in one of a hundred holes. Mice leaving from a stable entrance learned to efficiently navigate to the food without the need for landmarks. We develop a quantitative framework to reveal how the mice estimate the food location based on analyses of trajectories and active hole checks. After learning, the computed “target estimation vector” (TEV) closely approximated the mice’s trajectory and its hole check distribution. We propose that the TEV can be precisely connected to the properties of hippocampal place cells. Finally, we provide the first demonstration that, after learning the location of two food sites, the mice took a shortcut between the sites, demonstrating that they had generated a cognitive map.</p></abstract>
<abstract>
<title>Teaser</title>
<p>Mice can learn a cognitive map using only a fixed start location and self-motion signals.</p></abstract>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>A very minor rewording of just two sentences. A needed correction before forwarding the manuscript to a journal for review.</p></fn>
</fn-group>
<fn-group content-type="external-links">
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://github.com/neuro-physics/mouse-cogmap">https://github.com/neuro-physics/mouse-cogmap</ext-link>
</p></fn>
<fn fn-type="dataset"><p>
<ext-link ext-link-type="uri" xlink:href="https://www.dropbox.com/s/ikts0dn1qcog4oi/mouse_36_Probe2_hole_check_synchronized.mp4?dl=0">https://www.dropbox.com/s/ikts0dn1qcog4oi/mouse_36_Probe2_hole_check_synchronized.mp4?dl=0</ext-link>
</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Animals must learn the spatial layout of their environment to successfully forage and then return home. Local (<italic><xref ref-type="bibr" rid="c1">1</xref></italic>) or distal (<italic><xref ref-type="bibr" rid="c2">2</xref></italic>) landmark(s) are typically important spatial cues. Landmarks can act as simple beacons, as stimuli for response learning or for more flexible “place” learning strategies (<italic><xref ref-type="bibr" rid="c2">2</xref>-<xref ref-type="bibr" rid="c5">5</xref></italic>). Experimental studies addressing this issue have used one (<italic><xref ref-type="bibr" rid="c6">6</xref></italic>) or many (<italic><xref ref-type="bibr" rid="c7">7</xref></italic>) distal landmarks that provide allocentric coordinates for learning trajectories from a start site to a hidden location. A second source of spatial information derives from idiothetic cues that provide a reference frame via path integration of self-motion signals (<italic><xref ref-type="bibr" rid="c8">8</xref>, <xref ref-type="bibr" rid="c9">9</xref></italic>). Research on the interaction of landmark and self-motion cues has concluded that a “spatial map” can be generated by self-motion cues anchored to stable landmarks (<italic><xref ref-type="bibr" rid="c8">8</xref>, <xref ref-type="bibr" rid="c10">10</xref>-<xref ref-type="bibr" rid="c12">12</xref></italic>). This spatial map can link start sites to important locations via efficient trajectories. However, it is not clear whether such a map is sufficient for flexible navigation using entirely novel routes.</p>
<p>We designed a circular open maze where navigation trajectories are unconstrained, the mice allocentric reference frame is determined by large visual cues and food is hidden in one of 100 holes. We found that mice did not use the landmarks but required only minimal cues, namely a stable start location, self-motion signals and active sensing (hole checks), to learn to find food. Trajectories and hole checking strategies dramatically changed as the mice learned to efficiently navigate to the hidden food. Averaged trajectory directions converged to a “mean displacement direction”, and hole checking became concentrated near the expected food hole. These analyses resulted in a computed target estimation vector (TEV) that closely approximated the most direct route between the start location and food. When, after learning, the mice were transferred to another start site, their TEVs rotated to the “rotationally equivalent location” (REL), therefore demonstrating that they were relying entirely on self-motion cues for navigation. We propose ways to link the mean displacement and hole checking components of the TEV to the properties of hippocampal place cells and suggest a neural equivalent of the TEV that might be computed by downstream hippocampal targets.</p>
<p>The cognitive map hypothesis proposes that animals can learn a metric map of their environment and use it to flexibly guide their navigation, that is, they can take shortcuts, detours and novel routes when needed (<italic><xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c13">13</xref>, <xref ref-type="bibr" rid="c14">14</xref></italic>). It is further proposed that the hippocampus and closely connected cortical areas generate a cognitive map (<italic><xref ref-type="bibr" rid="c15">15</xref>, <xref ref-type="bibr" rid="c16">16</xref></italic>). We found that, after training to find food in two distinct sites, mice were able to take an unrehearsed shortcut between the sites on a final probe (<italic>i</italic>.<italic>e</italic>., no food) trial. The trajectories and hole check analyses demonstrated that the computed TEVs were accurate and efficient. To the best of our knowledge, this is the first demonstration that a stable start location and self-motion cues are sufficient for a rodent to compute a cognitive map. It is not clear whether current theories based on electrophysiological studies of the hippocampus and associated cortices can account for the cognitive map we have observed (<italic><xref ref-type="bibr" rid="c15">15</xref>, <xref ref-type="bibr" rid="c17">17</xref></italic>).</p>
</sec>
<sec id="s2">
<title>Results</title>
<p>We designed a behavioural framework, the Hidden Food Maze (HFM), to tease apart the roles of idiothetic and allothetic cues for navigation in a foraging task (<xref rid="fig1" ref-type="fig">Fig. 1A</xref>). Mice are trained to find a food reward hidden inside one hole (the target) out of 100 in a large, circular open maze (120 cm in diameter). The target hole has a “rotationally equivalent location” (REL) in each of the arena’s quadrants (<xref rid="fig1" ref-type="fig">Fig. 1B</xref>; see “REL” in Methods for a description). In the mouse’s perspective, the displacement from the entrance location to the target is the same as from the entrance in any quadrant to their respective REL. The HFM has several unique features such as 90° rotational symmetry to eliminate geometric cues and control for distal cues, movable home cage entranceways, and experimenter-controlled visual cues (see Methods). These features allow us to control whether mice orient to allothetic or idiothetic cues, enabling us to investigate the respective role of landmarks versus path integration in spatial navigation.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Hidden Food Maze and experimental setup.</title>
<p><bold>A</bold>. The floor of the arena is 120cm in diameter, and the walls are 45cm tall. The home cage has a 10.5x6.5cm<sup>2</sup> floor area. The door slides upward (mice enter without handling). The floor and the home cages can be separated. The subfloor containing food is not illustrated. <bold>B</bold>. Camera view of a mouse searching for hidden food (target, pointed by the target vector). The REL of the target is marked for each entrance (from the mouse’s perspective, the displacement from the start in each quadrant to its respective REL is the same for any entrance; <italic>e</italic>.<italic>g</italic>., “70cm forward + 30cm to the left”; and it is equal to the displacement from the trained start to target). <bold>C</bold> “Random entrances” experiment. Mice enter from any of the four entrances randomly over trials to search for food (“A”-labeled star) always in front of the X landmark. Arrows show the four possible displacements. <bold>D</bold>. “Static entrances” experiment. Mice start from the same entrance (labeled “Start”) in every trial to search for food in front of the same landmark. Blue/cyan arrows=food vector (start→food); Orange arrow=REL vector (start→REL). After training, the start position in a probe trial can be rotated (“180° Start”) to check whether mice follow idiothetic (start→REL; ignoring landmarks) or allothetic (start→A; following landmarks) cues; going via the REL vector is regarded as evidence of path integration. <bold>E</bold>. “Two food location” experiment. Mice start from a static entrance to search for food (red vector to target A). Afterwards, mice are trained to find food in a different location (blue vector to target B). After learning both targets, a probe trial (i.e., a trial without food) is designed to check whether mice can compute shortcuts from B to A (B-A vector, orange arrow).</p></caption>
<graphic xlink:href="529984v4_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We first analyzed the effects of randomizing the entrance location taken by the mouse on successive trials (<xref rid="fig1" ref-type="fig">Fig. 1C</xref>), versus maintaining a static entrance throughout training (<xref rid="fig1" ref-type="fig">Fig. 1D</xref>). We quantified the geometric and kinetic features of the trajectories and the behavior of hole checking throughout the arena. We developed statistical methods to directly infer the mice estimation of the target location (the “target estimation vector”, or TEV) and showed that it coincides with the actual target vector only for the static entrance protocol. In order to eliminate the effect of visual cues, we performed rotated probe trials after training in static entrance, where mice went either to the target (following landmarks) or to the REL (ignoring landmarks; see <xref rid="fig1" ref-type="fig">Fig. 1D</xref>).</p>
<p>Finally, we investigated the features of the mice trajectories and active sensing behavior when trained on two targets consecutively under the static entrance protocol (<xref rid="fig1" ref-type="fig">Fig. 1E</xref>). In this case, the TEV method was employed to demonstrate the learning of both target directions and the use of shortcuts, one manifestation of a cognitive map (<italic><xref ref-type="bibr" rid="c14">14</xref></italic>). See Methods and the Supplementary Material for the definition of all measured quantities and details on experimental protocols.</p>
<sec id="s2a">
<title>Mice used idiothetic sensory input but did not utilize 2D wall cues for spatial learning</title>
<sec id="s2a1">
<title>Random Entrance experiments</title>
<p>Mice were trained with their entrance changing randomly from trial to trial, so their only reliable orienting cues were the wall cues. The configuration of the 4 cues varied relative to the entrance, but the food was always placed in the same hole and nearest the X-shaped landmark (<xref rid="fig2" ref-type="fig">Fig. 2</xref>, Methods). Individual mice showed persistent complex search trajectories throughout the learning period (<xref rid="fig2" ref-type="fig">Fig. 2A, B</xref>). The latency to reach the food target was significantly negatively correlated with trial number (statistics in <xref rid="fig2" ref-type="fig">Fig. 2D</xref>) but with a non-significant difference between the first and last trials (N=8; First trial mean±SD = 151.34 ± 148.91 s; Last trial mean±SD = 80.38 ± 43.86 s; P=0.2602). Despite the decrease in latency, mice did not appear to exhibit spatial search strategies (<xref rid="fig2" ref-type="fig">Fig. 2C</xref>) given that the time spent in each quadrant during the probe trial is similar (target quadrant=28.78%, other quadrants=24.93%, 28.04%, 18.25%; 1-Way ANOVA: P=0.070574, F-ratio=2.71621; see Behavioral Analysis in Methods). This suggests latency decreased for reasons independent of spatial learning.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Mouse spatial learning with random entrances.</title>
<p><bold>A</bold>. Two examples of mouse search trajectories during early learning (trial 3) when the entrance changes from trial to trial. They are irregular and vary unpredictably across trials. <bold>A, B</bold>. Star = target location. Yellow Square = entrance site. <bold>B</bold>. Two examples of mouse search trajectories during late learning (trial 14) after starting from different entrances. Trajectories look as irregular as in early trials. <bold>C. (Top)</bold> Heatmap of the first 2min of a probe trial done after trial 18. <bold>(Bottom)</bold> Mice spent about the same time (25%) in each of the four sectors, regardless of being close to the target (red) or to its REL (white). <bold>D</bold>. Some significant reduction in latency to reach target is seen across trials (p=0.008; N=8). <bold>d-i:</bold> Error bars = S.E. Shaded area = data range. <bold>E</bold>. Some significant increase in speed is seen (p=0.002; N=8). <bold>F</bold>. Average normalized distance traveled to reach target (<italic>d</italic><sub>total</sub>/<italic>d</italic><sub>target</sub>=1 is optimal; p=0.05, N=8). <bold>G</bold>. Hole-checking density (number of hole checks per distance traveled) in each half of the trajectory. The density remains constant for both halves and across trials, suggesting that mice remained uncertain as to the food location. <bold>G-inset</bold>. The S.D. of the density over the mice sample remains constant for both halves (N=8). <bold>H</bold>. The average distance of the checked holes to the food <italic>d</italic><sub>(<italic>checks</italic>→<italic>food</italic>)</sub> remains almost constant across trials. Horizontal lines are just guides to the eye. <bold>I</bold>. The probability density of the distance of hole checks to the food <italic>d</italic><sub>(<italic>checks</italic>→<italic>food</italic>)</sub> for the first and last learning trials (the corresponding averages over trials are in panel <bold>H</bold>). The density remains unaltered. Vertical dotted lines mark the same distances as the horizontal lines in panel <bold>H</bold>.</p></caption>
<graphic xlink:href="529984v4_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We found a corresponding significant positive correlation of speed and trial number (<xref rid="fig2" ref-type="fig">Fig. 2E</xref>) with non-significant differences between first and last trials (N=8; First trial mean±SD = 6.68 ± 3.79 cm/s; Last trial mean±SD = 11.40 ± 5.07 cm/s; P=0.0704). Since the distance from start to target (<italic>d</italic><sub><italic>target</italic></sub>) varies over trials due to changing entrance location, we defined the normalized trajectory length (<xref rid="fig2" ref-type="fig">Fig. 2F</xref>). It is the ratio between total traveled distance (<italic>d</italic><sub><italic>total</italic></sub>) and <italic>d</italic><sub><italic>target</italic></sub>; <italic>d</italic><sub><italic>total</italic></sub>/<italic>d</italic><sub><italic>target</italic></sub>=1 is optimal. There is no significant correlation of this quantity and trial number (P=0.295). The first and last normalized trajectory lengths were not significantly different either (N=8; First trial mean±SD = 11.79 ± 8.25; Last trial mean±SD = 15.51 ± 9.92; P=0.4241). We hypothesize that the mice simply moved more quickly, but that they were still far from optimal in the distance traveled (see <xref rid="fig3" ref-type="fig">Fig. 3F</xref>), consistent with the random trajectories before and after learning (<xref rid="fig2" ref-type="fig">Fig. 2A,B</xref>).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Mouse spatial learning with static entrances.</title>
<p><bold>A</bold>. Two examples of mouse search trajectories during early learning (trial 3). They are irregular and variable similarly to those in the random entrance experiments. <bold>A, B</bold>. Star = target location. Yellow Square = entrance site. <bold>B</bold>. Two examples of mouse search trajectories during late learning (trial 14). They go directly towards the food or go along the wall before turning to the food, creating variation across mice and trials. <bold>C. (Top)</bold> Heatmap of the first 2min of a probe trial done after trial 14. <bold>(Bottom)</bold> Mice spent almost 50% of the time within 15cm radius of the target (red) compared to the RELs (white). <bold>D</bold>. Latency dramatically decreases (p&lt;10<sup>-7</sup>; N=8). <bold>D-I:</bold> Error bars = S.E. Shaded area = data range. <bold>E</bold>. Speed significantly increases during trials (p=0.0001; N=8). <bold>F</bold>. Normalized distance to reach target (<italic>d</italic><sub>total</sub>/<italic>d</italic><sub>target</sub>=1 is optimal) becomes almost optimal (p&lt;10<sup>-7</sup>; N=8). <bold>G</bold>. Hole-checking density over distance in each half of the trajectory. It significantly decreases in the first half (p=0.05), and stays constant in the second. <bold>G-inset:</bold> The S.D. of the density is larger in the second half. <bold>H</bold>. The average distance of the checked holes to the food <italic>d</italic><sub>(<italic>checks</italic>→<italic>food</italic>)</sub> decreases for both halves of the trajectory. After learning, the hole checks happen closer to the food (<italic>d</italic><sub>(<italic>checks</italic>→<italic>food</italic>)</sub> is almost zero), although there are more checks per distance. <bold>I</bold>. The probability density of the distance of hole checks to the food <italic>d</italic><sub>(<italic>checks</italic>→<italic>food</italic>)</sub> for the first and last trials (the corresponding averages over trials are in panel h). After learning (trial 14), the density is larger closer to the food, a feature that does not appear in the random entrance experiments.</p></caption>
<graphic xlink:href="529984v4_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We next examined hole checking as an active sensing indicator of the mouse’s expectation of the food location (see Methods, Fig. S2A,B and Supp. Video for hole-check detection after spatial learning). Even though hole check counts increase with the total trajectory length (Fig. S4B), we expected that the mice would increase the number of hole checks near the expected food location, or along their path toward it. Thus, we split the trajectories into two halves of same duration to identify whether hole checks would increase in the second half (being closer to the target). However, the hole checking density (ratio between number of checks and distance travelled) remains constant between the first and second halves of any trial (<xref rid="fig2" ref-type="fig">Fig. 2G</xref>), suggesting mice did not anticipate where the food is placed. Mice also did not increase their hole sampling rate as they approached the target, again suggesting no expectation of its location (<xref rid="fig2" ref-type="fig">Fig. 2H,I</xref>). Mice do not appear to learn a landmark-based allocentric spatial map.</p>
</sec>
<sec id="s2a2">
<title>Static Entrance Experiments</title>
<p>We tested whether the mice might acquire an allocentric spatial map if, contrary to the random entrance case, they had a single stable view of the landmarks and could associate one cue configuration with the food location (see Methods). For this, each mouse entered the arena from the same entrance during the training trials (hence “static entrance”). Mice greatly improved their trajectory efficiency after learning (<xref rid="fig3" ref-type="fig">Fig. 3A,B</xref>). During early learning, mice showed random search trajectories that transformed to stereotyped trajectories towards food by late learning (<xref rid="fig3" ref-type="fig">Fig. 3B</xref>). Typical trajectories were either (i) directly to the food, (ii) initially displaced towards the maze center then returning to a food-oriented trajectory, or (iii) initially along the wall and then turning and heading to the food (<xref rid="fig3" ref-type="fig">Fig. 3B</xref>).</p>
<p>During the probe trial, mice spent the most time searching in the target quadrant (44.26%; <xref rid="fig3" ref-type="fig">Fig. 3C</xref>), compared to the time spent in the other quadrants, respectively 19.38% (P=0.007), 16.55% (P=0.0065), 19.81% (P=0.007; p-values obtained for a pairwise t-test and adjusted for multiple comparison via the Benjamini-Hochberg method). This demonstrates acquisition of spatial knowledge. The latency to target strongly decreased over trials (<xref rid="fig3" ref-type="fig">Fig. 3D</xref>) and the last trial latency was significantly reduced compared to the first (N=8; First trial mean±SD = 255.39 ± 153.28 s; Last trial mean±SD = 7.38 ± 4.03 s; P=0.004). The speed dramatically increased over trials (<xref rid="fig3" ref-type="fig">Fig. 3E</xref>) and the ending speed was significantly greater than the initial speed (N=8, First trial mean±SD = 6.04 ± 2.48 cm/s; Last trial mean±SD = 17.25 ± 4.64 cm/s; P=0.0002). The normalized trajectory length strongly negatively correlated with trial number (<xref rid="fig3" ref-type="fig">Fig. 3F</xref>) and the final normalized length greatly reduced (N=8; First trial mean±SD = 18.02 ± 11.36; Last trial mean±SD = 1.40 ± 0.50; P=0.0061), becoming almost optimal (<xref ref-type="bibr" rid="c1">1</xref>). See also Fig. S4D,E,F.</p>
<p>After learning, hole checking density varied across trajectories and differed between early and late learning trials. The density significantly decreased with trial number in the first half of trajectories (R=-0.54; P=0.0455, <xref rid="fig3" ref-type="fig">Fig. 3G</xref>) but not the second half (R=0.17z; P= 0.559, <xref rid="fig3" ref-type="fig">Fig. 3G</xref>). The hole checks also happened significantly closer to the target in the second half of the trajectory (<xref rid="fig3" ref-type="fig">Fig. 3H</xref>; First trial mean±SD = 48.06 ± 11.50 cm; Last trial mean±SD = 3.13 ± 5.70 cm; P=3x10<sup>-6</sup>). A remarkable effect of learning is that the probability of checking holes increases as the mouse approaches the food (<xref rid="fig3" ref-type="fig">Fig. 3I</xref>). These results (<xref rid="fig3" ref-type="fig">Fig. 3H,I</xref>) suggest that the mice may be predicting the food location and checking their prediction as they approach the estimated food location (see also Figs. S4 and S5 for other quantities and scatter plots of trajectory features vs. hole checking). Hole checking near the food site also implies that the mice are not using odorant or visual cues to sense the precise food location, but instead rely on a memory-based estimate of the food-containing hole (see also <xref rid="fig4" ref-type="fig">Fig. 4G,H</xref>).</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Trajectory directionality and active sensing for random and static experiments.</title>
<p>Arenas on the top row (mean displacement vector – see color scale between panels b and e) correspond to the ones immediately below them (hole checking spatial distribution); the red “A” label marks the target (food site), which is pointed by the food (target) vector (purple arrow). <bold>Top row (A</bold>,<bold>B</bold>,<bold>E</bold>,<bold>F)</bold>: the color and arrows indicate the most probable route taken (red=more probable; only p&lt;0.001 displacements shown; pink arrow=inferred target position, or TEV; shaded pink sector=S.D. of TEV; see Methods, and Fig. S7). <bold>Bottom row (C</bold>,<bold>D</bold>,<bold>G</bold>,<bold>H)</bold>: spatial distribution of holechecks; size and color of circles=normalized frequency that a hole was checked (larger gray circles=higher frequency); Black ellipse (x=mean): covariance of spatial distribution. Green ellipse (+=mean): covariance of spatial distribution restricted to ≤20cm of the target. <bold>Random entrance</bold> experiments (N=8; panels <bold>A</bold>,<bold>C: trial 1; B</bold>,<bold>D: trial 14</bold>): regardless of training stage, no significant preferred routes and the TEV does not point to target (<bold>A</bold>,<bold>B</bold>); hole checks are randomly distributed throughout the arena, and shift from the walls (c) to the center (d) after learning. <bold>Static entrance</bold> experiments (N=8; panels <bold>E</bold>,<bold>G: trial 1; f</bold>,<bold>h: trial 14</bold>): after learning (f) the TEV and significant displacements go straight to the target (although individual trajectories are variable); and hole checks align along the starttarget path (h). <bold>Panel I:</bold> deviation between the TEV (pink arrow) and the target vector (purple arrow) illustrated in top panels. Directionality is quickly learned (static case). <bold>Panels J</bold>,<bold>K:</bold> hole-check area density corresponding to the spatial profiles in bottom panels. Density after learning is larger near the target (static case), supporting the path integration hypothesis. Asterisks/star: p&lt;0.05 (paired t-test). Note the presence of more significant displacements in late learning for static entrances only, and the associated alignment of the TEV and food vector.</p></caption>
<graphic xlink:href="529984v4_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2a3">
<title>Revealing the mouse estimate of target position from behavior</title>
<p>Although quantitative, the analysis so far only showed a broad comparison between random versus static entrance experimental conditions. We developed a method to map out the directions that the mice stepped towards more frequently from each particular location in the arena, yielding a <italic>displacement map</italic>. This map can generate a precise estimate of the mean directionality of the trajectories for each experimental condition (<xref rid="fig4" ref-type="fig">Fig. 4A,B,E,F</xref>). Additionally, we also made a frequency plot of the checks for each particular hole in the arena, yielding the spatial distribution of hole checks (<xref rid="fig4" ref-type="fig">Fig. 4C,D,G,H</xref>). These two maps are combined to give the Target Estimation Vector (TEV; see Statistical Analysis of Trajectories in Methods). The TEV is interpreted as the mouse’s estimate of the target position (pink vectors in <xref rid="fig4" ref-type="fig">Fig. 4A,B,E,F</xref>).</p>
<p>In random entrance training, no significant directionality was found in the arena (<xref rid="fig4" ref-type="fig">Fig. 4A,B</xref>), again consistent with a random search. The spatial distribution of hole checks migrated from near the walls towards the center of the arena but remained random and displaced from the target (<xref rid="fig4" ref-type="fig">Fig. 4C,D</xref>), consistent with the broad results of <xref rid="fig2" ref-type="fig">Fig. 2</xref>. Conversely, there was a clear and significant flow of trajectories for mice trained with static entrance (<xref rid="fig4" ref-type="fig">Fig. 4E, F</xref>; P&lt;0.0001; see Methods for the definition of these p-values assigned to directions). The hole checks reflected this and became solely concentrated along the route from start to target (<xref rid="fig4" ref-type="fig">Fig. 4G,H</xref>). In the static entrance condition, the entropy (uncertainty) of the number of hole checks near (&lt;20 cm) the target was lower than that for the far (&gt;20 cm) condition (Fig. S7F,G). In other words, mice were more consistent in the number of their hole checks near the target compared to far from the target, suggesting that they had an internal representation of their proximity to the food site.</p>
<p>We compared the deviation between the TEV and the true target vector (that points from start directly to the food hole; <xref rid="fig4" ref-type="fig">Fig. 4I</xref>). While the random entrance mice had a persistent deviation between TEV and target of more than 70°, the static entrance mice were able to significantly learn the direction of the target almost perfectly by trial 6 (TEV-target deviation in first trial mean±SD = 57.27° ± 41.61°; last trial mean±SD = 5.16° ± 0.20°; P=0.0166).</p>
<p>Under the path integration hypothesis, it is expected that error accumulates as the mouse walks (<italic><xref ref-type="bibr" rid="c15">15</xref></italic>). This motivated us to investigate the frequency of hole checks per area near the target (within 20 cm) vs. far (further from 20 cm away), <xref rid="fig4" ref-type="fig">Fig. 4J,K</xref>. The density of hole checks in both conditions remained constant for random entrance mice, regardless of training duration. However, static entrance mice had significantly higher density of hole checks near the target (<xref rid="fig4" ref-type="fig">Fig. 4K</xref>). The mean position of hole checks near (≤20cm) the target is interpreted as the mouse estimated target (<xref rid="fig4" ref-type="fig">Fig. 4C,D,G,H</xref>; green x = mean position; green ellipsis = covariance of spatial hole check distribution restricted to 20cm near the target). Thus, we use the distance from this point to the entrance as the magnitude of the TEV. This definition reveals that the TEV is nearly coincident with the direct route between start location and the food containing hole (pink vectors in <xref rid="fig4" ref-type="fig">Fig. 4F</xref>), consistent with the near optimal normalized trajectory length (<xref rid="fig3" ref-type="fig">Fig. 3F</xref>).</p>
</sec>
<sec id="s2a4">
<title>Ruling out landmarks</title>
<p>These results demonstrate that mice can learn the spatial location of the food target from a static entrance. We next investigated whether the performance gain can be attributed to the cues by manipulating the mouse’s entrance. Well-trained static entrance mice were subject to rotation of their home cage by 180°, +90°, or -90° for probe trials using a different cohort of N=8 mice for each rotation. If the mice were using the distal landmarks, they would still be expected to find the correct food location. If they relied on self-motion cues, they should travel to the REL, since this is the location where the target would have been if the mouse had been trained from that entrance. In other words, going to the REL means that the trajectory is anchored to the mouse’s home cage entrance and not to the wall cues. As illustrated in <xref rid="fig1" ref-type="fig">Fig. 1B</xref>, the displacement between each start-REL pair is exactly equal from the mouse’s point of view (<italic>e</italic>.<italic>g</italic>., going 70 cm forward then 30 cm to the left reaches the respective REL of the target).</p>
<p>Following all rotations, mice searched at the REL instead of the correct location for the food reward regardless of the arena having wall cues (<xref rid="fig5" ref-type="fig">Fig. 5A,B,C</xref>), meaning that they were not using landmarks to compensate for rotation. In fact, the trajectory kinetics of the 180°-rotated probe for reaching the REL target (mean±SD latency = 4.80 ± 3.06 s; speed = 14.60 ± 5.21 cm/s; normalized distance to REL = 1.96 ± 0.90) is indistinguishable (within one SD or less) from the kinetics of the last trial of static entrance for reaching the true target. The criterion for reaching the REL target was getting within 5cm of its position (the average inter-hole distance is 10cm).</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Changing start position after training in static protocol.</title>
<p>Mice are trained in the static entrance protocol to find food at the target labeled “A” (blue circle), and a probe trial is executed with mice entering from a rotated entrance after 18 trials. Panels <bold>A</bold>,<bold>B</bold>,<bold>C</bold> show the comparison between trajectories from the last learning trial (blue) versus the probe (red). The training was performed without landmarks (<bold>A:</bold> N=8, -90° rotation) and with landmarks (<bold>B:</bold> N=8, 90° rotation; <bold>c:</bold> N=8, 180° rotation). In all instances, mice ignored landmarks and went to the REL location (“REL A” label, red triangle), something that is expected under the path integration hypothesis. <bold>Panel D:</bold> trajectory directionality analysis and TEV (pink arrow; shaded sector: S.D.) show that significant paths of all mice (p&lt;0.001; N=8; see Methods) point to the REL-A location in the same way that it pointed to the target without rotated entrance in <bold><xref ref-type="fig" rid="fig4">Fig. 4F</xref>. Panel E:</bold> the spatial distribution shows that hole checks accumulate along the start-REL vector, instead of the start-target vector of the case without rotation in <bold><xref ref-type="fig" rid="fig4">Fig. 4H</xref></bold>. Black ellipse (x=mean): covariance of hole check distribution. Green ellipse (+=mean): covariance of the data within 20cm of the REL-A location. This suggests that mice follow trajectories anchored to their start location (idiothetic frame of reference).</p></caption>
<graphic xlink:href="529984v4_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We also show the displacement maps (mean trajectory directionality), hole check spatial profile and TEV for the 180°-rotated probe trial (<xref rid="fig5" ref-type="fig">Fig. 5C</xref>). The TEV now points to the REL, and the hole checks accumulate along the route to the REL. These maps are also very similar to the static entrance maps in <xref rid="fig4" ref-type="fig">Fig. 4</xref>. Thus, the mice failed to use allothetic cues for navigation in the novel start location test.</p>
</sec>
<sec id="s2a5">
<title>Further controls</title>
<p>It is possible that mice, like gerbils(<italic><xref ref-type="bibr" rid="c6">6</xref></italic>), choose one landmark and learn the food location relative to that landmark (e.g., the “X” in <xref rid="fig3" ref-type="fig">Fig. 3B</xref>); in this case, the mice would only have to associate their initial orientation to that landmark without identifying the image on it. We used two additional controls to assess this possibility. Mice were trained without any cues on the wall, eliminating the possibility that they provided orienting guides. The learning curve of mice with or without the 2D wall cues were not significantly different (Fig. S6A,B).</p>
<p>Mice, well trained in the lighted maze, were given trials in complete darkness. These mice still showed the same learning curve compared to untrained mice or mice following rotation (Fig. S6C,D).</p>
<p>Finally, to completely rule out both landmark and possible olfactory cues, we trained and tested mice in total darkness. Head direction tuning may be impaired in sighted mice navigating in darkness (<italic><xref ref-type="bibr" rid="c18">18</xref></italic>), but spatial learning was not affected in our experiments. Mice can also use localized odor sources as landmarks for spatial learning (<italic><xref ref-type="bibr" rid="c19">19</xref></italic>), and might therefore use odor gradients from their home cage as a cue. We eliminated odor cues by applying negative pressure inside the home cage via fans that drew in outside air from the cage bottom and from the maze and vented cage air out the top (see Methods). The mice were still able to learn the food location in the absence of visual and olfactory cues (Fig. S6E,F). These experiments demonstrate that the mice learn to efficiently navigate from a fixed start location to the food location using only path integration of self-motion cues.</p>
</sec>
</sec>
<sec id="s2b">
<title>Mice can use a shortcut to navigate between remembered targets</title>
<p>Our results established that mice learn the spatial location of a food reward using path integration of self-motion cues. Have the mice learned a flexible cognitive map? A test of cognitive mapping would be if mice can take a short cut and navigate from one remembered location to another along a novel, unreinforced path. The “two food location experiment” set out to test this possibility by training mice to travel to food from their home cage to two very differently located sites. The two locations were trained sequentially so that one site was trained first (target A) followed by training on the second site (target B). A probe trial without food after training target A was designed to check if mice had learned it successfully. Only one hole was filled with food in any given training trial. In a second probe trial after training on B, mice were tested to see whether they can travel between the two remembered locations (food is absent; probe B-A trial) despite no prior training nor reinforced experience on the short cut route (<xref rid="fig1" ref-type="fig">Fig. 1E</xref>).</p>
<p>Mice successfully learned the location of target A, evidenced by their direct search trajectories and significant decreases in distance traveled (<xref rid="fig6" ref-type="fig">Fig. 6A</xref>), with the same performance as in the static entrance case. During the learning of target A, the distance of the mouse to the future location of target B was always larger than that expected by chance, i.e., to a randomly chosen location in the maze (see Methods, Fig. S10A,B). In fact, the trajectories stayed, on average, approximately 40 cm away from the forthcoming target B position. In other words, the mice did not learn, by chance, direct unreinforced routes from “near B to A”. In <xref rid="fig6" ref-type="fig">Fig. 6A</xref>, for example, the mouse passed within 16 cm of the future target B site in an early learning trial, but this close approach does not appear to constitute a B-&gt;A trajectory. The first probe trial (without food) confirmed that mice had learned the location of target A. After not finding food in A, the mice re-initiated a random search (<xref rid="fig6" ref-type="fig">Fig. 6B</xref>).</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Two food location experiment. Panels</title>
<p><bold>A-D</bold>. Trajectory exemplars of four sequential stages of the experiment (all trials done with static entrance, N=8): <bold>(A)</bold> training target A (trials 1-A and 16-A for early and late learning, respectively); <bold>(B)</bold> probe A (no food is found, triggering a random search); <bold>(C)</bold> training target B (keeping A empty; trials 1-B and 8-B for early and late learning); <bold>(D)</bold> probe B-A (where both targets are trained and empty, and the mice take a shortcut from B to A; see Fig. S8 for all exemplars). Filled circles=filled target; empty circles=empty target. In the A and B learning stages, the trajectories evolve from random to going straight from start to the respective target. <bold>Panels E-F</bold>. Standard boxplot statistics of learning versus probe (diamonds are averages; asterisks: p&lt;0.05 in a paired t-test comparison). Quantities are defined in Fig. S4<bold>A</bold>. Significant differences between early and late learning were observed for the traveled distance <bold>(E)</bold>, heading angle <bold>(F)</bold>, and distance to the food line <bold>(G)</bold>. Density of hole checks <bold>(H)</bold> remained nearly constant, as expected. In all instances, the values of all quantities in the B-A probe resembled the values of the late learning trials, whereas the randomized B-A probe (gray) had values that resembled early learning, suggesting the B-A behavior is not random. In the Probe B→A trials, the “food line” is the straight line that connects B to A, along which the reference distance <italic>d</italic><sub><italic>target</italic></sub> is measured between A and B. In the other trials, the food line is a straight line from start to the specific target, either A or B, along which <italic>d</italic><sub><italic>target</italic></sub> is measured between start and target.</p></caption>
<graphic xlink:href="529984v4_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>After the probe trial, mice were trained to learn target B. During this training, 3 mice (Mouse 33, 35, 36) first learned a route to target B but, on subsequent searches, they would sometimes first check the site of the previous target A and then travel to the correct target B along a direct short cut route (see Discussion). Nevertheless, on average the mice kept farther from the previous site A than the expected by chance (Fig. S10A,B). A first visit to B then to A was never observed during training because mice go back home after getting the food in B.</p>
<p>After learning the location of target B (<xref rid="fig6" ref-type="fig">Fig. 6C</xref>), food was also omitted from this target for Probe B-A. As illustrated in <xref rid="fig6" ref-type="fig">Fig. 6D</xref> and the Supplementary Video (all mice shown in Fig.S8B), 5 of 8 mice were observed to go from B to A via varying trajectories (namely, mice numbered 33, 35, 36, 57 and 59). Two (number 58 and 60) of the remaining three mice went first to A and subsequently to B via direct or indirect routes; these mice had previously taken direct routes to B, suggesting that going to A first is not due to a learning deficiency. The remaining one, mouse 34, went from B to the start location and then, to A. This mouse had previously taken the B-A route during training. In all cases, the mice clearly remembered the location of both targets, even though target A had not been presented or rewarded for 4 days.</p>
<p>The geometric and kinetic features of these experiments for early and late learning of each target, and for Probe B-A, are presented in <xref rid="fig6" ref-type="fig">Fig. 6E-H</xref>. For defining the trajectory quantities in the Probe B-A trial, the “start” position is taken as target B, and the “target” is the A site (<italic>e</italic>.<italic>g</italic>., the normalized trajectory length is the ratio between total traveled and direct B-A distances). The quantities in probe B-A are statistically indistinguishable from late learning of targets (<italic>i</italic>.<italic>e</italic>., trials 14-A and 8-B). Conversely, all the Probe B-A values are significantly different both from trial 1-8 and from randomized B-A trajectories (see Methods; P&lt;0.05; except for the density of hole checks which is statistically equal for all considered trials, <xref rid="fig6" ref-type="fig">Fig. 6H</xref>). Therefore, the behavior of the mice when going from B to A in the probe is compatible with the behavior of an animal that acquired spatial memory about the trajectory, even though this trajectory was never reinforced. This suggests that the mouse computed the shortcuts without prior experience.</p>
<p>We calculated the displacement and hole check maps and the TEV for the whole training protocol, including the probe B-A (<xref rid="fig7" ref-type="fig">Fig. 7</xref>). Again, the data show that, after training for A, the TEV pointed directly to A and hole checks accumulated along its path (<xref rid="fig7" ref-type="fig">Fig. 7A,B</xref>). The beginning of training for B (trial 1-B) generated random search patterns, while the TEV and hole checks tended towards A. After learning B, we see that the TEV and hole checks completely shifted to it (<xref rid="fig7" ref-type="fig">Fig. 7C,D,E,F</xref>). Remarkably, the probe B-A trajectories revealed a strong directed flow with a TEV pointing from B to A, whilst hole checks visibly accumulated along this route (<xref rid="fig7" ref-type="fig">Fig. 7G,H</xref>). The TEVtarget deviation remained close to zero in late learning and probe B-A (<xref rid="fig7" ref-type="fig">Fig. 7I</xref>), whereas the area density of hole checks is increased near the target compared to far only after learning and in probe B-A (<xref rid="fig7" ref-type="fig">Fig. 7J</xref>). These maps suggest the emergence of a cognitive map guiding the mice when taking the B to A unrehearsed shortcut routes.</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7.</label>
<caption><title>Trajectory directionality and active sensing in two food location experiment.</title>
<p>Arenas on the top row (mean displacement vector) correspond to the ones immediately below them (hole checking spatial distribution); the red “A” and blue “B” labels mark the targets (food sites), which are pointed by the target vector (purple arrow). <bold>Top row (A</bold>,<bold>C</bold>,<bold>D</bold>,<bold>G)</bold>: the color and arrows indicate the most probable route taken (red=more probable; only p&lt;0.001 displacements shown; pink arrow=inferred target position, or TEV; shaded pink sector=S.D. of TEV; see Methods, and Fig. S7). <bold>Bottom row (B</bold>,<bold>E</bold>,<bold>F</bold>,<bold>H)</bold>: spatial distribution of hole-checks; size and color of circles=normalized frequency at which a hole was checked (larger gray circles=higher frequency); Black ellipse (x=mean): covariance of spatial distribution. Green ellipse (+=mean): covariance of spatial distribution restricted to ≤20cm of the target. Three stages of the experiment are shown (N=8; all training done in <bold>static entrance with no landmarks</bold>): after learning the target A (<bold>A</bold>,<bold>B:</bold> trial 16-A; significant routes and hole checks are observed only along the target vector, as expected); training of the target B (<bold>C</bold>,<bold>E</bold>: trial 1-B; <bold>D</bold>,<bold>F</bold>: trial 8-B; it shows the evolution of the TEV from pointing to A to pointing to B, and the hole checks distribution becomes limited to the newly learned target vector towards B); probe B-A (<bold>G</bold>,<bold>H</bold>) shows significant routes from B to A (shortcuts; N=5 out of 8 performed the route Start→B→A; see Fig. S8 for all samples); hole-checks accumulated along the B-A path suggesting that mice remember both locations. <bold>Panels I</bold>,<bold>J:</bold> TEV-target deviation and hole-check area density, respectively. Probe B-A measures are compatible with trials where trajectories have already been learned. Standard boxplot statistics. Diamond: mean. Asterisks/star: p&lt;0.05 (t-test).</p></caption>
<graphic xlink:href="529984v4_fig7.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>As a stringent control, we performed a two-food-locations experiment with a 180°-rotated probe B-A trial (<xref rid="fig8" ref-type="fig">Fig. 8</xref>; N=8). Landmarks were never present (neither for training nor for probe). In the rotated probe B-A, the mice went to the REL of B and then to the REL of A. The displacement map, hole check spatial distribution and TEV now all pointed from REL B to REL A (instead of B to A). This is consistent with both the independent experiments of the rotated probe with static entrance training and of the two-food location. Mice can thus take a novel short cut and have therefore computed a cognitive map based on a fixed starting point and self-motion cues alone.</p>
<fig id="fig8" position="float" fig-type="figure">
<label>Figure 8.</label>
<caption><title>Two food location training with 180° rotated probe.</title>
<p>Mice (N=8) are trained to find food in the target labeled “A” (red circle, panel <bold>A</bold>), and in target labeled “B” (blue circle, panel <bold>B</bold>) afterwards; then a 180° rotated probe trial (no food; panel <bold>c</bold>) is realized to check whether the mice are able to generalize and take the shortcut from RELB (blue triangle) to REL-A (red triangle), instead of the A and B targets. No landmarks are present. Panels <bold>A</bold>,<bold>C</bold>,<bold>E</bold> show exemplars of trajectories in three stages of the experiment, and <bold>B</bold>,<bold>D</bold>,<bold>F</bold> show their time course and hole-check locations marked with circles that increase with elapsed time. <bold>G</bold>. Trajectory directionality analysis and TEV (pink arrow; shaded sector: S.D.) show that significant paths (p&lt;0.001; N=8; see Methods) point from REL-B to REL-A in the same way that it pointed from B to A without rotated entrance in <bold><xref ref-type="fig" rid="fig7">Fig. 7G</xref>. Panel H:</bold> the spatial density shows that hole checks accumulate along the REL-B to REL-A direction, instead of the B-A direction in the case without rotation in <bold><xref ref-type="fig" rid="fig7">Fig. 7H</xref></bold>. Black ellipse (x=mean): covariance of hole check density. Green ellipse (+=mean): covariance of the same data restricted to ≤20cm of the REL-A location. This suggests that mice follow shortcut trajectories anchored to their start location (idiothetic frame of reference).</p></caption>
<graphic xlink:href="529984v4_fig8.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>We have shown that mice can learn the location of a hidden food site when their entrance to an open maze remains constant across trials. Trajectories initially appeared random and took, on average, over 100 seconds and covered a distance of about 10-fold that of the direct route between start and food sites (<xref rid="fig3" ref-type="fig">Fig. 3</xref>). After a maximum of 14 trials, mice reached asymptotic performance taking, on average, &lt;10 s to reach the food site and with trajectories reaching a near optimal distance: 1.4 times greater than the direct route (<xref rid="fig3" ref-type="fig">Fig. 3F</xref>). The pretraining trials had food randomly placed within numerous holes. In the spatial learning trials, mice frequently checked holes for food along their start to food trajectories. Analyses of hole checks demonstrated the distribution of hole check sites was also modified during learning (<xref rid="fig4" ref-type="fig">Fig. 4G,H</xref>). Hole check density decreased with learning in the first half of trajectories but remained constant during the second half. At higher spatial resolution, hole checks occurred most frequently closer to the food site after learning (<xref rid="fig4" ref-type="fig">Fig. 4K</xref>). Finally, the number of holes sampled near the food site became more consistent with learning (lower entropy: see Fig. S7G). We conclude that, given a static entrance, the mice can learn an accurate estimate of food location that guides their trajectories and associated hole check distribution.</p>
<p>Similar results have been reported for rats trained to find food in a virtual reality (VR) 2D spatial navigation task (<italic><xref ref-type="bibr" rid="c20">20</xref></italic>). During spatial learning, the reward check rate increased as the rat approached the reward edge for both visual and auditory reward location cues. Navigation (trajectories) and reward checking were, however, in register only for distal visual cues. In our experiments, hole checking at a reward site was not dependent on distal visual cues (see REL discussion below) suggesting that a different source(s) of spatial sensory input permits registration of trajectories and hole checking during real world (RW) spatial learning.</p>
<sec id="s3a">
<title>Exogenous cues are not required for learning the food location</title>
<p>A number of exogenous and self-motion cues might be responsible for the spatial learning we observed. The exogenous cues may include scratches or odor trails on the maze floor, odor gradients emanating from the mouse home cage, local odor cues from the food-filled hole, and visual cues from the prominent landmarks. Scratches and odor trails were eliminated by washing and rotating the maze floor between trials. Possible odor gradient cues were eliminated by experiments where such gradients were prevented with vacuum fans (Fig. S6E). Probe trials of fully trained mice resulted in trajectories and initial hole checking identical to that of regular trials thereby demonstrating that local odor cues are not essential for spatial learning. Reinforcing this conclusion is the observation that, even when a mouse ran directly to the food site, it still did hole checks at nearby empty holes before finally finding the food (<xref rid="fig4" ref-type="fig">Fig. 4H</xref>). The REL experiments strongly support all these conclusions as described below.</p>
<p>Rodent vision is important for tasks such as navigating complex environments, finding shelter, prey capture and predator avoidance (see (<italic><xref ref-type="bibr" rid="c21">21</xref></italic>) for a review). Previous behavioral and physiological studies suggested that our wall cues could be resolved by the mouse visual system (<italic><xref ref-type="bibr" rid="c22">22</xref>-<xref ref-type="bibr" rid="c26">26</xref></italic>). It was therefore surprising that the mice were unable to find the food site when its start location was randomly switched between trials. A comparison of static versus random start sites after learning revealed that, unlike the static case, there was no reduction of trajectory length or hole checks near the food site in the random start experiments. We considered whether the mice were learning slowly and simply needed more trials to learn the random start site task. We therefore checked if there was any improvement in target estimation over 3 successive trials. As shown in Fig. S8, actual hole checks over 3 trials are no different from randomized hole checks suggesting that the mice are randomly choosing holes to check.</p>
<p>The random start task requires the mouse to learn the relative location of food with respect to a changing view of the landmarks. Rats have been shown to be able to solve this task in the MWM (<italic><xref ref-type="bibr" rid="c7">7</xref></italic>). Previous studies showed that mice can use distal cues under different experimental conditions, such as in a one-dimensional T-maze, linear track, or when the cues consist of multiple highly salient cues (<italic><xref ref-type="bibr" rid="c7">7</xref>, <xref ref-type="bibr" rid="c27">27</xref>-<xref ref-type="bibr" rid="c30">30</xref></italic>). Our failure to observe spatial learning in the random entrance experiments may be due to the lesser saliency of our visual cues preventing their discrimination. Alternatively, it may be due to our pre-training procedure. Mice were hesitant to explore the center of the maze and, to expedite training, we ran “pretraining trials” where we omitted landmarks and placed treats in numerous holes (see Fig. S1A and Methods). It is therefore also possible that the mice learned to search randomly during pretraining and then continued to employ a random search strategy to find food during training trials when food location was not consistent over trials. Future experiments will be required to clarify these issues.</p>
</sec>
<sec id="s3b">
<title>A fixed start location and self-motion cues are required for spatial learning</title>
<p>We also considered that mice, unlike rats (<italic><xref ref-type="bibr" rid="c7">7</xref></italic>), may be unable to learn the random entrance task because it requires associating four different spatial cue configurations with a food location. In the static entrance task, the mice might be learning a unique configuration of the cues or even the relative location of a single cue and the food location (<italic><xref ref-type="bibr" rid="c6">6</xref></italic>). In the REL experiments we therefore first fully trained the mice with a static entrance and, in a probe trial, randomly switched them to another entrance rotated by 90°, 180°, or -90°. Unlike rats in the MWM (<italic><xref ref-type="bibr" rid="c7">7</xref></italic>), the mice ran to the REL location (<xref rid="fig5" ref-type="fig">Fig. 5</xref>) clearly demonstrating that they assume that their start location has not changed and that neither the visual cues nor any of the possible confounding cues guided the mice. Additional control experiments made without landmarks or in darkness also showed that visual input is not required for spatial learning in our maze (Fig. S6).</p>
</sec>
<sec id="s3c">
<title>Combining trajectories and the hole check distributions yields a Target Estimation Vector</title>
<p>Averaging trajectories gave a mean displacement direction. The mice, after learning with static entrances, made the greatest number of hole checks in the vicinity of the food-containing hole. We therefore used the mean of the “near food” hole check distribution (see <xref rid="fig4" ref-type="fig">Fig. 4</xref>) to give a magnitude to the displacement direction, thus generating the TEV. With learning, the TEV rapidly converged to closely approximate the direct start-to-food vector (<xref rid="fig4" ref-type="fig">Fig. 4E,F,I</xref>). In rotated trials, the calculated TEV pointed to the REL despite the lack of food at the hole check sites (<xref rid="fig5" ref-type="fig">Fig. 5</xref>). A close analysis of individual trajectories revealed that, while some closely approximated the TEV and went directly to food, others deviated from the TEV/direct route and then returned to it (<xref rid="fig4" ref-type="fig">Fig. 4F</xref> and S7D). The standard assumption is that deviations from a direct route are due to path integration errors (<italic><xref ref-type="bibr" rid="c31">31</xref></italic>). It is not obvious why errors only occur on some routes. A second possibility is that the deviations are intended and meant to prevent route predictability and therefore predation (<italic><xref ref-type="bibr" rid="c32">32</xref></italic>). It is not clear why the mouse does hole checks if it is only reducing route predictability. A plausible hypothesis is that the mice deliberately deviate from the TEV in order to continue exploring for food-containing holes, en route to exploit the food reward. We hypothesize that a path integration mechanism operates continuously to return the mouse to its computed TEV no matter what the reason for the deviations from the TEV.</p>
</sec>
<sec id="s3d">
<title>Implications for theories of hippocampal representations of spatial maps</title>
<p>The TEV is learned using self-motion cues alone and we hypothesize that it guides locomotion to the food hole via a path integration mechanism. This conclusion is in accord with an extensive literature that emphasizes the importance of self-motion cues and path integration for spatial learning (<italic><xref ref-type="bibr" rid="c8">8</xref>, <xref ref-type="bibr" rid="c33">33</xref></italic>). The conclusion is also not surprising given studies on weakly electric fish that demonstrate that, with a fixed initial location, active sensing and self-motion cues are sufficient for learning the location of a food site in the dark (<italic><xref ref-type="bibr" rid="c34">34</xref>, <xref ref-type="bibr" rid="c35">35</xref></italic>), and that accumulation of path integration error degrades performance as a function of trajectory length (<italic><xref ref-type="bibr" rid="c36">36</xref>, <xref ref-type="bibr" rid="c37">37</xref></italic>). Given the presumed accumulation of error by the mammalian path integration mechanism (<italic><xref ref-type="bibr" rid="c31">31</xref></italic>), it is generally assumed that proximal and/or distal exogenous cues must calibrate the putative path integrator in order to determine not only target direction but also target distance from a start site (<italic><xref ref-type="bibr" rid="c8">8</xref>, <xref ref-type="bibr" rid="c12">12</xref>, <xref ref-type="bibr" rid="c33">33</xref>, <xref ref-type="bibr" rid="c38">38</xref></italic>). Path integration gain of hippocampal neurons is a plastic variable that can be altered by conflicts between self-motion cues and feedback from landmarks (<italic><xref ref-type="bibr" rid="c38">38</xref></italic>). The independence of the TEV from landmark cues (REL experiments) again demonstrates that, in absence of such “conflicts”, self-motion provides consistent cues for path integration and spatial map formation.</p>
<p>The use of hole checking to compute a mouse’s estimate of the food location allows us to refine these conclusions. The TEV provides not only an estimate of the food location, but also of the distance from start to food site; this is especially clear in the REL experiments where, given the lack of food, a mouse’s search is clearly centered at the expected food location (<xref rid="fig5" ref-type="fig">Fig. 5</xref>). Sophisticated analyses have been used to link the spatial coding neurons of entorhinal, subicular and hippocampal neurons to behavioral studies on the interaction of exogenous and self-motion signals (<italic><xref ref-type="bibr" rid="c15">15</xref>, <xref ref-type="bibr" rid="c39">39</xref></italic>). Here, we provide strong behavioral evidence to support the role of hippocampal place cells in encoding the trajectories and food site locations observed in our study. Two studies suggest that, in the rat, CA1 place fields will remain stable in the absence of visual cues. Many place cells responses observed in the presence of visual cues will remain after these cues are removed; the authors conclude that self-motion cues are sufficient to maintain normal place fields (<italic><xref ref-type="bibr" rid="c11">11</xref></italic>). Experiments with blind rats have shown vision is not necessary for the development of normal firing of hippocampal place cells (<italic><xref ref-type="bibr" rid="c40">40</xref></italic>). Together, these studies suggest that mice CA1 cells will exhibit place fields in our open maze. Analyses of spatial learning in VR versus RW (rats) suggested that distal visual cues, and self-motion (i.e., proprioceptive, vestibular) cues may be required to activate place cells representing allocentric space. In the absence of distal visual cues, CA1 cells preferentially encoded distance traveled during learned trajectories toward a food goal (<italic><xref ref-type="bibr" rid="c41">41</xref>, <xref ref-type="bibr" rid="c42">42</xref></italic>).</p>
<p>Rats can learn to navigate, in VR, from different start locations to a hidden goal using very salient distal visual cues (<italic><xref ref-type="bibr" rid="c43">43</xref></italic>). Unlike RW spatial learning, CA1 pyramidal cells then only weakly encoded allocentric spatial information (place fields) but instead, primarily encoded trajectory distance and head direction. This suggests that these cells may comprise the neural implementation of the behavioral TEV in the VR case, which may share similarities with the corresponding implementation in the RW scenario. These experiments demonstrate great flexibility in the hippocampal encoding of trajectories and location both across pyramidal cells and, for individual cells, across the learned trajectory. An important question is how CA1 pyramidal cells will discharge as a mouse runs along the stereotyped trajectories learned with only self-motion cues as in our experiments. A stringent prediction of the discussion above is that mouse CA1 cells activated along trajectories towards the hidden food should be activated at equivalent locations in REL experiments, and in response to the same multiplexed cues: trajectory distance, head direction and allocentric location.</p>
<p>A subset of hippocampal (CA1) neurons in the bat were reported to encode the direction and/or distance of a hidden goal (<italic><xref ref-type="bibr" rid="c44">44</xref></italic>). The vectorial representation of goals by such cells could be the substrate of the start-to-food location trajectories we have observed. Recently described CA1 convergence sink (ConSink) place cells (<italic><xref ref-type="bibr" rid="c45">45</xref></italic>) may also have the properties needed to account for the learned start-to-food trajectories we observed. ConSink cells are directional place cells that can encode local direction towards a goal. ConSink cells will, with training, shift their direction tuning to a new goal. The ConSink population vector average, like the TEV, then points directly from start to goal. In both cited studies, landmarks were present, and it is unknown whether such cells will be found in the absence of visual cues.</p>
<p>ConSink-like cells were reported in the CA1 of a mouse foraging in an open field, but their direction tuning was not pointed towards a singular goal (<italic><xref ref-type="bibr" rid="c46">46</xref></italic>). We hypothesize that in the pretraining foraging phase of our spatial learning task, ConSink cells will also have random direction tuning. Upon fixed start location training, we hypothesize that the ConSink direction tuning will become aligned with the mouse’s trajectories and their population average will closely approximate the computed behavioral TEV. The TEV and the ConSink cell population average are statistical measures derived from behavioral and electrophysiological data respectively. An important question is whether an explicit TEV is computed and defines the spatial map guiding the mouse’s food-finding trajectories. An equally plausible hypothesis is that the “spatial map” remains a distributed computation in the CA1 targeted neural networks. Experimental tests of these alternatives address an essential question: how is spatial information represented in neural networks?</p>
<p>Numerous studies have reported that goal sites are overrepresented by CA1 place cells (<italic><xref ref-type="bibr" rid="c4">4</xref></italic>). The requirements for such overrepresentation are that there are stereotyped trajectories directed towards an invisible memory-based goal associated with reward (<italic><xref ref-type="bibr" rid="c4">4</xref></italic>). The stereotyped trajectories and the hidden memory-based goal of our study imply that these requirements are met. Interestingly, the “goal-related place cells” are activated before the goal is reached (<italic><xref ref-type="bibr" rid="c4">4</xref></italic>), just as hole checks mostly occur as the mice approach the food containing hole from any direction (<xref rid="fig4" ref-type="fig">Fig. 4F,H</xref>). We hypothesize that, after learning, CA1 place cells will overrepresent the maze region containing the goal location, and that their place fields therefore overlap the hole check sites surrounding the hidden food hole.</p>
<p>Behavioral time scale plasticity (BTSP) has been proposed to be the cellular mechanism that generates new CA1 place fields at important locations, including those associated with reward (<italic><xref ref-type="bibr" rid="c47">47</xref>-<xref ref-type="bibr" rid="c49">49</xref></italic>). BTSP operates up to a ∼3 s time frame. If BTSP is operating during spatial learning in our maze, there will be excessive place fields within the &lt;3 s search time before it finds the food hole. BTSP is bidirectional and can result in CA1 place fields translocating with experience (<italic><xref ref-type="bibr" rid="c49">49</xref></italic>) and the location of CA1 cell place fields may therefore evolve during static entrance training. We note that the cited experiments were done with virtual movement constrained to 1D and in the presence of landmarks. It remains to be shown whether similar results obtain in our unconstrained 2D maze and with only self-motion cues available.</p>
<p>The putative emergent CA1 place fields might be randomly distributed but might also be connected with the “special” hole check locations. We plotted the evolution of &lt;3 s from target hole checks in the static and random entrance experiments (Fig. S9). With spatial learning (static entrance), temporally “close to target” hole checks increase relative to temporally distant hole checks and converge to the target site. Active sensing is critical for electric fish spatial learning (<italic><xref ref-type="bibr" rid="c34">34</xref></italic>), and is also known to potentiate or induce CA1 cell place fields (<italic><xref ref-type="bibr" rid="c50">50</xref></italic>). We hypothesize that the persistent &lt;3s hole checks near the food site that increase during training will, via the BTSP mechanism, drive the emergence and translocation of CA1 cell place fields so that they accumulate centered on checked holes near the rewarded food site (<italic><xref ref-type="bibr" rid="c4">4</xref></italic>). This leads to the prediction that a place cell discharging during a hole check near the food site should also discharge after the mouse start site has been rotated and it checks an empty REL hole.</p>
</sec>
<sec id="s3e">
<title>Shortcutting – Evidence for a cognitive map derived from self-motion signals</title>
<p>The O’Keefe and Nadel text (<italic><xref ref-type="bibr" rid="c16">16</xref></italic>) connected hippocampal place cells to the abstract concept of a cognitive map developed by Tolman (<italic><xref ref-type="bibr" rid="c13">13</xref></italic>), and this linkage has been generally supported with few dissenting views (<italic><xref ref-type="bibr" rid="c51">51</xref>-<xref ref-type="bibr" rid="c54">54</xref></italic>). The criteria for a cognitive map are of animals taking unrehearsed shortcuts (<italic><xref ref-type="bibr" rid="c14">14</xref></italic>), detours (<italic><xref ref-type="bibr" rid="c13">13</xref></italic>) or novel routes (<italic><xref ref-type="bibr" rid="c7">7</xref></italic>). In this literature animals typically have both landmark and self-motion cues available for spatial learning. To the best of our knowledge, unrehearsed shortcut behavior using only self-motion cues and a fixed start location has only been shown in humans (<italic><xref ref-type="bibr" rid="c33">33</xref>, <xref ref-type="bibr" rid="c55">55</xref></italic>). Our result on shortcutting after spatial learning based entirely on a fixed start location and self-motion cues (<xref rid="fig7" ref-type="fig">Fig. 7</xref>) is therefore the first behavioral demonstration of a rodent cognitive map learned without exogenous cues and using the strict Tolman definition. The TEV for the shortcut trajectories well approximates the direct route between the Site B and Site A food locations (<xref rid="fig7" ref-type="fig">Fig. 7G,H</xref>) demonstrating the accuracy of the putative cognitive map food location estimate.</p>
<p>The shortcut trajectory from Site B to Site A (<xref rid="fig7" ref-type="fig">Fig. 7G,H</xref>) might be formally computed in two ways. For the 3 mice that first took the Site A to Site B route during training, the following vector arithmetic is required for the final trial when it went from Site B to Site A:
<disp-formula id="ueqn1">
<graphic xlink:href="529984v4_ueqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
For the 4 mice that had never taken the Site A to Site B route during training, the following vector arithmetic is required for the final Site B to Site A shortcut:
<disp-formula id="ueqn2">
<graphic xlink:href="529984v4_ueqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
The TEVs for Start-&gt;A and Start-&gt;B appear to be still remembered by the mice in the probe trial, since the accumulation of hole checks at both sites is still evident (<xref rid="fig7" ref-type="fig">Fig. 7H</xref>). The hypothesized ConSink place cells directed to Targets A and B and the accumulation of cells with place fields at both sites will therefore, as described above, still encode the trajectories to each location. To our knowledge, neurons that might compute the required vector arithmetic have not been identified in any part of the rodent brain.</p>
<p>We hypothesize that the TEVs estimated by neural networks downstream of goal vector cells, CA1 ConSink cells and goal location place field cells will be used to compute the shortcut trajectories. Discovering the networks that do these putative computation(s) may provide insight into the neural bases of the spatial cognitive map.</p>
</sec>
</sec>
<sec id="d1e1515" sec-type="supplementary-material">
<title>Supporting information</title>
<supplementary-material id="d1e1601">
<label>Supplementary Figures</label>
<media xlink:href="supplements/529984_file02.pdf"/>
</supplementary-material>
<supplementary-material id="d1e1608">
<label>Supplementary Video</label>
<media xlink:href="supplements/529984_file03.mp4"/>
</supplementary-material>
</sec>
</body>
<back>
<sec id="s4">
<title>Author Contributions</title>
<p>All experiments were carried out in the L.M. laboratory at the University of Ottawa. J.X ran all experiments, analysed learning and contributed to experiment design, writing the manuscript and preparing figures. M.G-S. developed analysis for trajectories and hole checks, and carried out the analyses plus associated figures and contributed to writing the manuscript. J-C. B. contributed to writing the manuscript. A.L. contributed to developing trajectory analysis methods and writing the manuscript. L.M. developed the conceptual framework for the experiments and contributed to and supervised all aspects of the experiments and data analyses and wrote the manuscript.</p>
</sec>
<ack>
<title>Acknowledgments</title>
<p>We would like to thank Dr. Érik Harvey-Girard for technical support, and William Moldenhauer de Jesus for joining the short cut experiment video with the hole check data. This work was supported by the Canadian Institutes for Health Research Grant # 153143 to AL and LM and J-C B, a Brockhouse award (493076-2017) to AL and LM, an NSERC award (RGPIN/06204-2014) to AL, an NSERC award to LM (RGPIN/2017-147489-2017) and a grant from the Krembil Foundation to AL, LM and J-C B.</p></ack>
<sec id="s5">
<title>Data availability</title>
<p>All codes and data are available in <ext-link ext-link-type="uri" xlink:href="https://github.com/neuro-physics/mouse-cogmap">https://github.com/neuro-physics/mouse-cogmap</ext-link></p>
</sec>
<sec id="s6">
<title>Declaration of interests</title>
<p>The authors declare no competing interests.</p>
</sec>
<sec id="s7">
<title>Material and Methods</title>
<sec id="s7a">
<title>Animals</title>
<p>All animals were housed in the University of Ottawa Animal Care and Veterinary Services (ACVS) facility. C57Bl/6 wild-type male and female mice were ordered from Charles River, arriving at 8-9 weeks old. Mice were individually housed in 12h light/12h dark cycles (lights on at 11:00PM EST, lights off at 11:00AM EST). Animals had had food and water available <italic>ad libitum</italic>. The temperature of the room was kept at 22.5°C and the humidity was 40%. Mice were habituated in ACVS facilities for 1 week and began testing when they were 10-11 weeks old. Testing of each cohort took place over the course of approximately 2 weeks, 1 hour after the lights turned off. Subjects weighed 22-27 grams at the start of behavioural training. Both male and female mice were used; the same results were obtained in both sexes and were therefore pooled. All animal procedures were conducted with the approval of the University of Ottawa’s Animal Care Committee and in accordance with guidelines set out by the Canadian Council of Animal Care.</p>
</sec>
<sec id="s7b">
<title>Apparatus Design &amp; Setup</title>
<p>The Hidden Food Maze (HFM) is a framework that trains mice to search for a food reward hidden in an open, circular arena (<xref rid="fig1" ref-type="fig">Fig. 1</xref>). The protocol for the task was inspired by an open maze protocol used to study electric fish spatial learning (<italic><xref ref-type="bibr" rid="c35">35</xref></italic>) and by the Cheese Board spatial task in which rats are placed inside an arena with many holes in the floor, one of which contains a food reward (<italic><xref ref-type="bibr" rid="c56">56</xref></italic>). Unlike the Kesner et al task, the HFM does not require the animal to be handled, and the pattern of holes is arbitrary rather than grid-like. This task design was also chosen to mirror the setup of the Morris Water Maze (MWM) (<italic><xref ref-type="bibr" rid="c7">7</xref></italic>), which can test allothetic or idiothetic navigation. Like the MWM and the electric fish arena, mice are searching for a food reward location in a circular environment after starting from one of four starting home locations. External landmarks can, if desired, be placed on the maze walls or local cues placed in the maze. In contrast to the MWM, this spatial learning task is a dry maze that is food motivated, which is more naturalistic and less stressful than motivation by the aversion to swimming and fear of drowning. Notably, the task has specific design features to control for against unwanted cues, such as odours, visual cues, and handling.</p>
<p>The maze has a removable floor that is washed &amp; rotated between trials to eliminate odor trails which mice from previous trials might leave behind. The circular floor is 120 cm in diameter and has 100 holes (1.2cm diameter) randomly dispersed throughout the surface, with 25 holes in each quadrant. The distance between each hole is, on average, 10 cm. The pattern of the holes is rotationally symmetrical, so the pattern looks the same regardless of whether the floor is rotated 90°, 180°, or 270° with respect to the mouse’s entrance. This ensures that the mouse will have the same initial view of the holes regardless of which entrance it starts from and how the floor is rotated. Each hole is encircled by a 1 cm plastic rib, sticking downwards, which can be capped at the bottom to hold food that remains invisible from the surface. Thus, the mice cannot discern the contents of the hole just by looking across the floor from their home, but instead need to approach the hole and look inside. The surface of the floor is sanded to be matte to avoid generating reflections from the lights which might interfere with the cameras or distract the mice.</p>
<p>The maze floor is circular and uniform from the inside so as not to provide any directional cues. The floor of the arena is encircled by tall black walls. The walls are made of solid black PVC plastic which forms a cylinder around the maze and is open at the top. The walls are 1 cm thick and 45 cm tall, which is tall enough so the mice cannot jump out. The walls are symmetrical and designed to eliminate geometric cues that would give away directional information from asymmetries in the environment shape. Mice can use odors as landmarks for spatial learning (<italic><xref ref-type="bibr" rid="c19">19</xref></italic>) and we wanted to eliminate local food odour from a filled hole as a landmark. The arena is resting on a subfloor that contains crumbled food; food odor will diffuse through the open holes and saturate the maze thus masking the odor from a food-filled hole.</p>
<p>The home cages attach to the main arena by being slotted into each entrance. The home cages are 27cm x 16.5cm x 45cm and are open at the top. They contain a food hopper and a water bottle feeder. The dimensions of the home cage are based on commercial mouse cages and comply with the Canadian Council on Animal Care mouse housing standards.</p>
<p>When moving mice to a different starting quadrant, the home cages are designed to slide out from the maze and into a new entrance so the mice do not need to be handled and will therefore not be stressed. The home cages include their own doors, separate from the doors that provide entry into the maze, so the home cage can be freely moved and the mice remain securely confined. The detachable home cages allow the mice to be moved to different starting locations, allowing us to control against navigational strategies that rely solely on response learning or pathintegration from a fixed starting point.</p>
<p>Mice can perform the entirety of the trial without experimenter handling. The maze doors are designed to slide upwards and provide access to the main arena. When the trial is finished, the experimenter can slide the doors back into place and the mouse is confined to its home cage once again. To not disturb the mice, the doors are left open while they navigate.</p>
<p>Four LED flashlights were aimed at a white ceiling in order to create dim, diffuse lighting throughout the maze. The illuminance is measured to be 50 lux at the surface of the arena. Dim light was used to allow the mice to properly see all visual cues as well as the maze details. This procedure is assumed to not perturb the nocturnal cycle of mice (<italic><xref ref-type="bibr" rid="c57">57</xref>, <xref ref-type="bibr" rid="c58">58</xref></italic>). Black curtains surrounded the maze to prevent the interference of non-controlled visual cues.</p>
<p>We used additional experiments to control for possible visual or odorant cues from the open home door. We did some experiments in total darkness using infrared LEDs with emission spectra detected by our camera. In order to exclude any potential olfactory cues emanating from the open cage door we did experiments where odor absorbent kitty litter was placed on the cage floor and two connected exhaust fans (AC Infinity MULTIFAN S5, Quiet Dual 80mm USB Fan) placed above the home cage. At their lowest (quiet) setting, the fans drew air from the home cage and blew it to the outside; replacement air from the outside came in via small openings at the bottom of the home cage. The home cage air volume was evacuated 30 times/minute, effectively equilibrating the cage and open maze air before the doors were slid upwards. Fans were turned on for 5 minutes (150 evacuations) before the trial started and for the duration of the trial. After the door was opened, the fans induced negative pressure to eliminate diffusion of odors from the home cage to the maze. The two fans were placed over each home cage and turned on to eliminate a potential directional noise cue.</p>
</sec>
<sec id="s7c">
<title>Behavioural Training</title>
<sec id="s7c1">
<title>Pre-training</title>
<p>Five days before training, mice are transferred from standard animal facility cages to the experimental home cages for habituation. On the first day, mice are allowed to habituate to their new home cages. On the second day, the door dividing the home cage and the arena is removed and each mouse is given free access to explore the empty arena for 10 minutes. There are no extra-maze landmarks present during pretraining. Animals are food restricted, with 10% of their body weight in food given back each day which they could consume <italic>ad libitum</italic>. On day 3, randomly chosen 50% of the holes in the arena are filled with food treats (a piece of Cheerio), and each mouse is given 10 minutes to forage for food. This is repeated on day 4, where 25% of the arena’s holes are filled with food treats. On day 5, only four holes placed at the maze center contained treats. Mice pass the pre-training stage when they successfully found treats at all locations within 20 minutes. Mice mostly confined their search to circular trajectories near the wall of the maze for Days 3 and 4 but, after training with food near the maze center (Day 5), they checked holes throughout the maze (Fig. S1A). Training in the spatial learning task then commenced.</p>
</sec>
<sec id="s7c2">
<title>Visual Cues + Randomized Entrances Training</title>
<p>The mice are trained to locate a food reward that has a fixed relationship with four visual cues on the walls. The protocol mimics classic Morris Water Maze setups to test allocentric landmark-based learning. One of the holes in the area is capped from the bottom with a food-containing insert that is not visible from the surface. Extra-maze landmarks (described in the Visual Cues section) are placed on the walls of the maze to serve as location cues. At the start of the trial, the door is slid upwards so the mice can enter the maze, and the mice are given a maximum of 20 minutes to find the target hole. The home door is kept open to permit the mice free access to return to their home cage during the trial; preliminary experiments indicated that closing the door perturbed the mice. The door is re-inserted after the mouse has found the food reward and returned home. If the mouse has not returned home by itself after 1 minute of finishing the food reward, it is gently guided back by the experimenter. There is an inter-trial interval of approximately 20 minutes.</p>
<p>Initial experiments used two trials per day but this was increased to speed up learning; our analyses and graphs are truncated at 14 trials to permit averaging over all the mice. In most experiments, three trials a day were given, over six days; at the end of each trial the mouse’s home is moved to a different entrance. The home location was changed for each trial; the floor was washed and rotated by 90°, 180°, or 270° between trials, independent on whether the home entrance was the same (static trials) or rotated (random trials). The location of the entrance is randomized with the following constraints: no two trials in a row have the same entrance, and all entrances are selected the same number of times so there is no bias. On the 7th day, a probe trial is given where the mouse is allowed to search for food in the absence of any food. Learning continues over 1 more day and, on the 9<sup>th</sup> day, a reversal trial is given where the visual landmarks are rotated by 180°. The location of the home cage is randomized before every trial. In this task, the mouse would have to learn the invariant relation between the food hole and up to four visual cues in order to locate the food.</p>
<sec id="s7c2a">
<title>Visual Cues</title>
<p>Four black symbols on white backgrounds: a square, a cross, vertical bars, and horizontal bars. The cues are taped 5 cm above the floor. The square was 15 by 15 cm. The cross consisted of two 2.5 cm wide and 14 cm long bars. The four vertical and four horizontal bars were 2.5 cm wide and 14 cm long. Previous behavioral studies have shown that mice can discriminate the visual stimuli we use (<italic><xref ref-type="bibr" rid="c22">22</xref>, <xref ref-type="bibr" rid="c24">24</xref>, <xref ref-type="bibr" rid="c25">25</xref></italic>). Recording of neurons in mouse V1 have additionally shown that orientation selective cells in mice visual cortex can discriminate our visual stimuli (<italic><xref ref-type="bibr" rid="c23">23</xref></italic>).</p>
</sec>
</sec>
<sec id="s7c3">
<title>Visual Cues + Static Entrance Training</title>
<p>This protocol allows mice to navigate by potentially using visual cues in cooperation with path integration or by path integration alone. The setup is the same as visual cues training, except mice enter from the same entrance each trial instead of a randomized entrance. Mice are considered well trained once their latency learning curve has plateaued for 3 successive trials. The mice’s latencies had plateaued by 14 trials but training continued till 18 trials.</p>
<p>After 18 trials, reversal trials were done with no food present and the mouse’s home cage rotated 180°. The mouse was allowed to search for food for 10 minutes. If the mice were able to learn the invariant landmark/food spatial relationship, we would expect them to search at the learned food site. If they had used path integration of self-motion cues to navigate from the fixed entrance to the food, we would expect them to search at the rotationally equivalent location (REL).</p>
</sec>
<sec id="s7c4">
<title>Rotationally Equivalent Location (REL)</title>
<p>The four quadrants of the arena’s floor are identical. This means that the position of the holes in the second quadrant (Q2, <xref rid="fig1" ref-type="fig">Fig. 1B</xref>; also Fig. S4A) is equal to the position of the holes in the first quadrant (Q1) rotated by 90° counter clockwise (CCW) about the center of the arena. Q3 is Q1 rotated by 180° (CCW) and Q4 is Q1 rotated by -90° (i.e., 90° CW). In other words, every hole in Q1 has an REL in each quadrant achieved by the respective rotation. The REL target works in the same way: it is the position (relative to the entrance used in the trial) where the food would have been had the mouse been trained from the entrance it used in the trial. To illustrate this, consider <xref rid="fig1" ref-type="fig">Fig. 1D</xref>: we put the food (target) in a particular hole in Q1 for a mouse that is trained to enter from Q2 (such as the example in <xref rid="fig1" ref-type="fig">Fig. 1B</xref>) in the static entrance protocol. The vector that points from the mouse’s start point (in Q2) to the target in Q1 (i.e., the target vector) is “anchored” to the start position at Q2. For example, in the mouse’s perspective, the target vector is equivalent to going forward for 70cm, and then turn left and follow for another 30cm. If in a probe trial, we now let the mouse enter from Q4 instead, there are two options: either the mouse uses the landmarks and searches for the food in Q1 (where the food actually used to be), or it follows the target vector (70cm forward + 30cm left) and goes to the REL location of the target in Q3. Following the target vector is a sign of path integration using self-motion signals (idiothetic cues).</p>
</sec>
</sec>
<sec id="s7d">
<title>Control Experiments</title>
<sec id="s7d1">
<title>Rotations following Static Entrances – with and without visual cues</title>
<p>We performed additional tests for the use of visual landmarks in the Visual Cues + Static Entrance protocol. Well-trained mice had their home cages rotated to another quadrant and tested on how well they found the food from a new starting location. Mice were rotated 180°, 90°, and then -90° with respect to their original location (<xref rid="fig5" ref-type="fig">Fig. 5A,B,C</xref>). Mice were given 6 consecutive trials at each new location. One control group of mice had the visual cues on the arena wall removed during rotation training. If mice were able to use visual cues, we would expect them to improve their search efficiency when visual cues were available. Lack of improvement or similar performance compared to the control group without visual cues suggests that the mice do not rely on the type of visual cues we provided for spatial learning and navigation.</p>
</sec>
<sec id="s7d2">
<title>Navigating and Training without visual cues and in Darkness</title>
<p>To control for the effects of all visual information, one cohort (4 mice) was trained and tested without any cues (Fig. S6A,B). A second cohort (4 mice) was trained in the light according to the Visual Cues + Static Entrance protocol, then the lights are turned off and the mice are given a trial in darkness (Fig. S6C,D). The lights were opened in between trials so the mice did not acclimatize to the darkness. Mice were tracked using infrared LEDs with emission spectra detected by our camera. The following conditions were tested: darkness during a regular trial with food present in the arena and during a probe trial where there is no food present in the arena; both conditions gave the same results.</p>
<p>We additionally both trained and tested a cohort (4 mice) in darkness and with control of potential odors. A recent study has shown that placing sighted mice in darkness impairs entorhinal cortex head direction cell tuning(<italic><xref ref-type="bibr" rid="c18">18</xref></italic>), but here the mice successfully learned to find food and with the same time course of learning (Fig. S6E,F).</p>
</sec>
<sec id="s7d3">
<title>Two Food Location Training</title>
<p>This protocol aims to test flexibility of spatial learning using only path integration (N=8 mice). No visual cues are placed on the arena walls. Mice entered the arena from the same entrance each trial. Food was placed in a target well in “Target A” and mice were trained to find this location for 18 trials, 3 trials a day. A probe trial (“Probe A”) was done after trial 18. For trials 1926, the food was moved to a different location, “Target B”, and mice are trained to find the new location. We were careful to choose Target B so that Target A and B were not symmetric with respect to the mouse’s entrance. A second probe trial (“Probe B-A”) was done after trial 26. The purpose of the “Probe B-A” trial is to check whether mice take a shortcut between B (latest learned target position) and A (first learned target position). For some cohorts, the training continued until trial 34 and a third probe was given.</p>
</sec>
<sec id="s7d4">
<title>Two Food Location Training with rotated probe</title>
<p>The mice (N=8) were trained exactly as in the “Two food location” experiment described above. However, the mice start location was rotated by 180° prior to the second probe trial. This protocol joins the “Static entrances with rotated probe” protocol with the “Two food location protocol”, and is designed to provide further support for our path integration hypothesis. Each of the trained targets have their REL counterparts (180° rotated around the center of the arena). Now, the purpose of the rotated “Probe B-A” trial is to check which of the two options will happen: either mice take shortcuts between B (latest learned target position) and A (first learned target position); or they take shortcuts between REL B and REL A, supporting path integration via self-motion cues.</p>
</sec>
</sec>
<sec id="s7e">
<title>Behavioural Analysis</title>
<p>Path tracking was done with Ethovision XT15 (Noldus) based on contrast detection. Mice were tracked according to 3 body points at 30 frames per second on a 1080P USB camera with OV2710 CMOS. Videos were first recorded on AMCap webcam recording software and imported into Ethovision in order to preserve high quality videos. Trajectory plotting was done in Python.</p>
<p>Latency to target was calculated from when the nose point of the mouse enters the arena until the nose of the mouse enters the target hole. Trajectory analyses are based on the nose point sequence of the mouse. Speed and distance were calculated based on trajectory coordinates exported from Ethovision.</p>
<p>Search bias during probe trials is calculated by totalling the time a mouse spent within a 30x30cm square centered around the target vs. the RELs in the other 3 quadrants during a 2minute trial (<xref rid="fig2" ref-type="fig">Fig. 2C</xref>, <xref rid="fig3" ref-type="fig">Fig. 3C</xref>).</p>
</sec>
<sec id="s7f">
<title>Statistical Tests</title>
<p>Significance testing was conducted in a manner that was appropriate for each dataset. Paired comparisons utilized the t-test for parametric data and the Wilcoxon signed-rank test for non-parametric data. The significance cut-off was set at 0.05. Statistics were calculated either using R (URL <ext-link ext-link-type="uri" xlink:href="http://www.R-project.org/">http://www.R-project.org/</ext-link>) or scipy 1.8.0 in python 3.8.2. The statistical significance testing of the trajectory directionality analysis was developed from first principles, since it involves angular variables (the direction of each vector). It is presented in the “Analysis of Trajectories” section ahead.</p>
<p>Figures showing a quantity evolution over trials [<xref rid="fig2" ref-type="fig">Fig. 2D-I</xref>; <xref rid="fig3" ref-type="fig">Fig. 3D-I</xref>; <xref rid="fig4" ref-type="fig">Fig. 4I</xref>; Fig. S4; Fig. S7E; Fig. S10A,B] have symbols as averages, error bars as standard error, and the shading around the curve corresponds to the full data range (lower and upper shading limits correspond to minimum and maximum sampled data points, respectively).</p>
<p>Boxplot figures [<xref rid="fig4" ref-type="fig">Fig. 4J,K</xref>; <xref rid="fig6" ref-type="fig">Fig. 6E-H</xref>; <xref rid="fig7" ref-type="fig">Fig. 7I,J</xref>; Fig. S7L] have the diamond symbol as the average, the thick black line as the median, the box covering the interquartile range (IQR), and the whiskers extend from the box limits to ± 1.5IQR in both directions. No outliers were detected in any of these plots.</p>
</sec>
<sec id="s7g">
<title>Randomized trials</title>
<p>For the Two Food Location experiment, we calculated a randomized version of the Probe B-A trial for comparison. It consisted of extracting ten random pieces of the trajectory. Each piece was defined by randomly selecting a pair of points in the trial trajectory that are separated by the B to A distance. Then, the particular quantity of interest was averaged over each piece of the trajectory, and these averages were then averaged to obtain a single value for the “Probe B-A Rand.” condition in <xref rid="fig6" ref-type="fig">Figs. 6</xref> and <xref rid="fig7" ref-type="fig">7</xref>. See Fig. S8 for a definition of the quantities.</p>
</sec>
<sec id="s7h">
<title>Statistical Analysis of Trajectories</title>
<sec id="s7h1">
<title>Experiment Alignment</title>
<p>The procedure described in this section is applied to calculate trajectory directionality (and hence the target estimation vector, TEV) and the hole checking spatial distributions. Each mouse in the Random Entrance experiment started from a different quadrant of the arena, for each consecutive trial, and the target was fixed relative to the arena (global reference frame). However, in order to increase sampling, we need to coherently align the mice entrances, generating the mouse’s perspective reference frame (see Fig. S1B-F). Each experiment batch was performed with four mice, such that at any given trial, a given mouse entered from quadrant 1 [Fig. S1C], another entered from quadrant 2 [Fig. S1D], the next entered from quadrant 3 [Fig. S1E], and the last entered the arena from quadrant 4 [Fig. S1F]. Most of the experiments, then, consisted of two different batches of four mice that had to be conveniently aligned to increase sampling. In this figure, we aligned all the entrances to the Start point at the top of the arena (trajectories were rotated accordingly), emphasizing the four possible positions of the target from the mouse’s perspective.</p>
<p>We had to find a way to align all the targets in a given trial to one of the four possible positions, such that the experiment stays coherent over trials (i.e., the target randomly switches in between these four positions from trial to trial). For example, in Fig. S1B-F, we show trial 14. The target position for each starting quadrant is labeled with a red letter A and a red circle, whereas the target for the previous trial is labeled with a green circle and a green letter A subscripted with “trial 13”. These two positions (trial and previous trial) must always be different to keep the random characteristic of the experiment.</p>
<p>Notice that the target positions in each of the panels D, E and F in Fig. S1 are simply rotated relative to the target positions in panel C. The target configuration in panel D is 90° clockwise rotated relative to the target configuration in panel C. The configuration in panel E is 180° clockwise rotated, and panel F, 270° clockwise rotated; both angles are relative to the configuration in panel C. Thus, in order to sample all the mice together, we simply rotate the trajectories from the mice that started in quadrant 2 [panel D] counter-clockwise by 90°; the trajectories from the mice that started in quadrant 3 [panel E] are rotated by 180° counter-clockwise; and the trajectories starting from quadrant 4 [panel F] are rotated by 270° counter-clockwise. This reduces all the experiments to the first quadrant, allowing us to sample all the trajectories of all the mice together in each individual trial.</p>
</sec>
<sec id="s7h2">
<title>Active sensing and hole-check detection</title>
<p>We developed an algorithm to detect the mouse’s behavior of sniffing holes to detect food as a measure of active sensing. The hole checking events are used to infer the mouse’s memory and uncertainty about its environment. We then compute the spatial distribution 𝒫(<italic>X</italic><sub><italic>i</italic></sub>, <italic>Y</italic><sub><italic>i</italic></sub>) for the count of hole checks for each hole <italic>i</italic> positioned in (<italic>X</italic><sub><italic>i</italic></sub>, <italic>Y</italic><sub><italic>i</italic></sub>) in the arena, accumulated across all mice in a given experiment (<xref rid="fig4" ref-type="fig">Fig. 4C,D,G,H</xref>; <xref rid="fig5" ref-type="fig">Fig. 5C</xref>; <xref rid="fig7" ref-type="fig">Fig. 7B,E,F,H</xref>; <xref rid="fig8" ref-type="fig">Fig. 8C</xref>; and Fig. S1B-F; usually N=8 mice for each experiment), and normalized by the total count. The frequency of checks in each hole is coded both in the color and size of the filled circles: larger gray circles correspond to larger number of checks in that particular hole (pink small circles is a small number of checks). The black ellipsis marks the covariance of the 𝒫(<italic>X</italic><sub><italic>i</italic></sub>, <italic>Y</italic><sub><italic>i</italic></sub>) spatial distribution (“x” in the figures marking the mean position of hole checks). It is constructed from the eigenvalues and eigenvectors of the covariance matrix <italic>C</italic> of the hole check coordinates (<italic>X</italic><sub><italic>i</italic></sub>, <italic>Y</italic><sub><italic>i</italic></sub>) weighted by 𝒫(<italic>X</italic><sub><italic>i</italic></sub>, <italic>Y</italic><sub><italic>i</italic></sub>): the eigenvectors give the directions of the ellipsis semi-axes, whereas the eigenvalues give the width of each semi-axes. The center of the ellipsis (mean of the ellipsis’ foci) is aligned with the mean of the spatial distribution.</p>
<p>Under the path integration hypothesis, it is expected that error accumulates as the mouse walks(<italic><xref ref-type="bibr" rid="c15">15</xref></italic>). This is consistent with the increase in number of hole checks per unit area near the target (<xref rid="fig4" ref-type="fig">Fig. 4J,K</xref>; “near”=less than 20cm away from the target). We consider that the change in number of hole checks measures the variability of the mouse’s estimate of the target position.</p>
<p>We therefore calculate the mean and covariance of the distribution of hole check events restricted to within 20cm of the target (again, the green “x”=mean). The distance from the start to this restricted mean is used to scale the TEV vector (see next section).</p>
<p>The arena design forces the mouse to put its nose very close to the hole to be able to see the food or detect any food odour. With that in mind, we defined two methods for detecting a hole check (see Fig. S2A,B, and Supplementary Video). The two methods are complementary, and the second can find hole-check events missed by the first method: we apply the first method, then perform a visual check on the data to see if there were potential hole-checks that were missed. Then, we apply the second method to capture any remaining events.</p>
<p>The first method is the minimum velocity criterion and provides a high threshold for hole check identification. Four conditions must be satisfied simultaneously to detect an event: (i) the nose of the mouse must be within 3 cm of an arena hole; (ii) the velocity has to be less than 20% its maximum value; (iii) the velocity must be at a minimum; and (iv) the velocity has to have dropped by at least 5 cm/s to reach that minimum.</p>
<p>The second method is more inclusive and defines a hole-checking event by a simple slowing down event, provided that: the nose is within 3 cm of an arena hole, and the slowing down is enough for the velocity to drop past the 20% threshold of its maximum.</p>
<p>The detected events by the application of these two methods in sequence are marked for all trajectory samples of the Probe B-A in Fig. S8B as examples. A particular case is shown in more details in Fig. S2, and in the Supplementary Information Video (mouse_36_Probe2_hole_check_synchronized.mp4) with the recording of a mouse’s performance. It is worth mentioning that in the video, there is a clear hole-check miss by our algorithm in the 25 to 27 second range. This is because the velocity of the mouse was already below the 20% maximum before and after the hole check, hence the two sets of criteria defined above were not met for this particular event and it was counted by the manual check. Otherwise, we clearly see that all the other events are captured by sequential use our two methods.</p>
</sec>
<sec id="s7h3">
<title>Trajectory directionality (displacement map)</title>
<p>This analysis is a way to visualize mouse trajectories and directionality across all the mice for each trial. It is related to a velocity map of the arena, except that here, the arrows point in the direction of most probable movement instead of the direction of the velocity. Fig. S2B shows a scheme for how we compute this map, and we detail it below. We call this quantity as the “displacement map”, since it gives the displacement of the mouse for each position in the arena. In this section, we explain how to calculate the displacement map for a single sample of <italic>N</italic> mice. The procedure here is applied to each individual trial independently (either during learning, or for a probe trial). This map is used for inferring the learned directionality of the target (relative to entrance). The error, average and significance of this quantity is estimated from first principles by a jackknife procedure explained in the next section. In the figures we show the average displacement map vectors that were found to be significant. These maps are then used to compute the target estimation vector (TEV; detailed in the last section).</p>
<p>We start by overlaying a lattice of size <italic>L</italic> on top of the arena recording. This means that there are <italic>L</italic> boxes on the <italic>x</italic> (horizontal) direction, and <italic>L</italic> boxes on the <italic>y</italic> (vertical) direction, making a total of <italic>L</italic><sup>2</sup> boxes in the lattice. Each box defines a lattice site with coordinates (<italic>x, y</italic>), such that <italic>x</italic> and <italic>y</italic> are integers between 1 and <italic>L</italic>. Each mouse corresponds to an independent observation of a trajectory, so we overlay all mice trajectories for each trial separately in the calculations below. Next, we map the coordinates of the trajectories into the lattice coordinates in order to obtain a temporal sequence of visited lattice sites in each trial. We are interested in counting the number of times that each subsequent pair of adjacent lattice sites appears in this sequence, regardless of what mouse it came from. This will be used to define the displacement map, detailed in what follows.</p>
<p>The displacement map <inline-formula><inline-graphic xlink:href="529984v4_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is a vector field defined on the lattice that assigns to each site the preferential direction of movement. This direction is estimated from the trajectories data. Mathematically, it can be written as <inline-formula><inline-graphic xlink:href="529984v4_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, <italic>M</italic><sub>𝒱</sub>(<italic>x, y</italic>)], where <italic>M</italic><sub><italic>h</italic></sub> is the horizontal component and <italic>M</italic><sub>𝒱</sub> is the vertical component. The horizontal component expresses the trend to move to the left or right (along the lattice <italic>x</italic>-axis), and the vertical component in the perpendicular direction, <italic>i</italic>.<italic>e</italic>., “up” or “down” in the top view of the lattice of Fig. S2D (along the lattice <italic>y</italic>-axis). Each component is a function of the lattice coordinates, (<italic>x, y</italic>). The vector <inline-formula><inline-graphic xlink:href="529984v4_inline3.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is defined as the spatial gradient of the probabilities to move out of (<italic>x, y</italic>) towards one of its adjacent sites. Thus, its components are given by
<disp-formula id="eqn1">
<graphic xlink:href="529984v4_eqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>P</italic><sub>→</sub>(<italic>x, y</italic>) is the probability of stepping right, <italic>i</italic>.<italic>e</italic>., from (<italic>x, y</italic>) to (<italic>x</italic> + 1, <italic>y</italic>); <italic>P</italic><sub>←</sub>(<italic>x, y</italic>) is the probability of stepping left [from (<italic>x, y</italic>) to (<italic>x</italic> − 1, <italic>y</italic>)]; <italic>P</italic><sub>↑</sub>(<italic>x, y</italic>) is the probability of stepping up [from (<italic>x, y</italic>) to (<italic>x, y</italic> + 1)]; and <italic>P</italic><sub>↓</sub>(<italic>x, y</italic>) is the probability of stepping down [from (<italic>x, y</italic>) to (<italic>x, y</italic> − 1)]. The probabilities of stepping out of (<italic>x, y</italic>) must be normalized, therefore <italic>P</italic><sub>→</sub>(<italic>x, y</italic>) + <italic>P</italic><sub>←</sub>(<italic>x, y</italic>) + <italic>P</italic><sub>↑</sub>(<italic>x, y</italic>) + <italic>P</italic><sub>↓</sub>(<italic>x, y</italic>) = 1. If there is no trajectory going through a particular site, the probability of going from that site into each of the directions is equal to the “null” probability, <italic>P</italic><sub>0</sub> = 1/4. Time sequences where the mouse does not move are ignored, since we are only interested in the movement between adjacent sites.</p>
<p>The stepping-out probabilities are computed from the mouse trajectory in the following way. This procedure is applied to all mice overlayed together in each individual trial. First, a step is defined as moving from a box at (<italic>x, y</italic>) to one of its four adjacent boxes, say the one on the right (<italic>x</italic> + 1, <italic>y</italic>). Now, if we wanted to calculate the probability of going right from a position (<italic>x, y</italic>), we need to go through the sequence of visited lattice sites looking for (<italic>x, y</italic>) in an instant followed by (<italic>x</italic> + 1, <italic>y</italic>) in the immediately next instant. We count the number of times <italic>S</italic><sub>→</sub>(<italic>x, y</italic>) that this pair appears. The count of the transitions of (<italic>x, y</italic>) to (<italic>x</italic> + 1, <italic>y</italic>), in this example, is made regardless of when these transitions happened during the trajectory. The only condition is that the position (<italic>x, y</italic>) must be immediately followed by (<italic>x</italic> + 1, <italic>y</italic>). The same counting is made for the transitions from (<italic>x, y</italic>) to (<italic>x</italic> − 1, <italic>y</italic>) and stored in <italic>S</italic><sub>←</sub>(<italic>x, y</italic>), from (<italic>x, y</italic>) to (<italic>x, y</italic> + 1) in <italic>S</italic><sub>↑</sub>(<italic>x, y</italic>), and from (<italic>x, y</italic>) to (<italic>x, y</italic> − 1) in <italic>S</italic><sub>↓</sub>(<italic>x, y</italic>).</p>
<p>With these sums of steps performed, we can calculate the probability of stepping right, left, up or down. First, note that initially the chance of going to any direction is <italic>P</italic><sub>0</sub>, assuming we know nothing about the trajectories. Now, given that we observed <italic>S</italic><sub>→</sub>(<italic>x, y</italic>) steps going to the right, we need to update the chance of going to the right using the union (i.e. sum) of the observed chance <italic>S</italic><sub>→</sub>(<italic>x, y</italic>)/<italic>n</italic><sub><italic>s</italic></sub> with <italic>P</italic><sub>0</sub>, where <italic>n</italic><sub><italic>s</italic></sub> is the total number of steps counted toward any direction in all lattice sites in a given trial:
<disp-formula id="eqn2">
<graphic xlink:href="529984v4_eqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>W</italic><sub>→</sub>(<italic>x, y</italic>) is the direction weight of the action “step to the right from (<italic>x, y</italic>)”. Alternatively, this can be written as a weighted sum of memory-driven stepping with probability 1 and random stepping with probability <italic>P</italic><sub>0</sub>:
<disp-formula id="ueqn3">
<graphic xlink:href="529984v4_ueqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
We employ <xref ref-type="disp-formula" rid="eqn2">Eq. (2)</xref> because the mouse could, in principle, have chosen any of the other three directions. This ensures that every time the memory is increased (adding <italic>S</italic><sub>→</sub>/<italic>n</italic><sub><italic>s</italic></sub> to the weight), the random contribution for that step decreases; this justifies the last term in <xref ref-type="disp-formula" rid="eqn2">Eq. (2)</xref>, where the intersection between the memory term and the “null” probability, <italic>S</italic><sub>→</sub><italic>P</italic><sub>0</sub>/<italic>n</italic><sub><italic>s</italic></sub>, is subtracted from the aforementioned union. One can easily see that the formula guarantees that the null probability is automatically recovered, <italic>i</italic>.<italic>e. W</italic><sub>→</sub>(<italic>x, y</italic>) = <italic>P</italic><sub><italic>o</italic></sub>, when there are zero observed steps in a given direction at position (<italic>x, y</italic>), and that <italic>W</italic><sub>→</sub>(<italic>x, y</italic>) = 1 if all steps are to the right at position (<italic>x, y</italic>).</p>
<p>Finally, we use these weights to calculate the probabilities, first defining the total weight of stepping out of (<italic>x, y</italic>),
<disp-formula id="eqn3">
<graphic xlink:href="529984v4_eqn3.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
and then calculating the probabilities by
<disp-formula id="eqn4">
<graphic xlink:href="529984v4_eqn4.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
The same is made for the other directions (left, up and down). <xref ref-type="disp-formula" rid="eqn4">Equation (4)</xref> ensures that the probability of stepping out of (<italic>x, y</italic>) is always normalized. This is then applied to <xref ref-type="disp-formula" rid="eqn1">Eq. (1)</xref> to obtain the displacement map.</p>
<p>Let us go through the simple example shown in Fig. S2C-F. In this case, the accumulated trajectories in the center box located at (<italic>x, y</italic>) = (<xref ref-type="bibr" rid="c3">3</xref>,<xref ref-type="bibr" rid="c3">3</xref>) are such that there are two passes going up and one pass going down. Thus, each direction has the following weight [given by <xref ref-type="disp-formula" rid="eqn2">Eq. (2)</xref>]: <inline-formula><inline-graphic xlink:href="529984v4_inline4.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="529984v4_inline5.gif" mimetype="image" mime-subtype="gif"/></inline-formula>.</p>
<p>Applying <xref ref-type="disp-formula" rid="eqn4">Eq. (4)</xref>, we obtain the probabilities <italic>P</italic><sub>↑</sub>(<xref ref-type="bibr" rid="c3">3</xref>,<xref ref-type="bibr" rid="c3">3</xref>) ≈ 0.43, <italic>P</italic><sub>↓</sub>(<xref ref-type="bibr" rid="c3">3</xref>,<xref ref-type="bibr" rid="c3">3</xref>) ≈ 0.29, and <italic>P</italic><sub>→</sub>(<xref ref-type="bibr" rid="c3">3</xref>,<xref ref-type="bibr" rid="c3">3</xref>) = <italic>P</italic><sub>←</sub>(<xref ref-type="bibr" rid="c3">3</xref>,<xref ref-type="bibr" rid="c3">3</xref>) ≈ 0.14. This results in a step map vector <inline-formula><inline-graphic xlink:href="529984v4_inline6.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. This vector represents the preferred direction of movement out of site (<xref ref-type="bibr" rid="c3">3</xref>,<xref ref-type="bibr" rid="c3">3</xref>), meaning the mice are likely to pass in the vertical direction, going from bottom to top (hence a positive vertical quantity); and are not picky regarding left or right (hence a null horizontal quantity).</p>
<p>The trajectories of the mice obey box-scaling independently of trial or experimental condition. Boxscaling is a standard method to measure the dimensionality of curves, and is described in Falconer(<italic><xref ref-type="bibr" rid="c59">59</xref></italic>). In other words, the number of boxes needed to cover any trajectory scales linearly with the lattice dimension <italic>L</italic>; see Fig. S2F. This means that the choice of <italic>L</italic> is somewhat arbitrary, and we chose <italic>L</italic> = 11 to make each box the size of a few centimeters as expected for the size of a place field from a DG cell (<italic><xref ref-type="bibr" rid="c60">60</xref></italic>).</p>
</sec>
<sec id="s7h4">
<title>Trajectory directionality statistical significance</title>
<p>The method above gives a single displacement map <inline-formula><inline-graphic xlink:href="529984v4_inline7.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and enables the calculation of the TEV <inline-formula><inline-graphic xlink:href="529984v4_inline8.gif" mimetype="image" mime-subtype="gif"/></inline-formula> (see below) for each trial of an experiment containing <italic>N</italic> mice. We have to generate multiple samples for the same experiment using different mice to estimate the significance of the mean displacement direction calculation. We employ a jackknife procedure to achieve this goal. It consists of the “leave one out” rule: this means that a sample of <italic>N</italic> mice give <italic>N</italic> unique jackknife samples, each of which containing <italic>N</italic> − 1 unique mice. Then, we get <italic>N</italic> estimates <inline-formula><inline-graphic xlink:href="529984v4_inline9.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, with <italic>k</italic> from 1 to <italic>N</italic>, by applying the previously described procedure to each jackknife sample of <italic>N</italic> − 1 mice (instead of the whole sample). Finally, we calculate the average, <inline-formula><inline-graphic xlink:href="529984v4_inline10.gif" mimetype="image" mime-subtype="gif"/></inline-formula> for the displacement map. This is the vector map that we show as small arrows colored from blue to red (<xref rid="fig4" ref-type="fig">Fig. 4A,B,E,F</xref>; <xref rid="fig5" ref-type="fig">Fig. 5C</xref>; <xref rid="fig7" ref-type="fig">Fig. 7A,C,D,G</xref>; <xref rid="fig8" ref-type="fig">Fig. 8C</xref>; and Fig. S7; we only show statistically significant averages).</p>
<p>The statistical significance of the average <inline-formula><inline-graphic xlink:href="529984v4_inline11.gif" mimetype="image" mime-subtype="gif"/></inline-formula> map in each lattice position (<italic>x, y</italic>) is built from first principles as follows (see Fig. S3). The main feature of each of the vectors in this map is its direction (<italic>i</italic>.<italic>e</italic>., the angle it makes with the positive x-axis). Strong directionality means that the vectors <inline-formula><inline-graphic xlink:href="529984v4_inline12.gif" mimetype="image" mime-subtype="gif"/></inline-formula> all pointed roughly in the same direction (<italic>i</italic>.<italic>e</italic>., roughly same angles), whereas weak directionality means uniformly distributed angles around the circle (Fig. S3A,B). The stronger the directionality of the sample <inline-formula><inline-graphic xlink:href="529984v4_inline13.gif" mimetype="image" mime-subtype="gif"/></inline-formula> the more significant the average <inline-formula><inline-graphic xlink:href="529984v4_inline14.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. A simple measure of the spread of the angles (<italic>i</italic>.<italic>e</italic>., the directionality strength) is the standard deviation (S.D.) of the sample angles that <inline-formula><inline-graphic xlink:href="529984v4_inline15.gif" mimetype="image" mime-subtype="gif"/></inline-formula> make with the positive x-axis: stronger directionality implies a smaller S.D. (Fig. S3C). Thus, the significance (<italic>p</italic>) of directionality is how likely it is for a sample of <italic>N</italic> uniformly distributed angles to display a given S.D. value collectively.</p>
<p>The S.D. of <italic>N</italic> angles (with zero average) is <inline-formula><inline-graphic xlink:href="529984v4_inline16.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, where the <italic>θ</italic><sub><italic>k</italic></sub> are uniformly distributed from -180° to 180°. If we could determine the probability density function <italic>ρ</italic>(<italic>σ</italic>), then the significance would be given by (<italic><xref ref-type="bibr" rid="c61">61</xref></italic>) <italic>p</italic>(<italic>S. D</italic>.) <inline-formula><inline-graphic xlink:href="529984v4_inline17.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, which is the probability of observing a given S.D. from the sample. In other words, <italic>p</italic>(<italic>S. D</italic>.) is the probability that an observed S.D. came from a set of <italic>N</italic> uniformly distributed angles with zero mean. Thus, given an experimental observation S.D. from the jackknife sample, we will know what is the probability <italic>p</italic> that the angles from the sample were uniformly distributed in the circle (<italic>i</italic>.<italic>e</italic>., have weak directionality). A small <italic>p</italic> value, therefore, indicates strong directionality (since having small S.D. is very unlikely for uniformly distributed angles – Fig. S3D).</p>
<p>We need to estimate <italic>ρ</italic>(<italic>σ</italic>) to be able to calculate <italic>p</italic> for any S.D. Although it has an integral representation similar to the Chi distribution(<italic><xref ref-type="bibr" rid="c62">62</xref></italic>), it is easier to make a numerical estimation: we fix, for instance, <italic>N</italic> = 8 (since we have 8 jackknife samples) and generate 10,000 independent <italic>σ</italic> values applying the S.D. formula above to <italic>N</italic> independent uniform angles <italic>θ</italic><sub><italic>k</italic></sub> from -180° to 180°. The normalized histogram of all the observed <italic>σ</italic> is a good estimate of <italic>ρ</italic>(<italic>σ</italic>) (Fig. S3D). The <italic>p</italic> value is obtained by numerically integrating <italic>ρ</italic>(<italic>σ</italic>) from 0 to the observed S.D. value (Fig. S3E).</p>
<p>Now, it suffices to calculate the S.D. of the angles of the vectors <inline-formula><inline-graphic xlink:href="529984v4_inline18.gif" mimetype="image" mime-subtype="gif"/></inline-formula> in the jackknife sample (unbiased to make the average vector <inline-formula><inline-graphic xlink:href="529984v4_inline19.gif" mimetype="image" mime-subtype="gif"/></inline-formula> have <italic>θ</italic> = 0<sup>∘</sup>). An observed <italic>S</italic>.<italic>D</italic>.=30° corresponds to <italic>p</italic>=10<sup>-4</sup> (i.e., the sample has very strong directionality). We only show in the figures the displacement vectors that have <italic>S</italic>.<italic>D</italic>.≤5°, yielding vanishing <italic>p</italic>&lt;10<sup>-7</sup> (all vectors regardless of significance are shown in Fig. S7 for comparison for random and static entrance experiments). Comparing Fig. S7 to <xref rid="fig4" ref-type="fig">Fig. 4</xref>, we notice that, as expected, only vectors from trials that are supposed to have random directionality vanish (i.e., trials for random entrance experiments, and trial 1 for static entrance). The vectors in strongly directed flow trials (such as trial 14 in static entrance experiments) remain. The same happens for the two-food location experiment.</p>
</sec>
<sec id="s7h5">
<title>Target Estimation Vector (TEV)</title>
<p>The target estimation vector (TEV) is an estimate of the position of the target based only on the observed trajectories and hole checks of the mice. We write the average TEV as <inline-formula><inline-graphic xlink:href="529984v4_inline20.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="529984v4_inline21.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is the TEV for a particular jackknife sample <italic>k</italic>. The magnitude <italic>D</italic> is inferred from the hole checks and the direction <italic>û</italic> <sub><italic>k</italic></sub> is calculated from the displacement map <inline-formula><inline-graphic xlink:href="529984v4_inline22.gif" mimetype="image" mime-subtype="gif"/></inline-formula> as follows. The total sum of the displacement map <inline-formula><inline-graphic xlink:href="529984v4_inline23.gif" mimetype="image" mime-subtype="gif"/></inline-formula> over all arena sites (<italic>x, y</italic>) gives the estimate of the learned direction <inline-formula><inline-graphic xlink:href="529984v4_inline24.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, with <inline-formula><inline-graphic xlink:href="529984v4_inline25.gif" mimetype="image" mime-subtype="gif"/></inline-formula>. The magnitude <italic>D</italic> is the distance from start to the average of the hole check distribution restricted to 20cm around the target (<italic>i</italic>.<italic>e</italic>., <italic>D</italic> is the distance from the start to the “x” in the green ellipsis in <xref rid="fig4" ref-type="fig">Fig. 4G,H</xref>; <xref rid="fig5" ref-type="fig">Fig. 5C</xref>; <xref rid="fig7" ref-type="fig">Fig. 7B,F,H</xref>; <xref rid="fig8" ref-type="fig">Fig. 8C</xref>; and Fig. S1B-F). In the case of the Probe B-A trial, we use <italic>D</italic> as the distance from B (instead of “start”) to the restricted average of the hole check distribution around target A. In trials where no preferred direction is detected (such as in the random entrances experiment, or in the first trial after switching from target A to B), the magnitude <inline-formula><inline-graphic xlink:href="529984v4_inline26.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is already roughly the distance from start to the arena’s center (expressing the randomness in the displacement map), and hence we take the TEV to be just <inline-formula><inline-graphic xlink:href="529984v4_inline27.gif" mimetype="image" mime-subtype="gif"/></inline-formula> instead.</p>
<p>The error in the magnitude <italic>D</italic> of the TEV is obtained from the covariance matrix <italic>C</italic> of the spatial distribution of hole checks restricted to less than 20cm of the target. It is given by <italic>σ</italic><sub><italic>D</italic></sub> = <inline-formula><inline-graphic xlink:href="529984v4_inline28.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, where λ<sub>1,2</sub> are the eigenvalues of <italic>C</italic>. In the plots [<xref rid="fig4" ref-type="fig">Figs. 4</xref>, <xref rid="fig5" ref-type="fig">5</xref>, <xref rid="fig7" ref-type="fig">7</xref>, <xref rid="fig8" ref-type="fig">8</xref>], we simply represent the covariance matrix by the green ellipses in the same way we do for the uncensored distribution (see previous section). The error in the direction of <inline-formula><inline-graphic xlink:href="529984v4_inline29.gif" mimetype="image" mime-subtype="gif"/></inline-formula> is simply the S.D. of the angles of <inline-formula><inline-graphic xlink:href="529984v4_inline30.gif" mimetype="image" mime-subtype="gif"/></inline-formula> with respect to the positive x-axis (calculated by shifting <inline-formula><inline-graphic xlink:href="529984v4_inline31.gif" mimetype="image" mime-subtype="gif"/></inline-formula> to 0°, and making the angles of <inline-formula><inline-graphic xlink:href="529984v4_inline32.gif" mimetype="image" mime-subtype="gif"/></inline-formula> between -180° and 180°, similarly to what is done for the displacement map). This gives the pink shaded circular sector accompanying the TEV in the figures of the displacement maps and the error bars in the TEV-target deviation plot (<xref rid="fig4" ref-type="fig">Figs. 4I</xref> and <xref ref-type="fig" rid="fig7">7I</xref>).</p>
</sec>
</sec>
</sec>
<sec id="s8">
<title>Data Availability</title>
<p>All codes and data are available in <ext-link ext-link-type="uri" xlink:href="https://github.com/neuro-physics/mouse-cogmap">https://github.com/neuro-physics/mouse-cogmap</ext-link></p>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><given-names>M.</given-names> <surname>Rosenberg</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Zhang</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Perona</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Meister</surname></string-name>, <article-title>Mice in a labyrinth show rapid learning, sudden insight, and efficient exploration</article-title>. <source>eLife</source> <volume>10</volume>, (<year>2021</year>).</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><given-names>E.</given-names> <surname>Chan</surname></string-name>, <string-name><given-names>O.</given-names> <surname>Baumann</surname></string-name>, <string-name><given-names>M. A.</given-names> <surname>Bellgrove</surname></string-name>, <string-name><given-names>J. B.</given-names> <surname>Mattingley</surname></string-name>, <article-title>From objects to landmarks: the function of visual location information in spatial navigation</article-title>. <source>Frontiers in psychology</source> <volume>3</volume>, <fpage>304</fpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><given-names>J.</given-names> <surname>Goodman</surname></string-name>, <article-title>Place vs. Response Learning: History, Controversy, and Neurobiology</article-title>. <source>Front Behav Neurosci</source> <volume>14</volume>, <fpage>598570</fpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><given-names>N.</given-names> <surname>Nyberg</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Duvelle</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Barry</surname></string-name>, <string-name><given-names>H. J.</given-names> <surname>Spiers</surname></string-name>, <article-title>Spatial goal coding in the hippocampal formation</article-title>. <source>Neuron</source> <volume>110</volume>, <fpage>394</fpage>–<lpage>422</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><given-names>E. C.</given-names> <surname>Tolman</surname></string-name>, <string-name><given-names>B. F.</given-names> <surname>Ritchie</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Kalish</surname></string-name>, <article-title>Studies in spatial learning; place learning versus response learning</article-title>. <source>J Exp Psychol</source> <volume>36</volume>, <fpage>221</fpage>–<lpage>229</lpage> (<year>1946</year>).</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><given-names>T. S.</given-names> <surname>Collett</surname></string-name>, <string-name><given-names>B. A.</given-names> <surname>Cartwright</surname></string-name>, <string-name><given-names>B. A.</given-names> <surname>Smith</surname></string-name>, <article-title>Landmark learning and visuo-spatial memories in gerbils</article-title>. <source>J Comp Physiol A</source> <volume>158</volume>, <fpage>835</fpage>–<lpage>851</lpage> (<year>1986</year>).</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><given-names>R. G. M.</given-names> <surname>Morris</surname></string-name>, <article-title>Spatial Localization Does Not Require the Presence of Local Cues</article-title>. <source>LEARNING AND MOTIVATION</source> <volume>12</volume>, <fpage>239</fpage>–<lpage>260</lpage> (<year>1981</year>).</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><given-names>B. L.</given-names> <surname>McNaughton</surname></string-name>, <string-name><given-names>C. A.</given-names> <surname>Barnes</surname></string-name>, <string-name><given-names>J. L.</given-names> <surname>Gerrard</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Gothard</surname></string-name>, <string-name><given-names>M. W.</given-names> <surname>Jung</surname></string-name>, <string-name><given-names>J. J.</given-names> <surname>Knierim</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Kudrimoti</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Qin</surname></string-name>, <string-name><given-names>W. E.</given-names> <surname>Skaggs</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Suster</surname></string-name>, <string-name><given-names>K. L.</given-names> <surname>Weaver</surname></string-name>, <article-title>Deciphering the hippocampal polyglot: the hippocampus as a path integration system</article-title>. <source>J Exp Biol</source> <volume>199</volume>, <fpage>173</fpage>–<lpage>185</lpage> (<year>1996</year>).</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><given-names>M. L.</given-names> <surname>Mittelstaedt</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Mittelstaedt</surname></string-name>, <article-title>Homing by path integration in a mammal</article-title>. <source>Naturwissenschaften</source> <volume>67</volume>, <fpage>566</fpage>–<lpage>567</lpage> (<year>1980</year>).</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><given-names>N.</given-names> <surname>Burgess</surname></string-name>, <article-title>Spatial memory: how egocentric and allocentric combine</article-title>. <source>Trends Cogn Sci</source> <volume>10</volume>, <fpage>551</fpage>–<lpage>557</lpage> (<year>2006</year>).</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><given-names>G.</given-names> <surname>Chen</surname></string-name>, <string-name><given-names>J. A.</given-names> <surname>King</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Burgess</surname></string-name>, <string-name><given-names>J.</given-names> <surname>O’Keefe</surname></string-name>, <article-title>How vision and movement combine in the hippocampal place code</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>110</volume>, <fpage>378</fpage>–<lpage>383</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><given-names>J. J.</given-names> <surname>Knierim</surname></string-name>, <string-name><given-names>D. A.</given-names> <surname>Hamilton</surname></string-name>, <article-title>Framing spatial cognition: neural representations of proximal and distal frames of reference and their roles in navigation</article-title>. <source>Physiol Rev</source> <volume>91</volume>, <fpage>1245</fpage>–<lpage>1279</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><given-names>E. C.</given-names> <surname>Tolman</surname></string-name>, <article-title>Cognitive maps in rats and men</article-title>. <source>Psychological review</source> <volume>55</volume>, <fpage>189</fpage>–<lpage>208</lpage> (<year>1948</year>).</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><string-name><given-names>E. C.</given-names> <surname>Tolman</surname></string-name>, <string-name><given-names>B. F.</given-names> <surname>Ritchie</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Kalish</surname></string-name>, <article-title>Studies in spatial learning: Orientation and the shortcut</article-title>. <source>J Exp Psychol</source> <volume>36</volume>, <fpage>13</fpage>–<lpage>24</lpage> (<year>1946</year>).</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><given-names>B. L.</given-names> <surname>McNaughton</surname></string-name>, <string-name><given-names>F. P.</given-names> <surname>Battaglia</surname></string-name>, <string-name><given-names>O.</given-names> <surname>Jensen</surname></string-name>, <string-name><given-names>E. I.</given-names> <surname>Moser</surname></string-name>, <string-name><given-names>M. B.</given-names> <surname>Moser</surname></string-name>, <article-title>Path integration and the neural basis of the ‘cognitive map’</article-title>. <source>Nat Rev Neurosci</source> <volume>7</volume>, <fpage>663</fpage>–<lpage>678</lpage> (<year>2006</year>).</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="book"><string-name><given-names>J.</given-names> <surname>O’Keefe</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Nadel</surname></string-name>, <source>The Hippocampus as a Cognitive Map</source> (<publisher-name>Oxford University Press</publisher-name>, <publisher-loc>Oxford, U.K</publisher-loc>., <year>1978</year>).</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><given-names>A.</given-names> <surname>Banino</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Barry</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Uria</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Blundell</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Lillicrap</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Mirowski</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Pritzel</surname></string-name>, <string-name><given-names>M. J.</given-names> <surname>Chadwick</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Degris</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Modayil</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Wayne</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Soyer</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Viola</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Zhang</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Goroshin</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Rabinowitz</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Pascanu</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Beattie</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Petersen</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Sadik</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Gaffney</surname></string-name>, <string-name><given-names>H.</given-names> <surname>King</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Kavukcuoglu</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Hassabis</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Hadsell</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Kumaran</surname></string-name>, <article-title>Vector-based navigation using grid-like representations in artificial agents</article-title>. <source>Nature</source> <volume>557</volume>, <fpage>429</fpage>–<lpage>433</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><string-name><given-names>K.</given-names> <surname>Asumbisa</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Peyrache</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Trenholm</surname></string-name>, <article-title>Flexible cue anchoring strategies enable stable head direction coding in both sighted and blind animals</article-title>. <source>Nature communications</source> <volume>13</volume>, <fpage>5483</fpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><given-names>W.</given-names> <surname>Fischler-Ruiz</surname></string-name>, <string-name><given-names>D. G.</given-names> <surname>Clark</surname></string-name>, <string-name><given-names>N. R.</given-names> <surname>Joshi</surname></string-name>, <string-name><given-names>V.</given-names> <surname>Devi-Chou</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Kitch</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Schnitzer</surname></string-name>, <string-name><given-names>L. F.</given-names> <surname>Abbott</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Axel</surname></string-name>, <article-title>Olfactory landmarks and path integration converge to form a cognitive spatial map</article-title>. <source>Neuron</source> <volume>109</volume>, <fpage>4036</fpage>–<lpage>4049</lpage> e4035 (<year>2021</year>).</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><string-name><given-names>J. D.</given-names> <surname>Cushman</surname></string-name>, <string-name><given-names>D. B.</given-names> <surname>Aharoni</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Willers</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Ravassard</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Kees</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Vuong</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Popeney</surname></string-name>, <string-name><given-names>K.</given-names> <surname>Arisaka</surname></string-name>, <string-name><given-names>M. R.</given-names> <surname>Mehta</surname></string-name>, <article-title>Multisensory control of multimodal behavior: do the legs know what the tongue is doing?</article-title> <source>PLoS One</source> <volume>8</volume>, <fpage>e80465</fpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><given-names>A. B.</given-names> <surname>Saleem</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Busse</surname></string-name>, <article-title>Interactions between rodent visual and spatial systems during navigation</article-title>. <source>Nat Rev Neurosci</source> <volume>24</volume>, <fpage>487</fpage>–<lpage>501</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><given-names>A. L.</given-names> <surname>Jacobs</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Fridman</surname></string-name>, <string-name><given-names>R. M.</given-names> <surname>Douglas</surname></string-name>, <string-name><given-names>N. M.</given-names> <surname>Alam</surname></string-name>, <string-name><given-names>P. E.</given-names> <surname>Latham</surname></string-name>, <string-name><given-names>G. T.</given-names> <surname>Prusky</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Nirenberg</surname></string-name>, <article-title>Ruling out and ruling in neural codes</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>106</volume>, <fpage>5936</fpage>–<lpage>5941</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><given-names>M.</given-names> <surname>Long</surname></string-name>, <string-name><given-names>W.</given-names> <surname>Jiang</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Liu</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Yao</surname></string-name>, <article-title>Contrast-dependent orientation discrimination in the mouse</article-title>. <source>Sci Rep</source> <volume>5</volume>, <fpage>15830</fpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><given-names>G. T.</given-names> <surname>Prusky</surname></string-name>, <string-name><given-names>R. M.</given-names> <surname>Douglas</surname></string-name>, <article-title>Characterization of mouse cortical spatial vision</article-title>. <source>Vision Res</source> <volume>44</volume>, <fpage>3411</fpage>–<lpage>3418</lpage> (<year>2004</year>).</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><given-names>G. T.</given-names> <surname>Prusky</surname></string-name>, <string-name><given-names>P. W.</given-names> <surname>West</surname></string-name>, <string-name><given-names>R. M.</given-names> <surname>Douglas</surname></string-name>, <article-title>Behavioral assessment of visual acuity in mice and rats</article-title>. <source>Vision Res</source> <volume>40</volume>, <fpage>2201</fpage>–<lpage>2209</lpage> (<year>2000</year>).</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="other"><string-name><given-names>A. B.</given-names> <surname>Saleem</surname></string-name>, <string-name><given-names>E. M.</given-names> <surname>Diamanti</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Fournier</surname></string-name>, <string-name><given-names>K. D.</given-names> <surname>Harris</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Carandini</surname></string-name>, <article-title>Coherent encoding of subjective spatial position in visual cortex and hippocampus</article-title>. <source>Nature</source>, (<year>2018</year>).</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><string-name><given-names>P.</given-names> <surname>Chapillon</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Roullet</surname></string-name>, <article-title>Use of proximal and distal cues in place navigation by mice changes during ontogeny</article-title>. <source>Dev Psychobiol</source> <volume>29</volume>, <fpage>529</fpage>–<lpage>545</lpage> (<year>1996</year>).</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><string-name><given-names>M.</given-names> <surname>Hebert</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Bulla</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Vivien</surname></string-name>, <string-name><given-names>V.</given-names> <surname>Agin</surname></string-name>, <article-title>Are Distal and Proximal Visual Cues Equally Important during Spatial Learning in Mice? A Pilot Study of Overshadowing in the Spatial Domain</article-title>. <source>Front Behav Neurosci</source> <volume>11</volume>, <fpage>109</fpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><string-name><given-names>J.</given-names> <surname>Rogers</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Churilov</surname></string-name>, <string-name><given-names>A. J.</given-names> <surname>Hannan</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Renoir</surname></string-name>, <article-title>Search strategy selection in the Morris water maze indicates allocentric map formation during learning that underpins spatial memory formation</article-title>. <source>Neurobiol Learn Mem</source> <volume>139</volume>, <fpage>37</fpage>–<lpage>49</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><string-name><given-names>I. A.</given-names> <surname>Youngstrom</surname></string-name>, <string-name><given-names>B. W.</given-names> <surname>Strowbridge</surname></string-name>, <article-title>Visual landmarks facilitate rodent spatial navigation in virtual reality environments</article-title>. <source>Learn Mem</source> <volume>19</volume>, <fpage>84</fpage>–<lpage>90</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><string-name><given-names>A. S.</given-names> <surname>Etienne</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Maurer</surname></string-name>, <string-name><given-names>V.</given-names> <surname>Seguinot</surname></string-name>, <article-title>Path integration in mammals and its interaction with visual landmarks</article-title>. <source>J Exp Biol</source> <volume>199</volume>, <fpage>201</fpage>–<lpage>209</lpage> (<year>1996</year>).</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><string-name><given-names>J. J.</given-names> <surname>Jun</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Longtin</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Maler</surname></string-name>, <article-title>Enhanced sensory sampling precedes self-initiated locomotion in an electric fish</article-title>. <source>J Exp Biol</source> <volume>217</volume>, <fpage>3615</fpage>–<lpage>3628</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><string-name><given-names>A. S.</given-names> <surname>Etienne</surname></string-name>, <string-name><given-names>K. J.</given-names> <surname>Jeffery</surname></string-name>, <article-title>Path integration in mammals</article-title>. <source>Hippocampus</source> <volume>14</volume>, <fpage>180</fpage>–<lpage>192</lpage> (<year>2004</year>).</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><string-name><given-names>J.</given-names> <surname>Engelmann</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Wallach</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Maler</surname></string-name>, <article-title>Linking active sensing and spatial learning in weakly electric fish</article-title>. <source>Curr Opin Neurobiol</source> <volume>71</volume>, <fpage>1</fpage>–<lpage>10</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><string-name><given-names>J. J.</given-names> <surname>Jun</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Longtin</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Maler</surname></string-name>, <article-title>Active sensing associated with spatial learning reveals memory-based attention in an electric fish</article-title>. <source>Journal of Neurophysiology</source> <volume>115</volume>, <fpage>2577</fpage>–<lpage>2592</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><string-name><given-names>C.</given-names> <surname>Mirmiran</surname></string-name>, <string-name><given-names>M.</given-names> <surname>Fraser</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Maler</surname></string-name>, <article-title>Finding food in the dark: how trajectories of a gymnotiform fish change with spatial learning</article-title>. <source>J Exp Biol</source> <volume>225</volume>, (<year>2022</year>).</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><string-name><given-names>A.</given-names> <surname>Wallach</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Harvey-Girard</surname></string-name>, <string-name><given-names>J. J.</given-names> <surname>Jun</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Longtin</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Maler</surname></string-name>, <article-title>A time-stamp mechanism may provide temporal information necessary for egocentric to allocentric spatial transformations</article-title>. <source>eLife</source> <volume>7</volume>, <fpage>e36769</fpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><string-name><given-names>R. P.</given-names> <surname>Jayakumar</surname></string-name>, <string-name><given-names>M. S.</given-names> <surname>Madhav</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Savelli</surname></string-name>, <string-name><given-names>H. T.</given-names> <surname>Blair</surname></string-name>, <string-name><given-names>N. J.</given-names> <surname>Cowan</surname></string-name>, <string-name><given-names>J. J.</given-names> <surname>Knierim</surname></string-name>, <article-title>Recalibration of path integration in hippocampal place cells</article-title>. <source>Nature</source> <volume>566</volume>, <fpage>533</fpage>–<lpage>537</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><string-name><given-names>F.</given-names> <surname>Savelli</surname></string-name>, <string-name><given-names>J. J.</given-names> <surname>Knierim</surname></string-name>, <article-title>Origin and role of path integration in the cognitive representations of the hippocampus: computational insights into open questions</article-title>. <source>J Exp Biol</source> <volume>222</volume>, (<year>2019</year>).</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><string-name><given-names>E.</given-names> <surname>Save</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Cressant</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Thinus-Blanc</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Poucet</surname></string-name>, <article-title>Spatial firing of hippocampal place cells in blind rats</article-title>. <source>J Neurosci</source> <volume>18</volume>, <fpage>1818</fpage>–<lpage>1826</lpage> (<year>1998</year>).</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><string-name><given-names>Z. M.</given-names> <surname>Aghajan</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Acharya</surname></string-name>, <string-name><given-names>J. J.</given-names> <surname>Moore</surname></string-name>, <string-name><given-names>J. D.</given-names> <surname>Cushman</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Vuong</surname></string-name>, <string-name><given-names>M. R.</given-names> <surname>Mehta</surname></string-name>, <article-title>Impaired spatial selectivity and intact phase precession in two-dimensional virtual reality</article-title>. <source>Nat Neurosci</source> <volume>18</volume>, <fpage>121</fpage>–<lpage>128</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><string-name><given-names>P.</given-names> <surname>Ravassard</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Kees</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Willers</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Ho</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Aharoni</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Cushman</surname></string-name>, <string-name><given-names>Z. M.</given-names> <surname>Aghajan</surname></string-name>, <string-name><given-names>M. R.</given-names> <surname>Mehta</surname></string-name>, <article-title>Multisensory control of hippocampal spatiotemporal selectivity</article-title>. <source>Science</source> <volume>340</volume>, <fpage>1342</fpage>–<lpage>1346</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><string-name><given-names>J. J.</given-names> <surname>Moore</surname></string-name>, <string-name><given-names>J. D.</given-names> <surname>Cushman</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Acharya</surname></string-name>, <string-name><given-names>B.</given-names> <surname>Popeney</surname></string-name>, <string-name><given-names>M. R.</given-names> <surname>Mehta</surname></string-name>, <article-title>Linking hippocampal multiplexed tuning, Hebbian plasticity and navigation</article-title>. <source>Nature</source> <volume>599</volume>, <fpage>442</fpage>–<lpage>448</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><string-name><given-names>A.</given-names> <surname>Sarel</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Finkelstein</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Las</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Ulanovsky</surname></string-name>, <article-title>Vectorial representation of spatial goals in the hippocampus of bats</article-title>. <source>Science</source> <volume>355</volume>, <fpage>176</fpage>–<lpage>180</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><string-name><given-names>J.</given-names> <surname>Ormond</surname></string-name>, <string-name><given-names>J.</given-names> <surname>O’Keefe</surname></string-name>, <article-title>Hippocampal place cells have goal-oriented vector fields during navigation</article-title>. <source>Nature</source> <volume>607</volume>, <fpage>741</fpage>–<lpage>746</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><string-name><given-names>P. E.</given-names> <surname>Jercog</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Ahmadian</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Woodruff</surname></string-name>, <string-name><given-names>R.</given-names> <surname>Deb-Sen</surname></string-name>, <string-name><given-names>L. F.</given-names> <surname>Abbott</surname></string-name>, <string-name><given-names>E. R.</given-names> <surname>Kandel</surname></string-name>, <article-title>Heading direction with respect to a reference point modulates place-cell activity</article-title>. <source>Nature communications</source> <volume>10</volume>, <fpage>2333</fpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><string-name><given-names>K. C.</given-names> <surname>Bittner</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Grienberger</surname></string-name>, <string-name><given-names>S. P.</given-names> <surname>Vaidya</surname></string-name>, <string-name><given-names>A. D.</given-names> <surname>Milstein</surname></string-name>, <string-name><given-names>J. J.</given-names> <surname>Macklin</surname></string-name>, <string-name><given-names>J.</given-names> <surname>Suh</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Tonegawa</surname></string-name>, <string-name><given-names>J. C.</given-names> <surname>Magee</surname></string-name>, <article-title>Conjunctive input processing drives feature selectivity in hippocampal CA1 neurons</article-title>. <source>Nat Neurosci</source> <volume>18</volume>, <fpage>1133</fpage>–<lpage>1142</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><string-name><given-names>K. C.</given-names> <surname>Bittner</surname></string-name>, <string-name><given-names>A. D.</given-names> <surname>Milstein</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Grienberger</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Romani</surname></string-name>, <string-name><given-names>J. C.</given-names> <surname>Magee</surname></string-name>, <article-title>Behavioral time scale synaptic plasticity underlies CA1 place fields</article-title>. <source>Science</source> <volume>357</volume>, <fpage>1033</fpage>–<lpage>1036</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><string-name><given-names>A. D.</given-names> <surname>Milstein</surname></string-name>, <string-name><given-names>Y.</given-names> <surname>Li</surname></string-name>, <string-name><given-names>K. C.</given-names> <surname>Bittner</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Grienberger</surname></string-name>, <string-name><given-names>I.</given-names> <surname>Soltesz</surname></string-name>, <string-name><given-names>J. C.</given-names> <surname>Magee</surname></string-name>, <string-name><given-names>S.</given-names> <surname>Romani</surname></string-name>, <article-title>Bidirectional synaptic plasticity rapidly modifies hippocampal representations</article-title>. <source>eLife</source> <volume>10</volume>, (<year>2021</year>).</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><string-name><given-names>J. D.</given-names> <surname>Monaco</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Rao</surname></string-name>, <string-name><given-names>E. D.</given-names> <surname>Roth</surname></string-name>, <string-name><given-names>J. J.</given-names> <surname>Knierim</surname></string-name>, <article-title>Attentive scanning behavior drives one-trial potentiation of hippocampal place fields</article-title>. <source>Nat Neurosci</source> <volume>17</volume>, <fpage>725</fpage>–<lpage>731</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><string-name><given-names>A. T.</given-names> <surname>Bennett</surname></string-name>, <article-title>Do animals have cognitive maps?</article-title> <source>J Exp Biol</source> <volume>199</volume>, <fpage>219</fpage>–<lpage>224</lpage> (<year>1996</year>).</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><string-name><given-names>R.</given-names> <surname>Grieves</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Dudchenko</surname></string-name>, <article-title>Cognitive maps and spatial inference in animals: Rats fail to take a novel shortcut, but can take a previously experienced one</article-title>. <source>Learning and Motivation</source> <volume>84</volume>, <fpage>81</fpage>–<lpage>92</lpage> (<year>2012</year>).</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><string-name><given-names>S.</given-names> <surname>Benhamou</surname></string-name>, <article-title>No evidence for cognitive mapping in rats</article-title>. <source>Animal Behaviour</source> <volume>52</volume>, <fpage>201</fpage>–<lpage>212</lpage> (<year>1996</year>).</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><string-name><given-names>P.</given-names> <surname>Shamash</surname></string-name>, <string-name><given-names>S. F.</given-names> <surname>Olesen</surname></string-name>, <string-name><given-names>P.</given-names> <surname>Iordanidou</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Campagner</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Banerjee</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Branco</surname></string-name>, <article-title>Mice learn multi-step routes by memorizing subgoal locations</article-title>. <source>Nat Neurosci</source> <volume>24</volume>, <fpage>1270</fpage>–<lpage>1279</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><string-name><given-names>B.</given-names> <surname>Landau</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Spelke</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Gleitman</surname></string-name>, <article-title>Spatial knowledge in a young blind child</article-title>. <source>Cognition</source> <volume>16</volume>, <fpage>225</fpage>–<lpage>260</lpage> (<year>1984</year>).</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><string-name><given-names>R. P.</given-names> <surname>Kesner</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Farnsworth</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Kametani</surname></string-name>, <article-title>Role of parietal cortex and hippocampus in representing spatial information</article-title>. <source>Cereb Cortex</source> <volume>1</volume>, <fpage>367</fpage>–<lpage>373</lpage> (<year>1991</year>).</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><string-name><given-names>N.</given-names> <surname>Kronfeld-Schor</surname></string-name>, <string-name><given-names>D.</given-names> <surname>Dominoni</surname></string-name>, <string-name><given-names>H.</given-names> <surname>de la Iglesia</surname></string-name>, <string-name><given-names>O.</given-names> <surname>Levy</surname></string-name>, <string-name><given-names>E. D.</given-names> <surname>Herzog</surname></string-name>, <string-name><given-names>T.</given-names> <surname>Dayan</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Helfrich-Forster</surname></string-name>, <article-title>Chronobiology by moonlight</article-title>. <source>Proc Biol Sci</source> <volume>280</volume>, <fpage>20123088</fpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><string-name><given-names>N.</given-names> <surname>Upham</surname></string-name>, <string-name><given-names>S. J. C.</given-names> <surname>Hafner</surname></string-name>, <article-title>Do nocturnal rodents in the great basin desert avoid moonlight?</article-title> <source>Journal of Mammology</source> <volume>94</volume>, <fpage>59</fpage>–<lpage>72</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="book"><string-name><given-names>K.</given-names> <surname>Falconer</surname></string-name>, <source>Fractal Geometry: Mathematical Foundations and Application</source> (<publisher-name>John Wiley and Sons</publisher-name>, <year>2004</year>).</mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="journal"><string-name><given-names>D.</given-names> <surname>GoodSmith</surname></string-name>, <string-name><given-names>X.</given-names> <surname>Chen</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>S. H.</given-names> <surname>Kim</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Song</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Burgalossi</surname></string-name>, <string-name><given-names>K. M.</given-names> <surname>Christian</surname></string-name>, <string-name><given-names>J. J.</given-names> <surname>Knierim</surname></string-name>, <article-title>Spatial Representations of Granule Cells and Mossy Cells of the Dentate Gyrus</article-title>. <source>Neuron</source> <volume>93</volume>, <fpage>677</fpage>–<lpage>690</lpage>.e675-677–690.e675 (<year>2017</year>).</mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="other"><string-name><given-names>J. F.</given-names> <surname>Hair</surname></string-name>, <string-name><given-names>W. C.</given-names> <surname>Black</surname></string-name>, <string-name><given-names>B. J.</given-names> <surname>Babin</surname></string-name>, <string-name><given-names>R. E.</given-names> <surname>Anderson</surname></string-name>, <source>Multivariate Data Analysis (Pearson</source>, ed. <edition>7th</edition>, <year>2013</year>).</mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="book"><string-name><given-names>T.</given-names> <surname>Tomé</surname></string-name>, <string-name><given-names>M. J.</given-names> <surname>Oliveira</surname></string-name>, <source>Stochastic Dynamics and Irreversibility</source> (<publisher-name>Springer International Publishing</publisher-name>, <year>2015</year>).</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.95764.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Cowan</surname>
<given-names>Noah J</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Johns Hopkins University</institution>
</institution-wrap>
<city>Baltimore</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>important</bold> work presents a creative and thoughtful analysis of mouse foraging behavior and its dependence on body reference frame-based vs world reference frame-based cues. It <bold>convincingly</bold> demonstrates that a robust map capable of supporting taking novel shortcuts is learned based primarily on self-motion cues from a known starting location and this can be done in contexts where there is little reliance on distal visual landmarks; this may be a unique finding outside of the human literature. The discussion is rich with ideas about the role of the hippocampus in supporting the behavior that should be interesting to test in future analyses of brain recordings as mice perform the tasks considered by the study.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.95764.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Assessment:</p>
<p>This important work advances our understanding of navigation and path integration in mammals by using a clever behavioral paradigm. The paper provides compelling evidence that mice are able to create and use a cognitive map to find &quot;short cuts&quot; in an environment, using only the location of rewards relative to the point of entry to the environment and path integration, and need not rely on visual landmarks.</p>
<p>Summary:</p>
<p>The authors have designed a novel experimental apparatus called the 'Hidden Food Maze (HFM)' and a beautiful suite of behavioral experiments using this apparatus to investigate the interplay between allothetic and idiothetic cues in navigation. The results presented provide a clear demonstration of the central claim of the paper, namely that mice only need a fixed start location and path integration to develop a cognitive map. The experiments and analyses conducted to test the main claim of the paper -- that the animals have formed a cognitive map -- are conclusive. While I think the results are quite interesting and sound, one issue that needs to be addressed is the framing of how landmarks are used (or not), as discussed below, although I believe this will be a straightforward issue for the authors to address.</p>
<p>Strengths:</p>
<p>The 90-degree rotationally symmetric design and use of 4 distal landmarks and 4 quadrants with their corresponding rotationally equivalent locations (REL) lends itself to teasing apart the influence of path integration and landmark-based navigation in a clever way. The authors use a really complete set of experiments and associated controls to show that mice can use a start location and path integration to develop a cognitive map and generate shortcut routes to new locations.</p>
<p>Weaknesses:</p>
<p>I have two comments. The second comment is perhaps major and would require rephrasing multiple sentences/paragraphs throughout the paper.</p>
<p>(1) The data clearly indicate that in the hidden food maze (HFM) task mice did not use external visual &quot;cue cards&quot; to navigate, as this is clearly shown in the errors mice make when they start trials from a different start location when trained in the static entrance condition. The absence of visual landmark-guided behavior is indeed surprising, given the previous literature showing the use of distal landmarks to navigate and neural correlates of visual landmarks in hippocampal formation. While the authors briefly mention that the mice might not be using distal landmarks because of their pretraining procedure - I think it is worth highlighting this point (about the importance of landmark stability and citing relevant papers) and elaborating on it in greater detail. It is very likely that mice do not use the distal visual landmarks in this task because the pretraining of animals leads to them not identifying them as stable landmarks. For example, if they thought that each time they were introduced to the arena, it was &quot;through the same door&quot;, then the landmarks would appear to be in arbitrary locations compared to the last time. In the same way, we as humans wouldn't use clouds or the location of people or other animate objects as trusted navigational beacons. In addition, the animals are introduced to the environment without any extra-maze landmarks that could help them resolve this ambiguity. Previous work (and what we see in our dome experiments) has shown that in environments with 'unreliable' landmarks, place cells are not controlled by landmarks - <ext-link ext-link-type="uri" xlink:href="https://www.sciencedirect.com/science/article/pii/S0028390898000537">https://www.sciencedirect.com/science/article/pii/S0028390898000537</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://pubmed.ncbi.nlm.nih.gov/7891125/">https://pubmed.ncbi.nlm.nih.gov/7891125/</ext-link>. This makes it likely that the absence of these distal visual landmarks when the animal first entered the maze ensured that the animal does not 'trust' these visual features as landmarks.</p>
<p>(2) I don't agree with the statement that 'Exogenous cues are not required for learning the food location'. There are many cues that the animal is likely using to help reduce errors in path integration. For example, the start location of the rat could act as a landmark/exogenous cue in the sense of partially correcting path integration errors. The maze has four identical entrances (90-degree rotationally symmetric). Despite this, it is entirely plausible that the animal can correct path integration errors by identifying the correct start entrance for a given trial, and indeed the distance/bearing to the others would also help triangulate one's location. Further, the overall arena geometry could help reduce PI error. For example, with a food source learned to be &quot;near the middle&quot; of the arena, the animal would surely not estimate the position to be near the far wall (and an interesting follow-on experiment would be to have two different-sized, but otherwise nearly identical arenas). As the rat travels away from the start location, small path integration errors are bound to accumulate, these errors could be at least partially corrected based on entrance and distal wall locations. If this process of periodically checking the location of the entrance to correct path integration errors is done every few seconds, path integration would be aided 'exogenously' to build a cognitive map. While the original claim of the paper still stands, i.e. mice can learn the location of a hidden food size when their starting point in the environment remains constant across trials. I would advise rewording portions of the paper, including the discussion throughout the paper that states claims such as &quot;Exogenous cues are not required for learning the food location&quot; to account for the possibility that the start and the overall arena geometry could be used as helpful exogenous cues to correct for path integration errors.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.95764.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This manuscript reports interesting findings about the navigational behavior of mice. The authors have dissected this behavior in various components using a sophisticated behavioral maze and statistical analysis of the data. ​</p>
<p>Strengths:</p>
<p>The results are solid and they support the main conclusions, which will be of considerable value to many scientists.</p>
<p>Weaknesses:</p>
<p>Figure 1: In some trials the mice seem to be doing thigmotaxis, walking along the perimeter of the maze. This is perhaps due to the fear of the open arena. But, these paths along the perimeter would significantly influence all metrics of navigation, e.g. the distance or time to reward. Perhaps analysis can be done that treats such behavior separately and the factors it out from the paths that are away from the perimeter.</p>
<p>Figure 1c: the color axis seems unusual. Red colors indicate less frequently visited regions (less than 25%) and white corresponds to more frequently visited places (&gt;25%)? Why use such a binary measure instead of a graded map as commonly done?</p>
<p>Some figures use linear scale and others use logarithmic scale. Is there a scientific justification? For example, average latency is on a log scale and average speed is on a linear scale, but both quantify the same behavior. The y-axis in panel 1-I is much wider than the data. Is there a reason for this? Or can the authors zoom into the y-axis so that the reader can discern any pattern?</p>
<p>1F shows no significant reduction in distance to reward. Does that mean there is no improvement with experience and all the improvement in the latency is due to increasing running speed with experience?</p>
<p>Figure 3: The distance traveled was reduced by nearly 10-fold and speed increased by by about 3fold. So, the time to reach the reward should decrease by only 3 fold (t=d/v) but that too reduced by 10fold. How does one reconcile the 3fold difference between the expected and observed values?</p>
<p>Figure 4: The reader is confused about the use of a binary color scheme here for the checking behavior: gray for a large amount of checking, and pink for small. But, there is a large ellipse that is gray and there are smaller circles that are also gray, but these two gray areas mean very different things as far as the reader can tell. Is that so? Why not show the entire graded colormap of checking probability instead of such a seemingly arbitrary binary depiction?</p>
<p>Figure 4C: What would explain the large amount of checking behavior at the perimeter? Does that occur predominantly during thigmotaxis?</p>
<p>Was there a correlation between the amount of time spent by the animals in a part of the maze and the amount of reward checking? Previous studies have shown that the two behaviors are often positively correlated, e.g. reference 20 in the manuscript.  How does this fit with the path integration hypothesis?</p>
<p>&quot;Scratches and odor trails were eliminated by washing and rotating the maze floor between trials.&quot; Can one eliminate scratches by just washing the maze floor? Rotation of the maze floor between trials can make these cues unreliable or variable but will not eliminate them. Ditto for odor cues.</p>
<p>&quot;Possible odor gradient cues were eliminated by experiments where such gradients were prevented with vacuum fans (Fig. S6E)&quot; What tests were done to ensure that these were *eliminated* versus just diminished?</p>
<p>&quot;Probe trials of fully trained mice resulted in trajectories and initial hole checking identical to that of regular trials thereby demonstrating that local odor cues are not essential for spatial learning.&quot; As far as the reader can tell, probe trials only eliminated the food odor cues but did not eliminate all other odors. If so, this conclusion can be modified accordingly.</p>
<p>
The interpretation of direction selectivity is a bit tricky. At different places in this manuscript, this is interpreted as a path integration signal that encodes goal location, including the Consync cells. However, studies show that (e.g. Acharya et al. 2016) direction selectivity in virtual reality is comparable to that during natural mazes, despite large differences in vestibular cues and spatial selectivity. How would one reconcile these observations with path integration interpretation?</p>
<p>The manuscript would be improved if the speculations about place cells, grid cells, BTSP, etc. were pared down. I could easily imagine the outcome of these speculations to go the other way and some claims are not supported by data. &quot;We note that the cited experiments were done with virtual movement constrained to 1D and in the presence of landmarks. It remains to be shown whether similar results are obtained in our unconstrained 2D maze and with only self-motion cues available.&quot; There are many studies that have measured the evolution of place cells in non-virtual mazes, look up papers from the 1990s. Reference 43 reports such results in a 2D virtual maze.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.95764.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>How is it that animals find learned food locations in their daily life? Do they use landmarks to home in on these learned locations or do they learn a path based on self-motion (turn left, take ten steps forward, turn right, etc.). This study carefully examines this question in a well-designed behavioral apparatus. A key finding is that to support the observed behavior in the hidden food arena, mice appear to not use the distal cues that are present in the environment for performing this task. Removal of such cues did not change the learning rate, for example. In a clever analysis of whether the resulting cognitive map based on self-motion cues could allow a mouse to take a shortcut, it was found that indeed they are. The work nicely shows the evolution of the rodent's learning of the task, and the role of active sensing in the targeted reduction of uncertainty of food location proximal to its expected location.</p>
<p>Strengths:</p>
<p>A convincing demonstration that mice can synthesize a cognitive map for the finding of a static reward using body frame-based cues. This shows that the uncertainty of the final target location is resolved by an active sensing process of probing holes proximal to the expected location. Showing that changing the position of entry into the arena rotates the anticipated location of the reward in a manner consistent with failure to use distal cues.</p>
<p>Weaknesses:</p>
<p>The task is low stakes, and thus the failure to use distal cues at most costs the animal a delay in finding the food; this delay is likely unimportant to the animal. Thus, it is unclear whether this result would generalize to a situation where the animal may be under some time pressure, urgency due to food (or water) restriction, or due to predatory threat. In such cases, the use of distal cues to make locating the reward robust to changing start locations may be more likely to be observed.</p>
</body>
</sub-article>
<sub-article id="sa4" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.95764.1.sa4</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Xu</surname>
<given-names>Jiayun</given-names>
</name>
<role specific-use="author">Author</role>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Girardi-Schappo</surname>
<given-names>Mauricio</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9111-4905</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Béïque</surname>
<given-names>Jean-Claude</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7278-4906</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Longtin</surname>
<given-names>André</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0678-9893</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Maler</surname>
<given-names>Leonard</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7666-2754</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<p>We would like to thank all the reviewers and editors for their thoughtful and detailed comments, critiques and suggestions. We will revise our manuscript in accordance with all the points raised by the reviewers. Here we summarize some of the main points that we intend to address in our revised manuscript.</p>
<p>The reviewers noted that we were not sufficiently careful in identifying possible exogenous cues that the mice might be using to locate the cues and that we did not consider why such cues might be ineffective. As the reviewers point out, the mice may be ignoring the visual landmarks (and floor scratches) because they are not reliable cues and their relation to the food varies with the entrance the mice have used. In particular, a reviewer refers to papers that show that “in environments with 'unreliable' landmarks, place cells are not controlled by landmarks”. These papers were known to the authors but failed to make final cut of our extensive discussion. This important point will be thoroughly addressed.</p>
<p>Another critical point was the mice were often doing thigmotaxis. The literature on thigmotaxis was known to us and we will now directly refer to this point. We do note that the final average start to food trajectory (TEV) is directly to the food. In other words, the thigmotaxic trajectories and “towards the center” trajectories effectively average out.</p>
<p>There was a very cogent point about the difficulty of totally eliminating odor cues that we will now address. Finally, based on studies using a virtual reality environment, one reviewer questioned the use of “path integration” as a signal that encodes goal location. The relevance of path integration to spatial learning and performance is a very difficult issue that, to our knowledge, has never been entirely settled in the vast spatial learning literature. We do not think that our data can “settle’ this issue but will try to at least be explicit re the complexity of the path integration hypothesis as it applies to both our own data and the virtual reality literature. In particular, we will discuss the potential roles of optic flow versus proprioceptive and vestibular inputs to a putative path integration mechanism.</p>
<p>Finally, the reviewers raised many important technical points re statistics reporting and how the figures are presented. In our revision, we will completely comply with all these helpful critiques.</p>
</body>
</sub-article>
</article>