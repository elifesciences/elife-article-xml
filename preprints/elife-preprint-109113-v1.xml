<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">109113</article-id>
<article-id pub-id-type="doi">10.7554/eLife.109113</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.109113.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.5</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>How Occam’s razor guides human decision-making</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0384-7699</contrib-id>
<name>
<surname>Piasini</surname>
<given-names>Eugenio</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n1">*</xref>
<email>epiasini@sissa.it</email>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3946-5003</contrib-id>
<name>
<surname>Liu</surname>
<given-names>Shuze</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="author-notes" rid="n1">*</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4590-1956</contrib-id>
<name>
<surname>Chaudhari</surname>
<given-names>Pratik</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6497-3819</contrib-id>
<name>
<surname>Balasubramanian</surname>
<given-names>Vijay</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="aff" rid="a5">5</xref>
<xref ref-type="author-notes" rid="n2">†</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6018-0483</contrib-id>
<name>
<surname>Gold</surname>
<given-names>Joshua I</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n2">†</xref>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/004fze387</institution-id><institution>International School for Advanced Studies (SISSA)</institution></institution-wrap>, <city>Trieste</city>, <country country="IT">Italy</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00b30xv10</institution-id><institution>University of Pennsylvania</institution></institution-wrap>, <city>Philadelphia</city>, <country country="US">United States</country></aff>
<aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03vek6s52</institution-id><institution>PhD Program in Neuroscience, Harvard University</institution></institution-wrap>, <city>Boston</city>, <country country="US">United States</country></aff>
<aff id="a4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01arysc35</institution-id><institution>Santa Fe Institute</institution></institution-wrap>, <city>Santa Fe</city>, <country country="US">United States</country></aff>
<aff id="a5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>Rudolf Peierls Centre for Theoretical Physics, University of Oxford</institution></institution-wrap>, <city>Oxford</city>, <country country="GB">United Kingdom</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Hanks</surname>
<given-names>Timothy D</given-names>
</name>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-4147-4475</contrib-id><role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/05rrcem69</institution-id><institution>University of California, Davis</institution>
</institution-wrap>
<city>Davis</city>
<country>United States of America</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-8451-0523</contrib-id><role>Senior Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="equal"><label>*</label><p>Contributed equally</p></fn>
<fn id="n2" fn-type="equal"><label>†</label><p>Contributed equally</p></fn>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-12-09">
<day>09</day>
<month>12</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP109113</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-09-05">
<day>05</day>
<month>09</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-08-27">
<day>27</day>
<month>08</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.01.10.523479"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Piasini et al</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Piasini et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-109113-v1.pdf"/>
<abstract>
<p>Occam’s razor is the principle that, all else being equal, simpler explanations should be preferred over more complex ones. This principle is thought to guide human decision-making, but the nature of this guidance is not known. Here we used preregistered behavioral experiments to show that people tend to prefer the simpler of two alternative explanations for uncertain data. These preferences match predictions of formal theories of model selection that penalize excessive flexibility. These penalties emerge when considering not just the best explanation but the integral over all possible, relevant explanations. We further show that these simplicity preferences persist in humans, but not in certain artificial neural networks, even when they are maladaptive. Our results imply that principled notions of statistical model selection, including integrating over possible, latent causes to avoid overfitting to noisy observations, may play a central role in human decision-making.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Expanded the Introduction with more in-depth discussion of previous work.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>To make decisions in the real world, we must often choose between multiple, plausible explanations for noisy, sparse data. When evaluating competing explanations, Occam’s razor says that we should consider not just how well they account for data that have been observed, but also their potentially excessive flexibility in describing alternative, and potentially irrelevant, data that have not been observed (<xref ref-type="bibr" rid="c2">Baker, 2022</xref>) (e.g., “a ghost did it!”; <xref rid="fig1" ref-type="fig">Figure 1a,b</xref>). This kind of simplicity preference has long been proposed as an organizing principle for mental function (<xref ref-type="bibr" rid="c12">Feldman, 2016</xref>), such as in the early concept of Prägnanz in Gestalt psychology (<xref ref-type="bibr" rid="c27">Koffka, 2014</xref>; <xref ref-type="bibr" rid="c54">Wagemans et al., 2012</xref>), a number of “minimum principles” for vision (<xref ref-type="bibr" rid="c22">Hatfield, 1985</xref>) and theories that posit a central role for data compression in cognition (<xref ref-type="bibr" rid="c7">Chater, 1999</xref>; <xref ref-type="bibr" rid="c8">Chater &amp; Vitányi, 2003</xref>). Simplicity has also been proposed as one of the key features that help us assess the merit of an explanation within broader theories of explanatory value (<xref ref-type="bibr" rid="c56">Wojtowicz &amp; DeDeo, 2020</xref>).</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Formalizing Occam’s razor as Bayesian model selection to understand simplicity preferences in human decision-making.</title>
<p><bold>a</bold>: Occam’s razor prescribes an aversion to complex explanations (models). In Bayesian model selection, model complexity quantifies the flexibility of a model, or its capacity to account for a broad range of empirical observations. In this example, we observe an apple falling from a tree (left) and compare two possible explanations: classical mechanics, and 2) the intervention of a ghost. <bold>b</bold>: Schematic comparison of the evidence of the two models in a. Classical mechanics (pink) explains a narrower range of observations than the ghost (green), which is a valid explanation for essentially any conceivable phenomenon (e.g., both a falling and spinning-upward trajectory, as in the insets). Absent further evidence and given equal prior probabilities, Occam’s razor posits that the simpler model (classical mechanics) is preferred, because its hypothesis space is more concentrated around the sparse, noisy data and thus avoids “overfitting” to noise. <bold>c</bold>: A geometrical view of the model-selection problem. Two alternative models are represented as geometrical manifolds, and the maximum-likelihood point for each model is represented as the projection of the data (red star) onto the manifolds. <bold>d</bold>: Systematic expansion of the log evidence of a model M (see previous work by <xref ref-type="bibr" rid="c3">Balasubramanian (1997)</xref> and Methods section A.2). <inline-formula id="inline-eqn-1"><inline-graphic xlink:href="523479v5_inline46.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is the maximum-likelihood point on model ℳ for data X, N is the number of observations, d is the number of parameters of the model, <inline-formula id="inline-eqn-2"><inline-graphic xlink:href="523479v5_inline47.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is the likelihood gradient evaluated at <inline-formula id="inline-eqn-3"><inline-graphic xlink:href="523479v5_inline48.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, h is the observed Fisher information matrix, and g is the expected Fisher information matrix (see Methods). g(ϑ) captures how distinguishable elements of ℳ are in the neighborhood of ϑ (see Methods section A.2 and previous work by <xref ref-type="bibr" rid="c3">Balasubramanian (1997)</xref>). When M is the true source of the data X, h(X; ϑ) can be seen as a noisy version of g(ϑ), estimated from limited data (<xref ref-type="bibr" rid="c3">Balasubramanian, 1997</xref>). ĥ<sup>−1</sup> is a shorthand for<inline-formula id="inline-eqn-4"><inline-graphic xlink:href="523479v5_inline49.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, and <inline-formula id="inline-eqn-5"><inline-graphic xlink:href="523479v5_inline50.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is the length of <inline-formula id="inline-eqn-6"><inline-graphic xlink:href="523479v5_inline51.gif" mime-subtype="gif" mimetype="image"/></inline-formula> measured in the metric defined by ĥ<sup>−1</sup>. The ellipsis collects terms that decrease as N grows. Each term of the expansion represents a distinct geometrical feature of the model (<xref ref-type="bibr" rid="c3">Balasubramanian, 1997</xref>): dimensionality penalizes models with many parameters; boundary (a novel contribution of this work) penalizes models for which <inline-formula id="inline-eqn-7"><inline-graphic xlink:href="523479v5_inline52.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is on the boundary; volume counts the number of distinguishable probability distributions contained in ℳ; and robustness captures the shape (curvature) of ℳ near <inline-formula id="inline-eqn-8"><inline-graphic xlink:href="523479v5_inline53.gif" mime-subtype="gif" mimetype="image"/></inline-formula> (see Methods section A.2 and previous work by <xref ref-type="bibr" rid="c3">Balasubramanian (1997)</xref>). <bold>e</bold>: Psychophysical task with variants designed to probe each geometrical feature in d. For each trial, a random location on one model was selected (gray star), and data (red dots) were sampled from a Gaussian centered around that point (gray shading). The red star represents the empirical centroid of the data, by analogy with c. The maximum-likelihood point can be found by projecting the empirical centroid onto one of the models. Participants saw the models (black lines) and data (red dots) only and were required to choose which model was best for the data. Insets: task performance for the given task variant, for a set of 100 simulated ideal Bayesian observers (orange) versus a set of 100 simulated maximum-likelihood observers (i.e., choosing based only on whichever model was the closest to the empirical centroid of the data on a given trial; cyan).</p></caption>
<graphic xlink:href="523479v5_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Numerous behavioral studies have shown that human decision-makers exhibit simplicity preferences when performing a variety of tasks including perceptual estimation, source reconstruction, and causal explanation (<xref ref-type="bibr" rid="c7">Chater, 1999</xref>; <xref ref-type="bibr" rid="c16">Genewein &amp; Braun, 2014</xref>; <xref ref-type="bibr" rid="c17">Gershman &amp; Niv, 2013</xref>; <xref ref-type="bibr" rid="c19">Griffiths &amp; Tenenbaum, 2005</xref>; <xref ref-type="bibr" rid="c26">Johnson et al., 2014</xref>; <xref ref-type="bibr" rid="c28">Körding et al., 2007</xref>; <xref ref-type="bibr" rid="c31">Little &amp; Shiffrin, 2009</xref>; <xref ref-type="bibr" rid="c43">Pothos &amp; Chater, 2002</xref>). Multiple formal definitions have been proposed for what exactly may constitute the “simplicity” that is favored (or, equivalently, “complexity” that is disfavored) under these conditions, for instance the number of unobserved or unexplained causes invoked by an explanation (<xref ref-type="bibr" rid="c39">Pacer &amp; Lombrozo, 2017</xref>), description length and Kolmogorov complexity (<xref ref-type="bibr" rid="c7">Chater, 1999</xref>), or statistical complexity arising from the computation of marginal likelihoods in Bayesian inference (<xref ref-type="bibr" rid="c19">Griffiths &amp; Tenenbaum, 2005</xref>; <xref ref-type="bibr" rid="c28">Körding et al., 2007</xref>). Consistent with a Bayesian explanation, in some cases these kinds of simplicity preferences are diminished when more probabilistic evidence is provided, which has been proposed to reflect a Bayesian prior that places a heavier weight on simpler explanations (<xref ref-type="bibr" rid="c6">Bonawitz &amp; Lombrozo, 2012</xref>; <xref ref-type="bibr" rid="c32">Lombrozo, 2007</xref>; <xref ref-type="bibr" rid="c39">Pacer &amp; Lombrozo, 2017</xref>). However, it remains unknown if and how this kind of prior, or other factors that might be driving these simplicity preferences, relate quantitatively to the specific trade-offs between simplicity and goodness-of-fit of an explanation that are prescribed by theoretical notions of complexity.</p>
<p>The goal of the present study was to establish a the-oretically grounded, quantitative account of simplicity biases in human perceptual decision-making. To do so, we formalized human decision-making as a statistical model-selection problem. This approach allowed us to identify specific features that make one model (i.e., potential source of perceptual observations) more (or less) complex than another and thus require specific penalties to counteract their predicted effects on goodness-of-fit because of excessive flexibility (<xref ref-type="bibr" rid="c3">Balasubramanian, 1997</xref>). Critically, these penalties can depend on the data and therefore cannot be fully mimicked by a more general simplicity preference (<xref ref-type="bibr" rid="c32">Lombrozo, 2007</xref>). As we detail below, this approach allowed us to identify specific forms of simplicity biases that support the idea that our predilection for Occam’s razor is not merely a preference but rather a manifestation of core decision processes that integrate over possible, latent causes to counteract the problems that arise when attempting to match flexible explanations to noisy observations.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Occam’s razor formalized as model selection</title>
<p>Given a set <italic>X</italic> of <italic>N</italic> observations and a set of possible parametric statistical models {ℳ<sub>1</sub>, ℳ<sub>2</sub>, …}, we seek the model ℳ that in some sense is the best description of the data <italic>X</italic>. In this context, Occam’s razor can be interpreted as requiring the goodness-of-fit of a model to be penalized by some measure of its flexibility, or complexity, when comparing it against other models. Bayesian statistics offers a natural characterization of such a measure of complexity and specifies the way in which it should be traded off against goodness-of-fit to maximize decision accuracy, typically because the increased flexibility provided by increased complexity tends to cause errors by overfitting to noise in the observations (<xref ref-type="bibr" rid="c3">Balasubramanian, 1997</xref>; <xref ref-type="bibr" rid="c18">Good, 1968</xref>; <xref ref-type="bibr" rid="c21">Gull, 1988</xref>; <xref ref-type="bibr" rid="c23">Jaynes, 2003</xref>; H. <xref ref-type="bibr" rid="c24">Jeffreys, 1939</xref>; W. <xref ref-type="bibr" rid="c25">Jeffreys &amp; Berger, 1991</xref>; <xref ref-type="bibr" rid="c33">MacKay, 1992</xref>; <xref ref-type="bibr" rid="c49">Smith &amp; Spiegelhalter, 1980</xref>). According to the Bayesian framework, models should be compared based on their evidence or marginal likelihood <italic>p</italic>(<italic>X</italic>|ℳ) = d<italic>ϑw</italic>(<italic>ϑ</italic>)<italic>p</italic>(<italic>X</italic>|ℳ, <italic>ϑ</italic>), where <italic>ϑ</italic> represents model parameters and <italic>w</italic>(<italic>ϑ</italic>) their associated prior. By varying the parameters, we can explore instances of a model and sweep out a manifold of possible descriptions of the data. Two such manifolds are visualized in <xref rid="fig1" ref-type="fig">Figure 1c</xref>, along with the maximum-likelihood parameters that assign the highest probability to the observed data. Under mild regularity assumptions and with sufficient data, the (log) evidence can be written as the sum of the maximum log likelihood of ℳ and several penalty factors (<xref rid="fig1" ref-type="fig">Figure 1d</xref>). These penalty factors, which are found even when the prior (data-independent) probabilities of the models under consideration are equal, can be interpreted as providing quantitatively defined preferences against certain models according to specific forms of complexity that they embody (<xref ref-type="bibr" rid="c3">Balasubramanian, 1997</xref>; <xref ref-type="bibr" rid="c33">MacKay, 1992</xref>). This approach, which we call the Fisher Information Approximation (FIA), has been used to identify worse-fitting, but better-generalizing, psychophysical models describing the relationship between physical variables (e.g., light intensity) and their psychological counterparts (e.g., brightness) (<xref ref-type="bibr" rid="c37">Myung et al., 2000</xref>). It is related to similar quantitative definitions of statistical model complexity, such as the Minimum Description Length (<xref ref-type="bibr" rid="c20">Grünwald, 2007</xref>; <xref ref-type="bibr" rid="c30">Lanterman, 2001</xref>; <xref ref-type="bibr" rid="c46">Rissanen, 1996</xref>), Minimum Message Length (<xref ref-type="bibr" rid="c55">Wallace, 2005</xref>), and Predictive Information (<xref ref-type="bibr" rid="c5">Bialek et al., 2001</xref>) frameworks. A key feature of the FIA is that if the prior over parameters <italic>w</italic>(<italic>ϑ</italic>) is taken to be uninformative (<xref ref-type="bibr" rid="c23">Jaynes, 2003</xref>), each penalty factor can be shown to capture a distinct geometric property of the model (<xref ref-type="bibr" rid="c3">Balasubramanian, 1997</xref>). These properties include not just the model’s dimensionality (number of parameters), which is the well-known Bayesian Information Criterion (BIC) for model selection (<xref ref-type="bibr" rid="c38">Neath &amp; Cavanaugh, 2012</xref>; <xref ref-type="bibr" rid="c48">Schwarz, 1978</xref>), but also its boundary (a novel term, detailed in Methods section A.2; see also the Discussion), volume, and shape (<xref rid="fig1" ref-type="fig">Figure 1c,d</xref>).</p>
<p>The complexity penalties depicted in <xref rid="fig1" ref-type="fig">Figure 1</xref> emerge because the Bayesian framework marginalizes over the model parameters. In applying this framework to human decision-making, we interpret this marginalization as an integration over latent causes: to evaluate a particular explanation (or “model”) for a given set of observed data, one considers how likely the data are under that explanation, on average over all possible configurations of that explanation. Intuitively, flexible explanations are penalized by the averaging because many of their configurations have nothing to do with the observed state of the world <italic>X</italic> and thus possess a vanishingly small likelihood <italic>p</italic>(<italic>X</italic>|ℳ, <italic>ϑ</italic>). Consider the following example, in which the data are represented by a point on a plane, <italic>X</italic> = (<italic>x, y</italic>) (<xref rid="fig2" ref-type="fig">Figure 2</xref>, top left). The problem is to decide between two alternative explanations (models) for the data: 1) ℳ<sub>1</sub>, a Gaussian distribution centered in (0, 0) with unit, isotropic variance; and 2) ℳ<sub>2</sub>, a parametric family of Gaussians, also with unit variance, but with centers located anywhere along the straight line connecting (−1<italic>/</italic>2, 1) and (1<italic>/</italic>2, 1). It is clear that ℳ<sub>2</sub> can explain a wider range of data, just like the ghost in <xref rid="fig1" ref-type="fig">Figure 1a</xref>, and is therefore more complex. For data that are equidistant from the two models, <italic>X</italic> = (0, 1<italic>/</italic>2), Occam’s razor prescribes that we should choose ℳ<sub>1</sub>. In other words, the decision boundary separating the area where one or the other model should be preferred is closer to ℳ<sub>2</sub> (the more complex model) than ℳ<sub>1</sub> (the simpler one). This simplicity bias is specific to a decision-maker that integrates over the latent causes (model configurations) and does not result from sampling multiple possible explanations via other, less systematic means, for example by adding sensory and/or choice noise (<xref rid="fig2" ref-type="fig">Figure 2</xref>; see also Supplementary Figure B.9).</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Integration over latent causes leads to Occam’s razor.</title>
<p><bold>a</bold>: Schematic of a simple decision-making scenario. A single datapoint (star) is sampled from one of two models (pink dot, green bar). One of the models (ℳ<sub>1</sub>) is a Gaussian with known variance, centered at the location of the pink dot. The other model (ℳ <sub>2</sub>) is a parametric family of Gaussians, with known and fixed variance and center located at a latent location along the green bar. Cyan line: boundary indicating locations in data space that are equidistant from ℳ<sub>1</sub> and ℳ<sub>2</sub>. <bold>b-d</bold>: Potential components of a decision-making observer for this scenario, which we call Noise-Integration-Noise observer (see Methods section A.1 and Supplementary Information section B.7 for further details). <bold>b</bold>: Sensory noise: the observer does not have access to the true data (location of the star), but a noisy version of it corrupted by Gaussian noise with variance ρ. <bold>c</bold>: Integration over latent causes: the observer can consider possible positions of the center of the Gaussian in model ℳ<sub>2</sub>. <bold>d</bold>: Choice noise: after forming an internal estimate of the relative likelihood of ℳ<sub>1</sub> and ℳ<sub>2</sub>, the observer can choose a model based on a deterministic process (for instance, always pick the most likely one), or a stochastic one where the probability of sampling one model is related to its likelihood. <bold>e-h</bold>: Behavior of the observer as a function of the location of the datapoint, within the zoomed-in region highlighted in a, and of the presence of the mechanisms illustrated in b-d. <bold>e</bold>: probability that the observer will report ℳ<sub>2</sub> as a function of the location of the datapoint, when sensory and choice noise are low and in absence of integration over latent causes. <bold>f</bold>: same as e, but in presence of integration over latent causes. The decision boundary of the observer (white area) is shifted towards the more complex model (ℳ <sub>2</sub>) compared to e. This shift means that, when the data is equidistant from ℳ<sub>1</sub> and ℳ<sub>2</sub>, the observer prefers the simplest model (ℳ<sub>1</sub>). <bold>g</bold>: same as e, but with strong sensory noise. The decision boundary of the observer is shifted in the opposite direction as f. <bold>h</bold>: same as e, but with strong choice noise. Choice noise has no effect on the location of the decision boundary.</p></caption>
<graphic xlink:href="523479v5_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s2b">
<title>Humans exhibit theoretically grounded simplicity preferences</title>
<p>To relate the FIA complexity terms to the potential preferences exhibited by both human and artificial decision-makers, we designed a simple decision-making task. For each trial, <italic>N</italic> = 10 simultaneously presented, noisy observations (red dots in <xref rid="fig1" ref-type="fig">Figure 1e</xref>) were sampled from a 2D Normal (“generative”) distribution centered somewhere within one of two possible shapes (black shapes in <xref rid="fig1" ref-type="fig">Figure 1e</xref>). The identity of the shape generating the data (top versus bottom) was chosen at random with equal probability. Likewise, the location of the center of the Normal distribution within the selected shape was sampled uniformly at random, in a way that did not depend on the model parameterization, by using Jeffrey’s prior (<xref ref-type="bibr" rid="c23">Jaynes, 2003</xref>). Given the observations, the decision-maker chose the shape (model) that was more likely to contain the center of the generative distribution. We used four task variants, each designed to probe primarily one of the distinct geometrical features that are penalized in Bayesian model selection (i.e., a Bayesian observer is expected to have a particular, quantitative preference away from the more-complex alternative in each pair; <xref rid="fig1" ref-type="fig">Figure 1c</xref> and <xref ref-type="fig" rid="fig1">d</xref>). For this task, the FIA provided a good approximation of the exact Bayesian posterior (Supplementary Information section B.1). Accordingly, simulated observers that increasingly integrated over latent causes, like the Bayesian observer, exhibited increasing FIA-like biases. These biases were distinguishable from (and degraded by) effects of increasing sensory and/or choice noise (Supplementary Information B.7.1 and <xref ref-type="fig" rid="figB10">Supplementary Figure B.10</xref>).</p>
<p>For our human studies, we used the on-line research platform Pavlovia to implement the task, and Prolific to recruit and test participants. Following our preregistered approaches (<xref ref-type="bibr" rid="c40">Piasini et al., 2020</xref>, <xref ref-type="bibr" rid="c41">2021</xref>, <xref ref-type="bibr" rid="c42">2022</xref>), we collected data from 202 participants, divided into four groups that each performed one of the four separate versions of the task depicted in <xref rid="fig1" ref-type="fig">Figure 1e</xref> (each group comprised ∼50 participants). We provided instructions that used the analogy of seeds from a flower located in one of two flower beds, to provide an intuitive framing of the key concepts of noisy data generated by a particular instance of a parametric model from one of two model families. To minimize the possibility that participants would simply learn from implicit or explicit feedback over the course of each session to make more optimal (i.e., simplicity-preferring) choices of flower beds, we: 1) used conditions for which the difference in performance between ideal observers that penalized model complexity according to the FIA and simulated observers that used only model likelihood was ∼1% (depending on the task type; <xref rid="fig1" ref-type="fig">Figure 1e</xref>, insets), which translates to ∼5 additional correct trials over the course of an entire experiment; and 2) provided feedback only at the end of each block of 100 trials, not each trial. We used hierarchical (Bayesian) logistic regression to measure the degree to which each participant’s choices were affected by model likelihood (distance from the data to a given model) and each of the FIA features (see Methods section A.6). We defined each participant’s sensitivity to each FIA term as a normalized quantity, relative to their likelihood sensitivity (i.e., by dividing the logistic coefficient associated with a given FIA term by the logistic coefficient associated with the likelihood).</p>
<p>The human participants were sensitive to all four forms of model complexity (<xref rid="fig3" ref-type="fig">Figure 3</xref>). Specifically, the estimated normalized population-level sensitivity (posterior mean ± st. dev., where zero implies no sensitivity and one implies Bayes-optimal sensitivity) was 4.66±0.96 for dimensionality, 1.12±0.10 for boundary, 0.23±0.12 for volume, and 2.21±0.12 for robustness (note that, following our preregistered plan, we emphasize parameter estimation using Bayesian approaches (<xref ref-type="bibr" rid="c15">Gelman et al., 2014</xref>; <xref ref-type="bibr" rid="c29">Kruschke, 2015</xref>; <xref ref-type="bibr" rid="c35">McElreath, 2016</xref>) here and throughout the main text, and we provide complementary null hypothesis significance testing in the Supplementary Information section B.6 and <xref ref-type="table" rid="tblB8">Table B.8</xref>). Formal model comparison (WAIC; see Supplementary Information section B.6.1 and <xref ref-type="table" rid="tblB6">Tables B.6</xref> and <xref ref-type="table" rid="tblB7">B.7</xref>) confirmed that their behavior was better described by taking into account the geometric penalties defined by the theory of Bayesian model selection, rather than by relying only on the minimum distance between model and data (i.e., the maximum-likelihood solution). Consistent with these analyses, their decisions were consistent with processes that tended to integrate over latent causes (and tended to exhibit moderate levels of sensory noise and low choice noise; Supplementary Information B.7 and <xref ref-type="fig" rid="figB11">Supplementary Figures B.11</xref> and <xref ref-type="fig" rid="figB12">B.12</xref>). Overall, our data indicate that people tend to integrate over latent causes in a way that gives rise to Occam’s razor, manifesting as sensitivity to the geometrical features in Bayesian model selection that characterize model complexity.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Humans exhibit theoretically grounded simplicity preferences.</title>
<p><bold>a</bold>: Summary of human behavior. Hue (pink/green): k-nearest-neighbor interpolation of the model choice, as a function of the empirical centroid of the data. Color gradient (light/dark): marginal density of empirical data centroids for the given model pair, showing the region of space where data were more likely to fall. Cyan solid line: decision boundary for an observer that always chooses the model with highest maximum likelihood. Orange dashed line: decision boundary for an ideal Bayesian observer. The participants’ choices tended to reflect a preference for the simpler model, particularly near the center of the screen, where the evidence for the alternatives was weak. For instance, in the left panel there is a region where data were closer to the line than to the dot, but participants chose the dot (the simpler, lower-dimensional “model”) more often than the line. <bold>b</bold>: Participant sensitivity to each geometrical feature characterizing model complexity was estimated via hierarchical logistic regression (see Methods section A.6 and Supplementary Information section B.2), using as predictors a constant to account for an up/down choice bias, the difference in likelihoods for the two models (L<sub>2</sub> − L<sub>1</sub>) and the difference in each FIA term for the two models (D<sub>2</sub> −D<sub>1</sub>, etc). Following a hierarchical regression scheme, the participant-level sensitivities were in turn modeled as being sampled from a population-level distribution. The mean of this distribution is our population-level estimate for the sensitivity. <bold>c</bold>: Overall accuracy versus estimated relative FIA sensitivity for each task condition, as indicated. Points are data from individual participants. Each fitted FIA coefficient was normalized to the likelihood coefficient and thus could be interpreted as a relative sensitivity to the associated FIA term. For each term, an ideal Bayesian observer would have a relative sensitivity of one (dashed orange lines), whereas an observer that relied on only maximum-likelihood estimation (i.e., choosing “up” or “down” based on only the model that was the closest to the data) would have a relative sensitivity of zero (solid cyan lines). Top, gray: Population-level estimates (posterior distribution of population-level relative sensitivity given the experimental observations). Bottom: each gray dot represents the task accuracy of one participant (y axis) versus the posterior mean estimate of the relative sensitivity for that participant (x axis). Intuitively, the population-level posterior can be interpreted as an estimate of the location of the center of the cloud of dots representing individual subjects in the panel below. See Methods section A.6 for further details on statistical inference and the relationship between population-level and participant-level estimates. Purple: relative sensitivity of an ideal observer that samples from the exact Bayesian posterior (not the approximated one provided by the FIA). Shading: posterior mean ± 1 or 2 stdev., estimated by simulating 50 such observers.</p></caption>
<graphic xlink:href="523479v5_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>The participants exhibited substantial individual variability in performance that included ranges of sensitivities to each FIA term that spanned optimal and sub-optimal values. This variability was large compared to the uncertainty associated with participant-level sensitivity estimates (Supplementary Information B.4) and impacted performance in a manner that highlighted the usefulness of appropriately tuned (i.e., close to Bayes optimal) simplicity preferences: accuracy tended to decline for participants with FIA sensitivities further away from the theoretical predictions (<xref rid="fig2" ref-type="fig">Figure 2c</xref>; posterior mean ± st. dev. of Spearman’s rho between accuracy and |<italic>β</italic>− 1|, where <italic>β</italic> is the sensitivity: dimensionality, −0.69±0.05; boundary, −0.21±0.11; volume, −0.10±0.10; robustness, −0.54±0.10). The sub-optimal sensitivities exhibited by many participants did not appear to result simply from a lack of task engagement, because FIA sensitivity did not correlate with errors on easy trials (posterior mean ± st. dev. of Spearman’s rho between lapse rate, estimated with an extended regression model detailed in Methods section A.6.1, and the absolute difference from optimal sensitivity for: dimensionality, 0.08±0.12; boundary, 0.15±0.12; volume, −0.04±0.13; robustness, 0.15±0.14; see Supplementary Information section B.5). Likewise, sub-optimal FIA sensitivity did not correlate with weaker likelihood sensitivity for the boundary (rho=-0.13±0.11) and volume (−0.06±0.11) terms, although stronger, negative relationships with the dimensionality (−0.35±0.07) and robustness terms (−0.56±0.10) suggest that the more extreme and variable simplicity preferences under those conditions (and lower performance, on average; see <xref rid="fig2" ref-type="fig">Figure 2c</xref>) reflected a more general difficulty in performing those versions of the task.</p>
</sec>
<sec id="s2c">
<title>Artificial Neural Networks learn optimal simplicity preferences</title>
<p>To better understand the optimality, variability, and generality of the simplicity preferences exhibited by our human participants, we compared their performance to that of artificial neural networks (ANNs) trained to optimize performance on this task. We used a novel ANN architecture that we designed to perform statistical model selection, in a form applicable to the task described above (<xref rid="fig4" ref-type="fig">Figure 4a,b</xref>). On each trial, the network took as input two images representing the models to be compared, and a set of coordinates representing the observations on that trial. The output of the network was a decision between the two models, encoded as a softmax vector. We analyzed 50 instances of the ANN that differed only in the random initialization of their weights and in the examples seen during training, using the same logistic-regression approach we used for the human participants.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Artificial neural networks exhibit theoretically grounded simplicity preferences.</title>
<p><bold>a</bold>: A novel deep neural-network architecture for statistical model selection. The network (see text and Methods for details) takes two images as input, each representing a model, and a set of 2D coordinates, each representing a datapoint. The output is a softmax-encoded choice between the two models. <bold>b</bold>: Each network was trained on multiple variants of the task, including systematically varied model length or curvature, then tested using the same configurations as for the human studies. <bold>c</bold>: Summary of network behavior, like <xref ref-type="fig" rid="fig3">Figure 3a</xref>. Hue (pink/green): k-nearest-neighbor interpolation of the model choice, as a function of the empirical centroid of the data. Color gradient (light/dark): marginal density of empirical data centroids for the given model pair, showing the region of space where data were more likely to fall. Cyan solid line: decision boundary for an observer that always chooses the model with highest maximum likelihood. Orange dashed line: decision boundary for an ideal Bayesian observer. <bold>d</bold>: Estimated relative sensitivity to geometrical features characterizing model complexity. As for the human participants, each fitted FIA coefficient was normalized to the likelihood coefficient and thus can be interpreted as a relative sensitivity to the associated FIA term. For each term, an ideal Bayesian observer would have a relative sensitivity of one (dashed orange lines), whereas an observer that relied on only maximum-likelihood estimation (i.e., choosing”up” or “down” based on only the model that was the closest to the data) would have a relative sensitivity of zero (solid cyan lines). Top: population-level estimate (posterior distribution of population-level relative sensitivity given the experimental observations; see Methods section A.6 for details). Bottom: each gray dot represents the task accuracy of one of 50 trained networks (y axis) versus the posterior mean estimate of the relative sensitivity for that network (x axis). Intuitively, the population-level posterior can be interpreted as an estimate of the location of the center of the cloud of dots representing individual subjects in the panel below. See Methods section A.6 for further details on statistical inference and the relationship between population-level and participant-level estimates. Purple: relative sensitivity of an ideal observer that samples from the exact Bayesian posterior (not the approximated one provided by the FIA). Shading: posterior mean ± 1 or 2 stdev., estimated by simulating 50 such observers.</p></caption>
<graphic xlink:href="523479v5_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>The ANN was designed as follows (see Methods for more details). The input stage consisted of two pretrained VGG16 convolutional neural networks (CNNs), each of which took in a pictorial representation of one of the two models under consideration. VGG was chosen as a popular architecture that is often taken as a benchmark for comparisons with the human visual system (<xref ref-type="bibr" rid="c36">Muratore et al., 2022</xref>; <xref ref-type="bibr" rid="c47">Schrimpf et al., 2020</xref>). The CNNs were composed of a stack of convolutional layers whose weights were kept frozen at their pretrained values, followed by three fully-connected layers whose weights were allowed to change during training. The output of the CNNs were each fed into a multilayer perceptron (MLP) consisting of linear, rectified-linear (ReLU), and batch-normalization layers. The MLP outputs were then concatenated and fed into an equivariant MLP, which enforces equivariance of the network output under position swap of the two models through a custom parameter-sharing scheme (<xref ref-type="bibr" rid="c45">Ravanbakhsh et al., 2017</xref>). The network also contained two conditional variational autoencoder (C-VAE) structures, which sought to replicate the data-generation process conditioned on each model and therefore encouraged the fully connected layers upstream to learn model representations that captured task-relevant features.</p>
<p>After training, the ANNs performed the task substantially better than the human participants, with higher overall accuracies that included higher likelihood sensitivities (Supplementary Information section B.3) and simplicity preferences that more closely matched the theoretically optimal values (<xref rid="fig4" ref-type="fig">Figure 4c,d</xref>). These simplicity preferences were closer to those expected from simulated observers that use the exact Bayesian model posterior rather than the FIA-approximated one, consistent with the fact that the FIA provides an imperfect approximation to the exact Bayesian posterior. These simplicity preferences varied slightly in magnitude across the different networks, but unlike for the human participants this variability was relatively small (compare ranges of values in <xref rid="fig3" ref-type="fig">Figures 3c</xref> and 4d, plotted on different <italic>x</italic>-axis scales) and it was not an indication of suboptimal network behavior because it was not related systematically to any differences in the generally high accuracy rates for each condition (<xref rid="fig4" ref-type="fig">Figure 4d</xref>; posterior mean ± st. dev. of Spearman’s rho between accuracy and |<italic>β</italic>−1|, where <italic>β</italic> is the sensitivity: dimensionality, −0.14±0.10; boundary, 0.08±0.11; volume, −0.12±0.11; robustness, −0.08±0.11). These results imply that the stochastic nature of the task gives rise to some variability in simplicity biases even after extensive training to optimize performance accuracy, but this source of variability cannot by itself account for the range of sensitivities (and suboptimalities) exhibited by the human participants.</p>
</sec>
<sec id="s2d">
<title>Humans, unlike ANNs, maintain suboptimal simplicity preferences</title>
<p>Our results, combined with the fact that we did not provide trial-by-trial feedback to the participants while they performed the task, suggest that the human simplicity preferences we measured were not simply learned optimizations for these particular task conditions but rather are a more inherent (and variable) part of how we make decisions under uncertainty. However, because we provided each participant with instructions that echoed Bayesian-like reasoning (see Methods) and a brief training set with feedback before their testing session, we cannot rule out from the data presented in <xref rid="fig3" ref-type="fig">Figure 3</xref> alone that at least some aspects of the simplicity preferences we measured from the human participants depended on those specific instructions and training conditions. We therefore ran a second experiment to rule out this possibility. For this experiment, we used the same task variants as above but a different set of instructions and training, designed to encourage participants to pick the model with the maximum likelihood (i.e., not integrate over latent causes but instead just consider the single cause that best matches the observed data), thus disregarding model complexity. Specifically, the visual cues were the same as in the original experiment, but the participants were asked to report which of the two shapes on the screen was closest to the center-of-mass of the dot cloud. We ensured that the participants recruited for this “maximum-likelihood” task had not participated in the original, “generative” task. We also trained and tested ANNs on this version of the task, using the maximum-likelihood solution as the correct answer.</p>
<p>Despite this major difference in instructions and training, the human participants exhibited similar simplicity preferences on the generative and maximum-likelihood tasks, suggesting that humans have a general predilection for simplicity even without relevant instructions or incentives (<xref rid="fig5" ref-type="fig">Figure 5</xref>, left). Specifically, despite some quantitative differences, the distributions of relative sensitivities showed the same basic patterns for both tasks, with a general increase of relative sensitivity from volume (0.19±0.08 for the maximum-likelihood task; compare to values above), to boundary (0.89±0.10), to robustness (2.27±0.15), to dimensionality (2.29±0.41). In stark contrast to the human data and to ANNs trained on the true generative task, ANN sensitivity to model complexity on the maximum-likelihood task was close to zero for all four terms (<xref rid="fig5" ref-type="fig">Figure 5</xref>, right). To summarize the similarities and differences between how humans and ANNs used simplicity biases to guide their decision-making behaviors for these tasks, and their implications for performance, <xref rid="fig6" ref-type="fig">Figure 6</xref> shows overall accuracy for each set of conditions we tested. Specifically, for each participant or ANN, task configuration, and instruction set, we computed the percentage of correct responses with respect to both the generative task (i.e., for which theoretically optimal performance depends on simplicity biases) and the maximum-likelihood task (i.e., for which theoretically optimal performance does not depend on simplicity biases). Because the maximum-likelihood solutions are deterministic (they depend only on which model the data centroid is closest to, and thus there exists an optimal, sharp decision boundary that leads to perfect performance) and the generative solutions are not (they depend probabilistically on the likelihood and bias terms, so it is generally impossible to achieve perfect performance), performance on the former is expected to be higher than on the latter. Accordingly, both ANNs and (to a lesser extent) humans tended to perform better when assessed relative to maximum-likelihood solutions. Moreover, the ANNs tended to exhibit behavior that was consistent with optimization to the given task conditions: networks trained to find maximum-likelihood solutions did better than networks trained to find generative solutions for the maximum-likelihood task, and networks trained to find generative solutions did better than networks trained to find maximum-likelihood solutions for the generative task. In contrast, humans tended to adopt similar strategies regardless of the task conditions, in all cases using Bayesian-like simplicity biases.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Humans, but not artificial networks, exhibit simplicity preferences even when they are suboptimal.</title>
<p><bold>a</bold>: Relative sensitivity of human participants to the geometric complexity terms (population-level estimates, as in <xref ref-type="fig" rid="fig3">Figure 3c</xref>, top) for two task conditions: 1) the original, “generative” task where participants were implicitly instructed to solve a model-selection problem (same data as in <xref ref-type="fig" rid="fig3">Figure 3c</xref>, top; orange); and 2) a “maximum-likelihood” task variant, where participants were instructed to report which of two models has the highest likelihood (shortest distance from the data; cyan). The two task variants were tested on distinct participant pools of roughly the same size (202 participants for the generative task, 201 for the maximum-likelihood task, in both cases divided in four groups of roughly 50 participants each). Solid cyan lines: relative sensitivity of a maximum-likelihood observer. Orange dashed lines: relative sensitivity of an ideal Bayesian observer. <bold>b</bold>: Same comparison and format (note the different x-axis scaling), but for two distinct populations of 50 deep neural networks trained on the two variants of the task (orange is the same data as in <xref ref-type="fig" rid="fig4">Figure 4d</xref>, top).</p></caption>
<graphic xlink:href="523479v5_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Humans and artificial neural networks have different patterns of accuracy reflecting their different use of simplicity preferences.</title>
<p>Each panel shows accuracy with respect to maximum-likelihood solutions (i.e., the model closest to the centroid of the data; ordinate) versus with respect to generative solutions (i.e., the model that generated the data; abscissa). The gray line is the identity. Columns correspond to the four task variants associated with the four geometric complexity terms, as indicated. <bold>a</bold>: Data from individual human participants (points), instructed to find the generative (orange) or maximum-likelihood (cyan) solution. Human performance was higher when evaluated against maximum-likelihood solutions than it was when evaluated against generative solutions, for all groups of participants (two-tailed paired t-test, generative task participants: dimensionality, t-statistic 2.21, p-value 0.03; boundary, 6.21, 1e-7; volume, 9.57, 8e-13; robustness, 10.6, 2e-14. Maximum-likelihood task participants: dimensionality, 5.75, 5e-7; boundary, 4.79, 2e-6; volume, 10.8, 2e-14; robustness, 12.2, 2e-16). <bold>b</bold>: Data from individual ANNs (points), trained on the generative (orange) or maximum-likelihood (cyan) task. Network performance was always highest when evaluated against maximum-likelihood solutions, compared to generative solutions (all dots are above the identity line).</p></caption>
<graphic xlink:href="523479v5_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Put briefly, ANNs exhibited simplicity preferences only when trained to do so, whereas human participants exhibited them regardless of their instructions and training.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>Simplicity has long been regarded as a key element of effective reasoning and rational decision-making. It has been proposed as a foundational principle in philosophy (<xref ref-type="bibr" rid="c2">Baker, 2022</xref>), psychology (<xref ref-type="bibr" rid="c8">Chater &amp; Vitányi, 2003</xref>; <xref ref-type="bibr" rid="c12">Feldman, 2016</xref>), statistical inference (<xref ref-type="bibr" rid="c3">Balasubramanian, 1997</xref>; <xref ref-type="bibr" rid="c10">de Mulatier &amp; Marsili, 2024</xref>; <xref ref-type="bibr" rid="c20">Grünwald, 2007</xref>; <xref ref-type="bibr" rid="c21">Gull, 1988</xref>; H. <xref ref-type="bibr" rid="c24">Jeffreys, 1939</xref>; <xref ref-type="bibr" rid="c33">MacKay, 1992</xref>; <xref ref-type="bibr" rid="c55">Wallace, 2005</xref>; <xref ref-type="bibr" rid="c57">Xie &amp; Marsili, 2024</xref>), and more recently machine learning (<xref ref-type="bibr" rid="c9">Chaudhari et al., 2019</xref>; <xref ref-type="bibr" rid="c11">De Palma et al., 2019</xref>; <xref ref-type="bibr" rid="c53">Valle-Perez et al., 2019</xref>; <xref ref-type="bibr" rid="c58">Yang et al., 2022</xref>). Accordingly, various forms of simplicity preferences have been identified in human cognition (<xref ref-type="bibr" rid="c17">Gershman &amp; Niv, 2013</xref>; <xref ref-type="bibr" rid="c31">Little &amp; Shiffrin, 2009</xref>; <xref ref-type="bibr" rid="c43">Pothos &amp; Chater, 2002</xref>), such as a tendency to prefer smoother (simpler) curves as the inferred, latent source of noisy observed data (<xref ref-type="bibr" rid="c16">Genewein &amp; Braun, 2014</xref>; <xref ref-type="bibr" rid="c26">Johnson et al., 2014</xref>), and visual perception related to grouping, contour detection, and shape identification (<xref ref-type="bibr" rid="c13">Feldman &amp; Singh, 2006</xref>; <xref ref-type="bibr" rid="c14">Froyen et al., 2015</xref>; <xref ref-type="bibr" rid="c55a">Wilder et al., 2016</xref>). However, despite the solid theoretical grounding of these works, none of them attempted to define a quantitative notion of simplicity bias that could be measured (as opposed to simply detected) in human perception and behavior. In this work, we showed that simplicity preferences are closely related to a specific mathematical formulation of Occam’s razor, situated at the convergence of Bayesian model selection and information theory (<xref ref-type="bibr" rid="c3">Balasubramanian, 1997</xref>). This formulation enabled us to go beyond the mere detection of a preference for simple explanations for data and to measure precisely the strength of this preference in artificial and human participants under a variety of theoretically motivated conditions.</p>
<p>Our study makes several novel contributions. The first is theoretical: we derived a new term of the Fisher Information Approximation (FIA) in Bayesian model selection that accounts for the possibility that the best model is on the boundary of the model family (see details in Methods section A.2). This boundary term is important because it can account for the possibility that, because of the noise in the data, the best value of one parameter (or of a combination of parameters) takes on an extreme value. This condition is related to the phenomenon of “parameter evaporation” that is common in real-world models for data (<xref ref-type="bibr" rid="c52">Transtrum et al., 2015</xref>). Moreover, boundaries for parameters are particularly important for studies of perceptual decision-making, in which sensory stimuli are limited by the physical constraints of the experimental setup and thus reasoning about unbounded parameters would be problematic for observers. For example, imagine designing an experiment that requires participants to report the location of a visual stimulus. In this case, an unbounded set of possible locations (e.g., along a line that stretches infinitely far in the distance to the left and to the right) is clearly untenable. Our “boundary” term formalizes the impact of considering the set of possibilities as having boundaries, which tend to increase local complexity because they tend to reduce the number of local hypotheses close to the data (see <xref rid="fig1" ref-type="fig">Figure 1b</xref>).</p>
<p>The second contribution of this work relates to Artificial Neural Networks: we showed that these networks can learn to use or ignore simplicity preferences in an optimal way (i.e., according to the magnitudes prescribed by theory), depending on how they are trained. These results are different from, and complementary to, recent work that has focused on the idea that implementation of simple functions could be key to generalization in deep neural networks (<xref ref-type="bibr" rid="c9">Chaudhari et al., 2019</xref>; <xref ref-type="bibr" rid="c11">De Palma et al., 2019</xref>; <xref ref-type="bibr" rid="c53">Valle-Perez et al., 2019</xref>; <xref ref-type="bibr" rid="c58">Yang et al., 2022</xref>). Here we have shown that effective learning can take into account the complexity of the hypothesis space, rather than that of the decision function, in producing normative simplicity preferences. On the one hand, these results do not seem surprising, because ANNs, and deep networks in particular, are powerful function approximators that perform well in practice on a vast range of inference tasks (<xref ref-type="bibr" rid="c4">Bengio et al., 2021</xref>). Accordingly, our ANNs trained with respect to the true generative solutions were able to make effective decisions, including simplicity preferences, about the generative source of a given set of observations. Likewise, our ANNs trained with respect to maximum-likelihood solutions were able to make effective decisions, without simplicity preferences, about the maximum-likelihood match for a given set of observations. On the other hand, these results also provide new insights into how ANNs might be analyzed to better understand the kinds of solutions they produce for particular problems. In particular, assessing the presence or absence of the kinds of simplicity preferences that we observed might help identify if and/or how well an ANN is likely to avoid overfitting to training data and provide more generalizable solutions.</p>
<p>The third, and most important, contribution of this work relates to human behavior: people tend to use simplicity preferences when making decisions, and unlike ANNs these preferences do not seem to be simply consequences of learning specific tasks but rather an inherent part of how we interpret uncertain information. This tendency has important implications for the kinds of computations our brains must use to solve these kinds of tasks and how those computations appear to differ from those implemented by the ANNs we used. From a theoretical perspective, the difference between a Bayesian solution (i.e., one that includes the simplicity preferences) and a maximum-likelihood solution (i.e., one that does not include the simplicity preferences) to these tasks is that the latter considers only the single best-fitting model from each family, whereas the former integrates over all possible models in each family. This integration process is what gives rise to the simplicity bias, which, crucially, cannot emerge from simpler mechanisms such as sampling over different possible causes of the stimulus due to an unreliable sensory representation or a stochastic choice process (see <xref rid="fig2" ref-type="fig">Figure 2</xref>). Our finding that ANNs can converge on either strategy when trained appropriately indicates that both are, in principle, learnable. However, our finding that people tend to use the Bayesian solution even when instructed to use the maximum-likelihood solution suggests that we naturally do not make decisions based on the single best or archetypical instance within a family of possibilities but rather integrate across that family. Put more concretely in terms of our task, when told to identify the shape closest to the data points, participants were likely uncertain about which exact location on each shape was closest. They therefore naturally integrated over the possibilities, which induces the simplicity preferences as prescribed by the Bayesian solution. These findings will help motivate and inform future studies to identify where and how the brain implements and stores these integrated solutions to relevant decision problems.</p>
<p>Another key feature of our findings that merits further study is the magnitude and variability of preferences exhibited by the human participants. On average, human sensitivity to each geometrical model feature was: 1) larger than zero, 2) at least slightly different from the optimal value (e.g., larger for dimensionality and robustness, smaller for volume), 3) different for distinct features and different participants, and 4) relatively insensitive to instructions and training. What is the source of this diversity? One hypothesis is that people may weigh more heavily the model features that are easier or cheaper to compute. In our experiments, the most heavily weighted feature was model dimensionality. In our mathematical framework, this feature corresponds to the number of degrees of freedom of a possible explanation for the observed data and thus can be relatively easy to assess. By contrast, the least heavily weighted feature was model volume. This feature involves integrating over the whole model family (to count how many distinct states of the world can be explained by a certain hypothesis, one needs to enumerate them) and thus can be very difficult to compute. The other two terms, boundary and robustness, are intermediate in terms of human weighting and computational difficulty: they are harder to compute than dimensionality, because they depend on the data and on the properties of the model at the maximum likelihood location, but are also simpler than the volume term, because they are local quantities that do not require integration over the whole model manifold. This intuition leads to new questions about the relationship between the complexity of explanations being compared and the complexity of the decision-making process itself, calling into question notions of bounded rationality and diminishing returns in optimal inference (<xref ref-type="bibr" rid="c50">Tavoni et al., 2019</xref>, <xref ref-type="bibr" rid="c51">2022</xref>). Answering such questions is beyond the scope of the present work but merits further study.</p>
<p>A different, intriguing future direction is a comparison with other formal approaches to the emergence of simplicity that can lead to different predictions. Recent studies have argued that Jeffrey’s prior (upon which our geometric approach is based) could give an incomplete picture of the complexity of a class of models that occur commonly in the natural sciences, which contain many combinations of parameters that do not affect model behavior, and proposed instead the use of data-dependent priors (<xref ref-type="bibr" rid="c34">Mattingly et al., 2018</xref>; <xref ref-type="bibr" rid="c44">Quinn et al., 2022</xref>). The two methods lead to different results, especially in the data-limited regime (<xref ref-type="bibr" rid="c1">Abbott &amp; Machta, 2023</xref>). It would be useful to understand the relevance of these differences to human and machine decision-making. Finally, our task design and analyses were constrained to conditions in which the FIA for the models involved could be computed analytically. Generalizing our approach to other conditions is another important future direction.</p>
<p>In summary, our work demonstrates the direct, quantitative relevance of formal notions of model complexity to human behavior. By relying on a combination of theoretical advances, computational modeling, and behavioral experiments, we have established a novel set of normative reference points for decision-making under uncertainty. These findings open up a new arena in which human cognition could be measured against optimal inferential processes, potentially leading to new insights into the constraints affecting information processing in the brain.</p>
</sec>
</body>
<back>
<sec id="s4" sec-type="data-availability">
<title>Data availability</title>
<p>All data and code needed to reproduce the experiments (including running the online psychophysics tasks and training and testing the neural networks), and to analyze the data and produce all figures is available at <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.17605/OSF.IO/R6D8N">10.17605/OSF.IO/R6D8N</ext-link>.</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>We thank Kamesh Krishnamurthy for discussions and acknowledge the financial support of R01 NS113241 (EP), R01 EB026945 (JIG and VB), IIS-2145164 (PC), CCF-2212519 (PC) as well as a hardware grant from the NVIDIA Corporation (EP). The HPC Collaboration Agreement between SISSA and CINECA granted access to the Marconi100 and Leonardo clusters. VB was supported in part by the Eastman Professorship at Balliol College, University of Oxford.</p>
</ack>
<sec id="additional-info" sec-type="additional-information">
<title>Additional information</title>
<sec id="s6" sec-type="ethics-statement">
<title>Ethics</title>
<p>Human participant protocols were approved and determined to be Exempt by the University of Pennsylvania Internal Review Board (IRB protocol 844474). Participants provided consent on-line before they began the task.</p>
</sec>
<sec id="s7">
<title>Author contribution</title>
<p>Conceptualization: EP VB JG. Methodology: EP SL PC VB JG. Software: EP SL. Formal analysis: EP SL. Investigation: EP SL. Resources: EP VB JG. Data curation: EP SL. Writing - original draft: EP JG. Writing-editing and reviewing: EP SL PC VB JG. Supervision: VB JG. Project administration: JG. Funding acquisition: VB JG.</p>
</sec>
</sec>
<app-group>
<app id="app1">
<title>Appendix A</title>
<sec id="s8">
<title>Methods</title>
<sec id="s8a">
<label>A.1</label>
<title>Noise-Integration-Noise (NIN) ideal observer</title>
<p>To formalize the intuition around Occam’s razor emerging from a process of integration over latent causes, we define an ideal observer that can perform the model-selection tasks described in the main text based on a simple set of heuristics. The observer has three degrees of freedom: 1) the intensity of sensory noise, 2) the extent to which it performs integration over latent causes, and 3) the intensity of the choice noise. We call this the Noise-Integration-Noise (NIN) observer.</p>
<p>In particular, we assume that some empirical data <inline-formula id="inline-eqn-9"><inline-graphic xlink:href="523479v5_inline1.gif" mime-subtype="gif" mimetype="image"/></inline-formula> are generated from one of the models described in section A.4. Briefly, each datapoint <italic>x</italic><sub><italic>i</italic></sub> ∈ ℝ<sup>2</sup> is sampled independently with
<disp-formula id="ueqn1">
<graphic xlink:href="523479v5_ueqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>σ</italic> is fixed and known (in practice, <italic>σ</italic> = 1 for our simulations), ∥ · ∥ is the Euclidean norm in ℝ<sup>2</sup>, and the (smooth) function <italic>µ</italic><sub>ℳ</sub> : [0, 1] →ℝ<sup>2</sup> is specific to the model ℳ generating the data. For instance, in the example shown in <xref rid="fig1" ref-type="fig">Figure 1</xref> in the main text (the Dimensionality task), <italic>µ</italic><sub>ℳ</sub> (<italic>t</italic>) = (0, 0) for the model on the bottom (the dot) and <italic>µ</italic><sub>ℳ</sub> (<italic>t</italic>) = ((<italic>t</italic> 1)<italic>/</italic>2, 1) for the model on top (the line).</p>
<p>For data generated according to the procedure above, the ideal observer starts by computing the average of the empirical data
<disp-formula id="ueqn2">
<graphic xlink:href="523479v5_ueqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
This representation of the data is corrupted by normally distributed sensory noise of intensity <italic>ρ</italic>:
<disp-formula id="ueqn3">
<graphic xlink:href="523479v5_ueqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Based on this (noisy) internal representation of the data, the participant computes an approximate Bayesian posterior, based on computing the evidence in a restricted neighborhood of the maximum-likelihood point:
<disp-formula id="ueqn4">
<graphic xlink:href="523479v5_ueqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>w</italic> is uniform over Ψ, and the neighborhood Ψ(<italic>b</italic>) is defined as a function of the integration parameter <italic>b</italic> in such a way that the observer will:</p>
<list list-type="order">
<list-item><p>perform full Bayesian integration for <italic>b</italic> = 1,</p></list-item>
<list-item><p>take into account only the maximum-likelihood point for <italic>b</italic> = 0, so that<inline-formula id="inline-eqn-10"><inline-graphic xlink:href="523479v5_inline2.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, and</p></list-item>
<list-item><p>will perform an operation that interpolates between these two extremes for intermediate values of <italic>b</italic>.</p></list-item>
</list>
<p>This behavior is obtained by setting
<disp-formula id="ueqn5">
<graphic xlink:href="523479v5_ueqn5.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
In practice, the observer considers only the portion of the model contained within a circle of radius <italic>d</italic>(<italic>b</italic>) centered on the data, with the radius set such that: 1) for <italic>b</italic> = 0, the circle will touch the model only at the point that is closest to the data; 2) for <italic>b</italic> = 1, the circle will include all of the model; and 3) for intermediate values, the circle will interpolate linearly between these two cases.</p>
<p>Finally, the participant picks a model sampling from the following distribution:
<disp-formula id="ueqn6">
<graphic xlink:href="523479v5_ueqn6.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Where the “temperature” parameter <italic>T</italic> controls the level of choice noise. This procedure corresponds to sampling from the approximate Bayesian posterior when <italic>T</italic> = 1, picking the model with the highest posterior for <italic>T</italic> → ∞, and picking a model at random for <italic>T</italic> → 0.</p>
<sec id="s8a1">
<label>A.1.1</label>
<title>Model-free analysis of simplicity bias for the NIN observer</title>
<p>We performed an elementary, model-free assessment of the simplicity bias exhibited by the NIN observer as a function of the observer’s parameters. For a given configuration of the observer, we simulated 10000 trials for each of the task types described in the main text. We then quantified the choice bias by fitting a sigmoid psychometric curve (as a function of <italic>y</italic>, the vertical coordinate) to data falling in a restricted region in the center of the data space (−0.1 <italic>&lt; x &lt;</italic> 0.1, 0 <italic>&lt; y &lt;</italic> 1):
<disp-formula id="ueqn7">
<graphic xlink:href="523479v5_ueqn7.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>a</italic> governs the shape (slope) of the psychometric curve, and <italic>b</italic> governs the bias that here is defined as the distance between the decision boundary and the midpoint between the models (<italic>x</italic> = 0, <italic>y</italic> = 0.5). The sign of the bias is taken such that a positive bias pushes the decision boundary towards the more complex model (this is the direction expected from Occam’s razor), and a negative bias has the opposite effect.</p>
</sec>
</sec>
<sec id="s8b">
<title>Derivation of the boundary term in the Fisher Information Approximation</title>
<p>Here we generalize the derivation of the Fisher Information Approximation (FIA) given by <xref ref-type="bibr" rid="c3">Balasubramanian (1997)</xref> to the case where the maximum-likelihood solution for a model lies on the boundary of the parameter space. This generalization is important because it relies on more realistic assumptions than existing approaches. In particular, existing approaches typically assume that the maximum-likelihood solution is in the interior of the parameter space of a given model. In contrast, models are just approximations of the true processes in the real world that generated a given set of observations, implying that those observations may fall outside of the range that can be expected based on the parameter space of a given model. In these cases (or even when the observations are based on samples generated by the model but are corrupted by noise to fall outside of the range implied by most values of the model’s parameters space), the maximum-likelihood solution for that model, given those data, may fall on the boundary of the model’s parameter space. To account for this condition, we extended the FIA to deal with the simple case of a linear boundary in parameter space. When the maximum-likelihood solution is on such a boundary, an additional penalty term appears in the FIA, which we denote “boundary” (see <xref rid="fig1" ref-type="fig">Figure 1d</xref> in the main text).</p>
<p>Apart from the more general assumptions, the following derivation follows closely the original one, with some minor notational changes. This derivation appeared in preliminary form in <xref ref-type="bibr" rid="cs8">Piasini et al. (2021a)</xref>.</p>
<sec id="s8b1">
<title>Sketch of the derivation</title>
<p>Our derivation below uses a well-known approximation method to yield a closed-form expression for the model evidence in the limit of large sample size (large <italic>N</italic>). The evidence is the integral of the likelihood over all possible parameter values, weighted by the prior. Up to constant terms, this integral can be written in the form ∫ d<italic>ϑ</italic> exp [−<italic>Nψ</italic> (<italic>ϑ, X</italic>)], where <italic>ψ</italic> (<italic>ϑ, X</italic>) is a function that depends on the data <italic>X</italic> and on a location in parameter space <italic>ϑ</italic>. In a nutshell, the approximation consists in noticing that, as <italic>N</italic> increases, the integral will come to be dominated by the behavior of the integrand within a small neighborhood of the maximum-likelihood point <inline-formula id="inline-eqn-11"><inline-graphic xlink:href="523479v5_inline3.gif" mime-subtype="gif" mimetype="image"/></inline-formula> in parameter space (which is itself dependent on the data:<inline-formula id="inline-eqn-12"><inline-graphic xlink:href="523479v5_inline4.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. In this neighborhood, we rewrite the integrand by Taylor-expanding <italic>ψ</italic>(<italic>ϑ, X</italic>) around the maximum-likelihood point. By inspecting the resulting series, we drop the terms of the expansion that decrease in magnitude when <italic>N</italic> grows, keeping only those that dominate in that regime. The end result is a Gaussian integral, which we can solve in closed form to yield the Fisher Information Approximation. This procedure is the same whether the maximum-likelihood point is in the interior of or on the boundary of the parameter space; the difference is that with a few technical passages we can show that, in the latter case, an additional term appears in the solution to the Gaussian integral. Intuitively, this extra term is due to the fact that when the maximum likelihood point <inline-formula id="inline-eqn-13"><inline-graphic xlink:href="523479v5_inline5.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is on the boundary of the parameter space the gradient of the likelihood in <inline-formula id="inline-eqn-14"><inline-graphic xlink:href="523479v5_inline6.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is not zero.</p>
</sec>
<sec id="s8b2">
<label>A.2.1</label>
<title>Set-up and hypotheses</title>
<p>The problem we consider here is that of selecting between two models (say ℳ<sub>1</sub> and ℳ<sub>2</sub>), after observing empirical data<inline-formula id="inline-eqn-15"><inline-graphic xlink:href="523479v5_inline7.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. <italic>N</italic> is the sample size and ℳ<sub>1</sub> is assumed to have <italic>d</italic> parameters, collectively indexed as <italic>ϑ</italic> taking values in a compact domain Θ. As a prior over <italic>ϑ</italic> we take Jeffrey’s prior:
<disp-formula id="eqnA1">
<graphic xlink:href="523479v5_eqnA1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>g</italic> is the (expected) Fisher Information of the model ℳ<sub>1</sub>:
<disp-formula id="eqnA2">
<graphic xlink:href="523479v5_eqnA2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The Bayesian posterior
<disp-formula id="eqnA3">
<graphic xlink:href="523479v5_eqnA3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
then becomes, after assuming a flat prior over models and dropping irrelevant terms:
<disp-formula id="eqnA4">
<graphic xlink:href="523479v5_eqnA4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Just as in <xref ref-type="bibr" rid="c3">Balasubramanian (1997)</xref>, we now make a number of regularity assumptions: 1) ln ℙ (<italic>X</italic> |<italic>ϑ</italic>) is smooth; 2) there is a unique global minimum <inline-formula id="inline-eqn-16"><inline-graphic xlink:href="523479v5_inline8.gif" mime-subtype="gif" mimetype="image"/></inline-formula> for ln ℙ (<italic>X</italic> |<italic>ϑ</italic>); 3) <italic>g</italic><sub><italic>µν</italic></sub>(<italic>ϑ</italic>) is smooth; 4) <inline-formula id="inline-eqn-17"><inline-graphic xlink:href="523479v5_inline9.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is positive definite; 5) Θ ⊂ ℝ<sup><italic>d</italic></sup> is compact; and 6) the values of the local minima of ln ℙ (<italic>X</italic> |<italic>ϑ</italic>) are bounded away from the global minimum by some <italic>ϵ &gt;</italic> 0. Importantly, unlike in <xref ref-type="bibr" rid="c3">Balasubramanian (1997)</xref>, we do not assume that is in the interior of Θ.</p>
</sec>
<sec id="s8b3">
<title>The shape of Θ</title>
<p>Because we are interested in understanding what happens at a boundary of the parameter space, we add a further assumption that, while being not very restrictive in spirit, allows us to derive a particularly interpretable result. In particular, we assume that Θ is specified by a single linear constraint of the form:
<disp-formula id="eqnA5">
<graphic xlink:href="523479v5_eqnA5.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Without loss of generality, we also take the constraint to be expressed in Hessian normal form, namely, ∥<italic>D</italic><sub><italic>µ</italic></sub>∥ = 1. For clarity, note this assumption on the shape of Θ is used only from subsubsection A.2.3 onward.</p>
</sec>
<sec id="s8b4">
<label>A.2.2</label>
<title>Preliminaries</title>
<p>We now proceed to set up a low-temperature expansion of <xref rid="eqnA3" ref-type="disp-formula">Equation A4</xref> around the saddle point <inline-formula id="inline-eqn-18"><inline-graphic xlink:href="523479v5_inline10.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. We start by rewriting the numerator in <xref rid="eqnA4" ref-type="disp-formula">Equation A4</xref> as:
<disp-formula id="eqnA6">
<graphic xlink:href="523479v5_eqnA6.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The idea of the FIA is to expand the integrand in <xref rid="eqnA6" ref-type="disp-formula">Equation A6</xref> in powers of <italic>N</italic> around the maximum likelihood point<inline-formula id="inline-eqn-19"><inline-graphic xlink:href="523479v5_inline11.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. To this end, we define three useful objects:
<disp-formula id="ueqn8">
<graphic xlink:href="523479v5_ueqn8.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
We immediately note that:
<disp-formula id="ueqn9">
<graphic xlink:href="523479v5_ueqn9.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
which is useful to compute
<disp-formula id="ueqn10">
<graphic xlink:href="523479v5_ueqn10.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
It is also useful to center the integration variables by introducing
<disp-formula id="eqnA7">
<graphic xlink:href="523479v5_eqnA7.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA8">
<graphic xlink:href="523479v5_eqnA8.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
so that
<disp-formula id="eqnA9">
<graphic xlink:href="523479v5_eqnA9.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and <xref rid="eqnA6" ref-type="disp-formula">Equation A6</xref> becomes:

<disp-formula id="ueqn11">
<graphic xlink:href="523479v5_ueqn11.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Therefore,
<disp-formula id="eqnA10">
<graphic xlink:href="523479v5_eqnA10.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where
<disp-formula id="eqnA11">
<graphic xlink:href="523479v5_eqnA11.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and
<disp-formula id="eqnA12">
<graphic xlink:href="523479v5_eqnA12.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>G</italic>(<italic>φ</italic>) collects the terms that are suppressed by powers of <italic>N</italic>.</p>
<p>Our problem has been now reduced to computing <italic>Q</italic> by performing the integral in <xref rid="eqnA11" ref-type="disp-formula">Equation A11</xref>. Now our assumptions come into play for the key approximation step. For the sake of simplicity, assuming that <italic>N</italic> is large we drop <italic>G</italic>(<italic>φ</italic>) from the expression above, so that <italic>Q</italic> becomes a simple Gaussian integral with a linear term:
<disp-formula id="eqnA13">
<graphic xlink:href="523479v5_eqnA13.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
</sec>
<sec id="s8b5">
<label>A.3.3</label>
<title>Choosing a good system of coordinates</title>
<p>Consider now the Observed Fisher Information at the maximum likelihood, <italic>Ĩ</italic><sub><italic>µν</italic></sub>. As long as it is not singular, we can define its inverse Δ<sup><italic>µν</italic></sup> = (<italic>Ĩ</italic><sub><italic>µν</italic></sub>)<sup><italic>−</italic>1</sup>. If <italic>Ĩ</italic><sub><italic>µν</italic></sub> is positive definite, then the matrix representation of <italic>Ĩ</italic><sub><italic>µν</italic></sub> has a set of <italic>d</italic> positive eigenvalues, which we denote by <inline-formula id="inline-eqn-20"><inline-graphic xlink:href="523479v5_inline12.gif" mime-subtype="gif" mimetype="image"/></inline-formula>.The matrix representation of Δ<sup><italic>µν</italic></sup> has eigenvalues<inline-formula id="inline-eqn-21"><inline-graphic xlink:href="523479v5_inline13.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, and is diagonal in the same choice of coordinates as <italic>Ĩ</italic><sub><italic>µν</italic></sub>. We denote by <italic>U</italic> the (orthogonal) diagonalizing matrix; i.e., <italic>U</italic> is such that
<disp-formula id="eqnA14">
<graphic xlink:href="523479v5_eqnA14.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
We define also the matrix <italic>K</italic> as the product of the diagonal matrix with elements 1<italic>/σ</italic><sub>(<italic>k</italic>)</sub> along the diagonal and <italic>U</italic> :
<disp-formula id="eqnA15">
<graphic xlink:href="523479v5_eqnA15.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Note that
<disp-formula id="ueqn12">
<graphic xlink:href="523479v5_ueqn12.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and that <italic>K</italic> corresponds to a sphering transformation, in the sense that
<disp-formula id="eqnA16">
<graphic xlink:href="523479v5_eqnA16.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and therefore, if we define the inverse
<disp-formula id="ueqn13">
<graphic xlink:href="523479v5_ueqn13.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
we have
<disp-formula id="eqnA17">
<graphic xlink:href="523479v5_eqnA17.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
We can now define a new set of coordinates by centering and sphering, as follows:
<disp-formula id="eqnA18">
<graphic xlink:href="523479v5_eqnA18.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Then,
<disp-formula id="eqnA19">
<graphic xlink:href="523479v5_eqnA19.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and
<disp-formula id="eqnA20">
<graphic xlink:href="523479v5_eqnA20.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
In this new set of coordinates,
<disp-formula id="eqnA21">
<graphic xlink:href="523479v5_eqnA21.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where we have used <xref rid="eqnA17" ref-type="disp-formula">Equation A17</xref> as well as the fact that Δ<sup><italic>µν</italic></sup> = Δ<sup><italic>νµ</italic></sup> and that Δ<sup><italic>µκ</italic></sup><italic>Ĩ</italic><sub><italic>κν</italic></sub> = <italic>δ</italic><sup><italic>µ</italic></sup><sub><italic>ν</italic></sub> by definition.</p>
<p>Therefore, putting <xref rid="eqnA19" ref-type="disp-formula">Equation A19</xref> and <xref rid="eqnA21" ref-type="disp-formula">Equation A21</xref> together, <xref rid="eqnA13" ref-type="disp-formula">Equation A13</xref> becomes
<disp-formula id="eqnA22">
<graphic xlink:href="523479v5_eqnA22.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The problem is reduced to a (truncated) spherical gaussian integral, where the domain of integration Ξwill depend on the original domain Θ but also on <italic>Ĩ</italic><sub><italic>µ</italic></sub>, <italic>Ĩ</italic><sub><italic>µν</italic></sub> and<inline-formula id="inline-eqn-22"><inline-graphic xlink:href="523479v5_inline14.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. To complete the calculation, we now need to make this dependence explicit.</p>
</sec>
<sec id="s8b6">
<label>A.2.4</label>
<title>Determining the domain of integration</title>
<p>We start by combining <xref rid="eqnA7" ref-type="disp-formula">Equation A7</xref> and <xref rid="eqnA20" ref-type="disp-formula">Equation A20</xref> to yield:
<disp-formula id="eqnA23">
<graphic xlink:href="523479v5_eqnA23.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
By substituting <xref rid="eqnA23" ref-type="disp-formula">Equation A23</xref> into <xref rid="eqnA5" ref-type="disp-formula">Equation A5</xref> we get
<disp-formula id="ueqn14">
<graphic xlink:href="523479v5_ueqn14.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
which we can rewrite as
<disp-formula id="eqnA24">
<graphic xlink:href="523479v5_eqnA24.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
With
<disp-formula id="eqnA25">
<graphic xlink:href="523479v5_eqnA25.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and
<disp-formula id="eqnA26">
<graphic xlink:href="523479v5_eqnA26.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where by ⟨·, ·⟩ <sub>Δ</sub> we mean the inner product in the inverse observed Fisher information metric. Note that whenever <italic>Ĩ</italic><sub><italic>µ</italic></sub> is not zero, it will be parallel to <italic>D</italic><sub><italic>µ</italic></sub>. Indeed, by construction of the maximum-likelihood point<inline-formula id="inline-eqn-23"><inline-graphic xlink:href="523479v5_inline15.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, the gradient of the log likelihood can be orthogonal to the boundary only at<inline-formula id="inline-eqn-24"><inline-graphic xlink:href="523479v5_inline16.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, where it points towards the outside of the domain. Therefore <italic>Ĩ</italic><sub><italic>µ</italic></sub>, which is defined as minus the gradient, will point inward. At the same time, <italic>D</italic><sub><italic>µ</italic></sub> will also always point toward the interior of the domain because of the form of the constraint we have chosen in <xref rid="eqnA5" ref-type="disp-formula">Equation A5</xref>. Because by assumption ∥<italic>D</italic><sub><italic>µ</italic></sub>∥ = 1, we have that
<disp-formula id="ueqn15">
<graphic xlink:href="523479v5_ueqn15.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and
<disp-formula id="ueqn16">
<graphic xlink:href="523479v5_ueqn16.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
so that
<disp-formula id="eqnA27">
<graphic xlink:href="523479v5_eqnA27.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Now, the signed distance of the boundary to the origin in <italic>ξ</italic>-space is
<disp-formula id="ueqn17">
<graphic xlink:href="523479v5_ueqn17.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the sign is taken such that <italic>l</italic> is negative when the origin is included in the integration domain. But noting that
<disp-formula id="ueqn18">
<graphic xlink:href="523479v5_ueqn18.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
we have
<disp-formula id="ueqn19">
<graphic xlink:href="523479v5_ueqn19.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and therefore
<disp-formula id="eqnA28">
<graphic xlink:href="523479v5_eqnA28.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Finally, by plugging <xref rid="eqnA27" ref-type="disp-formula">Equation A27</xref> into <xref rid="eqnA28" ref-type="disp-formula">Equation A28</xref> we obtain
<disp-formula id="eqnA29">
<graphic xlink:href="523479v5_eqnA29.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>m</italic> and <italic>s</italic> are defined for convenience like so:
<disp-formula id="eqnA30">
<graphic xlink:href="523479v5_eqnA30.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA31">
<graphic xlink:href="523479v5_eqnA31.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
We note that <italic>m</italic> is a rescaled version of the margin defined by the constraint on the parameters (and therefore is never negative by assumption), and <italic>s</italic> is a rescaled version of the norm of the gradient of the log likelihood in the inverse observed Fisher metric (and therefore is nonnegative by construction).</p>
</sec>
<sec id="s8b7">
<label>A.2.5</label>
<title>Computing the penalty</title>
<p>We can now perform a final change of variables in the integral in <xref rid="eqnA22" ref-type="disp-formula">Equation A22</xref>. We rotate our coordinates to align them to the boundary, so that
<disp-formula id="ueqn20">
<graphic xlink:href="523479v5_ueqn20.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Note that we can always do this as our integrand is invariant under rotation. In this coordinate system, <xref rid="eqnA22" ref-type="disp-formula">Equation A22</xref> factorizes:
<disp-formula id="eqnA32">
<graphic xlink:href="523479v5_eqnA32.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where erfc(·) is the complementary error function (<xref ref-type="bibr" rid="sc1">Abramowitz &amp; Stegun, 1972</xref>, section 7.1.2).</p>
<p>Finally, plugging <xref rid="eqnA32" ref-type="disp-formula">Equation A32</xref> into <xref rid="eqnA10" ref-type="disp-formula">Equation A10</xref> and taking the log, we obtain the extended FIA:
<disp-formula id="eqnA33">
<graphic xlink:href="523479v5_eqnA33.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where
<disp-formula id="eqnA34">
<graphic xlink:href="523479v5_eqnA34.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
can be interpreted as a penalty arising from the presence of the boundary in parameter space.</p>
</sec>
<sec id="s8b8">
<label>A.2.6</label>
<title>Interpreting the penalty</title>
<p>We now take a closer look at <xref rid="eqnA34" ref-type="disp-formula">Equation A34</xref>. One key observation is that, by construction, at most one of <italic>m</italic> and <italic>s</italic> is ever nonzero. In the interior of the manifold, <italic>m &gt;</italic> 0 by definition, but <italic>s</italic> = 0 because the gradient of the likelihood is zero at <inline-formula id="inline-eqn-25"><inline-graphic xlink:href="523479v5_inline17.gif" mime-subtype="gif" mimetype="image"/></inline-formula>.On the boundary, <italic>m</italic> = 0 by definition, and <italic>s</italic> can be either zero or positive.</p>
<sec id="s8b8a">
<title>Interior of the manifold</title>
<p>When <inline-formula id="inline-eqn-26"><inline-graphic xlink:href="523479v5_inline18.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is in the interior of the parameter space Θ, then <italic>Ĩ</italic><sub><italic>µ</italic></sub> = 0⇒ <italic>s</italic> = 0, and <xref rid="eqnA34" ref-type="disp-formula">Equation A34</xref> simplifies to
<disp-formula id="eqnA35">
<graphic xlink:href="523479v5_eqnA35.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
but because <italic>N</italic> is large we have <italic>m</italic>≫ 0, erfc(−<italic>m</italic>) →2 and <italic>B</italic> →0, so our result passes the first sanity check: we recover the expression in <xref ref-type="bibr" rid="c3">Balasubramanian (1997)</xref>.</p>
</sec>
<sec id="s8b8b">
<title>Boundary of the manifold</title>
<p>When <inline-formula id="inline-eqn-27"><inline-graphic xlink:href="523479v5_inline19.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is on the boundary of Θ, <italic>m</italic> = 0 and <italic>s</italic> ≥ 0. <xref rid="eqnA34" ref-type="disp-formula">Equation A34</xref> becomes
<disp-formula id="eqnA36">
<graphic xlink:href="523479v5_eqnA36.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>w</italic> is the Feddeeva function (<xref ref-type="bibr" rid="sc1">Abramowitz &amp; Stegun, 1972</xref>, p. 7.1.3):
<disp-formula id="ueqn21">
<graphic xlink:href="523479v5_ueqn21.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
This function is tabulated and can be computed efficiently. However, it is interesting to analyze its limiting behavior, as follows.</p>
<p>As a consistency check, when <italic>s</italic> is small we have at fixed <italic>N</italic>, to first order:
<disp-formula id="eqnA37">
<graphic xlink:href="523479v5_eqnA37.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and <italic>B</italic> = ln(2) when <italic>Ĩ</italic><sub><italic>µ</italic></sub> = 0, as expected.</p>
<p>However, the real case of interest is the behavior of the penalty when <italic>N</italic> is assumed to be large, which is consistent with the fact that we derived <xref rid="eqnA32" ref-type="disp-formula">Equation A32</xref> as an asymptotic expansion of <xref rid="eqnA11" ref-type="disp-formula">Equation A11</xref>. In this case, using the asymptotic expansion for the Feddeeva function (<xref ref-type="bibr" rid="sc1">Abramowitz &amp; Stegun, 1972</xref>, section 7.1.23):
<disp-formula id="ueqn22">
<graphic xlink:href="523479v5_ueqn22.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
To leading order, we obtain
<disp-formula id="ueqn23">
<graphic xlink:href="523479v5_ueqn23.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
which we can rewrite as
<disp-formula id="eqnA38">
<graphic xlink:href="523479v5_eqnA38.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
We can summarize the above by saying that a new penalty term of order ln <italic>N</italic> arose due to the presence of the boundary. Interestingly, comparing <xref rid="eqnA38" ref-type="disp-formula">Equation A38</xref> with <xref rid="eqnA33" ref-type="disp-formula">Equation A33</xref> we see that the first term in <xref rid="eqnA38" ref-type="disp-formula">Equation A38</xref> is analogous to counting an extra parameter dimension in the original Fisher Information Approximation.</p>
</sec>
</sec>
</sec>
<sec id="s8c">
<label>A.3</label>
<title>Human psychophysics</title>
<p>The behavioral task required participants to view a screen showing two curves (one on the upper half, the other on the lower half of the screen) and 10 dots and decide, based on different instructions (see below for details), which curve was the more likely source of the observed dots. There were four task types that differed in terms of the shapes of the curves, corresponding to the different terms of the FIA (see <xref rid="fig1" ref-type="fig">Figure 1</xref> in the main text and Figure B.1): <italic>dimensionality, boundary, volume</italic>, and <italic>robustness</italic>. In each case, the curves represent two parametric statistical models of the form:
<disp-formula id="eqnA39">
<graphic xlink:href="523479v5_eqnA39.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>x</italic> is a location on the 2D plane visualized on the screen, and <italic>µ</italic>(<italic>t</italic>), <italic>t</italic> ∈ [0, 1] is a parametrization of the curve. In other words, the curves represent Gaussians of unit isotropic variance whose mean <italic>µ</italic> can be located at any point along them. The dots shown to the participants were sampled iid from one of the two models, selected at random with uniform probability. The location of the true mean of the Gaussian generating the dots (i.e., the value of <italic>t</italic> in the expression above) was sampled randomly from Jeffrey’s prior for the selected model. All dots shown within a trial come from the same distribution (same model and same true mean). In the “generative” version of the task, the participants had to report which curve (model) the dots are more likely to come from. In the “maximum-likelihood” version, the participants had to report which curve was closest to the empirical centroid of the dot cloud. In both versions of the task, they pressed the “up” or “down” keys on their keyboard to select the curve in the upper or lower part of the screen, respectively.</p>
<p>Each model pairing was designed to emphasize a different term of the FIA. In the dimensionality variant, models have different dimensionality (<italic>d</italic> = 0 for the point and <italic>d</italic> = 1 for the line). In the boundary variant, both models have the same dimensionality and volume and are both flat so that their robustness terms are always identically zero. However, they are oriented such that, for ambiguous data falling around the midpoint between the two models, the influence of the boundary of the vertical model is stronger than that of the horizontal model. In the volume variant, models have the same dimensionality but different volumes (length). In the robustness variant, models have the same dimensionality and volume, but their curvature is such that one of them bends away from the region of data space that is more likely to contain ambiguous stimuli, whereas the other bends around it (and therefore the robustness term for these models has opposite sign for data points that fall in that region).</p>
<p>A single run of the task consisted of a brief tutorial followed by 500 trials, divided in 5 blocks of 100 trials each. For each trial, the chosen curve pairing was presented, randomly flipped vertically to dissociate a fixed preference for one of the two models from a fixed preference for reporting “up” or “down”. At the end of each block, the participant received feedback on their overall performance during that block. Participants received a fixed compensation for taking part in the experiment.</p>
<p>We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. We ran both experiments (generative and maximum-likelihood) on the online platform Pavlovia (<ext-link ext-link-type="uri" xlink:href="http://pavlovia.org">pavlovia.org</ext-link>). For each task type, we collected data from at least 50 participants who passed a pre-established performance threshold (60% correct for the robustness task variant and 70% correct for the other variants; the sample size and the thresholds were chosen based on pilot data and were fixed at preregistration (<xref ref-type="bibr" rid="c40">Piasini et al., 2020</xref>, <xref ref-type="bibr" rid="c40">2021b</xref>, <xref ref-type="bibr" rid="c42">2022</xref>)). We discarded the data collected from all other participants. For the generative task, the final dataset included 52 participants for the robustness task variant and 50 participants for each of the other task variants. For the maximum-likelihood task, the final dataset included 51 participants for the dimensionality task variant and 50 participants for each of the others.</p>
</sec>
<sec id="s8d">
<label>A.4</label>
<title>Detailed model definitions and computation of FIA terms</title>
<p>In this section, we report the detailed mathematical form of the models we used for the psychophysics experiment. Each model is defined by specifying the form of the function <italic>µ</italic> in <xref rid="eqnA39" ref-type="disp-formula">Equation A39</xref>. Given this function, we then derive the analytical solution to the maximum-likelihood problem for any value of <inline-formula id="inline-eqn-28"><inline-graphic xlink:href="523479v5_inline20.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, and finally the expressions for the likelihood (<italic>L</italic>), dimensionality (<italic>D</italic>), boundary (<italic>B</italic>), volume (<italic>V</italic>), and robustness (<italic>R</italic>) terms in the FIA for the model pairings we use in the experiment.</p>
<p>We also show that the (expected) Fisher information is constant for all models considered:
<disp-formula id="eqnA40">
<graphic xlink:href="523479v5_eqnA40.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
so that Jeffrey’s prior is simply the uniform probability distribution over the [0, 1] interval:
<disp-formula id="eqnA41">
<graphic xlink:href="523479v5_eqnA41.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
<sec id="s8d1">
<label>A.4.1</label>
<title>Fisher information and robustness term for curved exponential families</title>
<p>In the following, we compute the observed Fisher information for each of our models. To do so, it is convenient to have a general expression for the Hessian of the log likelihood and for the observed and expected Fisher information for curved exponential families.</p>
<p>The general form of a curved exponential family is:
<disp-formula id="eqnA42">
<graphic xlink:href="523479v5_eqnA42.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>ϑ</italic>(<italic>u</italic>) : ℝ<sup><italic>d</italic></sup> → ℝ<sup><italic>k</italic></sup>, <italic>k</italic> ≥ <italic>d</italic>, is a smooth parametrization. The Hessian of the log-likelihood is:
<disp-formula id="eqnA43">
<graphic xlink:href="523479v5_eqnA43.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where we note that <italic>g</italic><sub><italic>ij</italic></sub> = −Cov<sub><italic>u</italic></sub>[<italic>F</italic>]<sub><italic>ji</italic></sub> (remember that by <italic>g</italic><sub><italic>ij</italic></sub> we indicate the Fisher information of the ambient family). Therefore, the (expected) Fisher information is:
<disp-formula id="eqnA44">
<graphic xlink:href="523479v5_eqnA44.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and the oberved Fisher information is:
<disp-formula id="eqnA45">
<graphic xlink:href="523479v5_eqnA45.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
As a corollary, we note that <italic>h</italic><sub><italic>ab</italic></sub> = <italic>g</italic><sub><italic>ab</italic></sub> whenever <italic>ϑ</italic>(·) is an affine transformation, that is when
<disp-formula id="eqnA46">
<graphic xlink:href="523479v5_eqnA46.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
For some constant <inline-formula id="inline-eqn-29"><inline-graphic xlink:href="523479v5_inline21.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and <italic>B</italic><sup><italic>i</italic></sup>. In this case (which corresponds to autoparallel submanifolds in the exponential connection, (<xref ref-type="bibr" rid="sc2">Amari &amp; Nagaoka, 2000</xref>, Theorem 1.1)), the robustness term in the FIA is identically zero:
<disp-formula id="eqnA47">
<graphic xlink:href="523479v5_eqnA47.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
</sec>
<sec id="s8d2">
<label>A.4.2</label>
<title>General properties of curved 2D Gaussian models</title>
<p>Our models of interest, defined through <xref rid="eqnA39" ref-type="disp-formula">Equation A39</xref>, are a special case of curved exponential families. They are all submanifolds of the same, larger model — the 2-dimensional exponential family of 2D Gaussian distributions with known isotropic covariance and unknown center. We call this larger family the <italic>ambient family</italic> 𝒮 ⊃ ℳ, composed by all probability distributions whose density is of the form:
<disp-formula id="eqnA48">
<graphic xlink:href="523479v5_eqnA48.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
We can reduce <xref rid="eqnA39" ref-type="disp-formula">Equation A39</xref> to the notation of <xref rid="eqnA42" ref-type="disp-formula">Equation A42</xref> by noting that
<disp-formula id="eqnA49">
<graphic xlink:href="523479v5_eqnA49.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where we indicate by <italic>g</italic><sub><italic>ij</italic></sub> the Fisher information of the ambient family 𝒮:
<disp-formula id="eqnA50">
<graphic xlink:href="523479v5_eqnA50.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
By comparing <xref rid="eqnA49" ref-type="disp-formula">Equation A49</xref> with <xref rid="eqnA42" ref-type="disp-formula">Equation A42</xref>, we see that
<disp-formula id="eqnA51">
<graphic xlink:href="523479v5_eqnA51.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA52">
<graphic xlink:href="523479v5_eqnA52.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA53">
<graphic xlink:href="523479v5_eqnA53.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and that <italic>µ</italic>(<italic>t</italic>) plays the role that <italic>ϑ</italic>(<italic>u</italic>) played in <xref rid="eqnA42" ref-type="disp-formula">Equation A42</xref>.</p>
<p>We can now compute the expected and observed Fisher information for our models by specializing <xref rid="eqnA44" ref-type="disp-formula">Equation A44</xref> and <xref rid="eqnA45" ref-type="disp-formula">Equation A45</xref>:
<disp-formula id="eqnA54">
<graphic xlink:href="523479v5_eqnA54.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA55">
<graphic xlink:href="523479v5_eqnA55.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Where <inline-formula id="inline-eqn-30"><inline-graphic xlink:href="523479v5_inline22.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is the empirical centroid of the dataset <italic>X</italic>,
<disp-formula id="eqnA56">
<graphic xlink:href="523479v5_eqnA56.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and <italic>g</italic> and <italic>h</italic> have no indices, because they are scalar functions of <italic>t</italic>.</p>
<p>We note then that <italic>g</italic>(<italic>t</italic>) is simply the squared Euclidean norm of the vector <inline-formula id="inline-eqn-31"><inline-graphic xlink:href="523479v5_inline23.gif" mime-subtype="gif" mimetype="image"/></inline-formula> divided by <italic>σ</italic><sup>2</sup>. In other words, the geometry of ℳ coincides, up to scaling by <italic>σ</italic><sup>2</sup>, with the Euclidean geometry of the plane curve <italic>µ</italic>(<italic>t</italic>). This very convenient fact is a consequence of the particularly simple noise model we have assumed (Gaussian with known isotropic covariance).</p>
<sec id="s8d2a">
<title>Model volume</title>
<p>The volume of a model described by <italic>µ</italic>(·) is
<disp-formula id="eqnA57">
<graphic xlink:href="523479v5_eqnA57.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
In other words, it is simply the length of the curve <italic>µ</italic>(·) measured in units of <italic>σ</italic>.</p>
</sec>
<sec id="s8d2b">
<title>Likelihood gradient and maximum-likelihood point</title>
<p>In the following, we will indicate the log-likelihood function for a model by
<disp-formula id="eqnA58">
<graphic xlink:href="523479v5_eqnA58.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
In order to find the maximum-likelihood point for our models, it is convenient to write a general expression for the score function (the derivative of the log likelihood with respect to the parameter). We start by noting that
<disp-formula id="ueqn24">
<graphic xlink:href="523479v5_ueqn24.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Therefore, to find the maximum likelihood point <inline-formula id="inline-eqn-32"><inline-graphic xlink:href="523479v5_inline24.gif" mime-subtype="gif" mimetype="image"/></inline-formula> for a certain <italic>X</italic> we can simply solve the corresponding one-sample (<italic>N</italic> = 1) case for the centroid <inline-formula id="inline-eqn-33"><inline-graphic xlink:href="523479v5_inline25.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. We can also write the rescaled likelihood gradient (which appears in the FIA as <italic>I</italic><sub><italic>µ</italic></sub>) as
<disp-formula id="eqnA59">
<graphic xlink:href="523479v5_eqnA59.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
If we interpret <inline-formula id="inline-eqn-34"><inline-graphic xlink:href="523479v5_inline26.gif" mime-subtype="gif" mimetype="image"/></inline-formula> as the tangent vector to <italic>µ</italic> in <italic>t</italic>, we see that away from model boundaries this equation expresses the familiar condition that the maximum-likelihood point (where <italic>∂l/∂t</italic> = 0) is the (Euclidean) orthogonal projection of <inline-formula id="inline-eqn-35"><inline-graphic xlink:href="523479v5_inline27.gif" mime-subtype="gif" mimetype="image"/></inline-formula> onto the model manifold. Again, this convenient property is a consequence of assuming isotropic Gaussian noise.</p>
</sec>
</sec>
<sec id="s8d3">
<label>A.4.3</label>
<title>Horizontal model</title>
<p>This model, used in the Dimensionality, Boundary, and Volume tasks, is defined as
<disp-formula id="eqnA60">
<graphic xlink:href="523479v5_eqnA60.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
It is immediately evident that this model has volume (length) <italic>T/σ</italic>. The “base” model corresponds to <italic>T</italic> = 1, <italic>τ</italic> = 0, and the model type called “horizontal” is defined with <italic>T</italic> = 3, <italic>τ</italic> = 1.</p>
<p>Because
<disp-formula id="eqnA61">
<graphic xlink:href="523479v5_eqnA61.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and following <xref rid="eqnA54" ref-type="disp-formula">Equation A54</xref> and <xref rid="eqnA55" ref-type="disp-formula">Equation A55</xref>, the observed and expected Fisher information coincide and are given by
<disp-formula id="eqnA62">
<graphic xlink:href="523479v5_eqnA62.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Given a centroid <italic>X</italic> = [<italic>X</italic><sup>1</sup>, <italic>X</italic><sup>2</sup>]<sup>⊺</sup>, the rescaled likelihood gradient is (from <xref rid="eqnA59" ref-type="disp-formula">Equation A59</xref>)
<disp-formula id="eqnA63">
<graphic xlink:href="523479v5_eqnA63.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and the maximum-likelihood point <inline-formula id="inline-eqn-36"><inline-graphic xlink:href="523479v5_inline28.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is
<disp-formula id="eqnA64">
<graphic xlink:href="523479v5_eqnA64.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
All the FIA terms can be computed in closed form from these expressions:
<disp-formula id="eqnA65">
<graphic xlink:href="523479v5_eqnA65.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA66">
<graphic xlink:href="523479v5_eqnA66.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA67">
<graphic xlink:href="523479v5_eqnA67.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA68">
<graphic xlink:href="523479v5_eqnA68.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA69">
<graphic xlink:href="523479v5_eqnA69.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
</sec>
<sec id="s8d4">
<label>A.4.4</label>
<title>Vertical model</title>
<p>This model, used the Boundary task, is just a rotated and translated version of the horizontal model. It is defined as
<disp-formula id="eqnA70">
<graphic xlink:href="523479v5_eqnA70.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where we keep <italic>T</italic> and <italic>τ</italic> as arbitrary parameters for notational clarity, although in practice they are both fixed to 1 in our study. From the definition, it follows that
<disp-formula id="eqnA71">
<graphic xlink:href="523479v5_eqnA71.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA72">
<graphic xlink:href="523479v5_eqnA72.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA73">
<graphic xlink:href="523479v5_eqnA73.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and
<disp-formula id="eqnA74">
<graphic xlink:href="523479v5_eqnA74.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
so that the FIA terms can be written as
<disp-formula id="eqnA75">
<graphic xlink:href="523479v5_eqnA75.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA76">
<graphic xlink:href="523479v5_eqnA76.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA77">
<graphic xlink:href="523479v5_eqnA77.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA78">
<graphic xlink:href="523479v5_eqnA78.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA79">
<graphic xlink:href="523479v5_eqnA79.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
</sec>
<sec id="s8d5">
<label>A.4.5</label>
<title>Circular-arc model</title>
<p>This model, used in the Robustness task, is constituted by an arc of a circle, and is defined as
<disp-formula id="eqnA80">
<graphic xlink:href="523479v5_eqnA80.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where
<disp-formula id="eqnA81">
<graphic xlink:href="523479v5_eqnA81.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and <italic>γ</italic> is a positive constant. Concretely, in the experiments we fixed <italic>γ</italic> = (3<italic>/</italic>5)<italic>π</italic> and <italic>T</italic> to the value determined below for the rounded model type ( <xref rid="eqnA99" ref-type="disp-formula">Equation A99</xref>). The radius of the circle is <italic>r</italic> = <italic>T/γ</italic>, and the y-coordinate of the center is <italic>τ</italic> + <italic>r</italic>. The tangent vector <inline-formula id="inline-eqn-37"><inline-graphic xlink:href="523479v5_inline29.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and the acceleration vector <inline-formula id="inline-eqn-38"><inline-graphic xlink:href="523479v5_inline58.gif" mime-subtype="gif" mimetype="image"/></inline-formula> in <italic>t</italic> are, respectively:
<disp-formula id="eqnA82">
<graphic xlink:href="523479v5_eqnA82.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA83">
<graphic xlink:href="523479v5_eqnA83.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
so that, by substitution in <xref rid="eqnA54" ref-type="disp-formula">Equation A54</xref>,
<disp-formula id="eqnA84">
<graphic xlink:href="523479v5_eqnA84.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and by substitution in <xref rid="eqnA55" ref-type="disp-formula">Equation A55</xref>
<disp-formula id="eqnA85">
<graphic xlink:href="523479v5_eqnA85.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
The rescaled likelihood gradient is (from <xref rid="eqnA59" ref-type="disp-formula">Equation A59</xref>)
<disp-formula id="eqnA86">
<graphic xlink:href="523479v5_eqnA86.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
(note that <italic>h</italic> can also be obtained by differentiating this last expression).</p>
<p>To compute the FIA, we need the maximum-likelihood projection. As for the other models, this projection is defined piecewise because of the presence of model boundaries. To properly partition the plane, we need to define first the equation for the line intersecting the model perpendicularly at <italic>t</italic>:
<disp-formula id="eqnA87">
<graphic xlink:href="523479v5_eqnA87.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<italic>ρ</italic>(<italic>x</italic>; <italic>t</italic>) = <italic>τ</italic> + <italic>r</italic> − cot(<italic>α</italic>(<italic>t</italic>))<italic>x</italic> With this definition, the maximum-likelihood point is
<disp-formula id="eqnA88">
<graphic xlink:href="523479v5_eqnA88.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and therefore the FIA terms are:
<disp-formula id="eqnA89">
<graphic xlink:href="523479v5_eqnA89.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA90">
<graphic xlink:href="523479v5_eqnA90.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA91">
<graphic xlink:href="523479v5_eqnA91.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA92">
<graphic xlink:href="523479v5_eqnA92.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA93">
<graphic xlink:href="523479v5_eqnA93.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the value given for <italic>B</italic> is relevant only when <inline-formula id="inline-eqn-39"><inline-graphic xlink:href="523479v5_inline30.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is either 0 or 1. Note that, because of the shape of the model and the presence of the boundary, there are regions of the data space such that the log-likelihood function at the maximum likelihood point will not be concave. These regions represent a complete breakdown of the FIA, but they are not a problem in practice because the approximation holds in the region of data space that is relevant for the experiments (see <xref ref-type="fig" rid="figB1">Figure B.1</xref>).</p>
</sec>
<sec id="s8d6">
<label>A.4.6</label>
<title>Rounded model</title>
<p>This model, also used in the Robustness task, is a circular arc (like the “circular” model described above) with two straight arms attached on either side. The ratio of the length of the circular section of the model over its total length is defined as a parameter <italic>f</italic>. The model definition is
<disp-formula id="eqnA94">
<graphic xlink:href="523479v5_eqnA94.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>µ</italic><sub><italic>c</italic></sub> is the <italic>µ</italic> mapping defined for the circular model, <xref rid="eqnA80" ref-type="disp-formula">Equation A80</xref>.</p>
<p>For the experiment, the values of the parameters were chosen to guarantee that the circular section of this model would have the same center as a circular model (described above) with <italic>γ</italic> = (3<italic>/</italic>5)<italic>π</italic> and <italic>τ</italic> = 0, and that a relatively large fraction of the two models is in close proximity. The values are
<disp-formula id="eqnA95">
<graphic xlink:href="523479v5_eqnA95.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA96">
<graphic xlink:href="523479v5_eqnA96.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA97">
<graphic xlink:href="523479v5_eqnA97.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA98">
<graphic xlink:href="523479v5_eqnA98.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Closed-form expressions for all FIA terms can be derived for this model by a straightforward, if somewhat laborious, extension of those presented above for the circular-arc model. We do not report them here in the interest of brevity.</p>
</sec>
<sec id="s8d7">
<label>A.4.7</label>
<title>Point model</title>
<p>This model, used in the Dimensionality task variant, has no associated latent parameters (it is zerodimensional). To cast it in the same language as the others, we can define it as
<disp-formula id="eqnA99">
<graphic xlink:href="523479v5_eqnA99.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
For the point model, the FIA (which is an approximation to a model’s log evidence) is replaced by the exact evidence, which simply coincides with the log likelihood. For notational consistency, we adopt the following values for the FIA terms:
<disp-formula id="eqnA100">
<graphic xlink:href="523479v5_eqnA100.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA101">
<graphic xlink:href="523479v5_eqnA101.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA102">
<graphic xlink:href="523479v5_eqnA102.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA103">
<graphic xlink:href="523479v5_eqnA103.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA104">
<graphic xlink:href="523479v5_eqnA104.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
</sec>
</sec>
<sec id="s8e">
<label>A.5</label>
<title>Numerical experiments with Artificial neural networks</title>
<sec id="s8e1">
<label>A.5.1</label>
<title>Inputs</title>
<p>On each trial, our artificial neural network (“ANN”) takes as input: 1) two images, each depicting one candidate model’s location in the data space; and 2) a length-20 vector, containing the horizontal and vertical coordinates of the <italic>N</italic> = 10 data points. Each of the two images is provided as one RGB matrix of size (3*256*256). In data-space units (used for the model definitions in subsection A.4), each image extends from <italic>x</italic> = −4 to <italic>x</italic> = 4 and from <italic>y</italic> = −3.5 to <italic>y</italic> = 4.5, so that the center of the image (located in (0, 0.5)) is equidistant from the models in each model pair.</p>
</sec>
<sec id="s8e2">
<label>A.5.2</label>
<title>Training dataset</title>
<p>The training dataset consisted of 5000 model pairs. Each model pair was used for generating 50 trials. This approach led to a total of 250,000 trials in the entire dataset.</p>
<p>The random generation of model pairs was performed as follows (see subsection A.4 for the detailed mathematical definitions of each model and the precise meaning of the parameters controlling its shape). Each model pair could be of one of the four variants described in subsection A.3, chosen randomly with equal probabilities. Each model pair could be flipped vertically with probability 0.5. For the robustness variant, the separation of the model pair was 0.6 data-space units; for all other model pairs, the separation was 1 data-space unit. For the dimensionality variant, the length <italic>T</italic> (in data-space units) of the one-dimensional model was sampled uniformly from 𝒰 (0.5, 5). For the boundary variant, the length of both model families were kept identical and sampled from 𝒰 (0.5, 3). For the volume variant, the lengths of both models were sampled independently from 𝒰 (0.5, 5); if their length difference was no greater than the task’s noise level <italic>σ</italic> = 1, then the length of one model was resampled from 𝒰 (0.5, 5) until the length difference was greater than 1. For the robustness variant, the length of both model families was kept constant at (27<italic>/</italic>50) <italic>π</italic>. The length proportion of the rounded model that was perfectly circular was <italic>f</italic> = 1<italic>/</italic>3, and both model families share the same curvature parameter <italic>γ</italic> sampled from 𝒰 (1.5, 3). The model pairs were centered around the center of each input image.</p>
<p>Given a model pair, each trial was generated randomly as follows: 1) select one model randomly with equal probability; 2) sample a location along this model uniformly; and 3) using this location as the center of a 2D isotropic Gaussian and standard deviation of <italic>σ</italic> = 1 data-space units, sample <italic>N</italic> = 10 data points that were given to the network.</p>
<p>The training dataset was pre-shuffled randomly for training purposes. The input batch size was always 50 trials.</p>
</sec>
<sec id="s8e3">
<label>A.5.3</label>
<title>Test dataset</title>
<p>The test dataset consisted of 8 model pairs, each generating 15,000 trials. Thus, there was a total of 120,000 trials in the dataset.</p>
<p>The model pairs were as follows. For the Dimensionality task, the one-dimensional model had length (in data space units) 1. For the Boundary task, both model families had length 1. For the Volume task, one model had length 1, the other had 3. For the Robustness task, both model families had length <italic>T</italic> = (27<italic>/</italic>50) · <italic>π, f</italic> = 1<italic>/</italic>3, and curvature parameter <italic>γ</italic> = (3<italic>/</italic>5)<italic>π</italic>. Each model pair was presented in the “upright” position (as per the definitions in subsection A.4) and in the vertically flipped position, for a total of 8 cases. The separation between model families and the generation of trials was identical to as in the training dataset.</p>
</sec>
<sec id="s8e4">
<label>A.5.4</label>
<title>Artificial neural network architecture</title>
<p>Our ANN had the following architecture (see <xref rid="fig4" ref-type="fig">Figure 4</xref>). Each of the two model input images was passed through the pretrained convolutional neural network VGG16, which had its parameters frozen during training. We replaced the fully connected layers at the end of VGG16 with our own structure of Linear-ReLU-BatchNorm1D layers and allowed the updating of weights in these and all subsequent layers. For each image input, the output of this image-processing module was a length-50 vector (model image representation).</p>
<p>In parallel, the length-20 vector of raw data point coordinates was fed through a permutation-invariant layer. This layer featured shared weights such that its outputs were not affected by the sequence of the N=10 data points in the length-20 vector input. This layer also outputted a length-20 vector, which was concatenated to the end of each of the length-50 vectors (the model image representations) along the preexisting dimension, producing two length-70 vectors.</p>
<p>Each length-70 vector was fed through Linear-ReLU-BatchNorm1D layers (identical weights used to process each vector). The resultant two length-50 output vectors were then concatenated together along the preexisting dimension, with the first input image’s representation in front.</p>
<p>The resultant length-100 vector was then fed through EquiLinear-ReLU-BatchNorm1D layers. The EquiLinear layers were permutation-equivariant layers of our design, again achieved by weight sharing. They ensure that if we concatenated the two length-50 output vectors in the opposite sequence, then their output, a length-2 vector, also had the same values but in opposite sequence. This length-2 vector was passed through a log softmax layer to produce the ANN’s final output, which was also a length-2 vector.</p>
<p>We also introduced a conditional variational encoder (CVAE) structure and used its output as part of the loss function (discussed later), to encourage model representations to preserve information about the data generation process. The details are described below.</p>
<p>We concatenated the length-20 raw data points vector (before passing input the permutation-invariant layers) to the end of each length-50 model image representation vector. The resultant two length-70 vectors (each corresponding to one model) were used as inputs for our CVAE (identical weights used to process each vector). The CVAE took each length-70 vector through its encoder structure to produce 10-dimensional vectors, which were used as parameters (<italic>µ</italic><sub><italic>CVAE</italic></sub>, <italic>σ</italic><sub><italic>CVAE</italic></sub>) for the Gaussian random generation of another 10-dimensional vector. The latter vector was again concatenated to the end of the length-50 model image representation vector responsible for its own generation, before being fed to the CVAE decoder, which mapped back to a 20-dimensional output vector reminiscent of data points. Hence, there were two 20-dimensional output vectors generated, each originating from one model.</p>
</sec>
<sec id="s8e5">
<label>A.5.5</label>
<title>Loss function</title>
<p>The loss function for each trial consisted of 2 parts: 1) the final output loss, and 2) the CVAE output loss. For the final output loss, we used Pytorch’s negative log likelihood loss function <monospace>NLLLoss()</monospace>, which computed the loss between the ANN’s length-2 output vector and the target label. For each trial’s CVAE output loss, we considered only the CVAE output associated with the correct model image/target label (hence one out of the two CVAE output vectors). The CVAE output loss was the sum of a MSE reconstruction loss (between the length-20 CVAE output vector and the length-20 raw data points vector) and a KL Divergence Loss (considering (<italic>µ</italic><sub><italic>CVAE</italic></sub>, <italic>σ</italic><sub><italic>CVAE</italic></sub>) used in the CVAE data generation process, using sum reduction). The total loss was the sum of the final output loss and the CVAE output loss.</p>
</sec>
<sec id="s8e6">
<label>A.5.6</label>
<title>Update rule</title>
<p>We used Pytorch’s Adam optimizer with learning rate 0.005, keeping all other arguments at their default values.</p>
</sec>
<sec id="s8e7">
<label>A.5.7</label>
<title>ANN predictions</title>
<p>To evaluate ANN task performance in a way that was comparable to human performance, we needed to specify how the ANN output, a length-2 log softmax vector, mapped onto a chosen candidate model. The mapping was as follows: we compared the two entries in the output vector and assumed that the ANN chose the candidate model associated with the larger entry.</p>
</sec>
</sec>
<sec id="s8f">
<label>A.6</label>
<title>Experimental data analysis</title>
<p>For both human and ANN experiments, we modeled behavior assuming that each observer samples from a posterior over models determined by a modified version of the FIA, where each term of the approximation is multiplied by a free parameter to be inferred, representing the sensitivity of the participant to that term.</p>
<p>Specifically, in our experimental scenario the theory of Bayesian model selection applies directly. Given two models ℳ<sub>1</sub> and ℳ<sub>2</sub>, assuming a flat prior over models <italic>p</italic>(ℳ<sub>1</sub>) = <italic>p</italic>(ℳ<sub>2</sub>) = 1<italic>/</italic>2 and an uninformative prior (Jeffrey’s prior, see <xref ref-type="bibr" rid="c3">Balasubramanian (1997)</xref> and <xref ref-type="bibr" rid="c23">Jaynes (2003)</xref>) over the parameters of each model, when <italic>N</italic> is sufficiently large we can use the asymptotic expansion in <xref rid="fig1" ref-type="fig">Figure 1</xref> and <xref rid="eqnA33" ref-type="disp-formula">Equation A33</xref> to write the log posterior ratio for ℳ<sub>1</sub> over ℳ<sub>2</sub> as
<disp-formula id="eqnA105">
<graphic xlink:href="523479v5_eqnA105.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>L</italic><sub><italic>i</italic></sub>, <italic>D</italic><sub><italic>i</italic></sub>, etc represent the FIA terms for model <italic>i</italic>:
<disp-formula id="ueqn25">
<graphic xlink:href="523479v5_ueqn25.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
This expression suggests a simple normative model for participant behavior. <xref rid="eqnA105" ref-type="disp-formula">Equation A105</xref> determines the probability of reporting ℳ<sub>1</sub> for an ideal Bayesian observer performing probability matching. We can then compare participant behavior to the normative prescription by allowing participants to have distinct sensitivities to the various terms of the FIA:
<disp-formula id="eqnA106">
<graphic xlink:href="523479v5_eqnA106.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>α</italic> and <italic>β</italic> were free parameters: <italic>α</italic> captures any fixed bias, <italic>β</italic><sub><italic>L</italic></sub> the sensitivity to differences in maximum likelihood, <italic>β</italic><sub><italic>D</italic></sub> the sensitivity to differences in dimensionality, and so on.</p>
<p>We fitted the model expressed by <xref rid="eqnA106" ref-type="disp-formula">Equation A106</xref> to participant behavior using a hierarchical, Bayesian logistic-regression scheme:
<disp-formula id="eqnA107">
<graphic xlink:href="523479v5_eqnA107.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA108">
<graphic xlink:href="523479v5_eqnA108.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA109">
<graphic xlink:href="523479v5_eqnA109.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA110">
<graphic xlink:href="523479v5_eqnA110.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA111">
<graphic xlink:href="523479v5_eqnA111.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>

<disp-formula id="eqnA112">
<graphic xlink:href="523479v5_eqnA112.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA113">
<graphic xlink:href="523479v5_eqnA113.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA114">
<graphic xlink:href="523479v5_eqnA114.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>C</italic><sub><italic>i,t</italic></sub> is the choice made by participant <italic>i</italic> on trial <italic>t, X</italic><sub><italic>i,t</italic></sub> is the sensory stimulus on that same trial, lpr is the log posterior ratio defined by <xref rid="eqnA106" ref-type="disp-formula">Equation A106</xref>, <italic>α</italic><sub><italic>i</italic></sub> is the bias for participant <italic>i, β</italic><sub><italic>L,i</italic></sub> is the likelihood sensitivity of that same participant, and so on for the other sensitivity parameters. The bias and sensitivity parameters describing each participant are modeled as independent samples from a population-level Student-T probability distribution characterized by a certain shape (<italic>ν</italic>), location (<italic>µ</italic>), and scale (<italic>σ</italic>). The priors assumed over these population-level parameters are standard weakly informative priors (<xref ref-type="bibr" rid="c15">Gelman et al., 2014</xref>; <xref ref-type="bibr" rid="c29">Kruschke, 2015</xref>). The model was implemented in PyMC (<xref ref-type="bibr" rid="cs11">Salvatier et al., 2016</xref>), and inference was performed by sampling from the posterior for the parameters given the experimental data {<italic>C</italic><sub><italic>i,t</italic></sub>, <italic>X</italic><sub><italic>i,t</italic></sub>} using the No-U-Turn Sampler algorithm (<xref ref-type="bibr" rid="sc4">Betancourt, 2018</xref>; <xref ref-type="bibr" rid="sc7">Hoffman &amp; Gelman, 2014</xref>). Further technical details on the inference procedure can be found in subsubsection A.6.2.</p>
<sec id="s8f1">
<title>Definition of relative sensitivity</title>
<p>Relative sensitivity for a certain feature was defined as the sensitivity for that feature divided by the relevant posterior mean for the likelihood sensitivity. For instance, for dimensionality:
<disp-formula id="eqnA115">
<graphic xlink:href="523479v5_eqnA115.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
This formulation applies both at the participant level and at the population level.</p>
<p>Because each human participant performed only one task variant, not all sensitivities could be estimated for all participants. For instance, <italic>β</italic><sub><italic>D</italic></sub> entered the behavioral model (and therefore could be estimated) only for the participants that performed the Dimensionality task, where the alternative models had different dimensionality. The same holds with <italic>β</italic><sub><italic>V</italic></sub> and the Volume task, and <italic>β</italic><sub><italic>R</italic></sub> and the Robustness task. The boundary term entered the behavioral model for all task variants, although by design it took on a much broader range of values for the Boundary task. For consistency, for each sensitivity parameter, we reported its estimate only for those participants that performed the task variant designed to test it.</p>
</sec>
<sec id="s8f2">
<title>A.6.1 Lapse rates</title>
<p>We designed a variant of the behavioral model that accounts for lapses in participants’ responses (i.e., errors on easy trials). Specifically, we modified <xref rid="eqnA106" ref-type="disp-formula">Equation A106</xref> as follows:
<disp-formula id="eqnA116">
<graphic xlink:href="523479v5_eqnA116.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>ϵ</italic> ∈ [0, 1] is the lapse rate, representing the probability that a given response is completely random. For <italic>ϵ</italic> = 1 the responses are random on every trial, whereas for <italic>ϵ</italic> = 0 this model is equivalent to the original one in <xref rid="eqnA106" ref-type="disp-formula">Equation A106</xref>.</p>
<p>To estimate <italic>ϵ</italic> from our experimental data jointly with all other parameters, we kept the same structure as in Equations A107–A114 and extended it by modeling the population level distribution of <italic>ϵ</italic> as a Beta distribution, parameterized by count parameters <italic>a</italic> and <italic>b</italic>. Following the recommendations by <xref ref-type="bibr" rid="c15">Gelman et al. (2014</xref>, section 5.3) and <xref ref-type="bibr" rid="sc5">development team (2022</xref>, section 24.2), we specify hyperpriors in terms of the mean of the distribution <italic>φ</italic> = <italic>a/</italic>(<italic>a</italic> + <italic>b</italic>) <italic>λ</italic> = <italic>a</italic> + <italic>b</italic>:
<disp-formula id="eqnA117">
<graphic xlink:href="523479v5_eqnA117.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA118">
<graphic xlink:href="523479v5_eqnA118.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA119">
<graphic xlink:href="523479v5_eqnA119.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA120">
<graphic xlink:href="523479v5_eqnA120.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnA121">
<graphic xlink:href="523479v5_eqnA121.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>ϵ</italic><sub><italic>i</italic></sub> is the lapse rate for participant <italic>i</italic>.</p>
</sec>
<sec id="s8f3">
<label>A.6.2</label>
<title>Technical details of the inference procedure</title>
<p>Posterior sampling was performed with PyMC (<xref ref-type="bibr" rid="cs11">Salvatier et al., 2016</xref>) version 4.2.0, using the NUTS Hamiltonian Monte Carlo algorithm (<xref ref-type="bibr" rid="sc7">Hoffman &amp; Gelman, 2014</xref>). Target acceptance probability was set to 0.9 for the human data (both generative and maximum-likelihood task), to 0.8 for the generative task for ANNs, and 0.99 for the maximum-likelihood task for ANNs. The posterior distributions were built by sampling 12 independent Markov chains for 10000 draws each. No divergence occurred in any of the chains. Effective sample size and <inline-formula id="inline-eqn-40"><inline-graphic xlink:href="523479v5_inline59.gif" mime-subtype="gif" mimetype="image"/></inline-formula> diagnostics for some of the key parameters are given in <xref ref-type="table" rid="tblA_1">Table A.1.</xref></p>

<table-wrap id="tblA_1" orientation="portrait" position="float">
<label>Table A1.</label>
<caption><title><inline-formula id="inline-eqn-41"><inline-graphic xlink:href="523479v5_inline55.gif" mime-subtype="gif" mimetype="image"/></inline-formula> statistic and effective sample size (ESS) for 12 Markov Chain traces run as described in the text, for the fit to human data for the generative task.</title>
<p>See <xref ref-type="bibr" rid="c15">Gelman et al. (2014</xref>, sections 11.4–11.5) and <xref ref-type="bibr" rid="sc19">Vehtari et al. (2020)</xref> for in-depth discussion of chain quality diagnostics. Briefly, <inline-formula id="inline-eqn-42"><inline-graphic xlink:href="523479v5_inline56.gif" mime-subtype="gif" mimetype="image"/></inline-formula> depends on the relationship between the variance of the draws estimated within and between contiguous draw sequences. <inline-formula id="inline-eqn-43"><inline-graphic xlink:href="523479v5_inline57.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is close to 1 when the chains have successfully converged. The effective sample size estimates how many independent samples one would need to extract the same amount of information as that contained in the (correlated) MCMC draws.</p></caption>
<graphic xlink:href="523479v5_tblA_1.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
</sec>
<sec id="s8f4">
<label>A.6.3</label>
<title>Reporting of posterior distributions for inferred parameters</title>
<p>The posterior distributions reported in all figures are Kernel Density Estimates with bandwidth chosen according to Scott’s rule (<xref ref-type="bibr" rid="sc11">Pedregosa et al., 2011</xref>).</p>
</sec>
</sec>
<sec id="s8g">
<label>A.7</label>
<title>Fitting the NIN observer to participant data</title>
<p>We fit the NIN model to our human behavioral data by maximum likelihood, on a single-participant basis and marginalizing numerically over the effect of sensory noise. In particular, say that <inline-formula id="inline-eqn-44"><inline-graphic xlink:href="523479v5_inline31.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is the centroid of the dot cloud. Recall that the NIN model involves a latent (internal) sensory noise process that corrupts the sensory data by adding noise <italic>η</italic> ∼ 𝒩 (0, <italic>ρ</italic>):
<disp-formula id="ueqn26">
<graphic xlink:href="523479v5_ueqn26.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Then, the model observer computes a Bayesian posterior <inline-formula id="inline-eqn-45"><inline-graphic xlink:href="523479v5_inline32.gif" mime-subtype="gif" mimetype="image"/></inline-formula>by integrating locally around the maximum-likelihood point <inline-formula id="inline-eqn-46"><inline-graphic xlink:href="523479v5_inline33.gif" mime-subtype="gif" mimetype="image"/></inline-formula>.The range of the local integration is controlled by an integration parameter <italic>b</italic>, so we write
<disp-formula id="ueqn27">
<graphic xlink:href="523479v5_ueqn27.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Finally, choice noise is implemented through a softmax transform:
<disp-formula id="ueqn28">
<graphic xlink:href="523479v5_ueqn28.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>β</italic> = 1<italic>/T</italic> is the “inverse temperature” parameter controlling the intensity of the choice noise. Inference is based on calculating the (log)likelihood of the model (parameterized by <italic>ρ, b</italic> and <italic>β</italic>), obtained by marginalizing over the sensory noise <italic>η</italic>:
<disp-formula id="eqnA122">
<graphic xlink:href="523479v5_eqnA122.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
We approximate the integral in <xref rid="eqnA122" ref-type="disp-formula">Equation A122</xref> using a randomized quasi-Monte Carlo (QMC) approach (<xref ref-type="bibr" rid="sc10">Owen, 2023</xref>):
<disp-formula id="eqnA123">
<graphic xlink:href="523479v5_eqnA123.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Where<inline-formula id="inline-eqn-47"><inline-graphic xlink:href="523479v5_inline34.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, for any <italic>i</italic>, is a bivariate normal QMC set of points generated from a scrambled Sobol’ sequence with <italic>K</italic> = 1024 using the <monospace>scipy.stats.qmc</monospace> module (<xref ref-type="bibr" rid="sc16">Roy et al., 2023</xref>), centered in (0, 0) and with variance <italic>ρ</italic><sup><italic>2</italic></sup>. We used an independent set of QMC points for each participant and each trial, but we kept this set fixed throughout the optimization (that is, we did not resample the QMC set at each iteration of the optimization procedure) to avoid introducing stochasticity in the loss function and to help with convergence.</p>
<p>To fit the model, we maximised the likelihood <xref rid="eqnA123" ref-type="disp-formula">Equation A123</xref> using Differential Evolution (<xref ref-type="bibr" rid="sc18">Storn &amp; Price, 1997</xref>) as implemented in the <monospace>scipy.optimize</monospace> module with a candidate population of size 64. The model parameters were constrained to the following ranges: <italic>ρ</italic> ∈ (0, 2], <italic>b</italic> ∈ [0, 1], <italic>β</italic> ∈ [0, 10].</p>
</sec>
</sec>
</app>
<app id="app2">
<title>Appendix B</title>
<sec id="s9">
<title>Supplementary information</title>
<sec id="s9a">
<label>B.1</label>
<title>Numerical comparison of the extended FIA vs exact Bayes</title>
<p><xref ref-type="fig" rid="figB1">Figure B.1</xref> shows that the FIA computed with the expressions given in this document provides a very good approximation to the exact Bayesian log posterior ratio (LPR) for the model pairs used in the psychophysics experiments, and for the chosen sample size (<italic>N</italic> = 10). As highlighted in the panels in the rightmost column, the discrepancies between the exact and the approximated LPR are generally small in relative terms, and therefore are not very important for the purpose of model fitting and interpretation. Note that here, as well as for the results in the main text, the <italic>B</italic> term in the FIA is computed using <xref rid="eqnA34" ref-type="disp-formula">Equation A34</xref> rather than <xref rid="eqnA38" ref-type="disp-formula">Equation A38</xref> to avoid infinities (that for finite <italic>N</italic> can arise when the likelihood gradient is very small) and discontinuities (that for finite <italic>N</italic> can arise on the interior of the manifold, in proximity to the boundary, where the value of <italic>B</italic> goes from zero when <inline-formula id="inline-eqn-48"><inline-graphic xlink:href="523479v5_inline35.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is in the interior to log(2) when <inline-formula id="inline-eqn-49"><inline-graphic xlink:href="523479v5_inline36.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is exactly on the boundary).</p>
<p>Even though overall the agreement between the approximation is good, it is interesting to look more closely at where the approximation is poorest. The task type for which the discrepancies are the largest (both in absolute and relative terms) is the “robustness” type (fourth row in <xref ref-type="fig" rid="figB1">Figure B.1</xref>). This discrepancy arises because the FIA hypotheses are not fully satisfied everywhere for one of the models. Specifically, the models in that task variant are a circular arc (the bottom model in <xref ref-type="fig" rid="figB1">Figure B.1</xref>, third row) and a smaller circular arc, concentric with the first, with a straight segment attached to either side (the top model). The log-likelihood function for this second model is smooth only to first order, but its second derivative (and therefore its Fisher Information and its observed Fisher Information) is not continuous at the points where the circular arc is joined with the straight segments, locally breaking hypothesis number 3 in subsubsection A.2.1. Geometrically, this discontinuity is analogous to saying that the curvature of the manifold changes abruptly at the joints. It is likely that the FIA for a model with a smoother transition between the circular arc and the straight arms would have been even closer to the exact value for all points on the 2D plane (the data space). More generally, this line of reasoning suggests that it would be interesting to investigate the features of a model that affect the quality of the Fisher Information Approximation.</p>
<fig id="figB1" position="float" fig-type="figure">
<label>Figure B1.</label>
<caption><title>Comparison of the full Bayesian and FIA computation of the log posterior ratio (LPR) for the model pairs used in our psychophysical tasks (N = 10).</title>
<p>Each row corresponds to one task variant (from top to bottom, “dimensionality”, “boundary”, “volume”, “robustness”). First column from the left: full Bayesian LPR, computed by numerical integration. Second column: LPR computed with the FIA. Third column: difference between FIA and exact LPR. Fourth column: relative difference (difference divided by the absolute value of the FIA LPR). Adapted from <xref ref-type="bibr" rid="cs8">Piasini et al. (2021a)</xref>.</p></caption>
<graphic xlink:href="523479v5_figB1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s9b">
<label>B.2</label>
<title>Posterior predictive checks</title>
<fig id="figB2" position="float" fig-type="figure">
<label>Figure B2.</label>
<caption><title>Posterior predictive check for human performance on the generative task.</title>
<p>We sampled 240 samples from the posterior over model parameters by thinning the MCMC chains used for model inference. For each of these samples, we ran a simulation of the experiment using the actual stimuli shown to the participants, and we recorded the resulting performance of all 202 simulated participants. This procedure yielded 240 samples of the joint posterior-predictive distribution of task performance over all participants. To visualize this distribution, for each participant we plotted a cloud of 240 dots, where the y coordinate of each dot is the simulated performance of that participant in one of the simulations, and the x coordinate is the true performance of that participant in the experiment plus a small random jitter (for ease of visualization). The gray line is the identity, showing that our inference procedure captures well the behavioral patterns in the experimental data. Colors indicate different task types, as indicated.</p></caption>
<graphic xlink:href="523479v5_figB2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We performed a simple posterior predictive check (<xref ref-type="bibr" rid="c29">Kruschke, 2015</xref>) to ensure that the Bayesian hierarchical model described in the text captures the main pattern of behavior across our participants. In <xref ref-type="fig" rid="figB2">Figure B.2</xref>, the behavioral performance of the participants is compared with its posterior predictive distribution under the model, for the case of the human participants in the generative task. As can be seen from the figure, the performance of each participant is correctly captured by the model, across systematic differences between task types (with participants performing better in the boundary task variant than the robustness task variant, for instance) as well as individual differences between participants that performed the same task variant.</p>
</sec>
<sec id="s9c">
<label>B.3</label>
<title>Details on raw estimated sensitivities</title>
<p>Table B.3 reports the posterior mean and standard deviation of the population-level parameters entering the regression (<xref rid="eqnA106" ref-type="disp-formula">Equation A106</xref>). Note that these are the raw parameters, not their normalized counterparts relative to the likelihood sensitivity as reported in the rest of the paper.</p>
</sec>
<sec id="s9d">
<label>B.4</label>
<title>Uncertainty in participant-level sensitivities</title>
<p><xref ref-type="fig" rid="figB4">Figure B.4</xref> illustrates the uncertainty in the estimate for the relative sensitivity of each participant. This uncertainty is typically small compared to between-participant variability of the sensitivity, which is therefore not a trivial consequence of the noise in the sensitivity estimation for individual participants.</p>
<fig id="figB4" position="float" fig-type="figure">
<label>Figure B4.</label>
<caption><title>Participant-level relative sensitivities to the geometric features that determine model complexity.</title>
<p>Dots with error bars: posterior mean ± standard deviation of the relative sensitivity (the dots are the same as in <xref ref-type="fig" rid="fig3">Figure 3c</xref>). For ease of visualization, participants are ranked based on their posterior mean.</p></caption>
<graphic xlink:href="523479v5_figB4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<table-wrap id="tblB3" orientation="portrait" position="float">
<label>Table B3.</label>
<caption><title>Posterior mean ± standard deviation for population-level parameters.</title>
<p>See <xref ref-type="disp-formula" rid="eqnA106">Equation A106</xref> to <xref ref-type="disp-formula" rid="eqnA114">Equation A114</xref> for the precise definition of each parameter and its role in the hierarchical model of behavior.</p></caption>
<graphic xlink:href="523479v5_tblB3.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
</sec>
<sec id="s9e">
<label>B.5</label>
<title>Lapse-rate analysis</title>
<p>To ensure that our findings were not sensitive to possible lapses in attention by the participants, we used the model variant described in Section A.6.1 to estimate a lapse rate for each participant simultaneously with the sensitivity parameters (<xref ref-type="fig" rid="figB5">Figure B.5</xref>). There was a substantial spread of lapse rates in the range 0–0.2 but no clear relationship between lapse rates and sensitivity. The sensitivity parameters estimated with this extended model were qualitatively compatible with those presented everywhere else in the text.</p>
</sec>
<sec id="s9f">
<label>B.6</label>
<title>Outcome of significance tests specified in the preregistration documents</title>
<sec id="s9f1">
<label>B.6.1</label>
<title>Formal comparison between ideal observers</title>
<p>We compared the Bayesian hierarchical model described in section A.6 to a simpler model, where participants were assumed to be sensitive only to likelihood differences, or in other words to choose ℳ <sub>1</sub> over ℳ <sub>2</sub> based only on which model was on average closer to the dot cloud constituting the stimulus on a given trial. Mathematically, this “likelihood-only” model was equivalent to fixing all <italic>β</italic> parameters to zero except for <italic>β</italic><sub><italic>L</italic></sub> in the model described in section A.6. All other details of the model were the same, and in particular the model still had a hierarchical structure with adaptive shrinkage (the participant-level parameters <italic>α</italic> and <italic>β</italic><sub><italic>L</italic></sub> were modeled as coming from Student T distributions controlled by population-level parameters). We compared the full model and the likelihood-only model on our human behavior data using WAIC (<xref ref-type="bibr" rid="c15">Gelman et al., 2014</xref>). This comparison indicated strong evidence in favor of the full model for both the generative task (<xref ref-type="table" rid="tblB6">Table B.6</xref>) and the maximum-likelihood task (<xref ref-type="table" rid="tblB7">Table B.7</xref>).</p>
<table-wrap id="tblB6" orientation="portrait" position="float">
<label>Table B6.</label>
<caption><title>WAIC comparison of the full model and the likelihood-only model for human performance on the generative task, reported in the standard format used by <xref ref-type="bibr" rid="c35">McElreath (2016</xref>, section 6.4.2).</title>
<p>WAIC is the value of the criterion (log-score scale, where higher is better), pWAIC is the estimated effective number of parameters, dWAIC is the difference between the WAIC of the given model and the highest-ranked one, SE is the standard error of the WAIC estimate, and dSE is the standard error of the difference in WAIC. These estimates were produced with the compare function provided by ArviZ (<xref ref-type="bibr" rid="cs3">Kumar et al., 2019</xref>), using 12 MCMC chains with 10000 samples each for each model (in total, 120,000 samples for each model).</p></caption>
<graphic xlink:href="523479v5_tblB6.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<table-wrap id="tblB7" orientation="portrait" position="float">
<label>Table B7.</label>
<caption><title>Same as <xref ref-type="table" rid="tblB6">Table B.6</xref>, for the maximum-likelihood task, where participants were asked to report the model that was closest to the data.</title></caption>
<graphic xlink:href="523479v5_tblB7.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<table-wrap id="tblB8" orientation="portrait" position="float">
<label>Table B8.</label>
<caption><title>HDI vs ROPE comparison and Probability of Direction (PD) for the population-level parameters in the human experiments.</title>
<p>See Supplementary Information section B.6.2 and <xref ref-type="bibr" rid="c29">Kruschke (2015)</xref> for an explanation of the ROPE-HDI comparison, and <xref ref-type="bibr" rid="cs4">Makowski, Ben-Shachar, Chen, and Lüdecke (2019)</xref> and <xref ref-type="bibr" rid="cs5">Makowski, Ben-Shachar, and Lüdecke (2019)</xref> for more details on the probability of direction metric. Note that the ROPE and HDI definitions were preregistered (<xref ref-type="bibr" rid="c40">Piasini et al., 2020</xref>, <xref ref-type="bibr" rid="c41">2021b</xref>, <xref ref-type="bibr" rid="c42">2022</xref>).</p></caption>
<graphic xlink:href="523479v5_tblB8.tif" mime-subtype="tiff" mimetype="image"/>
</table-wrap>
<fig id="figB5" position="float" fig-type="figure">
<label>Figure B5.</label>
<caption><title>Lapse rate versus relative sensitivity to complexity across participants.</title>
<p>Each dot gives the posterior mean estimate of the relative sensitivity to one of the features that determine model complexity (abscissa) and the posterior mean estimate of the lapse rate, as defined in Section A.6.1.</p></caption>
<graphic xlink:href="523479v5_figB5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s9f2">
<label>B.6.2</label>
<title>Other statistical tests</title>
<p>As described in the preregistration documents (<xref ref-type="bibr" rid="c40">Piasini et al., 2020</xref>, <xref ref-type="bibr" rid="c41">2021b</xref>, <xref ref-type="bibr" rid="c42">2022</xref>), in this work we have emphasized parameter estimation and information criteria-based model comparison over null hypothesis significance testing (see for instance <xref ref-type="bibr" rid="c35">McElreath (2016)</xref>, and <xref ref-type="bibr" rid="c29">Kruschke (2015)</xref> for a discussion and comparison of these ideas). However, for completeness, we report in <xref ref-type="table" rid="tblB8">Table B.8</xref> (1) the comparison between the Regions of Practical Equivalence (ROPE, <xref ref-type="bibr" rid="c29">Kruschke (2015)</xref>) and the 95% highest-density interval (HDI) for each population-level parameter, and (2) the “probability of direction” (<xref ref-type="bibr" rid="cs4">Makowski, Ben-Shachar, Chen, &amp; Lüdecke, 2019</xref>; <xref ref-type="bibr" rid="cs5">Makowski, Ben-Shachar, &amp; Lüdecke, 2019</xref>) for the same parameters (see below for more details on these methods). The ROPE-HDI tests highlight that the null value of zero sensitivity is not credible (rejected) for <italic>L, D</italic> and <italic>R</italic>, and neither rejected not accepted for <italic>V</italic>. The probability of direction is high for all parameters, including <italic>V</italic>, which has <italic>PD</italic> = 0.97 for the generative task and <italic>PD</italic> = 0.99 for the maximum-likelihood task. Overall, these analyses point to a significant sensitivity for all terms of the FIA in both experiments (generative and maximum-likelihood), with <italic>V</italic> having a more moderate effect size than the other terms.</p>
<sec id="s9f2a">
<title>Technical details on the ROPE-HDI comparison and on the Probability of Direction for sensitivity parameters</title>
<p>Briefly, the ROPE for a parameter is the range around a null value for that parameter such that variations within this range would imply only a “negligible change” in the behavior of the model, if all other parameters were held at their null values. The HDI is the smallest interval that contains a certain probability mass for the posterior of that parameter. The ROPE-HDI comparison is based on the idea that if the bulk of the posterior distribution for that parameter (represented by the HDI) falls outside the ROPE, then the null value for that parameter can be considered not credible (rejected). On the other hand, if the bulk of the posterior for the parameter falls within the ROPE, the null value can be considered credible (accepted). Finally, if the posterior distribution has a partial overlap with the ROPE (neither mostly contained within it, nor mostly falling outside of it), then the test is inconclusive. Note that, just like frequentist null hypothesis significance testing procedures and unlike the information criterion approach used above, this method depends on some arbitrary assumptions, namely the definition of the ROPE and the probability to use in computing the HDI.</p>
<p>In practice (for details, see our preregistration documents (<xref ref-type="bibr" rid="c40">Piasini et al., 2020</xref>, <xref ref-type="bibr" rid="c41">2021b</xref>, <xref ref-type="bibr" rid="c42">2022</xref>)), here we define, conventionally, the HDI as the smallest interval that contains 95% of the posterior. The ROPE is computed as follows. We start by defining a “negligible change” over the probability of the choice variable over the “main range” [<italic>µ</italic><sub><italic>x</italic></sub> −2<italic>σ</italic><sub><italic>x</italic></sub>, <italic>µ</italic><sub><italic>x</italic></sub> + 2<italic>σ</italic><sub><italic>x</italic></sub>] of one of the predictors in our model (<italic>L, D, B, V</italic>, or <italic>R</italic>). In other word, pick an interval of probabilities [<italic>π</italic><sub>0</sub> −<italic>δ, π</italic><sub>0</sub> + <italic>δ</italic>] such that if the probability stays within [<italic>π</italic><sub>0</sub> −<italic>δ, π</italic><sub>0</sub> + <italic>δ</italic>] when <italic>x</italic> varies over its typical range, then the probability is not meaningfully affected by <italic>x</italic>. Mathematically, if the probability of choosing one of the alternatives in the task is <italic>π</italic> and the log-odds is logit(<italic>π</italic>) = log(<italic>π/</italic>(1 − <italic>π</italic>)) =, then in a logistic regression setting
<disp-formula id="eqnB1">
<graphic xlink:href="523479v5_eqnB1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
If <italic>π</italic><sub>0</sub> = logit<sup><italic>−</italic>1</sup>(<italic>α</italic>), then the ROPE for <italic>β</italic> is defined as
<disp-formula id="eqnB2">
<graphic xlink:href="523479v5_eqnB2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnB3">
<graphic xlink:href="523479v5_eqnB3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
so that
<disp-formula id="eqnB4">
<graphic xlink:href="523479v5_eqnB4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<disp-formula id="eqnB5">
<graphic xlink:href="523479v5_eqnB5.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
In our case, assuming a negligible influence of the up/down bias (<italic>α</italic> in <xref rid="eqnA106" ref-type="disp-formula">Equation A106</xref>), <italic>π</italic><sub>0</sub> = 0.5, and therefore we can assume <italic>α</italic> = 0. The definition of the ROPE further depends on the arbitrary choice of <italic>δ</italic>, and on the values of <italic>µ</italic><sub><italic>x</italic></sub> and <italic>σ</italic><sub><italic>x</italic></sub>. We choose <italic>δ</italic> = 0.025, and we estimated <italic>µ</italic><sub><italic>x</italic></sub> and <italic>σ</italic><sub><italic>x</italic></sub> by generating 25,000 experimental trials per task type (Dimensionality, Boundary, Volume, Robustness) and computing the empirical average and standard deviation of the predictors over that trial set. These numbers were all fixed at preregistration time (<xref ref-type="bibr" rid="c40">Piasini et al., 2020</xref>, <xref ref-type="bibr" rid="c41">2021b</xref>, <xref ref-type="bibr" rid="c42">2022</xref>).</p>
</sec>
</sec>
</sec>
<sec id="s9g">
<label>B.7</label>
<title>Further details and results on the Noise-Integration-Noise observer</title>
<sec id="s9g1">
<label>B.7.1</label>
<title>Estimation of the simplicity bias in the NIN observer</title>
<p>To estimate the magnitude and source(s) of simplicity biases exhibited by the Noise-Integration-Noise (NIN) observer, for a given configuration of the observer we started by simulating 10000 trials for each task type. Using this simulated data, we first quantified the bias in a model-free way, following the procedure outlined in A.1.1. This analysis showed that integration, and not sensory or choice noise, is the only parameter that is associated with consistent changes in the simplicity bias for all task types (<xref ref-type="fig" rid="figB9">Figure B.9</xref>).</p>
<fig id="figB9" position="float" fig-type="figure">
<label>Figure B9.</label>
<caption><title>Model-free estimate of simplicity bias in the Noise-Integration-Noise (NIN) observer, as a function of the observer’s parameters, for each of the four task types (Dimensionality, Boundary, Volume, and Robustness; different columns show results for different task types).</title>
<p>The example in Figure 2b in the main text corresponds to the Dimensionality task type. Top: simplicity bias as a function of sensory noise ρ and choice noise T, when the integration parameter b is set to 0, meaning that the observer does not integrate over latent causes (see section A.1). Note that the grid of choice noise values tested in the figure is not equally spaced; the values of T shown here are [0.10, 0.50, 0.56, 0.63, 0.71, 0.83, 1.00, 2.00], which correspond to the following values for the inverse temperature 1/T: [10, 2.0, 1.8, 1.6, 1.4, 1.2, 1.0, 0.5]. Bottom: simplicity bias as a function of the integration parameter b, with sensory noise and choice noise fixed to the values indicated in the top panels with the colored crosses. Note how integration is the only parameter that is associated with consistent changes in the simplicity bias for all task types (increasing integration increases the simplicity bias). Sensory noise has inconsistent effects across task types, and choice noise does not affect the simplicity bias.</p></caption>
<graphic xlink:href="523479v5_figB9.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We then measured the sensitivity of the NIN observer to the terms of the FIA expansion. To do so, we fitted to the simulated data a simplified version of the model we used for humans and artificial neural networks, described in detail in A.6. Briefly, the log odds for the observer to choose model ℳ<sub>1</sub> over ℳ<sub>2</sub> was taken to be similar to <xref rid="eqnA106" ref-type="disp-formula">Equation A106</xref>:
<disp-formula id="ueqn29">
<graphic xlink:href="523479v5_ueqn29.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>L</italic><sub><italic>i</italic></sub>, <italic>D</italic><sub><italic>i</italic></sub>, <italic>B</italic><sub><italic>i</italic></sub>, <italic>V</italic><sub><italic>i</italic></sub> and <italic>R</italic><sub><italic>i</italic></sub> are the FIA expansion terms for model ℳ<sub><italic>i</italic></sub>, and <italic>β</italic><sub><italic>k</italic></sub> are parameters to be fitted, with, for instance, <italic>β</italic><sub><italic>D</italic></sub> representing the sensitivity of the observer to model dimensionality. We fit this expression to the behavior of the observer in the 10000 simulated trials using a regularized logistic regression:
<disp-formula id="ueqn30">
<graphic xlink:href="523479v5_ueqn30.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>C</italic><sub><italic>t</italic></sub> is the choice of the observer on model <italic>t</italic>, with <italic>C</italic><sub><italic>t</italic></sub> = 1 indicating that the observer chooses to report model ℳ<sub>1</sub> on that trial. For each NIN configuration tested, we report in <xref ref-type="fig" rid="figB10">Figure B.10</xref> the maximum a posteriori (MAP) fit of the <italic>β</italic> values, obtained using the <monospace>find_MAP</monospace> function in PyMC (<xref ref-type="bibr" rid="cs11">Salvatier et al., 2016</xref>). Our results were broadly consistent to those in <xref ref-type="fig" rid="figB9">Figure B.9</xref>, showing that integration was the only observer parameter with a consistent effect on FIA term sensitivity (<xref ref-type="fig" rid="figB10">Figure B.10</xref>, top and middle). Finally, we normalized the FIA term sensitivity by the likelihood sensitivity, in the same way as we did in the main text for human and artificial neural network observers. This analysis showed an even stronger qualitative match between the model-free and the FIA-based quantification of the simplicity bias (compare <xref ref-type="fig" rid="figB9">Figure B.9</xref> and <xref ref-type="fig" rid="figB10">Figure B.10</xref>, bottom).</p>
<fig id="figB10" position="float" fig-type="figure">
<label>Figure B10.</label>
<caption><title>Sensitivity to model likelihood and to the geometric features that characterize model complexity, for the Noise-Integration-Noise observer, as a function of the parameters of the observer.</title>
<p>The parameter values tested are the same as in Figure B.9. Top: dependence of the sensitivities on the sensory noise σ and the choice noise T, when the integration parameter b is fixed to zero (meaning that the observer does not integrate over latent causes). Middle: dependence on the sensitivities on integration, when sensory and choice noise are fixed to the values indicated by the colored crosses in the top panels. Bottom: same as middle, but for the normalized sensitivities, obtained by dividing the raw sensitivities by the likelihood sensitivity. Note that, reflecting the results in <xref ref-type="fig" rid="figB9">Figure B.9</xref>, the parameter controlling integration (x axis on each individual subplot) is the only one that has a consistent effect on the sensitivity to all features, generally increasing it. Note also the qualitative match between the bottom panels here and those in Figure B.9. The agreement with the data presented here and that in <xref ref-type="fig" rid="figB9">Figure B.9</xref> further confirms that our theory-driven approach captures the intuitive notion of simplicity bias in this task.</p></caption>
<graphic xlink:href="523479v5_figB10.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s9g2">
<label>B.7.3</label>
<title>Human simplicity preference is compatible with integration over latent causes</title>
<p>Fits of the Noise-Integration-Noise (NIN) model indicated that the behavior of most of our human participants was consistent with integrating over latent causes. Specifically, for thefor the Robustness and Dimensionality versions of the generative task most participants had their “integration indices” <italic>b</italic> pinned at 1, which is the maximum possible value and indicated integration over the full statistical manifolds (<xref ref-type="fig" rid="figB11">Figure B.11b</xref>). For the Volume and Boundary tasks, some participants failed to integrate (<italic>b</italic> = 0) but the others showed a range of propensities toward integration. These results are consistent with the sensitivities extracted with the FIA analysis (<xref ref-type="table" rid="tblB3">Table B.3</xref>), which showed that participants were generally more strongly sensitive to dimensionality and robustness than volume and boundary.</p>
<p>The distribution of best-fitting values of the sensory noise parameter <italic>ρ</italic> (<xref ref-type="fig" rid="figB11">Figure B.11a</xref>) exhibited two components: 1) a spike at zero, indicating a number of participants with negligible sensory noise; and 2) a separate, broader peak. This peak was centered around an “efficent” value, as we will now argue. As a reminder, on each trial of the experiment we showed a cloud of <italic>N</italic> = 10 dots to the participants, with each dot being sampled from a 2D Gaussian distribution with isotropic variance and standard deviation <italic>σ</italic> = 1. For our task, the location of the cloud centroid <inline-formula id="inline-eqn-50"><inline-graphic xlink:href="523479v5_inline37.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is a sufficient statistic, in the sense that it is enough to compute the posterior <italic>η</italic> ∼ 𝒩, <italic>ρ x</italic> probabilities for our behavioral models (both FIA and NIN). The standard deviation of the sampling distribution for <inline-formula id="inline-eqn-51"><inline-graphic xlink:href="523479v5_inline38.gif" mime-subtype="gif" mimetype="image"/></inline-formula> (its standard error) therefore captures the intrinsic reliability of the raw visual information provided to the participants, before it is corrupted by the sensory noise (0). From the definition of,<inline-formula id="inline-eqn-52"><inline-graphic xlink:href="523479v5_inline39.gif" mime-subtype="gif" mimetype="image"/></inline-formula> its standard error is simply<inline-formula id="inline-eqn-53"><inline-graphic xlink:href="523479v5_inline40.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. The variance of the perceived centroid location <inline-formula id="inline-eqn-54"><inline-graphic xlink:href="523479v5_inline41.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is then <italic>σ</italic><sup>2</sup><italic>/N</italic> + <italic>ρ</italic><sup>2</sup>, which is dominated by <italic>ρ</italic><sup>2</sup> when <inline-formula id="inline-eqn-55"><inline-graphic xlink:href="523479v5_inline42.gif" mime-subtype="gif" mimetype="image"/></inline-formula> and by <inline-formula id="inline-eqn-56"><inline-graphic xlink:href="523479v5_inline43.gif" mime-subtype="gif" mimetype="image"/></inline-formula> when<inline-formula id="inline-eqn-57"><inline-graphic xlink:href="523479v5_inline44.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. Therefore, <inline-formula id="inline-eqn-58"><inline-graphic xlink:href="523479v5_inline45.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is the “efficient” value of <italic>ρ</italic>, corresponding to the maximum spatial resolution beyond which it is not convenient to encode the location of the centroid due to diminishing returns. This value is reported in <xref ref-type="fig" rid="figB11">Figure B.11a</xref> as an arrow, showing that the estimated values of <italic>ρ</italic> for the participants with non-negligible sensory noise are centered around this value.</p>
<fig id="figB11" position="float" fig-type="figure">
<label>Figure B11.</label>
<caption><title>Analysis of human behavior on the generative task, using the Noise-Integration-Noise (NIN) model.</title>
<p><bold>a</bold>: sensory noise (ρ) estimate for all participants, broken down by task type (colors). Arrow: standard error of the location of the centroid of the dot cloud that, on any trial, represented the data X shown to the participants (<inline-formula id="inline-eqn-59"><inline-graphic mime-subtype="gif" xlink:href="523479v5_inline54.gif" mimetype="image"/></inline-formula>, using the notation N of A.3 and A.4.2). <bold>b</bold>: estimates of integration parameter b. <bold>c</bold>: estimates of inverse temperature of the choice noise β = 1/T. Inset: detail of the inverse temperature histogram for β ∈ [0, 1]. Arrow: numerical value of the population estimate of likelihood sensitivity from the FIA model. <bold>d</bold>: simple participant-level model comparison (Akaike Information Criterion) between the NIN model and the behavioral model based on the FIA (<xref ref-type="disp-formula" rid="eqnA106">Equation A106</xref>). Lower is better; the dashed diagonal line is the identity. Inset: histogram of NIN-FIA difference, excluding outliers with large positive values, which are overwhelmingly better described by FIA. The AIC is lower (better) for the FIA than for the NIN model for 182 out of 201 subjects.</p></caption>
<graphic xlink:href="523479v5_figB11.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>The best-fitting inverse-temperature parameters have a distribution with two components (<xref ref-type="fig" rid="figB11">Figure B.11c</xref>): 1) a bulk below 1, and 2) a tail with values that go far above 1. As a reminder, for this parameter, 0 corresponds to making random choices, 1 corresponds to sampling from the posterior over models (computed by integrating in a neighborhood of the max likelihood point whose radius is determined by the “integration” parameter <italic>b</italic>), and infinity corresponds to selecting deterministically the model with the largest posterior. Also recall from A.7 that the inverse temperature <italic>β</italic> is bounded in the fitting procedure to the interval [0, 10], so the participants with <italic>β</italic> = 10 could possibly be fit even better by larger values. However, in practice this constraint does not make a large difference with respect to the behavior of the fitted model, as <italic>β</italic> = 10 can be already considered close enough to a deterministic choice regime. The peak of the inverse-temperature distribution is very close to the mean posterior estimate for the (population-level) sensitivity to likelihood in our FIA model (which is 0.46 in the generative task, plotted as a dashed cyan line in <xref ref-type="fig" rid="figB11">Figure B.11c</xref>). This result is consistent with the idea that the likelihood sensitivity captures an overall scaling of the slope of the psychometric function, and further supports our choice to focus on normalized sensitivities in the main text.</p>
<p>Applying the same analysis to the data from the maximum-likelihood task gives broadly consistent results, with the exception that the inferred degree of integration is less peaked around 1 and much more distributed over a continuum between 0 and 1 for all tasks (<xref ref-type="fig" rid="figB12">Figure B.12</xref>). This result implies that the participants still performed integration under these conditions, albeit to a lesser extent than for the generative task, corroborating the results of the FIA analysis in <xref rid="fig5" ref-type="fig">Figure 5</xref> in the main text.</p>
<fig id="figB12" position="float" fig-type="figure">
<label>Figure B12.</label>
<caption><title>Analysis of human behavior on the maximum-likelihood task, using the Noise-Integration-Noise (NIN) model.</title>
<p>Same as <xref ref-type="fig" rid="figB11">Figure B.11</xref>, but for the behavioral data of the subjects that performed the maximum-likelihood task. In panel d, the AIC is lower (better) for the FIA than for the NIN model for 144 out of 201 subjects.</p></caption>
<graphic xlink:href="523479v5_figB12.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s9g3">
<label>B.7.3</label>
<title>Model comparison between NIN and FIA</title>
<p>We checked whether our more refined, theory-driven behavioral model based on the FIA explained participant behavior better than the more elementary NIN model. To do so in a fair way, we re-fit the FIA model on a individual-participant basis (that is, we removed the hierarchical structure) using maximum likelihood, with the same optimization algorithm described for the NIN model in A.7. This procedure allowed us to compute an Akaike Information Criterion for each model on each participant. <xref ref-type="fig" rid="figB11">Figure B.11b</xref> shows that the the vast majority of participants (182 out of 202) were better described by the FIA model.</p>
</sec>
</sec>
</sec>
</app>
</app-group>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Abbott</surname>, <given-names>M. C.</given-names></string-name>, &amp; <string-name><surname>Machta</surname>, <given-names>B. B.</given-names></string-name></person-group> (<year>2023</year>). <article-title>Far from Asymptopia: Unbiased High-Dimensional Inference Cannot Assume Unlimited Data</article-title>. <source>Entropy</source>, <volume>25</volume> (<issue>3</issue>), <fpage>434</fpage>. <pub-id pub-id-type="doi">10.3390/e25030434</pub-id></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Baker</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2022</year>). <chapter-title>Simplicity</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>E. N.</given-names> <surname>Zalta</surname></string-name></person-group> (Ed.), <source>The Stanford Encyclopedia of Philosophy (Summer 2022)</source>. <publisher-name>Metaphysics Research Lab, Stanford Uni-versity</publisher-name>. Retrieved August 9, 2022, from <ext-link ext-link-type="uri" xlink:href="https://plato.stanford.edu/archives/sum2022/entries/simplicity/">https://plato.stanford.edu/archives/sum2022/entries/simplicity/</ext-link></mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Balasubramanian</surname>, <given-names>V.</given-names></string-name></person-group> (<year>1997</year>). <article-title>Statistical Inference, Occam’s Razor, and Statistical Mechanics on the Space of Probability Distributions</article-title>. <source>Neural Computation</source>, <volume>9</volume> (<issue>2</issue>), <fpage>349</fpage>–<lpage>368</lpage>. <pub-id pub-id-type="doi">10.1162/neco.1997.9.2.349</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bengio</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Lecun</surname>, <given-names>Y.</given-names></string-name>, &amp; <string-name><surname>Hinton</surname>, <given-names>G.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Deep learning for AI</article-title>. <source>Communications of the ACM</source>, <volume>64</volume> (<issue>7</issue>), <fpage>58</fpage>–<lpage>65</lpage>. <pub-id pub-id-type="doi">10.1145/3448250</pub-id></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bialek</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Nemenman</surname>, <given-names>I.</given-names></string-name>, &amp; <string-name><surname>Tishby</surname>, <given-names>N.</given-names></string-name></person-group> (<year>2001</year>). <article-title>Predictability, Complexity and Learning</article-title>. <source>Neural Computation</source>, (<issue>13</issue>), <fpage>2409</fpage>–<lpage>2463</lpage>. <pub-id pub-id-type="doi">10.1162/089976601753195969</pub-id></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bonawitz</surname>, <given-names>E. B.</given-names></string-name>, &amp; <string-name><surname>Lombrozo</surname>, <given-names>T.</given-names></string-name></person-group> (<year>2012</year>). <article-title>Occam’s rattle: Children’s use of simplicity and probability to constrain inference</article-title>. <source>Developmental Psychology</source>, <volume>48</volume> (<issue>4</issue>), <fpage>1156</fpage>–<lpage>1164</lpage>. <pub-id pub-id-type="doi">10.1037/a0026471</pub-id></mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chater</surname>, <given-names>N.</given-names></string-name></person-group> (<year>1999</year>). <article-title>The Search for Simplicity: A Fundamental Cognitive Principle?</article-title> <source>The Quarterly Journal of Experimental Psychology Section A</source>, <volume>52</volume> (<issue>2</issue>), <fpage>273</fpage>–<lpage>302</lpage>. <pub-id pub-id-type="doi">10.1080/713755819</pub-id></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chater</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Vitányi</surname>, <given-names>P.</given-names></string-name></person-group> (<year>2003</year>). <article-title>Simplicity: A unifying principle in cognitive science?</article-title> <source>Trends in Cognitive Sciences</source>, <volume>7</volume> (<issue>1</issue>), <fpage>19</fpage>–<lpage>22</lpage>. <pub-id pub-id-type="doi">10.1016/S1364-6613(02)00005-0</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chaudhari</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Choromanska</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Soatto</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>LeCun</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Baldassi</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Borgs</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Chayes</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Sagun</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>Zecchina</surname>, <given-names>R.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Entropy-SGD: Biasing gradient descent into wide valleys*</article-title>. <source>Journal of Statistical Mechanics: Theory and Experiment</source>, <volume>2019</volume> (<issue>12</issue>), <fpage>124018</fpage>. <pub-id pub-id-type="doi">10.1088/1742-5468/ab39d9</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>de Mulatier</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Marsili</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2024</year>, <month>August</month> 27). <article-title>Bayesian Inference of Minimally Complex Models with Interactions of Arbitrary Order</article-title>. <source>arXiv</source>.<pub-id pub-id-type="doi">10.48550/arXiv.2008.00520</pub-id></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>De Palma</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Kiani</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Lloyd</surname>, <given-names>S.</given-names></string-name></person-group> (<year>2019</year>). <chapter-title>Random deep neural networks are biased towards simple functions</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>H.</given-names> <surname>Wallach</surname></string-name>, <string-name><given-names>H.</given-names> <surname>Larochelle</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Beygelzimer</surname></string-name>, <string-name><given-names>F.</given-names> <surname>d’Alché-Buc</surname></string-name>, <string-name><given-names>E.</given-names> <surname>Fox</surname></string-name>, &amp; <string-name><given-names>R.</given-names> <surname>Garnett</surname></string-name></person-group> (Eds.), <source>Advances in Neural Information Processing Systems</source> (Vol. <volume>32</volume>). <publisher-name>Curran Associates, Inc</publisher-name>. <ext-link ext-link-type="uri" xlink:href="https://proceedings.neurips.cc/paper/2019/file/feab05aa91085b7a8012516bc3533958-Paper.pdf">https://proceedings.neurips.cc/paper/2019/file/feab05aa91085b7a8012516bc3533958-Paper.pdf</ext-link></mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Feldman</surname>, <given-names>J.</given-names></string-name></person-group> (<year>2016</year>). <article-title>The simplicity principle in perception and cognition: The simplicity principle</article-title>. <source>Wiley Interdisciplinary Reviews: Cognitive Science</source>, <volume>7</volume> (<issue>5</issue>), <fpage>330</fpage>–<lpage>340</lpage>. <pub-id pub-id-type="doi">10.1002/wcs.1406</pub-id></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Feldman</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Singh</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2006</year>). <article-title>Bayesian estimation of the shape skeleton</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>103</volume> (<issue>47</issue>), <fpage>18014</fpage>–<lpage>18019</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.0608811103</pub-id></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Froyen</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Feldman</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Singh</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2015</year>). <article-title>Bayesian hierarchical grouping: Perceptual grouping as mixture estimation</article-title>. <source>Psychological Review</source>, <volume>122</volume> (<issue>4</issue>), <fpage>575</fpage>–<lpage>597</lpage>. <pub-id pub-id-type="doi">10.1037/a0039540</pub-id></mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Gelman</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Carlin</surname>, <given-names>J. B.</given-names></string-name>, <string-name><surname>Stern</surname>, <given-names>H. S.</given-names></string-name>, <string-name><surname>Dunson</surname>, <given-names>D. B.</given-names></string-name>, <string-name><surname>Vehtari</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Rubin</surname>, <given-names>D. B.</given-names></string-name></person-group> (<year>2014</year>). <source>Bayesian Data Analysis</source> (<edition>3rd ed.</edition>). <publisher-name>CRC Press</publisher-name>.</mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Genewein</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Braun</surname>, <given-names>D. A.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Occam’s Razor in sensorimotor learning</article-title>. <source>Proceedings of the Royal Society B: Biological Sciences</source>, <volume>281</volume> (<issue>1783</issue>), <fpage>20132952</fpage>. <pub-id pub-id-type="doi">10.1098/rspb.2013.2952</pub-id></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name>, &amp; <string-name><surname>Niv</surname>, <given-names>Y.</given-names></string-name></person-group> (<year>2013</year>). <article-title>Perceptual estimation obeys Occam’s razor</article-title>. <source>Frontiers in Psychology</source>, <volume>4</volume>. <pub-id pub-id-type="doi">10.3389/fpsyg.2013.00623</pub-id></mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Good</surname>, <given-names>I. J.</given-names></string-name></person-group> (<year>1968</year>). <article-title>Corroboration, Explanation, Evolving Probability, Simplicity and a Sharpened Razor</article-title>. <source>The British Journal for the Philosophy of Science</source>, <volume>19</volume> (<issue>2</issue>), <fpage>123</fpage>–<lpage>143</lpage>. <ext-link ext-link-type="uri" xlink:href="http://www.jstor.org/stable/686791">http://www.jstor.org/stable/686791</ext-link></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Griffiths</surname>, <given-names>T. L.</given-names></string-name>, &amp; <string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name></person-group> (<year>2005</year>). <article-title>Structure and strength in causal induction</article-title>. <source>Cognitive Psychology</source>, <volume>51</volume> (<issue>4</issue>), <fpage>334</fpage>–<lpage>384</lpage>. <pub-id pub-id-type="doi">10.1016/j.cogpsych.2005.05.004</pub-id></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Grünwald</surname>, <given-names>P. D.</given-names></string-name></person-group> (<year>2007</year>). <source>The Minimum Description Length Principle</source>. <publisher-name>MIT press</publisher-name>.</mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Gull</surname>, <given-names>S. F.</given-names></string-name></person-group> (<year>1988</year>). <chapter-title>Bayesian Inductive Inference and Maximum Entropy</chapter-title>. In <person-group person-group-type="editor"><string-name><given-names>G.J.</given-names> <surname>Erickson</surname></string-name> &amp; <string-name><given-names>C. R.</given-names> <surname>Smith</surname></string-name></person-group> (Eds.), <source>Maximum-Entropy and Bayesian Methods in Science and Engineering: Foundations</source> (pp. <fpage>53</fpage>–<lpage>74</lpage>). <publisher-name>Springer Netherlands</publisher-name>. <pub-id pub-id-type="doi">10.1007/978-94-009-3049-0_4</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hatfield</surname>, <given-names>G.</given-names></string-name></person-group> (<year>1985</year>). <article-title>The status of the minimum principle in the theoretical analysis of visual perception</article-title>. <source>Psychological Bulletin</source>, <volume>97</volume> (<issue>2</issue>), <fpage>155</fpage>. <pub-id pub-id-type="doi">10.1037/0033-2909.97.2.155</pub-id></mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Jaynes</surname>, <given-names>E. T.</given-names></string-name></person-group> (<year>2003</year>, <month>April</month> 1). <source>Probability Theory: The Logic of Science</source>. <publisher-name>Cambridge University Press</publisher-name>.</mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Jeffreys</surname>, <given-names>H.</given-names></string-name></person-group> (<year>1939</year>). <source>Theory of probability</source>. <publisher-name>Clarendon Press</publisher-name>.</mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="report"><person-group person-group-type="author"><string-name><surname>Jeffreys</surname>, <given-names>W.</given-names></string-name>, &amp; <string-name><surname>Berger</surname>, <given-names>J.</given-names></string-name></person-group> (<year>1991</year>, <month>August</month>). <source>Sharpening Ockham’s razor on a Bayesian strop (No. 9144C)</source>. <publisher-name>Department of Statistics, Purdue University</publisher-name>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Johnson</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Jin</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Keil</surname>, <given-names>F.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Simplicity and Goodness-of-Fit in Explanation: The Case of Intuitive Curve-Fitting</article-title>. <source>Proceedings of the Annual Meeting of the Cognitive Science Society</source>, <volume>36</volume>(<issue>36</issue>).</mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Koffka</surname>, <given-names>K.</given-names></string-name></person-group> (<year>2014</year>). <source>Principles of Gestalt psychology</source>. <publisher-name>Mimesis international</publisher-name>.</mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Körding</surname>, <given-names>K. P.</given-names></string-name>, <string-name><surname>Beierholm</surname>, <given-names>U.</given-names></string-name>, <string-name><surname>Ma</surname>, <given-names>W. J.</given-names></string-name>, <string-name><surname>Quartz</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Tenenbaum</surname>, <given-names>J. B.</given-names></string-name>, &amp; <string-name><surname>Shams</surname>, <given-names>L.</given-names></string-name></person-group> (<year>2007</year>). <article-title>Causal Inference in Multisensory Perception</article-title>. <source>PLOS One</source>, <volume>2</volume> (<issue>9</issue>), <fpage>e943</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0000943</pub-id></mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Kruschke</surname>, <given-names>J. K.</given-names></string-name></person-group> (<year>2015</year>). <source>Doing Bayesian Data Analysis</source> (<edition>2nd ed.</edition>). <publisher-name>Academic Press</publisher-name>.</mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lanterman</surname>, <given-names>A. D.</given-names></string-name></person-group> (<year>2001</year>). <article-title>Schwarz, Wallace, and Rissanen: Intertwining Themes in Theories of Model Selection</article-title>. <source>International Statistical Review</source>, <volume>69</volume> (<issue>2</issue>), <fpage>185</fpage>–<lpage>212</lpage>. <pub-id pub-id-type="doi">10.1111/j.1751-5823.2001.tb00456.x</pub-id></mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Little</surname>, <given-names>D. R. B.</given-names></string-name>, &amp; <string-name><surname>Shiffrin</surname>, <given-names>R.</given-names></string-name></person-group> (<year>2009</year>). <article-title>Simplicity Bias in the Estimation of Causal Functions</article-title>. <source>Proceedings of the Annual Meeting of the Cognitive Science Society</source>, <volume>31</volume> (<issue>31</issue>). <ext-link ext-link-type="uri" xlink:href="https://escholarship.org/uc/item/3d85q7zt">https://escholarship.org/uc/item/3d85q7zt</ext-link></mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lombrozo</surname>, <given-names>T.</given-names></string-name></person-group> (<year>2007</year>). <article-title>Simplicity and probability in causal explanation</article-title>. <source>Cognitive Psychology</source>, <volume>55</volume> (<issue>3</issue>), <fpage>232</fpage>– <lpage>257</lpage>. <pub-id pub-id-type="doi">10.1016/j.cogpsych.2006.09.006</pub-id></mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>MacKay</surname>, <given-names>D. J. C.</given-names></string-name></person-group> (<year>1992</year>). <article-title>Bayesian Interpolation</article-title>. <source>Neural Computation</source>, <volume>4</volume> (<issue>3</issue>), <fpage>415</fpage>–<lpage>447</lpage>. <pub-id pub-id-type="doi">10.1162/neco.1992.4.3.415</pub-id></mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mattingly</surname>, <given-names>H. H.</given-names></string-name>, <string-name><surname>Transtrum</surname>, <given-names>M. K.</given-names></string-name>, <string-name><surname>Abbott</surname>, <given-names>M. C.</given-names></string-name>, &amp; <string-name><surname>Machta</surname>, <given-names>B. B.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Maximizing the information learned from finite data selects a simple model</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>, <volume>115</volume> (<issue>8</issue>), <fpage>1760</fpage>–<lpage>1765</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.1715306115</pub-id></mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>McElreath</surname>, <given-names>R.</given-names></string-name></person-group> (<year>2016</year>). <source>Statistical Rethinking</source>. <publisher-name>CRC Press</publisher-name>.</mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Muratore</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Tafazoli</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Piasini</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Laio</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Zoccolan</surname>, <given-names>D.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Prune and distill: Similar reformatting of image information along rat visual cortex and deep neural networks</article-title>. <conf-name>Advances in Neural Information Processing Systems</conf-name>, <volume>35</volume>, <fpage>30206</fpage>–<lpage>30218</lpage>. <ext-link ext-link-type="uri" xlink:href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/c2d82a425af4c18a35049899fea5ee82-Abstract-Conference.html">https://proceedings.neurips.cc/paper_files/paper/2022/hash/c2d82a425af4c18a35049899fea5ee82-Abstract-Conference.html</ext-link></mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Myung</surname>, <given-names>I. J.</given-names></string-name>, <string-name><surname>Balasubramanian</surname>, <given-names>V.</given-names></string-name>, &amp; <string-name><surname>Pitt</surname>, <given-names>M. A.</given-names></string-name></person-group> (<year>2000</year>). <article-title>Counting probability distributions: Differential geometry and model selection</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>97</volume> (<issue>21</issue>), <fpage>11170</fpage>– <lpage>11175</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.170283897</pub-id></mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Neath</surname>, <given-names>A. A.</given-names></string-name>, &amp; <string-name><surname>Cavanaugh</surname>, <given-names>J. E.</given-names></string-name></person-group> (<year>2012</year>). <article-title>The Bayesian information criterion: Background, derivation, and applications</article-title>. <source>WIREs Computational Statistics</source>, <volume>4</volume> (<issue>2</issue>), <fpage>199</fpage>–<lpage>203</lpage>. <pub-id pub-id-type="doi">10.1002/wics.199</pub-id></mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pacer</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Lombrozo</surname>, <given-names>T.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Ockham’s razor cuts to the root: Simplicity in causal explanation</article-title>. <source>Journal of Experimental Psychology: General</source>, <volume>146</volume> (<issue>12</issue>), <fpage>1761</fpage>–<lpage>1780</lpage>. <pub-id pub-id-type="doi">10.1037/xge0000318</pub-id></mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Piasini</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Balasubramanian</surname>, <given-names>V.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name></person-group> (<year>2020</year>). <article-title>Effect of geometric complexity on intuitive model selection - experiment on Pavlovia</article-title>. <source>OSF Preregistration</source> <pub-id pub-id-type="doi">10.17605/OSF.IO/2X9H6</pub-id></mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Piasini</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Balasubramanian</surname>, <given-names>V.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Addendum #2 to osf.io/2x9h6 - Effect of geometric complexity on intuitive model selection - rounded task</article-title>. <source>OSF Preregistration</source> <pub-id pub-id-type="doi">10.17605/OSF.IO/5HDQZ</pub-id></mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Piasini</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Balasubramanian</surname>, <given-names>V.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J.I.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Effect of geometric complexity on intuitive model selection - Maximum likelihood task</article-title>. <source>OSF Preregistration</source> <pub-id pub-id-type="doi">10.17605/OSF.IO/826JV</pub-id></mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pothos</surname>, <given-names>E. M.</given-names></string-name>, &amp; <string-name><surname>Chater</surname>, <given-names>N.</given-names></string-name></person-group> (<year>2002</year>). <article-title>A simplicity principle in unsupervised human categorization</article-title>. <source>Cognitive Science</source>, <volume>26</volume> (<issue>3</issue>), <fpage>303</fpage>–<lpage>343</lpage>. <pub-id pub-id-type="doi">10.1207/s15516709cog2603_6</pub-id></mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Quinn</surname>, <given-names>K. N.</given-names></string-name>, <string-name><surname>Abbott</surname>, <given-names>M. C.</given-names></string-name>, <string-name><surname>Transtrum</surname>, <given-names>M. K.</given-names></string-name>, <string-name><surname>Machta</surname>, <given-names>B. B.</given-names></string-name>, &amp; <string-name><surname>Sethna</surname>, <given-names>J. P.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Information geometry for multiparameter models: New perspectives on the origin of simplicity</article-title>. <source>Reports on Progress in Physics</source>, <volume>86</volume> (<issue>3</issue>), <fpage>035901</fpage>. <pub-id pub-id-type="doi">10.1088/1361-6633/aca6f8</pub-id></mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Ravanbakhsh</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Schneider</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Póczos</surname>, <given-names>B.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Equivariance Through Parameter-Sharing</article-title>. <conf-name>Proceedings of the 34th International Conference on Machine Learning</conf-name>, <fpage>2892</fpage>–<lpage>2901</lpage>. <ext-link ext-link-type="uri" xlink:href="https://proceedings.mlr.press/v70/ravanbakhsh17a.html">https://proceedings.mlr.press/v70/ravanbakhsh17a.html</ext-link></mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rissanen</surname>, <given-names>J.</given-names></string-name></person-group> (<year>1996</year>). <article-title>Fisher information and stochastic complexity</article-title>. <source>IEEE Transactions on Information Theory</source>, <volume>42</volume> (<issue>1</issue>), <fpage>40</fpage>–<lpage>47</lpage>. <pub-id pub-id-type="doi">10.1109/18.481776</pub-id></mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Schrimpf</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Kubilius</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Hong</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Majaj</surname>, <given-names>N. J.</given-names></string-name>, <string-name><surname>Rajalingham</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Issa</surname>, <given-names>E. B.</given-names></string-name>, <string-name><surname>Kar</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Bashivan</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Prescott-Roy</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Geiger</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Schmidt</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Yamins</surname>, <given-names>D. L. K.</given-names></string-name>, &amp; <string-name><surname>DiCarlo</surname>, <given-names>J. J.</given-names></string-name></person-group> (<year>2020</year>). <article-title>Brain-Score: Which Artificial Neural Network for Object Recognition is most Brain-Like?</article-title> <source>bioRxiv</source>, <fpage>407007</fpage>. <pub-id pub-id-type="doi">10.1101/407007</pub-id></mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schwarz</surname>, <given-names>G.</given-names></string-name></person-group> (<year>1978</year>). <article-title>Estimating the Dimension of a Model</article-title>. <source>The Annals of Statistics</source>, <volume>6</volume> (<issue>2</issue>), <fpage>461</fpage>–<lpage>464</lpage>. <pub-id pub-id-type="doi">10.1214/aos/1176344136</pub-id></mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Smith</surname>, <given-names>A. F. M.</given-names></string-name>, &amp; <string-name><surname>Spiegelhalter</surname>, <given-names>D. J.</given-names></string-name></person-group> (<year>1980</year>). <article-title>Bayes Factors and Choice Criteria for Linear Models</article-title>. <source>Journal of the Royal Statistical Society: Series B (Methodological)</source>, <volume>42</volume> (<issue>2</issue>), <fpage>213</fpage>–<lpage>220</lpage>. <pub-id pub-id-type="doi">10.1111/j.2517-6161.1980.tb01122.x</pub-id></mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tavoni</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Balasubramanian</surname>, <given-names>V.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name></person-group> (<year>2019</year>). <article-title>What is optimal in optimal inference?</article-title> <source>Current Opinion in Behavioral Sciences</source>, <volume>29</volume>, <fpage>117</fpage>–<lpage>126</lpage>. <pub-id pub-id-type="doi">10.1016/j.cobeha.2019.07.008</pub-id></mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tavoni</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Doi</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Pizzica</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Balasubramanian</surname>, <given-names>V.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Human inference reflects a normative balance of complexity and accuracy</article-title>. <source>Nature Human Behaviour</source>, <volume>6</volume> (<issue>8</issue>), <fpage>1153</fpage>–<lpage>1168</lpage>. <pub-id pub-id-type="doi">10.1038/s41562-022-01357-z</pub-id></mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Transtrum</surname>, <given-names>M. K.</given-names></string-name>, <string-name><surname>Machta</surname>, <given-names>B. B.</given-names></string-name>, <string-name><surname>Brown</surname>, <given-names>K. S.</given-names></string-name>, <string-name><surname>Daniels</surname>, <given-names>B. C.</given-names></string-name>, <string-name><surname>Myers</surname>, <given-names>C. R.</given-names></string-name>, &amp; <string-name><surname>Sethna</surname>, <given-names>J. P.</given-names></string-name></person-group> (<year>2015</year>). <article-title>Perspective: Sloppiness and emergent theories in physics, biology, and beyond</article-title>. <source>The Journal of Chemical Physics</source>, <volume>143</volume> (<issue>1</issue>), <fpage>010901</fpage>. <pub-id pub-id-type="doi">10.1063/1.4923066</pub-id></mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Valle-Perez</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Camargo</surname>, <given-names>C. Q.</given-names></string-name>, &amp; <string-name><surname>Louis</surname>, <given-names>A. A.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Deep learning generalizes because the parameterfunction map is biased towards simple functions</article-title>. <conf-name>International Conference on Learning Representations.</conf-name></mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wagemans</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Elder</surname>, <given-names>J. H.</given-names></string-name>, <string-name><surname>Kubovy</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Palmer</surname>, <given-names>S. E.</given-names></string-name>,<string-name><surname>Peterson</surname>, <given-names>M. A.</given-names></string-name>, <string-name><surname>Singh</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>von der Heydt</surname>, <given-names>R.</given-names></string-name></person-group> (<year>2012</year>). <article-title>A century of Gestalt psychology in visual perception: I. Perceptual grouping and figure–ground organization</article-title>. <source>Psychological Bulletin</source>, <volume>138</volume> (<issue>6</issue>), <fpage>1172</fpage>–<lpage>1217</lpage>. <pub-id pub-id-type="doi">10.1037/a0029333</pub-id></mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Wallace</surname>, <given-names>C. S.</given-names></string-name></person-group> (<year>2005</year>). <source>Statistical and inductive inference by minimum message length</source>. <publisher-name>Springer</publisher-name>.</mixed-citation></ref>
<ref id="c55a"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wilder</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Feldman</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Singh</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2016</year>). <article-title>The role of shape complexity in the detection of closed contours</article-title>. <source>Vision Research</source>, <volume>126</volume>, <fpage>220</fpage>–<lpage>231</lpage>. <pub-id pub-id-type="doi">10.1016/j.visres.2015.10.011</pub-id></mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wojtowicz</surname>, <given-names>Z.</given-names></string-name>, &amp; <string-name><surname>DeDeo</surname>, <given-names>S.</given-names></string-name></person-group> (<year>2020</year>). <article-title>From Probability to Consilience: How Explanatory Values Implement Bayesian Reasoning</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>24</volume> (<issue>12</issue>), <fpage>981</fpage>–<lpage>993</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2020.09.013</pub-id></mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Xie</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Marsili</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2024</year>). <article-title>A simple probabilistic neural network for machine understanding</article-title>. <source>Journal of Statistical Mechanics: Theory and Experiment</source>,<volume>2024</volume> (<issue>2</issue>), <fpage>023403</fpage>. <pub-id pub-id-type="doi">10.1088/1742-5468/ad0a8c</pub-id></mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Yang</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Mao</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Chaudhari</surname>, <given-names>P.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Does the Data Induce Capacity Control in Deep Learning?</article-title> <conf-name>Proceedings of the 39th International Conference on Machine Learning</conf-name>, <fpage>25166</fpage>–<lpage>25197</lpage>. <ext-link ext-link-type="uri" xlink:href="https://proceedings.mlr.press/v162/yang22k.html">https://proceedings.mlr.press/v162/yang22k.html</ext-link></mixed-citation></ref>
<ref id="sc1"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Abramowitz</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Stegun</surname>, <given-names>I. A.</given-names></string-name></person-group> (<year>1972</year>). <source>Handbook of mathematical functions: With formulas, graphs, and mathematical tables</source>. <publisher-name>Dover</publisher-name>.</mixed-citation></ref>
<ref id="sc2"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Amari</surname>, <given-names>S.-i.</given-names></string-name>, &amp; <string-name><surname>Nagaoka</surname>, <given-names>H.</given-names></string-name></person-group> (<year>2000</year>). <source>Methods of information geometry</source> (D. Harada, Trans.). <publisher-name>American Mathematical Society</publisher-name>.</mixed-citation></ref>
<ref id="sc3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Balasubramanian</surname>, <given-names>V.</given-names></string-name></person-group> (<year>1997</year>). <article-title>Statistical Inference, Occam’s Razor, and Statistical Mechanics on the Space of Probability Distributions</article-title>. <source>Neural Computation</source>, <volume>9</volume> (<issue>2</issue>), <fpage>349</fpage>–<lpage>368</lpage>. <pub-id pub-id-type="doi">10.1162/neco.1997.9.2.349</pub-id></mixed-citation></ref>
<ref id="sc4"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Betancourt</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2018</year>, <month>July</month> 15). <article-title>A Conceptual Introduction to Hamiltonian Monte Carlo</article-title>. <source>arXiv</source> .<pub-id pub-id-type="doi">10.48550/arXiv.1701.02434</pub-id></mixed-citation></ref>
<ref id="sc5"><mixed-citation publication-type="report"><person-group person-group-type="author"><collab>Stan development team</collab></person-group> (<year>2022</year>). <source>Stan Modeling Language Users Guide</source>, version <version>2.31</version>.</mixed-citation></ref>
<ref id="sc7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Hoffman</surname>, <given-names>M. D.</given-names></string-name>, &amp; <string-name><surname>Gelman</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2014</year>). <article-title>The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo</article-title>. <source>Journal of Machine Learning Research</source>, <volume>15</volume> (<issue>47</issue>), <fpage>1593</fpage>–<lpage>1623</lpage>. <ext-link ext-link-type="uri" xlink:href="http://jmlr.org/papers/v15/hoffman14a.html">http://jmlr.org/papers/v15/hoffman14a.html</ext-link></mixed-citation></ref>
<ref id="sc8"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Jaynes</surname>, <given-names>E. T.</given-names></string-name></person-group> (<year>2003</year>, <month>April</month> 1). <source>Probability Theory: The Logic of Science</source>. <publisher-name>Cambridge University Press</publisher-name>.</mixed-citation></ref>
<ref id="sc10"><mixed-citation publication-type="web"><person-group person-group-type="author"><string-name><surname>Owen</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2023</year>). <source>Practical Quasi-Monte Carlo Integration</source>. <ext-link ext-link-type="uri" xlink:href="https://artowen.su.domains/mc/practicalqmc.pdf">https://artowen.su.domains/mc/practicalqmc.pdf</ext-link></mixed-citation></ref>
<ref id="sc11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pedregosa</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Varoquaux</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Gramfort</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Michel</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Thirion</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Grisel</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Blondel</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Prettenhofer</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Weiss</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Dubourg</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Vanderplas</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Passos</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Cournapeau</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Brucher</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Perrot</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Duchesnay</surname>, <given-names>É.</given-names></string-name></person-group> (<year>2011</year>). <article-title>Scikit-learn: Machine Learning in Python</article-title>. <source>Journal of Machine Learning Research</source>, <volume>12</volume> (<issue>85</issue>), <fpage>2825</fpage>–<lpage>2830</lpage>. Retrieved January 6, 2023, from <ext-link ext-link-type="uri" xlink:href="http://jmlr.org/papers/v12/pedregosa11a.html">http://jmlr.org/papers/v12/pedregosa11a.html</ext-link></mixed-citation></ref>
<ref id="sc13"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Piasini</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Balasubramanian</surname>, <given-names>V.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name></person-group> (<year>2021a</year>). <article-title>Effect of Geometric Complexity on Intuitive Model Selection</article-title>. <conf-name>The First International Symposium on AI and Neuroscience - ACAIN 2021</conf-name>.</mixed-citation></ref>
<ref id="sc16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Roy</surname>, <given-names>P. T.</given-names></string-name>, <string-name><surname>Owen</surname>, <given-names>A. B.</given-names></string-name>, <string-name><surname>Balandat</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Haberland</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2023</year>). <article-title>Quasi-Monte Carlo Methods in Python</article-title>. <source>Journal of Open Source Software</source>, <volume>8</volume> (<issue>84</issue>), <fpage>5309</fpage>. <pub-id pub-id-type="doi">10.21105/joss.05309</pub-id></mixed-citation></ref>
<ref id="sc17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Salvatier</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Wiecki</surname>, <given-names>T. V.</given-names></string-name>, &amp; <string-name><surname>Fonnesbeck</surname>, <given-names>C.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Probabilistic programming in Python using PyMC3</article-title>. <source>PeerJ Computer Science</source>, <volume>2</volume>, <fpage>e55</fpage>. <pub-id pub-id-type="doi">10.7717/peerj-cs.55</pub-id></mixed-citation></ref>
<ref id="sc18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Storn</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Price</surname>, <given-names>K.</given-names></string-name></person-group> (<year>1997</year>). <article-title>Differential Evolution – A Simple and Efficient Heuristic for global Optimization over Continuous Spaces</article-title>. <source>Journal of Global Optimization</source>, <volume>11</volume> (<issue>4</issue>), <fpage>341</fpage>–<lpage>359</lpage>. <pub-id pub-id-type="doi">10.1023/A:1008202821328</pub-id></mixed-citation></ref>
<ref id="sc19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vehtari</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Gelman</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Simpson</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Carpenter</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Bürkner</surname>, <given-names>P.-C.</given-names></string-name></person-group> (<year>2020</year>). <article-title>Rank-Normalization, Folding, and Localization: An Improved $\hatR$ for Assessing Convergence of MCMC</article-title>. <source>Bayesian Analysis</source>. <pub-id pub-id-type="doi">10.1214/20-ba1221</pub-id></mixed-citation></ref>
<ref id="cs3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kumar</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Carroll</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Hartikainen</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Martin</surname>, <given-names>O.</given-names></string-name></person-group> (<year>2019</year>). <article-title>ArviZ a unified library for exploratory analysis of Bayesian models in Python</article-title>. <source>Journal of Open Source Software</source>, <volume>4</volume> (<issue>33</issue>), <fpage>1143</fpage>. <pub-id pub-id-type="doi">10.21105/joss.01143</pub-id></mixed-citation></ref>
<ref id="cs4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Makowski</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Ben-Shachar</surname>, <given-names>M. S.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>S. H. A.</given-names></string-name>, &amp; <string-name><surname>Lüdecke</surname>, <given-names>D.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Indices of Effect Existence and Significance in the Bayesian Framework</article-title>. <source>Frontiers in Psychology</source>, <volume>10</volume>. <ext-link ext-link-type="uri" xlink:href="https://www.frontiersin.org/articles/10.3389/fpsyg.2019.02767">https://www.frontiersin.org/articles/10.3389/fpsyg.2019.02767</ext-link></mixed-citation></ref>
<ref id="cs5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Makowski</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Ben-Shachar</surname>, <given-names>M. S.</given-names></string-name>, &amp; <string-name><surname>Lüdecke</surname>, <given-names>D.</given-names></string-name></person-group> (<year>2019</year>). <article-title>bayestestR: Describing Effects and their Uncertainty, Existence and Significance within the Bayesian Framework</article-title>. <source>Journal of Open Source Software</source>, <volume>4</volume> (<issue>40</issue>), <fpage>1541</fpage>. <pub-id pub-id-type="doi">10.21105/joss.01541</pub-id></mixed-citation></ref>
<ref id="cs6"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>McElreath</surname>, <given-names>R.</given-names></string-name></person-group> (<year>2016</year>). <source>Statistical Rethinking</source>. <publisher-name>CRC Press</publisher-name>.</mixed-citation></ref>
<ref id="cs8"><mixed-citation publication-type="confproc"><person-group person-group-type="author"><string-name><surname>Piasini</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Balasubramanian</surname>, <given-names>V.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name></person-group> (<year>2021a</year>). <article-title>Effect of Geometric Complexity on Intuitive Model Selection</article-title>. <conf-name>The First International Symposium on AI and Neuroscience - ACAIN 2021</conf-name>.</mixed-citation></ref>
<ref id="cs11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Salvatier</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Wiecki</surname>, <given-names>T. V.</given-names></string-name>, &amp; <string-name><surname>Fonnesbeck</surname>, <given-names>C.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Probabilistic programming in Python using PyMC3</article-title>. <source>PeerJ Computer Science</source>, <volume>2</volume>, <fpage>e55</fpage>. <pub-id pub-id-type="doi">10.7717/peerj-cs.55</pub-id></mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.109113.1.sa4</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Hanks</surname>
<given-names>Timothy D</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-4147-4475</contrib-id>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/05rrcem69</institution-id><institution>University of California, Davis</institution>
</institution-wrap>
<city>Davis</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Convincing</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Important</kwd>
</kwd-group>
</front-stub>
<body>
<p>This study presents an <bold>important</bold> new approach to quantifying parsimony preferences in human inference. The work provides <bold>convincing</bold> evidence that humans are sensitive to specific formalizations of parsimony, such as the dimensionality of perceptual shapes. The work is considered timely, well-written, and technically sophisticated, effectively bridging concepts from statistical inference and human decision-making.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.109113.1.sa3</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>I have to preface my evaluation with a disclosure that I lack the mathematical expertise to fully assess what seems to be the authors' main theoretical contribution. I am providing this assessment to the best of my ability, but I cannot substitute for a reviewer with more advanced mathematical/physical training.</p>
<p>Summary:</p>
<p>This paper describes a new theoretical framework for measuring parsimony preferences in human judgments. The authors derive four metrics that they associate with parsimony (dimensionality, boundary, volume, and robustness) and measure whether human adults are sensitive to these metrics. In two tasks, adults had to choose one of two flower beds which a statistical sample was generated from, with or without explicit instruction to choose the flower bed perceptually closest to the sample. The authors conduct extensive statistical analyses showing that humans are sensitive to most of the derived quantities, even when the instructions encouraged participants to choose only based on perceptual distance. The authors complement their study with a computational neural network model that learns to make judgments about the same stimuli with feedback. They show that the computational model is sensitive to the tasks communicated by feedback and only uses the parsimony-associated metrics when feedback trains it to do so.</p>
<p>Strengths:</p>
<p>(1) The paper derives and applies new mathematical quantities associated with parsimony. The mathematical rigor is very impressive and is much more extensive than in most other work in the field, where studies often adopt only one metric (such as the number of causes or parameters). These formal metrics can be very useful for the field.</p>
<p>(2) The studies are preregistered, and the statistical analyses are strong.</p>
<p>(3) The computational model complements the behavioral findings, showing that the derived quantities are not simply equivalent to maximum-likelihood inference in the task.</p>
<p>(4) The speculations in the discussion section (e.g., the idea that human sensitivity is driven by the computational demands each metric requires) are intriguing and could usefully guide future work.</p>
<p>Weaknesses:</p>
<p>(1) The paper is very hard to understand. Many of the key details of the derived metrics are in the appendix, with very little accessible explanation in the main text. The figures helped me understand the metrics somewhat, although I am still not sure how some of them (such as boundary or robustness as measured here) are linked to parsimony. I understand that this is addressed by the derivations in the appendix, but as a computational cognitive scientist, I would have benefited from more accessible explanations. Important aspects of the human studies are also missing from the main text, such as the sample size for Experiment 2.</p>
<p>(2) It is not fully clear whether the sensitivity of human participants to some of the quantities convincingly reported here actually means that participants preferred shapes according to the corresponding aspect of parsimony. The title and framing suggest that parsimony &quot;guides&quot; human decision-making, which may lead readers to conclude that humans prefer more parsimonious shapes. I am not sure the sensitivity findings alone support this framing, but it might just be my misunderstanding of the analyses.</p>
<p>(3) The stimulus set included only four combinations of shapes, each designed to diagnostically target one of the theoretical quantities. It is unclear whether the results are robust or specific to these particular 4 stimuli.</p>
<p>(4) The study is framed as measuring &quot;decision-making,&quot; but the task resembles statistical inference (e.g., which shape generated the data) or perceptual judgment. This is a minor point since &quot;decision-making&quot; is not well defined in the literature, yet the current framing in the title gave me the initial impression that humans would be making preference choices and learning about them over time with feedback.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.109113.1.sa2</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This manuscript presents a sophisticated investigation into the computational mechanisms underlying human decision-making, and it presents evidence for a preference for simpler explanations (Occam's razor). The authors dissect the simplicity bias into four different components, and they design experiments to target each of them by presenting choices whose underlying models differ only in one of these components. In the learning tasks, participants must infer a &quot;law&quot; (a logical rule) from observed data in a way that operationalizes the process of scientific reasoning in a controlled laboratory setting. The tasks are complex enough to be engaging but simple enough to allow for precise computational modeling.</p>
<p>As a further novel feature, authors derive a further term in the expansion of the log-evidence, which arises from boundary terms. This is combined with a choice model, which is the one that is tested in experiments. Experiments are run, but with humans and with artificial intelligence agents, showing that humans have an enhanced preference for simplicity as compared to artificial neural networks.</p>
<p>Overall, the work is well written, interesting, and timely, bridging concepts in statistical inference and human decision making. Although technical details are rather elaborate, my understanding is that they represent the state of the art.</p>
<p>I have only one main comment that I think deserves more comments. Computing the complexity penalty of models may be hard. It is unlikely that humans can perform such a calculation on the fly. As authors discuss in the final section, while the dimensionality term may be easier to compute, others (e.g., the volume term, which requires an integral) may be considerably harder to compute (it is true that they should be computed once and for all for each task, but still...). I wonder whether the sensitivity of human decision making with reference to the different terms is so different, and in particular whether it aligns with computational simplicity, or with the possibility of approximating each term by simple heuristics. Indeed, the sensitivity to the volume term is significantly and systematically lower than that of other terms. I wonder whether this relation could be made more quantitative using neural networks, using as a proxy of computational hardness the number of samples needed to reach a given error level in learning each of these terms.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.109113.1.sa1</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This is a very interesting paper that documents how humans use a variety of factors that penalize model complexity and integrate over a possible set of parameters within each model. By comparison, trained neural networks also use these biases, but only on tasks where model selection was part of the reward structure. In the situation where training emphasizes maximum-likelihood decisions, only neural networks, but not humans, were able to adapt their decision-making. Humans continue to use model integration simplicity biases.</p>
<p>Strengths:</p>
<p>This study used a pre-registered plan for analyzing human data, which exceeds the standards compared to other current studies.</p>
<p>The results are technically correct.</p>
<p>Weaknesses:</p>
<p>The presentation of the results could be improved.</p>
</body>
</sub-article>
<sub-article id="sa4" article-type="author-comment">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.109113.1.sa0</article-id>
<title-group>
<article-title>Author response:</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Piasini</surname>
<given-names>Eugenio</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0384-7699</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Liu</surname>
<given-names>Shuze</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3946-5003</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Chaudhari</surname>
<given-names>Pratik</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4590-1956</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Balasubramanian</surname>
<given-names>Vijay</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6497-3819</contrib-id></contrib>
<contrib contrib-type="author">
<name>
<surname>Gold</surname>
<given-names>Joshua I</given-names>
</name>
<role specific-use="author">Author</role>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-6018-0483</contrib-id></contrib>
</contrib-group>
</front-stub>
<body>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #1 (Public review)</bold></p>
<p>I have to preface my evaluation with a disclosure that I lack the mathematical expertise to fully assess what seems to be the authors' main theoretical contribution. I am providing this assessment to the best of my ability, but I cannot substitute for a reviewer with more advanced mathematical/physical training.</p>
<p>Summary:</p>
<p>This paper describes a new theoretical framework for measuring parsimony preferences in human judgments. The authors derive four metrics that they associate with parsimony (dimensionality, boundary, volume, and robustness) and measure whether human adults are sensitive to these metrics. In two tasks, adults had to choose one of two flower beds which a statistical sample was generated from, with or without explicit instruction to choose the flower bed perceptually closest to the sample. The authors conduct extensive statistical analyses showing that humans are sensitive to most of the derived quantities, even when the instructions encouraged participants to choose only based on perceptual distance. The authors complement their study with a computational neural network model that learns to make judgments about the same stimuli with feedback. They show that the computational model is sensitive to the tasks communicated by feedback and only uses the parsimony-associated metrics when feedback trains it to do so.</p>
<p>Strengths:</p>
<p>(1)  The paper derives and applies new mathematical quantities associated with parsimony. The mathematical rigor is very impressive and is much more extensive than in most other work in the field, where studies often adopt only one metric (such as the number of causes or parameters). These formal metrics can be very useful for the field.</p>
<p>(2)  The studies are preregistered, and the statistical analyses are strong.</p>
<p>(3)  The computational model complements the behavioral findings, showing that the derived quantities are not simply equivalent to maximum-likelihood inference in the task.</p>
<p>(4)  The speculations in the discussion section (e.g., the idea that human sensitivity is driven by the computational demands each metric requires) are intriguing and could usefully guide future work.</p>
<p>Weaknesses:</p>
<p>(1) The paper is very hard to understand. Many of the key details of the derived metrics are in the appendix, with very little accessible explanation in the main text. The figures helped me understand the metrics somewhat, although I am still not sure how some of them (such as boundary or robustness as measured here) are linked to parsimony. I understand that this is addressed by the derivations in the appendix, but as a computational cognitive scientist, I would have benefited from more accessible explanations. Important aspects of the human studies are also missing from the main text, such as the sample size for Experiment 2.</p>
<p>(2) It is not fully clear whether the sensitivity of human participants to some of the quantities convincingly reported here actually means that participants preferred shapes according to the corresponding aspect of parsimony. The title and framing suggest that parsimony &quot;guides&quot; human decision-making, which may lead readers to conclude that humans prefer more parsimonious shapes. I am not sure the sensitivity findings alone support this framing, but it might just be my misunderstanding of the analyses.</p>
<p>(3) The stimulus set included only four combinations of shapes, each designed to diagnostically target one of the theoretical quantities. It is unclear whether the results are robust or specific to these particular 4 stimuli.</p>
<p>(4) The study is framed as measuring &quot;decision-making,&quot; but the task resembles statistical inference (e.g., which shape generated the data) or perceptual judgment. This is a minor point since &quot;decision-making&quot; is not well defined in the literature, yet the current framing in the title gave me the initial impression that humans would be making preference choices and learning about them over time with feedback.</p>
</disp-quote>
<p>We are grateful for the supportive comments highlighting the rigor of our experimental design and data analysis. The Reviewer lists four points under “weaknesses”, to which we reply below.</p>
<p>(1)  The paper is very hard to understand</p>
<p>In the revised version of the paper, we will expand the main text to include a more detailed and intuitive description of the terms of the Fisher Information Approximation, in particular clarifying the interpretation of robustness and boundary as parsimony. We also will include more details that are now given only in Methods, such as the sample size for the second experiment.</p>
<p>(2) Sensitivity of human participants</p>
<p>We do argue, and believe, that our data show that people tend to prefer simpler shapes. However, giving a well-posed definition of &quot;preference&quot; in this context turns out to be nontrivial.</p>
<p>At the very least, any statement such as &quot;people prefer shape A over B&quot; should be qualified with something like “when the distance of the data from both shapes is the same.” In other words, one should control for goodness-of-fit. Even before making any reference to our behavioral model, this phenomenon (a preference for the simpler model when goodness of fit is matched between models) is visible in Figure 3a, where the effective decision boundary used by human participants is closer to the more complex model than the cyan line representing the locus of points with equal goodness of fit under the two models (or equivalently, with the same Euclidean distance from the two shapes). The goal of our theory and our behavioral model is precisely to systematize this sort of control, extending it beyond just goodness-of-fit and allowing us to control simultaneously for multiple features of model complexity that may affect human behavior in different ways. In other words, it allows us not only to ask whether people prefer shape A over B after controlling for the distance of the data to the shapes, but also to understand to what extent this preference is driven by important geometrical features such as dimensionality, volume, curvature, and boundaries of the shapes. More specifically, and importantly, our theory makes it possible to measure the strength of the preference, rather than merely asserting its existence. In our modeling framework, the existence of a preference for simpler shapes is captured by the fact that the estimated sensitivities to the complexity penalties are positive (and although they differ in magnitude, all are statistically reliable).</p>
<p>(3) Generalization to different shapes</p>
<p>Thank you for bringing up this important topic. First, note that while dimensionality and volume are global properties of models and only take two possible values in our human tasks, the boundary and robustness penalties depend on the model and on the data and therefore assume a continuum of values through the tasks (note also that the boundary penalty is relevant for all task types, not just the one designed specifically to study it, because all models except the zero-dimensional dot have boundaries). Therefore, our experimental setting is less restrictive of what it may seem, because it explores a range of possible values for two of the four model features. However, we agree that it would be interesting to repeat our experiment with a broader range of models, perhaps allowing their dimensionality and volume to vary more. In the same spirit, it would be interesting to study the dependence of human behavior on the amount of available data. We believe that these are all excellent ideas for further study that exceed the scope of the present paper. We will include these important points in a revised Discussion.</p>
<p>(4) Usage of “decision making” vs “perceptual judgment”</p>
<p>Thank you. We will clarify better in the text that our usage of “decision making” overlaps with the idea of a perceptual judgment and that our experiments do not tackle sequential aspects of repeated decisions.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #2 (Public review):</bold></p>
<p>This manuscript presents a sophisticated investigation into the computational mechanisms underlying human decision-making, and it presents evidence for a preference for simpler explanations (Occam's razor). The authors dissect the simplicity bias into four different components, and they design experiments to target each of them by presenting choices whose underlying models differ only in one of these components. In the learning tasks, participants must infer a &quot;law&quot; (a logical rule) from observed data in a way that operationalizes the process of scientific reasoning in a controlled laboratory setting. The tasks are complex enough to be engaging but simple enough to allow for precise computational modeling.</p>
<p>As a further novel feature, authors derive a further term in the expansion of the logevidence, which arises from boundary terms. This is combined with a choice model, which is the one that is tested in experiments. Experiments are run, but with humans and with artificial intelligence agents, showing that humans have an enhanced preference for simplicity as compared to artificial neural networks.</p>
<p>Overall, the work is well written, interesting, and timely, bridging concepts in statistical inference and human decision making. Although technical details are rather elaborate, my understanding is that they represent the state of the art.</p>
<p>I have only one main comment that I think deserves more comments. Computing the complexity penalty of models may be hard. It is unlikely that humans can perform such a calculation on the fly. As authors discuss in the final section, while the dimensionality term may be easier to compute, others (e.g., the volume term, which requires an integral) may be considerably harder to compute (it is true that they should be computed once and for all for each task, but still...). I wonder whether the sensitivity of human decision making with reference to the different terms is so different, and in particular whether it aligns with computational simplicity, or with the possibility of approximating each term by simple heuristics. Indeed, the sensitivity to the volume term is significantly and systematically lower than that of other terms. I wonder whether this relation could be made more quantitative using neural networks, using as a proxy of computational hardness the number of samples needed to reach a given error level in learning each of these terms.</p>
</disp-quote>
<p>Thank you. The computational complexity associated with calculating the different terms and its potential connection to human sensitivity to the terms is an intriguing topic. As we hinted at in the discussion, we agree with the reviewer that this is a natural candidate for further research, which likely deserves its own study and exceeds the scope of the present paper.</p>
<p>As a minor aside, at least for the present task the volume term may not be that hard to compute, because it can be expressed with the number of distinguishable probability distributions in the model (Balasubramanian 1996). Given the nature of our task, where noise is Gaussian, isotropic and with known variance, the geometry of the model is actually the Euclidean geometry of the plane, and the volume is simply the (log of the) length of the line that represents the one-dimensional models, measured in units of the standard deviation of the noise.</p>
<disp-quote content-type="editor-comment">
<p><bold>Reviewer #3 (Public review):</bold></p>
<p>Summary:</p>
<p>This is a very interesting paper that documents how humans use a variety of factors that penalize model complexity and integrate over a possible set of parameters within each model. By comparison, trained neural networks also use these biases, but only on tasks where model selection was part of the reward structure. In the situation where training emphasizes maximum-likelihood decisions, only neural networks, but not humans, were able to adapt their decision-making. Humans continue to use model integration simplicity biases.</p>
<p>Strengths:</p>
<p>This study used a pre-registered plan for analyzing human data, which exceeds the standards compared to other current studies.</p>
<p>The results are technically correct.</p>
<p>Weaknesses:</p>
<p>The presentation of the results could be improved.</p>
</disp-quote>
<p>We thank the reviewer for their appreciation of our experimental design and methodology, and for pointing out (in the separate &quot;recommendations to authors&quot;) a few passages of the paper where the presentation could be improved. We will clarify these passages in the revision.</p>
</body>
</sub-article>
</article>