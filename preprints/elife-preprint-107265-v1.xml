<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">107265</article-id>
<article-id pub-id-type="doi">10.7554/eLife.107265</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.107265.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories><title-group>
<article-title>Spatial learning in multi-scale environments: Roles of hippocampus, orbitofrontal cortex, and retrosplenial cortex</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Qiu</surname>
<given-names>Yidan</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">¶</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes">
<name>
<surname>Zheng</surname>
<given-names>Senning</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="author-notes" rid="n1">¶</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Li</surname>
<given-names>Huakang</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Lin</surname>
<given-names>Shuting</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">https://orcid.org/0000-0003-3889-169X</contrib-id>
<name>
<surname>Huang</surname>
<given-names>Ruiwang</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<email>ruiwang.huang@gmail.com</email>
</contrib>
<aff id="a1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01kq0pv72</institution-id><institution>School of Psychology, Center for Studies of Psychological Application, Guangdong Key Laboratory of Mental Health and Cognitive Science, South China Normal University</institution></institution-wrap>, <city>Guangzhou</city>, <country country="CN">China</country></aff>
<aff id="a2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02vj1vm13</institution-id><institution>School of Education and Psychology, Institute of Applied Psychology, Fujian Province, Key Laboratory of Applied Cognition and Personality, Minnan Normal University</institution></institution-wrap>, <city>Zhangzhou</city>, <country country="CN">China</country></aff>
<aff id="a3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0530pts50</institution-id><institution>School of Computer Science and Engineering, South China University of Technology</institution></institution-wrap>, <city>Guangzhou</city>, <country country="CN">China</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Kahnt</surname>
<given-names>Thorsten</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/00fq5cm18</institution-id>
<institution>National Institute on Drug Abuse Intramural Research Program</institution>
</institution-wrap>
<city>Baltimore</city>
<country country="US">United States</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Frank</surname>
<given-names>Michael J</given-names>
</name>
<contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8451-0523</contrib-id>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id>
<institution>Brown University</institution>
</institution-wrap>
<city>Providence</city>
<country country="US">United States</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="equal"><label>¶</label><p>equal contribution</p></fn>
<fn fn-type="coi-statement"><p>Competing interests: No competing interests declared</p></fn>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2025-12-29">
<day>29</day>
<month>12</month>
<year>2025</year>
</pub-date>
<volume>14</volume>
<elocation-id>RP107265</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2025-10-20">
<day>20</day>
<month>10</month>
<year>2025</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2025-10-21">
<day>21</day>
<month>10</month>
<year>2025</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.10.20.683540"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2025, Qiu et al</copyright-statement>
<copyright-year>2025</copyright-year>
<copyright-holder>Qiu et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-107265-v1.pdf"/>
<abstract>
<p>Navigation cognition involves the learning of multi-scale environments and the formation of cognitive maps. How do humans build cognitive maps in multi-scale environments? Cognitive maps are thought to be organized hierarchically, with local representations for subareas and global representations for the entire environment. However, it remains unclear how spatial learning influences the representations of multi-scale environments and their underlying neural mechanisms across different levels of representation. In the current study, we built a virtual environment (VE) with four orthogonally positioned rectangular rooms, each containing eight objects at the corners. Twenty-three healthy subjects completed a four-session spatial memory experiment conducted over two weeks. We measured their brain activity by using BOLD-fMRI at two stages: pre-learning stage and post-learning, when they were judging the relative direction between the objects within the VE. We found that with the progression of learning, the subjects shifted from relying on local, directional cues to using more global representations of the environment. At the neural level, the hippocampus (HIP), retrosplenial cortex (RSC), and orbitofrontal cortex (OFC) played distinct roles in encoding spatial information across the two learning stages. Specifically, after learning, the HIP shifted from local to global representations, while the RSC and OFC supported the integration of spatial information across these representational levels. In addition, the anterior cingulate cortex was involved in forming global representations, facilitating efficient spatial processing as learning advanced. These findings revealed how spatial learning leads to adaptive shifts in brain activity, contributing to the formation of cognitive maps in complex, multi-scale environments.</p>
</abstract>
<abstract abstract-type="summary">
<title>Highlights</title>
<list list-type="bullet">
<list-item><p>Using fMRI to study neural mechanisms of cognitive map formation in a multi-scale environment.</p></list-item>
<list-item><p>Detected that local and global spatial representations coexist and evolve during spatial learning.</p></list-item>
<list-item><p>Found that learning progress is associated with activation changes in the entorhinal cortex, hippocampus, and retrosplenial cortex.</p></list-item>
<list-item><p>Revealed the complementary roles of hippocampus and orbitofrontal cortex in representing the environment.</p></list-item>
<list-item><p>Showed that the retrosplenial cortex improves both local and global representations, supporting the integration of multi-scale spatial information.</p></list-item>
</list>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>spatial navigation</kwd>
<kwd>reference frame (RF)</kwd>
<kwd>multi-scale environment</kwd>
<kwd>hierarchical representation</kwd>
<kwd>map-like representation</kwd>
</kwd-group>
<funding-group>
<award-group id="par-1">
<funding-source>
<institution-wrap>
<institution>Key Technologies P&amp;D Program of Guangdong Province</institution>
</institution-wrap>
</funding-source>
<award-id>2023B0303020002</award-id>
<principal-award-recipient>
<name>
<surname>Huang</surname>
<given-names>Ruiwang</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="par-2">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id>
<institution>MOST | National Natural Science Foundation of China (NSFC)</institution>
</institution-wrap>
</funding-source>
<award-id>32371101</award-id>
<principal-award-recipient>
<name>
<surname>Huang</surname>
<given-names>Ruiwang</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="par-3">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id>
<institution>MOST | National Natural Science Foundation of China (NSFC)</institution>
</institution-wrap>
</funding-source>
<award-id>82171914</award-id>
<principal-award-recipient>
<name>
<surname>Huang</surname>
<given-names>Ruiwang</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="par-4">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100012166</institution-id>
<institution>MOST | National Key Research and Development Program of China (NKPs)</institution>
</institution-wrap>
</funding-source>
<award-id>2018YFC1705006</award-id>
<principal-award-recipient>
<name>
<surname>Huang</surname>
<given-names>Ruiwang</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="par-5">
<funding-source>
<institution-wrap>
<institution>SIH key discipline for psychology in South China Normal University</institution>
</institution-wrap>
</funding-source>
<principal-award-recipient>
<name>
<surname>Huang</surname>
<given-names>Ruiwang</given-names>
</name>
</principal-award-recipient>
</award-group>
</funding-group>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="s1">
<label>1.</label>
<title>Introduction</title>
<p>Imagine navigating a large amusement park with various themed areas, each containing different rides and attractions. To get around, you need to understand both the layout within each area (i.e., local reference frame, RF) and the connections between the areas across the entire park (i.e., global RF). This navigational ability relies on cognitive maps, which are mental representations of spatial environments that help us to know where we are, to plan routes, and to make navigation decisions <sup><xref ref-type="bibr" rid="c1">1</xref>,<xref ref-type="bibr" rid="c2">2</xref></sup>. Cognitive maps are essential for navigating complex environments with multiple subareas and landmarks, as they integrate information across RFs <sup><xref ref-type="bibr" rid="c3">3</xref>,<xref ref-type="bibr" rid="c4">4</xref></sup>. Beyond navigation, cognitive maps support broader cognitive functions such as episodic memory and decision-making <sup><xref ref-type="bibr" rid="c5">5</xref>,<xref ref-type="bibr" rid="c6">6</xref></sup>, enabling efficient inferences from limited experience, guiding novel decisions, and supporting flexible behavior <sup><xref ref-type="bibr" rid="c4">4</xref></sup>.</p>
<p>How are cognitive maps organized in multi-scale environments? This issue has been studied using behavioral <sup><xref ref-type="bibr" rid="c7">7</xref>–<xref ref-type="bibr" rid="c9">9</xref></sup> and neuroimaging <sup><xref ref-type="bibr" rid="c10">10</xref>–<xref ref-type="bibr" rid="c12">12</xref></sup> experiments. A widely accepted framework is that cognitive maps are structured hierarchically in multi-scale environments, with three levels of representation: local, categorical, and global <sup><xref ref-type="bibr" rid="c13">13</xref>–<xref ref-type="bibr" rid="c15">15</xref></sup>. Local representations capture spatial relationships within smaller areas (e.g., individual rooms), enabling navigation within specific areas <sup><xref ref-type="bibr" rid="c13">13</xref>,<xref ref-type="bibr" rid="c16">16</xref></sup>. Categorical representations can distinguish boundaries and characteristics between areas, supporting transitions across different areas <sup><xref ref-type="bibr" rid="c17">17</xref></sup>. Global representations provide a unified view of the entire environment, using global coordinates to represent spatial relationships across all areas, thus facilitating flexible navigation <sup><xref ref-type="bibr" rid="c17">17</xref>–<xref ref-type="bibr" rid="c19">19</xref></sup>. The organization of cognitive maps is influenced by learning <sup><xref ref-type="bibr" rid="c16">16</xref>,<xref ref-type="bibr" rid="c20">20</xref></sup>. Some studies <sup><xref ref-type="bibr" rid="c21">21</xref>,<xref ref-type="bibr" rid="c22">22</xref></sup> suggested that individuals initially rely on local representations, gradually incorporating local spatial information into a global framework. Conversely, other studies <sup><xref ref-type="bibr" rid="c23">23</xref>,<xref ref-type="bibr" rid="c24">24</xref></sup> proposed that global representations are build first, and are then refined into hierarchical structures to capture detailed local relationships. Based on the hierarchical organization framework, the current study aims to reveal how spatial learning influences the development and integration of local and global representations.</p>
<p>How does the brain support the formation of cognitive maps in multi-scale environments? Previous studies <sup><xref ref-type="bibr" rid="c1">1</xref>,<xref ref-type="bibr" rid="c25">25</xref>,<xref ref-type="bibr" rid="c26">26</xref></sup> identified several brain regions involving in spatial representation, such as the hippocampus (HIP), entorhinal cortex (EC), orbitofrontal cortex (OFC), and retrosplenial cortex (RSC). Specifically, the HIP is essential for encoding memory, spatial distances, and location information, particularly through place cells <sup><xref ref-type="bibr" rid="c24">24</xref>,<xref ref-type="bibr" rid="c27">27</xref>,<xref ref-type="bibr" rid="c28">28</xref></sup>. The EC is critical for providing a coordinate system through grid cells, which helps in the formation of cognitive maps <sup><xref ref-type="bibr" rid="c2">2</xref>,<xref ref-type="bibr" rid="c6">6</xref></sup>. Together, the HIP and EC support the spatial coding necessary for navigation and cognitive mapping <sup><xref ref-type="bibr" rid="c25">25</xref>,<xref ref-type="bibr" rid="c29">29</xref></sup>. The OFC is believed involving in cognitive mapping to support flexible decision-making, particularly when tasks require integrating local and global information <sup><xref ref-type="bibr" rid="c30">30</xref>,<xref ref-type="bibr" rid="c31">31</xref></sup>. The OFC is also engaged in planning routes during navigation <sup><xref ref-type="bibr" rid="c29">29</xref></sup>. The RSC is involved in anchoring cognitive maps to the environment and integrating different perspectives for a location <sup><xref ref-type="bibr" rid="c25">25</xref>,<xref ref-type="bibr" rid="c32">32</xref></sup>. Moreover, the RSC has been found to represent location and facing direction in multi-scale environments <sup><xref ref-type="bibr" rid="c33">33</xref></sup>, suggesting its role in linking local and global RFs. Collectively, these regions are involved in building cognitive maps of novel environments <sup><xref ref-type="bibr" rid="c34">34</xref>,<xref ref-type="bibr" rid="c35">35</xref></sup>.</p>
<p>The present study aimed to understand how cognitive maps are built and updated during spatial learning in multi-scale environments. Following the paradigm of Marchette et al. <sup><xref ref-type="bibr" rid="c33">33</xref></sup>, we invited young adult healthy subjects to perform a judgement of direction (JRD) task in a virtual environment containing subareas (<xref rid="fig1" ref-type="fig">Fig. 1</xref>), requiring the subjects to integrate local, categorical, and global RFs. We hypothesized that as learning progresses, the subjects would shift from relying on local to more global spatial representations, with corresponding changes in brain activity across key regions such as the RSC, HIP, EC, and OFC. To track the updating of cognitive maps, we extended this approach with a multi-stage learning design, incorporating two task-fMRI sessions: a pre-learning stage and a post-learning stage (after extensive learning). This design allowed us to examine the changes in both behavior and brain activity as the subjects became familiar with the environment. In the behavioral analysis, we examined the influence of different levels of spatial information on task performance across the two learning stages, revealing how reliance on local, categorical, and global representations evolved. In the fMRI analysis, we identified the roles of key brain regions, including the RSC, HIP, EC, and OFC, in supporting local and global representations during learning. Our study provides new insights into the neural mechanisms underlying cognitive maps and the interaction between hierarchical and map-like representations in complex environments.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Fig. 1.</label>
<caption><title>Overview of the experimental tasks.</title>
<p><bold>(a)</bold> Virtual environment (VE). (Left) An aerial view of the park with four rooms, R1-R4, arranged orthogonally. (Middle) Subject’s perspective at the entrance and center of the VE. (Right) Subject’s perspective from outside and inside the rooms. The directions N, E, S, and W represent north, east, south, and west, respectively. <bold>(b)</bold> Experimental timeline. The experiment was conducted over 4 non-consecutive days. The intervals between each behavioral training and fMRI sessions was ≤ 2 days, while the interval between the 1<sup>st</sup> fMRI scan session and the 2<sup>nd</sup> behavioral training session was ≤ 8 days. RA = response accuracy. <bold>(c)</bold> Object familiarization task. Subjects learned about the objects used in the VE through an object learning phase and an object memory test. <bold>(d)</bold> Exploration task. Subjects freely explored the VE to learn its layout and object locations. <bold>(e)</bold> Object finding task. Subjects were instructed to locate specific objects within the VE. <bold>(f)</bold> Judgment of relative direction (JRD) task. Subjects judged the direction of one object relative to another. The blue icons indicate the tasks being conducted outside the scanner, and the green icon indicates a task being conducted inside the scanner.</p></caption>
<graphic xlink:href="683540v1_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2">
<label>2.</label>
<title>Methods</title>
<sec id="s2a">
<label>2.1</label>
<title>Subjects</title>
<p>Twenty-five healthy adults initially enrolled in a 4-day spatial memory experiment (<xref rid="fig1" ref-type="fig">Fig. 1</xref>). One subject withdrew from the study, and another did not meet the required accuracy threshold in the second behavioral training session, resulting in a final sample of 23 subjects (11 F/12 M; mean age = 21.61 years old, range = 18-25 years old). All of the subjects had normal or corrected-to-normal vision and no history of neurological or psychiatric disorders. The study was approved by the Institutional Review Board (IRB) of South China Normal University (SCNU). Written informed consent was obtained from all subjects prior to the experiment, and they were compensated for their participation.</p>
</sec>
<sec id="s2b">
<label>2.2</label>
<title>Stimuli</title>
<p>A virtual environment (VE) was created using the Source SDK Hammer Editor implemented in <italic>Counter-Strike</italic> (<ext-link ext-link-type="uri" xlink:href="https://www.counter-strike.net/workshop/workshop">https://www.counter-strike.net/workshop/workshop</ext-link>). <xref rid="fig1" ref-type="fig">Fig. 1a</xref> shows that the VE consisted of a park with four rectangular rooms positioned in the north, east, south, and west. Each room contained eight objects (two objects in each corner), for a total of 32 objects in the four rooms. The objects were of four types, animals, plants, vehicles, and furniture, each type including eight objects. The placement of objects was randomized, and the objects of different types were evenly distributed across the four rooms to minimize memory effects based on the object types. No two objects of the same type were placed in similar locations across different rooms. According to the spatial scales, we defined (1) a global RF for the entire park based on the cardinal directions, and (2) a local RF for each room based on the positions relative to specific landmarks (door, opposite wall, left, or right) (<xref rid="fig2" ref-type="fig">Fig. 2</xref>). Thereby, the VE involves three hierarchical levels (<xref rid="fig2" ref-type="fig">Fig. 2</xref>): (1) local level, which represents the spatial relationships between objects within a room based on the local RF, (2) categorical level, which represents the rooms as separate spatial units, and (3) global level, which represents the spatial layout of the entire park using the global RF.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Fig. 2.</label>
<caption><title>Illustration of the relationships among the three hierarchical levels, reference frames (RFs), and the learning process in the experiment.</title>
<p>The local level of the environment captures spatial relationships between the objects within each room, based on the local RF. After learning, the subjects may strengthen and generalize these relationships to similar spatial structures. The categorical level reflects the semantic distinction between rooms (R1-R4). The global level represents the spatial layout of the entire park using the global RF, with spatial relationships across rooms becoming clearer after learning.</p></caption>
<graphic xlink:href="683540v1_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
</sec>
<sec id="s2c">
<label>2.3</label>
<title>Experimental tasks</title>
<p>Experimental tasks were programmed in E-prime 2.0 (Psychology Software Tools, Pittsburgh, PA, USA).</p>
<sec id="s2c1">
<label>2.3.1</label>
<title>Object familiarization task</title>
<p>The subjects familiarized themselves with the 32 objects by reviewing a document that contained the names and pictures of each object (<xref rid="fig1" ref-type="fig">Fig. 1c</xref>). Once they felt prepared, they were requested to complete a memory test about the objects on a desktop. In each trial of the memory test, the subjects were shown the name of an object and were asked to select the corresponding picture from three options (<xref rid="fig1" ref-type="fig">Fig. 1c</xref>). They were required to achieve accuracy ≥ 95% (i.e., no more than a mistake).</p>
</sec>
<sec id="s2c2">
<label>2.3.2</label>
<title>Exploration task</title>
<p>The subjects moved freely through the rooms and observed the 32 objects to learn their locations in the VE (<xref rid="fig1" ref-type="fig">Fig. 1d</xref>). The subjects controlled the first-place perspective using the mouse and adjusted the movement direction by pressing the arrow keys on the keyboard. They were asked to enter each room at least once. The task lasted approximately 10 minutes.</p>
</sec>
<sec id="s2c3">
<label>2.3.3</label>
<title>Object finding task</title>
<p>The object finding task was conducted on two desktops, one for displaying the target objects (referred to as the “presentation desktop”) and the other for displaying the VE navigation (referred to as the “navigation desktop”). This setup allowed the subjects to view the indicator of target objects and to navigate within the VE simultaneously, without the indicator affecting their perspective.</p>
<p>The task involved the learning of 32 objects, each being presented twice in a pseudo-random order, resulting in a total of 64 trials. In each trial, a picture was shown on the presentation desktop to indicate the object to be located (<xref rid="fig1" ref-type="fig">Fig. 1e</xref>). On the navigation desktop, the subjects used the mouse and keyboard arrow keys to navigate and position themselves in front of the object. Once the subjects reached the object, they pressed the space bar on the presentation desktop to trigger the appearance of the next target object. There was no time limit for the subjects’ responses, allowing them ample time to locate the target object.</p>
<p>These trials were organized into 8 blocks, each block containing 8 trials. In each block, two objects from the same room were presented consecutively, and the order of room presentation was randomized. For example, using A-D to represent the four rooms and 1-8 to represent the 8 objects in each room, a possible trial order in a block could be “A1-A2-C4-C7-D6-D4-B2-B8”. The entire task lasted about 15 minutes. The object finding task was designed to reinforce the subjects’ memory of the object locations, facilitating the acquisition of both the local spatial relationships between the objects within each room and the global relationships between the rooms in the VE.</p>
</sec>
<sec id="s2c4">
<label>2.3.4</label>
<title>Judgement of direction (JRD) task</title>
<p>In the JRD task, the subjects were required to judge the relative directional relationship between two objects within the same room. The task consisted of 64 trials and was conducted only on the presentation desktop. Each trial began with a 1 s fixation cross, followed by the presentation of two object names on the screen. The subjects were asked to imagine themselves standing in front of the first object (the reference object) and to judge whether the second object (the target object) was located to their left or right. They had 4.8 s to respond by pressing either the key of “1” (for left) or “2” (for right) on the keyboard. Both the objects were located in the same room. Additional 16 catch trials were randomly inserted to the JRD task to test whether the subjects were actively retrieving the object locations in the park. In these catch trials, only an object name was shown on the screen and the subjects were asked to identify which room contained the object. They had 4.8 s to respond by pressing either the “1”, “2”, “3”, or “4” key for the four rooms on the keyboard. No feedback was provided during the task.</p>
</sec>
</sec>
<sec id="s2d">
<label>2.4</label>
<title>Experimental procedures</title>
<p><xref rid="fig1" ref-type="fig">Fig. 1b</xref> shows the experimental procedures that were conducted over four sessions in 2 consecutive weeks: (1) the 1<sup>st</sup> behavioral training session, (2) the 1<sup>st</sup> fMRI scan session (pre-learning stage), (3) the 2<sup>nd</sup> behavioral training session, and (4) the 2<sup>nd</sup> fMRI scan session (post-learning stage). The interval between each training and scan sessions was less than 2 days and the interval between the two training sessions was about a week.</p>
<p>In the 1<sup>st</sup> behavioral training session, the subjects first performed the object familiarization task (<xref rid="fig1" ref-type="fig">Fig. 1c</xref>), and then entered the VE for object location learning by completing the exploration task (<xref rid="fig1" ref-type="fig">Fig.1d</xref>) and the object finding task (<xref rid="fig1" ref-type="fig">Fig. 1e</xref>). Next, the subjects performed the JRD task. If their accuracy was &lt; 60%, they repeated the object finding task before performing the JRD task again, until they achieved accuracy ≥ 60% in the JRD task. To prevent ceiling effects, we excluded any subject who achieved accuracy ≥ 70% in JRD task of the 1<sup>st</sup> behavioral training session from further experiments. No subject exceeded this threshold.</p>
<p>The 1<sup>st</sup> fMRI scan session included six runs of the JRD task (<xref rid="fig1" ref-type="fig">Fig. 1f</xref>). Each run consisted of 64 JRD trials and 4 catch trials. Before the fMRI scan, the subjects completed a 5-minute exploration task outside the scanner to consolidate memory of the object locations. Following the method of Marchette et al. <sup><xref ref-type="bibr" rid="c33">33</xref></sup>, we used only the objects from two orthogonally-aligned rooms in the 1<sup>st</sup> fMRI scan session. The objects from the remaining two rooms were reserved for the 2<sup>nd</sup> fMRI scan session. In each fMRI run, the duration of the fixation cross was adjusted to 1.2 s to match the fMRI acquisition timing. The object names were displayed for 4.8 s, which is the response window for both the JRD and catch trials. If the subjects responded within the response window, the trial screen remained on display until the end of the response window. The next trial began immediately after the response window. After the subjects completed each fMRI run, we requested them to report no sleep during the scanning. After the subjects completed the six runs in about 40 min, they took a 10 min break outside of the scanner.</p>
<p>In the 2<sup>nd</sup> behavioral training session, the subjects first performed the object finding task, followed by the JRD task. This process was repeated until their accuracy in the JRD task was increased to at least 90%. In the 2<sup>nd</sup> fMRI scan session, the subjects followed the same procedure as the 1<sup>st</sup> fMRI scan session but the objects come from the remaining two rooms. The subjects first completed a 5-minute exploration task before the fMRI scan, then completed 6 runs of the JRD task during the scan.</p>
</sec>
<sec id="s2e">
<label>2.5</label>
<title>MRI data acquisition</title>
<p>All imaging data were collected on a Siemens Trio 3T MRI scanner equipped with a 32-channel phased-array head/neck coil. The functional MRI (fMRI) data were acquired using a single-shot, simultaneous multi-slice (SMS) gradient-echo echo-planar imaging (EPI) sequence with the following parameters: repetition time (TR) = 1,200 ms, echo time (TE) = 41.6 ms, flip angle = 52°, slice acceleration factor = 5, field of view (FOV) = 211 × 211 mm<sup>2</sup>, data matrix = 88 × 88, slice thickness = 2.4 mm without inter-slice gap, voxel size = (2.4 mm)<sup>3</sup>, anterior-to-posterior phase encoding direction, and 65 transversal slices covering the whole brain. To correct for susceptibility-induced geometric distortions and BOLD signal loss, we also acquired a field map by using a double-echo gradient-echo sequence with TR = 735 ms, TE1/TE2 = 5.04 ms/7.50 ms, flip angle = 60°, FOV = 211 × 211 mm<sup>2</sup>, voxel size = (2.4 mm)<sup>3</sup>, and 65 axial slices. High-resolution anatomical images were obtained using a T1-weighted 3D MP-RAGE sequence with TR = 1,600 ms, TE = 2.98 ms, flip angle = 9°, slice thickness = 1 mm, FOV = 256 × 256 mm<sup>2</sup>, data matrix = 256 × 256, voxel size = (1.0 mm)<sup>3</sup>, and 176 sagittal slices covering the whole brain. For each subject, all the imaging data were obtained in the same session.</p>
<p>During the fMRI scan, the subjects viewed the stimuli on a screen via a mirror mounted on the head coil. Behavioral responses were recorded using a 4-button bimanual response box. Foam padding was used to minimize head movement, and earplugs were provided to reduce acoustic noise. To enhance BOLD signal quality in the OFC and temporal cortex, each subject’s head was tilted backward at an angle of 15-30° by placing a towel under the neck during scanning <sup><xref ref-type="bibr" rid="c36">36</xref></sup>. The MRI data were preprocessed using fMRIPrep 20.2.7 <sup><xref ref-type="bibr" rid="c37">37</xref></sup>. The detailed pre-processing procedure is described in Supplementary Materials.</p>
</sec>
<sec id="s2f">
<label>2.6</label>
<title>Definition of the regions of interest (ROIs)</title>
<p>We selected eight ROIs, including the bilateral HIP, EC, OFC, and RSC. The HIP was defined according to the Harvard-Oxford subcortical structural atlas <sup><xref ref-type="bibr" rid="c38">38</xref></sup> with a probability ≥ 50%. The EC was defined according to the Juelich Histological Atlas <sup><xref ref-type="bibr" rid="c39">39</xref></sup>, also with a probability ≥ 50%. The OFC was defined according to the Brainnetome Atlas <sup><xref ref-type="bibr" rid="c40">40</xref></sup>, which provides a fine-grained parcellation based on functional and structural connectivity. The RSC was defined as Brodmann’s Areas (BA) 29 and 30 within the posterior cingulate cortex (PCC) <sup><xref ref-type="bibr" rid="c41">41</xref></sup>. We also selected the bilateral primary motor cortex (M1) as the control ROIs. The M1 was defined according to the Juelich Histological Atlas <sup><xref ref-type="bibr" rid="c39">39</xref></sup> with a probability ≥ 50%.</p>
</sec>
<sec id="s2g">
<label>2.7</label>
<title>Linear mixed-effects model (LMM) for behavior analysis</title>
<p>Linear mixed-effects models were used to assess how spatial information influenced subjects’ response time (RT) across two different learning stages. Specifically, we built two candidate models, LMM1 and LMM2, by using the same fixed-effect terms. Their difference was that LMM1 (<xref ref-type="disp-formula" rid="eqn1">Eq. 1</xref>) did not include the learning stage as a random effect, while LMM2 (<xref ref-type="disp-formula" rid="eqn2">Eq. 2</xref>) included it as a random effect.
<disp-formula id="eqn1">
<graphic xlink:href="683540v1_eqn1.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
<disp-formula id="eqn2">
<graphic xlink:href="683540v1_eqn2.gif" mimetype="image" mime-subtype="gif"/>
</disp-formula>
where <italic>Learning</italic> is a categorical variable denoting the two learning stages (i.e., the pre-learning and post-learning stages). <italic>ED</italic><sub><italic>ref-tar</italic></sub> is Euclidean distance between the reference (<italic>ref</italic>) and the target (<italic>tar</italic>) objects (<xref ref-type="supplementary-material" rid="supp1">Fig. S1 in Supplementary Materials</xref>). Because the reference object and the target object were in the same room in all of the trials, the <italic>ED</italic><sub><italic>ref-tar</italic></sub> is the same under the local and global RFs. <inline-formula id="inline-eqn-1"><inline-graphic xlink:href="683540v1_inline1.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula id="inline-eqn-2"><inline-graphic xlink:href="683540v1_inline2.gif" mimetype="image" mime-subtype="gif"/></inline-formula> are categorical variables representing the 4 possible directions (north, east, south, and west), denoting the global (<italic>glo</italic>) or local (<italic>loc</italic>) facing directions of the reference (<italic>ref</italic>) or target (<italic>tar</italic>) objects (<xref ref-type="supplementary-material" rid="supp1">Fig. S1 in Supplementary Materials</xref>). Because only two orthogonally-aligned rooms were included in each of the fMRI sessions, we set the <italic>Room</italic> variable as a binary factor, indicating whether the room was aligned along the north-south or east-west axis. <italic>Learning</italic> × (·) denotes the interaction between the learning stage and other variables, (1| <italic>Subject</italic>) in Eq.1 denotes the random intercept for each subject, and (1+ <italic>Learning</italic> | <italic>Subject</italic>) in Eq.2 represents the random intercept and the random slope for the learning stage within each subject.</p>
<p>All the LMMs were conducted using the lme4 package in <italic>R</italic> <sup><xref ref-type="bibr" rid="c42">42</xref></sup>. The values of RT were log-transformed prior to modeling to meet the assumption of normality. The models were compared using the Akaike Information Criterion (<italic>AIC</italic>), with lower <italic>AIC</italic> values indicating better model fit.</p>
</sec>
<sec id="s2h">
<label>2.8</label>
<title>General linear model (GLM) for fMRI data</title>
<p>We conducted both the ROI-based and whole-brain voxel-wise GLM analyses to identify brain regions involving in the JRD task. The GLM analyses were carried out with FSL (version 6.0.5.1). At the subject-level, the GLM included three regressors: (1) the JRD trials, (2) a parametric modulator for the <italic>ED</italic><sub><italic>ref-tar</italic></sub>, and (3) catch trials. In addition, six nuisance regressors for head motion parameters (three translations and three rotations) were included to control for motion-related artifacts. For each subject, we estimated the <italic>β</italic>-values associated with the JRD trials and the <italic>ED</italic><sub><italic>ref-tar</italic></sub>.</p>
<p>At the group-level, we performed a random-effects analysis to assess the effects of the JRD trials and the <italic>ED</italic><sub><italic>ref-tar</italic></sub> on brain activation across both learning sessions. Gender and age were included as covariates to control for potential demographic effects. Specifically, we conducted an ROI-based analysis to evaluate activation patterns related to the JRD trials and the influence of <italic>ED</italic><sub><italic>ref-tar</italic></sub> within the pre-defined brain regions. A paired-sample <italic>t</italic>-tests was used to examine the differences in brain activation between the pre- and post-learning stages for the JRD trials and the <italic>ED</italic><sub><italic>ref-tar</italic></sub> separately. In addition, we also performed the voxel-wise GLM analysis in the whole-brain to identify other brain regions with differential activation between the two stages.</p>
<p>A brain-behavior correlation analysis was performed to examine the relationship between brain activation during the JRD task and individual differences in the learning process. For brain functional data, we first created spherical masks with a radius of 4 mm centered at the peak coordinates of significant clusters identified in the ROI-based GLM analysis. From these masks, we extracted the average <italic>β</italic>-values associated with the JRD trials and the <italic>ED</italic><sub><italic>ref-tar</italic></sub> from the subject-level GLM. For behavioral data, we extracted the random slopes for the leaning stage (denoted as <italic>η</italic>-values) from the LMM with lower <italic>AIC</italic> value for each subject. These <italic>η</italic>-values represent the effect of the learning stage on RT for each individual, capturing variability in learning effects across the subjects. Finally, we calculated Pearson’s correlation between the <italic>η</italic>-values and the extracted <italic>β</italic>-values.</p>
</sec>
<sec id="s2i">
<label>2.9</label>
<title>Representational similarity analysis (RSA) for fMRI data</title>
<p>We performed RSA to determine whether brain regions encoded the local and global RFs at different learning stages (<xref rid="fig2" ref-type="fig">Fig. 2</xref>). The RSA was conducted using python packages, including NiBabel and SciPy. For each subject, two theoretical representational dissimilarity matrices (RDMs) were built to capture the spatial relationships of the reference objects at the local and global RFs during each learning stage (<xref rid="fig4" ref-type="fig">Fig. 4a</xref>). Because each room contained 8 objects and each learning stage used two rooms (containing 16 objects in total), the theoretical RDMs were 16 × 16 matrices. To build the local RDM, we aligned the four rooms within the VE according to their local spatial structures, i.e., rotating the rooms to unify the orientation of the doors and stacking them (<xref rid="fig4" ref-type="fig">Fig. 4a</xref>). Then, we computed the Euclidean distance between the 16 reference objects under the local RF <inline-formula id="inline-eqn-3"><inline-graphic xlink:href="683540v1_inline3.gif" mimetype="image" mime-subtype="gif"/></inline-formula> to capture their spatial relationships in a localized context, regardless of the room’s global orientation. In contrast, the global RDM was built to capture spatial relationships of the objects across the entire VE by using the Euclidean distance between the global coordinates of the 16 reference objects <inline-formula id="inline-eqn-4"><inline-graphic xlink:href="683540v1_inline4.gif" mimetype="image" mime-subtype="gif"/></inline-formula> (<xref rid="fig4" ref-type="fig">Fig. 4a</xref>). We also built a categorical RDM to capture whether the objects were located in the same room or not (<xref ref-type="supplementary-material" rid="supp1">Fig. S2 in Supplementary Materials</xref>). The objects in the same room were defined as similar, and the objects in different rooms were considered dissimilar. However, due to the high inherent similarity between the global and categorical RDMs, we chose to exclude the categorical RDM from subsequent RSA.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Fig. 3.</label>
<caption><title>Behavioral performance and brain activation in the judgement of relative direction (JRD) task.</title>
<p><bold>(a)</bold> Interaction between spatial information and learning stage on response time (RT). <italic>ED</italic><sub><italic>ref-tar</italic></sub> represents the Euclidean distance between the reference and target objects, which was divided into four equal bins based on the quartiles of the distance distribution for ease of visualization. Bin1, Bin2, Bin3, and Bin4 represent increasing distances from closest to furthest. <inline-formula id="inline-eqn-5"><inline-graphic mime-subtype="gif" mimetype="image" xlink:href="683540v1_inline23.gif"/></inline-formula> represent the local directions of a reference object. Because only two orthogonally-aligned rooms were included in each fMRI session, we set the <italic>Room</italic> variable as a binary factor, indicating whether the room was aligned along the north-south or east-west axis. <inline-formula id="inline-eqn-6"><inline-graphic mime-subtype="gif" mimetype="image" xlink:href="683540v1_inline24.gif"/></inline-formula> represent the global direction of a reference object. The boxplots indicate the interquartile range (IQR), with horizontal lines within the boxes representing the median, whiskers extending to 1.5 times the IQR, and dots showing outliers beyond 1.5 times the IQR. Asterisks above each learning session denote the main effect of spatial information, and asterisks across learning stages indicate interaction effects between learning stage and spatial information. *, <italic>p</italic> &lt; .05, **, <italic>p</italic> &lt; .01, ***, <italic>p</italic> &lt; .001. The results of post-hoc analysis are provided in <xref ref-type="supplementary-material" rid="supp2">Table S1 (Supplementary Data)</xref>. <bold>(b)</bold> Brain regions with significant activations in the JRD task. <bold>(c)</bold> Significant activation in the left retrosplenial cortex (RSC) for the contrast of post-learning &gt; pre-learning stage in the JRD trials. No regions showed significant activation for the contrast of post-learning &lt; pre-learning stages in the JRD task. <bold>(d)</bold> Brain regions showing the activation associated with <italic>ED</italic><sub><italic>ref-tar</italic></sub> in the JRD task. The warm/cold colors indicate positive/negative correlation. L/R indicates the left/right hemisphere. <bold>(e)</bold> Significant brain-behavior correlation. The <italic>x-</italic>axis represents the random effect coefficients (<italic>η</italic>) of the learning stage from the linear mixed-effects model (LMM), and the <italic>y</italic>-axis represents the <italic>β</italic>-values from the general linear model (GLM) analysis for the JRD trials and <italic>ED</italic><sub><italic>ref-tar</italic></sub>. The coordinates indicate the centers of ROIs. The shaded area indicates the 95% confidence interval (CI). The detailed brain-behavior correlation for all brain regions involved in the JRD task are listed in <xref ref-type="supplementary-material" rid="supp2">Table S2 (Supplementary Data)</xref>.</p></caption>
<graphic xlink:href="683540v1_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<fig id="fig4" position="float" fig-type="figure">
<label>Fig. 4.</label>
<caption><title>Representational similarity analysis (RSA).</title>
<p><bold>(a)</bold> Schematic of the RSA. Two theoretical representational dissimilarity matrices (RDMs), one for global and one for local levels, were built separately for both the learning stages (pre-learning and post-learning) to capture the spatial relationships of the reference objects. Considering that each room contained 8 objects and each learning stage used two rooms (16 objects total), we built the RDMs as 16 × 16 matrices. The left panel is an example of a pair of reference objects (highlighted in yellow in the matrices) in a single learning stage. Black (gray) rectangles indicate rooms that were (not) used in the learning stage. The global RDM and local RDM were built using the Euclidean distance between the reference objects within the global reference frame <inline-formula id="inline-eqn-7"><inline-graphic mime-subtype="gif" mimetype="image" xlink:href="683540v1_inline25.gif"/></inline-formula> and the local reference frame <inline-formula id="inline-eqn-8"><inline-graphic mime-subtype="gif" mimetype="image" xlink:href="683540v1_inline26.gif"/></inline-formula>, respectively, with larger distances indicating greater dissimilarity. For both the pre-learning and post-learning stages, the neural RDM was built by (1 - <italic>r</italic><sub><italic>ij</italic></sub>), where <italic>r</italic><sub><italic>ij</italic></sub> represents Pearson’s correlation coefficient between the <italic>β</italic>-values for the <italic>i</italic><sup>th</sup> and <italic>j</italic><sup>th</sup> reference objects within a given brain region. Light (dark) colors in the matrices indicate high (low) similarity. Corresponding to the two hierarchical levels and two learning stages, four Spearman’s rank correlations were computed by estimating the correlation between the neural RDMs and each theoretical RDM. This yielded four correlation coefficients: <inline-formula id="inline-eqn-9"><inline-graphic mime-subtype="gif" mimetype="image" xlink:href="683540v1_inline27.gif"/></inline-formula>, and <inline-formula id="inline-eqn-10"><inline-graphic mime-subtype="gif" mimetype="image" xlink:href="683540v1_inline28.gif"/></inline-formula> <bold>(b)</bold> Significant results of the ROI-based RSA. The coordinates represent the gravity centers of ROIs. Pre = pre-learning stage, Post = post-learning stage. <bold>(c)</bold> Brain regions showing significant differences in the correlation coefficients. Brain regions outlined by yellow and green dashed lines showed significant <inline-formula id="inline-eqn-11"><inline-graphic mime-subtype="gif" mimetype="image" xlink:href="683540v1_inline29.gif"/></inline-formula> and <inline-formula id="inline-eqn-12"><inline-graphic mime-subtype="gif" mimetype="image" xlink:href="683540v1_inline30.gif"/></inline-formula> respectively. Abbreviations: HIP = hippocampus, RSC = retrosplenial cortex, l/mOFC = lateral/medial orbitofrontal cortex, d/vACC = dorsal/ventral anterior cingulate cortex, THA = thalamus, MiFG = middle frontal gyrus, INS = insula, MTG = middle temporal gyrus. L/R represents left/right hemisphere.</p></caption>
<graphic xlink:href="683540v1_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>The neural RDM was calculated based on the fMRI data. For each trial, <italic>β</italic>-maps representing brain activity were computed using Nibetaseries toolbox (<ext-link ext-link-type="uri" xlink:href="https://nibetaseries.readthedocs.io/en/v0.6.0/">https://nibetaseries.readthedocs.io/en/v0.6.0/</ext-link>). The <italic>β</italic>-maps for each reference object were averaged across trials to create an overall <italic>β</italic>-map for that object. The neural RDM was then generated by calculating the dissimilarity (1 - <italic>r</italic><sub><italic>ij</italic></sub>) between the <italic>β</italic>-values of different reference objects within each brain region, where <italic>r</italic><sub><italic>ij</italic></sub> is the Pearson’s correlation coefficient between the activation patterns for the <italic>i</italic><sup>th</sup> and <italic>j</italic><sup>th</sup> objects. This process was repeated for each brain region and for each of the two learning stages.</p>
<p>We conducted both the ROI-based and whole-brain searchlight RSA. In the ROI-based RSA, we created 4 mm-radius spherical ROIs centered at the peak coordinates of significant clusters which were identified in the GLM analysis. In addition, we used the bilateral M1 as the control ROIs. Neural RDMs were computed within these ROIs. For each subject at each learning stage, Spearman’s rank correlation (<italic>ρ</italic>) was calculated between each of the theoretical RDMs (local and global) and the neural RDM to assess the spatial representation in each ROI between the local and global levels (<xref rid="fig4" ref-type="fig">Fig. 4a</xref>). In the whole-brain searchlight RSA, we used a 4 mm-radius spherical searchlight and moved it across the brain with a stride of 1 voxel along each axis (<italic>x, y, z</italic>) to generate the whole-brain <italic>ρ</italic>-maps representing the correlation between the theoretical and neural RDMs for each subject in each learning stage. Fisher’s <italic>ρ</italic>-to-<italic>Z</italic>-transformation was applied to standardize the <italic>ρ</italic>-maps.</p>
</sec>
<sec id="s2j">
<label>2.10</label>
<title>Statistics</title>
<p>For the group-level GLM analysis, we used a one-sample <italic>t</italic>-tests to assess the effects of the JRD trials and <italic>ED</italic><sub><italic>ref-tar</italic></sub> on brain activation. A paired-sample <italic>t</italic>-tests was conducted to evaluate the effects of learning on the task-related activation. Multiple comparisons were corrected using Gaussian Random Field (GRF) theory, with a voxel-wise threshold of <italic>Z</italic> &gt; 3.1 and a cluster significance threshold of <italic>p</italic> &lt; 0.05. For the RSA, each brain region yielded four Spearman’s rank correlations <inline-formula id="inline-eqn-13"><inline-graphic xlink:href="683540v1_inline5.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, and <inline-formula id="inline-eqn-14"><inline-graphic xlink:href="683540v1_inline6.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, corresponding to the two hierarchical levels (global/local) and two learning stages (pre/post), which were computed between each of the neural RDMs and each of the theoretical RDMs. In the ROI-based RSA, a repeated measures ANOVA was performed to examine the effects of the hierarchical level and the learning stage on spatial representations within the ROIs, using a Python package, statsmodels (<ext-link ext-link-type="uri" xlink:href="https://www.statsmodels.org/stable/index.html">https://www.statsmodels.org/stable/index.html</ext-link>). For the whole-brain searchlight RSA, we performed a repeated measures ANOVA by using PALM (permutation analysis of linear models) to identify the brain regions where the spatial representation varied by the hierarchical level and the learning stage. Threshold-free cluster enhancement (TFCE) with 10,000 permutations and family-wise error (FWE) correction were used to control for multiple comparisons. The significant level was set at <italic>p</italic> &lt; 0.01. A simple main effect analysis was conducted for significant ANOVA results. For the main effect of the learning stage on spatial representation, we tested whether the enhancement in spatial representation at each level after learning (i.e., <inline-formula id="inline-eqn-15"><inline-graphic xlink:href="683540v1_inline7.gif" mimetype="image" mime-subtype="gif"/></inline-formula> was significant. For the main effect of hierarchical levels on spatial representation, we tested the difference in spatial representation between the two levels in each learning stage (i.e.,<inline-formula id="inline-eqn-16"><inline-graphic xlink:href="683540v1_inline8.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula id="inline-eqn-17"><inline-graphic xlink:href="683540v1_inline9.gif" mimetype="image" mime-subtype="gif"/></inline-formula> . In addition, we tested whether the post-learning improvement in spatial representation differed between the two hierarchical levels (i.e., Δ<sub><italic>glo</italic></sub> vs. Δ<sub><italic>loc</italic></sub> ). TFCE with 10,000 permutations and FWE correction were used to control for multiple comparisons in the main effect analyses, and the significant level was set at <italic>p</italic> &lt; 0.01.</p>
</sec>
</sec>
<sec id="s3">
<label>3</label>
<title>Results</title>
<sec id="s3a">
<label>3.1</label>
<title>Behavioral analysis using LMM</title>
<p>LMMs were used to analyze the influence of spatial information at different hierarchical levels on the subjects’ response in the two learning stages. Model comparison showed that LMM2 provided a better fit than LMM1, as indicated by the <italic>AIC</italic> values (<italic>AIC</italic><sub>LMM1</sub> = 5,737 &gt; <italic>AIC</italic><sub>LMM2</sub> = 5,518), suggesting individual differences in the learning process. In the following, we reported the results obtained from LMM2.</p>
<p><xref rid="tbl1" ref-type="table">Table 1</xref> lists the main effects of different factors on RT, and their interactions with <italic>Learning</italic>. We found significant main effect of <italic>Learning</italic> (<italic>F</italic> = 39.61, <italic>p</italic> &lt; .001), <italic>ED</italic><sub><italic>ref-tar</italic></sub> (<italic>F</italic> = 309.36, <italic>p</italic> &lt; .001), <inline-formula id="inline-eqn-18"><inline-graphic xlink:href="683540v1_inline10.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, <italic>Room</italic> (<italic>F</italic> = 5.17, <italic>p</italic> = .023) and <inline-formula id="inline-eqn-19"><inline-graphic xlink:href="683540v1_inline11.gif" mimetype="image" mime-subtype="gif"/></inline-formula> on RT. We also found significant interactions between <italic>Learning</italic> and <italic>ED</italic> (<italic>F</italic> = 6.03, <italic>p</italic> = .014) as well as between <italic>Learning</italic> and <inline-formula id="inline-eqn-20"><inline-graphic xlink:href="683540v1_inline12.gif" mimetype="image" mime-subtype="gif"/></inline-formula> Specifically, the effect of <italic>ED</italic><sub><italic>ref-tar</italic></sub> on RT was stronger in the post-learning stage than in the pre-learning stage, suggesting that the subjects developed a better understanding of the spatial relationships between the objects after learning. Conversely, the effect of <inline-formula id="inline-eqn-21"><inline-graphic xlink:href="683540v1_inline13.gif" mimetype="image" mime-subtype="gif"/></inline-formula> on RT was decreased after learning, indicating that the subjects may have formed internal representation of the environment (<xref ref-type="supplementary-material" rid="supp2">Table S1 in Supplementary Data</xref>). However, no significance was found in either the interaction between <italic>Room</italic> and <italic>Learning</italic> (<italic>F</italic> = 1.36, <italic>p</italic> = .244) or the interaction between <inline-formula id="inline-eqn-22"><inline-graphic xlink:href="683540v1_inline14.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <italic>Learning</italic> (<italic>F</italic> = 2.04, <italic>p</italic> = .106). This indicates that the influence of room alignment and global reference direction on RT was independent of the learning stages. For <inline-formula id="inline-eqn-23"><inline-graphic xlink:href="683540v1_inline15.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and <inline-formula id="inline-eqn-24"><inline-graphic xlink:href="683540v1_inline16.gif" mimetype="image" mime-subtype="gif"/></inline-formula>, neither the main effects (<inline-formula id="inline-eqn-25"><inline-graphic xlink:href="683540v1_inline17.gif" mimetype="image" mime-subtype="gif"/></inline-formula> : <italic>F</italic> = 1.15, <italic>p</italic> = .329; <inline-formula id="inline-eqn-26"><inline-graphic xlink:href="683540v1_inline18.gif" mimetype="image" mime-subtype="gif"/></inline-formula>: <italic>F</italic> = 2.58, <italic>p</italic> = .051) nor their interactions with <italic>Learning</italic> (<inline-formula id="inline-eqn-27"><inline-graphic xlink:href="683540v1_inline19.gif" mimetype="image" mime-subtype="gif"/></inline-formula> : <italic>F</italic> = 2.37, <italic>p</italic> = .069; <inline-formula id="inline-eqn-28"><inline-graphic xlink:href="683540v1_inline20.gif" mimetype="image" mime-subtype="gif"/></inline-formula> : <italic>F</italic> = 1.97, <italic>p</italic> = .116) reached the significance level.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><title>Fixed-effects ANOVA results obtained from the linear mixed-effects model (LMM).</title></caption>
<graphic xlink:href="683540v1_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
<graphic xlink:href="683540v1_tbl1a.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s3b">
<label>3.2</label>
<title>Brain activation during spatial memory</title>
<p><xref rid="fig3" ref-type="fig">Fig. 3b</xref> shows seven clusters with significant activation and five clusters with significant deactivation in the JRD trials, which were identified from the ROI-based GLM analysis. The activated clusters were located in the bilateral RSC, EC, and lateral OFC (lOFC). The deactivated clusters were located in the bilateral medial OFC (mOFC), ventral lOFC, HIP, and EC. In the JRD trials, we found a cluster in the left RSC showing significant activation in post-learning &gt; pre-learning (<xref rid="fig3" ref-type="fig">Fig. 3c</xref>). In addition, the activation in the left RSC was significantly positively correlated with <italic>ED</italic><sub><italic>ref-tar</italic></sub> (<xref rid="fig3" ref-type="fig">Fig. 3d</xref>). Conversely, the activation in the left mOFC, right HIP, and left lOFC was significantly negatively correlated with <italic>ED</italic><sub><italic>ref-tar</italic></sub> in the JRD trials. However, none of these correlations showed significant differences between the pre- and post-learning stages. The detailed information about these clusters is provided in <xref ref-type="supplementary-material" rid="supp2">Table S2 (Supplementary Data)</xref>.</p>
<p>The whole-brain GLM analysis showed significant activation in the bilateral RSC and the left HIP for post-learning &gt; pre-learning in the JRD task (Fig. S3, Supplementary Materials). We found that several regions, including the bilateral lateral occipital cortex (LOC), precuneus, supramarginal gyrus (SMG), left parahippocampal gyrus (PHG), and left middle temporal gyrus, showed significant activation for post-learning &gt; pre-learning (Fig. S3, Supplementary Materials). The detailed information about these regions is listed in <xref ref-type="supplementary-material" rid="supp2">Table S3 (Supplementary Data)</xref>.</p>
<p><xref rid="fig3" ref-type="fig">Fig. 3e</xref> shows the brain-behavior correlations based on the random slopes of the learning stage from LMM2. Specifically, for the JRD trials, we found that the <italic>β</italic>-values of two right EC clusters (MNI peak: [28, -22, -28], <italic>r</italic> = -0.45, <italic>p</italic> = .032; MNI peak: [40, -6, -26], <italic>r</italic> = -0.50, <italic>p</italic> = .016) were significantly negatively correlated with the <italic>η</italic>-values. For the <italic>ED</italic><sub><italic>ref-tar</italic></sub>, we found that the <italic>β</italic>-values of the right RSC (MNI peak: [14, -52, 20], <italic>r</italic> = 0.46, <italic>p</italic> = .029) and right HIP (MNI peak: [34, -22, -18], <italic>r</italic> = 0.66, <italic>p</italic> &lt; .001) were significantly positively correlated with the <italic>η</italic>-values.</p>
</sec>
<sec id="s3c">
<label>3.3</label>
<title>Spatial representation across learning stages</title>
<p><xref rid="fig4" ref-type="fig">Fig. 4b</xref> shows the brain regions where spatial representations were significantly influenced by the hierarchical levels and/or the learning stages, as revealed by the ROI-based RSA. Specifically, we observed a significant interaction between the hierarchical level and the learning stage in the right HIP (MNI peak: [34, -22, -18], <italic>F</italic> = 6.34, <italic>p</italic> = .020). As learning progressed, the pattern similarity associated with the global RDM was increased, while that associated with the local RDM was decreased. This result suggests that the right HIP was more involved in representing the global spatial structure, contributing to the formation of a more integrated and comprehensive cognitive map of the VE.</p>
<p>In the right RSC (MNI peak: [16, -50, 20]), we also observed a significant interaction between the hierarchical level and the learning stage (<italic>F</italic> = 5.59, <italic>p</italic> = .027). Specifically, the enhancement in global representation after learning was greater than that in local representation (<xref rid="fig4" ref-type="fig">Fig. 4b</xref>). In addition, the main effect of learning stages on spatial representations was significant in the right RSC (<italic>F</italic> = 8.92, <italic>p</italic> = .007), with the pattern similarity increasing across both the local and global RDMs after learning. These results indicate the key role of the right RSC in integrating spatial information across different hierarchical levels.</p>
<p>Spatial representations in the OFC were influenced by both the hierarchical level and the learning stage. Specifically, in the left mOFC, we observed significant main effects of both the hierarchical level (MNI peak: [-10, 48, -4], <italic>F</italic> = 4.86, <italic>p</italic> = .038) and the learning stage (MNI peak: [-4, 54, 0], <italic>F</italic> = 9.35, <italic>p</italic> = .006). The pattern similarity of the local RDM was higher than that of the global RDM in both stages, and pattern similarity of both the RDMs were increased after learning (<xref rid="fig4" ref-type="fig">Fig. 4b</xref>). In the right lOFC (MNI peak: [42, 28, -14]), we observed a significant main effect of the hierarchical level (<italic>F</italic> = 21.30, <italic>p</italic> &lt; .001), with the pattern similarity of the local RDM being stronger than that of the global RDM in both the pre- and post-learning stages. In the left lOFC (MNI peak: [-30, 50, -12]), we observed a significant main effect of the learning stage (<italic>F</italic> = 5.16, <italic>p</italic> = .033), with the pattern similarity of both the RDMs being increased after learning. No significant effects of the hierarchical level or the learning stage were found in the bilateral M1 (the control ROIs). The detailed information about these ROI-based RSA results is provided in <xref ref-type="supplementary-material" rid="supp2">Table S4 (Supplementary Data)</xref>.</p>
<p>The whole-brain searchlight RSA revealed additional brain regions showing significant changes in spatial representations between the pre- and post-learning stages. Using ANOVA, we identified 13 brain clusters with different pattern similarity for the local and global RDMs across the two learning stages (<xref rid="fig4" ref-type="fig">Fig. 4c</xref>). These clusters were located in the bilateral ACC, bilateral thalami, bilateral lateral prefrontal cortex (lPFC), left OFC, right middle temporal gyrus (MTG), right lateral occipital cortex (LOC), right post-central gyrus (PoCG), and right pre-central gyrus (PrCG) (<xref ref-type="supplementary-material" rid="supp2">Table S5 in Supplementary Data</xref>). In the post-learning stage, these regions showed higher pattern similarity for the global RDM than in the pre-learning stage and higher similarity for the global RDM than the local RDM (<xref ref-type="supplementary-material" rid="supp1">Fig. S4 in Supplementary Materials</xref>). However, only the bilateral ACC showed these differences to be statistically significant (<xref rid="fig4" ref-type="fig">Fig. 4c</xref>). Both the bilateral ACC and lPFC showed reduced pattern similarity for the local RDM after learning. These regions also showed lower pattern similarity for the global RDM than the local RDM in the pre-learning stage (<xref ref-type="supplementary-material" rid="supp1">Fig. S4 in Supplementary Materials</xref>). However, neither of these results reached the significant level.</p>
<p>When comparing the two learning stages, we observed significant differences in the local and global spatial representations in four clusters. These clusters were located in the bilateral ACC, left inferior frontal gyrus (IFG), and right superior frontal gyrus (SFG), with the corresponding details provided in <xref ref-type="supplementary-material" rid="supp1">Fig. S5 (Supplementary Materials)</xref>. In these clusters, the post-learning enhancement in pattern similarity of the global RDM was greater than that of the local RDM ( Δ<sub><italic>glo</italic></sub> &gt; Δ<sub><italic>loc</italic></sub> ). The detailed information about these searchlight RSA results is provided in <xref ref-type="supplementary-material" rid="supp2">Table S5 (Supplementary Data)</xref>.</p>
</sec>
</sec>
<sec id="s4">
<label>4.</label>
<title>Discussion</title>
<p>The current study examined how cognitive maps develop in a multi-scale environment through learning. We used a virtual environment (VE) that included spatial information at three hierarchical levels: local, categorical, and global (<xref rid="fig2" ref-type="fig">Fig. 2</xref>), allowing the subjects to learn the spatial relationships between objects. Their spatial memory was measured during both pre-learning and post-learning stages using a JRD task (<xref rid="fig1" ref-type="fig">Fig. 1</xref>). By analyzing the behavioral data, we found that as learning progressed, the subjects gradually shifted from relying on explicit directional cues to processing implicit spatial distance (<xref rid="fig3" ref-type="fig">Fig. 3a</xref>), indicating a refinement of cognitive map. By analyzing the fMRI data, we revealed that the HIP, EC, RSC, and OFC were engaged in encoding spatial information during the JRD task (<xref rid="fig3" ref-type="fig">Fig. 3</xref>). These regions played distinct roles in representing spatial information at the local and global levels in the pre-and post-learning stages (<xref rid="fig4" ref-type="fig">Fig. 4</xref>). Specifically, learning enhanced global representations in the HIP, strengthened local representations in the OFC, and increased representations at both hierarchical levels in the RSC (<xref rid="fig4" ref-type="fig">Fig. 4b</xref>). These findings indicate the different roles of these key brain regions in supporting the dynamic construction of cognitive maps. By uncovering how hierarchical spatial representations emerge and re-organize with learning, the current study advances our understanding of the neural basis of flexible navigation in complex environments.</p>
<sec id="s4a">
<label>4.1</label>
<title>Refinement on cognitive map through learning</title>
<p>The LMM analysis revealed significant improvements in behavioral performance from the pre-learning to the post-learning stage (<xref rid="tbl1" ref-type="table">Table 1</xref>). After learning, the subjects showed a better understanding of the spatial relationships between objects, as indicated by the increased influence of <italic>ED</italic><sub><italic>ref-tar</italic></sub> on RT in the post-learning stage than the pre-learning stage (<xref rid="fig3" ref-type="fig">Fig. 3a</xref>). In addition, the influence of categorical information (i.e., the <italic>Room</italic>) on RT was decreased after learning (<xref ref-type="supplementary-material" rid="supp2">Table S1, Supplementary Data</xref>), indicating a reduced reliance on room-level distinctions as the subjects became more familiar with the environment. These results are consistent with previous findings <sup><xref ref-type="bibr" rid="c21">21</xref>,<xref ref-type="bibr" rid="c22">22</xref></sup>, which showed that individuals tend to shift from using explicit categorical information to using more implicit spatial representations during spatial learning.</p>
<p>How did local and global representations evolve throughout the learning process? From the LMM, we found a significant influence of the local directions <inline-formula id="inline-eqn-29"><inline-graphic xlink:href="683540v1_inline21.gif" mimetype="image" mime-subtype="gif"/></inline-formula> and global directions <inline-formula id="inline-eqn-30"><inline-graphic xlink:href="683540v1_inline22.gif" mimetype="image" mime-subtype="gif"/></inline-formula> of the reference objects on RT in both the pre- and post-learning stages (<xref rid="tbl1" ref-type="table">Table 1</xref>). This indicates that both local and global representations co-existed in both the learning stages. However, the influence of these directional cues on the representation was reduced in the post-learning than the pre-learning stages (<xref rid="fig3" ref-type="fig">Fig. 3a</xref>), suggesting a decreased reliance on the explicit directional cues as learning progressed. These findings align with previous studies <sup><xref ref-type="bibr" rid="c16">16</xref>,<xref ref-type="bibr" rid="c20">20</xref></sup>, which showed that both local and global representations co-exist in multi-scale environments and are recruited flexibly according to task demands.</p>
</sec>
<sec id="s4b">
<label>4.2</label>
<title>Neural mechanisms in the JRD task facilitating spatial learning</title>
<p>The GLM analysis revealed that the bilateral HIP, EC, RSC, and OFC were engaged in the JRD task (<xref rid="fig3" ref-type="fig">Fig. 3b</xref>). These regions are involved in various cognitive functions, such as learning, memory, spatial navigation, and cognitive maps formation <sup><xref ref-type="bibr" rid="c1">1</xref>,<xref ref-type="bibr" rid="c25">25</xref>,<xref ref-type="bibr" rid="c26">26</xref></sup>. In the current study, we found that the left RSC showed significantly greater activation in the post-learning stage than in the pre-learning stage (<xref rid="fig3" ref-type="fig">Fig. 3c</xref>). This result aligns with a previous research <sup><xref ref-type="bibr" rid="c35">35</xref></sup>, which showed the critical role of the RSC in building cognitive maps of novel environments. This result indicates that the RSC may be involved in processing spatial relationships across different scales of the environment <sup><xref ref-type="bibr" rid="c33">33</xref>,<xref ref-type="bibr" rid="c43">43</xref></sup>. In addition, we found that the individuals with greater learning progress showed weaker activation in the right EC (<xref rid="fig3" ref-type="fig">Fig. 3e</xref>). The EC is proposed encoding general, non-localized spatial information across different environmental scales <sup><xref ref-type="bibr" rid="c2">2</xref>,<xref ref-type="bibr" rid="c6">6</xref></sup>. This negative correlation between EC activation and learning progress suggests that spatial representations may be transferred from the EC to other brain regions with the progress of learning, leading to a reduced reliance on the EC <sup><xref ref-type="bibr" rid="c44">44</xref>,<xref ref-type="bibr" rid="c45">45</xref></sup>.</p>
<p>We also observed that activation in the left mOFC, right lOFC, right HIP, and right RSC was significantly correlated with <italic>ED</italic><sub><italic>ref-tar</italic></sub> in the JRD task (<xref rid="fig3" ref-type="fig">Fig. 3d</xref>). This result is consistent with previous studies <sup><xref ref-type="bibr" rid="c24">24</xref>,<xref ref-type="bibr" rid="c46">46</xref>,<xref ref-type="bibr" rid="c47">47</xref></sup>, which showed that the HIP and RSC are involved in encoding distances in both physical and abstract spaces. The mOFC and HIP are suggested to contribute to the construction of cognitive maps that support flexible decision-making and adaptive behavior <sup><xref ref-type="bibr" rid="c2">2</xref>,<xref ref-type="bibr" rid="c5">5</xref>,<xref ref-type="bibr" rid="c15">15</xref></sup>. In addition, we found the positive correlation between activation in the RSC and HIP with the progress of individuals’ learning (<xref rid="fig3" ref-type="fig">Fig. 3e</xref>). This result suggests that the RSA and HIP may support the formation of individual-specific spatial representations <sup><xref ref-type="bibr" rid="c25">25</xref>,<xref ref-type="bibr" rid="c35">35</xref></sup>.</p>
</sec>
<sec id="s4c">
<label>4.3</label>
<title>Adaptive shifts in spatial representations during learning</title>
<p>The RSA results revealed that the brain regions involved in the JRD task played distinct roles in the formation of a cognitive map in a multi-scale environment (<xref rid="fig4" ref-type="fig">Fig. 4</xref>). Specifically, in the right HIP, we observed a shift from a local representation in the pre-learning stage to a global representation in the post-learning stage (<xref rid="fig4" ref-type="fig">Fig. 4b</xref>). This observation aligns with previous studies <sup><xref ref-type="bibr" rid="c35">35</xref>,<xref ref-type="bibr" rid="c48">48</xref>,<xref ref-type="bibr" rid="c49">49</xref></sup>, which showed that the HIP is crucial for integrating local information into a global layout as learning progresses. In the RSC, spatial representations of both local and global levels were increased from pre-learning to post-learning (<xref rid="fig4" ref-type="fig">Fig. 4b</xref>), indicating the RSC’s role in integrating spatial information across spatial scales. This aligns with previous studies <sup><xref ref-type="bibr" rid="c25">25</xref>,<xref ref-type="bibr" rid="c32">32</xref>,<xref ref-type="bibr" rid="c33">33</xref></sup>, which implicated the roles of RSC in representing location and facing direction in multi-scale environments. Similarly, both local and global representations were increased in the left OFC in the post-learning stage (<xref rid="fig4" ref-type="fig">Fig. 4b</xref>), suggesting that it coordinates spatial information across different scales, and supporting adaptive decision-making and goal-directed behavior <sup><xref ref-type="bibr" rid="c34">34</xref>,<xref ref-type="bibr" rid="c50">50</xref>,<xref ref-type="bibr" rid="c51">51</xref></sup>. In contrast, the right lOFC consistently showed strong local representation in both the pre and post-learning stages (<xref rid="fig4" ref-type="fig">Fig. 4b</xref>), indicating its role in processing specific location and direction information for decision-making <sup><xref ref-type="bibr" rid="c30">30</xref>,<xref ref-type="bibr" rid="c31">31</xref>,<xref ref-type="bibr" rid="c50">50</xref></sup>.</p>
<p>Using whole-brain searchlight RSA, we found additional brain regions showing changes in spatial representations across the two learning stages (<xref rid="fig4" ref-type="fig">Fig. 4c</xref>). Specifically, the bilateral ACC showed an increase in global representation after sufficient learning (<xref rid="fig4" ref-type="fig">Fig. 4c</xref>). The enhancement of global representations in the ACC was more pronounced than that of local representations (<xref ref-type="supplementary-material" rid="supp1">Fig. S5 in Supplementary Materials</xref>), resulting in a higher global representation than local representation after learning (<xref rid="fig4" ref-type="fig">Fig. 4c</xref>). Previous studies indicated that the ACC is functionally connected to the OFC and HIP in spatial memory, especially in tasks relating to exploration in novel environments <sup><xref ref-type="bibr" rid="c52">52</xref>–<xref ref-type="bibr" rid="c54">54</xref></sup>. Our results suggest that the ACC may be engaged in integrating spatial information to form global representations, thereby facilitating efficient and flexible spatial processing. In addition, other brain regions, including the bilateral lPFC, bilateral thalami, right insula, left ventral ACC, and right MTG, showed varying spatial representations across the learning stages (<xref rid="fig4" ref-type="fig">Fig. 4c</xref>). In these regions, both global and local representations were increased after sufficient learning, with global representations remaining consistently stronger than local representations across both learning stages (<xref ref-type="supplementary-material" rid="supp1">Fig. S4 in Supplementary Materials</xref>). Though these regions did not show statistical significant main effects of spatial hierarchical levels or learning stages, they have been implicated in various learning processes and are associated with the HIP in explicit memory <sup><xref ref-type="bibr" rid="c55">55</xref>–<xref ref-type="bibr" rid="c57">57</xref></sup>. Our results suggest that forming cognitive maps in multi-scale environments recruits multiple brain regions to integrate information across spatial levels.</p>
</sec>
<sec id="s4d">
<label>4.4</label>
<title>Disentangling Global and Categorical Representations</title>
<p>We observed an increase in global representations after sufficient learning, which could arise from two potential mechanisms. First, the subjects may have acquired precise spatial relationships between the rooms and objects. This hypothesis is supported by the LMM results, which showed that the distance information became more influential in behavioral performance after learning (<xref rid="fig3" ref-type="fig">Fig. 3a</xref>). Second, the increase in global representation could be resulted from the improved differentiation of rooms (i.e., categorical processing), rather than the acquisition of precise spatial distances. In this case, the subjects may have enhanced their categorical-level spatial representation, which does not require the precise distance relationships inherent to the global representation.</p>
<p>Categorical representations are essential for distinguishing boundaries and characteristics between areas, enabling transitions across different areas in multi-scale environments <sup><xref ref-type="bibr" rid="c17">17</xref></sup>. These representations lie between the local and global representations in the hierarchical representation framework (<xref rid="fig2" ref-type="fig">Fig. 2</xref>). Unlike the global representation, which conveys precise distance relationships between objects, the local and categorical representations are less precise. Local representations assimilate rooms by treating the distance between them as zero, and categorical representations differentiate rooms by treating the inter-room distance as infinite. Our LMM analysis indicated that the categorical information had a reduced influence on the behavioral performance after learning (<xref rid="fig3" ref-type="fig">Fig. 3a</xref>). This result suggested that the increased global representation observed in the RSA may be driven by the acquisition of precise distance information rather than the acquisition of categorical information. However, the high similarity between the global and categorical RDMs (<xref ref-type="supplementary-material" rid="supp1">Fig. S4 in Supplementary Materials</xref>) makes it challenging to distinguish brain representations at these two hierarchical levels. Therefore, further studies are needed to understand how spatial representations evolve across different hierarchical levels through learning.</p>
</sec>
<sec id="s4e">
<label>4.5</label>
<title>Limitations</title>
<p>The current study has several limitations. First, we used a virtual reality (VR) environment to simulate spatial learning and navigation. Although VR offers a valuable tool for investigating spatial cognition <sup><xref ref-type="bibr" rid="c58">58</xref>,<xref ref-type="bibr" rid="c59">59</xref></sup>, it may not fully capture the complexities and sensory richness of real-world environments. Sensory cues such as proprioceptive feedback and natural visual information, which are limited in VR settings, can influence the subjects’ spatial encoding strategies <sup><xref ref-type="bibr" rid="c60">60</xref></sup> and their reliance on the local and global spatial information. Second, our study employed a cross-sectional design, measuring subjects at two time points (pre- and post-learning). Although this design allows us to observe changes in brain activation and behavioral performance, it does not provide a direct measure of the process of learning over time. Longitudinal studies tracking the trajectory of individual learning would provide deeper insights into the dynamic nature of spatial learning and cognitive map development. Third, although we accounted for individual differences in the LMM analysis, variations in cognitive strategies and previous experiences with spatial tasks could influence how individuals process spatial information. Future studies could explore which factors, such as prior spatial experience, cognitive abilities, and personality traits, influence the progress of learning and the representation of spatial information. Last, our sample consisted of 23 adult healthy university students, their age range and educational levels may limit the generalizability of the findings <sup><xref ref-type="bibr" rid="c61">61</xref>,<xref ref-type="bibr" rid="c62">62</xref></sup>. A larger and more diverse sample would help to test the observed effects.</p>
<p>In conclusion, the current study provides new insights into the neural mechanisms underlying spatial learning and the formation of cognitive maps in multi-scale environments. Using a combination of behavioral data and neuroimaging techniques, we showed how spatial representations evolve across two different learning stages. Specifically, we found that as learning progressed, individuals increasingly relied on global representations of the environment, with a shift away from local, directional cues. Brain regions including the hippocampus, retrosplenial cortex, and orbitofrontal cortex played distinct roles in encoding spatial information at multiple hierarchical levels, supporting the development of flexible and adaptive cognitive maps. These results revealed the dynamic nature of spatial learning and the distinct roles of the hippocampus, retrosplenial cortex, and orbitofrontal cortex in integrating local and global spatial information over time. The findings advance our understanding of the neural mechanisms of spatial learning in complex environments.</p>
</sec>
</sec>
</body>
<back>
<sec id="das" sec-type="data-availability">
<title>Data availability</title>
<p>The data that support the findings of this study are available from the corresponding author upon reasonable request.</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>This work was supported by funding from the Key Technologies R&amp;D Program of Guangdong Province (Grant number: 2023B0303020002), National Natural Science Foundation of China (Grant numbers: 32371101 and 82171914), striving for the first-class, improving weak links and highlighting features (SIH) key discipline for psychology in South China Normal University, and National Key Research and Development Program of China (Grant number: 2018YFC1705006). We thank the Center for Magnetic Resonance Research (CMRR) at the University of Minnesota for providing the SMS-EPI sequence used in the current study.</p>
</ack>
<sec id="additional-files" sec-type="supplementary-material">
<title>Additional files</title>
<supplementary-material id="supp1">
<label>Supplementary materials</label>
<media mimetype="application" mime-subtype="pdf" xlink:href="supp1.pdf"/>
</supplementary-material>
<supplementary-material id="supp2">
<label>Supplementary data</label>
<media mimetype="application" mime-subtype="vnd.ms-excel" xlink:href="supp2.xlsx"/>
</supplementary-material>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Behrens</surname>, <given-names>T. E. J.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>What Is a Cognitive Map? Organizing Knowledge for Flexible Behavior</article-title>. <source>Neuron</source> <volume>100</volume>, <fpage>490</fpage>–<lpage>509</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Whittington</surname>, <given-names>J. C. R.</given-names></string-name>, <string-name><surname>McCaffary</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Bakermans</surname>, <given-names>J. J. W.</given-names></string-name> &amp; <string-name><surname>Behrens</surname>, <given-names>T. E. J.</given-names></string-name></person-group> <article-title>How to build a cognitive map</article-title>. <source>Nat Neurosci</source> <volume>25</volume>, <fpage>1257</fpage>–<lpage>1272</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Alexander</surname>, <given-names>A. S.</given-names></string-name> &amp; <string-name><surname>Nitz</surname>, <given-names>D. A.</given-names></string-name></person-group> <article-title>Spatially Periodic Activation Patterns of Retrosplenial Cortex Encode Route Sub-spaces and Distance Traveled</article-title>. <source>Current Biology</source> <volume>27</volume>, <fpage>1551</fpage>–<lpage>1560.e4</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Park</surname>, <given-names>S. A.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>D. S.</given-names></string-name>, <string-name><surname>Nili</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Ranganath</surname>, <given-names>C.</given-names></string-name> &amp; <string-name><surname>Boorman</surname>, <given-names>E. D.</given-names></string-name></person-group> <article-title>Map Making: Constructing, Combining, and Inferring on Abstract Cognitive Maps</article-title>. <source>Neuron</source> <volume>107</volume>, <fpage>1226</fpage>–<lpage>1238.e8</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Niv</surname>, <given-names>Y.</given-names></string-name></person-group> <article-title>Learning task-state representations</article-title>. <source>Nat Neurosci</source> <volume>22</volume>, <fpage>1544</fpage>–<lpage>1553</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Baram</surname>, <given-names>A. B.</given-names></string-name>, <string-name><surname>Muller</surname>, <given-names>T. H.</given-names></string-name>, <string-name><surname>Nili</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Garvert</surname>, <given-names>M. M.</given-names></string-name> &amp; <string-name><surname>Behrens</surname>, <given-names>T. E. J.</given-names></string-name></person-group> <article-title>Entorhinal and ventromedial prefrontal cortices abstract and generalize the structure of reinforcement learning problems</article-title>. <source>Neuron</source> <volume>109</volume>, <fpage>713</fpage>–<lpage>723.e7</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kim</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Doeller</surname>, <given-names>C. F.</given-names></string-name></person-group> <article-title>Adaptive cognitive maps for curved surfaces in the 3D world</article-title>. <source>Cognition</source> <volume>225</volume>, <fpage>105126</fpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mark</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Moran</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Parr</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Kennerley</surname>, <given-names>S. W.</given-names></string-name> &amp; <string-name><surname>Behrens</surname>, <given-names>T. E. J.</given-names></string-name></person-group> <article-title>Transferring structural knowledge across cognitive maps in humans and models</article-title>. <source>Nat Commun</source> <volume>11</volume>, <fpage>4783</fpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Farzanfar</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Spiers</surname>, <given-names>H. J.</given-names></string-name>, <string-name><surname>Moscovitch</surname>, <given-names>M.</given-names></string-name> &amp; <string-name><surname>Rosenbaum</surname>, <given-names>R. S.</given-names></string-name></person-group> <article-title>From cognitive maps to spatial schemas</article-title>. <source>Nat Rev Neurosci</source> <volume>24</volume>, <fpage>63</fpage>–<lpage>79</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>George</surname>, <given-names>D.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Clone-structured graph representations enable flexible learning and vicarious evaluation of cognitive maps</article-title>. <source>Nat Commun</source> <volume>12</volume>, <fpage>2392</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nieh</surname>, <given-names>E. H.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Geometry of abstract learned knowledge in the hippocampus</article-title>. <source>Nature</source> <volume>595</volume>, <fpage>80</fpage>–<lpage>84</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Crivelli-Decker</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Goal-oriented representations in the human hippocampus during planning and navigation</article-title>. <source>Nat Commun</source> <volume>14</volume>, <fpage>2946</fpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Tomov</surname>, <given-names>M. S.</given-names></string-name>, <string-name><surname>Yagati</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Kumar</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>W.</given-names></string-name> &amp; <string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name></person-group> <article-title>Discovery of hierarchical representations for efficient planning</article-title>. <source>PLOS Computational Biology</source> <volume>16</volume>, <fpage>e1007594</fpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schapiro</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Turk-Browne</surname>, <given-names>N. B.</given-names></string-name>, <string-name><surname>Norman</surname>, <given-names>K. A.</given-names></string-name> &amp; <string-name><surname>Botvinick</surname>, <given-names>M. M.</given-names></string-name></person-group> <article-title>Statistical learning of temporal community structure in the hippocampus: STATISTICAL LEARNING OF TEMPORAL COMMUNITY STRUCTURE</article-title>. <source>Hippocampus</source> <volume>26</volume>, <fpage>3</fpage>–<lpage>8</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schuck</surname>, <given-names>N. W.</given-names></string-name>, <string-name><surname>Cai</surname>, <given-names>M. B.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>R. C.</given-names></string-name> &amp; <string-name><surname>Niv</surname>, <given-names>Y.</given-names></string-name></person-group> <article-title>Human Orbitofrontal Cortex Represents a Cognitive Map of State Space</article-title>. <source>Neuron</source> <volume>91</volume>, <fpage>1402</fpage>–<lpage>1412</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Peer</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Brunec</surname>, <given-names>I. K.</given-names></string-name>, <string-name><surname>Newcombe</surname>, <given-names>N. S.</given-names></string-name> &amp; <string-name><surname>Epstein</surname>, <given-names>R. A.</given-names></string-name></person-group> <article-title>Structuring Knowledge with Cognitive Maps and Cognitive Graphs</article-title>. <source>Trends in Cognitive Sciences</source> <volume>25</volume>, <fpage>37</fpage>–<lpage>54</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Constantinescu</surname>, <given-names>A. O.</given-names></string-name>, <string-name><surname>O’Reilly</surname>, <given-names>J. X.</given-names></string-name> &amp; <string-name><surname>Behrens</surname>, <given-names>T. E. J.</given-names></string-name></person-group> <article-title>Organizing conceptual knowledge in humans with a gridlike code</article-title>. <source>Science</source> <volume>352</volume>, <fpage>1464</fpage>–<lpage>1468</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bao</surname>, <given-names>X.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Grid-like Neural Representations Support Olfactory Navigation of a Two-Dimensional Odor Space</article-title>. <source>Neuron</source> <volume>102</volume>, <fpage>1066</fpage>–<lpage>1075</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Park</surname>, <given-names>S. A.</given-names></string-name>, <string-name><surname>Miller</surname>, <given-names>D. S.</given-names></string-name> &amp; <string-name><surname>Boorman</surname>, <given-names>E. D.</given-names></string-name></person-group> <article-title>Inferences on a multidimensional social hierarchy use a grid-like code</article-title>. <source>Nat Neurosci</source> <volume>24</volume>, <fpage>1292</fpage>–<lpage>1301</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Marchette</surname>, <given-names>S. A.</given-names></string-name>, <string-name><surname>Ryan</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Epstein</surname>, <given-names>R. A.</given-names></string-name></person-group> <article-title>Schematic representations of local environmental space guide goal-directed navigation</article-title>. <source>Cognition</source> <volume>158</volume>, <fpage>68</fpage>–<lpage>80</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Wernle</surname>, <given-names>T.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Integration of grid maps in merged environments</article-title>. <source>Nat Neurosci</source> <volume>21</volume>, <fpage>92</fpage>–<lpage>101</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Carpenter</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Manson</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Jeffery</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Burgess</surname>, <given-names>N.</given-names></string-name> &amp; <string-name><surname>Barry</surname>, <given-names>C.</given-names></string-name></person-group> <article-title>Grid Cells Form a Global Representation of Connected Environments</article-title>. <source>Current Biology</source> <volume>25</volume>, <fpage>1176</fpage>–<lpage>1182</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Mao</surname>, <given-names>D.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Hippocampus-dependent emergence of spatial sequence coding in retrosplenial cortex</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>115</volume>, <fpage>8015</fpage>–<lpage>8018</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Patai</surname>, <given-names>E. Z.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Hippocampal and Retrosplenial Goal Distance Coding After Long-term Consolidation of a Real-World Environment</article-title>. <source>Cerebral Cortex</source> <volume>29</volume>, <fpage>2748</fpage>–<lpage>2758</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bellmund</surname>, <given-names>J. L. S.</given-names></string-name>, <string-name><surname>Gärdenfors</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Moser</surname>, <given-names>E. I.</given-names></string-name> &amp; <string-name><surname>Doeller</surname>, <given-names>C. F.</given-names></string-name></person-group> <article-title>Navigating cognition: Spatial codes for human thinking</article-title>. <source>Science</source> <volume>362</volume>, <fpage>eaat6766</fpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Qiu</surname>, <given-names>Y.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Representation of human spatial navigation responding to input spatial information and output navigational strategies: An ALE meta-analysis</article-title>. <source>Neuroscience &amp; Biobehavioral Reviews</source> <volume>103</volume>, <fpage>60</fpage>–<lpage>72</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kurth-Nelson</surname>, <given-names>Z.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Replay and compositional computation</article-title>. <source>Neuron</source> <volume>111</volume>, <fpage>454</fpage>–<lpage>469</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liu</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Mattar</surname>, <given-names>M. G.</given-names></string-name>, <string-name><surname>Behrens</surname>, <given-names>T. E. J.</given-names></string-name>, <string-name><surname>Daw</surname>, <given-names>N. D.</given-names></string-name> &amp; <string-name><surname>Dolan</surname>, <given-names>R. J.</given-names></string-name></person-group> <article-title>Experience replay is associated with efficient nonlocal learning</article-title>. <source>Science</source> <volume>372</volume>, <fpage>eabf1357</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Epstein</surname>, <given-names>R. A.</given-names></string-name>, <string-name><surname>Patai</surname>, <given-names>E. Z.</given-names></string-name>, <string-name><surname>Julian</surname>, <given-names>J. B.</given-names></string-name> &amp; <string-name><surname>Spiers</surname>, <given-names>H. J.</given-names></string-name></person-group> <article-title>The cognitive map in humans: spatial navigation and beyond</article-title>. <source>Nat Neurosci</source> <volume>20</volume>, <fpage>1504</fpage>–<lpage>1513</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Basu</surname>, <given-names>R.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>The orbitofrontal cortex maps future navigational goals</article-title>. <source>Nature</source> <volume>599</volume>, <fpage>449</fpage>–<lpage>452</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Knudsen</surname>, <given-names>E. B.</given-names></string-name> &amp; <string-name><surname>Wallis</surname>, <given-names>J. D.</given-names></string-name></person-group> <article-title>Taking stock of value in the orbitofrontal cortex</article-title>. <source>Nat Rev Neurosci</source> <volume>23</volume>, <fpage>428</fpage>–<lpage>438</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Alexander</surname>, <given-names>A. S.</given-names></string-name> &amp; <string-name><surname>Nitz</surname>, <given-names>D. A.</given-names></string-name></person-group> <article-title>Retrosplenial cortex maps the conjunction of internal and external spaces</article-title>. <source>Nat Neurosci</source> <volume>18</volume>, <fpage>1143</fpage>–<lpage>1151</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Marchette</surname>, <given-names>S. A.</given-names></string-name>, <string-name><surname>Vass</surname>, <given-names>L. K.</given-names></string-name>, <string-name><surname>Ryan</surname>, <given-names>J.</given-names></string-name> &amp; <string-name><surname>Epstein</surname>, <given-names>R. A.</given-names></string-name></person-group> <article-title>Anchoring the neural compass: coding of local spatial reference frames in human medial parietal lobe</article-title>. <source>Nat Neurosci</source> <volume>17</volume>, <fpage>1598</fpage>–<lpage>1606</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Costa</surname>, <given-names>K. M.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>The role of the lateral orbitofrontal cortex in creating cognitive maps</article-title>. <source>Nat Neurosci</source> <volume>26</volume>, <fpage>107</fpage>–<lpage>115</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Qiu</surname>, <given-names>Y.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Forming cognitive maps for abstract spaces: the roles of the human hippocampus and orbitofrontal cortex</article-title>. <source>Commun Biol</source> <volume>7</volume>, <fpage>517</fpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Deichmann</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Gottfried</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Hutton</surname>, <given-names>C.</given-names></string-name> &amp; <string-name><surname>Turner</surname>, <given-names>R.</given-names></string-name></person-group> <article-title>Optimized EPI for fMRI studies of the orbitofrontal cortex</article-title>. <source>NeuroImage</source> <volume>19</volume>, <fpage>430</fpage>–<lpage>441</lpage> (<year>2003</year>).</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Esteban</surname>, <given-names>O.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>fMRIPrep: a robust preprocessing pipeline for functional MRI</article-title>. <source>Nat Methods</source> <volume>16</volume>, <fpage>111</fpage>–<lpage>116</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Desikan</surname>, <given-names>R. S.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>An automated labeling system for subdividing the human cerebral cortex on MRI scans into gyral based regions of interest</article-title>. <source>Neuroimage</source> <volume>31</volume>, <fpage>968</fpage>–<lpage>980</lpage> (<year>2006</year>).</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Eickhoff</surname>, <given-names>S. B.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Assignment of functional activations to probabilistic cytoarchitectonic areas revisited</article-title>. <source>Neuroimage</source> <volume>36</volume>, <fpage>511</fpage>–<lpage>521</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Fan</surname>, <given-names>L.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>The Human Brainnetome Atlas: A New Brain Atlas Based on Connectional Architecture</article-title>. <source>Cereb. Cortex</source> <volume>26</volume>, <fpage>3508</fpage>–<lpage>3526</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vann</surname>, <given-names>S. D.</given-names></string-name>, <string-name><surname>Aggleton</surname>, <given-names>J. P.</given-names></string-name> &amp; <string-name><surname>Maguire</surname>, <given-names>E. A.</given-names></string-name></person-group> <article-title>What does the retrosplenial cortex do?</article-title> <source>Nat Rev Neurosci</source> <volume>10</volume>, <fpage>792</fpage>–<lpage>802</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kuznetsova</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Brockhoff</surname>, <given-names>P. B.</given-names></string-name> &amp; <string-name><surname>Christensen</surname>, <given-names>R. H. B.</given-names></string-name></person-group> <article-title>lmerTest Package: Tests in Linear Mixed Effects Models</article-title>. <source>Journal of Statistical Software</source> <volume>82</volume>, <fpage>1</fpage>–<lpage>26</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Li</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Human spatial navigation: Neural representations of spatial scales and reference frames obtained from an ALE meta-analysis</article-title>. <source>NeuroImage</source> <volume>238</volume>, <fpage>118264</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Buckley</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>The well-worn route revisited: Striatal and hippocampal system contributions to familiar route navigation</article-title>. <source>Hippocampus</source> <volume>34</volume>, <fpage>310</fpage>–<lpage>326</lpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Brown</surname>, <given-names>T. I.</given-names></string-name> &amp; <string-name><surname>Stern</surname>, <given-names>C. E.</given-names></string-name></person-group> <article-title>Contributions of Medial Temporal Lobe and Striatal Memory Systems to Learning and Retrieving Overlapping Spatial Memories</article-title>. <source>Cereb. Cortex</source> <volume>24</volume>, <fpage>1906</fpage>–<lpage>1922</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Howard</surname>, <given-names>L. R.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>The Hippocampus and Entorhinal Cortex Encode the Path and Euclidean Distances to Goals during Navigation</article-title>. <source>Current Biology</source> <volume>24</volume>, <fpage>1331</fpage>–<lpage>1340</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Theves</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Fernandez</surname>, <given-names>G.</given-names></string-name> &amp; <string-name><surname>Doeller</surname>, <given-names>C. F.</given-names></string-name></person-group> <article-title>The Hippocampus Encodes Distances in Multidimensional Feature Space</article-title>. <source>Current Biology</source> <volume>29</volume>, <fpage>1226</fpage>–<lpage>1231.e3</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Peer</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Ron</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Monsa</surname>, <given-names>R.</given-names></string-name> &amp; <string-name><surname>Arzy</surname>, <given-names>S.</given-names></string-name></person-group> <article-title>Processing of different spatial scales in the human brain</article-title>. <source>eLife</source> <volume>8</volume>, <elocation-id>e47492</elocation-id> (<year>2019</year>). <pub-id pub-id-type="doi">10.7554/eLife.47492</pub-id></mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Javadi</surname>, <given-names>A.-H.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Hippocampal and prefrontal processing of network topology to simulate the future</article-title>. <source>Nat Commun</source> <volume>8</volume>, <fpage>14652</fpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Qiu</surname>, <given-names>L.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Functional specialization of medial and lateral orbitofrontal cortex in inferential decision-making</article-title>. <source>iScience</source> <volume>27</volume>, <fpage>110007</fpage> (<year>2024</year>).</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Liao</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Dissociable contributions of the hippocampus and orbitofrontal cortex to representing task space in a social context</article-title>. <source>Cerebral Cortex</source> <volume>34</volume>, <fpage>bhad447</fpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Malik</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Schamiloglu</surname>, <given-names>S.</given-names></string-name> &amp; <string-name><surname>Sohal</surname>, <given-names>V. S.</given-names></string-name></person-group> <article-title>Top-down control of hippocampal signal-to-noise by prefrontal long-range inhibition</article-title>. <source>Cell</source> <volume>185</volume>, <fpage>1602</fpage>–<lpage>1617</lpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Griffin</surname>, <given-names>A. L.</given-names></string-name></person-group> <article-title>The nucleus reuniens orchestrates prefrontal-hippocampal synchrony during spatial working memory</article-title>. <source>Neurosci. Biobehav. Rev</source>. <volume>128</volume>, <fpage>415</fpage>–<lpage>420</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rolls</surname>, <given-names>E. T.</given-names></string-name></person-group> <article-title>The hippocampus, ventromedial prefrontal cortex, and episodic and semantic memory</article-title>. <source>Progress in Neurobiology</source> <volume>217</volume>, <fpage>102334</fpage> (<year>2022</year>).</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Aggleton</surname>, <given-names>J. P.</given-names></string-name>, <string-name><surname>Poirier</surname>, <given-names>G. L.</given-names></string-name>, <string-name><surname>Aggleton</surname>, <given-names>H. S.</given-names></string-name>, <string-name><surname>Vann</surname>, <given-names>S. D.</given-names></string-name> &amp; <string-name><surname>Pearce</surname>, <given-names>J. M.</given-names></string-name></person-group> <article-title>Lesions of the fornix and anterior thalamic nuclei dissociate different aspects of hippocampal-dependent spatial learning: Implications for the neural basis of scene learning</article-title>. <source>Behavioral Neuroscience</source> <volume>123</volume>, <fpage>504</fpage>–<lpage>519</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bick</surname>, <given-names>S. K.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Caudate stimulation enhances learning</article-title>. <source>Brain</source> <volume>142</volume>, <fpage>2930</fpage>–<lpage>2937</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Dickerson</surname>, <given-names>B. C.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Prefrontal-hippocampal-fusiform activity during encoding predicts intraindividual differences in free recall ability: An event-related functional-anatomic MRI study</article-title>. <source>Hippocampus</source> <volume>17</volume>, <fpage>1060</fpage>–<lpage>1070</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Stangl</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Maoz</surname>, <given-names>S. L.</given-names></string-name> &amp; <string-name><surname>Suthana</surname>, <given-names>N.</given-names></string-name></person-group> <article-title>Mobile cognition: imaging the human brain in the ‘real world’</article-title>. <source>Nat Rev Neurosci</source> <volume>24</volume>, <fpage>347</fpage>–<lpage>362</lpage> (<year>2023</year>).</mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ekstrom</surname>, <given-names>A. D.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>Cellular networks underlying human spatial navigation</article-title>. <source>Nature</source> <volume>425</volume>, <fpage>184</fpage>–<lpage>188</lpage> (<year>2003</year>).</mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Ekstrom</surname>, <given-names>A. D.</given-names></string-name>, <string-name><surname>Spiers</surname>, <given-names>H. J.</given-names></string-name>, <string-name><surname>Bohbot</surname>, <given-names>V. D.</given-names></string-name> &amp; <string-name><surname>Rosenbaum</surname>, <given-names>R. S.</given-names></string-name></person-group> <source>Human Spatial Navigation</source>. (<publisher-name>Princeton University Press</publisher-name>, <publisher-loc>Princeton, New Jersey</publisher-loc>, <year>2018</year>).</mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Szucs</surname>, <given-names>D.</given-names></string-name> &amp; <string-name><surname>Ioannidis</surname>, <given-names>J. Pa</given-names></string-name></person-group>. <article-title>Sample size evolution in neuroimaging research: An evaluation of highly-cited studies (1990–2012) and of latest practices (2017–2018) in high-impact journals</article-title>. <source>NeuroImage</source> <volume>221</volume>, <fpage>117164</fpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bossier</surname>, <given-names>H.</given-names></string-name> <etal>et al.</etal></person-group> <article-title>The empirical replicability of task-based fMRI as a function of sample size</article-title>. <source>NeuroImage</source> <volume>212</volume>, <fpage>116601</fpage> (<year>2020</year>).</mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107265.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Kahnt</surname>
<given-names>Thorsten</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution-id institution-id-type="ror">https://ror.org/00fq5cm18</institution-id>
<institution>National Institute on Drug Abuse Intramural Research Program</institution>
</institution-wrap>
<city>Baltimore</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Useful</kwd>
</kwd-group>
</front-stub>
<body>
<p>The goal of this <bold>useful</bold> study is to examine learning-related changes in neural representations of global and local spatial reference frames in a spatial navigation task. Although the study addresses an interesting question, the evidence for neural representations in the hippocampus and retrosplenial cortex remains <bold>incomplete</bold> because of confounds in the experimental design and partial data analysis. There are further concerns about the framing of the study in the context of the relevant literature as well as the discussion.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107265.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>In this paper, Qiu et al. developed a novel spatial navigation task to investigate the formation of multi-scale representations in the human brain. Over multiple sessions and diverse tasks, participants learned the location of 32 objects distributed across 4 different rooms. The key task was a &quot;judgement of relative direction&quot; task delivered in the scanner, which was designed to assess whether object representations reflect local (within-room) or global (across-room) similarity structures. In between the two scanning sessions, participants received extensive further training. The goal of this manipulation was to test how spatial representations change with learning.</p>
<p>Strengths:</p>
<p>The authors designed a very comprehensive set of tasks in virtual reality to teach participants a novel spatial map. The spatial layout is well-designed to address the question of interest in principle. Participants were trained in a multi-day procedure, and representations were assessed twice, allowing the authors to investigate changes in the representation over multiple days.</p>
<p>Weaknesses:</p>
<p>Unfortunately, I see multiple problems with the experimental design that make it difficult to draw conclusions from the results.</p>
<p>(1) In the JRD task (the key task in this paper), participants were instructed to imagine standing in front of the reference object and judge whether the second object was to their left or right. The authors assume that participants solve this task by retrieving the corresponding object locations from memory, rotating their imagined viewpoint and computing the target object's relative orientation. This is a challenging task, so it is not surprising that participants do not perform particularly well after the initial training (performance between 60-70% accuracy). Notably, the authors report that after extensive training, they reached more than 90% accuracy.</p>
<p>However, I wonder whether participants indeed perform the task as intended by the authors, especially after the second training session. A much simpler behavioural strategy is memorising the mapping between a reference object and an associated button press, irrespective of the specific target object. This basic strategy should lead to quite high success rates, since the same direction is always correct for four of the eight objects (the two objects located at the door and the two opposite the door). For the four remaining objects, the correct button press is still the same for four of the six target objects that are not located opposite to the reference object. Simply memorising the button press associated with each reference object should therefore lead to a high overall task accuracy without the necessity to mentally simulate the spatial geometry of the object relations at all.</p>
<p>I also wonder whether the random effect coefficients might reflect interindividual differences in such a strategy shift - someone who learnt this relationship between objects and buttons might show larger increases in RTs compared to someone who did not.</p>
<p>(2) On a related note, the neural effect that appears to reflect the emergence of a global representation might be more parsimoniously explained by the formation of pairwise associations between reference and target objects. Since both objects always came from the same room, an RDM reflecting how many times an object pair acted as a reference-target pair will correlate with the categorical RDM reflecting the rooms corresponding to each object. Since the categorical RDM is highly correlated with the global RDM, this means that what the authors measure here might not reflect the formation of a global spatial map, but simply the formation of pairwise associations between objects presented jointly.</p>
<p>(3) In general, the authors attribute changes in neural effects to new learning. But of course, many things can change between sessions (expectancy, fatigue, change in strategy, but also physiological factors...). Baseline phsiological effects are less likely to influence patterns of activity, so the RSA analyses should be less sensitive to this problem, but especially the basic differences in activation for the contrast of post-learning &gt; pre-learning stages in the judgment of relative direction (JRD) task could in theory just reflect baseline differences in blood oxygenation, possibly due to differences in time of day, caffeine intake, sleep, etc. To really infer that any change in activity or representation is due to learning, an active control would have been great.</p>
<p>(4) RSA typically compares voxel patterns associated with specific stimuli. However, the authors always presented two objects on the screen simultaneously. From what I understand, this is not considered in the analysis (&quot;The β-maps for each reference object were averaged across trials to create an overall β-map for that object.&quot;). Furthermore, participants were asked to perform a complex mental operation on each trial (&quot;imagine standing at A, looking at B, then perform the corresponding motor response&quot;). Assuming that participants did this (although see points 1 and 2 above), this means that the resulting neural representation likely reflects a mixture of the two object representations, the mental transformation and the corresponding motor command, and possibly additionally the semantic and perceptual similarity between the two presented words. This means that the βs taken to reflect the reference object representation must be very noisy.</p>
<p>This problem is aggravated by two additional points. Firstly, not all object pairs occurred equally often, because only a fraction of all potential pairs were sampled. If the selection of the object pairs is not carefully balanced, this could easily lead to sampling biases, which RSA is highly sensitive to.</p>
<p>Secondly, the events in the scanner are not jittered. Instead, they are phase-locked to the TR (1.2 sec TR, 1.2 sec fixation, 4.8 sec stimulus presentation). This means that every object onset starts at the same phase of the image acquisition, making HRF sampling inefficient and hurting trial-wise estimation of betas used for the RSA. This likely significantly weakens the strength of the neural inferences that are possible using this dataset.</p>
<p>(5) It is not clear why the authors focus their report of the results in the main manuscript on the preselected ROIs instead of showing whole-brain results. This can be misleading, as it provides the false impression that the neural effects are highly specific to those regions.</p>
<p>(6) I am missing behavioural support for the authors' claims.</p>
<p>Overall, I am not convinced that the main conclusion that global spatial representations emerge during learning is supported by the data. Unfortunately, I think there are some fundamental problems in the experimental design that might make it difficult to address the concerns.</p>
<p>However, if the authors can provide convincing evidence for their claims, I think the paper will have an impact on the field. The question of how multi-scale representations are represented in the human brain is a timely and important one.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107265.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Qui and colleagues studied human participants who learned about the locations of 32 different objects located across 4 different rooms in a common spatial environment. Participants were extensively trained on the object locations, and fMRI scans were done during a relative direction judgement task in a pre- and post-session. Using RSA analysis, the authors report that the hippocampus increased global relative to local representations with learning; the RSC showed a similar pattern, but also increased effects of both global and local information with time.</p>
<p>Strengths:</p>
<p>(1) The manuscript asks a generally interesting question concerning the learning of global versus local spatial information.</p>
<p>(2) The virtual environment task provides a rich and naturalistic spatial setting for participants, and the setup with 32 objects across 4 rooms is interesting.</p>
<p>(3) The within-subject design and use of verbal cues for spatial retrieval is elegant .</p>
<p>Weaknesses:</p>
<p>(1) My main concern is that the global Euclidean distances and room identity are confounded. I fear this means that all neural effects in the RSA could be alternatively explained by associations to the visual features of the rooms that build up over time.</p>
<p>(2) The direction judgement task is not very informative about cognitive changes, as only objects in a room are compared. The setup also discourages global learning, and leaves unclear whether participants focussed on learning the left/right relationships required by the task.</p>
<p>(3) With N = 23, the power is low, and the effects are weak.</p>
<p>(4) It appears no real multiple comparisons correction is done for the ROI based approach, and significance across ROIs is not tested directly.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.107265.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The manuscript by Qui et al. explores the issue of spatial learning in both local (rooms) and global (connected rooms) environments. The authors perform a pointing task, which involves either pressing the right or left button in the scanner to indicate where an object is located relative to another object. Participants are repeatedly exposed to rooms over sessions of learning, with one &quot;pre&quot; and one &quot;post&quot; learning session. The authors report that the hippocampus shifted from lower to higher RSA for the global but not the local environment after learning. RSC and OFC showed higher RSA for global object pointing. Other brain regions also showed effects, including ACC, which seemed to show a similar pattern as the hippocampus, as well as other regions shown in Figure S5. The authors attempt to tie their results in with local vs. global spatial representations.</p>
<p>Strengths:</p>
<p>Extensive testing of subjects before and after learning a spatial environment, with data suggesting that there may be fMRI codes sensitive to both global and local codes. Behavioral data suggest that subjects are performing well at the task and learning both global and local object locations, although see further comments.</p>
<p>Weaknesses:</p>
<p>(1) The authors frame the entire introduction around confirming the presence of the cognitive map either locally or globally. There are some significant issues with this framing. For one, the introduction appears to be confirmatory and not testing specific hypotheses that can be falsified. What exactly are the hypotheses being tested? I believe that this relates to the testing whether neural representations are global and/or local. However, this is not clear. Given that a previous paper (Marchette et al. 2014 Nature Neuro, which bears many similarities) showed only local coding in RSC, this paper needs to be discussed in far more depth in terms of its similarities and differences. This paper looked at both position and direction, while the current paper looks at direction. Even here, direction in the current study is somewhat impoverished: it involves either pointing right or left to an object, and much of this could be categorical or even lucky guesses. From what I could tell, all behavioral inferences are based on reaction time and not accuracy, and therefore, it is difficult to determine if the subject's behavior actually reflects knowledge gained or simply faster reaction time, either due to motor learning or a speed-accuracy trade-off. The pointing task is largely egocentric: it can be solved by remembering a facing direction and an object relative to that. It is not the JRD task as has been used in other studies (e.g., Huffman et al. 2019 Neuron), which is continuous and has an allocentric component. This &quot;version&quot; of the task would be largely egocentric. In this way, the pointing task used does not test the core tenets of the cognitive map during navigation, which is defined as allocentric and Euclidean (please see O'Keefe and Nadel 1978, The Hippocampus as a Cognitive Map). Since neither of these assumptions appears valid, the paper should be reframed to reflect spatial representations more broadly or even egocentric spatial representations.</p>
<p>(2) The fMRI data workup is insufficient. What do the authors mean by &quot;deactivations&quot; in Figure 3b? Does this mean the object task showed more activation than the spatial task in HSC? Given that HSC is one of these regions, this would seem to suggest that the hippocampus is more involved in object than spatial processing, although it is difficult to tell from how things are written. The RSA is more helpful, but now a concern is that the analysis focuses on small clusters that are based on analyses determined previously. This appears to be the case for the correlations shown in Figure 3e as well. The issues here are several-fold. For one, it has been shown in previous work that basing secondary analyses on related first analyses can inflate the risk of false positives (i.e., Kriegeskorte et al. 2009 Nature Neuro). The authors should perform secondary analyses in ways that are unbiased by the first analyses, preferably, selecting cluster centers (if they choose to go this route) from previous papers rather than their own analyses. Another option would be to perform analyses at the level of the entire ROI, meaning that the results would generalize more readily. The authors should also perform permutation tests to ensure that the RSA results are reliable, as these can run the risk of false positives (e.g., Nolan et al. 2018 eNeuro). If these results hold, the authors should perform post-hoc (corrected) t-tests for global vs. local before and after learning to ensure these differences are robust and not simply rely on the interaction effect. The figures were difficult to follow in this regard, and an interaction effect does not necessarily mean the differences that are critical (global higher than local after) are necessarily significant. The end part of the results was hard to follow. If ACC showed a similar effect to HC and RSC, why is it not being considered? Many other areas that seemed to show local vs. global effects were dismissed, but these should instead be discussed in terms of whether they are consistent or inconsistent with the hypotheses.</p>
<p>(3) Concerns about the discussion: there are areas involving reverse inference about brain areas rather than connecting the findings with hypotheses (see Poldrack et al. 2006 Trends in Cognitive Science). The authors also argue for 'transfer&quot; of information (for example, from ACC to OFC), but did not perform any connectivity analyses, so these conclusions are not based on any results. Instead, the authors should carefully compare what can be concluded from the reaction time findings and the fMRI data. What is consistent vs. inconsistent with the hypotheses? The authors should also provide a much more detailed comparison with past work. The Marchette et al. paper comes to different conclusions regarding RSC and involves more detailed analyses than those done here, including position. What is different in the current paper that might explain the differences in results? Another previous paper that came to a different conclusion (hippocampus local, retrosplenial global) and should be carefully considered and compared, as it also involved learning of environments and comparisons at different phases (e.g., Wolbers &amp; Buchel 2005 J Neuro). Other papers that have used the JRD task have demonstrated similar, although not identical, networks (e.g., Huffman et al. 2019 Neuron) and the results here should be more carefully compared, as the current task is largely egocentric while the Huffman et al. paper involves a continuous and allocentric version of the JRD task.</p>
<p>(4) The authors cite rodent papers involving single neuron recordings. These are quite different experiments, however: they involve rodents, the rodents are freely moving, and single neurons are recorded. Here, the study involves humans who are supine and an indirect vascular measure of neural activity. Citations should be to studies of spatial memory and navigation in humans using fMRI: over-reliance on rodent studies should be avoided for the reasons mentioned above.</p>
</body>
</sub-article>
</article>