<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">94727</article-id>
<article-id pub-id-type="doi">10.7554/eLife.94727</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.94727.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.2</article-version>
</article-version-alternatives>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Learned response dynamics reflect stimulus timing and encode temporal expectation violations in superficial layers of mouse V1</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Knudstrup</surname>
<given-names>Scott G.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Martinez</surname>
<given-names>Catalina</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8420-8973</contrib-id>
<name>
<surname>Gavornik</surname>
<given-names>Jeffrey P.</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="corresp" rid="cor1">*</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Center for Systems Neuroscience, Department of Biology, Boston University</institution>, Boston, MA 02215</aff>
<aff id="a2"><label>2</label><institution>Neurophotonics Center, Boston University</institution>, Boston, MA, 02215</aff>
<aff id="a3"><label>3</label><institution>Graduate Program in Neuroscience, Boston University</institution>, Boston, MA 02215</aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Sharpee</surname>
<given-names>Tatyana O</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Salk Institute for Biological Studies</institution>
</institution-wrap>
<city>La Jolla</city>
<country>United States of America</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Moore</surname>
<given-names>Tirin</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>Stanford University, Howard Hughes Medical Institute</institution>
</institution-wrap>
<city>Stanford</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>*</label>Correspondence should be addressed to JPG (<email>gavornik@bu.edu</email>)</corresp>
</author-notes>
<pub-date date-type="original-publication" iso-8601-date="2024-03-13">
<day>13</day>
<month>03</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP94727</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-01-19">
<day>19</day>
<month>01</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-02-11">
<day>11</day>
<month>02</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.01.20.576433"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Knudstrup et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Knudstrup et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-94727-v1.pdf"/>
<abstract>
<title>Abstract</title><p>The ability to recognize ordered event sequences is a fundamental component of sensory cognition and underlies the capacity to generate temporally specific expectations of future events based on previous experience. Various lines of evidence suggest that the primary visual cortex participates in some form of predictive processing, but many details remain ambiguous. Here we use two-photon calcium imaging in layer 2/3 (L2/3) of the mouse primary visual cortex (V1) to study changes to neural activity under a multi-day sequence learning paradigm with respect to prediction error responses, stimulus encoding, and time. We find increased neural activity at the time an expected, but omitted, stimulus would have occurred but no significant prediction error responses following an unexpected stimulus substitution. Sequence representations became sparser and less correlated with training, although these changes had no effect on decoding accuracy of stimulus identity or timing. Additionally, we find that experience modifies the temporal structure of stimulus responses to produce a bias towards predictive stimulus-locked activity. Finally, we find significant temporal structure during intersequence rest periods that was largely unchanged by training.</p>
</abstract>

</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Corrected mislabeled figures.</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>Repeated exposure to visual sequences shapes responses in mouse primary visual cortex (V1) in a sequence- and timing-specific manner (<xref ref-type="bibr" rid="c11">Gavornik &amp; Bear, 2014</xref>; <xref ref-type="bibr" rid="c28">Price et al., 2023</xref>; <xref ref-type="bibr" rid="c29">Sidorov et al., 2020</xref>; <xref ref-type="bibr" rid="c32">Tang et al., 2023</xref>). While the functional implication of these modifications is unclear, proponents of predictive processing theories have posited that the changes in visually evoked responses over days of spatiotemporal sequence exposure represent a physiological consequence of plasticity through which cortical circuits learn to predict statistical regularities in the environment. According to the predictive coding model (recently reviewed in <xref ref-type="bibr" rid="c16">Keller &amp; Mrsic-Flogel, 2018</xref>), heightened responses when visual inputs do not match internally generated predictions constitute a prediction-error signal that carries information about the identity of the unexpected stimulus and the degree of its unlikelihood. While a variety of evidence from primary sensory regions supports this basic framework (<xref ref-type="bibr" rid="c1">Audette &amp; Schneider, 2023</xref>; <xref ref-type="bibr" rid="c7">Eliades &amp; Wang, 2008</xref>; <xref ref-type="bibr" rid="c8">Fiser et al., 2016</xref>; <xref ref-type="bibr" rid="c15">Keller et al., 2012</xref>; <xref ref-type="bibr" rid="c31">Stanley &amp; Miall, 2007</xref>; <xref ref-type="bibr" rid="c35">Zmarz &amp; Keller, 2016</xref>), the degree to which predictive coding theories can explain visually evoked responses is unclear. Our lab recently used extracellularly recorded multi-unit activity to investigate how passive exposure to spatiotemporal patterns modifies cells at the layer 4/5 boundary (<xref ref-type="bibr" rid="c28">Price et al., 2023</xref>) and found evidence for temporally specific activity consistent with prediction errors in these cells though not to the extent originally observed with LFP-based recordings (<xref ref-type="bibr" rid="c11">Gavornik &amp; Bear, 2014</xref>). The convergence of bottom-up and top-down signals in L2/3 suggests that it hosts comparison circuits required in the predictive coding model, an idea supported by recent experiments in the context of visuomotor feedback (<xref ref-type="bibr" rid="c14">Jordan &amp; Keller, 2020</xref>). Accordingly, we sought to determine whether cells in L2/3 generate prediction errors when presented with modifications to a training sequence repeatedly viewed over 5 days of training.</p>
<p>One notable aspect of our previous work is that responses to a predicted sequence are modified when the constituent elements are presented with the expected order but novel timing. Accurately predicting when events will occur requires forming memories that explicitly encode temporal durations and some sort of internal clock to track elapsed time relative to stimulus events. While temporal processing has been studied in many brain areas, including hippocampus (<xref ref-type="bibr" rid="c21">Kraus et al., 2013</xref>; <xref ref-type="bibr" rid="c23">MacDonald et al., 2011</xref>; <xref ref-type="bibr" rid="c26">Pastalkova et al., 2008</xref>), entorhinal cortex (<xref ref-type="bibr" rid="c13">Heys &amp; Dombeck, 2018</xref>; <xref ref-type="bibr" rid="c20">Kraus et al., 2015</xref>; <xref ref-type="bibr" rid="c33">Tsao et al., 2018</xref>), sensory thalamus (<xref ref-type="bibr" rid="c19">Komura et al., 2001</xref>), and motor cortex (<xref ref-type="bibr" rid="c2">Balasubramaniam et al., 2021</xref>) and the visual cortex (<xref ref-type="bibr" rid="c3">Benucci et al., 2009</xref>; <xref ref-type="bibr" rid="c28">Price et al., 2023</xref>), there are still gaps in understanding how experience encodes temporal expectations into neural circuits.</p>
<p>We used an implicit sequence learning paradigm and two-photon Ca imaging to study how exposure to visual sequences shape L2/3 responses in head-fixed mice when ordinal or temporal expectations are violated. After baseline imaging sessions, mice were exposed to a single training sequence for four consecutive days. On the fifth day, we exposed the mice to the training sequence and two test sequences designed to elicit temporal or ordinal prediction errors. We found little evidence of prediction errors when elements were presented with an unexpected order, but did find elevated activity at the time an omitted element should have been presented that we interpret as a form of temporal prediction error. Though evoked response dynamics are modified with training, decorrelating and shifting towards stimulus-locked responses, this has no obvious advantage for decoding elapsed time or stimulus identity at the population level. Finally, we find temporally specific activity in the gray inter-sequence period.</p>
</sec>
<sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Experimental design</title>
<p>We used a multiday experimental protocol in which mice were exposed to a standard sequence (ABCD) and two variants (ABBD and ACBD) designed to elicit positive (unexpected element C in the B position) and negative (element C omitted by keeping B on the screen for twice the expected duration) prediction errors (<xref rid="fig1" ref-type="fig">figure 1A</xref>). To establish a baseline for comparison, mice viewed all three sequences on day 0 (pre-training). After two days with no visual stimulation, mice were then show the ABCD sequence exclusively during days 1-4 (training). On day 5, mice saw all three sequences again (testing). The training period serves to build an expectation for the sequence ABCD, while the day 0 baseline allowed us to compare responses to all sequences before and after the ABCD had been established as the expected sequence.</p>
<fig id="fig1" position="float" orientation="portrait" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Experimental design</title>
<p>(A) Awake head-fixed mice viewed sequences of oriented gratings while undergoing two-photon imaging of V1. Location of V1 was determined by widefield retinotopic mapping prior to experiment. Mice saw ABCD, ABBD, and ACBD for day 0 (pre-training) and day 5 (test) and ABCD only for the four days in between (training). Each image was shown for 250 ms, and sequences were separated by an 800 ms gray screen. (B) Fluorescence extracted from ROIs was deconvolved prior to analysis. (C) Trial-averaged responses of 1368 cells on day 0 to sequence ABCD.</p></caption>
<graphic xlink:href="576433v2_fig1.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Mice were awake and head fixed while viewing stimuli during all sessions. Sequences were composed of four oriented gratings, each of which was presented for 250 ms for a total sequence length of 1 second and sequence presentations were separated by 800 ms of gray screen. Sequences were presented in 5 blocks of 100 with a 30 second gray period between blocks. Since gratings transitioned directly one into another, element B in ABBD was essentially a single element lasting 500 ms and there was no visual indicator of when the first B ended and second began. We notate individual sequence elements using bold lettering (e.g., A<bold>B</bold>CD refers to B in ABCD). As detailed in the Methods section, ROIs designating visually responsive somas were identified. The average pixel fluorescence value within each ROI was calculated for each frame and this signal was deconvolved in time (<xref ref-type="bibr" rid="c25">Pachitariu et al., 2016</xref>) to produce an activity metric with a relatively high degree of temporal precision relative to the underlying calcium signal (<xref rid="fig1" ref-type="fig">figure 1B</xref>). This approach produced a population of neural responses that clearly shows unique responses to each element of the sequence with activity spanning the entire period of stimulation (<xref rid="fig1" ref-type="fig">figure 1C</xref>).</p>
<p>Binocular visual cortex was identified via retinotopic stimulation (see Methods) and landmarks from reference images taken on day 0 were used to target same approximate population of neurons on 5. We imaged a total of 1368 and 1500 cells on days 0 and 1, respectively from 8 mice. Cells were categorized by stimulus-selectivity and visual responsiveness within the sequence (see <xref rid="tbl1" ref-type="table">Table 1</xref>). We did not track the response properties of individual neurons across training days, but the percent of neurons representing each element decreased by an average of 2.8 % between days 0 and 1 while the number of cells classified as gray responsive stayed approximately the same.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><title>Stimulus selectivity</title><p>Stimulus-selectivity for day 0 (n=1368) and day 5 (n=1500). A cell was considered stimulus-selective for an element if the average activity evoked by that stimulus was more than two standard deviations higher than any other stimulus.</p></caption>
<graphic xlink:href="576433v2_tbl1.tif" mimetype="image" mime-subtype="tiff"/>
</table-wrap>
</sec>
<sec id="s2b">
<title>Omissions, but not substitutions, drive prediction errors</title>
<p>The first goal of our experiments was to test whether layer 2/3 neurons display prediction errors in response to stimulus omissions or substitutions. The sequence ABBD contains an omission violation in sequence position 3 where since B is held on screen. The sequence ACBD contains a substitution violation at the second element since C appears where B is expected. The predictive coding model holds that both forms of expectation violation should result in elevated responses on day 5 relative to the day 0 baseline as diagramed in <xref rid="fig2" ref-type="fig">figure 2A</xref>.</p>
<fig id="fig2" position="float" orientation="portrait" fig-type="figure">
<label>Figure 2:</label>
<caption><title>Prediction errors</title>
<p>(A) Diagram of putative prediction error (PE) responses to omissions (middle) and substitutions (right) where the omitted/substituted element is expected to drive elevated responses on day 5 compared with day 0 (x indicates that this response is not present in our data). (B) PE ratios were computed by dividing trial- and time-averaged activity to the deviant image by activity during a corresponding standard image. (C) Average trace of B-responsive cells to ABCD with bootstrapped 95% confidence intervals. (D) Average trace of B-responsive cells to ABBD (left) and distributions of omission-type PE ratios (right) on days 0 (gray) and 5 (red). Note that there is no change in visual stimulus at the B1B2 transition. On day 0, mean PE=1.1 (n=138). On day 5, mean PE=1.4 (n=107). Distributions were significantly different (p &lt;&lt; 0.05; KS-test). (E) Average trace of C-responsive cells to ACBD (left) and ABCD (middle). (right) Distributions of substitution-type PE ratios for C-responsive cells. On day 0, mean PE=0.88 (n=88). On day 5, mean PE=0.84 (n=39). Day 0 and day 5 distributions were not significantly different (p&gt;0.05; KS-test).</p></caption>
<graphic xlink:href="576433v2_fig2.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We first classified cells based on their stimulus-selectivity with and without regard for sequence context (see Methods). This approach was designed to filter for cells that, for example, fire preferentially to element C in at either ABCD or ACBD. In this example, a cell that fires more during A<bold>C</bold>BD than AB<bold>C</bold>D would exhibit a pattern of excessive activity associated with prediction errors signals. We quantified this effect using a prediction error metric (PE) where the trial- and time-averaged activity during an unexpected event is divided by the activity during a similar but expected event. If training drives changes to prediction error responses, then the distribution of PE ratios should be significantly different before and after training.</p>
<p>To look for omission errors, we filtered for B-responsive cells and computed their PE ratios using AB<bold>B</bold>D and A<bold>B</bold>BD as the unexpected and expected stimuli, respectively (<xref rid="fig2" ref-type="fig">figure 2B</xref>, left). The average response to element B in position 2 increased slightly with training (<xref rid="fig2" ref-type="fig">figure 2C</xref>) and was approximately the same during the second position regardless of which stimulus followed on days 0 and 5 (<xref rid="fig2" ref-type="fig">figure 2</xref> C,D). Training produced significant differences in the temporal characteristics of B-responsive cells. On day 0, activity in B responsive neurons decreased consistently as the B element was held into position 3. After training, however, activity was elevated during this period with a slight increase following the point in time at which element C would normally be seen (<xref rid="fig2" ref-type="fig">figure 2D</xref>). The PE ratio increased significantly with training (p = 0.005, n=276; KS-test). We interpret this result, wherein evoked activity increases at a point in time where visual inputs are unchanging, as representing a temporally specific prediction error following the omission of an expected visual transition. This finding is broadly consistent with our previous findings in deep layer 4 (<xref ref-type="bibr" rid="c28">Price et al., 2023</xref>) and suggest that temporal prediction errors can be found in the population of excitatory neurons selective for an expected stimulus. We did not identify a separate population of otherwise sequence non-responsive “prediction error cells” uniquely activated during stimulus omissions as posited by some predictive coding models.</p>
<p>To look for substitution errors, we filtered for C-responsive cells and computed their PE ratios using the C response in both the unexpected and expected position within the sequence (<xref rid="fig2" ref-type="fig">figure 2B</xref>, right). If substitution drives a prediction error in following an unexpected substitution, the PE ratios for these cells would be approximately equal to 1 at baseline and higher than 1 after training. The average response to element C was higher at baseline than on day 5 (<xref rid="fig2" ref-type="fig">figure 2E</xref>). We found that mean PE ratios were approximately equal to 1 on both days, with a slight but statistically insignificant decrease following training (p = 0.64, n = 160; KS-test). Contrary to our expectations coming into this experiment, training did not facilitate a significant change in responses to the expected vs unexpected element during element substitutions. As with during the omission case, we did not identify a unique population of otherwise visually non-responsive “prediction error cells” following substitution. Overall, and in contrast to our previous publications, we find no evidence that unexpected ordinal substitutions drive elevated activity consistent with predictive coding models in excitatory layer 2/3 cells.</p>
</sec>
<sec id="s2c">
<title>Experience simplifies activity in principal component space and drives sparsification</title>
<p>Sequence responses on day 5 look qualitatively different at the population level relative to baseline (<xref rid="fig3" ref-type="fig">figure 3A</xref>). To quantify this observation, we performed principal component analysis on pre- and post-training datasets. Prior to training, stimuli drive activity along several axes in principal component space in complex combinations and the principal components do not neatly reflect activity driven by any particular sequence element (<xref rid="fig3" ref-type="fig">figure 3B</xref>). In contrast, activity in principal component space is highly discretized or “untangled” after training with clearly defined peaks reflecting sequence elements. Though the total number of principle components required to account for 90% of total variance did not change appreciably with training (approximately 10 PCs on days 0 and 5), the components accounting for the majority of variance neatly reflect specific sequence elements after training.</p>
<fig id="fig3" position="float" orientation="portrait" fig-type="figure">
<label>Figure 3:</label>
<caption><title>Principal Component and Sparsity Analysis</title>
<p>(A) Trial average population responses, sorted by time to peak latency in each cell, to each sequence before and after training. (B) Prior to training, activity is driven along principal components jointly in complex combinations. After training, each of the most significant principal components correspond neatly to individual stimuli. In both datasets, the first five components explain ∼80% of the variance. (C) To test whether changes in principal component space reflected the decorrelation of responses, we computed Pearson-correlation coefficients between all four images for each sequence presentation individually. Empirical PDFs (top panels) and CDFs (bottom panels) of Pearson-correlation coefficients. After training, activity became significantly less correlated (p &lt; 0.05; KS-test) for ABCD and ACBD. Delta (Δ) on bottom panels indicates area between curves on CDFs.</p></caption>
<graphic xlink:href="576433v2_fig3.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Training also facilitated a reduction in the fraction of neurons that responded preferentially to individual stimuli. Prior to training, 40.8% of neurons were driven more than two standard deviations above their baseline firing rate by one of the stimuli compared with 27.1% after training. We also quantified how many cells were “visually modulated”, a more permissive metric that simply compares activity between gray and non-gray periods. Under this measure, the percentages of visually modulated cells went from 72% on day 0 to 60% after training. Overall, responses are sparser after training than at baseline.</p>
<p>Since information theory holds that codes gain efficiency by eliminating redundant information (see <xref ref-type="bibr" rid="c27">Price &amp; Gavornik 2022</xref> of how this relates to predictive coding in the visual system), we also examined correlation coefficients between stimuli to determine if our day 5 activity was less correlated than day 0 activity. For each sequence presentation, we calculated the Pearson correlation coefficients between all pairs of stimuli, yielding a collection of coefficients for each sequence on each day (<xref rid="fig3" ref-type="fig">figure 3C</xref>). We found that correlations were reduced by 10-20% on day 5 compared with day 0. Across all sequences, the differences in correlation distributions were significantly different between days (ABCD: p &lt; 1e-3, n=6000; ACBD: p &lt; 1e-3, n=6000; KS-test). This, coupled with the overall decrease in number of cells responding to visual stimulation, suggests that experience-dependent spatiotemporal plasticity increases coding efficiency.</p>
</sec>
<sec id="s2d">
<title>Plasticity does not increase decoding accuracy</title>
<p>Our principal component analysis suggests that experience creates representations that are more easily separable in high-dimensional space. To test whether experiential shaping of cortical circuits increases the ability to differentiate between different visual stimuli, we trained a linear decoder with responses from all stimulus contexts (<xref rid="fig4" ref-type="fig">figure 4A</xref>). We found that accuracy was well above chance (1/15 = 6.7% ± 0.4%) on day 0 (78%) and day 5 (76%) and that the decoder was able to discriminate between cases we expected to be indistinguishable. For example, we expected <bold>A</bold>BCD would be more-or-less indistinguishable from <bold>A</bold>BBD and <bold>A</bold>CBD since A occurs first in each sequence and always preceded by a long (800 ms) gray period. This was not the case. Most often, the decoder correctly identified which sequence stimulus A came from. This pattern was observed with other cases as well, including the intersequence gray periods.</p>
<fig id="fig4" position="float" orientation="portrait" fig-type="figure">
<label>Figure 4:</label>
<caption><title>Stimulus decoding and representational drift</title>
<p>(<bold>A</bold>) Average confusion matrices (100 iterations) for decoders trained on responses to all images. Average decoder accuracy was 78% and 76% for days 0 and 5, respectively. Both are well above chance (6.7% ± 0.4%). The ability to differentiate correctly between the same image in different contexts, such as <bold>A</bold>BCD vs <bold>A</bold>BBD, prompted us to consider whether responses slowly drifted over time since sequences were presented in large blocks. (B) A decoder trained on individual elements (for example, <bold>A</bold>BCD) accurately classifies which block responses came from, with errors decreasing along with distance between blocks (e.g., block 1 is often confused with block 2 but not block 5). Decoder accuracy was 68% on day 0 and 56% on day 5. (C) We measured drift by computing Pearson-correlation coefficients between all pairs of population vectors driven by a particular sequence element and grouped these values by how far apart the pairs were in time/trial. Responses clearly become less correlated as distance between trials increases during both stimulus-evoked and gray periods. The largest change in overall temporal correlation was seen between gray periods on days 0 and 5.</p></caption>
<graphic xlink:href="576433v2_fig4.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We next trained a decoder with data from the same sequence element (e.g., <bold>A</bold>BCD) and found that decoder accurately predicted which block the stimulus came from and that the rate of false positives decreased with time (<xref rid="fig4" ref-type="fig">figure 4B</xref>). This implied a slow, continuous change in stimulus representations. We found no significant change in overall firing rates that might indicate that this effect could be a consequence of adaptation, repetition suppression, or photobleaching (effects that should be minimized anyway by our use of deconvolved data).</p>
<p>To understand how the decoder was able to accurately determine which block stimuli came from, we computed Pearson-correlation coefficients between all population vectors for a given sequence element and found that vector similarity falls away with time between presentations (<xref rid="fig4" ref-type="fig">figure 4C</xref>). These findings suggest that there is a measurable amount of representational drift across a single 30 min recording session in V1 and are consistent with previous work on representational drift in V1 (<xref ref-type="bibr" rid="c6">Deitch et al., 2021</xref>). The amount of drift within a session was comparable on days 0 and 5, with a slightly elevated drift rate on day 5. This was especially pronounced in gray periods, which were significantly more variable on day 5.</p>
</sec>
<sec id="s2e">
<title>Experience facilitates stimulus-locked responses and temporal echoes</title>
<p>To analyze changes in stimulus locking and how post-onset durations are represented in the brain, we assigned a time bin to each cell based on its point of maximal activity (<xref rid="fig5" ref-type="fig">figure 5A</xref>, also see Methods). At baseline, few cells have peak firing times immediately after stimulus onset and the percent of cells with late maximal response times increases gradually over each stimulus (<xref rid="fig3" ref-type="fig">figure 3B</xref>). After training, the pattern is reversed. More cells fire maximally at or near stimulus onset, and the number of cells that fire at intermediate time points decreases, and there is a sizeable population of cells that fires immediately before the next stimulus transition. There is no obvious shift in response latencies following stimulus substitution or omission, though the response profile to element D is disrupted in both cases after training relative to baseline. Despite the shift in temporal response latency profiles, the ability of a linear decoder to determine time within the stimulation period did not increase following training (<xref rid="fig5" ref-type="fig">figure 5C</xref>).</p>
<fig id="fig5" position="float" orientation="portrait" fig-type="figure">
<label>Figure 5:</label>
<caption><title>Stimulus responses</title>
<p>(A) Heatmaps display trial-averaged responses to all sequences sorted by peak response to ABCD. Histograms reflect locations of peak activity for each cell and shift towards stimulus locked phasic responses after training. Red and green rectangles highlight area of decreased and increased activity on day 5 relative to baseline. (B) Combining histograms across all stimulus conditions shows how temporal response latency patterning changes over days. Note that the first two time bins (66 ms) after onsets are omitted in histograms to compensate for the transmission delay from retina to L2/3 cells. Prior to training, responses slowly build up after onset. After training, responses are robust at onset and undergo quick depression prior to ramping up for the next element. Histograms based only on early trials (first 100) show that this pattern does not change significantly over the course of the imaging session. (C) To test whether changes to temporal patterning might reflect a change in the ability to discern durations, we trained decoders on responses from different time bins following sequence onset. Decoder accuracy did not change significantly with training.</p></caption>
<graphic xlink:href="576433v2_fig5.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>We performed the same analysis on the intersequence gray periods and found that a subpopulation of cells was activated ∼300 ms after gray period onset (<xref rid="fig6" ref-type="fig">figure 6</xref>), slightly later than the 250 ms interval suggested by the temporal structure of our visual sequence. A second population of cells exhibited ramping activity leading up to the end of the 800 ms gray period. While this response looks like it anticipates the onset of the next sequence, it is present at baseline including in early trials and did not change significantly with training. The only noticeable difference after training is a decrease in the percentage of cells firing early in the gray period on day 5 relative to baseline. Overall, the static nature of temporal firing patterns during the gray period contrasts with the evolution of stimulus-driven temporal patterning over days.</p>
<fig id="fig6" position="float" orientation="portrait" fig-type="figure">
<label>Figure 6:</label>
<caption><title>Gray responses</title>
<p>(A) Heatmaps displaying trial-averaged responses during gray periods following sequence presentations. Cells were sorted by peak response time to ABCD (top panels) and gray periods only (middle panels). Histograms (bottom) reflect locations of peak activity for each cell and show that there is an increase in active population size about 300 ms after gray onset and a second uptick towards preceding the next sequence presentation at 800 ms. (B) Average confusion matrices (100 iterations) for decoders trained on responses at different delays from gray onset for day 0 (left), day 5 (middle), and the difference between them (right). (C) Overall decoder accuracy as a function of time since gray onset did not change significantly with training.</p></caption>
<graphic xlink:href="576433v2_fig6.tif" mimetype="image" mime-subtype="tiff"/>
</fig>
<p>Temporal decoding accuracy during the gray period was highest early, with small increases around the 300 ms peak and 800 ms ramp. As we saw with sequence evoked responses, temporal decoding accuracy did not change significantly over days.</p>
<p>To assess whether these changes in temporal pattern allowed the brain to more precisely represent durations, we trained a decoder on population vectors classified by their time bin and asked the decoder to classify testing data by which time bin it belonged to (<xref rid="fig5" ref-type="fig">figures 5C</xref>, 6C).</p>
<p>Decoding was performed 100 times from which mean and 95% confidence intervals for decoder accuracy were generated. We found no significant change in temporal decoding during either sequence or intersequence gray periods. On average, decoding accuracy was 23.4% on day 0 and 23.4% on day 5. Both are well above chance (3.1% ± 0.2%). However, we did notice that decoding accuracy does not decline uniformly after the onset of a gray period. There are moderate increases in decoding accuracy in about 300-400 ms and nearing the end of the 800 ms gray period.</p>
</sec>
</sec>
<sec id="s3">
<title>Discussion</title>
<p>In this study, we used chronic two-photon imaging to measure activity in L2/3 of mouse V1 during passive exposure to standard and deviant visual sequences before and after a four-day training period. This study was designed to test the hypotheses that neurons in L2/3 exhibit prediction error responses elicited by expectation violations by comparing how V1 responded to identical sequence before and after exposure established an expectation of how different sequence elements relate to each other in time. We focused on two types of violations (omissions and substitutions) and found mixed support for hypothesized prediction errors. We also found that experience yielded a sparsification of neural responses in the form of fewer visually responsive cells. Response vectors in principal component space were also altered by experience, yielding simpler more compartmentalized representations after training. Finally, we found changes in the temporal code that reveal a reorganization of stimulus-driven activity and possible evidence of temporal predictions.</p>
<p>When an expected transition was omitted by holding the preceding image on the screen, we found an elevated response after training that peaked when the omitted element would have been seen and was sustained throughout the omitted stimulus period. This contrasted with a decaying response observed at baseline. The temporal specificity of the response supports our previous findings that V1 responses are actively modulated by temporal expectations formed during exposure to spatiotemporal visual sequences (<xref ref-type="bibr" rid="c28">Price et al., 2023</xref>). Other work outside of our lab has provided evidence for omission-errors in L2/3 of V1, but the experimental paradigms vary in ways that make direct comparisons difficult. <xref ref-type="bibr" rid="c8">Fiser <italic>et al</italic>. 2016</xref> found a subset of cells that responded anticipatorily to an omitted grating that was expected be found at a particular location along a linear track. In this case, the task involved spatial location, locomotion, water reward, and perhaps most crucially, the complete omission of a grating at an expected location rather than a held-over grating and no predetermined timing of the grating presentations. In another study, Garrett <italic>et al</italic>. observed ramping activity in vasoactive intestinal peptide (VIP) expressing inhibitory cells but not excitatory cells in L2/3 in response to an omitted image (<xref ref-type="bibr" rid="c10">Garrett et al., 2020</xref>). The images were separated by 500 ms gray periods and omitted activity could have been predicated in part by visual transitions that were absent here and in <xref ref-type="bibr" rid="c28">Price <italic>et al</italic>. 2023</xref>.</p>
<p>When an expected grating was substituted with a different (but familiar) grating, we did not observe elevated activity consistent with predictive coding theory. As with omission-type errors, we implemented a strategy to filter out cells deemed non-responsive to the substituted element in any context since 1. predictive coding theory posits that prediction-error signals are feature-specific (<xref ref-type="bibr" rid="c16">Keller &amp; Mrsic-Flogel, 2018</xref>) and 2. such a highly specific signal may be too small in comparison with total activity to elicit noticeable changes in global activity levels. This negative result is consistent with recent work in monkey V1 and human EEG that found little evidence of substitution-type prediction errors in a conceptually similar experiment involving passive exposure to standard and deviant visual sequences (<xref ref-type="bibr" rid="c30">Solomon et al., 2021</xref>). However, in Solomon et al., the electrodes read from an unknown cortical depth, and so it is possible that few prediction error responses were found due to a mismatch between lamina recorded and lamina involved in prediction errors. It is also possible that the dynamics of calcium imaging (both the dynamics of the calcium signals and frame rate of two photon acquisition) are too slow to accurately capture prediction error responses. This has been suggested as an explanation for why Stimulus Selective Response potentiation, a similar but mechanistically distinct form of visual plasticity, is not readily apparent in calcium signals (Montgomery et al., 2022). Recent work in the auditory cortex found that prediction error cells respond with rapid, transient responses lasting only about 40 ms (<xref ref-type="bibr" rid="c1">Audette and Schneider, 2023</xref>). Finally, we cannot rule out that exposure to the ACBD sequence during baseline prevented an error by durably encoding this sequence as “familiar”. Regardless, this finding is in relatively stark contrast to the large effect seen in LFP data when sequence elements are reordered after training (<xref ref-type="bibr" rid="c11">Gavornik &amp; Bear, 2014</xref>; <xref ref-type="bibr" rid="c29">Sidorov et al., 2020</xref>). This discrepancy could reflect the fact that the LFP represents dendritic currents (e.g. inputs, see <xref ref-type="bibr" rid="c5">Buzsáki et al. 2012</xref>) rather than somatic spiking (e.g. outputs) and includes inhibitory activity that we are functionally blind to in these experiments. Additional work is required to resolve this issue.</p>
<p>Consistent with principles of efficient coding (<xref ref-type="bibr" rid="c27">Price &amp; Gavornik 2022</xref>), we found that training had the effect of creating relatively sparse response patterns. Using two different measures, we estimate that the training reduced the number of visually modulated cells by 20-30%. The sparsification may be related with the qualitative changes in principal component space where training creates principal components with dynamics that neatly corresponded to individual stimuli. In addition to being more efficient, a sparser orthogonalized code could also be easier for other brain regions to interpret. Admittedly, this argument would be stronger if element or temporal decoding accuracy had increased with training. While it is certainly true that brain processes operate very differently than a linear decoder, and may take greater advantage of modified dynamics, it is also worth noting that the decoders on day 5 were as accurate as those trained against baseline data despite the smaller proportion of visually responsive neurons on day 5.</p>
<p>Neural sequences have been proposed as one of several mechanisms for representing durations, and there is growing support for this regime in different parts of the brain (<xref ref-type="bibr" rid="c34">Tsao et al., 2022</xref>). In this view, different cells fire preferentially at different delays relative to the onset of an external event, thereby forming a stable neural trajectory from which different points in time can be read out. We speculated that the distribution of observed “time fields” (i.e., locations of peak activity) might be altered with training in some way to reflect the 250 ms stimulus durations. By focusing our analysis on cells with consistently timed activity, we found significant differences in sequential activation following training. Prior to training, relatively few cells peaked at or near stimulus onset, and time fields distributions became increasingly densely throughout the ∼200 ms post-onset window (<xref rid="fig5" ref-type="fig">Figure 5B</xref>). After training, more cells peaked at stimulus onsets, and intermediate durations were less densely represented. Our analysis of time fields during the interstimulus gray period showed a surprising degree of temporal structure, though no evidence of experience dependent plasticity. A cluster of peaks in the 300 and 750 ms ranges are tantalizingly close to the 250 ms element time and 800 ms gray period intervals, but the fact that they are in early traces from baseline recordings makes it unlikely to reflect anything like a learned response. These peaks might be related to visually evoked theta-range oscillations reported previously (<xref ref-type="bibr" rid="c9">Gao et al., 2021</xref>; <xref ref-type="bibr" rid="c18">Kissinger et al., 2020</xref>; <xref ref-type="bibr" rid="c22">Levy et al., 2017</xref>; <xref ref-type="bibr" rid="c36">Zold &amp; Hussain Shuler, 2015</xref>) though these are reported to develop with familiarity (<xref ref-type="bibr" rid="c17">Kissinger et al., 2018</xref>).</p>
<p>Our findings build on previous work to show that sequence plasticity modifies evoked responses in superficial layers in a manner consistent with that seen in thalamocortical input layers. Overall, the work continues the recent tradition of providing ambiguous support for the idea that cortical dynamics are best described by predictive coding models while simultaneously demonstrating that evoked dynamics in V1 are far more complex than canonical visual processing models suggest.</p>
</sec>
<sec id="s4">
<title>Methods</title>
<sec id="s4a">
<title>Animal subjects</title>
<p>A total of eight mice (3 male, 5 female) aged 2-5 months were used for this study [CaMKII-tTA:tetO-GCaMP6s (Jackson Laboratories stock numbers 007004 and 024742)]. Mice were housed in a climate-controlled environment on a standard 12-hour light-dark cycle and were provided with food and water <italic>ad libitum</italic>. Cranial windows were implanted in mice at P40-P70. Experiments were performed during the mouse’s light cycle. All procedures were approved by the Institutional Animal Care and Use Committee (IACUC) of Boston University.</p>
</sec>
<sec id="s4b">
<title>Cranial Windows</title>
<p>Mice were briefly anesthetized with isoflurane (∼2% by volume in O2) and placed on a stereotactic surgical stage with warming pads to maintain body temperature. Anesthetic gas (1-2%) was passively applied through a nose mask and adjusted as necessary to maintain respiratory rate and suppressed hind-paw and tail-pinch reflexes. Eyes were coated with a thin layer of Soothe eye lubricant (Bausch and Lomb, Canada). The scalp was shaved and opened with a rostrocaudal incision at the midline using scissors, and the periosteum was removed. A 5 mm circular craniotomy was made over the left visual cortex (2.9 mm lateral and 0.5 mm anterior to lambda). A 5 mm cranial window (Deckglaser) was placed over the craniotomy and secured with metabond. A steel headplate was then affixed to the skull. Mice recovered for 7-10 days prior to imaging.</p>
</sec>
<sec id="s4c">
<title>Retinotopic Mapping</title>
<p>1-3 days prior to beginning the sequence learning experiment, a retinotopic map of the visual cortex was generated using widefield one-photon microscopy. The brain was illuminated with a 470 nm light source (X-Cite 200DC), and images were acquired through a 10x objective, a sCMOS camera (Thorlabs Quantalux, CS2100M-SB), and ThorImageLS 3.0 (Thorlabs Inc.). A 22-inch LED monitor (1920 x 1080 pixels, refresh rate 60 Hz) was positioned 15 cm from the mouse’s right eye, and a narrow sweeping stimulus moved across the screen in four directions (left-to-right, right-to-left, top-to-bottom, and bottom-to-top). Trial-averaged responses were used to determine the location of binocular V1.</p>
</sec>
<sec id="s4d">
<title>Two-photon Imaging</title>
<p>Two-photon Ca2+ imaging was performed on days 1 and 6 using a Bergamo microscope (Thorlabs Inc., Newton, NJ, USA) controlled by ThorImage OCT software (ThorImageLS, v3). The visual cortex was illuminated with a Ti:Sapphire fs-pulsed laser (Mai Tai Deep-See, Spectraphysics) tuned to 920 nm. The laser was focused onto L2/3 of binocular V1 through a 16x water-immersion objective lens (0.8NA, Nikon). Ca2+ transients were obtained from neuronal populations at a resolution of 512 x 512 pixels (sampling rate ∼30 Hz). The obtained images were motion-corrected using CaImAn (<xref ref-type="bibr" rid="c12">Giovannucci et al., 2019</xref>). Segmentation, neuropil subtractions, and deconvolution were performed using Suite2p (<xref ref-type="bibr" rid="c25">Pachitariu et al., 2016</xref>).</p>
</sec>
<sec id="s4e">
<title>Visual Stimulus</title>
<p>Visual stimuli were generated and displayed using MATLAB with the PsychToolbox extension (<xref ref-type="bibr" rid="c4">Brainard, 1997</xref>), with custom software (<ext-link ext-link-type="uri" xlink:href="https://github.com/jeffgavornik/VEPStimulusSuite">https://github.com/jeffgavornik/VEPStimulusSuite</ext-link>) used to control timing and hardware signals. Stimuli were displayed on a 22-inch LED monitor (1920 x 1080 pixels, refresh rate 60 Hz) positioned 25 cm directly in front of the mouse in order to stimulate binocular V1. All stimuli were matched for luminance.</p>
<p>Four images (referred to A, B, C, and D), each an oriented sinusoidal grating, had angles 15, 75, 165, and 120 degrees, respectively) with spatial frequency 0.05 cycles/degree. These images were displayed for 250 ms each. All images were matched for total luminance. Images were combined into three sequences (ABCD, ABBD, and ACBD). Every sequence presentation was followed by an 800 ms period of gray screen. Therefore, each sequence presentation, including its following gray period, lasted 1800 ms. Note: since there were no gray periods between images in a sequence, BB in ABBD was essentially a single 500 ms presentation of B.</p>
</sec>
<sec id="s4f">
<title>Experimental Design</title>
<p>On day 0, all sequences (ABCD, ABBD, and ACBD) were shown in blocks of 100 sequences (e.g. ABCD x 100, ABBD x 100, ACBD x 100), and each block was separated by a 10 second rest period (see <xref rid="fig1" ref-type="fig">Figure 1</xref>). This structure was repeated 5 times, yielding 500 presentations of each sequence on any given day. Day 0 and day 1 were separated by a two-day buffer period. During the training period (days 1-4), only ABCD was shown and in 5 blocks of 100 presentations. Day 5 (testing) was identical to day 0. Additionally, there was a 1-minute gray period preceding and post-ceding the experiment.</p>
</sec>
<sec id="s4g">
<title>Stimulus and context selectivity</title>
<p>Trial- and time-averaged responses were computed for all cells. We applied a 67 ms offset from stimulus onset to account for the information delay from retina to L2/3. The duration of this delay was verified by looking at individual cell responses after stimulus onset. For each cell, we compared the mean activity during for a given stimulus with the mean activity over all other stimuli. If the mean activity for a given stimulus was over two standard deviations of the other stimuli, it was assigned selectivity for that stimulus. This was first done for stimuli regardless of sequence context. The procedure was performed again with sequence context taken into account to look for cells that were primarily active within a particular sequence (e.g., cells that fired to image C in ACBD but not ABCD). Manual inspection of all cells (n=2868) validated this approach for &gt;80% of cells. Some manual curation was performed to assign context selectivity when necessary.</p>
</sec>
<sec id="s4h">
<title>Principal Component Analysis</title>
<p>Trial-averaged responses for ABCD, ABBD, and ACBD were computed and pooled across mice. These responses were then concatenated across time yielding a time-by-cell matrix. After performing PCA, the resulting principal components were then split in time to show how the shared set of principal components behaved during each of the three sequences.</p>
</sec>
<sec id="s4i">
<title>Sparseness estimation</title>
<p>We estimated sparseness of single-cell responses in two ways.
<list list-type="order">
<list-item><p>Stimulus selectivity: We counted the number of neurons that are driven by a particular stimulus more than two standard deviations above their mean rates. For each neuron, we computed the trial- and time-averaged responses for each image. The mean firing rate and standard deviation was computed across time regardless of stimulus. A neuron was considered as responsive to a given stimulus if its response was more than two times this standard deviation plus its mean firing rate.</p></list-item>
<list-item><p>Visual modulation: We counted the number of cells that had significantly different activity during gratings vs gray periods. For each neuron, we collected and time averaged 266 ms chunks for gratings and gray periods separately. We then performed a ks-test on these two groups, and if the two distributions were significantly different (p &lt; 0.05), then the cell was classified as visually modulated. Note that we threw away 133 ms in between 266 ms chunks in order to reduce correlations between samples.</p></list-item>
</list>
</p>
</sec>
<sec id="s4j">
<title>Correlation analysis</title>
<p>For each sequence presentation we extracted time-averaged responses for each stimulus (excluding the first 66 ms after image onset). We then computed Pearson-correlation coefficients for all 6 pairs in the presentation. For example, for the first presentation of ABCD, we would first extract and time-average population vectors for each image A, B, C, and D. We would then compute Pearson correlation coefficients between all 6 pairs: A to B, A to C, A to D, etc. In this way, we had 500 presentations x 6 pairs = 3000 coefficients for each sequence for each day. We compared coefficients between days with KS-tests.</p>
</sec>
<sec id="s4k">
<title>Stimulus decoding</title>
<p>Time-averaged responses to all stimuli were used to train a linear decoder. We excluded the first two time bins (67 ms) to account for the information delay to L2/3 and avoid contamination from the previous stimulus. Data was randomly split into two equally sized groups (250 trials each) for training and testing. This was repeated 100 times. Accuracy by random chance was 1/15 = 6.7%.</p>
</sec>
<sec id="s4l">
<title>Temporal decoding</title>
<p>Data from all 800 ms intersequence gray periods (n=1500) was collected and randomly split into two equally-sized groups (750 trials each). The decoder was trained on one set and tested on the other. This was repeated 100 times. Accuracy by random chance was 1/24 = 4.2%.</p>
</sec>
<sec id="s4m">
<title>Time field estimation</title>
<p>Trials were split into even/odd groups, and responses were averaged over trials for both groups. For each cell, we found where the cell fired maximally in each group. If the location of even-group maximum was within 133 ms (4 time bins) of the odd-group maximum, the cell was considered to have a temporally consistent firing pattern (∼60% of cells on both days), and the remaining cells were discarded. Consistently firing cells were assigned a time bin based on their points of maximum activity using data averaged over all trials.</p>
</sec>
<sec id="s4n">
<title>Code/software</title>
<p>All data analysis was performed in Python using the Python scientific stack (Numpy, Scipy, Sci-Kit Learn). For decoder analysis, we used sci-kit learn’s support vector classifier with a linear kernel.</p>
</sec>
</sec>
</body>
<back>
<sec id="s5">
<title>Author Contributions</title>
<p>Experimental conception and design: SGK and JPG. Experiments and surgeries: SGK, CM. Data analysis and figures: GSK and CM. Writing: SGK and JPG.</p>
</sec>
<sec id="s6">
<title>Data Availability</title>
<p>All data and analysis code is available at <ext-link ext-link-type="uri" xlink:href="https://gavorniklab.bu.edu/supplemental-materials.html">https://gavorniklab.bu.edu/supplemental-materials.html</ext-link>.</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>Special thanks to Marc Howard for his insight and Byron Price for his feedback and discussions throughout the design and analysis of these experiments. This work was supported by NEI R001EY030200.</p>
</ack>
<ref-list>
<title>Bibliography</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Audette</surname>, <given-names>N. J.</given-names></string-name>, &amp; <string-name><surname>Schneider</surname>, <given-names>D. M</given-names></string-name>. (<year>2023</year>). <article-title>Stimulus-specific prediction error neurons in mouse auditory cortex</article-title>. <source>The Journal of Neuroscience</source>, JN-RM-0512-23. <pub-id pub-id-type="doi">10.1523/jneurosci.0512-23.2023</pub-id></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><string-name><surname>Balasubramaniam</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Haegens</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Jazayeri</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Merchant</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Sternad</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name><surname>Song</surname>, <given-names>J. H</given-names></string-name>. (<year>2021</year>). <article-title>Neural encoding and representation of time for sensorimotor control and learning</article-title>. <source>Journal of Neuroscience</source>, <volume>41</volume>(<issue>5</issue>), <fpage>866</fpage>–<lpage>872</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.1652-20.2020</pub-id></mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Benucci</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Ringach</surname>, <given-names>D. L.</given-names></string-name>, &amp; <string-name><surname>Carandini</surname>, <given-names>M</given-names></string-name>. (<year>2009</year>). <article-title>Coding of stimulus sequences by population responses in visual cortex</article-title>. <source>Nature Neuroscience</source>, <volume>12</volume>(<issue>10</issue>), <fpage>1317</fpage>–<lpage>1324</lpage>. <pub-id pub-id-type="doi">10.1038/nn.2398</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>Brainard</surname>, <given-names>D. H</given-names></string-name>. (<year>1997</year>) <article-title>The Psychophysics Toolbox</article-title>, <source>Spatial Vision</source> <volume>10</volume>:<fpage>433</fpage>–<lpage>436</lpage>.</mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="journal"><string-name><surname>Buzsáki</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Anastassiou</surname>, <given-names>C. A.</given-names></string-name>, &amp; <string-name><surname>Koch</surname>, <given-names>C</given-names></string-name>. (<year>2012</year>). <article-title>The origin of extracellular fields and currents-EEG, ECoG</article-title>, <source>LFP and spikes. In Nature Reviews Neuroscience</source> (Vol. <volume>13</volume>, Issue <issue>6</issue>, pp. <fpage>407</fpage>–<lpage>420</lpage>). <pub-id pub-id-type="doi">10.1038/nrn3241</pub-id></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="journal"><string-name><surname>Deitch</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Rubin</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Ziv</surname>, <given-names>Y</given-names></string-name>. (<year>2021</year>). <article-title>Representational drift in the mouse visual cortex</article-title>. <source>Current Biology</source>, <volume>31</volume>(<issue>19</issue>), <fpage>4327</fpage>–<lpage>4339</lpage>.e6. <pub-id pub-id-type="doi">10.1016/j.cub.2021.07.062</pub-id></mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Eliades</surname>, <given-names>S. J.</given-names></string-name>, &amp; <string-name><surname>Wang</surname>, <given-names>X</given-names></string-name>. (<year>2008</year>). <article-title>Neural substrates of vocalization feedback monitoring in primate auditory cortex</article-title>. <source>Nature</source>, <volume>453</volume>(<issue>7198</issue>), <fpage>1102</fpage>–<lpage>1106</lpage>. <pub-id pub-id-type="doi">10.1038/nature06910</pub-id></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Fiser</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Mahringer</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Oyibo</surname>, <given-names>H. K.</given-names></string-name>, <string-name><surname>Petersen</surname>, <given-names>A. V.</given-names></string-name>, <string-name><surname>Leinweber</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Keller</surname>, <given-names>G. B</given-names></string-name>. (<year>2016</year>). <article-title>Experience-dependent spatial expectations in mouse visual cortex</article-title>. <source>Nature Neuroscience</source>, <volume>19</volume>(<issue>12</issue>), <fpage>1658</fpage>–<lpage>1664</lpage>. <pub-id pub-id-type="doi">10.1038/nn.4385</pub-id></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Gao</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Lim</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Chubykin</surname>, <given-names>A. A</given-names></string-name>. (<year>2021</year>). <article-title>Visual familiarity induced 5-Hz oscillations and improved orientation and direction selectivities in V1</article-title>. <source>Journal of Neuroscience</source>, <volume>41</volume>(<issue>12</issue>), <fpage>2656</fpage>–<lpage>2667</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.1337-20.2021</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Garrett</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Manavi</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Roll</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Ollerenshaw</surname>, <given-names>D. R.</given-names></string-name>, <string-name><surname>Groblewski</surname>, <given-names>P. A.</given-names></string-name>, <string-name><surname>Ponvert</surname>, <given-names>N. D.</given-names></string-name>, <string-name><surname>Kiggins</surname>, <given-names>J. T.</given-names></string-name>, <string-name><surname>Casal</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Mace</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Williford</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Leon</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Jia</surname>, <given-names>X.</given-names></string-name>, <string-name><surname>Ledochowitsch</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Buice</surname>, <given-names>M. A.</given-names></string-name>, <string-name><surname>Wakeman</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Mihalas</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Olsen</surname>, <given-names>S. R</given-names></string-name>. (<year>2020</year>). <article-title>Experience shapes activity dynamics and stimulus coding of VIP inhibitory cells</article-title>. <source>ELife</source>, <volume>9</volume>, <fpage>1</fpage>–<lpage>25</lpage>. <pub-id pub-id-type="doi">10.7554/eLife.50340</pub-id></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Gavornik</surname>, <given-names>J. P.</given-names></string-name>, &amp; <string-name><surname>Bear</surname>, <given-names>M. F</given-names></string-name>. (<year>2014</year>). <article-title>Learned spatiotemporal sequence recognition and prediction in primary visual cortex</article-title>. <source>Nature Neuroscience</source>, <volume>17</volume>(<issue>5</issue>), <fpage>732</fpage>–<lpage>737</lpage>. <pub-id pub-id-type="doi">10.1038/nn.3683</pub-id></mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><string-name><surname>Giovannucci</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Friedrich</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Gunn</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Kalfon</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Brown</surname>, <given-names>B. L.</given-names></string-name>, <string-name><surname>Koay</surname>, <given-names>S. A.</given-names></string-name>, <string-name><surname>Taxidis</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Najafi</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Gauthier</surname>, <given-names>J. L.</given-names></string-name>, <string-name><surname>Zhou</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Khakh</surname>, <given-names>B. S.</given-names></string-name>, <string-name><surname>Tank</surname>, <given-names>D. W.</given-names></string-name>, <string-name><surname>Chklovskii</surname>, <given-names>D. B.</given-names></string-name>, &amp; <string-name><surname>Pnevmatikakis</surname>, <given-names>E. A</given-names></string-name>. (<year>2019</year>). <article-title>Caiman an open source tool for scalable calcium imaging data analysis</article-title>. <source>ELife</source>, <volume>8</volume>, <fpage>1</fpage>–<lpage>45</lpage>. <pub-id pub-id-type="doi">10.7554/eLife.38173</pub-id></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><string-name><surname>Heys</surname>, <given-names>J. G.</given-names></string-name>, &amp; <string-name><surname>Dombeck</surname>, <given-names>D. A</given-names></string-name>. (<year>2018</year>). <article-title>Evidence for a subcircuit in medial entorhinal cortex representing elapsed time during immobility</article-title>. <source>Nature Neuroscience</source>, <volume>21</volume>(<issue>11</issue>), <fpage>1574</fpage>–<lpage>1582</lpage>. <pub-id pub-id-type="doi">10.1038/s41593-018-0252-8</pub-id></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Jordan</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Keller</surname>, <given-names>G. B</given-names></string-name>. (<year>2020</year>). <article-title>Opposing Influence of Top-down and Bottom-up Input on Excitatory Layer 2/3 Neurons in Mouse Primary Visual Cortex</article-title>. <source>Neuron</source>, <volume>108</volume>(<issue>6</issue>), <fpage>1194</fpage>–<lpage>1206</lpage>.e5. <pub-id pub-id-type="doi">10.1016/j.neuron.2020.09.024</pub-id></mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><string-name><surname>Keller</surname>, <given-names>G. B.</given-names></string-name>, <string-name><surname>Bonhoeffer</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Hübener</surname>, <given-names>M</given-names></string-name>. (<year>2012</year>). <article-title>Sensorimotor Mismatch Signals in Primary Visual Cortex of the Behaving Mouse</article-title>. <source>Neuron</source>, <volume>74</volume>(<issue>5</issue>), <fpage>809</fpage>–<lpage>815</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2012.03.040</pub-id></mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><string-name><surname>Keller</surname>, <given-names>G. B.</given-names></string-name>, &amp; <string-name><surname>Mrsic-Flogel</surname>, <given-names>T. D</given-names></string-name>. (<year>2018</year>). <article-title>Predictive Processing: A Canonical Cortical Computation</article-title>. <source>Neuron</source>, <volume>100</volume>(<issue>2</issue>), <fpage>424</fpage>–<lpage>435</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2018.10.003</pub-id></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>Kissinger</surname>, <given-names>S. T.</given-names></string-name>, <string-name><surname>Pak</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Tang</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Masmanidis</surname>, <given-names>S. C.</given-names></string-name>, &amp; <string-name><surname>Chubykin</surname>, <given-names>A. A</given-names></string-name>. (<year>2018</year>). <article-title>Oscillatory encoding of visual stimulus familiarity</article-title>. <source>Journal of Neuroscience</source>, <volume>38</volume>(<issue>27</issue>), <fpage>6223</fpage>–<lpage>6240</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.3646-17.2018</pub-id></mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><string-name><surname>Kissinger</surname>, <given-names>S. T.</given-names></string-name>, <string-name><surname>Wu</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Quinn</surname>, <given-names>C. J.</given-names></string-name>, <string-name><surname>Anderson</surname>, <given-names>A. K.</given-names></string-name>, <string-name><surname>Pak</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Chubykin</surname>, <given-names>A. A</given-names></string-name>. (<year>2020</year>). <article-title>Visual Experience-Dependent Oscillations and Underlying Circuit Connectivity Changes Are Impaired in Fmr1 KO Mice</article-title>. <source>Cell Reports</source>, <volume>31</volume>(<issue>1</issue>), <fpage>107486</fpage>. <pub-id pub-id-type="doi">10.1016/j.celrep.2020.03.050</pub-id></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Komura</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Tamura</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Uwano</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Nishijo</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Kaga</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name><surname>Ono</surname>, <given-names>T</given-names></string-name>. (<year>2001</year>). <article-title>Retrospective and prospective coding for predicted reward in the sensory thalamus</article-title>. <source>Nature</source>, <volume>412</volume>(<issue>6846</issue>), <fpage>546</fpage>–<lpage>549</lpage>. <pub-id pub-id-type="doi">10.1038/35087595</pub-id></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><string-name><surname>Kraus</surname>, <given-names>B. J.</given-names></string-name>, <string-name><surname>Brandon</surname>, <given-names>M. P.</given-names></string-name>, <string-name><surname>Robinson</surname>, <given-names>R. J.</given-names></string-name>, <string-name><surname>Connerney</surname>, <given-names>M. A.</given-names></string-name>, <string-name><surname>Hasselmo</surname>, <given-names>M. E.</given-names></string-name>, &amp; <string-name><surname>Eichenbaum</surname>, <given-names>H</given-names></string-name>. (<year>2015</year>). <article-title>During Running in Place, Grid Cells Integrate Elapsed Time and Distance Run</article-title>. <source>Neuron</source>, <volume>88</volume>(<issue>3</issue>), <fpage>578</fpage>–<lpage>589</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.031</pub-id></mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Kraus</surname>, <given-names>B. J.</given-names></string-name>, <string-name><surname>Robinson</surname>, <given-names>R. J.</given-names></string-name>, <string-name><surname>White</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Eichenbaum</surname>, <given-names>H.</given-names></string-name>, &amp; <string-name><surname>Hasselmo</surname>, <given-names>M. E</given-names></string-name>. (<year>2013</year>). <article-title>Hippocampal “Time Cells”: Time versus Path Integration</article-title>. <source>Neuron</source>, <volume>78</volume>(<issue>6</issue>), <fpage>1090</fpage>–<lpage>1101</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2013.04.015</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Levy</surname>, <given-names>J. M.</given-names></string-name>, <string-name><surname>Zold</surname>, <given-names>C. L.</given-names></string-name>, <string-name><surname>Namboodiri</surname>, <given-names>V. M. K.</given-names></string-name>, &amp; <string-name><surname>Hussain Shuler</surname>, <given-names>M. G</given-names></string-name>. (<year>2017</year>). <article-title>The timing of reward-seeking action tracks visually cued theta oscillations in primary visual cortex</article-title>. <source>Journal of Neuroscience</source>, <volume>37</volume>(<issue>43</issue>), <fpage>10408</fpage>–<lpage>10420</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.0923-17.2017</pub-id></mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>MacDonald</surname>, <given-names>C. J.</given-names></string-name>, <string-name><surname>Lepage</surname>, <given-names>K. Q.</given-names></string-name>, <string-name><surname>Eden</surname>, <given-names>U. T.</given-names></string-name>, &amp; <string-name><surname>Eichenbaum</surname>, <given-names>H</given-names></string-name>. (<year>2011</year>). <article-title>Hippocampal “time cells” bridge the gap in memory for discontiguous events</article-title>. <source>Neuron</source>, <volume>71</volume>(<issue>4</issue>), <fpage>737</fpage>–<lpage>749</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2011.07.012</pub-id></mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Montgomery</surname>, <given-names>D. P.</given-names></string-name>, <string-name><surname>Hayden</surname>, <given-names>D. J.</given-names></string-name>, <string-name><surname>Chaloner</surname>, <given-names>F. A.</given-names></string-name>, <string-name><surname>Cooke</surname>, <given-names>S. F.</given-names></string-name>, &amp; <string-name><surname>Bear</surname>, <given-names>M. F</given-names></string-name>. (<year>2021</year>). <article-title>Stimulus-Selective Response Plasticity in Primary Visual Cortex: Progress and Puzzles</article-title>. <source>Frontiers in Neural Circuits</source>, <volume>15</volume>. <pub-id pub-id-type="doi">10.3389/FNCIR.2021.815554</pub-id></mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><string-name><surname>Pachitariu</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Packer</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Pettit</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Dalgleish</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Hausser</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Sahani</surname>, <given-names>M</given-names></string-name>. (<year>2016</year>). <article-title>Suite2p: beyond 10,000 neurons with standard two-photon microscopy</article-title>. <source>BioRxiv</source>, <fpage>1</fpage>–<lpage>30</lpage>.</mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><string-name><surname>Pastalkova</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Itskov</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Amarasingham</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Buzsáki</surname>, <given-names>G</given-names></string-name>. (<year>2008</year>). <article-title>Internally Generated Cell Assembly Sequences in the Rat Hippocampus</article-title>. <source>Science</source>, <volume>321</volume>(<issue>5894</issue>), <fpage>1322</fpage>–<lpage>1327</lpage>. <pub-id pub-id-type="doi">10.1126/science.1159775</pub-id></mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>Price</surname>, <given-names>B. H.</given-names></string-name>, &amp; <string-name><surname>Gavornik</surname>, <given-names>J. P</given-names></string-name>. (<year>2022</year>). <article-title>Efficient Temporal Coding in the Early Visual System: Existing Evidence and Future Directions</article-title>. <source>Frontiers in Computational Neuroscience</source>, <volume>16</volume>(<fpage>July</fpage>). <pub-id pub-id-type="doi">10.3389/fncom.2022.929348</pub-id></mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><string-name><surname>Price</surname>, <given-names>B. H.</given-names></string-name>, <string-name><surname>Jensen</surname>, <given-names>C. M.</given-names></string-name>, <string-name><surname>Khoudary</surname>, <given-names>A. A.</given-names></string-name>, &amp; <string-name><surname>Gavornik</surname>, <given-names>J. P</given-names></string-name>. (<year>2023</year>). <article-title>Expectation violations produce error signals in mouse V1</article-title>. <source>Cerebral Cortex</source>. <pub-id pub-id-type="doi">10.1093/cercor/bhad163</pub-id></mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><string-name><surname>Sidorov</surname>, <given-names>M. S.</given-names></string-name>, <string-name><surname>Kim</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Rougie</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Williams</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Siegel</surname>, <given-names>J. J.</given-names></string-name>, <string-name><surname>Gavornik</surname>, <given-names>J. P.</given-names></string-name>, &amp; <string-name><surname>Philpot</surname>, <given-names>B. D</given-names></string-name>. (<year>2020</year>). <article-title>Visual Sequences Drive Experience-Dependent Plasticity in Mouse Anterior Cingulate Cortex</article-title>. <source>Cell Reports</source>, <volume>32</volume>(<issue>11</issue>), <fpage>108152</fpage>. <pub-id pub-id-type="doi">10.1016/j.celrep.2020.108152</pub-id></mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>Solomon</surname>, <given-names>S. S.</given-names></string-name>, <string-name><surname>Tang</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Sussman</surname>, <given-names>E.</given-names></string-name>, &amp; <string-name><surname>Kohn</surname>, <given-names>A</given-names></string-name>. (<year>2021</year>). <article-title>Limited Evidence for Sensory Prediction Error Responses in Visual Cortex of Macaques and Humans. <italic>Cerebral Cortex (New York</italic></article-title>, <source>N.Y</source><italic>. :</italic> <volume>1991</volume><italic>)</italic>, <italic>31</italic>(6), 3136–3152. <pub-id pub-id-type="doi">10.1093/cercor/bhab014</pub-id></mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>Stanley</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Miall</surname>, <given-names>R. C</given-names></string-name>. (<year>2007</year>). <article-title>Functional activation in parieto-premotor and visual areas dependent on congruency between hand movement and visual stimuli during motor-visual priming</article-title>. <source>NeuroImage</source>, <volume>34</volume>(<issue>1</issue>), <fpage>290</fpage>–<lpage>299</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.08.043</pub-id></mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><string-name><surname>Tang</surname>, <given-names>M. F.</given-names></string-name>, <string-name><surname>Kheradpezhouh</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>C. C. Y.</given-names></string-name>, <string-name><surname>Dickinson</surname>, <given-names>J. E.</given-names></string-name>, <string-name><surname>Mattingley</surname>, <given-names>J. B.</given-names></string-name>, &amp; <string-name><surname>Arabzadeh</surname>, <given-names>E</given-names></string-name>. (<year>2023</year>). <article-title>Expectation violations enhance neuronal encoding of sensory information in mouse primary visual cortex</article-title>. <source>Nature Communications</source>, <volume>14</volume>(<issue>1</issue>), <fpage>1</fpage>–<lpage>14</lpage>. <pub-id pub-id-type="doi">10.1038/s41467-023-36608-8</pub-id></mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><string-name><surname>Tsao</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Sugar</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Lu</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Knierim</surname>, <given-names>J. J.</given-names></string-name>, <string-name><surname>Moser</surname>, <given-names>M. B.</given-names></string-name>, &amp; <string-name><surname>Moser</surname>, <given-names>E. I</given-names></string-name>. (<year>2018</year>). <article-title>Integrating time from experience in the lateral entorhinal cortex</article-title>. <source>Nature</source>, <volume>561</volume>(<issue>7721</issue>), <fpage>57</fpage>–<lpage>62</lpage>. <pub-id pub-id-type="doi">10.1038/s41586-018-0459-6</pub-id></mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Tsao</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Yousefzadeh</surname>, <given-names>S. A.</given-names></string-name>, <string-name><surname>Meck</surname>, <given-names>W. H.</given-names></string-name>, <string-name><surname>Moser</surname>, <given-names>M. B.</given-names></string-name>, &amp; <string-name><surname>Moser</surname>, <given-names>E. I</given-names></string-name>. (<year>2022</year>). <article-title>The neural bases for timing of durations</article-title>. <source>In Nature Reviews Neuroscience</source> (Vol. <volume>23</volume>, Issue <issue>11</issue>, pp. <fpage>646</fpage>– <lpage>665</lpage>). Springer Nature. <pub-id pub-id-type="doi">10.1038/s41583-022-00623-3</pub-id></mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>Zmarz</surname>, <given-names>P.</given-names></string-name>, &amp; <string-name><surname>Keller</surname>, <given-names>G. B</given-names></string-name>. (<year>2016</year>). <article-title>Mismatch Receptive Fields in Mouse Visual Cortex</article-title>. <source>Neuron</source>, <volume>92</volume>(<issue>4</issue>), <fpage>766</fpage>–<lpage>772</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2016.09.057</pub-id></mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><string-name><surname>Zold</surname>, <given-names>C. L.</given-names></string-name>, &amp; <string-name><surname>Hussain Shuler</surname>, <given-names>M. G</given-names></string-name>. (<year>2015</year>). <article-title>Theta oscillations in visual cortex emerge with experience to convey expected reward time and experienced reward rate</article-title>. <source>Journal of Neuroscience</source>, <volume>35</volume>(<issue>26</issue>), <fpage>9603</fpage>–<lpage>9614</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.0296-15.2015</pub-id></mixed-citation></ref>
</ref-list>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94727.1.sa3</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Sharpee</surname>
<given-names>Tatyana O</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>Salk Institute for Biological Studies</institution>
</institution-wrap>
<city>La Jolla</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Incomplete</kwd>
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Useful</kwd>
</kwd-group>
</front-stub>
<body>
<p>This paper presents <bold>useful</bold> results that extend our understanding of how the visual cortex encodes temporal structure, providing new information about sequence representations in superficial layers of the visual cortex. The evidence for prediction errors is <bold>solid</bold>, however, support for other claims regarding sparsification and simplification of activity following training is <bold>incomplete</bold>.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94727.1.sa2</article-id>
<title-group>
<article-title>Reviewer #1 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>Knudstrup et al. use two-photon calcium imaging to measure neural responses in the mouse primary visual cortex (V1) in response to image sequences. The authors presented mice with many repetitions of the same four-image sequence (ABCD) for four days. Then on the fifth day, they presented unexpected stimulus orderings where one stimulus was either omitted (ABBD) or substituted (ACBD). After analyzing trial-averaged responses of neurons pooled across multiple mice, they observed that stimulus omission (ABBD) caused a small, but significant, strengthening of neural responses but observed no significant change in the response to stimulus substitution (ACBD). Next, they performed population analyses of this dataset. They showed that there were changes in the correlation structure of activity and that many features of sequence ordering could be reliably decoded. This second set of analyses is interesting and exhibited larger effect sizes than the first results about predictive coding. However, concerns about the design of the experiment temper my enthusiasm.</p>
<p>Strengths:</p>
<p>(1) The topic of predictive coding in the visual cortex is exciting, and this task builds on previous important work by the senior author (Gavornik and Bear 2014) where unexpectedly shuffling sequence order caused changes in LFPs recorded from the visual cortex.</p>
<p>(2) Deconvolved calcium responses were used appropriately here to look at the timing of the neural responses.</p>
<p>(3) Neural decoding results showing that the context of the stimuli could be reliably decoded from trial-averaged responses were interesting. However I have concerns about how the data was formatted for performing these analyses.</p>
<p>Weaknesses:</p>
<p>(1) All analyses were performed on trial-averaged neural responses that were pooled across mice. Owing to differences between subjects in behavior, experimental preparation quality, and biological variability, it seems important to perform at least some analyses on individual analyses to assess how behavioral training might differently affect each animal.</p>
<p>(2) The correlation analyses presented in Figure 3 (labeled the second Figure 2 in the text) should be conducted on a single-animal basis. Studying population codes constructed by pooling across mice, particularly when there is no behavioral readout to assess whether learning has had similar effects on all animals, appears inappropriate to me. If the results in Figure 3 hold up on single animals, I think that is definitely an interesting result.</p>
<p>(3) On Day 0 and Day 5, the reordered stimuli are presented in trial blocks where each image sequence is shown 100 times. Why wasn't the trial ordering randomized as was done in previous studies (e.g. Gavornik and Bear 2014)? Given this lack of reordering, did neurons show reduced predictive responses because the unexpected sequence was shown so many times in quick succession? This might change the results seen in Figure 2, as well as the decoder results where there is a neural encoding of sequence order (Figure 4). It would be interesting if the Figure 4 decoder stopped working when the higher-order block structure of the task was disrupted.</p>
<p>(4) A primary advantage of using two-photon calcium imaging over other techniques like extracellular electrophysiology is that the same neurons can be tracked over many days. This is a standard approach that can be accomplished by using many software packages-including Suite2P (Pachitariu et al. 2017), which is what the authors already used for the rest of their data preprocessing. The authors of this paper did not appear to do this. Instead, it appears that different neurons were imaged on Day 0 (baseline) and Day 5 (test). This is a significant weakness of the current dataset.</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94727.1.sa1</article-id>
<title-group>
<article-title>Reviewer #2 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Knudstrup et al set out to probe prediction errors in the mouse visual cortex. They use a variant of an oddball paradigm and test how repeated passive exposure to a specific sequence of visual stimuli affects oddball responses in layer 2/3 neurons. Unfortunately, there are problems with the experimental design which make it difficult to interpret the results in light of the question the authors want to address. The conceptual framing, choice of block design structure, and not tracking the same cells over days, are just some of the reasons that make this work difficult to interpret. Specific comments are as follows:</p>
<p>(1) There appears to be some confusion regarding the conceptual framing of predictive coding. Assuming the mouse learns to expect the sequence ABCD, then ABBD does not probe just for negative prediction errors, and ACBD is not just for positive prediction errors. With ABBD, there is a combination of a negative prediction error for the missing C in the 3rd position, and a positive prediction error for B in the 3rd. Likewise, with ACBD, there is a negative prediction error for the missing B at 2nd and missing C at 3rd, and a positive prediction error for the C in 2nd and B in 3rd. Thus, the authors' experimental design does not have the power to isolate either negative or positive prediction errors. Moreover, looking at the raw data in Figure 2C, this does not look like an &quot;omission&quot; response to C, but more like a stronger response to a longer B. The pitch of the paper as investigating prediction error responses is probably not warranted - we see no way to align the authors' results with this interpretation.</p>
<p>(2) Related to the interpretation of the findings, just because something can be described as a prediction error does not mean it is computed in (or even is relevant to) the visual cortex. To the best of our knowledge, it is still unclear where in the visual stream the responses described here are computed. It is possible that this type of computation happens before the signals reach the visual cortex, similar to mechanisms predicting moving stimuli already in the retina (<ext-link ext-link-type="uri" xlink:href="https://pubmed.ncbi.nlm.nih.gov/10192333/">https://pubmed.ncbi.nlm.nih.gov/10192333/</ext-link>). This would also be consistent with the authors' finding (in previous work) that single-cell recordings in V1 exhibit weaker sequence violation responses than the author's earlier work using LFP recordings.</p>
<p>(3) Recording from the same neurons over the course of this paradigm is well within the technical standards of the field, and there is no reason not to do this. Given that the authors chose to record from different neurons, it is difficult to distinguish representational drift from drift in the population of neurons recorded.</p>
<p>(4) The block paradigm to test for prediction errors appears ill-chosen. Why not interleave oddball stimuli randomly in a sequence of normal stimuli? The concern is related to the question of how many repetitions it takes to learn a sequence. Can the mice not learn ACBD over 100x repetitions? The authors should definitely look at early vs. late responses in the oddball block. Also, the first few presentations after the block transition might be potentially interesting. The authors' analysis in the paper already strongly suggests that the mice learn rather rapidly. The authors conclude: &quot;we expected ABCD would be more-or-less indistinguishable from ABBD and ACBD since A occurs first in each sequence and always preceded by a long (800 ms) gray period. This was not the case. Most often, the decoder correctly identified which sequence stimulus A came from.&quot; This would suggest that whatever learning/drift could happen within one block did indeed happen and responses to different sequences are harder to interpret.</p>
<p>(5) Throughout the manuscript, many of the claims are not statistically tested, and where they are the tests do not appear to be hierarchical (<ext-link ext-link-type="uri" xlink:href="https://pubmed.ncbi.nlm.nih.gov/24671065/">https://pubmed.ncbi.nlm.nih.gov/24671065/</ext-link>), even though the data are likely nested.</p>
<p>(6) The manuscript would greatly benefit from thorough proofreading (not just in regard to figure references).</p>
<p>(7) With a sequence of stimuli that are 250ms in length each, the use of GCaMP6s appears like a very poor choice.</p>
<p>(8) The data shown are unnecessarily selective. E.g. it would probably be interesting to see how the average population response evolves with days. The relevant question for most prediction error interpretations would be whether there are subpopulations of neurons that selectively respond to any of the oddballs. E.g. while the authors state they &quot;did&quot; not identify a separate population of omission-responsive neurons, they provide no evidence for this. However, it is unclear whether the block structure of the experiments allows the authors to analyze this.</p>
</body>
</sub-article>
<sub-article id="sa3" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.94727.1.sa0</article-id>
<title-group>
<article-title>Reviewer #3 (Public Review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>This work provides insights into predictive coding models of visual cortex processing. These models predict that visual cortex neurons will show elevated responses when there are unexpected changes to learned sequential stimulus patterns. This model is currently controversial, with recent publications providing conflicting evidence. In this work, the authors test two types of unexpected pattern variations in layer 2/3 of the mouse visual cortex. They show that pattern omission evokes elevated responses, in favor of a predictive coding model, but find no evidence for prediction errors with substituted patterns, which conflicts with both prior results in L4, and with the expectations of a predictive coding model. They also report that with sequence training, responses sparsify and decorrelate, but surprisingly find no changes in the ability of an ideal observer to decode stimulus identity or timing.</p>
<p>These results are an important contribution to the understanding of how temporal sequences and expectations are encoded in the primary visual cortex. However, there are several methodological concerns with the study, and some of the authors' interpretations and conclusions are unsupported by data.</p>
<p>Major concerns:</p>
<p>(1) Experimental design using a block structure. The use of a block structure on test days (0 and 5) in which sequences were presented in 100 repetition blocks leads to several potential confounds. First, there is the potential for plasticity within blocks, which could alter the responses and induce learned expectations. The ability of the authors to clearly distinguish blocks 1 and 2 on Day 0 with a decoder suggests this change over time may be meaningful.</p>
<p>Repeating the experiments with fully interleaved sequences on test days would alleviate this concern. With the existing data, the authors should compare responses from the first trials in a block to the last trials in a block.</p>
<p>This block design likely also accounts for the ability of a decoder to readily distinguish stimulus A in ABCD from A in ABBD. As all ABCD sequences were run in a contiguous block separate from ABBD, the recent history of experience is different for A stimuli in ABCD versus ABBD. Running fully interleaved sequences would also address this point, and would also potentially mitigate the impact of drift over blocks (discussed below).</p>
<p>(2) The computation of prediction error differs significantly for omission as opposed to substitutions, in meaningful ways the authors do not address. For omission errors, PE compares the responses of B1 and B2 within ABBD blocks. These responses are measured from the same trial, within tens of milliseconds of each other. In contrast, substitution PE is computed by comparing C in ABCD to C in ACBD. As noted above, the block structure means that these C responses were recorded in different blocks, when the state of the brain could be different. This may account for the authors' detection of prediction error for omission but not substitution. To address this, the authors should calculate PE for omission using B responses from ABCD.</p>
<p>(3) The behavior of responses to B and C within the trained sequence ABCD differs considerably, yet is not addressed. Responses to B in ABCD potentiate from d0-&gt; d5, yet responses to C in the same sequence go down. This suggests there may be some difference in either the representation of B vs C or position 2 vs 3 in the sequence that may also be contributing to the appearance of prediction errors in ABBD but not ACBD. The authors do not appear to consider this point, which could potentially impact their results. Presenting different stimuli for A,B,C,D across mice would help (in the current paper B is 75 deg and C is 165 deg in all cases). Additionally, other omissions or substitutions at different sequence positions should be tested (eg ABCC or ABDC).</p>
<p>(4) The authors' interpretation of their PCA results is flawed. The authors write &quot;Experience simplifies activity in principal component space&quot;. This is untrue based on their data. The variance explained by the first set of PCs does not change with training, indicating that the data is not residing in a lower dimensional (&quot;simpler&quot;) space. Instead, the authors show that the first 5 PCs better align with their a priori expectations of the stimulus structure, but that does not mean these PCs necessarily represent more information about the stimulus (and the fact that the authors fail to see an improvement in decoding performance argues against this case). Addressing such a question would be highly interesting, but is lacking in the current manuscript. Without such analysis, referring to the PCs after training as &quot;highly discretized&quot; and &quot;untangled&quot; are largely meaningless descriptions that lack analytical support.</p>
<p>(5) The authors report that activity sparsifies, yet provide only the fraction of stimulus-selective cells. Given that cell detection was automated in a manner that takes into account neural activity (using Suite2p), it is difficult to interpret these results as presented. If the authors wish to claim sparsification, they need to provide evidence that the total number of ROIs drawn on each day (the denominator for sparseness in their calculation) is unbiased. Including more (or less) ROIs can dramatically change the calculated sparseness.</p>
<p>The authors mention sparsification as contributing to coding efficiency but do not test this. Training a decoder on variously sized subsets of their data on days 0 and 5 would test whether redundant information is being eliminated in the network over training.</p>
<p>(6) The authors claim their results show representational drift, but this isn't supported in the data. Rather they show that there is some information in the structure of activity that allows a decoder to learn block ID. But this does not show whether the actual stimulus representations change, and could instead reflect an unrelated artifact that changes over time (responsivity, alertness, bleaching, etc). To actually assess representational drift, the authors should directly compare representations across blocks (one could train a decoder on block 1 and test on blocks 2-5). In the absence of this or other tests of representational drift over blocks, the authors should remove the statement that &quot;These findings suggest that there is a measurable amount of representational drift&quot;.</p>
<p>(7) The authors allude to &quot;temporal echoes&quot; in a subheading. This term is never defined, or substantiated with analysis, and should be removed.</p>
</body>
</sub-article>
</article>