<?xml version="1.0" ?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.3 20210610//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">elife</journal-id>
<journal-id journal-id-type="publisher-id">eLife</journal-id>
<journal-title-group>
<journal-title>eLife</journal-title>
</journal-title-group>
<issn publication-format="electronic" pub-type="epub">2050-084X</issn>
<publisher>
<publisher-name>eLife Sciences Publications, Ltd</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">99266</article-id>
<article-id pub-id-type="doi">10.7554/eLife.99266</article-id>
<article-id pub-id-type="doi" specific-use="version">10.7554/eLife.99266.1</article-id>
<article-version-alternatives>
<article-version article-version-type="publication-state">reviewed preprint</article-version>
<article-version article-version-type="preprint-version">1.1</article-version>
</article-version-alternatives>
<article-categories><subj-group subj-group-type="heading">
<subject>Neuroscience</subject>
</subj-group>
<subj-group subj-group-type="heading">
<subject>Computational and Systems Biology</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Adaptive Integration of Perceptual and Reward Information in an Uncertain World</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0009-0003-2066-6651</contrib-id>
<name>
<surname>Ganesh</surname>
<given-names>Prashanti</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Cichy</surname>
<given-names>Radoslaw M</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Schuck</surname>
<given-names>Nicolas W</given-names>
</name>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
</contrib>
<contrib contrib-type="author">
<name>
<surname>Finke</surname>
<given-names>Carsten</given-names>
</name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a5">5</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-3033-6299</contrib-id>
<name>
<surname>Bruckner</surname>
<given-names>Rasmus</given-names>
</name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
<xref ref-type="aff" rid="a4">4</xref>
<email>rasmus.bruckner@fu-berlin.de</email>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Education and Psychology, Freie Universität Berlin</institution>, <city>Berlin</city>, <country>Germany</country></aff>
<aff id="a2"><label>2</label><institution>Humboldt-Universität zu Berlin, Berlin School of Mind and Brain</institution>, <city>Berlin</city>, <country>Germany</country></aff>
<aff id="a3"><label>3</label><institution>Max Planck Research Group NeuroCode, Max Planck Institute for Human Development</institution>, <city>Berlin</city>, <country>Germany</country></aff>
<aff id="a4"><label>4</label><institution>Institute of Psychology, Universität Hamburg</institution>, <city>Hamburg</city>, <country>Germany</country></aff>
<aff id="a5"><label>5</label><institution>Department of Neurology, Charité – Universitätsmedizin Berlin</institution>, <city>Berlin</city>, <country>Germany</country></aff>
</contrib-group>
<contrib-group content-type="section">
<contrib contrib-type="editor">
<name>
<surname>Gold</surname>
<given-names>Joshua I</given-names>
</name>
<role>Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Pennsylvania</institution>
</institution-wrap>
<city>Philadelphia</city>
<country>United States of America</country>
</aff>
</contrib>
<contrib contrib-type="senior_editor">
<name>
<surname>Gold</surname>
<given-names>Joshua I</given-names>
</name>
<role>Senior Editor</role>
<aff>
<institution-wrap>
<institution>University of Pennsylvania</institution>
</institution-wrap>
<city>Philadelphia</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<pub-date date-type="original-publication" iso-8601-date="2024-11-07">
<day>07</day>
<month>11</month>
<year>2024</year>
</pub-date>
<volume>13</volume>
<elocation-id>RP99266</elocation-id>
<history>
<date date-type="sent-for-review" iso-8601-date="2024-06-05">
<day>05</day>
<month>06</month>
<year>2024</year>
</date>
</history>
<pub-history>
<event>
<event-desc>Preprint posted</event-desc>
<date date-type="preprint" iso-8601-date="2024-04-28">
<day>28</day>
<month>04</month>
<year>2024</year>
</date>
<self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.04.24.590947"/>
</event>
</pub-history>
<permissions>
<copyright-statement>© 2024, Ganesh et al</copyright-statement>
<copyright-year>2024</copyright-year>
<copyright-holder>Ganesh et al</copyright-holder>
<ali:free_to_read/>
<license xlink:href="https://creativecommons.org/licenses/by/4.0/">
<ali:license_ref>https://creativecommons.org/licenses/by/4.0/</ali:license_ref>
<license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="elife-preprint-99266-v1.pdf"/>
<abstract>
<p>Perceptual uncertainty and salience both impact decision-making, but how these factors precisely impact trial-and-error reinforcement learning is not well understood. Here, we test the hypotheses that (H1) perceptual uncertainty modulates reward-based learning and that (H2) economic decision-making is driven by the value and the salience of sensory information. For this, we combined computational modeling with a perceptual uncertainty-augmented reward-learning task in a human behavioral experiment (<italic>N</italic> = 98). In line with our hypotheses, we found that subjects regulated learning behavior in response to the uncertainty with which they could distinguish choice options based on sensory information (belief state), in addition to the errors they made in predicting outcomes. Moreover, subjects considered a combination of expected values and sensory salience for economic decision-making. Taken together, this shows that perceptual and economic decision-making are closely intertwined and share a common basis for behavior in the real world.</p>
</abstract>
<custom-meta-group>
<custom-meta specific-use="meta-only">
<meta-name>publishing-route</meta-name>
<meta-value>prc</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
</notes>
</front>
<body>
<sec id="s0">
<title>Introduction</title>
<p>In the real world, economic choices fundamentally depend on the processing of perceptual information. An agent first needs to make perceptual decisions, that is, identify the stimuli or states of the environment based on sensory information, to then compute expected values for economic decision-making (<xref ref-type="bibr" rid="c43">Rangel et al., 2008</xref>; <xref ref-type="bibr" rid="c51">Summerfield &amp; Tsetsos, 2012</xref>). For example, consider a customer who chooses between different types of bread in a bakery. To do so, they need to first identify the available types of bread (states) based on perceptual information to then ascertain the expected taste of the options (expected value). This seemingly simple interplay of perceptual and economic decision-making becomes particularly challenging when perceptual information is ambiguous (perceptual uncertainty) or when outcomes are risky (reward uncertainty) (<xref ref-type="bibr" rid="c3">Bach &amp; Dolan, 2012</xref>; <xref ref-type="bibr" rid="c6">Bruckner et al., 2020</xref>; <xref ref-type="bibr" rid="c7">Bruckner &amp; Nassar, 2024</xref>; <xref ref-type="bibr" rid="c11">Daw, 2014</xref>; <xref ref-type="bibr" rid="c28">Ma &amp; Jazayeri, 2014</xref>; <xref ref-type="bibr" rid="c42">Platt &amp; Huettel, 2008</xref>; <xref ref-type="bibr" rid="c51">Summerfield &amp; Tsetsos, 2012</xref>). For example, different loaves of bread might look very similar, yielding perceptual uncertainty. Moreover, the taste of the same type of bread may vary over time or across bakeries due to differences in the ingredients, which leads to reward uncertainty. Therefore, to understand real-world decision-making and learning, we must study the interplay between perceptual and economic choices under uncertainty. Here, we focus on two fundamental questions about this interplay: (i) How does perceptual uncertainty modulate reward learning in humans? (ii) To what extent is human economic decision-making driven by perceptual and value information?</p>
<p>Reward learning requires assigning experienced rewards (e.g., experienced taste after eating a slice of bread) to the states and stimuli of the environment (e.g., type of bread), which is often described as credit assignment (<xref ref-type="bibr" rid="c13">Doya, 2008</xref>; <xref ref-type="bibr" rid="c38">O’Reilly &amp; Frank, 2006</xref>). This is relatively straightforward when there is clear perceptual information (two distinct types of bread, such as pretzel and baguette; <xref rid="fig1" ref-type="fig">Fig. 1a</xref>). However, learning typically takes place amidst perceptual uncertainty due to ambiguous sensory information and internal noise (<xref ref-type="bibr" rid="c55">Walker et al., 2023</xref>). In such cases, the state of the environment cannot be clearly identified (<xref ref-type="bibr" rid="c6">Bruckner et al., 2020</xref>; <xref ref-type="bibr" rid="c11">Daw, 2014</xref>). Therefore, perceptual uncertainty leads to a credit-assignment problem in that the association between reward and state that should be learned is unclear (<xref rid="fig1" ref-type="fig">Fig. 1b</xref>). If the decision maker correctly identifies the state, they can accurately learn the association. However, if the decision maker perceives the state incorrectly, they will learn the wrong association between state and outcome.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Dynamic integration of visual and reward information under uncertainty.</title>
<p><bold>a</bold>| Learning requires assigning experienced rewards (e.g., taste experience) to the stimuli or states of the environment (e.g., type of bread). In this example, the person can clearly distinguish the two states (pretzel and baguette). When choosing an option (e.g., eating the baguette), they can easily learn an association between reward and state (corresponding to the stimulus “baguette” in this case). <bold>b</bold>| However, when states cannot be clearly dissociated based on sensory information, the person experiences perceptual uncertainty (e.g., two very similar types of bread). In this case, they can compute a belief about the state (belief state), quantifying how confidently the states can be distinguished (e.g., 40% baguette, 60% ciabatta). This leads to a credit-assignment problem, making it unclear what association between state and reward should be updated, and thus, the risk of learning the incorrect association between state and reward. <bold>c</bold>| Our first hypothesis concerns learning under different degrees of uncertainty of belief states. Learning behavior can be quantified using the learning rate (LR; illustrated by the slope of the line). It stands for the rate at which updates about reward expectations change with the prediction error. A learning rate of 1 indicates that only the prediction error is used to make a corresponding update. In contrast, when the learning rate is 0, it indicates that the prediction error has been ignored altogether. We hypothesized that the learning rate tends to be higher, leading to larger updates for a given prediction error when belief states are certain (e.g., 99% baguette, 1% pretzel; dark green line). In contrast, under higher belief-state uncertainty (e.g., 40% baguette, 60% ciabatta; light green line), learning rates are lower. <bold>d</bold>| Our second hypothesis concerns the integration of learned reward expectations (expected value) and visual salience during decision-making. Different options often have, next to different expected values, distinct perceptual features such as salience (e.g., one type of bread captures one’s attention). We hypothesized that both visual salience and expected value govern economic decision-making.</p></caption>
<graphic xlink:href="590947v1_fig1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Bayesian inference and reinforcement-learning approaches indicate that the degree of learning from new outcomes should be regulated to deal with perceptual uncertainty (<xref ref-type="bibr" rid="c6">Bruckner et al., 2020</xref>; <xref ref-type="bibr" rid="c8">Chrisman, 1992</xref>; <xref ref-type="bibr" rid="c15">Ez-zizi et al., 2023</xref>; <xref ref-type="bibr" rid="c23">Lak et al., 2017</xref>; <xref ref-type="bibr" rid="c25">Larsen et al., 2010</xref>). This dynamic regulation of learning behavior is typically quantified by the learning rate. The learning rate expresses to what extent an agent considers the prediction error (i.e., the difference between actual and expected reward) to update their belief about future reward. In doing this, an agent crucially needs to take the probability of being in a particular perceptual state (belief state) into account (<xref rid="fig1" ref-type="fig">Fig. 1a,b</xref>). In particular, when the belief state clearly favors a particular state (certain belief state), the learning rate should be higher compared to situations with an uncertain belief state (see light vs. dark green lines in <xref rid="fig1" ref-type="fig">Fig. 1c</xref>). In line with these ideas, previous results suggest that humans and animals consider belief states to flexibly regulate learning (<xref ref-type="bibr" rid="c6">Bruckner et al., 2020</xref>; <xref ref-type="bibr" rid="c9">Colizoli et al., 2018</xref>; <xref ref-type="bibr" rid="c16">Gershman &amp; Uchida, 2019</xref>). Moreover, animal work has shown that belief states modulate dopamine activity and choice behavior in perceptual and reward-based decision-making (<xref ref-type="bibr" rid="c2">Babayan et al., 2018</xref>; <xref ref-type="bibr" rid="c23">Lak et al., 2017</xref>; <xref ref-type="bibr" rid="c24">Lak et al., 2020</xref>; <xref ref-type="bibr" rid="c50">Starkweather et al., 2017</xref>). However, these findings are primarily based on model fitting of choice data, which does not give direct access to prediction errors, belief updates, and learning rates. Consequently, it only indirectly reveals the impact of belief states on learning. Thus, our goal was to go beyond model fitting by obtaining trial-by-trial measurements of learning and thereby test the direct impact of uncertainty on learning rates (<xref ref-type="bibr" rid="c34">Nassar &amp; Gold, 2013</xref>; <xref ref-type="bibr" rid="c36">Nassar et al., 2010</xref>; <xref ref-type="bibr" rid="c47">Sato &amp; Kording, 2014</xref>). Based on this, we hypothesized that human subjects use lower learning rates when belief states are more uncertain.</p>
<p>The integration of perceptual and reward information is important not only for adaptive learning but also for flexible decision-making under uncertainty. Customers often review bread along different dimensions, such as taste or appearance (artisanal, fluffy), before making a purchase (<xref rid="fig1" ref-type="fig">Fig. 1d</xref>). This poses the question of how humans combine perceptual and reward information during economic decision-making. Previous work suggests that humans combine both value information and visual salience of an option to harvest rewards. In many ecological contexts, visual salience elicits species-specific behavior given that they indicate higher levels of safety and certainty (<xref ref-type="bibr" rid="c19">Itti &amp; Koch, 2001</xref>; <xref ref-type="bibr" rid="c41">Pike, 2018</xref>; <xref ref-type="bibr" rid="c46">Rumbaugh et al., 2007</xref>). For instance, a ripe red fruit amidst green leaves reflexively captures one’s attention, thereby increasing the likelihood of survival. Therefore, specifically in perceptually cluttered and uncertain environments, salience could directly modulate economic choices (<xref ref-type="bibr" rid="c37">Navalpakkam et al., 2010</xref>; <xref ref-type="bibr" rid="c52">Towal et al., 2013</xref>). Based on these considerations, we hypothesized that human economic decision-making is governed by both expected value and perceptual salience.</p>
<p>To test our two hypotheses about the interplay of perception and reward during learning and decision-making, we combined a behavioral choice task with computational modeling. Our results support our first hypothesis that participants adjust their learning rate according to their belief states. In particular, we show that participants use lower learning rates when uncertainty over belief states is higher. This is in line with the predictions of a normative learning model that optimally regulates learning as a function of the belief state. However, next to this normative effect on learning, we also identified a constant effect of prediction errors irrespective of perceptual uncertainty. From the perspective of our model, this effect is sub-optimal, and we interpret it as a heuristic strategy that humans potentially employ to simplify learning. Our results further support our second hypothesis regarding the integration of expected value and salience for decision-making under uncertainty, showing that both drive economic decision-making. Taken together, our study demonstrates how humans integrate perceptual and reward information in the service of adaptive behavior and highlights the convergence of perceptual and economic choices.</p>
</sec>
<sec id="s1">
<title>Results</title>
<sec id="s1a">
<title>Task design and performance</title>
<p>To examine the interplay of perception and reward during learning and decision-making, we analyzed the behavioral data of 98 participants (60 male, 38 female; mean age = 23.82 <italic>±</italic> 3.30 standard error of the mean (SEM); range 18-29) completing an online version of the Gabor-Bandit task (<xref ref-type="bibr" rid="c6">Bruckner et al., 2020</xref>). Moreover, to optimize the task parameters of the main task, we ran a pilot study with 100 participants (52 female, 48 male; mean age = 22.91<italic>±</italic> 3.04; range 18-30), which we report in the supplement (see Pilot study). Participants were instructed that the goal of the task was to gain as much reward as possible and that each trial comprised three stages (<xref rid="fig2" ref-type="fig">Fig. 2a</xref>). In the first stage, participants had to make an economic choice between two Gabor patches. In the second stage, participants received reward feedback on their choice. Finally, in the third stage, they reported their belief about the reward probability using a slider ranging between 0 and 1.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Uncertainty-augmented Gabor-Bandit task, choice performance, and learning behavior.</title>
<p><bold>a</bold>| Subjects were asked to make an economic decision between two Gabor patches. Based on their choice, an outcome was presented. Finally, participants were required to report their subjective value expectation for a hypothetical choice using a slider. <bold>Inset plot</bold>| Experimental conditions. In the “both-uncertainties” condition, participants faced high levels of perceptual uncertainty, where Gabor patches were harder to distinguish, and reward uncertainty, which led to the “correct” option being rewarded with 70 % probability. In the perceptual-uncertainty condition, high levels of perceptual uncertainty were accompanied by low levels of reward uncertainty, which led to the “correct” option being rewarded with 90 % probability. In the reward-uncertainty condition, low levels of perceptual uncertainty, i.e., Gabor patches were easily distinguishable, were combined with high levels of reward uncertainty. <bold>b</bold>| Task contingency. The main aim of the task was to maximize rewards by learning the underlying task contingency between the action and reward, given the state of a trial. Each trial could potentially belong to state 0 or 1. The state determined the location of the high-contrast patch. In state 0, the right patch had a stronger contrast than the left patch and vice versa for state 1. The contingency parameter <italic>µ</italic> determined the reward probability given the action of the participant and the task state. In this example, in state 0, the probability of a reward is higher when choosing the left patch. In state 1, the reward probability is higher when choosing the right patch. Please note that in other blocks, this pattern was reversed, and participants were instructed to relearn the underlying contingency. <bold>c</bold>| Mean <italic>±</italic> standard error of the mean (SEM) economic performance, defined as the frequency of choosing the more rewarding or correct option. <bold>d</bold>| Mean <italic>±</italic> SEM subjective estimate of the reward probability based on the slider responses. <bold>e</bold>| Mean <italic>±</italic> SEM subjective estimate of reward probability based on the slider responses plotted across trials. <bold>f</bold>| Relationship between accuracy in learning (absolute estimation error reflecting absolute difference between true reward probability and slider response) and choice behavior. Lower average estimation errors signal better learning and are moderately correlated with higher levels of economic performance.</p></caption>
<graphic xlink:href="590947v1_fig2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Like in classical perceptual decision-making paradigms, the task featured perceptual uncertainty about the Gabor patches (<xref ref-type="bibr" rid="c18">Gold &amp; Stocker, 2017</xref>). Moreover, as in classical economic decision-making paradigms, rewards were delivered probabilistically, which is defined as risk or reward uncertainty (<xref ref-type="bibr" rid="c7">Bruckner &amp; Nassar, 2024</xref>; <xref ref-type="bibr" rid="c42">Platt &amp; Huettel, 2008</xref>; <xref ref-type="bibr" rid="c43">Rangel et al., 2008</xref>). On each trial, the patches had varying contrast-difference levels that were determined by a hidden state. In state 0, contrast differences were negative, indicating that the right patch was stronger, while in state 1, contrast differences were positive, and the left patch was stronger. Moreover, the hidden state and reward-contingency parameter governed what economic decision would be rewarded (<xref rid="fig2" ref-type="fig">Fig. 2b</xref>). For example, when the contingency parameter assumed the value of 0.9, then in state 0, the left patch with the lower contrast also had a reward probability of 90 %, and the right patch had a reward probability of 10 %. On the other hand, in state 1, the reward contingency was reversed. In this case, the left patch with the higher contrast had a reward probability of 10 % and the right patch of 90 % (see Contingencies, for more details). The participants’ responses on the slider crucially allowed us to track the participants’ beliefs about the reward probability from trial to trial. The task was divided into 12 blocks of 25 trials. The contingency parameter was consistent within each block. Since participants were unaware of the current block’s contingency parameter, they had to learn the parameter value during each block.</p>
<p>To induce perceptual uncertainty and manipulate belief states on a trial-by-trial basis, we manipulated the contrast differences of the patches. The contrast differences were sampled from a uniform distribution. The range of the distributions for high and low perceptual uncertainty was calibrated based on the pilot study. When the contrast differences were small (patches looked more similar), belief states were uncertain. Conversely, for trials in which the two patches had distinct contrast levels, belief-state uncertainty was low. To manipulate reward uncertainty, we manipulated the contingency parameter, where 0.7 (i.e., correct choices rewarded in 70 %) corresponds to higher reward uncertainty and 0.9 (i.e., correct choices rewarded in 90 %) to lower reward uncertainty. The systematic manipulation of uncertainty resulted in three experimental conditions (<xref rid="fig2" ref-type="fig">Fig. 2a</xref> inset). The first condition included trials with both forms of uncertainty (termed “both-uncertainties” condition). Consequently, trials with only perceptual or reward uncertainty belong to the perceptual- and reward-uncertainty conditions, respectively. Finally, to ensure that participants had to re-learn the reward contingencies on each block, we counter-balanced the mapping between states, actions, and rewards. That is, in half of the blocks, the patch with the higher contrast level was the rewarding choice option (which we refer to as the high-contrast blocks). In the other half of the blocks, the patch with the lower contrast level was the more rewarding choice option (low-contrast blocks). Please note that this manipulation is crucial since the same mapping between states, actions, and rewards across blocks would negate the need for re-learning after the initial block (see Task details for more details).</p>
<p>To test if participants learned to choose the more rewarding option under both perceptual and reward uncertainty, we analyzed their choices and subjectively reported reward probabilities. Indeed, participants learned to choose the correct option (high-reward option) in all conditions. The average economic choice performance was above chance in all conditions (<xref rid="fig2" ref-type="fig">Fig. 2c</xref>; both: mean = 0.72 <italic>±</italic> 0.014, <italic>t</italic><sub>97</sub> = 15.79, <italic>p</italic> &lt; 0.001, Cohen’s <italic>d</italic> = 5.23, perceptual: mean = 0.85 <italic>±</italic> 0.009, <italic>t</italic><sub>97</sub> = 38.95, <italic>p</italic> &lt; 0.001, Cohen’s <italic>d</italic> = 9.55, reward: mean = 0.79 <italic>±</italic> 0.014, <italic>t</italic><sub>97</sub> = 20.1, <italic>p</italic> &lt; 0.001, Cohen’s <italic>d</italic> = 5.52). Moreover, performance was significantly different between the conditions (<italic>F</italic><sub>2,291</sub> = 26.77, <italic>p &lt;</italic> 0.001). In line with the intuition that perceptual uncertainty impairs decision-making, economic choice performance in the both-uncertainties condition was lower as compared to the reward-uncertainty condition (<italic>t</italic><sub>194</sub> = <italic>−</italic> 3.56, <italic>p &lt;</italic> 0.001, Cohen’s <italic>d</italic> = <italic>−</italic> 0.51). Similarly, the results suggested that reward uncertainty reduced choice performance. Economic choice performance was lower in the both-uncertainties condition than in the perceptual-uncertainty condition (<italic>t</italic><sub>194</sub> = <italic>−</italic> 7.92, <italic>p &lt;</italic> 0.001, Cohen’s <italic>d</italic> = <italic>−</italic> 1.13). Choice performance was also better in the perceptual-uncertainty condition as compared to the reward-uncertainty condition (<italic>t</italic><sub>194</sub> = 3.51, <italic>p &lt;</italic> 0.001, Cohen’s <italic>d</italic> = 0.5), suggesting that given our experimental settings, the average impact of reward uncertainty was stronger than the impact of perceptual uncertainty on choice performance.</p>
<p>Consistent with the decision-making results, learning curves based on the slider responses clearly demonstrate that participants used the reward feedback to update their beliefs about the reward probabilities (<xref rid="fig2" ref-type="fig">Fig. 2d,e</xref>). Participants approached the actual probabilities despite slight underestimation of the probabilities for each condition across trials in a block (both: mean = 0.63<italic>±</italic> 0.01, Cohen’s <italic>d</italic> = 7.26, perceptual: mean = 0.82 <italic>±</italic> 0.01, Cohen’s <italic>d</italic> = 6.12, reward: mean = 0.66 <italic>±</italic> 0.01, Cohen’s <italic>d</italic> = 7.14). There was a significant effect of the type of uncertainty on the mean reported reward probability across the trials in a block (<italic>F</italic><sub>2,291</sub> = 87.08, <italic>p &lt;</italic> 0.001). The impact of uncertainty on the reported reward probability was similar to that of its effect on choice behavior. In the both-uncertainties condition, the reported reward probability was lower as compared to the reward-uncertainty condition (<italic>t</italic><sub>194</sub> = <italic>−</italic> 2.05, <italic>p</italic> = 0.04, Cohen’s <italic>d</italic> = <italic>−</italic> 0.29), and the perceptual-uncertainty condition (<italic>t</italic><sub>194</sub> = <italic>−</italic>11.5, <italic>p &lt;</italic> 0.001, Cohen’s <italic>d</italic> = <italic>−</italic>1.64). Reported reward probability was also higher in the perceptual-uncertainty condition as compared to the reward-uncertainty condition (<italic>t</italic><sub>194</sub> = 9.7, <italic>p &lt;</italic> 0.001, Cohen’s <italic>d</italic> = 1.39).</p>
<p>Finally, participants who reported more accurate estimates of the underlying reward probabilities were more likely to make better choices. To quantify the accuracy of participants’ reported reward probabilities, we computed the absolute difference between the actual reward probability and participants’ estimated reward probabilities (estimation error). Lower estimation error indicates higher accuracy of a participant’s belief about the reward probability. Results showed that lower estimation errors were significantly correlated with higher economic choice performance (<xref rid="fig2" ref-type="fig">Fig. 2f</xref>; Pearson’s <italic>r</italic><sub>97</sub> = −0.63, <italic>p</italic> &lt; 0.001). Building upon these findings about choice and learning behavior we next examined our key hypotheses about the interplay of perceptual and economic choices.</p>
</sec>
<sec id="s1b">
<title>A normative agent considers belief states to regulate the learning rate</title>
<p>Our first research question is how humans consider perceptual uncertainty during reward-based learning, and we hypothesized that perceptual uncertainty modulates participants’ learning rates. We now illustrate this hypothesis based on simulations using a normative Bayesian agent model that utilizes belief states to regulate learning rates optimally (<xref ref-type="bibr" rid="c6">Bruckner et al., 2020</xref>). Akin to human participants, the agent first observes the contrast difference of the Gabor patches. Due to perceptual uncertainty, the agent cannot see the objectively presented difference but instead observes contrasts that are distorted by Gaussian sensory noise (<xref rid="fig3" ref-type="fig">Fig. 3a</xref>). Based on its subjective observation, the agent computes the belief state (see Perceptual inference, for more details). Under lower perceptual uncertainty (i.e., less sensory noise), the agent is likely to have more distinct belief states (<italic>π</italic><sub><italic>s</italic></sub> = (0.1, 0.9)), that is, the agent can identify which patch displays the stronger contrast (<xref rid="fig3" ref-type="fig">Fig. 3b</xref>). The normative agent uses the belief states to compute the current expected value of the choice options (see Economic decision-making, for more details). For instance, in the example in <xref rid="fig3" ref-type="fig">Fig. 3c</xref>, the learned contingency parameter (<italic>µ</italic> = 1) has a high bearing on the expected values (0.1 for action 0, 0.9 for action 1) since the belief states are highly distinct from one another under lower perceptual uncertainty. In contrast, under higher perceptual uncertainty due to more sensory noise, the agent experiences more uncertain belief states (<italic>π</italic><sub><italic>s</italic></sub> = (0.4, 0.6)) that lead to discounted expected values (see light green bars in <xref rid="fig3" ref-type="fig">Fig. 3c</xref>). Thus, the contingency parameter (<italic>µ</italic> = 1) has lesser influence on expected values under hardly distinguishable belief states, resulting in similar expected values for both actions.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Normative agent.</title>
<p><bold>a</bold>| Contrast-difference observation. A trial can assume one of two hidden task states. The state determines the contrast difference between the high- and low-contrast patches (state <italic>st</italic> = 0 indicates that the right patch has a stronger contrast, and state <italic>st</italic> = 1 indicates that the left patch has a stronger contrast). Due to sensory noise (perceptual uncertainty), the agent cannot perceive the objectively presented contrast difference but a subjective observation that is sampled from a Gaussian observation distribution. Within this distribution, higher perceptual uncertainty is reflected in higher variance over possible observations. <bold>b</bold>| Belief state. The agent computes the probability of being in a given state (belief state) given the subjective observation. Larger contrast differences are translated into more distinct belief states. Subsequently, the agent considers the belief state for economic decision-making and learning. <bold>c</bold>| Uncertainty-weighted expected value. During decision-making, the agent combines the belief state and the learned reward probabilities to compute the expected value. The expected values for the two options are less distinct when belief states are more similar. <bold>d</bold>| Uncertainty-weighted learning. When receiving reward feedback after an economic choice, the agent takes into account the belief state during reward-based learning. The agent uses the belief states to determine how much the prediction error modulates the current trial’s update in the estimate of the contingency parameter. When there is less uncertainty regarding belief states, the agent uses a higher learning rate and, thus, engages in faster learning from prediction errors. However, to deal with the credit-assignment problem arising from highly uncertain belief states (i.e., due to uncertainty, it is unclear what association between stimulus and reward should be updated), the agent dynamically adjusts the learning rate to avoid incorrect assignment of obtained rewards to alternatives. <bold>e</bold>| When learning from multiple outcomes, the estimated contingency parameter approaches the actual contingency parameter with the passage of trials in a block. In contrast, an agent who ignores perceptual uncertainty and represents “categorical” belief states (i.e., assuming that it can perfectly perceive contrast differences and infer the hidden task state) shows reduced learning performance. In this case, the agent often updates the wrong association between stimuli and rewards, thereby leading to an underestimation of the contingency parameter.</p></caption>
<graphic xlink:href="590947v1_fig3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Subsequently, the agent makes a choice and receives a reward. Please note that we assumed that the agent’s decisions were free of noise to simulate exploitative choices. We express the underlying learning from the obtained reward as how much the agent updates its belief about the contingency parameter, given the prediction error. When belief states are clearly distinct, the agent uses moderate learning rates (<italic>π</italic><sub><italic>s</italic></sub> = (0.1, 0.9); see dark green line in <xref rid="fig3" ref-type="fig">Fig. 3d</xref>). In contrast, when belief states are more uncertain (<italic>π</italic><sub><italic>s</italic></sub> = (0.4, 0.6)), the learning rate is considerably lower (see light green line in <xref rid="fig3" ref-type="fig">Fig. 3d</xref>). That is, when belief states are ambiguous, the influence of the prediction error on learning from an outcome considerably reduces (see Learning, for more details). Therefore, when perceptual uncertainty is low, the agent makes better choices and learns reward probabilities more quickly (for a comparison between the three conditions, see <xref rid="figS11" ref-type="fig">Fig. S11</xref>).</p>
<p>Based on this normative belief-updating mechanism, the agent optimally learns the underlying contingency parameter (see black curve in <xref rid="fig3" ref-type="fig">Fig. 3e</xref>). Crucially, considering the belief state in this way during learning yields a more accurate belief about the contingency parameter compared to a learning mechanism that ignores perceptual uncertainty. Specifically, the learning curve of an agent that only represents binary or categorical belief states (belief states only assume 0 and 1 instead of values in between) reflects a less accurate and biased belief about the contingency parameter (categorical agent; see gray curve in <xref rid="fig3" ref-type="fig">Fig. 3e</xref>). In summary, these simulations illustrate our first hypothesis that the certainty of a belief state modulates learning rates. When belief states are more certain, learning rates tend to be higher than on trials with more uncertain belief states.</p>
</sec>
<sec id="s1c">
<title>Humans consider belief states to regulate the learning rate</title>
<p>We next tested our first hypothesis that humans take into account their belief states to regulate learning behavior. We quantified participants’ learning behavior on each trial by calculating the learning rate. To do so, we used the reported beliefs about the reward probability to compute each trial’s prediction error and belief update (see Data preprocessing, for more details). Sub-sequently, learning was measured as the extent to which participants updated their subjective estimate of the reward probability on the slider, given that trial’s prediction error. We approx-imated belief states using the level of contrast difference, where lower differences result in more uncertain belief states.</p>
<p>Directly comparing single-trial learning rates across bins of contrast-difference values (ordered from more to less uncertain approximated belief states), we observed an increase in the learning rate (<xref rid="fig4" ref-type="fig">Fig. 4a</xref>). That is, participants learned more when belief states were, on average, more certain, in line with our hypothesis that perceptual uncertainty leads to dynamic adjustment of learning rates.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Decomposing learning rates.</title>
<p><bold>a</bold>| We computed single-trial learning rates reflecting the extent to which prediction errors (difference between obtained reward and subjectively reported reward probability) drive slider updates (difference in reported reward probability between current and previous trial). To examine whether learning rates were dynamically adjusted to how well subjects could discriminate the choice options, we divided the data into 10 contrast-difference bins, where lower bins correspond to more uncertain belief states. The plot shows the mean<italic>±</italic> standard error of the mean (SEM) learning rate for each bin. The increase as a function of contrast difference (Pearson’s <italic>r</italic><sub>08</sub> = 0.87, <italic>p</italic> = 0.001) suggests that subjects use higher learning rates when belief states are more clearly distinct. <bold>b</bold>| To decompose the influences of different factors on the learning rate, we developed a regression model (see inset equation on top of plot, where <italic>δ</italic> denotes the prediction error). Mean <italic>±</italic> SEM coefficients for key regressors from the linear regression model are shown here. Positive fixed-LR coefficients indicate participants’ average tendency to learn from prediction errors (Cohen’s <italic>d</italic> = 0.68). <bold>c</bold>| The belief-state-adapted-LR coefficients reflect the adjustment of the learning conditional of the contrast difference (Cohen’s <italic>d</italic> = 0.53). <bold>d</bold>| This subplot shows an example participant illustrating the extent to which prediction errors weighted by contrast difference (belief-state-adapted LR) drive the update. In line with (a), this suggests a down-regulation of the learning rate when belief states are more uncertain. <bold>e</bold>| Across three levels of contrast-difference values, regression fits for a range of prediction errors of an example participant suggest that belief states modulated the learning rate. Higher contrast differences (i.e., on average, more distinct belief states) led to larger updates as compared to lower contrast differences.</p></caption>
<graphic xlink:href="590947v1_fig4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>While the previous analysis suggests uncertainty-driven belief updating on the group level, it does not indicate to what extent individual subjects use the belief state to weight the prediction error. Therefore, we used a linear regression model that quantified the impact of prediction errors and belief states on belief updating for each subject (<xref ref-type="bibr" rid="c29">McGuire et al., 2014</xref>; <xref ref-type="bibr" rid="c33">Nassar et al., 2019</xref>; <xref ref-type="bibr" rid="c47">Sato &amp; Kording, 2014</xref>). In the model, we expressed the reported belief update as a linear function of the prediction error, and the slope of this function is equivalent to a fixed learning rate as in typical error-driven learning models (often referred to as <italic>α</italic> in reinforcement learning; <xref ref-type="bibr" rid="c11">Daw, 2014</xref>). To model the dynamic impact of belief states, the model included an interaction term between belief state and prediction error (<xref rid="fig4" ref-type="fig">Fig. 4</xref> inset equation, where <italic>δ</italic> denotes prediction error). The model also allowed us to simultaneously control for the impact of choice confirmation and several nuisance variables (for more details on the model, see Regression analysis). We fit the model to participants’ single-trial updates as well as simulated data based on the normative agent. Comparison with the predictions of the model allowed us to ascertain to what extent human learning under uncertainty approaches normative belief updating.</p>
<p>Participants’ fixed learning rates reflecting the average influence of prediction errors were positive (mean = 0.12<italic>±</italic> 0.018, <italic>t</italic><sub>97</sub> = 6.72, <italic>p &lt;</italic> 0.001, Cohen’s <italic>d</italic> = 0.68; <xref rid="fig4" ref-type="fig">Fig. 4c</xref>, fixed-learning-rate (LR) coefficient). A systematic comparison to the normative agent suggests that participants’ positive fixed learning rates correspond to a heuristic, if not a biasing influence of the prediction error on learning. The agent shows a coefficient near zero, indicating that from a normative learning perspective, learning behavior should not be driven by a static influence of prediction error, thus leaving room for uncertainty-driven flexible learning.</p>
<p>Besides the overall effect of the prediction error, participants showed evidence of dynamic learning-rate adjustments similar to the normative model. We found that larger contrast differences (i.e., on average, more certain belief states) propelled updates for a given prediction error, as indicated by the positive coefficients for the interaction of prediction error and contrast difference (mean = 0.08 <italic>±</italic> 0.015, <italic>t</italic><sub>97</sub> = 5.23, <italic>p &lt;</italic> 0.001, Cohen’s <italic>d</italic> = 0.53; <xref rid="fig4" ref-type="fig">Fig. 4d</xref>, belief-state-adapted-LR coefficient). That is, in accordance with the normative model, participants flexibly adjust their learning rate depending on the belief state. Despite considerable hetero-geneity across participants, on average, participants align with the agent’s prescriptions to take perceptual uncertainty into account.</p>
<p>Follow-up analyses of the belief-state-adapted-LR coefficient suggested a small but concise influence on the learning rate. Expressing the relationship between this coefficient and the updates, after taking all other regressors into account, a robust relationship between the belief-state-weighted prediction errors and updates is evident. To illustrate this point, <xref rid="fig4" ref-type="fig">Fig. 4d</xref> shows an example participant whose regression coefficient is indicated by the blue dot in <xref rid="fig4" ref-type="fig">Fig. 4c</xref>. This plot shows that for a positive coefficient, the belief update systematically increases with contrast difference. Furthermore, we plotted the relationship between prediction errors and updates for varying contrast-difference levels for the same example participant (<xref rid="fig4" ref-type="fig">Fig. 4e</xref>). This analysis similarly shows that for a given prediction error, learning rates systematically increase with decreasing belief-state uncertainty (increasing contrast-difference values). Please refer to Regression diagnostics in the methods for more details and for additional information on other regressors, see Full learning-rate analysis. Moreover, we found evidence for a preference to learn more strongly from outcomes that confirm choices, suggesting the presence of a choice-confirmation bias. In our regression model, positive choice-confirmation coefficients indicate stronger updates following prediction errors computed after receiving reward feedback that confirms choices (mean = 0.07 <italic>±</italic> 0.009, <italic>t</italic><sub>97</sub> = 8.03, <italic>p &lt;</italic> 0.001, Cohen’s <italic>d</italic> = 0.81, <xref rid="figS2" ref-type="fig">Fig. S2a</xref>, confirmation bias). Finally, in our current approach, the coefficients for the belief-state-driven learning could either be due to (i) a strategic calibration of the learning rate to perceptual uncertainty or (ii) state confusion due to perceptual uncertainty. To tease these apart and focus on update magnitude, we fit the same model to absolute updates with absolute prediction errors (for more details, see Absolute learning-rate analysis). Our results from this approach were consistent with the aforementioned results (<xref rid="figS1" ref-type="fig">Fig. S1c</xref>). In conclusion, our combined analyses suggest that reward learning under perceptual uncertainty is molded by the belief state.</p>
</sec>
<sec id="s1d">
<title>Fixed but not flexible learning impacts belief accuracy</title>
<p>Thus far, our results suggest that humans adaptively adjust their learning rates under perceptual uncertainty. However, are individual differences in the degree of learning flexibly associated with the accuracy of a participant’s beliefs? An obvious benefit of such belief-state-adapted learning is that beliefs are less likely to be corrupted by perceptual uncertainty. One crucial question that follows from this is whether individual differences in the degree of flexible learning translate into differences in the accuracy of beliefs. To investigate this, we employed an exploratory approach to predicting average estimation error (absolute difference between the actual reward probability and the value reported by the participant) based on the fixed and flexible learning-rate coefficients from our regression analysis.</p>
<p>We found that subjects with high fixed learning-rate coefficients (i.e., prediction-error-driven learning) tended to have larger estimation errors (<italic>β</italic> = 0.65, <italic>p &lt;</italic> 0.001; <xref rid="fig5" ref-type="fig">Fig. 5a</xref>). In a stable environment, such as in our task, rash learning has adverse effects on belief updates as it is linked to large shifts in estimates and, possibly, stronger deviations from the actual reward probability. In contrast, subjects who made smaller learning adjustments (indicated by low and moderate fixed-LR coefficients) consequently reported more accurate estimates. However, individual differences in belief-state-adapted-LR coefficients did not have a significant relationship with estimation error (<italic>β</italic> = 0.09, <italic>p</italic> = 0.37; <xref rid="fig5" ref-type="fig">Fig. 5b</xref>). One explanation for the absence of an effect of the belief-state-adapted LR might be the strong biasing effect of the fixed LR on estimation errors that could potentially overwrite its influence. However, we found that absolute belief-state-adapted LRs have a significant relationship with belief accuracy. One key reason for this could be that absolute learning rates better capture strategic calibration of learning under uncertainty, hence are linked to more accurate beliefs (see Absolute learning and estimation error and <xref rid="figS9" ref-type="fig">Fig. S9b</xref>). Similarly, we found no significant links between estimation error and confirmation bias (<italic>β</italic> = 0.19, <italic>p</italic> = 0.055; <xref rid="fig5" ref-type="fig">Fig. 5c</xref>). We also found that the confirmation bias is linked with more accurate subjective estimates of the reward probability (see Confirmation bias and over-estimated beliefs and <xref rid="figS7" ref-type="fig">Fig. S7</xref>). See Signed learning rate and estimation error for details on other signed learning regressors.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Influence of learning on belief accuracy.</title>
<p>We examined the relationship between absolute estimation errors (difference between actual reward probability and subjective estimate of the probability) reflecting belief accuracy and several predictors of the regression model (fixed learning rates, belief states, confirmation bias). <bold>a</bold>| Larger fixed learning rates were associated with larger absolute estimation errors, suggesting that learning too much from a prediction error negatively impacts learning. We did not find a systematic effect of <bold>b</bold>| belief-state-adapted learning rates and <bold>c</bold>| the confirmation bias.</p></caption>
<graphic xlink:href="590947v1_fig5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s1e">
<title>Economic choices are governed by expected values and visual salience</title>
<p>We next tested our second hypothesis that both value and visual salience govern economic decision-making. In the context of our task, we assume that options with higher contrast levels have a higher perceptual salience than the options with lower contrast. To quantify a hypothetical effect of salience on economic decision-making, we compared economic choice performance between high- and low-contrast blocks. Please recall that in half of the blocks of our task, the high-contrast option yielded more rewards (high-contrast blocks), and in the other half, the low-contrast option was more rewarding (low-contrast blocks). Therefore, a higher economic choice performance in high-contrast than low-contrast blocks reveals a “salience” bias towards the more salient option, indicating a combined impact of perceptual and reward information as hypothesized. In contrast, an alternate hypothesis would state the absence of this bias, which translates to a similar reward-maximizing performance for high- and low-contrast blocks. This analysis indicated that participants showed a significant salience bias in the both-uncertainties (mean = 0.06 <italic>±</italic> 0.025, <italic>t</italic><sub>97</sub> = 2.61, <italic>p</italic> = 0.01, Cohen’s <italic>d</italic> = 0.26) and reward condition (mean = 0.1<italic>±</italic> 0.02, <italic>t</italic><sub>97</sub> = 5.02, <italic>p &lt;</italic> 0.001, Cohen’s <italic>d</italic> = 0.51). However, as hypothesized, in the perceptual-uncertainty condition (mean = 0.02<italic>±</italic> 0.012, <italic>t</italic><sub>97</sub> = 1.8, <italic>p</italic> = 0.08, Cohen’s <italic>d</italic> = 0.18), we did not find a significant salience bias (<xref rid="fig6" ref-type="fig">Fig. 6a</xref>).</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Salience bias.</title>
<p>We examined whether choice performance was governed by perceptual salience. In high-contrast blocks, the more salient option had a higher reward probability and vice versa for low-contrast blocks. Therefore, higher choice performance on high-contrast than low-contrast blocks reflects a positive choice bias towards the more salient option. The plot shows the mean <italic>±</italic> standard error of the mean (SEM) salience bias (difference in economic performance between high- and low-contrast blocks) for the different types of uncertainty, which is significant in the condition with both perceptual and reward uncertainty (both-uncertainties condition) and the reward-uncertainty condition but not in the perceptual-uncertainty condition.</p></caption>
<graphic xlink:href="590947v1_fig6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Next, we examined if the salience bias is more enhanced due to reward uncertainty by comparing the salience bias in high reward uncertainty (“both” and reward uncertainty) blocks with low reward uncertainty (perceptual uncertainty) blocks. Participants showed a significantly larger salience bias in the reward-uncertainty condition as compared to the perceptual-uncertainty condition (<italic>t</italic><sub>97</sub> = 4.04, <italic>p &lt;</italic> 0.001, Cohen’s <italic>d</italic> = <italic>−</italic> 0.49). However, participants did not show a significantly pronounced salience bias in the both-uncertainties condition as compared to the perceptual-uncertainty condition (<italic>t</italic><sub>97</sub> = 1.82, <italic>p</italic> = 0.07, Cohen’s <italic>d</italic> = <italic>−</italic>0.23). Pilot study results also showed a salience bias which is modulated by the extent of reward uncertainty (<xref rid="figS10" ref-type="fig">Fig. S10</xref>). Overall, these findings suggest that participants’ decisions are driven by both expected values and visual salience, and we identified reward uncertainty as a facilitating factor for the same.</p>
</sec>
</sec>
<sec id="s2">
<title>Discussion</title>
<p>In an uncertain world, the interplay of perceptual and reward information is crucial for adaptive behavior. To study this, we introduced an uncertainty-augmented task combining perceptual and economic decision-making that allows for the direct estimation of the learning rate in a trial-by-trial fashion. Combined with computational modeling, we found that uncertainty plays a key role in integrating perceptual and economic decision-making. First, we show that humans flexibly modulate learning rates according to the uncertainty over the distinguishability of choices based on sensory information (belief state). Thus, this provides crucial evidence for our first hypothesis (H1) that perceptual uncertainty drives the speed of reward learning. Second, we found that humans show a choice bias towards the more perceptually salient option. This aligns with our second hypothesis (H2) that reward uncertainty facilitates the combined impact of perceptual and reward information on choices. Together, our results emphasize the intertwined nature of perceptual and economic decision-making.</p>
<p>As hypothesized, we showed that humans adjust the learning rate in response to varying belief states. When sensory information was more ambiguous, and belief states were presumably more uncertain, subjects updated their estimates of expected values to a lesser extent, in line with a reduced learning rate. Under perceptual uncertainty, identifying stimuli and environmental states is difficult (<xref ref-type="bibr" rid="c3">Bach &amp; Dolan, 2012</xref>; <xref ref-type="bibr" rid="c28">Ma &amp; Jazayeri, 2014</xref>; <xref ref-type="bibr" rid="c44">Rao, 2010</xref>), which makes it challenging to assign experienced rewards to the correct state during credit assignment (<xref ref-type="bibr" rid="c2">Babayan et al., 2018</xref>; <xref ref-type="bibr" rid="c10">Courville et al., 2006</xref>; <xref ref-type="bibr" rid="c13">Doya, 2008</xref>; <xref ref-type="bibr" rid="c38">O’Reilly &amp; Frank, 2006</xref>; <xref ref-type="bibr" rid="c44">Rao, 2010</xref>). Our results suggest that to avoid incorrect pairing of state and reward, humans resort to a belief-state-guided learning strategy (<xref ref-type="bibr" rid="c6">Bruckner et al., 2020</xref>; <xref ref-type="bibr" rid="c8">Chrisman, 1992</xref>; <xref ref-type="bibr" rid="c15">Ez-zizi et al., 2023</xref>; <xref ref-type="bibr" rid="c23">Lak et al., 2017</xref>; <xref ref-type="bibr" rid="c24">Lak et al., 2020</xref>; <xref ref-type="bibr" rid="c25">Larsen et al., 2010</xref>; <xref ref-type="bibr" rid="c50">Starkweather et al., 2017</xref>).</p>
<p>Our results on learning-rate adjustments to perceptual uncertainty go beyond the domain of perceptual estimation and show that this mechanism is transferable to reward learning. <xref ref-type="bibr" rid="c47">Sato and Kording (2014)</xref> and <xref ref-type="bibr" rid="c54">Vilares et al. (2012)</xref> used a continuous perceptual estimation task in which visual targets had to be predicted based on uncertain sensory information. Subjects adjusted predictions to a lesser extent when perceptual uncertainty was higher, which aligns with our results despite key differences. Crucially, in these studies, perceptual uncertainty originated from external noise inherent to the presented information, while in our task, perceptual uncertainty is primarily due to the imprecision in the human visual system (exact contrast differences are hard to detect for humans). Moreover, in our work, subjects had to learn reward probabilities under perceptual uncertainty from binary rewards, as opposed to perceptual estimation. Together, these lines of research converge on the view that this mechanism is a ubiquitous phenomenon that generalizes across different scenarios.</p>
<p>Moreover, the findings from <xref ref-type="bibr" rid="c14">Drevet et al. (2022)</xref> are in line with our results regarding the regulation of learning rates to stimulus discriminability. However, the suggested mapping between belief state and learning rate differs between the studies. Most importantly, <xref ref-type="bibr" rid="c14">Drevet et al. (2022)</xref> found evidence of a belief-state threshold above which perceptual information is deemed to be strong and certain enough for learning. Below this threshold, newly arriving information is discarded, which differs from our more continuous down-regulation of learning in response to the belief state. However, there are crucial methodological differences. While <xref ref-type="bibr" rid="c14">Drevet et al. (2022)</xref> exposed participants to a changing environment and used binary-choice data to estimate learning dynamics based on model fitting, we used direct reports of belief updating in a stable environment. Future work could combine our direct learning-rate measurements and the extensive model space of <xref ref-type="bibr" rid="c14">Drevet et al. (2022)</xref> to compare the two explanations in a common study.</p>
<p>However, our results appear to be at odds with work suggesting that belief-state-driven flexible learning does not occur under perceptual uncertainty in a volatile environment (<xref ref-type="bibr" rid="c15">Ez-zizi et al., 2023</xref>). This could be explained by at least two reasons. One key difference to our study is how perceptual uncertainty was induced. Whereas in our work and other previous studies (<xref ref-type="bibr" rid="c6">Bruckner et al., 2020</xref>; <xref ref-type="bibr" rid="c23">Lak et al., 2017</xref>; <xref ref-type="bibr" rid="c24">Lak et al., 2020</xref>; <xref ref-type="bibr" rid="c47">Sato &amp; Kording, 2014</xref>; <xref ref-type="bibr" rid="c54">Vilares et al., 2012</xref>), perceptual information was associated with varying degrees of belief-state uncertainty, participants in <xref ref-type="bibr" rid="c15">Ez-zizi et al. (2023)</xref> were presented with fixed stimuli calibrated to a pre-defined accuracy level. This potentially leaves little room and need for fine-tuning of learning. Moreover, the computational model did not explicitly assume that reward probabilities changed throughout the task, potentially resulting in a worse model fit (<xref ref-type="bibr" rid="c15">Ez-zizi et al., 2023</xref>; <xref ref-type="bibr" rid="c25">Larsen et al., 2010</xref>). Future work could explicitly incorporate environmental changes into these models to further investigate the interplay of perceptual uncertainty and surprise (<xref ref-type="bibr" rid="c5">Bruckner et al., 2022</xref>).</p>
<p>A relevant topic for future research based on our findings is examining the psychophysiological mechanisms behind uncertainty-led flexible learning. Different forms of uncertainty have been linked to the arousal system (<xref ref-type="bibr" rid="c1">Aston-Jones &amp; Cohen, 2005</xref>; <xref ref-type="bibr" rid="c56">Yu &amp; Dayan, 2005</xref>). In particular, studies using pupillometry as a proxy of arousal suggest that arousal modulates the influence of incoming information on learning (<xref ref-type="bibr" rid="c35">Nassar et al., 2012</xref>), perceptual (<xref ref-type="bibr" rid="c22">Krishnamurthy et al., 2017</xref>), and choice (<xref ref-type="bibr" rid="c12">de Gee et al., 2017</xref>; <xref ref-type="bibr" rid="c53">Urai et al., 2017</xref>) biases. One potential neural mechanism behind these effects is the locus coeruleus-norepinephrine (LC-NE) system (<xref ref-type="bibr" rid="c1">Aston-Jones &amp; Cohen, 2005</xref>; <xref ref-type="bibr" rid="c17">Gilzenrat et al., 2010</xref>; <xref ref-type="bibr" rid="c20">Joshi et al., 2016</xref>; <xref ref-type="bibr" rid="c30">Megemont et al., 2022</xref>; <xref ref-type="bibr" rid="c31">Murphy et al., 2014</xref>; <xref ref-type="bibr" rid="c32">Murphy et al., 2011</xref>; <xref ref-type="bibr" rid="c45">Reimer et al., 2016</xref>). Therefore, future work could examine the link between arousal dynamics, learning-rate adjustments, and perceptual uncertainty.</p>
<p>Another avenue for future work is improving the slider design that we used to measure learning. We present analyses examining the split-half reliability of our parameters (see Split-half reliability for more details). We found moderately correlated fixed learning rates but weaker correlations for flexible learning (<xref rid="figS6" ref-type="fig">Fig. S6</xref>). These values seem to be comparable to similar state-of-the-art Bayesian and reinforcement-leaning approaches and sufficient for group-level analyses of healthy subjects (<xref ref-type="bibr" rid="c27">Loosen et al., 2022</xref>; <xref ref-type="bibr" rid="c39">Palminteri &amp; Chevallier, 2018</xref>; <xref ref-type="bibr" rid="c40">Patzelt et al., 2018</xref>; <xref ref-type="bibr" rid="c48">Schaaf et al., 2023</xref>). However, applying our approach to clinical populations or studies interested in individual differences would particularly benefit from more stable estimates. Among many factors that impact reliability, <xref ref-type="bibr" rid="c49">Schurr et al. (2024)</xref> identify random noise in behavioral measurements that could arise from discrepancies given the current application of the slider. Improvements to the slider design, including cues about previous estimates (to reduce motor noise) and modifying the starting point of the slider (requiring fewer adjustments), could increase the overall reliability of the parameters.</p>
<p>Furthermore, our second aim was to examine how economic decision-making is swayed by perceptual and reward information. We hypothesized that visual salience, next to the established role of expected values (<xref ref-type="bibr" rid="c4">Bartra et al., 2013</xref>; <xref ref-type="bibr" rid="c21">Kable &amp; Glimcher, 2009</xref>; <xref ref-type="bibr" rid="c26">Levy &amp; Glimcher, 2012</xref>; <xref ref-type="bibr" rid="c43">Rangel et al., 2008</xref>), impacts choices. Confirming this, we identified a salience bias that led to a preference for choice options with stronger as opposed to weaker contrasts. These findings suggest that people use salience as a proxy for expected value when value information is uncertain. This result aligns with studies reporting effects of both value and salience in a perceptual choice task (<xref ref-type="bibr" rid="c37">Navalpakkam et al., 2010</xref>; <xref ref-type="bibr" rid="c52">Towal et al., 2013</xref>). More generally, salience does impact decisions that should ideally be driven solely by value because of its evolutionary significance (<xref ref-type="bibr" rid="c19">Itti &amp; Koch, 2001</xref>; <xref ref-type="bibr" rid="c41">Pike, 2018</xref>; <xref ref-type="bibr" rid="c46">Rumbaugh et al., 2007</xref>) and hence, may be deemed more rewarding in risky environments.</p>
<p>To summarize, we found that humans effectively integrate uncertain perceptual and reward information for learning and decision-making. Humans dynamically adjust reward learning contingent on perceptual uncertainty. Moreover, perceptual salience, in addition to the expected value, drives economic decision-making, where the interaction is guided by reward uncertainty. These findings offer insight into mechanisms behind the interplay of perceptual and reward information, highlighting that each is not solely tied to either perceptual or economic decision-making.</p>
</sec>
<sec id="s3">
<title>Methods</title>
<sec id="s3a">
<title>Participants</title>
<p>The study included two experiments. 100 participants were recruited for the main task (38 female, 62 male; mean age = 23.82 <italic>±</italic> 3.30 SEM; range 18-29). All participants were recruited via Prolific (<ext-link ext-link-type="uri" xlink:href="http://www.prolific.co">www.prolific.co</ext-link>) for online behavioral experiments. Participants provided informed consent before starting the experiments. We applied several inclusion criteria using Prolific’s participant pre-screen tool. Participants had to be between the ages of 18 and 30 and have normal or corrected-to-normal vision. Additionally, only participants who reported not having used any medication to treat symptoms of depression, anxiety, or low mood were recruited. We did not recruit participants reporting mild cognitive impairment, dementia, and autism spectrum disorder. For taking part in the study, participants were paid a standard rate of £6.00. Moreover, to incentivize their performance, participants received an extra bonus payment of up to £2.50, determined by their economic choice performance. The study was approved by the ethics committee of the Department of Education and Psychology at Freie Universität Berlin (“Effects of Perceptual Uncertainty on Value-Based Decision Making”, protocol number: 121/2016). Data from two participants was rejected since they performed with less than 50% accuracy.</p>
</sec>
<sec id="s3b">
<title>Experimental task</title>
<sec id="s3c">
<title>Experimental procedure</title>
<p>The task was programmed in JavaScript using jsPsych (version 6.3.0). The Gabor-Bandit (GB) task version of this study comprised three stages (economic decision-making, reward feedback, slider response) (<xref rid="fig2" ref-type="fig">Fig. 2a</xref>). In the first stage, the stimulus material comprised a fixation cross and two sinusoidal gratings presented on a screen with a gray background color (#808080). These were created using HTML canvas, which is an in-built element of JavaScript that allows for dynamic rendering of 2-dimensional graphics. To create the gratings, we use a sine texture consisting of two alternative bands of black (#000) and white (#FFF) color with a spatial frequency of 2 cycles per cm. The orientation of the patches was kept constant at 0°.</p>
<p>To manipulate the Gabor-patch contrasts <italic>g</italic>, we controlled the patches’ visibility <italic>v</italic>, where 0 indicates that the patch is transparent (equal to the background) and 1 that it is fully opaque. Subsequently, the displayed contrast of each patch was a weighted combination of the stimulus properties <italic>z</italic> (as defined by the HTML canvas settings described above) and the background color <italic>h</italic>: <italic>g</italic> = <italic>vz</italic> + (1<italic>− v</italic>)<italic>h</italic>. The mean visibility of both patches was maintained at <italic>v</italic> = 0.5. The choice gratings were presented for 1000 ms, and the fixation cross remained on the screen throughout. During the stimulus presentation, participants were required to make the economic choice using the left and right cursor buttons of the computer keyboard. The participants’ responses did not end the patch presentation. In the second trial stage, participants were presented with feedback of winning either zero (“You win 0 points!”) or one (“You win 1 point!”) point based on their economic choice for 1000 ms. Finally, it included an additional probe phase during which participants reported their subjective estimate of the reward probability for a hypothetical choice using a slider. Participants completed 25 trials in each block of the task. The presentation order of blocks was randomized across participants. If a participant failed to respond to a trial, the same trial was repeated at the end of the block.</p>
</sec>
<sec id="s3d">
<title>Task contingencies</title>
<p>The central feature of our task is that each block of trials inherently features a particular stateaction-reward association. A trial could potentially belong to one of the two hidden task states <italic>s</italic><sub><italic>t</italic></sub> <italic>∈</italic>{0, 1}. When a trial belongs to <italic>s</italic><sub><italic>t</italic></sub> = 0, the patch on the left side of the fixation cross has a lower contrast level than the right patch. This relationship is reversed when the trial belongs to <italic>s</italic><sub><italic>t</italic></sub> = 1. Half of the trials in one block belonged to <italic>s</italic><sub><italic>t</italic></sub> = 0, while the other half belonged to <italic>s</italic><sub><italic>t</italic></sub> = 1. Moreover, we refer to the two choices (left vs. right patch) as actions <italic>a</italic><sub><italic>t</italic></sub> <italic>∈</italic>{0, 1}, where <italic>a</italic><sub><italic>t</italic></sub> = 0 indicates choosing the left patch and <italic>a</italic><sub><italic>t</italic></sub> = 1 the right patch. The reward probabilities depended on the state-action combination. For example, when the left patch had the lower contrast level (<italic>s</italic><sub><italic>t</italic></sub> = 0) and was chosen by the participant (<italic>a</italic><sub><italic>t</italic></sub> = 0), it was more likely that the participant would obtain a reward. Similarly, when the right patch had the lower contrast (<italic>s</italic><sub><italic>t</italic></sub> = 1) and was chosen by the participant (<italic>a</italic><sub><italic>t</italic></sub> = 1), it was likely to yield a reward. In contrast, when in state <italic>s</italic><sub><italic>t</italic></sub> = 0 (left patch has the lower contrast) and choosing action <italic>a</italic><sub><italic>t</italic></sub> = 1 (right patch) or when in state <italic>s</italic><sub><italic>t</italic></sub> = 1 (right patch has the lower contrast) and choosing <italic>a</italic><sub><italic>t</italic></sub> = 0 (left patch), the reward probability is low. Thus, in such blocks, the low-contrast patch was the more rewarding option (low-contrast blocks). Importantly, in half of the blocks, the state-action-reward contingency was reversed i.e., the high-contrast patch was the more rewarding option (high-contrast blocks). The block order was randomized, and hence, the reward contingencies had to be relearned on each block. Consequently, participants were required to learn the correct association between Gabor-patch locations (states), choices (actions), and obtained rewards to maximize their outcome.</p>
</sec>
<sec id="s3e">
<title>Task details</title>
<p>The main task comprised 12 blocks with 25 trials and featured three conditions: the “both-uncertainties” condition, the perceptual-uncertainty condition, and the reward-uncertainty condition. In the “both-uncertainties” and perceptual-uncertainty conditions, the contrast difference of two patches was randomly sampled from a uniform distribution of [−0.1 to 0] when the trial belonged to <italic>s</italic><sub><italic>t</italic></sub> = 0 with the left patch having the lower contrast and [0 to 0.1] when the trial belonged to <italic>s</italic><sub><italic>t</italic></sub> = 1 and the right patch had the lower contrast. Thus, the absolute contrast levels of the patches ranged from 0.40 to 0.60. In the reward-uncertainty condition with low perceptual uncertainty, the contrast difference of the two patches was in the range −0.35 to −0.45 for <italic>s</italic><sub><italic>t</italic></sub> = 0 and 0.35 to 0.45 for <italic>s</italic><sub><italic>t</italic></sub> = 1. Thus, the absolute range of contrast levels was 0.05 to 0.95.</p>
<p>Crucially, in the slider probe phase, the patches were clearly distinguishable; that is, participants did not experience uncertainty about the task state. To report their estimates of the reward probabilities, participants were instructed to click and drag across the slider that ranged from 0 to 100%. To ensure that exclusive use of the more rewarding option as the hypothetical choice does not help participants to learn the state-action-reward contingency, we ask them to report the estimated reward probabilities for both the more and less rewarding option across blocks in the task. In half of the blocks, the hypothetical choice was congruent with the more rewarding patch in the given block (congruent blocks). That is, in half of the high-contrast blocks, the hypothetical choice during the slider phase was congruent with the more rewarding option. Thus, the participants were asked to report their subjective estimate for the high-contrast patch (more rewarding option). However, on the other half of the high-contrast blocks, participants were asked to report for the low-contrast option (less rewarding option). That is, the hypothetical choice was incongruent with the more rewarding patch in that block of trials (incongruent blocks). Finally, the order of task blocks was randomized for each participant.</p>
</sec>
</sec>
<sec id="s3f">
<title>Gabor-Bandit task model</title>
<p>We simulated predictions of a Bayes-optimal learning model (<xref ref-type="bibr" rid="c6">Bruckner et al., 2020</xref>). To describe the model in detail, we first present a model of the Gabor-Bandit task. In line with <xref ref-type="bibr" rid="c6">Bruckner et al. (2020)</xref>,</p>
<list list-type="bullet">
<list-item><p><italic>T</italic> := 25 indicates the number of trials per block, where we use <italic>t</italic> as the trial index,</p></list-item>
<list-item><p><italic>S ∈</italic>{0, 1} denotes the set of task states, where 0 indicates that the right patch has stronger contrast than the right patch and vice versa for state 1; the state also determines the action-reward contingency in the task,</p></list-item>
<list-item><p><italic>C∈</italic> [<italic>− κ, κ</italic>] is the set of contrast differences between the patches, where <italic>κ</italic> indicates the maximal contrast difference, which differs across conditions in this work, as described above,</p></list-item>
<list-item><p><italic>A∈</italic>{0, 1}refers to the set of economic choices, where 0 refers to choosing the left patch, and 1 refers to choosing the right patch,</p></list-item>
<list-item><p><italic>R ∈</italic> {<italic>0, 1</italic>} denotes the set of rewards,</p></list-item>
<list-item><p><italic>p</italic><sup><italic>ϕ</italic></sup>(<italic>s</italic><sub><italic>t</italic></sub>) is the Bernoulli state distribution defined by
<disp-formula id="eqn1">
<graphic xlink:href="590947v1_eqn1.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
with <italic>ϕ</italic> := 0.5, which is the state-expectation parameter,</p></list-item>
<list-item><p><italic>p</italic>(<italic>c</italic><sub><italic>t</italic></sub>|<italic>s</italic><sub><italic>t</italic></sub>) is the state-conditional contrast-difference distribution defined by the uniform distribution,
<disp-formula id="eqn2">
<graphic xlink:href="590947v1_eqn2.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p></list-item>
<list-item><p><inline-formula><inline-graphic xlink:href="590947v1_inline1a.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is the action- and contingency-parameter-dependent and state-conditional reward distribution. This distribution is defined by
<disp-formula id="eqn3">
<graphic xlink:href="590947v1_eqn3.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
with contingency parameter <italic>µ</italic> := 0.9 for half of the blocks and <italic>µ</italic> := 0.1 for the other half under lower reward uncertainty. Similarly, the contingency parameter <italic>µ</italic> := 0.7 for half of the blocks and <italic>µ</italic> := 0.3 for the other half under higher reward uncertainty.</p></list-item></list>
</sec>
<sec id="s3g">
<title>Gabor-Bandit agent model</title>
<p>In our computational model, we assumed three computational stages corresponding to perceptual inference modeling visual processing of the displayed information, learning about the reward probabilities, and economic decision-making.</p>
</sec>
<sec id="s3h">
<title>Perceptual inference</title>
<p>To model perceptual inference, we assume</p>
<list list-type="bullet">
<list-item><p><italic>O∈</italic> ℝ is the set of the agent’s internal observations <italic>o</italic><sub><italic>t</italic></sub> that are dependent on the contrast difference of the external Gabor patches <italic>c</italic><sub><italic>t</italic></sub> along with perceptual uncertainty or noise,</p></list-item>
<list-item><p><inline-formula><inline-graphic xlink:href="590947v1_inline1.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is the agent’s observation likelihood, defined as the contrast difference-conditional observation distribution,
<disp-formula id="eqn4">
<graphic xlink:href="590947v1_eqn4.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where, in our simulations, we manipulate <italic>σ</italic> to induce high (<italic>σ</italic> = 0.03) and low (<italic>σ</italic> = 0.0001) levels of perceptual uncertainty.</p></list-item></list>
<p>To compute the agent’s belief state dependent on the observed contrast difference, we have
<disp-formula id="eqn5">
<graphic xlink:href="590947v1_eqn5.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where Φ is the Gaussian cumulative distribution function (CDF).</p>
</sec>
<sec id="s3i">
<title>Economic decision-making</title>
<p>For economic choices, we considered the following variables.</p>
<list list-type="bullet">
<list-item><p>In the agent, <italic>µ</italic> is a random variable representing the contingency parameter,</p></list-item>
<list-item><p>M := [0,1] is the outcome space of this random variable,</p></list-item>
<list-item><p><italic>p</italic>(<italic>µ</italic>) is the agent’s belief about the task-block contingency parameter</p></list-item>
</list>
<p>We assumed that the agent model chooses action <inline-formula><inline-graphic xlink:href="590947v1_inline2.gif" mime-subtype="gif" mimetype="image"/></inline-formula> with the higher expected reward
<disp-formula id="eqn6">
<graphic xlink:href="590947v1_eqn6.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where the expected value conditional on action <italic>a</italic><sub><italic>t</italic></sub> = 0 is given by
<disp-formula id="eqn7">
<graphic xlink:href="590947v1_eqn7.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and conditional on action <italic>a</italic><sub><italic>t</italic></sub> = 1 by
<disp-formula id="eqn8">
<graphic xlink:href="590947v1_eqn8.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
Where
<disp-formula id="eqn9">
<graphic xlink:href="590947v1_eqn9.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
is the average of the contingency parameter.</p>
</sec>
<sec id="s3j">
<title>Learning</title>
<p>To learn from the presented reward feedback, the agent updates the distribution over the contingency parameter
<disp-formula id="eqn10">
<graphic xlink:href="590947v1_eqn10.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
This is achieved by evaluating the polynomials in <italic>µ</italic>, where the polynomial coefficients <italic>ρ</italic><sub><italic>t</italic>,0</sub>, …, <italic>ρ</italic><sub><italic>t,t</italic></sub> of
<disp-formula id="eqn11">
<graphic xlink:href="590947v1_eqn11.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
can be evaluated based on <italic>ρ</italic><sub><italic>t−</italic>1,0</sub>, …, <italic>ρ</italic><sub><italic>t−</italic>1,<italic>t−</italic>1</sub> of
<disp-formula id="eqn12">
<graphic xlink:href="590947v1_eqn12.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where
<disp-formula id="eqn13">
<graphic xlink:href="590947v1_eqn13.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
and where
<disp-formula id="eqn14">
<graphic xlink:href="590947v1_eqn14.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
With
<disp-formula id="eqn15">
<graphic xlink:href="590947v1_eqn15.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p>
</sec>
<sec id="s3k">
<title>Data preprocessing</title>
<p>For our statistical analyses, we relied on participants’ single-trial slider responses, from which we derived updates, prediction errors, and learning rates.</p>
<list list-type="bullet">
<list-item><p><inline-formula><inline-graphic xlink:href="590947v1_inline3.gif" mime-subtype="gif" mimetype="image"/></inline-formula> indicates the subject’s slider response, which we take to indicate the subject’s belief about the contingency parameter <italic>µ</italic><sub><italic>t</italic></sub> in the Gabor-Bandit task. Please recall that we used congruent (the subject was asked to report the contingency parameter of the “correct”, i.e., more rewarding option) and incongruent (the subject was asked to report the contingency parameter of the “incorrect”, i.e., less rewarding option) blocks in our experiment. To map the slider responses on congruent and incongruent blocks onto a common scale, we recoded responses on incongruent blocks according to
<disp-formula id="eqn16">
<graphic xlink:href="590947v1_eqn16.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p></list-item>
<list-item><p><italic>Q ∈ {</italic>0, 1<italic>}</italic> indicates a correct (<italic>q</italic> = 1) and incorrect choice (<italic>q</italic> = 0), defined by
<disp-formula id="eqn17">
<graphic xlink:href="590947v1_eqn17.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
</p></list-item>
<list-item><p><italic>D ∈</italic> [<italic>−</italic>1, 1] denotes the set of prediction errors, defined by
<disp-formula id="eqn18">
<graphic xlink:href="590947v1_eqn18.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <inline-formula><inline-graphic xlink:href="590947v1_inline4.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. That is, when computing the prediction error, we take into account the state-action-reward contingency defined in the task model (<xref ref-type="disp-formula" rid="eqn3">eq. (3)</xref>). For example, when the presented contrast difference favors state <italic>s</italic><sub><italic>t</italic></sub> = 0, we assume <italic>π</italic><sub>0</sub> <italic>&gt; π</italic><sub>1</sub> and conditional on action <italic>a</italic><sub><italic>t</italic></sub> = 0, the expected reward probability is <inline-formula><inline-graphic xlink:href="590947v1_inline5.gif" mime-subtype="gif" mimetype="image"/></inline-formula>. To account for the action dependency of the reward, we rely on <inline-formula><inline-graphic xlink:href="590947v1_inline6.gif" mime-subtype="gif" mimetype="image"/></inline-formula>, so that, for example, <italic>r</italic><sub><italic>t</italic></sub> = 0 conditional on <italic>a</italic><sub><italic>t</italic></sub> = 1 corresponds to <inline-formula><inline-graphic xlink:href="590947v1_inline7.gif" mime-subtype="gif" mimetype="image"/></inline-formula> re-coded with respect to action <italic>a</italic><sub><italic>t</italic></sub> = 0 (where <italic>r</italic><sub><italic>t</italic></sub> = 1 had it been chosen). Similarly, to account for the state dependency of the reward, we rely on (<inline-formula><inline-graphic xlink:href="590947v1_inline8.gif" mime-subtype="gif" mimetype="image"/></inline-formula>) when state <italic>s</italic><sub><italic>t</italic></sub> = 1 is more likely than <italic>s</italic><sub><italic>t</italic></sub> = 0,</p></list-item>
<list-item><p><italic>U ∈</italic> [<italic>−</italic>1, 1] denotes the set of updates, defined by
<disp-formula id="eqn19">
<graphic xlink:href="590947v1_eqn19.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p></list-item>
<list-item><p><italic>B ∈</italic>{0, 1} indicates a choice-confirming outcome (<italic>b</italic><sub><italic>t</italic></sub> = 1) and a choice-dis-confirming outcome (<italic>b</italic><sub><italic>t</italic></sub> = 0), defined by
<disp-formula id="eqn20">
<graphic xlink:href="590947v1_eqn20.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula></p></list-item>
<list-item><p><italic>K ∈</italic>{0, 1} denotes the set of congruence-trial types, where <italic>k</italic><sub><italic>t</italic></sub> = 0 denotes an incongruent and <italic>k</italic><sub><italic>t</italic></sub> = 1 a congruent trial type,</p></list-item>
<list-item><p><italic>L ∈</italic>{0, 1} denotes the set of salience-trial types, where <italic>l</italic><sub><italic>t</italic></sub> = 0 denotes a low-salience and <italic>l</italic><sub><italic>t</italic></sub> = 1 a high-salience trial.</p></list-item>
</list>
</sec>
<sec id="s3l">
<title>Regression analysis</title>
<p>To better understand the factors influencing the single-trial updates, we used a regression model that allowed us to dissociate multiple factors driving the learning rate. This regression model can be interpreted through the lens of reinforcement learning, according to which prediction errors, scaled by a learning rate, determine belief updates (<xref ref-type="bibr" rid="c11">Daw, 2014</xref>; <xref ref-type="bibr" rid="c29">McGuire et al., 2014</xref>):
<disp-formula id="eqn21">
<graphic xlink:href="590947v1_eqn21.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
<italic>β</italic><sub>0</sub> is the intercept. <italic>β</italic><sub>1</sub> is the coefficient modeling the average effect of the prediction error on the update, which we interpret as the fixed learning rate, as common in reinforcement learning (usually denoted <italic>α</italic>). We refer to this term as fixed LR. To model how flexibly participants adjusted their learning for belief states emerging from various levels of contrast differences, we added the interaction term <italic>β</italic><sub>2</sub> between prediction error and absolute contrast difference. We refer to this term as belief-state-adapted LR. Please note that we excluded trials from the reward-uncertainty condition as contrast differences on these trials were high, and hence perceptual uncertainty was not induced. Next, to check for the presence of confirmation biases in learning, we use the interaction term <italic>β</italic><sub>3</sub> between prediction error and whether an outcome is confirming (confirmation bias). This is coded as a categorical variable, i.e., 0 for outcomes that dis-confirm the choice and 1 for outcomes that confirm the choice. Finally, we added two task-based block-level categorical variables as control regressors. <italic>β</italic><sub>4</sub> was the interaction term between salience (high vs. low contrast blocks) and prediction error where 0 denoted trials in a low-contrast block and 1 for trials in a high-contrast block, and <italic>β</italic><sub>5</sub> captured effects of congruence (congruent vs. incongruent block type) in interaction with prediction error where 0 denoted trials in an incongruent block and 1 for trials in a congruent block. All continuous regressors, except for prediction errors, were re-scaled within the range of 0 and 1 using the min-max normalization method
<disp-formula id="eqn22">
<graphic xlink:href="590947v1_eqn22.gif" mime-subtype="gif" mimetype="image"/>
</disp-formula>
where <italic>X</italic> is the variable of interest, <italic>x</italic><sub><italic>t</italic></sub> is the value on a given trial that gets normalized, and <inline-formula><inline-graphic xlink:href="590947v1_inline9.gif" mime-subtype="gif" mimetype="image"/></inline-formula> is the normalized value for a given trial. For prediction errors, we used its natural scale since it was key to retain its valence for the signed LR analyses.</p>
<p>The model was fit to each participant’s single-trial updates. Since prediction errors <italic>δ</italic><sub><italic>t</italic></sub> = 0 do not call for learning, we excluded such trials. Moreover, one potential drawback of using a canonical linear regression model is the assumption that the residuals are homoscedastic, that is, similar across the range of the predictor variable. However, in our model, the assumption of homoscedasticity is violated, particularly for larger prediction errors. Thus, we accounted for heteroscedasticity by using a weighted regression model, wherein more weight is given to the observations with smaller residuals providing more reliable information.</p>
</sec>
<sec id="s3m">
<title>Regression diagnostics</title>
<p>We used two statistical tools to illustrate the regression coefficients. First, to illustrate the incremental effect of a specified regressor on the single-trial updates, after accounting for the effects of all other terms, we created a partial regression plot (also known as an added variable plot). This plot is formed by plotting the (i) residuals from regressing single-trial updates against all regressors except the regressor of interest versus (ii) residuals from regressing the specified regressor against all the remaining regressors. This type of analysis emphasizes the marginal contribution of a given regressor in capturing the participant’s updates over and above all the other regressors. Second, we used an interaction plot to demonstrate the dynamics of interaction regressors on single-trial updates. We plotted the conditional effect of prediction errors given specific values of the other task-based variable in the interaction. For categorical regressors, the specific values were set to the different categories of the variable. For continuous regressors, we used three values, each corresponding to the lowest, highest, and median values. To plot this, we compute the adjusted model-predicted update for an observation of all the regressors contributing to an interaction term while averaging out the effect of the other regressors (also known as adjusted response).</p>
</sec>
</sec>
</body>
<back>
<sec id="s4" sec-type="data-availability">
<title>Data and code availability</title>
<p>All data and code will be made available on GitHub at the time of publication.</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>We thank Hauke Heekeren for his mentorship and amazing support throughout the project. We also thank Muhammad Hashim Satti for helpful comments on an earlier draft of the manuscript. P.G. was supported by Deutscher Akademischer Austauschdienst (DAAD) Graduate School Scholarship Programme, 2020. R.M.C. was supported by The German Research Council grants (CI241/3-1, INST 272/297-1) and the European Research Council grant (ERC-StG-2018-803370). N.W.S. is funded by a Starting Grant from the European Union (ERC-2019-StG REPLAY-852669) and the Federal Ministry of Education and Research (BMBF) and the Free and Hanseatic City of Hamburg under the Excellence Strategy of the Federal Government and the Länder. C.F. was supported by German Research Foundation (DFG), grant number FI 2309/1-1. R.B. was supported by DFG (Deutsche Forschungsgemeinschaft) grant 412917403.</p>
</ack>
<sec id="s5">
<title>Conflict of interest disclosure</title>
<p>The authors declare no competing interests.</p>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Aston-Jones</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Cohen</surname>, <given-names>J. D.</given-names></string-name></person-group> (<year>2005</year>). <article-title>An integrative theory of locus coeruleus-norepinephrine function: Adaptive gain and optimal performance</article-title>. <source>Annual Review of Neuroscience</source>, <volume>28</volume> (<issue>1</issue>), <fpage>403</fpage>–<lpage>450</lpage>. <pub-id pub-id-type="doi">10.1146/annurev.neuro.28.061604.135709</pub-id></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Babayan</surname>, <given-names>B. M.</given-names></string-name>, <string-name><surname>Uchida</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Belief state representation in the dopamine system</article-title>. <source>Nature Communications</source>, <volume>9</volume> (<issue>1</issue>). <pub-id pub-id-type="doi">10.1038/s41467-018-04397-0</pub-id></mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bach</surname>, <given-names>D. R.</given-names></string-name>, &amp; <string-name><surname>Dolan</surname>, <given-names>R. J.</given-names></string-name></person-group> (<year>2012</year>). <article-title>Knowing how much you don’t know: A neural organization of uncertainty estimates</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>13</volume> (<issue>8</issue>), <fpage>572</fpage>–<lpage>586</lpage>. <pub-id pub-id-type="doi">10.1038/nrn3289</pub-id></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Bartra</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>McGuire</surname>, <given-names>J. T.</given-names></string-name>, &amp; <string-name><surname>Kable</surname>, <given-names>J. W.</given-names></string-name></person-group> (<year>2013</year>). <article-title>The valuation system: A coordinate-based meta-analysis of bold fmri experiments examining neural correlates of subjective value</article-title>. <source>NeuroImage</source>, <volume>76</volume>, <fpage>412</fpage>–<lpage>427</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.02.063</pub-id></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Bruckner</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Heekeren</surname>, <given-names>H. R.</given-names></string-name>, &amp; <string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Understanding learning through uncer-tainty and bias</article-title>. <source>PsyArXiv</source>. <pub-id pub-id-type="doi">10.31234/osf.io/xjkbg</pub-id></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Bruckner</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Heekeren</surname>, <given-names>H. R.</given-names></string-name>, &amp; <string-name><surname>Ostwald</surname>, <given-names>D.</given-names></string-name></person-group> (<year>2020</year>). <article-title>Belief states and categorical-choice biases determine reward-based learning under perceptual uncertainty</article-title>. <source>bioRxiv</source>. <pub-id pub-id-type="doi">10.1101/2020.09.18.303495</pub-id></mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Bruckner</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name></person-group> (<year>2024</year>). <article-title>Decision-making under uncertainty</article-title>. <source>PsyArXiv</source>. <pub-id pub-id-type="doi">10.31234/osf.io/ce8jf</pub-id></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Chrisman</surname>, <given-names>L.</given-names></string-name></person-group> (<year>1992</year>). <article-title>Reinforcement learning with perceptual aliasing: The perceptual distinctions approach</article-title>. <source>AAAI</source>, <volume>1992</volume>, <fpage>183</fpage>–<lpage>188</lpage>.</mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Colizoli</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>de Gee</surname>, <given-names>J. W.</given-names></string-name>, <string-name><surname>Urai</surname>, <given-names>A. E.</given-names></string-name>, &amp; <string-name><surname>Donner</surname>, <given-names>T. H.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Task-evoked pupil responses reflect internal belief states</article-title>. <source>Scientific Reports</source>, <volume>8</volume> (<issue>1</issue>). <pub-id pub-id-type="doi">10.1038/s41598-018-31985-3</pub-id></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Courville</surname>, <given-names>A. C.</given-names></string-name>, <string-name><surname>Daw</surname>, <given-names>N. D.</given-names></string-name>, &amp; <string-name><surname>Touretzky</surname>, <given-names>D. S.</given-names></string-name></person-group> (<year>2006</year>). <article-title>Bayesian theories of conditioning in a changing world</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>10</volume> (<issue>7</issue>), <fpage>294</fpage>–<lpage>300</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2006.05.004</pub-id></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="book"><person-group person-group-type="author"><string-name><surname>Daw</surname>, <given-names>N. D.</given-names></string-name></person-group> (<year>2014</year>). <chapter-title>Advanced reinforcement learning</chapter-title>. <source>Neuroeconomics</source> (pp. <fpage>299</fpage>–<lpage>320</lpage>). <publisher-name>Elsevier</publisher-name>. <pub-id pub-id-type="doi">10.1016/b978-0-12-416008-8.00016-4</pub-id></mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>de Gee</surname>, <given-names>J. W.</given-names></string-name>, <string-name><surname>Colizoli</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Kloosterman</surname>, <given-names>N. A.</given-names></string-name>, <string-name><surname>Knapen</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Nieuwenhuis</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Donner</surname>, <given-names>T. H.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Dynamic modulation of decision biases by brainstem arousal systems</article-title>. <source>eLife</source>, <volume>6</volume>. <pub-id pub-id-type="doi">10.7554/elife.23232</pub-id></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Doya</surname>, <given-names>K.</given-names></string-name></person-group> (<year>2008</year>). <article-title>Modulators of decision making</article-title>. <source>Nature Neuroscience</source>, <volume>11</volume> (<issue>4</issue>), <fpage>410</fpage>–<lpage>416</lpage>. <pub-id pub-id-type="doi">10.1038/nn2077</pub-id></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Drevet</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Drugowitsch</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Wyart</surname>, <given-names>V.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Efficient stabilization of imprecise statistical inference through conditional belief updating</article-title>. <source>Nature Human Behaviour</source>, <volume>6</volume> (<issue>12</issue>), <fpage>1691</fpage>– <lpage>1704</lpage>. <pub-id pub-id-type="doi">10.1038/s41562-022-01445-0</pub-id></mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ez-zizi</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Farrell</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Leslie</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Malhotra</surname>, <given-names>G.</given-names></string-name>, &amp; <string-name><surname>Ludwig</surname>, <given-names>C. J.</given-names></string-name></person-group> (<year>2023</year>). <article-title>Reinforcement learning under uncertainty: Expected versus unexpected uncertainty and state versus reward uncertainty</article-title>. <source>Computational Brain &amp; Behavior</source>, <volume>6</volume> (<issue>4</issue>), <fpage>626</fpage>–<lpage>650</lpage>. <pub-id pub-id-type="doi">10.1007/s42113-022-00165-y</pub-id></mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name>, &amp; <string-name><surname>Uchida</surname>, <given-names>N.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Believing in dopamine</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>20</volume> (<issue>11</issue>), <fpage>703</fpage>–<lpage>714</lpage>. <pub-id pub-id-type="doi">10.1038/s41583-019-0220-7</pub-id></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gilzenrat</surname>, <given-names>M. S.</given-names></string-name>, <string-name><surname>Nieuwenhuis</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Jepma</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Cohen</surname>, <given-names>J. D.</given-names></string-name></person-group> (<year>2010</year>). <article-title>Pupil diameter tracks changes in control state predicted by the adaptive gain theory of locus coeruleus function</article-title>. <source>Cognitive, Affective, &amp; Behavioral Neuroscience</source>, <volume>10</volume> (<issue>2</issue>), <fpage>252</fpage>–<lpage>269</lpage>. <pub-id pub-id-type="doi">10.3758/cabn.10.2.252</pub-id></mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name>, &amp; <string-name><surname>Stocker</surname>, <given-names>A. A.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Visual decision-making in an uncertain and dynamic world</article-title>. <source>Annual Review of Vision Science</source>, <volume>3</volume> (<issue>1</issue>), <fpage>227</fpage>–<lpage>250</lpage>. <pub-id pub-id-type="doi">10.1146/annurev-vision-111815-114511</pub-id></mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Itti</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>Koch</surname>, <given-names>C.</given-names></string-name></person-group> (<year>2001</year>). <article-title>Computational modelling of visual attention</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>2</volume> (<issue>3</issue>), <fpage>194</fpage>–<lpage>203</lpage>. <pub-id pub-id-type="doi">10.1038/35058500</pub-id></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Joshi</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Kalwani</surname>, <given-names>R. M.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Relationships between pupil diameter and neuronal activity in the locus coeruleus, colliculi, and cingulate cortex</article-title>. <source>Neuron</source>, <volume>89</volume> (<issue>1</issue>), <fpage>221</fpage>–<lpage>234</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.028</pub-id></mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Kable</surname>, <given-names>J. W.</given-names></string-name>, &amp; <string-name><surname>Glimcher</surname>, <given-names>P. W.</given-names></string-name></person-group> (<year>2009</year>). <article-title>The neurobiology of decision: Consensus and controversy</article-title>. <source>Neuron</source>, <volume>63</volume> (<issue>6</issue>), <fpage>733</fpage>–<lpage>745</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2009.09.003</pub-id></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Krishnamurthy</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Sarode</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Arousal-related adjustments of perceptual biases optimize perception in dynamic environments</article-title>. <source>Nature Human Behaviour</source>, <volume>1</volume> (<issue>6</issue>). <pub-id pub-id-type="doi">10.1038/s41562-017-0107</pub-id></mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lak</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Nomoto</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Keramati</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Sakagami</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Kepecs</surname>, <given-names>A.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Midbrain dopamine neurons signal belief in choice accuracy during a perceptual decision</article-title>. <source>Current Biology</source>, <volume>27</volume> (<issue>6</issue>), <fpage>821</fpage>–<lpage>832</lpage>. <pub-id pub-id-type="doi">10.1016/j.cub.2017.02.026</pub-id></mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lak</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Okun</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Moss</surname>, <given-names>M. M.</given-names></string-name>, <string-name><surname>Gurnani</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Farrell</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Wells</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Reddy</surname>, <given-names>C. B.</given-names></string-name>, <string-name><surname>Kepecs</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Harris</surname>, <given-names>K. D.</given-names></string-name>, &amp; <string-name><surname>Carandini</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2020</year>). <article-title>Dopaminergic and prefrontal basis of learning from sensory confidence and reward value</article-title>. <source>Neuron</source>, <volume>105</volume> (<issue>4</issue>), <fpage>700</fpage>–<lpage>711</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2019.11.018</pub-id></mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Larsen</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Leslie</surname>, <given-names>D. S.</given-names></string-name>, <string-name><surname>Collins</surname>, <given-names>E. J.</given-names></string-name>, &amp; <string-name><surname>Bogacz</surname>, <given-names>R.</given-names></string-name></person-group> (<year>2010</year>). <article-title>Posterior weighted reinforcement learning with state uncertainty</article-title>. <source>Neural Computation</source>, <volume>22</volume> (<issue>5</issue>), <fpage>1149</fpage>–<lpage>1179</lpage>. <pub-id pub-id-type="doi">10.1162/neco.2010.01-09-948</pub-id></mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Levy</surname>, <given-names>D. J.</given-names></string-name>, &amp; <string-name><surname>Glimcher</surname>, <given-names>P. W.</given-names></string-name></person-group> (<year>2012</year>). <article-title>The root of all value: A neural common currency for choice</article-title>. <source>Current Opinion in Neurobiology</source>, <volume>22</volume> (<issue>6</issue>), <fpage>1027</fpage>–<lpage>1038</lpage>. <pub-id pub-id-type="doi">10.1016/j.conb.2012.06.001</pub-id></mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Loosen</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Seow</surname>, <given-names>T. X. F.</given-names></string-name>, &amp; <string-name><surname>Hauser</surname>, <given-names>T. U.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Consistency within change: Evaluating the psychometric properties of a widely-used predictive-inference task</article-title>. <source>PsyArXiv</source>. <pub-id pub-id-type="doi">10.31234/osf.io/qkf7j</pub-id></mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Ma</surname>, <given-names>W. J.</given-names></string-name>, &amp; <string-name><surname>Jazayeri</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Neural coding of uncertainty and probability</article-title>. <source>Annual Review of Neuroscience</source>, <volume>37</volume> (<issue>1</issue>), <fpage>205</fpage>–<lpage>220</lpage>. <pub-id pub-id-type="doi">10.1146/annurev-neuro-071013-014017</pub-id></mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>McGuire</surname>, <given-names>J. T.</given-names></string-name>, <string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name>, &amp; <string-name><surname>Kable</surname>, <given-names>J. W.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Functionally dissociable influences on learning rate in a dynamic environment</article-title>. <source>Neuron</source>, <volume>84</volume> (<issue>4</issue>), <fpage>870</fpage>–<lpage>881</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2014.10.013</pub-id></mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Megemont</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>McBurney-Lin</surname>, <given-names>J.</given-names></string-name>, &amp; <string-name><surname>Yang</surname>, <given-names>H.</given-names></string-name></person-group> (<year>2022</year>). <article-title>Pupil diameter is not an accurate real-time readout of locus coeruleus activity</article-title>. <source>eLife</source>, <volume>11</volume>. <pub-id pub-id-type="doi">10.7554/elife.70510</pub-id></mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Murphy</surname>, <given-names>P. R.</given-names></string-name>, <string-name><surname>O’Connell</surname>, <given-names>R. G.</given-names></string-name>, <string-name><surname>O’Sullivan</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Robertson</surname>, <given-names>I. H.</given-names></string-name>, &amp; <string-name><surname>Balsters</surname>, <given-names>J. H.</given-names></string-name></person-group> (<year>2014</year>). <article-title>Pupil diameter covaries with bold activity in human locus coeruleus</article-title>. <source>Human Brain Mapping</source>, <volume>35</volume> (<issue>8</issue>), <fpage>4140</fpage>–<lpage>4154</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.22466</pub-id></mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Murphy</surname>, <given-names>P. R.</given-names></string-name>, <string-name><surname>Robertson</surname>, <given-names>I. H.</given-names></string-name>, <string-name><surname>Balsters</surname>, <given-names>J. H.</given-names></string-name>, &amp; <string-name><surname>O’connell</surname>, <given-names>R. G.</given-names></string-name></person-group> (<year>2011</year>). <article-title>Pupillometry and p3 index the locus coeruleus–noradrenergic arousal function in humans</article-title>. <source>Psychophysiology</source>, <volume>48</volume> (<issue>11</issue>), <fpage>1532</fpage>–<lpage>1543</lpage>. <pub-id pub-id-type="doi">10.1111/j.1469-8986.2011.01226.x</pub-id></mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Bruckner</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Frank</surname>, <given-names>M. J.</given-names></string-name></person-group> (<year>2019</year>). <article-title>Statistical context dictates the relationship between feedback-related eeg signals and learning</article-title>. <source>eLife</source>, <volume>8</volume>. <pub-id pub-id-type="doi">10.7554/elife.46975</pub-id></mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name></person-group> (<year>2013</year>). <article-title>A healthy fear of the unknown: Perspectives on the inter-pretation of parameter fits from computational models in neuroscience (O. Sporns, Ed</article-title>.). <source>PLoS Computational Biology</source>, <volume>9</volume> (<issue>4</issue>), <fpage>e1003015</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1003015</pub-id></mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Rumsey</surname>, <given-names>K. M.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>Parikh</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Heasly</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name></person-group> (<year>2012</year>). <article-title>Rational regulation of learning dynamics by pupil-linked arousal systems</article-title>. <source>Nature Neuroscience</source>, <volume>15</volume> (<issue>7</issue>), <fpage>1040</fpage>–<lpage>1046</lpage>. <pub-id pub-id-type="doi">10.1038/nn.3130</pub-id></mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nassar</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Wilson</surname>, <given-names>R. C.</given-names></string-name>, <string-name><surname>Heasly</surname>, <given-names>B.</given-names></string-name>, &amp; <string-name><surname>Gold</surname>, <given-names>J. I.</given-names></string-name></person-group> (<year>2010</year>). <article-title>An approximately bayesian delta-rule model explains the dynamics of belief updating in a changing environment</article-title>. <source>The Journal of Neuroscience</source>, <volume>30</volume> (<issue>37</issue>), <fpage>12366</fpage>–<lpage>12378</lpage>. <pub-id pub-id-type="doi">10.1523/jneurosci.0822-10.2010</pub-id></mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Navalpakkam</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Koch</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Rangel</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Perona</surname>, <given-names>P.</given-names></string-name></person-group> (<year>2010</year>). <article-title>Optimal reward harvesting in complex perceptual environments</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>107</volume> (<issue>11</issue>), <fpage>5232</fpage>–<lpage>5237</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.0911972107</pub-id></mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>O’Reilly</surname>, <given-names>R. C.</given-names></string-name>, &amp; <string-name><surname>Frank</surname>, <given-names>M. J.</given-names></string-name></person-group> (<year>2006</year>). <article-title>Making working memory work: A computational model of learning in the prefrontal cortex and basal ganglia</article-title>. <source>Neural Computation</source>, <volume>18</volume> (<issue>2</issue>), <fpage>283</fpage>– <lpage>328</lpage>. <pub-id pub-id-type="doi">10.1162/089976606775093909</pub-id></mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Palminteri</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Chevallier</surname>, <given-names>C.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Can we infer inter-individual differences in risk-taking from behavioral tasks?</article-title> <source>Frontiers in Psychology</source>, <volume>9</volume>. <pub-id pub-id-type="doi">10.3389/fpsyg.2018.02307</pub-id></mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Patzelt</surname>, <given-names>E. H.</given-names></string-name>, <string-name><surname>Hartley</surname>, <given-names>C. A.</given-names></string-name>, &amp; <string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Computational phenotyping: Using models to understand individual differences in personality, development, and mental illness</article-title>. <source>Personality Neuroscience</source>, <volume>1</volume>. <pub-id pub-id-type="doi">10.1017/pen.2018.14</pub-id></mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pike</surname>, <given-names>T. W.</given-names></string-name></person-group> (<year>2018</year>). <article-title>Quantifying camouflage and conspicuousness using visual salience (D. (Hodgson, Ed</article-title>.). <source>Methods in Ecology and Evolution</source>, <volume>9</volume> (<issue>8</issue>), <fpage>1883</fpage>–<lpage>1895</lpage>. <pub-id pub-id-type="doi">10.1111/2041-210x.13019</pub-id></mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Platt</surname>, <given-names>M. L.</given-names></string-name>, &amp; <string-name><surname>Huettel</surname>, <given-names>S. A.</given-names></string-name></person-group> (<year>2008</year>). <article-title>Risky business: The neuroeconomics of decision making under uncertainty</article-title>. <source>Nature Neuroscience</source>, <volume>11</volume> (<issue>4</issue>), <fpage>398</fpage>–<lpage>403</lpage>. <pub-id pub-id-type="doi">10.1038/nn2062</pub-id></mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rangel</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Camerer</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Montague</surname>, <given-names>P. R.</given-names></string-name></person-group> (<year>2008</year>). <article-title>A framework for studying the neurobiology of value-based decision making</article-title>. <source>Nature Reviews Neuroscience</source>, <volume>9</volume> (<issue>7</issue>), <fpage>545</fpage>–<lpage>556</lpage>. <pub-id pub-id-type="doi">10.1038/nrn2357</pub-id></mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rao</surname>, <given-names>R. P. N.</given-names></string-name></person-group> (<year>2010</year>). <article-title>Decision making under uncertainty: A neural model based on partially observable markov decision processes</article-title>. <source>Frontiers in Computational Neuroscience</source>, <volume>4</volume>. <pub-id pub-id-type="doi">10.3389/fncom.2010.00146</pub-id></mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Reimer</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>McGinley</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Rodenkirch</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>McCormick</surname>, <given-names>D. A.</given-names></string-name>, &amp; <string-name><surname>Tolias</surname>, <given-names>A. S.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Pupil fluctuations track rapid changes in adrenergic and cholinergic activity in cortex</article-title>. <source>Nature Communications</source>, <volume>7</volume> (<issue>1</issue>). <pub-id pub-id-type="doi">10.1038/ncomms13289</pub-id></mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Rumbaugh</surname>, <given-names>D. M.</given-names></string-name>, <string-name><surname>King</surname>, <given-names>J. E.</given-names></string-name>, <string-name><surname>Beran</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Washburn</surname>, <given-names>D. A.</given-names></string-name>, &amp; <string-name><surname>Gould</surname>, <given-names>K. L.</given-names></string-name></person-group> (<year>2007</year>). <article-title>A salience theory of learning and behavior: With perspectives on neurobiology and cognition</article-title>. <source>International Journal of Primatology</source>, <volume>28</volume> (<issue>5</issue>), <fpage>973</fpage>–<lpage>996</lpage>. <pub-id pub-id-type="doi">10.1007/s10764-007-9179-8</pub-id></mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sato</surname>, <given-names>Y.</given-names></string-name>, &amp; <string-name><surname>Kording</surname>, <given-names>K. P.</given-names></string-name></person-group> (<year>2014</year>). <article-title>How much to trust the senses: Likelihood learning</article-title>. <source>Journal of Vision</source>, <volume>14</volume> (<issue>13</issue>), <fpage>13</fpage>–<lpage>13</lpage>. <pub-id pub-id-type="doi">10.1167/14.13.13</pub-id></mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schaaf</surname>, <given-names>J. V.</given-names></string-name>, <string-name><surname>Weidinger</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Molleman</surname>, <given-names>L.</given-names></string-name>, &amp; <string-name><surname>van den Bos</surname>, <given-names>W.</given-names></string-name></person-group> (<year>2023</year>). <article-title>Test–retest reliability of reinforcement learning parameters</article-title>. <source>Behavior Research Methods</source>. <pub-id pub-id-type="doi">10.3758/s13428-023-02203-4</pub-id></mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Schurr</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Reznik</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Hillman</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Bhui</surname>, <given-names>R.</given-names></string-name>, &amp; <string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name></person-group> (<year>2024</year>). <article-title>Dynamic computational phenotyping of human cognition</article-title>. <source>Nature Human Behaviour</source>. <pub-id pub-id-type="doi">10.1038/s41562-024-01814-x</pub-id></mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Starkweather</surname>, <given-names>C. K.</given-names></string-name>, <string-name><surname>Babayan</surname>, <given-names>B. M.</given-names></string-name>, <string-name><surname>Uchida</surname>, <given-names>N.</given-names></string-name>, &amp; <string-name><surname>Gershman</surname>, <given-names>S. J.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Dopamine reward prediction errors reflect hidden-state inference across time</article-title>. <source>Nature Neuroscience</source>, <volume>20</volume> (<issue>4</issue>), <fpage>581</fpage>–<lpage>589</lpage>. <pub-id pub-id-type="doi">10.1038/nn.4520</pub-id></mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Summerfield</surname>, <given-names>C.</given-names></string-name>, &amp; <string-name><surname>Tsetsos</surname>, <given-names>K.</given-names></string-name></person-group> (<year>2012</year>). <article-title>Building bridges between perceptual and economic decision-making: Neural and computational mechanisms</article-title>. <source>Frontiers in Neuroscience</source>, <volume>6</volume>. <pub-id pub-id-type="doi">10.3389/fnins.2012.00070</pub-id></mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Towal</surname>, <given-names>R. B.</given-names></string-name>, <string-name><surname>Mormann</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name><surname>Koch</surname>, <given-names>C.</given-names></string-name></person-group> (<year>2013</year>). <article-title>Simultaneous modeling of visual saliency and value computation improves predictions of economic choice</article-title>. <source>Proceedings of the National Academy of Sciences</source>, <volume>110</volume> (<issue>40</issue>). <pub-id pub-id-type="doi">10.1073/pnas.1304429110</pub-id></mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Urai</surname>, <given-names>A. E.</given-names></string-name>, <string-name><surname>Braun</surname>, <given-names>A.</given-names></string-name>, &amp; <string-name><surname>Donner</surname>, <given-names>T. H.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Pupil-linked arousal is driven by decision uncertainty and alters serial choice bias</article-title>. <source>Nature Communications</source>, <volume>8</volume> (<issue>1</issue>). <pub-id pub-id-type="doi">10.1038/ncomms14637</pub-id></mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Vilares</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Howard</surname>, <given-names>J. D.</given-names></string-name>, <string-name><surname>Fernandes</surname>, <given-names>H. L.</given-names></string-name>, <string-name><surname>Gottfried</surname>, <given-names>J. A.</given-names></string-name>, &amp; <string-name><surname>Kording</surname>, <given-names>K. P.</given-names></string-name></person-group> (<year>2012</year>). <article-title>Differential representations of prior and likelihood uncertainty in the human brain</article-title>. <source>Current Biology</source>, <volume>22</volume> (<issue>18</issue>), <fpage>1641</fpage>–<lpage>1648</lpage>. <pub-id pub-id-type="doi">10.1016/j.cub.2012.07.010</pub-id></mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Walker</surname>, <given-names>E. Y.</given-names></string-name>, <string-name><surname>Pohl</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Denison</surname>, <given-names>R. N.</given-names></string-name>, <string-name><surname>Barack</surname>, <given-names>D. L.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Block</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Ma</surname>, <given-names>W. J.</given-names></string-name>, &amp; <string-name><surname>Meyniel</surname>, <given-names>F.</given-names></string-name></person-group> (<year>2023</year>). <article-title>Studying the neural representations of uncertainty</article-title>. <source>Nature Neuroscience</source>, <volume>26</volume> (<issue>11</issue>), <fpage>1857</fpage>–<lpage>1867</lpage>. <pub-id pub-id-type="doi">10.1038/s41593-023-01444-y</pub-id></mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Yu</surname>, <given-names>A. J.</given-names></string-name>, &amp; <string-name><surname>Dayan</surname>, <given-names>P.</given-names></string-name></person-group> (<year>2005</year>). <article-title>Uncertainty, neuromodulation, and attention</article-title>. <source>Neuron</source>, <volume>46</volume> (<issue>4</issue>), <fpage>681</fpage>–<lpage>692</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2005.04.026</pub-id></mixed-citation></ref>
</ref-list>
<sec id="s6">
<title>Supplementary material</title>
<sec id="s6a">
<title>Extended results</title>
<sec id="s6a1">
<title>Absolute learning-rate analysis</title>
<p>Our analysis of signed learning rates based on the regression models shows that prediction errors in conjunction with multiple factors, such as belief states and choice-confirming outcomes, govern learning rates. However, one potential issue of our signed learning-rate approach is that lower learning rates could be an indicator of (i) a strategic calibration of the learning rate to perceptual uncertainty or (ii) more frequent confusion of the task states due to perceptual uncertainty. The first interpretation (strategic adjustment of the learning rate) would be in line with our hypothesis that humans adjust learning to uncertainty. However, according to the second interpretation (state confusion), lower fixed and belief-state-driven learning rates would arise when subjects misperceive the stimuli and learn in the wrong direction. To tease these two interpretations apart, we analyzed absolute prediction errors and updates. Running the analyses on absolute prediction errors and updates yields learning-rate estimates of how much participants learned independently of whether they learned in the correct or incorrect direction. As such, this approach allows us to examine the magnitude of updates independent of whether they confused the task states or not.</p>
<p>In line with the perspective that learning behavior is shaped by prediction errors, we found a significant correlation between absolute prediction errors and updates (<xref rid="figS1" ref-type="fig">Fig. S1a</xref>). Additionally, we found a significant relationship between contrast differences and absolute single-trial updates (<xref rid="figS1" ref-type="fig">Fig. S1b</xref>). That is, participants made larger updates on the slider when the contrast difference was larger.</p>
<p>However, the single-trial approach might also be more strongly affected by response noise, and we, therefore, next applied our regression model to absolute prediction errors and updates. The fixed learning rate reflecting the average influence of prediction errors on absolute updates was positive (mean = 0.13 <italic>±</italic> 0.02, <italic>t</italic><sub>97</sub> = 6.31, <italic>p &lt;</italic> 0.001, Cohen’s <italic>d</italic> = 0.64) (<xref rid="figS1" ref-type="fig">Fig. S1c</xref>, fixed-LR coefficient). This confirms our results from the analysis of signed learning rates that prediction errors drive learning.</p>
<p>Additionally, contrast differences appear to have a similar influence on absolute and signed learning. Consistent with the signed learning-rate approach, we found that larger contrast differences propelled absolute updates for a given prediction error, as indicated by the positive coefficients for belief-state-adapted learning (mean = 0.05 <italic>±</italic> 0.014, <italic>t</italic><sub>97</sub> = 3.47, <italic>p &lt;</italic> 0.001, Cohen’s <italic>d</italic> = 0.35) (<xref rid="figS1" ref-type="fig">Fig. S1c</xref>, belief-state-adapted-LR coefficient). This implies that absolute updates increase with increasing contrast-difference levels for a given prediction error (<xref rid="figS1" ref-type="fig">Fig. S1d</xref>; example participant). Additionally, across participants, signed belief-state-adapted-LR coefficients were strongly correlated with absolute coefficients (<xref rid="figS1" ref-type="fig">Fig. S1e</xref>), suggesting that both approaches capture dynamic learning in a comparable way.</p>
<p>Finally, we found evidence of the confirmation bias, similar to the signed learning-rate analysis. In our regression model, positive confirmation-bias coefficients indicate stronger updates following outcomes that confirm the participant’s choice (mean = 0.1 <italic>±</italic> 0.009, <italic>t</italic><sub>97</sub> = 10.61, <italic>p &lt;</italic> 0.001; Cohen’s <italic>d</italic> = 1.07 (<xref rid="figS1" ref-type="fig">Fig. S1c</xref>, confirmation bias; <xref rid="figS1" ref-type="fig">Fig. S1f</xref>). Again, these results coincide with the impact confirming outcomes had in the signed learning-rate approach.</p>
<fig id="figS1" position="float" fig-type="figure">
<label>Figure S1.</label>
<caption><title>Absolute learning-rate analysis.</title>
<p><bold>a</bold>| Mean <italic>±</italic> standard error of the mean (SEM) absolute single-trial updates grouped across 10 absolute single-trial prediction-error bins (Pearson’s <italic>r</italic><sub>08</sub> = 0.97, <italic>p</italic> &lt; 0.001). Participants’ slider updates were larger for larger prediction errors. <bold>b</bold>| Mean <italic>±</italic> SEM absolute single-trial updates grouped across 10 contrast-difference bins (Pearson’s <italic>r</italic><sub>08</sub> = 0.66, <italic>p</italic> = 0.038). <bold>c</bold>| Mean <italic>±</italic> SEM coefficients for key regressors from the linear regression model fit to absolute single-trial updates. Positive fixed-LR coefficients indicate participants’ proclivity to show larger updates for larger absolute prediction errors (Cohen’s <italic>d</italic> = 0.64). Similarly, belief-state-adapted-LR coefficients convey a contrast-difference-contingent update magnitude (Cohen’s <italic>d</italic> = 0.35). The confirmation-bias coefficient also revealed higher absolute learning from confirming outcomes (Cohen’s <italic>d</italic> = 1.07). <bold>d</bold>| Across three levels of contrast-difference values, regression fits for a range of absolute prediction-error values show contrast-difference-modulated flexible learning. Higher contrast differences led to larger updates, presumably driven by more distinct belief states, as compared to lower contrast differences, for a given prediction error. <bold>e</bold>| Relationship between absolute and signed belief-state-adapted LR across participants shows that both approaches to analyzing the data corroborate the presence of flexible learning (Pearson’s <italic>r</italic><sub>08</sub> = 0.92, <italic>p</italic> = 0.001). <bold>f</bold>| Larger updates were made on trials where the participant learned from outcomes that confirmed the participant’s belief estimate, across different values of prediction errors.</p></caption>
<graphic xlink:href="590947v1_figS1.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s6a2">
<title>Extended learning-rate analysis</title>
<p>Next to adjustments in learning rates for prediction errors and belief states (see <xref ref-type="disp-formula" rid="eqn21">eq. (21)</xref>), we now discuss the impact of choice confirmation and additional control regressors on signed updates. We found that choice-confirming outcomes impacted signed and absolute updates. These findings align with existing literature showing higher learning rates for choice-confirming outcomes, as compared to negative or neutral information that dis-confirms choices (<xref ref-type="bibr" rid="c58">Lefebvre et al., 2017</xref>; <xref ref-type="bibr" rid="c59">Nickerson, 1998</xref>; <xref ref-type="bibr" rid="c61">Palminteri et al., 2017</xref>; <xref ref-type="bibr" rid="c62">Pupillo &amp; Bruckner, 2023</xref>; <xref ref-type="bibr" rid="c63">Sharot &amp; Garrett, 2016</xref>). Studies suggest that the bias can be potentially beneficial in a risky environment in which outcomes can only partially be predicted. Learning preferentially from choice-confirming outcomes might yield more robust expected-value representations since dis-confirming outcomes that are due to outcome variability hold less sway over expected values (<xref ref-type="bibr" rid="c57">Kandroodi et al., 2021</xref>; <xref ref-type="bibr" rid="c58">Lefebvre et al., 2017</xref>; <xref ref-type="bibr" rid="c60">Palminteri &amp; Lebreton, 2022</xref>; <xref ref-type="bibr" rid="c64">Tarantola et al., 2021</xref>). Crucially, based on our study, it is not possible to clearly dissociate the confirmation bias (stronger learning from choice-confirming outcomes) from the positivity bias (stronger learning from positive outcomes), which might require a comparison between instrumental (as in our task) and Pavlovian tasks (where due to the absence of choices, only the positivity bias can show up; <xref ref-type="bibr" rid="c58">Lefebvre et al. (2017)</xref>).</p>
<p>Furthermore, the contrast (higher vs. lower) of the more rewarding option in a block termed as the “salience” of the more rewarding patch (mean = <italic>−</italic> 0.01 <italic>±</italic> 0.009, <italic>t</italic><sub>97</sub> = <italic>−</italic> 1.52, <italic>p</italic> = 0.13, Cohen’s <italic>d</italic> = 0.15) and slider congruence (congruent vs. incongruent) (mean = 0 0.009, <italic>t</italic><sub>97</sub> = <italic>−</italic> 0.15, <italic>p</italic> = 0.88, Cohen’s <italic>d</italic> = 0.01) did not have a significant effect on updates. Similarly, these regressors did not have a significant impact (mean = <italic>−</italic> 0.02 <italic>±</italic> 0.009, <italic>t</italic><sub>97</sub> = <italic>−</italic> 1.8, <italic>p</italic> = 0.08, Cohen’s <italic>d</italic> = 0.18; Salience and mean = 0 <italic>±</italic> 0.009, <italic>t</italic><sub>97</sub> = <italic>−</italic> 0.19, <italic>p</italic> = 0.85, Cohen’s <italic>d</italic> = 0.02; Congruence) on absolute updates (<xref rid="figS2" ref-type="fig">Fig. S2a</xref>). In addition to this result being in line with the normative agent, this also clarifies that peripheral task factors did not impact learning.</p>
<fig id="figS2" position="float" fig-type="figure">
<label>Figure S2.</label>
<caption><title>Full regression model and multi-collinearity check.</title>
<p><bold>a</bold>| Mean <italic>±</italic> standard error of the mean (SEM) coefficients for all key and control regressors from the signed and absolute linear regression model. <bold>b</bold>| Heat-map showing correlation coefficients between coefficient values for all regressors from the signed learning-rate analysis. <bold>c</bold>| Heat-map showing correlation coefficients between coefficient values for all regressors from the absolute learning-rate analysis.</p></caption>
<graphic xlink:href="590947v1_figS2.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>Additionally, we also checked for correlations between the estimated coefficients for both signed and absolute analysis. Correlation matrices show correlations in the low-to-moderate range between the estimated coefficients for both sets of analysis (<xref rid="figS2" ref-type="fig">Fig. S2b-c</xref>). This indicates that estimated coefficients are not spuriously exaggerated or mitigated, which could, in principle, be a result of multi-collinearity.</p>
<p>Moreover, to control for how learning changed with the different levels of reward probability, we added an additional term modeling the interaction between prediction error and the level of reward uncertainty (risk-adapted LR) as a control regressor to <xref ref-type="disp-formula" rid="eqn21">eq. (21)</xref>. This is coded as a categorical variable, i.e., 0 for high reward uncertainty and 1 for low reward uncertainty. This control analysis yielded that risk did not significantly impact signed (mean = <italic>−</italic> 0.02 <italic>±</italic> 0.019, <italic>t</italic><sub>98</sub> = <italic>−</italic> 1.31, <italic>p</italic> = 0.2, Cohen’s <italic>d</italic> = 0.15) and absolute (mean = <italic>−</italic> 0.01 <italic>±</italic> 0.018, <italic>t</italic><sub>97</sub> = <italic>−</italic> 0.62, <italic>p</italic> = 0.72, Cohen’s <italic>d</italic> = 0.06) updates (<xref rid="figS3" ref-type="fig">Fig. S3a</xref>). However, risk-adapted LR coefficients were correlated with fixed LR (Pearson’s <italic>r</italic><sub>97</sub> = <italic>−</italic> 0.62, <italic>p &lt;</italic> 0.001), and we, therefore, decided to exclude it from the regression model.</p>
<fig id="figS3" position="float" fig-type="figure">
<label>Figure S3.</label>
<caption><title>Full signed and absolute learning-rate analyses.</title>
<p><bold>a</bold>| Mean <italic>±</italic> standard error of the mean (SEM) coefficients for all key and control regressors, including risk-adapted learning-rate coefficients from the signed and absolute linear regression model. <bold>b</bold>| Mean <italic>±</italic> SEM coefficients for the salience-bias coefficient.</p></caption>
<graphic xlink:href="590947v1_figS3.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>We also extended the regression model to clarify if the salience bias identified during decision-making impacts learning. We added this as an interaction term between prediction errors and a categorical variable representing salience (low vs. high), which denotes if the more or less salient option was chosen on the given trial. Negative significant coefficients for this regressor show that participants preferentially up-regulated signed (mean = <italic>−</italic> 0.02 <italic>±</italic> 0.008, <italic>t</italic><sub>97</sub> = <italic>−</italic>2.28, <italic>p &lt;</italic> 0.05, Cohen’s <italic>d</italic> = 0.23) and absolute (mean = <italic>−</italic> 0.02 <italic>±</italic> 0.007, <italic>t</italic><sub>97</sub> = <italic>−</italic> 2.7, <italic>p &lt;</italic> 0.001, Cohen’s <italic>d</italic> = 0.27) updates after choosing the less salient option (<xref rid="figS3" ref-type="fig">Fig. S3b</xref>). This effect could reflect a strategy to compensate for the lower subjective expected value due to the salience bias affecting economic decision-making (via stronger prediction errors).</p>
</sec>
<sec id="s6a3">
<title>Model validation</title>
<fig id="figS4" position="float" fig-type="figure">
<label>Figure S4.</label>
<caption><title>Model-fit assessment.</title>
<p><bold>a</bold>| A visual representation of the goodness of fit, as illustrated by the model-predicted posterior updates using estimated parameters and single-trial regression data. <bold>b</bold>| <italic>R</italic><sup>2</sup> values show the regression model was moderately effective in capturing and explaining learning data despite heterogeneity across participants.</p></caption>
<graphic xlink:href="590947v1_figS4.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<p>To systematically compare the regression results to the empirical data, we performed posterior-predictive checks. Model-based updates captured the general trend in participants’ updates (<xref rid="figS4" ref-type="fig">Fig. S4a</xref>). One key difference is that empirical updates included a high frequency of extremely small updates (around 0 as indicated by the blue bar in <xref rid="figS4" ref-type="fig">Fig. S4a</xref>). We identified trial-by-trial variation in motor noise while responding with the slider as one potential reason for these extremely small updates. Such empirical updates are regardless of prediction errors and task-based variables. The regression fits feature extremely small posterior updates to a lesser extent since posterior updates are systematically scaled depending on the prediction error and other predictors of the model on a given trial.</p>
<p>We also illustrate that the model captures the learning dynamics for individual participants who also show evidence for a higher frequency of updates around 0 (<xref rid="figS5" ref-type="fig">Fig. S5</xref>). Finally, we examined the regression model’s goodness of fit using <italic>R</italic><sup>2</sup>, suggesting a moderate fit (<xref rid="figS4" ref-type="fig">Fig. S4b</xref>).</p>
<fig id="figS5" position="float" fig-type="figure">
<label>Figure S5.</label>
<caption><title>Example participant diagnostics.</title>
<p><bold>a-c</bold>| Added variable plots assessing the relationship between all model regressors and updates. The evident linear relationship (dark blue line) suggests that the model regressors made impactful contributions in capturing the general trend of single-trial updates for individual participants. <bold>d-f</bold>| Single-subject posterior updates predicted by the model efficiently capture single-subject updates.</p></caption>
<graphic xlink:href="590947v1_figS5.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS6" position="float" fig-type="figure">
<label>Figure S6.</label>
<caption><title>Split-half reliability correlation coefficients between odd and even trials.</title>
<p>Correlation between signed-analysis coefficients for <bold>a</bold>| fixed LR, <bold>b</bold>| belief-state-adapted LR, and <bold>c</bold>| confirmation bias. Correlation between absolute-analysis coefficients for <bold>d</bold>| fixed LR, <bold>e</bold>| belief-state-adapted LR, and <bold>f</bold>| confirmation bias.</p></caption>
<graphic xlink:href="590947v1_figS6.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
</sec>
<sec id="s6b">
<title>Split-half reliability for fixed and flexible learning parameters</title>
<p>To test how internally consistent our model’s estimated fixed and flexible learning parameters were, we adopted the split-half reliability measure. This involved grouping odd and even trials into different sub-sets to run separate regressions to obtain fixed and flexible learning rate coefficients for each subset. To quantify reliability, we computed the Pearson’s correlation coefficient between the parameters estimated (<xref rid="figS6" ref-type="fig">Fig. S6</xref>). We found that fixed learning-rate coefficients have moderate reliability (Pearson’s <italic>r</italic><sub>98</sub> = 0.57, <italic>p &lt;</italic> 0.001; signed analyses and Pearson’s <italic>r</italic> = 0.63, <italic>p &lt;</italic> 0.001; absolute analyses). However, we found weaker reliability measures for both belief-state-adapted LR (Pearson’s <italic>r</italic><sub>98</sub> = 0.32, <italic>p &lt;</italic> 0.01; signed analyses and Pearson’s <italic>r</italic><sub>98</sub> = 0.32, <italic>p &lt;</italic> 0.01; absolute analyses) and confirmation bias (Pearson’s <italic>r</italic><sub>98</sub> = 0.13, <italic>p</italic> = 0.19; signed analyses and Pearson’s <italic>r</italic><sub>98</sub> = 0.23, <italic>p &lt;</italic> 0.05; absolute analyses).</p>
</sec>
<sec id="s6c">
<title>Extended belief-accuracy analysis</title>
<fig id="figS7" position="float" fig-type="figure">
<label>Figure S7.</label>
<caption><title>Confirmation bias and signed estimation error.</title>
<p><bold>a</bold>| Illustration of the hypothetical role of the confirmation bias during learning under uncertainty. The confirmation bias reflects stronger learning from choice-confirming than dis-confirming outcomes. In some situations, it might boost learned value representations. In this example, the confirmation bias helps the learner estimate the value more accurately (lower underestimation of the true value) compared to an unbiased learner (higher underestimation of the true value). <bold>b</bold>| We tested this idea based on the experimental data. To do so, we relied on signed estimation errors indicating the degree of under-versus overestimation of the true but unknown reward probability. Most subjects tended to underestimate the reward probability (average estimation error across all blocks). The confirmation bias and the signed estimation error turned out to be associated in that stronger confirmation biases statistically predicted more accurate reward probabilities (less underestimation of the true probabilities). This result is consistent with the idea that under some circumstances, the confirmation bias can be adaptive.</p></caption>
<graphic xlink:href="590947v1_figS7.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<sec id="s6c1">
<title>Confirmation bias and over-estimated beliefs</title>
<p>To empirically test whether the confirmation bias is linked to the extent to which participants under-or overestimated the actual contingency parameter, we examined the relationship between our regression coefficients and signed estimation errors. We quantified signed estimation errors as the signed difference between the actual reward contingency and the value reported by the participant, which corresponds to whether participants over-or underestimated the reward probability. Due to reward uncertainty in our task, correct choices were sometimes not rewarded (e.g., in 30%, correct choices were not rewarded). It has been argued that a confirmation bias is beneficial to learning under such challenging conditions: When choice-confirming outcomes have a stronger effect on the learning rate, value representations might become more robust and might potentially be more weakly affected by reward uncertainty (<xref ref-type="bibr" rid="c58">Lefebvre et al., 2017</xref>; <xref ref-type="bibr" rid="c61">Palminteri et al., 2017</xref>). This could result in overestimated reward probabilities compared to an unbiased strategy (<xref rid="figS7" ref-type="fig">Fig. S7a</xref>). Indeed, we found a significant relationship between signed estimation error and confirmation bias (<italic>β</italic> = 0.25, <italic>p &lt;</italic> 0.01; <xref rid="figS7" ref-type="fig">Fig. S7b</xref>). That is, participants with higher confirmation bias showed less negative estimation errors, suggesting that the confirmation bias might have helped them calibrate learning to reward uncertainty. In line with this perspective, we found that participants with stronger choice-confirmation biases tended to show reduced underestimation of the actual reward probability.</p>
<fig id="figS8" position="float" fig-type="figure">
<label>Figure S8.</label>
<caption><title>Influence of learning on belief accuracy.</title>
<p>Relationship between absolute estimation error and <bold>a</bold>| salience and <bold>b</bold>| congruence.</p></caption>
<graphic xlink:href="590947v1_figS8.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s6c2">
<title>Signed learning rate and belief accuracy</title>
<p>Next, we also controlled for potential links between the adapted signed learning rate for control regressors from <xref ref-type="disp-formula" rid="eqn21">equation (21)</xref> and absolute estimation error. Salience had a significant impact on estimation error (<italic>β</italic> = 0.36, <italic>p</italic> = 0.02) whereas congruence did not have a significant relationship with estimation error (<italic>β</italic> = <italic>−</italic> 0.1, <italic>p</italic> = 0.428) (<xref rid="figS8" ref-type="fig">Fig. S8</xref>).</p>
<fig id="figS9" position="float" fig-type="figure">
<label>Figure S9.</label>
<caption><title>Influence of absolute learning rates on belief accuracy.</title>
<p>Relationship between absolute estimation error and coefficients for <bold>a</bold>| fixed LR, <bold>b</bold>| belief-state-adapted LR, <bold>c</bold>| confirmation bias, <bold>d</bold>| salience, and <bold>e</bold>| congruence.</p></caption>
<graphic xlink:href="590947v1_figS9.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
<sec id="s6c3">
<title>Absolute learning rate and belief accuracy</title>
<p>To check if absolute learning rates impacted belief accuracy, we fit a model containing all learning-rate coefficients from the absolute learning-rate analyses to absolute estimation errors. We found that subjects with high absolute fixed learning-rate coefficients (i.e., prediction-error-driven learning) tended to have larger estimation errors (<italic>β</italic> = 0.28, <italic>p</italic> = 0.02; <xref rid="figS9" ref-type="fig">Fig. S9a</xref>). Similarly, individual differences in belief-state-adapted-LR coefficients had a significant relationship with estimation error (<italic>β</italic> = 0.267, <italic>p</italic> = 0.04; <xref rid="figS9" ref-type="fig">Fig. S9b</xref>). We found no significant links between estimation error and confirmation bias LR (<italic>β</italic> = <italic>−</italic> 0.0014, <italic>p</italic> = 0.989; <xref rid="figS9" ref-type="fig">Fig. S9c</xref>). Similarly, we found no significant links between estimation error and salience (<italic>β</italic> = 0.199, <italic>p</italic> = 0.293; <xref rid="figS9" ref-type="fig">Fig. S9d</xref>). Finally, we found that congruence did not significantly impact estimation errors (<italic>β</italic> = <italic>−</italic>0.2028, <italic>p</italic> = 0.147; <xref rid="figS9" ref-type="fig">Fig. S9e</xref>).</p>
</sec>
<sec id="s6c4">
<title>Pilot study</title>
<p>We used a reduced version of the current task design (excluding the slider) in a pilot study. We integrated a combination of both perceptual and reward uncertainty as an extension to the Gabor-Bandit task (<xref ref-type="bibr" rid="c6">Bruckner et al., 2020</xref>). We collected pilot data of 100 participants (52 female, 48 male; mean age = 22.91 <italic>±</italic> 3.04; age range 18-30). We excluded data from seven participants as they performed with less than 50% accuracy. Participants completed a total of 16 blocks, with 25 trials each. Each block belonged to one of three within-subject experimental conditions similar to the Experimental task. We also added a fourth control condition with low levels of perceptual and reward uncertainty. For conditions with high perceptual uncertainty, we sampled contrast differences from [−0.08, 0] when the left patch had the lower contrast (<italic>s</italic><sub><italic>t</italic></sub> = 0) and [0, 0.08] when the right patch had the lower contrast (<italic>s</italic><sub><italic>t</italic></sub> = 1). In the conditions with low perceptual uncertainty, the contrast difference was in the range [−0.38, −0.3] when the contrast of the left patch was lower (<italic>s</italic><sub><italic>t</italic></sub> = 0) and [0.3, 0.38] when the contrast of the right patch was lower (<italic>s</italic><sub><italic>t</italic></sub> = 1). Finally, we counterbalanced the mapping between states, actions, and rewards. The order of the conditions was randomized for each participant. However, for the first fifty participants, the order was not completely randomized. The first and the eighth blocks deterministically belonged to the both-uncertainties condition.</p>
</sec>
<sec id="s6c5">
<title>Replicating decision-making results in pilot study</title>
<p>Results from the pilot study align with the salience bias seen in the analysis of choices from the primary Experimental task. Participants showed a significant salience bias in the both-uncertainties condition (mean = 0.07 <italic>±</italic> 0.017, <italic>t</italic><sub>92</sub> = 4.26, <italic>p &lt;</italic> 0.001), reward condition (mean = 0.09 <italic>±</italic> 0.016, <italic>t</italic><sub>92</sub> = 5.71, <italic>p &lt;</italic> 0.001), and control condition (mean = 0.04<italic>±</italic>0.008, <italic>t</italic><sub>92</sub> = 5.65, <italic>p &lt;</italic> 0.001). However, in the perceptual-uncertainty condition (mean = 0.02<italic>±</italic> 0.013, <italic>t</italic><sub>92</sub> = 1.22, <italic>p</italic> = 0.22), we did not find a significant salience bias. Next, we tested if the salience bias is more enhanced due to reward uncertainty. Participants showed a significantly pronounced salience bias in the both-uncertainties condition as compared to the perceptual-uncertainty condition (<italic>t</italic><sub>92</sub> = 3.25, <italic>p &lt;</italic> 0.01, Cohen’s <italic>d</italic> = <italic>−</italic> 0.38). Participants showed a significantly larger salience bias in the no-uncertainty condition as compared to the reward-uncertainty condition (<italic>t</italic><sub>92</sub> = 3.07, <italic>p &lt;</italic> 0.001, Cohen’s <italic>d</italic> = 0.41) (<xref rid="figS10" ref-type="fig">Fig. S10a</xref>). We also fitted a linear regression model to the participants’ average economic performance in a block. We used regressors that corresponded to the (i) perceptual (salience and uncertainty) and (ii) reward information on the block level (<xref rid="figS10" ref-type="fig">Fig. S10b</xref>). Crucially, in support of the hypothesis that humans integrate value and salience, positive coefficients for the main effect of salience reveal that economic choices were significantly more likely to be correct on high-contrast blocks, as opposed to low-contrast blocks (main task: mean = 0.06 <italic>±</italic> 0.014, <italic>t</italic><sub>97</sub> = 4.4, <italic>p &lt;</italic> 0.001, Cohen’s <italic>d</italic> = 0.44, pilot study: mean = 0.06<italic>±</italic> 0.009, <italic>t</italic><sub>92</sub> = 6.49, <italic>p &lt;</italic> 0.001; Cohen’s <italic>d</italic> = 0.67). Additionally, a negative and significant coefficient for high perceptual uncertainty shows that participants performed worse on blocks with high perceptual uncertainty, as compared to low perceptual uncertainty (main task: mean = <italic>−</italic> 0.07 <italic>±</italic> 0.013, <italic>t</italic><sub>97</sub> = −5.61, <italic>p &lt;</italic> 0.001, Cohen’s <italic>d</italic> = 0.57, pilot study: mean = <italic>−</italic> 0.09<italic>±</italic> 0.009, <italic>t</italic><sub>92</sub> = −9.51, <italic>p &lt;</italic> 0.001; Cohen’s <italic>d</italic> = 0.99). Finally, we also found that economic choice performance was significantly worse in blocks where reward uncertainty was high, as captured by negative coefficients for the main effect of high reward uncertainty (main task: mean = <italic>−</italic>0.13 <italic>±</italic> 0.012, <italic>t</italic><sub>97</sub> = −11.29, <italic>p &lt;</italic> 0.001, Cohen’s <italic>d</italic> = 1.14, pilot study: mean = <italic>−</italic>0.18 <italic>±</italic> 0.012, <italic>t</italic><sub>92</sub> = −15.16, <italic>p &lt;</italic> 0.001; Cohen’s <italic>d</italic> = 1.57).</p>
<fig id="figS10" position="float" fig-type="figure">
<label>Figure S10.</label>
<caption><title>Choice analysis of pilot experiment.</title>
<p><bold>a</bold>| Mean<italic>±</italic> standard error of the mean (SEM) salience bias for types of uncertainties. Positive salience bias indicates participants’ preference for the high-salience option. <bold>b</bold>| Mean ± SEM coefficients for key regressors after fitting a linear regression model to block-level choice accuracy. Positive coefficients for the main effect of high contrast indicate participants’ proclivity to choose the high salience option. Negative coefficients for high levels of perceptual and reward uncertainty capture the decrease in participant’s performance with increasing uncertainty in the environment. <bold>c</bold> Mean <italic>±</italic> standard error of the mean (SEM) choice performance across levels of perceptual uncertainty showing that high perceptual uncertainty leads to worse performance.</p></caption>
<graphic xlink:href="590947v1_figS10.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
<fig id="figS11" position="float" fig-type="figure">
<label>Figure S11.</label>
<caption><title>Normative agent’s simulated choice and learning behavior.</title>
<p><bold>a</bold>| Averaged across 100 simulations, choice performance is corrupted by higher perceptual uncertainty (“both” and “perceptual” condition). <bold>b</bold>| Learned contingency parameter (<italic>µ</italic>) converges towards the actual contingency parameter. Simulated learning curves are more noisy in the higher reward uncertainty blocks due to riskier outcomes that the agent is required to learn from. In comparison to blocks with low reward uncertainty, the agent shows systematically slower learning in the higher reward uncertainty blocks (“both”, “reward” and “high uncertainty” condition). Additionally, we see slower learning due to extremely high perceptual uncertainty which primarily dictates the agent’s learning patterns (see learning curve for high-uncertainty blocks) in conjunction with reward uncertainty.</p></caption>
<graphic xlink:href="590947v1_figS11.tif" mime-subtype="tiff" mimetype="image"/>
</fig>
</sec>
</sec>
</sec>
<ref-list>
<title>Supplementary references</title>
<ref id="c57"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Kandroodi</surname>, <given-names>M. R.</given-names></string-name>, <string-name><surname>Vahabie</surname>, <given-names>A.-H.</given-names></string-name>, <string-name><surname>Ahmadi</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Araabi</surname>, <given-names>B. N.</given-names></string-name>, &amp; <string-name><surname>Ahmadabadi</surname>, <given-names>M. N.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Optimal reinforcement learning with asymmetric updating in volatile environments: A simulation study</article-title>. <source>bioRxiv</source>. <pub-id pub-id-type="doi">10.1101/2021.02.15.431283</pub-id></mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Lefebvre</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Lebreton</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Meyniel</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Bourgeois-Gironde</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Palminteri</surname>, <given-names>S.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Behavioural and neural characterization of optimistic reinforcement learning</article-title>. <source>Nature Human Behaviour</source>, <volume>1</volume> (<issue>4</issue>). <pub-id pub-id-type="doi">10.1038/s41562-017-0067</pub-id></mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Nickerson</surname>, <given-names>R. S.</given-names></string-name></person-group> (<year>1998</year>). <article-title>Confirmation bias: A ubiquitous phenomenon in many guises</article-title>. <source>Review of General Psychology</source>, <volume>2</volume> (<issue>2</issue>), <fpage>175</fpage>–<lpage>220</lpage>. <pub-id pub-id-type="doi">10.1037/1089-2680.2.2.175</pub-id></mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Palminteri</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name><surname>Lebreton</surname>, <given-names>M.</given-names></string-name></person-group> (<year>2022</year>). <article-title>The computational roots of positivity and confirmation biases in reinforcement learning</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>26</volume> (<issue>7</issue>), <fpage>607</fpage>–<lpage>621</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2022.04.005</pub-id></mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Palminteri</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Lefebvre</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Kilford</surname>, <given-names>E. J.</given-names></string-name>, &amp; <string-name><surname>Blakemore</surname>, <given-names>S.-J.</given-names></string-name></person-group> (<year>2017</year>). <article-title>Confirmation bias in human reinforcement learning: Evidence from counterfactual feedback processing (A. M. Haith, Ed</article-title>.). <source>PLOS Computational Biology</source>, <volume>13</volume> (<issue>8</issue>), <fpage>e1005684</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pcbi.1005684</pub-id></mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Pupillo</surname>, <given-names>F.</given-names></string-name>, &amp; <string-name><surname>Bruckner</surname>, <given-names>R.</given-names></string-name></person-group> (<year>2023</year>). <article-title>Signed and unsigned effects of prediction error on memory: Is it a matter of choice?</article-title> <source>Neuroscience &amp; Biobehavioral Reviews</source>, <volume>153</volume>, <fpage>105371</fpage>. <pub-id pub-id-type="doi">10.1016/j.neubiorev.2023.105371</pub-id></mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name><surname>Sharot</surname>, <given-names>T.</given-names></string-name>, &amp; <string-name><surname>Garrett</surname>, <given-names>N.</given-names></string-name></person-group> (<year>2016</year>). <article-title>Forming beliefs: Why valence matters</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>20</volume> (<issue>1</issue>), <fpage>25</fpage>–<lpage>33</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2015.11.002</pub-id></mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="preprint"><person-group person-group-type="author"><string-name><surname>Tarantola</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Folke</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Boldt</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Pérez</surname>, <given-names>O. D.</given-names></string-name>, &amp; <string-name><surname>Martino</surname>, <given-names>B. D.</given-names></string-name></person-group> (<year>2021</year>). <article-title>Confirmation bias optimizes reward learning</article-title>. <source>bioRxiv</source>. <pub-id pub-id-type="doi">10.1101/2021.02.27.433214</pub-id></mixed-citation></ref>
</ref-list>
<sec id="s7">
<title>Extended task details</title>
<sec id="s7a">
<title>Practice task</title>
<p>Before taking part in the main task, participants were trained using an adapted version. The specific details differed across both studies.</p>
<p><bold>Study 1</bold> Participants performed four practice blocks, with 50 trials each. On half of the practice blocks, participants were presented with high perceptual uncertainty trials. However, reward-uncertainty levels were not manipulated across the two practice blocks. Thus, the latent state-action-reward contingency was such that on half of the practice blocks, the patch with higher contrast had a 100% reward probability, while on the other half, the patch with lower contrast had a 100% reward probability. The trial structure was the same as the main task and participants were expected to make an economic decision. The main aim of the practice blocks was to train participants in an easier version of the main task.</p>
<p><bold>Study 2</bold> Participants performed three practice blocks, with 25 trials each. Each block belonged to each of the three uncertainty conditions. Specifically, the blocks were sequentially presented to ensure increasing order of difficulty. Participants started off with the perceptual uncertainty condition followed by the reward uncertainty condition. Finally, participants did the both-uncertainties condition. The trial structure was the same as the main task and participants were expected to make an economic decision and learn to use the slider to report their estimated contingency parameter.</p>
</sec>
<sec id="s7b">
<title>Instructions</title>
<p>Participants were presented with an online version of the instructions. Multiple images demon-strated various stages of the task which was accompanied by written explanation. Post this, participants were asked to answer questions about the task in a quiz. For every incorrect answer, participants were reminded of the correct response with an appropriate description for the same. <italic>Here is a summary of the instructions for the main task. In this task, you will be presented with multiple blocks of trials. A fixation cross which looks like this (+) will precede each trial. Please fixate on the cross before the start of the trial. In each trial, you will be presented with two images. Both images may have different levels of contrast (i</italic>.<italic>e. brightness) on each trial. Your task is to choose one of these two images. If you want to choose the image presented on your left, please press the left arrow on your keyboard. If you want to choose the image presented on your right, press the right arrow on your keyboard. Your main aim is to figure out which image you should choose. On each block of trials there is a relationship between the contrast (brightness) level of the image and how often you may win 1 point if you choose that image. For example, on some blocks of trials, the image with higher contrast (brightness) is associated with winning 1 point more often while in another block of trial, the relationship may be reversed. This relationship may change when a new block of trials starts. You will learn this relationship from feedback after your choice. That is, after each trial, you will be presented with the points you win on that trial. You should try to maximize your winnings on each trial. If you have understood the instructions, please press any key to proceed with the experiment</italic>.</p>
<p>An additional set of instructions were presented to participants to explain the use of a slider in Experiment 2.</p>
<p><italic>Once you make a choice and receive feedback, you will be presented with a slider that ranges between 0 to 100 percent. Again, you will be presented with two images. Both images may have different contrast levels (i</italic>.<italic>e</italic>., <italic>brightness) on each trial. Additionally, one of these two images will have a border. You have to assume that you have hypothetically chosen that image with the border. Based on this hypothetical choice scenario, you are expected to indicate the chance with which you think you can win 1 point on the scale of 0 to 100 percent. Please make the response only when the color of the border changes from red to green. To select the chance, you can drag the slider based on the labels of the slider. You could also directly click on the slider above a particular percent to respond. After your response, please click on the Continue button to proceed in the task. If you have understood these instructions, please press any key to proceed to the experiment</italic>.</p>
<p>This was supplemented with an instructions quiz to ensure thorough understanding of the task, see Instructions quiz. At the end of the task, a debriefing quiz was used to ask participants about the strategies that they used in the task, see Debriefing quiz.</p>
</sec>
<sec id="s7c">
<title>Instructions quiz for Experiment 1</title>
<p>If you want to choose the image on the left of the fixation (+), which key should you press?</p>
<list list-type="bullet">
<list-item><p>Right arrow</p></list-item>
<list-item><p>Left arrow</p></list-item>
<list-item><p>Space Bar</p></list-item>
</list>
<p>Assume that you won 1 point after choosing the high-contrast image on the left-hand side. Does it mean that you will always win if you choose the image on the left side, irrespective of the contrast levels of the images?</p>
<list list-type="bullet">
<list-item><p>Yes</p></list-item>
<list-item><p>Maybe</p></list-item>
<list-item><p>No</p></list-item>
</list>
<p>Assume that you have previously won 1 point after choosing the image with high contrast in a certain block of trials. Does it mean that you will always win a point when choosing the dark patch in this block?</p>
<list list-type="bullet">
<list-item><p>No</p></list-item>
<list-item><p>May be</p></list-item>
<list-item><p>Yes</p></list-item>
</list>
<p>There could be trials when it can be difficult to distinguish between the patches based on their contrast levels.</p>
<list list-type="bullet">
<list-item><p>True</p></list-item>
<list-item><p>False</p></list-item>
</list>
<p>Assume that you did not win after choosing the patch that you previously mostly won on. Identify possible reason(s) for it.</p>
<list list-type="bullet">
<list-item><p>I may have been confused between the contrast levels of the images because they look similar.</p></list-item>
<list-item><p>It may happen that I may not win even after choosing the previously rewarding patch because there is no guarantee that you will win on the same patch in a block.</p></list-item>
<list-item><p>It is possible that there is no reward associated with both images on certain trials.</p></list-item>
<list-item><p>You may have been confused between the contrast levels of the images because they look similar. And it may happen that you do not win even after choosing the previously rewarding patch because there is no guarantee that you will win on the same patch in a block.</p></list-item>
</list>
<p>Assume that in block 1, the image with higher contrast was almost always rewarding. Does that mean the higher contrast patch will always reward you in the next block?</p>
<list list-type="bullet">
<list-item><p>Yes</p></list-item>
<list-item><p>No</p></list-item>
</list>
</sec>
<sec id="s7d">
<title>Instructions quiz for Experiment 2</title>
<p>The percentages on the slider indicate which of the following?</p>
<list list-type="bullet">
<list-item><p>Chances of winning 0 points, if you chose the image with the green border.</p></list-item>
<list-item><p>Chances of winning 1 point, if you chose the image with the red border.</p></list-item>
<list-item><p>Chances of winning 2 points, if you chose the image with the green border.</p></list-item>
<list-item><p>Chances of winning 1 point, if you chose the image with the green border.</p></list-item>
</list>
<p>Once you have clicked on the slider to respond, how can you use the slider to re-adjust your response to the desired percent level?</p>
<list list-type="bullet">
<list-item><p>Directly click on the slider corresponding to the desired percent labels.</p></list-item>
<list-item><p>Re-adjustment of response is not possible once the slider has been initially clicked.</p></list-item>
<list-item><p>Click on the slider and then drag it to a corresponding desired percent label.</p></list-item>
</list>
<p>If you think that the chance of winning 1 point is 70 percent when choosing the image with the green border, to which percent label would you drag the slider to?</p>
<list list-type="bullet">
<list-item><p>30 percent.</p></list-item>
<list-item><p>60 percent.</p></list-item>
<list-item><p>70 percent.</p></list-item>
</list>
<p>There may be trials where you win 0 points more often on choosing a certain image and yet, you may be asked to estimate the chances of winning 1 point for the same image using the slider.</p>
<list list-type="bullet">
<list-item><p>True.</p></list-item>
<list-item><p>False.</p></list-item>
</list>
<p>You are allowed to respond using the slider, when the color of the border is:</p>
<list list-type="bullet">
<list-item><p>Red.</p></list-item>
<list-item><p>Green.</p></list-item>
<list-item><p>None of the above.</p></list-item>
</list>
</sec>
<sec id="s7e">
<title>Debriefing quiz for Experiment 1</title>
<list list-type="order">
<list-item><p>1. Which of these options is correct? (To address the bias)</p>
<list list-type="bullet">
<list-item><p>a. I always chose the image with the high contrast level.</p></list-item>
<list-item><p>b. I always chose the image with the low contrast level.</p></list-item>
<list-item><p>c. I chose the low contrast image more often for some blocks of trials, while the reverse was true for other blocks of trials.</p></list-item></list></list-item>
<list-item><p>Assume that you won 1 point by choosing the image on the left side of the fixation (+). Consequently, did you always choose the image on the left side, irrespective of its contrast levels? (Location)</p>
<list list-type="bullet">
<list-item><p>a. Yes</p></list-item>
<list-item><p>b. No</p></list-item>
<list-item><p>c. Depended on the block of trials.</p></list-item></list></list-item>
<list-item><p>Assume that you won 1 point in a trial, after choosing a high contrast image. Consequently, did you always choose the image with high contrast in the next trials, in that given block? (Reward Uncertainty)</p>
<list list-type="bullet">
<list-item><p>a. Yes</p></list-item>
<list-item><p>b. No</p></list-item>
<list-item><p>c. Depended on the block of trials</p></list-item></list>
</list-item>
<list-item><p>There were trials in the task in which you were rewarded 0 points, despite choosing the image that you previously won on. (All types of Uncertainty)</p>
<list list-type="bullet">
<list-item><p>a. True</p></list-item>
<list-item><p>b. False If true, what do you think were the reasons for the same?</p></list-item>
<list-item><p>a. The images had similar contrast levels and I got confused between them.</p></list-item>
<list-item><p>b. This occurred because there was no guarantee that I would win 1 point even after choosing the image that was previously rewarding.</p></list-item>
<list-item><p>c. The images had no points associated with them.</p></list-item>
<list-item><p>d. There could be multiple reasons for it. I could have been confused because of the similar contrast levels between the images and there is no guarantee that I would 1 point despite choosing the more rewarding image.</p></list-item></list></list-item>
<list-item><p>I found it more difficult to tell the images apart from one another (based on contrast levels), on certain trials. (Perceptual Uncertainty)</p>
<list list-type="bullet">
<list-item><p>a. True</p></list-item>
<list-item><p>b. False</p></list-item></list>
</list-item>
<list-item><p>Assume you won 1 point more often, when you choose the high contrast image in block 1. Did the same happen to you in the next block of trials? (Block)</p>
<list list-type="bullet">
<list-item><p>a. Yes, always.</p></list-item>
<list-item><p>b. No, never.</p></list-item>
<list-item><p>c. Sometimes.</p></list-item></list>
</list-item>
<list-item><p>If you wanted to choose the image on the right side of the fixation (+), which key did you press? (Key Press)</p>
<list list-type="bullet">
<list-item><p>a. Right Arrow</p></list-item>
<list-item><p>b. Left Arrow</p></list-item>
<list-item><p>c. Space Bar</p></list-item>
<list-item><p>d. Any other key</p></list-item></list>
</list-item>
<list-item><p>Imagine that you were responding to a block of difficult trials i.e. when you were not able to figure out the more rewarding image. In such a scenario, did you have a preference to respond towards a particular image? If so, please indicate.</p>
<list list-type="bullet">
<list-item><p>a. High Contrast Image</p></list-item>
<list-item><p>b. Low Contrast Image</p></list-item>
<list-item><p>c. No, I had no such preference.</p></list-item>
</list></list-item></list>
</sec>
<sec id="s7f">
<title>Debriefing for Experiment 2</title>
<p>I used the slider to indicate the chances of winning 1 point, if I chose the image with the green border.</p>
<list list-type="bullet">
<list-item><p>True.</p></list-item>
<list-item><p>False.</p></list-item>
<list-item><p>Sometimes.</p></list-item>
</list>
</sec>
</sec>
</back>
<sub-article id="sa0" article-type="editor-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.99266.1.sa2</article-id>
<title-group>
<article-title>eLife Assessment</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name>
<surname>Gold</surname>
<given-names>Joshua I</given-names>
</name>
<role specific-use="editor">Reviewing Editor</role>
<aff>
<institution-wrap>
<institution>University of Pennsylvania</institution>
</institution-wrap>
<city>Philadelphia</city>
<country>United States of America</country>
</aff>
</contrib>
</contrib-group>
<kwd-group kwd-group-type="evidence-strength">
<kwd>Solid</kwd>
</kwd-group>
<kwd-group kwd-group-type="claim-importance">
<kwd>Valuable</kwd>
</kwd-group>
</front-stub>
<body>
<p>This <bold>valuable</bold> study by Ganesh and colleagues examined how both the value and salience of sensory information can affect economic decision-making. The results provide insights into how different sources of uncertainty found in the real world, including those related to the perception of objects and those related to values associated with objects, can together influence decision-making behavior in systematic ways. The evidence is <bold>solid</bold> but overlaps with previous studies and could be improved by clarifying novelty and experimental details and considering additional models.</p>
</body>
</sub-article>
<sub-article id="sa1" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.99266.1.sa1</article-id>
<title-group>
<article-title>Reviewer #1 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>This study examined the effects of uncertainty over states (i.e., stimuli) and uncertainty over rewards (i.e., reward probability) on human learning and decision-making in a simple reinforcement learning task. The authors proposed two hypotheses: (1) high uncertainty over states reduces the learning rate, and (2) visual salience drives decision-making. A Bayesian learner is proposed to support the first hypothesis and several regression analyses confirm this finding. Furthermore, the analysis of salience bias also supports the second hypothesis.</p>
<p>Strengths:</p>
<p>(1) The experiment is simple and solid.</p>
<p>(2) The experimental design is clever and consistent with several well-established paradigms.</p>
<p>Weaknesses:</p>
<p>(1) One of my main concerns is that the first conclusion &quot;high uncertainty over states reduces learning rate&quot; is not new and has been shown recently in Yoo et al. (2023). In that study, a slower learning rate was found when stimuli were perceptually similar. It seems to me that the only difference here is that simple Gabor patches are used instead of e.g., green vegetable images in that study. The conclusion is exactly the same.</p>
<p>(2) The second hypothesis should be more explicit. Instead of claiming &quot;A drives B&quot;, can you show specific predictions for the direction of this influence? For example, given the same expected value, do human learners prefer to choose a high-contrast stimulus? and why?</p>
<p>(3) The analyses of salience bias support the second hypothesis. However, If I understand it correctly, there is no salience parameter (i.e., absolute contrast of each stimulus) in the decision process, according to Eqs. 4,5, and 6 in the Methods. In other words, the Bayesian learner should not exhibit a salience bias. The question then became, why do human learners have such a bias? What are the underlying mechanisms of the salience bias?</p>
<p>(4) If high perceptual uncertainty reduces the learning rate, why does the normative agent, which takes perceptual uncertainty into account, learn faster than the categorical agent, which has no perceptual uncertainty at all? Did I miss something?</p>
<p>(5) The learning algorithm is different from the standard Q-learning modeling approach. Better to include more explanation of why this type of learning algorithm is Bayesian optimal?</p>
<p>(6) Similar to the above, Bayesian modeling here only confirms that high perceptual uncertainty reduces the learning rate in an optimal Bayesian learner. Two questions remain elusive: (a) whether human learners are close to the Bayesian learner (i.e., near optimal). It seems that (a) is unlikely given several suboptimal heuristics (e.g., confirmation bias) found in humans. Then the question is (b) how optimal learning and suboptimal heuristics are combined in the human learning process. One of the major disadvantages of this study is that no new model is proposed to fit trial-by-trial human choices. I believe that building formal process models is the key to improving this study.</p>
<p>(7) The writing should be substantially improved. The main concern here is that the authors used several seemingly related but ambiguous words to represent the same concept. For example, &quot;perceptual uncertainty&quot; in Figures 1 &amp; 2 indicate the contrast differences between two patches. But page 5 line 9 includes &quot;belief-state uncertainty&quot;. Are they the same concept? Moreover, on page 18 line 17, if I understand it correctly, &quot;perceptual uncertainty&quot; here indicates sensory noise not contrast differences. Please carefully check all terminologies and use a single and concrete one to represent a concept throughout the paper.</p>
<p>(8) Similarly, is the &quot;task state&quot; on page 17 the same as the &quot;perceptual state&quot; in Figure 1&amp;2?</p>
<p>(9) The Methods section could also be improved. For example, I am not sure how Eq. 5 is derived. Also, page 18 line 16 states that &quot;in our simulations, we manipulated...'. I did not find any information about the simulation. How was the simulation performed? Did I miss something?</p>
</body>
</sub-article>
<sub-article id="sa2" article-type="referee-report">
<front-stub>
<article-id pub-id-type="doi">10.7554/eLife.99266.1.sa0</article-id>
<title-group>
<article-title>Reviewer #2 (Public review):</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<anonymous/>
<role specific-use="referee">Reviewer</role>
</contrib>
</contrib-group>
</front-stub>
<body>
<p>Summary:</p>
<p>The authors addressed the question of how perceptual uncertainty and reward uncertainty jointly shape value-based decision-making. They sought to test two main hypotheses: (H1) perceptual uncertainty modulates learning rates, and (H2) perceptual salience is integrated in value computation. Through a series of analyses, including regression models and normative computational modeling, they showed that learning rates were modulated by perceptual uncertainty (reflected by differences in contrast), supporting H1, and the update was indeed biased toward high-contrast (ie, salient) stimuli, supporting H2.</p>
<p>Strengths:</p>
<p>This is a timely and interesting study, with a strong theory-driven focus, reflected by the sophisticated experimental design that systematically tests both perceptual and reward uncertainty. This paper is also well written, with relevant examples (bakery) that draw the analogy to explain the main research question. The main response by participants is reward probability estimation (on a slider), which goes beyond commonly used binary choices and offers richness of the data, that was eventually used in the regression analysis. This work may also open new directions to test the interaction between perceptual decision-making and value-based decision-making.</p>
<p>Weaknesses:</p>
<p>Despite the strengths, multiple points may need to be clarified, to make this paper stronger.</p>
<p>(1) Experimental design:</p>
<p>(1a) The authors stated (page 6) that &quot;The systematic manipulation of uncertainty resulted in three experimental conditions.&quot; If this is truly systematic, wouldn't there be a low-low condition, in a factorial design fashion? Essentially, the current study has H(perceptual uncertainty)-H(reward uncertainty), L(perceptual uncertainty)-H(reward uncertainty), H(perceptual uncertainty)-L(reward uncertainty), but naturally, one would anticipate a L-L condition. It could be argued that the L-L condition may seem too easy, causing a ceiling effect, but it nonetheless provides a benchmark for baseline learning when everting is not ambiguous. Unless the authors would love to, I am not asking the authors to run additional experiments to include all these 4 conditions. But it would be helpful to justify their initial choice of why a L-L condition was not included.</p>
<p>(1b) I feel there are certain degrees of imbalance regarding the levels of uncertainty. For reward uncertainty, {0.9, 0.1} is low uncertainty, and {0.7, 0.3} is uncertainty, whereas for perceptual uncertainty, the levels of differences in contrasts of the Gabor stimuli are much higher. This means the design appears to be more sensitive to detect any effect that can be caused by perceptual uncertainty (as there is sufficient variation) than reward uncertainty. Again, I am not asking the authors to run additional experiments, but it would be very helpful if they can explain/justify the choice of experimental set up and specification.</p>
<p>(2) Statistical Analysis:</p>
<p>(2a) There is some inconsistency regarding the stats used. For all the comparisons across the three conditions, sometimes an F-test is used followed by a series of t-tests (eg. page 6), but in other places, only pair-wise t-tests were reported without an F-test (eg, page 12). It would be helpful, for all of them, to have an F-test first, and then three t-tests. And for the F-test, I assume it was one-way ANOVA? This info was not explicit in the Methods. Also, what multiple comparison corrections were used, or whether it was used at all?</p>
<p>(2b) Regarding normative modeling, I am aware that this is a pure simulation without model fitting, but it loses the close relationship between the data and model without model fitting. I wonder if model fitting can be done at all. As it stands, there is even no qualitative evidence regarding how well the model could explain the data (eg, by adding real data to Figure 3e). In other words, now that it is a normative model, it is no surprise that it works, but it is not known if it works to account for human data. As a side note, I appreciate that certain groups of researchers tend not to run model estimation; instead, model simulations are used to qualitatively compare the model and data. This is particularly true for &quot;normative models&quot;. But at least in the current case, I believe model estimation can be implemented, and will provide mode insights.</p>
<p>(2c) Relatedly, regarding specific results shown in Figure 4b - the normative agent has a near-zero effect on the fixed learning rate. I do not find these results surprising, because since the normative agent &quot;knows&quot; what is going to happen, and which state the agent is in, there is no need to update the prediction error in the classic Q-learning fashion. But humans, on the other hand, do NOT know the environment, hence they do not know what they are supposed to do, like the model. In essence, the model knows more than the humans in the task know. We can leave this to debate, but I believe most cognitive modelers would agree that the model should not know more than humans know. I think it would be helpful if the authors could discuss the advantages and disadvantages of using normative models in this case.</p>
<p>(2d) I find the results in Figure 5 interesting. But given the dependent variable is identical across the three correlations (ie, absolute estimation error), I would suggest the authors put all three predicters into a single multiple regression. This way, shared variance, if any, could also be taken into account by the model.</p>
<p>(2e) I feel the focus on testing H2 is somewhat too less on H1. The authors did a series of analyses on testing and supporting H1, but then only briefly on H2. On first reading, I wondered why not having a normative model also tests the effect of salience, but actually, salience is indeed included in the model (buried in the methods). I am curious to know whether analyzing the salience-related parameter (beta_4) would also support H2.</p>
</body>
</sub-article>
</article>